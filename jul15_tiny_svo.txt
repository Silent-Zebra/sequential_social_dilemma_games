/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Process STDOUT and STDERR is being redirected to /tmp/ray/session_2020-07-15_19-33-00_22459/logs.
Waiting for redis server at 127.0.0.1:51615 to respond...
Waiting for redis server at 127.0.0.1:25469 to respond...
Warning: Capping object memory store to 20.0GB. To increase this further, specify `object_store_memory` when calling ray.init() or ray start.
Starting the Plasma object store with 20.0 GB memory using /dev/shm.

======================================================================
View the web UI at http://localhost:8888/notebooks/ray_ui.ipynb?token=3d28abfa6ff684d018fabd5514bf7875e1d408f12ee8f92f
======================================================================

Commencing experiment harvest_A3C
{'monitor': False, 'log_level': 'INFO', 'callbacks': {'on_episode_start': <ray.tune.suggest.variant_generator.function object at 0x7fe9326f3668>, 'on_episode_end': <ray.tune.suggest.variant_generator.function object at 0x7fe93073d1d0>}, 'model': {'custom_model': 'conv_to_fc_net', 'use_lstm': True, 'lstm_cell_size': 128}, 'optimizer': {}, 'gamma': 0.99, 'horizon': 1000, 'env_config': {'func_create': <ray.tune.suggest.variant_generator.function object at 0x7fe932691278>, 'env_name': 'harvest_env', 'run': 'A3C'}, 'env': None, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'num_workers': 2, 'num_gpus': 0, 'num_cpus_per_worker': 0.5, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'num_envs_per_worker': 1, 'sample_batch_size': 10, 'train_batch_size': 30000, 'batch_mode': 'truncate_episodes', 'sample_async': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_evaluator_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'input': 'sampler', 'input_evaluation': None, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policy_graphs': {}, 'policy_mapping_fn': None, 'policies_to_train': None}, 'use_pytorch': False, 'lambda': 1.0, 'grad_clip': 40.0, 'lr': 0.0001, 'lr_schedule': [[0, 0.00136], [20000000, 2.8e-05]], 'vf_loss_coeff': 0.5, 'entropy_coeff': -0.000687, 'min_iter_time_s': 5}
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.1/202.5 GB

Created LogSyncer for /h/zhaostep/ray_results/harvest_A3C/A3C_harvest_env_0_2020-07-15_19-33-014wu7gycq -> 
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING

/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-15 19:33:13,585	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 0 on CPU (please ignore any CUDA init errors)
2020-07-15 19:33:13.585876: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-15 19:33:24,996	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 1 on CPU (please ignore any CUDA init errors)
2020-07-15 19:33:24.998097: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-15 19:33:25,071	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 2 on CPU (please ignore any CUDA init errors)
2020-07-15 19:33:25.072638: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-33-36
  done: false
  episode_len_mean: .nan
  episode_reward_max: .nan
  episode_reward_mean: .nan
  episode_reward_min: .nan
  episodes_this_iter: 0
  episodes_total: 0
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 4.02
    dispatch_time_ms: 9.401
    learner:
      cur_lr: 0.0013599999947473407
      grad_gnorm: 40.000003814697266
      policy_entropy: 67.3991928100586
      policy_loss: -4385.552734375
      var_gnorm: 18.29357147216797
      vf_explained_var: -0.00019156932830810547
      vf_loss: 449834.875
    num_steps_sampled: 5000
    num_steps_trained: 5000
    wait_time_ms: 72.221
  iterations_since_restore: 1
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 21.685678720474243
  time_this_iter_s: 21.685678720474243
  time_total_s: 21.685678720474243
  timestamp: 1594856016
  timesteps_since_restore: 5000
  timesteps_this_iter: 5000
  timesteps_total: 5000
  training_iteration: 1
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 21 s, 1 iter, 5000 ts, nan rew

[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
agent-1: -20583.291734694016
agent-2: -10701.003407104876
agent-3: -34932.27376149635
agent-4: -31454.70509326523
agent-5: -36124.097875710475
Extrinsic Rewards:
-20430
-10608
-34751
-31292
-35958
Sum Reward: -133039
Avg Reward: -26607.8
Min Reward: -35958
Max Reward: -10608
Gini Coefficient: -0.19549455422845932
20:20 Ratio: 0.2950108459869848
Max-min Ratio: 0.2950108459869848
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-33-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -133795.3718722709
  episode_reward_mean: -133795.3718722709
  episode_reward_min: -133795.3718722709
  episodes_this_iter: 1
  episodes_total: 1
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.535
    dispatch_time_ms: 6.738
    learner:
      cur_lr: 0.0013596670469269156
      grad_gnorm: 40.0
      policy_entropy: 20.67997169494629
      policy_loss: -4890.15966796875
      var_gnorm: 18.48178482055664
      vf_explained_var: -7.998943328857422e-05
      vf_loss: 5241793.0
    num_steps_sampled: 10000
    num_steps_trained: 10000
    wait_time_ms: 80.464
  iterations_since_restore: 2
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 30.59681224822998
  time_this_iter_s: 8.911133527755737
  time_total_s: 30.59681224822998
  timestamp: 1594856025
  timesteps_since_restore: 10000
  timesteps_this_iter: 5000
  timesteps_total: 10000
  training_iteration: 2
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 30 s, 2 iter, 10000 ts, -1.34e+05 rew

[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
agent-1: -27561.903768208547
agent-2: -26075.154166648186
agent-3: -8647.753512524947
agent-4: -27089.86319148704
agent-5: -20722.55372813443
Extrinsic Rewards:
-27391
-25921
-8550
-26917
-20581
Sum Reward: -109360
Avg Reward: -21872.0
Min Reward: -27391
Max Reward: -8550
Gini Coefficient: -0.1610021945866862
20:20 Ratio: 0.31214632543536197
Max-min Ratio: 0.31214632543536197
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-33-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -110097.22836700326
  episode_reward_mean: -121946.30011963708
  episode_reward_min: -133795.3718722709
  episodes_this_iter: 1
  episodes_total: 2
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.117
    dispatch_time_ms: 10.699
    learner:
      cur_lr: 0.0013593339826911688
      grad_gnorm: 40.0
      policy_entropy: 6.151943206787109
      policy_loss: -55.60820388793945
      var_gnorm: 18.775806427001953
      vf_explained_var: 0.0
      vf_loss: 465600.78125
    num_steps_sampled: 15000
    num_steps_trained: 15000
    wait_time_ms: 71.948
  iterations_since_restore: 3
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 39.26513981819153
  time_this_iter_s: 8.668327569961548
  time_total_s: 39.26513981819153
  timestamp: 1594856034
  timesteps_since_restore: 15000
  timesteps_this_iter: 5000
  timesteps_total: 15000
  training_iteration: 3
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 39 s, 3 iter, 15000 ts, -1.22e+05 rew

agent-1: -37368.3431015665
agent-2: -16229.501959525836
agent-3: -41249.13077851012
agent-4: -63556.03953477979
agent-5: -20212.437170197973
Extrinsic Rewards:
-37241
-16163
-41089
-63332
-20104
Sum Reward: -177929
Avg Reward: -35585.8
Min Reward: -63332
Max Reward: -16163
Gini Coefficient: -0.2592562201777113
20:20 Ratio: 0.2552106360133898
Max-min Ratio: 0.2552106360133898
agent-1: -50701.153398075774
agent-2: -47553.93804610939
agent-3: -12161.601695841799
agent-4: -27722.227817223942
agent-5: -11310.600942707071
Extrinsic Rewards:
-50506
-47352
-12093
-27592
-11244
Sum Reward: -148787
Avg Reward: -29757.4
Min Reward: -50506
Max Reward: -11244
Gini Coefficient: -0.305895004267846
20:20 Ratio: 0.22262701461212528
Max-min Ratio: 0.22262701461212528
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-34-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -110097.22836700326
  episode_reward_mean: -142989.3936709531
  episode_reward_min: -178615.45254458045
  episodes_this_iter: 2
  episodes_total: 4
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.643
    dispatch_time_ms: 6.938
    learner:
      cur_lr: 0.0013590010348707438
      grad_gnorm: 40.000003814697266
      policy_entropy: 3.1838865280151367
      policy_loss: -74.19401550292969
      var_gnorm: 19.110950469970703
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 2310502.0
    num_steps_sampled: 20000
    num_steps_trained: 20000
    wait_time_ms: 71.898
  iterations_since_restore: 4
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 47.85115909576416
  time_this_iter_s: 8.586019277572632
  time_total_s: 47.85115909576416
  timestamp: 1594856042
  timesteps_since_restore: 20000
  timesteps_this_iter: 5000
  timesteps_total: 20000
  training_iteration: 4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 47 s, 4 iter, 20000 ts, -1.43e+05 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-34-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -110097.22836700326
  episode_reward_mean: -142989.3936709531
  episode_reward_min: -178615.45254458045
  episodes_this_iter: 0
  episodes_total: 4
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.878
    dispatch_time_ms: 9.3
    learner:
      cur_lr: 0.0013586679706349969
      grad_gnorm: 40.000003814697266
      policy_entropy: 3.0398035049438477
      policy_loss: -67.14139556884766
      var_gnorm: 19.5363826751709
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 2282699.75
    num_steps_sampled: 25000
    num_steps_trained: 25000
    wait_time_ms: 75.803
  iterations_since_restore: 5
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 56.44477701187134
  time_this_iter_s: 8.593617916107178
  time_total_s: 56.44477701187134
  timestamp: 1594856051
  timesteps_since_restore: 25000
  timesteps_this_iter: 5000
  timesteps_total: 25000
  training_iteration: 5
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 56 s, 5 iter, 25000 ts, -1.43e+05 rew

agent-1: -26470.238282497477
agent-2: -22640.659173577544
agent-3: -34385.72907745526
agent-4: -2970.1909259837203
agent-5: -45751.74553971721
Extrinsic Rewards:
-26341
-22543
-34232
-2945
-45539
Sum Reward: -131600
Avg Reward: -26320.0
Min Reward: -45539
Max Reward: -2945
Gini Coefficient: -0.29445896656534953
20:20 Ratio: 0.06466984343090537
Max-min Ratio: 0.06466984343090537
agent-1: -50477.25202042138
agent-2: -86831.26698928526
agent-3: -24514.703905866118
agent-4: -14068.698389036932
agent-5: -26251.155022749866
Extrinsic Rewards:
-50291
-86591
-24434
-14031
-26146
Sum Reward: -201493
Avg Reward: -40298.6
Min Reward: -86591
Max Reward: -14031
Gini Coefficient: -0.339420227997995
20:20 Ratio: 0.1620376251573489
Max-min Ratio: 0.1620376251573489
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-34-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -110097.22836700326
  episode_reward_mean: -151053.20233506724
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 2
  episodes_total: 6
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.785
    dispatch_time_ms: 11.089
    learner:
      cur_lr: 0.0013583350228145719
      grad_gnorm: 40.0
      policy_entropy: 4.387133598327637
      policy_loss: -125.72857666015625
      var_gnorm: 20.00286865234375
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 3322649.25
    num_steps_sampled: 30000
    num_steps_trained: 30000
    wait_time_ms: 73.442
  iterations_since_restore: 6
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 65.10553884506226
  time_this_iter_s: 8.660761833190918
  time_total_s: 65.10553884506226
  timestamp: 1594856060
  timesteps_since_restore: 30000
  timesteps_this_iter: 5000
  timesteps_total: 30000
  training_iteration: 6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 65 s, 6 iter, 30000 ts, -1.51e+05 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-34-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -110097.22836700326
  episode_reward_mean: -151053.20233506724
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 0
  episodes_total: 6
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.626
    dispatch_time_ms: 8.986
    learner:
      cur_lr: 0.001358001958578825
      grad_gnorm: 40.0
      policy_entropy: 10.027946472167969
      policy_loss: -112.65801239013672
      var_gnorm: 20.538959503173828
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 457963.25
    num_steps_sampled: 35000
    num_steps_trained: 35000
    wait_time_ms: 73.754
  iterations_since_restore: 7
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 73.79231357574463
  time_this_iter_s: 8.686774730682373
  time_total_s: 73.79231357574463
  timestamp: 1594856068
  timesteps_since_restore: 35000
  timesteps_this_iter: 5000
  timesteps_total: 35000
  training_iteration: 7
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 11.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 73 s, 7 iter, 35000 ts, -1.51e+05 rew

agent-1: -20395.606063575757
agent-2: -18291.203571285074
agent-3: -7364.569252015789
agent-4: -33485.2275589797
agent-5: -31252.56683077665
Extrinsic Rewards:
-20270
-18176
-7312
-33311
-31069
Sum Reward: -110138
Avg Reward: -22027.6
Min Reward: -33311
Max Reward: -7312
Gini Coefficient: -0.2356716119777007
20:20 Ratio: 0.2195070697367236
Max-min Ratio: 0.2195070697367236
agent-1: -3761.3631893326374
agent-2: -21415.64230573103
agent-3: -22150.39130751886
agent-4: -9340.303134487654
agent-5: -16126.660158942768
Extrinsic Rewards:
-3715
-21264
-21969
-9270
-16021
Sum Reward: -72239
Avg Reward: -14447.8
Min Reward: -21969
Max Reward: -3715
Gini Coefficient: -0.26856407203864946
20:20 Ratio: 0.1691019163366562
Max-min Ratio: 0.1691019163366562
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-34-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -72794.36009601272
  episode_reward_mean: -136237.84342288112
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 2
  episodes_total: 8
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.944
    dispatch_time_ms: 9.811
    learner:
      cur_lr: 0.0013576690107584
      grad_gnorm: 40.000003814697266
      policy_entropy: 8.709466934204102
      policy_loss: 287.2826232910156
      var_gnorm: 21.113361358642578
      vf_explained_var: 0.0
      vf_loss: 864429.5
    num_steps_sampled: 40000
    num_steps_trained: 40000
    wait_time_ms: 74.584
  iterations_since_restore: 8
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 82.35712814331055
  time_this_iter_s: 8.564814567565918
  time_total_s: 82.35712814331055
  timestamp: 1594856077
  timesteps_since_restore: 40000
  timesteps_this_iter: 5000
  timesteps_total: 40000
  training_iteration: 8
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 11.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 82 s, 8 iter, 40000 ts, -1.36e+05 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-34-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -72794.36009601272
  episode_reward_mean: -136237.84342288112
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 0
  episodes_total: 8
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.467
    dispatch_time_ms: 13.677
    learner:
      cur_lr: 0.001357335946522653
      grad_gnorm: 39.99999237060547
      policy_entropy: 27.326393127441406
      policy_loss: 20.096635818481445
      var_gnorm: 21.583526611328125
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 3281.3046875
    num_steps_sampled: 45000
    num_steps_trained: 45000
    wait_time_ms: 64.256
  iterations_since_restore: 9
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 90.48100304603577
  time_this_iter_s: 8.12387490272522
  time_total_s: 90.48100304603577
  timestamp: 1594856085
  timesteps_since_restore: 45000
  timesteps_this_iter: 5000
  timesteps_total: 45000
  training_iteration: 9
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 11.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 90 s, 9 iter, 45000 ts, -1.36e+05 rew

agent-1: -11479.517122127916
agent-2: -17681.927449157924
agent-3: -12613.753798986676
agent-4: -7237.801239944798
agent-5: -8034.631655558134
Extrinsic Rewards:
-11325
-17493
-12457
-7155
-7898
Sum Reward: -56328
Avg Reward: -11265.6
Min Reward: -17493
Max Reward: -7155
Gini Coefficient: -0.1792003976707854
20:20 Ratio: 0.4090207511576059
Max-min Ratio: 0.4090207511576059
agent-1: -14394.853529994427
agent-2: -14007.68754226559
agent-3: -7171.206485017096
agent-4: -5536.653610760375
agent-5: -4443.221688981407
Extrinsic Rewards:
-14186
-13813
-7045
-5452
-4359
Sum Reward: -44855
Avg Reward: -8971.0
Min Reward: -14186
Max Reward: -4359
Gini Coefficient: -0.24982722104559135
20:20 Ratio: 0.3072747779500916
Max-min Ratio: 0.3072747779500916
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-34-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -45553.62285701899
  episode_reward_mean: -119250.40015058436
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 2
  episodes_total: 10
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.148
    dispatch_time_ms: 9.086
    learner:
      cur_lr: 0.001357002998702228
      grad_gnorm: 40.0
      policy_entropy: 52.981754302978516
      policy_loss: -743.8760375976562
      var_gnorm: 22.152820587158203
      vf_explained_var: 0.0
      vf_loss: 383265.09375
    num_steps_sampled: 50000
    num_steps_trained: 50000
    wait_time_ms: 75.829
  iterations_since_restore: 10
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 98.73155045509338
  time_this_iter_s: 8.250547409057617
  time_total_s: 98.73155045509338
  timestamp: 1594856093
  timesteps_since_restore: 50000
  timesteps_this_iter: 5000
  timesteps_total: 50000
  training_iteration: 10
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 11.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 98 s, 10 iter, 50000 ts, -1.19e+05 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-35-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -45553.62285701899
  episode_reward_mean: -119250.40015058438
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 0
  episodes_total: 10
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.552
    dispatch_time_ms: 10.335
    learner:
      cur_lr: 0.001356670050881803
      grad_gnorm: 40.0
      policy_entropy: 25.44554328918457
      policy_loss: -1589.869140625
      var_gnorm: 22.8197078704834
      vf_explained_var: 0.0
      vf_loss: 2903792.0
    num_steps_sampled: 55000
    num_steps_trained: 55000
    wait_time_ms: 72.592
  iterations_since_restore: 11
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 107.26075148582458
  time_this_iter_s: 8.529201030731201
  time_total_s: 107.26075148582458
  timestamp: 1594856102
  timesteps_since_restore: 55000
  timesteps_this_iter: 5000
  timesteps_total: 55000
  training_iteration: 11
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 11.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 107 s, 11 iter, 55000 ts, -1.19e+05 rew

agent-1: -26380.468606387778
agent-2: -23583.717364763386
agent-3: -26962.221386267516
agent-4: -27803.77962355154
agent-5: -26729.71307955192
Extrinsic Rewards:
-26229
-23449
-26811
-27651
-26579
Sum Reward: -130719
Avg Reward: -26143.8
Min Reward: -27651
Max Reward: -23449
Gini Coefficient: -0.02749715037599737
20:20 Ratio: 0.8480344291345702
Max-min Ratio: 0.8480344291345702
agent-1: -10135.71281854473
agent-2: -33810.536653827425
agent-3: -28292.503843621373
agent-4: -13810.965830289664
agent-5: -29083.992038879813
Extrinsic Rewards:
-10055
-33614
-28123
-13725
-28916
Sum Reward: -114433
Avg Reward: -22886.6
Min Reward: -33614
Max Reward: -10055
Gini Coefficient: -0.2178008092071343
20:20 Ratio: 0.2991313143333135
Max-min Ratio: 0.2991313143333135
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-35-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -45553.62285701899
  episode_reward_mean: -119924.80106262736
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 2
  episodes_total: 12
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.87
    dispatch_time_ms: 8.127
    learner:
      cur_lr: 0.0013563369866460562
      grad_gnorm: 40.000003814697266
      policy_entropy: 27.982358932495117
      policy_loss: -4983.31005859375
      var_gnorm: 23.516122817993164
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1939632.875
    num_steps_sampled: 60000
    num_steps_trained: 60000
    wait_time_ms: 74.516
  iterations_since_restore: 12
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 115.85896682739258
  time_this_iter_s: 8.598215341567993
  time_total_s: 115.85896682739258
  timestamp: 1594856111
  timesteps_since_restore: 60000
  timesteps_this_iter: 5000
  timesteps_total: 60000
  training_iteration: 12
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 11.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 115 s, 12 iter, 60000 ts, -1.2e+05 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-35-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -45553.62285701899
  episode_reward_mean: -119924.80106262739
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 0
  episodes_total: 12
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.668
    dispatch_time_ms: 8.754
    learner:
      cur_lr: 0.0013560040388256311
      grad_gnorm: 40.0
      policy_entropy: 33.34608459472656
      policy_loss: -8676.76953125
      var_gnorm: 24.26448631286621
      vf_explained_var: 0.0
      vf_loss: 1941768.125
    num_steps_sampled: 65000
    num_steps_trained: 65000
    wait_time_ms: 72.774
  iterations_since_restore: 13
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 124.22906017303467
  time_this_iter_s: 8.37009334564209
  time_total_s: 124.22906017303467
  timestamp: 1594856119
  timesteps_since_restore: 65000
  timesteps_this_iter: 5000
  timesteps_total: 65000
  training_iteration: 13
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 11.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 124 s, 13 iter, 65000 ts, -1.2e+05 rew

agent-1: -9642.821178276634
agent-2: -14828.774198228979
agent-3: -23175.878489623403
agent-4: -13147.51337455049
agent-5: -23949.595397307545
Extrinsic Rewards:
-9548
-14691
-23000
-13018
-23759
Sum Reward: -84016
Avg Reward: -16803.2
Min Reward: -23759
Max Reward: -9548
Gini Coefficient: -0.18284136354980005
20:20 Ratio: 0.4018687655204344
Max-min Ratio: 0.4018687655204344
agent-1: -20872.820587684986
agent-2: -18187.840786881465
agent-3: -17736.83213715993
agent-4: -17332.53002463069
agent-5: -26393.87362772718
Extrinsic Rewards:
-20715
-18055
-17596
-17191
-26211
Sum Reward: -99768
Avg Reward: -19953.6
Min Reward: -26211
Max Reward: -17191
Gini Coefficient: -0.08483281212412798
20:20 Ratio: 0.6558696730380374
Max-min Ratio: 0.6558696730380374
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-35-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -45553.62285701899
  episode_reward_mean: -116026.1494681143
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 2
  episodes_total: 14
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.662
    dispatch_time_ms: 9.598
    learner:
      cur_lr: 0.0013556709745898843
      grad_gnorm: 40.0
      policy_entropy: 57.70283508300781
      policy_loss: 4775.9345703125
      var_gnorm: 24.997962951660156
      vf_explained_var: 0.0
      vf_loss: 340429.75
    num_steps_sampled: 70000
    num_steps_trained: 70000
    wait_time_ms: 75.115
  iterations_since_restore: 14
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 132.65564823150635
  time_this_iter_s: 8.42658805847168
  time_total_s: 132.65564823150635
  timestamp: 1594856127
  timesteps_since_restore: 70000
  timesteps_this_iter: 5000
  timesteps_total: 70000
  training_iteration: 14
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 11.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 132 s, 14 iter, 70000 ts, -1.16e+05 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-35-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -45553.62285701899
  episode_reward_mean: -116026.1494681143
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 0
  episodes_total: 14
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.467
    dispatch_time_ms: 7.503
    learner:
      cur_lr: 0.0013553380267694592
      grad_gnorm: 40.0
      policy_entropy: 47.00129699707031
      policy_loss: -371.7310485839844
      var_gnorm: 25.64627456665039
      vf_explained_var: 2.4437904357910156e-06
      vf_loss: 13249.1669921875
    num_steps_sampled: 75000
    num_steps_trained: 75000
    wait_time_ms: 75.852
  iterations_since_restore: 15
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 141.08916974067688
  time_this_iter_s: 8.433521509170532
  time_total_s: 141.08916974067688
  timestamp: 1594856136
  timesteps_since_restore: 75000
  timesteps_this_iter: 5000
  timesteps_total: 75000
  training_iteration: 15
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 12.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 141 s, 15 iter, 75000 ts, -1.16e+05 rew

agent-1: -6740.392158640493
agent-2: -10203.674222530992
agent-3: -9781.596307065956
agent-4: -10911.306915120302
agent-5: -6754.939363811059
Extrinsic Rewards:
-6616
-10033
-9630
-10735
-6632
Sum Reward: -43646
Avg Reward: -8729.2
Min Reward: -10735
Max Reward: -6616
Gini Coefficient: -0.10666727764285387
20:20 Ratio: 0.616301816488123
Max-min Ratio: 0.616301816488123
agent-1: -5555.508011393848
agent-2: -6770.975627405281
agent-3: -6841.815410529175
agent-4: -5534.368000658439
agent-5: -3965.8558629028807
Extrinsic Rewards:
-5404
-6587
-6722
-5369
-3858
Sum Reward: -27940
Avg Reward: -5588.0
Min Reward: -6722
Max Reward: -3858
Gini Coefficient: -0.09944166070150322
20:20 Ratio: 0.5739363284736686
Max-min Ratio: 0.5739363284736686
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-35-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -28668.5229128898
  episode_reward_mean: -106089.15777710365
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 2
  episodes_total: 16
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.976
    dispatch_time_ms: 8.093
    learner:
      cur_lr: 0.0013550049625337124
      grad_gnorm: 40.0
      policy_entropy: 38.85231018066406
      policy_loss: 5817.63623046875
      var_gnorm: 25.695072174072266
      vf_explained_var: -1.5735626220703125e-05
      vf_loss: 515585.9375
    num_steps_sampled: 80000
    num_steps_trained: 80000
    wait_time_ms: 74.861
  iterations_since_restore: 16
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 149.44279861450195
  time_this_iter_s: 8.353628873825073
  time_total_s: 149.44279861450195
  timestamp: 1594856144
  timesteps_since_restore: 80000
  timesteps_this_iter: 5000
  timesteps_total: 80000
  training_iteration: 16
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 12.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 149 s, 16 iter, 80000 ts, -1.06e+05 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-35-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -28668.5229128898
  episode_reward_mean: -106089.15777710367
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 0
  episodes_total: 16
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.125
    dispatch_time_ms: 8.155
    learner:
      cur_lr: 0.0013546720147132874
      grad_gnorm: 40.0000114440918
      policy_entropy: 59.32669448852539
      policy_loss: -657.1637573242188
      var_gnorm: 25.9776611328125
      vf_explained_var: 0.010878443717956543
      vf_loss: 39498.625
    num_steps_sampled: 85000
    num_steps_trained: 85000
    wait_time_ms: 69.614
  iterations_since_restore: 17
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 157.39557600021362
  time_this_iter_s: 7.95277738571167
  time_total_s: 157.39557600021362
  timestamp: 1594856152
  timesteps_since_restore: 85000
  timesteps_this_iter: 5000
  timesteps_total: 85000
  training_iteration: 17
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 12.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 157 s, 17 iter, 85000 ts, -1.06e+05 rew

agent-1: -1174.6627639487904
agent-2: -1185.8834057014458
agent-3: -946.1016159613368
agent-4: -750.2499175717734
agent-5: -738.3530202627827
Extrinsic Rewards:
-993
-1005
-819
-520
-633
Sum Reward: -3970
Avg Reward: -794.0
Min Reward: -1005
Max Reward: -520
Gini Coefficient: -0.1340050377833753
20:20 Ratio: 0.5174129353233831
Max-min Ratio: 0.5174129353233831
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-36-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4795.250723446154
  episode_reward_mean: -100130.69265630028
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 17
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.83
    dispatch_time_ms: 10.532
    learner:
      cur_lr: 0.0013543389504775405
      grad_gnorm: 40.0
      policy_entropy: 66.74799346923828
      policy_loss: 224.7180633544922
      var_gnorm: 26.13995361328125
      vf_explained_var: -0.6026862859725952
      vf_loss: 407.9569396972656
    num_steps_sampled: 90000
    num_steps_trained: 90000
    wait_time_ms: 69.619
  iterations_since_restore: 18
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 165.56075882911682
  time_this_iter_s: 8.165182828903198
  time_total_s: 165.56075882911682
  timestamp: 1594856160
  timesteps_since_restore: 90000
  timesteps_this_iter: 5000
  timesteps_total: 90000
  training_iteration: 18
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 12.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 165 s, 18 iter, 90000 ts, -1e+05 rew

agent-1: -1598.2946237931471
agent-2: -1743.3856629655868
agent-3: -1000.501561616644
agent-4: -1462.6940938287044
agent-5: -851.2129420021738
Extrinsic Rewards:
-1424
-1573
-874
-1319
-722
Sum Reward: -5912
Avg Reward: -1182.4
Min Reward: -1573
Max Reward: -722
Gini Coefficient: -0.1523680649526387
20:20 Ratio: 0.4589955499046408
Max-min Ratio: 0.4589955499046408
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-36-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4795.250723446154
  episode_reward_mean: -94937.65911340617
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 18
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.006
    dispatch_time_ms: 8.924
    learner:
      cur_lr: 0.0013540060026571155
      grad_gnorm: 40.0
      policy_entropy: 76.68529510498047
      policy_loss: 184.9855499267578
      var_gnorm: 26.090299606323242
      vf_explained_var: -5.7220458984375e-06
      vf_loss: 188.09881591796875
    num_steps_sampled: 95000
    num_steps_trained: 95000
    wait_time_ms: 71.643
  iterations_since_restore: 19
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 173.98441553115845
  time_this_iter_s: 8.423656702041626
  time_total_s: 173.98441553115845
  timestamp: 1594856169
  timesteps_since_restore: 95000
  timesteps_this_iter: 5000
  timesteps_total: 95000
  training_iteration: 19
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 12.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 173 s, 19 iter, 95000 ts, -9.49e+04 rew

agent-1: -1002.8239936104811
agent-2: -855.7823041821597
agent-3: -943.5827038051527
agent-4: -783.6692462625766
agent-5: -1278.3969360799906
Extrinsic Rewards:
-862
-719
-812
-661
-1106
Sum Reward: -4160
Avg Reward: -832.0
Min Reward: -1106
Max Reward: -661
Gini Coefficient: -0.09932692307692308
20:20 Ratio: 0.5976491862567812
Max-min Ratio: 0.5976491862567812
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-36-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4795.250723446154
  episode_reward_mean: -90196.95364343427
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 19
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.771
    dispatch_time_ms: 8.57
    learner:
      cur_lr: 0.0013536730548366904
      grad_gnorm: 40.000003814697266
      policy_entropy: 57.77363967895508
      policy_loss: 127.12242889404297
      var_gnorm: 25.860122680664062
      vf_explained_var: -1.0
      vf_loss: 212.0897674560547
    num_steps_sampled: 100000
    num_steps_trained: 100000
    wait_time_ms: 73.664
  iterations_since_restore: 20
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 182.39226818084717
  time_this_iter_s: 8.40785264968872
  time_total_s: 182.39226818084717
  timestamp: 1594856177
  timesteps_since_restore: 100000
  timesteps_this_iter: 5000
  timesteps_total: 100000
  training_iteration: 20
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 12.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 182 s, 20 iter, 100000 ts, -9.02e+04 rew

agent-1: -463.1352390525491
agent-2: -922.311488237507
agent-3: -808.2124213661717
agent-4: -473.36196042595685
agent-5: -677.403981275529
Extrinsic Rewards:
-361
-756
-660
-363
-563
Sum Reward: -2703
Avg Reward: -540.6
Min Reward: -756
Max Reward: -361
Gini Coefficient: -0.1608583055863855
20:20 Ratio: 0.4775132275132275
Max-min Ratio: 0.4775132275132275
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-36-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -3344.4250903576853
  episode_reward_mean: -85854.32721578045
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 20
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.858
    dispatch_time_ms: 9.126
    learner:
      cur_lr: 0.0013533399906009436
      grad_gnorm: 40.000003814697266
      policy_entropy: 36.62187194824219
      policy_loss: 71.41813659667969
      var_gnorm: 25.610332489013672
      vf_explained_var: 0.28351473808288574
      vf_loss: 185.15277099609375
    num_steps_sampled: 105000
    num_steps_trained: 105000
    wait_time_ms: 73.233
  iterations_since_restore: 21
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 190.84525632858276
  time_this_iter_s: 8.452988147735596
  time_total_s: 190.84525632858276
  timestamp: 1594856186
  timesteps_since_restore: 105000
  timesteps_this_iter: 5000
  timesteps_total: 105000
  training_iteration: 21
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 190 s, 21 iter, 105000 ts, -8.59e+04 rew

agent-1: -441.38668720990506
agent-2: -233.03330458318575
agent-3: -261.6761438650487
agent-4: -159.15804009184146
agent-5: -96.67914382595525
Extrinsic Rewards:
-254
-95
-149
-103
-49
Sum Reward: -650
Avg Reward: -130.0
Min Reward: -254
Max Reward: -49
Gini Coefficient: -0.2855384615384615
20:20 Ratio: 0.19291338582677164
Max-min Ratio: 0.19291338582677164
agent-1: -29.97523534649601
agent-2: -347.2886975023419
agent-3: -341.0484996384208
agent-4: -497.7807407436353
agent-5: -450.68070199946277
Extrinsic Rewards:
-6
-196
-154
-350
-198
Sum Reward: -904
Avg Reward: -180.8
Min Reward: -350
Max Reward: -6
Gini Coefficient: -0.3238938053097345
20:20 Ratio: 0.017142857142857144
Max-min Ratio: 0.017142857142857144
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-36-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -1191.933319575927
  episode_reward_mean: -78179.3296141098
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 2
  episodes_total: 22
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.78
    dispatch_time_ms: 8.831
    learner:
      cur_lr: 0.0013530070427805185
      grad_gnorm: 40.0
      policy_entropy: 27.872037887573242
      policy_loss: 367.08074951171875
      var_gnorm: 25.790668487548828
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 8671.9345703125
    num_steps_sampled: 110000
    num_steps_trained: 110000
    wait_time_ms: 71.904
  iterations_since_restore: 22
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 199.2890944480896
  time_this_iter_s: 8.443838119506836
  time_total_s: 199.2890944480896
  timestamp: 1594856194
  timesteps_since_restore: 110000
  timesteps_this_iter: 5000
  timesteps_total: 110000
  training_iteration: 22
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 199 s, 22 iter, 110000 ts, -7.82e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-36-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -1191.933319575927
  episode_reward_mean: -78179.3296141098
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 0
  episodes_total: 22
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 4.034
    dispatch_time_ms: 7.833
    learner:
      cur_lr: 0.0013526739785447717
      grad_gnorm: 40.0
      policy_entropy: 77.89154052734375
      policy_loss: -53.058109283447266
      var_gnorm: 25.844070434570312
      vf_explained_var: -5.960464477539062e-07
      vf_loss: 49.92792892456055
    num_steps_sampled: 115000
    num_steps_trained: 115000
    wait_time_ms: 71.597
  iterations_since_restore: 23
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 207.67232394218445
  time_this_iter_s: 8.383229494094849
  time_total_s: 207.67232394218445
  timestamp: 1594856203
  timesteps_since_restore: 115000
  timesteps_this_iter: 5000
  timesteps_total: 115000
  training_iteration: 23
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 207 s, 23 iter, 115000 ts, -7.82e+04 rew

agent-1: -463.17397458159763
agent-2: -345.36341060424985
agent-3: -399.65861507967134
agent-4: -255.90994644875963
agent-5: -179.37472194148322
Extrinsic Rewards:
-248
-100
-197
-100
-34
Sum Reward: -679
Avg Reward: -135.8
Min Reward: -248
Max Reward: -34
Gini Coefficient: -0.30927835051546393
20:20 Ratio: 0.13709677419354838
Max-min Ratio: 0.13709677419354838
agent-1: -577.6692716108687
agent-2: -328.51886906424437
agent-3: -323.4727418265555
agent-4: -350.9647816719107
agent-5: -298.29146497017774
Extrinsic Rewards:
-346
-198
-150
-45
-143
Sum Reward: -882
Avg Reward: -176.4
Min Reward: -346
Max Reward: -45
Gini Coefficient: -0.2979591836734694
20:20 Ratio: 0.13005780346820808
Max-min Ratio: 0.13005780346820808
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-36-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -1191.933319575927
  episode_reward_mean: -71811.15205450896
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 2
  episodes_total: 24
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.693
    dispatch_time_ms: 10.088
    learner:
      cur_lr: 0.0013523410307243466
      grad_gnorm: 39.999996185302734
      policy_entropy: 72.57823181152344
      policy_loss: 61.498130798339844
      var_gnorm: 25.821447372436523
      vf_explained_var: -0.5808752775192261
      vf_loss: 36.38993453979492
    num_steps_sampled: 120000
    num_steps_trained: 120000
    wait_time_ms: 72.731
  iterations_since_restore: 24
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 216.13620471954346
  time_this_iter_s: 8.463880777359009
  time_total_s: 216.13620471954346
  timestamp: 1594856211
  timesteps_since_restore: 120000
  timesteps_this_iter: 5000
  timesteps_total: 120000
  training_iteration: 24
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 216 s, 24 iter, 120000 ts, -7.18e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-37-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -1191.933319575927
  episode_reward_mean: -71811.15205450896
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 0
  episodes_total: 24
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.505
    dispatch_time_ms: 8.922
    learner:
      cur_lr: 0.0013520079664885998
      grad_gnorm: 39.999996185302734
      policy_entropy: 73.33058166503906
      policy_loss: -26.679096221923828
      var_gnorm: 25.87453269958496
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 52.56789016723633
    num_steps_sampled: 125000
    num_steps_trained: 125000
    wait_time_ms: 70.586
  iterations_since_restore: 25
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 224.45334339141846
  time_this_iter_s: 8.317138671875
  time_total_s: 224.45334339141846
  timestamp: 1594856220
  timesteps_since_restore: 125000
  timesteps_this_iter: 5000
  timesteps_total: 125000
  training_iteration: 25
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 224 s, 25 iter, 125000 ts, -7.18e+04 rew

agent-1: -72.97345579006179
agent-2: -138.28252278526642
agent-3: -503.4984207924052
agent-4: -300.8865599634692
agent-5: -266.50057476394426
Extrinsic Rewards:
17
-41
6
-39
-43
Sum Reward: -100
Avg Reward: -20.0
Min Reward: -43
Max Reward: 17
Gini Coefficient: -0.668
20:20 Ratio: -0.3953488372093023
Max-min Ratio: -0.3953488372093023
agent-1: -317.9075925465997
agent-2: -153.96080425557037
agent-3: -169.99604121595934
agent-4: -86.84479467928125
agent-5: -248.3713026071682
Extrinsic Rewards:
-46
-49
-40
0
1
Sum Reward: -134
Avg Reward: -26.8
Min Reward: -49
Max Reward: 1
Gini Coefficient: -0.43582089552238806
20:20 Ratio: -0.02040816326530612
Max-min Ratio: -0.02040816326530612
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-37-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -1191.933319575927
  episode_reward_mean: -68989.9916336924
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 25
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.922
    dispatch_time_ms: 9.579
    learner:
      cur_lr: 0.0013516750186681747
      grad_gnorm: 39.999996185302734
      policy_entropy: 78.492919921875
      policy_loss: 48.049522399902344
      var_gnorm: 25.879932403564453
      vf_explained_var: -1.0
      vf_loss: 35.55586242675781
    num_steps_sampled: 130000
    num_steps_trained: 130000
    wait_time_ms: 70.056
  iterations_since_restore: 26
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 232.86017513275146
  time_this_iter_s: 8.406831741333008
  time_total_s: 232.86017513275146
  timestamp: 1594856228
  timesteps_since_restore: 130000
  timesteps_this_iter: 5000
  timesteps_total: 130000
  training_iteration: 26
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 232 s, 26 iter, 130000 ts, -6.9e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-37-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -977.0805353045515
  episode_reward_mean: -66374.11043760055
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 26
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.669
    dispatch_time_ms: 9.49
    learner:
      cur_lr: 0.0013513419544324279
      grad_gnorm: 40.0
      policy_entropy: 69.28987121582031
      policy_loss: 28.344999313354492
      var_gnorm: 25.917646408081055
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 9.254691123962402
    num_steps_sampled: 135000
    num_steps_trained: 135000
    wait_time_ms: 68.309
  iterations_since_restore: 27
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 241.10122108459473
  time_this_iter_s: 8.241045951843262
  time_total_s: 241.10122108459473
  timestamp: 1594856236
  timesteps_since_restore: 135000
  timesteps_this_iter: 5000
  timesteps_total: 135000
  training_iteration: 27
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 241 s, 27 iter, 135000 ts, -6.64e+04 rew

agent-1: -215.97697394790418
agent-2: -168.2453485605337
agent-3: -244.27161513295783
agent-4: -311.21863506288776
agent-5: -320.3251706144695
Extrinsic Rewards:
-30
18
25
-72
-33
Sum Reward: -92
Avg Reward: -18.4
Min Reward: -72
Max Reward: 25
Gini Coefficient: -1.065217391304348
20:20 Ratio: -0.3472222222222222
Max-min Ratio: -0.3472222222222222
agent-1: -336.41083162575245
agent-2: -387.97266072528487
agent-3: -207.1386366989137
agent-4: -321.7648556758571
agent-5: -406.73225349822394
Extrinsic Rewards:
-42
-34
-45
16
-88
Sum Reward: -193
Avg Reward: -38.6
Min Reward: -88
Max Reward: 16
Gini Coefficient: -0.4538860103626943
20:20 Ratio: -0.18181818181818182
Max-min Ratio: -0.18181818181818182
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-37-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -977.0805353045515
  episode_reward_mean: -61737.39029854134
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 2
  episodes_total: 28
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.666
    dispatch_time_ms: 8.671
    learner:
      cur_lr: 0.0013510090066120028
      grad_gnorm: 40.0
      policy_entropy: 64.31903076171875
      policy_loss: 1021.431396484375
      var_gnorm: 25.95653533935547
      vf_explained_var: 0.0
      vf_loss: 5069.0107421875
    num_steps_sampled: 140000
    num_steps_trained: 140000
    wait_time_ms: 72.712
  iterations_since_restore: 28
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 249.34081602096558
  time_this_iter_s: 8.23959493637085
  time_total_s: 249.34081602096558
  timestamp: 1594856245
  timesteps_since_restore: 140000
  timesteps_this_iter: 5000
  timesteps_total: 140000
  training_iteration: 28
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 249 s, 28 iter, 140000 ts, -6.17e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-37-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -977.0805353045515
  episode_reward_mean: -61737.39029854134
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 0
  episodes_total: 28
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.311
    dispatch_time_ms: 9.206
    learner:
      cur_lr: 0.001350675942376256
      grad_gnorm: 40.0
      policy_entropy: 72.19886016845703
      policy_loss: -28.79392433166504
      var_gnorm: 25.977550506591797
      vf_explained_var: 0.0
      vf_loss: 46.20862579345703
    num_steps_sampled: 145000
    num_steps_trained: 145000
    wait_time_ms: 72.809
  iterations_since_restore: 29
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 257.6421332359314
  time_this_iter_s: 8.30131721496582
  time_total_s: 257.6421332359314
  timestamp: 1594856253
  timesteps_since_restore: 145000
  timesteps_this_iter: 5000
  timesteps_total: 145000
  training_iteration: 29
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 257 s, 29 iter, 145000 ts, -6.17e+04 rew

agent-1: -482.7485235745573
agent-2: -374.0481748329594
agent-3: -271.26291777953924
agent-4: -114.7740595829534
agent-5: -174.71721204135238
Extrinsic Rewards:
6
-97
-45
10
10
Sum Reward: -116
Avg Reward: -23.2
Min Reward: -97
Max Reward: 10
Gini Coefficient: -0.9275862068965517
20:20 Ratio: -0.10309278350515463
Max-min Ratio: -0.10309278350515463
agent-1: -474.23692606846305
agent-2: -134.10344902434514
agent-3: -443.94758566521665
agent-4: -335.140962461309
agent-5: -260.27289263020316
Extrinsic Rewards:
-147
2
13
4
5
Sum Reward: -123
Avg Reward: -24.6
Min Reward: -147
Max Reward: 13
Gini Coefficient: -1.0504065040650405
20:20 Ratio: -0.08843537414965986
Max-min Ratio: -0.08843537414965986
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-37-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -977.0805353045515
  episode_reward_mean: -57723.73936876061
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 2
  episodes_total: 30
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.804
    dispatch_time_ms: 8.155
    learner:
      cur_lr: 0.001350342994555831
      grad_gnorm: 40.0
      policy_entropy: 64.50675201416016
      policy_loss: 1325.96826171875
      var_gnorm: 26.079212188720703
      vf_explained_var: 2.980232238769531e-07
      vf_loss: 10191.93359375
    num_steps_sampled: 150000
    num_steps_trained: 150000
    wait_time_ms: 73.413
  iterations_since_restore: 30
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 266.06935143470764
  time_this_iter_s: 8.427218198776245
  time_total_s: 266.06935143470764
  timestamp: 1594856261
  timesteps_since_restore: 150000
  timesteps_this_iter: 5000
  timesteps_total: 150000
  training_iteration: 30
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 266 s, 30 iter, 150000 ts, -5.77e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-37-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -977.0805353045515
  episode_reward_mean: -57723.73936876061
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 0
  episodes_total: 30
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.589
    dispatch_time_ms: 11.389
    learner:
      cur_lr: 0.001350010046735406
      grad_gnorm: 40.0
      policy_entropy: 50.46213150024414
      policy_loss: 18.32692527770996
      var_gnorm: 26.009601593017578
      vf_explained_var: 0.0
      vf_loss: 9.687427520751953
    num_steps_sampled: 155000
    num_steps_trained: 155000
    wait_time_ms: 69.998
  iterations_since_restore: 31
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 274.4481158256531
  time_this_iter_s: 8.378764390945435
  time_total_s: 274.4481158256531
  timestamp: 1594856270
  timesteps_since_restore: 155000
  timesteps_this_iter: 5000
  timesteps_total: 155000
  training_iteration: 31
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 274 s, 31 iter, 155000 ts, -5.77e+04 rew

agent-1: -260.6243030776905
agent-2: -473.7691594205874
agent-3: -352.3889879770609
agent-4: -424.7016548174867
agent-5: -95.35364897734348
Extrinsic Rewards:
0
8
0
3
4
Sum Reward: 15
Avg Reward: 3.0
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.5333333333333333
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: -224.0904388043827
agent-2: -114.05628501346112
agent-3: -57.81440293589568
agent-4: -82.57211462523865
agent-5: -137.94963122074844
Extrinsic Rewards:
18
10
11
6
4
Sum Reward: 49
Avg Reward: 9.8
Min Reward: 4
Max Reward: 18
Gini Coefficient: 0.2693877551020408
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-37-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -616.4828725997095
  episode_reward_mean: -54185.48442780275
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 2
  episodes_total: 32
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.002
    dispatch_time_ms: 8.211
    learner:
      cur_lr: 0.001349676982499659
      grad_gnorm: 40.0
      policy_entropy: 40.564876556396484
      policy_loss: 904.7214965820312
      var_gnorm: 26.013771057128906
      vf_explained_var: 0.0
      vf_loss: 8655.431640625
    num_steps_sampled: 160000
    num_steps_trained: 160000
    wait_time_ms: 74.602
  iterations_since_restore: 32
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 282.97342252731323
  time_this_iter_s: 8.525306701660156
  time_total_s: 282.97342252731323
  timestamp: 1594856278
  timesteps_since_restore: 160000
  timesteps_this_iter: 5000
  timesteps_total: 160000
  training_iteration: 32
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 282 s, 32 iter, 160000 ts, -5.42e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-38-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -616.4828725997095
  episode_reward_mean: -54185.48442780276
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 0
  episodes_total: 32
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.126
    dispatch_time_ms: 8.494
    learner:
      cur_lr: 0.001349344034679234
      grad_gnorm: 40.0
      policy_entropy: 55.14607238769531
      policy_loss: -22.329130172729492
      var_gnorm: 25.990751266479492
      vf_explained_var: 0.0
      vf_loss: 31.008081436157227
    num_steps_sampled: 165000
    num_steps_trained: 165000
    wait_time_ms: 73.696
  iterations_since_restore: 33
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 291.1845955848694
  time_this_iter_s: 8.211173057556152
  time_total_s: 291.1845955848694
  timestamp: 1594856287
  timesteps_since_restore: 165000
  timesteps_this_iter: 5000
  timesteps_total: 165000
  training_iteration: 33
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 291 s, 33 iter, 165000 ts, -5.42e+04 rew

agent-1: -139.64533300728073
agent-2: -132.37177308295
agent-3: -146.18740767126917
agent-4: -110.53637549033623
agent-5: -137.47377297567945
Extrinsic Rewards:
-32
30
33
15
30
Sum Reward: 76
Avg Reward: 15.2
Min Reward: -32
Max Reward: 33
Gini Coefficient: 0.7631578947368421
20:20 Ratio: -1.03125
Max-min Ratio: -1.03125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-38-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -616.4828725997095
  episode_reward_mean: -52563.68837430047
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 33
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.758
    dispatch_time_ms: 7.795
    learner:
      cur_lr: 0.0013490109704434872
      grad_gnorm: 40.0
      policy_entropy: 57.11751937866211
      policy_loss: 34.3515625
      var_gnorm: 25.9217586517334
      vf_explained_var: 0.0
      vf_loss: 21.19190788269043
    num_steps_sampled: 170000
    num_steps_trained: 170000
    wait_time_ms: 73.082
  iterations_since_restore: 34
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 299.40863585472107
  time_this_iter_s: 8.224040269851685
  time_total_s: 299.40863585472107
  timestamp: 1594856295
  timesteps_since_restore: 170000
  timesteps_this_iter: 5000
  timesteps_total: 170000
  training_iteration: 34
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 299 s, 34 iter, 170000 ts, -5.26e+04 rew

agent-1: -252.19633276772018
agent-2: -230.999755474709
agent-3: -271.277862521712
agent-4: -272.69799616808496
agent-5: -222.0775554458974
Extrinsic Rewards:
19
-27
-31
-26
-18
Sum Reward: -83
Avg Reward: -16.6
Min Reward: -31
Max Reward: 19
Gini Coefficient: -0.5253012048192771
20:20 Ratio: -0.6129032258064516
Max-min Ratio: -0.6129032258064516
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-38-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -616.4828725997095
  episode_reward_mean: -51054.44017218512
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 34
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.899
    dispatch_time_ms: 9.601
    learner:
      cur_lr: 0.0013486780226230621
      grad_gnorm: 40.0
      policy_entropy: 41.8134880065918
      policy_loss: -69.45265197753906
      var_gnorm: 25.901525497436523
      vf_explained_var: 0.0
      vf_loss: 138.7270050048828
    num_steps_sampled: 175000
    num_steps_trained: 175000
    wait_time_ms: 73.238
  iterations_since_restore: 35
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 307.8769280910492
  time_this_iter_s: 8.468292236328125
  time_total_s: 307.8769280910492
  timestamp: 1594856303
  timesteps_since_restore: 175000
  timesteps_this_iter: 5000
  timesteps_total: 175000
  training_iteration: 35
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 307 s, 35 iter, 175000 ts, -5.11e+04 rew

agent-1: -211.903926508955
agent-2: -423.88802645690623
agent-3: -419.3848428394867
agent-4: -286.36721841570363
agent-5: -102.54431210325046
Extrinsic Rewards:
-47
5
3
-1
6
Sum Reward: -34
Avg Reward: -6.8
Min Reward: -47
Max Reward: 6
Gini Coefficient: -1.3176470588235294
20:20 Ratio: -0.1276595744680851
Max-min Ratio: -0.1276595744680851
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-38-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -616.4828725997095
  episode_reward_mean: -49637.00154801766
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 35
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.888
    dispatch_time_ms: 7.249
    learner:
      cur_lr: 0.0013483449583873153
      grad_gnorm: 22.25041389465332
      policy_entropy: 64.6822509765625
      policy_loss: 5.844690799713135
      var_gnorm: 25.93036651611328
      vf_explained_var: 0.0
      vf_loss: 9.376640319824219
    num_steps_sampled: 180000
    num_steps_trained: 180000
    wait_time_ms: 72.491
  iterations_since_restore: 36
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 316.2481367588043
  time_this_iter_s: 8.371208667755127
  time_total_s: 316.2481367588043
  timestamp: 1594856312
  timesteps_since_restore: 180000
  timesteps_this_iter: 5000
  timesteps_total: 180000
  training_iteration: 36
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 316 s, 36 iter, 180000 ts, -4.96e+04 rew

agent-1: -6.542360892132109
agent-2: -70.62348991270828
agent-3: -159.52043747161576
agent-4: -132.76440917197232
agent-5: -219.37007420565
Extrinsic Rewards:
2
19
12
8
12
Sum Reward: 53
Avg Reward: 10.6
Min Reward: 2
Max Reward: 19
Gini Coefficient: 0.28679245283018867
20:20 Ratio: 9.5
Max-min Ratio: 9.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-38-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -588.8207716540678
  episode_reward_mean: -48274.552082007554
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 36
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.322
    dispatch_time_ms: 9.698
    learner:
      cur_lr: 0.0013480120105668902
      grad_gnorm: 9.489825248718262
      policy_entropy: 56.16959762573242
      policy_loss: 4.487305641174316
      var_gnorm: 25.90414810180664
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 9.638017654418945
    num_steps_sampled: 185000
    num_steps_trained: 185000
    wait_time_ms: 71.432
  iterations_since_restore: 37
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 324.66171002388
  time_this_iter_s: 8.413573265075684
  time_total_s: 324.66171002388
  timestamp: 1594856320
  timesteps_since_restore: 185000
  timesteps_this_iter: 5000
  timesteps_total: 185000
  training_iteration: 37
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 324 s, 37 iter, 185000 ts, -4.83e+04 rew

agent-1: -126.39163987176053
agent-2: -114.03267258765487
agent-3: -111.3132989351499
agent-4: -183.8416224836003
agent-5: -196.07037993278294
Extrinsic Rewards:
2
4
3
6
5
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 2
Max Reward: 6
Gini Coefficient: 0.2
20:20 Ratio: 3.0
Max-min Ratio: 3.0
agent-1: -263.5375833211399
agent-2: -145.5599180430863
agent-3: -145.5599180430863
agent-4: -43.06018054784719
agent-5: -229.80731278556868
Extrinsic Rewards:
11
0
0
1
4
Sum Reward: 16
Avg Reward: 3.2
Min Reward: 0
Max Reward: 11
Gini Coefficient: 0.65
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-38-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -588.8207716540678
  episode_reward_mean: -45774.81709154799
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 2
  episodes_total: 38
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.637
    dispatch_time_ms: 9.599
    learner:
      cur_lr: 0.0013476789463311434
      grad_gnorm: 40.0
      policy_entropy: 65.49756622314453
      policy_loss: 21.95307731628418
      var_gnorm: 25.949758529663086
      vf_explained_var: -0.7342479228973389
      vf_loss: 18.885684967041016
    num_steps_sampled: 190000
    num_steps_trained: 190000
    wait_time_ms: 71.2
  iterations_since_restore: 38
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 333.14041566848755
  time_this_iter_s: 8.478705644607544
  time_total_s: 333.14041566848755
  timestamp: 1594856329
  timesteps_since_restore: 190000
  timesteps_this_iter: 5000
  timesteps_total: 190000
  training_iteration: 38
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 333 s, 38 iter, 190000 ts, -4.58e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-38-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -588.8207716540678
  episode_reward_mean: -45774.81709154799
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 0
  episodes_total: 38
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.241
    dispatch_time_ms: 7.202
    learner:
      cur_lr: 0.0013473459985107183
      grad_gnorm: 40.0
      policy_entropy: 61.20636749267578
      policy_loss: -80.22833251953125
      var_gnorm: 25.953311920166016
      vf_explained_var: 0.0
      vf_loss: 48.75104522705078
    num_steps_sampled: 195000
    num_steps_trained: 195000
    wait_time_ms: 75.468
  iterations_since_restore: 39
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 341.528954744339
  time_this_iter_s: 8.38853907585144
  time_total_s: 341.528954744339
  timestamp: 1594856337
  timesteps_since_restore: 195000
  timesteps_this_iter: 5000
  timesteps_total: 195000
  training_iteration: 39
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 341 s, 39 iter, 195000 ts, -4.58e+04 rew

agent-1: -103.92182295449994
agent-2: -220.88047734735335
agent-3: -55.57161096578356
agent-4: -60.85488458323416
agent-5: -219.6736125067611
Extrinsic Rewards:
4
5
3
2
8
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 2
Max Reward: 8
Gini Coefficient: 0.2545454545454545
20:20 Ratio: 4.0
Max-min Ratio: 4.0
agent-1: -300.2230097768366
agent-2: -288.60996925597993
agent-3: -359.3729510176141
agent-4: -190.34018614888222
agent-5: -309.73793784477806
Extrinsic Rewards:
-49
-47
-49
9
1
Sum Reward: -135
Avg Reward: -27.0
Min Reward: -49
Max Reward: 9
Gini Coefficient: -0.4918518518518519
20:20 Ratio: -0.1836734693877551
Max-min Ratio: -0.1836734693877551
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-39-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -588.8207716540678
  episode_reward_mean: -43538.805898530634
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 2
  episodes_total: 40
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.629
    dispatch_time_ms: 9.623
    learner:
      cur_lr: 0.0013470130506902933
      grad_gnorm: 40.000003814697266
      policy_entropy: 36.24873733520508
      policy_loss: 451.4772033691406
      var_gnorm: 25.942604064941406
      vf_explained_var: 0.0
      vf_loss: 5867.9033203125
    num_steps_sampled: 200000
    num_steps_trained: 200000
    wait_time_ms: 71.904
  iterations_since_restore: 40
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 349.8617205619812
  time_this_iter_s: 8.332765817642212
  time_total_s: 349.8617205619812
  timestamp: 1594856345
  timesteps_since_restore: 200000
  timesteps_this_iter: 5000
  timesteps_total: 200000
  training_iteration: 40
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 349 s, 40 iter, 200000 ts, -4.35e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-39-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -588.8207716540678
  episode_reward_mean: -43538.805898530634
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 0
  episodes_total: 40
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.799
    dispatch_time_ms: 8.249
    learner:
      cur_lr: 0.0013466799864545465
      grad_gnorm: 8.108095169067383
      policy_entropy: 50.32345962524414
      policy_loss: -1.1261918544769287
      var_gnorm: 25.88193702697754
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 10.152366638183594
    num_steps_sampled: 205000
    num_steps_trained: 205000
    wait_time_ms: 71.396
  iterations_since_restore: 41
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 358.0025019645691
  time_this_iter_s: 8.14078140258789
  time_total_s: 358.0025019645691
  timestamp: 1594856354
  timesteps_since_restore: 205000
  timesteps_this_iter: 5000
  timesteps_total: 205000
  training_iteration: 41
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 358 s, 41 iter, 205000 ts, -4.35e+04 rew

agent-1: -201.03681301781825
agent-2: -52.62099050657369
agent-3: -152.3861504395722
agent-4: -74.06472374669318
agent-5: -177.4091418872764
Extrinsic Rewards:
5
11
5
0
13
Sum Reward: 34
Avg Reward: 6.8
Min Reward: 0
Max Reward: 13
Gini Coefficient: 0.3764705882352941
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: -202.2605239777712
agent-2: -173.59955090425004
agent-3: -59.23543812949598
agent-4: -44.29913516797964
agent-5: -67.94160218743677
Extrinsic Rewards:
28
7
5
7
7
Sum Reward: 54
Avg Reward: 10.8
Min Reward: 5
Max Reward: 28
Gini Coefficient: 0.34074074074074073
20:20 Ratio: 5.6
Max-min Ratio: 5.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-39-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -547.3362503669158
  episode_reward_mean: -41494.21642883787
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 2
  episodes_total: 42
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.67
    dispatch_time_ms: 8.087
    learner:
      cur_lr: 0.0013463470386341214
      grad_gnorm: 40.0
      policy_entropy: 55.51515197753906
      policy_loss: 0.055267125368118286
      var_gnorm: 25.898569107055664
      vf_explained_var: -1.0
      vf_loss: 23.369325637817383
    num_steps_sampled: 210000
    num_steps_trained: 210000
    wait_time_ms: 72.363
  iterations_since_restore: 42
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 366.45001125335693
  time_this_iter_s: 8.447509288787842
  time_total_s: 366.45001125335693
  timestamp: 1594856362
  timesteps_since_restore: 210000
  timesteps_this_iter: 5000
  timesteps_total: 210000
  training_iteration: 42
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 366 s, 42 iter, 210000 ts, -4.15e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-39-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -547.3362503669158
  episode_reward_mean: -41494.21642883786
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 0
  episodes_total: 42
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.637
    dispatch_time_ms: 7.128
    learner:
      cur_lr: 0.0013460139743983746
      grad_gnorm: 16.778533935546875
      policy_entropy: 61.761417388916016
      policy_loss: -7.40188455581665
      var_gnorm: 25.8968448638916
      vf_explained_var: 0.0
      vf_loss: 2.5800561904907227
    num_steps_sampled: 215000
    num_steps_trained: 215000
    wait_time_ms: 71.829
  iterations_since_restore: 43
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 374.77743649482727
  time_this_iter_s: 8.327425241470337
  time_total_s: 374.77743649482727
  timestamp: 1594856370
  timesteps_since_restore: 215000
  timesteps_this_iter: 5000
  timesteps_total: 215000
  training_iteration: 43
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 374 s, 43 iter, 215000 ts, -4.15e+04 rew

agent-1: -212.4257458267719
agent-2: -145.39407655032448
agent-3: -110.505062784573
agent-4: -169.39580109566992
agent-5: -229.92407503073275
Extrinsic Rewards:
5
4
4
2
6
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 2
Max Reward: 6
Gini Coefficient: 0.17142857142857143
20:20 Ratio: 3.0
Max-min Ratio: 3.0
agent-1: -310.6346099894208
agent-2: -274.57062568516704
agent-3: -262.5707167155694
agent-4: -305.08832572164766
agent-5: -155.04316084825834
Extrinsic Rewards:
-29
5
7
8
2
Sum Reward: -7
Avg Reward: -1.4
Min Reward: -29
Max Reward: 8
Gini Coefficient: -4.514285714285714
20:20 Ratio: -0.27586206896551724
Max-min Ratio: -0.27586206896551724
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-39-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -547.3362503669158
  episode_reward_mean: -39657.56005025996
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 2
  episodes_total: 44
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.555
    dispatch_time_ms: 7.819
    learner:
      cur_lr: 0.0013456810265779495
      grad_gnorm: 40.0
      policy_entropy: 65.41101837158203
      policy_loss: 961.5103759765625
      var_gnorm: 25.9412784576416
      vf_explained_var: 0.0
      vf_loss: 4526.279296875
    num_steps_sampled: 220000
    num_steps_trained: 220000
    wait_time_ms: 73.706
  iterations_since_restore: 44
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 383.1749954223633
  time_this_iter_s: 8.39755892753601
  time_total_s: 383.1749954223633
  timestamp: 1594856379
  timesteps_since_restore: 220000
  timesteps_this_iter: 5000
  timesteps_total: 220000
  training_iteration: 44
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 383 s, 44 iter, 220000 ts, -3.97e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-39-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -547.3362503669158
  episode_reward_mean: -39657.56005025996
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 0
  episodes_total: 44
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.708
    dispatch_time_ms: 8.087
    learner:
      cur_lr: 0.0013453479623422027
      grad_gnorm: 40.0
      policy_entropy: 62.68062973022461
      policy_loss: -94.65901184082031
      var_gnorm: 25.952585220336914
      vf_explained_var: 0.0
      vf_loss: 82.79717254638672
    num_steps_sampled: 225000
    num_steps_trained: 225000
    wait_time_ms: 75.567
  iterations_since_restore: 45
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 391.6507132053375
  time_this_iter_s: 8.475717782974243
  time_total_s: 391.6507132053375
  timestamp: 1594856387
  timesteps_since_restore: 225000
  timesteps_this_iter: 5000
  timesteps_total: 225000
  training_iteration: 45
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 391 s, 45 iter, 225000 ts, -3.97e+04 rew

agent-1: -242.3139385480709
agent-2: -451.6125400193459
agent-3: -245.78546230868284
agent-4: -461.72625215945675
agent-5: -455.8609161062887
Extrinsic Rewards:
2
6
0
6
10
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 0
Max Reward: 10
Gini Coefficient: 0.4
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: -71.25099024115598
agent-2: -190.971176204549
agent-3: -41.767610352695236
agent-4: -225.105638841949
agent-5: -168.401123303078
Extrinsic Rewards:
1
5
1
6
5
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 1
Max Reward: 6
Gini Coefficient: 0.3111111111111111
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-39-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -547.3362503669158
  episode_reward_mean: -37988.85734477226
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 2
  episodes_total: 46
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.93
    dispatch_time_ms: 8.351
    learner:
      cur_lr: 0.0013450150145217776
      grad_gnorm: 40.0
      policy_entropy: 58.068870544433594
      policy_loss: 24.024150848388672
      var_gnorm: 25.986385345458984
      vf_explained_var: -0.4311407804489136
      vf_loss: 30.854251861572266
    num_steps_sampled: 230000
    num_steps_trained: 230000
    wait_time_ms: 72.021
  iterations_since_restore: 46
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 400.1093764305115
  time_this_iter_s: 8.45866322517395
  time_total_s: 400.1093764305115
  timestamp: 1594856396
  timesteps_since_restore: 230000
  timesteps_this_iter: 5000
  timesteps_total: 230000
  training_iteration: 46
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 400 s, 46 iter, 230000 ts, -3.8e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-40-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -547.3362503669158
  episode_reward_mean: -37988.85734477226
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 0
  episodes_total: 46
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.76
    dispatch_time_ms: 9.469
    learner:
      cur_lr: 0.0013446819502860308
      grad_gnorm: 17.159570693969727
      policy_entropy: 56.5252571105957
      policy_loss: -4.4154863357543945
      var_gnorm: 25.930370330810547
      vf_explained_var: 0.0
      vf_loss: 3.1962177753448486
    num_steps_sampled: 235000
    num_steps_trained: 235000
    wait_time_ms: 72.422
  iterations_since_restore: 47
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 408.492244720459
  time_this_iter_s: 8.38286828994751
  time_total_s: 408.492244720459
  timestamp: 1594856404
  timesteps_since_restore: 235000
  timesteps_this_iter: 5000
  timesteps_total: 235000
  training_iteration: 47
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 408 s, 47 iter, 235000 ts, -3.8e+04 rew

agent-1: -218.28592432588613
agent-2: -114.56659156882836
agent-3: -60.285766731893034
agent-4: -144.36009529942064
agent-5: -106.70080472410149
Extrinsic Rewards:
13
5
5
9
14
Sum Reward: 46
Avg Reward: 9.2
Min Reward: 5
Max Reward: 14
Gini Coefficient: 0.22608695652173913
20:20 Ratio: 2.8
Max-min Ratio: 2.8
agent-1: -142.99212491866095
agent-2: -130.5512346205058
agent-3: -206.13585276272474
agent-4: -216.1934099634856
agent-5: -139.40119638373432
Extrinsic Rewards:
0
1
6
8
2
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.49411764705882355
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-40-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -547.3362503669158
  episode_reward_mean: -36436.81064293381
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 2
  episodes_total: 48
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.76
    dispatch_time_ms: 7.009
    learner:
      cur_lr: 0.0013443490024656057
      grad_gnorm: 40.000003814697266
      policy_entropy: 56.74180603027344
      policy_loss: 30.011917114257812
      var_gnorm: 25.95766258239746
      vf_explained_var: -0.8553346395492554
      vf_loss: 18.42949676513672
    num_steps_sampled: 240000
    num_steps_trained: 240000
    wait_time_ms: 74.558
  iterations_since_restore: 48
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 416.8950445652008
  time_this_iter_s: 8.402799844741821
  time_total_s: 416.8950445652008
  timestamp: 1594856413
  timesteps_since_restore: 240000
  timesteps_this_iter: 5000
  timesteps_total: 240000
  training_iteration: 48
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 416 s, 48 iter, 240000 ts, -3.64e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-40-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -547.3362503669158
  episode_reward_mean: -36436.810642933815
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 0
  episodes_total: 48
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.03
    dispatch_time_ms: 9.332
    learner:
      cur_lr: 0.0013440160546451807
      grad_gnorm: 16.996326446533203
      policy_entropy: 63.523284912109375
      policy_loss: 0.1129499077796936
      var_gnorm: 25.930116653442383
      vf_explained_var: 0.0
      vf_loss: 2.051793098449707
    num_steps_sampled: 245000
    num_steps_trained: 245000
    wait_time_ms: 73.91
  iterations_since_restore: 49
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 425.2562234401703
  time_this_iter_s: 8.361178874969482
  time_total_s: 425.2562234401703
  timestamp: 1594856421
  timesteps_since_restore: 245000
  timesteps_this_iter: 5000
  timesteps_total: 245000
  training_iteration: 49
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 425 s, 49 iter, 245000 ts, -3.64e+04 rew

agent-1: -76.38029419640198
agent-2: -99.6409569643915
agent-3: -187.66087270996903
agent-4: -198.53200821380847
agent-5: -120.15922519824545
Extrinsic Rewards:
10
6
12
12
6
Sum Reward: 46
Avg Reward: 9.2
Min Reward: 6
Max Reward: 12
Gini Coefficient: 0.1565217391304348
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-40-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -547.3362503669158
  episode_reward_mean: -35707.128249349094
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 49
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.092
    dispatch_time_ms: 10.359
    learner:
      cur_lr: 0.0013436829904094338
      grad_gnorm: 4.2316765785217285
      policy_entropy: 62.86690139770508
      policy_loss: 0.8051828145980835
      var_gnorm: 25.927711486816406
      vf_explained_var: 0.0
      vf_loss: 2.0530223846435547
    num_steps_sampled: 250000
    num_steps_trained: 250000
    wait_time_ms: 70.748
  iterations_since_restore: 50
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 433.64231038093567
  time_this_iter_s: 8.38608694076538
  time_total_s: 433.64231038093567
  timestamp: 1594856430
  timesteps_since_restore: 250000
  timesteps_this_iter: 5000
  timesteps_total: 250000
  training_iteration: 50
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 433 s, 50 iter, 250000 ts, -3.57e+04 rew

agent-1: -142.9390212035741
agent-2: -214.82609889737304
agent-3: -144.1192256592579
agent-4: -151.64417430637263
agent-5: -75.30164390465606
Extrinsic Rewards:
4
4
4
2
2
Sum Reward: 16
Avg Reward: 3.2
Min Reward: 2
Max Reward: 4
Gini Coefficient: 0.15
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-40-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -547.3362503669158
  episode_reward_mean: -35007.562287641544
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 50
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.9
    dispatch_time_ms: 10.45
    learner:
      cur_lr: 0.0013433500425890088
      grad_gnorm: 40.0
      policy_entropy: 58.638545989990234
      policy_loss: -35.1044921875
      var_gnorm: 25.93037223815918
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 47.074832916259766
    num_steps_sampled: 255000
    num_steps_trained: 255000
    wait_time_ms: 72.174
  iterations_since_restore: 51
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 442.02016830444336
  time_this_iter_s: 8.37785792350769
  time_total_s: 442.02016830444336
  timestamp: 1594856438
  timesteps_since_restore: 255000
  timesteps_this_iter: 5000
  timesteps_total: 255000
  training_iteration: 51
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 442 s, 51 iter, 255000 ts, -3.5e+04 rew

agent-1: -137.29565332175852
agent-2: -206.45990550147334
agent-3: -162.74498687748772
agent-4: -91.07033358830455
agent-5: -110.33192259343463
Extrinsic Rewards:
9
11
4
3
6
Sum Reward: 33
Avg Reward: 6.6
Min Reward: 3
Max Reward: 11
Gini Coefficient: 0.2545454545454545
20:20 Ratio: 3.6666666666666665
Max-min Ratio: 3.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-40-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -547.3362503669158
  episode_reward_mean: -34335.01994478352
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 51
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.088
    dispatch_time_ms: 9.737
    learner:
      cur_lr: 0.001343016978353262
      grad_gnorm: 40.0
      policy_entropy: 61.831356048583984
      policy_loss: 34.78702163696289
      var_gnorm: 25.976655960083008
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 43.79508590698242
    num_steps_sampled: 260000
    num_steps_trained: 260000
    wait_time_ms: 71.747
  iterations_since_restore: 52
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 450.54749178886414
  time_this_iter_s: 8.527323484420776
  time_total_s: 450.54749178886414
  timestamp: 1594856447
  timesteps_since_restore: 260000
  timesteps_this_iter: 5000
  timesteps_total: 260000
  training_iteration: 52
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 450 s, 52 iter, 260000 ts, -3.43e+04 rew

agent-1: -256.08108128909686
agent-2: -25.231472257339572
agent-3: -241.2444995798392
agent-4: -497.358598754917
agent-5: -229.52225949327095
Extrinsic Rewards:
-36
5
-44
8
-47
Sum Reward: -114
Avg Reward: -22.8
Min Reward: -47
Max Reward: 8
Gini Coefficient: -0.5578947368421052
20:20 Ratio: -0.1702127659574468
Max-min Ratio: -0.1702127659574468
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-40-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -547.3362503669158
  episode_reward_mean: -33698.758751833346
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 52
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.555
    dispatch_time_ms: 8.953
    learner:
      cur_lr: 0.001342684030532837
      grad_gnorm: 40.0
      policy_entropy: 48.55660629272461
      policy_loss: -54.892520904541016
      var_gnorm: 25.996295928955078
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 60.053653717041016
    num_steps_sampled: 265000
    num_steps_trained: 265000
    wait_time_ms: 75.051
  iterations_since_restore: 53
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 458.94219875335693
  time_this_iter_s: 8.394706964492798
  time_total_s: 458.94219875335693
  timestamp: 1594856455
  timesteps_since_restore: 265000
  timesteps_this_iter: 5000
  timesteps_total: 265000
  training_iteration: 53
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 458 s, 53 iter, 265000 ts, -3.37e+04 rew

agent-1: -377.00003502857953
agent-2: -386.1654552199741
agent-3: -403.4090738486743
agent-4: -506.4554047889947
agent-5: -508.60523428316804
Extrinsic Rewards:
7
-41
2
2
3
Sum Reward: -27
Avg Reward: -5.4
Min Reward: -41
Max Reward: 7
Gini Coefficient: -1.4370370370370371
20:20 Ratio: -0.17073170731707318
Max-min Ratio: -0.17073170731707318
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-41-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -547.3362503669158
  episode_reward_mean: -33104.09604336799
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 53
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.117
    dispatch_time_ms: 9.322
    learner:
      cur_lr: 0.00134235096629709
      grad_gnorm: 40.0
      policy_entropy: 50.7066650390625
      policy_loss: 16.73406982421875
      var_gnorm: 26.00979995727539
      vf_explained_var: 0.0
      vf_loss: 23.207082748413086
    num_steps_sampled: 270000
    num_steps_trained: 270000
    wait_time_ms: 71.61
  iterations_since_restore: 54
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 467.3736345767975
  time_this_iter_s: 8.431435823440552
  time_total_s: 467.3736345767975
  timestamp: 1594856463
  timesteps_since_restore: 270000
  timesteps_this_iter: 5000
  timesteps_total: 270000
  training_iteration: 54
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 467 s, 54 iter, 270000 ts, -3.31e+04 rew

agent-1: -69.96555648599636
agent-2: -179.33141772975208
agent-3: -124.53856499101089
agent-4: -213.92546757136077
agent-5: -81.74696546497822
Extrinsic Rewards:
9
5
5
6
5
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 5
Max Reward: 9
Gini Coefficient: 0.12
20:20 Ratio: 1.8
Max-min Ratio: 1.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-41-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -547.3362503669158
  episode_reward_mean: -32503.455523532342
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 54
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 4.033
    dispatch_time_ms: 11.935
    learner:
      cur_lr: 0.001342018018476665
      grad_gnorm: 20.6893367767334
      policy_entropy: 39.44978713989258
      policy_loss: 9.124039649963379
      var_gnorm: 25.931737899780273
      vf_explained_var: 0.0
      vf_loss: 6.782909393310547
    num_steps_sampled: 275000
    num_steps_trained: 275000
    wait_time_ms: 67.48
  iterations_since_restore: 55
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 475.7683231830597
  time_this_iter_s: 8.394688606262207
  time_total_s: 475.7683231830597
  timestamp: 1594856472
  timesteps_since_restore: 275000
  timesteps_this_iter: 5000
  timesteps_total: 275000
  training_iteration: 55
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 475 s, 55 iter, 275000 ts, -3.25e+04 rew

agent-1: -308.3980947283297
agent-2: -290.94443518022564
agent-3: -197.51136431981823
agent-4: -328.770012399606
agent-5: -307.76174749383136
Extrinsic Rewards:
8
9
7
12
14
Sum Reward: 50
Avg Reward: 10.0
Min Reward: 7
Max Reward: 14
Gini Coefficient: 0.144
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-41-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -547.3362503669158
  episode_reward_mean: -31938.545162270333
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 55
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.697
    dispatch_time_ms: 9.821
    learner:
      cur_lr: 0.0013416849542409182
      grad_gnorm: 22.013973236083984
      policy_entropy: 59.37171936035156
      policy_loss: 8.638198852539062
      var_gnorm: 25.952054977416992
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 7.196980953216553
    num_steps_sampled: 280000
    num_steps_trained: 280000
    wait_time_ms: 74.221
  iterations_since_restore: 56
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 484.2161717414856
  time_this_iter_s: 8.447848558425903
  time_total_s: 484.2161717414856
  timestamp: 1594856480
  timesteps_since_restore: 280000
  timesteps_this_iter: 5000
  timesteps_total: 280000
  training_iteration: 56
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 484 s, 56 iter, 280000 ts, -3.19e+04 rew

agent-1: -214.44135107122506
agent-2: -222.9155507481711
agent-3: -52.43256738479782
agent-4: -67.92394253190285
agent-5: -68.79343350932818
Extrinsic Rewards:
11
11
5
4
1
Sum Reward: 32
Avg Reward: 6.4
Min Reward: 1
Max Reward: 11
Gini Coefficient: 0.3375
20:20 Ratio: 11.0
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-41-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -547.3362503669158
  episode_reward_mean: -31379.401620894885
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 56
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.92
    dispatch_time_ms: 8.946
    learner:
      cur_lr: 0.0013413520064204931
      grad_gnorm: 16.474369049072266
      policy_entropy: 50.718265533447266
      policy_loss: -6.0251641273498535
      var_gnorm: 25.9219970703125
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.230243444442749
    num_steps_sampled: 285000
    num_steps_trained: 285000
    wait_time_ms: 72.787
  iterations_since_restore: 57
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 492.6424424648285
  time_this_iter_s: 8.426270723342896
  time_total_s: 492.6424424648285
  timestamp: 1594856489
  timesteps_since_restore: 285000
  timesteps_this_iter: 5000
  timesteps_total: 285000
  training_iteration: 57
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 492 s, 57 iter, 285000 ts, -3.14e+04 rew

agent-1: -130.93390036931245
agent-2: -175.23011384030272
agent-3: -143.4822003235346
agent-4: -168.35784332344758
agent-5: -221.99815242709857
Extrinsic Rewards:
2
3
0
7
7
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.4
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-41-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -547.3362503669158
  episode_reward_mean: -30843.62268386662
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 57
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.609
    dispatch_time_ms: 11.213
    learner:
      cur_lr: 0.0013410189421847463
      grad_gnorm: 39.999996185302734
      policy_entropy: 44.594173431396484
      policy_loss: 28.699228286743164
      var_gnorm: 25.9554386138916
      vf_explained_var: 0.0
      vf_loss: 27.564990997314453
    num_steps_sampled: 290000
    num_steps_trained: 290000
    wait_time_ms: 68.452
  iterations_since_restore: 58
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 501.071227312088
  time_this_iter_s: 8.428784847259521
  time_total_s: 501.071227312088
  timestamp: 1594856497
  timesteps_since_restore: 290000
  timesteps_this_iter: 5000
  timesteps_total: 290000
  training_iteration: 58
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 501 s, 58 iter, 290000 ts, -3.08e+04 rew

agent-1: -243.10451859779212
agent-2: -157.53640074620182
agent-3: -146.1538457257231
agent-4: -67.40754563230726
agent-5: -42.60589244082574
Extrinsic Rewards:
11
5
5
4
4
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 4
Max Reward: 11
Gini Coefficient: 0.20689655172413793
20:20 Ratio: 2.75
Max-min Ratio: 2.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-41-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -547.3362503669158
  episode_reward_mean: -30323.160365233452
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 58
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.768
    dispatch_time_ms: 11.263
    learner:
      cur_lr: 0.0013406859943643212
      grad_gnorm: 8.076271057128906
      policy_entropy: 58.84552764892578
      policy_loss: 2.5977683067321777
      var_gnorm: 25.9094295501709
      vf_explained_var: 0.0
      vf_loss: 5.876824378967285
    num_steps_sampled: 295000
    num_steps_trained: 295000
    wait_time_ms: 71.663
  iterations_since_restore: 59
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 509.5570137500763
  time_this_iter_s: 8.485786437988281
  time_total_s: 509.5570137500763
  timestamp: 1594856506
  timesteps_since_restore: 295000
  timesteps_this_iter: 5000
  timesteps_total: 295000
  training_iteration: 59
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 509 s, 59 iter, 295000 ts, -3.03e+04 rew

agent-1: -162.5621156429725
agent-2: -154.242485445818
agent-3: -80.27796294778719
agent-4: -76.72171056644525
agent-5: -230.42814097371385
Extrinsic Rewards:
5
3
0
7
17
Sum Reward: 32
Avg Reward: 6.4
Min Reward: 0
Max Reward: 17
Gini Coefficient: 0.475
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-41-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -547.3362503669158
  episode_reward_mean: -29821.144637273166
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 59
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.699
    dispatch_time_ms: 8.332
    learner:
      cur_lr: 0.0013403530465438962
      grad_gnorm: 40.0
      policy_entropy: 64.48560333251953
      policy_loss: 43.08349609375
      var_gnorm: 25.929946899414062
      vf_explained_var: 0.0
      vf_loss: 37.395748138427734
    num_steps_sampled: 300000
    num_steps_trained: 300000
    wait_time_ms: 71.132
  iterations_since_restore: 60
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 517.9290215969086
  time_this_iter_s: 8.372007846832275
  time_total_s: 517.9290215969086
  timestamp: 1594856514
  timesteps_since_restore: 300000
  timesteps_this_iter: 5000
  timesteps_total: 300000
  training_iteration: 60
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 517 s, 60 iter, 300000 ts, -2.98e+04 rew

agent-1: -122.3573241307803
agent-2: -32.46645062119148
agent-3: -187.67142860129823
agent-4: -224.7684073101643
agent-5: -90.71532570542438
Extrinsic Rewards:
5
4
6
9
5
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 4
Max Reward: 9
Gini Coefficient: 0.15172413793103448
20:20 Ratio: 2.25
Max-min Ratio: 2.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-42-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -547.3362503669158
  episode_reward_mean: -29335.091875591428
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 60
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.405
    dispatch_time_ms: 8.865
    learner:
      cur_lr: 0.0013400199823081493
      grad_gnorm: 17.670391082763672
      policy_entropy: 74.9386215209961
      policy_loss: 2.8082568645477295
      var_gnorm: 25.908876419067383
      vf_explained_var: 0.0
      vf_loss: 8.127724647521973
    num_steps_sampled: 305000
    num_steps_trained: 305000
    wait_time_ms: 71.555
  iterations_since_restore: 61
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 526.27281665802
  time_this_iter_s: 8.34379506111145
  time_total_s: 526.27281665802
  timestamp: 1594856523
  timesteps_since_restore: 305000
  timesteps_this_iter: 5000
  timesteps_total: 305000
  training_iteration: 61
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 526 s, 61 iter, 305000 ts, -2.93e+04 rew

agent-1: -112.22690726411659
agent-2: -122.60676956647434
agent-3: -142.1479375421206
agent-4: -145.0787640986571
agent-5: -209.13184091126138
Extrinsic Rewards:
2
2
6
6
3
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 2
Max Reward: 6
Gini Coefficient: 0.25263157894736843
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-42-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -547.3362503669158
  episode_reward_mean: -28866.175487784727
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 61
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.128
    dispatch_time_ms: 10.576
    learner:
      cur_lr: 0.0013396870344877243
      grad_gnorm: 39.999996185302734
      policy_entropy: 71.19141387939453
      policy_loss: -131.73544311523438
      var_gnorm: 25.95175552368164
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 160.831787109375
    num_steps_sampled: 310000
    num_steps_trained: 310000
    wait_time_ms: 70.919
  iterations_since_restore: 62
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 534.6306738853455
  time_this_iter_s: 8.35785722732544
  time_total_s: 534.6306738853455
  timestamp: 1594856531
  timesteps_since_restore: 310000
  timesteps_this_iter: 5000
  timesteps_total: 310000
  training_iteration: 62
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 534 s, 62 iter, 310000 ts, -2.89e+04 rew

agent-1: -294.03094921493624
agent-2: -138.530411235255
agent-3: -326.6350332781127
agent-4: -200.99361210692211
agent-5: -224.26738391257896
Extrinsic Rewards:
8
3
4
0
5
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.36
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-42-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -547.3362503669158
  episode_reward_mean: -28419.69616362284
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 62
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.595
    dispatch_time_ms: 7.957
    learner:
      cur_lr: 0.0013393539702519774
      grad_gnorm: 21.439851760864258
      policy_entropy: 72.35314178466797
      policy_loss: 2.455335855484009
      var_gnorm: 25.922931671142578
      vf_explained_var: 0.0
      vf_loss: 6.0452070236206055
    num_steps_sampled: 315000
    num_steps_trained: 315000
    wait_time_ms: 75.496
  iterations_since_restore: 63
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 543.0490260124207
  time_this_iter_s: 8.418352127075195
  time_total_s: 543.0490260124207
  timestamp: 1594856539
  timesteps_since_restore: 315000
  timesteps_this_iter: 5000
  timesteps_total: 315000
  training_iteration: 63
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 543 s, 63 iter, 315000 ts, -2.84e+04 rew

agent-1: -98.23513190728278
agent-2: -234.31897834447582
agent-3: -105.36540168230744
agent-4: -142.6953902838883
agent-5: -238.57098552031755
Extrinsic Rewards:
3
5
5
1
8
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.2909090909090909
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-42-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -547.3362503669158
  episode_reward_mean: -27981.592825910386
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 63
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.782
    dispatch_time_ms: 7.829
    learner:
      cur_lr: 0.0013390210224315524
      grad_gnorm: 10.015006065368652
      policy_entropy: 49.0155143737793
      policy_loss: 2.586825132369995
      var_gnorm: 25.92515754699707
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.451176643371582
    num_steps_sampled: 320000
    num_steps_trained: 320000
    wait_time_ms: 75.236
  iterations_since_restore: 64
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 551.4598772525787
  time_this_iter_s: 8.410851240158081
  time_total_s: 551.4598772525787
  timestamp: 1594856548
  timesteps_since_restore: 320000
  timesteps_this_iter: 5000
  timesteps_total: 320000
  training_iteration: 64
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 551 s, 64 iter, 320000 ts, -2.8e+04 rew

agent-1: -63.05403450541373
agent-2: -220.86435826297685
agent-3: -136.7548652740813
agent-4: -98.84345093828038
agent-5: -182.21017371629134
Extrinsic Rewards:
2
7
6
3
4
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 2
Max Reward: 7
Gini Coefficient: 0.23636363636363636
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-42-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -547.3362503669158
  episode_reward_mean: -27555.34492054768
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 64
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.739
    dispatch_time_ms: 8.811
    learner:
      cur_lr: 0.0013386879581958055
      grad_gnorm: 8.319417953491211
      policy_entropy: 55.15857696533203
      policy_loss: -4.3914337158203125
      var_gnorm: 25.908231735229492
      vf_explained_var: 0.0
      vf_loss: 4.8406901359558105
    num_steps_sampled: 325000
    num_steps_trained: 325000
    wait_time_ms: 73.925
  iterations_since_restore: 65
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 559.9069390296936
  time_this_iter_s: 8.447061777114868
  time_total_s: 559.9069390296936
  timestamp: 1594856556
  timesteps_since_restore: 325000
  timesteps_this_iter: 5000
  timesteps_total: 325000
  training_iteration: 65
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 559 s, 65 iter, 325000 ts, -2.76e+04 rew

agent-1: -182.70997064626746
agent-2: -182.74949526114776
agent-3: -140.8302511146836
agent-4: -45.111347027310046
agent-5: -101.41000915774525
Extrinsic Rewards:
9
7
4
14
6
Sum Reward: 40
Avg Reward: 8.0
Min Reward: 4
Max Reward: 14
Gini Coefficient: 0.23
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-42-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -547.3362503669158
  episode_reward_mean: -27141.45978443475
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 65
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.863
    dispatch_time_ms: 10.468
    learner:
      cur_lr: 0.0013383550103753805
      grad_gnorm: 27.630369186401367
      policy_entropy: 52.34347152709961
      policy_loss: -4.309708118438721
      var_gnorm: 25.952831268310547
      vf_explained_var: 0.0
      vf_loss: 8.567557334899902
    num_steps_sampled: 330000
    num_steps_trained: 330000
    wait_time_ms: 70.64
  iterations_since_restore: 66
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 568.293931722641
  time_this_iter_s: 8.386992692947388
  time_total_s: 568.293931722641
  timestamp: 1594856565
  timesteps_since_restore: 330000
  timesteps_this_iter: 5000
  timesteps_total: 330000
  training_iteration: 66
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 568 s, 66 iter, 330000 ts, -2.71e+04 rew

agent-1: -143.37891144975276
agent-2: -102.91497198311
agent-3: -250.6659137712974
agent-4: -78.63108375366994
agent-5: -200.73435727238163
Extrinsic Rewards:
0
3
7
3
3
Sum Reward: 16
Avg Reward: 3.2
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.35
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-42-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -547.3362503669158
  episode_reward_mean: -26741.988048886193
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 66
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.826
    dispatch_time_ms: 8.678
    learner:
      cur_lr: 0.0013380219461396337
      grad_gnorm: 10.978591918945312
      policy_entropy: 45.59294891357422
      policy_loss: -6.339574813842773
      var_gnorm: 25.926422119140625
      vf_explained_var: 0.0
      vf_loss: 1.0572253465652466
    num_steps_sampled: 335000
    num_steps_trained: 335000
    wait_time_ms: 74.156
  iterations_since_restore: 67
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 576.7044267654419
  time_this_iter_s: 8.410495042800903
  time_total_s: 576.7044267654419
  timestamp: 1594856573
  timesteps_since_restore: 335000
  timesteps_this_iter: 5000
  timesteps_total: 335000
  training_iteration: 67
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 576 s, 67 iter, 335000 ts, -2.67e+04 rew

agent-1: -19.77971497421705
agent-2: -177.55856723605734
agent-3: -104.40671669747161
agent-4: -133.20863447731256
agent-5: -205.06121757443594
Extrinsic Rewards:
5
13
12
7
17
Sum Reward: 54
Avg Reward: 10.8
Min Reward: 5
Max Reward: 17
Gini Coefficient: 0.2222222222222222
20:20 Ratio: 3.4
Max-min Ratio: 3.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-43-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -547.3362503669158
  episode_reward_mean: -26352.4063593649
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 67
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.948
    dispatch_time_ms: 7.951
    learner:
      cur_lr: 0.0013376889983192086
      grad_gnorm: 39.999996185302734
      policy_entropy: 38.505008697509766
      policy_loss: 13.091402053833008
      var_gnorm: 25.930927276611328
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 14.326103210449219
    num_steps_sampled: 340000
    num_steps_trained: 340000
    wait_time_ms: 73.375
  iterations_since_restore: 68
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 585.2463619709015
  time_this_iter_s: 8.541935205459595
  time_total_s: 585.2463619709015
  timestamp: 1594856582
  timesteps_since_restore: 340000
  timesteps_this_iter: 5000
  timesteps_total: 340000
  training_iteration: 68
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 585 s, 68 iter, 340000 ts, -2.64e+04 rew

agent-1: -174.69492309730504
agent-2: -118.39451052079463
agent-3: -133.15467901947943
agent-4: -124.62553250777258
agent-5: -196.03860878358387
Extrinsic Rewards:
4
4
3
4
5
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 3
Max Reward: 5
Gini Coefficient: 0.08
20:20 Ratio: 1.6666666666666667
Max-min Ratio: 1.6666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-43-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -547.3362503669158
  episode_reward_mean: -25975.8549166379
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 68
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.133
    dispatch_time_ms: 7.914
    learner:
      cur_lr: 0.0013373560504987836
      grad_gnorm: 16.559762954711914
      policy_entropy: 54.13024139404297
      policy_loss: 2.879596471786499
      var_gnorm: 25.90904998779297
      vf_explained_var: 0.0
      vf_loss: 4.601403713226318
    num_steps_sampled: 345000
    num_steps_trained: 345000
    wait_time_ms: 73.004
  iterations_since_restore: 69
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 593.6317496299744
  time_this_iter_s: 8.385387659072876
  time_total_s: 593.6317496299744
  timestamp: 1594856590
  timesteps_since_restore: 345000
  timesteps_this_iter: 5000
  timesteps_total: 345000
  training_iteration: 69
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 593 s, 69 iter, 345000 ts, -2.6e+04 rew

agent-1: -104.64542804937673
agent-2: -68.39698538230027
agent-3: -90.24757791119035
agent-4: -213.88358149479157
agent-5: -172.27647542560754
Extrinsic Rewards:
10
7
10
10
10
Sum Reward: 47
Avg Reward: 9.4
Min Reward: 7
Max Reward: 10
Gini Coefficient: 0.05106382978723404
20:20 Ratio: 1.4285714285714286
Max-min Ratio: 1.4285714285714286
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-43-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -547.3362503669158
  episode_reward_mean: -25608.80557071942
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 69
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.729
    dispatch_time_ms: 8.151
    learner:
      cur_lr: 0.0013370229862630367
      grad_gnorm: 15.098997116088867
      policy_entropy: 58.40119552612305
      policy_loss: -4.412022113800049
      var_gnorm: 25.920211791992188
      vf_explained_var: 0.0
      vf_loss: 3.2608208656311035
    num_steps_sampled: 350000
    num_steps_trained: 350000
    wait_time_ms: 72.165
  iterations_since_restore: 70
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 602.000595331192
  time_this_iter_s: 8.368845701217651
  time_total_s: 602.000595331192
  timestamp: 1594856599
  timesteps_since_restore: 350000
  timesteps_this_iter: 5000
  timesteps_total: 350000
  training_iteration: 70
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 602 s, 70 iter, 350000 ts, -2.56e+04 rew

agent-1: -96.50791336388707
agent-2: -188.3717409379941
agent-3: -111.83779245025873
agent-4: -186.16636023042733
agent-5: -78.3354122590148
Extrinsic Rewards:
5
7
11
10
7
Sum Reward: 40
Avg Reward: 8.0
Min Reward: 5
Max Reward: 11
Gini Coefficient: 0.15
20:20 Ratio: 2.2
Max-min Ratio: 2.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-43-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -547.3362503669158
  episode_reward_mean: -25252.411479984028
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 70
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.266
    dispatch_time_ms: 10.534
    learner:
      cur_lr: 0.0013366900384426117
      grad_gnorm: 12.685798645019531
      policy_entropy: 47.90439987182617
      policy_loss: -3.7775485515594482
      var_gnorm: 25.90395164489746
      vf_explained_var: 0.0
      vf_loss: 5.121863842010498
    num_steps_sampled: 355000
    num_steps_trained: 355000
    wait_time_ms: 71.963
  iterations_since_restore: 71
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 610.4504561424255
  time_this_iter_s: 8.44986081123352
  time_total_s: 610.4504561424255
  timestamp: 1594856607
  timesteps_since_restore: 355000
  timesteps_this_iter: 5000
  timesteps_total: 355000
  training_iteration: 71
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 610 s, 71 iter, 355000 ts, -2.53e+04 rew

agent-1: -79.5386966447315
agent-2: -253.2909540954792
agent-3: -135.93562141217794
agent-4: -185.439119540933
agent-5: -82.01994740386303
Extrinsic Rewards:
4
4
0
9
3
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.38
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-43-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -547.3362503669158
  episode_reward_mean: -24907.113069549
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 71
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.061
    dispatch_time_ms: 9.979
    learner:
      cur_lr: 0.0013363569742068648
      grad_gnorm: 40.0
      policy_entropy: 26.487232208251953
      policy_loss: -14.228973388671875
      var_gnorm: 25.99633026123047
      vf_explained_var: 0.0
      vf_loss: 16.72960090637207
    num_steps_sampled: 360000
    num_steps_trained: 360000
    wait_time_ms: 71.773
  iterations_since_restore: 72
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 618.9597685337067
  time_this_iter_s: 8.509312391281128
  time_total_s: 618.9597685337067
  timestamp: 1594856616
  timesteps_since_restore: 360000
  timesteps_this_iter: 5000
  timesteps_total: 360000
  training_iteration: 72
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 618 s, 72 iter, 360000 ts, -2.49e+04 rew

agent-1: -65.5294353665795
agent-2: -254.52165858424516
agent-3: -141.94354650465505
agent-4: -184.78751701216262
agent-5: -152.64697480780944
Extrinsic Rewards:
1
7
3
4
0
Sum Reward: 15
Avg Reward: 3.0
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.4533333333333333
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-43-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -547.3362503669158
  episode_reward_mean: -24572.28412597576
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 72
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.242
    dispatch_time_ms: 9.062
    learner:
      cur_lr: 0.0013360240263864398
      grad_gnorm: 11.029833793640137
      policy_entropy: 26.090288162231445
      policy_loss: -5.973109722137451
      var_gnorm: 25.905622482299805
      vf_explained_var: 0.0
      vf_loss: 6.602839946746826
    num_steps_sampled: 365000
    num_steps_trained: 365000
    wait_time_ms: 68.936
  iterations_since_restore: 73
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 627.08327460289
  time_this_iter_s: 8.12350606918335
  time_total_s: 627.08327460289
  timestamp: 1594856624
  timesteps_since_restore: 365000
  timesteps_this_iter: 5000
  timesteps_total: 365000
  training_iteration: 73
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 627 s, 73 iter, 365000 ts, -2.46e+04 rew

agent-1: -117.95158792915574
agent-2: -70.07041254198678
agent-3: -88.99503547076627
agent-4: -143.66011384312043
agent-5: -106.74480383526189
Extrinsic Rewards:
32
17
22
34
30
Sum Reward: 135
Avg Reward: 27.0
Min Reward: 17
Max Reward: 34
Gini Coefficient: 0.13037037037037036
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-43-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -527.4219536202896
  episode_reward_mean: -24242.90245238185
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 73
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.81
    dispatch_time_ms: 9.109
    learner:
      cur_lr: 0.001335690962150693
      grad_gnorm: 10.118549346923828
      policy_entropy: 32.45537567138672
      policy_loss: -2.4695491790771484
      var_gnorm: 25.87779426574707
      vf_explained_var: 0.0
      vf_loss: 11.361239433288574
    num_steps_sampled: 370000
    num_steps_trained: 370000
    wait_time_ms: 71.615
  iterations_since_restore: 74
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 635.4368071556091
  time_this_iter_s: 8.353532552719116
  time_total_s: 635.4368071556091
  timestamp: 1594856632
  timesteps_since_restore: 370000
  timesteps_this_iter: 5000
  timesteps_total: 370000
  training_iteration: 74
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 635 s, 74 iter, 370000 ts, -2.42e+04 rew

agent-1: -190.0339950852825
agent-2: -25.498620411245035
agent-3: -137.76011250357655
agent-4: -90.82721608705185
agent-5: -45.890519184820654
Extrinsic Rewards:
28
5
16
13
8
Sum Reward: 70
Avg Reward: 14.0
Min Reward: 5
Max Reward: 28
Gini Coefficient: 0.30857142857142855
20:20 Ratio: 5.6
Max-min Ratio: 5.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-44-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -23921.917425501986
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 74
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.145
    dispatch_time_ms: 8.579
    learner:
      cur_lr: 0.001335358014330268
      grad_gnorm: 15.476374626159668
      policy_entropy: 35.679176330566406
      policy_loss: -0.0359409898519516
      var_gnorm: 25.896638870239258
      vf_explained_var: 0.0
      vf_loss: 6.616755962371826
    num_steps_sampled: 375000
    num_steps_trained: 375000
    wait_time_ms: 74.324
  iterations_since_restore: 75
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 643.8245942592621
  time_this_iter_s: 8.387787103652954
  time_total_s: 643.8245942592621
  timestamp: 1594856641
  timesteps_since_restore: 375000
  timesteps_this_iter: 5000
  timesteps_total: 375000
  training_iteration: 75
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 643 s, 75 iter, 375000 ts, -2.39e+04 rew

agent-1: -24.82590123537845
agent-2: -223.76934828276072
agent-3: -30.353485890934753
agent-4: -182.985252899953
agent-5: -163.81610975494425
Extrinsic Rewards:
1
6
3
11
6
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 1
Max Reward: 11
Gini Coefficient: 0.34074074074074073
20:20 Ratio: 11.0
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-44-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -23611.301861136148
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 75
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.074
    dispatch_time_ms: 9.398
    learner:
      cur_lr: 0.001335024950094521
      grad_gnorm: 6.945067405700684
      policy_entropy: 36.392581939697266
      policy_loss: -5.019071578979492
      var_gnorm: 25.913660049438477
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 6.415107727050781
    num_steps_sampled: 380000
    num_steps_trained: 380000
    wait_time_ms: 72.405
  iterations_since_restore: 76
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 652.3217179775238
  time_this_iter_s: 8.497123718261719
  time_total_s: 652.3217179775238
  timestamp: 1594856649
  timesteps_since_restore: 380000
  timesteps_this_iter: 5000
  timesteps_total: 380000
  training_iteration: 76
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 652 s, 76 iter, 380000 ts, -2.36e+04 rew

agent-1: -194.52907979874553
agent-2: -150.90032733018023
agent-3: -213.75259738688058
agent-4: -12.71756342082044
agent-5: -92.10894518329329
Extrinsic Rewards:
10
6
9
2
6
Sum Reward: 33
Avg Reward: 6.6
Min Reward: 2
Max Reward: 10
Gini Coefficient: 0.23030303030303031
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-44-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -23309.363790767515
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 76
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.718
    dispatch_time_ms: 9.497
    learner:
      cur_lr: 0.001334692002274096
      grad_gnorm: 12.780588150024414
      policy_entropy: 40.027374267578125
      policy_loss: 0.0638355016708374
      var_gnorm: 25.912761688232422
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 10.39755630493164
    num_steps_sampled: 385000
    num_steps_trained: 385000
    wait_time_ms: 72.256
  iterations_since_restore: 77
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 660.7283725738525
  time_this_iter_s: 8.406654596328735
  time_total_s: 660.7283725738525
  timestamp: 1594856658
  timesteps_since_restore: 385000
  timesteps_this_iter: 5000
  timesteps_total: 385000
  training_iteration: 77
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 660 s, 77 iter, 385000 ts, -2.33e+04 rew

agent-1: -210.8506197988425
agent-2: -77.37896670326651
agent-3: -7.601565852138836
agent-4: -38.89120364387577
agent-5: -243.26728455385145
Extrinsic Rewards:
10
7
1
3
14
Sum Reward: 35
Avg Reward: 7.0
Min Reward: 1
Max Reward: 14
Gini Coefficient: 0.37714285714285717
20:20 Ratio: 14.0
Max-min Ratio: 14.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-44-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -23014.151139466016
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 77
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.478
    dispatch_time_ms: 8.531
    learner:
      cur_lr: 0.001334359054453671
      grad_gnorm: 40.0
      policy_entropy: 18.127948760986328
      policy_loss: 7.182600975036621
      var_gnorm: 25.92072868347168
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 12.020793914794922
    num_steps_sampled: 390000
    num_steps_trained: 390000
    wait_time_ms: 70.334
  iterations_since_restore: 78
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 669.1776895523071
  time_this_iter_s: 8.44931697845459
  time_total_s: 669.1776895523071
  timestamp: 1594856666
  timesteps_since_restore: 390000
  timesteps_this_iter: 5000
  timesteps_total: 390000
  training_iteration: 78
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 669 s, 78 iter, 390000 ts, -2.3e+04 rew

agent-1: -186.5401758802954
agent-2: -101.11405469291401
agent-3: -148.13746905224502
agent-4: -160.43453685761168
agent-5: -143.75979820683423
Extrinsic Rewards:
6
3
6
5
7
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 3
Max Reward: 7
Gini Coefficient: 0.13333333333333333
20:20 Ratio: 2.3333333333333335
Max-min Ratio: 2.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-44-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -22728.584920174017
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 78
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.478
    dispatch_time_ms: 5.894
    learner:
      cur_lr: 0.0013340259902179241
      grad_gnorm: 12.874482154846191
      policy_entropy: 32.637203216552734
      policy_loss: 7.4541473388671875
      var_gnorm: 25.88666534423828
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 11.90655517578125
    num_steps_sampled: 395000
    num_steps_trained: 395000
    wait_time_ms: 74.296
  iterations_since_restore: 79
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 677.4812994003296
  time_this_iter_s: 8.303609848022461
  time_total_s: 677.4812994003296
  timestamp: 1594856674
  timesteps_since_restore: 395000
  timesteps_this_iter: 5000
  timesteps_total: 395000
  training_iteration: 79
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 677 s, 79 iter, 395000 ts, -2.27e+04 rew

agent-1: -159.6757471335112
agent-2: -189.8002830718363
agent-3: -59.397792134764764
agent-4: -64.15938365541025
agent-5: -150.31420642424388
Extrinsic Rewards:
9
22
11
8
10
Sum Reward: 60
Avg Reward: 12.0
Min Reward: 8
Max Reward: 22
Gini Coefficient: 0.2
20:20 Ratio: 2.75
Max-min Ratio: 2.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-44-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -22448.771787164467
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 79
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.237
    dispatch_time_ms: 9.606
    learner:
      cur_lr: 0.001333693042397499
      grad_gnorm: 3.873009443283081
      policy_entropy: 30.522666931152344
      policy_loss: 0.9838175773620605
      var_gnorm: 25.8980770111084
      vf_explained_var: 0.0
      vf_loss: 11.272329330444336
    num_steps_sampled: 400000
    num_steps_trained: 400000
    wait_time_ms: 71.655
  iterations_since_restore: 80
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 685.9391407966614
  time_this_iter_s: 8.457841396331787
  time_total_s: 685.9391407966614
  timestamp: 1594856683
  timesteps_since_restore: 400000
  timesteps_this_iter: 5000
  timesteps_total: 400000
  training_iteration: 80
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 685 s, 80 iter, 400000 ts, -2.24e+04 rew

agent-1: -154.77840707356842
agent-2: -86.42249395639087
agent-3: -106.25834164509621
agent-4: -40.74180492843625
agent-5: -151.63930702612646
Extrinsic Rewards:
27
20
19
9
17
Sum Reward: 92
Avg Reward: 18.4
Min Reward: 9
Max Reward: 27
Gini Coefficient: 0.16956521739130434
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-44-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -22174.910144257778
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 80
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.672
    dispatch_time_ms: 9.99
    learner:
      cur_lr: 0.0013333599781617522
      grad_gnorm: 8.479408264160156
      policy_entropy: 24.070159912109375
      policy_loss: 2.6354172229766846
      var_gnorm: 25.909509658813477
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 6.0302629470825195
    num_steps_sampled: 405000
    num_steps_trained: 405000
    wait_time_ms: 71.755
  iterations_since_restore: 81
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 694.2997915744781
  time_this_iter_s: 8.360650777816772
  time_total_s: 694.2997915744781
  timestamp: 1594856691
  timesteps_since_restore: 405000
  timesteps_this_iter: 5000
  timesteps_total: 405000
  training_iteration: 81
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 694 s, 81 iter, 405000 ts, -2.22e+04 rew

agent-1: -277.1265374372204
agent-2: -349.02545729590025
agent-3: -80.3763942001121
agent-4: -320.26365287632996
agent-5: -256.9543520127289
Extrinsic Rewards:
-39
3
1
3
1
Sum Reward: -31
Avg Reward: -6.2
Min Reward: -39
Max Reward: 3
Gini Coefficient: -1.1096774193548387
20:20 Ratio: -0.07692307692307693
Max-min Ratio: -0.07692307692307693
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-45-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -21916.994542400553
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 81
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.768
    dispatch_time_ms: 9.404
    learner:
      cur_lr: 0.0013330270303413272
      grad_gnorm: 21.26523208618164
      policy_entropy: 35.60784149169922
      policy_loss: 1.2487374544143677
      var_gnorm: 25.976640701293945
      vf_explained_var: 0.0
      vf_loss: 6.537909984588623
    num_steps_sampled: 410000
    num_steps_trained: 410000
    wait_time_ms: 73.09
  iterations_since_restore: 82
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 702.7689964771271
  time_this_iter_s: 8.469204902648926
  time_total_s: 702.7689964771271
  timestamp: 1594856700
  timesteps_since_restore: 410000
  timesteps_this_iter: 5000
  timesteps_total: 410000
  training_iteration: 82
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 702 s, 82 iter, 410000 ts, -2.19e+04 rew

agent-1: -130.6631467077234
agent-2: -167.91718062756243
agent-3: -217.47977482533327
agent-4: -24.64260810381223
agent-5: -95.31085021794692
Extrinsic Rewards:
8
6
15
5
4
Sum Reward: 38
Avg Reward: 7.6
Min Reward: 4
Max Reward: 15
Gini Coefficient: 0.2631578947368421
20:20 Ratio: 3.75
Max-min Ratio: 3.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-45-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -21657.470384084474
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 82
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.17
    dispatch_time_ms: 8.861
    learner:
      cur_lr: 0.0013326939661055803
      grad_gnorm: 17.284709930419922
      policy_entropy: 54.69990158081055
      policy_loss: 7.401211261749268
      var_gnorm: 25.93047523498535
      vf_explained_var: 0.0
      vf_loss: 10.765403747558594
    num_steps_sampled: 415000
    num_steps_trained: 415000
    wait_time_ms: 71.887
  iterations_since_restore: 83
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 711.1384634971619
  time_this_iter_s: 8.36946702003479
  time_total_s: 711.1384634971619
  timestamp: 1594856708
  timesteps_since_restore: 415000
  timesteps_this_iter: 5000
  timesteps_total: 415000
  training_iteration: 83
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 711 s, 83 iter, 415000 ts, -2.17e+04 rew

agent-1: -77.80249667080886
agent-2: -60.943472333789245
agent-3: -153.01565779985506
agent-4: -205.86801143441113
agent-5: -178.2863470154787
Extrinsic Rewards:
4
5
4
8
17
Sum Reward: 38
Avg Reward: 7.6
Min Reward: 4
Max Reward: 17
Gini Coefficient: 0.3157894736842105
20:20 Ratio: 4.25
Max-min Ratio: 4.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-45-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -21404.680572050376
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 83
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.846
    dispatch_time_ms: 7.951
    learner:
      cur_lr: 0.0013323610182851553
      grad_gnorm: 30.896421432495117
      policy_entropy: 43.5844612121582
      policy_loss: -10.41524600982666
      var_gnorm: 25.960905075073242
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 11.680355072021484
    num_steps_sampled: 420000
    num_steps_trained: 420000
    wait_time_ms: 73.852
  iterations_since_restore: 84
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 719.5423679351807
  time_this_iter_s: 8.403904438018799
  time_total_s: 719.5423679351807
  timestamp: 1594856717
  timesteps_since_restore: 420000
  timesteps_this_iter: 5000
  timesteps_total: 420000
  training_iteration: 84
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 719 s, 84 iter, 420000 ts, -2.14e+04 rew

agent-1: -95.4908205362108
agent-2: -215.16300354730532
agent-3: -137.37467900255007
agent-4: -222.89304560483833
agent-5: -21.050612422563134
Extrinsic Rewards:
0
12
10
13
6
Sum Reward: 41
Avg Reward: 8.2
Min Reward: 0
Max Reward: 13
Gini Coefficient: 0.3121951219512195
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-45-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -21158.100710015413
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 84
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.58
    dispatch_time_ms: 6.758
    learner:
      cur_lr: 0.0013320279540494084
      grad_gnorm: 10.584728240966797
      policy_entropy: 53.787330627441406
      policy_loss: 0.17352157831192017
      var_gnorm: 25.918485641479492
      vf_explained_var: 0.0
      vf_loss: 6.955105781555176
    num_steps_sampled: 425000
    num_steps_trained: 425000
    wait_time_ms: 75.852
  iterations_since_restore: 85
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 727.9379529953003
  time_this_iter_s: 8.395585060119629
  time_total_s: 727.9379529953003
  timestamp: 1594856725
  timesteps_since_restore: 425000
  timesteps_this_iter: 5000
  timesteps_total: 425000
  training_iteration: 85
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 727 s, 85 iter, 425000 ts, -2.12e+04 rew

agent-1: -219.7918076125776
agent-2: -66.68585004131702
agent-3: -98.41276945823762
agent-4: -188.60259006231928
agent-5: -33.152586935337006
Extrinsic Rewards:
21
7
8
9
2
Sum Reward: 47
Avg Reward: 9.4
Min Reward: 2
Max Reward: 21
Gini Coefficient: 0.3404255319148936
20:20 Ratio: 10.5
Max-min Ratio: 10.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-45-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -20916.318885240053
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 85
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.175
    dispatch_time_ms: 9.394
    learner:
      cur_lr: 0.0013316950062289834
      grad_gnorm: 26.102365493774414
      policy_entropy: 53.60677719116211
      policy_loss: 1.226579189300537
      var_gnorm: 25.921045303344727
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 8.870922088623047
    num_steps_sampled: 430000
    num_steps_trained: 430000
    wait_time_ms: 72.58
  iterations_since_restore: 86
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 736.3305797576904
  time_this_iter_s: 8.392626762390137
  time_total_s: 736.3305797576904
  timestamp: 1594856733
  timesteps_since_restore: 430000
  timesteps_this_iter: 5000
  timesteps_total: 430000
  training_iteration: 86
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 736 s, 86 iter, 430000 ts, -2.09e+04 rew

agent-1: -234.7939557507355
agent-2: -173.93965641761707
agent-3: -172.07530887099793
agent-4: -12.208021788531815
agent-5: -24.554525988376692
Extrinsic Rewards:
5
5
11
1
2
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 1
Max Reward: 11
Gini Coefficient: 0.38333333333333336
20:20 Ratio: 11.0
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-45-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -20680.286938537454
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 86
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.674
    dispatch_time_ms: 7.75
    learner:
      cur_lr: 0.0013313619419932365
      grad_gnorm: 9.670783996582031
      policy_entropy: 49.48859786987305
      policy_loss: 2.5828890800476074
      var_gnorm: 25.922456741333008
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 9.634408950805664
    num_steps_sampled: 435000
    num_steps_trained: 435000
    wait_time_ms: 74.042
  iterations_since_restore: 87
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 744.7289621829987
  time_this_iter_s: 8.398382425308228
  time_total_s: 744.7289621829987
  timestamp: 1594856742
  timesteps_since_restore: 435000
  timesteps_this_iter: 5000
  timesteps_total: 435000
  training_iteration: 87
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 744 s, 87 iter, 435000 ts, -2.07e+04 rew

agent-1: -180.31347066043142
agent-2: -113.65429690558915
agent-3: -220.86855105673402
agent-4: -119.47566530503642
agent-5: -89.59355198530774
Extrinsic Rewards:
5
1
9
4
2
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.3619047619047619
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-45-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -20450.903244254412
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 87
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.937
    dispatch_time_ms: 8.057
    learner:
      cur_lr: 0.0013310289941728115
      grad_gnorm: 40.0
      policy_entropy: 59.632625579833984
      policy_loss: 49.100154876708984
      var_gnorm: 25.972837448120117
      vf_explained_var: -0.25981128215789795
      vf_loss: 36.49390411376953
    num_steps_sampled: 440000
    num_steps_trained: 440000
    wait_time_ms: 76.119
  iterations_since_restore: 88
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 753.1538076400757
  time_this_iter_s: 8.424845457077026
  time_total_s: 753.1538076400757
  timestamp: 1594856750
  timesteps_since_restore: 440000
  timesteps_this_iter: 5000
  timesteps_total: 440000
  training_iteration: 88
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 753 s, 88 iter, 440000 ts, -2.05e+04 rew

agent-1: -248.52627185291016
agent-2: -15.461147774141466
agent-3: -105.96174415069109
agent-4: -136.52054308900176
agent-5: -225.00718076239008
Extrinsic Rewards:
9
1
5
0
9
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.43333333333333335
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-45-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -20226.818853838216
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 88
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.913
    dispatch_time_ms: 6.714
    learner:
      cur_lr: 0.0013306960463523865
      grad_gnorm: 10.852219581604004
      policy_entropy: 52.43545150756836
      policy_loss: 1.918493628501892
      var_gnorm: 25.930761337280273
      vf_explained_var: 0.0
      vf_loss: 5.571760177612305
    num_steps_sampled: 445000
    num_steps_trained: 445000
    wait_time_ms: 71.907
  iterations_since_restore: 89
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 761.4991862773895
  time_this_iter_s: 8.345378637313843
  time_total_s: 761.4991862773895
  timestamp: 1594856759
  timesteps_since_restore: 445000
  timesteps_this_iter: 5000
  timesteps_total: 445000
  training_iteration: 89
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 761 s, 89 iter, 445000 ts, -2.02e+04 rew

agent-1: -187.84128793593425
agent-2: -256.5018141155195
agent-3: -49.65216512826982
agent-4: -221.0188369522116
agent-5: -139.3389171628764
Extrinsic Rewards:
6
5
0
4
1
Sum Reward: 16
Avg Reward: 3.2
Min Reward: 0
Max Reward: 6
Gini Coefficient: 0.4
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-46-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -20009.15069841638
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 89
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.349
    dispatch_time_ms: 7.435
    learner:
      cur_lr: 0.0013303629821166396
      grad_gnorm: 12.29549503326416
      policy_entropy: 58.3823127746582
      policy_loss: 4.780660629272461
      var_gnorm: 25.93391227722168
      vf_explained_var: 0.0
      vf_loss: 5.589813232421875
    num_steps_sampled: 450000
    num_steps_trained: 450000
    wait_time_ms: 72.612
  iterations_since_restore: 90
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 769.919105052948
  time_this_iter_s: 8.419918775558472
  time_total_s: 769.919105052948
  timestamp: 1594856767
  timesteps_since_restore: 450000
  timesteps_this_iter: 5000
  timesteps_total: 450000
  training_iteration: 90
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 769 s, 90 iter, 450000 ts, -2e+04 rew

agent-1: -72.86354417370751
agent-2: -91.03948678148606
agent-3: -94.10507155410733
agent-4: -77.05837834218792
agent-5: -263.2222464446929
Extrinsic Rewards:
3
2
4
3
16
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 2
Max Reward: 16
Gini Coefficient: 0.4142857142857143
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-46-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -19793.474454292824
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 90
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.876
    dispatch_time_ms: 10.589
    learner:
      cur_lr: 0.0013300300342962146
      grad_gnorm: 13.155268669128418
      policy_entropy: 54.13103103637695
      policy_loss: 1.6827126741409302
      var_gnorm: 25.93427276611328
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 6.515829086303711
    num_steps_sampled: 455000
    num_steps_trained: 455000
    wait_time_ms: 70.44
  iterations_since_restore: 91
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 778.3197340965271
  time_this_iter_s: 8.400629043579102
  time_total_s: 778.3197340965271
  timestamp: 1594856776
  timesteps_since_restore: 455000
  timesteps_this_iter: 5000
  timesteps_total: 455000
  training_iteration: 91
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 778 s, 91 iter, 455000 ts, -1.98e+04 rew

agent-1: -138.8355478764784
agent-2: -116.32550254545028
agent-3: -189.3788977741893
agent-4: -30.0819137522263
agent-5: -222.74753769718555
Extrinsic Rewards:
4
4
5
1
6
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 1
Max Reward: 6
Gini Coefficient: 0.22
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-46-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -19583.627145999995
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 91
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.027
    dispatch_time_ms: 8.89
    learner:
      cur_lr: 0.0013296969700604677
      grad_gnorm: 39.999996185302734
      policy_entropy: 30.07826805114746
      policy_loss: 6.815260410308838
      var_gnorm: 25.94002914428711
      vf_explained_var: 0.0
      vf_loss: 15.988754272460938
    num_steps_sampled: 460000
    num_steps_trained: 460000
    wait_time_ms: 72.432
  iterations_since_restore: 92
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 786.7495224475861
  time_this_iter_s: 8.42978835105896
  time_total_s: 786.7495224475861
  timestamp: 1594856784
  timesteps_since_restore: 460000
  timesteps_this_iter: 5000
  timesteps_total: 460000
  training_iteration: 92
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 786 s, 92 iter, 460000 ts, -1.96e+04 rew

agent-1: -251.4293527206213
agent-2: -53.31804003881436
agent-3: -35.093609475174844
agent-4: -121.72881445652308
agent-5: -183.7086913609735
Extrinsic Rewards:
10
2
1
2
4
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 1
Max Reward: 10
Gini Coefficient: 0.42105263157894735
20:20 Ratio: 10.0
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-46-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -19377.775530370127
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 92
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.192
    dispatch_time_ms: 8.934
    learner:
      cur_lr: 0.0013293640222400427
      grad_gnorm: 26.93697166442871
      policy_entropy: 28.11758041381836
      policy_loss: -11.525053977966309
      var_gnorm: 25.90931510925293
      vf_explained_var: 0.0
      vf_loss: 3.382117509841919
    num_steps_sampled: 465000
    num_steps_trained: 465000
    wait_time_ms: 71.576
  iterations_since_restore: 93
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 795.2108826637268
  time_this_iter_s: 8.461360216140747
  time_total_s: 795.2108826637268
  timestamp: 1594856793
  timesteps_since_restore: 465000
  timesteps_this_iter: 5000
  timesteps_total: 465000
  training_iteration: 93
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 795 s, 93 iter, 465000 ts, -1.94e+04 rew

agent-1: -265.4742748211502
agent-2: -150.14697774629803
agent-3: -71.92381804299339
agent-4: -97.12325532915332
agent-5: -132.72309527342563
Extrinsic Rewards:
15
4
1
2
0
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 0
Max Reward: 15
Gini Coefficient: 0.6
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-46-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -19177.126238873814
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 93
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.888
    dispatch_time_ms: 8.22
    learner:
      cur_lr: 0.0013290309580042958
      grad_gnorm: 39.999996185302734
      policy_entropy: 28.653507232666016
      policy_loss: 26.603418350219727
      var_gnorm: 25.953073501586914
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 19.785144805908203
    num_steps_sampled: 470000
    num_steps_trained: 470000
    wait_time_ms: 73.057
  iterations_since_restore: 94
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 803.616946220398
  time_this_iter_s: 8.406063556671143
  time_total_s: 803.616946220398
  timestamp: 1594856801
  timesteps_since_restore: 470000
  timesteps_this_iter: 5000
  timesteps_total: 470000
  training_iteration: 94
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 803 s, 94 iter, 470000 ts, -1.92e+04 rew

agent-1: -94.85764319335594
agent-2: -74.95000651114226
agent-3: -147.49480249455036
agent-4: -138.18977466776647
agent-5: -85.37634822531186
Extrinsic Rewards:
8
16
27
26
20
Sum Reward: 97
Avg Reward: 19.4
Min Reward: 8
Max Reward: 27
Gini Coefficient: 0.1979381443298969
20:20 Ratio: 3.375
Max-min Ratio: 3.375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-46-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -18978.868178620818
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 94
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.331
    dispatch_time_ms: 8.364
    learner:
      cur_lr: 0.0013286980101838708
      grad_gnorm: 10.397406578063965
      policy_entropy: 46.17206573486328
      policy_loss: 0.787859320640564
      var_gnorm: 25.945627212524414
      vf_explained_var: 0.0
      vf_loss: 2.7738101482391357
    num_steps_sampled: 475000
    num_steps_trained: 475000
    wait_time_ms: 73.783
  iterations_since_restore: 95
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 811.9390773773193
  time_this_iter_s: 8.322131156921387
  time_total_s: 811.9390773773193
  timestamp: 1594856809
  timesteps_since_restore: 475000
  timesteps_this_iter: 5000
  timesteps_total: 475000
  training_iteration: 95
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 811 s, 95 iter, 475000 ts, -1.9e+04 rew

agent-1: -36.234711016167054
agent-2: -181.10670196840857
agent-3: -192.3728150058477
agent-4: -89.00724546443051
agent-5: -174.51481480912722
Extrinsic Rewards:
2
9
12
5
14
Sum Reward: 42
Avg Reward: 8.4
Min Reward: 2
Max Reward: 14
Gini Coefficient: 0.29523809523809524
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-46-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -18786.177316617064
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 95
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.681
    dispatch_time_ms: 10.761
    learner:
      cur_lr: 0.001328364945948124
      grad_gnorm: 5.744098663330078
      policy_entropy: 41.088417053222656
      policy_loss: -1.9393131732940674
      var_gnorm: 25.952848434448242
      vf_explained_var: 0.0
      vf_loss: 2.747901678085327
    num_steps_sampled: 480000
    num_steps_trained: 480000
    wait_time_ms: 72.99
  iterations_since_restore: 96
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 820.3438365459442
  time_this_iter_s: 8.404759168624878
  time_total_s: 820.3438365459442
  timestamp: 1594856818
  timesteps_since_restore: 480000
  timesteps_this_iter: 5000
  timesteps_total: 480000
  training_iteration: 96
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 820 s, 96 iter, 480000 ts, -1.88e+04 rew

agent-1: -106.85749419835422
agent-2: -121.95434111838924
agent-3: -75.94178890929685
agent-4: -164.59922528274927
agent-5: -228.618650822293
Extrinsic Rewards:
3
2
3
7
12
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 2
Max Reward: 12
Gini Coefficient: 0.35555555555555557
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-47-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -18597.758506030747
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 96
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.77
    dispatch_time_ms: 9.37
    learner:
      cur_lr: 0.001328031998127699
      grad_gnorm: 6.128284931182861
      policy_entropy: 42.03439712524414
      policy_loss: 0.07794547080993652
      var_gnorm: 25.956581115722656
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.758387804031372
    num_steps_sampled: 485000
    num_steps_trained: 485000
    wait_time_ms: 71.782
  iterations_since_restore: 97
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 828.7397744655609
  time_this_iter_s: 8.3959379196167
  time_total_s: 828.7397744655609
  timestamp: 1594856826
  timesteps_since_restore: 485000
  timesteps_this_iter: 5000
  timesteps_total: 485000
  training_iteration: 97
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 828 s, 97 iter, 485000 ts, -1.86e+04 rew

agent-1: -184.13896020709953
agent-2: -149.56120443418223
agent-3: -136.0792023340699
agent-4: -159.1050769187097
agent-5: -102.08162875401837
Extrinsic Rewards:
5
5
10
4
2
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 2
Max Reward: 10
Gini Coefficient: 0.26153846153846155
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-47-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -18413.564769604123
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 97
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.764
    dispatch_time_ms: 10.368
    learner:
      cur_lr: 0.0013276990503072739
      grad_gnorm: 4.857891082763672
      policy_entropy: 47.38957977294922
      policy_loss: 1.0652352571487427
      var_gnorm: 25.96186637878418
      vf_explained_var: 0.0
      vf_loss: 3.767988681793213
    num_steps_sampled: 490000
    num_steps_trained: 490000
    wait_time_ms: 69.718
  iterations_since_restore: 98
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 837.1504452228546
  time_this_iter_s: 8.410670757293701
  time_total_s: 837.1504452228546
  timestamp: 1594856835
  timesteps_since_restore: 490000
  timesteps_this_iter: 5000
  timesteps_total: 490000
  training_iteration: 98
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 837 s, 98 iter, 490000 ts, -1.84e+04 rew

agent-1: -137.22966385801348
agent-2: -156.70459111640037
agent-3: -32.096686323879105
agent-4: -164.11796110110288
agent-5: -222.6749405041811
Extrinsic Rewards:
3
1
1
5
7
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 1
Max Reward: 7
Gini Coefficient: 0.3764705882352941
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-47-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -18232.944964229624
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 98
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.516
    dispatch_time_ms: 8.863
    learner:
      cur_lr: 0.001327365986071527
      grad_gnorm: 13.932554244995117
      policy_entropy: 45.49235534667969
      policy_loss: 2.1497929096221924
      var_gnorm: 25.92607879638672
      vf_explained_var: 0.0
      vf_loss: 7.461049556732178
    num_steps_sampled: 495000
    num_steps_trained: 495000
    wait_time_ms: 73.123
  iterations_since_restore: 99
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 845.5046532154083
  time_this_iter_s: 8.354207992553711
  time_total_s: 845.5046532154083
  timestamp: 1594856843
  timesteps_since_restore: 495000
  timesteps_this_iter: 5000
  timesteps_total: 495000
  training_iteration: 99
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 845 s, 99 iter, 495000 ts, -1.82e+04 rew

agent-1: -246.63708706393186
agent-2: -170.7143429631849
agent-3: -46.27686370358429
agent-4: -148.018776285758
agent-5: -21.042441239893282
Extrinsic Rewards:
8
4
3
4
1
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.3
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-47-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -18055.164606118786
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 99
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.013
    dispatch_time_ms: 10.529
    learner:
      cur_lr: 0.001327033038251102
      grad_gnorm: 33.396297454833984
      policy_entropy: 43.64282989501953
      policy_loss: 4.70944881439209
      var_gnorm: 25.92514419555664
      vf_explained_var: 0.0
      vf_loss: 9.844324111938477
    num_steps_sampled: 500000
    num_steps_trained: 500000
    wait_time_ms: 70.449
  iterations_since_restore: 100
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 853.8906128406525
  time_this_iter_s: 8.38595962524414
  time_total_s: 853.8906128406525
  timestamp: 1594856852
  timesteps_since_restore: 500000
  timesteps_this_iter: 5000
  timesteps_total: 500000
  training_iteration: 100
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 853 s, 100 iter, 500000 ts, -1.81e+04 rew

agent-1: -54.46336122748286
agent-2: -248.06025434347958
agent-3: -29.58140009759918
agent-4: -225.08824919803226
agent-5: -49.04776179150982
Extrinsic Rewards:
3
7
1
5
3
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 1
Max Reward: 7
Gini Coefficient: 0.29473684210526313
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-47-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -17880.675370324177
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 100
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.593
    dispatch_time_ms: 6.42
    learner:
      cur_lr: 0.0013266999740153551
      grad_gnorm: 12.305392265319824
      policy_entropy: 40.19634246826172
      policy_loss: -3.1605896949768066
      var_gnorm: 25.921035766601562
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 4.21245002746582
    num_steps_sampled: 505000
    num_steps_trained: 505000
    wait_time_ms: 78.052
  iterations_since_restore: 101
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 862.1284472942352
  time_this_iter_s: 8.237834453582764
  time_total_s: 862.1284472942352
  timestamp: 1594856860
  timesteps_since_restore: 505000
  timesteps_this_iter: 5000
  timesteps_total: 505000
  training_iteration: 101
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 862 s, 101 iter, 505000 ts, -1.79e+04 rew

agent-1: -129.40739802958873
agent-2: -83.82975924188538
agent-3: -100.66417118804212
agent-4: -174.19782252001872
agent-5: -125.36684540019016
Extrinsic Rewards:
11
7
11
15
14
Sum Reward: 58
Avg Reward: 11.6
Min Reward: 7
Max Reward: 15
Gini Coefficient: 0.1310344827586207
20:20 Ratio: 2.142857142857143
Max-min Ratio: 2.142857142857143
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-47-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -16548.85631156527
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 101
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.722
    dispatch_time_ms: 8.757
    learner:
      cur_lr: 0.00132636702619493
      grad_gnorm: 40.0
      policy_entropy: 42.211978912353516
      policy_loss: -31.343942642211914
      var_gnorm: 25.949445724487305
      vf_explained_var: -1.0
      vf_loss: 34.76378631591797
    num_steps_sampled: 510000
    num_steps_trained: 510000
    wait_time_ms: 71.731
  iterations_since_restore: 102
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 870.501228094101
  time_this_iter_s: 8.372780799865723
  time_total_s: 870.501228094101
  timestamp: 1594856868
  timesteps_since_restore: 510000
  timesteps_this_iter: 5000
  timesteps_total: 510000
  training_iteration: 102
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 870 s, 102 iter, 510000 ts, -1.65e+04 rew

agent-1: -150.1239403853071
agent-2: -131.07982158919793
agent-3: -78.01274718721301
agent-4: -129.0286370271709
agent-5: -199.0947478053358
Extrinsic Rewards:
5
7
6
1
4
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 1
Max Reward: 7
Gini Coefficient: 0.24347826086956523
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-47-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -15454.757426835175
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 102
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.717
    dispatch_time_ms: 8.388
    learner:
      cur_lr: 0.0013260339619591832
      grad_gnorm: 18.46070098876953
      policy_entropy: 36.79372024536133
      policy_loss: 1.3219953775405884
      var_gnorm: 25.912952423095703
      vf_explained_var: 0.0
      vf_loss: 5.792948246002197
    num_steps_sampled: 515000
    num_steps_trained: 515000
    wait_time_ms: 73.618
  iterations_since_restore: 103
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 878.9182143211365
  time_this_iter_s: 8.416986227035522
  time_total_s: 878.9182143211365
  timestamp: 1594856877
  timesteps_since_restore: 515000
  timesteps_this_iter: 5000
  timesteps_total: 515000
  training_iteration: 103
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 878 s, 103 iter, 515000 ts, -1.55e+04 rew

agent-1: -16.21612468368655
agent-2: -78.9611683164688
agent-3: -176.62704542245112
agent-4: -212.3316419496923
agent-5: -83.17623106112195
Extrinsic Rewards:
2
15
10
8
9
Sum Reward: 44
Avg Reward: 8.8
Min Reward: 2
Max Reward: 15
Gini Coefficient: 0.2545454545454545
20:20 Ratio: 7.5
Max-min Ratio: 7.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-48-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -13965.93532994993
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 103
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.685
    dispatch_time_ms: 8.279
    learner:
      cur_lr: 0.0013257010141387582
      grad_gnorm: 6.25193977355957
      policy_entropy: 40.89545822143555
      policy_loss: -2.2376160621643066
      var_gnorm: 25.92420768737793
      vf_explained_var: 0.0
      vf_loss: 5.663395404815674
    num_steps_sampled: 520000
    num_steps_trained: 520000
    wait_time_ms: 74.361
  iterations_since_restore: 104
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 887.2837328910828
  time_this_iter_s: 8.365518569946289
  time_total_s: 887.2837328910828
  timestamp: 1594856885
  timesteps_since_restore: 520000
  timesteps_this_iter: 5000
  timesteps_total: 520000
  training_iteration: 104
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 887 s, 104 iter, 520000 ts, -1.4e+04 rew

agent-1: -206.173445528877
agent-2: -115.4251248922886
agent-3: -72.06139880651631
agent-4: -147.92125651470698
agent-5: -66.39089640364202
Extrinsic Rewards:
9
11
10
13
4
Sum Reward: 47
Avg Reward: 9.4
Min Reward: 4
Max Reward: 13
Gini Coefficient: 0.1702127659574468
20:20 Ratio: 3.25
Max-min Ratio: 3.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-48-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -12185.860525725591
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 104
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.606
    dispatch_time_ms: 6.631
    learner:
      cur_lr: 0.0013253679499030113
      grad_gnorm: 12.078839302062988
      policy_entropy: 31.851886749267578
      policy_loss: -2.670962333679199
      var_gnorm: 25.94463348388672
      vf_explained_var: 0.0
      vf_loss: 0.8959800004959106
    num_steps_sampled: 525000
    num_steps_trained: 525000
    wait_time_ms: 74.004
  iterations_since_restore: 105
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 895.662549495697
  time_this_iter_s: 8.378816604614258
  time_total_s: 895.662549495697
  timestamp: 1594856893
  timesteps_since_restore: 525000
  timesteps_this_iter: 5000
  timesteps_total: 525000
  training_iteration: 105
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 895 s, 105 iter, 525000 ts, -1.22e+04 rew

agent-1: -117.6217952320621
agent-2: -162.05329175918214
agent-3: -124.71426479135677
agent-4: -185.7165285087919
agent-5: -152.21509841289748
Extrinsic Rewards:
2
4
4
6
6
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 2
Max Reward: 6
Gini Coefficient: 0.18181818181818182
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-48-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -10871.09810552032
  episode_reward_min: -202143.07632735974
  episodes_this_iter: 1
  episodes_total: 105
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.656
    dispatch_time_ms: 9.043
    learner:
      cur_lr: 0.0013250350020825863
      grad_gnorm: 10.056025505065918
      policy_entropy: 37.30425262451172
      policy_loss: 3.3636863231658936
      var_gnorm: 25.950624465942383
      vf_explained_var: 0.0
      vf_loss: 6.920613765716553
    num_steps_sampled: 530000
    num_steps_trained: 530000
    wait_time_ms: 74.4
  iterations_since_restore: 106
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 904.0674941539764
  time_this_iter_s: 8.404944658279419
  time_total_s: 904.0674941539764
  timestamp: 1594856902
  timesteps_since_restore: 530000
  timesteps_this_iter: 5000
  timesteps_total: 530000
  training_iteration: 106
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 904 s, 106 iter, 530000 ts, -1.09e+04 rew

agent-1: -234.62170987115258
agent-2: -38.1606179293683
agent-3: -190.4557795891424
agent-4: -62.382856444572134
agent-5: -94.08024687682772
Extrinsic Rewards:
4
3
13
1
5
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 1
Max Reward: 13
Gini Coefficient: 0.4
20:20 Ratio: 13.0
Max-min Ratio: 13.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-48-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -8855.864354353836
  episode_reward_min: -131459.9000605219
  episodes_this_iter: 1
  episodes_total: 106
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.281
    dispatch_time_ms: 9.761
    learner:
      cur_lr: 0.0013247020542621613
      grad_gnorm: 20.828977584838867
      policy_entropy: 40.93870544433594
      policy_loss: -4.06636905670166
      var_gnorm: 25.94521713256836
      vf_explained_var: 0.0
      vf_loss: 4.77871036529541
    num_steps_sampled: 535000
    num_steps_trained: 535000
    wait_time_ms: 72.018
  iterations_since_restore: 107
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 912.4169840812683
  time_this_iter_s: 8.34948992729187
  time_total_s: 912.4169840812683
  timestamp: 1594856910
  timesteps_since_restore: 535000
  timesteps_this_iter: 5000
  timesteps_total: 535000
  training_iteration: 107
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 912 s, 107 iter, 535000 ts, -8.86e+03 rew

agent-1: -193.62042063971214
agent-2: -153.33264999227
agent-3: -124.251073710329
agent-4: -201.93040108815126
agent-5: -7.358561874135386
Extrinsic Rewards:
8
10
8
9
1
Sum Reward: 36
Avg Reward: 7.2
Min Reward: 1
Max Reward: 10
Gini Coefficient: 0.2111111111111111
20:20 Ratio: 10.0
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-48-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -8134.725684466754
  episode_reward_min: -131459.9000605219
  episodes_this_iter: 1
  episodes_total: 107
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.7
    dispatch_time_ms: 9.158
    learner:
      cur_lr: 0.0013243689900264144
      grad_gnorm: 40.000003814697266
      policy_entropy: 41.5278205871582
      policy_loss: 15.733573913574219
      var_gnorm: 25.953487396240234
      vf_explained_var: 0.0
      vf_loss: 10.611820220947266
    num_steps_sampled: 540000
    num_steps_trained: 540000
    wait_time_ms: 71.908
  iterations_since_restore: 108
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 920.8396761417389
  time_this_iter_s: 8.422692060470581
  time_total_s: 920.8396761417389
  timestamp: 1594856919
  timesteps_since_restore: 540000
  timesteps_this_iter: 5000
  timesteps_total: 540000
  training_iteration: 108
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 920 s, 108 iter, 540000 ts, -8.13e+03 rew

agent-1: -218.65629815493125
agent-2: -17.09840922257641
agent-3: -149.74057512402408
agent-4: -146.8274419467302
agent-5: -143.3933085994654
Extrinsic Rewards:
14
2
8
2
9
Sum Reward: 35
Avg Reward: 7.0
Min Reward: 2
Max Reward: 14
Gini Coefficient: 0.35428571428571426
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-48-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -7033.591112030903
  episode_reward_min: -131459.9000605219
  episodes_this_iter: 1
  episodes_total: 108
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.028
    dispatch_time_ms: 9.551
    learner:
      cur_lr: 0.0013240360422059894
      grad_gnorm: 5.844277381896973
      policy_entropy: 40.499881744384766
      policy_loss: -0.24610275030136108
      var_gnorm: 25.92166519165039
      vf_explained_var: 0.0
      vf_loss: 9.702271461486816
    num_steps_sampled: 545000
    num_steps_trained: 545000
    wait_time_ms: 70.477
  iterations_since_restore: 109
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 929.2354190349579
  time_this_iter_s: 8.395742893218994
  time_total_s: 929.2354190349579
  timestamp: 1594856927
  timesteps_since_restore: 545000
  timesteps_this_iter: 5000
  timesteps_total: 545000
  training_iteration: 109
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 929 s, 109 iter, 545000 ts, -7.03e+03 rew

agent-1: -17.99194338916454
agent-2: -191.68603209692967
agent-3: -249.38241872224722
agent-4: -61.291333979566296
agent-5: -81.23107621671454
Extrinsic Rewards:
1
4
14
5
6
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 1
Max Reward: 14
Gini Coefficient: 0.37333333333333335
20:20 Ratio: 14.0
Max-min Ratio: 14.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-48-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -6584.070711504759
  episode_reward_min: -131459.9000605219
  episodes_this_iter: 1
  episodes_total: 109
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.572
    dispatch_time_ms: 7.61
    learner:
      cur_lr: 0.0013237029779702425
      grad_gnorm: 40.0
      policy_entropy: 41.40324401855469
      policy_loss: 15.754157066345215
      var_gnorm: 25.922941207885742
      vf_explained_var: 0.0
      vf_loss: 10.601861953735352
    num_steps_sampled: 550000
    num_steps_trained: 550000
    wait_time_ms: 72.364
  iterations_since_restore: 110
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 937.6552844047546
  time_this_iter_s: 8.419865369796753
  time_total_s: 937.6552844047546
  timestamp: 1594856936
  timesteps_since_restore: 550000
  timesteps_this_iter: 5000
  timesteps_total: 550000
  training_iteration: 110
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 937 s, 110 iter, 550000 ts, -6.58e+03 rew

agent-1: -19.098637536967264
agent-2: -54.43141330018396
agent-3: -62.28120374279898
agent-4: -245.7205838878008
agent-5: -214.15229199803528
Extrinsic Rewards:
2
6
2
10
9
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 2
Max Reward: 10
Gini Coefficient: 0.31724137931034485
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-49-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -6019.551240151658
  episode_reward_min: -131459.9000605219
  episodes_this_iter: 1
  episodes_total: 110
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.376
    dispatch_time_ms: 10.553
    learner:
      cur_lr: 0.0013233700301498175
      grad_gnorm: 11.010701179504395
      policy_entropy: 41.738853454589844
      policy_loss: -3.924757957458496
      var_gnorm: 25.923131942749023
      vf_explained_var: 0.0
      vf_loss: 5.837628364562988
    num_steps_sampled: 555000
    num_steps_trained: 555000
    wait_time_ms: 72.468
  iterations_since_restore: 111
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 946.2897572517395
  time_this_iter_s: 8.634472846984863
  time_total_s: 946.2897572517395
  timestamp: 1594856944
  timesteps_since_restore: 555000
  timesteps_this_iter: 5000
  timesteps_total: 555000
  training_iteration: 111
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 946 s, 111 iter, 555000 ts, -6.02e+03 rew

W0715 19:49:13.981860 22529 node_manager.cc:250] Last heartbeat was sent 575 ms ago 
agent-1: -217.7983794287437
agent-2: -41.23626487572456
agent-3: -263.29900937553043
agent-4: -27.385409101074483
agent-5: -141.59002243536958
Extrinsic Rewards:
6
1
10
1
0
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 0
Max Reward: 10
Gini Coefficient: 0.5555555555555556
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: -124.67839577600942
agent-2: -226.313119501478
agent-3: -68.05072816871512
agent-4: -50.951074514181244
agent-5: -179.8191462079004
Extrinsic Rewards:
10
6
2
3
8
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 2
Max Reward: 10
Gini Coefficient: 0.2896551724137931
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-49-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -3567.0263431886583
  episode_reward_min: -100523.89716408448
  episodes_this_iter: 2
  episodes_total: 112
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.871
    dispatch_time_ms: 15.071
    learner:
      cur_lr: 0.0013230369659140706
      grad_gnorm: 40.0
      policy_entropy: 41.87433624267578
      policy_loss: 603.1582641601562
      var_gnorm: 25.96739959716797
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5119.369140625
    num_steps_sampled: 560000
    num_steps_trained: 560000
    wait_time_ms: 60.611
  iterations_since_restore: 112
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 957.3720414638519
  time_this_iter_s: 11.082284212112427
  time_total_s: 957.3720414638519
  timestamp: 1594856955
  timesteps_since_restore: 560000
  timesteps_this_iter: 5000
  timesteps_total: 560000
  training_iteration: 112
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 957 s, 112 iter, 560000 ts, -3.57e+03 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-49-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -3567.0263431886588
  episode_reward_min: -100523.89716408448
  episodes_this_iter: 0
  episodes_total: 112
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.716
    dispatch_time_ms: 9.886
    learner:
      cur_lr: 0.0013227040180936456
      grad_gnorm: 14.16309928894043
      policy_entropy: 33.75798416137695
      policy_loss: -3.4695074558258057
      var_gnorm: 25.922094345092773
      vf_explained_var: 0.0
      vf_loss: 8.075801849365234
    num_steps_sampled: 565000
    num_steps_trained: 565000
    wait_time_ms: 73.81
  iterations_since_restore: 113
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 965.3817687034607
  time_this_iter_s: 8.009727239608765
  time_total_s: 965.3817687034607
  timestamp: 1594856964
  timesteps_since_restore: 565000
  timesteps_this_iter: 5000
  timesteps_total: 565000
  training_iteration: 113
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 965 s, 113 iter, 565000 ts, -3.57e+03 rew

agent-1: -47.33858598219054
agent-2: -263.08507788043954
agent-3: -161.0487258543921
agent-4: -78.63042780834863
agent-5: -71.2217014069193
Extrinsic Rewards:
1
9
4
2
2
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.4
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-49-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -2568.000616737137
  episode_reward_min: -84744.58263798722
  episodes_this_iter: 1
  episodes_total: 113
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.196
    dispatch_time_ms: 9.015
    learner:
      cur_lr: 0.0013223709538578987
      grad_gnorm: 24.286222457885742
      policy_entropy: 54.86288833618164
      policy_loss: -1.434166669845581
      var_gnorm: 25.9198055267334
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 8.042315483093262
    num_steps_sampled: 570000
    num_steps_trained: 570000
    wait_time_ms: 72.402
  iterations_since_restore: 114
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 973.9293503761292
  time_this_iter_s: 8.547581672668457
  time_total_s: 973.9293503761292
  timestamp: 1594856973
  timesteps_since_restore: 570000
  timesteps_this_iter: 5000
  timesteps_total: 570000
  training_iteration: 114
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 973 s, 114 iter, 570000 ts, -2.57e+03 rew

agent-1: -124.39514207398312
agent-2: -268.7246799934013
agent-3: -40.60393148749693
agent-4: -41.16221014692382
agent-5: -74.8597090625615
Extrinsic Rewards:
5
10
2
2
5
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 2
Max Reward: 10
Gini Coefficient: 0.31666666666666665
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-49-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -1726.0522470849087
  episode_reward_min: -44391.90896716852
  episodes_this_iter: 1
  episodes_total: 114
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.793
    dispatch_time_ms: 11.969
    learner:
      cur_lr: 0.0013220380060374737
      grad_gnorm: 7.969203472137451
      policy_entropy: 54.152069091796875
      policy_loss: 0.2148219496011734
      var_gnorm: 25.96599006652832
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 0.7627809643745422
    num_steps_sampled: 575000
    num_steps_trained: 575000
    wait_time_ms: 72.188
  iterations_since_restore: 115
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 982.5088813304901
  time_this_iter_s: 8.579530954360962
  time_total_s: 982.5088813304901
  timestamp: 1594856981
  timesteps_since_restore: 575000
  timesteps_this_iter: 5000
  timesteps_total: 575000
  training_iteration: 115
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 982 s, 115 iter, 575000 ts, -1.73e+03 rew

agent-1: -95.72021813321214
agent-2: -156.40938985584427
agent-3: -171.6447512832066
agent-4: -199.62914012689228
agent-5: -104.24479624881629
Extrinsic Rewards:
4
6
4
7
4
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 4
Max Reward: 7
Gini Coefficient: 0.128
20:20 Ratio: 1.75
Max-min Ratio: 1.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-49-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -1446.6435009124898
  episode_reward_min: -44391.90896716852
  episodes_this_iter: 1
  episodes_total: 115
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 4.141
    dispatch_time_ms: 14.077
    learner:
      cur_lr: 0.0013217049418017268
      grad_gnorm: 4.709904670715332
      policy_entropy: 61.093780517578125
      policy_loss: -0.10203468799591064
      var_gnorm: 25.973909378051758
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.7323695421218872
    num_steps_sampled: 580000
    num_steps_trained: 580000
    wait_time_ms: 70.614
  iterations_since_restore: 116
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 991.0875062942505
  time_this_iter_s: 8.578624963760376
  time_total_s: 991.0875062942505
  timestamp: 1594856990
  timesteps_since_restore: 580000
  timesteps_this_iter: 5000
  timesteps_total: 580000
  training_iteration: 116
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 991 s, 116 iter, 580000 ts, -1.45e+03 rew

agent-1: -191.9460682550005
agent-2: -104.35296189934364
agent-3: -159.22358214128442
agent-4: -150.94934700889158
agent-5: -147.8232923879815
Extrinsic Rewards:
5
2
4
3
4
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 2
Max Reward: 5
Gini Coefficient: 0.15555555555555556
20:20 Ratio: 2.5
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-49-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -1010.2673637577299
  episode_reward_min: -6656.0888842062905
  episodes_this_iter: 1
  episodes_total: 116
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.049
    dispatch_time_ms: 11.152
    learner:
      cur_lr: 0.0013213719939813018
      grad_gnorm: 15.733614921569824
      policy_entropy: 66.56742095947266
      policy_loss: -3.451949119567871
      var_gnorm: 25.955772399902344
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 4.013764381408691
    num_steps_sampled: 585000
    num_steps_trained: 585000
    wait_time_ms: 72.37
  iterations_since_restore: 117
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 999.6012089252472
  time_this_iter_s: 8.513702630996704
  time_total_s: 999.6012089252472
  timestamp: 1594856999
  timesteps_since_restore: 585000
  timesteps_this_iter: 5000
  timesteps_total: 585000
  training_iteration: 117
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 999 s, 117 iter, 585000 ts, -1.01e+03 rew

agent-1: -209.60907314707572
agent-2: -180.2033544452508
agent-3: -85.86060648964254
agent-4: -50.036378733069384
agent-5: -181.97778783315857
Extrinsic Rewards:
7
4
3
2
3
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 2
Max Reward: 7
Gini Coefficient: 0.23157894736842105
20:20 Ratio: 3.5
Max-min Ratio: 3.5
agent-1: -177.24090123712767
agent-2: -173.6295029247894
agent-3: -82.80132512383679
agent-4: -209.46778579651698
agent-5: -21.90748408386292
Extrinsic Rewards:
9
3
5
14
4
Sum Reward: 35
Avg Reward: 7.0
Min Reward: 3
Max Reward: 14
Gini Coefficient: 0.30857142857142855
20:20 Ratio: 4.666666666666667
Max-min Ratio: 4.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-50-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -909.4813096793488
  episode_reward_min: -4864.255183940395
  episodes_this_iter: 2
  episodes_total: 118
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.639
    dispatch_time_ms: 8.665
    learner:
      cur_lr: 0.0013210390461608768
      grad_gnorm: 39.999996185302734
      policy_entropy: 59.00161361694336
      policy_loss: 809.8301391601562
      var_gnorm: 25.959461212158203
      vf_explained_var: 0.0
      vf_loss: 4650.904296875
    num_steps_sampled: 590000
    num_steps_trained: 590000
    wait_time_ms: 73.417
  iterations_since_restore: 118
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1007.6292400360107
  time_this_iter_s: 8.02803111076355
  time_total_s: 1007.6292400360107
  timestamp: 1594857008
  timesteps_since_restore: 590000
  timesteps_this_iter: 5000
  timesteps_total: 590000
  training_iteration: 118
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1007 s, 118 iter, 590000 ts, -909 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-50-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -909.4813096793488
  episode_reward_min: -4864.255183940395
  episodes_this_iter: 0
  episodes_total: 118
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.62
    dispatch_time_ms: 11.531
    learner:
      cur_lr: 0.0013207059819251299
      grad_gnorm: 6.467118263244629
      policy_entropy: 61.49416732788086
      policy_loss: -1.4601174592971802
      var_gnorm: 25.96387481689453
      vf_explained_var: 0.0
      vf_loss: 1.6226882934570312
    num_steps_sampled: 595000
    num_steps_trained: 595000
    wait_time_ms: 74.14
  iterations_since_restore: 119
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1016.2547979354858
  time_this_iter_s: 8.625557899475098
  time_total_s: 1016.2547979354858
  timestamp: 1594857016
  timesteps_since_restore: 595000
  timesteps_this_iter: 5000
  timesteps_total: 595000
  training_iteration: 119
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1016 s, 119 iter, 595000 ts, -909 rew

agent-1: -162.2754385502074
agent-2: -129.34872875535945
agent-3: -197.82284588963267
agent-4: -81.22813139438044
agent-5: -178.2250480927386
Extrinsic Rewards:
4
3
6
1
6
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 1
Max Reward: 6
Gini Coefficient: 0.26
20:20 Ratio: 6.0
Max-min Ratio: 6.0
agent-1: -88.29039689814523
agent-2: -195.02727990478243
agent-3: -213.60795677986394
agent-4: -150.85238837875565
agent-5: -196.20931631355373
Extrinsic Rewards:
2
5
6
0
5
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 0
Max Reward: 6
Gini Coefficient: 0.3333333333333333
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-50-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -843.3233822459422
  episode_reward_min: -2181.635203169405
  episodes_this_iter: 2
  episodes_total: 120
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.801
    dispatch_time_ms: 14.674
    learner:
      cur_lr: 0.0013203730341047049
      grad_gnorm: 39.999996185302734
      policy_entropy: 63.310646057128906
      policy_loss: 945.2600708007812
      var_gnorm: 26.024526596069336
      vf_explained_var: -3.5762786865234375e-07
      vf_loss: 6873.03662109375
    num_steps_sampled: 600000
    num_steps_trained: 600000
    wait_time_ms: 72.784
  iterations_since_restore: 120
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1024.882726430893
  time_this_iter_s: 8.627928495407104
  time_total_s: 1024.882726430893
  timestamp: 1594857025
  timesteps_since_restore: 600000
  timesteps_this_iter: 5000
  timesteps_total: 600000
  training_iteration: 120
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1024 s, 120 iter, 600000 ts, -843 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-50-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -843.3233822459422
  episode_reward_min: -2181.635203169405
  episodes_this_iter: 0
  episodes_total: 120
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 4.845
    dispatch_time_ms: 14.919
    learner:
      cur_lr: 0.001320039969868958
      grad_gnorm: 8.591787338256836
      policy_entropy: 59.43003463745117
      policy_loss: -2.1027441024780273
      var_gnorm: 25.951095581054688
      vf_explained_var: 0.0
      vf_loss: 5.522350788116455
    num_steps_sampled: 605000
    num_steps_trained: 605000
    wait_time_ms: 72.025
  iterations_since_restore: 121
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1033.1634645462036
  time_this_iter_s: 8.280738115310669
  time_total_s: 1033.1634645462036
  timestamp: 1594857034
  timesteps_since_restore: 605000
  timesteps_this_iter: 5000
  timesteps_total: 605000
  training_iteration: 121
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1033 s, 121 iter, 605000 ts, -843 rew

agent-1: -247.8546875614539
agent-2: -79.7126072755623
agent-3: -138.179620065322
agent-4: -199.59395763987723
agent-5: -113.93301616939037
Extrinsic Rewards:
8
4
0
6
2
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.4
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: -218.57891930906501
agent-2: -145.28662426863065
agent-3: -132.49094110322483
agent-4: -234.364664223646
agent-5: -75.29730500588435
Extrinsic Rewards:
5
0
4
6
2
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 0
Max Reward: 6
Gini Coefficient: 0.35294117647058826
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-50-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -830.5892337240996
  episode_reward_min: -2181.635203169405
  episodes_this_iter: 2
  episodes_total: 122
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.765
    dispatch_time_ms: 26.354
    learner:
      cur_lr: 0.001319707022048533
      grad_gnorm: 40.000003814697266
      policy_entropy: 69.96131896972656
      policy_loss: 1276.552490234375
      var_gnorm: 26.028148651123047
      vf_explained_var: -5.960464477539062e-07
      vf_loss: 7039.283203125
    num_steps_sampled: 610000
    num_steps_trained: 610000
    wait_time_ms: 64.566
  iterations_since_restore: 122
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1046.816954612732
  time_this_iter_s: 13.65349006652832
  time_total_s: 1046.816954612732
  timestamp: 1594857048
  timesteps_since_restore: 610000
  timesteps_this_iter: 5000
  timesteps_total: 610000
  training_iteration: 122
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1046 s, 122 iter, 610000 ts, -831 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-50-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -830.5892337240998
  episode_reward_min: -2181.635203169405
  episodes_this_iter: 0
  episodes_total: 122
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.436
    dispatch_time_ms: 28.035
    learner:
      cur_lr: 0.001319373957812786
      grad_gnorm: 32.24076843261719
      policy_entropy: 74.39547729492188
      policy_loss: 12.579813003540039
      var_gnorm: 25.97456932067871
      vf_explained_var: 0.0
      vf_loss: 5.492612361907959
    num_steps_sampled: 615000
    num_steps_trained: 615000
    wait_time_ms: 43.321
  iterations_since_restore: 123
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1056.3293719291687
  time_this_iter_s: 9.512417316436768
  time_total_s: 1056.3293719291687
  timestamp: 1594857057
  timesteps_since_restore: 615000
  timesteps_this_iter: 5000
  timesteps_total: 615000
  training_iteration: 123
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1056 s, 123 iter, 615000 ts, -831 rew

agent-1: -20.6663217021983
agent-2: -78.14896194710253
agent-3: -169.13026464478153
agent-4: -109.75784822163936
agent-5: -250.17265291177168
Extrinsic Rewards:
1
4
3
4
11
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 1
Max Reward: 11
Gini Coefficient: 0.3652173913043478
20:20 Ratio: 11.0
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-51-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -818.0788229269366
  episode_reward_min: -2181.635203169405
  episodes_this_iter: 1
  episodes_total: 123
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.736
    dispatch_time_ms: 26.662
    learner:
      cur_lr: 0.001319041009992361
      grad_gnorm: 33.13078689575195
      policy_entropy: 67.25923919677734
      policy_loss: 15.820143699645996
      var_gnorm: 25.955413818359375
      vf_explained_var: -0.6784465312957764
      vf_loss: 15.826079368591309
    num_steps_sampled: 620000
    num_steps_trained: 620000
    wait_time_ms: 40.321
  iterations_since_restore: 124
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1065.0783920288086
  time_this_iter_s: 8.749020099639893
  time_total_s: 1065.0783920288086
  timestamp: 1594857066
  timesteps_since_restore: 620000
  timesteps_this_iter: 5000
  timesteps_total: 620000
  training_iteration: 124
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1065 s, 124 iter, 620000 ts, -818 rew

agent-1: -55.463745577064884
agent-2: -112.57907543113214
agent-3: -172.1037718771681
agent-4: -241.99743627429478
agent-5: -72.23259107842641
Extrinsic Rewards:
5
3
5
8
2
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 2
Max Reward: 8
Gini Coefficient: 0.24347826086956523
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-51-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -808.1877824427597
  episode_reward_min: -2181.635203169405
  episodes_this_iter: 1
  episodes_total: 124
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.699
    dispatch_time_ms: 68.618
    learner:
      cur_lr: 0.0013187079457566142
      grad_gnorm: 20.564271926879883
      policy_entropy: 67.1484375
      policy_loss: 3.0166971683502197
      var_gnorm: 25.93817138671875
      vf_explained_var: 0.0
      vf_loss: 6.35100793838501
    num_steps_sampled: 625000
    num_steps_trained: 625000
    wait_time_ms: 32.115
  iterations_since_restore: 125
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1074.0743918418884
  time_this_iter_s: 8.995999813079834
  time_total_s: 1074.0743918418884
  timestamp: 1594857075
  timesteps_since_restore: 625000
  timesteps_this_iter: 5000
  timesteps_total: 625000
  training_iteration: 125
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1074 s, 125 iter, 625000 ts, -808 rew

agent-1: -137.86753503613687
agent-2: -98.28852540909351
agent-3: -60.729399615214206
agent-4: -265.11038142104235
agent-5: -155.05318193172076
Extrinsic Rewards:
0
3
1
12
8
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 0
Max Reward: 12
Gini Coefficient: 0.5166666666666667
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: -13.750062070907845
agent-2: -226.42667380657772
agent-3: -206.01657702372756
agent-4: -179.18087324087415
agent-5: -17.022911243995264
Extrinsic Rewards:
1
7
10
2
1
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 1
Max Reward: 10
Gini Coefficient: 0.45714285714285713
20:20 Ratio: 10.0
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-51-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -799.1900229567557
  episode_reward_min: -2181.635203169405
  episodes_this_iter: 2
  episodes_total: 126
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.054
    dispatch_time_ms: 19.169
    learner:
      cur_lr: 0.0013183749979361892
      grad_gnorm: 40.0
      policy_entropy: 67.56410217285156
      policy_loss: 936.617919921875
      var_gnorm: 25.980289459228516
      vf_explained_var: 0.0
      vf_loss: 5218.89111328125
    num_steps_sampled: 630000
    num_steps_trained: 630000
    wait_time_ms: 60.518
  iterations_since_restore: 126
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1082.8128988742828
  time_this_iter_s: 8.73850703239441
  time_total_s: 1082.8128988742828
  timestamp: 1594857084
  timesteps_since_restore: 630000
  timesteps_this_iter: 5000
  timesteps_total: 630000
  training_iteration: 126
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1082 s, 126 iter, 630000 ts, -799 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-51-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -799.190022956756
  episode_reward_min: -2181.635203169405
  episodes_this_iter: 0
  episodes_total: 126
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.454
    dispatch_time_ms: 35.535
    learner:
      cur_lr: 0.0013180420501157641
      grad_gnorm: 20.182729721069336
      policy_entropy: 63.100860595703125
      policy_loss: -7.923707962036133
      var_gnorm: 25.954511642456055
      vf_explained_var: 0.0
      vf_loss: 4.083095073699951
    num_steps_sampled: 635000
    num_steps_trained: 635000
    wait_time_ms: 42.721
  iterations_since_restore: 127
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1091.512451171875
  time_this_iter_s: 8.699552297592163
  time_total_s: 1091.512451171875
  timestamp: 1594857093
  timesteps_since_restore: 635000
  timesteps_this_iter: 5000
  timesteps_total: 635000
  training_iteration: 127
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1091 s, 127 iter, 635000 ts, -799 rew

agent-1: -240.00680158383534
agent-2: -213.75684657420854
agent-3: -21.01373120937219
agent-4: -111.57074079205442
agent-5: -52.383456413648545
Extrinsic Rewards:
10
6
1
2
1
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 1
Max Reward: 10
Gini Coefficient: 0.46
20:20 Ratio: 10.0
Max-min Ratio: 10.0
agent-1: -239.6282166761717
agent-2: -192.70985191967367
agent-3: -150.33864746497196
agent-4: -148.79885880857523
agent-5: -94.01971833660215
Extrinsic Rewards:
7
5
3
0
2
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.4
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-51-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -792.9769612892997
  episode_reward_min: -2181.635203169405
  episodes_this_iter: 1
  episodes_total: 127
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.086
    dispatch_time_ms: 18.013
    learner:
      cur_lr: 0.0013177089858800173
      grad_gnorm: 40.0
      policy_entropy: 75.47335052490234
      policy_loss: 53.01967239379883
      var_gnorm: 25.99786376953125
      vf_explained_var: -1.0
      vf_loss: 43.1536865234375
    num_steps_sampled: 640000
    num_steps_trained: 640000
    wait_time_ms: 68.987
  iterations_since_restore: 128
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1100.449958562851
  time_this_iter_s: 8.937507390975952
  time_total_s: 1100.449958562851
  timestamp: 1594857102
  timesteps_since_restore: 640000
  timesteps_this_iter: 5000
  timesteps_total: 640000
  training_iteration: 128
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1100 s, 128 iter, 640000 ts, -793 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-51-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -784.631721839119
  episode_reward_min: -2181.635203169405
  episodes_this_iter: 1
  episodes_total: 128
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.688
    dispatch_time_ms: 21.559
    learner:
      cur_lr: 0.0013173760380595922
      grad_gnorm: 21.318002700805664
      policy_entropy: 63.286773681640625
      policy_loss: -1.2061471939086914
      var_gnorm: 25.954057693481445
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 8.964812278747559
    num_steps_sampled: 645000
    num_steps_trained: 645000
    wait_time_ms: 61.118
  iterations_since_restore: 129
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1109.2884755134583
  time_this_iter_s: 8.8385169506073
  time_total_s: 1109.2884755134583
  timestamp: 1594857111
  timesteps_since_restore: 645000
  timesteps_this_iter: 5000
  timesteps_total: 645000
  training_iteration: 129
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1109 s, 129 iter, 645000 ts, -785 rew

agent-1: -24.300144031222146
agent-2: -203.90113261696786
agent-3: -71.8800420284241
agent-4: -141.55352036583201
agent-5: -265.93225003284755
Extrinsic Rewards:
1
3
3
0
11
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 0
Max Reward: 11
Gini Coefficient: 0.5333333333333333
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: -76.03817325017806
agent-2: -215.3913122526322
agent-3: -184.0373954853165
agent-4: -106.6125773612509
agent-5: -124.68847381549669
Extrinsic Rewards:
2
6
7
4
3
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 2
Max Reward: 7
Gini Coefficient: 0.23636363636363636
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-52-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -768.1225450149119
  episode_reward_min: -2181.635203169405
  episodes_this_iter: 2
  episodes_total: 130
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.535
    dispatch_time_ms: 21.542
    learner:
      cur_lr: 0.0013170429738238454
      grad_gnorm: 40.0
      policy_entropy: 73.00340270996094
      policy_loss: 993.313232421875
      var_gnorm: 25.995853424072266
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 5620.35498046875
    num_steps_sampled: 650000
    num_steps_trained: 650000
    wait_time_ms: 67.665
  iterations_since_restore: 130
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1118.3683292865753
  time_this_iter_s: 9.079853773117065
  time_total_s: 1118.3683292865753
  timestamp: 1594857120
  timesteps_since_restore: 650000
  timesteps_this_iter: 5000
  timesteps_total: 650000
  training_iteration: 130
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1118 s, 130 iter, 650000 ts, -768 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-52-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -768.1225450149119
  episode_reward_min: -2181.635203169405
  episodes_this_iter: 0
  episodes_total: 130
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.483
    dispatch_time_ms: 54.26
    learner:
      cur_lr: 0.0013167100260034204
      grad_gnorm: 32.48925018310547
      policy_entropy: 68.4635238647461
      policy_loss: -2.987945556640625
      var_gnorm: 25.958803176879883
      vf_explained_var: 0.0
      vf_loss: 4.032785892486572
    num_steps_sampled: 655000
    num_steps_trained: 655000
    wait_time_ms: 41.701
  iterations_since_restore: 131
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1127.324836730957
  time_this_iter_s: 8.956507444381714
  time_total_s: 1127.324836730957
  timestamp: 1594857129
  timesteps_since_restore: 655000
  timesteps_this_iter: 5000
  timesteps_total: 655000
  training_iteration: 131
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1127 s, 131 iter, 655000 ts, -768 rew

agent-1: -118.20019566344965
agent-2: -153.63770293984055
agent-3: -251.2866727090618
agent-4: -144.6944394885754
agent-5: -151.54075316152966
Extrinsic Rewards:
2
2
8
3
0
Sum Reward: 15
Avg Reward: 3.0
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.4533333333333333
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-52-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -760.2477651118346
  episode_reward_min: -2181.635203169405
  episodes_this_iter: 1
  episodes_total: 131
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.022
    dispatch_time_ms: 31.211
    learner:
      cur_lr: 0.0013163769617676735
      grad_gnorm: 40.0
      policy_entropy: 73.0224609375
      policy_loss: 30.671218872070312
      var_gnorm: 26.01840591430664
      vf_explained_var: -1.0
      vf_loss: 26.842561721801758
    num_steps_sampled: 660000
    num_steps_trained: 660000
    wait_time_ms: 55.257
  iterations_since_restore: 132
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1136.1101500988007
  time_this_iter_s: 8.785313367843628
  time_total_s: 1136.1101500988007
  timestamp: 1594857137
  timesteps_since_restore: 660000
  timesteps_this_iter: 5000
  timesteps_total: 660000
  training_iteration: 132
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1136 s, 132 iter, 660000 ts, -760 rew

agent-1: -105.65054563524583
agent-2: -42.95769803687571
agent-3: -145.8515921575893
agent-4: -253.77090250278934
agent-5: -61.77770453343507
Extrinsic Rewards:
0
5
4
8
6
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.3130434782608696
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-52-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -760.183020814497
  episode_reward_min: -2181.635203169405
  episodes_this_iter: 1
  episodes_total: 132
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.278
    dispatch_time_ms: 26.572
    learner:
      cur_lr: 0.0013160440139472485
      grad_gnorm: 15.324564933776855
      policy_entropy: 73.90232849121094
      policy_loss: -4.979019641876221
      var_gnorm: 25.96763801574707
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.8043813705444336
    num_steps_sampled: 665000
    num_steps_trained: 665000
    wait_time_ms: 61.405
  iterations_since_restore: 133
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1144.9422883987427
  time_this_iter_s: 8.832138299942017
  time_total_s: 1144.9422883987427
  timestamp: 1594857146
  timesteps_since_restore: 665000
  timesteps_this_iter: 5000
  timesteps_total: 665000
  training_iteration: 133
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1144 s, 133 iter, 665000 ts, -760 rew

agent-1: -111.5905791291269
agent-2: -145.23575904200825
agent-3: -163.16692830575607
agent-4: -205.59889695377836
agent-5: -72.42793126829721
Extrinsic Rewards:
4
7
3
10
6
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 3
Max Reward: 10
Gini Coefficient: 0.22666666666666666
20:20 Ratio: 3.3333333333333335
Max-min Ratio: 3.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-52-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -760.5010751392114
  episode_reward_min: -2181.635203169405
  episodes_this_iter: 1
  episodes_total: 133
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.995
    dispatch_time_ms: 12.834
    learner:
      cur_lr: 0.0013157109497115016
      grad_gnorm: 39.99999237060547
      policy_entropy: 55.472984313964844
      policy_loss: 23.21259307861328
      var_gnorm: 25.96404457092285
      vf_explained_var: 0.0
      vf_loss: 18.731599807739258
    num_steps_sampled: 670000
    num_steps_trained: 670000
    wait_time_ms: 75.421
  iterations_since_restore: 134
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1153.7987279891968
  time_this_iter_s: 8.856439590454102
  time_total_s: 1153.7987279891968
  timestamp: 1594857155
  timesteps_since_restore: 670000
  timesteps_this_iter: 5000
  timesteps_total: 670000
  training_iteration: 134
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1153 s, 134 iter, 670000 ts, -761 rew

agent-1: -60.63000162989245
agent-2: -15.954612128306383
agent-3: -213.72327341364107
agent-4: -175.12371877715623
agent-5: -93.95034403407101
Extrinsic Rewards:
11
2
11
12
10
Sum Reward: 46
Avg Reward: 9.2
Min Reward: 2
Max Reward: 12
Gini Coefficient: 0.1826086956521739
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-52-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -753.6023996152612
  episode_reward_min: -2181.635203169405
  episodes_this_iter: 1
  episodes_total: 134
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 5.175
    dispatch_time_ms: 25.43
    learner:
      cur_lr: 0.0013153780018910766
      grad_gnorm: 40.0
      policy_entropy: 66.65669250488281
      policy_loss: 33.844444274902344
      var_gnorm: 25.929487228393555
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 13.404637336730957
    num_steps_sampled: 675000
    num_steps_trained: 675000
    wait_time_ms: 59.769
  iterations_since_restore: 135
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1162.431824684143
  time_this_iter_s: 8.633096694946289
  time_total_s: 1162.431824684143
  timestamp: 1594857164
  timesteps_since_restore: 675000
  timesteps_this_iter: 5000
  timesteps_total: 675000
  training_iteration: 135
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1162 s, 135 iter, 675000 ts, -754 rew

agent-1: -123.5669207603748
agent-2: -134.60233367567574
agent-3: -41.29715878592181
agent-4: -119.42726657567468
agent-5: -158.62352707319974
Extrinsic Rewards:
11
11
7
18
17
Sum Reward: 64
Avg Reward: 12.8
Min Reward: 7
Max Reward: 18
Gini Coefficient: 0.175
20:20 Ratio: 2.5714285714285716
Max-min Ratio: 2.5714285714285716
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-52-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -744.936688420727
  episode_reward_min: -2181.635203169405
  episodes_this_iter: 1
  episodes_total: 135
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.084
    dispatch_time_ms: 18.161
    learner:
      cur_lr: 0.0013150450540706515
      grad_gnorm: 20.17583465576172
      policy_entropy: 63.976375579833984
      policy_loss: 4.203815937042236
      var_gnorm: 25.951948165893555
      vf_explained_var: 0.0
      vf_loss: 5.443070888519287
    num_steps_sampled: 680000
    num_steps_trained: 680000
    wait_time_ms: 76.124
  iterations_since_restore: 136
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1171.348603963852
  time_this_iter_s: 8.916779279708862
  time_total_s: 1171.348603963852
  timestamp: 1594857173
  timesteps_since_restore: 680000
  timesteps_this_iter: 5000
  timesteps_total: 680000
  training_iteration: 136
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1171 s, 136 iter, 680000 ts, -745 rew

agent-1: -74.7960978339434
agent-2: -54.13279699178947
agent-3: -163.05875378296443
agent-4: -177.5292736161964
agent-5: -104.88930604565773
Extrinsic Rewards:
15
10
18
15
14
Sum Reward: 72
Avg Reward: 14.4
Min Reward: 10
Max Reward: 18
Gini Coefficient: 0.09444444444444444
20:20 Ratio: 1.8
Max-min Ratio: 1.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-53-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -744.7925429868918
  episode_reward_min: -2181.635203169405
  episodes_this_iter: 1
  episodes_total: 136
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.929
    dispatch_time_ms: 25.245
    learner:
      cur_lr: 0.0013147119898349047
      grad_gnorm: 14.355010986328125
      policy_entropy: 47.04956817626953
      policy_loss: 4.084153175354004
      var_gnorm: 25.965253829956055
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.705175399780273
    num_steps_sampled: 685000
    num_steps_trained: 685000
    wait_time_ms: 67.165
  iterations_since_restore: 137
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1180.1102893352509
  time_this_iter_s: 8.761685371398926
  time_total_s: 1180.1102893352509
  timestamp: 1594857182
  timesteps_since_restore: 685000
  timesteps_this_iter: 5000
  timesteps_total: 685000
  training_iteration: 137
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1180 s, 137 iter, 685000 ts, -745 rew

agent-1: -166.71075169009694
agent-2: -56.97333637387814
agent-3: -200.5408368856309
agent-4: -126.60420902257803
agent-5: -176.04744297533435
Extrinsic Rewards:
6
2
7
3
3
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 2
Max Reward: 7
Gini Coefficient: 0.24761904761904763
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-53-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -744.7448126182576
  episode_reward_min: -2181.635203169405
  episodes_this_iter: 1
  episodes_total: 137
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.516
    dispatch_time_ms: 33.328
    learner:
      cur_lr: 0.0013143790420144796
      grad_gnorm: 7.788535118103027
      policy_entropy: 36.69789123535156
      policy_loss: 4.324720859527588
      var_gnorm: 25.9746036529541
      vf_explained_var: 0.0
      vf_loss: 5.7258453369140625
    num_steps_sampled: 690000
    num_steps_trained: 690000
    wait_time_ms: 42.056
  iterations_since_restore: 138
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1189.0668506622314
  time_this_iter_s: 8.95656132698059
  time_total_s: 1189.0668506622314
  timestamp: 1594857191
  timesteps_since_restore: 690000
  timesteps_this_iter: 5000
  timesteps_total: 690000
  training_iteration: 138
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1189 s, 138 iter, 690000 ts, -745 rew

agent-1: -107.74259181637719
agent-2: -189.83067267656446
agent-3: -52.3839076212247
agent-4: -77.30716520627374
agent-5: -226.22069898282706
Extrinsic Rewards:
7
4
7
5
14
Sum Reward: 37
Avg Reward: 7.4
Min Reward: 4
Max Reward: 14
Gini Coefficient: 0.23783783783783785
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-53-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -743.0044138538834
  episode_reward_min: -2181.635203169405
  episodes_this_iter: 1
  episodes_total: 138
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.539
    dispatch_time_ms: 20.001
    learner:
      cur_lr: 0.0013140459777787328
      grad_gnorm: 30.826663970947266
      policy_entropy: 68.88482666015625
      policy_loss: 8.388853073120117
      var_gnorm: 25.934051513671875
      vf_explained_var: 0.0
      vf_loss: 8.716660499572754
    num_steps_sampled: 695000
    num_steps_trained: 695000
    wait_time_ms: 70.665
  iterations_since_restore: 139
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1197.841875553131
  time_this_iter_s: 8.775024890899658
  time_total_s: 1197.841875553131
  timestamp: 1594857200
  timesteps_since_restore: 695000
  timesteps_this_iter: 5000
  timesteps_total: 695000
  training_iteration: 139
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1197 s, 139 iter, 695000 ts, -743 rew

agent-1: -179.7478037736453
agent-2: -86.65039847362227
agent-3: -65.59059520750637
agent-4: -71.56614882964999
agent-5: -143.96417421008465
Extrinsic Rewards:
9
14
8
5
17
Sum Reward: 53
Avg Reward: 10.6
Min Reward: 5
Max Reward: 17
Gini Coefficient: 0.22641509433962265
20:20 Ratio: 3.4
Max-min Ratio: 3.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-53-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -741.8705809752523
  episode_reward_min: -2181.635203169405
  episodes_this_iter: 1
  episodes_total: 139
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.809
    dispatch_time_ms: 24.766
    learner:
      cur_lr: 0.0013137130299583077
      grad_gnorm: 40.0
      policy_entropy: 69.50311279296875
      policy_loss: 41.23815155029297
      var_gnorm: 25.950830459594727
      vf_explained_var: 0.0
      vf_loss: 31.894615173339844
    num_steps_sampled: 700000
    num_steps_trained: 700000
    wait_time_ms: 66.807
  iterations_since_restore: 140
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1206.756497144699
  time_this_iter_s: 8.914621591567993
  time_total_s: 1206.756497144699
  timestamp: 1594857208
  timesteps_since_restore: 700000
  timesteps_this_iter: 5000
  timesteps_total: 700000
  training_iteration: 140
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1206 s, 140 iter, 700000 ts, -742 rew

agent-1: -147.3980446236724
agent-2: -23.009207535881906
agent-3: -163.01783297172793
agent-4: -123.16056750539552
agent-5: -171.39814403357062
Extrinsic Rewards:
19
2
14
16
9
Sum Reward: 60
Avg Reward: 12.0
Min Reward: 2
Max Reward: 19
Gini Coefficient: 0.2733333333333333
20:20 Ratio: 9.5
Max-min Ratio: 9.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-53-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -733.667578401514
  episode_reward_min: -2181.635203169405
  episodes_this_iter: 1
  episodes_total: 140
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.612
    dispatch_time_ms: 36.926
    learner:
      cur_lr: 0.0013133799657225609
      grad_gnorm: 26.199356079101562
      policy_entropy: 48.96026611328125
      policy_loss: -15.098501205444336
      var_gnorm: 25.972482681274414
      vf_explained_var: 0.0
      vf_loss: 2.5965285301208496
    num_steps_sampled: 705000
    num_steps_trained: 705000
    wait_time_ms: 51.668
  iterations_since_restore: 141
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1215.5804336071014
  time_this_iter_s: 8.823936462402344
  time_total_s: 1215.5804336071014
  timestamp: 1594857217
  timesteps_since_restore: 705000
  timesteps_this_iter: 5000
  timesteps_total: 705000
  training_iteration: 141
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1215 s, 141 iter, 705000 ts, -734 rew

agent-1: -163.16757284937665
agent-2: -103.60689042633336
agent-3: -220.3019135066927
agent-4: -140.29917190871018
agent-5: -195.77307632433894
Extrinsic Rewards:
4
2
9
0
2
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.47058823529411764
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-53-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -736.4257021479992
  episode_reward_min: -2181.635203169405
  episodes_this_iter: 1
  episodes_total: 141
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.993
    dispatch_time_ms: 35.97
    learner:
      cur_lr: 0.0013130470179021358
      grad_gnorm: 40.000003814697266
      policy_entropy: 54.163734436035156
      policy_loss: 56.02922058105469
      var_gnorm: 26.0178279876709
      vf_explained_var: 0.0
      vf_loss: 28.23101043701172
    num_steps_sampled: 710000
    num_steps_trained: 710000
    wait_time_ms: 50.346
  iterations_since_restore: 142
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1224.4090647697449
  time_this_iter_s: 8.828631162643433
  time_total_s: 1224.4090647697449
  timestamp: 1594857226
  timesteps_since_restore: 710000
  timesteps_this_iter: 5000
  timesteps_total: 710000
  training_iteration: 142
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1224 s, 142 iter, 710000 ts, -736 rew

agent-1: -203.89872260476255
agent-2: -105.45072272300048
agent-3: -105.60491309777595
agent-4: -70.82142230750597
agent-5: -219.16891115588797
Extrinsic Rewards:
7
2
3
2
5
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 2
Max Reward: 7
Gini Coefficient: 0.2736842105263158
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-53-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -736.8999708709094
  episode_reward_min: -2181.635203169405
  episodes_this_iter: 1
  episodes_total: 142
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.892
    dispatch_time_ms: 29.527
    learner:
      cur_lr: 0.001312713953666389
      grad_gnorm: 16.598026275634766
      policy_entropy: 49.61030960083008
      policy_loss: 4.803751468658447
      var_gnorm: 25.973915100097656
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 4.478088855743408
    num_steps_sampled: 715000
    num_steps_trained: 715000
    wait_time_ms: 58.621
  iterations_since_restore: 143
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1233.1531648635864
  time_this_iter_s: 8.744100093841553
  time_total_s: 1233.1531648635864
  timestamp: 1594857235
  timesteps_since_restore: 715000
  timesteps_this_iter: 5000
  timesteps_total: 715000
  training_iteration: 143
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1233 s, 143 iter, 715000 ts, -737 rew

agent-1: -90.43401934690412
agent-2: -209.28505343363605
agent-3: -239.40715696763365
agent-4: -137.862792700522
agent-5: -92.57841784789221
Extrinsic Rewards:
4
9
11
0
2
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 0
Max Reward: 11
Gini Coefficient: 0.4461538461538462
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-54-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -735.9191976609944
  episode_reward_min: -2181.635203169405
  episodes_this_iter: 1
  episodes_total: 143
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.169
    dispatch_time_ms: 41.69
    learner:
      cur_lr: 0.001312381005845964
      grad_gnorm: 34.54278564453125
      policy_entropy: 65.2198257446289
      policy_loss: 16.86690330505371
      var_gnorm: 26.010408401489258
      vf_explained_var: 0.0
      vf_loss: 6.369272708892822
    num_steps_sampled: 720000
    num_steps_trained: 720000
    wait_time_ms: 35.83
  iterations_since_restore: 144
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1242.1262516975403
  time_this_iter_s: 8.973086833953857
  time_total_s: 1242.1262516975403
  timestamp: 1594857244
  timesteps_since_restore: 720000
  timesteps_this_iter: 5000
  timesteps_total: 720000
  training_iteration: 144
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1242 s, 144 iter, 720000 ts, -736 rew

agent-1: -52.675791105441704
agent-2: -189.85091337862386
agent-3: -104.58755075963988
agent-4: -140.19270735795942
agent-5: -196.79983065338482
Extrinsic Rewards:
7
7
5
8
4
Sum Reward: 31
Avg Reward: 6.2
Min Reward: 4
Max Reward: 8
Gini Coefficient: 0.12903225806451613
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-54-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -729.6811912039446
  episode_reward_min: -2181.635203169405
  episodes_this_iter: 1
  episodes_total: 144
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.306
    dispatch_time_ms: 27.198
    learner:
      cur_lr: 0.001312048058025539
      grad_gnorm: 28.837013244628906
      policy_entropy: 69.96823120117188
      policy_loss: 0.022052884101867676
      var_gnorm: 25.96025276184082
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 9.647820472717285
    num_steps_sampled: 725000
    num_steps_trained: 725000
    wait_time_ms: 45.566
  iterations_since_restore: 145
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1250.8576798439026
  time_this_iter_s: 8.731428146362305
  time_total_s: 1250.8576798439026
  timestamp: 1594857253
  timesteps_since_restore: 725000
  timesteps_this_iter: 5000
  timesteps_total: 725000
  training_iteration: 145
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1250 s, 145 iter, 725000 ts, -730 rew

agent-1: -78.01723999950616
agent-2: -103.68481401131747
agent-3: -123.59543447701316
agent-4: -98.82988117667742
agent-5: -223.9113684954205
Extrinsic Rewards:
11
4
9
10
8
Sum Reward: 42
Avg Reward: 8.4
Min Reward: 4
Max Reward: 11
Gini Coefficient: 0.1523809523809524
20:20 Ratio: 2.75
Max-min Ratio: 2.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-54-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -717.3885874941246
  episode_reward_min: -2181.635203169405
  episodes_this_iter: 1
  episodes_total: 145
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.276
    dispatch_time_ms: 31.44
    learner:
      cur_lr: 0.001311714993789792
      grad_gnorm: 33.14960861206055
      policy_entropy: 56.40788650512695
      policy_loss: -16.836416244506836
      var_gnorm: 25.980710983276367
      vf_explained_var: 0.0
      vf_loss: 11.58095645904541
    num_steps_sampled: 730000
    num_steps_trained: 730000
    wait_time_ms: 48.928
  iterations_since_restore: 146
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1259.7092289924622
  time_this_iter_s: 8.85154914855957
  time_total_s: 1259.7092289924622
  timestamp: 1594857262
  timesteps_since_restore: 730000
  timesteps_this_iter: 5000
  timesteps_total: 730000
  training_iteration: 146
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1259 s, 146 iter, 730000 ts, -717 rew

agent-1: -253.46896137652692
agent-2: -119.795401778857
agent-3: -119.5300655756388
agent-4: -36.46745064882234
agent-5: -164.25067378508157
Extrinsic Rewards:
10
7
0
6
6
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 0
Max Reward: 10
Gini Coefficient: 0.2896551724137931
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-54-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -717.3487476363396
  episode_reward_min: -2181.635203169405
  episodes_this_iter: 1
  episodes_total: 146
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.553
    dispatch_time_ms: 24.06
    learner:
      cur_lr: 0.001311382045969367
      grad_gnorm: 9.262916564941406
      policy_entropy: 64.41896057128906
      policy_loss: -0.6607434153556824
      var_gnorm: 25.96152687072754
      vf_explained_var: 0.0
      vf_loss: 8.964884757995605
    num_steps_sampled: 735000
    num_steps_trained: 735000
    wait_time_ms: 57.275
  iterations_since_restore: 147
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1268.5163197517395
  time_this_iter_s: 8.807090759277344
  time_total_s: 1268.5163197517395
  timestamp: 1594857271
  timesteps_since_restore: 735000
  timesteps_this_iter: 5000
  timesteps_total: 735000
  training_iteration: 147
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1268 s, 147 iter, 735000 ts, -717 rew

agent-1: -86.95085453848404
agent-2: -234.94382370223437
agent-3: -70.84623611718777
agent-4: -25.8118651453366
agent-5: -215.89113772985812
Extrinsic Rewards:
2
12
2
2
6
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 2
Max Reward: 12
Gini Coefficient: 0.4
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-54-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -717.2511949821694
  episode_reward_min: -2181.635203169405
  episodes_this_iter: 1
  episodes_total: 147
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.731
    dispatch_time_ms: 30.17
    learner:
      cur_lr: 0.0013110489817336202
      grad_gnorm: 9.834633827209473
      policy_entropy: 52.31462478637695
      policy_loss: 3.8056790828704834
      var_gnorm: 25.95653533935547
      vf_explained_var: 0.0
      vf_loss: 9.035932540893555
    num_steps_sampled: 740000
    num_steps_trained: 740000
    wait_time_ms: 58.208
  iterations_since_restore: 148
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1277.5893003940582
  time_this_iter_s: 9.072980642318726
  time_total_s: 1277.5893003940582
  timestamp: 1594857280
  timesteps_since_restore: 740000
  timesteps_this_iter: 5000
  timesteps_total: 740000
  training_iteration: 148
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1277 s, 148 iter, 740000 ts, -717 rew

agent-1: -19.78410522813788
agent-2: -177.62765987716332
agent-3: -240.84777937546792
agent-4: -23.686292719862692
agent-5: -171.49209312464023
Extrinsic Rewards:
2
7
11
3
4
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 2
Max Reward: 11
Gini Coefficient: 0.32592592592592595
20:20 Ratio: 5.5
Max-min Ratio: 5.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-54-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -715.2328360989313
  episode_reward_min: -2181.635203169405
  episodes_this_iter: 1
  episodes_total: 148
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.521
    dispatch_time_ms: 34.496
    learner:
      cur_lr: 0.0013107160339131951
      grad_gnorm: 35.6387939453125
      policy_entropy: 46.9367790222168
      policy_loss: 7.301079273223877
      var_gnorm: 25.943172454833984
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 11.555816650390625
    num_steps_sampled: 745000
    num_steps_trained: 745000
    wait_time_ms: 46.776
  iterations_since_restore: 149
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1286.3583281040192
  time_this_iter_s: 8.769027709960938
  time_total_s: 1286.3583281040192
  timestamp: 1594857288
  timesteps_since_restore: 745000
  timesteps_this_iter: 5000
  timesteps_total: 745000
  training_iteration: 149
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1286 s, 149 iter, 745000 ts, -715 rew

agent-1: -122.16857868183637
agent-2: -93.39088015617897
agent-3: -216.60969103375237
agent-4: -36.627143721611226
agent-5: -187.25697611459557
Extrinsic Rewards:
9
8
3
2
2
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 2
Max Reward: 9
Gini Coefficient: 0.3333333333333333
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-55-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -714.9696352231834
  episode_reward_min: -2181.635203169405
  episodes_this_iter: 1
  episodes_total: 149
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.909
    dispatch_time_ms: 26.544
    learner:
      cur_lr: 0.0013103829696774483
      grad_gnorm: 40.0
      policy_entropy: 40.25000762939453
      policy_loss: 8.22298526763916
      var_gnorm: 25.964452743530273
      vf_explained_var: 0.0
      vf_loss: 15.355203628540039
    num_steps_sampled: 750000
    num_steps_trained: 750000
    wait_time_ms: 52.698
  iterations_since_restore: 150
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1300.2286975383759
  time_this_iter_s: 13.87036943435669
  time_total_s: 1300.2286975383759
  timestamp: 1594857302
  timesteps_since_restore: 750000
  timesteps_this_iter: 5000
  timesteps_total: 750000
  training_iteration: 150
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1300 s, 150 iter, 750000 ts, -715 rew

agent-1: -43.051308308731365
agent-2: -16.999255196665413
agent-3: -274.0390010272996
agent-4: -131.70800916380685
agent-5: -162.63470211152648
Extrinsic Rewards:
4
1
13
0
7
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 0
Max Reward: 13
Gini Coefficient: 0.512
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-55-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -713.9656563415515
  episode_reward_min: -2181.635203169405
  episodes_this_iter: 1
  episodes_total: 150
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.688
    dispatch_time_ms: 42.251
    learner:
      cur_lr: 0.0013100500218570232
      grad_gnorm: 7.752790927886963
      policy_entropy: 63.245670318603516
      policy_loss: -3.503350257873535
      var_gnorm: 25.969623565673828
      vf_explained_var: 0.0
      vf_loss: 7.554309844970703
    num_steps_sampled: 755000
    num_steps_trained: 755000
    wait_time_ms: 44.19
  iterations_since_restore: 151
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1308.668569803238
  time_this_iter_s: 8.43987226486206
  time_total_s: 1308.668569803238
  timestamp: 1594857311
  timesteps_since_restore: 755000
  timesteps_this_iter: 5000
  timesteps_total: 755000
  training_iteration: 151
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1308 s, 151 iter, 755000 ts, -714 rew

agent-1: -131.1516151159593
agent-2: -217.5463018384447
agent-3: -170.12984296723852
agent-4: -18.156385335291198
agent-5: -160.7521283805809
Extrinsic Rewards:
8
6
4
1
5
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.26666666666666666
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-55-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -713.8639910591019
  episode_reward_min: -2181.635203169405
  episodes_this_iter: 1
  episodes_total: 151
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.697
    dispatch_time_ms: 21.737
    learner:
      cur_lr: 0.0013097169576212764
      grad_gnorm: 38.05504608154297
      policy_entropy: 63.900474548339844
      policy_loss: -10.976154327392578
      var_gnorm: 26.0148983001709
      vf_explained_var: 0.0
      vf_loss: 8.127159118652344
    num_steps_sampled: 760000
    num_steps_trained: 760000
    wait_time_ms: 66.07
  iterations_since_restore: 152
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1317.480718612671
  time_this_iter_s: 8.812148809432983
  time_total_s: 1317.480718612671
  timestamp: 1594857320
  timesteps_since_restore: 760000
  timesteps_this_iter: 5000
  timesteps_total: 760000
  training_iteration: 152
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1317 s, 152 iter, 760000 ts, -714 rew

agent-1: -55.812097124475294
agent-2: -155.21189388020198
agent-3: -194.36638100020923
agent-4: -239.65360409938677
agent-5: -134.04237327865056
Extrinsic Rewards:
2
7
4
11
0
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 0
Max Reward: 11
Gini Coefficient: 0.45
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-55-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -709.1604754391867
  episode_reward_min: -2181.635203169405
  episodes_this_iter: 1
  episodes_total: 152
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.191
    dispatch_time_ms: 33.825
    learner:
      cur_lr: 0.0013093840098008513
      grad_gnorm: 24.2504825592041
      policy_entropy: 56.88737869262695
      policy_loss: 5.719722270965576
      var_gnorm: 25.96120262145996
      vf_explained_var: 0.0
      vf_loss: 9.685211181640625
    num_steps_sampled: 765000
    num_steps_trained: 765000
    wait_time_ms: 50.035
  iterations_since_restore: 153
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1326.196210384369
  time_this_iter_s: 8.715491771697998
  time_total_s: 1326.196210384369
  timestamp: 1594857328
  timesteps_since_restore: 765000
  timesteps_this_iter: 5000
  timesteps_total: 765000
  training_iteration: 153
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1326 s, 153 iter, 765000 ts, -709 rew

agent-1: -197.0939033501516
agent-2: -15.198443429578997
agent-3: -195.89423390638245
agent-4: -167.82606218523406
agent-5: -84.46449191871626
Extrinsic Rewards:
11
2
14
5
8
Sum Reward: 40
Avg Reward: 8.0
Min Reward: 2
Max Reward: 14
Gini Coefficient: 0.3
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-55-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -693.9488947553932
  episode_reward_min: -1433.3856541218
  episodes_this_iter: 1
  episodes_total: 153
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.614
    dispatch_time_ms: 14.589
    learner:
      cur_lr: 0.0013090509455651045
      grad_gnorm: 40.0
      policy_entropy: 59.998435974121094
      policy_loss: 30.12710189819336
      var_gnorm: 25.9466609954834
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 32.77849197387695
    num_steps_sampled: 770000
    num_steps_trained: 770000
    wait_time_ms: 83.355
  iterations_since_restore: 154
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1335.0367949008942
  time_this_iter_s: 8.840584516525269
  time_total_s: 1335.0367949008942
  timestamp: 1594857337
  timesteps_since_restore: 770000
  timesteps_this_iter: 5000
  timesteps_total: 770000
  training_iteration: 154
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1335 s, 154 iter, 770000 ts, -694 rew

agent-1: -96.24955901335734
agent-2: -27.501479850872816
agent-3: -62.468452017581676
agent-4: -258.4000748026378
agent-5: -69.77822422071388
Extrinsic Rewards:
10
5
2
9
5
Sum Reward: 31
Avg Reward: 6.2
Min Reward: 2
Max Reward: 10
Gini Coefficient: 0.25806451612903225
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-55-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -692.3977929320137
  episode_reward_min: -1433.3856541218
  episodes_this_iter: 1
  episodes_total: 154
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 8.019
    dispatch_time_ms: 29.13
    learner:
      cur_lr: 0.0013087179977446795
      grad_gnorm: 13.564474105834961
      policy_entropy: 65.61602783203125
      policy_loss: -7.390163898468018
      var_gnorm: 25.970027923583984
      vf_explained_var: 0.0
      vf_loss: 2.8220207691192627
    num_steps_sampled: 775000
    num_steps_trained: 775000
    wait_time_ms: 49.282
  iterations_since_restore: 155
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1343.7382049560547
  time_this_iter_s: 8.701410055160522
  time_total_s: 1343.7382049560547
  timestamp: 1594857346
  timesteps_since_restore: 775000
  timesteps_this_iter: 5000
  timesteps_total: 775000
  training_iteration: 155
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1343 s, 155 iter, 775000 ts, -692 rew

agent-1: -87.64083280146829
agent-2: -75.96919733682354
agent-3: -133.0542175359896
agent-4: -152.22884338546515
agent-5: -228.54357215007963
Extrinsic Rewards:
9
3
3
5
10
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 3
Max Reward: 10
Gini Coefficient: 0.26666666666666666
20:20 Ratio: 3.3333333333333335
Max-min Ratio: 3.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-55-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -684.8383030228941
  episode_reward_min: -1283.7463938222552
  episodes_this_iter: 1
  episodes_total: 155
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.38
    dispatch_time_ms: 42.262
    learner:
      cur_lr: 0.0013083850499242544
      grad_gnorm: 17.3214111328125
      policy_entropy: 65.3342514038086
      policy_loss: -0.5017469525337219
      var_gnorm: 25.980260848999023
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 2.7658402919769287
    num_steps_sampled: 780000
    num_steps_trained: 780000
    wait_time_ms: 47.152
  iterations_since_restore: 156
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1352.5975511074066
  time_this_iter_s: 8.859346151351929
  time_total_s: 1352.5975511074066
  timestamp: 1594857355
  timesteps_since_restore: 780000
  timesteps_this_iter: 5000
  timesteps_total: 780000
  training_iteration: 156
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1352 s, 156 iter, 780000 ts, -685 rew

agent-1: -91.09478721583476
agent-2: -102.36916430267831
agent-3: -236.31759510469922
agent-4: -150.34043444020904
agent-5: -123.55568895087968
Extrinsic Rewards:
1
3
5
4
5
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 1
Max Reward: 5
Gini Coefficient: 0.2222222222222222
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-56-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -685.610011270583
  episode_reward_min: -1283.7463938222552
  episodes_this_iter: 1
  episodes_total: 156
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.809
    dispatch_time_ms: 41.618
    learner:
      cur_lr: 0.0013080519856885076
      grad_gnorm: 14.410088539123535
      policy_entropy: 64.93792724609375
      policy_loss: -4.905080795288086
      var_gnorm: 25.96126937866211
      vf_explained_var: 0.0
      vf_loss: 5.6740922927856445
    num_steps_sampled: 785000
    num_steps_trained: 785000
    wait_time_ms: 43.589
  iterations_since_restore: 157
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1361.5952923297882
  time_this_iter_s: 8.997741222381592
  time_total_s: 1361.5952923297882
  timestamp: 1594857364
  timesteps_since_restore: 785000
  timesteps_this_iter: 5000
  timesteps_total: 785000
  training_iteration: 157
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1361 s, 157 iter, 785000 ts, -686 rew

agent-1: -223.5510452466807
agent-2: -159.24437643023853
agent-3: -78.24378714639487
agent-4: -37.321696079073654
agent-5: -176.63923008244495
Extrinsic Rewards:
7
4
5
3
7
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 3
Max Reward: 7
Gini Coefficient: 0.16923076923076924
20:20 Ratio: 2.3333333333333335
Max-min Ratio: 2.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-56-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -683.9599905175943
  episode_reward_min: -1283.7463938222552
  episodes_this_iter: 1
  episodes_total: 157
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.251
    dispatch_time_ms: 24.061
    learner:
      cur_lr: 0.0013077190378680825
      grad_gnorm: 13.193110466003418
      policy_entropy: 70.23844146728516
      policy_loss: 8.9627046585083
      var_gnorm: 25.958843231201172
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 7.660510063171387
    num_steps_sampled: 790000
    num_steps_trained: 790000
    wait_time_ms: 66.321
  iterations_since_restore: 158
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1370.463323354721
  time_this_iter_s: 8.868031024932861
  time_total_s: 1370.463323354721
  timestamp: 1594857373
  timesteps_since_restore: 790000
  timesteps_this_iter: 5000
  timesteps_total: 790000
  training_iteration: 158
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1370 s, 158 iter, 790000 ts, -684 rew

agent-1: -127.40678894090482
agent-2: -59.32445370958133
agent-3: -110.5436574116992
agent-4: -247.37494742838817
agent-5: -30.70995882713838
Extrinsic Rewards:
12
5
4
6
2
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 2
Max Reward: 12
Gini Coefficient: 0.30344827586206896
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-56-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -683.1455065493432
  episode_reward_min: -1283.7463938222552
  episodes_this_iter: 1
  episodes_total: 158
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.424
    dispatch_time_ms: 29.464
    learner:
      cur_lr: 0.0013073859736323357
      grad_gnorm: 9.765953063964844
      policy_entropy: 69.82605743408203
      policy_loss: -4.214433193206787
      var_gnorm: 25.977771759033203
      vf_explained_var: 0.0
      vf_loss: 4.652801036834717
    num_steps_sampled: 795000
    num_steps_trained: 795000
    wait_time_ms: 60.672
  iterations_since_restore: 159
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1379.3052186965942
  time_this_iter_s: 8.841895341873169
  time_total_s: 1379.3052186965942
  timestamp: 1594857382
  timesteps_since_restore: 795000
  timesteps_this_iter: 5000
  timesteps_total: 795000
  training_iteration: 159
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1379 s, 159 iter, 795000 ts, -683 rew

agent-1: -96.91060771384508
agent-2: -201.19630731553016
agent-3: -52.519278628075575
agent-4: -123.07757145923951
agent-5: -222.70577765536825
Extrinsic Rewards:
1
5
2
5
6
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 1
Max Reward: 6
Gini Coefficient: 0.2736842105263158
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-56-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -683.0672778212963
  episode_reward_min: -1283.7463938222552
  episodes_this_iter: 1
  episodes_total: 159
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.781
    dispatch_time_ms: 19.402
    learner:
      cur_lr: 0.0013070530258119106
      grad_gnorm: 40.0
      policy_entropy: 69.56519317626953
      policy_loss: 53.99413299560547
      var_gnorm: 26.02684783935547
      vf_explained_var: 0.0
      vf_loss: 35.48505783081055
    num_steps_sampled: 800000
    num_steps_trained: 800000
    wait_time_ms: 59.119
  iterations_since_restore: 160
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1388.1167488098145
  time_this_iter_s: 8.811530113220215
  time_total_s: 1388.1167488098145
  timestamp: 1594857391
  timesteps_since_restore: 800000
  timesteps_this_iter: 5000
  timesteps_total: 800000
  training_iteration: 160
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1388 s, 160 iter, 800000 ts, -683 rew

agent-1: -226.22894769741984
agent-2: -173.28684978006498
agent-3: -124.52078693967339
agent-4: -166.8737318059178
agent-5: -141.23404896806133
Extrinsic Rewards:
7
4
4
5
0
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.3
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-56-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -684.8089321095191
  episode_reward_min: -1283.7463938222552
  episodes_this_iter: 1
  episodes_total: 160
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.074
    dispatch_time_ms: 21.853
    learner:
      cur_lr: 0.0013067199615761638
      grad_gnorm: 20.09800148010254
      policy_entropy: 53.950645446777344
      policy_loss: 0.7989868521690369
      var_gnorm: 25.988311767578125
      vf_explained_var: 0.0
      vf_loss: 5.516940116882324
    num_steps_sampled: 805000
    num_steps_trained: 805000
    wait_time_ms: 60.137
  iterations_since_restore: 161
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1396.9227108955383
  time_this_iter_s: 8.805962085723877
  time_total_s: 1396.9227108955383
  timestamp: 1594857399
  timesteps_since_restore: 805000
  timesteps_this_iter: 5000
  timesteps_total: 805000
  training_iteration: 161
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1396 s, 161 iter, 805000 ts, -685 rew

agent-1: -170.30548204348926
agent-2: -136.53099975990077
agent-3: -102.44634406822249
agent-4: -252.34888997156196
agent-5: -93.1116537581924
Extrinsic Rewards:
7
0
4
10
5
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 0
Max Reward: 10
Gini Coefficient: 0.35384615384615387
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-56-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -685.0444436117065
  episode_reward_min: -1283.7463938222552
  episodes_this_iter: 1
  episodes_total: 161
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.268
    dispatch_time_ms: 27.838
    learner:
      cur_lr: 0.0013063870137557387
      grad_gnorm: 15.731332778930664
      policy_entropy: 28.56747055053711
      policy_loss: -0.4984588921070099
      var_gnorm: 26.029386520385742
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.804588794708252
    num_steps_sampled: 810000
    num_steps_trained: 810000
    wait_time_ms: 56.03
  iterations_since_restore: 162
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1405.7790942192078
  time_this_iter_s: 8.856383323669434
  time_total_s: 1405.7790942192078
  timestamp: 1594857408
  timesteps_since_restore: 810000
  timesteps_this_iter: 5000
  timesteps_total: 810000
  training_iteration: 162
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1405 s, 162 iter, 810000 ts, -685 rew

agent-1: -201.75407602970427
agent-2: -63.16533451945324
agent-3: -39.546296546168
agent-4: -179.7729582192982
agent-5: -215.269457694982
Extrinsic Rewards:
5
2
1
4
5
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 1
Max Reward: 5
Gini Coefficient: 0.25882352941176473
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-56-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -680.1949509443247
  episode_reward_min: -1283.7463938222552
  episodes_this_iter: 1
  episodes_total: 162
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.057
    dispatch_time_ms: 26.184
    learner:
      cur_lr: 0.0013060539495199919
      grad_gnorm: 39.999996185302734
      policy_entropy: 46.28476333618164
      policy_loss: 58.856964111328125
      var_gnorm: 25.948898315429688
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 61.856056213378906
    num_steps_sampled: 815000
    num_steps_trained: 815000
    wait_time_ms: 58.854
  iterations_since_restore: 163
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1414.4353358745575
  time_this_iter_s: 8.656241655349731
  time_total_s: 1414.4353358745575
  timestamp: 1594857417
  timesteps_since_restore: 815000
  timesteps_this_iter: 5000
  timesteps_total: 815000
  training_iteration: 163
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1414 s, 163 iter, 815000 ts, -680 rew

agent-1: -182.30318170939492
agent-2: -75.17652096995863
agent-3: -127.65650861334802
agent-4: -116.94690018543321
agent-5: -73.13080455848281
Extrinsic Rewards:
30
13
10
7
15
Sum Reward: 75
Avg Reward: 15.0
Min Reward: 7
Max Reward: 30
Gini Coefficient: 0.272
20:20 Ratio: 4.285714285714286
Max-min Ratio: 4.285714285714286
agent-1: -100.6925211197047
agent-2: -133.0545535069274
agent-3: -138.68452121513621
agent-4: -141.57794564435835
agent-5: -100.47836076837623
Extrinsic Rewards:
14
13
18
14
17
Sum Reward: 76
Avg Reward: 15.2
Min Reward: 13
Max Reward: 18
Gini Coefficient: 0.06842105263157895
20:20 Ratio: 1.3846153846153846
Max-min Ratio: 1.3846153846153846
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-57-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -676.8828414228824
  episode_reward_min: -1283.7463938222552
  episodes_this_iter: 2
  episodes_total: 164
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.71
    dispatch_time_ms: 23.938
    learner:
      cur_lr: 0.0013057210016995668
      grad_gnorm: 40.0
      policy_entropy: 42.2685661315918
      policy_loss: 10.394112586975098
      var_gnorm: 25.988378524780273
      vf_explained_var: -0.7478585243225098
      vf_loss: 26.56664276123047
    num_steps_sampled: 820000
    num_steps_trained: 820000
    wait_time_ms: 66.186
  iterations_since_restore: 164
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1423.272050857544
  time_this_iter_s: 8.83671498298645
  time_total_s: 1423.272050857544
  timestamp: 1594857426
  timesteps_since_restore: 820000
  timesteps_this_iter: 5000
  timesteps_total: 820000
  training_iteration: 164
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1423 s, 164 iter, 820000 ts, -677 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-57-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -676.8828414228825
  episode_reward_min: -1283.7463938222552
  episodes_this_iter: 0
  episodes_total: 164
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.894
    dispatch_time_ms: 30.098
    learner:
      cur_lr: 0.0013053880538791418
      grad_gnorm: 15.147266387939453
      policy_entropy: 45.29576873779297
      policy_loss: 2.8503570556640625
      var_gnorm: 25.972412109375
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 9.641403198242188
    num_steps_sampled: 825000
    num_steps_trained: 825000
    wait_time_ms: 59.923
  iterations_since_restore: 165
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1432.1275975704193
  time_this_iter_s: 8.855546712875366
  time_total_s: 1432.1275975704193
  timestamp: 1594857435
  timesteps_since_restore: 825000
  timesteps_this_iter: 5000
  timesteps_total: 825000
  training_iteration: 165
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1432 s, 165 iter, 825000 ts, -677 rew

agent-1: -170.81991281033885
agent-2: -160.2151182941667
agent-3: -103.0545318608888
agent-4: -73.81634420474309
agent-5: -180.61940148379875
Extrinsic Rewards:
5
3
4
11
4
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 3
Max Reward: 11
Gini Coefficient: 0.2518518518518518
20:20 Ratio: 3.6666666666666665
Max-min Ratio: 3.6666666666666665
agent-1: -134.12310916451835
agent-2: -97.37124099742657
agent-3: -272.82021429017055
agent-4: -13.90685901401974
agent-5: -18.168537478586153
Extrinsic Rewards:
6
5
12
1
1
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 1
Max Reward: 12
Gini Coefficient: 0.432
20:20 Ratio: 12.0
Max-min Ratio: 12.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-57-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -677.2399837773507
  episode_reward_min: -1283.7463938222552
  episodes_this_iter: 1
  episodes_total: 165
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.655
    dispatch_time_ms: 25.056
    learner:
      cur_lr: 0.001305054989643395
      grad_gnorm: 19.308435440063477
      policy_entropy: 36.431331634521484
      policy_loss: -2.1750173568725586
      var_gnorm: 25.973772048950195
      vf_explained_var: -1.0
      vf_loss: 36.144020080566406
    num_steps_sampled: 830000
    num_steps_trained: 830000
    wait_time_ms: 60.61
  iterations_since_restore: 166
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1440.9770166873932
  time_this_iter_s: 8.849419116973877
  time_total_s: 1440.9770166873932
  timestamp: 1594857444
  timesteps_since_restore: 830000
  timesteps_this_iter: 5000
  timesteps_total: 830000
  training_iteration: 166
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1440 s, 166 iter, 830000 ts, -677 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-57-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -674.8406310044958
  episode_reward_min: -1283.7463938222552
  episodes_this_iter: 1
  episodes_total: 166
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.826
    dispatch_time_ms: 29.081
    learner:
      cur_lr: 0.00130472204182297
      grad_gnorm: 9.711278915405273
      policy_entropy: 18.358945846557617
      policy_loss: 5.4365553855896
      var_gnorm: 25.980159759521484
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 6.262800693511963
    num_steps_sampled: 835000
    num_steps_trained: 835000
    wait_time_ms: 59.28
  iterations_since_restore: 167
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1449.9505360126495
  time_this_iter_s: 8.973519325256348
  time_total_s: 1449.9505360126495
  timestamp: 1594857453
  timesteps_since_restore: 835000
  timesteps_this_iter: 5000
  timesteps_total: 835000
  training_iteration: 167
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1449 s, 167 iter, 835000 ts, -675 rew

agent-1: -259.4371615945486
agent-2: -87.54224704533854
agent-3: -136.60932565829464
agent-4: -24.377216729481255
agent-5: -112.06384051589886
Extrinsic Rewards:
11
3
6
1
2
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 1
Max Reward: 11
Gini Coefficient: 0.41739130434782606
20:20 Ratio: 11.0
Max-min Ratio: 11.0
agent-1: -206.5379579960969
agent-2: -128.065024492352
agent-3: -146.96289193213926
agent-4: -101.28516877037536
agent-5: -236.99501497422676
Extrinsic Rewards:
5
3
0
3
5
Sum Reward: 16
Avg Reward: 3.2
Min Reward: 0
Max Reward: 5
Gini Coefficient: 0.3
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-57-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -674.6407804103366
  episode_reward_min: -1283.7463938222552
  episodes_this_iter: 1
  episodes_total: 167
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.992
    dispatch_time_ms: 20.923
    learner:
      cur_lr: 0.001304388977587223
      grad_gnorm: 32.50056076049805
      policy_entropy: 22.07265853881836
      policy_loss: -2.5464394092559814
      var_gnorm: 26.02276039123535
      vf_explained_var: 0.0
      vf_loss: 7.211119174957275
    num_steps_sampled: 840000
    num_steps_trained: 840000
    wait_time_ms: 72.243
  iterations_since_restore: 168
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1458.9452974796295
  time_this_iter_s: 8.99476146697998
  time_total_s: 1458.9452974796295
  timestamp: 1594857462
  timesteps_since_restore: 840000
  timesteps_this_iter: 5000
  timesteps_total: 840000
  training_iteration: 168
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1458 s, 168 iter, 840000 ts, -675 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-57-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -675.3701584526991
  episode_reward_min: -1283.7463938222552
  episodes_this_iter: 1
  episodes_total: 168
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.84
    dispatch_time_ms: 27.23
    learner:
      cur_lr: 0.001304056029766798
      grad_gnorm: 33.35337829589844
      policy_entropy: 32.12995529174805
      policy_loss: 6.308455467224121
      var_gnorm: 25.964111328125
      vf_explained_var: 0.0
      vf_loss: 6.220034122467041
    num_steps_sampled: 845000
    num_steps_trained: 845000
    wait_time_ms: 64.097
  iterations_since_restore: 169
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1467.5816442966461
  time_this_iter_s: 8.636346817016602
  time_total_s: 1467.5816442966461
  timestamp: 1594857470
  timesteps_since_restore: 845000
  timesteps_this_iter: 5000
  timesteps_total: 845000
  training_iteration: 169
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1467 s, 169 iter, 845000 ts, -675 rew

agent-1: -85.14736425651658
agent-2: -124.87338863424554
agent-3: -72.34261246585643
agent-4: -107.6499346317483
agent-5: -121.26494529600711
Extrinsic Rewards:
22
31
17
26
42
Sum Reward: 138
Avg Reward: 27.6
Min Reward: 17
Max Reward: 42
Gini Coefficient: 0.17101449275362318
20:20 Ratio: 2.4705882352941178
Max-min Ratio: 2.4705882352941178
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-57-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -673.9884404229102
  episode_reward_min: -1283.7463938222552
  episodes_this_iter: 1
  episodes_total: 169
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.28
    dispatch_time_ms: 29.196
    learner:
      cur_lr: 0.0013037229655310512
      grad_gnorm: 40.000003814697266
      policy_entropy: 29.952999114990234
      policy_loss: 5.31275749206543
      var_gnorm: 25.956125259399414
      vf_explained_var: 0.0
      vf_loss: 17.9882755279541
    num_steps_sampled: 850000
    num_steps_trained: 850000
    wait_time_ms: 57.55
  iterations_since_restore: 170
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1476.3582565784454
  time_this_iter_s: 8.776612281799316
  time_total_s: 1476.3582565784454
  timestamp: 1594857479
  timesteps_since_restore: 850000
  timesteps_this_iter: 5000
  timesteps_total: 850000
  training_iteration: 170
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1476 s, 170 iter, 850000 ts, -674 rew

agent-1: -186.59813694587282
agent-2: -204.5224427169565
agent-3: -53.167398172812845
agent-4: -81.72394026061308
agent-5: -40.915677205336834
Extrinsic Rewards:
16
16
9
13
9
Sum Reward: 63
Avg Reward: 12.6
Min Reward: 9
Max Reward: 16
Gini Coefficient: 0.13333333333333333
20:20 Ratio: 1.7777777777777777
Max-min Ratio: 1.7777777777777777
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-58-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -673.0455241835105
  episode_reward_min: -1283.7463938222552
  episodes_this_iter: 1
  episodes_total: 170
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.476
    dispatch_time_ms: 33.928
    learner:
      cur_lr: 0.0013033900177106261
      grad_gnorm: 15.385476112365723
      policy_entropy: 46.15187072753906
      policy_loss: -0.5368413925170898
      var_gnorm: 25.951181411743164
      vf_explained_var: 0.0
      vf_loss: 7.517337322235107
    num_steps_sampled: 855000
    num_steps_trained: 855000
    wait_time_ms: 50.786
  iterations_since_restore: 171
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1485.1294963359833
  time_this_iter_s: 8.771239757537842
  time_total_s: 1485.1294963359833
  timestamp: 1594857488
  timesteps_since_restore: 855000
  timesteps_this_iter: 5000
  timesteps_total: 855000
  training_iteration: 171
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1485 s, 171 iter, 855000 ts, -673 rew

agent-1: -58.85612456570748
agent-2: -92.49706319761941
agent-3: -85.91224309832413
agent-4: -263.2765634388111
agent-5: -50.339485985268496
Extrinsic Rewards:
3
2
6
8
4
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 2
Max Reward: 8
Gini Coefficient: 0.2608695652173913
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-58-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -671.192095595396
  episode_reward_min: -1283.7463938222552
  episodes_this_iter: 1
  episodes_total: 171
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.284
    dispatch_time_ms: 30.135
    learner:
      cur_lr: 0.0013030569534748793
      grad_gnorm: 19.443832397460938
      policy_entropy: 52.078861236572266
      policy_loss: -3.771467924118042
      var_gnorm: 25.948781967163086
      vf_explained_var: 0.0
      vf_loss: 12.648021697998047
    num_steps_sampled: 860000
    num_steps_trained: 860000
    wait_time_ms: 56.324
  iterations_since_restore: 172
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1493.9974584579468
  time_this_iter_s: 8.867962121963501
  time_total_s: 1493.9974584579468
  timestamp: 1594857497
  timesteps_since_restore: 860000
  timesteps_this_iter: 5000
  timesteps_total: 860000
  training_iteration: 172
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1493 s, 172 iter, 860000 ts, -671 rew

agent-1: -190.8742380902979
agent-2: -68.6591533170691
agent-3: -88.41118808356481
agent-4: -168.39573984310462
agent-5: -30.14654327785591
Extrinsic Rewards:
10
12
19
9
9
Sum Reward: 59
Avg Reward: 11.8
Min Reward: 9
Max Reward: 19
Gini Coefficient: 0.15593220338983052
20:20 Ratio: 2.111111111111111
Max-min Ratio: 2.111111111111111
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-58-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -490.0104632719787
  episode_reward_mean: -668.6626728987599
  episode_reward_min: -1283.7463938222552
  episodes_this_iter: 1
  episodes_total: 172
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.626
    dispatch_time_ms: 30.814
    learner:
      cur_lr: 0.0013027240056544542
      grad_gnorm: 12.466482162475586
      policy_entropy: 46.53343963623047
      policy_loss: -3.202942371368408
      var_gnorm: 25.97891616821289
      vf_explained_var: 0.0
      vf_loss: 4.171714782714844
    num_steps_sampled: 865000
    num_steps_trained: 865000
    wait_time_ms: 65.196
  iterations_since_restore: 173
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1502.835123538971
  time_this_iter_s: 8.83766508102417
  time_total_s: 1502.835123538971
  timestamp: 1594857506
  timesteps_since_restore: 865000
  timesteps_this_iter: 5000
  timesteps_total: 865000
  training_iteration: 173
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1502 s, 173 iter, 865000 ts, -669 rew

agent-1: -97.94424897035984
agent-2: -50.07726720954094
agent-3: -199.98522068353188
agent-4: -156.1607374969063
agent-5: -185.38397046955026
Extrinsic Rewards:
6
4
6
8
5
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 4
Max Reward: 8
Gini Coefficient: 0.12413793103448276
20:20 Ratio: 2.0
Max-min Ratio: 2.0
agent-1: -210.34556108263476
agent-2: -177.9792271240312
agent-3: -143.29211433716952
agent-4: -55.62950971878108
agent-5: -220.8052104046635
Extrinsic Rewards:
5
7
0
2
5
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.35789473684210527
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-58-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -511.27824528437776
  episode_reward_mean: -673.4643794048088
  episode_reward_min: -1283.7463938222552
  episodes_this_iter: 2
  episodes_total: 174
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.486
    dispatch_time_ms: 29.37
    learner:
      cur_lr: 0.0013023910578340292
      grad_gnorm: 40.000003814697266
      policy_entropy: 36.27684020996094
      policy_loss: -42.52631378173828
      var_gnorm: 26.034305572509766
      vf_explained_var: -1.0
      vf_loss: 59.080135345458984
    num_steps_sampled: 870000
    num_steps_trained: 870000
    wait_time_ms: 55.67
  iterations_since_restore: 174
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1511.6647293567657
  time_this_iter_s: 8.8296058177948
  time_total_s: 1511.6647293567657
  timestamp: 1594857515
  timesteps_since_restore: 870000
  timesteps_this_iter: 5000
  timesteps_total: 870000
  training_iteration: 174
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1511 s, 174 iter, 870000 ts, -673 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-58-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -511.27824528437776
  episode_reward_mean: -673.4643794048087
  episode_reward_min: -1283.7463938222552
  episodes_this_iter: 0
  episodes_total: 174
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.692
    dispatch_time_ms: 35.303
    learner:
      cur_lr: 0.0013020579935982823
      grad_gnorm: 20.94588279724121
      policy_entropy: 55.35453796386719
      policy_loss: -7.9978485107421875
      var_gnorm: 25.970016479492188
      vf_explained_var: 0.0
      vf_loss: 3.0023105144500732
    num_steps_sampled: 875000
    num_steps_trained: 875000
    wait_time_ms: 55.758
  iterations_since_restore: 175
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1520.3908638954163
  time_this_iter_s: 8.726134538650513
  time_total_s: 1520.3908638954163
  timestamp: 1594857524
  timesteps_since_restore: 875000
  timesteps_this_iter: 5000
  timesteps_total: 875000
  training_iteration: 175
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1520 s, 175 iter, 875000 ts, -673 rew

agent-1: -58.59278031709928
agent-2: -30.467891245043987
agent-3: -227.38108443326058
agent-4: -46.77757623613601
agent-5: -105.66723539015435
Extrinsic Rewards:
6
3
14
9
17
Sum Reward: 49
Avg Reward: 9.8
Min Reward: 3
Max Reward: 17
Gini Coefficient: 0.2938775510204082
20:20 Ratio: 5.666666666666667
Max-min Ratio: 5.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-59-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -468.88656762170353
  episode_reward_mean: -671.8957441003855
  episode_reward_min: -1283.7463938222552
  episodes_this_iter: 1
  episodes_total: 175
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.332
    dispatch_time_ms: 26.736
    learner:
      cur_lr: 0.0013017250457778573
      grad_gnorm: 28.734317779541016
      policy_entropy: 54.86625671386719
      policy_loss: 6.850742816925049
      var_gnorm: 25.963134765625
      vf_explained_var: 0.0
      vf_loss: 13.740653991699219
    num_steps_sampled: 880000
    num_steps_trained: 880000
    wait_time_ms: 53.592
  iterations_since_restore: 176
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1549.0611686706543
  time_this_iter_s: 28.670304775238037
  time_total_s: 1549.0611686706543
  timestamp: 1594857552
  timesteps_since_restore: 880000
  timesteps_this_iter: 5000
  timesteps_total: 880000
  training_iteration: 176
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1549 s, 176 iter, 880000 ts, -672 rew

agent-1: -177.38884644901376
agent-2: -80.9020224853813
agent-3: -135.0681193664938
agent-4: -101.42337030351582
agent-5: -176.78940399085457
Extrinsic Rewards:
15
7
3
5
17
Sum Reward: 47
Avg Reward: 9.4
Min Reward: 3
Max Reward: 17
Gini Coefficient: 0.32340425531914896
20:20 Ratio: 5.666666666666667
Max-min Ratio: 5.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-59-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -468.88656762170353
  episode_reward_mean: -671.971376595139
  episode_reward_min: -1283.7463938222552
  episodes_this_iter: 1
  episodes_total: 176
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.664
    dispatch_time_ms: 24.879
    learner:
      cur_lr: 0.0013013919815421104
      grad_gnorm: 18.90428352355957
      policy_entropy: 53.714134216308594
      policy_loss: -3.5408480167388916
      var_gnorm: 25.966142654418945
      vf_explained_var: 0.0
      vf_loss: 8.384486198425293
    num_steps_sampled: 885000
    num_steps_trained: 885000
    wait_time_ms: 58.703
  iterations_since_restore: 177
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1557.8803007602692
  time_this_iter_s: 8.819132089614868
  time_total_s: 1557.8803007602692
  timestamp: 1594857561
  timesteps_since_restore: 885000
  timesteps_this_iter: 5000
  timesteps_total: 885000
  training_iteration: 177
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1557 s, 177 iter, 885000 ts, -672 rew

agent-1: -208.79153707837958
agent-2: -128.48643780544575
agent-3: -35.83923236434348
agent-4: -30.522863900378134
agent-5: -219.59001942850267
Extrinsic Rewards:
6
7
3
2
1
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 1
Max Reward: 7
Gini Coefficient: 0.3368421052631579
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-59-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -468.88656762170353
  episode_reward_mean: -672.4237810953898
  episode_reward_min: -1283.7463938222552
  episodes_this_iter: 1
  episodes_total: 177
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.464
    dispatch_time_ms: 41.123
    learner:
      cur_lr: 0.0013010590337216854
      grad_gnorm: 40.0
      policy_entropy: 51.74192810058594
      policy_loss: 29.03396987915039
      var_gnorm: 26.006591796875
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 24.505226135253906
    num_steps_sampled: 890000
    num_steps_trained: 890000
    wait_time_ms: 40.127
  iterations_since_restore: 178
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1566.7264070510864
  time_this_iter_s: 8.84610629081726
  time_total_s: 1566.7264070510864
  timestamp: 1594857570
  timesteps_since_restore: 890000
  timesteps_this_iter: 5000
  timesteps_total: 890000
  training_iteration: 178
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1566 s, 178 iter, 890000 ts, -672 rew

agent-1: -213.10458530051582
agent-2: -114.64594778093014
agent-3: -63.202173964675076
agent-4: -131.71992476170536
agent-5: -222.1514732766668
Extrinsic Rewards:
15
0
4
3
6
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 0
Max Reward: 15
Gini Coefficient: 0.4714285714285714
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-59-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -468.88656762170353
  episode_reward_mean: -672.4721617993357
  episode_reward_min: -1283.7463938222552
  episodes_this_iter: 1
  episodes_total: 178
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.248
    dispatch_time_ms: 25.236
    learner:
      cur_lr: 0.0013007259694859385
      grad_gnorm: 8.378341674804688
      policy_entropy: 46.86455535888672
      policy_loss: 1.3067556619644165
      var_gnorm: 25.99785041809082
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 5.01037073135376
    num_steps_sampled: 895000
    num_steps_trained: 895000
    wait_time_ms: 64.74
  iterations_since_restore: 179
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1581.4655385017395
  time_this_iter_s: 14.739131450653076
  time_total_s: 1581.4655385017395
  timestamp: 1594857585
  timesteps_since_restore: 895000
  timesteps_this_iter: 5000
  timesteps_total: 895000
  training_iteration: 179
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1581 s, 179 iter, 895000 ts, -672 rew

agent-1: -149.5028524055189
agent-2: -165.1081282660925
agent-3: -221.73853258635532
agent-4: -216.0134680768943
agent-5: -74.74048790059902
Extrinsic Rewards:
0
4
5
6
2
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 0
Max Reward: 6
Gini Coefficient: 0.35294117647058826
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-59-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -468.88656762170353
  episode_reward_mean: -674.5097223674925
  episode_reward_min: -1283.7463938222552
  episodes_this_iter: 1
  episodes_total: 179
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.715
    dispatch_time_ms: 24.281
    learner:
      cur_lr: 0.0013003930216655135
      grad_gnorm: 30.160247802734375
      policy_entropy: 44.96186065673828
      policy_loss: 8.360904693603516
      var_gnorm: 26.036758422851562
      vf_explained_var: 0.0
      vf_loss: 5.510804176330566
    num_steps_sampled: 900000
    num_steps_trained: 900000
    wait_time_ms: 67.166
  iterations_since_restore: 180
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1590.294701576233
  time_this_iter_s: 8.829163074493408
  time_total_s: 1590.294701576233
  timestamp: 1594857594
  timesteps_since_restore: 900000
  timesteps_this_iter: 5000
  timesteps_total: 900000
  training_iteration: 180
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1590 s, 180 iter, 900000 ts, -675 rew

agent-1: -142.04236459094872
agent-2: -153.1952486680081
agent-3: -135.15953876500618
agent-4: -16.6093120275413
agent-5: -233.23715493988522
Extrinsic Rewards:
5
8
4
1
7
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.272
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-00-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -468.88656762170353
  episode_reward_mean: -675.9137550111107
  episode_reward_min: -1283.7463938222552
  episodes_this_iter: 1
  episodes_total: 180
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.537
    dispatch_time_ms: 27.403
    learner:
      cur_lr: 0.0013000599574297667
      grad_gnorm: 6.194431781768799
      policy_entropy: 33.54837417602539
      policy_loss: -0.1335241049528122
      var_gnorm: 25.98642349243164
      vf_explained_var: 0.0
      vf_loss: 8.915397644042969
    num_steps_sampled: 905000
    num_steps_trained: 905000
    wait_time_ms: 46.992
  iterations_since_restore: 181
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1599.075016260147
  time_this_iter_s: 8.780314683914185
  time_total_s: 1599.075016260147
  timestamp: 1594857602
  timesteps_since_restore: 905000
  timesteps_this_iter: 5000
  timesteps_total: 905000
  training_iteration: 181
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1599 s, 181 iter, 905000 ts, -676 rew

agent-1: -206.184815723096
agent-2: -220.8003179540073
agent-3: -104.97580796010256
agent-4: -112.65663818062269
agent-5: -88.05247499528528
Extrinsic Rewards:
6
12
0
5
11
Sum Reward: 34
Avg Reward: 6.8
Min Reward: 0
Max Reward: 12
Gini Coefficient: 0.35294117647058826
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-00-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -468.88656762170353
  episode_reward_mean: -670.4029916210188
  episode_reward_min: -854.3530212948167
  episodes_this_iter: 1
  episodes_total: 181
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.996
    dispatch_time_ms: 19.55
    learner:
      cur_lr: 0.0012997270096093416
      grad_gnorm: 40.0
      policy_entropy: 33.27748489379883
      policy_loss: 11.733033180236816
      var_gnorm: 26.049365997314453
      vf_explained_var: -0.2050783634185791
      vf_loss: 29.07666015625
    num_steps_sampled: 910000
    num_steps_trained: 910000
    wait_time_ms: 56.989
  iterations_since_restore: 182
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1607.9607887268066
  time_this_iter_s: 8.885772466659546
  time_total_s: 1607.9607887268066
  timestamp: 1594857611
  timesteps_since_restore: 910000
  timesteps_this_iter: 5000
  timesteps_total: 910000
  training_iteration: 182
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1607 s, 182 iter, 910000 ts, -670 rew

agent-1: -41.553372748944625
agent-2: -147.85341044579985
agent-3: -234.7649369048974
agent-4: -204.4213866907022
agent-5: -120.53755902300195
Extrinsic Rewards:
5
3
10
6
0
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 0
Max Reward: 10
Gini Coefficient: 0.38333333333333336
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-00-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -468.88656762170353
  episode_reward_mean: -671.5341626743284
  episode_reward_min: -854.3530212948167
  episodes_this_iter: 1
  episodes_total: 182
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.003
    dispatch_time_ms: 31.308
    learner:
      cur_lr: 0.0012993939453735948
      grad_gnorm: 3.9561517238616943
      policy_entropy: 34.44835662841797
      policy_loss: -1.2012685537338257
      var_gnorm: 26.009775161743164
      vf_explained_var: 0.0
      vf_loss: 0.9618770480155945
    num_steps_sampled: 915000
    num_steps_trained: 915000
    wait_time_ms: 49.712
  iterations_since_restore: 183
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1616.8176634311676
  time_this_iter_s: 8.856874704360962
  time_total_s: 1616.8176634311676
  timestamp: 1594857620
  timesteps_since_restore: 915000
  timesteps_this_iter: 5000
  timesteps_total: 915000
  training_iteration: 183
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1616 s, 183 iter, 915000 ts, -672 rew

agent-1: -102.62616644668317
agent-2: -133.51288237882585
agent-3: -155.92974333958983
agent-4: -160.29522392933904
agent-5: -163.01966737586315
Extrinsic Rewards:
10
5
6
12
3
Sum Reward: 36
Avg Reward: 7.2
Min Reward: 3
Max Reward: 12
Gini Coefficient: 0.25555555555555554
20:20 Ratio: 4.0
Max-min Ratio: 4.0
agent-1: -208.21603806679292
agent-2: -206.29413135448726
agent-3: -24.487168913864213
agent-4: -120.79731096162095
agent-5: -122.34942847670789
Extrinsic Rewards:
8
7
2
8
3
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 2
Max Reward: 8
Gini Coefficient: 0.24285714285714285
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-00-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -468.88656762170353
  episode_reward_mean: -671.8305588230886
  episode_reward_min: -854.3530212948167
  episodes_this_iter: 2
  episodes_total: 184
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.564
    dispatch_time_ms: 22.767
    learner:
      cur_lr: 0.0012990609975531697
      grad_gnorm: 40.0
      policy_entropy: 27.368295669555664
      policy_loss: 556.552490234375
      var_gnorm: 26.009326934814453
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 5004.93896484375
    num_steps_sampled: 920000
    num_steps_trained: 920000
    wait_time_ms: 70.761
  iterations_since_restore: 184
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1625.8478178977966
  time_this_iter_s: 9.030154466629028
  time_total_s: 1625.8478178977966
  timestamp: 1594857629
  timesteps_since_restore: 920000
  timesteps_this_iter: 5000
  timesteps_total: 920000
  training_iteration: 184
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1625 s, 184 iter, 920000 ts, -672 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-00-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -468.88656762170353
  episode_reward_mean: -671.8305588230886
  episode_reward_min: -854.3530212948167
  episodes_this_iter: 0
  episodes_total: 184
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.701
    dispatch_time_ms: 46.508
    learner:
      cur_lr: 0.0012987280497327447
      grad_gnorm: 21.259571075439453
      policy_entropy: 31.958171844482422
      policy_loss: -10.232508659362793
      var_gnorm: 25.975210189819336
      vf_explained_var: 0.0
      vf_loss: 7.897052764892578
    num_steps_sampled: 925000
    num_steps_trained: 925000
    wait_time_ms: 46.664
  iterations_since_restore: 185
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1634.7973725795746
  time_this_iter_s: 8.949554681777954
  time_total_s: 1634.7973725795746
  timestamp: 1594857638
  timesteps_since_restore: 925000
  timesteps_this_iter: 5000
  timesteps_total: 925000
  training_iteration: 185
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1634 s, 185 iter, 925000 ts, -672 rew

agent-1: -124.74885413812903
agent-2: -71.03703942557858
agent-3: -167.49830685703864
agent-4: -62.34390938260504
agent-5: -178.25225651065327
Extrinsic Rewards:
14
12
15
21
25
Sum Reward: 87
Avg Reward: 17.4
Min Reward: 12
Max Reward: 25
Gini Coefficient: 0.15172413793103448
20:20 Ratio: 2.0833333333333335
Max-min Ratio: 2.0833333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-00-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -468.88656762170353
  episode_reward_mean: -671.8029064451309
  episode_reward_min: -854.3530212948167
  episodes_this_iter: 1
  episodes_total: 185
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.709
    dispatch_time_ms: 25.827
    learner:
      cur_lr: 0.0012983949854969978
      grad_gnorm: 12.309544563293457
      policy_entropy: 22.617185592651367
      policy_loss: 5.723808288574219
      var_gnorm: 25.993017196655273
      vf_explained_var: 0.0
      vf_loss: 7.860019207000732
    num_steps_sampled: 930000
    num_steps_trained: 930000
    wait_time_ms: 60.988
  iterations_since_restore: 186
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1643.5754103660583
  time_this_iter_s: 8.778037786483765
  time_total_s: 1643.5754103660583
  timestamp: 1594857647
  timesteps_since_restore: 930000
  timesteps_this_iter: 5000
  timesteps_total: 930000
  training_iteration: 186
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1643 s, 186 iter, 930000 ts, -672 rew

agent-1: -22.035954388656993
agent-2: -203.36537219724457
agent-3: -205.59823733451327
agent-4: -39.915720349624664
agent-5: -190.70230152676814
Extrinsic Rewards:
2
7
4
4
7
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 2
Max Reward: 7
Gini Coefficient: 0.21666666666666667
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-00-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -468.88656762170353
  episode_reward_mean: -672.243367614937
  episode_reward_min: -854.3530212948167
  episodes_this_iter: 1
  episodes_total: 186
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.487
    dispatch_time_ms: 33.751
    learner:
      cur_lr: 0.0012980620376765728
      grad_gnorm: 3.5503945350646973
      policy_entropy: 33.07834243774414
      policy_loss: -4.060838222503662
      var_gnorm: 25.979366302490234
      vf_explained_var: 0.0
      vf_loss: 5.160867691040039
    num_steps_sampled: 935000
    num_steps_trained: 935000
    wait_time_ms: 54.397
  iterations_since_restore: 187
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1652.357892036438
  time_this_iter_s: 8.782481670379639
  time_total_s: 1652.357892036438
  timestamp: 1594857656
  timesteps_since_restore: 935000
  timesteps_this_iter: 5000
  timesteps_total: 935000
  training_iteration: 187
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1652 s, 187 iter, 935000 ts, -672 rew

agent-1: -165.6437990733603
agent-2: -41.39894975590828
agent-3: -121.95548141725196
agent-4: -205.2762731387535
agent-5: -98.8924816751662
Extrinsic Rewards:
6
8
9
12
11
Sum Reward: 46
Avg Reward: 9.2
Min Reward: 6
Max Reward: 12
Gini Coefficient: 0.13043478260869565
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-01-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -468.88656762170353
  episode_reward_mean: -671.3359821064104
  episode_reward_min: -854.3530212948167
  episodes_this_iter: 1
  episodes_total: 187
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.935
    dispatch_time_ms: 27.166
    learner:
      cur_lr: 0.001297728973440826
      grad_gnorm: 5.310186862945557
      policy_entropy: 37.01632308959961
      policy_loss: -0.6243478655815125
      var_gnorm: 25.99729347229004
      vf_explained_var: 0.0
      vf_loss: 5.126811504364014
    num_steps_sampled: 940000
    num_steps_trained: 940000
    wait_time_ms: 62.208
  iterations_since_restore: 188
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1661.2377877235413
  time_this_iter_s: 8.879895687103271
  time_total_s: 1661.2377877235413
  timestamp: 1594857665
  timesteps_since_restore: 940000
  timesteps_this_iter: 5000
  timesteps_total: 940000
  training_iteration: 188
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1661 s, 188 iter, 940000 ts, -671 rew

agent-1: -11.161625815887597
agent-2: -173.97336945937988
agent-3: -114.69593986575677
agent-4: -166.7644331606559
agent-5: -186.27203628566977
Extrinsic Rewards:
1
13
10
15
12
Sum Reward: 51
Avg Reward: 10.2
Min Reward: 1
Max Reward: 15
Gini Coefficient: 0.24313725490196078
20:20 Ratio: 15.0
Max-min Ratio: 15.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-01-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -468.88656762170353
  episode_reward_mean: -670.5498872759922
  episode_reward_min: -854.3530212948167
  episodes_this_iter: 1
  episodes_total: 188
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.237
    dispatch_time_ms: 17.456
    learner:
      cur_lr: 0.001297396025620401
      grad_gnorm: 13.481539726257324
      policy_entropy: 43.39647674560547
      policy_loss: 4.546607494354248
      var_gnorm: 25.99213981628418
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.050265312194824
    num_steps_sampled: 945000
    num_steps_trained: 945000
    wait_time_ms: 58.388
  iterations_since_restore: 189
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1670.061312198639
  time_this_iter_s: 8.823524475097656
  time_total_s: 1670.061312198639
  timestamp: 1594857674
  timesteps_since_restore: 945000
  timesteps_this_iter: 5000
  timesteps_total: 945000
  training_iteration: 189
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1670 s, 189 iter, 945000 ts, -671 rew

agent-1: -48.756516042387254
agent-2: -156.09019980115613
agent-3: -84.09408252623729
agent-4: -109.57893152221133
agent-5: -250.53821643995656
Extrinsic Rewards:
1
5
2
2
8
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.37777777777777777
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-01-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -468.88656762170353
  episode_reward_mean: -668.4969365263632
  episode_reward_min: -843.9873382751232
  episodes_this_iter: 1
  episodes_total: 189
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.181
    dispatch_time_ms: 25.364
    learner:
      cur_lr: 0.001297062961384654
      grad_gnorm: 40.0
      policy_entropy: 44.32430648803711
      policy_loss: 20.86092185974121
      var_gnorm: 25.999258041381836
      vf_explained_var: -0.9108701944351196
      vf_loss: 20.856050491333008
    num_steps_sampled: 950000
    num_steps_trained: 950000
    wait_time_ms: 59.727
  iterations_since_restore: 190
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1678.852374792099
  time_this_iter_s: 8.791062593460083
  time_total_s: 1678.852374792099
  timestamp: 1594857682
  timesteps_since_restore: 950000
  timesteps_this_iter: 5000
  timesteps_total: 950000
  training_iteration: 190
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1678 s, 190 iter, 950000 ts, -668 rew

agent-1: -194.61387803420033
agent-2: -85.15065845986459
agent-3: -164.11562802675186
agent-4: -87.06592960873064
agent-5: -164.39830281977
Extrinsic Rewards:
4
4
8
9
2
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 2
Max Reward: 9
Gini Coefficient: 0.26666666666666666
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-01-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -468.88656762170353
  episode_reward_mean: -669.467493222895
  episode_reward_min: -843.9873382751232
  episodes_this_iter: 1
  episodes_total: 190
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.961
    dispatch_time_ms: 36.363
    learner:
      cur_lr: 0.001296730013564229
      grad_gnorm: 10.8357515335083
      policy_entropy: 43.31634521484375
      policy_loss: -7.332162380218506
      var_gnorm: 25.98898696899414
      vf_explained_var: 0.0
      vf_loss: 5.442942142486572
    num_steps_sampled: 955000
    num_steps_trained: 955000
    wait_time_ms: 60.126
  iterations_since_restore: 191
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1687.7095034122467
  time_this_iter_s: 8.857128620147705
  time_total_s: 1687.7095034122467
  timestamp: 1594857691
  timesteps_since_restore: 955000
  timesteps_this_iter: 5000
  timesteps_total: 955000
  training_iteration: 191
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1687 s, 191 iter, 955000 ts, -669 rew

agent-1: -135.95754698137145
agent-2: -213.64126443991188
agent-3: -30.651995719900214
agent-4: -138.28961619384674
agent-5: -134.8739853839321
Extrinsic Rewards:
12
10
5
4
6
Sum Reward: 37
Avg Reward: 7.4
Min Reward: 4
Max Reward: 12
Gini Coefficient: 0.22702702702702704
20:20 Ratio: 3.0
Max-min Ratio: 3.0
agent-1: -145.16477619476365
agent-2: -183.37648122626715
agent-3: -163.77317274150707
agent-4: -58.50905951622227
agent-5: -144.39503758878422
Extrinsic Rewards:
5
8
6
8
10
Sum Reward: 37
Avg Reward: 7.4
Min Reward: 5
Max Reward: 10
Gini Coefficient: 0.12972972972972974
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-01-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -468.88656762170353
  episode_reward_mean: -669.5273435057834
  episode_reward_min: -843.9873382751232
  episodes_this_iter: 2
  episodes_total: 192
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.782
    dispatch_time_ms: 20.047
    learner:
      cur_lr: 0.0012963969493284822
      grad_gnorm: 40.0
      policy_entropy: 35.00725173950195
      policy_loss: 470.3479309082031
      var_gnorm: 26.005170822143555
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 4643.13525390625
    num_steps_sampled: 960000
    num_steps_trained: 960000
    wait_time_ms: 63.449
  iterations_since_restore: 192
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1696.498096704483
  time_this_iter_s: 8.788593292236328
  time_total_s: 1696.498096704483
  timestamp: 1594857700
  timesteps_since_restore: 960000
  timesteps_this_iter: 5000
  timesteps_total: 960000
  training_iteration: 192
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1696 s, 192 iter, 960000 ts, -670 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-01-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -468.88656762170353
  episode_reward_mean: -669.5273435057832
  episode_reward_min: -843.9873382751232
  episodes_this_iter: 0
  episodes_total: 192
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.669
    dispatch_time_ms: 39.705
    learner:
      cur_lr: 0.0012960640015080571
      grad_gnorm: 21.073104858398438
      policy_entropy: 41.0286865234375
      policy_loss: -5.135960102081299
      var_gnorm: 25.951601028442383
      vf_explained_var: 0.0
      vf_loss: 6.205578804016113
    num_steps_sampled: 965000
    num_steps_trained: 965000
    wait_time_ms: 51.099
  iterations_since_restore: 193
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1705.1419534683228
  time_this_iter_s: 8.643856763839722
  time_total_s: 1705.1419534683228
  timestamp: 1594857709
  timesteps_since_restore: 965000
  timesteps_this_iter: 5000
  timesteps_total: 965000
  training_iteration: 193
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1705 s, 193 iter, 965000 ts, -670 rew

agent-1: -76.33984556358264
agent-2: -140.49305690894474
agent-3: -76.64578495113929
agent-4: -128.95503069736301
agent-5: -175.05534537641083
Extrinsic Rewards:
14
17
12
17
30
Sum Reward: 90
Avg Reward: 18.0
Min Reward: 12
Max Reward: 30
Gini Coefficient: 0.17333333333333334
20:20 Ratio: 2.5
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-01-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -468.88656762170353
  episode_reward_mean: -668.3283199286275
  episode_reward_min: -843.9873382751232
  episodes_this_iter: 1
  episodes_total: 193
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.225
    dispatch_time_ms: 47.306
    learner:
      cur_lr: 0.001295731053687632
      grad_gnorm: 19.625852584838867
      policy_entropy: 45.703800201416016
      policy_loss: 5.919449806213379
      var_gnorm: 25.962871551513672
      vf_explained_var: 0.0
      vf_loss: 11.983135223388672
    num_steps_sampled: 970000
    num_steps_trained: 970000
    wait_time_ms: 35.853
  iterations_since_restore: 194
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1714.1324005126953
  time_this_iter_s: 8.990447044372559
  time_total_s: 1714.1324005126953
  timestamp: 1594857718
  timesteps_since_restore: 970000
  timesteps_this_iter: 5000
  timesteps_total: 970000
  training_iteration: 194
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1714 s, 194 iter, 970000 ts, -668 rew

agent-1: -34.1493261513107
agent-2: -272.3435607255118
agent-3: -27.666603374946064
agent-4: -143.14521849101143
agent-5: -19.792730745271726
Extrinsic Rewards:
4
11
4
6
1
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 1
Max Reward: 11
Gini Coefficient: 0.3384615384615385
20:20 Ratio: 11.0
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-02-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -468.88656762170353
  episode_reward_mean: -667.8906085725866
  episode_reward_min: -843.9873382751232
  episodes_this_iter: 1
  episodes_total: 194
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.687
    dispatch_time_ms: 27.227
    learner:
      cur_lr: 0.0012953979894518852
      grad_gnorm: 26.665781021118164
      policy_entropy: 30.753278732299805
      policy_loss: -7.263671875
      var_gnorm: 25.961132049560547
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.8854498863220215
    num_steps_sampled: 975000
    num_steps_trained: 975000
    wait_time_ms: 62.967
  iterations_since_restore: 195
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1722.9928047657013
  time_this_iter_s: 8.860404253005981
  time_total_s: 1722.9928047657013
  timestamp: 1594857727
  timesteps_since_restore: 975000
  timesteps_this_iter: 5000
  timesteps_total: 975000
  training_iteration: 195
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1722 s, 195 iter, 975000 ts, -668 rew

agent-1: -255.70310282107135
agent-2: -12.969618529087796
agent-3: -53.685753485098715
agent-4: -50.55052881467075
agent-5: -32.23068080073363
Extrinsic Rewards:
5
2
7
7
6
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 2
Max Reward: 7
Gini Coefficient: 0.17777777777777778
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-02-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -665.2096425344538
  episode_reward_min: -843.9873382751232
  episodes_this_iter: 1
  episodes_total: 195
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.632
    dispatch_time_ms: 29.629
    learner:
      cur_lr: 0.0012950650416314602
      grad_gnorm: 32.393531799316406
      policy_entropy: 26.146528244018555
      policy_loss: -12.044301986694336
      var_gnorm: 25.952880859375
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 6.291247367858887
    num_steps_sampled: 980000
    num_steps_trained: 980000
    wait_time_ms: 55.621
  iterations_since_restore: 196
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1731.8152186870575
  time_this_iter_s: 8.822413921356201
  time_total_s: 1731.8152186870575
  timestamp: 1594857736
  timesteps_since_restore: 980000
  timesteps_this_iter: 5000
  timesteps_total: 980000
  training_iteration: 196
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1731 s, 196 iter, 980000 ts, -665 rew

agent-1: -117.80856971022156
agent-2: -162.05901086932923
agent-3: -209.97100001971495
agent-4: -171.51442095119543
agent-5: -27.464148035848623
Extrinsic Rewards:
7
6
9
5
5
Sum Reward: 32
Avg Reward: 6.4
Min Reward: 5
Max Reward: 9
Gini Coefficient: 0.125
20:20 Ratio: 1.8
Max-min Ratio: 1.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-02-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -665.1180990270062
  episode_reward_min: -843.9873382751232
  episodes_this_iter: 1
  episodes_total: 196
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.54
    dispatch_time_ms: 31.595
    learner:
      cur_lr: 0.0012947319773957133
      grad_gnorm: 15.023416519165039
      policy_entropy: 44.83249282836914
      policy_loss: -3.5069236755371094
      var_gnorm: 25.958282470703125
      vf_explained_var: 0.0
      vf_loss: 8.013391494750977
    num_steps_sampled: 985000
    num_steps_trained: 985000
    wait_time_ms: 55.255
  iterations_since_restore: 197
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1740.5302875041962
  time_this_iter_s: 8.715068817138672
  time_total_s: 1740.5302875041962
  timestamp: 1594857744
  timesteps_since_restore: 985000
  timesteps_this_iter: 5000
  timesteps_total: 985000
  training_iteration: 197
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1740 s, 197 iter, 985000 ts, -665 rew

agent-1: -73.90307090295688
agent-2: -97.0546396528686
agent-3: -174.86622810265172
agent-4: -66.59087829776658
agent-5: -177.636844697251
Extrinsic Rewards:
12
10
12
20
9
Sum Reward: 63
Avg Reward: 12.6
Min Reward: 9
Max Reward: 20
Gini Coefficient: 0.1523809523809524
20:20 Ratio: 2.2222222222222223
Max-min Ratio: 2.2222222222222223
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-02-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -663.7089549170611
  episode_reward_min: -843.9873382751232
  episodes_this_iter: 1
  episodes_total: 197
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.205
    dispatch_time_ms: 30.273
    learner:
      cur_lr: 0.0012943990295752883
      grad_gnorm: 34.47986602783203
      policy_entropy: 48.67646408081055
      policy_loss: 12.065343856811523
      var_gnorm: 25.988990783691406
      vf_explained_var: 0.0
      vf_loss: 9.031986236572266
    num_steps_sampled: 990000
    num_steps_trained: 990000
    wait_time_ms: 50.363
  iterations_since_restore: 198
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1749.359337568283
  time_this_iter_s: 8.829050064086914
  time_total_s: 1749.359337568283
  timestamp: 1594857753
  timesteps_since_restore: 990000
  timesteps_this_iter: 5000
  timesteps_total: 990000
  training_iteration: 198
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1749 s, 198 iter, 990000 ts, -664 rew

agent-1: -146.69007758662977
agent-2: -65.02825121140131
agent-3: -193.61791262370843
agent-4: -148.85653110367292
agent-5: -122.87827611336598
Extrinsic Rewards:
5
9
17
16
9
Sum Reward: 56
Avg Reward: 11.2
Min Reward: 5
Max Reward: 17
Gini Coefficient: 0.22142857142857142
20:20 Ratio: 3.4
Max-min Ratio: 3.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-02-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -663.3514269744132
  episode_reward_min: -843.9873382751232
  episodes_this_iter: 1
  episodes_total: 198
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.505
    dispatch_time_ms: 30.719
    learner:
      cur_lr: 0.0012940659653395414
      grad_gnorm: 18.346092224121094
      policy_entropy: 53.727394104003906
      policy_loss: -5.021066188812256
      var_gnorm: 25.986299514770508
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 5.319906711578369
    num_steps_sampled: 995000
    num_steps_trained: 995000
    wait_time_ms: 63.059
  iterations_since_restore: 199
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1758.1718065738678
  time_this_iter_s: 8.812469005584717
  time_total_s: 1758.1718065738678
  timestamp: 1594857762
  timesteps_since_restore: 995000
  timesteps_this_iter: 5000
  timesteps_total: 995000
  training_iteration: 199
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1758 s, 199 iter, 995000 ts, -663 rew

agent-1: -200.84929042471853
agent-2: -205.12686954514433
agent-3: -117.86016730601607
agent-4: -117.86016730601607
agent-5: -217.12724420014243
Extrinsic Rewards:
13
8
0
0
13
Sum Reward: 34
Avg Reward: 6.8
Min Reward: 0
Max Reward: 13
Gini Coefficient: 0.4588235294117647
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-02-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -665.6127692496701
  episode_reward_min: -858.8237387820633
  episodes_this_iter: 1
  episodes_total: 199
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.747
    dispatch_time_ms: 28.559
    learner:
      cur_lr: 0.0012937330175191164
      grad_gnorm: 20.54551887512207
      policy_entropy: 57.11228942871094
      policy_loss: 6.476138591766357
      var_gnorm: 26.03960418701172
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.731862545013428
    num_steps_sampled: 1000000
    num_steps_trained: 1000000
    wait_time_ms: 62.709
  iterations_since_restore: 200
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1766.971513748169
  time_this_iter_s: 8.799707174301147
  time_total_s: 1766.971513748169
  timestamp: 1594857771
  timesteps_since_restore: 1000000
  timesteps_this_iter: 5000
  timesteps_total: 1000000
  training_iteration: 200
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1766 s, 200 iter, 1000000 ts, -666 rew

agent-1: -94.89729396042135
agent-2: -245.75066170355183
agent-3: -160.8530821318417
agent-4: -137.53750929455595
agent-5: -28.080948741717055
Extrinsic Rewards:
4
9
2
3
1
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.37894736842105264
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-03-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -666.2215539414105
  episode_reward_min: -858.8237387820633
  episodes_this_iter: 1
  episodes_total: 200
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.672
    dispatch_time_ms: 30.164
    learner:
      cur_lr: 0.0012933999532833695
      grad_gnorm: 10.63133716583252
      policy_entropy: 51.9565315246582
      policy_loss: -0.8972467184066772
      var_gnorm: 25.992063522338867
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 6.0504560470581055
    num_steps_sampled: 1005000
    num_steps_trained: 1005000
    wait_time_ms: 55.006
  iterations_since_restore: 201
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1775.7055475711823
  time_this_iter_s: 8.734033823013306
  time_total_s: 1775.7055475711823
  timestamp: 1594857780
  timesteps_since_restore: 1005000
  timesteps_this_iter: 5000
  timesteps_total: 1005000
  training_iteration: 201
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1775 s, 201 iter, 1005000 ts, -666 rew

agent-1: -107.81114327848971
agent-2: -252.45046182530268
agent-3: -181.3585415878248
agent-4: -81.24575724319023
agent-5: -29.92860454586367
Extrinsic Rewards:
3
8
4
2
1
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.35555555555555557
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-03-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -666.6148390624198
  episode_reward_min: -858.8237387820633
  episodes_this_iter: 1
  episodes_total: 201
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.753
    dispatch_time_ms: 44.817
    learner:
      cur_lr: 0.0012930670054629445
      grad_gnorm: 18.638872146606445
      policy_entropy: 46.04180145263672
      policy_loss: 2.2481391429901123
      var_gnorm: 25.97495460510254
      vf_explained_var: 0.0
      vf_loss: 9.90793514251709
    num_steps_sampled: 1010000
    num_steps_trained: 1010000
    wait_time_ms: 40.144
  iterations_since_restore: 202
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1784.6361031532288
  time_this_iter_s: 8.930555582046509
  time_total_s: 1784.6361031532288
  timestamp: 1594857789
  timesteps_since_restore: 1010000
  timesteps_this_iter: 5000
  timesteps_total: 1010000
  training_iteration: 202
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1784 s, 202 iter, 1010000 ts, -667 rew

agent-1: -114.14028243412098
agent-2: -33.11605517019187
agent-3: -59.899977559725194
agent-4: -69.08020318841055
agent-5: -241.049585621426
Extrinsic Rewards:
10
5
3
11
9
Sum Reward: 38
Avg Reward: 7.6
Min Reward: 3
Max Reward: 11
Gini Coefficient: 0.22105263157894736
20:20 Ratio: 3.6666666666666665
Max-min Ratio: 3.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-03-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -664.9143011622162
  episode_reward_min: -858.8237387820633
  episodes_this_iter: 1
  episodes_total: 202
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.312
    dispatch_time_ms: 24.738
    learner:
      cur_lr: 0.0012927340576425195
      grad_gnorm: 6.67294454574585
      policy_entropy: 40.94038391113281
      policy_loss: -0.3318835198879242
      var_gnorm: 25.985958099365234
      vf_explained_var: 0.0
      vf_loss: 6.893448829650879
    num_steps_sampled: 1015000
    num_steps_trained: 1015000
    wait_time_ms: 66.29
  iterations_since_restore: 203
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1793.6590495109558
  time_this_iter_s: 9.02294635772705
  time_total_s: 1793.6590495109558
  timestamp: 1594857798
  timesteps_since_restore: 1015000
  timesteps_this_iter: 5000
  timesteps_total: 1015000
  training_iteration: 203
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1793 s, 203 iter, 1015000 ts, -665 rew

agent-1: -184.75057965799576
agent-2: -169.92455600670164
agent-3: -214.4673489379233
agent-4: -48.90575403303608
agent-5: -71.48128694404393
Extrinsic Rewards:
3
2
7
3
5
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 2
Max Reward: 7
Gini Coefficient: 0.24
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-03-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -666.1364743036787
  episode_reward_min: -858.8237387820633
  episodes_this_iter: 1
  episodes_total: 203
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.88
    dispatch_time_ms: 33.419
    learner:
      cur_lr: 0.0012924009934067726
      grad_gnorm: 40.0
      policy_entropy: 44.2114143371582
      policy_loss: 31.562528610229492
      var_gnorm: 25.995838165283203
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 23.00277328491211
    num_steps_sampled: 1020000
    num_steps_trained: 1020000
    wait_time_ms: 45.144
  iterations_since_restore: 204
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1802.4696094989777
  time_this_iter_s: 8.81055998802185
  time_total_s: 1802.4696094989777
  timestamp: 1594857807
  timesteps_since_restore: 1020000
  timesteps_this_iter: 5000
  timesteps_total: 1020000
  training_iteration: 204
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1802 s, 204 iter, 1020000 ts, -666 rew

agent-1: -245.1891442463682
agent-2: -104.69958664334486
agent-3: -104.51342358604366
agent-4: -137.83467404247585
agent-5: -13.536734281156303
Extrinsic Rewards:
16
6
3
8
3
Sum Reward: 36
Avg Reward: 7.2
Min Reward: 3
Max Reward: 16
Gini Coefficient: 0.34444444444444444
20:20 Ratio: 5.333333333333333
Max-min Ratio: 5.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-03-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -666.1144887102121
  episode_reward_min: -858.8237387820633
  episodes_this_iter: 1
  episodes_total: 204
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.953
    dispatch_time_ms: 18.232
    learner:
      cur_lr: 0.0012920680455863476
      grad_gnorm: 40.00000762939453
      policy_entropy: 49.17566680908203
      policy_loss: 1.6162939071655273
      var_gnorm: 25.97408676147461
      vf_explained_var: 0.0
      vf_loss: 10.520248413085938
    num_steps_sampled: 1025000
    num_steps_trained: 1025000
    wait_time_ms: 66.623
  iterations_since_restore: 205
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1811.3522126674652
  time_this_iter_s: 8.882603168487549
  time_total_s: 1811.3522126674652
  timestamp: 1594857816
  timesteps_since_restore: 1025000
  timesteps_this_iter: 5000
  timesteps_total: 1025000
  training_iteration: 205
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1811 s, 205 iter, 1025000 ts, -666 rew

agent-1: -187.93350711282588
agent-2: -228.86096937124896
agent-3: -25.996206957444205
agent-4: -16.133569159306788
agent-5: -109.0743393238691
Extrinsic Rewards:
7
8
6
1
12
Sum Reward: 34
Avg Reward: 6.8
Min Reward: 1
Max Reward: 12
Gini Coefficient: 0.2823529411764706
20:20 Ratio: 12.0
Max-min Ratio: 12.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-03-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -664.3712648424166
  episode_reward_min: -858.8237387820633
  episodes_this_iter: 1
  episodes_total: 205
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.029
    dispatch_time_ms: 28.057
    learner:
      cur_lr: 0.0012917349813506007
      grad_gnorm: 40.0
      policy_entropy: 51.41227722167969
      policy_loss: 18.801498413085938
      var_gnorm: 26.003990173339844
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 12.716294288635254
    num_steps_sampled: 1030000
    num_steps_trained: 1030000
    wait_time_ms: 52.93
  iterations_since_restore: 206
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1820.1286878585815
  time_this_iter_s: 8.776475191116333
  time_total_s: 1820.1286878585815
  timestamp: 1594857824
  timesteps_since_restore: 1030000
  timesteps_this_iter: 5000
  timesteps_total: 1030000
  training_iteration: 206
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1820 s, 206 iter, 1030000 ts, -664 rew

agent-1: -22.304837962240722
agent-2: -259.5989588623116
agent-3: -224.54246975325194
agent-4: -58.81366021424682
agent-5: -138.88932313076552
Extrinsic Rewards:
1
11
5
2
0
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 0
Max Reward: 11
Gini Coefficient: 0.5473684210526316
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-04-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -665.2157452345336
  episode_reward_min: -858.8237387820633
  episodes_this_iter: 1
  episodes_total: 206
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.422
    dispatch_time_ms: 19.271
    learner:
      cur_lr: 0.0012914020335301757
      grad_gnorm: 16.69154930114746
      policy_entropy: 51.32219696044922
      policy_loss: -4.908439636230469
      var_gnorm: 25.981246948242188
      vf_explained_var: 0.0
      vf_loss: 4.663337230682373
    num_steps_sampled: 1035000
    num_steps_trained: 1035000
    wait_time_ms: 70.38
  iterations_since_restore: 207
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1835.6411781311035
  time_this_iter_s: 15.512490272521973
  time_total_s: 1835.6411781311035
  timestamp: 1594857840
  timesteps_since_restore: 1035000
  timesteps_this_iter: 5000
  timesteps_total: 1035000
  training_iteration: 207
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1835 s, 207 iter, 1035000 ts, -665 rew

agent-1: -110.06993218352409
agent-2: -153.10469686065173
agent-3: -114.60436437640358
agent-4: -86.29767858586017
agent-5: -152.116697224653
Extrinsic Rewards:
16
12
11
11
9
Sum Reward: 59
Avg Reward: 11.8
Min Reward: 9
Max Reward: 16
Gini Coefficient: 0.1016949152542373
20:20 Ratio: 1.7777777777777777
Max-min Ratio: 1.7777777777777777
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-04-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -664.5727478537982
  episode_reward_min: -858.8237387820633
  episodes_this_iter: 1
  episodes_total: 207
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.538
    dispatch_time_ms: 17.449
    learner:
      cur_lr: 0.0012910689692944288
      grad_gnorm: 16.760683059692383
      policy_entropy: 46.630516052246094
      policy_loss: -0.9057462811470032
      var_gnorm: 25.99685287475586
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 6.017602443695068
    num_steps_sampled: 1040000
    num_steps_trained: 1040000
    wait_time_ms: 69.251
  iterations_since_restore: 208
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1844.4827315807343
  time_this_iter_s: 8.841553449630737
  time_total_s: 1844.4827315807343
  timestamp: 1594857849
  timesteps_since_restore: 1040000
  timesteps_this_iter: 5000
  timesteps_total: 1040000
  training_iteration: 208
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1844 s, 208 iter, 1040000 ts, -665 rew

agent-1: -178.13538031280808
agent-2: -76.8468652110601
agent-3: -144.69228049837616
agent-4: -60.33197342648126
agent-5: -170.16468222475447
Extrinsic Rewards:
6
3
17
12
13
Sum Reward: 51
Avg Reward: 10.2
Min Reward: 3
Max Reward: 17
Gini Coefficient: 0.27450980392156865
20:20 Ratio: 5.666666666666667
Max-min Ratio: 5.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-04-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -664.1172993400556
  episode_reward_min: -858.8237387820633
  episodes_this_iter: 1
  episodes_total: 208
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.654
    dispatch_time_ms: 33.39
    learner:
      cur_lr: 0.0012907360214740038
      grad_gnorm: 19.331016540527344
      policy_entropy: 49.40742492675781
      policy_loss: -5.068929195404053
      var_gnorm: 25.98677635192871
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 8.256790161132812
    num_steps_sampled: 1045000
    num_steps_trained: 1045000
    wait_time_ms: 60.55
  iterations_since_restore: 209
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1853.3615372180939
  time_this_iter_s: 8.87880563735962
  time_total_s: 1853.3615372180939
  timestamp: 1594857858
  timesteps_since_restore: 1045000
  timesteps_this_iter: 5000
  timesteps_total: 1045000
  training_iteration: 209
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1853 s, 209 iter, 1045000 ts, -664 rew

agent-1: -15.297907234198632
agent-2: -221.6077496820377
agent-3: -59.5513809319285
agent-4: -127.6037780052788
agent-5: -200.62051869684538
Extrinsic Rewards:
3
14
4
7
9
Sum Reward: 37
Avg Reward: 7.4
Min Reward: 3
Max Reward: 14
Gini Coefficient: 0.2918918918918919
20:20 Ratio: 4.666666666666667
Max-min Ratio: 4.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-04-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -664.3482846415119
  episode_reward_min: -858.8237387820633
  episodes_this_iter: 1
  episodes_total: 209
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.172
    dispatch_time_ms: 29.45
    learner:
      cur_lr: 0.001290402957238257
      grad_gnorm: 12.427621841430664
      policy_entropy: 41.62761688232422
      policy_loss: -0.36071810126304626
      var_gnorm: 25.99359703063965
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 5.430971145629883
    num_steps_sampled: 1050000
    num_steps_trained: 1050000
    wait_time_ms: 63.665
  iterations_since_restore: 210
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1862.1790852546692
  time_this_iter_s: 8.817548036575317
  time_total_s: 1862.1790852546692
  timestamp: 1594857867
  timesteps_since_restore: 1050000
  timesteps_this_iter: 5000
  timesteps_total: 1050000
  training_iteration: 210
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1862 s, 210 iter, 1050000 ts, -664 rew

agent-1: -105.9382103859328
agent-2: -70.62806274431635
agent-3: -244.98866843472098
agent-4: -169.4700445285629
agent-5: -54.23287667735063
Extrinsic Rewards:
3
5
14
4
3
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 3
Max Reward: 14
Gini Coefficient: 0.3310344827586207
20:20 Ratio: 4.666666666666667
Max-min Ratio: 4.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-04-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -664.844021964563
  episode_reward_min: -858.8237387820633
  episodes_this_iter: 1
  episodes_total: 210
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.636
    dispatch_time_ms: 41.373
    learner:
      cur_lr: 0.001290070009417832
      grad_gnorm: 14.648626327514648
      policy_entropy: 51.354225158691406
      policy_loss: -2.510822296142578
      var_gnorm: 25.986970901489258
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 6.494948387145996
    num_steps_sampled: 1055000
    num_steps_trained: 1055000
    wait_time_ms: 47.558
  iterations_since_restore: 211
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1870.9861278533936
  time_this_iter_s: 8.807042598724365
  time_total_s: 1870.9861278533936
  timestamp: 1594857875
  timesteps_since_restore: 1055000
  timesteps_this_iter: 5000
  timesteps_total: 1055000
  training_iteration: 211
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1870 s, 211 iter, 1055000 ts, -665 rew

agent-1: -85.15382651749377
agent-2: -155.95193375157587
agent-3: -193.19251308061985
agent-4: -44.48837970570996
agent-5: -117.85658297835158
Extrinsic Rewards:
13
12
15
9
11
Sum Reward: 60
Avg Reward: 12.0
Min Reward: 9
Max Reward: 15
Gini Coefficient: 0.09333333333333334
20:20 Ratio: 1.6666666666666667
Max-min Ratio: 1.6666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-04-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -663.8973634727355
  episode_reward_min: -858.8237387820633
  episodes_this_iter: 1
  episodes_total: 211
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.357
    dispatch_time_ms: 32.284
    learner:
      cur_lr: 0.001289736945182085
      grad_gnorm: 40.0
      policy_entropy: 54.45090103149414
      policy_loss: 54.2474365234375
      var_gnorm: 26.000408172607422
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 29.230972290039062
    num_steps_sampled: 1060000
    num_steps_trained: 1060000
    wait_time_ms: 61.934
  iterations_since_restore: 212
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1880.0322184562683
  time_this_iter_s: 9.046090602874756
  time_total_s: 1880.0322184562683
  timestamp: 1594857885
  timesteps_since_restore: 1060000
  timesteps_this_iter: 5000
  timesteps_total: 1060000
  training_iteration: 212
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1880 s, 212 iter, 1060000 ts, -664 rew

agent-1: -232.66743669813047
agent-2: -125.10692132005644
agent-3: -59.53106542296702
agent-4: -123.70953878998115
agent-5: -159.9074562678616
Extrinsic Rewards:
4
4
2
4
3
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 2
Max Reward: 4
Gini Coefficient: 0.11764705882352941
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-04-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -664.4084630160427
  episode_reward_min: -858.8237387820633
  episodes_this_iter: 1
  episodes_total: 212
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.303
    dispatch_time_ms: 30.187
    learner:
      cur_lr: 0.00128940399736166
      grad_gnorm: 10.81812858581543
      policy_entropy: 46.43790817260742
      policy_loss: -3.742896795272827
      var_gnorm: 25.986431121826172
      vf_explained_var: 0.0
      vf_loss: 6.037787914276123
    num_steps_sampled: 1065000
    num_steps_trained: 1065000
    wait_time_ms: 59.031
  iterations_since_restore: 213
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1888.8367757797241
  time_this_iter_s: 8.80455732345581
  time_total_s: 1888.8367757797241
  timestamp: 1594857893
  timesteps_since_restore: 1065000
  timesteps_this_iter: 5000
  timesteps_total: 1065000
  training_iteration: 213
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1888 s, 213 iter, 1065000 ts, -664 rew

agent-1: -59.7630248447466
agent-2: -176.09025115102926
agent-3: -30.634930617209424
agent-4: -210.08561227660846
agent-5: -213.1440754007542
Extrinsic Rewards:
1
7
1
5
6
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 1
Max Reward: 7
Gini Coefficient: 0.34
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-05-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -665.0923967696228
  episode_reward_min: -858.8237387820633
  episodes_this_iter: 1
  episodes_total: 213
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.479
    dispatch_time_ms: 26.846
    learner:
      cur_lr: 0.001289071049541235
      grad_gnorm: 10.77629566192627
      policy_entropy: 29.632261276245117
      policy_loss: 1.3195176124572754
      var_gnorm: 25.98904800415039
      vf_explained_var: 0.0
      vf_loss: 9.608915328979492
    num_steps_sampled: 1070000
    num_steps_trained: 1070000
    wait_time_ms: 57.38
  iterations_since_restore: 214
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1898.0557253360748
  time_this_iter_s: 9.218949556350708
  time_total_s: 1898.0557253360748
  timestamp: 1594857903
  timesteps_since_restore: 1070000
  timesteps_this_iter: 5000
  timesteps_total: 1070000
  training_iteration: 214
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1898 s, 214 iter, 1070000 ts, -665 rew

agent-1: -186.93617475816907
agent-2: -219.80903065409228
agent-3: -18.73764357114394
agent-4: -82.6651154530429
agent-5: -66.3884687539372
Extrinsic Rewards:
9
9
4
5
15
Sum Reward: 42
Avg Reward: 8.4
Min Reward: 4
Max Reward: 15
Gini Coefficient: 0.24761904761904763
20:20 Ratio: 3.75
Max-min Ratio: 3.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-05-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -665.340304373883
  episode_reward_min: -858.8237387820633
  episodes_this_iter: 1
  episodes_total: 214
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.767
    dispatch_time_ms: 32.606
    learner:
      cur_lr: 0.0012887379853054881
      grad_gnorm: 16.27654457092285
      policy_entropy: 32.63832473754883
      policy_loss: -6.884526252746582
      var_gnorm: 25.974287033081055
      vf_explained_var: 0.0
      vf_loss: 7.303266525268555
    num_steps_sampled: 1075000
    num_steps_trained: 1075000
    wait_time_ms: 53.411
  iterations_since_restore: 215
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1906.5158371925354
  time_this_iter_s: 8.460111856460571
  time_total_s: 1906.5158371925354
  timestamp: 1594857911
  timesteps_since_restore: 1075000
  timesteps_this_iter: 5000
  timesteps_total: 1075000
  training_iteration: 215
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1906 s, 215 iter, 1075000 ts, -665 rew

agent-1: -173.13739777209494
agent-2: -120.4965132799021
agent-3: -99.62281512163581
agent-4: -95.29968837899136
agent-5: -70.04734652136445
Extrinsic Rewards:
21
21
13
8
15
Sum Reward: 78
Avg Reward: 15.6
Min Reward: 8
Max Reward: 21
Gini Coefficient: 0.17435897435897435
20:20 Ratio: 2.625
Max-min Ratio: 2.625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-05-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -663.6498590281435
  episode_reward_min: -858.8237387820633
  episodes_this_iter: 1
  episodes_total: 215
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.863
    dispatch_time_ms: 23.359
    learner:
      cur_lr: 0.001288405037485063
      grad_gnorm: 20.853836059570312
      policy_entropy: 36.601444244384766
      policy_loss: 11.478240013122559
      var_gnorm: 25.980878829956055
      vf_explained_var: 0.0
      vf_loss: 8.216676712036133
    num_steps_sampled: 1080000
    num_steps_trained: 1080000
    wait_time_ms: 68.422
  iterations_since_restore: 216
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1915.390703201294
  time_this_iter_s: 8.874866008758545
  time_total_s: 1915.390703201294
  timestamp: 1594857920
  timesteps_since_restore: 1080000
  timesteps_this_iter: 5000
  timesteps_total: 1080000
  training_iteration: 216
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1915 s, 216 iter, 1080000 ts, -664 rew

agent-1: -187.94259842696513
agent-2: -26.73043486988988
agent-3: -204.0453194779181
agent-4: -86.00990379691054
agent-5: -128.19275571476032
Extrinsic Rewards:
11
5
7
12
7
Sum Reward: 42
Avg Reward: 8.4
Min Reward: 5
Max Reward: 12
Gini Coefficient: 0.17142857142857143
20:20 Ratio: 2.4
Max-min Ratio: 2.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-05-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -662.4361166340832
  episode_reward_min: -858.8237387820633
  episodes_this_iter: 1
  episodes_total: 216
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.903
    dispatch_time_ms: 20.422
    learner:
      cur_lr: 0.0012880719732493162
      grad_gnorm: 10.5577974319458
      policy_entropy: 55.33951950073242
      policy_loss: -0.37550753355026245
      var_gnorm: 25.977624893188477
      vf_explained_var: 0.0
      vf_loss: 8.709229469299316
    num_steps_sampled: 1085000
    num_steps_trained: 1085000
    wait_time_ms: 53.708
  iterations_since_restore: 217
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1924.160180568695
  time_this_iter_s: 8.769477367401123
  time_total_s: 1924.160180568695
  timestamp: 1594857929
  timesteps_since_restore: 1085000
  timesteps_this_iter: 5000
  timesteps_total: 1085000
  training_iteration: 217
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1924 s, 217 iter, 1085000 ts, -662 rew

agent-1: -72.2415416547003
agent-2: -143.1533855106542
agent-3: -218.33598864586972
agent-4: -88.95611686873923
agent-5: -120.51039800962016
Extrinsic Rewards:
12
11
6
4
6
Sum Reward: 39
Avg Reward: 7.8
Min Reward: 4
Max Reward: 12
Gini Coefficient: 0.2153846153846154
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-05-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -661.7912189344969
  episode_reward_min: -858.8237387820633
  episodes_this_iter: 1
  episodes_total: 217
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 5.286
    dispatch_time_ms: 30.337
    learner:
      cur_lr: 0.0012877390254288912
      grad_gnorm: 12.227051734924316
      policy_entropy: 53.818084716796875
      policy_loss: 0.24588201940059662
      var_gnorm: 25.980297088623047
      vf_explained_var: 0.0
      vf_loss: 8.698280334472656
    num_steps_sampled: 1090000
    num_steps_trained: 1090000
    wait_time_ms: 54.424
  iterations_since_restore: 218
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1933.0082476139069
  time_this_iter_s: 8.848067045211792
  time_total_s: 1933.0082476139069
  timestamp: 1594857938
  timesteps_since_restore: 1090000
  timesteps_this_iter: 5000
  timesteps_total: 1090000
  training_iteration: 218
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1933 s, 218 iter, 1090000 ts, -662 rew

agent-1: -229.93273758297954
agent-2: -13.082790463597776
agent-3: -178.7182151278307
agent-4: -53.41703189193034
agent-5: -144.44203522838504
Extrinsic Rewards:
10
2
6
5
10
Sum Reward: 33
Avg Reward: 6.6
Min Reward: 2
Max Reward: 10
Gini Coefficient: 0.2545454545454545
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-05-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -661.3366770457824
  episode_reward_min: -858.8237387820633
  episodes_this_iter: 1
  episodes_total: 218
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.749
    dispatch_time_ms: 28.741
    learner:
      cur_lr: 0.0012874059611931443
      grad_gnorm: 14.05416202545166
      policy_entropy: 33.649227142333984
      policy_loss: 2.8784806728363037
      var_gnorm: 25.964420318603516
      vf_explained_var: 0.0
      vf_loss: 10.461533546447754
    num_steps_sampled: 1095000
    num_steps_trained: 1095000
    wait_time_ms: 64.944
  iterations_since_restore: 219
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1941.8729033470154
  time_this_iter_s: 8.86465573310852
  time_total_s: 1941.8729033470154
  timestamp: 1594857947
  timesteps_since_restore: 1095000
  timesteps_this_iter: 5000
  timesteps_total: 1095000
  training_iteration: 219
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1941 s, 219 iter, 1095000 ts, -661 rew

agent-1: -152.7256504414126
agent-2: -242.207646758955
agent-3: -149.10503054370287
agent-4: -101.35414389448862
agent-5: -133.74964382964387
Extrinsic Rewards:
3
12
6
4
0
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 0
Max Reward: 12
Gini Coefficient: 0.432
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-05-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -661.6390962736416
  episode_reward_min: -858.8237387820633
  episodes_this_iter: 1
  episodes_total: 219
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.003
    dispatch_time_ms: 25.624
    learner:
      cur_lr: 0.0012870730133727193
      grad_gnorm: 18.52173614501953
      policy_entropy: 43.24565887451172
      policy_loss: -7.507265567779541
      var_gnorm: 26.016704559326172
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 13.241909980773926
    num_steps_sampled: 1100000
    num_steps_trained: 1100000
    wait_time_ms: 71.105
  iterations_since_restore: 220
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1950.8101201057434
  time_this_iter_s: 8.937216758728027
  time_total_s: 1950.8101201057434
  timestamp: 1594857956
  timesteps_since_restore: 1100000
  timesteps_this_iter: 5000
  timesteps_total: 1100000
  training_iteration: 220
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1950 s, 220 iter, 1100000 ts, -662 rew

agent-1: -278.28662412700595
agent-2: -105.13217961645198
agent-3: -119.71901521520844
agent-4: -21.517124965597066
agent-5: -78.29840453881214
Extrinsic Rewards:
17
4
0
1
5
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 0
Max Reward: 17
Gini Coefficient: 0.562962962962963
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-06-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -659.2287563755209
  episode_reward_min: -858.8237387820633
  episodes_this_iter: 1
  episodes_total: 220
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.099
    dispatch_time_ms: 36.594
    learner:
      cur_lr: 0.0012867399491369724
      grad_gnorm: 7.582499027252197
      policy_entropy: 52.74773406982422
      policy_loss: 2.3502912521362305
      var_gnorm: 25.988601684570312
      vf_explained_var: 0.0
      vf_loss: 7.5197038650512695
    num_steps_sampled: 1105000
    num_steps_trained: 1105000
    wait_time_ms: 49.096
  iterations_since_restore: 221
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1959.7068402767181
  time_this_iter_s: 8.896720170974731
  time_total_s: 1959.7068402767181
  timestamp: 1594857964
  timesteps_since_restore: 1105000
  timesteps_this_iter: 5000
  timesteps_total: 1105000
  training_iteration: 221
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1959 s, 221 iter, 1105000 ts, -659 rew

agent-1: -202.68242171020276
agent-2: -115.04219422126013
agent-3: -5.085230513601142
agent-4: -204.55338776180247
agent-5: -138.26050726365995
Extrinsic Rewards:
12
11
1
10
5
Sum Reward: 39
Avg Reward: 7.8
Min Reward: 1
Max Reward: 12
Gini Coefficient: 0.28717948717948716
20:20 Ratio: 12.0
Max-min Ratio: 12.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-06-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -657.824809251122
  episode_reward_min: -858.8237387820633
  episodes_this_iter: 1
  episodes_total: 221
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.734
    dispatch_time_ms: 19.033
    learner:
      cur_lr: 0.0012864070013165474
      grad_gnorm: 26.117610931396484
      policy_entropy: 55.70320129394531
      policy_loss: -8.611750602722168
      var_gnorm: 26.018993377685547
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 9.105456352233887
    num_steps_sampled: 1110000
    num_steps_trained: 1110000
    wait_time_ms: 69.323
  iterations_since_restore: 222
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1968.5519502162933
  time_this_iter_s: 8.845109939575195
  time_total_s: 1968.5519502162933
  timestamp: 1594857973
  timesteps_since_restore: 1110000
  timesteps_this_iter: 5000
  timesteps_total: 1110000
  training_iteration: 222
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1968 s, 222 iter, 1110000 ts, -658 rew

agent-1: -265.57951487848555
agent-2: -139.08966081492332
agent-3: -58.8610119078529
agent-4: -143.8493846311177
agent-5: -130.7088642347127
Extrinsic Rewards:
12
0
3
4
3
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 0
Max Reward: 12
Gini Coefficient: 0.45454545454545453
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-06-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -657.4129547286764
  episode_reward_min: -858.8237387820633
  episodes_this_iter: 1
  episodes_total: 222
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.861
    dispatch_time_ms: 27.189
    learner:
      cur_lr: 0.0012860740534961224
      grad_gnorm: 10.010804176330566
      policy_entropy: 51.8701286315918
      policy_loss: 4.084477424621582
      var_gnorm: 25.974023818969727
      vf_explained_var: 0.0
      vf_loss: 8.378036499023438
    num_steps_sampled: 1115000
    num_steps_trained: 1115000
    wait_time_ms: 51.153
  iterations_since_restore: 223
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1977.3290464878082
  time_this_iter_s: 8.777096271514893
  time_total_s: 1977.3290464878082
  timestamp: 1594857982
  timesteps_since_restore: 1115000
  timesteps_this_iter: 5000
  timesteps_total: 1115000
  training_iteration: 223
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1977 s, 223 iter, 1115000 ts, -657 rew

agent-1: -109.28391189999233
agent-2: -35.1554555216649
agent-3: -273.4480661389818
agent-4: -52.86838679288278
agent-5: -63.94016406743301
Extrinsic Rewards:
6
3
11
3
3
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 3
Max Reward: 11
Gini Coefficient: 0.2923076923076923
20:20 Ratio: 3.6666666666666665
Max-min Ratio: 3.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-06-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -656.4811540786108
  episode_reward_min: -858.8237387820633
  episodes_this_iter: 1
  episodes_total: 223
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.524
    dispatch_time_ms: 28.492
    learner:
      cur_lr: 0.0012857409892603755
      grad_gnorm: 23.88198471069336
      policy_entropy: 51.231632232666016
      policy_loss: 3.894378185272217
      var_gnorm: 25.958824157714844
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 11.2509765625
    num_steps_sampled: 1120000
    num_steps_trained: 1120000
    wait_time_ms: 59.956
  iterations_since_restore: 224
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1986.1570789813995
  time_this_iter_s: 8.828032493591309
  time_total_s: 1986.1570789813995
  timestamp: 1594857991
  timesteps_since_restore: 1120000
  timesteps_this_iter: 5000
  timesteps_total: 1120000
  training_iteration: 224
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1986 s, 224 iter, 1120000 ts, -656 rew

agent-1: -190.91537062247144
agent-2: -17.340311798620334
agent-3: -69.53615244505373
agent-4: -40.2538913408582
agent-5: -244.92515000757717
Extrinsic Rewards:
6
4
5
9
13
Sum Reward: 37
Avg Reward: 7.4
Min Reward: 4
Max Reward: 13
Gini Coefficient: 0.23783783783783785
20:20 Ratio: 3.25
Max-min Ratio: 3.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-06-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -655.5670966383755
  episode_reward_min: -858.8237387820633
  episodes_this_iter: 1
  episodes_total: 224
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.886
    dispatch_time_ms: 30.644
    learner:
      cur_lr: 0.0012854080414399505
      grad_gnorm: 20.99509048461914
      policy_entropy: 40.162601470947266
      policy_loss: 5.060694217681885
      var_gnorm: 25.97701072692871
      vf_explained_var: 0.0
      vf_loss: 5.232151031494141
    num_steps_sampled: 1125000
    num_steps_trained: 1125000
    wait_time_ms: 62.815
  iterations_since_restore: 225
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 1995.0992460250854
  time_this_iter_s: 8.942167043685913
  time_total_s: 1995.0992460250854
  timestamp: 1594858000
  timesteps_since_restore: 1125000
  timesteps_this_iter: 5000
  timesteps_total: 1125000
  training_iteration: 225
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 1995 s, 225 iter, 1125000 ts, -656 rew

agent-1: -69.92159021162549
agent-2: -250.9134658607342
agent-3: -141.83487859608664
agent-4: -65.40685143402303
agent-5: -99.69092807818937
Extrinsic Rewards:
2
12
4
2
8
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 2
Max Reward: 12
Gini Coefficient: 0.37142857142857144
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-06-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -655.4208028063216
  episode_reward_min: -858.8237387820633
  episodes_this_iter: 1
  episodes_total: 225
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.787
    dispatch_time_ms: 23.669
    learner:
      cur_lr: 0.0012850749772042036
      grad_gnorm: 40.000003814697266
      policy_entropy: 39.87529754638672
      policy_loss: 16.303993225097656
      var_gnorm: 26.022098541259766
      vf_explained_var: 0.0
      vf_loss: 12.078240394592285
    num_steps_sampled: 1130000
    num_steps_trained: 1130000
    wait_time_ms: 59.689
  iterations_since_restore: 226
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2003.8612077236176
  time_this_iter_s: 8.761961698532104
  time_total_s: 2003.8612077236176
  timestamp: 1594858009
  timesteps_since_restore: 1130000
  timesteps_this_iter: 5000
  timesteps_total: 1130000
  training_iteration: 226
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2003 s, 226 iter, 1130000 ts, -655 rew

agent-1: -119.95791580582122
agent-2: -202.01140857604875
agent-3: -200.4363077024614
agent-4: -125.68050010536324
agent-5: -151.31769990931332
Extrinsic Rewards:
6
5
4
0
10
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 0
Max Reward: 10
Gini Coefficient: 0.352
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-06-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -656.2443508931793
  episode_reward_min: -858.8237387820633
  episodes_this_iter: 1
  episodes_total: 226
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.752
    dispatch_time_ms: 19.459
    learner:
      cur_lr: 0.0012847420293837786
      grad_gnorm: 8.196338653564453
      policy_entropy: 52.80459213256836
      policy_loss: -1.0922698974609375
      var_gnorm: 25.996858596801758
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.164022207260132
    num_steps_sampled: 1135000
    num_steps_trained: 1135000
    wait_time_ms: 64.407
  iterations_since_restore: 227
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2012.6407248973846
  time_this_iter_s: 8.77951717376709
  time_total_s: 2012.6407248973846
  timestamp: 1594858018
  timesteps_since_restore: 1135000
  timesteps_this_iter: 5000
  timesteps_total: 1135000
  training_iteration: 227
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2012 s, 227 iter, 1135000 ts, -656 rew

agent-1: -80.5598824333192
agent-2: -101.75984602482811
agent-3: -111.43356084701009
agent-4: -199.88917612634108
agent-5: -164.01587552289575
Extrinsic Rewards:
7
16
6
17
8
Sum Reward: 54
Avg Reward: 10.8
Min Reward: 6
Max Reward: 17
Gini Coefficient: 0.22962962962962963
20:20 Ratio: 2.8333333333333335
Max-min Ratio: 2.8333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-07-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -656.4336185369925
  episode_reward_min: -858.8237387820633
  episodes_this_iter: 1
  episodes_total: 227
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.791
    dispatch_time_ms: 31.886
    learner:
      cur_lr: 0.0012844089651480317
      grad_gnorm: 16.53756332397461
      policy_entropy: 57.446773529052734
      policy_loss: -2.8304672241210938
      var_gnorm: 25.998825073242188
      vf_explained_var: 0.0
      vf_loss: 5.916634559631348
    num_steps_sampled: 1140000
    num_steps_trained: 1140000
    wait_time_ms: 60.111
  iterations_since_restore: 228
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2021.454078912735
  time_this_iter_s: 8.813354015350342
  time_total_s: 2021.454078912735
  timestamp: 1594858026
  timesteps_since_restore: 1140000
  timesteps_this_iter: 5000
  timesteps_total: 1140000
  training_iteration: 228
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2021 s, 228 iter, 1140000 ts, -656 rew

agent-1: -43.67892749468022
agent-2: -93.84903620450862
agent-3: -89.25582579664677
agent-4: -222.94033845828608
agent-5: -175.51300940285998
Extrinsic Rewards:
3
12
2
4
9
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 2
Max Reward: 12
Gini Coefficient: 0.3466666666666667
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-07-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -654.4310369785026
  episode_reward_min: -858.8237387820633
  episodes_this_iter: 1
  episodes_total: 228
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.657
    dispatch_time_ms: 27.39
    learner:
      cur_lr: 0.0012840760173276067
      grad_gnorm: 13.757534980773926
      policy_entropy: 51.26530838012695
      policy_loss: 6.334620952606201
      var_gnorm: 25.985002517700195
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 8.60618782043457
    num_steps_sampled: 1145000
    num_steps_trained: 1145000
    wait_time_ms: 58.26
  iterations_since_restore: 229
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2030.3820645809174
  time_this_iter_s: 8.927985668182373
  time_total_s: 2030.3820645809174
  timestamp: 1594858035
  timesteps_since_restore: 1145000
  timesteps_this_iter: 5000
  timesteps_total: 1145000
  training_iteration: 229
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2030 s, 229 iter, 1145000 ts, -654 rew

agent-1: -187.52647656859122
agent-2: -202.748590206362
agent-3: -146.31004410224543
agent-4: -40.98242304189439
agent-5: -61.82933108856849
Extrinsic Rewards:
6
8
5
7
6
Sum Reward: 32
Avg Reward: 6.4
Min Reward: 5
Max Reward: 8
Gini Coefficient: 0.0875
20:20 Ratio: 1.6
Max-min Ratio: 1.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-07-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -653.757326306931
  episode_reward_min: -858.8237387820633
  episodes_this_iter: 1
  episodes_total: 229
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.346
    dispatch_time_ms: 23.087
    learner:
      cur_lr: 0.0012837429530918598
      grad_gnorm: 5.284661293029785
      policy_entropy: 61.10820770263672
      policy_loss: 3.314124822616577
      var_gnorm: 25.98450469970703
      vf_explained_var: 0.0
      vf_loss: 8.773146629333496
    num_steps_sampled: 1150000
    num_steps_trained: 1150000
    wait_time_ms: 71.172
  iterations_since_restore: 230
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2039.482136964798
  time_this_iter_s: 9.100072383880615
  time_total_s: 2039.482136964798
  timestamp: 1594858045
  timesteps_since_restore: 1150000
  timesteps_this_iter: 5000
  timesteps_total: 1150000
  training_iteration: 230
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2039 s, 230 iter, 1150000 ts, -654 rew

agent-1: -265.8374836631589
agent-2: -32.199316197100934
agent-3: -116.4811030704669
agent-4: -13.63995953567562
agent-5: -144.98298984669077
Extrinsic Rewards:
15
2
6
1
4
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 1
Max Reward: 15
Gini Coefficient: 0.45714285714285713
20:20 Ratio: 15.0
Max-min Ratio: 15.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-07-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -652.4130639393093
  episode_reward_min: -858.8237387820633
  episodes_this_iter: 1
  episodes_total: 230
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.82
    dispatch_time_ms: 26.927
    learner:
      cur_lr: 0.0012834100052714348
      grad_gnorm: 15.956439971923828
      policy_entropy: 65.54246520996094
      policy_loss: 0.4093896150588989
      var_gnorm: 25.986949920654297
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 9.302491188049316
    num_steps_sampled: 1155000
    num_steps_trained: 1155000
    wait_time_ms: 54.025
  iterations_since_restore: 231
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2048.141569375992
  time_this_iter_s: 8.659432411193848
  time_total_s: 2048.141569375992
  timestamp: 1594858053
  timesteps_since_restore: 1155000
  timesteps_this_iter: 5000
  timesteps_total: 1155000
  training_iteration: 231
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2048 s, 231 iter, 1155000 ts, -652 rew

agent-1: -169.78245612506979
agent-2: -231.82902698682497
agent-3: -119.67554361967701
agent-4: -13.943388468321197
agent-5: -113.73281328085231
Extrinsic Rewards:
6
4
3
1
9
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.33043478260869563
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-07-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -650.7090985844923
  episode_reward_min: -858.8237387820633
  episodes_this_iter: 1
  episodes_total: 231
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.589
    dispatch_time_ms: 29.584
    learner:
      cur_lr: 0.0012830770574510098
      grad_gnorm: 40.0
      policy_entropy: 52.60866165161133
      policy_loss: -111.31340789794922
      var_gnorm: 26.037633895874023
      vf_explained_var: 0.0
      vf_loss: 129.75636291503906
    num_steps_sampled: 1160000
    num_steps_trained: 1160000
    wait_time_ms: 50.085
  iterations_since_restore: 232
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2056.989327430725
  time_this_iter_s: 8.847758054733276
  time_total_s: 2056.989327430725
  timestamp: 1594858062
  timesteps_since_restore: 1160000
  timesteps_this_iter: 5000
  timesteps_total: 1160000
  training_iteration: 232
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2056 s, 232 iter, 1160000 ts, -651 rew

agent-1: -29.25383695146085
agent-2: -179.30013664124837
agent-3: -325.2401198440483
agent-4: -285.32744284407744
agent-5: -361.9914440072444
Extrinsic Rewards:
2
-50
7
4
14
Sum Reward: -23
Avg Reward: -4.6
Min Reward: -50
Max Reward: 14
Gini Coefficient: -2.3130434782608695
20:20 Ratio: -0.28
Max-min Ratio: -0.28
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-07-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -656.4201439587133
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 232
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.643
    dispatch_time_ms: 36.443
    learner:
      cur_lr: 0.0012827439932152629
      grad_gnorm: 10.713592529296875
      policy_entropy: 53.99763488769531
      policy_loss: -0.21646468341350555
      var_gnorm: 25.993898391723633
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 5.699155807495117
    num_steps_sampled: 1165000
    num_steps_trained: 1165000
    wait_time_ms: 55.268
  iterations_since_restore: 233
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2065.7836554050446
  time_this_iter_s: 8.794327974319458
  time_total_s: 2065.7836554050446
  timestamp: 1594858071
  timesteps_since_restore: 1165000
  timesteps_this_iter: 5000
  timesteps_total: 1165000
  training_iteration: 233
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2065 s, 233 iter, 1165000 ts, -656 rew

agent-1: -270.682350488195
agent-2: -115.13945403590671
agent-3: -99.59581132765429
agent-4: -69.6462961508208
agent-5: -136.15321854299026
Extrinsic Rewards:
16
5
3
1
0
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 0
Max Reward: 16
Gini Coefficient: 0.576
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-08-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -656.3521143171794
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 233
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.543
    dispatch_time_ms: 30.081
    learner:
      cur_lr: 0.0012824110453948379
      grad_gnorm: 17.45077133178711
      policy_entropy: 61.831722259521484
      policy_loss: 11.175731658935547
      var_gnorm: 26.034481048583984
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 5.6768574714660645
    num_steps_sampled: 1170000
    num_steps_trained: 1170000
    wait_time_ms: 57.34
  iterations_since_restore: 234
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2074.5661101341248
  time_this_iter_s: 8.7824547290802
  time_total_s: 2074.5661101341248
  timestamp: 1594858080
  timesteps_since_restore: 1170000
  timesteps_this_iter: 5000
  timesteps_total: 1170000
  training_iteration: 234
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2074 s, 234 iter, 1170000 ts, -656 rew

agent-1: -94.91332661894906
agent-2: -37.6480590443675
agent-3: -235.02975493264623
agent-4: -145.4838904202486
agent-5: -109.98008941765501
Extrinsic Rewards:
3
7
18
8
5
Sum Reward: 41
Avg Reward: 8.2
Min Reward: 3
Max Reward: 18
Gini Coefficient: 0.32195121951219513
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-08-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -656.9888460216869
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 234
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.509
    dispatch_time_ms: 8.097
    learner:
      cur_lr: 0.001282077981159091
      grad_gnorm: 28.174259185791016
      policy_entropy: 57.292598724365234
      policy_loss: -3.663957357406616
      var_gnorm: 26.00082015991211
      vf_explained_var: 0.0
      vf_loss: 7.161876201629639
    num_steps_sampled: 1175000
    num_steps_trained: 1175000
    wait_time_ms: 77.221
  iterations_since_restore: 235
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2090.2462317943573
  time_this_iter_s: 15.680121660232544
  time_total_s: 2090.2462317943573
  timestamp: 1594858096
  timesteps_since_restore: 1175000
  timesteps_this_iter: 5000
  timesteps_total: 1175000
  training_iteration: 235
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2090 s, 235 iter, 1175000 ts, -657 rew

agent-1: -17.43909011097274
agent-2: -137.4691191957279
agent-3: -136.23416869273976
agent-4: -197.3295610488914
agent-5: -252.099331581768
Extrinsic Rewards:
1
0
5
8
5
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.42105263157894735
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-08-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -658.6193866592794
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 235
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.979
    dispatch_time_ms: 6.247
    learner:
      cur_lr: 0.001281745033338666
      grad_gnorm: 39.999996185302734
      policy_entropy: 48.977779388427734
      policy_loss: 27.233030319213867
      var_gnorm: 26.075349807739258
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 24.150896072387695
    num_steps_sampled: 1180000
    num_steps_trained: 1180000
    wait_time_ms: 72.359
  iterations_since_restore: 236
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2098.538332462311
  time_this_iter_s: 8.292100667953491
  time_total_s: 2098.538332462311
  timestamp: 1594858104
  timesteps_since_restore: 1180000
  timesteps_this_iter: 5000
  timesteps_total: 1180000
  training_iteration: 236
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2098 s, 236 iter, 1180000 ts, -659 rew

agent-1: -76.89954276232807
agent-2: -240.28160777525392
agent-3: -126.37037788738188
agent-4: -225.28579270491466
agent-5: -38.53679774257307
Extrinsic Rewards:
6
8
0
7
4
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.304
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-08-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -659.9490655652986
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 236
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.537
    dispatch_time_ms: 8.069
    learner:
      cur_lr: 0.001281411969102919
      grad_gnorm: 10.047245979309082
      policy_entropy: 51.87539291381836
      policy_loss: 3.1502811908721924
      var_gnorm: 26.003379821777344
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 8.394426345825195
    num_steps_sampled: 1185000
    num_steps_trained: 1185000
    wait_time_ms: 73.016
  iterations_since_restore: 237
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2106.828270673752
  time_this_iter_s: 8.28993821144104
  time_total_s: 2106.828270673752
  timestamp: 1594858112
  timesteps_since_restore: 1185000
  timesteps_this_iter: 5000
  timesteps_total: 1185000
  training_iteration: 237
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2106 s, 237 iter, 1185000 ts, -660 rew

agent-1: -238.2278284341961
agent-2: -95.70705071195272
agent-3: -146.8710221262837
agent-4: -8.860137767688721
agent-5: -82.40487559322051
Extrinsic Rewards:
8
7
10
1
7
Sum Reward: 33
Avg Reward: 6.6
Min Reward: 1
Max Reward: 10
Gini Coefficient: 0.23030303030303031
20:20 Ratio: 10.0
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-08-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -658.4010089421572
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 237
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.5
    dispatch_time_ms: 6.868
    learner:
      cur_lr: 0.001281079021282494
      grad_gnorm: 7.325324535369873
      policy_entropy: 53.82503890991211
      policy_loss: -1.3605594635009766
      var_gnorm: 25.995336532592773
      vf_explained_var: 0.0
      vf_loss: 4.515774250030518
    num_steps_sampled: 1190000
    num_steps_trained: 1190000
    wait_time_ms: 75.136
  iterations_since_restore: 238
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2115.176259279251
  time_this_iter_s: 8.347988605499268
  time_total_s: 2115.176259279251
  timestamp: 1594858121
  timesteps_since_restore: 1190000
  timesteps_this_iter: 5000
  timesteps_total: 1190000
  training_iteration: 238
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2115 s, 238 iter, 1190000 ts, -658 rew

agent-1: -73.28434274164147
agent-2: -89.66960185577253
agent-3: -141.41517164203532
agent-4: -222.1700541818308
agent-5: -101.39457823624436
Extrinsic Rewards:
5
3
12
12
7
Sum Reward: 39
Avg Reward: 7.8
Min Reward: 3
Max Reward: 12
Gini Coefficient: 0.2564102564102564
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-08-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -658.1454960656998
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 238
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.493
    dispatch_time_ms: 7.679
    learner:
      cur_lr: 0.0012807459570467472
      grad_gnorm: 21.709152221679688
      policy_entropy: 51.862361907958984
      policy_loss: -7.289393901824951
      var_gnorm: 25.99686622619629
      vf_explained_var: 0.0
      vf_loss: 6.464305877685547
    num_steps_sampled: 1195000
    num_steps_trained: 1195000
    wait_time_ms: 73.173
  iterations_since_restore: 239
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2123.5138790607452
  time_this_iter_s: 8.33761978149414
  time_total_s: 2123.5138790607452
  timestamp: 1594858129
  timesteps_since_restore: 1195000
  timesteps_this_iter: 5000
  timesteps_total: 1195000
  training_iteration: 239
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2123 s, 239 iter, 1195000 ts, -658 rew

agent-1: -204.63273125585053
agent-2: -137.42980692191594
agent-3: -212.70831576167433
agent-4: -137.42980692191594
agent-5: -220.14440084410336
Extrinsic Rewards:
6
0
9
0
6
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.45714285714285713
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-08-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -661.7937554778093
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 239
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.79
    dispatch_time_ms: 6.947
    learner:
      cur_lr: 0.0012804130092263222
      grad_gnorm: 40.0
      policy_entropy: 53.77518844604492
      policy_loss: 24.397655487060547
      var_gnorm: 26.119396209716797
      vf_explained_var: -1.0
      vf_loss: 35.517112731933594
    num_steps_sampled: 1200000
    num_steps_trained: 1200000
    wait_time_ms: 75.547
  iterations_since_restore: 240
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2131.8471777439117
  time_this_iter_s: 8.333298683166504
  time_total_s: 2131.8471777439117
  timestamp: 1594858138
  timesteps_since_restore: 1200000
  timesteps_this_iter: 5000
  timesteps_total: 1200000
  training_iteration: 240
  
agent-1: -100.47452542929756
agent-2: -142.8819287382027
agent-3: -54.649056530996695
agent-4: -250.22982493107517
agent-5: -204.7622664052491
Extrinsic Rewards:
3
0
2
11
1
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 0
Max Reward: 11
Gini Coefficient: 0.5647058823529412
20:20 Ratio: Undefined
Max-min Ratio: Undefined
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2131 s, 240 iter, 1200000 ts, -662 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-09-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -663.0438935314546
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 240
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.99
    dispatch_time_ms: 5.769
    learner:
      cur_lr: 0.0012800799449905753
      grad_gnorm: 15.861926078796387
      policy_entropy: 45.27421569824219
      policy_loss: -4.521340370178223
      var_gnorm: 26.03070068359375
      vf_explained_var: 0.0
      vf_loss: 2.0942132472991943
    num_steps_sampled: 1205000
    num_steps_trained: 1205000
    wait_time_ms: 76.684
  iterations_since_restore: 241
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2140.1182322502136
  time_this_iter_s: 8.27105450630188
  time_total_s: 2140.1182322502136
  timestamp: 1594858146
  timesteps_since_restore: 1205000
  timesteps_this_iter: 5000
  timesteps_total: 1205000
  training_iteration: 241
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2140 s, 241 iter, 1205000 ts, -663 rew

agent-1: -153.8341439395587
agent-2: -153.5806893921328
agent-3: -147.20799410027703
agent-4: -218.317132069698
agent-5: -179.79643273284645
Extrinsic Rewards:
4
3
0
5
6
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 0
Max Reward: 6
Gini Coefficient: 0.3111111111111111
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-09-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -663.3397712036457
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 241
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.447
    dispatch_time_ms: 6.015
    learner:
      cur_lr: 0.0012797469971701503
      grad_gnorm: 40.0
      policy_entropy: 50.64675521850586
      policy_loss: 37.09315490722656
      var_gnorm: 26.06242561340332
      vf_explained_var: -0.3195441961288452
      vf_loss: 66.37338256835938
    num_steps_sampled: 1210000
    num_steps_trained: 1210000
    wait_time_ms: 75.351
  iterations_since_restore: 242
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2148.4604139328003
  time_this_iter_s: 8.34218168258667
  time_total_s: 2148.4604139328003
  timestamp: 1594858154
  timesteps_since_restore: 1210000
  timesteps_this_iter: 5000
  timesteps_total: 1210000
  training_iteration: 242
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2148 s, 242 iter, 1210000 ts, -663 rew

agent-1: -63.98308711123399
agent-2: -204.55065511634155
agent-3: -158.29426454965753
agent-4: -45.22246360544778
agent-5: -115.57106005613106
Extrinsic Rewards:
6
17
4
10
21
Sum Reward: 58
Avg Reward: 11.6
Min Reward: 4
Max Reward: 21
Gini Coefficient: 0.3103448275862069
20:20 Ratio: 5.25
Max-min Ratio: 5.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-09-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -662.1665395891443
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 242
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.462
    dispatch_time_ms: 5.955
    learner:
      cur_lr: 0.0012794140493497252
      grad_gnorm: 9.637245178222656
      policy_entropy: 51.16574478149414
      policy_loss: -5.004055976867676
      var_gnorm: 26.029985427856445
      vf_explained_var: 0.0
      vf_loss: 5.454342842102051
    num_steps_sampled: 1215000
    num_steps_trained: 1215000
    wait_time_ms: 77.271
  iterations_since_restore: 243
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2156.8304352760315
  time_this_iter_s: 8.370021343231201
  time_total_s: 2156.8304352760315
  timestamp: 1594858163
  timesteps_since_restore: 1215000
  timesteps_this_iter: 5000
  timesteps_total: 1215000
  training_iteration: 243
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2156 s, 243 iter, 1215000 ts, -662 rew

agent-1: -66.88843070130261
agent-2: -142.60693851440672
agent-3: -138.53786387324217
agent-4: -186.61110815055451
agent-5: -244.59326475172546
Extrinsic Rewards:
2
5
0
6
13
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 0
Max Reward: 13
Gini Coefficient: 0.46153846153846156
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-09-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -662.2632412460907
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 243
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.51
    dispatch_time_ms: 8.902
    learner:
      cur_lr: 0.0012790809851139784
      grad_gnorm: 12.014607429504395
      policy_entropy: 43.90800476074219
      policy_loss: 3.0123696327209473
      var_gnorm: 26.071958541870117
      vf_explained_var: 0.0
      vf_loss: 2.491184949874878
    num_steps_sampled: 1220000
    num_steps_trained: 1220000
    wait_time_ms: 72.529
  iterations_since_restore: 244
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2165.173969268799
  time_this_iter_s: 8.343533992767334
  time_total_s: 2165.173969268799
  timestamp: 1594858171
  timesteps_since_restore: 1220000
  timesteps_this_iter: 5000
  timesteps_total: 1220000
  training_iteration: 244
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2165 s, 244 iter, 1220000 ts, -662 rew

agent-1: -165.37877756879055
agent-2: -188.36084664692217
agent-3: -185.48439793048786
agent-4: -119.98596624183828
agent-5: -65.43630621067824
Extrinsic Rewards:
6
4
6
4
2
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 2
Max Reward: 6
Gini Coefficient: 0.18181818181818182
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-09-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -662.6686362595269
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 244
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.64
    dispatch_time_ms: 6.919
    learner:
      cur_lr: 0.0012787480372935534
      grad_gnorm: 16.3515682220459
      policy_entropy: 43.7040901184082
      policy_loss: 5.545470714569092
      var_gnorm: 26.0168514251709
      vf_explained_var: 0.0
      vf_loss: 9.074337005615234
    num_steps_sampled: 1225000
    num_steps_trained: 1225000
    wait_time_ms: 76.289
  iterations_since_restore: 245
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2173.53928899765
  time_this_iter_s: 8.365319728851318
  time_total_s: 2173.53928899765
  timestamp: 1594858179
  timesteps_since_restore: 1225000
  timesteps_this_iter: 5000
  timesteps_total: 1225000
  training_iteration: 245
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2173 s, 245 iter, 1225000 ts, -663 rew

agent-1: -128.55416306936846
agent-2: -55.18897892443139
agent-3: -114.418005517454
agent-4: -198.11106378819895
agent-5: -194.43040754100676
Extrinsic Rewards:
8
3
9
7
7
Sum Reward: 34
Avg Reward: 6.8
Min Reward: 3
Max Reward: 9
Gini Coefficient: 0.15294117647058825
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-09-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -663.2952750663324
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 245
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.601
    dispatch_time_ms: 8.955
    learner:
      cur_lr: 0.0012784149730578065
      grad_gnorm: 40.000003814697266
      policy_entropy: 52.11768341064453
      policy_loss: -19.05484390258789
      var_gnorm: 26.07550811767578
      vf_explained_var: 0.0
      vf_loss: 10.602285385131836
    num_steps_sampled: 1230000
    num_steps_trained: 1230000
    wait_time_ms: 71.654
  iterations_since_restore: 246
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2181.860360622406
  time_this_iter_s: 8.32107162475586
  time_total_s: 2181.860360622406
  timestamp: 1594858188
  timesteps_since_restore: 1230000
  timesteps_this_iter: 5000
  timesteps_total: 1230000
  training_iteration: 246
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2181 s, 246 iter, 1230000 ts, -663 rew

agent-1: -144.2273168118207
agent-2: -133.837095537967
agent-3: -133.837095537967
agent-4: -265.05733786954903
agent-5: -158.3993847182775
Extrinsic Rewards:
7
0
0
8
6
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.4380952380952381
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-09-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -664.713731839439
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 246
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.112
    dispatch_time_ms: 7.408
    learner:
      cur_lr: 0.0012780820252373815
      grad_gnorm: 19.78717803955078
      policy_entropy: 56.143768310546875
      policy_loss: 3.1844472885131836
      var_gnorm: 26.021493911743164
      vf_explained_var: 0.0
      vf_loss: 5.373405933380127
    num_steps_sampled: 1235000
    num_steps_trained: 1235000
    wait_time_ms: 73.568
  iterations_since_restore: 247
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2190.300528049469
  time_this_iter_s: 8.440167427062988
  time_total_s: 2190.300528049469
  timestamp: 1594858196
  timesteps_since_restore: 1235000
  timesteps_this_iter: 5000
  timesteps_total: 1235000
  training_iteration: 247
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2190 s, 247 iter, 1235000 ts, -665 rew

agent-1: -233.1806852648735
agent-2: -18.35739193260876
agent-3: -118.64301108771572
agent-4: -212.0114433482422
agent-5: -133.4254646622054
Extrinsic Rewards:
9
2
0
3
9
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.43478260869565216
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: -238.49634533549957
agent-2: -133.55240520535543
agent-3: -79.16464590694056
agent-4: -172.17546648117226
agent-5: -165.51580177545222
Extrinsic Rewards:
9
0
2
6
8
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.384
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-10-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -667.0801399738556
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 2
  episodes_total: 248
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.773
    dispatch_time_ms: 7.959
    learner:
      cur_lr: 0.0012777489610016346
      grad_gnorm: 39.999996185302734
      policy_entropy: 47.56288146972656
      policy_loss: 734.3295288085938
      var_gnorm: 26.09264373779297
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 6806.2568359375
    num_steps_sampled: 1240000
    num_steps_trained: 1240000
    wait_time_ms: 74.478
  iterations_since_restore: 248
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2198.588660478592
  time_this_iter_s: 8.288132429122925
  time_total_s: 2198.588660478592
  timestamp: 1594858205
  timesteps_since_restore: 1240000
  timesteps_this_iter: 5000
  timesteps_total: 1240000
  training_iteration: 248
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2198 s, 248 iter, 1240000 ts, -667 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-10-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -667.0801399738556
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 0
  episodes_total: 248
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.909
    dispatch_time_ms: 9.357
    learner:
      cur_lr: 0.0012774160131812096
      grad_gnorm: 11.166476249694824
      policy_entropy: 40.281578063964844
      policy_loss: -2.696065664291382
      var_gnorm: 26.03236198425293
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.198702335357666
    num_steps_sampled: 1245000
    num_steps_trained: 1245000
    wait_time_ms: 71.207
  iterations_since_restore: 249
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2207.045376777649
  time_this_iter_s: 8.456716299057007
  time_total_s: 2207.045376777649
  timestamp: 1594858213
  timesteps_since_restore: 1245000
  timesteps_this_iter: 5000
  timesteps_total: 1245000
  training_iteration: 249
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2207 s, 249 iter, 1245000 ts, -667 rew

agent-1: -77.21118203299594
agent-2: -143.14307204547254
agent-3: -100.70020501723535
agent-4: -168.7363155594448
agent-5: -264.3253751664781
Extrinsic Rewards:
1
0
2
6
9
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.5111111111111111
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: -105.1273729243195
agent-2: -194.28488571265794
agent-3: -144.35289310438796
agent-4: -219.13170580264756
agent-5: -168.0127655387242
Extrinsic Rewards:
3
2
0
9
3
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.4470588235294118
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-10-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -670.0855422477384
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 2
  episodes_total: 250
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.737
    dispatch_time_ms: 8.761
    learner:
      cur_lr: 0.0012770829489454627
      grad_gnorm: 40.000003814697266
      policy_entropy: 55.50823974609375
      policy_loss: 981.86474609375
      var_gnorm: 26.114294052124023
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 7373.00244140625
    num_steps_sampled: 1250000
    num_steps_trained: 1250000
    wait_time_ms: 72.239
  iterations_since_restore: 250
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2215.395396709442
  time_this_iter_s: 8.350019931793213
  time_total_s: 2215.395396709442
  timestamp: 1594858221
  timesteps_since_restore: 1250000
  timesteps_this_iter: 5000
  timesteps_total: 1250000
  training_iteration: 250
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2215 s, 250 iter, 1250000 ts, -670 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-10-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -670.0855422477387
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 0
  episodes_total: 250
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.098
    dispatch_time_ms: 8.088
    learner:
      cur_lr: 0.0012767500011250377
      grad_gnorm: 14.780984878540039
      policy_entropy: 46.136207580566406
      policy_loss: -6.411247253417969
      var_gnorm: 26.029407501220703
      vf_explained_var: 0.0
      vf_loss: 4.419601917266846
    num_steps_sampled: 1255000
    num_steps_trained: 1255000
    wait_time_ms: 73.366
  iterations_since_restore: 251
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2223.857956647873
  time_this_iter_s: 8.462559938430786
  time_total_s: 2223.857956647873
  timestamp: 1594858230
  timesteps_since_restore: 1255000
  timesteps_this_iter: 5000
  timesteps_total: 1255000
  training_iteration: 251
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2223 s, 251 iter, 1255000 ts, -670 rew

agent-1: -229.74660256215515
agent-2: -85.91094313553174
agent-3: -145.617676718534
agent-4: -148.41201643664564
agent-5: -207.94902022501728
Extrinsic Rewards:
5
3
0
4
6
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 0
Max Reward: 6
Gini Coefficient: 0.3111111111111111
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: -36.889510029597965
agent-2: -257.0868072674393
agent-3: -49.64215353207385
agent-4: -121.00474786059094
agent-5: -107.81938280028604
Extrinsic Rewards:
2
9
3
4
9
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 2
Max Reward: 9
Gini Coefficient: 0.2962962962962963
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-10-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -669.2181046232129
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 2
  episodes_total: 252
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.468
    dispatch_time_ms: 9.529
    learner:
      cur_lr: 0.0012764170533046126
      grad_gnorm: 39.999996185302734
      policy_entropy: 35.567901611328125
      policy_loss: 342.35797119140625
      var_gnorm: 26.047348022460938
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5352.7998046875
    num_steps_sampled: 1260000
    num_steps_trained: 1260000
    wait_time_ms: 71.111
  iterations_since_restore: 252
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2232.1771047115326
  time_this_iter_s: 8.319148063659668
  time_total_s: 2232.1771047115326
  timestamp: 1594858238
  timesteps_since_restore: 1260000
  timesteps_this_iter: 5000
  timesteps_total: 1260000
  training_iteration: 252
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2232 s, 252 iter, 1260000 ts, -669 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-10-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -669.2181046232129
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 0
  episodes_total: 252
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.424
    dispatch_time_ms: 7.172
    learner:
      cur_lr: 0.0012760839890688658
      grad_gnorm: 4.534790992736816
      policy_entropy: 43.082275390625
      policy_loss: -1.754772424697876
      var_gnorm: 26.031391143798828
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 3.6707022190093994
    num_steps_sampled: 1265000
    num_steps_trained: 1265000
    wait_time_ms: 73.251
  iterations_since_restore: 253
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2240.4893069267273
  time_this_iter_s: 8.312202215194702
  time_total_s: 2240.4893069267273
  timestamp: 1594858247
  timesteps_since_restore: 1265000
  timesteps_this_iter: 5000
  timesteps_total: 1265000
  training_iteration: 253
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2240 s, 253 iter, 1265000 ts, -669 rew

agent-1: -184.6264985084487
agent-2: -91.79343303839444
agent-3: -158.11721174435039
agent-4: -63.77755076158169
agent-5: -188.39479858975133
Extrinsic Rewards:
8
5
7
8
7
Sum Reward: 35
Avg Reward: 7.0
Min Reward: 5
Max Reward: 8
Gini Coefficient: 0.08
20:20 Ratio: 1.6
Max-min Ratio: 1.6
agent-1: -174.65038497338134
agent-2: -148.63803093931375
agent-3: -191.75186691661128
agent-4: -160.28635418102684
agent-5: -39.22276396553468
Extrinsic Rewards:
2
5
12
3
2
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 2
Max Reward: 12
Gini Coefficient: 0.38333333333333336
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-10-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -671.4819443124449
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 2
  episodes_total: 254
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.494
    dispatch_time_ms: 7.796
    learner:
      cur_lr: 0.0012757510412484407
      grad_gnorm: 40.0
      policy_entropy: 56.17962646484375
      policy_loss: 812.0958251953125
      var_gnorm: 26.039403915405273
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 4887.181640625
    num_steps_sampled: 1270000
    num_steps_trained: 1270000
    wait_time_ms: 72.554
  iterations_since_restore: 254
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2248.8565735816956
  time_this_iter_s: 8.367266654968262
  time_total_s: 2248.8565735816956
  timestamp: 1594858255
  timesteps_since_restore: 1270000
  timesteps_this_iter: 5000
  timesteps_total: 1270000
  training_iteration: 254
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2248 s, 254 iter, 1270000 ts, -671 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-11-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -671.4819443124449
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 0
  episodes_total: 254
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.216
    dispatch_time_ms: 25.627
    learner:
      cur_lr: 0.0012754179770126939
      grad_gnorm: 8.67393970489502
      policy_entropy: 49.04679870605469
      policy_loss: -4.6394476890563965
      var_gnorm: 26.02431297302246
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.157672882080078
    num_steps_sampled: 1275000
    num_steps_trained: 1275000
    wait_time_ms: 62.372
  iterations_since_restore: 255
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2257.410003900528
  time_this_iter_s: 8.553430318832397
  time_total_s: 2257.410003900528
  timestamp: 1594858264
  timesteps_since_restore: 1275000
  timesteps_this_iter: 5000
  timesteps_total: 1275000
  training_iteration: 255
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2257 s, 255 iter, 1275000 ts, -671 rew

agent-1: -175.50961662987294
agent-2: -176.89598096027458
agent-3: -158.4348865812523
agent-4: -91.0332043576945
agent-5: -125.5291770668827
Extrinsic Rewards:
8
4
5
2
3
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 2
Max Reward: 8
Gini Coefficient: 0.2545454545454545
20:20 Ratio: 4.0
Max-min Ratio: 4.0
agent-1: -224.56133996371605
agent-2: -107.92131135231774
agent-3: -95.29367756551433
agent-4: -231.00336693694283
agent-5: -144.5261950479399
Extrinsic Rewards:
7
2
3
6
0
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.4
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-11-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -672.9778885448272
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 2
  episodes_total: 256
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.288
    dispatch_time_ms: 28.311
    learner:
      cur_lr: 0.0012750850291922688
      grad_gnorm: 39.999996185302734
      policy_entropy: 32.7567253112793
      policy_loss: 488.46087646484375
      var_gnorm: 26.069820404052734
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 5975.85888671875
    num_steps_sampled: 1280000
    num_steps_trained: 1280000
    wait_time_ms: 55.026
  iterations_since_restore: 256
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2266.2398402690887
  time_this_iter_s: 8.829836368560791
  time_total_s: 2266.2398402690887
  timestamp: 1594858273
  timesteps_since_restore: 1280000
  timesteps_this_iter: 5000
  timesteps_total: 1280000
  training_iteration: 256
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2266 s, 256 iter, 1280000 ts, -673 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-11-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -672.9778885448272
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 0
  episodes_total: 256
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.175
    dispatch_time_ms: 22.358
    learner:
      cur_lr: 0.001274751964956522
      grad_gnorm: 9.431448936462402
      policy_entropy: 47.96657180786133
      policy_loss: -0.4824921488761902
      var_gnorm: 26.022693634033203
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 8.773765563964844
    num_steps_sampled: 1285000
    num_steps_trained: 1285000
    wait_time_ms: 61.321
  iterations_since_restore: 257
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2275.0440397262573
  time_this_iter_s: 8.804199457168579
  time_total_s: 2275.0440397262573
  timestamp: 1594858281
  timesteps_since_restore: 1285000
  timesteps_this_iter: 5000
  timesteps_total: 1285000
  training_iteration: 257
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2275 s, 257 iter, 1285000 ts, -673 rew

agent-1: -65.5436289092137
agent-2: -63.546715370267925
agent-3: -209.49858025422603
agent-4: -78.52048283221808
agent-5: -178.84912258436114
Extrinsic Rewards:
9
11
16
2
14
Sum Reward: 52
Avg Reward: 10.4
Min Reward: 2
Max Reward: 16
Gini Coefficient: 0.25384615384615383
20:20 Ratio: 8.0
Max-min Ratio: 8.0
agent-1: -101.41193202545675
agent-2: -178.984300613556
agent-3: -59.75377672477803
agent-4: -160.67144985716965
agent-5: -194.36527019662967
Extrinsic Rewards:
9
3
5
5
6
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 3
Max Reward: 9
Gini Coefficient: 0.18571428571428572
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-11-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -673.3857417254812
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 2
  episodes_total: 258
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.87
    dispatch_time_ms: 33.848
    learner:
      cur_lr: 0.001274419017136097
      grad_gnorm: 40.0
      policy_entropy: 52.521724700927734
      policy_loss: 21.770341873168945
      var_gnorm: 26.020565032958984
      vf_explained_var: -0.8962740898132324
      vf_loss: 31.74630355834961
    num_steps_sampled: 1290000
    num_steps_trained: 1290000
    wait_time_ms: 49.423
  iterations_since_restore: 258
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2284.0933310985565
  time_this_iter_s: 9.049291372299194
  time_total_s: 2284.0933310985565
  timestamp: 1594858290
  timesteps_since_restore: 1290000
  timesteps_this_iter: 5000
  timesteps_total: 1290000
  training_iteration: 258
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2284 s, 258 iter, 1290000 ts, -673 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-11-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -673.3857417254812
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 0
  episodes_total: 258
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.618
    dispatch_time_ms: 56.863
    learner:
      cur_lr: 0.00127408595290035
      grad_gnorm: 13.381319046020508
      policy_entropy: 56.337310791015625
      policy_loss: 1.027021884918213
      var_gnorm: 25.999635696411133
      vf_explained_var: 0.0
      vf_loss: 8.019112586975098
    num_steps_sampled: 1295000
    num_steps_trained: 1295000
    wait_time_ms: 41.258
  iterations_since_restore: 259
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2293.103908061981
  time_this_iter_s: 9.010576963424683
  time_total_s: 2293.103908061981
  timestamp: 1594858300
  timesteps_since_restore: 1295000
  timesteps_this_iter: 5000
  timesteps_total: 1295000
  training_iteration: 259
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2293 s, 259 iter, 1295000 ts, -673 rew

agent-1: -134.17874097625116
agent-2: -39.50058640975029
agent-3: -191.23955106996198
agent-4: -129.36756404441158
agent-5: -250.71921070481133
Extrinsic Rewards:
6
2
7
0
9
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.38333333333333336
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-11-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -673.871702829813
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 259
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.456
    dispatch_time_ms: 21.784
    learner:
      cur_lr: 0.001273753005079925
      grad_gnorm: 23.492612838745117
      policy_entropy: 55.949459075927734
      policy_loss: 1.379831314086914
      var_gnorm: 26.030420303344727
      vf_explained_var: 0.0
      vf_loss: 8.321124076843262
    num_steps_sampled: 1300000
    num_steps_trained: 1300000
    wait_time_ms: 62.02
  iterations_since_restore: 260
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2301.6858716011047
  time_this_iter_s: 8.581963539123535
  time_total_s: 2301.6858716011047
  timestamp: 1594858308
  timesteps_since_restore: 1300000
  timesteps_this_iter: 5000
  timesteps_total: 1300000
  training_iteration: 260
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2301 s, 260 iter, 1300000 ts, -674 rew

agent-1: -54.80288247275731
agent-2: -85.36206995576393
agent-3: -115.51216871609357
agent-4: -275.03909913615894
agent-5: -23.742630047800976
Extrinsic Rewards:
1
2
2
13
1
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 1
Max Reward: 13
Gini Coefficient: 0.5263157894736842
20:20 Ratio: 13.0
Max-min Ratio: 13.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-11-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -671.0948476811875
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 260
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.699
    dispatch_time_ms: 19.087
    learner:
      cur_lr: 0.0012734200572595
      grad_gnorm: 8.252252578735352
      policy_entropy: 43.93032455444336
      policy_loss: -2.950566530227661
      var_gnorm: 26.02273941040039
      vf_explained_var: 0.0
      vf_loss: 5.242035865783691
    num_steps_sampled: 1305000
    num_steps_trained: 1305000
    wait_time_ms: 78.324
  iterations_since_restore: 261
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2310.5519473552704
  time_this_iter_s: 8.86607575416565
  time_total_s: 2310.5519473552704
  timestamp: 1594858317
  timesteps_since_restore: 1305000
  timesteps_this_iter: 5000
  timesteps_total: 1305000
  training_iteration: 261
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2310 s, 261 iter, 1305000 ts, -671 rew

agent-1: -229.1907081086186
agent-2: -152.55768177082874
agent-3: -115.51112978867769
agent-4: -132.22831898471134
agent-5: -159.66385208180358
Extrinsic Rewards:
13
8
0
6
7
Sum Reward: 34
Avg Reward: 6.8
Min Reward: 0
Max Reward: 13
Gini Coefficient: 0.32941176470588235
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-12-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -671.4389308925206
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 261
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.213
    dispatch_time_ms: 31.845
    learner:
      cur_lr: 0.0012730869930237532
      grad_gnorm: 32.1141242980957
      policy_entropy: 50.096107482910156
      policy_loss: -8.410636901855469
      var_gnorm: 26.100833892822266
      vf_explained_var: 0.0
      vf_loss: 3.3894104957580566
    num_steps_sampled: 1310000
    num_steps_trained: 1310000
    wait_time_ms: 52.265
  iterations_since_restore: 262
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2319.179644346237
  time_this_iter_s: 8.627696990966797
  time_total_s: 2319.179644346237
  timestamp: 1594858326
  timesteps_since_restore: 1310000
  timesteps_this_iter: 5000
  timesteps_total: 1310000
  training_iteration: 262
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2319 s, 262 iter, 1310000 ts, -671 rew

agent-1: -122.34967086995651
agent-2: -173.72841414506541
agent-3: -187.56589475886489
agent-4: -162.02620268729555
agent-5: -179.34272473573054
Extrinsic Rewards:
0
4
9
8
5
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.3384615384615385
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-12-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -672.6939787343936
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 262
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.882
    dispatch_time_ms: 36.171
    learner:
      cur_lr: 0.0012727540452033281
      grad_gnorm: 12.334439277648926
      policy_entropy: 48.45771408081055
      policy_loss: 0.9619436264038086
      var_gnorm: 26.048158645629883
      vf_explained_var: 0.0
      vf_loss: 4.510639190673828
    num_steps_sampled: 1315000
    num_steps_trained: 1315000
    wait_time_ms: 110.444
  iterations_since_restore: 263
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2328.622451066971
  time_this_iter_s: 9.442806720733643
  time_total_s: 2328.622451066971
  timestamp: 1594858335
  timesteps_since_restore: 1315000
  timesteps_this_iter: 5000
  timesteps_total: 1315000
  training_iteration: 263
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2328 s, 263 iter, 1315000 ts, -673 rew

agent-1: -141.86895239506035
agent-2: -157.2878377657768
agent-3: -194.75143379662734
agent-4: -23.54181602725283
agent-5: -181.48389942972278
Extrinsic Rewards:
5
6
9
3
7
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 3
Max Reward: 9
Gini Coefficient: 0.18666666666666668
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-12-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -673.9311789681719
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 263
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.419
    dispatch_time_ms: 9.858
    learner:
      cur_lr: 0.0012724209809675813
      grad_gnorm: 40.0
      policy_entropy: 42.112403869628906
      policy_loss: 46.98682403564453
      var_gnorm: 26.03732681274414
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 44.24227523803711
    num_steps_sampled: 1320000
    num_steps_trained: 1320000
    wait_time_ms: 70.589
  iterations_since_restore: 264
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2336.7201688289642
  time_this_iter_s: 8.097717761993408
  time_total_s: 2336.7201688289642
  timestamp: 1594858343
  timesteps_since_restore: 1320000
  timesteps_this_iter: 5000
  timesteps_total: 1320000
  training_iteration: 264
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2336 s, 264 iter, 1320000 ts, -674 rew

agent-1: -118.05855000686631
agent-2: -195.0615150599954
agent-3: -49.9189407949076
agent-4: -169.94066782198254
agent-5: -141.86198257465622
Extrinsic Rewards:
6
7
11
8
7
Sum Reward: 39
Avg Reward: 7.8
Min Reward: 6
Max Reward: 11
Gini Coefficient: 0.11282051282051282
20:20 Ratio: 1.8333333333333333
Max-min Ratio: 1.8333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-12-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -674.534716508211
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 264
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.682
    dispatch_time_ms: 13.352
    learner:
      cur_lr: 0.0012720880331471562
      grad_gnorm: 13.315537452697754
      policy_entropy: 45.4704475402832
      policy_loss: -7.167004108428955
      var_gnorm: 26.018911361694336
      vf_explained_var: 0.0
      vf_loss: 2.299699544906616
    num_steps_sampled: 1325000
    num_steps_trained: 1325000
    wait_time_ms: 67.565
  iterations_since_restore: 265
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2345.1323008537292
  time_this_iter_s: 8.412132024765015
  time_total_s: 2345.1323008537292
  timestamp: 1594858352
  timesteps_since_restore: 1325000
  timesteps_this_iter: 5000
  timesteps_total: 1325000
  training_iteration: 265
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2345 s, 265 iter, 1325000 ts, -675 rew

agent-1: -197.43013108213714
agent-2: -169.06821562451594
agent-3: -26.69692369036287
agent-4: -229.16400430108675
agent-5: -33.64500502967662
Extrinsic Rewards:
8
4
1
8
1
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.38181818181818183
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-12-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -674.2095062189494
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 265
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.947
    dispatch_time_ms: 9.503
    learner:
      cur_lr: 0.0012717549689114094
      grad_gnorm: 6.095498085021973
      policy_entropy: 50.551204681396484
      policy_loss: -2.138749837875366
      var_gnorm: 26.027690887451172
      vf_explained_var: 0.0
      vf_loss: 2.164165735244751
    num_steps_sampled: 1330000
    num_steps_trained: 1330000
    wait_time_ms: 70.969
  iterations_since_restore: 266
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2353.479969739914
  time_this_iter_s: 8.347668886184692
  time_total_s: 2353.479969739914
  timestamp: 1594858360
  timesteps_since_restore: 1330000
  timesteps_this_iter: 5000
  timesteps_total: 1330000
  training_iteration: 266
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2353 s, 266 iter, 1330000 ts, -674 rew

agent-1: -162.66240910703482
agent-2: -114.45908538321065
agent-3: -182.53545729254353
agent-4: -87.81285639644663
agent-5: -133.23082335513132
Extrinsic Rewards:
13
14
14
13
5
Sum Reward: 59
Avg Reward: 11.8
Min Reward: 5
Max Reward: 14
Gini Coefficient: 0.1288135593220339
20:20 Ratio: 2.8
Max-min Ratio: 2.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-12-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -675.6526129248456
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 266
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.868
    dispatch_time_ms: 8.47
    learner:
      cur_lr: 0.0012714220210909843
      grad_gnorm: 16.115690231323242
      policy_entropy: 50.71310043334961
      policy_loss: -4.07369327545166
      var_gnorm: 26.021724700927734
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 4.705175399780273
    num_steps_sampled: 1335000
    num_steps_trained: 1335000
    wait_time_ms: 71.485
  iterations_since_restore: 267
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2361.7646424770355
  time_this_iter_s: 8.284672737121582
  time_total_s: 2361.7646424770355
  timestamp: 1594858368
  timesteps_since_restore: 1335000
  timesteps_this_iter: 5000
  timesteps_total: 1335000
  training_iteration: 267
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2361 s, 267 iter, 1335000 ts, -676 rew

agent-1: -163.60713403018042
agent-2: -138.47222665907466
agent-3: -236.09279184091238
agent-4: -116.02288133782814
agent-5: -149.49551959964444
Extrinsic Rewards:
6
0
7
3
7
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.3130434782608696
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-12-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -677.489220544086
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 267
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.968
    dispatch_time_ms: 9.327
    learner:
      cur_lr: 0.0012710889568552375
      grad_gnorm: 40.0
      policy_entropy: 57.73722839355469
      policy_loss: 35.307533264160156
      var_gnorm: 26.123889923095703
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 21.944393157958984
    num_steps_sampled: 1340000
    num_steps_trained: 1340000
    wait_time_ms: 71.479
  iterations_since_restore: 268
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2370.1084394454956
  time_this_iter_s: 8.343796968460083
  time_total_s: 2370.1084394454956
  timestamp: 1594858377
  timesteps_since_restore: 1340000
  timesteps_this_iter: 5000
  timesteps_total: 1340000
  training_iteration: 268
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2370 s, 268 iter, 1340000 ts, -677 rew

agent-1: -212.81914875378894
agent-2: -152.9850443255545
agent-3: -186.9810201556692
agent-4: -141.81097470127364
agent-5: -135.39740780505753
Extrinsic Rewards:
5
3
10
2
0
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 0
Max Reward: 10
Gini Coefficient: 0.46
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-13-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -677.5906959198475
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 268
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.551
    dispatch_time_ms: 10.984
    learner:
      cur_lr: 0.0012707560090348125
      grad_gnorm: 10.742073059082031
      policy_entropy: 51.23395919799805
      policy_loss: 1.9876590967178345
      var_gnorm: 26.034244537353516
      vf_explained_var: 0.0
      vf_loss: 4.1143083572387695
    num_steps_sampled: 1345000
    num_steps_trained: 1345000
    wait_time_ms: 70.317
  iterations_since_restore: 269
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2378.47797870636
  time_this_iter_s: 8.369539260864258
  time_total_s: 2378.47797870636
  timestamp: 1594858385
  timesteps_since_restore: 1345000
  timesteps_this_iter: 5000
  timesteps_total: 1345000
  training_iteration: 269
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2378 s, 269 iter, 1345000 ts, -678 rew

agent-1: -207.72657205254453
agent-2: -149.1745439523217
agent-3: -54.25552178310644
agent-4: -151.05444409526947
agent-5: -94.94487994331458
Extrinsic Rewards:
12
12
7
7
3
Sum Reward: 41
Avg Reward: 8.2
Min Reward: 3
Max Reward: 12
Gini Coefficient: 0.22439024390243903
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-13-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -679.049473085269
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 269
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.117
    dispatch_time_ms: 8.391
    learner:
      cur_lr: 0.0012704229447990656
      grad_gnorm: 27.718791961669922
      policy_entropy: 35.81903076171875
      policy_loss: -9.872366905212402
      var_gnorm: 26.06131935119629
      vf_explained_var: 0.0
      vf_loss: 9.443172454833984
    num_steps_sampled: 1350000
    num_steps_trained: 1350000
    wait_time_ms: 71.464
  iterations_since_restore: 270
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2386.892575740814
  time_this_iter_s: 8.414597034454346
  time_total_s: 2386.892575740814
  timestamp: 1594858394
  timesteps_since_restore: 1350000
  timesteps_this_iter: 5000
  timesteps_total: 1350000
  training_iteration: 270
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2386 s, 270 iter, 1350000 ts, -679 rew

agent-1: -246.78644474355232
agent-2: -177.16239741241796
agent-3: -150.756794392956
agent-4: -129.01551333879104
agent-5: -44.71763262963516
Extrinsic Rewards:
6
5
6
0
4
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 0
Max Reward: 6
Gini Coefficient: 0.26666666666666666
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-13-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -680.8645849574264
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 270
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.578
    dispatch_time_ms: 6.744
    learner:
      cur_lr: 0.0012700899969786406
      grad_gnorm: 10.831259727478027
      policy_entropy: 28.912382125854492
      policy_loss: -0.9901018142700195
      var_gnorm: 25.99531364440918
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 10.63237476348877
    num_steps_sampled: 1355000
    num_steps_trained: 1355000
    wait_time_ms: 71.962
  iterations_since_restore: 271
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2395.1672348976135
  time_this_iter_s: 8.274659156799316
  time_total_s: 2395.1672348976135
  timestamp: 1594858402
  timesteps_since_restore: 1355000
  timesteps_this_iter: 5000
  timesteps_total: 1355000
  training_iteration: 271
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2395 s, 271 iter, 1355000 ts, -681 rew

agent-1: -25.91407629088286
agent-2: -219.2093321037043
agent-3: -28.622244083509777
agent-4: -232.25229003379644
agent-5: -71.94260810373666
Extrinsic Rewards:
5
12
7
14
5
Sum Reward: 43
Avg Reward: 8.6
Min Reward: 5
Max Reward: 14
Gini Coefficient: 0.23255813953488372
20:20 Ratio: 2.8
Max-min Ratio: 2.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-13-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -681.1351756607254
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 271
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.404
    dispatch_time_ms: 7.092
    learner:
      cur_lr: 0.0012697570491582155
      grad_gnorm: 16.334796905517578
      policy_entropy: 17.64802360534668
      policy_loss: 2.2270445823669434
      var_gnorm: 25.972736358642578
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 12.324191093444824
    num_steps_sampled: 1360000
    num_steps_trained: 1360000
    wait_time_ms: 74.403
  iterations_since_restore: 272
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2403.5682072639465
  time_this_iter_s: 8.400972366333008
  time_total_s: 2403.5682072639465
  timestamp: 1594858410
  timesteps_since_restore: 1360000
  timesteps_this_iter: 5000
  timesteps_total: 1360000
  training_iteration: 272
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2403 s, 272 iter, 1360000 ts, -681 rew

agent-1: -87.70695964461076
agent-2: -37.82245203729929
agent-3: -44.315783379008366
agent-4: -22.309003401005235
agent-5: -239.89833271322775
Extrinsic Rewards:
12
7
7
6
8
Sum Reward: 40
Avg Reward: 8.0
Min Reward: 6
Max Reward: 12
Gini Coefficient: 0.13
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-13-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -679.9908323463583
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 272
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.552
    dispatch_time_ms: 8.109
    learner:
      cur_lr: 0.0012694239849224687
      grad_gnorm: 21.61127471923828
      policy_entropy: 40.6141242980957
      policy_loss: -3.23982572555542
      var_gnorm: 25.989845275878906
      vf_explained_var: 0.0
      vf_loss: 7.020188331604004
    num_steps_sampled: 1365000
    num_steps_trained: 1365000
    wait_time_ms: 76.718
  iterations_since_restore: 273
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2411.921177148819
  time_this_iter_s: 8.352969884872437
  time_total_s: 2411.921177148819
  timestamp: 1594858419
  timesteps_since_restore: 1365000
  timesteps_this_iter: 5000
  timesteps_total: 1365000
  training_iteration: 273
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2411 s, 273 iter, 1365000 ts, -680 rew

agent-1: -92.92621036966206
agent-2: -214.32368660536014
agent-3: -128.3947676653552
agent-4: -61.23212571052071
agent-5: -145.31311032568132
Extrinsic Rewards:
4
24
14
5
14
Sum Reward: 61
Avg Reward: 12.2
Min Reward: 4
Max Reward: 24
Gini Coefficient: 0.32131147540983607
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-13-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -679.5172169048253
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 273
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.977
    dispatch_time_ms: 6.643
    learner:
      cur_lr: 0.0012690910371020436
      grad_gnorm: 30.045581817626953
      policy_entropy: 35.419166564941406
      policy_loss: 4.4951324462890625
      var_gnorm: 26.019376754760742
      vf_explained_var: 0.0
      vf_loss: 6.698249340057373
    num_steps_sampled: 1370000
    num_steps_trained: 1370000
    wait_time_ms: 72.948
  iterations_since_restore: 274
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2420.210229873657
  time_this_iter_s: 8.289052724838257
  time_total_s: 2420.210229873657
  timestamp: 1594858427
  timesteps_since_restore: 1370000
  timesteps_this_iter: 5000
  timesteps_total: 1370000
  training_iteration: 274
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2420 s, 274 iter, 1370000 ts, -680 rew

agent-1: -18.26049190051078
agent-2: -130.20645085611133
agent-3: -83.03287423787704
agent-4: -181.35630204385785
agent-5: -230.94835434726753
Extrinsic Rewards:
2
4
4
3
15
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 2
Max Reward: 15
Gini Coefficient: 0.38571428571428573
20:20 Ratio: 7.5
Max-min Ratio: 7.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-13-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -677.8747454120087
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 274
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.0
    dispatch_time_ms: 9.135
    learner:
      cur_lr: 0.0012687579728662968
      grad_gnorm: 20.451976776123047
      policy_entropy: 27.939830780029297
      policy_loss: -6.5695481300354
      var_gnorm: 26.014892578125
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.2899887561798096
    num_steps_sampled: 1375000
    num_steps_trained: 1375000
    wait_time_ms: 73.309
  iterations_since_restore: 275
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2428.6872622966766
  time_this_iter_s: 8.47703242301941
  time_total_s: 2428.6872622966766
  timestamp: 1594858436
  timesteps_since_restore: 1375000
  timesteps_this_iter: 5000
  timesteps_total: 1375000
  training_iteration: 275
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2428 s, 275 iter, 1375000 ts, -678 rew

agent-1: -193.9454272176438
agent-2: -102.08115384562937
agent-3: -202.19175505928285
agent-4: -148.57735174166348
agent-5: -87.17930940388942
Extrinsic Rewards:
5
2
5
3
2
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 2
Max Reward: 5
Gini Coefficient: 0.21176470588235294
20:20 Ratio: 2.5
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-14-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -680.5256297084729
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 275
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.917
    dispatch_time_ms: 7.969
    learner:
      cur_lr: 0.0012684250250458717
      grad_gnorm: 40.0
      policy_entropy: 27.755939483642578
      policy_loss: 4.132857322692871
      var_gnorm: 26.014413833618164
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 16.75119400024414
    num_steps_sampled: 1380000
    num_steps_trained: 1380000
    wait_time_ms: 73.015
  iterations_since_restore: 276
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2437.082615852356
  time_this_iter_s: 8.395353555679321
  time_total_s: 2437.082615852356
  timestamp: 1594858444
  timesteps_since_restore: 1380000
  timesteps_this_iter: 5000
  timesteps_total: 1380000
  training_iteration: 276
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2437 s, 276 iter, 1380000 ts, -681 rew

agent-1: -56.15662487008385
agent-2: -202.08745736532393
agent-3: -33.7183763827467
agent-4: -56.33490061111609
agent-5: -245.8400773035561
Extrinsic Rewards:
4
6
2
7
9
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 2
Max Reward: 9
Gini Coefficient: 0.24285714285714285
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-14-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -679.7512864478485
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 276
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.632
    dispatch_time_ms: 5.295
    learner:
      cur_lr: 0.0012680919608101249
      grad_gnorm: 4.979458332061768
      policy_entropy: 31.94162368774414
      policy_loss: -2.5100982189178467
      var_gnorm: 26.011058807373047
      vf_explained_var: 0.0
      vf_loss: 7.824825286865234
    num_steps_sampled: 1385000
    num_steps_trained: 1385000
    wait_time_ms: 77.698
  iterations_since_restore: 277
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2445.4605078697205
  time_this_iter_s: 8.377892017364502
  time_total_s: 2445.4605078697205
  timestamp: 1594858453
  timesteps_since_restore: 1385000
  timesteps_this_iter: 5000
  timesteps_total: 1385000
  training_iteration: 277
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2445 s, 277 iter, 1385000 ts, -680 rew

agent-1: -144.96542806604683
agent-2: -144.92588174363763
agent-3: -234.5188009221275
agent-4: -28.46219693715624
agent-5: -120.00353522703715
Extrinsic Rewards:
4
3
5
2
8
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 2
Max Reward: 8
Gini Coefficient: 0.2545454545454545
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-14-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -680.2477439710382
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 277
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.913
    dispatch_time_ms: 7.892
    learner:
      cur_lr: 0.0012677590129896998
      grad_gnorm: 40.000003814697266
      policy_entropy: 41.513004302978516
      policy_loss: 12.511700630187988
      var_gnorm: 26.05539894104004
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 26.32428741455078
    num_steps_sampled: 1390000
    num_steps_trained: 1390000
    wait_time_ms: 72.878
  iterations_since_restore: 278
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2453.8617832660675
  time_this_iter_s: 8.401275396347046
  time_total_s: 2453.8617832660675
  timestamp: 1594858461
  timesteps_since_restore: 1390000
  timesteps_this_iter: 5000
  timesteps_total: 1390000
  training_iteration: 278
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2453 s, 278 iter, 1390000 ts, -680 rew

agent-1: -228.3713857263832
agent-2: -43.59868538860263
agent-3: -193.43215689991385
agent-4: -124.92194696998457
agent-5: -178.33115324154846
Extrinsic Rewards:
12
2
10
0
10
Sum Reward: 34
Avg Reward: 6.8
Min Reward: 0
Max Reward: 12
Gini Coefficient: 0.3764705882352941
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-14-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -680.4860562024578
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 278
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.686
    dispatch_time_ms: 8.239
    learner:
      cur_lr: 0.001267425948753953
      grad_gnorm: 11.475231170654297
      policy_entropy: 39.92583084106445
      policy_loss: -5.5824127197265625
      var_gnorm: 26.00897789001465
      vf_explained_var: 0.0
      vf_loss: 3.2469964027404785
    num_steps_sampled: 1395000
    num_steps_trained: 1395000
    wait_time_ms: 72.856
  iterations_since_restore: 279
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2462.1774668693542
  time_this_iter_s: 8.315683603286743
  time_total_s: 2462.1774668693542
  timestamp: 1594858469
  timesteps_since_restore: 1395000
  timesteps_this_iter: 5000
  timesteps_total: 1395000
  training_iteration: 279
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2462 s, 279 iter, 1395000 ts, -680 rew

agent-1: -146.47736961763815
agent-2: -106.90216408532791
agent-3: -110.35557596456565
agent-4: -210.65938706539316
agent-5: -87.92794278023761
Extrinsic Rewards:
8
9
4
12
15
Sum Reward: 48
Avg Reward: 9.6
Min Reward: 4
Max Reward: 15
Gini Coefficient: 0.21666666666666667
20:20 Ratio: 3.75
Max-min Ratio: 3.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-14-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -678.8382459052348
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 279
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.325
    dispatch_time_ms: 7.514
    learner:
      cur_lr: 0.001267093000933528
      grad_gnorm: 22.835880279541016
      policy_entropy: 32.97221374511719
      policy_loss: 4.483407974243164
      var_gnorm: 26.04452896118164
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 7.476660251617432
    num_steps_sampled: 1400000
    num_steps_trained: 1400000
    wait_time_ms: 73.679
  iterations_since_restore: 280
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2470.5134279727936
  time_this_iter_s: 8.335961103439331
  time_total_s: 2470.5134279727936
  timestamp: 1594858478
  timesteps_since_restore: 1400000
  timesteps_this_iter: 5000
  timesteps_total: 1400000
  training_iteration: 280
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2470 s, 280 iter, 1400000 ts, -679 rew

agent-1: -47.234098813640784
agent-2: -117.47255493445381
agent-3: -76.15514892554397
agent-4: -202.61041466235818
agent-5: -243.46128464774972
Extrinsic Rewards:
3
0
10
8
8
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 0
Max Reward: 10
Gini Coefficient: 0.3448275862068966
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-14-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -678.9051447351583
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 280
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.757
    dispatch_time_ms: 8.081
    learner:
      cur_lr: 0.001266760053113103
      grad_gnorm: 7.884365081787109
      policy_entropy: 18.277544021606445
      policy_loss: -2.5848803520202637
      var_gnorm: 26.024555206298828
      vf_explained_var: 0.0
      vf_loss: 2.0644919872283936
    num_steps_sampled: 1405000
    num_steps_trained: 1405000
    wait_time_ms: 72.481
  iterations_since_restore: 281
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2478.8743195533752
  time_this_iter_s: 8.360891580581665
  time_total_s: 2478.8743195533752
  timestamp: 1594858486
  timesteps_since_restore: 1405000
  timesteps_this_iter: 5000
  timesteps_total: 1405000
  training_iteration: 281
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2478 s, 281 iter, 1405000 ts, -679 rew

agent-1: -47.57316845862125
agent-2: -76.17203234113528
agent-3: -120.18027388161963
agent-4: -253.55001075265363
agent-5: -135.7900273843535
Extrinsic Rewards:
3
3
4
8
8
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 3
Max Reward: 8
Gini Coefficient: 0.23076923076923078
20:20 Ratio: 2.6666666666666665
Max-min Ratio: 2.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-14-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -677.911099315211
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 281
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.345
    dispatch_time_ms: 9.467
    learner:
      cur_lr: 0.001266426988877356
      grad_gnorm: 24.703947067260742
      policy_entropy: 17.02430534362793
      policy_loss: 0.11110340803861618
      var_gnorm: 26.023298263549805
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 11.591169357299805
    num_steps_sampled: 1410000
    num_steps_trained: 1410000
    wait_time_ms: 69.878
  iterations_since_restore: 282
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2487.3090612888336
  time_this_iter_s: 8.434741735458374
  time_total_s: 2487.3090612888336
  timestamp: 1594858495
  timesteps_since_restore: 1410000
  timesteps_this_iter: 5000
  timesteps_total: 1410000
  training_iteration: 282
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2487 s, 282 iter, 1410000 ts, -678 rew

agent-1: -192.35373221124905
agent-2: -199.8748838977249
agent-3: -113.37852410675309
agent-4: -130.1612432497886
agent-5: -92.09630018553221
Extrinsic Rewards:
4
6
5
1
4
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 1
Max Reward: 6
Gini Coefficient: 0.22
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-15-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -677.6984394935881
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 282
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.277
    dispatch_time_ms: 8.606
    learner:
      cur_lr: 0.001266094041056931
      grad_gnorm: 15.77440071105957
      policy_entropy: 38.19806671142578
      policy_loss: -3.1415834426879883
      var_gnorm: 25.998363494873047
      vf_explained_var: 0.0
      vf_loss: 4.899237155914307
    num_steps_sampled: 1415000
    num_steps_trained: 1415000
    wait_time_ms: 72.823
  iterations_since_restore: 283
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2495.6372277736664
  time_this_iter_s: 8.328166484832764
  time_total_s: 2495.6372277736664
  timestamp: 1594858503
  timesteps_since_restore: 1415000
  timesteps_this_iter: 5000
  timesteps_total: 1415000
  training_iteration: 283
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2495 s, 283 iter, 1415000 ts, -678 rew

agent-1: -155.3495248259696
agent-2: -34.46347769401385
agent-3: -204.83105774455484
agent-4: -178.36346864564834
agent-5: -36.51005853628977
Extrinsic Rewards:
13
6
7
4
9
Sum Reward: 39
Avg Reward: 7.8
Min Reward: 4
Max Reward: 13
Gini Coefficient: 0.2153846153846154
20:20 Ratio: 3.25
Max-min Ratio: 3.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-15-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -676.9721745903182
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 283
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.989
    dispatch_time_ms: 8.367
    learner:
      cur_lr: 0.0012657609768211842
      grad_gnorm: 32.38642501831055
      policy_entropy: 41.47380065917969
      policy_loss: 5.303977966308594
      var_gnorm: 26.015274047851562
      vf_explained_var: 0.0
      vf_loss: 17.81374168395996
    num_steps_sampled: 1420000
    num_steps_trained: 1420000
    wait_time_ms: 72.144
  iterations_since_restore: 284
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2504.025246858597
  time_this_iter_s: 8.38801908493042
  time_total_s: 2504.025246858597
  timestamp: 1594858511
  timesteps_since_restore: 1420000
  timesteps_this_iter: 5000
  timesteps_total: 1420000
  training_iteration: 284
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2504 s, 284 iter, 1420000 ts, -677 rew

agent-1: -169.38064127265162
agent-2: -66.02731420253323
agent-3: -91.5119025909437
agent-4: -150.52990672120845
agent-5: -163.1755372339941
Extrinsic Rewards:
11
14
12
18
12
Sum Reward: 67
Avg Reward: 13.4
Min Reward: 11
Max Reward: 18
Gini Coefficient: 0.0955223880597015
20:20 Ratio: 1.6363636363636365
Max-min Ratio: 1.6363636363636365
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-15-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -676.2245907758286
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 284
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.094
    dispatch_time_ms: 7.842
    learner:
      cur_lr: 0.0012654280290007591
      grad_gnorm: 6.957474231719971
      policy_entropy: 46.7425422668457
      policy_loss: -3.5718154907226562
      var_gnorm: 26.028154373168945
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.1381337642669678
    num_steps_sampled: 1425000
    num_steps_trained: 1425000
    wait_time_ms: 73.375
  iterations_since_restore: 285
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2512.3783192634583
  time_this_iter_s: 8.35307240486145
  time_total_s: 2512.3783192634583
  timestamp: 1594858520
  timesteps_since_restore: 1425000
  timesteps_this_iter: 5000
  timesteps_total: 1425000
  training_iteration: 285
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2512 s, 285 iter, 1425000 ts, -676 rew

agent-1: -96.44263689422898
agent-2: -215.40962908818827
agent-3: -146.20090106455285
agent-4: -219.20066867145349
agent-5: -148.89028688486667
Extrinsic Rewards:
3
5
0
5
5
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 0
Max Reward: 5
Gini Coefficient: 0.26666666666666666
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-15-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -678.4472283387211
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 285
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.503
    dispatch_time_ms: 8.153
    learner:
      cur_lr: 0.0012650949647650123
      grad_gnorm: 20.268465042114258
      policy_entropy: 54.926307678222656
      policy_loss: 8.9282865524292
      var_gnorm: 26.08246421813965
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.5180435180664062
    num_steps_sampled: 1430000
    num_steps_trained: 1430000
    wait_time_ms: 74.569
  iterations_since_restore: 286
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2520.7250344753265
  time_this_iter_s: 8.346715211868286
  time_total_s: 2520.7250344753265
  timestamp: 1594858528
  timesteps_since_restore: 1430000
  timesteps_this_iter: 5000
  timesteps_total: 1430000
  training_iteration: 286
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2520 s, 286 iter, 1430000 ts, -678 rew

agent-1: -160.57250833319745
agent-2: -55.48565001466645
agent-3: -110.38025694194492
agent-4: -184.8552565643599
agent-5: -209.16836620423754
Extrinsic Rewards:
6
2
3
4
5
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 2
Max Reward: 6
Gini Coefficient: 0.2
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-15-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -679.0356728613363
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 286
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.146
    dispatch_time_ms: 7.685
    learner:
      cur_lr: 0.0012647620169445872
      grad_gnorm: 21.921110153198242
      policy_entropy: 55.9132080078125
      policy_loss: 3.0545284748077393
      var_gnorm: 26.0226993560791
      vf_explained_var: 0.0
      vf_loss: 7.737636566162109
    num_steps_sampled: 1435000
    num_steps_trained: 1435000
    wait_time_ms: 74.413
  iterations_since_restore: 287
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2529.0955996513367
  time_this_iter_s: 8.370565176010132
  time_total_s: 2529.0955996513367
  timestamp: 1594858537
  timesteps_since_restore: 1435000
  timesteps_this_iter: 5000
  timesteps_total: 1435000
  training_iteration: 287
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2529 s, 287 iter, 1435000 ts, -679 rew

agent-1: -182.48441243539898
agent-2: -249.90015552675843
agent-3: -24.37368020504787
agent-4: -131.15694701750388
agent-5: -39.66857641121799
Extrinsic Rewards:
9
11
1
3
2
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 1
Max Reward: 11
Gini Coefficient: 0.4153846153846154
20:20 Ratio: 11.0
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-15-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -678.9798407266906
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 287
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.956
    dispatch_time_ms: 10.287
    learner:
      cur_lr: 0.0012644289527088404
      grad_gnorm: 15.278234481811523
      policy_entropy: 57.301513671875
      policy_loss: 1.118699312210083
      var_gnorm: 26.021577835083008
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 6.379760265350342
    num_steps_sampled: 1440000
    num_steps_trained: 1440000
    wait_time_ms: 71.675
  iterations_since_restore: 288
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2537.5235981941223
  time_this_iter_s: 8.427998542785645
  time_total_s: 2537.5235981941223
  timestamp: 1594858545
  timesteps_since_restore: 1440000
  timesteps_this_iter: 5000
  timesteps_total: 1440000
  training_iteration: 288
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2537 s, 288 iter, 1440000 ts, -679 rew

agent-1: -167.99792226602162
agent-2: -134.51615480989167
agent-3: -77.24414334924674
agent-4: -243.5076767700156
agent-5: -20.22994681679646
Extrinsic Rewards:
4
5
3
11
1
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 1
Max Reward: 11
Gini Coefficient: 0.36666666666666664
20:20 Ratio: 11.0
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-15-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -678.8861251209369
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 288
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.96
    dispatch_time_ms: 8.568
    learner:
      cur_lr: 0.0012640960048884153
      grad_gnorm: 19.652210235595703
      policy_entropy: 56.30726623535156
      policy_loss: -2.8711447715759277
      var_gnorm: 26.02753448486328
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 3.8262670040130615
    num_steps_sampled: 1445000
    num_steps_trained: 1445000
    wait_time_ms: 73.944
  iterations_since_restore: 289
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2545.9239292144775
  time_this_iter_s: 8.400331020355225
  time_total_s: 2545.9239292144775
  timestamp: 1594858553
  timesteps_since_restore: 1445000
  timesteps_this_iter: 5000
  timesteps_total: 1445000
  training_iteration: 289
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2545 s, 289 iter, 1445000 ts, -679 rew

agent-1: -141.7911027273773
agent-2: -201.1720415573267
agent-3: -141.7911027273773
agent-4: -244.20581127151559
agent-5: -179.1861239629404
Extrinsic Rewards:
0
7
0
6
5
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.4444444444444444
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-16-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -681.477007480083
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 289
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.003
    dispatch_time_ms: 9.242
    learner:
      cur_lr: 0.0012637630570679903
      grad_gnorm: 23.42414093017578
      policy_entropy: 64.22021484375
      policy_loss: 7.842111587524414
      var_gnorm: 26.09302520751953
      vf_explained_var: 0.0
      vf_loss: 4.516543865203857
    num_steps_sampled: 1450000
    num_steps_trained: 1450000
    wait_time_ms: 64.393
  iterations_since_restore: 290
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2554.219948530197
  time_this_iter_s: 8.296019315719604
  time_total_s: 2554.219948530197
  timestamp: 1594858562
  timesteps_since_restore: 1450000
  timesteps_this_iter: 5000
  timesteps_total: 1450000
  training_iteration: 290
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2554 s, 290 iter, 1450000 ts, -681 rew

agent-1: -109.14273668436586
agent-2: -111.99980372457932
agent-3: -91.73581450118671
agent-4: -99.1573361154105
agent-5: -238.68955329951248
Extrinsic Rewards:
4
4
6
9
9
Sum Reward: 32
Avg Reward: 6.4
Min Reward: 4
Max Reward: 9
Gini Coefficient: 0.1875
20:20 Ratio: 2.25
Max-min Ratio: 2.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-16-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -681.0308159538403
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 290
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.69
    dispatch_time_ms: 8.57
    learner:
      cur_lr: 0.0012634299928322434
      grad_gnorm: 18.041217803955078
      policy_entropy: 66.93566131591797
      policy_loss: 2.334805727005005
      var_gnorm: 26.045488357543945
      vf_explained_var: 0.0
      vf_loss: 8.758776664733887
    num_steps_sampled: 1455000
    num_steps_trained: 1455000
    wait_time_ms: 72.13
  iterations_since_restore: 291
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2562.5643479824066
  time_this_iter_s: 8.344399452209473
  time_total_s: 2562.5643479824066
  timestamp: 1594858570
  timesteps_since_restore: 1455000
  timesteps_this_iter: 5000
  timesteps_total: 1455000
  training_iteration: 291
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2562 s, 291 iter, 1455000 ts, -681 rew

agent-1: -129.14650803687198
agent-2: -167.52449244954522
agent-3: -249.2058811965952
agent-4: -44.60179305396478
agent-5: -119.19380844099936
Extrinsic Rewards:
2
11
7
6
0
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 0
Max Reward: 11
Gini Coefficient: 0.4153846153846154
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-16-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -681.5933966984304
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 291
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.971
    dispatch_time_ms: 7.764
    learner:
      cur_lr: 0.0012630970450118184
      grad_gnorm: 8.626763343811035
      policy_entropy: 43.19121551513672
      policy_loss: 2.9654250144958496
      var_gnorm: 26.07717514038086
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.183377504348755
    num_steps_sampled: 1460000
    num_steps_trained: 1460000
    wait_time_ms: 74.943
  iterations_since_restore: 292
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2571.4044473171234
  time_this_iter_s: 8.840099334716797
  time_total_s: 2571.4044473171234
  timestamp: 1594858579
  timesteps_since_restore: 1460000
  timesteps_this_iter: 5000
  timesteps_total: 1460000
  training_iteration: 292
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2571 s, 292 iter, 1460000 ts, -682 rew

agent-1: -74.30689844194801
agent-2: -214.0132874509294
agent-3: -120.0136314598335
agent-4: -98.11419890234092
agent-5: -197.96033390927886
Extrinsic Rewards:
2
8
4
3
6
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 2
Max Reward: 8
Gini Coefficient: 0.2608695652173913
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-16-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -681.6852949273981
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 292
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.533
    dispatch_time_ms: 9.817
    learner:
      cur_lr: 0.0012627639807760715
      grad_gnorm: 17.440338134765625
      policy_entropy: 52.849796295166016
      policy_loss: 4.72084903717041
      var_gnorm: 26.01438331604004
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 9.548325538635254
    num_steps_sampled: 1465000
    num_steps_trained: 1465000
    wait_time_ms: 73.357
  iterations_since_restore: 293
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2579.6539874076843
  time_this_iter_s: 8.249540090560913
  time_total_s: 2579.6539874076843
  timestamp: 1594858587
  timesteps_since_restore: 1465000
  timesteps_this_iter: 5000
  timesteps_total: 1465000
  training_iteration: 293
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2579 s, 293 iter, 1465000 ts, -682 rew

agent-1: -252.92365163705523
agent-2: -32.13630532069208
agent-3: -79.5861758880418
agent-4: -169.37346604398473
agent-5: -28.525751511254718
Extrinsic Rewards:
13
3
8
9
6
Sum Reward: 39
Avg Reward: 7.8
Min Reward: 3
Max Reward: 13
Gini Coefficient: 0.2358974358974359
20:20 Ratio: 4.333333333333333
Max-min Ratio: 4.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-16-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -681.3358577964339
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 293
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.884
    dispatch_time_ms: 6.705
    learner:
      cur_lr: 0.0012624310329556465
      grad_gnorm: 14.863364219665527
      policy_entropy: 28.35800552368164
      policy_loss: 7.833409786224365
      var_gnorm: 26.01758575439453
      vf_explained_var: 0.0
      vf_loss: 11.312444686889648
    num_steps_sampled: 1470000
    num_steps_trained: 1470000
    wait_time_ms: 73.949
  iterations_since_restore: 294
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2588.0648140907288
  time_this_iter_s: 8.410826683044434
  time_total_s: 2588.0648140907288
  timestamp: 1594858596
  timesteps_since_restore: 1470000
  timesteps_this_iter: 5000
  timesteps_total: 1470000
  training_iteration: 294
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2588 s, 294 iter, 1470000 ts, -681 rew

agent-1: -176.48911040887538
agent-2: -137.46490688892374
agent-3: -91.47063439743322
agent-4: -131.75711933656882
agent-5: -39.75578125675676
Extrinsic Rewards:
16
9
15
25
8
Sum Reward: 73
Avg Reward: 14.6
Min Reward: 8
Max Reward: 25
Gini Coefficient: 0.22465753424657534
20:20 Ratio: 3.125
Max-min Ratio: 3.125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-16-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -405.1396844506915
  episode_reward_mean: -682.1342589244391
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 294
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.847
    dispatch_time_ms: 8.621
    learner:
      cur_lr: 0.0012620979687198997
      grad_gnorm: 33.610111236572266
      policy_entropy: 40.97484588623047
      policy_loss: 10.85495376586914
      var_gnorm: 26.006372451782227
      vf_explained_var: 0.0
      vf_loss: 6.837123394012451
    num_steps_sampled: 1475000
    num_steps_trained: 1475000
    wait_time_ms: 71.062
  iterations_since_restore: 295
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2596.2982647418976
  time_this_iter_s: 8.233450651168823
  time_total_s: 2596.2982647418976
  timestamp: 1594858604
  timesteps_since_restore: 1475000
  timesteps_this_iter: 5000
  timesteps_total: 1475000
  training_iteration: 295
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2596 s, 295 iter, 1475000 ts, -682 rew

agent-1: -162.50494616530193
agent-2: -161.3436603863583
agent-3: -93.35205302164383
agent-4: -139.33838121647597
agent-5: -43.28247941033952
Extrinsic Rewards:
19
27
9
16
7
Sum Reward: 78
Avg Reward: 15.6
Min Reward: 7
Max Reward: 27
Gini Coefficient: 0.2564102564102564
20:20 Ratio: 3.857142857142857
Max-min Ratio: 3.857142857142857
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-16-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -684.0810772819334
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 295
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.066
    dispatch_time_ms: 7.594
    learner:
      cur_lr: 0.0012617650208994746
      grad_gnorm: 21.231081008911133
      policy_entropy: 57.64841079711914
      policy_loss: 7.154025077819824
      var_gnorm: 26.018774032592773
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 11.971771240234375
    num_steps_sampled: 1480000
    num_steps_trained: 1480000
    wait_time_ms: 72.648
  iterations_since_restore: 296
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2604.6179513931274
  time_this_iter_s: 8.319686651229858
  time_total_s: 2604.6179513931274
  timestamp: 1594858612
  timesteps_since_restore: 1480000
  timesteps_this_iter: 5000
  timesteps_total: 1480000
  training_iteration: 296
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2604 s, 296 iter, 1480000 ts, -684 rew

agent-1: -126.07645045079349
agent-2: -106.54691227669987
agent-3: -105.22399307492438
agent-4: -84.96407579884773
agent-5: -106.07901325223543
Extrinsic Rewards:
38
25
23
19
27
Sum Reward: 132
Avg Reward: 26.4
Min Reward: 19
Max Reward: 38
Gini Coefficient: 0.12727272727272726
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-17-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -682.4818102346051
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 296
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.63
    dispatch_time_ms: 9.025
    learner:
      cur_lr: 0.0012614319566637278
      grad_gnorm: 15.086316108703613
      policy_entropy: 53.27193832397461
      policy_loss: 2.7390880584716797
      var_gnorm: 26.019912719726562
      vf_explained_var: 0.0
      vf_loss: 6.942607879638672
    num_steps_sampled: 1485000
    num_steps_trained: 1485000
    wait_time_ms: 71.901
  iterations_since_restore: 297
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2612.952850341797
  time_this_iter_s: 8.334898948669434
  time_total_s: 2612.952850341797
  timestamp: 1594858621
  timesteps_since_restore: 1485000
  timesteps_this_iter: 5000
  timesteps_total: 1485000
  training_iteration: 297
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2612 s, 297 iter, 1485000 ts, -682 rew

agent-1: -182.82883346736884
agent-2: -116.46148418372077
agent-3: -211.26408959306173
agent-4: -8.61587172462721
agent-5: -144.2150347000486
Extrinsic Rewards:
8
9
14
1
11
Sum Reward: 43
Avg Reward: 8.6
Min Reward: 1
Max Reward: 14
Gini Coefficient: 0.26976744186046514
20:20 Ratio: 14.0
Max-min Ratio: 14.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-17-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -683.215146754758
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 297
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.932
    dispatch_time_ms: 6.369
    learner:
      cur_lr: 0.0012610990088433027
      grad_gnorm: 40.000003814697266
      policy_entropy: 53.42058563232422
      policy_loss: 17.5025577545166
      var_gnorm: 26.027170181274414
      vf_explained_var: 0.0
      vf_loss: 12.605396270751953
    num_steps_sampled: 1490000
    num_steps_trained: 1490000
    wait_time_ms: 69.419
  iterations_since_restore: 298
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2621.3250200748444
  time_this_iter_s: 8.372169733047485
  time_total_s: 2621.3250200748444
  timestamp: 1594858629
  timesteps_since_restore: 1490000
  timesteps_this_iter: 5000
  timesteps_total: 1490000
  training_iteration: 298
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2621 s, 298 iter, 1490000 ts, -683 rew

agent-1: -254.2062436678293
agent-2: -122.81517064068949
agent-3: -59.911279516712526
agent-4: -35.50725834312125
agent-5: -111.4897464849629
Extrinsic Rewards:
6
3
2
2
10
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 2
Max Reward: 10
Gini Coefficient: 0.34782608695652173
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-17-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -682.2837332549029
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 298
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.031
    dispatch_time_ms: 7.258
    learner:
      cur_lr: 0.0012607659446075559
      grad_gnorm: 13.594274520874023
      policy_entropy: 54.853267669677734
      policy_loss: -5.690423965454102
      var_gnorm: 26.03672981262207
      vf_explained_var: 0.0
      vf_loss: 3.9489378929138184
    num_steps_sampled: 1495000
    num_steps_trained: 1495000
    wait_time_ms: 74.262
  iterations_since_restore: 299
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2629.6949746608734
  time_this_iter_s: 8.369954586029053
  time_total_s: 2629.6949746608734
  timestamp: 1594858638
  timesteps_since_restore: 1495000
  timesteps_this_iter: 5000
  timesteps_total: 1495000
  training_iteration: 299
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2629 s, 299 iter, 1495000 ts, -682 rew

agent-1: -174.03604459607226
agent-2: -170.30597524817958
agent-3: -183.47190454992491
agent-4: -124.77344689465184
agent-5: -171.52369593397987
Extrinsic Rewards:
9
6
4
0
8
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.32592592592592595
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-17-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -681.9366065393103
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 299
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.862
    dispatch_time_ms: 8.196
    learner:
      cur_lr: 0.0012604329967871308
      grad_gnorm: 25.195968627929688
      policy_entropy: 48.020572662353516
      policy_loss: 7.511099338531494
      var_gnorm: 26.07874870300293
      vf_explained_var: 0.0
      vf_loss: 7.629365921020508
    num_steps_sampled: 1500000
    num_steps_trained: 1500000
    wait_time_ms: 73.204
  iterations_since_restore: 300
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2638.052613258362
  time_this_iter_s: 8.357638597488403
  time_total_s: 2638.052613258362
  timestamp: 1594858646
  timesteps_since_restore: 1500000
  timesteps_this_iter: 5000
  timesteps_total: 1500000
  training_iteration: 300
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2638 s, 300 iter, 1500000 ts, -682 rew

agent-1: -211.3030134121546
agent-2: -239.5436124296766
agent-3: -30.1487345763931
agent-4: -107.2146585101726
agent-5: -58.97730470507615
Extrinsic Rewards:
5
9
1
4
1
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.4
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-17-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -681.7372848173238
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 300
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.233
    dispatch_time_ms: 7.11
    learner:
      cur_lr: 0.0012601000489667058
      grad_gnorm: 21.028640747070312
      policy_entropy: 47.22481155395508
      policy_loss: -7.053807258605957
      var_gnorm: 26.000720977783203
      vf_explained_var: 0.0
      vf_loss: 7.214207172393799
    num_steps_sampled: 1505000
    num_steps_trained: 1505000
    wait_time_ms: 72.346
  iterations_since_restore: 301
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2646.2852556705475
  time_this_iter_s: 8.232642412185669
  time_total_s: 2646.2852556705475
  timestamp: 1594858654
  timesteps_since_restore: 1505000
  timesteps_this_iter: 5000
  timesteps_total: 1505000
  training_iteration: 301
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2646 s, 301 iter, 1505000 ts, -682 rew

agent-1: -142.21945153588877
agent-2: -140.50198931892447
agent-3: -51.05850092654422
agent-4: -106.24315604725098
agent-5: -104.62123814075477
Extrinsic Rewards:
25
19
12
20
18
Sum Reward: 94
Avg Reward: 18.8
Min Reward: 12
Max Reward: 25
Gini Coefficient: 0.11914893617021277
20:20 Ratio: 2.0833333333333335
Max-min Ratio: 2.0833333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-17-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -680.6557830922111
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 301
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.232
    dispatch_time_ms: 9.728
    learner:
      cur_lr: 0.001259766984730959
      grad_gnorm: 40.000003814697266
      policy_entropy: 51.32267379760742
      policy_loss: 33.214813232421875
      var_gnorm: 26.04268455505371
      vf_explained_var: 0.0
      vf_loss: 32.68954849243164
    num_steps_sampled: 1510000
    num_steps_trained: 1510000
    wait_time_ms: 72.482
  iterations_since_restore: 302
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2654.7417800426483
  time_this_iter_s: 8.45652437210083
  time_total_s: 2654.7417800426483
  timestamp: 1594858663
  timesteps_since_restore: 1510000
  timesteps_this_iter: 5000
  timesteps_total: 1510000
  training_iteration: 302
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2654 s, 302 iter, 1510000 ts, -681 rew

agent-1: -85.86700840808004
agent-2: -72.11553488579632
agent-3: -279.07315631576756
agent-4: -34.78118517753045
agent-5: -124.12408296321577
Extrinsic Rewards:
6
5
9
3
0
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.3652173913043478
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-17-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -681.4425317299763
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 302
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.02
    dispatch_time_ms: 9.456
    learner:
      cur_lr: 0.001259434036910534
      grad_gnorm: 23.485868453979492
      policy_entropy: 52.0469856262207
      policy_loss: -1.5619456768035889
      var_gnorm: 26.03165626525879
      vf_explained_var: 0.0
      vf_loss: 5.649314880371094
    num_steps_sampled: 1515000
    num_steps_trained: 1515000
    wait_time_ms: 71.135
  iterations_since_restore: 303
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2663.1134016513824
  time_this_iter_s: 8.37162160873413
  time_total_s: 2663.1134016513824
  timestamp: 1594858671
  timesteps_since_restore: 1515000
  timesteps_this_iter: 5000
  timesteps_total: 1515000
  training_iteration: 303
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2663 s, 303 iter, 1515000 ts, -681 rew

agent-1: -29.44629602057891
agent-2: -203.9497918006961
agent-3: -245.27891206664484
agent-4: -50.25235718820061
agent-5: -28.01553255356626
Extrinsic Rewards:
6
7
10
3
5
Sum Reward: 31
Avg Reward: 6.2
Min Reward: 3
Max Reward: 10
Gini Coefficient: 0.2064516129032258
20:20 Ratio: 3.3333333333333335
Max-min Ratio: 3.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-18-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -680.1166653704767
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 303
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.317
    dispatch_time_ms: 8.624
    learner:
      cur_lr: 0.001259100972674787
      grad_gnorm: 9.928153991699219
      policy_entropy: 46.95802688598633
      policy_loss: -2.8024401664733887
      var_gnorm: 26.030542373657227
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 7.322904586791992
    num_steps_sampled: 1520000
    num_steps_trained: 1520000
    wait_time_ms: 70.287
  iterations_since_restore: 304
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2671.49910569191
  time_this_iter_s: 8.385704040527344
  time_total_s: 2671.49910569191
  timestamp: 1594858680
  timesteps_since_restore: 1520000
  timesteps_this_iter: 5000
  timesteps_total: 1520000
  training_iteration: 304
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2671 s, 304 iter, 1520000 ts, -680 rew

agent-1: -184.51400776489086
agent-2: -26.681908532274612
agent-3: -130.99902437180066
agent-4: -230.00865974831976
agent-5: -95.03754233051733
Extrinsic Rewards:
6
2
6
5
1
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 1
Max Reward: 6
Gini Coefficient: 0.28
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-18-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -680.731341169961
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 304
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.578
    dispatch_time_ms: 10.371
    learner:
      cur_lr: 0.001258768024854362
      grad_gnorm: 7.767400741577148
      policy_entropy: 49.726409912109375
      policy_loss: -2.8044378757476807
      var_gnorm: 26.02393341064453
      vf_explained_var: 0.0
      vf_loss: 8.421920776367188
    num_steps_sampled: 1525000
    num_steps_trained: 1525000
    wait_time_ms: 72.363
  iterations_since_restore: 305
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2679.813075065613
  time_this_iter_s: 8.313969373703003
  time_total_s: 2679.813075065613
  timestamp: 1594858688
  timesteps_since_restore: 1525000
  timesteps_this_iter: 5000
  timesteps_total: 1525000
  training_iteration: 305
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2679 s, 305 iter, 1525000 ts, -681 rew

agent-1: -188.568721857869
agent-2: -235.50970876625374
agent-3: -40.1402559120442
agent-4: -131.03160327122538
agent-5: -46.6832524039185
Extrinsic Rewards:
3
6
5
3
5
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 3
Max Reward: 6
Gini Coefficient: 0.14545454545454545
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-18-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -681.4706906728269
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 305
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.541
    dispatch_time_ms: 8.347
    learner:
      cur_lr: 0.0012584349606186152
      grad_gnorm: 29.381532669067383
      policy_entropy: 45.763771057128906
      policy_loss: 11.18532657623291
      var_gnorm: 26.05452537536621
      vf_explained_var: 0.0
      vf_loss: 11.636503219604492
    num_steps_sampled: 1530000
    num_steps_trained: 1530000
    wait_time_ms: 73.05
  iterations_since_restore: 306
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2688.1937952041626
  time_this_iter_s: 8.380720138549805
  time_total_s: 2688.1937952041626
  timestamp: 1594858696
  timesteps_since_restore: 1530000
  timesteps_this_iter: 5000
  timesteps_total: 1530000
  training_iteration: 306
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2688 s, 306 iter, 1530000 ts, -681 rew

agent-1: -88.08069549682975
agent-2: -145.8956102396161
agent-3: -71.88094359049977
agent-4: -167.05043993623653
agent-5: -200.29671928900595
Extrinsic Rewards:
19
8
0
17
10
Sum Reward: 54
Avg Reward: 10.8
Min Reward: 0
Max Reward: 19
Gini Coefficient: 0.34814814814814815
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-18-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -681.161242259121
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 306
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.279
    dispatch_time_ms: 8.197
    learner:
      cur_lr: 0.0012581020127981901
      grad_gnorm: 19.104673385620117
      policy_entropy: 47.97797775268555
      policy_loss: -0.21016579866409302
      var_gnorm: 26.029624938964844
      vf_explained_var: 0.0
      vf_loss: 5.537229061126709
    num_steps_sampled: 1535000
    num_steps_trained: 1535000
    wait_time_ms: 72.156
  iterations_since_restore: 307
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2696.527816772461
  time_this_iter_s: 8.33402156829834
  time_total_s: 2696.527816772461
  timestamp: 1594858705
  timesteps_since_restore: 1535000
  timesteps_this_iter: 5000
  timesteps_total: 1535000
  training_iteration: 307
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2696 s, 307 iter, 1535000 ts, -681 rew

agent-1: -140.3012024015677
agent-2: -68.53344483593418
agent-3: -168.61153663701498
agent-4: -39.90636032246106
agent-5: -209.39587594279962
Extrinsic Rewards:
12
4
18
6
18
Sum Reward: 58
Avg Reward: 11.6
Min Reward: 4
Max Reward: 18
Gini Coefficient: 0.27586206896551724
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-18-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -681.2667927682076
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 307
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.205
    dispatch_time_ms: 8.46
    learner:
      cur_lr: 0.0012577689485624433
      grad_gnorm: 35.91109085083008
      policy_entropy: 48.27177429199219
      policy_loss: 13.286706924438477
      var_gnorm: 26.04840660095215
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 18.7081356048584
    num_steps_sampled: 1540000
    num_steps_trained: 1540000
    wait_time_ms: 70.361
  iterations_since_restore: 308
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2704.883643388748
  time_this_iter_s: 8.355826616287231
  time_total_s: 2704.883643388748
  timestamp: 1594858713
  timesteps_since_restore: 1540000
  timesteps_this_iter: 5000
  timesteps_total: 1540000
  training_iteration: 308
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2704 s, 308 iter, 1540000 ts, -681 rew

agent-1: -117.67871594883212
agent-2: -139.03399768074823
agent-3: -52.64170951863738
agent-4: -147.86626050698214
agent-5: -189.36629376153994
Extrinsic Rewards:
11
5
7
1
11
Sum Reward: 35
Avg Reward: 7.0
Min Reward: 1
Max Reward: 11
Gini Coefficient: 0.29714285714285715
20:20 Ratio: 11.0
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-18-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -681.4309507256403
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 308
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.777
    dispatch_time_ms: 9.313
    learner:
      cur_lr: 0.0012574360007420182
      grad_gnorm: 14.381223678588867
      policy_entropy: 58.860294342041016
      policy_loss: -0.40873992443084717
      var_gnorm: 26.04233169555664
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 5.533329486846924
    num_steps_sampled: 1545000
    num_steps_trained: 1545000
    wait_time_ms: 71.114
  iterations_since_restore: 309
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2713.2320716381073
  time_this_iter_s: 8.34842824935913
  time_total_s: 2713.2320716381073
  timestamp: 1594858722
  timesteps_since_restore: 1545000
  timesteps_this_iter: 5000
  timesteps_total: 1545000
  training_iteration: 309
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2713 s, 309 iter, 1545000 ts, -681 rew

agent-1: -196.60029926887154
agent-2: -76.67921290347871
agent-3: -104.74644855580436
agent-4: -206.32629540737108
agent-5: -172.88389167842556
Extrinsic Rewards:
13
6
0
11
7
Sum Reward: 37
Avg Reward: 7.4
Min Reward: 0
Max Reward: 13
Gini Coefficient: 0.33513513513513515
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-18-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -682.7564988582774
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 309
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.15
    dispatch_time_ms: 9.231
    learner:
      cur_lr: 0.0012571030529215932
      grad_gnorm: 39.999996185302734
      policy_entropy: 54.155330657958984
      policy_loss: 36.590904235839844
      var_gnorm: 26.075939178466797
      vf_explained_var: 0.0
      vf_loss: 22.216556549072266
    num_steps_sampled: 1550000
    num_steps_trained: 1550000
    wait_time_ms: 71.592
  iterations_since_restore: 310
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2721.633013486862
  time_this_iter_s: 8.400941848754883
  time_total_s: 2721.633013486862
  timestamp: 1594858730
  timesteps_since_restore: 1550000
  timesteps_this_iter: 5000
  timesteps_total: 1550000
  training_iteration: 310
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2721 s, 310 iter, 1550000 ts, -683 rew

agent-1: -127.05652082155771
agent-2: -229.0952995612787
agent-3: -11.906802961304193
agent-4: -139.81089784920576
agent-5: -158.9779764161488
Extrinsic Rewards:
3
7
1
10
5
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 1
Max Reward: 10
Gini Coefficient: 0.3384615384615385
20:20 Ratio: 10.0
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-18-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -682.9723952066632
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 310
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.621
    dispatch_time_ms: 7.787
    learner:
      cur_lr: 0.0012567699886858463
      grad_gnorm: 5.362178325653076
      policy_entropy: 52.57400894165039
      policy_loss: 0.736426055431366
      var_gnorm: 26.051538467407227
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 7.955998420715332
    num_steps_sampled: 1555000
    num_steps_trained: 1555000
    wait_time_ms: 73.785
  iterations_since_restore: 311
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2729.9432525634766
  time_this_iter_s: 8.31023907661438
  time_total_s: 2729.9432525634766
  timestamp: 1594858738
  timesteps_since_restore: 1555000
  timesteps_this_iter: 5000
  timesteps_total: 1555000
  training_iteration: 311
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2729 s, 311 iter, 1555000 ts, -683 rew

agent-1: -183.48759013316334
agent-2: -247.444388474577
agent-3: -161.6444035010474
agent-4: -129.79341282083882
agent-5: -31.129527418020952
Extrinsic Rewards:
9
6
3
0
2
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.44
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-19-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -684.5409560698025
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 311
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.649
    dispatch_time_ms: 6.243
    learner:
      cur_lr: 0.0012564370408654213
      grad_gnorm: 19.458833694458008
      policy_entropy: 37.4621467590332
      policy_loss: -5.169479846954346
      var_gnorm: 26.131031036376953
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 3.168184280395508
    num_steps_sampled: 1560000
    num_steps_trained: 1560000
    wait_time_ms: 76.148
  iterations_since_restore: 312
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2738.2984755039215
  time_this_iter_s: 8.355222940444946
  time_total_s: 2738.2984755039215
  timestamp: 1594858747
  timesteps_since_restore: 1560000
  timesteps_this_iter: 5000
  timesteps_total: 1560000
  training_iteration: 312
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2738 s, 312 iter, 1560000 ts, -685 rew

agent-1: -170.93577604464943
agent-2: -206.3193424291748
agent-3: -177.28780039241818
agent-4: -142.7222836651746
agent-5: -152.65983508262912
Extrinsic Rewards:
7
7
3
0
1
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.4444444444444444
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-19-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -686.030982260953
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 312
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.008
    dispatch_time_ms: 9.244
    learner:
      cur_lr: 0.0012561039766296744
      grad_gnorm: 11.693403244018555
      policy_entropy: 46.403770446777344
      policy_loss: 5.973903179168701
      var_gnorm: 26.0439453125
      vf_explained_var: 0.0
      vf_loss: 10.179986953735352
    num_steps_sampled: 1565000
    num_steps_trained: 1565000
    wait_time_ms: 71.265
  iterations_since_restore: 313
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2746.4904491901398
  time_this_iter_s: 8.191973686218262
  time_total_s: 2746.4904491901398
  timestamp: 1594858755
  timesteps_since_restore: 1565000
  timesteps_this_iter: 5000
  timesteps_total: 1565000
  training_iteration: 313
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2746 s, 313 iter, 1565000 ts, -686 rew

agent-1: -206.63474671890728
agent-2: -52.24706102076867
agent-3: -188.09102446060325
agent-4: -55.85029682830645
agent-5: -73.4305605164463
Extrinsic Rewards:
10
5
5
13
6
Sum Reward: 39
Avg Reward: 7.8
Min Reward: 5
Max Reward: 13
Gini Coefficient: 0.2153846153846154
20:20 Ratio: 2.6
Max-min Ratio: 2.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-19-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -684.8963402134998
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 313
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.207
    dispatch_time_ms: 9.204
    learner:
      cur_lr: 0.0012557710288092494
      grad_gnorm: 11.911422729492188
      policy_entropy: 39.42305374145508
      policy_loss: 3.373176336288452
      var_gnorm: 26.018932342529297
      vf_explained_var: 0.0
      vf_loss: 9.321331977844238
    num_steps_sampled: 1570000
    num_steps_trained: 1570000
    wait_time_ms: 69.371
  iterations_since_restore: 314
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2754.8591141700745
  time_this_iter_s: 8.368664979934692
  time_total_s: 2754.8591141700745
  timestamp: 1594858763
  timesteps_since_restore: 1570000
  timesteps_this_iter: 5000
  timesteps_total: 1570000
  training_iteration: 314
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2754 s, 314 iter, 1570000 ts, -685 rew

agent-1: -103.33247250679474
agent-2: -73.29177647857614
agent-3: -242.03082371703368
agent-4: -20.555497455568656
agent-5: -104.42940948161623
Extrinsic Rewards:
8
6
16
2
6
Sum Reward: 38
Avg Reward: 7.6
Min Reward: 2
Max Reward: 16
Gini Coefficient: 0.3157894736842105
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-19-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -684.5873756779921
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 314
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.58
    dispatch_time_ms: 7.398
    learner:
      cur_lr: 0.0012554379645735025
      grad_gnorm: 26.633413314819336
      policy_entropy: 54.984352111816406
      policy_loss: -13.106242179870605
      var_gnorm: 26.00857925415039
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 4.944364547729492
    num_steps_sampled: 1575000
    num_steps_trained: 1575000
    wait_time_ms: 74.104
  iterations_since_restore: 315
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2763.060261964798
  time_this_iter_s: 8.20114779472351
  time_total_s: 2763.060261964798
  timestamp: 1594858772
  timesteps_since_restore: 1575000
  timesteps_this_iter: 5000
  timesteps_total: 1575000
  training_iteration: 315
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2763 s, 315 iter, 1575000 ts, -685 rew

agent-1: -173.17651038227666
agent-2: -135.50177612461104
agent-3: -162.69540270819266
agent-4: -85.09290548892263
agent-5: -102.58718976125849
Extrinsic Rewards:
5
22
8
13
6
Sum Reward: 54
Avg Reward: 10.8
Min Reward: 5
Max Reward: 22
Gini Coefficient: 0.3037037037037037
20:20 Ratio: 4.4
Max-min Ratio: 4.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-19-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -685.5918759119049
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 315
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.2
    dispatch_time_ms: 7.689
    learner:
      cur_lr: 0.0012551050167530775
      grad_gnorm: 29.694599151611328
      policy_entropy: 53.57199478149414
      policy_loss: 0.6973405480384827
      var_gnorm: 26.024333953857422
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 9.327966690063477
    num_steps_sampled: 1580000
    num_steps_trained: 1580000
    wait_time_ms: 70.709
  iterations_since_restore: 316
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2771.334461927414
  time_this_iter_s: 8.274199962615967
  time_total_s: 2771.334461927414
  timestamp: 1594858780
  timesteps_since_restore: 1580000
  timesteps_this_iter: 5000
  timesteps_total: 1580000
  training_iteration: 316
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2771 s, 316 iter, 1580000 ts, -686 rew

agent-1: -100.40905443118027
agent-2: -215.0315893754286
agent-3: -45.17366087609858
agent-4: -86.42296707058792
agent-5: -66.30947954046196
Extrinsic Rewards:
12
18
9
6
11
Sum Reward: 56
Avg Reward: 11.2
Min Reward: 6
Max Reward: 18
Gini Coefficient: 0.19285714285714287
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-19-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -684.3961333019778
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 316
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.815
    dispatch_time_ms: 7.682
    learner:
      cur_lr: 0.0012547719525173306
      grad_gnorm: 10.675126075744629
      policy_entropy: 50.11767578125
      policy_loss: -0.9564740061759949
      var_gnorm: 26.02894401550293
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.354698657989502
    num_steps_sampled: 1585000
    num_steps_trained: 1585000
    wait_time_ms: 73.126
  iterations_since_restore: 317
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2779.681832075119
  time_this_iter_s: 8.347370147705078
  time_total_s: 2779.681832075119
  timestamp: 1594858788
  timesteps_since_restore: 1585000
  timesteps_this_iter: 5000
  timesteps_total: 1585000
  training_iteration: 317
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2779 s, 317 iter, 1585000 ts, -684 rew

agent-1: -240.72717302765173
agent-2: -156.64767198252815
agent-3: -106.85333915570256
agent-4: -94.82219761536982
agent-5: -46.012128585285524
Extrinsic Rewards:
8
6
6
5
2
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 2
Max Reward: 8
Gini Coefficient: 0.1925925925925926
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-19-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -684.4147840987472
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 317
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.682
    dispatch_time_ms: 6.346
    learner:
      cur_lr: 0.0012544390046969056
      grad_gnorm: 10.296459197998047
      policy_entropy: 47.02384567260742
      policy_loss: -0.12288662791252136
      var_gnorm: 26.038103103637695
      vf_explained_var: 0.0
      vf_loss: 6.360507965087891
    num_steps_sampled: 1590000
    num_steps_trained: 1590000
    wait_time_ms: 73.828
  iterations_since_restore: 318
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2788.0497267246246
  time_this_iter_s: 8.367894649505615
  time_total_s: 2788.0497267246246
  timestamp: 1594858797
  timesteps_since_restore: 1590000
  timesteps_this_iter: 5000
  timesteps_total: 1590000
  training_iteration: 318
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2788 s, 318 iter, 1590000 ts, -684 rew

agent-1: -43.378482712954295
agent-2: -59.59387679887969
agent-3: -173.9242302770678
agent-4: -215.09004929284293
agent-5: -142.82847381228515
Extrinsic Rewards:
5
7
17
6
5
Sum Reward: 40
Avg Reward: 8.0
Min Reward: 5
Max Reward: 17
Gini Coefficient: 0.26
20:20 Ratio: 3.4
Max-min Ratio: 3.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-20-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -684.5670071247406
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 318
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.858
    dispatch_time_ms: 7.296
    learner:
      cur_lr: 0.0012541060568764806
      grad_gnorm: 14.658698081970215
      policy_entropy: 51.812435150146484
      policy_loss: -6.15673303604126
      var_gnorm: 26.051355361938477
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 2.040225028991699
    num_steps_sampled: 1595000
    num_steps_trained: 1595000
    wait_time_ms: 77.695
  iterations_since_restore: 319
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2796.442898273468
  time_this_iter_s: 8.393171548843384
  time_total_s: 2796.442898273468
  timestamp: 1594858805
  timesteps_since_restore: 1595000
  timesteps_this_iter: 5000
  timesteps_total: 1595000
  training_iteration: 319
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2796 s, 319 iter, 1595000 ts, -685 rew

agent-1: -186.56903716976583
agent-2: -96.07676679149827
agent-3: -103.35314598206573
agent-4: -100.32726103875193
agent-5: -214.54697866338702
Extrinsic Rewards:
8
2
2
4
2
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 2
Max Reward: 8
Gini Coefficient: 0.3111111111111111
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-20-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -683.7843178665133
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 319
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.345
    dispatch_time_ms: 6.829
    learner:
      cur_lr: 0.0012537729926407337
      grad_gnorm: 6.271785736083984
      policy_entropy: 56.34808349609375
      policy_loss: -1.2511451244354248
      var_gnorm: 26.056678771972656
      vf_explained_var: 0.0
      vf_loss: 1.9887919425964355
    num_steps_sampled: 1600000
    num_steps_trained: 1600000
    wait_time_ms: 72.951
  iterations_since_restore: 320
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2805.1536552906036
  time_this_iter_s: 8.71075701713562
  time_total_s: 2805.1536552906036
  timestamp: 1594858814
  timesteps_since_restore: 1600000
  timesteps_this_iter: 5000
  timesteps_total: 1600000
  training_iteration: 320
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2805 s, 320 iter, 1600000 ts, -684 rew

agent-1: -178.92915367959694
agent-2: -58.37407484376494
agent-3: -174.6445079711776
agent-4: -164.2220403146386
agent-5: -165.48520397884002
Extrinsic Rewards:
4
1
4
5
2
Sum Reward: 16
Avg Reward: 3.2
Min Reward: 1
Max Reward: 5
Gini Coefficient: 0.25
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-20-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -685.1713341897629
  episode_reward_min: -1181.1129802880462
  episodes_this_iter: 1
  episodes_total: 320
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.147
    dispatch_time_ms: 8.508
    learner:
      cur_lr: 0.0012534400448203087
      grad_gnorm: 15.483099937438965
      policy_entropy: 57.32053756713867
      policy_loss: 5.780856132507324
      var_gnorm: 26.016752243041992
      vf_explained_var: 0.0
      vf_loss: 8.616673469543457
    num_steps_sampled: 1605000
    num_steps_trained: 1605000
    wait_time_ms: 72.684
  iterations_since_restore: 321
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2813.4670379161835
  time_this_iter_s: 8.313382625579834
  time_total_s: 2813.4670379161835
  timestamp: 1594858822
  timesteps_since_restore: 1605000
  timesteps_this_iter: 5000
  timesteps_total: 1605000
  training_iteration: 321
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2813 s, 321 iter, 1605000 ts, -685 rew

agent-1: -330.70920358181024
agent-2: -112.55546221369202
agent-3: -305.886345513368
agent-4: -201.88692713236745
agent-5: -282.6008657075796
Extrinsic Rewards:
8
3
3
5
7
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 3
Max Reward: 8
Gini Coefficient: 0.2153846153846154
20:20 Ratio: 2.6666666666666665
Max-min Ratio: 2.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-20-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -690.8514848165452
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 321
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.722
    dispatch_time_ms: 8.11
    learner:
      cur_lr: 0.0012531069805845618
      grad_gnorm: 39.999996185302734
      policy_entropy: 59.15373992919922
      policy_loss: 61.59674072265625
      var_gnorm: 26.094161987304688
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 48.17616271972656
    num_steps_sampled: 1610000
    num_steps_trained: 1610000
    wait_time_ms: 72.567
  iterations_since_restore: 322
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2821.923929452896
  time_this_iter_s: 8.456891536712646
  time_total_s: 2821.923929452896
  timestamp: 1594858831
  timesteps_since_restore: 1610000
  timesteps_this_iter: 5000
  timesteps_total: 1610000
  training_iteration: 322
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2821 s, 322 iter, 1610000 ts, -691 rew

agent-1: -287.35115058500753
agent-2: -66.32539065648967
agent-3: -143.73279206087557
agent-4: -54.268138436200374
agent-5: -86.63988152314107
Extrinsic Rewards:
9
2
0
1
3
Sum Reward: 15
Avg Reward: 3.0
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.5333333333333333
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-20-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -689.8537739844916
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 322
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.939
    dispatch_time_ms: 6.188
    learner:
      cur_lr: 0.0012527740327641368
      grad_gnorm: 6.374893665313721
      policy_entropy: 57.884796142578125
      policy_loss: -1.1552706956863403
      var_gnorm: 26.055768966674805
      vf_explained_var: 0.0
      vf_loss: 3.64133882522583
    num_steps_sampled: 1615000
    num_steps_trained: 1615000
    wait_time_ms: 73.306
  iterations_since_restore: 323
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2830.2820179462433
  time_this_iter_s: 8.358088493347168
  time_total_s: 2830.2820179462433
  timestamp: 1594858839
  timesteps_since_restore: 1615000
  timesteps_this_iter: 5000
  timesteps_total: 1615000
  training_iteration: 323
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2830 s, 323 iter, 1615000 ts, -690 rew

agent-1: -78.84017213678699
agent-2: -167.19622247590448
agent-3: -77.46238911230053
agent-4: -126.4322490508891
agent-5: -239.5491965907989
Extrinsic Rewards:
2
6
1
3
7
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 1
Max Reward: 7
Gini Coefficient: 0.3368421052631579
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-20-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -691.4016164339492
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 323
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.603
    dispatch_time_ms: 7.612
    learner:
      cur_lr: 0.00125244096852839
      grad_gnorm: 40.000003814697266
      policy_entropy: 53.093666076660156
      policy_loss: 23.90378761291504
      var_gnorm: 26.05320167541504
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 26.164121627807617
    num_steps_sampled: 1620000
    num_steps_trained: 1620000
    wait_time_ms: 73.62
  iterations_since_restore: 324
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2838.6209692955017
  time_this_iter_s: 8.338951349258423
  time_total_s: 2838.6209692955017
  timestamp: 1594858848
  timesteps_since_restore: 1620000
  timesteps_this_iter: 5000
  timesteps_total: 1620000
  training_iteration: 324
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2838 s, 324 iter, 1620000 ts, -691 rew

agent-1: -16.69965171987145
agent-2: -127.48787695725021
agent-3: -213.96529661907266
agent-4: -97.42241097831223
agent-5: -169.7956370201965
Extrinsic Rewards:
5
8
11
11
11
Sum Reward: 46
Avg Reward: 9.2
Min Reward: 5
Max Reward: 11
Gini Coefficient: 0.13043478260869565
20:20 Ratio: 2.2
Max-min Ratio: 2.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-20-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -692.0256164047506
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 324
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.057
    dispatch_time_ms: 6.937
    learner:
      cur_lr: 0.001252108020707965
      grad_gnorm: 27.733840942382812
      policy_entropy: 44.05663299560547
      policy_loss: 7.4417314529418945
      var_gnorm: 26.036441802978516
      vf_explained_var: 0.0
      vf_loss: 8.596695899963379
    num_steps_sampled: 1625000
    num_steps_trained: 1625000
    wait_time_ms: 74.199
  iterations_since_restore: 325
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2847.03413772583
  time_this_iter_s: 8.41316843032837
  time_total_s: 2847.03413772583
  timestamp: 1594858856
  timesteps_since_restore: 1625000
  timesteps_this_iter: 5000
  timesteps_total: 1625000
  training_iteration: 325
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2847 s, 325 iter, 1625000 ts, -692 rew

agent-1: -23.19315513176327
agent-2: -141.88463553220075
agent-3: -244.96600527882364
agent-4: -134.23853655548183
agent-5: -116.87700910016915
Extrinsic Rewards:
1
6
4
5
4
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 1
Max Reward: 6
Gini Coefficient: 0.22
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-21-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -692.3595326789286
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 325
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.665
    dispatch_time_ms: 11.947
    learner:
      cur_lr: 0.001251774956472218
      grad_gnorm: 12.777844429016113
      policy_entropy: 48.366336822509766
      policy_loss: 5.490169525146484
      var_gnorm: 26.03760528564453
      vf_explained_var: 0.0
      vf_loss: 8.597478866577148
    num_steps_sampled: 1630000
    num_steps_trained: 1630000
    wait_time_ms: 73.007
  iterations_since_restore: 326
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2855.429408311844
  time_this_iter_s: 8.395270586013794
  time_total_s: 2855.429408311844
  timestamp: 1594858864
  timesteps_since_restore: 1630000
  timesteps_this_iter: 5000
  timesteps_total: 1630000
  training_iteration: 326
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2855 s, 326 iter, 1630000 ts, -692 rew

agent-1: -253.34858756770052
agent-2: -55.109143672744494
agent-3: -177.85612937412373
agent-4: -70.50616612834648
agent-5: -24.60067787678165
Extrinsic Rewards:
15
3
11
5
3
Sum Reward: 37
Avg Reward: 7.4
Min Reward: 3
Max Reward: 15
Gini Coefficient: 0.34594594594594597
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-21-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -690.1797014041352
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 326
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.762
    dispatch_time_ms: 10.568
    learner:
      cur_lr: 0.001251442008651793
      grad_gnorm: 19.15563201904297
      policy_entropy: 52.7974853515625
      policy_loss: -4.565889835357666
      var_gnorm: 26.049463272094727
      vf_explained_var: 0.0
      vf_loss: 3.3686270713806152
    num_steps_sampled: 1635000
    num_steps_trained: 1635000
    wait_time_ms: 70.849
  iterations_since_restore: 327
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2863.800562620163
  time_this_iter_s: 8.371154308319092
  time_total_s: 2863.800562620163
  timestamp: 1594858873
  timesteps_since_restore: 1635000
  timesteps_this_iter: 5000
  timesteps_total: 1635000
  training_iteration: 327
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2863 s, 327 iter, 1635000 ts, -690 rew

agent-1: -64.71064745757589
agent-2: -160.66354049020833
agent-3: -153.51984289803366
agent-4: -115.52960550969767
agent-5: -206.22642580809898
Extrinsic Rewards:
9
5
6
8
7
Sum Reward: 35
Avg Reward: 7.0
Min Reward: 5
Max Reward: 9
Gini Coefficient: 0.11428571428571428
20:20 Ratio: 1.8
Max-min Ratio: 1.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-21-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -690.6096186162275
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 327
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.189
    dispatch_time_ms: 6.609
    learner:
      cur_lr: 0.0012511089444160461
      grad_gnorm: 40.0
      policy_entropy: 48.08531188964844
      policy_loss: 27.179588317871094
      var_gnorm: 26.056652069091797
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 38.04137420654297
    num_steps_sampled: 1640000
    num_steps_trained: 1640000
    wait_time_ms: 75.536
  iterations_since_restore: 328
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2872.2191150188446
  time_this_iter_s: 8.41855239868164
  time_total_s: 2872.2191150188446
  timestamp: 1594858881
  timesteps_since_restore: 1640000
  timesteps_this_iter: 5000
  timesteps_total: 1640000
  training_iteration: 328
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2872 s, 328 iter, 1640000 ts, -691 rew

agent-1: -189.09723758505064
agent-2: -236.36477695428584
agent-3: -71.24389518784994
agent-4: -76.14953909694559
agent-5: -65.35509026583024
Extrinsic Rewards:
6
8
5
3
5
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 3
Max Reward: 8
Gini Coefficient: 0.16296296296296298
20:20 Ratio: 2.6666666666666665
Max-min Ratio: 2.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-21-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -690.7393526335575
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 328
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.755
    dispatch_time_ms: 7.6
    learner:
      cur_lr: 0.0012507759965956211
      grad_gnorm: 4.3417582511901855
      policy_entropy: 28.34424591064453
      policy_loss: -1.5955206155776978
      var_gnorm: 26.047487258911133
      vf_explained_var: 0.0
      vf_loss: 6.777554512023926
    num_steps_sampled: 1645000
    num_steps_trained: 1645000
    wait_time_ms: 75.543
  iterations_since_restore: 329
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2880.5901741981506
  time_this_iter_s: 8.37105917930603
  time_total_s: 2880.5901741981506
  timestamp: 1594858890
  timesteps_since_restore: 1645000
  timesteps_this_iter: 5000
  timesteps_total: 1645000
  training_iteration: 329
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2880 s, 329 iter, 1645000 ts, -691 rew

agent-1: -197.5191154993351
agent-2: -212.76413435859854
agent-3: -56.89282419019684
agent-4: -21.358050557998627
agent-5: -190.94919719713621
Extrinsic Rewards:
5
6
4
1
6
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 1
Max Reward: 6
Gini Coefficient: 0.21818181818181817
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-21-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -691.1402172015128
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 329
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.532
    dispatch_time_ms: 8.741
    learner:
      cur_lr: 0.001250443048775196
      grad_gnorm: 3.1487739086151123
      policy_entropy: 24.943878173828125
      policy_loss: 1.0890834331512451
      var_gnorm: 26.05316734313965
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.3062334060668945
    num_steps_sampled: 1650000
    num_steps_trained: 1650000
    wait_time_ms: 72.557
  iterations_since_restore: 330
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2889.044311285019
  time_this_iter_s: 8.454137086868286
  time_total_s: 2889.044311285019
  timestamp: 1594858898
  timesteps_since_restore: 1650000
  timesteps_this_iter: 5000
  timesteps_total: 1650000
  training_iteration: 330
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2889 s, 330 iter, 1650000 ts, -691 rew

agent-1: -35.52427689780313
agent-2: -250.59146841982928
agent-3: -145.80258872461982
agent-4: -114.10004906770585
agent-5: -99.53096190079383
Extrinsic Rewards:
1
9
3
3
3
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.3368421052631579
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-21-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -691.8643021284893
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 330
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.047
    dispatch_time_ms: 8.134
    learner:
      cur_lr: 0.0012501099845394492
      grad_gnorm: 17.48634910583496
      policy_entropy: 26.051254272460938
      policy_loss: -3.5844168663024902
      var_gnorm: 26.019723892211914
      vf_explained_var: 0.0
      vf_loss: 7.724328994750977
    num_steps_sampled: 1655000
    num_steps_trained: 1655000
    wait_time_ms: 72.151
  iterations_since_restore: 331
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2897.2762768268585
  time_this_iter_s: 8.2319655418396
  time_total_s: 2897.2762768268585
  timestamp: 1594858906
  timesteps_since_restore: 1655000
  timesteps_this_iter: 5000
  timesteps_total: 1655000
  training_iteration: 331
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2897 s, 331 iter, 1655000 ts, -692 rew

agent-1: -123.62717871405762
agent-2: -110.27036849137974
agent-3: -98.611037013236
agent-4: -77.63195957336934
agent-5: -99.56648537049918
Extrinsic Rewards:
25
25
16
14
16
Sum Reward: 96
Avg Reward: 19.2
Min Reward: 14
Max Reward: 25
Gini Coefficient: 0.12916666666666668
20:20 Ratio: 1.7857142857142858
Max-min Ratio: 1.7857142857142858
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-21-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -690.4717401353071
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 331
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.427
    dispatch_time_ms: 7.115
    learner:
      cur_lr: 0.0012497770367190242
      grad_gnorm: 17.257339477539062
      policy_entropy: 33.956363677978516
      policy_loss: 2.832545757293701
      var_gnorm: 26.026933670043945
      vf_explained_var: 0.0
      vf_loss: 10.839176177978516
    num_steps_sampled: 1660000
    num_steps_trained: 1660000
    wait_time_ms: 76.014
  iterations_since_restore: 332
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2905.6746838092804
  time_this_iter_s: 8.398406982421875
  time_total_s: 2905.6746838092804
  timestamp: 1594858915
  timesteps_since_restore: 1660000
  timesteps_this_iter: 5000
  timesteps_total: 1660000
  training_iteration: 332
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2905 s, 332 iter, 1660000 ts, -690 rew

agent-1: -82.16963821744628
agent-2: -82.49382768252313
agent-3: -168.79167176966016
agent-4: -48.18507788848778
agent-5: -206.16518674271128
Extrinsic Rewards:
4
10
13
8
6
Sum Reward: 41
Avg Reward: 8.2
Min Reward: 4
Max Reward: 13
Gini Coefficient: 0.2146341463414634
20:20 Ratio: 3.25
Max-min Ratio: 3.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-22-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -684.5386643554349
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 332
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.739
    dispatch_time_ms: 8.5
    learner:
      cur_lr: 0.0012494439724832773
      grad_gnorm: 13.659158706665039
      policy_entropy: 53.812171936035156
      policy_loss: -5.198553562164307
      var_gnorm: 26.065324783325195
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 4.624484539031982
    num_steps_sampled: 1665000
    num_steps_trained: 1665000
    wait_time_ms: 72.77
  iterations_since_restore: 333
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2913.9942905902863
  time_this_iter_s: 8.31960678100586
  time_total_s: 2913.9942905902863
  timestamp: 1594858923
  timesteps_since_restore: 1665000
  timesteps_this_iter: 5000
  timesteps_total: 1665000
  training_iteration: 333
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2913 s, 333 iter, 1665000 ts, -685 rew

agent-1: -86.2580335473458
agent-2: -142.36421701798355
agent-3: -71.21618798549044
agent-4: -206.32339157976472
agent-5: -143.01767421703275
Extrinsic Rewards:
4
11
14
12
11
Sum Reward: 52
Avg Reward: 10.4
Min Reward: 4
Max Reward: 14
Gini Coefficient: 0.16153846153846155
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-22-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -684.1182880934552
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 333
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.218
    dispatch_time_ms: 7.391
    learner:
      cur_lr: 0.0012491110246628523
      grad_gnorm: 4.6762285232543945
      policy_entropy: 50.32775115966797
      policy_loss: 0.22162789106369019
      var_gnorm: 26.085655212402344
      vf_explained_var: 0.0
      vf_loss: 4.433083534240723
    num_steps_sampled: 1670000
    num_steps_trained: 1670000
    wait_time_ms: 75.043
  iterations_since_restore: 334
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2922.370596408844
  time_this_iter_s: 8.37630581855774
  time_total_s: 2922.370596408844
  timestamp: 1594858932
  timesteps_since_restore: 1670000
  timesteps_this_iter: 5000
  timesteps_total: 1670000
  training_iteration: 334
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2922 s, 334 iter, 1670000 ts, -684 rew

agent-1: -164.91721483935672
agent-2: -122.54369196708056
agent-3: -197.68275546292597
agent-4: -33.13972073894915
agent-5: -185.82611022827854
Extrinsic Rewards:
9
5
9
4
8
Sum Reward: 35
Avg Reward: 7.0
Min Reward: 4
Max Reward: 9
Gini Coefficient: 0.16
20:20 Ratio: 2.25
Max-min Ratio: 2.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-22-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -684.9288318214826
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 334
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.849
    dispatch_time_ms: 10.812
    learner:
      cur_lr: 0.0012487779604271054
      grad_gnorm: 9.402844429016113
      policy_entropy: 50.06675338745117
      policy_loss: 2.776904821395874
      var_gnorm: 26.066131591796875
      vf_explained_var: 0.0
      vf_loss: 10.874870300292969
    num_steps_sampled: 1675000
    num_steps_trained: 1675000
    wait_time_ms: 68.993
  iterations_since_restore: 335
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2930.781323194504
  time_this_iter_s: 8.41072678565979
  time_total_s: 2930.781323194504
  timestamp: 1594858940
  timesteps_since_restore: 1675000
  timesteps_this_iter: 5000
  timesteps_total: 1675000
  training_iteration: 335
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2930 s, 335 iter, 1675000 ts, -685 rew

agent-1: -137.85661569858968
agent-2: -217.2340036940582
agent-3: -205.6718587675792
agent-4: -148.3198553986596
agent-5: -133.2128785727033
Extrinsic Rewards:
4
6
3
0
4
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 0
Max Reward: 6
Gini Coefficient: 0.3058823529411765
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-22-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -685.9460712364976
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 335
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.383
    dispatch_time_ms: 8.268
    learner:
      cur_lr: 0.0012484450126066804
      grad_gnorm: 9.086226463317871
      policy_entropy: 37.97913360595703
      policy_loss: 2.4624664783477783
      var_gnorm: 26.16218376159668
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 12.19247817993164
    num_steps_sampled: 1680000
    num_steps_trained: 1680000
    wait_time_ms: 74.169
  iterations_since_restore: 336
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2939.241103887558
  time_this_iter_s: 8.4597806930542
  time_total_s: 2939.241103887558
  timestamp: 1594858949
  timesteps_since_restore: 1680000
  timesteps_this_iter: 5000
  timesteps_total: 1680000
  training_iteration: 336
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2939 s, 336 iter, 1680000 ts, -686 rew

agent-1: -191.4804907236351
agent-2: -15.194349109096617
agent-3: -264.57070111058135
agent-4: -93.7934645102468
agent-5: -128.71003198866907
Extrinsic Rewards:
2
1
9
6
0
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.5111111111111111
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-22-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -685.8098204221952
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 336
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.589
    dispatch_time_ms: 7.877
    learner:
      cur_lr: 0.0012481119483709335
      grad_gnorm: 6.700474262237549
      policy_entropy: 42.42823791503906
      policy_loss: 1.5047619342803955
      var_gnorm: 26.08209800720215
      vf_explained_var: 0.0
      vf_loss: 9.54232406616211
    num_steps_sampled: 1685000
    num_steps_trained: 1685000
    wait_time_ms: 73.721
  iterations_since_restore: 337
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2947.539103746414
  time_this_iter_s: 8.297999858856201
  time_total_s: 2947.539103746414
  timestamp: 1594858957
  timesteps_since_restore: 1685000
  timesteps_this_iter: 5000
  timesteps_total: 1685000
  training_iteration: 337
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2947 s, 337 iter, 1685000 ts, -686 rew

agent-1: -72.5374508719956
agent-2: -100.65044627694972
agent-3: -166.3966690593834
agent-4: -196.53075669451138
agent-5: -141.58700593747912
Extrinsic Rewards:
3
9
10
17
9
Sum Reward: 48
Avg Reward: 9.6
Min Reward: 3
Max Reward: 17
Gini Coefficient: 0.24166666666666667
20:20 Ratio: 5.666666666666667
Max-min Ratio: 5.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-22-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -686.8661345642643
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 337
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.655
    dispatch_time_ms: 6.615
    learner:
      cur_lr: 0.0012477790005505085
      grad_gnorm: 39.999996185302734
      policy_entropy: 60.022315979003906
      policy_loss: 23.349836349487305
      var_gnorm: 26.082935333251953
      vf_explained_var: 0.0
      vf_loss: 12.263155937194824
    num_steps_sampled: 1690000
    num_steps_trained: 1690000
    wait_time_ms: 67.852
  iterations_since_restore: 338
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2955.9000408649445
  time_this_iter_s: 8.360937118530273
  time_total_s: 2955.9000408649445
  timestamp: 1594858965
  timesteps_since_restore: 1690000
  timesteps_this_iter: 5000
  timesteps_total: 1690000
  training_iteration: 338
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2955 s, 338 iter, 1690000 ts, -687 rew

agent-1: -27.376093846006086
agent-2: -172.94963878662014
agent-3: -19.61594507765071
agent-4: -177.10076652860334
agent-5: -218.40941695954933
Extrinsic Rewards:
5
9
4
4
17
Sum Reward: 39
Avg Reward: 7.8
Min Reward: 4
Max Reward: 17
Gini Coefficient: 0.31794871794871793
20:20 Ratio: 4.25
Max-min Ratio: 4.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-22-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -686.7413156896733
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 338
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.822
    dispatch_time_ms: 6.806
    learner:
      cur_lr: 0.0012474460527300835
      grad_gnorm: 16.791135787963867
      policy_entropy: 61.77225112915039
      policy_loss: -5.086465358734131
      var_gnorm: 26.082386016845703
      vf_explained_var: 0.0
      vf_loss: 2.2316715717315674
    num_steps_sampled: 1695000
    num_steps_trained: 1695000
    wait_time_ms: 76.636
  iterations_since_restore: 339
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2964.333338499069
  time_this_iter_s: 8.433297634124756
  time_total_s: 2964.333338499069
  timestamp: 1594858974
  timesteps_since_restore: 1695000
  timesteps_this_iter: 5000
  timesteps_total: 1695000
  training_iteration: 339
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2964 s, 339 iter, 1695000 ts, -687 rew

agent-1: -92.76853015837801
agent-2: -101.95099431257621
agent-3: -161.9333017913497
agent-4: -44.89635424827717
agent-5: -240.24814182400746
Extrinsic Rewards:
6
3
11
2
13
Sum Reward: 35
Avg Reward: 7.0
Min Reward: 2
Max Reward: 13
Gini Coefficient: 0.34285714285714286
20:20 Ratio: 6.5
Max-min Ratio: 6.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-23-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -684.0358382959649
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 339
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.497
    dispatch_time_ms: 8.326
    learner:
      cur_lr: 0.0012471129884943366
      grad_gnorm: 39.999996185302734
      policy_entropy: 60.49895477294922
      policy_loss: 17.96021842956543
      var_gnorm: 26.087034225463867
      vf_explained_var: 0.0
      vf_loss: 9.63232421875
    num_steps_sampled: 1700000
    num_steps_trained: 1700000
    wait_time_ms: 74.529
  iterations_since_restore: 340
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2972.677394390106
  time_this_iter_s: 8.344055891036987
  time_total_s: 2972.677394390106
  timestamp: 1594858982
  timesteps_since_restore: 1700000
  timesteps_this_iter: 5000
  timesteps_total: 1700000
  training_iteration: 340
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2972 s, 340 iter, 1700000 ts, -684 rew

agent-1: -122.54334280979135
agent-2: -207.75750669227298
agent-3: -146.27100132268546
agent-4: -177.2365702879393
agent-5: -76.10481783917638
Extrinsic Rewards:
4
5
4
3
2
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 2
Max Reward: 5
Gini Coefficient: 0.15555555555555556
20:20 Ratio: 2.5
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-23-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -683.8049946651353
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 340
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 4.254
    dispatch_time_ms: 6.167
    learner:
      cur_lr: 0.0012467800406739116
      grad_gnorm: 6.230776309967041
      policy_entropy: 55.85746383666992
      policy_loss: -2.4176321029663086
      var_gnorm: 26.089570999145508
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.7714554071426392
    num_steps_sampled: 1705000
    num_steps_trained: 1705000
    wait_time_ms: 68.819
  iterations_since_restore: 341
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2980.9302291870117
  time_this_iter_s: 8.252834796905518
  time_total_s: 2980.9302291870117
  timestamp: 1594858991
  timesteps_since_restore: 1705000
  timesteps_this_iter: 5000
  timesteps_total: 1705000
  training_iteration: 341
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2980 s, 341 iter, 1705000 ts, -684 rew

agent-1: -122.45252428632534
agent-2: -31.731097332315695
agent-3: -109.33583436082311
agent-4: -169.46875357228726
agent-5: -245.28596650759548
Extrinsic Rewards:
4
1
1
3
8
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.4
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-23-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -682.0603725033837
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 341
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.747
    dispatch_time_ms: 5.548
    learner:
      cur_lr: 0.0012464469764381647
      grad_gnorm: 6.3021674156188965
      policy_entropy: 55.5062255859375
      policy_loss: -1.7215710878372192
      var_gnorm: 26.092483520507812
      vf_explained_var: 0.0
      vf_loss: 1.755150318145752
    num_steps_sampled: 1710000
    num_steps_trained: 1710000
    wait_time_ms: 77.808
  iterations_since_restore: 342
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2989.323063135147
  time_this_iter_s: 8.392833948135376
  time_total_s: 2989.323063135147
  timestamp: 1594858999
  timesteps_since_restore: 1710000
  timesteps_this_iter: 5000
  timesteps_total: 1710000
  training_iteration: 342
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2989 s, 342 iter, 1710000 ts, -682 rew

agent-1: -128.8843374363642
agent-2: -194.69194148278012
agent-3: -126.89245599499864
agent-4: -92.61385896388862
agent-5: -181.34260116371252
Extrinsic Rewards:
5
3
7
3
6
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 3
Max Reward: 7
Gini Coefficient: 0.18333333333333332
20:20 Ratio: 2.3333333333333335
Max-min Ratio: 2.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-23-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -683.4284091494125
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 342
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.761
    dispatch_time_ms: 7.151
    learner:
      cur_lr: 0.0012461140286177397
      grad_gnorm: 10.362672805786133
      policy_entropy: 51.992435455322266
      policy_loss: -3.4428741931915283
      var_gnorm: 26.05447006225586
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 7.783059120178223
    num_steps_sampled: 1715000
    num_steps_trained: 1715000
    wait_time_ms: 73.316
  iterations_since_restore: 343
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 2997.618916749954
  time_this_iter_s: 8.295853614807129
  time_total_s: 2997.618916749954
  timestamp: 1594859007
  timesteps_since_restore: 1715000
  timesteps_this_iter: 5000
  timesteps_total: 1715000
  training_iteration: 343
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 2997 s, 343 iter, 1715000 ts, -683 rew

agent-1: -213.38074682144267
agent-2: -33.09763507190264
agent-3: -64.03065336527064
agent-4: -116.78583638133397
agent-5: -187.9721316569154
Extrinsic Rewards:
8
6
8
10
13
Sum Reward: 45
Avg Reward: 9.0
Min Reward: 6
Max Reward: 13
Gini Coefficient: 0.14222222222222222
20:20 Ratio: 2.1666666666666665
Max-min Ratio: 2.1666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-23-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -681.7887031224686
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 343
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.922
    dispatch_time_ms: 7.967
    learner:
      cur_lr: 0.0012457809643819928
      grad_gnorm: 17.043977737426758
      policy_entropy: 48.73090362548828
      policy_loss: -6.523284435272217
      var_gnorm: 26.054885864257812
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 9.571976661682129
    num_steps_sampled: 1720000
    num_steps_trained: 1720000
    wait_time_ms: 71.69
  iterations_since_restore: 344
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3005.9057672023773
  time_this_iter_s: 8.286850452423096
  time_total_s: 3005.9057672023773
  timestamp: 1594859016
  timesteps_since_restore: 1720000
  timesteps_this_iter: 5000
  timesteps_total: 1720000
  training_iteration: 344
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3005 s, 344 iter, 1720000 ts, -682 rew

agent-1: -57.64479340893643
agent-2: -260.15988655032396
agent-3: -146.78946047122875
agent-4: -29.602026973123362
agent-5: -35.2510395230207
Extrinsic Rewards:
2
7
10
2
4
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 2
Max Reward: 10
Gini Coefficient: 0.336
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-23-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -679.836712245748
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 344
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.482
    dispatch_time_ms: 8.047
    learner:
      cur_lr: 0.0012454480165615678
      grad_gnorm: 20.969751358032227
      policy_entropy: 61.92193603515625
      policy_loss: 1.8731704950332642
      var_gnorm: 26.04250717163086
      vf_explained_var: 0.0
      vf_loss: 10.54168701171875
    num_steps_sampled: 1725000
    num_steps_trained: 1725000
    wait_time_ms: 72.658
  iterations_since_restore: 345
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3014.078481197357
  time_this_iter_s: 8.172713994979858
  time_total_s: 3014.078481197357
  timestamp: 1594859024
  timesteps_since_restore: 1725000
  timesteps_this_iter: 5000
  timesteps_total: 1725000
  training_iteration: 345
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3014 s, 345 iter, 1725000 ts, -680 rew

agent-1: -205.78425015029737
agent-2: -58.90754794955591
agent-3: -183.03965735441034
agent-4: -54.270559205932045
agent-5: -61.248458641337976
Extrinsic Rewards:
31
11
15
3
10
Sum Reward: 70
Avg Reward: 14.0
Min Reward: 3
Max Reward: 31
Gini Coefficient: 0.3485714285714286
20:20 Ratio: 10.333333333333334
Max-min Ratio: 10.333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-23-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -678.5621907903586
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 345
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.208
    dispatch_time_ms: 10.98
    learner:
      cur_lr: 0.001245114952325821
      grad_gnorm: 20.464006423950195
      policy_entropy: 66.65573120117188
      policy_loss: 2.0680460929870605
      var_gnorm: 26.062387466430664
      vf_explained_var: 0.0
      vf_loss: 10.464468002319336
    num_steps_sampled: 1730000
    num_steps_trained: 1730000
    wait_time_ms: 69.351
  iterations_since_restore: 346
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3022.4362297058105
  time_this_iter_s: 8.35774850845337
  time_total_s: 3022.4362297058105
  timestamp: 1594859032
  timesteps_since_restore: 1730000
  timesteps_this_iter: 5000
  timesteps_total: 1730000
  training_iteration: 346
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3022 s, 346 iter, 1730000 ts, -679 rew

agent-1: -192.9208335476946
agent-2: -215.5081630636336
agent-3: -40.672941529485286
agent-4: -48.00894348265476
agent-5: -105.13159276532612
Extrinsic Rewards:
8
10
6
8
7
Sum Reward: 39
Avg Reward: 7.8
Min Reward: 6
Max Reward: 10
Gini Coefficient: 0.09230769230769231
20:20 Ratio: 1.6666666666666667
Max-min Ratio: 1.6666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-24-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -676.2310332294909
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 346
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.508
    dispatch_time_ms: 7.025
    learner:
      cur_lr: 0.0012447820045053959
      grad_gnorm: 20.408796310424805
      policy_entropy: 66.40187072753906
      policy_loss: -1.330209732055664
      var_gnorm: 26.08004379272461
      vf_explained_var: 0.0
      vf_loss: 8.263836860656738
    num_steps_sampled: 1735000
    num_steps_trained: 1735000
    wait_time_ms: 75.51
  iterations_since_restore: 347
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3030.8233020305634
  time_this_iter_s: 8.387072324752808
  time_total_s: 3030.8233020305634
  timestamp: 1594859041
  timesteps_since_restore: 1735000
  timesteps_this_iter: 5000
  timesteps_total: 1735000
  training_iteration: 347
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3030 s, 347 iter, 1735000 ts, -676 rew

agent-1: -139.46599832262677
agent-2: -188.54300996656687
agent-3: -101.75751356994297
agent-4: -238.49923030456858
agent-5: -140.0710369815465
Extrinsic Rewards:
0
7
1
8
3
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.4631578947368421
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-24-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -676.425354473899
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 347
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.093
    dispatch_time_ms: 20.364
    learner:
      cur_lr: 0.0012444490566849709
      grad_gnorm: 28.458105087280273
      policy_entropy: 61.745731353759766
      policy_loss: 8.260472297668457
      var_gnorm: 26.126256942749023
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 8.87769889831543
    num_steps_sampled: 1740000
    num_steps_trained: 1740000
    wait_time_ms: 35.122
  iterations_since_restore: 348
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3045.271585702896
  time_this_iter_s: 14.448283672332764
  time_total_s: 3045.271585702896
  timestamp: 1594859055
  timesteps_since_restore: 1740000
  timesteps_this_iter: 5000
  timesteps_total: 1740000
  training_iteration: 348
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3045 s, 348 iter, 1740000 ts, -676 rew

agent-1: -19.69841966223689
agent-2: -159.0991429422885
agent-3: -249.6371910080567
agent-4: -167.69399680780688
agent-5: -29.445966019380926
Extrinsic Rewards:
1
3
11
6
1
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 1
Max Reward: 11
Gini Coefficient: 0.45454545454545453
20:20 Ratio: 11.0
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-24-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -675.5249216753406
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 348
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.815
    dispatch_time_ms: 27.676
    learner:
      cur_lr: 0.001244115992449224
      grad_gnorm: 15.435850143432617
      policy_entropy: 70.11048889160156
      policy_loss: -7.233958721160889
      var_gnorm: 26.09389877319336
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1.9211618900299072
    num_steps_sampled: 1745000
    num_steps_trained: 1745000
    wait_time_ms: 61.163
  iterations_since_restore: 349
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3054.0071260929108
  time_this_iter_s: 8.735540390014648
  time_total_s: 3054.0071260929108
  timestamp: 1594859064
  timesteps_since_restore: 1745000
  timesteps_this_iter: 5000
  timesteps_total: 1745000
  training_iteration: 349
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3054 s, 349 iter, 1745000 ts, -676 rew

agent-1: -148.14548644685928
agent-2: -124.69398054510023
agent-3: -110.28046434068942
agent-4: -151.84899705645282
agent-5: -128.00144936559917
Extrinsic Rewards:
7
8
13
12
11
Sum Reward: 51
Avg Reward: 10.2
Min Reward: 7
Max Reward: 13
Gini Coefficient: 0.12549019607843137
20:20 Ratio: 1.8571428571428572
Max-min Ratio: 1.8571428571428572
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-24-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -673.8455292220601
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 349
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.666
    dispatch_time_ms: 53.131
    learner:
      cur_lr: 0.001243783044628799
      grad_gnorm: 40.0
      policy_entropy: 72.4315414428711
      policy_loss: 40.077919006347656
      var_gnorm: 26.117549896240234
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 33.619873046875
    num_steps_sampled: 1750000
    num_steps_trained: 1750000
    wait_time_ms: 35.683
  iterations_since_restore: 350
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3062.883512735367
  time_this_iter_s: 8.876386642456055
  time_total_s: 3062.883512735367
  timestamp: 1594859073
  timesteps_since_restore: 1750000
  timesteps_this_iter: 5000
  timesteps_total: 1750000
  training_iteration: 350
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3062 s, 350 iter, 1750000 ts, -674 rew

agent-1: -164.3442183587636
agent-2: -162.69836525205847
agent-3: -195.92078216320925
agent-4: -140.85389572061985
agent-5: -81.45891322497876
Extrinsic Rewards:
4
2
7
4
2
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 2
Max Reward: 7
Gini Coefficient: 0.25263157894736843
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-24-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -673.7571294710398
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 350
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.685
    dispatch_time_ms: 26.179
    learner:
      cur_lr: 0.001243449980393052
      grad_gnorm: 25.88483238220215
      policy_entropy: 56.629581451416016
      policy_loss: -11.747285842895508
      var_gnorm: 26.083881378173828
      vf_explained_var: 0.0
      vf_loss: 5.642179012298584
    num_steps_sampled: 1755000
    num_steps_trained: 1755000
    wait_time_ms: 58.476
  iterations_since_restore: 351
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3071.8632225990295
  time_this_iter_s: 8.97970986366272
  time_total_s: 3071.8632225990295
  timestamp: 1594859082
  timesteps_since_restore: 1755000
  timesteps_this_iter: 5000
  timesteps_total: 1755000
  training_iteration: 351
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3071 s, 351 iter, 1755000 ts, -674 rew

agent-1: -42.78135242754515
agent-2: -206.06025459801748
agent-3: -153.1495758236537
agent-4: -150.61592124397146
agent-5: -244.91974397666948
Extrinsic Rewards:
1
4
3
0
7
Sum Reward: 15
Avg Reward: 3.0
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.4533333333333333
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-24-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -676.0079719368385
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 351
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.201
    dispatch_time_ms: 17.15
    learner:
      cur_lr: 0.001243117032572627
      grad_gnorm: 40.0
      policy_entropy: 67.47615051269531
      policy_loss: 56.089046478271484
      var_gnorm: 26.114818572998047
      vf_explained_var: 0.0
      vf_loss: 35.71818161010742
    num_steps_sampled: 1760000
    num_steps_trained: 1760000
    wait_time_ms: 70.584
  iterations_since_restore: 352
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3080.7855920791626
  time_this_iter_s: 8.922369480133057
  time_total_s: 3080.7855920791626
  timestamp: 1594859091
  timesteps_since_restore: 1760000
  timesteps_this_iter: 5000
  timesteps_total: 1760000
  training_iteration: 352
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3080 s, 352 iter, 1760000 ts, -676 rew

agent-1: -22.729109072854463
agent-2: -54.60304915304978
agent-3: -218.6477967580885
agent-4: -40.47778852456164
agent-5: -246.01440550046937
Extrinsic Rewards:
2
5
9
3
9
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 2
Max Reward: 9
Gini Coefficient: 0.2857142857142857
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-25-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -673.6563308361501
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 352
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.771
    dispatch_time_ms: 23.268
    learner:
      cur_lr: 0.0012427839683368802
      grad_gnorm: 14.877483367919922
      policy_entropy: 70.42342376708984
      policy_loss: -2.9429919719696045
      var_gnorm: 26.086563110351562
      vf_explained_var: 0.0
      vf_loss: 5.512197017669678
    num_steps_sampled: 1765000
    num_steps_trained: 1765000
    wait_time_ms: 62.088
  iterations_since_restore: 353
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3089.699964761734
  time_this_iter_s: 8.914372682571411
  time_total_s: 3089.699964761734
  timestamp: 1594859100
  timesteps_since_restore: 1765000
  timesteps_this_iter: 5000
  timesteps_total: 1765000
  training_iteration: 353
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3089 s, 353 iter, 1765000 ts, -674 rew

agent-1: -95.52124967248217
agent-2: -172.9926051343223
agent-3: -80.37948701036113
agent-4: -140.98079569731772
agent-5: -261.45443201699203
Extrinsic Rewards:
3
6
1
0
11
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 0
Max Reward: 11
Gini Coefficient: 0.5142857142857142
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-25-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -674.024122521706
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 353
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.731
    dispatch_time_ms: 18.585
    learner:
      cur_lr: 0.0012424510205164552
      grad_gnorm: 40.0
      policy_entropy: 66.03384399414062
      policy_loss: 31.47837257385254
      var_gnorm: 26.128582000732422
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 25.511173248291016
    num_steps_sampled: 1770000
    num_steps_trained: 1770000
    wait_time_ms: 67.002
  iterations_since_restore: 354
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3098.573652744293
  time_this_iter_s: 8.873687982559204
  time_total_s: 3098.573652744293
  timestamp: 1594859109
  timesteps_since_restore: 1770000
  timesteps_this_iter: 5000
  timesteps_total: 1770000
  training_iteration: 354
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3098 s, 354 iter, 1770000 ts, -674 rew

agent-1: -142.23055099343523
agent-2: -38.995227936349764
agent-3: -142.24055839211536
agent-4: -247.20919978785525
agent-5: -107.08862763878487
Extrinsic Rewards:
3
1
3
9
4
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.34
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-25-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -673.9346692427661
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 354
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.245
    dispatch_time_ms: 67.67
    learner:
      cur_lr: 0.0012421179562807083
      grad_gnorm: 10.19096565246582
      policy_entropy: 58.4893798828125
      policy_loss: 4.335093021392822
      var_gnorm: 26.1033878326416
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 6.0398736000061035
    num_steps_sampled: 1775000
    num_steps_trained: 1775000
    wait_time_ms: 57.384
  iterations_since_restore: 355
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3107.787755250931
  time_this_iter_s: 9.214102506637573
  time_total_s: 3107.787755250931
  timestamp: 1594859118
  timesteps_since_restore: 1775000
  timesteps_this_iter: 5000
  timesteps_total: 1775000
  training_iteration: 355
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3107 s, 355 iter, 1775000 ts, -674 rew

agent-1: -137.6312311723127
agent-2: -59.67433420866103
agent-3: -220.12855232575544
agent-4: -166.2249164169329
agent-5: -120.41432849680345
Extrinsic Rewards:
4
4
9
3
3
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 3
Max Reward: 9
Gini Coefficient: 0.22608695652173913
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-25-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -673.7013742130113
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 355
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.703
    dispatch_time_ms: 9.505
    learner:
      cur_lr: 0.0012417850084602833
      grad_gnorm: 40.0
      policy_entropy: 56.92568588256836
      policy_loss: 25.964685440063477
      var_gnorm: 26.102563858032227
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 22.26827621459961
    num_steps_sampled: 1780000
    num_steps_trained: 1780000
    wait_time_ms: 70.837
  iterations_since_restore: 356
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3115.9120223522186
  time_this_iter_s: 8.124267101287842
  time_total_s: 3115.9120223522186
  timestamp: 1594859126
  timesteps_since_restore: 1780000
  timesteps_this_iter: 5000
  timesteps_total: 1780000
  training_iteration: 356
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3115 s, 356 iter, 1780000 ts, -674 rew

agent-1: -183.8501100037305
agent-2: -120.30436815665045
agent-3: -23.280596053332186
agent-4: -243.6247397240224
agent-5: -83.86961382740208
Extrinsic Rewards:
5
5
1
9
3
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.3130434782608696
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-25-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -672.2176095819985
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 356
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.619
    dispatch_time_ms: 9.153
    learner:
      cur_lr: 0.0012414519442245364
      grad_gnorm: 8.69790267944336
      policy_entropy: 47.85800552368164
      policy_loss: -3.73922061920166
      var_gnorm: 26.110260009765625
      vf_explained_var: 0.0
      vf_loss: 0.4704180955886841
    num_steps_sampled: 1785000
    num_steps_trained: 1785000
    wait_time_ms: 73.217
  iterations_since_restore: 357
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3124.3037416934967
  time_this_iter_s: 8.391719341278076
  time_total_s: 3124.3037416934967
  timestamp: 1594859134
  timesteps_since_restore: 1785000
  timesteps_this_iter: 5000
  timesteps_total: 1785000
  training_iteration: 357
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3124 s, 357 iter, 1785000 ts, -672 rew

agent-1: -142.14446750888234
agent-2: -182.71568960462093
agent-3: -157.6642440650276
agent-4: -148.520662053056
agent-5: -125.5907685221305
Extrinsic Rewards:
4
5
4
4
3
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 3
Max Reward: 5
Gini Coefficient: 0.08
20:20 Ratio: 1.6666666666666667
Max-min Ratio: 1.6666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-25-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -673.8243826000327
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 357
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.124
    dispatch_time_ms: 7.638
    learner:
      cur_lr: 0.0012411189964041114
      grad_gnorm: 40.0
      policy_entropy: 50.232357025146484
      policy_loss: 27.8134708404541
      var_gnorm: 26.112457275390625
      vf_explained_var: 0.0
      vf_loss: 11.55737018585205
    num_steps_sampled: 1790000
    num_steps_trained: 1790000
    wait_time_ms: 73.103
  iterations_since_restore: 358
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3132.7802987098694
  time_this_iter_s: 8.47655701637268
  time_total_s: 3132.7802987098694
  timestamp: 1594859143
  timesteps_since_restore: 1790000
  timesteps_this_iter: 5000
  timesteps_total: 1790000
  training_iteration: 358
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3132 s, 358 iter, 1790000 ts, -674 rew

agent-1: -244.64867543264003
agent-2: -98.48802161514999
agent-3: -85.21534749998965
agent-4: -65.53689680002381
agent-5: -175.4542596734199
Extrinsic Rewards:
9
4
3
2
4
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 2
Max Reward: 9
Gini Coefficient: 0.2727272727272727
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-25-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -673.5659473160684
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 358
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.324
    dispatch_time_ms: 6.873
    learner:
      cur_lr: 0.0012407860485836864
      grad_gnorm: 8.964591026306152
      policy_entropy: 61.360984802246094
      policy_loss: -0.727526843547821
      var_gnorm: 26.063602447509766
      vf_explained_var: 0.0
      vf_loss: 10.775883674621582
    num_steps_sampled: 1795000
    num_steps_trained: 1795000
    wait_time_ms: 75.049
  iterations_since_restore: 359
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3141.0972266197205
  time_this_iter_s: 8.316927909851074
  time_total_s: 3141.0972266197205
  timestamp: 1594859151
  timesteps_since_restore: 1795000
  timesteps_this_iter: 5000
  timesteps_total: 1795000
  training_iteration: 359
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3141 s, 359 iter, 1795000 ts, -674 rew

agent-1: -49.94202851948483
agent-2: -260.9713715543436
agent-3: -100.5344150880937
agent-4: -16.096420042517593
agent-5: -75.26855062278797
Extrinsic Rewards:
4
14
7
3
12
Sum Reward: 40
Avg Reward: 8.0
Min Reward: 3
Max Reward: 14
Gini Coefficient: 0.3
20:20 Ratio: 4.666666666666667
Max-min Ratio: 4.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-26-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -671.1440186422884
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 359
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.911
    dispatch_time_ms: 7.435
    learner:
      cur_lr: 0.0012404529843479395
      grad_gnorm: 17.79729461669922
      policy_entropy: 59.75513458251953
      policy_loss: -5.907352924346924
      var_gnorm: 26.059906005859375
      vf_explained_var: 0.0
      vf_loss: 10.82606029510498
    num_steps_sampled: 1800000
    num_steps_trained: 1800000
    wait_time_ms: 72.721
  iterations_since_restore: 360
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3149.495475769043
  time_this_iter_s: 8.39824914932251
  time_total_s: 3149.495475769043
  timestamp: 1594859160
  timesteps_since_restore: 1800000
  timesteps_this_iter: 5000
  timesteps_total: 1800000
  training_iteration: 360
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3149 s, 360 iter, 1800000 ts, -671 rew

agent-1: -106.39938641237973
agent-2: -196.90253994216417
agent-3: -31.41051463099077
agent-4: -191.8064608832618
agent-5: -57.663859548870775
Extrinsic Rewards:
9
13
7
12
12
Sum Reward: 53
Avg Reward: 10.6
Min Reward: 7
Max Reward: 13
Gini Coefficient: 0.11320754716981132
20:20 Ratio: 1.8571428571428572
Max-min Ratio: 1.8571428571428572
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-26-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -671.4412577531797
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 360
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.858
    dispatch_time_ms: 24.311
    learner:
      cur_lr: 0.0012401200365275145
      grad_gnorm: 2.3644254207611084
      policy_entropy: 62.947662353515625
      policy_loss: -1.4479882717132568
      var_gnorm: 26.075111389160156
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 7.7599778175354
    num_steps_sampled: 1805000
    num_steps_trained: 1805000
    wait_time_ms: 65.651
  iterations_since_restore: 361
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3158.2852668762207
  time_this_iter_s: 8.789791107177734
  time_total_s: 3158.2852668762207
  timestamp: 1594859169
  timesteps_since_restore: 1805000
  timesteps_this_iter: 5000
  timesteps_total: 1805000
  training_iteration: 361
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3158 s, 361 iter, 1805000 ts, -671 rew

agent-1: -144.13484636658183
agent-2: -17.277296038403282
agent-3: -257.83033417839715
agent-4: -125.43054565094144
agent-5: -53.06606861243107
Extrinsic Rewards:
5
1
9
2
3
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.38
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-26-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -669.5271317543006
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 361
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.991
    dispatch_time_ms: 58.19
    learner:
      cur_lr: 0.0012397869722917676
      grad_gnorm: 35.10446548461914
      policy_entropy: 60.50105285644531
      policy_loss: -10.754779815673828
      var_gnorm: 26.118423461914062
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 10.307479858398438
    num_steps_sampled: 1810000
    num_steps_trained: 1810000
    wait_time_ms: 44.839
  iterations_since_restore: 362
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3167.3307983875275
  time_this_iter_s: 9.045531511306763
  time_total_s: 3167.3307983875275
  timestamp: 1594859178
  timesteps_since_restore: 1810000
  timesteps_this_iter: 5000
  timesteps_total: 1810000
  training_iteration: 362
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3167 s, 362 iter, 1810000 ts, -670 rew

agent-1: -42.479325497468395
agent-2: -239.96576120230063
agent-3: -140.22393252722955
agent-4: -101.79503632918227
agent-5: -230.947090186469
Extrinsic Rewards:
1
7
0
2
10
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 0
Max Reward: 10
Gini Coefficient: 0.52
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-26-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -668.831114139758
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 362
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.208
    dispatch_time_ms: 28.846
    learner:
      cur_lr: 0.0012394540244713426
      grad_gnorm: 11.40664291381836
      policy_entropy: 56.15425109863281
      policy_loss: 0.2833654284477234
      var_gnorm: 26.074865341186523
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 11.30798053741455
    num_steps_sampled: 1815000
    num_steps_trained: 1815000
    wait_time_ms: 56.826
  iterations_since_restore: 363
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3176.2823214530945
  time_this_iter_s: 8.951523065567017
  time_total_s: 3176.2823214530945
  timestamp: 1594859187
  timesteps_since_restore: 1815000
  timesteps_this_iter: 5000
  timesteps_total: 1815000
  training_iteration: 363
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3176 s, 363 iter, 1815000 ts, -669 rew

agent-1: -29.00719977180224
agent-2: -50.562665227295746
agent-3: -60.35120258292846
agent-4: -244.94897137004463
agent-5: -137.42031236178704
Extrinsic Rewards:
1
6
5
2
7
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 1
Max Reward: 7
Gini Coefficient: 0.3047619047619048
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-26-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -667.0646782587522
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 363
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.851
    dispatch_time_ms: 28.361
    learner:
      cur_lr: 0.0012391209602355957
      grad_gnorm: 35.94037628173828
      policy_entropy: 53.83632278442383
      policy_loss: 6.2190656661987305
      var_gnorm: 26.062307357788086
      vf_explained_var: 0.0
      vf_loss: 11.3198881149292
    num_steps_sampled: 1820000
    num_steps_trained: 1820000
    wait_time_ms: 64.149
  iterations_since_restore: 364
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3185.2174797058105
  time_this_iter_s: 8.935158252716064
  time_total_s: 3185.2174797058105
  timestamp: 1594859196
  timesteps_since_restore: 1820000
  timesteps_this_iter: 5000
  timesteps_total: 1820000
  training_iteration: 364
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3185 s, 364 iter, 1820000 ts, -667 rew

agent-1: -41.22702911536231
agent-2: -234.44526883907173
agent-3: -238.14083386902092
agent-4: -16.325459650979315
agent-5: -46.469241151955025
Extrinsic Rewards:
3
5
9
1
5
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.3130434782608696
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-26-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -666.0823400224319
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 364
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.172
    dispatch_time_ms: 16.23
    learner:
      cur_lr: 0.0012387880124151707
      grad_gnorm: 14.885612487792969
      policy_entropy: 61.66383743286133
      policy_loss: -4.4035491943359375
      var_gnorm: 26.093355178833008
      vf_explained_var: 0.0
      vf_loss: 4.92054557800293
    num_steps_sampled: 1825000
    num_steps_trained: 1825000
    wait_time_ms: 68.117
  iterations_since_restore: 365
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3194.089511156082
  time_this_iter_s: 8.872031450271606
  time_total_s: 3194.089511156082
  timestamp: 1594859205
  timesteps_since_restore: 1825000
  timesteps_this_iter: 5000
  timesteps_total: 1825000
  training_iteration: 365
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3194 s, 365 iter, 1825000 ts, -666 rew

agent-1: -145.73566164423258
agent-2: -121.80110015634101
agent-3: -59.29454727219905
agent-4: -210.74434414852036
agent-5: -167.17366343341075
Extrinsic Rewards:
6
6
2
12
7
Sum Reward: 33
Avg Reward: 6.6
Min Reward: 2
Max Reward: 12
Gini Coefficient: 0.2545454545454545
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-26-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -666.5697903917012
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 365
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.882
    dispatch_time_ms: 25.462
    learner:
      cur_lr: 0.0012384549481794238
      grad_gnorm: 40.0
      policy_entropy: 59.246707916259766
      policy_loss: 64.53376770019531
      var_gnorm: 26.109642028808594
      vf_explained_var: 0.0
      vf_loss: 59.02473449707031
    num_steps_sampled: 1830000
    num_steps_trained: 1830000
    wait_time_ms: 60.1
  iterations_since_restore: 366
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3202.960411787033
  time_this_iter_s: 8.870900630950928
  time_total_s: 3202.960411787033
  timestamp: 1594859213
  timesteps_since_restore: 1830000
  timesteps_this_iter: 5000
  timesteps_total: 1830000
  training_iteration: 366
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3202 s, 366 iter, 1830000 ts, -667 rew

agent-1: -132.8787218206376
agent-2: -179.90902389066068
agent-3: -238.16829565725982
agent-4: -64.61259008193406
agent-5: -46.95404077794104
Extrinsic Rewards:
3
6
14
1
1
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 1
Max Reward: 14
Gini Coefficient: 0.496
20:20 Ratio: 14.0
Max-min Ratio: 14.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-27-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -666.388010798642
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 366
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.921
    dispatch_time_ms: 25.327
    learner:
      cur_lr: 0.0012381220003589988
      grad_gnorm: 16.098369598388672
      policy_entropy: 63.73819351196289
      policy_loss: -2.9737462997436523
      var_gnorm: 26.101512908935547
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 6.536930561065674
    num_steps_sampled: 1835000
    num_steps_trained: 1835000
    wait_time_ms: 63.808
  iterations_since_restore: 367
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3211.844465970993
  time_this_iter_s: 8.884054183959961
  time_total_s: 3211.844465970993
  timestamp: 1594859222
  timesteps_since_restore: 1835000
  timesteps_this_iter: 5000
  timesteps_total: 1835000
  training_iteration: 367
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3211 s, 367 iter, 1835000 ts, -666 rew

agent-1: -206.2626694374576
agent-2: -195.8763279458859
agent-3: -172.93912283080257
agent-4: -55.86558590499113
agent-5: -65.68511246576354
Extrinsic Rewards:
6
9
5
1
4
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.288
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-27-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -665.3173934498149
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 367
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.496
    dispatch_time_ms: 7.64
    learner:
      cur_lr: 0.0012377890525385737
      grad_gnorm: 40.0
      policy_entropy: 48.14084243774414
      policy_loss: 16.945552825927734
      var_gnorm: 26.1485595703125
      vf_explained_var: 0.0
      vf_loss: 14.876766204833984
    num_steps_sampled: 1840000
    num_steps_trained: 1840000
    wait_time_ms: 71.767
  iterations_since_restore: 368
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3220.5269989967346
  time_this_iter_s: 8.682533025741577
  time_total_s: 3220.5269989967346
  timestamp: 1594859231
  timesteps_since_restore: 1840000
  timesteps_this_iter: 5000
  timesteps_total: 1840000
  training_iteration: 368
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3220 s, 368 iter, 1840000 ts, -665 rew

agent-1: -183.0095607085467
agent-2: -74.00324439530232
agent-3: -233.74598497975762
agent-4: -132.4782010649895
agent-5: -164.75055698698196
Extrinsic Rewards:
5
5
9
0
3
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.36363636363636365
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-27-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -664.8973329737574
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 368
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.006
    dispatch_time_ms: 8.66
    learner:
      cur_lr: 0.0012374559883028269
      grad_gnorm: 18.755298614501953
      policy_entropy: 65.75354766845703
      policy_loss: -7.723911285400391
      var_gnorm: 26.08852195739746
      vf_explained_var: 0.0
      vf_loss: 3.993511915206909
    num_steps_sampled: 1845000
    num_steps_trained: 1845000
    wait_time_ms: 72.096
  iterations_since_restore: 369
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3229.019331216812
  time_this_iter_s: 8.492332220077515
  time_total_s: 3229.019331216812
  timestamp: 1594859240
  timesteps_since_restore: 1845000
  timesteps_this_iter: 5000
  timesteps_total: 1845000
  training_iteration: 369
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3229 s, 369 iter, 1845000 ts, -665 rew

agent-1: -94.68405133847516
agent-2: -213.08488908246076
agent-3: -67.15152610242686
agent-4: -128.29610293569743
agent-5: -183.4616928107722
Extrinsic Rewards:
8
8
3
7
2
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 2
Max Reward: 8
Gini Coefficient: 0.24285714285714285
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-27-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -665.1925559781905
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 369
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.97
    dispatch_time_ms: 8.664
    learner:
      cur_lr: 0.0012371230404824018
      grad_gnorm: 40.0
      policy_entropy: 66.65978240966797
      policy_loss: 56.0
      var_gnorm: 26.15144920349121
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 36.530338287353516
    num_steps_sampled: 1850000
    num_steps_trained: 1850000
    wait_time_ms: 71.976
  iterations_since_restore: 370
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3237.239030599594
  time_this_iter_s: 8.219699382781982
  time_total_s: 3237.239030599594
  timestamp: 1594859248
  timesteps_since_restore: 1850000
  timesteps_this_iter: 5000
  timesteps_total: 1850000
  training_iteration: 370
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3237 s, 370 iter, 1850000 ts, -665 rew

agent-1: -150.67647327888497
agent-2: -284.259319063757
agent-3: -146.24502889267444
agent-4: -146.24502889267444
agent-5: -59.68455280765221
Extrinsic Rewards:
3
11
0
0
2
Sum Reward: 16
Avg Reward: 3.2
Min Reward: 0
Max Reward: 11
Gini Coefficient: 0.625
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-27-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -665.5792721823734
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 370
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.756
    dispatch_time_ms: 8.354
    learner:
      cur_lr: 0.001236789976246655
      grad_gnorm: 11.219573974609375
      policy_entropy: 55.45904541015625
      policy_loss: -2.501147985458374
      var_gnorm: 26.122825622558594
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.2618869543075562
    num_steps_sampled: 1855000
    num_steps_trained: 1855000
    wait_time_ms: 76.28
  iterations_since_restore: 371
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3245.6166110038757
  time_this_iter_s: 8.377580404281616
  time_total_s: 3245.6166110038757
  timestamp: 1594859257
  timesteps_since_restore: 1855000
  timesteps_this_iter: 5000
  timesteps_total: 1855000
  training_iteration: 371
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3245 s, 371 iter, 1855000 ts, -666 rew

agent-1: -199.5976956914585
agent-2: -220.23956719945141
agent-3: -60.154804931722516
agent-4: -164.8135862021411
agent-5: -49.3949943189093
Extrinsic Rewards:
4
7
1
5
1
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 1
Max Reward: 7
Gini Coefficient: 0.35555555555555557
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-27-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -432.0525311751596
  episode_reward_mean: -666.7418731596538
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 371
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.959
    dispatch_time_ms: 7.515
    learner:
      cur_lr: 0.00123645702842623
      grad_gnorm: 4.755584239959717
      policy_entropy: 58.26873016357422
      policy_loss: -1.122658610343933
      var_gnorm: 26.119836807250977
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.2732999324798584
    num_steps_sampled: 1860000
    num_steps_trained: 1860000
    wait_time_ms: 74.128
  iterations_since_restore: 372
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3254.0055618286133
  time_this_iter_s: 8.388950824737549
  time_total_s: 3254.0055618286133
  timestamp: 1594859265
  timesteps_since_restore: 1860000
  timesteps_this_iter: 5000
  timesteps_total: 1860000
  training_iteration: 372
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3254 s, 372 iter, 1860000 ts, -667 rew

agent-1: -155.7725399637751
agent-2: -204.24923785222217
agent-3: -117.88663765223617
agent-4: -105.54580686462123
agent-5: -148.33001077573894
Extrinsic Rewards:
4
6
5
1
7
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 1
Max Reward: 7
Gini Coefficient: 0.24347826086956523
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-27-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -502.81278582721365
  episode_reward_mean: -669.7391901789881
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 372
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.66
    dispatch_time_ms: 6.834
    learner:
      cur_lr: 0.001236123964190483
      grad_gnorm: 15.724163055419922
      policy_entropy: 62.381649017333984
      policy_loss: -2.302920341491699
      var_gnorm: 26.09980010986328
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.093058109283447
    num_steps_sampled: 1865000
    num_steps_trained: 1865000
    wait_time_ms: 73.003
  iterations_since_restore: 373
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3262.3347611427307
  time_this_iter_s: 8.329199314117432
  time_total_s: 3262.3347611427307
  timestamp: 1594859273
  timesteps_since_restore: 1865000
  timesteps_this_iter: 5000
  timesteps_total: 1865000
  training_iteration: 373
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3262 s, 373 iter, 1865000 ts, -670 rew

agent-1: -136.97924050772696
agent-2: -64.27896684743737
agent-3: -245.0774205009573
agent-4: -173.14338836665692
agent-5: -162.52979594664703
Extrinsic Rewards:
0
1
11
3
3
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 0
Max Reward: 11
Gini Coefficient: 0.5333333333333333
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-28-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -502.81278582721365
  episode_reward_mean: -671.1373792939163
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 373
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.682
    dispatch_time_ms: 8.329
    learner:
      cur_lr: 0.001235791016370058
      grad_gnorm: 40.000003814697266
      policy_entropy: 67.5985336303711
      policy_loss: 43.23884201049805
      var_gnorm: 26.15477180480957
      vf_explained_var: 0.0
      vf_loss: 35.6477165222168
    num_steps_sampled: 1870000
    num_steps_trained: 1870000
    wait_time_ms: 72.335
  iterations_since_restore: 374
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3270.722132921219
  time_this_iter_s: 8.38737177848816
  time_total_s: 3270.722132921219
  timestamp: 1594859282
  timesteps_since_restore: 1870000
  timesteps_this_iter: 5000
  timesteps_total: 1870000
  training_iteration: 374
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3270 s, 374 iter, 1870000 ts, -671 rew

agent-1: -191.90261051724576
agent-2: -109.26433575588356
agent-3: -49.26703697484368
agent-4: -107.3967367576954
agent-5: -208.90090562241588
Extrinsic Rewards:
9
4
9
5
7
Sum Reward: 34
Avg Reward: 6.8
Min Reward: 4
Max Reward: 9
Gini Coefficient: 0.16470588235294117
20:20 Ratio: 2.25
Max-min Ratio: 2.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-28-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -502.81278582721365
  episode_reward_mean: -671.3666508163409
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 374
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.495
    dispatch_time_ms: 7.269
    learner:
      cur_lr: 0.0012354579521343112
      grad_gnorm: 9.646037101745605
      policy_entropy: 64.88714599609375
      policy_loss: -0.17464497685432434
      var_gnorm: 26.1009464263916
      vf_explained_var: 0.0
      vf_loss: 5.4271650314331055
    num_steps_sampled: 1875000
    num_steps_trained: 1875000
    wait_time_ms: 74.288
  iterations_since_restore: 375
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3279.023843050003
  time_this_iter_s: 8.30171012878418
  time_total_s: 3279.023843050003
  timestamp: 1594859290
  timesteps_since_restore: 1875000
  timesteps_this_iter: 5000
  timesteps_total: 1875000
  training_iteration: 375
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3279 s, 375 iter, 1875000 ts, -671 rew

agent-1: -37.01052689672761
agent-2: -6.138976648685437
agent-3: -144.6982386395892
agent-4: -228.79191604366363
agent-5: -177.81910074310247
Extrinsic Rewards:
5
1
14
5
10
Sum Reward: 35
Avg Reward: 7.0
Min Reward: 1
Max Reward: 14
Gini Coefficient: 0.35428571428571426
20:20 Ratio: 14.0
Max-min Ratio: 14.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-28-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -502.81278582721365
  episode_reward_mean: -669.9714884333775
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 375
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.559
    dispatch_time_ms: 7.017
    learner:
      cur_lr: 0.0012351250043138862
      grad_gnorm: 39.999996185302734
      policy_entropy: 61.743221282958984
      policy_loss: 26.766267776489258
      var_gnorm: 26.097145080566406
      vf_explained_var: 0.0
      vf_loss: 18.641700744628906
    num_steps_sampled: 1880000
    num_steps_trained: 1880000
    wait_time_ms: 72.412
  iterations_since_restore: 376
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3287.42932844162
  time_this_iter_s: 8.405485391616821
  time_total_s: 3287.42932844162
  timestamp: 1594859299
  timesteps_since_restore: 1880000
  timesteps_this_iter: 5000
  timesteps_total: 1880000
  training_iteration: 376
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3287 s, 376 iter, 1880000 ts, -670 rew

agent-1: -249.11122841658374
agent-2: -88.18533448787383
agent-3: -189.2405067433609
agent-4: -66.41991194547671
agent-5: -70.20165700521446
Extrinsic Rewards:
7
2
4
2
2
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 2
Max Reward: 7
Gini Coefficient: 0.2823529411764706
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-28-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -502.81278582721365
  episode_reward_mean: -670.6617004540337
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 376
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.72
    dispatch_time_ms: 8.721
    learner:
      cur_lr: 0.0012347920564934611
      grad_gnorm: 11.821680068969727
      policy_entropy: 48.657535552978516
      policy_loss: -5.450644493103027
      var_gnorm: 26.116621017456055
      vf_explained_var: 0.0
      vf_loss: 3.556499719619751
    num_steps_sampled: 1885000
    num_steps_trained: 1885000
    wait_time_ms: 71.958
  iterations_since_restore: 377
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3300.6944811344147
  time_this_iter_s: 13.2651526927948
  time_total_s: 3300.6944811344147
  timestamp: 1594859312
  timesteps_since_restore: 1885000
  timesteps_this_iter: 5000
  timesteps_total: 1885000
  training_iteration: 377
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3300 s, 377 iter, 1885000 ts, -671 rew

agent-1: -90.23903845210369
agent-2: -131.480032927233
agent-3: -205.10220148342756
agent-4: -81.04355461894139
agent-5: -191.72286657330602
Extrinsic Rewards:
5
2
9
5
7
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 2
Max Reward: 9
Gini Coefficient: 0.22857142857142856
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-28-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -502.81278582721365
  episode_reward_mean: -670.9288189656239
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 377
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.706
    dispatch_time_ms: 9.428
    learner:
      cur_lr: 0.0012344589922577143
      grad_gnorm: 34.331756591796875
      policy_entropy: 40.7426872253418
      policy_loss: -12.26697063446045
      var_gnorm: 26.170679092407227
      vf_explained_var: 0.0
      vf_loss: 4.9863080978393555
    num_steps_sampled: 1890000
    num_steps_trained: 1890000
    wait_time_ms: 70.658
  iterations_since_restore: 378
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3309.058249235153
  time_this_iter_s: 8.363768100738525
  time_total_s: 3309.058249235153
  timestamp: 1594859320
  timesteps_since_restore: 1890000
  timesteps_this_iter: 5000
  timesteps_total: 1890000
  training_iteration: 378
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3309 s, 378 iter, 1890000 ts, -671 rew

agent-1: -203.9791676816536
agent-2: -179.80940150112986
agent-3: -146.78165931995477
agent-4: -108.8092997423994
agent-5: -206.27380083090046
Extrinsic Rewards:
4
6
0
2
5
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 0
Max Reward: 6
Gini Coefficient: 0.35294117647058826
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-28-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -502.81278582721365
  episode_reward_mean: -671.6987989741191
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 378
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.63
    dispatch_time_ms: 9.272
    learner:
      cur_lr: 0.0012341260444372892
      grad_gnorm: 14.026606559753418
      policy_entropy: 52.04692840576172
      policy_loss: -2.225719690322876
      var_gnorm: 26.117572784423828
      vf_explained_var: 0.0
      vf_loss: 5.968583106994629
    num_steps_sampled: 1895000
    num_steps_trained: 1895000
    wait_time_ms: 71.335
  iterations_since_restore: 379
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3317.426507472992
  time_this_iter_s: 8.368258237838745
  time_total_s: 3317.426507472992
  timestamp: 1594859329
  timesteps_since_restore: 1895000
  timesteps_this_iter: 5000
  timesteps_total: 1895000
  training_iteration: 379
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3317 s, 379 iter, 1895000 ts, -672 rew

agent-1: -118.93544026076611
agent-2: -35.506866733541386
agent-3: -221.14757915655102
agent-4: -72.03836499342532
agent-5: -211.11971691951186
Extrinsic Rewards:
2
1
8
4
3
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.35555555555555557
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-28-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -502.81278582721365
  episode_reward_mean: -671.6630542596255
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 379
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.735
    dispatch_time_ms: 12.331
    learner:
      cur_lr: 0.0012337929802015424
      grad_gnorm: 34.18994903564453
      policy_entropy: 45.88013458251953
      policy_loss: -12.316960334777832
      var_gnorm: 26.155778884887695
      vf_explained_var: 0.0
      vf_loss: 8.741625785827637
    num_steps_sampled: 1900000
    num_steps_trained: 1900000
    wait_time_ms: 68.952
  iterations_since_restore: 380
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3325.792538166046
  time_this_iter_s: 8.3660306930542
  time_total_s: 3325.792538166046
  timestamp: 1594859337
  timesteps_since_restore: 1900000
  timesteps_this_iter: 5000
  timesteps_total: 1900000
  training_iteration: 380
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3325 s, 380 iter, 1900000 ts, -672 rew

agent-1: -41.181641247280766
agent-2: -167.3090004585622
agent-3: -225.05726363506128
agent-4: -210.34688099054466
agent-5: -128.01835192570593
Extrinsic Rewards:
3
6
12
8
0
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 0
Max Reward: 12
Gini Coefficient: 0.4
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-29-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -502.81278582721365
  episode_reward_mean: -672.5128506223597
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 380
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.738
    dispatch_time_ms: 8.888
    learner:
      cur_lr: 0.0012334600323811173
      grad_gnorm: 25.37847137451172
      policy_entropy: 39.336631774902344
      policy_loss: 3.4405975341796875
      var_gnorm: 26.107166290283203
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.779414176940918
    num_steps_sampled: 1905000
    num_steps_trained: 1905000
    wait_time_ms: 72.808
  iterations_since_restore: 381
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3334.2083854675293
  time_this_iter_s: 8.415847301483154
  time_total_s: 3334.2083854675293
  timestamp: 1594859345
  timesteps_since_restore: 1905000
  timesteps_this_iter: 5000
  timesteps_total: 1905000
  training_iteration: 381
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3334 s, 381 iter, 1905000 ts, -673 rew

agent-1: -30.121131483190894
agent-2: -244.83977819591186
agent-3: -91.7303184690602
agent-4: -45.7036841625709
agent-5: -207.2174852105179
Extrinsic Rewards:
3
7
6
4
4
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 3
Max Reward: 7
Gini Coefficient: 0.16666666666666666
20:20 Ratio: 2.3333333333333335
Max-min Ratio: 2.3333333333333335
agent-1: -109.49329758178072
agent-2: -27.735236911770638
agent-3: -144.5085275338254
agent-4: -168.8151353242139
agent-5: -196.43057078650017
Extrinsic Rewards:
15
4
9
4
9
Sum Reward: 41
Avg Reward: 8.2
Min Reward: 4
Max Reward: 15
Gini Coefficient: 0.2634146341463415
20:20 Ratio: 3.75
Max-min Ratio: 3.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-29-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -502.81278582721365
  episode_reward_mean: -671.5675003142586
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 2
  episodes_total: 382
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.519
    dispatch_time_ms: 6.739
    learner:
      cur_lr: 0.0012331269681453705
      grad_gnorm: 17.363439559936523
      policy_entropy: 43.184654235839844
      policy_loss: 4.493766784667969
      var_gnorm: 26.104602813720703
      vf_explained_var: -1.0
      vf_loss: 22.61396598815918
    num_steps_sampled: 1910000
    num_steps_trained: 1910000
    wait_time_ms: 77.76
  iterations_since_restore: 382
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3342.607600212097
  time_this_iter_s: 8.399214744567871
  time_total_s: 3342.607600212097
  timestamp: 1594859354
  timesteps_since_restore: 1910000
  timesteps_this_iter: 5000
  timesteps_total: 1910000
  training_iteration: 382
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3342 s, 382 iter, 1910000 ts, -672 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-29-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -502.81278582721365
  episode_reward_mean: -671.5675003142588
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 0
  episodes_total: 382
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.542
    dispatch_time_ms: 6.607
    learner:
      cur_lr: 0.0012327940203249454
      grad_gnorm: 9.648141860961914
      policy_entropy: 44.10249710083008
      policy_loss: -2.3393607139587402
      var_gnorm: 26.093427658081055
      vf_explained_var: 0.0
      vf_loss: 7.4582343101501465
    num_steps_sampled: 1915000
    num_steps_trained: 1915000
    wait_time_ms: 74.838
  iterations_since_restore: 383
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3350.8621954917908
  time_this_iter_s: 8.254595279693604
  time_total_s: 3350.8621954917908
  timestamp: 1594859362
  timesteps_since_restore: 1915000
  timesteps_this_iter: 5000
  timesteps_total: 1915000
  training_iteration: 383
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3350 s, 383 iter, 1915000 ts, -672 rew

agent-1: -146.01390820700288
agent-2: -144.4881865476599
agent-3: -146.01390820700288
agent-4: -186.01448278248114
agent-5: -261.81481649533526
Extrinsic Rewards:
0
3
0
6
9
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.5333333333333333
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: -231.55940845545635
agent-2: -109.77948928104767
agent-3: -61.77729217881919
agent-4: -133.81456290823903
agent-5: -221.88450826242047
Extrinsic Rewards:
11
6
1
0
4
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 0
Max Reward: 11
Gini Coefficient: 0.4909090909090909
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-29-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -502.81278582721365
  episode_reward_mean: -675.4976770528351
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 2
  episodes_total: 384
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.187
    dispatch_time_ms: 10.052
    learner:
      cur_lr: 0.0012324609560891986
      grad_gnorm: 40.0
      policy_entropy: 40.51356506347656
      policy_loss: 733.2500610351562
      var_gnorm: 26.211776733398438
      vf_explained_var: 2.980232238769531e-07
      vf_loss: 7981.767578125
    num_steps_sampled: 1920000
    num_steps_trained: 1920000
    wait_time_ms: 70.139
  iterations_since_restore: 384
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3359.208040714264
  time_this_iter_s: 8.345845222473145
  time_total_s: 3359.208040714264
  timestamp: 1594859371
  timesteps_since_restore: 1920000
  timesteps_this_iter: 5000
  timesteps_total: 1920000
  training_iteration: 384
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3359 s, 384 iter, 1920000 ts, -675 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-29-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -502.81278582721365
  episode_reward_mean: -675.4976770528349
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 0
  episodes_total: 384
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.101
    dispatch_time_ms: 9.213
    learner:
      cur_lr: 0.0012321280082687736
      grad_gnorm: 5.116467475891113
      policy_entropy: 39.571659088134766
      policy_loss: 1.9987943172454834
      var_gnorm: 26.1398868560791
      vf_explained_var: 0.0
      vf_loss: 1.591349482536316
    num_steps_sampled: 1925000
    num_steps_trained: 1925000
    wait_time_ms: 71.822
  iterations_since_restore: 385
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3367.6775319576263
  time_this_iter_s: 8.469491243362427
  time_total_s: 3367.6775319576263
  timestamp: 1594859379
  timesteps_since_restore: 1925000
  timesteps_this_iter: 5000
  timesteps_total: 1925000
  training_iteration: 385
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3367 s, 385 iter, 1925000 ts, -675 rew

agent-1: -173.6204715894884
agent-2: -144.6648420972867
agent-3: -218.38488081327986
agent-4: -110.37117482434383
agent-5: -190.24185728871223
Extrinsic Rewards:
3
0
7
4
4
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.3333333333333333
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: -144.90849759917845
agent-2: -180.84329031809
agent-3: -155.05592786673787
agent-4: -78.02355058508036
agent-5: -180.33325698463474
Extrinsic Rewards:
4
5
6
3
3
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 3
Max Reward: 6
Gini Coefficient: 0.1523809523809524
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-29-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -502.81278582721365
  episode_reward_mean: -675.7960929458864
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 2
  episodes_total: 386
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.775
    dispatch_time_ms: 30.353
    learner:
      cur_lr: 0.0012317949440330267
      grad_gnorm: 39.999996185302734
      policy_entropy: 36.58879852294922
      policy_loss: 12.006200790405273
      var_gnorm: 26.17683219909668
      vf_explained_var: -0.43866586685180664
      vf_loss: 25.479501724243164
    num_steps_sampled: 1930000
    num_steps_trained: 1930000
    wait_time_ms: 56.513
  iterations_since_restore: 386
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3376.202020406723
  time_this_iter_s: 8.52448844909668
  time_total_s: 3376.202020406723
  timestamp: 1594859388
  timesteps_since_restore: 1930000
  timesteps_this_iter: 5000
  timesteps_total: 1930000
  training_iteration: 386
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3376 s, 386 iter, 1930000 ts, -676 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-29-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -502.81278582721365
  episode_reward_mean: -675.7960929458862
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 0
  episodes_total: 386
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.027
    dispatch_time_ms: 26.17
    learner:
      cur_lr: 0.0012314619962126017
      grad_gnorm: 9.585489273071289
      policy_entropy: 41.87373352050781
      policy_loss: 0.9600669741630554
      var_gnorm: 26.119430541992188
      vf_explained_var: 0.0
      vf_loss: 7.577428817749023
    num_steps_sampled: 1935000
    num_steps_trained: 1935000
    wait_time_ms: 50.639
  iterations_since_restore: 387
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3385.005304336548
  time_this_iter_s: 8.803283929824829
  time_total_s: 3385.005304336548
  timestamp: 1594859397
  timesteps_since_restore: 1935000
  timesteps_this_iter: 5000
  timesteps_total: 1935000
  training_iteration: 387
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3385 s, 387 iter, 1935000 ts, -676 rew

agent-1: -125.55248381002714
agent-2: -232.99251628681935
agent-3: -204.1011955016507
agent-4: -122.42285968182938
agent-5: -67.17070916154528
Extrinsic Rewards:
0
8
5
9
5
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.3111111111111111
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: -114.76391520951348
agent-2: -215.32416556089353
agent-3: -33.651743129057635
agent-4: -170.93384504376294
agent-5: -175.71749110573415
Extrinsic Rewards:
3
6
1
3
5
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 1
Max Reward: 6
Gini Coefficient: 0.26666666666666666
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-30-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -502.81278582721365
  episode_reward_mean: -677.7116060347157
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 2
  episodes_total: 388
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.705
    dispatch_time_ms: 19.639
    learner:
      cur_lr: 0.0012311290483921766
      grad_gnorm: 39.999996185302734
      policy_entropy: 32.94452667236328
      policy_loss: 598.1851806640625
      var_gnorm: 26.148935317993164
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 5814.53662109375
    num_steps_sampled: 1940000
    num_steps_trained: 1940000
    wait_time_ms: 66.589
  iterations_since_restore: 388
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3393.900688648224
  time_this_iter_s: 8.895384311676025
  time_total_s: 3393.900688648224
  timestamp: 1594859405
  timesteps_since_restore: 1940000
  timesteps_this_iter: 5000
  timesteps_total: 1940000
  training_iteration: 388
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3393 s, 388 iter, 1940000 ts, -678 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-30-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -502.81278582721365
  episode_reward_mean: -677.7116060347158
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 0
  episodes_total: 388
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.075
    dispatch_time_ms: 28.855
    learner:
      cur_lr: 0.0012307959841564298
      grad_gnorm: 23.25592613220215
      policy_entropy: 25.859128952026367
      policy_loss: 10.66626262664795
      var_gnorm: 26.11332893371582
      vf_explained_var: 0.0
      vf_loss: 8.11884593963623
    num_steps_sampled: 1945000
    num_steps_trained: 1945000
    wait_time_ms: 69.91
  iterations_since_restore: 389
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3402.8685624599457
  time_this_iter_s: 8.967873811721802
  time_total_s: 3402.8685624599457
  timestamp: 1594859414
  timesteps_since_restore: 1945000
  timesteps_this_iter: 5000
  timesteps_total: 1945000
  training_iteration: 389
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3402 s, 389 iter, 1945000 ts, -678 rew

agent-1: -108.8825638783443
agent-2: -198.06219974922234
agent-3: -171.75668071808116
agent-4: -174.10726487889073
agent-5: -65.51080317345775
Extrinsic Rewards:
4
10
4
4
1
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 1
Max Reward: 10
Gini Coefficient: 0.3130434782608696
20:20 Ratio: 10.0
Max-min Ratio: 10.0
agent-1: -39.136999481729404
agent-2: -83.2656486261358
agent-3: -278.49429529198494
agent-4: -103.2502498672355
agent-5: -46.14010174960798
Extrinsic Rewards:
1
2
10
3
1
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 1
Max Reward: 10
Gini Coefficient: 0.47058823529411764
20:20 Ratio: 10.0
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-30-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -502.81278582721365
  episode_reward_mean: -674.8089598431474
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 2
  episodes_total: 390
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 6.396
    dispatch_time_ms: 28.549
    learner:
      cur_lr: 0.0012304630363360047
      grad_gnorm: 40.0
      policy_entropy: 12.374068260192871
      policy_loss: 153.134521484375
      var_gnorm: 26.103965759277344
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 4063.005859375
    num_steps_sampled: 1950000
    num_steps_trained: 1950000
    wait_time_ms: 59.837
  iterations_since_restore: 390
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3411.999482154846
  time_this_iter_s: 9.130919694900513
  time_total_s: 3411.999482154846
  timestamp: 1594859424
  timesteps_since_restore: 1950000
  timesteps_this_iter: 5000
  timesteps_total: 1950000
  training_iteration: 390
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3411 s, 390 iter, 1950000 ts, -675 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-30-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -502.81278582721365
  episode_reward_mean: -674.8089598431474
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 0
  episodes_total: 390
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.254
    dispatch_time_ms: 19.961
    learner:
      cur_lr: 0.0012301299721002579
      grad_gnorm: 29.24186134338379
      policy_entropy: 29.053255081176758
      policy_loss: -2.1739540100097656
      var_gnorm: 26.070146560668945
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 4.533941268920898
    num_steps_sampled: 1955000
    num_steps_trained: 1955000
    wait_time_ms: 67.443
  iterations_since_restore: 391
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3420.6721205711365
  time_this_iter_s: 8.672638416290283
  time_total_s: 3420.6721205711365
  timestamp: 1594859432
  timesteps_since_restore: 1955000
  timesteps_this_iter: 5000
  timesteps_total: 1955000
  training_iteration: 391
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3420 s, 391 iter, 1955000 ts, -675 rew

agent-1: -132.01964644612025
agent-2: -83.65961966918309
agent-3: -87.68713187027207
agent-4: -142.18841929437315
agent-5: -156.80832275514044
Extrinsic Rewards:
2
10
13
14
7
Sum Reward: 46
Avg Reward: 9.2
Min Reward: 2
Max Reward: 14
Gini Coefficient: 0.2608695652173913
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-30-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -502.81278582721365
  episode_reward_mean: -673.7358664117185
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 391
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.681
    dispatch_time_ms: 26.07
    learner:
      cur_lr: 0.0012297970242798328
      grad_gnorm: 39.999996185302734
      policy_entropy: 38.36859893798828
      policy_loss: 24.015195846557617
      var_gnorm: 26.09552001953125
      vf_explained_var: -0.18913185596466064
      vf_loss: 48.49916458129883
    num_steps_sampled: 1960000
    num_steps_trained: 1960000
    wait_time_ms: 52.901
  iterations_since_restore: 392
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3429.440175294876
  time_this_iter_s: 8.768054723739624
  time_total_s: 3429.440175294876
  timestamp: 1594859441
  timesteps_since_restore: 1960000
  timesteps_this_iter: 5000
  timesteps_total: 1960000
  training_iteration: 392
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3429 s, 392 iter, 1960000 ts, -674 rew

agent-1: -153.28319032477023
agent-2: -111.29624458229341
agent-3: -58.7070156972735
agent-4: -132.87782124844415
agent-5: -97.04598130484617
Extrinsic Rewards:
14
25
15
13
19
Sum Reward: 86
Avg Reward: 17.2
Min Reward: 13
Max Reward: 25
Gini Coefficient: 0.13488372093023257
20:20 Ratio: 1.9230769230769231
Max-min Ratio: 1.9230769230769231
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-30-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -502.81278582721365
  episode_reward_mean: -672.2238854416514
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 392
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.652
    dispatch_time_ms: 28.724
    learner:
      cur_lr: 0.001229463960044086
      grad_gnorm: 18.49061393737793
      policy_entropy: 43.14143753051758
      policy_loss: -2.3695757389068604
      var_gnorm: 26.10870933532715
      vf_explained_var: 0.0
      vf_loss: 4.2972540855407715
    num_steps_sampled: 1965000
    num_steps_trained: 1965000
    wait_time_ms: 56.174
  iterations_since_restore: 393
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3438.2878947257996
  time_this_iter_s: 8.847719430923462
  time_total_s: 3438.2878947257996
  timestamp: 1594859450
  timesteps_since_restore: 1965000
  timesteps_this_iter: 5000
  timesteps_total: 1965000
  training_iteration: 393
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3438 s, 393 iter, 1965000 ts, -672 rew

agent-1: -154.13082803396696
agent-2: -95.01265927774851
agent-3: -26.777385079163967
agent-4: -217.18225139180834
agent-5: -202.57794807977362
Extrinsic Rewards:
3
3
1
5
6
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 1
Max Reward: 6
Gini Coefficient: 0.26666666666666666
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-30-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -502.81278582721365
  episode_reward_mean: -673.5552426562658
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 393
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.907
    dispatch_time_ms: 21.458
    learner:
      cur_lr: 0.001229131012223661
      grad_gnorm: 39.999996185302734
      policy_entropy: 39.53543472290039
      policy_loss: 24.267208099365234
      var_gnorm: 26.160160064697266
      vf_explained_var: -0.450464129447937
      vf_loss: 29.459413528442383
    num_steps_sampled: 1970000
    num_steps_trained: 1970000
    wait_time_ms: 63.619
  iterations_since_restore: 394
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3447.158713579178
  time_this_iter_s: 8.870818853378296
  time_total_s: 3447.158713579178
  timestamp: 1594859459
  timesteps_since_restore: 1970000
  timesteps_this_iter: 5000
  timesteps_total: 1970000
  training_iteration: 394
  
agent-1: -201.45122939245385
agent-2: -77.84634367743904
agent-3: -185.8948140932982
agent-4: -220.0488801388953
agent-5: -148.13253143678642
Extrinsic Rewards:
5
1
4
6
0
Sum Reward: 16
Avg Reward: 3.2
Min Reward: 0
Max Reward: 6
Gini Coefficient: 0.4
20:20 Ratio: Undefined
Max-min Ratio: Undefined
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3447 s, 394 iter, 1970000 ts, -674 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-31-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -502.81278582721365
  episode_reward_mean: -676.1196051207688
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 394
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.574
    dispatch_time_ms: 29.584
    learner:
      cur_lr: 0.001228797947987914
      grad_gnorm: 23.018442153930664
      policy_entropy: 37.64933395385742
      policy_loss: 7.882078170776367
      var_gnorm: 26.087785720825195
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 10.529500961303711
    num_steps_sampled: 1975000
    num_steps_trained: 1975000
    wait_time_ms: 55.202
  iterations_since_restore: 395
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3455.9530940055847
  time_this_iter_s: 8.79438042640686
  time_total_s: 3455.9530940055847
  timestamp: 1594859468
  timesteps_since_restore: 1975000
  timesteps_this_iter: 5000
  timesteps_total: 1975000
  training_iteration: 395
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3455 s, 395 iter, 1975000 ts, -676 rew

agent-1: -69.17380659807245
agent-2: -23.520437301285494
agent-3: -53.87247622335832
agent-4: -250.3026671575139
agent-5: -90.14060298430046
Extrinsic Rewards:
7
5
5
11
7
Sum Reward: 35
Avg Reward: 7.0
Min Reward: 5
Max Reward: 11
Gini Coefficient: 0.16
20:20 Ratio: 2.2
Max-min Ratio: 2.2
agent-1: -265.0242097684758
agent-2: -122.20117108380273
agent-3: -56.82829088114633
agent-4: -134.0545871637617
agent-5: -31.047278906405204
Extrinsic Rewards:
4
0
6
8
3
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.3619047619047619
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-31-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -675.7941407509143
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 2
  episodes_total: 396
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.917
    dispatch_time_ms: 14.812
    learner:
      cur_lr: 0.001228465000167489
      grad_gnorm: 40.0
      policy_entropy: 41.943031311035156
      policy_loss: 407.79913330078125
      var_gnorm: 26.07929039001465
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3216.343017578125
    num_steps_sampled: 1980000
    num_steps_trained: 1980000
    wait_time_ms: 77.769
  iterations_since_restore: 396
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3464.821857690811
  time_this_iter_s: 8.86876368522644
  time_total_s: 3464.821857690811
  timestamp: 1594859477
  timesteps_since_restore: 1980000
  timesteps_this_iter: 5000
  timesteps_total: 1980000
  training_iteration: 396
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3464 s, 396 iter, 1980000 ts, -676 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-31-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -675.7941407509144
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 0
  episodes_total: 396
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.757
    dispatch_time_ms: 6.147
    learner:
      cur_lr: 0.001228132052347064
      grad_gnorm: 20.6965274810791
      policy_entropy: 36.11344909667969
      policy_loss: 1.7636799812316895
      var_gnorm: 26.076467514038086
      vf_explained_var: 0.0
      vf_loss: 8.62181568145752
    num_steps_sampled: 1985000
    num_steps_trained: 1985000
    wait_time_ms: 76.438
  iterations_since_restore: 397
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3473.0793232917786
  time_this_iter_s: 8.257465600967407
  time_total_s: 3473.0793232917786
  timestamp: 1594859485
  timesteps_since_restore: 1985000
  timesteps_this_iter: 5000
  timesteps_total: 1985000
  training_iteration: 397
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3473 s, 397 iter, 1985000 ts, -676 rew

agent-1: -244.42299892825687
agent-2: -66.1073308429176
agent-3: -34.45720251866033
agent-4: -201.24076045504816
agent-5: -43.931267107884274
Extrinsic Rewards:
11
1
5
15
2
Sum Reward: 34
Avg Reward: 6.8
Min Reward: 1
Max Reward: 15
Gini Coefficient: 0.43529411764705883
20:20 Ratio: 15.0
Max-min Ratio: 15.0
agent-1: -106.24866262312764
agent-2: -138.0681285399629
agent-3: -38.60894336425364
agent-4: -232.81911188540695
agent-5: -81.0460287616727
Extrinsic Rewards:
5
13
6
10
5
Sum Reward: 39
Avg Reward: 7.8
Min Reward: 5
Max Reward: 13
Gini Coefficient: 0.2153846153846154
20:20 Ratio: 2.6
Max-min Ratio: 2.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-31-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -675.1904949779648
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 2
  episodes_total: 398
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.856
    dispatch_time_ms: 10.177
    learner:
      cur_lr: 0.0012277989881113172
      grad_gnorm: 40.000003814697266
      policy_entropy: 26.92868995666504
      policy_loss: 399.4908142089844
      var_gnorm: 26.085546493530273
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3483.18359375
    num_steps_sampled: 1990000
    num_steps_trained: 1990000
    wait_time_ms: 70.489
  iterations_since_restore: 398
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3481.389150619507
  time_this_iter_s: 8.309827327728271
  time_total_s: 3481.389150619507
  timestamp: 1594859493
  timesteps_since_restore: 1990000
  timesteps_this_iter: 5000
  timesteps_total: 1990000
  training_iteration: 398
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3481 s, 398 iter, 1990000 ts, -675 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-31-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -675.1904949779648
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 0
  episodes_total: 398
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.409
    dispatch_time_ms: 9.032
    learner:
      cur_lr: 0.0012274660402908921
      grad_gnorm: 8.103575706481934
      policy_entropy: 46.19919967651367
      policy_loss: -0.9868766665458679
      var_gnorm: 26.06357765197754
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 4.675778865814209
    num_steps_sampled: 1995000
    num_steps_trained: 1995000
    wait_time_ms: 69.713
  iterations_since_restore: 399
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3489.5046162605286
  time_this_iter_s: 8.115465641021729
  time_total_s: 3489.5046162605286
  timestamp: 1594859501
  timesteps_since_restore: 1995000
  timesteps_this_iter: 5000
  timesteps_total: 1995000
  training_iteration: 399
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3489 s, 399 iter, 1995000 ts, -675 rew

agent-1: -21.410179659608353
agent-2: -246.7309700013801
agent-3: -59.31237376313171
agent-4: -110.67744475030773
agent-5: -76.17087661053576
Extrinsic Rewards:
1
12
6
16
4
Sum Reward: 39
Avg Reward: 7.8
Min Reward: 1
Max Reward: 16
Gini Coefficient: 0.38974358974358975
20:20 Ratio: 16.0
Max-min Ratio: 16.0
agent-1: -138.5985243611014
agent-2: -131.901754812612
agent-3: -134.44126780335765
agent-4: -74.00832297413595
agent-5: -123.16737758746682
Extrinsic Rewards:
20
16
22
12
16
Sum Reward: 86
Avg Reward: 17.2
Min Reward: 12
Max Reward: 22
Gini Coefficient: 0.11162790697674418
20:20 Ratio: 1.8333333333333333
Max-min Ratio: 1.8333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-31-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -671.641701992638
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 2
  episodes_total: 400
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.633
    dispatch_time_ms: 6.492
    learner:
      cur_lr: 0.0012271329760551453
      grad_gnorm: 29.46116828918457
      policy_entropy: 48.850250244140625
      policy_loss: 5.005131721496582
      var_gnorm: 26.076683044433594
      vf_explained_var: -1.0
      vf_loss: 18.578279495239258
    num_steps_sampled: 2000000
    num_steps_trained: 2000000
    wait_time_ms: 73.432
  iterations_since_restore: 400
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3497.8478829860687
  time_this_iter_s: 8.343266725540161
  time_total_s: 3497.8478829860687
  timestamp: 1594859510
  timesteps_since_restore: 2000000
  timesteps_this_iter: 5000
  timesteps_total: 2000000
  training_iteration: 400
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3497 s, 400 iter, 2000000 ts, -672 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-31-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -671.641701992638
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 0
  episodes_total: 400
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.724
    dispatch_time_ms: 10.541
    learner:
      cur_lr: 0.0012268000282347202
      grad_gnorm: 14.934480667114258
      policy_entropy: 40.307952880859375
      policy_loss: -2.2685868740081787
      var_gnorm: 26.09644889831543
      vf_explained_var: 0.0
      vf_loss: 4.524164199829102
    num_steps_sampled: 2005000
    num_steps_trained: 2005000
    wait_time_ms: 71.709
  iterations_since_restore: 401
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3506.196043252945
  time_this_iter_s: 8.34816026687622
  time_total_s: 3506.196043252945
  timestamp: 1594859518
  timesteps_since_restore: 2005000
  timesteps_this_iter: 5000
  timesteps_total: 2005000
  training_iteration: 401
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3506 s, 401 iter, 2005000 ts, -672 rew

agent-1: -140.6458790737506
agent-2: -144.2830899954401
agent-3: -260.0394571257804
agent-4: -92.06677879906103
agent-5: -143.68078789237146
Extrinsic Rewards:
3
0
8
3
3
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.3764705882352941
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-32-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -674.0024185618081
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 401
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.563
    dispatch_time_ms: 7.803
    learner:
      cur_lr: 0.0012264669639989734
      grad_gnorm: 11.819839477539062
      policy_entropy: 45.67851257324219
      policy_loss: 6.074400901794434
      var_gnorm: 26.153392791748047
      vf_explained_var: 0.0
      vf_loss: 2.288661003112793
    num_steps_sampled: 2010000
    num_steps_trained: 2010000
    wait_time_ms: 75.3
  iterations_since_restore: 402
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3514.5217192173004
  time_this_iter_s: 8.325675964355469
  time_total_s: 3514.5217192173004
  timestamp: 1594859527
  timesteps_since_restore: 2010000
  timesteps_this_iter: 5000
  timesteps_total: 2010000
  training_iteration: 402
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3514 s, 402 iter, 2010000 ts, -674 rew

agent-1: -141.92485130341703
agent-2: -149.36399871310584
agent-3: -170.14821220199215
agent-4: -75.31645254659334
agent-5: -175.98496777260138
Extrinsic Rewards:
4
7
4
8
7
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 4
Max Reward: 8
Gini Coefficient: 0.14666666666666667
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-32-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -675.1701937096816
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 402
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.909
    dispatch_time_ms: 5.127
    learner:
      cur_lr: 0.0012261340161785483
      grad_gnorm: 5.637048244476318
      policy_entropy: 46.62512969970703
      policy_loss: -0.08593135327100754
      var_gnorm: 26.112627029418945
      vf_explained_var: 0.0
      vf_loss: 5.418849945068359
    num_steps_sampled: 2015000
    num_steps_trained: 2015000
    wait_time_ms: 72.261
  iterations_since_restore: 403
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3522.8752088546753
  time_this_iter_s: 8.353489637374878
  time_total_s: 3522.8752088546753
  timestamp: 1594859535
  timesteps_since_restore: 2015000
  timesteps_this_iter: 5000
  timesteps_total: 2015000
  training_iteration: 403
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3522 s, 403 iter, 2015000 ts, -675 rew

agent-1: -241.71596899671636
agent-2: -129.2609577052516
agent-3: -106.97905281980461
agent-4: -165.22332680881016
agent-5: -119.00812095895786
Extrinsic Rewards:
5
0
2
8
7
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.38181818181818183
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-32-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -677.2226390862801
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 403
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.657
    dispatch_time_ms: 8.79
    learner:
      cur_lr: 0.0012258009519428015
      grad_gnorm: 40.0
      policy_entropy: 43.83869552612305
      policy_loss: -25.774784088134766
      var_gnorm: 26.203529357910156
      vf_explained_var: 0.0
      vf_loss: 14.751612663269043
    num_steps_sampled: 2020000
    num_steps_trained: 2020000
    wait_time_ms: 73.58
  iterations_since_restore: 404
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3531.262724161148
  time_this_iter_s: 8.387515306472778
  time_total_s: 3531.262724161148
  timestamp: 1594859543
  timesteps_since_restore: 2020000
  timesteps_this_iter: 5000
  timesteps_total: 2020000
  training_iteration: 404
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3531 s, 404 iter, 2020000 ts, -677 rew

agent-1: -141.02607259039408
agent-2: -186.5243016288323
agent-3: -146.28863251780987
agent-4: -210.04131491096783
agent-5: -172.95358344535464
Extrinsic Rewards:
3
7
0
4
4
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.3333333333333333
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-32-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -679.1185667097354
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 404
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.762
    dispatch_time_ms: 6.842
    learner:
      cur_lr: 0.0012254680041223764
      grad_gnorm: 15.077491760253906
      policy_entropy: 42.0474853515625
      policy_loss: 4.423758506774902
      var_gnorm: 26.137325286865234
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 7.9740376472473145
    num_steps_sampled: 2025000
    num_steps_trained: 2025000
    wait_time_ms: 71.579
  iterations_since_restore: 405
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3539.795197725296
  time_this_iter_s: 8.53247356414795
  time_total_s: 3539.795197725296
  timestamp: 1594859552
  timesteps_since_restore: 2025000
  timesteps_this_iter: 5000
  timesteps_total: 2025000
  training_iteration: 405
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3539 s, 405 iter, 2025000 ts, -679 rew

agent-1: -19.428316889492148
agent-2: -54.277948256970845
agent-3: -223.07343370298622
agent-4: -155.5270303612227
agent-5: -214.00710728360963
Extrinsic Rewards:
1
2
8
5
10
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 1
Max Reward: 10
Gini Coefficient: 0.36923076923076925
20:20 Ratio: 10.0
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-32-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -679.3623696525652
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 405
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.799
    dispatch_time_ms: 6.219
    learner:
      cur_lr: 0.0012251350563019514
      grad_gnorm: 39.99999237060547
      policy_entropy: 30.422658920288086
      policy_loss: 30.011072158813477
      var_gnorm: 26.117822647094727
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 22.60727310180664
    num_steps_sampled: 2030000
    num_steps_trained: 2030000
    wait_time_ms: 72.154
  iterations_since_restore: 406
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3548.1052799224854
  time_this_iter_s: 8.310082197189331
  time_total_s: 3548.1052799224854
  timestamp: 1594859560
  timesteps_since_restore: 2030000
  timesteps_this_iter: 5000
  timesteps_total: 2030000
  training_iteration: 406
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3548 s, 406 iter, 2030000 ts, -679 rew

agent-1: -202.91100052069928
agent-2: -103.3465106198706
agent-3: -207.21330147549082
agent-4: -150.4329161855981
agent-5: -36.63569051946063
Extrinsic Rewards:
5
4
4
4
2
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 2
Max Reward: 5
Gini Coefficient: 0.12631578947368421
20:20 Ratio: 2.5
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-32-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -679.6357197602545
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 406
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.692
    dispatch_time_ms: 6.29
    learner:
      cur_lr: 0.0012248019920662045
      grad_gnorm: 8.207612037658691
      policy_entropy: 37.113258361816406
      policy_loss: -2.718903064727783
      var_gnorm: 26.089588165283203
      vf_explained_var: 0.0
      vf_loss: 7.190534591674805
    num_steps_sampled: 2035000
    num_steps_trained: 2035000
    wait_time_ms: 69.605
  iterations_since_restore: 407
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3556.2633266448975
  time_this_iter_s: 8.15804672241211
  time_total_s: 3556.2633266448975
  timestamp: 1594859568
  timesteps_since_restore: 2035000
  timesteps_this_iter: 5000
  timesteps_total: 2035000
  training_iteration: 407
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3556 s, 407 iter, 2035000 ts, -680 rew

agent-1: -162.20099827199925
agent-2: -72.56169383336805
agent-3: -65.29325577568866
agent-4: -88.75089549542416
agent-5: -107.47226045224275
Extrinsic Rewards:
19
8
10
16
20
Sum Reward: 73
Avg Reward: 14.6
Min Reward: 8
Max Reward: 20
Gini Coefficient: 0.18082191780821918
20:20 Ratio: 2.5
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-32-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -678.3310265971444
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 407
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.681
    dispatch_time_ms: 6.441
    learner:
      cur_lr: 0.0012244690442457795
      grad_gnorm: 27.817913055419922
      policy_entropy: 38.47496795654297
      policy_loss: 7.816010475158691
      var_gnorm: 26.07976531982422
      vf_explained_var: 0.0
      vf_loss: 13.380508422851562
    num_steps_sampled: 2040000
    num_steps_trained: 2040000
    wait_time_ms: 75.851
  iterations_since_restore: 408
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3564.526871442795
  time_this_iter_s: 8.263544797897339
  time_total_s: 3564.526871442795
  timestamp: 1594859577
  timesteps_since_restore: 2040000
  timesteps_this_iter: 5000
  timesteps_total: 2040000
  training_iteration: 408
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3564 s, 408 iter, 2040000 ts, -678 rew

agent-1: -106.99562668870954
agent-2: -16.37458157732341
agent-3: -103.30179499972839
agent-4: -225.63342569890574
agent-5: -197.11478147765862
Extrinsic Rewards:
6
1
8
6
10
Sum Reward: 31
Avg Reward: 6.2
Min Reward: 1
Max Reward: 10
Gini Coefficient: 0.25806451612903225
20:20 Ratio: 10.0
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-33-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -678.3593589273997
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 408
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.216
    dispatch_time_ms: 9.056
    learner:
      cur_lr: 0.0012241359800100327
      grad_gnorm: 14.814309120178223
      policy_entropy: 44.56477737426758
      policy_loss: 2.15220308303833
      var_gnorm: 26.08985710144043
      vf_explained_var: 0.0
      vf_loss: 10.862016677856445
    num_steps_sampled: 2045000
    num_steps_trained: 2045000
    wait_time_ms: 70.628
  iterations_since_restore: 409
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3572.8025238513947
  time_this_iter_s: 8.275652408599854
  time_total_s: 3572.8025238513947
  timestamp: 1594859585
  timesteps_since_restore: 2045000
  timesteps_this_iter: 5000
  timesteps_total: 2045000
  training_iteration: 409
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3572 s, 409 iter, 2045000 ts, -678 rew

agent-1: -141.8649636883878
agent-2: -217.5048484678681
agent-3: -137.89273769505974
agent-4: -32.28345350499504
agent-5: -105.59364726685139
Extrinsic Rewards:
12
15
4
5
8
Sum Reward: 44
Avg Reward: 8.8
Min Reward: 4
Max Reward: 15
Gini Coefficient: 0.2636363636363636
20:20 Ratio: 3.75
Max-min Ratio: 3.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-33-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -677.1383939554917
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 409
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.781
    dispatch_time_ms: 7.409
    learner:
      cur_lr: 0.0012238030321896076
      grad_gnorm: 39.999996185302734
      policy_entropy: 51.071937561035156
      policy_loss: 15.691658973693848
      var_gnorm: 26.152883529663086
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 17.464557647705078
    num_steps_sampled: 2050000
    num_steps_trained: 2050000
    wait_time_ms: 75.846
  iterations_since_restore: 410
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3581.073963880539
  time_this_iter_s: 8.271440029144287
  time_total_s: 3581.073963880539
  timestamp: 1594859593
  timesteps_since_restore: 2050000
  timesteps_this_iter: 5000
  timesteps_total: 2050000
  training_iteration: 410
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3581 s, 410 iter, 2050000 ts, -677 rew

agent-1: -124.19743950654212
agent-2: -124.19743950654212
agent-3: -240.75285242132605
agent-4: -236.1732243592469
agent-5: -99.48528068582058
Extrinsic Rewards:
0
0
8
7
4
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.4842105263157895
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-33-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -678.7179813441917
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 410
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.444
    dispatch_time_ms: 7.665
    learner:
      cur_lr: 0.0012234699679538608
      grad_gnorm: 10.916836738586426
      policy_entropy: 46.27164840698242
      policy_loss: -0.8867121338844299
      var_gnorm: 26.13758659362793
      vf_explained_var: 0.0
      vf_loss: 4.51478910446167
    num_steps_sampled: 2055000
    num_steps_trained: 2055000
    wait_time_ms: 73.659
  iterations_since_restore: 411
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3589.3940002918243
  time_this_iter_s: 8.3200364112854
  time_total_s: 3589.3940002918243
  timestamp: 1594859602
  timesteps_since_restore: 2055000
  timesteps_this_iter: 5000
  timesteps_total: 2055000
  training_iteration: 411
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3589 s, 411 iter, 2055000 ts, -679 rew

agent-1: -200.43526441581923
agent-2: -143.3026831370305
agent-3: -167.10246053122015
agent-4: -25.033954526488536
agent-5: -126.33204062618898
Extrinsic Rewards:
9
12
12
2
13
Sum Reward: 48
Avg Reward: 9.6
Min Reward: 2
Max Reward: 13
Gini Coefficient: 0.20833333333333334
20:20 Ratio: 6.5
Max-min Ratio: 6.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-33-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -677.8050521530828
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 411
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.908
    dispatch_time_ms: 8.588
    learner:
      cur_lr: 0.0012231370201334357
      grad_gnorm: 40.0
      policy_entropy: 58.63862991333008
      policy_loss: 40.86487579345703
      var_gnorm: 26.135616302490234
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 30.47059440612793
    num_steps_sampled: 2060000
    num_steps_trained: 2060000
    wait_time_ms: 72.362
  iterations_since_restore: 412
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3597.7773423194885
  time_this_iter_s: 8.383342027664185
  time_total_s: 3597.7773423194885
  timestamp: 1594859610
  timesteps_since_restore: 2060000
  timesteps_this_iter: 5000
  timesteps_total: 2060000
  training_iteration: 412
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3597 s, 412 iter, 2060000 ts, -678 rew

agent-1: -41.914903997502265
agent-2: -182.52688571701188
agent-3: -100.11739930861978
agent-4: -257.09180743116104
agent-5: -57.11084941165995
Extrinsic Rewards:
1
3
3
8
1
Sum Reward: 16
Avg Reward: 3.2
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.4
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-33-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -675.6934202356017
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 412
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.337
    dispatch_time_ms: 9.584
    learner:
      cur_lr: 0.0012228039558976889
      grad_gnorm: 14.431187629699707
      policy_entropy: 65.21672058105469
      policy_loss: 2.8751583099365234
      var_gnorm: 26.125471115112305
      vf_explained_var: 0.0
      vf_loss: 6.954461574554443
    num_steps_sampled: 2065000
    num_steps_trained: 2065000
    wait_time_ms: 70.185
  iterations_since_restore: 413
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3606.0337975025177
  time_this_iter_s: 8.256455183029175
  time_total_s: 3606.0337975025177
  timestamp: 1594859619
  timesteps_since_restore: 2065000
  timesteps_this_iter: 5000
  timesteps_total: 2065000
  training_iteration: 413
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3606 s, 413 iter, 2065000 ts, -676 rew

agent-1: -258.54105150667453
agent-2: -24.41490489237814
agent-3: -72.16863686156594
agent-4: -116.62982785098066
agent-5: -141.8627861395376
Extrinsic Rewards:
4
1
3
6
4
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 1
Max Reward: 6
Gini Coefficient: 0.24444444444444444
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-33-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -676.0670554126623
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 413
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.703
    dispatch_time_ms: 7.33
    learner:
      cur_lr: 0.0012224710080772638
      grad_gnorm: 12.600543022155762
      policy_entropy: 62.60108184814453
      policy_loss: -3.5797066688537598
      var_gnorm: 26.12471580505371
      vf_explained_var: 0.0
      vf_loss: 5.007650375366211
    num_steps_sampled: 2070000
    num_steps_trained: 2070000
    wait_time_ms: 73.641
  iterations_since_restore: 414
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3614.400366306305
  time_this_iter_s: 8.366568803787231
  time_total_s: 3614.400366306305
  timestamp: 1594859627
  timesteps_since_restore: 2070000
  timesteps_this_iter: 5000
  timesteps_total: 2070000
  training_iteration: 414
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3614 s, 414 iter, 2070000 ts, -676 rew

agent-1: -76.77379374283971
agent-2: -55.705920718394836
agent-3: -107.68479805873882
agent-4: -217.02671928847218
agent-5: -222.37157616981105
Extrinsic Rewards:
3
1
2
8
6
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.36
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-33-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -677.4262836960484
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 414
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.155
    dispatch_time_ms: 9.32
    learner:
      cur_lr: 0.001222137943841517
      grad_gnorm: 29.93619728088379
      policy_entropy: 58.79026412963867
      policy_loss: -0.28041762113571167
      var_gnorm: 26.13181495666504
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 5.717013835906982
    num_steps_sampled: 2075000
    num_steps_trained: 2075000
    wait_time_ms: 72.993
  iterations_since_restore: 415
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3622.8441014289856
  time_this_iter_s: 8.443735122680664
  time_total_s: 3622.8441014289856
  timestamp: 1594859635
  timesteps_since_restore: 2075000
  timesteps_this_iter: 5000
  timesteps_total: 2075000
  training_iteration: 415
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3622 s, 415 iter, 2075000 ts, -677 rew

agent-1: -90.82126571767174
agent-2: -83.1025460669988
agent-3: -93.44877354171855
agent-4: -161.52453054639165
agent-5: -249.36219765207068
Extrinsic Rewards:
3
2
1
4
6
Sum Reward: 16
Avg Reward: 3.2
Min Reward: 1
Max Reward: 6
Gini Coefficient: 0.3
20:20 Ratio: 6.0
Max-min Ratio: 6.0
agent-1: -39.13923418397364
agent-2: -156.58210333704642
agent-3: -65.20180073057034
agent-4: -216.3059274065707
agent-5: -205.21935129386597
Extrinsic Rewards:
2
5
4
7
4
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 2
Max Reward: 7
Gini Coefficient: 0.2
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-34-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -679.3093556432266
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 2
  episodes_total: 416
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.898
    dispatch_time_ms: 8.043
    learner:
      cur_lr: 0.001221804996021092
      grad_gnorm: 40.000003814697266
      policy_entropy: 53.50688934326172
      policy_loss: 16.190183639526367
      var_gnorm: 26.137771606445312
      vf_explained_var: -0.925223708152771
      vf_loss: 29.189380645751953
    num_steps_sampled: 2080000
    num_steps_trained: 2080000
    wait_time_ms: 72.862
  iterations_since_restore: 416
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3631.190864086151
  time_this_iter_s: 8.346762657165527
  time_total_s: 3631.190864086151
  timestamp: 1594859644
  timesteps_since_restore: 2080000
  timesteps_this_iter: 5000
  timesteps_total: 2080000
  training_iteration: 416
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3631 s, 416 iter, 2080000 ts, -679 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-34-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -679.3093556432267
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 0
  episodes_total: 416
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.694
    dispatch_time_ms: 6.9
    learner:
      cur_lr: 0.001221472048200667
      grad_gnorm: 18.899520874023438
      policy_entropy: 55.47494888305664
      policy_loss: -5.021685600280762
      var_gnorm: 26.12490463256836
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 4.428240776062012
    num_steps_sampled: 2085000
    num_steps_trained: 2085000
    wait_time_ms: 72.001
  iterations_since_restore: 417
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3639.5596072673798
  time_this_iter_s: 8.368743181228638
  time_total_s: 3639.5596072673798
  timestamp: 1594859652
  timesteps_since_restore: 2085000
  timesteps_this_iter: 5000
  timesteps_total: 2085000
  training_iteration: 417
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3639 s, 417 iter, 2085000 ts, -679 rew

agent-1: -58.632171731157996
agent-2: -191.15533531672833
agent-3: -120.92834567697145
agent-4: -244.53700478676888
agent-5: -121.31864121995572
Extrinsic Rewards:
3
13
0
14
4
Sum Reward: 34
Avg Reward: 6.8
Min Reward: 0
Max Reward: 14
Gini Coefficient: 0.4470588235294118
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: -72.5826152922122
agent-2: -188.611750574003
agent-3: -231.578701798689
agent-4: -75.10436073374343
agent-5: -107.04651539384022
Extrinsic Rewards:
2
2
12
4
2
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 2
Max Reward: 12
Gini Coefficient: 0.4
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-34-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -680.625533835862
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 2
  episodes_total: 418
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.663
    dispatch_time_ms: 6.906
    learner:
      cur_lr: 0.00122113898396492
      grad_gnorm: 39.999996185302734
      policy_entropy: 54.962257385253906
      policy_loss: -66.20866394042969
      var_gnorm: 26.171939849853516
      vf_explained_var: -1.0
      vf_loss: 57.053565979003906
    num_steps_sampled: 2090000
    num_steps_trained: 2090000
    wait_time_ms: 72.58
  iterations_since_restore: 418
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3647.923556804657
  time_this_iter_s: 8.363949537277222
  time_total_s: 3647.923556804657
  timestamp: 1594859661
  timesteps_since_restore: 2090000
  timesteps_this_iter: 5000
  timesteps_total: 2090000
  training_iteration: 418
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3647 s, 418 iter, 2090000 ts, -681 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-34-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -680.625533835862
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 0
  episodes_total: 418
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.849
    dispatch_time_ms: 7.377
    learner:
      cur_lr: 0.001220806036144495
      grad_gnorm: 25.07677459716797
      policy_entropy: 58.813865661621094
      policy_loss: 4.807582378387451
      var_gnorm: 26.134519577026367
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.317767858505249
    num_steps_sampled: 2095000
    num_steps_trained: 2095000
    wait_time_ms: 76.574
  iterations_since_restore: 419
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3656.217212200165
  time_this_iter_s: 8.293655395507812
  time_total_s: 3656.217212200165
  timestamp: 1594859669
  timesteps_since_restore: 2095000
  timesteps_this_iter: 5000
  timesteps_total: 2095000
  training_iteration: 419
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3656 s, 419 iter, 2095000 ts, -681 rew

agent-1: -206.44331632534613
agent-2: -21.580562599160974
agent-3: -91.16555859977511
agent-4: -116.94115660936649
agent-5: -222.40553158102838
Extrinsic Rewards:
5
2
6
1
6
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 1
Max Reward: 6
Gini Coefficient: 0.28
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-34-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -680.202163196554
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 419
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.433
    dispatch_time_ms: 7.546
    learner:
      cur_lr: 0.0012204729719087481
      grad_gnorm: 40.0
      policy_entropy: 59.637168884277344
      policy_loss: 35.05409622192383
      var_gnorm: 26.133182525634766
      vf_explained_var: 0.0
      vf_loss: 23.533111572265625
    num_steps_sampled: 2100000
    num_steps_trained: 2100000
    wait_time_ms: 71.665
  iterations_since_restore: 420
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3664.5685267448425
  time_this_iter_s: 8.351314544677734
  time_total_s: 3664.5685267448425
  timestamp: 1594859677
  timesteps_since_restore: 2100000
  timesteps_this_iter: 5000
  timesteps_total: 2100000
  training_iteration: 420
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3664 s, 420 iter, 2100000 ts, -680 rew

agent-1: -100.69529710195238
agent-2: -84.5148840658057
agent-3: -248.1928280952203
agent-4: -125.6161031782227
agent-5: -114.34603597783189
Extrinsic Rewards:
3
2
11
2
3
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 2
Max Reward: 11
Gini Coefficient: 0.3619047619047619
20:20 Ratio: 5.5
Max-min Ratio: 5.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-34-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -679.5192648728643
  episode_reward_min: -1233.6388041488037
  episodes_this_iter: 1
  episodes_total: 420
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.477
    dispatch_time_ms: 5.76
    learner:
      cur_lr: 0.0012201400240883231
      grad_gnorm: 21.9743595123291
      policy_entropy: 52.9160270690918
      policy_loss: -3.336683750152588
      var_gnorm: 26.0999755859375
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 11.440667152404785
    num_steps_sampled: 2105000
    num_steps_trained: 2105000
    wait_time_ms: 77.319
  iterations_since_restore: 421
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3672.90140581131
  time_this_iter_s: 8.332879066467285
  time_total_s: 3672.90140581131
  timestamp: 1594859686
  timesteps_since_restore: 2105000
  timesteps_this_iter: 5000
  timesteps_total: 2105000
  training_iteration: 421
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3672 s, 421 iter, 2105000 ts, -680 rew

agent-1: -135.82437973533334
agent-2: -267.72192842966024
agent-3: -14.410746953786001
agent-4: -45.01220031030963
agent-5: -79.47734204106881
Extrinsic Rewards:
8
7
1
2
4
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.34545454545454546
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-34-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -672.6073428060776
  episode_reward_min: -884.3453022394721
  episodes_this_iter: 1
  episodes_total: 421
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.765
    dispatch_time_ms: 6.493
    learner:
      cur_lr: 0.0012198069598525763
      grad_gnorm: 40.0
      policy_entropy: 57.24816131591797
      policy_loss: -10.391122817993164
      var_gnorm: 26.132495880126953
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 14.93126392364502
    num_steps_sampled: 2110000
    num_steps_trained: 2110000
    wait_time_ms: 76.135
  iterations_since_restore: 422
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3681.2529768943787
  time_this_iter_s: 8.351571083068848
  time_total_s: 3681.2529768943787
  timestamp: 1594859694
  timesteps_since_restore: 2110000
  timesteps_this_iter: 5000
  timesteps_total: 2110000
  training_iteration: 422
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3681 s, 422 iter, 2110000 ts, -673 rew

agent-1: -131.5507114825108
agent-2: -54.56200018988915
agent-3: -253.69669193247537
agent-4: -219.83642293475168
agent-5: -15.99537505592624
Extrinsic Rewards:
0
3
9
12
1
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 0
Max Reward: 12
Gini Coefficient: 0.512
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-35-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -672.980581289416
  episode_reward_min: -884.3453022394721
  episodes_this_iter: 1
  episodes_total: 422
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.367
    dispatch_time_ms: 7.248
    learner:
      cur_lr: 0.0012194740120321512
      grad_gnorm: 6.6038970947265625
      policy_entropy: 45.98870849609375
      policy_loss: 1.0556273460388184
      var_gnorm: 26.129562377929688
      vf_explained_var: 0.0
      vf_loss: 6.784848213195801
    num_steps_sampled: 2115000
    num_steps_trained: 2115000
    wait_time_ms: 73.532
  iterations_since_restore: 423
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3689.5850055217743
  time_this_iter_s: 8.33202862739563
  time_total_s: 3689.5850055217743
  timestamp: 1594859702
  timesteps_since_restore: 2115000
  timesteps_this_iter: 5000
  timesteps_total: 2115000
  training_iteration: 423
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3689 s, 423 iter, 2115000 ts, -673 rew

agent-1: -150.33778375761327
agent-2: -230.72304694383783
agent-3: -56.6140990660511
agent-4: -210.73154662078545
agent-5: -130.94101843442925
Extrinsic Rewards:
8
7
3
6
0
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.3333333333333333
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-35-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -673.8792539439762
  episode_reward_min: -884.3453022394721
  episodes_this_iter: 1
  episodes_total: 423
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.974
    dispatch_time_ms: 7.749
    learner:
      cur_lr: 0.0012191409477964044
      grad_gnorm: 40.0
      policy_entropy: 43.52055358886719
      policy_loss: 44.335182189941406
      var_gnorm: 26.223955154418945
      vf_explained_var: 0.0
      vf_loss: 33.494808197021484
    num_steps_sampled: 2120000
    num_steps_trained: 2120000
    wait_time_ms: 73.838
  iterations_since_restore: 424
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3697.9758710861206
  time_this_iter_s: 8.390865564346313
  time_total_s: 3697.9758710861206
  timestamp: 1594859711
  timesteps_since_restore: 2120000
  timesteps_this_iter: 5000
  timesteps_total: 2120000
  training_iteration: 424
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3697 s, 424 iter, 2120000 ts, -674 rew

agent-1: -77.31640590364785
agent-2: -137.4981924418453
agent-3: -243.0536659210944
agent-4: -181.65627607766766
agent-5: -129.49133510076987
Extrinsic Rewards:
4
6
8
7
0
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.304
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-35-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -675.3157039654792
  episode_reward_min: -884.3453022394721
  episodes_this_iter: 1
  episodes_total: 424
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.146
    dispatch_time_ms: 6.716
    learner:
      cur_lr: 0.0012188079999759793
      grad_gnorm: 18.933103561401367
      policy_entropy: 43.216251373291016
      policy_loss: -6.759533405303955
      var_gnorm: 26.15604591369629
      vf_explained_var: 0.0
      vf_loss: 4.711404800415039
    num_steps_sampled: 2125000
    num_steps_trained: 2125000
    wait_time_ms: 72.441
  iterations_since_restore: 425
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3706.382977962494
  time_this_iter_s: 8.407106876373291
  time_total_s: 3706.382977962494
  timestamp: 1594859719
  timesteps_since_restore: 2125000
  timesteps_this_iter: 5000
  timesteps_total: 2125000
  training_iteration: 425
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3706 s, 425 iter, 2125000 ts, -675 rew

agent-1: -237.4859891613176
agent-2: -83.31987801628495
agent-3: -143.299068346689
agent-4: -175.7495884926169
agent-5: -51.23481960674299
Extrinsic Rewards:
7
1
4
5
1
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 1
Max Reward: 7
Gini Coefficient: 0.35555555555555557
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-35-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -675.6150039857312
  episode_reward_min: -884.3453022394721
  episodes_this_iter: 1
  episodes_total: 425
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.066
    dispatch_time_ms: 9.982
    learner:
      cur_lr: 0.0012184750521555543
      grad_gnorm: 40.000003814697266
      policy_entropy: 45.41401290893555
      policy_loss: 16.015836715698242
      var_gnorm: 26.190532684326172
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 14.05160903930664
    num_steps_sampled: 2130000
    num_steps_trained: 2130000
    wait_time_ms: 70.841
  iterations_since_restore: 426
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3714.8535118103027
  time_this_iter_s: 8.470533847808838
  time_total_s: 3714.8535118103027
  timestamp: 1594859728
  timesteps_since_restore: 2130000
  timesteps_this_iter: 5000
  timesteps_total: 2130000
  training_iteration: 426
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3714 s, 426 iter, 2130000 ts, -676 rew

agent-1: -152.4821465520007
agent-2: -103.71206186629038
agent-3: -141.56441460610856
agent-4: -233.07915733309991
agent-5: -185.64450762418784
Extrinsic Rewards:
2
2
0
9
8
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.45714285714285713
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-35-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -677.9656198193512
  episode_reward_min: -884.3453022394721
  episodes_this_iter: 1
  episodes_total: 426
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.828
    dispatch_time_ms: 8.666
    learner:
      cur_lr: 0.0012181419879198074
      grad_gnorm: 17.857927322387695
      policy_entropy: 59.33344650268555
      policy_loss: -1.1763721704483032
      var_gnorm: 26.149497985839844
      vf_explained_var: 0.0
      vf_loss: 5.578319549560547
    num_steps_sampled: 2135000
    num_steps_trained: 2135000
    wait_time_ms: 73.427
  iterations_since_restore: 427
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3723.2182507514954
  time_this_iter_s: 8.364738941192627
  time_total_s: 3723.2182507514954
  timestamp: 1594859736
  timesteps_since_restore: 2135000
  timesteps_this_iter: 5000
  timesteps_total: 2135000
  training_iteration: 427
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3723 s, 427 iter, 2135000 ts, -678 rew

agent-1: -145.15228968938845
agent-2: -223.53126701978243
agent-3: -57.7883998359542
agent-4: -46.23561983993181
agent-5: -209.7106610860019
Extrinsic Rewards:
5
5
2
1
4
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 1
Max Reward: 5
Gini Coefficient: 0.25882352941176473
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-35-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -677.7833015724257
  episode_reward_min: -884.3453022394721
  episodes_this_iter: 1
  episodes_total: 427
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.758
    dispatch_time_ms: 7.395
    learner:
      cur_lr: 0.0012178090400993824
      grad_gnorm: 37.92795181274414
      policy_entropy: 57.48417282104492
      policy_loss: 13.424311637878418
      var_gnorm: 26.14460563659668
      vf_explained_var: 0.0
      vf_loss: 10.858530044555664
    num_steps_sampled: 2140000
    num_steps_trained: 2140000
    wait_time_ms: 70.353
  iterations_since_restore: 428
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3731.5657935142517
  time_this_iter_s: 8.347542762756348
  time_total_s: 3731.5657935142517
  timestamp: 1594859745
  timesteps_since_restore: 2140000
  timesteps_this_iter: 5000
  timesteps_total: 2140000
  training_iteration: 428
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3731 s, 428 iter, 2140000 ts, -678 rew

agent-1: -189.21484401892786
agent-2: -25.429790270227738
agent-3: -164.93367671161892
agent-4: -95.0246049236843
agent-5: -210.61883558239913
Extrinsic Rewards:
8
1
3
5
3
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.32
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-35-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -678.2534136965951
  episode_reward_min: -884.3453022394721
  episodes_this_iter: 1
  episodes_total: 428
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.677
    dispatch_time_ms: 5.803
    learner:
      cur_lr: 0.0012174759758636355
      grad_gnorm: 21.587322235107422
      policy_entropy: 44.36326599121094
      policy_loss: 6.994009971618652
      var_gnorm: 26.115924835205078
      vf_explained_var: 0.0
      vf_loss: 9.427032470703125
    num_steps_sampled: 2145000
    num_steps_trained: 2145000
    wait_time_ms: 71.811
  iterations_since_restore: 429
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3739.8966500759125
  time_this_iter_s: 8.330856561660767
  time_total_s: 3739.8966500759125
  timestamp: 1594859753
  timesteps_since_restore: 2145000
  timesteps_this_iter: 5000
  timesteps_total: 2145000
  training_iteration: 429
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3739 s, 429 iter, 2145000 ts, -678 rew

agent-1: -129.57627271272798
agent-2: -98.1325879920695
agent-3: -186.97551780486074
agent-4: -218.26941114463838
agent-5: -61.928773126667245
Extrinsic Rewards:
4
3
6
7
4
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 3
Max Reward: 7
Gini Coefficient: 0.16666666666666666
20:20 Ratio: 2.3333333333333335
Max-min Ratio: 2.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-36-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -678.407406106372
  episode_reward_min: -884.3453022394721
  episodes_this_iter: 1
  episodes_total: 429
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.843
    dispatch_time_ms: 8.277
    learner:
      cur_lr: 0.0012171430280432105
      grad_gnorm: 20.19428825378418
      policy_entropy: 54.36305236816406
      policy_loss: -4.884842872619629
      var_gnorm: 26.151878356933594
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 12.613862991333008
    num_steps_sampled: 2150000
    num_steps_trained: 2150000
    wait_time_ms: 71.678
  iterations_since_restore: 430
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3748.235993385315
  time_this_iter_s: 8.339343309402466
  time_total_s: 3748.235993385315
  timestamp: 1594859761
  timesteps_since_restore: 2150000
  timesteps_this_iter: 5000
  timesteps_total: 2150000
  training_iteration: 430
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3748 s, 430 iter, 2150000 ts, -678 rew

agent-1: -69.61608770798195
agent-2: -65.19054996994595
agent-3: -275.16404793596365
agent-4: -82.17968054906045
agent-5: -132.34104654391402
Extrinsic Rewards:
5
3
12
5
0
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 0
Max Reward: 12
Gini Coefficient: 0.416
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-36-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -678.1968267833331
  episode_reward_min: -884.3453022394721
  episodes_this_iter: 1
  episodes_total: 430
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.174
    dispatch_time_ms: 6.839
    learner:
      cur_lr: 0.0012168099638074636
      grad_gnorm: 2.966536045074463
      policy_entropy: 55.64484405517578
      policy_loss: -1.0100816488265991
      var_gnorm: 26.151945114135742
      vf_explained_var: 0.0
      vf_loss: 2.0336403846740723
    num_steps_sampled: 2155000
    num_steps_trained: 2155000
    wait_time_ms: 74.261
  iterations_since_restore: 431
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3756.6784901618958
  time_this_iter_s: 8.44249677658081
  time_total_s: 3756.6784901618958
  timestamp: 1594859770
  timesteps_since_restore: 2155000
  timesteps_this_iter: 5000
  timesteps_total: 2155000
  training_iteration: 431
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3756 s, 431 iter, 2155000 ts, -678 rew

agent-1: -106.33087598575776
agent-2: -94.88409277408016
agent-3: -171.832602313663
agent-4: -127.67304366010205
agent-5: -218.8424919960789
Extrinsic Rewards:
4
1
4
3
9
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.3238095238095238
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-36-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -680.2953875590043
  episode_reward_min: -884.3453022394721
  episodes_this_iter: 1
  episodes_total: 431
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.463
    dispatch_time_ms: 7.332
    learner:
      cur_lr: 0.0012164770159870386
      grad_gnorm: 6.317882061004639
      policy_entropy: 54.08218002319336
      policy_loss: -0.15231937170028687
      var_gnorm: 26.155376434326172
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 2.715524673461914
    num_steps_sampled: 2160000
    num_steps_trained: 2160000
    wait_time_ms: 73.154
  iterations_since_restore: 432
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3765.0048129558563
  time_this_iter_s: 8.326322793960571
  time_total_s: 3765.0048129558563
  timestamp: 1594859778
  timesteps_since_restore: 2160000
  timesteps_this_iter: 5000
  timesteps_total: 2160000
  training_iteration: 432
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3765 s, 432 iter, 2160000 ts, -680 rew

agent-1: -116.3874041221402
agent-2: -181.8970734468453
agent-3: -216.79087371128372
agent-4: -74.76535668954175
agent-5: -125.65766361777804
Extrinsic Rewards:
4
3
7
2
5
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 2
Max Reward: 7
Gini Coefficient: 0.22857142857142856
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-36-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -681.572317251872
  episode_reward_min: -884.3453022394721
  episodes_this_iter: 1
  episodes_total: 432
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.127
    dispatch_time_ms: 7.153
    learner:
      cur_lr: 0.0012161439517512918
      grad_gnorm: 17.51874542236328
      policy_entropy: 52.47835159301758
      policy_loss: 4.079492092132568
      var_gnorm: 26.121313095092773
      vf_explained_var: 0.0
      vf_loss: 6.73065185546875
    num_steps_sampled: 2165000
    num_steps_trained: 2165000
    wait_time_ms: 72.231
  iterations_since_restore: 433
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3773.597864627838
  time_this_iter_s: 8.593051671981812
  time_total_s: 3773.597864627838
  timestamp: 1594859787
  timesteps_since_restore: 2165000
  timesteps_this_iter: 5000
  timesteps_total: 2165000
  training_iteration: 433
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3773 s, 433 iter, 2165000 ts, -682 rew

agent-1: -108.55233292964813
agent-2: -74.06279096047446
agent-3: -182.55010388625908
agent-4: -93.05295961664693
agent-5: -206.73569495774777
Extrinsic Rewards:
15
2
4
1
6
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 1
Max Reward: 15
Gini Coefficient: 0.45714285714285713
20:20 Ratio: 15.0
Max-min Ratio: 15.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-36-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -681.7300610319039
  episode_reward_min: -884.3453022394721
  episodes_this_iter: 1
  episodes_total: 433
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.209
    dispatch_time_ms: 8.001
    learner:
      cur_lr: 0.0012158110039308667
      grad_gnorm: 40.0
      policy_entropy: 52.864017486572266
      policy_loss: 19.13676643371582
      var_gnorm: 26.128198623657227
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 11.165987014770508
    num_steps_sampled: 2170000
    num_steps_trained: 2170000
    wait_time_ms: 72.372
  iterations_since_restore: 434
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3782.0121097564697
  time_this_iter_s: 8.414245128631592
  time_total_s: 3782.0121097564697
  timestamp: 1594859795
  timesteps_since_restore: 2170000
  timesteps_this_iter: 5000
  timesteps_total: 2170000
  training_iteration: 434
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3782 s, 434 iter, 2170000 ts, -682 rew

agent-1: -45.6924548183252
agent-2: -104.35901321099787
agent-3: -82.9390202515302
agent-4: -86.00906858673065
agent-5: -257.82936997206826
Extrinsic Rewards:
2
4
4
6
7
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 2
Max Reward: 7
Gini Coefficient: 0.20869565217391303
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-36-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -680.4572553679344
  episode_reward_min: -884.3453022394721
  episodes_this_iter: 1
  episodes_total: 434
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.7
    dispatch_time_ms: 6.528
    learner:
      cur_lr: 0.0012154780561104417
      grad_gnorm: 13.99332332611084
      policy_entropy: 41.93254089355469
      policy_loss: -3.5790960788726807
      var_gnorm: 26.130264282226562
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 6.676465034484863
    num_steps_sampled: 2175000
    num_steps_trained: 2175000
    wait_time_ms: 77.287
  iterations_since_restore: 435
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3790.3803577423096
  time_this_iter_s: 8.368247985839844
  time_total_s: 3790.3803577423096
  timestamp: 1594859804
  timesteps_since_restore: 2175000
  timesteps_this_iter: 5000
  timesteps_total: 2175000
  training_iteration: 435
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3790 s, 435 iter, 2175000 ts, -680 rew

agent-1: -191.8595485480358
agent-2: -37.87789999676245
agent-3: -233.79173137085127
agent-4: -44.561825399877684
agent-5: -135.77578986673473
Extrinsic Rewards:
10
4
10
2
6
Sum Reward: 32
Avg Reward: 6.4
Min Reward: 2
Max Reward: 10
Gini Coefficient: 0.275
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-36-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -678.4729711984407
  episode_reward_min: -884.3453022394721
  episodes_this_iter: 1
  episodes_total: 435
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.546
    dispatch_time_ms: 7.097
    learner:
      cur_lr: 0.0012151449918746948
      grad_gnorm: 40.0
      policy_entropy: 41.09820556640625
      policy_loss: 17.614158630371094
      var_gnorm: 26.180971145629883
      vf_explained_var: 0.0
      vf_loss: 22.149608612060547
    num_steps_sampled: 2180000
    num_steps_trained: 2180000
    wait_time_ms: 73.247
  iterations_since_restore: 436
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3798.79420876503
  time_this_iter_s: 8.413851022720337
  time_total_s: 3798.79420876503
  timestamp: 1594859812
  timesteps_since_restore: 2180000
  timesteps_this_iter: 5000
  timesteps_total: 2180000
  training_iteration: 436
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3798 s, 436 iter, 2180000 ts, -678 rew

agent-1: -102.61908474978878
agent-2: -128.55737454184882
agent-3: -255.70676553723555
agent-4: -137.45733875229897
agent-5: -157.95333600803966
Extrinsic Rewards:
4
4
9
0
3
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.38
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-37-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -679.3584198199103
  episode_reward_min: -884.3453022394721
  episodes_this_iter: 1
  episodes_total: 436
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.506
    dispatch_time_ms: 10.352
    learner:
      cur_lr: 0.0012148120440542698
      grad_gnorm: 8.02505874633789
      policy_entropy: 37.3779296875
      policy_loss: 0.4519287645816803
      var_gnorm: 26.147153854370117
      vf_explained_var: 0.0
      vf_loss: 7.069490432739258
    num_steps_sampled: 2185000
    num_steps_trained: 2185000
    wait_time_ms: 71.647
  iterations_since_restore: 437
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3807.116529941559
  time_this_iter_s: 8.32232117652893
  time_total_s: 3807.116529941559
  timestamp: 1594859820
  timesteps_since_restore: 2185000
  timesteps_this_iter: 5000
  timesteps_total: 2185000
  training_iteration: 437
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3807 s, 437 iter, 2185000 ts, -679 rew

agent-1: -215.83148794521523
agent-2: -59.73036235298375
agent-3: -221.0644648375016
agent-4: -111.92921114095843
agent-5: -26.272961940094245
Extrinsic Rewards:
10
6
15
3
2
Sum Reward: 36
Avg Reward: 7.2
Min Reward: 2
Max Reward: 15
Gini Coefficient: 0.36666666666666664
20:20 Ratio: 7.5
Max-min Ratio: 7.5
agent-1: -99.16768315284244
agent-2: -230.15182957729948
agent-3: -171.53792314765056
agent-4: -15.783161422371194
agent-5: -159.75428050168725
Extrinsic Rewards:
5
12
7
1
5
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 1
Max Reward: 12
Gini Coefficient: 0.32
20:20 Ratio: 12.0
Max-min Ratio: 12.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-37-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -679.5391115797081
  episode_reward_min: -884.3453022394721
  episodes_this_iter: 2
  episodes_total: 438
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.106
    dispatch_time_ms: 7.173
    learner:
      cur_lr: 0.001214478979818523
      grad_gnorm: 40.0
      policy_entropy: 37.55373001098633
      policy_loss: 342.85467529296875
      var_gnorm: 26.147085189819336
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 4277.9599609375
    num_steps_sampled: 2190000
    num_steps_trained: 2190000
    wait_time_ms: 74.211
  iterations_since_restore: 438
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3815.6220405101776
  time_this_iter_s: 8.505510568618774
  time_total_s: 3815.6220405101776
  timestamp: 1594859829
  timesteps_since_restore: 2190000
  timesteps_this_iter: 5000
  timesteps_total: 2190000
  training_iteration: 438
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3815 s, 438 iter, 2190000 ts, -680 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-37-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -679.5391115797081
  episode_reward_min: -884.3453022394721
  episodes_this_iter: 0
  episodes_total: 438
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.953
    dispatch_time_ms: 8.754
    learner:
      cur_lr: 0.001214146031998098
      grad_gnorm: 23.371849060058594
      policy_entropy: 56.70479965209961
      policy_loss: 2.0356483459472656
      var_gnorm: 26.13532829284668
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 6.808913707733154
    num_steps_sampled: 2195000
    num_steps_trained: 2195000
    wait_time_ms: 72.375
  iterations_since_restore: 439
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3823.846439599991
  time_this_iter_s: 8.224399089813232
  time_total_s: 3823.846439599991
  timestamp: 1594859837
  timesteps_since_restore: 2195000
  timesteps_this_iter: 5000
  timesteps_total: 2195000
  training_iteration: 439
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3823 s, 439 iter, 2195000 ts, -680 rew

agent-1: -59.317822447946
agent-2: -180.23516465400357
agent-3: -219.27999958578914
agent-4: -59.836705987118634
agent-5: -113.25639431842805
Extrinsic Rewards:
8
8
11
9
4
Sum Reward: 40
Avg Reward: 8.0
Min Reward: 4
Max Reward: 11
Gini Coefficient: 0.15
20:20 Ratio: 2.75
Max-min Ratio: 2.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-37-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -679.4403992262951
  episode_reward_min: -884.3453022394721
  episodes_this_iter: 1
  episodes_total: 439
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.519
    dispatch_time_ms: 5.97
    learner:
      cur_lr: 0.001213812967762351
      grad_gnorm: 14.050942420959473
      policy_entropy: 41.34635925292969
      policy_loss: -5.699042797088623
      var_gnorm: 26.146209716796875
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 4.724384307861328
    num_steps_sampled: 2200000
    num_steps_trained: 2200000
    wait_time_ms: 77.916
  iterations_since_restore: 440
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3832.330956697464
  time_this_iter_s: 8.484517097473145
  time_total_s: 3832.330956697464
  timestamp: 1594859846
  timesteps_since_restore: 2200000
  timesteps_this_iter: 5000
  timesteps_total: 2200000
  training_iteration: 440
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3832 s, 440 iter, 2200000 ts, -679 rew

agent-1: -109.55354727970258
agent-2: -193.92729908073196
agent-3: -184.17939154775277
agent-4: -38.01974294844151
agent-5: -125.96612630502753
Extrinsic Rewards:
5
12
20
7
6
Sum Reward: 50
Avg Reward: 10.0
Min Reward: 5
Max Reward: 20
Gini Coefficient: 0.288
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-37-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -678.6577279083931
  episode_reward_min: -884.3453022394721
  episodes_this_iter: 1
  episodes_total: 440
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.448
    dispatch_time_ms: 8.037
    learner:
      cur_lr: 0.001213480019941926
      grad_gnorm: 15.98318099975586
      policy_entropy: 46.891849517822266
      policy_loss: -7.389187335968018
      var_gnorm: 26.122907638549805
      vf_explained_var: 0.0
      vf_loss: 4.45719575881958
    num_steps_sampled: 2205000
    num_steps_trained: 2205000
    wait_time_ms: 73.183
  iterations_since_restore: 441
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3840.6780700683594
  time_this_iter_s: 8.347113370895386
  time_total_s: 3840.6780700683594
  timestamp: 1594859854
  timesteps_since_restore: 2205000
  timesteps_this_iter: 5000
  timesteps_total: 2205000
  training_iteration: 441
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3840 s, 441 iter, 2205000 ts, -679 rew

agent-1: -36.841441710874534
agent-2: -203.40680675958075
agent-3: -277.3024196320494
agent-4: -148.72370604772442
agent-5: -148.72370604772442
Extrinsic Rewards:
1
4
11
0
0
Sum Reward: 16
Avg Reward: 3.2
Min Reward: 0
Max Reward: 11
Gini Coefficient: 0.65
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-37-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -680.024966949779
  episode_reward_min: -884.3453022394721
  episodes_this_iter: 1
  episodes_total: 441
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.717
    dispatch_time_ms: 8.825
    learner:
      cur_lr: 0.0012131469557061791
      grad_gnorm: 17.23811912536621
      policy_entropy: 44.166465759277344
      policy_loss: 4.114683628082275
      var_gnorm: 26.196073532104492
      vf_explained_var: 0.0
      vf_loss: 4.643260478973389
    num_steps_sampled: 2210000
    num_steps_trained: 2210000
    wait_time_ms: 73.386
  iterations_since_restore: 442
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3849.013345718384
  time_this_iter_s: 8.335275650024414
  time_total_s: 3849.013345718384
  timestamp: 1594859863
  timesteps_since_restore: 2210000
  timesteps_this_iter: 5000
  timesteps_total: 2210000
  training_iteration: 442
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3849 s, 442 iter, 2210000 ts, -680 rew

agent-1: -67.05405566710417
agent-2: -165.5336051408518
agent-3: -57.893145325560916
agent-4: -150.30833959634217
agent-5: -231.19517485436413
Extrinsic Rewards:
3
8
1
3
14
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 1
Max Reward: 14
Gini Coefficient: 0.42758620689655175
20:20 Ratio: 14.0
Max-min Ratio: 14.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-37-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -679.500558205204
  episode_reward_min: -884.3453022394721
  episodes_this_iter: 1
  episodes_total: 442
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.213
    dispatch_time_ms: 9.926
    learner:
      cur_lr: 0.0012128140078857541
      grad_gnorm: 11.672876358032227
      policy_entropy: 54.48158264160156
      policy_loss: -3.327500104904175
      var_gnorm: 26.1545352935791
      vf_explained_var: 0.0
      vf_loss: 4.56423807144165
    num_steps_sampled: 2215000
    num_steps_trained: 2215000
    wait_time_ms: 72.068
  iterations_since_restore: 443
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3857.5000886917114
  time_this_iter_s: 8.486742973327637
  time_total_s: 3857.5000886917114
  timestamp: 1594859871
  timesteps_since_restore: 2215000
  timesteps_this_iter: 5000
  timesteps_total: 2215000
  training_iteration: 443
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3857 s, 443 iter, 2215000 ts, -680 rew

agent-1: -211.3451447321588
agent-2: -128.74002496747528
agent-3: -71.80914409217682
agent-4: -154.64453719206276
agent-5: -145.54833450027994
Extrinsic Rewards:
5
7
2
7
5
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 2
Max Reward: 7
Gini Coefficient: 0.18461538461538463
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-37-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -680.4687600270769
  episode_reward_min: -884.3453022394721
  episodes_this_iter: 1
  episodes_total: 443
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.684
    dispatch_time_ms: 8.034
    learner:
      cur_lr: 0.0012124809436500072
      grad_gnorm: 40.0
      policy_entropy: 59.57747268676758
      policy_loss: 36.19991683959961
      var_gnorm: 26.198360443115234
      vf_explained_var: 0.0
      vf_loss: 21.96848487854004
    num_steps_sampled: 2220000
    num_steps_trained: 2220000
    wait_time_ms: 73.92
  iterations_since_restore: 444
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3865.824248313904
  time_this_iter_s: 8.324159622192383
  time_total_s: 3865.824248313904
  timestamp: 1594859879
  timesteps_since_restore: 2220000
  timesteps_this_iter: 5000
  timesteps_total: 2220000
  training_iteration: 444
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3865 s, 444 iter, 2220000 ts, -680 rew

agent-1: -94.5337540072889
agent-2: -249.45797673571334
agent-3: -208.79028191104754
agent-4: -152.40068671645395
agent-5: -92.81453459854843
Extrinsic Rewards:
1
7
5
0
2
Sum Reward: 15
Avg Reward: 3.0
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.48
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-38-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -683.1542602975007
  episode_reward_min: -884.3453022394721
  episodes_this_iter: 1
  episodes_total: 444
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.832
    dispatch_time_ms: 8.279
    learner:
      cur_lr: 0.0012121479958295822
      grad_gnorm: 39.999996185302734
      policy_entropy: 60.20022201538086
      policy_loss: 7.663487434387207
      var_gnorm: 26.153892517089844
      vf_explained_var: 0.0
      vf_loss: 6.873577117919922
    num_steps_sampled: 2225000
    num_steps_trained: 2225000
    wait_time_ms: 69.561
  iterations_since_restore: 445
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3874.1963772773743
  time_this_iter_s: 8.372128963470459
  time_total_s: 3874.1963772773743
  timestamp: 1594859888
  timesteps_since_restore: 2225000
  timesteps_this_iter: 5000
  timesteps_total: 2225000
  training_iteration: 445
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3874 s, 445 iter, 2225000 ts, -683 rew

agent-1: -107.10688403212896
agent-2: -88.33400663442745
agent-3: -181.53326993321002
agent-4: -206.46270838330156
agent-5: -143.87866498524698
Extrinsic Rewards:
4
3
7
6
3
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 3
Max Reward: 7
Gini Coefficient: 0.19130434782608696
20:20 Ratio: 2.3333333333333335
Max-min Ratio: 2.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-38-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -684.7949109041685
  episode_reward_min: -884.3453022394721
  episodes_this_iter: 1
  episodes_total: 445
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.697
    dispatch_time_ms: 7.655
    learner:
      cur_lr: 0.0012118150480091572
      grad_gnorm: 39.999996185302734
      policy_entropy: 59.82377243041992
      policy_loss: 18.944133758544922
      var_gnorm: 26.147022247314453
      vf_explained_var: 0.0
      vf_loss: 9.345687866210938
    num_steps_sampled: 2230000
    num_steps_trained: 2230000
    wait_time_ms: 73.244
  iterations_since_restore: 446
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3882.5744800567627
  time_this_iter_s: 8.378102779388428
  time_total_s: 3882.5744800567627
  timestamp: 1594859896
  timesteps_since_restore: 2230000
  timesteps_this_iter: 5000
  timesteps_total: 2230000
  training_iteration: 446
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3882 s, 446 iter, 2230000 ts, -685 rew

agent-1: -262.36491598369713
agent-2: -112.58508074480486
agent-3: -131.40856301343712
agent-4: -60.024389858982865
agent-5: -38.636219267356225
Extrinsic Rewards:
7
6
5
2
2
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 2
Max Reward: 7
Gini Coefficient: 0.2545454545454545
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-38-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -684.8226778489635
  episode_reward_min: -884.3453022394721
  episodes_this_iter: 1
  episodes_total: 446
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.814
    dispatch_time_ms: 9.509
    learner:
      cur_lr: 0.0012114819837734103
      grad_gnorm: 5.926730155944824
      policy_entropy: 53.07383728027344
      policy_loss: -1.7359715700149536
      var_gnorm: 26.148357391357422
      vf_explained_var: 0.0
      vf_loss: 5.479820728302002
    num_steps_sampled: 2235000
    num_steps_trained: 2235000
    wait_time_ms: 72.334
  iterations_since_restore: 447
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3891.3500814437866
  time_this_iter_s: 8.775601387023926
  time_total_s: 3891.3500814437866
  timestamp: 1594859905
  timesteps_since_restore: 2235000
  timesteps_this_iter: 5000
  timesteps_total: 2235000
  training_iteration: 447
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3891 s, 447 iter, 2235000 ts, -685 rew

agent-1: -80.50312827695195
agent-2: -50.55400657555343
agent-3: -227.61380618461087
agent-4: -215.42844436341042
agent-5: -104.81942181245884
Extrinsic Rewards:
3
1
8
5
3
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.32
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-38-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -683.5284980296408
  episode_reward_min: -884.3453022394721
  episodes_this_iter: 1
  episodes_total: 447
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.822
    dispatch_time_ms: 6.584
    learner:
      cur_lr: 0.0012111490359529853
      grad_gnorm: 29.458011627197266
      policy_entropy: 51.23846435546875
      policy_loss: 10.12208080291748
      var_gnorm: 26.15576171875
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 9.420900344848633
    num_steps_sampled: 2240000
    num_steps_trained: 2240000
    wait_time_ms: 75.744
  iterations_since_restore: 448
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3899.767221927643
  time_this_iter_s: 8.417140483856201
  time_total_s: 3899.767221927643
  timestamp: 1594859914
  timesteps_since_restore: 2240000
  timesteps_this_iter: 5000
  timesteps_total: 2240000
  training_iteration: 448
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3899 s, 448 iter, 2240000 ts, -684 rew

agent-1: -132.5646864596155
agent-2: -93.28334973602178
agent-3: -234.42622195774277
agent-4: -165.1703007434767
agent-5: -63.062413887140764
Extrinsic Rewards:
2
3
7
7
3
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 2
Max Reward: 7
Gini Coefficient: 0.2545454545454545
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-38-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -684.1578205930825
  episode_reward_min: -884.3453022394721
  episodes_this_iter: 1
  episodes_total: 448
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.268
    dispatch_time_ms: 9.221
    learner:
      cur_lr: 0.0012108159717172384
      grad_gnorm: 10.276089668273926
      policy_entropy: 46.0273323059082
      policy_loss: 1.27322518825531
      var_gnorm: 26.14995765686035
      vf_explained_var: 0.0
      vf_loss: 5.124881744384766
    num_steps_sampled: 2245000
    num_steps_trained: 2245000
    wait_time_ms: 75.286
  iterations_since_restore: 449
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3908.1201531887054
  time_this_iter_s: 8.352931261062622
  time_total_s: 3908.1201531887054
  timestamp: 1594859922
  timesteps_since_restore: 2245000
  timesteps_this_iter: 5000
  timesteps_total: 2245000
  training_iteration: 449
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3908 s, 449 iter, 2245000 ts, -684 rew

agent-1: -107.44268411048245
agent-2: -144.24767156185618
agent-3: -209.9384863969983
agent-4: -210.0323653983842
agent-5: -13.319107554578192
Extrinsic Rewards:
3
2
7
8
1
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.3619047619047619
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-38-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -684.3779199657592
  episode_reward_min: -884.3453022394721
  episodes_this_iter: 1
  episodes_total: 449
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.214
    dispatch_time_ms: 7.514
    learner:
      cur_lr: 0.0012104830238968134
      grad_gnorm: 22.202869415283203
      policy_entropy: 22.47257423400879
      policy_loss: -4.610581398010254
      var_gnorm: 26.204212188720703
      vf_explained_var: 0.0
      vf_loss: 7.238152027130127
    num_steps_sampled: 2250000
    num_steps_trained: 2250000
    wait_time_ms: 71.126
  iterations_since_restore: 450
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3916.526528596878
  time_this_iter_s: 8.406375408172607
  time_total_s: 3916.526528596878
  timestamp: 1594859930
  timesteps_since_restore: 2250000
  timesteps_this_iter: 5000
  timesteps_total: 2250000
  training_iteration: 450
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3916 s, 450 iter, 2250000 ts, -684 rew

agent-1: -102.68566160083863
agent-2: -157.83560971921264
agent-3: -260.8476075794701
agent-4: -115.31241554387871
agent-5: -147.06907093185262
Extrinsic Rewards:
3
3
8
3
0
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.3764705882352941
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-38-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -684.7626618723158
  episode_reward_min: -884.3453022394721
  episodes_this_iter: 1
  episodes_total: 450
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.449
    dispatch_time_ms: 11.081
    learner:
      cur_lr: 0.0012101499596610665
      grad_gnorm: 10.53471851348877
      policy_entropy: 43.16914367675781
      policy_loss: 3.3433923721313477
      var_gnorm: 26.136503219604492
      vf_explained_var: 0.0
      vf_loss: 7.685949325561523
    num_steps_sampled: 2255000
    num_steps_trained: 2255000
    wait_time_ms: 69.329
  iterations_since_restore: 451
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3924.7697076797485
  time_this_iter_s: 8.243179082870483
  time_total_s: 3924.7697076797485
  timestamp: 1594859939
  timesteps_since_restore: 2255000
  timesteps_this_iter: 5000
  timesteps_total: 2255000
  training_iteration: 451
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3924 s, 451 iter, 2255000 ts, -685 rew

agent-1: -103.15182680185703
agent-2: -114.7359685858397
agent-3: -51.425968409059315
agent-4: -193.90249666548124
agent-5: -119.11982018112447
Extrinsic Rewards:
13
18
10
19
16
Sum Reward: 76
Avg Reward: 15.2
Min Reward: 10
Max Reward: 19
Gini Coefficient: 0.12105263157894737
20:20 Ratio: 1.9
Max-min Ratio: 1.9
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-39-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -682.6107541980507
  episode_reward_min: -884.3453022394721
  episodes_this_iter: 1
  episodes_total: 451
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.811
    dispatch_time_ms: 6.297
    learner:
      cur_lr: 0.0012098170118406415
      grad_gnorm: 17.20183563232422
      policy_entropy: 35.66651153564453
      policy_loss: -3.7921884059906006
      var_gnorm: 26.127042770385742
      vf_explained_var: 0.0
      vf_loss: 7.5521111488342285
    num_steps_sampled: 2260000
    num_steps_trained: 2260000
    wait_time_ms: 73.44
  iterations_since_restore: 452
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3933.149235725403
  time_this_iter_s: 8.379528045654297
  time_total_s: 3933.149235725403
  timestamp: 1594859947
  timesteps_since_restore: 2260000
  timesteps_this_iter: 5000
  timesteps_total: 2260000
  training_iteration: 452
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3933 s, 452 iter, 2260000 ts, -683 rew

agent-1: -72.90827354337077
agent-2: -94.29221361207921
agent-3: -32.878429173872306
agent-4: -96.14067741999693
agent-5: -252.03629358312492
Extrinsic Rewards:
7
13
2
8
19
Sum Reward: 49
Avg Reward: 9.8
Min Reward: 2
Max Reward: 19
Gini Coefficient: 0.32653061224489793
20:20 Ratio: 9.5
Max-min Ratio: 9.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-39-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -682.2685915812849
  episode_reward_min: -884.3453022394721
  episodes_this_iter: 1
  episodes_total: 452
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.712
    dispatch_time_ms: 7.322
    learner:
      cur_lr: 0.0012094839476048946
      grad_gnorm: 32.79956817626953
      policy_entropy: 46.235755920410156
      policy_loss: -5.7015485763549805
      var_gnorm: 26.12247657775879
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 14.468173027038574
    num_steps_sampled: 2265000
    num_steps_trained: 2265000
    wait_time_ms: 66.994
  iterations_since_restore: 453
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3941.5092532634735
  time_this_iter_s: 8.360017538070679
  time_total_s: 3941.5092532634735
  timestamp: 1594859955
  timesteps_since_restore: 2265000
  timesteps_this_iter: 5000
  timesteps_total: 2265000
  training_iteration: 453
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3941 s, 453 iter, 2265000 ts, -682 rew

agent-1: -4.419950779072359
agent-2: -14.806070192271575
agent-3: -21.37603525788398
agent-4: -207.71397949580464
agent-5: -247.78896584672802
Extrinsic Rewards:
1
3
4
18
19
Sum Reward: 45
Avg Reward: 9.0
Min Reward: 1
Max Reward: 19
Gini Coefficient: 0.4533333333333333
20:20 Ratio: 19.0
Max-min Ratio: 19.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-39-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -679.7163559016881
  episode_reward_min: -884.3453022394721
  episodes_this_iter: 1
  episodes_total: 453
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.848
    dispatch_time_ms: 6.837
    learner:
      cur_lr: 0.0012091509997844696
      grad_gnorm: 40.0
      policy_entropy: 42.67393112182617
      policy_loss: -16.735118865966797
      var_gnorm: 26.15982437133789
      vf_explained_var: 0.0
      vf_loss: 8.887043952941895
    num_steps_sampled: 2270000
    num_steps_trained: 2270000
    wait_time_ms: 75.714
  iterations_since_restore: 454
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3949.908808708191
  time_this_iter_s: 8.399555444717407
  time_total_s: 3949.908808708191
  timestamp: 1594859964
  timesteps_since_restore: 2270000
  timesteps_this_iter: 5000
  timesteps_total: 2270000
  training_iteration: 454
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3949 s, 454 iter, 2270000 ts, -680 rew

agent-1: -202.35992941072365
agent-2: -141.2031314193699
agent-3: -82.98218964530263
agent-4: -235.05841217621656
agent-5: -146.23365745562995
Extrinsic Rewards:
5
5
1
7
0
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.4
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-39-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -681.0170874552749
  episode_reward_min: -884.3453022394721
  episodes_this_iter: 1
  episodes_total: 454
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.9
    dispatch_time_ms: 7.635
    learner:
      cur_lr: 0.0012088180519640446
      grad_gnorm: 4.951639175415039
      policy_entropy: 44.7203369140625
      policy_loss: -1.1523768901824951
      var_gnorm: 26.150976181030273
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 6.451208114624023
    num_steps_sampled: 2275000
    num_steps_trained: 2275000
    wait_time_ms: 73.323
  iterations_since_restore: 455
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3958.2760956287384
  time_this_iter_s: 8.367286920547485
  time_total_s: 3958.2760956287384
  timestamp: 1594859972
  timesteps_since_restore: 2275000
  timesteps_this_iter: 5000
  timesteps_total: 2275000
  training_iteration: 455
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3958 s, 455 iter, 2275000 ts, -681 rew

agent-1: -66.19232229973518
agent-2: -24.412431024918853
agent-3: -180.16098465335202
agent-4: -218.71387134991184
agent-5: -178.40286152344004
Extrinsic Rewards:
4
3
8
8
7
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 3
Max Reward: 8
Gini Coefficient: 0.18666666666666668
20:20 Ratio: 2.6666666666666665
Max-min Ratio: 2.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-39-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -680.6551785375831
  episode_reward_min: -884.3453022394721
  episodes_this_iter: 1
  episodes_total: 455
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.356
    dispatch_time_ms: 6.99
    learner:
      cur_lr: 0.0012084849877282977
      grad_gnorm: 7.832708835601807
      policy_entropy: 42.44639587402344
      policy_loss: 0.3786146640777588
      var_gnorm: 26.155046463012695
      vf_explained_var: 0.0
      vf_loss: 5.871562480926514
    num_steps_sampled: 2280000
    num_steps_trained: 2280000
    wait_time_ms: 72.756
  iterations_since_restore: 456
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3966.612819671631
  time_this_iter_s: 8.336724042892456
  time_total_s: 3966.612819671631
  timestamp: 1594859981
  timesteps_since_restore: 2280000
  timesteps_this_iter: 5000
  timesteps_total: 2280000
  training_iteration: 456
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3966 s, 456 iter, 2280000 ts, -681 rew

agent-1: -213.36647867856104
agent-2: -177.9998439463989
agent-3: -26.343194247588084
agent-4: -141.42969271141718
agent-5: -99.05719369449335
Extrinsic Rewards:
5
5
3
11
6
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 3
Max Reward: 11
Gini Coefficient: 0.22666666666666666
20:20 Ratio: 3.6666666666666665
Max-min Ratio: 3.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-39-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -680.6878482927162
  episode_reward_min: -884.3453022394721
  episodes_this_iter: 1
  episodes_total: 456
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.332
    dispatch_time_ms: 7.733
    learner:
      cur_lr: 0.0012081520399078727
      grad_gnorm: 9.490022659301758
      policy_entropy: 34.66450881958008
      policy_loss: -1.9683760404586792
      var_gnorm: 26.143997192382812
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.56144905090332
    num_steps_sampled: 2285000
    num_steps_trained: 2285000
    wait_time_ms: 72.935
  iterations_since_restore: 457
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3974.959287881851
  time_this_iter_s: 8.346468210220337
  time_total_s: 3974.959287881851
  timestamp: 1594859989
  timesteps_since_restore: 2285000
  timesteps_this_iter: 5000
  timesteps_total: 2285000
  training_iteration: 457
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3974 s, 457 iter, 2285000 ts, -681 rew

agent-1: -91.23874273625479
agent-2: -147.56386526015976
agent-3: -147.56386526015976
agent-4: -247.03495770625565
agent-5: -244.1745368609773
Extrinsic Rewards:
2
0
0
7
7
Sum Reward: 16
Avg Reward: 3.2
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.525
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-39-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -681.8972496534171
  episode_reward_min: -884.3453022394721
  episodes_this_iter: 1
  episodes_total: 457
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.321
    dispatch_time_ms: 7.852
    learner:
      cur_lr: 0.0012078189756721258
      grad_gnorm: 25.437484741210938
      policy_entropy: 49.51719284057617
      policy_loss: 6.847567081451416
      var_gnorm: 26.209556579589844
      vf_explained_var: 0.0
      vf_loss: 5.976315021514893
    num_steps_sampled: 2290000
    num_steps_trained: 2290000
    wait_time_ms: 71.549
  iterations_since_restore: 458
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3983.323690891266
  time_this_iter_s: 8.364403009414673
  time_total_s: 3983.323690891266
  timestamp: 1594859997
  timesteps_since_restore: 2290000
  timesteps_this_iter: 5000
  timesteps_total: 2290000
  training_iteration: 458
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3983 s, 458 iter, 2290000 ts, -682 rew

agent-1: -167.8269594590174
agent-2: -196.03488877363085
agent-3: -205.44114687183676
agent-4: -17.636993087913464
agent-5: -97.42139031533999
Extrinsic Rewards:
10
6
6
1
5
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 1
Max Reward: 10
Gini Coefficient: 0.2714285714285714
20:20 Ratio: 10.0
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-40-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -682.0474314282826
  episode_reward_min: -884.3453022394721
  episodes_this_iter: 1
  episodes_total: 458
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.794
    dispatch_time_ms: 8.207
    learner:
      cur_lr: 0.0012074860278517008
      grad_gnorm: 17.729106903076172
      policy_entropy: 44.03925323486328
      policy_loss: -0.40233486890792847
      var_gnorm: 26.152463912963867
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 6.540511608123779
    num_steps_sampled: 2295000
    num_steps_trained: 2295000
    wait_time_ms: 72.848
  iterations_since_restore: 459
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3991.6357684135437
  time_this_iter_s: 8.312077522277832
  time_total_s: 3991.6357684135437
  timestamp: 1594860006
  timesteps_since_restore: 2295000
  timesteps_this_iter: 5000
  timesteps_total: 2295000
  training_iteration: 459
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3991 s, 459 iter, 2295000 ts, -682 rew

agent-1: -182.55703696929967
agent-2: -70.29547224912879
agent-3: -111.68102094747017
agent-4: -211.95231780781546
agent-5: -37.74964796545654
Extrinsic Rewards:
21
4
6
7
4
Sum Reward: 42
Avg Reward: 8.4
Min Reward: 4
Max Reward: 21
Gini Coefficient: 0.3523809523809524
20:20 Ratio: 5.25
Max-min Ratio: 5.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-40-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -683.1616585294021
  episode_reward_min: -884.3453022394721
  episodes_this_iter: 1
  episodes_total: 459
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.748
    dispatch_time_ms: 6.859
    learner:
      cur_lr: 0.001207152963615954
      grad_gnorm: 11.151510238647461
      policy_entropy: 44.3122673034668
      policy_loss: 0.45748764276504517
      var_gnorm: 26.149776458740234
      vf_explained_var: 0.0
      vf_loss: 6.546570301055908
    num_steps_sampled: 2300000
    num_steps_trained: 2300000
    wait_time_ms: 71.79
  iterations_since_restore: 460
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 3999.94323015213
  time_this_iter_s: 8.307461738586426
  time_total_s: 3999.94323015213
  timestamp: 1594860014
  timesteps_since_restore: 2300000
  timesteps_this_iter: 5000
  timesteps_total: 2300000
  training_iteration: 460
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 3999 s, 460 iter, 2300000 ts, -683 rew

agent-1: -117.44889622386826
agent-2: -37.23371386449464
agent-3: -72.60091532198162
agent-4: -191.28251549470198
agent-5: -226.9558112144444
Extrinsic Rewards:
3
7
2
9
9
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 2
Max Reward: 9
Gini Coefficient: 0.26666666666666666
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-40-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -683.7750494364201
  episode_reward_min: -884.3453022394721
  episodes_this_iter: 1
  episodes_total: 460
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.668
    dispatch_time_ms: 10.109
    learner:
      cur_lr: 0.0012068200157955289
      grad_gnorm: 15.308355331420898
      policy_entropy: 44.80275344848633
      policy_loss: -1.5715011358261108
      var_gnorm: 26.148122787475586
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 5.754544258117676
    num_steps_sampled: 2305000
    num_steps_trained: 2305000
    wait_time_ms: 357.313
  iterations_since_restore: 461
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4011.093137025833
  time_this_iter_s: 11.149906873703003
  time_total_s: 4011.093137025833
  timestamp: 1594860025
  timesteps_since_restore: 2305000
  timesteps_this_iter: 5000
  timesteps_total: 2305000
  training_iteration: 461
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4011 s, 461 iter, 2305000 ts, -684 rew

agent-1: -171.96928730005834
agent-2: -22.01935958005773
agent-3: -120.37767490297118
agent-4: -210.69897667992925
agent-5: -181.5643695036769
Extrinsic Rewards:
5
1
2
6
6
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 1
Max Reward: 6
Gini Coefficient: 0.28
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-40-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -684.8639552076191
  episode_reward_min: -884.3453022394721
  episodes_this_iter: 1
  episodes_total: 461
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.661
    dispatch_time_ms: 7.564
    learner:
      cur_lr: 0.001206486951559782
      grad_gnorm: 40.0
      policy_entropy: 43.07939529418945
      policy_loss: 22.65980339050293
      var_gnorm: 26.155622482299805
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 30.08229637145996
    num_steps_sampled: 2310000
    num_steps_trained: 2310000
    wait_time_ms: 73.495
  iterations_since_restore: 462
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4018.9261059761047
  time_this_iter_s: 7.8329689502716064
  time_total_s: 4018.9261059761047
  timestamp: 1594860033
  timesteps_since_restore: 2310000
  timesteps_this_iter: 5000
  timesteps_total: 2310000
  training_iteration: 462
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4018 s, 462 iter, 2310000 ts, -685 rew

agent-1: -90.77932913379567
agent-2: -228.85116426936403
agent-3: -70.3832116389125
agent-4: -64.45689187642297
agent-5: -158.19762421837527
Extrinsic Rewards:
5
4
6
1
10
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 1
Max Reward: 10
Gini Coefficient: 0.3076923076923077
20:20 Ratio: 10.0
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-40-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -683.4365259615611
  episode_reward_min: -884.3453022394721
  episodes_this_iter: 1
  episodes_total: 462
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.909
    dispatch_time_ms: 7.823
    learner:
      cur_lr: 0.001206154003739357
      grad_gnorm: 8.92233657836914
      policy_entropy: 35.60836410522461
      policy_loss: 3.263059377670288
      var_gnorm: 26.14935302734375
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 5.1638898849487305
    num_steps_sampled: 2315000
    num_steps_trained: 2315000
    wait_time_ms: 73.86
  iterations_since_restore: 463
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4027.2921781539917
  time_this_iter_s: 8.366072177886963
  time_total_s: 4027.2921781539917
  timestamp: 1594860042
  timesteps_since_restore: 2315000
  timesteps_this_iter: 5000
  timesteps_total: 2315000
  training_iteration: 463
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4027 s, 463 iter, 2315000 ts, -683 rew

agent-1: -276.48736540008076
agent-2: -146.9124897540253
agent-3: -76.10742000242931
agent-4: -119.57748902208512
agent-5: -87.78905354002828
Extrinsic Rewards:
11
0
1
3
1
Sum Reward: 16
Avg Reward: 3.2
Min Reward: 0
Max Reward: 11
Gini Coefficient: 0.6
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-40-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -685.2823606256092
  episode_reward_min: -884.3453022394721
  episodes_this_iter: 1
  episodes_total: 463
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.762
    dispatch_time_ms: 4.993
    learner:
      cur_lr: 0.001205821055918932
      grad_gnorm: 40.000003814697266
      policy_entropy: 46.70234680175781
      policy_loss: 68.1766357421875
      var_gnorm: 26.200084686279297
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 118.13262939453125
    num_steps_sampled: 2320000
    num_steps_trained: 2320000
    wait_time_ms: 76.776
  iterations_since_restore: 464
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4035.76824593544
  time_this_iter_s: 8.476067781448364
  time_total_s: 4035.76824593544
  timestamp: 1594860050
  timesteps_since_restore: 2320000
  timesteps_this_iter: 5000
  timesteps_total: 2320000
  training_iteration: 464
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4035 s, 464 iter, 2320000 ts, -685 rew

agent-1: -152.24049209501138
agent-2: -114.42874293091316
agent-3: -197.5422113738716
agent-4: -151.96971551472512
agent-5: -133.26537233945277
Extrinsic Rewards:
4
3
4
4
3
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 3
Max Reward: 4
Gini Coefficient: 0.06666666666666667
20:20 Ratio: 1.3333333333333333
Max-min Ratio: 1.3333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-40-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -687.0107476418847
  episode_reward_min: -884.3453022394721
  episodes_this_iter: 1
  episodes_total: 464
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.689
    dispatch_time_ms: 7.73
    learner:
      cur_lr: 0.001205487991683185
      grad_gnorm: 8.051822662353516
      policy_entropy: 43.940521240234375
      policy_loss: -1.0163215398788452
      var_gnorm: 26.145170211791992
      vf_explained_var: 0.0
      vf_loss: 5.629188060760498
    num_steps_sampled: 2325000
    num_steps_trained: 2325000
    wait_time_ms: 73.971
  iterations_since_restore: 465
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4044.107136964798
  time_this_iter_s: 8.33889102935791
  time_total_s: 4044.107136964798
  timestamp: 1594860059
  timesteps_since_restore: 2325000
  timesteps_this_iter: 5000
  timesteps_total: 2325000
  training_iteration: 465
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4044 s, 465 iter, 2325000 ts, -687 rew

agent-1: -261.29611029854385
agent-2: -144.24866755353298
agent-3: -142.3371490120491
agent-4: -140.40388749696078
agent-5: -56.61864251916433
Extrinsic Rewards:
9
5
0
5
1
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.44
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: -53.8718249011929
agent-2: -140.44042750216622
agent-3: -68.4145965218002
agent-4: -55.65719930727346
agent-5: -264.67572668810976
Extrinsic Rewards:
3
7
1
4
9
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.3333333333333333
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-41-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -686.6176700710614
  episode_reward_min: -884.3453022394721
  episodes_this_iter: 2
  episodes_total: 466
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.668
    dispatch_time_ms: 8.73
    learner:
      cur_lr: 0.00120515504386276
      grad_gnorm: 40.000003814697266
      policy_entropy: 40.08701705932617
      policy_loss: 19.4360408782959
      var_gnorm: 26.182985305786133
      vf_explained_var: -0.25560104846954346
      vf_loss: 20.603986740112305
    num_steps_sampled: 2330000
    num_steps_trained: 2330000
    wait_time_ms: 72.343
  iterations_since_restore: 466
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4052.5615453720093
  time_this_iter_s: 8.454408407211304
  time_total_s: 4052.5615453720093
  timestamp: 1594860067
  timesteps_since_restore: 2330000
  timesteps_this_iter: 5000
  timesteps_total: 2330000
  training_iteration: 466
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4052 s, 466 iter, 2330000 ts, -687 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-41-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -686.6176700710613
  episode_reward_min: -884.3453022394721
  episodes_this_iter: 0
  episodes_total: 466
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.713
    dispatch_time_ms: 10.601
    learner:
      cur_lr: 0.0012048219796270132
      grad_gnorm: 12.113037109375
      policy_entropy: 45.36505126953125
      policy_loss: -2.911644697189331
      var_gnorm: 26.16588020324707
      vf_explained_var: 0.0
      vf_loss: 2.4340014457702637
    num_steps_sampled: 2335000
    num_steps_trained: 2335000
    wait_time_ms: 73.111
  iterations_since_restore: 467
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4060.880315065384
  time_this_iter_s: 8.318769693374634
  time_total_s: 4060.880315065384
  timestamp: 1594860075
  timesteps_since_restore: 2335000
  timesteps_this_iter: 5000
  timesteps_total: 2335000
  training_iteration: 467
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4060 s, 467 iter, 2335000 ts, -687 rew

agent-1: -138.74623660422662
agent-2: -246.77157946731282
agent-3: -184.64136620127329
agent-4: -138.74623660422662
agent-5: -192.1123393084845
Extrinsic Rewards:
0
9
6
0
6
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.45714285714285713
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: -153.40957064248337
agent-2: -192.31913999232572
agent-3: -69.03323202085632
agent-4: -136.82862337783655
agent-5: -149.07566338286645
Extrinsic Rewards:
8
8
7
8
5
Sum Reward: 36
Avg Reward: 7.2
Min Reward: 5
Max Reward: 8
Gini Coefficient: 0.07777777777777778
20:20 Ratio: 1.6
Max-min Ratio: 1.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-41-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -687.7883462798746
  episode_reward_min: -901.0177581855133
  episodes_this_iter: 2
  episodes_total: 468
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.031
    dispatch_time_ms: 8.38
    learner:
      cur_lr: 0.0012044890318065882
      grad_gnorm: 40.0
      policy_entropy: 42.44023132324219
      policy_loss: 812.6069946289062
      var_gnorm: 26.23472785949707
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 6796.37890625
    num_steps_sampled: 2340000
    num_steps_trained: 2340000
    wait_time_ms: 71.576
  iterations_since_restore: 468
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4069.246384382248
  time_this_iter_s: 8.366069316864014
  time_total_s: 4069.246384382248
  timestamp: 1594860084
  timesteps_since_restore: 2340000
  timesteps_this_iter: 5000
  timesteps_total: 2340000
  training_iteration: 468
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4069 s, 468 iter, 2340000 ts, -688 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-41-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -687.7883462798749
  episode_reward_min: -901.0177581855133
  episodes_this_iter: 0
  episodes_total: 468
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.343
    dispatch_time_ms: 9.155
    learner:
      cur_lr: 0.0012041559675708413
      grad_gnorm: 5.2327680587768555
      policy_entropy: 44.463905334472656
      policy_loss: 0.7962781190872192
      var_gnorm: 26.16767692565918
      vf_explained_var: 0.0
      vf_loss: 6.629725933074951
    num_steps_sampled: 2345000
    num_steps_trained: 2345000
    wait_time_ms: 71.801
  iterations_since_restore: 469
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4077.6264474391937
  time_this_iter_s: 8.3800630569458
  time_total_s: 4077.6264474391937
  timestamp: 1594860092
  timesteps_since_restore: 2345000
  timesteps_this_iter: 5000
  timesteps_total: 2345000
  training_iteration: 469
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4077 s, 469 iter, 2345000 ts, -688 rew

agent-1: -218.02666040499474
agent-2: -186.2807823178898
agent-3: -21.193596146080584
agent-4: -50.85161650261536
agent-5: -190.19223630231923
Extrinsic Rewards:
9
6
1
2
8
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.3384615384615385
20:20 Ratio: 9.0
Max-min Ratio: 9.0
agent-1: -132.16917008196114
agent-2: -96.92419310521402
agent-3: -88.82150735484937
agent-4: -193.31283428441236
agent-5: -244.99226149052416
Extrinsic Rewards:
0
4
6
7
6
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.2782608695652174
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-41-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -687.2781082077283
  episode_reward_min: -901.0177581855133
  episodes_this_iter: 2
  episodes_total: 470
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.243
    dispatch_time_ms: 6.74
    learner:
      cur_lr: 0.0012038230197504163
      grad_gnorm: 40.000003814697266
      policy_entropy: 46.313758850097656
      policy_loss: 774.8298950195312
      var_gnorm: 26.194536209106445
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 5481.77783203125
    num_steps_sampled: 2350000
    num_steps_trained: 2350000
    wait_time_ms: 75.266
  iterations_since_restore: 470
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4086.009463071823
  time_this_iter_s: 8.383015632629395
  time_total_s: 4086.009463071823
  timestamp: 1594860101
  timesteps_since_restore: 2350000
  timesteps_this_iter: 5000
  timesteps_total: 2350000
  training_iteration: 470
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4086 s, 470 iter, 2350000 ts, -687 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-41-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -487.0099902645439
  episode_reward_mean: -687.2781082077283
  episode_reward_min: -901.0177581855133
  episodes_this_iter: 0
  episodes_total: 470
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.727
    dispatch_time_ms: 5.908
    learner:
      cur_lr: 0.0012034899555146694
      grad_gnorm: 22.25712013244629
      policy_entropy: 45.70035934448242
      policy_loss: -5.976648330688477
      var_gnorm: 26.133859634399414
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 9.244274139404297
    num_steps_sampled: 2355000
    num_steps_trained: 2355000
    wait_time_ms: 74.255
  iterations_since_restore: 471
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4094.3077189922333
  time_this_iter_s: 8.298255920410156
  time_total_s: 4094.3077189922333
  timestamp: 1594860109
  timesteps_since_restore: 2355000
  timesteps_this_iter: 5000
  timesteps_total: 2355000
  training_iteration: 471
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4094 s, 471 iter, 2355000 ts, -687 rew

agent-1: -255.1401711025519
agent-2: -23.02895837340036
agent-3: -54.96630071215667
agent-4: -54.37215489052226
agent-5: -82.31087940411302
Extrinsic Rewards:
11
5
9
9
3
Sum Reward: 37
Avg Reward: 7.4
Min Reward: 3
Max Reward: 11
Gini Coefficient: 0.21621621621621623
20:20 Ratio: 3.6666666666666665
Max-min Ratio: 3.6666666666666665
agent-1: -207.41357810067328
agent-2: -120.48823864710819
agent-3: -183.76361768310693
agent-4: -214.22794554329295
agent-5: -18.819143746985073
Extrinsic Rewards:
4
0
10
14
1
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 0
Max Reward: 14
Gini Coefficient: 0.5103448275862069
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-41-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -685.1635692752451
  episode_reward_min: -901.0177581855133
  episodes_this_iter: 2
  episodes_total: 472
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.776
    dispatch_time_ms: 24.512
    learner:
      cur_lr: 0.0012031570076942444
      grad_gnorm: 40.000003814697266
      policy_entropy: 50.72930145263672
      policy_loss: 29.627864837646484
      var_gnorm: 26.142118453979492
      vf_explained_var: -1.0
      vf_loss: 15.320913314819336
    num_steps_sampled: 2360000
    num_steps_trained: 2360000
    wait_time_ms: 61.129
  iterations_since_restore: 472
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4103.021322965622
  time_this_iter_s: 8.713603973388672
  time_total_s: 4103.021322965622
  timestamp: 1594860118
  timesteps_since_restore: 2360000
  timesteps_this_iter: 5000
  timesteps_total: 2360000
  training_iteration: 472
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4103 s, 472 iter, 2360000 ts, -685 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-42-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -685.1635692752451
  episode_reward_min: -901.0177581855133
  episodes_this_iter: 0
  episodes_total: 472
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 4.396
    dispatch_time_ms: 29.276
    learner:
      cur_lr: 0.0012028239434584975
      grad_gnorm: 14.308926582336426
      policy_entropy: 56.42578887939453
      policy_loss: -4.386903285980225
      var_gnorm: 26.14679527282715
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 4.409177780151367
    num_steps_sampled: 2365000
    num_steps_trained: 2365000
    wait_time_ms: 56.141
  iterations_since_restore: 473
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4111.99250793457
  time_this_iter_s: 8.971184968948364
  time_total_s: 4111.99250793457
  timestamp: 1594860127
  timesteps_since_restore: 2365000
  timesteps_this_iter: 5000
  timesteps_total: 2365000
  training_iteration: 473
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4111 s, 473 iter, 2365000 ts, -685 rew

agent-1: -244.80527078427932
agent-2: -203.358683246849
agent-3: -34.90284919845001
agent-4: -23.459799878347507
agent-5: -130.6628455362227
Extrinsic Rewards:
9
5
2
1
3
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.38
20:20 Ratio: 9.0
Max-min Ratio: 9.0
agent-1: -135.09236483352026
agent-2: -168.67522294254343
agent-3: -63.34784124501645
agent-4: -221.10528063971188
agent-5: -82.31085763415305
Extrinsic Rewards:
8
6
3
4
4
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 3
Max Reward: 8
Gini Coefficient: 0.192
20:20 Ratio: 2.6666666666666665
Max-min Ratio: 2.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-42-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -683.7533750566608
  episode_reward_min: -901.0177581855133
  episodes_this_iter: 2
  episodes_total: 474
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.948
    dispatch_time_ms: 8.728
    learner:
      cur_lr: 0.0012024909956380725
      grad_gnorm: 40.0
      policy_entropy: 46.42824172973633
      policy_loss: 587.057373046875
      var_gnorm: 26.149547576904297
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 4045.9677734375
    num_steps_sampled: 2370000
    num_steps_trained: 2370000
    wait_time_ms: 71.071
  iterations_since_restore: 474
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4120.612561702728
  time_this_iter_s: 8.620053768157959
  time_total_s: 4120.612561702728
  timestamp: 1594860135
  timesteps_since_restore: 2370000
  timesteps_this_iter: 5000
  timesteps_total: 2370000
  training_iteration: 474
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4120 s, 474 iter, 2370000 ts, -684 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-42-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -683.7533750566611
  episode_reward_min: -901.0177581855133
  episodes_this_iter: 0
  episodes_total: 474
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.644
    dispatch_time_ms: 9.327
    learner:
      cur_lr: 0.0012021580478176475
      grad_gnorm: 7.000734329223633
      policy_entropy: 47.51045227050781
      policy_loss: 1.6474298238754272
      var_gnorm: 26.141366958618164
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 5.58651876449585
    num_steps_sampled: 2375000
    num_steps_trained: 2375000
    wait_time_ms: 72.066
  iterations_since_restore: 475
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4128.939788103104
  time_this_iter_s: 8.327226400375366
  time_total_s: 4128.939788103104
  timestamp: 1594860144
  timesteps_since_restore: 2375000
  timesteps_this_iter: 5000
  timesteps_total: 2375000
  training_iteration: 475
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4128 s, 475 iter, 2375000 ts, -684 rew

agent-1: -245.14829086787753
agent-2: -68.85643958565225
agent-3: -101.16970865113178
agent-4: -71.38663178661955
agent-5: -131.76360458262195
Extrinsic Rewards:
5
6
5
5
5
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 5
Max Reward: 6
Gini Coefficient: 0.03076923076923077
20:20 Ratio: 1.2
Max-min Ratio: 1.2
agent-1: -226.3505134415562
agent-2: -128.89998943117897
agent-3: -152.53543547216015
agent-4: -56.58029418176148
agent-5: -210.63177386420287
Extrinsic Rewards:
10
0
4
3
9
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 0
Max Reward: 10
Gini Coefficient: 0.4
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-42-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -683.9920342216819
  episode_reward_min: -901.0177581855133
  episodes_this_iter: 1
  episodes_total: 475
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.011
    dispatch_time_ms: 11.585
    learner:
      cur_lr: 0.0012018249835819006
      grad_gnorm: 30.927047729492188
      policy_entropy: 41.29739761352539
      policy_loss: 17.295318603515625
      var_gnorm: 26.180923461914062
      vf_explained_var: -1.0
      vf_loss: 20.156103134155273
    num_steps_sampled: 2380000
    num_steps_trained: 2380000
    wait_time_ms: 66.83
  iterations_since_restore: 476
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4137.2637593746185
  time_this_iter_s: 8.323971271514893
  time_total_s: 4137.2637593746185
  timestamp: 1594860152
  timesteps_since_restore: 2380000
  timesteps_this_iter: 5000
  timesteps_total: 2380000
  training_iteration: 476
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4137 s, 476 iter, 2380000 ts, -684 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-42-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -685.1104278996058
  episode_reward_min: -901.0177581855133
  episodes_this_iter: 1
  episodes_total: 476
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.422
    dispatch_time_ms: 8.649
    learner:
      cur_lr: 0.0012014920357614756
      grad_gnorm: 13.933555603027344
      policy_entropy: 47.55276107788086
      policy_loss: -3.6646511554718018
      var_gnorm: 26.16924476623535
      vf_explained_var: 0.0
      vf_loss: 2.515678882598877
    num_steps_sampled: 2385000
    num_steps_trained: 2385000
    wait_time_ms: 74.018
  iterations_since_restore: 477
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4145.65505194664
  time_this_iter_s: 8.391292572021484
  time_total_s: 4145.65505194664
  timestamp: 1594860161
  timesteps_since_restore: 2385000
  timesteps_this_iter: 5000
  timesteps_total: 2385000
  training_iteration: 477
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4145 s, 477 iter, 2385000 ts, -685 rew

agent-1: -213.3409014015157
agent-2: -169.44954512385766
agent-3: -109.41037054691506
agent-4: -142.72477405478995
agent-5: -200.9653192504046
Extrinsic Rewards:
8
4
2
0
5
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.4
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: -117.90939079231573
agent-2: -176.6303327172005
agent-3: -146.13196480840057
agent-4: -201.512201152145
agent-5: -206.13925119798262
Extrinsic Rewards:
3
3
0
6
5
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 0
Max Reward: 6
Gini Coefficient: 0.32941176470588235
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-42-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -686.5001581787506
  episode_reward_min: -901.0177581855133
  episodes_this_iter: 2
  episodes_total: 478
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.415
    dispatch_time_ms: 8.841
    learner:
      cur_lr: 0.0012011589715257287
      grad_gnorm: 40.000003814697266
      policy_entropy: 54.29494094848633
      policy_loss: 1017.6600341796875
      var_gnorm: 26.26732063293457
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 8171.2822265625
    num_steps_sampled: 2390000
    num_steps_trained: 2390000
    wait_time_ms: 71.769
  iterations_since_restore: 478
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4154.049602031708
  time_this_iter_s: 8.394550085067749
  time_total_s: 4154.049602031708
  timestamp: 1594860169
  timesteps_since_restore: 2390000
  timesteps_this_iter: 5000
  timesteps_total: 2390000
  training_iteration: 478
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4154 s, 478 iter, 2390000 ts, -687 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-42-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -686.5001581787504
  episode_reward_min: -901.0177581855133
  episodes_this_iter: 0
  episodes_total: 478
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.325
    dispatch_time_ms: 10.678
    learner:
      cur_lr: 0.0012008260237053037
      grad_gnorm: 9.323360443115234
      policy_entropy: 51.83765411376953
      policy_loss: 1.5568033456802368
      var_gnorm: 26.18632698059082
      vf_explained_var: 0.0
      vf_loss: 2.409876823425293
    num_steps_sampled: 2395000
    num_steps_trained: 2395000
    wait_time_ms: 70.489
  iterations_since_restore: 479
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4162.391840696335
  time_this_iter_s: 8.342238664627075
  time_total_s: 4162.391840696335
  timestamp: 1594860177
  timesteps_since_restore: 2395000
  timesteps_this_iter: 5000
  timesteps_total: 2395000
  training_iteration: 479
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4162 s, 479 iter, 2395000 ts, -687 rew

agent-1: -173.01155147108747
agent-2: -36.87831671856006
agent-3: -131.788014695154
agent-4: -23.065490098970827
agent-5: -250.59652519561084
Extrinsic Rewards:
8
3
3
2
10
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 2
Max Reward: 10
Gini Coefficient: 0.3230769230769231
20:20 Ratio: 5.0
Max-min Ratio: 5.0
agent-1: -170.10864839154658
agent-2: -213.54900434421305
agent-3: -147.0241971803223
agent-4: -85.32248855181768
agent-5: -104.89884762680747
Extrinsic Rewards:
5
4
1
3
5
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 1
Max Reward: 5
Gini Coefficient: 0.2222222222222222
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-43-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -685.5559779582819
  episode_reward_min: -901.0177581855133
  episodes_this_iter: 2
  episodes_total: 480
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.819
    dispatch_time_ms: 6.869
    learner:
      cur_lr: 0.0012004929594695568
      grad_gnorm: 40.0
      policy_entropy: 52.79286575317383
      policy_loss: 27.240888595581055
      var_gnorm: 26.166061401367188
      vf_explained_var: 0.034545838832855225
      vf_loss: 26.857107162475586
    num_steps_sampled: 2400000
    num_steps_trained: 2400000
    wait_time_ms: 74.079
  iterations_since_restore: 480
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4170.818832397461
  time_this_iter_s: 8.426991701126099
  time_total_s: 4170.818832397461
  timestamp: 1594860186
  timesteps_since_restore: 2400000
  timesteps_this_iter: 5000
  timesteps_total: 2400000
  training_iteration: 480
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4170 s, 480 iter, 2400000 ts, -686 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-43-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -685.5559779582819
  episode_reward_min: -901.0177581855133
  episodes_this_iter: 0
  episodes_total: 480
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.852
    dispatch_time_ms: 8.014
    learner:
      cur_lr: 0.0012001600116491318
      grad_gnorm: 19.250221252441406
      policy_entropy: 47.66700744628906
      policy_loss: -7.281580924987793
      var_gnorm: 26.157508850097656
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 4.565704345703125
    num_steps_sampled: 2405000
    num_steps_trained: 2405000
    wait_time_ms: 75.641
  iterations_since_restore: 481
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4179.191912889481
  time_this_iter_s: 8.373080492019653
  time_total_s: 4179.191912889481
  timestamp: 1594860194
  timesteps_since_restore: 2405000
  timesteps_this_iter: 5000
  timesteps_total: 2405000
  training_iteration: 481
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4179 s, 481 iter, 2405000 ts, -686 rew

agent-1: -161.49703788086538
agent-2: -63.93011745459956
agent-3: -150.79131786450864
agent-4: -123.86962761518384
agent-5: -265.39330355849603
Extrinsic Rewards:
2
1
0
3
9
Sum Reward: 15
Avg Reward: 3.0
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.5333333333333333
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-43-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -686.7409643206373
  episode_reward_min: -901.0177581855133
  episodes_this_iter: 1
  episodes_total: 481
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.879
    dispatch_time_ms: 9.341
    learner:
      cur_lr: 0.001199826947413385
      grad_gnorm: 39.999996185302734
      policy_entropy: 47.90663528442383
      policy_loss: 27.298486709594727
      var_gnorm: 26.203006744384766
      vf_explained_var: -0.11427414417266846
      vf_loss: 30.544017791748047
    num_steps_sampled: 2410000
    num_steps_trained: 2410000
    wait_time_ms: 71.791
  iterations_since_restore: 482
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4187.496438503265
  time_this_iter_s: 8.30452561378479
  time_total_s: 4187.496438503265
  timestamp: 1594860203
  timesteps_since_restore: 2410000
  timesteps_this_iter: 5000
  timesteps_total: 2410000
  training_iteration: 482
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4187 s, 482 iter, 2410000 ts, -687 rew

agent-1: -87.02034732022886
agent-2: -148.2157026193844
agent-3: -206.3181940111489
agent-4: -74.271588797841
agent-5: -200.0146350224142
Extrinsic Rewards:
1
2
9
2
6
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.4
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-43-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -687.7032450231354
  episode_reward_min: -901.0177581855133
  episodes_this_iter: 1
  episodes_total: 482
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.567
    dispatch_time_ms: 7.571
    learner:
      cur_lr: 0.0011994939995929599
      grad_gnorm: 8.398468971252441
      policy_entropy: 53.945396423339844
      policy_loss: -0.8092725276947021
      var_gnorm: 26.159133911132812
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 7.819301605224609
    num_steps_sampled: 2415000
    num_steps_trained: 2415000
    wait_time_ms: 74.112
  iterations_since_restore: 483
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4195.85426902771
  time_this_iter_s: 8.35783052444458
  time_total_s: 4195.85426902771
  timestamp: 1594860211
  timesteps_since_restore: 2415000
  timesteps_this_iter: 5000
  timesteps_total: 2415000
  training_iteration: 483
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4195 s, 483 iter, 2415000 ts, -688 rew

agent-1: -209.36937221202817
agent-2: -157.24115434195235
agent-3: -239.5292086195038
agent-4: -133.4868383488622
agent-5: -133.4868383488622
Extrinsic Rewards:
6
4
16
0
0
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 0
Max Reward: 16
Gini Coefficient: 0.5846153846153846
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: -47.21975407923677
agent-2: -225.4080931034214
agent-3: -232.95007032780407
agent-4: -69.18503494263715
agent-5: -57.048910468722845
Extrinsic Rewards:
1
5
6
5
3
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 1
Max Reward: 6
Gini Coefficient: 0.24
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-43-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -686.3208921378117
  episode_reward_min: -901.0177581855133
  episodes_this_iter: 2
  episodes_total: 484
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.767
    dispatch_time_ms: 8.61
    learner:
      cur_lr: 0.0011991610517725348
      grad_gnorm: 40.0
      policy_entropy: 56.338836669921875
      policy_loss: 820.2986450195312
      var_gnorm: 26.19822883605957
      vf_explained_var: 0.0
      vf_loss: 5669.05712890625
    num_steps_sampled: 2420000
    num_steps_trained: 2420000
    wait_time_ms: 71.818
  iterations_since_restore: 484
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4204.298455238342
  time_this_iter_s: 8.444186210632324
  time_total_s: 4204.298455238342
  timestamp: 1594860219
  timesteps_since_restore: 2420000
  timesteps_this_iter: 5000
  timesteps_total: 2420000
  training_iteration: 484
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4204 s, 484 iter, 2420000 ts, -686 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-43-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -686.3208921378116
  episode_reward_min: -901.0177581855133
  episodes_this_iter: 0
  episodes_total: 484
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.472
    dispatch_time_ms: 6.821
    learner:
      cur_lr: 0.001198827987536788
      grad_gnorm: 15.4480619430542
      policy_entropy: 53.998287200927734
      policy_loss: -1.940453290939331
      var_gnorm: 26.163724899291992
      vf_explained_var: 0.0
      vf_loss: 3.7881898880004883
    num_steps_sampled: 2425000
    num_steps_trained: 2425000
    wait_time_ms: 74.17
  iterations_since_restore: 485
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4212.657445430756
  time_this_iter_s: 8.35899019241333
  time_total_s: 4212.657445430756
  timestamp: 1594860228
  timesteps_since_restore: 2425000
  timesteps_this_iter: 5000
  timesteps_total: 2425000
  training_iteration: 485
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4212 s, 485 iter, 2425000 ts, -686 rew

agent-1: -234.2414764799727
agent-2: -36.80444463254326
agent-3: -130.17363614581103
agent-4: -97.87167794157536
agent-5: -151.81268814676017
Extrinsic Rewards:
9
4
8
5
4
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 4
Max Reward: 9
Gini Coefficient: 0.18666666666666668
20:20 Ratio: 2.25
Max-min Ratio: 2.25
agent-1: -113.56192200723028
agent-2: -148.33301554701293
agent-3: -133.687748837788
agent-4: -189.08440102806588
agent-5: -242.57015891669258
Extrinsic Rewards:
3
0
3
4
7
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.35294117647058826
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-43-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -685.337826334978
  episode_reward_min: -901.0177581855133
  episodes_this_iter: 2
  episodes_total: 486
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.985
    dispatch_time_ms: 7.276
    learner:
      cur_lr: 0.001198495039716363
      grad_gnorm: 40.0
      policy_entropy: 49.45469284057617
      policy_loss: 935.303466796875
      var_gnorm: 26.200807571411133
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 5672.01904296875
    num_steps_sampled: 2430000
    num_steps_trained: 2430000
    wait_time_ms: 74.451
  iterations_since_restore: 486
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4221.064935922623
  time_this_iter_s: 8.407490491867065
  time_total_s: 4221.064935922623
  timestamp: 1594860236
  timesteps_since_restore: 2430000
  timesteps_this_iter: 5000
  timesteps_total: 2430000
  training_iteration: 486
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4221 s, 486 iter, 2430000 ts, -685 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-44-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -685.3378263349779
  episode_reward_min: -901.0177581855133
  episodes_this_iter: 0
  episodes_total: 486
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.429
    dispatch_time_ms: 8.2
    learner:
      cur_lr: 0.001198161975480616
      grad_gnorm: 7.550972938537598
      policy_entropy: 46.32855224609375
      policy_loss: 1.7863444089889526
      var_gnorm: 26.174270629882812
      vf_explained_var: 0.0
      vf_loss: 3.393108367919922
    num_steps_sampled: 2435000
    num_steps_trained: 2435000
    wait_time_ms: 73.079
  iterations_since_restore: 487
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4229.437832355499
  time_this_iter_s: 8.372896432876587
  time_total_s: 4229.437832355499
  timestamp: 1594860245
  timesteps_since_restore: 2435000
  timesteps_this_iter: 5000
  timesteps_total: 2435000
  training_iteration: 487
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4229 s, 487 iter, 2435000 ts, -685 rew

agent-1: -193.09418141523355
agent-2: -91.10243557798351
agent-3: -112.65667079919811
agent-4: -91.32166753664085
agent-5: -166.87902456545507
Extrinsic Rewards:
4
14
12
1
9
Sum Reward: 40
Avg Reward: 8.0
Min Reward: 1
Max Reward: 14
Gini Coefficient: 0.34
20:20 Ratio: 14.0
Max-min Ratio: 14.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-44-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -684.7844545334337
  episode_reward_min: -901.0177581855133
  episodes_this_iter: 1
  episodes_total: 487
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.827
    dispatch_time_ms: 8.747
    learner:
      cur_lr: 0.001197829027660191
      grad_gnorm: 40.0
      policy_entropy: 51.83187484741211
      policy_loss: 21.148839950561523
      var_gnorm: 26.17412567138672
      vf_explained_var: 0.0
      vf_loss: 12.894007682800293
    num_steps_sampled: 2440000
    num_steps_trained: 2440000
    wait_time_ms: 70.414
  iterations_since_restore: 488
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4237.784473419189
  time_this_iter_s: 8.346641063690186
  time_total_s: 4237.784473419189
  timestamp: 1594860253
  timesteps_since_restore: 2440000
  timesteps_this_iter: 5000
  timesteps_total: 2440000
  training_iteration: 488
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4237 s, 488 iter, 2440000 ts, -685 rew

agent-1: -189.18384841881885
agent-2: -170.61387298187822
agent-3: -212.7422756082098
agent-4: -109.56795827285812
agent-5: -27.954513887995457
Extrinsic Rewards:
6
4
6
4
1
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 1
Max Reward: 6
Gini Coefficient: 0.22857142857142856
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-44-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -684.3626815807125
  episode_reward_min: -901.0177581855133
  episodes_this_iter: 1
  episodes_total: 488
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.536
    dispatch_time_ms: 9.207
    learner:
      cur_lr: 0.0011974959634244442
      grad_gnorm: 31.548194885253906
      policy_entropy: 44.48203659057617
      policy_loss: -0.6797776818275452
      var_gnorm: 26.13320541381836
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 4.759835720062256
    num_steps_sampled: 2445000
    num_steps_trained: 2445000
    wait_time_ms: 71.895
  iterations_since_restore: 489
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4246.128850221634
  time_this_iter_s: 8.344376802444458
  time_total_s: 4246.128850221634
  timestamp: 1594860262
  timesteps_since_restore: 2445000
  timesteps_this_iter: 5000
  timesteps_total: 2445000
  training_iteration: 489
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4246 s, 489 iter, 2445000 ts, -684 rew

agent-1: -31.95290327820384
agent-2: -120.21546196152869
agent-3: -244.5133512902272
agent-4: -132.6240956331112
agent-5: -78.3033249674673
Extrinsic Rewards:
3
0
2
7
8
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.42
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-44-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -683.2555778280376
  episode_reward_min: -901.0177581855133
  episodes_this_iter: 1
  episodes_total: 489
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.106
    dispatch_time_ms: 7.848
    learner:
      cur_lr: 0.0011971630156040192
      grad_gnorm: 17.4601993560791
      policy_entropy: 38.237613677978516
      policy_loss: 3.7605907917022705
      var_gnorm: 26.15766716003418
      vf_explained_var: 0.0
      vf_loss: 10.4029541015625
    num_steps_sampled: 2450000
    num_steps_trained: 2450000
    wait_time_ms: 71.117
  iterations_since_restore: 490
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4261.782513618469
  time_this_iter_s: 15.653663396835327
  time_total_s: 4261.782513618469
  timestamp: 1594860277
  timesteps_since_restore: 2450000
  timesteps_this_iter: 5000
  timesteps_total: 2450000
  training_iteration: 490
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4261 s, 490 iter, 2450000 ts, -683 rew

agent-1: -131.4010318853284
agent-2: -39.64023991907465
agent-3: -88.20286025043158
agent-4: -212.33535217773775
agent-5: -199.83764243748055
Extrinsic Rewards:
4
1
1
16
5
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 1
Max Reward: 16
Gini Coefficient: 0.5037037037037037
20:20 Ratio: 16.0
Max-min Ratio: 16.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-44-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -684.466876144571
  episode_reward_min: -901.0177581855133
  episodes_this_iter: 1
  episodes_total: 490
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.671
    dispatch_time_ms: 8.037
    learner:
      cur_lr: 0.0011968299513682723
      grad_gnorm: 9.492941856384277
      policy_entropy: 37.1137809753418
      policy_loss: -0.7844794392585754
      var_gnorm: 26.158740997314453
      vf_explained_var: 0.0
      vf_loss: 4.121729373931885
    num_steps_sampled: 2455000
    num_steps_trained: 2455000
    wait_time_ms: 73.36
  iterations_since_restore: 491
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4270.145909070969
  time_this_iter_s: 8.36339545249939
  time_total_s: 4270.145909070969
  timestamp: 1594860286
  timesteps_since_restore: 2455000
  timesteps_this_iter: 5000
  timesteps_total: 2455000
  training_iteration: 491
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4270 s, 491 iter, 2455000 ts, -684 rew

agent-1: -151.242912920218
agent-2: -237.25526847868494
agent-3: -77.83045151884306
agent-4: -162.32554131719235
agent-5: -67.56109295778207
Extrinsic Rewards:
2
6
1
4
2
Sum Reward: 15
Avg Reward: 3.0
Min Reward: 1
Max Reward: 6
Gini Coefficient: 0.32
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-44-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -685.4053974161474
  episode_reward_min: -901.0177581855133
  episodes_this_iter: 1
  episodes_total: 491
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.772
    dispatch_time_ms: 10.428
    learner:
      cur_lr: 0.0011964970035478473
      grad_gnorm: 32.84430694580078
      policy_entropy: 45.3291130065918
      policy_loss: -15.94929027557373
      var_gnorm: 26.202653884887695
      vf_explained_var: 0.0
      vf_loss: 4.358636856079102
    num_steps_sampled: 2460000
    num_steps_trained: 2460000
    wait_time_ms: 75.631
  iterations_since_restore: 492
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4278.566169977188
  time_this_iter_s: 8.420260906219482
  time_total_s: 4278.566169977188
  timestamp: 1594860294
  timesteps_since_restore: 2460000
  timesteps_this_iter: 5000
  timesteps_total: 2460000
  training_iteration: 492
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4278 s, 492 iter, 2460000 ts, -685 rew

agent-1: -137.37229267105567
agent-2: -197.8096914925438
agent-3: -160.83462156597395
agent-4: -193.05389883004776
agent-5: -153.12454139264787
Extrinsic Rewards:
0
8
4
5
3
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.36
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-45-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -688.2952453440935
  episode_reward_min: -901.0177581855133
  episodes_this_iter: 1
  episodes_total: 492
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.742
    dispatch_time_ms: 9.152
    learner:
      cur_lr: 0.0011961640557274222
      grad_gnorm: 13.020523071289062
      policy_entropy: 45.27040481567383
      policy_loss: -2.085632801055908
      var_gnorm: 26.15694808959961
      vf_explained_var: 0.0
      vf_loss: 4.903964996337891
    num_steps_sampled: 2465000
    num_steps_trained: 2465000
    wait_time_ms: 71.254
  iterations_since_restore: 493
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4286.938112974167
  time_this_iter_s: 8.37194299697876
  time_total_s: 4286.938112974167
  timestamp: 1594860302
  timesteps_since_restore: 2465000
  timesteps_this_iter: 5000
  timesteps_total: 2465000
  training_iteration: 493
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4286 s, 493 iter, 2465000 ts, -688 rew

agent-1: -243.29632378736582
agent-2: -63.861143965088644
agent-3: -67.01257689520028
agent-4: -35.11092896716983
agent-5: -209.4191414353645
Extrinsic Rewards:
13
4
1
2
5
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 1
Max Reward: 13
Gini Coefficient: 0.432
20:20 Ratio: 13.0
Max-min Ratio: 13.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-45-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -687.5254357759711
  episode_reward_min: -901.0177581855133
  episodes_this_iter: 1
  episodes_total: 493
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.9
    dispatch_time_ms: 7.879
    learner:
      cur_lr: 0.0011958309914916754
      grad_gnorm: 3.273266077041626
      policy_entropy: 39.70671081542969
      policy_loss: -0.8378892540931702
      var_gnorm: 26.147319793701172
      vf_explained_var: 0.0
      vf_loss: 4.920349597930908
    num_steps_sampled: 2470000
    num_steps_trained: 2470000
    wait_time_ms: 68.758
  iterations_since_restore: 494
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4295.327511787415
  time_this_iter_s: 8.38939881324768
  time_total_s: 4295.327511787415
  timestamp: 1594860311
  timesteps_since_restore: 2470000
  timesteps_this_iter: 5000
  timesteps_total: 2470000
  training_iteration: 494
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4295 s, 494 iter, 2470000 ts, -688 rew

agent-1: -129.7579979831662
agent-2: -35.19236821658231
agent-3: -174.4616252816364
agent-4: -95.90110921262612
agent-5: -243.18483430804758
Extrinsic Rewards:
4
1
4
3
7
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 1
Max Reward: 7
Gini Coefficient: 0.2736842105263158
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-45-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -685.976677138603
  episode_reward_min: -901.0177581855133
  episodes_this_iter: 1
  episodes_total: 494
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.328
    dispatch_time_ms: 7.244
    learner:
      cur_lr: 0.0011954980436712503
      grad_gnorm: 9.815921783447266
      policy_entropy: 47.91542053222656
      policy_loss: -3.399831771850586
      var_gnorm: 26.149234771728516
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.442002296447754
    num_steps_sampled: 2475000
    num_steps_trained: 2475000
    wait_time_ms: 74.397
  iterations_since_restore: 495
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4303.629171133041
  time_this_iter_s: 8.301659345626831
  time_total_s: 4303.629171133041
  timestamp: 1594860319
  timesteps_since_restore: 2475000
  timesteps_this_iter: 5000
  timesteps_total: 2475000
  training_iteration: 495
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4303 s, 495 iter, 2475000 ts, -686 rew

agent-1: -240.79749599357768
agent-2: -86.8982607857776
agent-3: -142.404209145067
agent-4: -92.23167479005305
agent-5: -215.68959536730432
Extrinsic Rewards:
6
2
0
1
10
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 0
Max Reward: 10
Gini Coefficient: 0.5263157894736842
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-45-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -688.8867895967753
  episode_reward_min: -901.0177581855133
  episodes_this_iter: 1
  episodes_total: 495
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.924
    dispatch_time_ms: 7.841
    learner:
      cur_lr: 0.0011951649794355035
      grad_gnorm: 18.73863410949707
      policy_entropy: 51.449275970458984
      policy_loss: 0.9435560703277588
      var_gnorm: 26.19976234436035
      vf_explained_var: 0.0
      vf_loss: 3.5026392936706543
    num_steps_sampled: 2480000
    num_steps_trained: 2480000
    wait_time_ms: 73.481
  iterations_since_restore: 496
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4312.10205745697
  time_this_iter_s: 8.472886323928833
  time_total_s: 4312.10205745697
  timestamp: 1594860328
  timesteps_since_restore: 2480000
  timesteps_this_iter: 5000
  timesteps_total: 2480000
  training_iteration: 496
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4312 s, 496 iter, 2480000 ts, -689 rew

agent-1: -145.78937617199043
agent-2: -116.95960758404978
agent-3: -210.9493546868688
agent-4: -44.165179537814154
agent-5: -172.6337969529984
Extrinsic Rewards:
5
4
15
3
11
Sum Reward: 38
Avg Reward: 7.6
Min Reward: 3
Max Reward: 15
Gini Coefficient: 0.3263157894736842
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-45-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -689.7002073680762
  episode_reward_min: -901.0177581855133
  episodes_this_iter: 1
  episodes_total: 496
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.142
    dispatch_time_ms: 10.89
    learner:
      cur_lr: 0.0011948320316150784
      grad_gnorm: 14.049528121948242
      policy_entropy: 47.46860885620117
      policy_loss: 3.154794216156006
      var_gnorm: 26.16624641418457
      vf_explained_var: 0.0
      vf_loss: 4.897853851318359
    num_steps_sampled: 2485000
    num_steps_trained: 2485000
    wait_time_ms: 71.211
  iterations_since_restore: 497
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4320.4651935100555
  time_this_iter_s: 8.363136053085327
  time_total_s: 4320.4651935100555
  timestamp: 1594860336
  timesteps_since_restore: 2485000
  timesteps_this_iter: 5000
  timesteps_total: 2485000
  training_iteration: 497
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4320 s, 497 iter, 2485000 ts, -690 rew

agent-1: -171.4136836008067
agent-2: -94.97729102963014
agent-3: -86.93193347845457
agent-4: -198.30160579016493
agent-5: -135.0404422614621
Extrinsic Rewards:
8
6
3
6
15
Sum Reward: 38
Avg Reward: 7.6
Min Reward: 3
Max Reward: 15
Gini Coefficient: 0.2736842105263158
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-45-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -690.6652613311537
  episode_reward_min: -901.0177581855133
  episodes_this_iter: 1
  episodes_total: 497
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.607
    dispatch_time_ms: 38.255
    learner:
      cur_lr: 0.0011944989673793316
      grad_gnorm: 7.609541416168213
      policy_entropy: 38.54229736328125
      policy_loss: -0.46393364667892456
      var_gnorm: 26.166120529174805
      vf_explained_var: 0.0
      vf_loss: 4.897578716278076
    num_steps_sampled: 2490000
    num_steps_trained: 2490000
    wait_time_ms: 49.921
  iterations_since_restore: 498
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4329.2440140247345
  time_this_iter_s: 8.778820514678955
  time_total_s: 4329.2440140247345
  timestamp: 1594860345
  timesteps_since_restore: 2490000
  timesteps_this_iter: 5000
  timesteps_total: 2490000
  training_iteration: 498
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4329 s, 498 iter, 2490000 ts, -691 rew

agent-1: -182.24703297116582
agent-2: -161.45128108527075
agent-3: -224.7557857962318
agent-4: -43.83028322455668
agent-5: -68.48225371618305
Extrinsic Rewards:
7
4
11
3
1
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 1
Max Reward: 11
Gini Coefficient: 0.36923076923076925
20:20 Ratio: 11.0
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-45-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -691.5050189473437
  episode_reward_min: -901.0177581855133
  episodes_this_iter: 1
  episodes_total: 498
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.841
    dispatch_time_ms: 35.458
    learner:
      cur_lr: 0.0011941660195589066
      grad_gnorm: 8.822651863098145
      policy_entropy: 33.79609298706055
      policy_loss: 0.4929245114326477
      var_gnorm: 26.13204574584961
      vf_explained_var: 0.0
      vf_loss: 7.81660270690918
    num_steps_sampled: 2495000
    num_steps_trained: 2495000
    wait_time_ms: 51.098
  iterations_since_restore: 499
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4337.998105764389
  time_this_iter_s: 8.754091739654541
  time_total_s: 4337.998105764389
  timestamp: 1594860354
  timesteps_since_restore: 2495000
  timesteps_this_iter: 5000
  timesteps_total: 2495000
  training_iteration: 499
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4337 s, 499 iter, 2495000 ts, -692 rew

agent-1: -70.3398438338922
agent-2: -59.03940318094472
agent-3: -93.69286989186556
agent-4: -165.78210671011811
agent-5: -147.4438641687933
Extrinsic Rewards:
11
11
32
19
17
Sum Reward: 90
Avg Reward: 18.0
Min Reward: 11
Max Reward: 32
Gini Coefficient: 0.2222222222222222
20:20 Ratio: 2.909090909090909
Max-min Ratio: 2.909090909090909
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-46-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -691.7249813773503
  episode_reward_min: -901.0177581855133
  episodes_this_iter: 1
  episodes_total: 499
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.768
    dispatch_time_ms: 30.937
    learner:
      cur_lr: 0.0011938329553231597
      grad_gnorm: 37.533939361572266
      policy_entropy: 38.53890609741211
      policy_loss: -8.21196174621582
      var_gnorm: 26.1602783203125
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 10.206382751464844
    num_steps_sampled: 2500000
    num_steps_trained: 2500000
    wait_time_ms: 47.035
  iterations_since_restore: 500
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4346.897143602371
  time_this_iter_s: 8.899037837982178
  time_total_s: 4346.897143602371
  timestamp: 1594860363
  timesteps_since_restore: 2500000
  timesteps_this_iter: 5000
  timesteps_total: 2500000
  training_iteration: 500
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4346 s, 500 iter, 2500000 ts, -692 rew

agent-1: -214.27096699632162
agent-2: -241.37108491749746
agent-3: -138.30191250510975
agent-4: -100.92400851129182
agent-5: -56.34170628918402
Extrinsic Rewards:
10
5
0
3
1
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 0
Max Reward: 10
Gini Coefficient: 0.5052631578947369
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-46-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -693.2159056941578
  episode_reward_min: -901.0177581855133
  episodes_this_iter: 1
  episodes_total: 500
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.779
    dispatch_time_ms: 24.984
    learner:
      cur_lr: 0.0011935000075027347
      grad_gnorm: 11.852190017700195
      policy_entropy: 31.730018615722656
      policy_loss: 4.372758388519287
      var_gnorm: 26.13286018371582
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 11.286728858947754
    num_steps_sampled: 2505000
    num_steps_trained: 2505000
    wait_time_ms: 71.213
  iterations_since_restore: 501
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4355.7735097408295
  time_this_iter_s: 8.876366138458252
  time_total_s: 4355.7735097408295
  timestamp: 1594860372
  timesteps_since_restore: 2505000
  timesteps_this_iter: 5000
  timesteps_total: 2505000
  training_iteration: 501
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4355 s, 501 iter, 2505000 ts, -693 rew

agent-1: -257.5879295569212
agent-2: -12.257257495145936
agent-3: -69.3075902225302
agent-4: -196.13538393646385
agent-5: -21.245197613682418
Extrinsic Rewards:
14
2
4
12
3
Sum Reward: 35
Avg Reward: 7.0
Min Reward: 2
Max Reward: 14
Gini Coefficient: 0.37714285714285717
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-46-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -690.9740793535409
  episode_reward_min: -901.0177581855133
  episodes_this_iter: 1
  episodes_total: 501
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.495
    dispatch_time_ms: 25.277
    learner:
      cur_lr: 0.0011931669432669878
      grad_gnorm: 13.663973808288574
      policy_entropy: 38.23291015625
      policy_loss: -5.070287704467773
      var_gnorm: 26.125574111938477
      vf_explained_var: 0.0
      vf_loss: 7.498810291290283
    num_steps_sampled: 2510000
    num_steps_trained: 2510000
    wait_time_ms: 61.407
  iterations_since_restore: 502
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4364.567363739014
  time_this_iter_s: 8.793853998184204
  time_total_s: 4364.567363739014
  timestamp: 1594860380
  timesteps_since_restore: 2510000
  timesteps_this_iter: 5000
  timesteps_total: 2510000
  training_iteration: 502
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4364 s, 502 iter, 2510000 ts, -691 rew

agent-1: -229.39576708329486
agent-2: -22.659372671409372
agent-3: -154.05523955231862
agent-4: -42.811002574338566
agent-5: -175.6562309777111
Extrinsic Rewards:
7
1
9
5
11
Sum Reward: 33
Avg Reward: 6.6
Min Reward: 1
Max Reward: 11
Gini Coefficient: 0.2909090909090909
20:20 Ratio: 11.0
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-46-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -690.0924706567545
  episode_reward_min: -901.0177581855133
  episodes_this_iter: 1
  episodes_total: 502
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.394
    dispatch_time_ms: 23.133
    learner:
      cur_lr: 0.0011928339954465628
      grad_gnorm: 21.800945281982422
      policy_entropy: 31.445350646972656
      policy_loss: -7.6344099044799805
      var_gnorm: 26.141401290893555
      vf_explained_var: 0.0
      vf_loss: 2.167888641357422
    num_steps_sampled: 2515000
    num_steps_trained: 2515000
    wait_time_ms: 63.564
  iterations_since_restore: 503
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4373.417153596878
  time_this_iter_s: 8.84978985786438
  time_total_s: 4373.417153596878
  timestamp: 1594860389
  timesteps_since_restore: 2515000
  timesteps_this_iter: 5000
  timesteps_total: 2515000
  training_iteration: 503
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4373 s, 503 iter, 2515000 ts, -690 rew

agent-1: -112.27201204648038
agent-2: -151.6639390586373
agent-3: -199.671040000728
agent-4: -99.43103974709314
agent-5: -159.16627716937597
Extrinsic Rewards:
5
4
6
8
7
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 4
Max Reward: 8
Gini Coefficient: 0.13333333333333333
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-46-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -689.6926394640817
  episode_reward_min: -901.0177581855133
  episodes_this_iter: 1
  episodes_total: 503
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.965
    dispatch_time_ms: 39.877
    learner:
      cur_lr: 0.0011925010476261377
      grad_gnorm: 24.63079833984375
      policy_entropy: 23.314838409423828
      policy_loss: 3.8884365558624268
      var_gnorm: 26.18419647216797
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 11.63479232788086
    num_steps_sampled: 2520000
    num_steps_trained: 2520000
    wait_time_ms: 42.355
  iterations_since_restore: 504
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4382.325296640396
  time_this_iter_s: 8.908143043518066
  time_total_s: 4382.325296640396
  timestamp: 1594860398
  timesteps_since_restore: 2520000
  timesteps_this_iter: 5000
  timesteps_total: 2520000
  training_iteration: 504
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4382 s, 504 iter, 2520000 ts, -690 rew

agent-1: -180.87480591422886
agent-2: -235.7139199261689
agent-3: -77.3355184801156
agent-4: -164.44787557929104
agent-5: -126.75277677617417
Extrinsic Rewards:
4
11
6
3
0
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 0
Max Reward: 11
Gini Coefficient: 0.4166666666666667
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-46-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -688.9755493799082
  episode_reward_min: -901.0177581855133
  episodes_this_iter: 1
  episodes_total: 504
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.853
    dispatch_time_ms: 15.77
    learner:
      cur_lr: 0.0011921679833903909
      grad_gnorm: 7.558194160461426
      policy_entropy: 30.471988677978516
      policy_loss: -2.7443478107452393
      var_gnorm: 26.159021377563477
      vf_explained_var: 0.0
      vf_loss: 2.2957520484924316
    num_steps_sampled: 2525000
    num_steps_trained: 2525000
    wait_time_ms: 70.556
  iterations_since_restore: 505
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4391.187036514282
  time_this_iter_s: 8.861739873886108
  time_total_s: 4391.187036514282
  timestamp: 1594860407
  timesteps_since_restore: 2525000
  timesteps_this_iter: 5000
  timesteps_total: 2525000
  training_iteration: 505
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4391 s, 505 iter, 2525000 ts, -689 rew

agent-1: -154.42159446830132
agent-2: -111.84850745704435
agent-3: -71.35463109854747
agent-4: -84.56514989263829
agent-5: -233.30182748554162
Extrinsic Rewards:
4
6
7
8
12
Sum Reward: 37
Avg Reward: 7.4
Min Reward: 4
Max Reward: 12
Gini Coefficient: 0.1945945945945946
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-46-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -688.8673281189862
  episode_reward_min: -901.0177581855133
  episodes_this_iter: 1
  episodes_total: 505
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.19
    dispatch_time_ms: 21.973
    learner:
      cur_lr: 0.0011918350355699658
      grad_gnorm: 9.561849594116211
      policy_entropy: 45.23530578613281
      policy_loss: -2.2615966796875
      var_gnorm: 26.15667152404785
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 5.982248783111572
    num_steps_sampled: 2530000
    num_steps_trained: 2530000
    wait_time_ms: 56.04
  iterations_since_restore: 506
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4400.084936380386
  time_this_iter_s: 8.897899866104126
  time_total_s: 4400.084936380386
  timestamp: 1594860416
  timesteps_since_restore: 2530000
  timesteps_this_iter: 5000
  timesteps_total: 2530000
  training_iteration: 506
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4400 s, 506 iter, 2530000 ts, -689 rew

agent-1: -181.02518208260454
agent-2: -155.29114365773302
agent-3: -170.5096246291866
agent-4: -155.6752001849495
agent-5: -56.74893534273828
Extrinsic Rewards:
9
5
9
5
4
Sum Reward: 32
Avg Reward: 6.4
Min Reward: 4
Max Reward: 9
Gini Coefficient: 0.175
20:20 Ratio: 2.25
Max-min Ratio: 2.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-47-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -689.054434784747
  episode_reward_min: -901.0177581855133
  episodes_this_iter: 1
  episodes_total: 506
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 4.598
    dispatch_time_ms: 33.1
    learner:
      cur_lr: 0.001191501971334219
      grad_gnorm: 11.29747200012207
      policy_entropy: 41.64828872680664
      policy_loss: -0.22208552062511444
      var_gnorm: 26.144044876098633
      vf_explained_var: 0.0
      vf_loss: 7.001228332519531
    num_steps_sampled: 2535000
    num_steps_trained: 2535000
    wait_time_ms: 52.361
  iterations_since_restore: 507
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4409.201867580414
  time_this_iter_s: 9.116931200027466
  time_total_s: 4409.201867580414
  timestamp: 1594860425
  timesteps_since_restore: 2535000
  timesteps_this_iter: 5000
  timesteps_total: 2535000
  training_iteration: 507
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4409 s, 507 iter, 2535000 ts, -689 rew

agent-1: -241.7243644410763
agent-2: -70.13084561293104
agent-3: -24.467161320906325
agent-4: -135.87743113521543
agent-5: -163.22727129239337
Extrinsic Rewards:
10
6
3
4
4
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 3
Max Reward: 10
Gini Coefficient: 0.23703703703703705
20:20 Ratio: 3.3333333333333335
Max-min Ratio: 3.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-47-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -690.445914484485
  episode_reward_min: -901.0177581855133
  episodes_this_iter: 1
  episodes_total: 507
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.902
    dispatch_time_ms: 11.493
    learner:
      cur_lr: 0.001191169023513794
      grad_gnorm: 12.815053939819336
      policy_entropy: 35.13763427734375
      policy_loss: 2.853818416595459
      var_gnorm: 26.140972137451172
      vf_explained_var: 0.0
      vf_loss: 7.007801055908203
    num_steps_sampled: 2540000
    num_steps_trained: 2540000
    wait_time_ms: 69.354
  iterations_since_restore: 508
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4417.621098279953
  time_this_iter_s: 8.419230699539185
  time_total_s: 4417.621098279953
  timestamp: 1594860434
  timesteps_since_restore: 2540000
  timesteps_this_iter: 5000
  timesteps_total: 2540000
  training_iteration: 508
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4417 s, 508 iter, 2540000 ts, -690 rew

agent-1: -243.14556547310661
agent-2: -135.1756984962729
agent-3: -39.84735140592677
agent-4: -198.4121575614539
agent-5: -34.073171728036165
Extrinsic Rewards:
10
4
1
3
1
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 1
Max Reward: 10
Gini Coefficient: 0.4421052631578947
20:20 Ratio: 10.0
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-47-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -690.4582518267099
  episode_reward_min: -901.0177581855133
  episodes_this_iter: 1
  episodes_total: 508
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.588
    dispatch_time_ms: 8.142
    learner:
      cur_lr: 0.001190835959278047
      grad_gnorm: 21.997936248779297
      policy_entropy: 37.68840408325195
      policy_loss: 7.351200103759766
      var_gnorm: 26.130403518676758
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 11.988935470581055
    num_steps_sampled: 2545000
    num_steps_trained: 2545000
    wait_time_ms: 73.835
  iterations_since_restore: 509
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4426.07769036293
  time_this_iter_s: 8.456592082977295
  time_total_s: 4426.07769036293
  timestamp: 1594860442
  timesteps_since_restore: 2545000
  timesteps_this_iter: 5000
  timesteps_total: 2545000
  training_iteration: 509
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4426 s, 509 iter, 2545000 ts, -690 rew

agent-1: -49.342386905914545
agent-2: -61.857922000422306
agent-3: -235.99899786799685
agent-4: -145.12780419013242
agent-5: -168.92762905708582
Extrinsic Rewards:
3
4
9
8
2
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 2
Max Reward: 9
Gini Coefficient: 0.2923076923076923
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-47-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -690.719402720694
  episode_reward_min: -901.0177581855133
  episodes_this_iter: 1
  episodes_total: 509
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.688
    dispatch_time_ms: 8.382
    learner:
      cur_lr: 0.001190503011457622
      grad_gnorm: 15.793212890625
      policy_entropy: 25.614805221557617
      policy_loss: -5.469224452972412
      var_gnorm: 26.124799728393555
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 8.6860990524292
    num_steps_sampled: 2550000
    num_steps_trained: 2550000
    wait_time_ms: 68.485
  iterations_since_restore: 510
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4434.465146780014
  time_this_iter_s: 8.38745641708374
  time_total_s: 4434.465146780014
  timestamp: 1594860451
  timesteps_since_restore: 2550000
  timesteps_this_iter: 5000
  timesteps_total: 2550000
  training_iteration: 510
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4434 s, 510 iter, 2550000 ts, -691 rew

agent-1: -260.80827228550106
agent-2: -23.339554801407044
agent-3: -223.45181909064917
agent-4: -19.53594464402139
agent-5: -27.455106879959406
Extrinsic Rewards:
10
1
6
1
1
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 1
Max Reward: 10
Gini Coefficient: 0.4842105263157895
20:20 Ratio: 10.0
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-47-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -688.0172473329145
  episode_reward_min: -901.0177581855133
  episodes_this_iter: 1
  episodes_total: 510
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.506
    dispatch_time_ms: 8.6
    learner:
      cur_lr: 0.0011901699472218752
      grad_gnorm: 15.009223937988281
      policy_entropy: 35.16080093383789
      policy_loss: -3.5956969261169434
      var_gnorm: 26.121274948120117
      vf_explained_var: 0.0
      vf_loss: 5.808087348937988
    num_steps_sampled: 2555000
    num_steps_trained: 2555000
    wait_time_ms: 72.194
  iterations_since_restore: 511
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4442.830970287323
  time_this_iter_s: 8.36582350730896
  time_total_s: 4442.830970287323
  timestamp: 1594860459
  timesteps_since_restore: 2555000
  timesteps_this_iter: 5000
  timesteps_total: 2555000
  training_iteration: 511
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4442 s, 511 iter, 2555000 ts, -688 rew

agent-1: -155.02453842302512
agent-2: -110.86291761598231
agent-3: -219.9557980320589
agent-4: -150.55382779172328
agent-5: -32.119506452408885
Extrinsic Rewards:
5
6
12
12
4
Sum Reward: 39
Avg Reward: 7.8
Min Reward: 4
Max Reward: 12
Gini Coefficient: 0.2358974358974359
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-47-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -688.0803491836989
  episode_reward_min: -901.0177581855133
  episodes_this_iter: 1
  episodes_total: 511
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.901
    dispatch_time_ms: 7.891
    learner:
      cur_lr: 0.0011898369994014502
      grad_gnorm: 28.85580825805664
      policy_entropy: 51.85219955444336
      policy_loss: -8.687887191772461
      var_gnorm: 26.141294479370117
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 15.54953670501709
    num_steps_sampled: 2560000
    num_steps_trained: 2560000
    wait_time_ms: 74.085
  iterations_since_restore: 512
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4451.244476318359
  time_this_iter_s: 8.413506031036377
  time_total_s: 4451.244476318359
  timestamp: 1594860467
  timesteps_since_restore: 2560000
  timesteps_this_iter: 5000
  timesteps_total: 2560000
  training_iteration: 512
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4451 s, 512 iter, 2560000 ts, -688 rew

agent-1: -205.13222377169384
agent-2: -31.117079130912256
agent-3: -80.39855727158606
agent-4: -53.864284115412254
agent-5: -230.5133012125093
Extrinsic Rewards:
18
5
0
6
10
Sum Reward: 39
Avg Reward: 7.8
Min Reward: 0
Max Reward: 18
Gini Coefficient: 0.4205128205128205
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-47-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -687.7029851800603
  episode_reward_min: -901.0177581855133
  episodes_this_iter: 1
  episodes_total: 512
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.585
    dispatch_time_ms: 8.137
    learner:
      cur_lr: 0.0011895040515810251
      grad_gnorm: 8.919442176818848
      policy_entropy: 45.24348068237305
      policy_loss: -1.1595344543457031
      var_gnorm: 26.163904190063477
      vf_explained_var: 0.0
      vf_loss: 2.4031174182891846
    num_steps_sampled: 2565000
    num_steps_trained: 2565000
    wait_time_ms: 72.5
  iterations_since_restore: 513
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4459.579408407211
  time_this_iter_s: 8.334932088851929
  time_total_s: 4459.579408407211
  timestamp: 1594860476
  timesteps_since_restore: 2565000
  timesteps_this_iter: 5000
  timesteps_total: 2565000
  training_iteration: 513
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4459 s, 513 iter, 2565000 ts, -688 rew

agent-1: -423.104127749652
agent-2: -300.6505469933932
agent-3: -363.3925735537032
agent-4: -519.922415256997
agent-5: -414.6783749971151
Extrinsic Rewards:
-148
-102
-205
-254
-148
Sum Reward: -857
Avg Reward: -171.4
Min Reward: -254
Max Reward: -102
Gini Coefficient: -0.16849474912485415
20:20 Ratio: 0.4015748031496063
Max-min Ratio: 0.4015748031496063
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-48-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -701.7842934930575
  episode_reward_min: -2021.7480385508343
  episodes_this_iter: 1
  episodes_total: 513
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.05
    dispatch_time_ms: 9.988
    learner:
      cur_lr: 0.0011891709873452783
      grad_gnorm: 33.72526168823242
      policy_entropy: 32.80698013305664
      policy_loss: 4.635469436645508
      var_gnorm: 26.26504898071289
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 10.682441711425781
    num_steps_sampled: 2570000
    num_steps_trained: 2570000
    wait_time_ms: 70.344
  iterations_since_restore: 514
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4468.108938217163
  time_this_iter_s: 8.529529809951782
  time_total_s: 4468.108938217163
  timestamp: 1594860484
  timesteps_since_restore: 2570000
  timesteps_this_iter: 5000
  timesteps_total: 2570000
  training_iteration: 514
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4468 s, 514 iter, 2570000 ts, -702 rew

agent-1: -556.2856263344755
agent-2: -285.7455892415944
agent-3: -216.73912504181558
agent-4: -445.33670252273913
agent-5: -531.1800152227099
Extrinsic Rewards:
-297
-159
-97
-250
-401
Sum Reward: -1204
Avg Reward: -240.8
Min Reward: -401
Max Reward: -97
Gini Coefficient: -0.2478405315614618
20:20 Ratio: 0.24189526184538654
Max-min Ratio: 0.24189526184538654
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-48-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -715.3415359969086
  episode_reward_min: -2035.2870583633294
  episodes_this_iter: 1
  episodes_total: 514
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.391
    dispatch_time_ms: 6.406
    learner:
      cur_lr: 0.0011888380395248532
      grad_gnorm: 40.0
      policy_entropy: 42.247581481933594
      policy_loss: -42.013755798339844
      var_gnorm: 26.319854736328125
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 38.714935302734375
    num_steps_sampled: 2575000
    num_steps_trained: 2575000
    wait_time_ms: 71.434
  iterations_since_restore: 515
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4476.320656776428
  time_this_iter_s: 8.211718559265137
  time_total_s: 4476.320656776428
  timestamp: 1594860493
  timesteps_since_restore: 2575000
  timesteps_this_iter: 5000
  timesteps_total: 2575000
  training_iteration: 515
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4476 s, 515 iter, 2575000 ts, -715 rew

agent-1: -457.05609197160504
agent-2: -428.150580591172
agent-3: -312.03126179800057
agent-4: -306.38198626455966
agent-5: -384.17755482234054
Extrinsic Rewards:
-50
-45
-42
1
-40
Sum Reward: -176
Avg Reward: -35.2
Min Reward: -50
Max Reward: 1
Gini Coefficient: -0.2431818181818182
20:20 Ratio: -0.02
Max-min Ratio: -0.02
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-48-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -727.4369176161366
  episode_reward_min: -2035.2870583633294
  episodes_this_iter: 1
  episodes_total: 515
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.76
    dispatch_time_ms: 8.566
    learner:
      cur_lr: 0.0011885049752891064
      grad_gnorm: 39.999996185302734
      policy_entropy: 46.357582092285156
      policy_loss: -8.195995330810547
      var_gnorm: 26.511730194091797
      vf_explained_var: 0.0
      vf_loss: 72.52195739746094
    num_steps_sampled: 2580000
    num_steps_trained: 2580000
    wait_time_ms: 71.168
  iterations_since_restore: 516
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4484.656318902969
  time_this_iter_s: 8.335662126541138
  time_total_s: 4484.656318902969
  timestamp: 1594860501
  timesteps_since_restore: 2580000
  timesteps_this_iter: 5000
  timesteps_total: 2580000
  training_iteration: 516
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4484 s, 516 iter, 2580000 ts, -727 rew

agent-1: -173.673558941177
agent-2: -405.01879058234795
agent-3: -209.05326338229676
agent-4: -545.3602205003486
agent-5: -522.6523570448859
Extrinsic Rewards:
1
-44
-47
5
4
Sum Reward: -81
Avg Reward: -16.2
Min Reward: -47
Max Reward: 5
Gini Coefficient: -0.7506172839506173
20:20 Ratio: -0.10638297872340426
Max-min Ratio: -0.10638297872340426
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-48-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -739.1700153511275
  episode_reward_min: -2035.2870583633294
  episodes_this_iter: 1
  episodes_total: 516
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.323
    dispatch_time_ms: 6.196
    learner:
      cur_lr: 0.0011881720274686813
      grad_gnorm: 39.999996185302734
      policy_entropy: 44.90325927734375
      policy_loss: -15.246513366699219
      var_gnorm: 26.47515106201172
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 66.40265655517578
    num_steps_sampled: 2585000
    num_steps_trained: 2585000
    wait_time_ms: 78.317
  iterations_since_restore: 517
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4492.986862659454
  time_this_iter_s: 8.330543756484985
  time_total_s: 4492.986862659454
  timestamp: 1594860509
  timesteps_since_restore: 2585000
  timesteps_this_iter: 5000
  timesteps_total: 2585000
  training_iteration: 517
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4492 s, 517 iter, 2585000 ts, -739 rew

agent-1: -206.74260597750168
agent-2: -492.5954079525458
agent-3: -84.45010993951445
agent-4: -473.55124298151895
agent-5: -169.27002728886967
Extrinsic Rewards:
-48
2
5
0
8
Sum Reward: -33
Avg Reward: -6.6
Min Reward: -48
Max Reward: 8
Gini Coefficient: -1.4181818181818182
20:20 Ratio: -0.16666666666666666
Max-min Ratio: -0.16666666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-48-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -746.6868698546022
  episode_reward_min: -2035.2870583633294
  episodes_this_iter: 1
  episodes_total: 517
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.647
    dispatch_time_ms: 8.402
    learner:
      cur_lr: 0.0011878389632329345
      grad_gnorm: 39.99999237060547
      policy_entropy: 51.74451446533203
      policy_loss: -24.996231079101562
      var_gnorm: 26.635334014892578
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 71.59554290771484
    num_steps_sampled: 2590000
    num_steps_trained: 2590000
    wait_time_ms: 71.863
  iterations_since_restore: 518
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4511.429437637329
  time_this_iter_s: 18.442574977874756
  time_total_s: 4511.429437637329
  timestamp: 1594860528
  timesteps_since_restore: 2590000
  timesteps_this_iter: 5000
  timesteps_total: 2590000
  training_iteration: 518
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4511 s, 518 iter, 2590000 ts, -747 rew

agent-1: -38.65764774865393
agent-2: -447.89109503192094
agent-3: -304.1504450967201
agent-4: -466.08827200431006
agent-5: -458.1366165762323
Extrinsic Rewards:
8
5
-35
11
7
Sum Reward: -4
Avg Reward: -0.8
Min Reward: -35
Max Reward: 11
Gini Coefficient: -9.5
20:20 Ratio: -0.3142857142857143
Max-min Ratio: -0.3142857142857143
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-48-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -756.4703956318643
  episode_reward_min: -2035.2870583633294
  episodes_this_iter: 1
  episodes_total: 518
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.553
    dispatch_time_ms: 8.62
    learner:
      cur_lr: 0.0011875060154125094
      grad_gnorm: 38.48551559448242
      policy_entropy: 37.35956573486328
      policy_loss: -11.228327751159668
      var_gnorm: 26.719823837280273
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 24.502307891845703
    num_steps_sampled: 2595000
    num_steps_trained: 2595000
    wait_time_ms: 72.29
  iterations_since_restore: 519
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4519.795758485794
  time_this_iter_s: 8.366320848464966
  time_total_s: 4519.795758485794
  timestamp: 1594860536
  timesteps_since_restore: 2595000
  timesteps_this_iter: 5000
  timesteps_total: 2595000
  training_iteration: 519
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4519 s, 519 iter, 2595000 ts, -756 rew

agent-1: -485.2664796294994
agent-2: -510.7082752827167
agent-3: -502.94768496851196
agent-4: -437.69179170429135
agent-5: -220.26122236010852
Extrinsic Rewards:
4
2
4
0
3
Sum Reward: 13
Avg Reward: 2.6
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.3076923076923077
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-49-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -771.4537889141689
  episode_reward_min: -2156.8754539451443
  episodes_this_iter: 1
  episodes_total: 519
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.194
    dispatch_time_ms: 8.595
    learner:
      cur_lr: 0.0011871729511767626
      grad_gnorm: 40.0
      policy_entropy: 42.43645095825195
      policy_loss: 73.319580078125
      var_gnorm: 26.860445022583008
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 83.72502136230469
    num_steps_sampled: 2600000
    num_steps_trained: 2600000
    wait_time_ms: 68.995
  iterations_since_restore: 520
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4528.166710615158
  time_this_iter_s: 8.370952129364014
  time_total_s: 4528.166710615158
  timestamp: 1594860545
  timesteps_since_restore: 2600000
  timesteps_this_iter: 5000
  timesteps_total: 2600000
  training_iteration: 520
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4528 s, 520 iter, 2600000 ts, -771 rew

agent-1: -401.7566754024188
agent-2: -474.57464992891613
agent-3: -529.0195966303197
agent-4: -114.50757396138414
agent-5: -336.7238099968903
Extrinsic Rewards:
6
5
-39
-42
-91
Sum Reward: -161
Avg Reward: -32.2
Min Reward: -91
Max Reward: 6
Gini Coefficient: -0.5987577639751552
20:20 Ratio: -0.06593406593406594
Max-min Ratio: -0.06593406593406594
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-49-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -783.2859604891778
  episode_reward_min: -2156.8754539451443
  episodes_this_iter: 1
  episodes_total: 520
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.613
    dispatch_time_ms: 8.721
    learner:
      cur_lr: 0.0011868400033563375
      grad_gnorm: 40.0
      policy_entropy: 45.58675765991211
      policy_loss: 48.98536682128906
      var_gnorm: 26.664791107177734
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 33.156776428222656
    num_steps_sampled: 2605000
    num_steps_trained: 2605000
    wait_time_ms: 70.068
  iterations_since_restore: 521
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4536.459215641022
  time_this_iter_s: 8.292505025863647
  time_total_s: 4536.459215641022
  timestamp: 1594860553
  timesteps_since_restore: 2605000
  timesteps_this_iter: 5000
  timesteps_total: 2605000
  training_iteration: 521
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4536 s, 521 iter, 2605000 ts, -783 rew

agent-1: -188.83767852778175
agent-2: -78.36576384178629
agent-3: -229.43757583933308
agent-4: -159.1006234057428
agent-5: -24.41722983087404
Extrinsic Rewards:
4
4
8
6
1
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.2782608695652174
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-49-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -784.6630832289316
  episode_reward_min: -2156.8754539451443
  episodes_this_iter: 1
  episodes_total: 521
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.264
    dispatch_time_ms: 6.118
    learner:
      cur_lr: 0.0011865070555359125
      grad_gnorm: 40.0
      policy_entropy: 45.03244400024414
      policy_loss: -51.02040481567383
      var_gnorm: 26.658336639404297
      vf_explained_var: 0.0
      vf_loss: 69.59788513183594
    num_steps_sampled: 2610000
    num_steps_trained: 2610000
    wait_time_ms: 76.95
  iterations_since_restore: 522
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4544.891113042831
  time_this_iter_s: 8.431897401809692
  time_total_s: 4544.891113042831
  timestamp: 1594860561
  timesteps_since_restore: 2610000
  timesteps_this_iter: 5000
  timesteps_total: 2610000
  training_iteration: 522
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4544 s, 522 iter, 2610000 ts, -785 rew

agent-1: -450.9929047663477
agent-2: -433.55940559420355
agent-3: -450.1520301599262
agent-4: -460.53050311541125
agent-5: -213.9787930167212
Extrinsic Rewards:
7
4
6
6
1
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 1
Max Reward: 7
Gini Coefficient: 0.23333333333333334
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-49-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -797.9988075795019
  episode_reward_min: -2156.8754539451443
  episodes_this_iter: 1
  episodes_total: 522
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.922
    dispatch_time_ms: 8.439
    learner:
      cur_lr: 0.0011861739913001657
      grad_gnorm: 40.0
      policy_entropy: 40.95156478881836
      policy_loss: 32.3254280090332
      var_gnorm: 26.501514434814453
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 20.76549530029297
    num_steps_sampled: 2615000
    num_steps_trained: 2615000
    wait_time_ms: 72.209
  iterations_since_restore: 523
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4553.194317340851
  time_this_iter_s: 8.30320429801941
  time_total_s: 4553.194317340851
  timestamp: 1594860570
  timesteps_since_restore: 2615000
  timesteps_this_iter: 5000
  timesteps_total: 2615000
  training_iteration: 523
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4553 s, 523 iter, 2615000 ts, -798 rew

agent-1: -203.5094164544074
agent-2: -186.58765329435562
agent-3: -172.88602896592687
agent-4: -158.14013897745735
agent-5: -210.01914573905148
Extrinsic Rewards:
3
7
10
4
-40
Sum Reward: -16
Avg Reward: -3.2
Min Reward: -40
Max Reward: 10
Gini Coefficient: -2.6
20:20 Ratio: -0.25
Max-min Ratio: -0.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-49-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -799.5167564655872
  episode_reward_min: -2156.8754539451443
  episodes_this_iter: 1
  episodes_total: 523
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.673
    dispatch_time_ms: 8.976
    learner:
      cur_lr: 0.0011858410434797406
      grad_gnorm: 40.0
      policy_entropy: 41.518898010253906
      policy_loss: -64.99012756347656
      var_gnorm: 26.51885414123535
      vf_explained_var: 0.0
      vf_loss: 89.50945281982422
    num_steps_sampled: 2620000
    num_steps_trained: 2620000
    wait_time_ms: 70.386
  iterations_since_restore: 524
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4561.517804384232
  time_this_iter_s: 8.323487043380737
  time_total_s: 4561.517804384232
  timestamp: 1594860578
  timesteps_since_restore: 2620000
  timesteps_this_iter: 5000
  timesteps_total: 2620000
  training_iteration: 524
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4561 s, 524 iter, 2620000 ts, -800 rew

agent-1: -390.62279440997366
agent-2: -341.8643186104118
agent-3: -396.8323637224777
agent-4: -430.89966047349367
agent-5: -211.9611817205298
Extrinsic Rewards:
4
1
4
10
5
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 1
Max Reward: 10
Gini Coefficient: 0.31666666666666665
20:20 Ratio: 10.0
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-49-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -809.5484009005055
  episode_reward_min: -2156.8754539451443
  episodes_this_iter: 1
  episodes_total: 524
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.14
    dispatch_time_ms: 7.3
    learner:
      cur_lr: 0.0011855079792439938
      grad_gnorm: 40.0
      policy_entropy: 38.49734878540039
      policy_loss: 18.9266300201416
      var_gnorm: 26.448232650756836
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 16.617441177368164
    num_steps_sampled: 2625000
    num_steps_trained: 2625000
    wait_time_ms: 73.348
  iterations_since_restore: 525
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4569.819991111755
  time_this_iter_s: 8.302186727523804
  time_total_s: 4569.819991111755
  timestamp: 1594860586
  timesteps_since_restore: 2625000
  timesteps_this_iter: 5000
  timesteps_total: 2625000
  training_iteration: 525
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4569 s, 525 iter, 2625000 ts, -810 rew

agent-1: -264.0734700629242
agent-2: -290.84694987982243
agent-3: -251.83831085360032
agent-4: -167.33371800256137
agent-5: -351.13590875344903
Extrinsic Rewards:
3
6
6
4
10
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 3
Max Reward: 10
Gini Coefficient: 0.2206896551724138
20:20 Ratio: 3.3333333333333335
Max-min Ratio: 3.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-49-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -815.8897910397925
  episode_reward_min: -2156.8754539451443
  episodes_this_iter: 1
  episodes_total: 525
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.768
    dispatch_time_ms: 6.173
    learner:
      cur_lr: 0.0011851750314235687
      grad_gnorm: 40.0
      policy_entropy: 36.904117584228516
      policy_loss: 67.2533950805664
      var_gnorm: 26.54245948791504
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 87.18524932861328
    num_steps_sampled: 2630000
    num_steps_trained: 2630000
    wait_time_ms: 74.821
  iterations_since_restore: 526
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4578.173337936401
  time_this_iter_s: 8.353346824645996
  time_total_s: 4578.173337936401
  timestamp: 1594860595
  timesteps_since_restore: 2630000
  timesteps_this_iter: 5000
  timesteps_total: 2630000
  training_iteration: 526
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4578 s, 526 iter, 2630000 ts, -816 rew

agent-1: -476.3456260819337
agent-2: -286.4155918679357
agent-3: -453.52348753820417
agent-4: -445.50287704283994
agent-5: -475.9706001331688
Extrinsic Rewards:
3
7
9
4
1
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.3333333333333333
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-50-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -829.1025499866164
  episode_reward_min: -2156.8754539451443
  episodes_this_iter: 1
  episodes_total: 526
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.808
    dispatch_time_ms: 9.079
    learner:
      cur_lr: 0.0011848419671878219
      grad_gnorm: 39.999996185302734
      policy_entropy: 45.008853912353516
      policy_loss: -71.96578216552734
      var_gnorm: 26.51168441772461
      vf_explained_var: 0.0
      vf_loss: 80.39041137695312
    num_steps_sampled: 2635000
    num_steps_trained: 2635000
    wait_time_ms: 73.023
  iterations_since_restore: 527
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4586.523795604706
  time_this_iter_s: 8.350457668304443
  time_total_s: 4586.523795604706
  timestamp: 1594860603
  timesteps_since_restore: 2635000
  timesteps_this_iter: 5000
  timesteps_total: 2635000
  training_iteration: 527
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4586 s, 527 iter, 2635000 ts, -829 rew

agent-1: -242.39342211223124
agent-2: -385.1260757461507
agent-3: -205.86870610142918
agent-4: -334.40124382045826
agent-5: -242.39342211223124
Extrinsic Rewards:
0
-43
4
6
0
Sum Reward: -33
Avg Reward: -6.6
Min Reward: -43
Max Reward: 6
Gini Coefficient: -1.2363636363636363
20:20 Ratio: -0.13953488372093023
Max-min Ratio: -0.13953488372093023
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-50-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -836.3801963108308
  episode_reward_min: -2156.8754539451443
  episodes_this_iter: 1
  episodes_total: 527
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.2
    dispatch_time_ms: 9.614
    learner:
      cur_lr: 0.0011845090193673968
      grad_gnorm: 39.90105438232422
      policy_entropy: 41.743316650390625
      policy_loss: -13.834789276123047
      var_gnorm: 26.60555076599121
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 69.54811096191406
    num_steps_sampled: 2640000
    num_steps_trained: 2640000
    wait_time_ms: 70.013
  iterations_since_restore: 528
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4594.793848991394
  time_this_iter_s: 8.270053386688232
  time_total_s: 4594.793848991394
  timestamp: 1594860612
  timesteps_since_restore: 2640000
  timesteps_this_iter: 5000
  timesteps_total: 2640000
  training_iteration: 528
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4594 s, 528 iter, 2640000 ts, -836 rew

agent-1: -263.25636575093694
agent-2: -559.297053020305
agent-3: -406.5116607261977
agent-4: -538.6714911712684
agent-5: -534.5229403860195
Extrinsic Rewards:
-49
8
2
-44
10
Sum Reward: -73
Avg Reward: -14.6
Min Reward: -49
Max Reward: 10
Gini Coefficient: -0.9315068493150684
20:20 Ratio: -0.20408163265306123
Max-min Ratio: -0.20408163265306123
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-50-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -852.5505739063088
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 528
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.819
    dispatch_time_ms: 9.115
    learner:
      cur_lr: 0.00118417595513165
      grad_gnorm: 40.0
      policy_entropy: 38.31827926635742
      policy_loss: 19.71207046508789
      var_gnorm: 26.4711971282959
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 11.374869346618652
    num_steps_sampled: 2645000
    num_steps_trained: 2645000
    wait_time_ms: 72.731
  iterations_since_restore: 529
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4603.131321430206
  time_this_iter_s: 8.337472438812256
  time_total_s: 4603.131321430206
  timestamp: 1594860620
  timesteps_since_restore: 2645000
  timesteps_this_iter: 5000
  timesteps_total: 2645000
  training_iteration: 529
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4603 s, 529 iter, 2645000 ts, -853 rew

agent-1: -149.94173606202796
agent-2: -285.9353132506034
agent-3: -231.37116850867616
agent-4: -130.73411330137495
agent-5: -131.8526762534559
Extrinsic Rewards:
0
7
9
-49
8
Sum Reward: -25
Avg Reward: -5.0
Min Reward: -49
Max Reward: 9
Gini Coefficient: -1.984
20:20 Ratio: -0.1836734693877551
Max-min Ratio: -0.1836734693877551
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-50-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -854.900098352261
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 529
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.012
    dispatch_time_ms: 19.156
    learner:
      cur_lr: 0.001183843007311225
      grad_gnorm: 40.000003814697266
      policy_entropy: 55.876121520996094
      policy_loss: 22.682615280151367
      var_gnorm: 26.372203826904297
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.951828956604004
    num_steps_sampled: 2650000
    num_steps_trained: 2650000
    wait_time_ms: 67.581
  iterations_since_restore: 530
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4611.80163526535
  time_this_iter_s: 8.670313835144043
  time_total_s: 4611.80163526535
  timestamp: 1594860629
  timesteps_since_restore: 2650000
  timesteps_this_iter: 5000
  timesteps_total: 2650000
  training_iteration: 530
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4611 s, 530 iter, 2650000 ts, -855 rew

agent-1: -69.641162996641
agent-2: -172.0127476782117
agent-3: -165.22528428869393
agent-4: -138.7495266261929
agent-5: -159.7684154588244
Extrinsic Rewards:
1
13
8
13
4
Sum Reward: 39
Avg Reward: 7.8
Min Reward: 1
Max Reward: 13
Gini Coefficient: 0.3384615384615385
20:20 Ratio: 13.0
Max-min Ratio: 13.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-50-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -855.7091555956781
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 530
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.907
    dispatch_time_ms: 21.437
    learner:
      cur_lr: 0.001183509943075478
      grad_gnorm: 9.68438720703125
      policy_entropy: 55.526851654052734
      policy_loss: 4.240784168243408
      var_gnorm: 26.276960372924805
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.3558863401412964
    num_steps_sampled: 2655000
    num_steps_trained: 2655000
    wait_time_ms: 68.462
  iterations_since_restore: 531
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4620.792801856995
  time_this_iter_s: 8.991166591644287
  time_total_s: 4620.792801856995
  timestamp: 1594860638
  timesteps_since_restore: 2655000
  timesteps_this_iter: 5000
  timesteps_total: 2655000
  training_iteration: 531
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4620 s, 531 iter, 2655000 ts, -856 rew

agent-1: -129.22457099973627
agent-2: -210.67377770497475
agent-3: -156.93009817809732
agent-4: -143.88003422479767
agent-5: -197.8488816105181
Extrinsic Rewards:
4
9
5
0
2
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.42
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-50-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -856.8990981555628
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 531
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.41
    dispatch_time_ms: 23.948
    learner:
      cur_lr: 0.001183176995255053
      grad_gnorm: 40.000003814697266
      policy_entropy: 59.36903381347656
      policy_loss: 12.687180519104004
      var_gnorm: 26.255470275878906
      vf_explained_var: 0.0
      vf_loss: 8.445744514465332
    num_steps_sampled: 2660000
    num_steps_trained: 2660000
    wait_time_ms: 61.417
  iterations_since_restore: 532
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4629.593324422836
  time_this_iter_s: 8.800522565841675
  time_total_s: 4629.593324422836
  timestamp: 1594860646
  timesteps_since_restore: 2660000
  timesteps_this_iter: 5000
  timesteps_total: 2660000
  training_iteration: 532
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4629 s, 532 iter, 2660000 ts, -857 rew

agent-1: -169.6172761442113
agent-2: -250.5300512045622
agent-3: -121.46727584401138
agent-4: -19.251007163045806
agent-5: -77.70901936965853
Extrinsic Rewards:
3
9
5
1
5
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.3130434782608696
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-50-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -856.1298607369416
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 532
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.989
    dispatch_time_ms: 30.446
    learner:
      cur_lr: 0.001182844047434628
      grad_gnorm: 35.635658264160156
      policy_entropy: 59.15555191040039
      policy_loss: 5.245392799377441
      var_gnorm: 26.199880599975586
      vf_explained_var: 0.0
      vf_loss: 10.057832717895508
    num_steps_sampled: 2665000
    num_steps_trained: 2665000
    wait_time_ms: 45.4
  iterations_since_restore: 533
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4638.403250455856
  time_this_iter_s: 8.80992603302002
  time_total_s: 4638.403250455856
  timestamp: 1594860655
  timesteps_since_restore: 2665000
  timesteps_this_iter: 5000
  timesteps_total: 2665000
  training_iteration: 533
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4638 s, 533 iter, 2665000 ts, -856 rew

agent-1: -220.12394267087677
agent-2: -229.28003299646258
agent-3: -85.77458117811294
agent-4: -51.380354064720855
agent-5: -110.68032744655315
Extrinsic Rewards:
7
12
9
5
0
Sum Reward: 33
Avg Reward: 6.6
Min Reward: 0
Max Reward: 12
Gini Coefficient: 0.3393939393939394
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-51-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -856.4527142970014
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 533
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.722
    dispatch_time_ms: 34.648
    learner:
      cur_lr: 0.0011825109831988811
      grad_gnorm: 27.08930778503418
      policy_entropy: 59.557159423828125
      policy_loss: -10.313719749450684
      var_gnorm: 26.23302459716797
      vf_explained_var: 0.0
      vf_loss: 7.615000247955322
    num_steps_sampled: 2670000
    num_steps_trained: 2670000
    wait_time_ms: 56.166
  iterations_since_restore: 534
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4647.4637362957
  time_this_iter_s: 9.06048583984375
  time_total_s: 4647.4637362957
  timestamp: 1594860664
  timesteps_since_restore: 2670000
  timesteps_this_iter: 5000
  timesteps_total: 2670000
  training_iteration: 534
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4647 s, 534 iter, 2670000 ts, -856 rew

agent-1: -103.57183922555234
agent-2: -120.24349767230731
agent-3: -206.71585826362363
agent-4: -99.4122104795365
agent-5: -227.63102723166938
Extrinsic Rewards:
8
0
8
4
6
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.3076923076923077
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-51-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -858.2601693573315
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 534
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.073
    dispatch_time_ms: 30.138
    learner:
      cur_lr: 0.0011821780353784561
      grad_gnorm: 40.0
      policy_entropy: 53.329994201660156
      policy_loss: -76.27179718017578
      var_gnorm: 26.205501556396484
      vf_explained_var: 0.0
      vf_loss: 132.44711303710938
    num_steps_sampled: 2675000
    num_steps_trained: 2675000
    wait_time_ms: 60.278
  iterations_since_restore: 535
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4656.298655748367
  time_this_iter_s: 8.834919452667236
  time_total_s: 4656.298655748367
  timestamp: 1594860673
  timesteps_since_restore: 2675000
  timesteps_this_iter: 5000
  timesteps_total: 2675000
  training_iteration: 535
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4656 s, 535 iter, 2675000 ts, -858 rew

agent-1: -150.99259371109622
agent-2: -96.3421172357236
agent-3: -253.0314497671457
agent-4: -54.80063647140462
agent-5: -27.641725241060314
Extrinsic Rewards:
5
3
6
5
4
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 3
Max Reward: 6
Gini Coefficient: 0.12173913043478261
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-51-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -857.6495866297732
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 535
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.044
    dispatch_time_ms: 13.844
    learner:
      cur_lr: 0.0011818449711427093
      grad_gnorm: 40.0
      policy_entropy: 39.617454528808594
      policy_loss: 23.17115020751953
      var_gnorm: 26.224626541137695
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 18.677602767944336
    num_steps_sampled: 2680000
    num_steps_trained: 2680000
    wait_time_ms: 79.106
  iterations_since_restore: 536
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4665.201230764389
  time_this_iter_s: 8.902575016021729
  time_total_s: 4665.201230764389
  timestamp: 1594860682
  timesteps_since_restore: 2680000
  timesteps_this_iter: 5000
  timesteps_total: 2680000
  training_iteration: 536
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4665 s, 536 iter, 2680000 ts, -858 rew

agent-1: -276.9973861804824
agent-2: -445.45705188543457
agent-3: -506.82863066118847
agent-4: -54.00882872557018
agent-5: -455.0101119072683
Extrinsic Rewards:
-49
1
9
3
2
Sum Reward: -34
Avg Reward: -6.8
Min Reward: -49
Max Reward: 9
Gini Coefficient: -1.388235294117647
20:20 Ratio: -0.1836734693877551
Max-min Ratio: -0.1836734693877551
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-51-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -867.2096677274807
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 536
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.41
    dispatch_time_ms: 29.081
    learner:
      cur_lr: 0.0011815120233222842
      grad_gnorm: 8.201770782470703
      policy_entropy: 50.53974151611328
      policy_loss: -0.6264980435371399
      var_gnorm: 26.210588455200195
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1.975368618965149
    num_steps_sampled: 2685000
    num_steps_trained: 2685000
    wait_time_ms: 54.613
  iterations_since_restore: 537
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4674.03854393959
  time_this_iter_s: 8.837313175201416
  time_total_s: 4674.03854393959
  timestamp: 1594860691
  timesteps_since_restore: 2685000
  timesteps_this_iter: 5000
  timesteps_total: 2685000
  training_iteration: 537
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4674 s, 537 iter, 2685000 ts, -867 rew

agent-1: -211.28920160106028
agent-2: -76.65110004238049
agent-3: -121.30941727627192
agent-4: -145.9056831152598
agent-5: -178.74383164351616
Extrinsic Rewards:
6
1
2
2
4
Sum Reward: 15
Avg Reward: 3.0
Min Reward: 1
Max Reward: 6
Gini Coefficient: 0.32
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-51-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -867.7847112862474
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 537
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.663
    dispatch_time_ms: 7.96
    learner:
      cur_lr: 0.0011811789590865374
      grad_gnorm: 4.65162992477417
      policy_entropy: 48.234867095947266
      policy_loss: 0.72038733959198
      var_gnorm: 26.213207244873047
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.3644847869873047
    num_steps_sampled: 2690000
    num_steps_trained: 2690000
    wait_time_ms: 71.47
  iterations_since_restore: 538
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4682.635521173477
  time_this_iter_s: 8.596977233886719
  time_total_s: 4682.635521173477
  timestamp: 1594860700
  timesteps_since_restore: 2690000
  timesteps_this_iter: 5000
  timesteps_total: 2690000
  training_iteration: 538
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4682 s, 538 iter, 2690000 ts, -868 rew

agent-1: -153.26380110782145
agent-2: -101.7607523114297
agent-3: -132.79620971263301
agent-4: -103.10864059700148
agent-5: -189.10537640198987
Extrinsic Rewards:
7
8
16
2
15
Sum Reward: 48
Avg Reward: 9.6
Min Reward: 2
Max Reward: 16
Gini Coefficient: 0.3
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-51-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -868.2367742053891
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 538
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.829
    dispatch_time_ms: 7.841
    learner:
      cur_lr: 0.0011808460112661123
      grad_gnorm: 15.612228393554688
      policy_entropy: 60.411827087402344
      policy_loss: -1.6894333362579346
      var_gnorm: 26.204811096191406
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 2.081791877746582
    num_steps_sampled: 2695000
    num_steps_trained: 2695000
    wait_time_ms: 72.062
  iterations_since_restore: 539
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4691.070063829422
  time_this_iter_s: 8.434542655944824
  time_total_s: 4691.070063829422
  timestamp: 1594860708
  timesteps_since_restore: 2695000
  timesteps_this_iter: 5000
  timesteps_total: 2695000
  training_iteration: 539
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4691 s, 539 iter, 2695000 ts, -868 rew

agent-1: -29.007684456522725
agent-2: -175.2760455211981
agent-3: -116.22515407712541
agent-4: -239.17222850438537
agent-5: -33.67694748856176
Extrinsic Rewards:
3
7
12
6
5
Sum Reward: 33
Avg Reward: 6.6
Min Reward: 3
Max Reward: 12
Gini Coefficient: 0.24242424242424243
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-51-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -867.8510939359342
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 539
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.169
    dispatch_time_ms: 8.476
    learner:
      cur_lr: 0.0011805129470303655
      grad_gnorm: 10.628376007080078
      policy_entropy: 62.43097686767578
      policy_loss: -3.9114739894866943
      var_gnorm: 26.20099449157715
      vf_explained_var: 0.0
      vf_loss: 2.1272594928741455
    num_steps_sampled: 2700000
    num_steps_trained: 2700000
    wait_time_ms: 73.783
  iterations_since_restore: 540
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4699.510240077972
  time_this_iter_s: 8.440176248550415
  time_total_s: 4699.510240077972
  timestamp: 1594860717
  timesteps_since_restore: 2700000
  timesteps_this_iter: 5000
  timesteps_total: 2700000
  training_iteration: 540
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4699 s, 540 iter, 2700000 ts, -868 rew

agent-1: -70.93604311927183
agent-2: -170.13457011662672
agent-3: -138.76315469922216
agent-4: -202.29131511019818
agent-5: -145.23838237752867
Extrinsic Rewards:
4
6
2
9
2
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 2
Max Reward: 9
Gini Coefficient: 0.3130434782608696
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-52-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -868.6082675185457
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 540
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.469
    dispatch_time_ms: 5.757
    learner:
      cur_lr: 0.0011801799992099404
      grad_gnorm: 16.69260597229004
      policy_entropy: 65.6740951538086
      policy_loss: -3.691474437713623
      var_gnorm: 26.196672439575195
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 4.424242973327637
    num_steps_sampled: 2705000
    num_steps_trained: 2705000
    wait_time_ms: 79.905
  iterations_since_restore: 541
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4707.902430295944
  time_this_iter_s: 8.392190217971802
  time_total_s: 4707.902430295944
  timestamp: 1594860725
  timesteps_since_restore: 2705000
  timesteps_this_iter: 5000
  timesteps_total: 2705000
  training_iteration: 541
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4707 s, 541 iter, 2705000 ts, -869 rew

agent-1: -148.76757252832934
agent-2: -194.44484240938976
agent-3: -28.110931548523855
agent-4: -199.2934665244007
agent-5: -124.47688378259303
Extrinsic Rewards:
10
7
2
6
4
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 2
Max Reward: 10
Gini Coefficient: 0.2620689655172414
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-52-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -867.4092236844986
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 541
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.926
    dispatch_time_ms: 9.09
    learner:
      cur_lr: 0.0011798470513895154
      grad_gnorm: 40.0
      policy_entropy: 64.18190002441406
      policy_loss: 23.875375747680664
      var_gnorm: 26.197528839111328
      vf_explained_var: 0.0
      vf_loss: 9.399482727050781
    num_steps_sampled: 2710000
    num_steps_trained: 2710000
    wait_time_ms: 72.431
  iterations_since_restore: 542
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4716.267927408218
  time_this_iter_s: 8.36549711227417
  time_total_s: 4716.267927408218
  timestamp: 1594860734
  timesteps_since_restore: 2710000
  timesteps_this_iter: 5000
  timesteps_total: 2710000
  training_iteration: 542
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4716 s, 542 iter, 2710000 ts, -867 rew

agent-1: -143.08797846177248
agent-2: -5.953951837367709
agent-3: -220.6909875690671
agent-4: -37.2363836013101
agent-5: -210.472732000041
Extrinsic Rewards:
4
1
9
9
11
Sum Reward: 34
Avg Reward: 6.8
Min Reward: 1
Max Reward: 11
Gini Coefficient: 0.29411764705882354
20:20 Ratio: 11.0
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-52-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -866.8638008133523
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 542
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.639
    dispatch_time_ms: 10.684
    learner:
      cur_lr: 0.0011795139871537685
      grad_gnorm: 8.05372142791748
      policy_entropy: 62.36708068847656
      policy_loss: -2.0560731887817383
      var_gnorm: 26.204181671142578
      vf_explained_var: 0.0
      vf_loss: 5.0782790184021
    num_steps_sampled: 2715000
    num_steps_trained: 2715000
    wait_time_ms: 73.65
  iterations_since_restore: 543
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4724.721453905106
  time_this_iter_s: 8.453526496887207
  time_total_s: 4724.721453905106
  timestamp: 1594860742
  timesteps_since_restore: 2715000
  timesteps_this_iter: 5000
  timesteps_total: 2715000
  training_iteration: 543
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4724 s, 543 iter, 2715000 ts, -867 rew

agent-1: -51.2518250823409
agent-2: -190.84981204703564
agent-3: -55.447381671471156
agent-4: -174.29691055719607
agent-5: -221.82549465452402
Extrinsic Rewards:
1
4
2
5
6
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 1
Max Reward: 6
Gini Coefficient: 0.28888888888888886
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-52-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -866.6796431986364
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 543
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.715
    dispatch_time_ms: 9.331
    learner:
      cur_lr: 0.0011791810393333435
      grad_gnorm: 37.23835372924805
      policy_entropy: 54.31324005126953
      policy_loss: -11.918342590332031
      var_gnorm: 26.24295997619629
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 5.166467189788818
    num_steps_sampled: 2720000
    num_steps_trained: 2720000
    wait_time_ms: 72.996
  iterations_since_restore: 544
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4733.050634860992
  time_this_iter_s: 8.32918095588684
  time_total_s: 4733.050634860992
  timestamp: 1594860750
  timesteps_since_restore: 2720000
  timesteps_this_iter: 5000
  timesteps_total: 2720000
  training_iteration: 544
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4733 s, 544 iter, 2720000 ts, -867 rew

agent-1: -208.26726799560046
agent-2: -180.91373435651454
agent-3: -185.75703071100804
agent-4: -132.77839361789378
agent-5: -144.86000114233633
Extrinsic Rewards:
4
4
5
5
0
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 0
Max Reward: 5
Gini Coefficient: 0.24444444444444444
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-52-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -867.2254351371795
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 544
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.053
    dispatch_time_ms: 7.838
    learner:
      cur_lr: 0.0011788479750975966
      grad_gnorm: 9.762372016906738
      policy_entropy: 55.764190673828125
      policy_loss: -0.027698591351509094
      var_gnorm: 26.223669052124023
      vf_explained_var: 0.0
      vf_loss: 3.237841844558716
    num_steps_sampled: 2725000
    num_steps_trained: 2725000
    wait_time_ms: 73.011
  iterations_since_restore: 545
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4741.393663883209
  time_this_iter_s: 8.343029022216797
  time_total_s: 4741.393663883209
  timestamp: 1594860759
  timesteps_since_restore: 2725000
  timesteps_this_iter: 5000
  timesteps_total: 2725000
  training_iteration: 545
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4741 s, 545 iter, 2725000 ts, -867 rew

agent-1: -430.75985007056966
agent-2: -398.61848958577207
agent-3: -58.29810332585166
agent-4: -257.8359572401964
agent-5: -345.92064469353494
Extrinsic Rewards:
10
5
9
-34
3
Sum Reward: -7
Avg Reward: -1.4
Min Reward: -34
Max Reward: 10
Gini Coefficient: -5.371428571428571
20:20 Ratio: -0.29411764705882354
Max-min Ratio: -0.29411764705882354
agent-1: -166.2850508010437
agent-2: -149.41855270695987
agent-3: -233.84320459066868
agent-4: -147.62152062209472
agent-5: -148.88476638462936
Extrinsic Rewards:
4
3
6
2
0
Sum Reward: 15
Avg Reward: 3.0
Min Reward: 0
Max Reward: 6
Gini Coefficient: 0.37333333333333335
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-52-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -877.2769495090266
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 2
  episodes_total: 546
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.612
    dispatch_time_ms: 36.329
    learner:
      cur_lr: 0.0011785150272771716
      grad_gnorm: 40.00000762939453
      policy_entropy: 43.28474426269531
      policy_loss: 37.594486236572266
      var_gnorm: 26.306928634643555
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 51.727848052978516
    num_steps_sampled: 2730000
    num_steps_trained: 2730000
    wait_time_ms: 37.959
  iterations_since_restore: 546
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4758.567120075226
  time_this_iter_s: 17.1734561920166
  time_total_s: 4758.567120075226
  timestamp: 1594860776
  timesteps_since_restore: 2730000
  timesteps_this_iter: 5000
  timesteps_total: 2730000
  training_iteration: 546
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4758 s, 546 iter, 2730000 ts, -877 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-53-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -877.2769495090267
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 0
  episodes_total: 546
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.153
    dispatch_time_ms: 53.284
    learner:
      cur_lr: 0.0011781819630414248
      grad_gnorm: 10.854843139648438
      policy_entropy: 45.50613784790039
      policy_loss: -0.028556540608406067
      var_gnorm: 26.224048614501953
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 5.820451736450195
    num_steps_sampled: 2735000
    num_steps_trained: 2735000
    wait_time_ms: 40.141
  iterations_since_restore: 547
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4767.056631803513
  time_this_iter_s: 8.489511728286743
  time_total_s: 4767.056631803513
  timestamp: 1594860785
  timesteps_since_restore: 2735000
  timesteps_this_iter: 5000
  timesteps_total: 2735000
  training_iteration: 547
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4767 s, 547 iter, 2735000 ts, -877 rew

agent-1: -38.19353417792538
agent-2: -211.4043080984849
agent-3: -71.72327109874166
agent-4: -42.17892102463365
agent-5: -179.17392176204922
Extrinsic Rewards:
12
14
7
0
14
Sum Reward: 47
Avg Reward: 9.4
Min Reward: 0
Max Reward: 14
Gini Coefficient: 0.2978723404255319
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-53-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -875.9145009985155
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 547
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.695
    dispatch_time_ms: 23.542
    learner:
      cur_lr: 0.0011778490152209997
      grad_gnorm: 40.0
      policy_entropy: 35.1377067565918
      policy_loss: 11.932904243469238
      var_gnorm: 26.203609466552734
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 15.781585693359375
    num_steps_sampled: 2740000
    num_steps_trained: 2740000
    wait_time_ms: 51.807
  iterations_since_restore: 548
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4775.927188873291
  time_this_iter_s: 8.870557069778442
  time_total_s: 4775.927188873291
  timestamp: 1594860793
  timesteps_since_restore: 2740000
  timesteps_this_iter: 5000
  timesteps_total: 2740000
  training_iteration: 548
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4775 s, 548 iter, 2740000 ts, -876 rew

agent-1: -121.85938072025708
agent-2: -206.07811416194218
agent-3: -52.79938199948988
agent-4: -58.11607024892113
agent-5: -179.16489151518738
Extrinsic Rewards:
7
25
11
7
16
Sum Reward: 66
Avg Reward: 13.2
Min Reward: 7
Max Reward: 25
Gini Coefficient: 0.2727272727272727
20:20 Ratio: 3.5714285714285716
Max-min Ratio: 3.5714285714285716
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-53-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -875.2096096571335
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 548
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.863
    dispatch_time_ms: 29.766
    learner:
      cur_lr: 0.0011775159509852529
      grad_gnorm: 4.612388610839844
      policy_entropy: 35.335750579833984
      policy_loss: 1.5835998058319092
      var_gnorm: 26.184165954589844
      vf_explained_var: 0.0
      vf_loss: 7.331768035888672
    num_steps_sampled: 2745000
    num_steps_trained: 2745000
    wait_time_ms: 66.442
  iterations_since_restore: 549
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4785.004979610443
  time_this_iter_s: 9.0777907371521
  time_total_s: 4785.004979610443
  timestamp: 1594860803
  timesteps_since_restore: 2745000
  timesteps_this_iter: 5000
  timesteps_total: 2745000
  training_iteration: 549
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4785 s, 549 iter, 2745000 ts, -875 rew

agent-1: -157.40509814393732
agent-2: -36.74524627722604
agent-3: -225.98161039646038
agent-4: -63.451746902553474
agent-5: -117.38595096280923
Extrinsic Rewards:
7
7
9
6
4
Sum Reward: 33
Avg Reward: 6.6
Min Reward: 4
Max Reward: 9
Gini Coefficient: 0.13333333333333333
20:20 Ratio: 2.25
Max-min Ratio: 2.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-53-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -874.36950303374
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 549
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.199
    dispatch_time_ms: 15.647
    learner:
      cur_lr: 0.0011771830031648278
      grad_gnorm: 15.022453308105469
      policy_entropy: 32.834861755371094
      policy_loss: 2.5459094047546387
      var_gnorm: 26.214216232299805
      vf_explained_var: 0.0
      vf_loss: 10.867762565612793
    num_steps_sampled: 2750000
    num_steps_trained: 2750000
    wait_time_ms: 70.22
  iterations_since_restore: 550
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4793.786546945572
  time_this_iter_s: 8.781567335128784
  time_total_s: 4793.786546945572
  timestamp: 1594860811
  timesteps_since_restore: 2750000
  timesteps_this_iter: 5000
  timesteps_total: 2750000
  training_iteration: 550
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4793 s, 550 iter, 2750000 ts, -874 rew

agent-1: -203.32356303689784
agent-2: -129.71068132800286
agent-3: -205.29438580068256
agent-4: -104.4526255128799
agent-5: -107.28665528217896
Extrinsic Rewards:
9
4
8
10
0
Sum Reward: 31
Avg Reward: 6.2
Min Reward: 0
Max Reward: 10
Gini Coefficient: 0.3225806451612903
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-53-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -874.032678489594
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 550
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.072
    dispatch_time_ms: 26.992
    learner:
      cur_lr: 0.0011768500553444028
      grad_gnorm: 7.011862277984619
      policy_entropy: 55.51262664794922
      policy_loss: -0.8931314945220947
      var_gnorm: 26.208723068237305
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.8942477703094482
    num_steps_sampled: 2755000
    num_steps_trained: 2755000
    wait_time_ms: 41.422
  iterations_since_restore: 551
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4802.727969408035
  time_this_iter_s: 8.941422462463379
  time_total_s: 4802.727969408035
  timestamp: 1594860820
  timesteps_since_restore: 2755000
  timesteps_this_iter: 5000
  timesteps_total: 2755000
  training_iteration: 551
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4802 s, 551 iter, 2755000 ts, -874 rew

agent-1: -187.24913504527706
agent-2: -177.70720342197112
agent-3: -139.93901202255375
agent-4: -203.3667843054018
agent-5: -73.25015113978053
Extrinsic Rewards:
6
7
10
9
4
Sum Reward: 36
Avg Reward: 7.2
Min Reward: 4
Max Reward: 10
Gini Coefficient: 0.16666666666666666
20:20 Ratio: 2.5
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-53-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -876.0244405425104
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 551
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.078
    dispatch_time_ms: 34.32
    learner:
      cur_lr: 0.001176516991108656
      grad_gnorm: 40.0
      policy_entropy: 67.09989929199219
      policy_loss: 12.588800430297852
      var_gnorm: 26.222328186035156
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 13.586640357971191
    num_steps_sampled: 2760000
    num_steps_trained: 2760000
    wait_time_ms: 47.702
  iterations_since_restore: 552
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4811.62101149559
  time_this_iter_s: 8.893042087554932
  time_total_s: 4811.62101149559
  timestamp: 1594860829
  timesteps_since_restore: 2760000
  timesteps_this_iter: 5000
  timesteps_total: 2760000
  training_iteration: 552
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4811 s, 552 iter, 2760000 ts, -876 rew

agent-1: -164.84207972319535
agent-2: -187.6482801745474
agent-3: -117.7233398951439
agent-4: -152.30020056009505
agent-5: -74.27479800054505
Extrinsic Rewards:
9
7
6
6
6
Sum Reward: 34
Avg Reward: 6.8
Min Reward: 6
Max Reward: 9
Gini Coefficient: 0.08235294117647059
20:20 Ratio: 1.5
Max-min Ratio: 1.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-53-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -877.5097686527205
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 552
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.307
    dispatch_time_ms: 31.376
    learner:
      cur_lr: 0.001176184043288231
      grad_gnorm: 10.206182479858398
      policy_entropy: 69.22881317138672
      policy_loss: -1.7989791631698608
      var_gnorm: 26.205707550048828
      vf_explained_var: 0.0
      vf_loss: 5.248713970184326
    num_steps_sampled: 2765000
    num_steps_trained: 2765000
    wait_time_ms: 54.918
  iterations_since_restore: 553
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4820.499548912048
  time_this_iter_s: 8.87853741645813
  time_total_s: 4820.499548912048
  timestamp: 1594860838
  timesteps_since_restore: 2765000
  timesteps_this_iter: 5000
  timesteps_total: 2765000
  training_iteration: 553
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4820 s, 553 iter, 2765000 ts, -878 rew

agent-1: -31.97013431520288
agent-2: -203.3307948933403
agent-3: -80.56782817533714
agent-4: -141.57110797550123
agent-5: -229.18467407053336
Extrinsic Rewards:
1
7
1
1
5
Sum Reward: 15
Avg Reward: 3.0
Min Reward: 1
Max Reward: 7
Gini Coefficient: 0.4266666666666667
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-54-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -879.4149640313018
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 553
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.965
    dispatch_time_ms: 38.607
    learner:
      cur_lr: 0.001175850979052484
      grad_gnorm: 40.000003814697266
      policy_entropy: 51.75642395019531
      policy_loss: 28.211841583251953
      var_gnorm: 26.231943130493164
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 13.661099433898926
    num_steps_sampled: 2770000
    num_steps_trained: 2770000
    wait_time_ms: 45.351
  iterations_since_restore: 554
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4829.390675783157
  time_this_iter_s: 8.891126871109009
  time_total_s: 4829.390675783157
  timestamp: 1594860847
  timesteps_since_restore: 2770000
  timesteps_this_iter: 5000
  timesteps_total: 2770000
  training_iteration: 554
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4829 s, 554 iter, 2770000 ts, -879 rew

agent-1: -125.55823117126477
agent-2: -246.55640416428415
agent-3: -80.3792688538027
agent-4: -112.30048969118262
agent-5: -173.2660729692754
Extrinsic Rewards:
0
8
4
7
9
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.3142857142857143
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-54-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -878.7171954987278
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 554
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.117
    dispatch_time_ms: 9.181
    learner:
      cur_lr: 0.001175518031232059
      grad_gnorm: 10.02527904510498
      policy_entropy: 49.55781936645508
      policy_loss: -3.915461540222168
      var_gnorm: 26.216936111450195
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 4.5044426918029785
    num_steps_sampled: 2775000
    num_steps_trained: 2775000
    wait_time_ms: 73.875
  iterations_since_restore: 555
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4837.835263252258
  time_this_iter_s: 8.444587469100952
  time_total_s: 4837.835263252258
  timestamp: 1594860856
  timesteps_since_restore: 2775000
  timesteps_this_iter: 5000
  timesteps_total: 2775000
  training_iteration: 555
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4837 s, 555 iter, 2775000 ts, -879 rew

agent-1: -115.48476538618092
agent-2: -197.75409716289147
agent-3: -198.9218358999973
agent-4: -28.169650786416597
agent-5: -154.46360008612248
Extrinsic Rewards:
7
6
9
2
4
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 2
Max Reward: 9
Gini Coefficient: 0.24285714285714285
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-54-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -878.9863102834304
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 555
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.059
    dispatch_time_ms: 8.978
    learner:
      cur_lr: 0.0011751849669963121
      grad_gnorm: 40.0
      policy_entropy: 40.52200698852539
      policy_loss: 22.47429656982422
      var_gnorm: 26.21839714050293
      vf_explained_var: 0.0
      vf_loss: 18.355627059936523
    num_steps_sampled: 2780000
    num_steps_trained: 2780000
    wait_time_ms: 67.651
  iterations_since_restore: 556
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4846.167085886002
  time_this_iter_s: 8.331822633743286
  time_total_s: 4846.167085886002
  timestamp: 1594860864
  timesteps_since_restore: 2780000
  timesteps_this_iter: 5000
  timesteps_total: 2780000
  training_iteration: 556
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4846 s, 556 iter, 2780000 ts, -879 rew

agent-1: -219.47756572482723
agent-2: -210.3408973659216
agent-3: -57.65091060053061
agent-4: -107.72600516869059
agent-5: -64.97668345867662
Extrinsic Rewards:
12
8
7
2
2
Sum Reward: 31
Avg Reward: 6.2
Min Reward: 2
Max Reward: 12
Gini Coefficient: 0.33548387096774196
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-54-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -879.0060668738324
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 556
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.793
    dispatch_time_ms: 6.129
    learner:
      cur_lr: 0.001174852019175887
      grad_gnorm: 15.328288078308105
      policy_entropy: 49.96623229980469
      policy_loss: -1.697077989578247
      var_gnorm: 26.19016456604004
      vf_explained_var: 0.0
      vf_loss: 9.388394355773926
    num_steps_sampled: 2785000
    num_steps_trained: 2785000
    wait_time_ms: 75.45
  iterations_since_restore: 557
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4854.448614835739
  time_this_iter_s: 8.281528949737549
  time_total_s: 4854.448614835739
  timestamp: 1594860872
  timesteps_since_restore: 2785000
  timesteps_this_iter: 5000
  timesteps_total: 2785000
  training_iteration: 557
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4854 s, 557 iter, 2785000 ts, -879 rew

agent-1: -231.92535488736098
agent-2: -90.58978578836337
agent-3: -65.1104858868844
agent-4: -178.6600330346856
agent-5: -29.2039188103268
Extrinsic Rewards:
7
1
9
13
3
Sum Reward: 33
Avg Reward: 6.6
Min Reward: 1
Max Reward: 13
Gini Coefficient: 0.36363636363636365
20:20 Ratio: 13.0
Max-min Ratio: 13.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-54-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -876.1852029796707
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 557
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.741
    dispatch_time_ms: 7.924
    learner:
      cur_lr: 0.0011745189549401402
      grad_gnorm: 15.99006462097168
      policy_entropy: 58.68856430053711
      policy_loss: -4.611416816711426
      var_gnorm: 26.194284439086914
      vf_explained_var: 0.0
      vf_loss: 3.8242530822753906
    num_steps_sampled: 2790000
    num_steps_trained: 2790000
    wait_time_ms: 72.291
  iterations_since_restore: 558
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4862.820777416229
  time_this_iter_s: 8.372162580490112
  time_total_s: 4862.820777416229
  timestamp: 1594860881
  timesteps_since_restore: 2790000
  timesteps_this_iter: 5000
  timesteps_total: 2790000
  training_iteration: 558
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4862 s, 558 iter, 2790000 ts, -876 rew

agent-1: -191.10021340076366
agent-2: -193.32418974808243
agent-3: -48.436053356573936
agent-4: -27.112801633781903
agent-5: -174.51314287758433
Extrinsic Rewards:
5
9
10
4
5
Sum Reward: 33
Avg Reward: 6.6
Min Reward: 4
Max Reward: 10
Gini Coefficient: 0.19393939393939394
20:20 Ratio: 2.5
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-54-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -875.6864532047609
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 558
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.083
    dispatch_time_ms: 10.03
    learner:
      cur_lr: 0.0011741860071197152
      grad_gnorm: 9.607207298278809
      policy_entropy: 62.62525939941406
      policy_loss: -4.190149784088135
      var_gnorm: 26.209070205688477
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.8589963912963867
    num_steps_sampled: 2795000
    num_steps_trained: 2795000
    wait_time_ms: 72.446
  iterations_since_restore: 559
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4871.067881345749
  time_this_iter_s: 8.247103929519653
  time_total_s: 4871.067881345749
  timestamp: 1594860889
  timesteps_since_restore: 2795000
  timesteps_this_iter: 5000
  timesteps_total: 2795000
  training_iteration: 559
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4871 s, 559 iter, 2795000 ts, -876 rew

agent-1: -232.70728587826557
agent-2: -120.75858962216155
agent-3: -73.39869180913225
agent-4: -120.99345312134558
agent-5: -163.4395728137102
Extrinsic Rewards:
7
2
2
3
5
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 2
Max Reward: 7
Gini Coefficient: 0.2736842105263158
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-54-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -876.6570741778154
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 559
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.033
    dispatch_time_ms: 7.705
    learner:
      cur_lr: 0.0011738529428839684
      grad_gnorm: 31.12895965576172
      policy_entropy: 63.315582275390625
      policy_loss: 13.298580169677734
      var_gnorm: 26.224435806274414
      vf_explained_var: 0.0
      vf_loss: 7.626119136810303
    num_steps_sampled: 2800000
    num_steps_trained: 2800000
    wait_time_ms: 71.304
  iterations_since_restore: 560
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4879.40945482254
  time_this_iter_s: 8.341573476791382
  time_total_s: 4879.40945482254
  timestamp: 1594860897
  timesteps_since_restore: 2800000
  timesteps_this_iter: 5000
  timesteps_total: 2800000
  training_iteration: 560
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4879 s, 560 iter, 2800000 ts, -877 rew

agent-1: -106.73555251176121
agent-2: -108.04531530751095
agent-3: -181.9124045108896
agent-4: -83.84544919316963
agent-5: -208.43021266176697
Extrinsic Rewards:
5
3
9
7
11
Sum Reward: 35
Avg Reward: 7.0
Min Reward: 3
Max Reward: 11
Gini Coefficient: 0.22857142857142856
20:20 Ratio: 3.6666666666666665
Max-min Ratio: 3.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-55-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -877.0915449984714
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 560
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.898
    dispatch_time_ms: 6.604
    learner:
      cur_lr: 0.0011735199950635433
      grad_gnorm: 22.326251983642578
      policy_entropy: 60.12055969238281
      policy_loss: 2.8534603118896484
      var_gnorm: 26.183513641357422
      vf_explained_var: 0.0
      vf_loss: 9.308899879455566
    num_steps_sampled: 2805000
    num_steps_trained: 2805000
    wait_time_ms: 77.18
  iterations_since_restore: 561
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4887.772776842117
  time_this_iter_s: 8.363322019577026
  time_total_s: 4887.772776842117
  timestamp: 1594860906
  timesteps_since_restore: 2805000
  timesteps_this_iter: 5000
  timesteps_total: 2805000
  training_iteration: 561
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4887 s, 561 iter, 2805000 ts, -877 rew

agent-1: -176.58366049572987
agent-2: -259.4385706665711
agent-3: -36.960832896716425
agent-4: -9.550568787935367
agent-5: -57.988890651553824
Extrinsic Rewards:
12
13
2
1
4
Sum Reward: 32
Avg Reward: 6.4
Min Reward: 1
Max Reward: 13
Gini Coefficient: 0.425
20:20 Ratio: 13.0
Max-min Ratio: 13.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-55-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -875.4304735537894
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 561
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.911
    dispatch_time_ms: 6.511
    learner:
      cur_lr: 0.0011731870472431183
      grad_gnorm: 40.00000762939453
      policy_entropy: 54.725746154785156
      policy_loss: -0.16603416204452515
      var_gnorm: 26.1744327545166
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 9.317899703979492
    num_steps_sampled: 2810000
    num_steps_trained: 2810000
    wait_time_ms: 72.442
  iterations_since_restore: 562
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4896.0921721458435
  time_this_iter_s: 8.319395303726196
  time_total_s: 4896.0921721458435
  timestamp: 1594860914
  timesteps_since_restore: 2810000
  timesteps_this_iter: 5000
  timesteps_total: 2810000
  training_iteration: 562
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4896 s, 562 iter, 2810000 ts, -875 rew

agent-1: -57.100470635746284
agent-2: -30.305948457002344
agent-3: -28.417543557901872
agent-4: -262.7895784734641
agent-5: -188.4376654012108
Extrinsic Rewards:
2
1
1
9
7
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.44
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-55-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -874.9743034076743
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 562
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.6
    dispatch_time_ms: 7.338
    learner:
      cur_lr: 0.0011728539830073714
      grad_gnorm: 15.898256301879883
      policy_entropy: 49.29904556274414
      policy_loss: -6.439195156097412
      var_gnorm: 26.200904846191406
      vf_explained_var: 0.0
      vf_loss: 4.891468048095703
    num_steps_sampled: 2815000
    num_steps_trained: 2815000
    wait_time_ms: 74.562
  iterations_since_restore: 563
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4904.400306940079
  time_this_iter_s: 8.30813479423523
  time_total_s: 4904.400306940079
  timestamp: 1594860923
  timesteps_since_restore: 2815000
  timesteps_this_iter: 5000
  timesteps_total: 2815000
  training_iteration: 563
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4904 s, 563 iter, 2815000 ts, -875 rew

agent-1: -49.55853151535683
agent-2: -196.53229765667115
agent-3: -224.26251454838126
agent-4: -116.22517053134403
agent-5: -85.88150777123522
Extrinsic Rewards:
4
7
11
9
1
Sum Reward: 32
Avg Reward: 6.4
Min Reward: 1
Max Reward: 11
Gini Coefficient: 0.3125
20:20 Ratio: 11.0
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-55-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -874.6301654507173
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 563
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.702
    dispatch_time_ms: 7.131
    learner:
      cur_lr: 0.0011725210351869464
      grad_gnorm: 36.7719612121582
      policy_entropy: 37.10999298095703
      policy_loss: 14.781784057617188
      var_gnorm: 26.217002868652344
      vf_explained_var: 0.0
      vf_loss: 15.573756217956543
    num_steps_sampled: 2820000
    num_steps_trained: 2820000
    wait_time_ms: 73.184
  iterations_since_restore: 564
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4912.798641443253
  time_this_iter_s: 8.398334503173828
  time_total_s: 4912.798641443253
  timestamp: 1594860931
  timesteps_since_restore: 2820000
  timesteps_this_iter: 5000
  timesteps_total: 2820000
  training_iteration: 564
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4912 s, 564 iter, 2820000 ts, -875 rew

agent-1: -233.32855275056406
agent-2: -103.91084315408884
agent-3: -140.69530956568056
agent-4: -63.32816871440413
agent-5: -136.1936095681003
Extrinsic Rewards:
9
7
3
6
1
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.3076923076923077
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-55-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -873.9102649457068
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 564
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.073
    dispatch_time_ms: 7.809
    learner:
      cur_lr: 0.0011721879709511995
      grad_gnorm: 21.9766902923584
      policy_entropy: 51.16489028930664
      policy_loss: 3.4096968173980713
      var_gnorm: 26.18453598022461
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 12.12143611907959
    num_steps_sampled: 2825000
    num_steps_trained: 2825000
    wait_time_ms: 72.79
  iterations_since_restore: 565
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4920.981828689575
  time_this_iter_s: 8.183187246322632
  time_total_s: 4920.981828689575
  timestamp: 1594860939
  timesteps_since_restore: 2825000
  timesteps_this_iter: 5000
  timesteps_total: 2825000
  training_iteration: 565
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4920 s, 565 iter, 2825000 ts, -874 rew

agent-1: -181.13027246979888
agent-2: -61.10334502513229
agent-3: -225.4447500758576
agent-4: -74.00377104970408
agent-5: -69.72949025520121
Extrinsic Rewards:
8
0
21
14
10
Sum Reward: 53
Avg Reward: 10.6
Min Reward: 0
Max Reward: 21
Gini Coefficient: 0.3622641509433962
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-55-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -874.1937834852582
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 565
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.65
    dispatch_time_ms: 5.521
    learner:
      cur_lr: 0.0011718550231307745
      grad_gnorm: 24.012115478515625
      policy_entropy: 52.690895080566406
      policy_loss: 3.380436658859253
      var_gnorm: 26.214237213134766
      vf_explained_var: 0.0
      vf_loss: 4.022469997406006
    num_steps_sampled: 2830000
    num_steps_trained: 2830000
    wait_time_ms: 74.565
  iterations_since_restore: 566
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4929.254502058029
  time_this_iter_s: 8.27267336845398
  time_total_s: 4929.254502058029
  timestamp: 1594860948
  timesteps_since_restore: 2830000
  timesteps_this_iter: 5000
  timesteps_total: 2830000
  training_iteration: 566
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4929 s, 566 iter, 2830000 ts, -874 rew

agent-1: -98.75779082187564
agent-2: -217.15032151193137
agent-3: -98.3240284812567
agent-4: -161.27569154845435
agent-5: -59.880929774901496
Extrinsic Rewards:
1
7
3
16
3
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 1
Max Reward: 16
Gini Coefficient: 0.4533333333333333
20:20 Ratio: 16.0
Max-min Ratio: 16.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-55-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -873.0986265378399
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 566
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.065
    dispatch_time_ms: 9.252
    learner:
      cur_lr: 0.0011715219588950276
      grad_gnorm: 23.99650764465332
      policy_entropy: 52.39482116699219
      policy_loss: 2.9308133125305176
      var_gnorm: 26.200761795043945
      vf_explained_var: 0.0
      vf_loss: 8.955025672912598
    num_steps_sampled: 2835000
    num_steps_trained: 2835000
    wait_time_ms: 69.101
  iterations_since_restore: 567
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4937.57904624939
  time_this_iter_s: 8.324544191360474
  time_total_s: 4937.57904624939
  timestamp: 1594860956
  timesteps_since_restore: 2835000
  timesteps_this_iter: 5000
  timesteps_total: 2835000
  training_iteration: 567
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4937 s, 567 iter, 2835000 ts, -873 rew

agent-1: -192.00717959731816
agent-2: -26.374199159960355
agent-3: -28.143109066769615
agent-4: -227.3418512287176
agent-5: -161.01749738147169
Extrinsic Rewards:
12
3
3
9
4
Sum Reward: 31
Avg Reward: 6.2
Min Reward: 3
Max Reward: 12
Gini Coefficient: 0.3096774193548387
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-56-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -872.440802608019
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 567
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.549
    dispatch_time_ms: 9.485
    learner:
      cur_lr: 0.0011711890110746026
      grad_gnorm: 12.625591278076172
      policy_entropy: 53.459110260009766
      policy_loss: 1.119867205619812
      var_gnorm: 26.203031539916992
      vf_explained_var: 0.0
      vf_loss: 4.878039360046387
    num_steps_sampled: 2840000
    num_steps_trained: 2840000
    wait_time_ms: 70.618
  iterations_since_restore: 568
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4945.877108812332
  time_this_iter_s: 8.298062562942505
  time_total_s: 4945.877108812332
  timestamp: 1594860964
  timesteps_since_restore: 2840000
  timesteps_this_iter: 5000
  timesteps_total: 2840000
  training_iteration: 568
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4945 s, 568 iter, 2840000 ts, -872 rew

agent-1: -41.79212570638754
agent-2: -179.59432968291404
agent-3: -219.22942563114051
agent-4: -30.737582208531474
agent-5: -180.49354127659242
Extrinsic Rewards:
5
6
12
2
10
Sum Reward: 35
Avg Reward: 7.0
Min Reward: 2
Max Reward: 12
Gini Coefficient: 0.2857142857142857
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-56-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -869.9490950712196
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 568
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.563
    dispatch_time_ms: 9.011
    learner:
      cur_lr: 0.0011708559468388557
      grad_gnorm: 11.500384330749512
      policy_entropy: 51.83317947387695
      policy_loss: -5.0910420417785645
      var_gnorm: 26.1845645904541
      vf_explained_var: 0.0
      vf_loss: 8.444148063659668
    num_steps_sampled: 2845000
    num_steps_trained: 2845000
    wait_time_ms: 73.555
  iterations_since_restore: 569
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4954.268918991089
  time_this_iter_s: 8.391810178756714
  time_total_s: 4954.268918991089
  timestamp: 1594860973
  timesteps_since_restore: 2845000
  timesteps_this_iter: 5000
  timesteps_total: 2845000
  training_iteration: 569
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4954 s, 569 iter, 2845000 ts, -870 rew

agent-1: -5.652879160280889
agent-2: -52.82716488691215
agent-3: -29.746144049720346
agent-4: -240.21122925651213
agent-5: -195.5726415393256
Extrinsic Rewards:
1
9
5
11
6
Sum Reward: 32
Avg Reward: 6.4
Min Reward: 1
Max Reward: 11
Gini Coefficient: 0.3
20:20 Ratio: 11.0
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-56-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -867.6269959969778
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 569
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.615
    dispatch_time_ms: 8.029
    learner:
      cur_lr: 0.0011705229990184307
      grad_gnorm: 13.933876037597656
      policy_entropy: 46.77355194091797
      policy_loss: -4.963290214538574
      var_gnorm: 26.21634864807129
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1.5050073862075806
    num_steps_sampled: 2850000
    num_steps_trained: 2850000
    wait_time_ms: 74.344
  iterations_since_restore: 570
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4962.645973920822
  time_this_iter_s: 8.377054929733276
  time_total_s: 4962.645973920822
  timestamp: 1594860981
  timesteps_since_restore: 2850000
  timesteps_this_iter: 5000
  timesteps_total: 2850000
  training_iteration: 570
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4962 s, 570 iter, 2850000 ts, -868 rew

agent-1: -227.1979837244277
agent-2: -144.0888662898651
agent-3: -238.88153356440216
agent-4: -61.19866605893054
agent-5: -100.3828347962612
Extrinsic Rewards:
8
0
6
2
4
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.4
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-56-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -868.6790459245778
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 570
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.826
    dispatch_time_ms: 5.275
    learner:
      cur_lr: 0.0011701900511980057
      grad_gnorm: 16.82520294189453
      policy_entropy: 35.86206817626953
      policy_loss: 5.145761013031006
      var_gnorm: 26.211082458496094
      vf_explained_var: 0.0
      vf_loss: 6.760615825653076
    num_steps_sampled: 2855000
    num_steps_trained: 2855000
    wait_time_ms: 77.834
  iterations_since_restore: 571
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4970.969422578812
  time_this_iter_s: 8.323448657989502
  time_total_s: 4970.969422578812
  timestamp: 1594860989
  timesteps_since_restore: 2855000
  timesteps_this_iter: 5000
  timesteps_total: 2855000
  training_iteration: 571
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4970 s, 571 iter, 2855000 ts, -869 rew

agent-1: -117.78366244180677
agent-2: -61.07431298789256
agent-3: -48.6590093068368
agent-4: -226.4100537613432
agent-5: -198.74986129502628
Extrinsic Rewards:
5
3
7
6
6
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 3
Max Reward: 7
Gini Coefficient: 0.13333333333333333
20:20 Ratio: 2.3333333333333335
Max-min Ratio: 2.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-56-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -469.8184644827469
  episode_reward_mean: -867.7586896852953
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 571
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.517
    dispatch_time_ms: 9.401
    learner:
      cur_lr: 0.0011698569869622588
      grad_gnorm: 17.270305633544922
      policy_entropy: 40.361690521240234
      policy_loss: -5.825425624847412
      var_gnorm: 26.199321746826172
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 6.00002384185791
    num_steps_sampled: 2860000
    num_steps_trained: 2860000
    wait_time_ms: 71.06
  iterations_since_restore: 572
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4979.376161575317
  time_this_iter_s: 8.406738996505737
  time_total_s: 4979.376161575317
  timestamp: 1594860998
  timesteps_since_restore: 2860000
  timesteps_this_iter: 5000
  timesteps_total: 2860000
  training_iteration: 572
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4979 s, 572 iter, 2860000 ts, -868 rew

agent-1: -66.46091400230065
agent-2: -127.10683076881
agent-3: -55.86370967503885
agent-4: -238.03394324391772
agent-5: -146.48455093830626
Extrinsic Rewards:
3
5
3
4
8
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 3
Max Reward: 8
Gini Coefficient: 0.20869565217391303
20:20 Ratio: 2.6666666666666665
Max-min Ratio: 2.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-56-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -524.0100588927507
  episode_reward_mean: -869.4000045267516
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 572
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.042
    dispatch_time_ms: 8.277
    learner:
      cur_lr: 0.0011695240391418338
      grad_gnorm: 11.161736488342285
      policy_entropy: 53.80734634399414
      policy_loss: -0.1304042786359787
      var_gnorm: 26.217622756958008
      vf_explained_var: 0.0
      vf_loss: 5.562204837799072
    num_steps_sampled: 2865000
    num_steps_trained: 2865000
    wait_time_ms: 75.773
  iterations_since_restore: 573
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4987.762112379074
  time_this_iter_s: 8.385950803756714
  time_total_s: 4987.762112379074
  timestamp: 1594861006
  timesteps_since_restore: 2865000
  timesteps_this_iter: 5000
  timesteps_total: 2865000
  training_iteration: 573
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4987 s, 573 iter, 2865000 ts, -869 rew

agent-1: -189.0482417047686
agent-2: -143.0668859382516
agent-3: -211.52717344442084
agent-4: -188.07340053694423
agent-5: -112.26323268808602
Extrinsic Rewards:
4
0
6
5
3
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 0
Max Reward: 6
Gini Coefficient: 0.3111111111111111
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-56-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -524.0100588927507
  episode_reward_mean: -871.1344781969268
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 573
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.613
    dispatch_time_ms: 5.741
    learner:
      cur_lr: 0.001169190974906087
      grad_gnorm: 34.61665725708008
      policy_entropy: 57.079307556152344
      policy_loss: 13.872366905212402
      var_gnorm: 26.25864028930664
      vf_explained_var: 0.0
      vf_loss: 9.154537200927734
    num_steps_sampled: 2870000
    num_steps_trained: 2870000
    wait_time_ms: 72.967
  iterations_since_restore: 574
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 4996.071397066116
  time_this_iter_s: 8.309284687042236
  time_total_s: 4996.071397066116
  timestamp: 1594861015
  timesteps_since_restore: 2870000
  timesteps_this_iter: 5000
  timesteps_total: 2870000
  training_iteration: 574
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 4996 s, 574 iter, 2870000 ts, -871 rew

agent-1: -45.219247298680536
agent-2: -192.03263650894235
agent-3: -55.155889265442475
agent-4: -227.19763683150813
agent-5: -165.45786333874463
Extrinsic Rewards:
2
5
2
8
2
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 2
Max Reward: 8
Gini Coefficient: 0.3157894736842105
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-57-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -524.0100588927507
  episode_reward_mean: -871.6132164429188
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 574
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.799
    dispatch_time_ms: 8.714
    learner:
      cur_lr: 0.0011688580270856619
      grad_gnorm: 10.378003120422363
      policy_entropy: 56.083560943603516
      policy_loss: 2.7384727001190186
      var_gnorm: 26.223352432250977
      vf_explained_var: 0.0
      vf_loss: 5.596595764160156
    num_steps_sampled: 2875000
    num_steps_trained: 2875000
    wait_time_ms: 74.86
  iterations_since_restore: 575
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5004.804578304291
  time_this_iter_s: 8.733181238174438
  time_total_s: 5004.804578304291
  timestamp: 1594861023
  timesteps_since_restore: 2875000
  timesteps_this_iter: 5000
  timesteps_total: 2875000
  training_iteration: 575
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5004 s, 575 iter, 2875000 ts, -872 rew

agent-1: -143.35720336884626
agent-2: -20.139707401183212
agent-3: -113.90147413764313
agent-4: -169.85778400658648
agent-5: -224.48780495087502
Extrinsic Rewards:
2
2
9
9
8
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 2
Max Reward: 9
Gini Coefficient: 0.28
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-57-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -524.0100588927507
  episode_reward_mean: -872.1474094268311
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 575
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.181
    dispatch_time_ms: 8.768
    learner:
      cur_lr: 0.001168524962849915
      grad_gnorm: 40.0
      policy_entropy: 49.934932708740234
      policy_loss: 9.59496021270752
      var_gnorm: 26.2575626373291
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 11.246065139770508
    num_steps_sampled: 2880000
    num_steps_trained: 2880000
    wait_time_ms: 71.833
  iterations_since_restore: 576
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5013.161439180374
  time_this_iter_s: 8.356860876083374
  time_total_s: 5013.161439180374
  timestamp: 1594861032
  timesteps_since_restore: 2880000
  timesteps_this_iter: 5000
  timesteps_total: 2880000
  training_iteration: 576
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5013 s, 576 iter, 2880000 ts, -872 rew

agent-1: -241.68804212867065
agent-2: -173.65827207646106
agent-3: -143.85828817328132
agent-4: -120.83629435220683
agent-5: -124.99323620326561
Extrinsic Rewards:
4
7
0
4
4
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.29473684210526313
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-57-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -524.0100588927507
  episode_reward_mean: -872.4477706922612
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 576
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.99
    dispatch_time_ms: 7.47
    learner:
      cur_lr: 0.00116819201502949
      grad_gnorm: 9.603864669799805
      policy_entropy: 50.605628967285156
      policy_loss: 3.1926400661468506
      var_gnorm: 26.205522537231445
      vf_explained_var: 0.0
      vf_loss: 6.368887424468994
    num_steps_sampled: 2885000
    num_steps_trained: 2885000
    wait_time_ms: 73.498
  iterations_since_restore: 577
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5021.496809720993
  time_this_iter_s: 8.335370540618896
  time_total_s: 5021.496809720993
  timestamp: 1594861040
  timesteps_since_restore: 2885000
  timesteps_this_iter: 5000
  timesteps_total: 2885000
  training_iteration: 577
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5021 s, 577 iter, 2885000 ts, -872 rew

agent-1: -193.84694349367155
agent-2: -96.70534624030945
agent-3: -27.294091265302903
agent-4: -206.89055672160478
agent-5: -92.13224459605489
Extrinsic Rewards:
7
10
7
20
7
Sum Reward: 51
Avg Reward: 10.2
Min Reward: 7
Max Reward: 20
Gini Coefficient: 0.22745098039215686
20:20 Ratio: 2.857142857142857
Max-min Ratio: 2.857142857142857
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-57-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -524.0100588927507
  episode_reward_mean: -870.2575534116564
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 577
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.529
    dispatch_time_ms: 7.504
    learner:
      cur_lr: 0.0011678589507937431
      grad_gnorm: 15.01368522644043
      policy_entropy: 41.40787887573242
      policy_loss: -4.857528209686279
      var_gnorm: 26.1997127532959
      vf_explained_var: 0.0
      vf_loss: 6.322441577911377
    num_steps_sampled: 2890000
    num_steps_trained: 2890000
    wait_time_ms: 75.235
  iterations_since_restore: 578
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5029.868035793304
  time_this_iter_s: 8.371226072311401
  time_total_s: 5029.868035793304
  timestamp: 1594861049
  timesteps_since_restore: 2890000
  timesteps_this_iter: 5000
  timesteps_total: 2890000
  training_iteration: 578
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5029 s, 578 iter, 2890000 ts, -870 rew

agent-1: -140.4621246123426
agent-2: -93.47381876399066
agent-3: -35.92519976400539
agent-4: -85.44047011142472
agent-5: -246.43973241754543
Extrinsic Rewards:
7
9
2
6
15
Sum Reward: 39
Avg Reward: 7.8
Min Reward: 2
Max Reward: 15
Gini Coefficient: 0.29743589743589743
20:20 Ratio: 7.5
Max-min Ratio: 7.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-57-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -524.0100588927507
  episode_reward_mean: -867.791735461669
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 578
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.827
    dispatch_time_ms: 8.223
    learner:
      cur_lr: 0.001167526002973318
      grad_gnorm: 22.836164474487305
      policy_entropy: 46.236427307128906
      policy_loss: -5.289399147033691
      var_gnorm: 26.182348251342773
      vf_explained_var: 0.0
      vf_loss: 5.907279014587402
    num_steps_sampled: 2895000
    num_steps_trained: 2895000
    wait_time_ms: 75.708
  iterations_since_restore: 579
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5038.191012382507
  time_this_iter_s: 8.32297658920288
  time_total_s: 5038.191012382507
  timestamp: 1594861057
  timesteps_since_restore: 2895000
  timesteps_this_iter: 5000
  timesteps_total: 2895000
  training_iteration: 579
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5038 s, 579 iter, 2895000 ts, -868 rew

agent-1: -69.64111606769514
agent-2: -66.77513508561204
agent-3: -166.0295080822933
agent-4: -177.42402299765973
agent-5: -104.70934464848807
Extrinsic Rewards:
18
12
8
20
15
Sum Reward: 73
Avg Reward: 14.6
Min Reward: 8
Max Reward: 20
Gini Coefficient: 0.1643835616438356
20:20 Ratio: 2.5
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-57-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -524.0100588927507
  episode_reward_mean: -867.4841277486921
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 579
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.583
    dispatch_time_ms: 7.853
    learner:
      cur_lr: 0.001167193055152893
      grad_gnorm: 14.637130737304688
      policy_entropy: 56.685020446777344
      policy_loss: -5.732575416564941
      var_gnorm: 26.21372413635254
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 5.23539924621582
    num_steps_sampled: 2900000
    num_steps_trained: 2900000
    wait_time_ms: 71.507
  iterations_since_restore: 580
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5046.61940908432
  time_this_iter_s: 8.428396701812744
  time_total_s: 5046.61940908432
  timestamp: 1594861065
  timesteps_since_restore: 2900000
  timesteps_this_iter: 5000
  timesteps_total: 2900000
  training_iteration: 580
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5046 s, 580 iter, 2900000 ts, -867 rew

agent-1: -22.011480488735085
agent-2: -147.1892567523019
agent-3: -174.9805580784503
agent-4: -112.78350678943312
agent-5: -179.00581160451955
Extrinsic Rewards:
3
11
14
10
19
Sum Reward: 57
Avg Reward: 11.4
Min Reward: 3
Max Reward: 19
Gini Coefficient: 0.25263157894736843
20:20 Ratio: 6.333333333333333
Max-min Ratio: 6.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-57-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -524.0100588927507
  episode_reward_mean: -866.6348020248793
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 580
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.988
    dispatch_time_ms: 6.743
    learner:
      cur_lr: 0.0011668599909171462
      grad_gnorm: 16.937034606933594
      policy_entropy: 38.20206832885742
      policy_loss: 4.06793212890625
      var_gnorm: 26.217504501342773
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 10.524553298950195
    num_steps_sampled: 2905000
    num_steps_trained: 2905000
    wait_time_ms: 75.164
  iterations_since_restore: 581
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5054.987504482269
  time_this_iter_s: 8.368095397949219
  time_total_s: 5054.987504482269
  timestamp: 1594861074
  timesteps_since_restore: 2905000
  timesteps_this_iter: 5000
  timesteps_total: 2905000
  training_iteration: 581
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5054 s, 581 iter, 2905000 ts, -867 rew

agent-1: -41.13499982515552
agent-2: -275.3728410783956
agent-3: -495.75840689388156
agent-4: -486.1703717974444
agent-5: -276.09308803450654
Extrinsic Rewards:
4
-41
6
2
-45
Sum Reward: -74
Avg Reward: -14.8
Min Reward: -45
Max Reward: 6
Gini Coefficient: -0.7945945945945946
20:20 Ratio: -0.13333333333333333
Max-min Ratio: -0.13333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-58-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -524.0100588927507
  episode_reward_mean: -874.725285057437
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 581
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.619
    dispatch_time_ms: 6.963
    learner:
      cur_lr: 0.0011665270430967212
      grad_gnorm: 40.0
      policy_entropy: 43.47377014160156
      policy_loss: 18.366104125976562
      var_gnorm: 26.29242706298828
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 13.71461009979248
    num_steps_sampled: 2910000
    num_steps_trained: 2910000
    wait_time_ms: 71.764
  iterations_since_restore: 582
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5063.324973106384
  time_this_iter_s: 8.33746862411499
  time_total_s: 5063.324973106384
  timestamp: 1594861082
  timesteps_since_restore: 2910000
  timesteps_this_iter: 5000
  timesteps_total: 2910000
  training_iteration: 582
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5063 s, 582 iter, 2910000 ts, -875 rew

agent-1: -110.0588424432085
agent-2: -288.2004590552958
agent-3: -201.92960714930666
agent-4: -364.0389275388506
agent-5: -274.9766417670935
Extrinsic Rewards:
2
3
1
19
13
Sum Reward: 38
Avg Reward: 7.6
Min Reward: 1
Max Reward: 19
Gini Coefficient: 0.49473684210526314
20:20 Ratio: 19.0
Max-min Ratio: 19.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-58-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -524.0100588927507
  episode_reward_mean: -879.9589251592639
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 582
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.832
    dispatch_time_ms: 9.375
    learner:
      cur_lr: 0.0011661939788609743
      grad_gnorm: 5.389784336090088
      policy_entropy: 48.48326873779297
      policy_loss: 0.9009137749671936
      var_gnorm: 26.23954200744629
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.6458791494369507
    num_steps_sampled: 2915000
    num_steps_trained: 2915000
    wait_time_ms: 71.848
  iterations_since_restore: 583
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5071.718354701996
  time_this_iter_s: 8.393381595611572
  time_total_s: 5071.718354701996
  timestamp: 1594861091
  timesteps_since_restore: 2915000
  timesteps_this_iter: 5000
  timesteps_total: 2915000
  training_iteration: 583
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5071 s, 583 iter, 2915000 ts, -880 rew

agent-1: -18.02598785975685
agent-2: -187.46338917378424
agent-3: -203.50743401746283
agent-4: -14.403397270326204
agent-5: -218.96671818597775
Extrinsic Rewards:
1
4
10
1
6
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 1
Max Reward: 10
Gini Coefficient: 0.41818181818181815
20:20 Ratio: 10.0
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-58-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -524.0100588927507
  episode_reward_mean: -877.6514603056244
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 583
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.546
    dispatch_time_ms: 7.287
    learner:
      cur_lr: 0.0011658610310405493
      grad_gnorm: 9.666240692138672
      policy_entropy: 45.80424118041992
      policy_loss: -2.9997146129608154
      var_gnorm: 26.224597930908203
      vf_explained_var: 0.0
      vf_loss: 1.7136213779449463
    num_steps_sampled: 2920000
    num_steps_trained: 2920000
    wait_time_ms: 73.185
  iterations_since_restore: 584
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5080.095790863037
  time_this_iter_s: 8.37743616104126
  time_total_s: 5080.095790863037
  timestamp: 1594861099
  timesteps_since_restore: 2920000
  timesteps_this_iter: 5000
  timesteps_total: 2920000
  training_iteration: 584
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5080 s, 584 iter, 2920000 ts, -878 rew

agent-1: -156.94310012932
agent-2: -189.0599023268899
agent-3: -73.60117484233012
agent-4: -120.74468519382141
agent-5: -161.25663722578773
Extrinsic Rewards:
3
14
3
5
13
Sum Reward: 38
Avg Reward: 7.6
Min Reward: 3
Max Reward: 14
Gini Coefficient: 0.3368421052631579
20:20 Ratio: 4.666666666666667
Max-min Ratio: 4.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-58-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -524.0100588927507
  episode_reward_mean: -878.3493966735876
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 584
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.076
    dispatch_time_ms: 7.88
    learner:
      cur_lr: 0.0011655279668048024
      grad_gnorm: 16.818180084228516
      policy_entropy: 56.56208038330078
      policy_loss: -2.0654499530792236
      var_gnorm: 26.196840286254883
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 4.817189693450928
    num_steps_sampled: 2925000
    num_steps_trained: 2925000
    wait_time_ms: 77.703
  iterations_since_restore: 585
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5088.5116856098175
  time_this_iter_s: 8.415894746780396
  time_total_s: 5088.5116856098175
  timestamp: 1594861107
  timesteps_since_restore: 2925000
  timesteps_this_iter: 5000
  timesteps_total: 2925000
  training_iteration: 585
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5088 s, 585 iter, 2925000 ts, -878 rew

agent-1: -108.3411212113243
agent-2: -268.5491486886987
agent-3: -147.0213691254881
agent-4: -60.61360411591628
agent-5: -13.889566749618558
Extrinsic Rewards:
0
13
13
1
2
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 0
Max Reward: 13
Gini Coefficient: 0.5241379310344828
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-58-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -524.0100588927507
  episode_reward_mean: -877.8245055390315
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 585
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.643
    dispatch_time_ms: 6.401
    learner:
      cur_lr: 0.0011651950189843774
      grad_gnorm: 13.74951457977295
      policy_entropy: 59.362483978271484
      policy_loss: 3.260402202606201
      var_gnorm: 26.224557876586914
      vf_explained_var: 0.0
      vf_loss: 4.620612621307373
    num_steps_sampled: 2930000
    num_steps_trained: 2930000
    wait_time_ms: 74.289
  iterations_since_restore: 586
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5096.936700105667
  time_this_iter_s: 8.42501449584961
  time_total_s: 5096.936700105667
  timestamp: 1594861116
  timesteps_since_restore: 2930000
  timesteps_this_iter: 5000
  timesteps_total: 2930000
  training_iteration: 586
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5096 s, 586 iter, 2930000 ts, -878 rew

agent-1: -240.8696644895555
agent-2: -117.53962944875113
agent-3: -55.248346866562095
agent-4: -182.33897689671963
agent-5: -81.19487307485183
Extrinsic Rewards:
7
3
2
6
2
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 2
Max Reward: 7
Gini Coefficient: 0.28
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-58-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -524.0100588927507
  episode_reward_mean: -876.3240479834279
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 586
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.651
    dispatch_time_ms: 5.937
    learner:
      cur_lr: 0.0011648619547486305
      grad_gnorm: 12.236383438110352
      policy_entropy: 41.91188430786133
      policy_loss: 5.083335876464844
      var_gnorm: 26.199871063232422
      vf_explained_var: 0.0
      vf_loss: 9.31945514678955
    num_steps_sampled: 2935000
    num_steps_trained: 2935000
    wait_time_ms: 75.533
  iterations_since_restore: 587
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5105.282479047775
  time_this_iter_s: 8.345778942108154
  time_total_s: 5105.282479047775
  timestamp: 1594861124
  timesteps_since_restore: 2935000
  timesteps_this_iter: 5000
  timesteps_total: 2935000
  training_iteration: 587
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5105 s, 587 iter, 2935000 ts, -876 rew

agent-1: -251.66486109705514
agent-2: -23.483280615853406
agent-3: -154.40019499810057
agent-4: -105.24880817971187
agent-5: -81.94695932626847
Extrinsic Rewards:
11
2
8
7
2
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 2
Max Reward: 11
Gini Coefficient: 0.32
20:20 Ratio: 5.5
Max-min Ratio: 5.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-58-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -524.0100588927507
  episode_reward_mean: -875.9409492266526
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 587
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.759
    dispatch_time_ms: 8.916
    learner:
      cur_lr: 0.0011645290069282055
      grad_gnorm: 22.28106117248535
      policy_entropy: 26.554141998291016
      policy_loss: 2.3829736709594727
      var_gnorm: 26.1876220703125
      vf_explained_var: 0.0
      vf_loss: 13.844406127929688
    num_steps_sampled: 2940000
    num_steps_trained: 2940000
    wait_time_ms: 71.086
  iterations_since_restore: 588
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5113.765170812607
  time_this_iter_s: 8.482691764831543
  time_total_s: 5113.765170812607
  timestamp: 1594861133
  timesteps_since_restore: 2940000
  timesteps_this_iter: 5000
  timesteps_total: 2940000
  training_iteration: 588
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5113 s, 588 iter, 2940000 ts, -876 rew

agent-1: -91.95017853805744
agent-2: -157.33307476009094
agent-3: -260.1729953138147
agent-4: -27.47996020443603
agent-5: -35.17725143704408
Extrinsic Rewards:
4
5
9
2
5
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 2
Max Reward: 9
Gini Coefficient: 0.24
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-59-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -524.0100588927507
  episode_reward_mean: -874.5614591374892
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 588
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.38
    dispatch_time_ms: 6.931
    learner:
      cur_lr: 0.0011641959426924586
      grad_gnorm: 21.635831832885742
      policy_entropy: 41.84653091430664
      policy_loss: 3.3751251697540283
      var_gnorm: 26.170562744140625
      vf_explained_var: 0.0
      vf_loss: 9.156025886535645
    num_steps_sampled: 2945000
    num_steps_trained: 2945000
    wait_time_ms: 74.164
  iterations_since_restore: 589
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5121.972211360931
  time_this_iter_s: 8.207040548324585
  time_total_s: 5121.972211360931
  timestamp: 1594861141
  timesteps_since_restore: 2945000
  timesteps_this_iter: 5000
  timesteps_total: 2945000
  training_iteration: 589
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5121 s, 589 iter, 2945000 ts, -875 rew

agent-1: -47.19061249239601
agent-2: -85.7360432933549
agent-3: -47.03416412968992
agent-4: -212.4029289636675
agent-5: -55.8717368493919
Extrinsic Rewards:
13
10
7
24
14
Sum Reward: 68
Avg Reward: 13.6
Min Reward: 7
Max Reward: 24
Gini Coefficient: 0.2235294117647059
20:20 Ratio: 3.4285714285714284
Max-min Ratio: 3.4285714285714284
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-59-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -872.9677226234686
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 589
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.555
    dispatch_time_ms: 11.256
    learner:
      cur_lr: 0.0011638629948720336
      grad_gnorm: 22.07917594909668
      policy_entropy: 40.856319427490234
      policy_loss: -1.9294729232788086
      var_gnorm: 26.161306381225586
      vf_explained_var: 0.0
      vf_loss: 9.051876068115234
    num_steps_sampled: 2950000
    num_steps_trained: 2950000
    wait_time_ms: 71.352
  iterations_since_restore: 590
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5130.397854566574
  time_this_iter_s: 8.4256432056427
  time_total_s: 5130.397854566574
  timestamp: 1594861149
  timesteps_since_restore: 2950000
  timesteps_this_iter: 5000
  timesteps_total: 2950000
  training_iteration: 590
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5130 s, 590 iter, 2950000 ts, -873 rew

agent-1: -171.48742590975556
agent-2: -66.55894513655191
agent-3: -126.18122064372916
agent-4: -89.98706593418831
agent-5: -72.19693626659442
Extrinsic Rewards:
33
18
19
24
20
Sum Reward: 114
Avg Reward: 22.8
Min Reward: 18
Max Reward: 33
Gini Coefficient: 0.12280701754385964
20:20 Ratio: 1.8333333333333333
Max-min Ratio: 1.8333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-59-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -871.5176672956763
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 590
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.949
    dispatch_time_ms: 7.661
    learner:
      cur_lr: 0.0011635300470516086
      grad_gnorm: 21.4443302154541
      policy_entropy: 51.035194396972656
      policy_loss: -5.864213466644287
      var_gnorm: 26.195255279541016
      vf_explained_var: 0.0
      vf_loss: 6.035757541656494
    num_steps_sampled: 2955000
    num_steps_trained: 2955000
    wait_time_ms: 72.835
  iterations_since_restore: 591
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5138.762526035309
  time_this_iter_s: 8.364671468734741
  time_total_s: 5138.762526035309
  timestamp: 1594861158
  timesteps_since_restore: 2955000
  timesteps_this_iter: 5000
  timesteps_total: 2955000
  training_iteration: 591
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5138 s, 591 iter, 2955000 ts, -872 rew

agent-1: -153.97453746321062
agent-2: -112.82919010506063
agent-3: -136.1276950504541
agent-4: -72.20145611300096
agent-5: -262.0810707625362
Extrinsic Rewards:
4
4
0
5
11
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 0
Max Reward: 11
Gini Coefficient: 0.38333333333333336
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-59-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -871.9276541186919
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 591
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.476
    dispatch_time_ms: 7.091
    learner:
      cur_lr: 0.0011631969828158617
      grad_gnorm: 27.249353408813477
      policy_entropy: 43.59858322143555
      policy_loss: -8.651317596435547
      var_gnorm: 26.295255661010742
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 4.929056167602539
    num_steps_sampled: 2960000
    num_steps_trained: 2960000
    wait_time_ms: 74.29
  iterations_since_restore: 592
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5147.152631044388
  time_this_iter_s: 8.39010500907898
  time_total_s: 5147.152631044388
  timestamp: 1594861166
  timesteps_since_restore: 2960000
  timesteps_this_iter: 5000
  timesteps_total: 2960000
  training_iteration: 592
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5147 s, 592 iter, 2960000 ts, -872 rew

agent-1: -178.91406479862533
agent-2: -119.2536080439625
agent-3: -127.82606229614633
agent-4: -146.40714806066538
agent-5: -215.65380501625575
Extrinsic Rewards:
9
0
5
11
7
Sum Reward: 32
Avg Reward: 6.4
Min Reward: 0
Max Reward: 11
Gini Coefficient: 0.325
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-59-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -871.3862505413261
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 592
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.444
    dispatch_time_ms: 5.62
    learner:
      cur_lr: 0.0011628640349954367
      grad_gnorm: 9.87951946258545
      policy_entropy: 34.87163162231445
      policy_loss: -2.329974889755249
      var_gnorm: 26.230239868164062
      vf_explained_var: 0.0
      vf_loss: 7.330924034118652
    num_steps_sampled: 2965000
    num_steps_trained: 2965000
    wait_time_ms: 74.324
  iterations_since_restore: 593
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5155.467333316803
  time_this_iter_s: 8.314702272415161
  time_total_s: 5155.467333316803
  timestamp: 1594861175
  timesteps_since_restore: 2965000
  timesteps_this_iter: 5000
  timesteps_total: 2965000
  training_iteration: 593
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5155 s, 593 iter, 2965000 ts, -871 rew

agent-1: -150.4754222938048
agent-2: -245.91297282263469
agent-3: -151.34432400081997
agent-4: -192.5378156551725
agent-5: -70.15696901778892
Extrinsic Rewards:
0
7
3
4
1
Sum Reward: 15
Avg Reward: 3.0
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.4533333333333333
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-59-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -873.3035244287258
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 593
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.483
    dispatch_time_ms: 5.521
    learner:
      cur_lr: 0.0011625309707596898
      grad_gnorm: 8.800076484680176
      policy_entropy: 47.03626251220703
      policy_loss: 2.9392011165618896
      var_gnorm: 26.2712459564209
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.440078854560852
    num_steps_sampled: 2970000
    num_steps_trained: 2970000
    wait_time_ms: 78.978
  iterations_since_restore: 594
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5163.842750072479
  time_this_iter_s: 8.37541675567627
  time_total_s: 5163.842750072479
  timestamp: 1594861183
  timesteps_since_restore: 2970000
  timesteps_this_iter: 5000
  timesteps_total: 2970000
  training_iteration: 594
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5163 s, 594 iter, 2970000 ts, -873 rew

agent-1: -149.34457799380175
agent-2: -101.86516549201065
agent-3: -144.10985837704288
agent-4: -103.56040953365635
agent-5: -126.66633880083212
Extrinsic Rewards:
16
19
23
10
16
Sum Reward: 84
Avg Reward: 16.8
Min Reward: 10
Max Reward: 23
Gini Coefficient: 0.1380952380952381
20:20 Ratio: 2.3
Max-min Ratio: 2.3
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-59-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -872.7740085806784
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 594
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.016
    dispatch_time_ms: 6.796
    learner:
      cur_lr: 0.0011621980229392648
      grad_gnorm: 12.4252290725708
      policy_entropy: 41.369625091552734
      policy_loss: -1.5670713186264038
      var_gnorm: 26.231449127197266
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 4.132603645324707
    num_steps_sampled: 2975000
    num_steps_trained: 2975000
    wait_time_ms: 73.605
  iterations_since_restore: 595
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5172.2497527599335
  time_this_iter_s: 8.407002687454224
  time_total_s: 5172.2497527599335
  timestamp: 1594861191
  timesteps_since_restore: 2975000
  timesteps_this_iter: 5000
  timesteps_total: 2975000
  training_iteration: 595
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5172 s, 595 iter, 2975000 ts, -873 rew

agent-1: -245.63205952391698
agent-2: -73.70910308330315
agent-3: -76.1188127505055
agent-4: -109.2153009992197
agent-5: -149.47373881683654
Extrinsic Rewards:
14
3
1
5
3
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 1
Max Reward: 14
Gini Coefficient: 0.4307692307692308
20:20 Ratio: 14.0
Max-min Ratio: 14.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-00-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -871.5352863715984
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 595
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.793
    dispatch_time_ms: 7.771
    learner:
      cur_lr: 0.001161864958703518
      grad_gnorm: 6.5975022315979
      policy_entropy: 38.24089813232422
      policy_loss: -1.8105080127716064
      var_gnorm: 26.231340408325195
      vf_explained_var: 0.0
      vf_loss: 2.7614312171936035
    num_steps_sampled: 2980000
    num_steps_trained: 2980000
    wait_time_ms: 75.19
  iterations_since_restore: 596
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5180.619916200638
  time_this_iter_s: 8.370163440704346
  time_total_s: 5180.619916200638
  timestamp: 1594861200
  timesteps_since_restore: 2980000
  timesteps_this_iter: 5000
  timesteps_total: 2980000
  training_iteration: 596
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5180 s, 596 iter, 2980000 ts, -872 rew

agent-1: -178.55817376152658
agent-2: -102.49170366282996
agent-3: -66.56705250458724
agent-4: -165.31387114401107
agent-5: -177.62324815366557
Extrinsic Rewards:
12
4
8
9
5
Sum Reward: 38
Avg Reward: 7.6
Min Reward: 4
Max Reward: 12
Gini Coefficient: 0.21052631578947367
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-00-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -871.5358537145277
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 596
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.914
    dispatch_time_ms: 7.96
    learner:
      cur_lr: 0.0011615320108830929
      grad_gnorm: 8.892648696899414
      policy_entropy: 46.716094970703125
      policy_loss: -3.184805154800415
      var_gnorm: 26.22576332092285
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.8173917531967163
    num_steps_sampled: 2985000
    num_steps_trained: 2985000
    wait_time_ms: 72.368
  iterations_since_restore: 597
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5188.921511411667
  time_this_iter_s: 8.301595211029053
  time_total_s: 5188.921511411667
  timestamp: 1594861208
  timesteps_since_restore: 2985000
  timesteps_this_iter: 5000
  timesteps_total: 2985000
  training_iteration: 597
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5188 s, 597 iter, 2985000 ts, -872 rew

agent-1: -117.39904993443398
agent-2: -199.0584995741544
agent-3: -134.68878518862428
agent-4: -46.51778271314471
agent-5: -167.69483999224929
Extrinsic Rewards:
16
9
6
9
6
Sum Reward: 46
Avg Reward: 9.2
Min Reward: 6
Max Reward: 16
Gini Coefficient: 0.2
20:20 Ratio: 2.6666666666666665
Max-min Ratio: 2.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-00-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -871.3227937269487
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 597
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.898
    dispatch_time_ms: 7.694
    learner:
      cur_lr: 0.001161198946647346
      grad_gnorm: 40.0
      policy_entropy: 54.23535919189453
      policy_loss: 31.894399642944336
      var_gnorm: 26.239349365234375
      vf_explained_var: 0.0
      vf_loss: 17.669090270996094
    num_steps_sampled: 2990000
    num_steps_trained: 2990000
    wait_time_ms: 73.581
  iterations_since_restore: 598
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5197.283214569092
  time_this_iter_s: 8.361703157424927
  time_total_s: 5197.283214569092
  timestamp: 1594861217
  timesteps_since_restore: 2990000
  timesteps_this_iter: 5000
  timesteps_total: 2990000
  training_iteration: 598
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5197 s, 598 iter, 2990000 ts, -871 rew

agent-1: -144.54158324935008
agent-2: -119.48379662311801
agent-3: -201.03434935317026
agent-4: -94.43555050969344
agent-5: -169.5280748282003
Extrinsic Rewards:
4
4
7
6
3
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 3
Max Reward: 7
Gini Coefficient: 0.16666666666666666
20:20 Ratio: 2.3333333333333335
Max-min Ratio: 2.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-00-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -871.8053609046501
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 598
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.01
    dispatch_time_ms: 10.269
    learner:
      cur_lr: 0.001160865998826921
      grad_gnorm: 12.276329040527344
      policy_entropy: 55.56074142456055
      policy_loss: 2.9040985107421875
      var_gnorm: 26.209867477416992
      vf_explained_var: 0.0
      vf_loss: 10.631373405456543
    num_steps_sampled: 2995000
    num_steps_trained: 2995000
    wait_time_ms: 69.56
  iterations_since_restore: 599
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5205.720298290253
  time_this_iter_s: 8.437083721160889
  time_total_s: 5205.720298290253
  timestamp: 1594861225
  timesteps_since_restore: 2995000
  timesteps_this_iter: 5000
  timesteps_total: 2995000
  training_iteration: 599
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5205 s, 599 iter, 2995000 ts, -872 rew

agent-1: -183.71615282817427
agent-2: -222.58875210197422
agent-3: -51.80522960673766
agent-4: -94.12898971119742
agent-5: -14.196943041287298
Extrinsic Rewards:
8
11
11
16
2
Sum Reward: 48
Avg Reward: 9.6
Min Reward: 2
Max Reward: 16
Gini Coefficient: 0.25833333333333336
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-00-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -872.106740699688
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 599
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.59
    dispatch_time_ms: 8.012
    learner:
      cur_lr: 0.001160533051006496
      grad_gnorm: 40.0
      policy_entropy: 56.69383239746094
      policy_loss: -15.434346199035645
      var_gnorm: 26.242876052856445
      vf_explained_var: 0.0
      vf_loss: 8.072980880737305
    num_steps_sampled: 3000000
    num_steps_trained: 3000000
    wait_time_ms: 72.257
  iterations_since_restore: 600
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5213.977655649185
  time_this_iter_s: 8.257357358932495
  time_total_s: 5213.977655649185
  timestamp: 1594861233
  timesteps_since_restore: 3000000
  timesteps_this_iter: 5000
  timesteps_total: 3000000
  training_iteration: 600
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5213 s, 600 iter, 3000000 ts, -872 rew

agent-1: -87.42221517997194
agent-2: -139.85921977351114
agent-3: -237.50494507242274
agent-4: -195.64628749405136
agent-5: -146.2680846897336
Extrinsic Rewards:
3
0
7
5
5
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.32
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-00-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -872.661651429591
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 600
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.901
    dispatch_time_ms: 8.013
    learner:
      cur_lr: 0.001160199986770749
      grad_gnorm: 11.779196739196777
      policy_entropy: 58.77237319946289
      policy_loss: 3.4786040782928467
      var_gnorm: 26.239835739135742
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 6.695075988769531
    num_steps_sampled: 3005000
    num_steps_trained: 3005000
    wait_time_ms: 72.542
  iterations_since_restore: 601
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5222.260891199112
  time_this_iter_s: 8.283235549926758
  time_total_s: 5222.260891199112
  timestamp: 1594861242
  timesteps_since_restore: 3005000
  timesteps_this_iter: 5000
  timesteps_total: 3005000
  training_iteration: 601
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5222 s, 601 iter, 3005000 ts, -873 rew

agent-1: -138.0227540300906
agent-2: -136.32005572736793
agent-3: -98.68044554634884
agent-4: -187.96135219417744
agent-5: -183.38648682688634
Extrinsic Rewards:
5
2
2
5
6
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 2
Max Reward: 6
Gini Coefficient: 0.22
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-00-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -874.5400287845924
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 601
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.947
    dispatch_time_ms: 9.068
    learner:
      cur_lr: 0.001159867038950324
      grad_gnorm: 21.88660430908203
      policy_entropy: 52.50864028930664
      policy_loss: 7.0888237953186035
      var_gnorm: 26.236066818237305
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 6.086311340332031
    num_steps_sampled: 3010000
    num_steps_trained: 3010000
    wait_time_ms: 71.405
  iterations_since_restore: 602
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5230.604798316956
  time_this_iter_s: 8.343907117843628
  time_total_s: 5230.604798316956
  timestamp: 1594861250
  timesteps_since_restore: 3010000
  timesteps_this_iter: 5000
  timesteps_total: 3010000
  training_iteration: 602
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5230 s, 602 iter, 3010000 ts, -875 rew

agent-1: -209.37537061885115
agent-2: -230.4874336362826
agent-3: -82.36886906651482
agent-4: -80.1933941030585
agent-5: -37.82994785960119
Extrinsic Rewards:
9
8
2
3
4
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 2
Max Reward: 9
Gini Coefficient: 0.2923076923076923
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-00-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -874.6968028088446
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 602
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.722
    dispatch_time_ms: 6.38
    learner:
      cur_lr: 0.0011595339747145772
      grad_gnorm: 10.652989387512207
      policy_entropy: 55.14501953125
      policy_loss: 0.3844970762729645
      var_gnorm: 26.22089195251465
      vf_explained_var: 0.0
      vf_loss: 4.5959086418151855
    num_steps_sampled: 3015000
    num_steps_trained: 3015000
    wait_time_ms: 75.74
  iterations_since_restore: 603
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5239.393061637878
  time_this_iter_s: 8.788263320922852
  time_total_s: 5239.393061637878
  timestamp: 1594861259
  timesteps_since_restore: 3015000
  timesteps_this_iter: 5000
  timesteps_total: 3015000
  training_iteration: 603
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5239 s, 603 iter, 3015000 ts, -875 rew

agent-1: -79.82550599898487
agent-2: -83.07458882241713
agent-3: -248.61160534690586
agent-4: -178.95582772433917
agent-5: -78.28784593372727
Extrinsic Rewards:
2
1
8
4
2
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.3764705882352941
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-01-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -874.1623134668857
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 603
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.708
    dispatch_time_ms: 7.314
    learner:
      cur_lr: 0.0011592010268941522
      grad_gnorm: 22.125268936157227
      policy_entropy: 51.59025955200195
      policy_loss: 6.162319660186768
      var_gnorm: 26.226163864135742
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.788685321807861
    num_steps_sampled: 3020000
    num_steps_trained: 3020000
    wait_time_ms: 78.27
  iterations_since_restore: 604
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5247.748644828796
  time_this_iter_s: 8.355583190917969
  time_total_s: 5247.748644828796
  timestamp: 1594861267
  timesteps_since_restore: 3020000
  timesteps_this_iter: 5000
  timesteps_total: 3020000
  training_iteration: 604
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5247 s, 604 iter, 3020000 ts, -874 rew

agent-1: -166.67326661220926
agent-2: -214.43281068864226
agent-3: -5.5282649198019485
agent-4: -96.7919755216207
agent-5: -168.78772447759542
Extrinsic Rewards:
12
13
1
2
13
Sum Reward: 41
Avg Reward: 8.2
Min Reward: 1
Max Reward: 13
Gini Coefficient: 0.34146341463414637
20:20 Ratio: 13.0
Max-min Ratio: 13.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-01-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -872.833204922325
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 604
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.582
    dispatch_time_ms: 8.182
    learner:
      cur_lr: 0.0011588679626584053
      grad_gnorm: 22.635278701782227
      policy_entropy: 52.297210693359375
      policy_loss: 1.2047123908996582
      var_gnorm: 26.21953582763672
      vf_explained_var: 0.0
      vf_loss: 4.92792272567749
    num_steps_sampled: 3025000
    num_steps_trained: 3025000
    wait_time_ms: 70.345
  iterations_since_restore: 605
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5256.138383150101
  time_this_iter_s: 8.389738321304321
  time_total_s: 5256.138383150101
  timestamp: 1594861276
  timesteps_since_restore: 3025000
  timesteps_this_iter: 5000
  timesteps_total: 3025000
  training_iteration: 605
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5256 s, 605 iter, 3025000 ts, -873 rew

agent-1: -241.7670756968039
agent-2: -121.89585935338546
agent-3: -135.25442333252442
agent-4: -144.3743740459222
agent-5: -117.08430757651372
Extrinsic Rewards:
9
0
9
4
9
Sum Reward: 31
Avg Reward: 6.2
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.2967741935483871
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-01-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -873.8820482183561
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 605
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.483
    dispatch_time_ms: 7.884
    learner:
      cur_lr: 0.0011585350148379803
      grad_gnorm: 39.999996185302734
      policy_entropy: 40.42659378051758
      policy_loss: 32.89958953857422
      var_gnorm: 26.270862579345703
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 39.715965270996094
    num_steps_sampled: 3030000
    num_steps_trained: 3030000
    wait_time_ms: 73.14
  iterations_since_restore: 606
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5264.517596721649
  time_this_iter_s: 8.379213571548462
  time_total_s: 5264.517596721649
  timestamp: 1594861284
  timesteps_since_restore: 3030000
  timesteps_this_iter: 5000
  timesteps_total: 3030000
  training_iteration: 606
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5264 s, 606 iter, 3030000 ts, -874 rew

agent-1: -71.17315520140644
agent-2: -177.61306623265185
agent-3: -51.8824421182695
agent-4: -144.3268230491498
agent-5: -239.1032019975183
Extrinsic Rewards:
1
4
1
4
7
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 1
Max Reward: 7
Gini Coefficient: 0.35294117647058826
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-01-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -873.5305342453738
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 606
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.582
    dispatch_time_ms: 6.192
    learner:
      cur_lr: 0.0011582019506022334
      grad_gnorm: 10.171551704406738
      policy_entropy: 44.416717529296875
      policy_loss: -3.76658296585083
      var_gnorm: 26.23019790649414
      vf_explained_var: 0.0
      vf_loss: 1.0183348655700684
    num_steps_sampled: 3035000
    num_steps_trained: 3035000
    wait_time_ms: 72.904
  iterations_since_restore: 607
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5272.8620018959045
  time_this_iter_s: 8.344405174255371
  time_total_s: 5272.8620018959045
  timestamp: 1594861293
  timesteps_since_restore: 3035000
  timesteps_this_iter: 5000
  timesteps_total: 3035000
  training_iteration: 607
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5272 s, 607 iter, 3035000 ts, -874 rew

agent-1: -182.89261310469587
agent-2: -109.56638246928085
agent-3: -149.73226609653182
agent-4: -163.70555707891802
agent-5: -123.92323604021722
Extrinsic Rewards:
6
5
7
5
8
Sum Reward: 31
Avg Reward: 6.2
Min Reward: 5
Max Reward: 8
Gini Coefficient: 0.1032258064516129
20:20 Ratio: 1.6
Max-min Ratio: 1.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-01-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -874.4744640552447
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 607
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.528
    dispatch_time_ms: 7.988
    learner:
      cur_lr: 0.0011578690027818084
      grad_gnorm: 34.519161224365234
      policy_entropy: 40.48710632324219
      policy_loss: -2.966872215270996
      var_gnorm: 26.261579513549805
      vf_explained_var: 0.0
      vf_loss: 7.055783748626709
    num_steps_sampled: 3040000
    num_steps_trained: 3040000
    wait_time_ms: 71.924
  iterations_since_restore: 608
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5281.183135271072
  time_this_iter_s: 8.321133375167847
  time_total_s: 5281.183135271072
  timestamp: 1594861301
  timesteps_since_restore: 3040000
  timesteps_this_iter: 5000
  timesteps_total: 3040000
  training_iteration: 608
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5281 s, 608 iter, 3040000 ts, -874 rew

agent-1: -213.07582359321827
agent-2: -150.2465160340175
agent-3: -100.28618111877687
agent-4: -191.61753104744554
agent-5: -82.56362950865082
Extrinsic Rewards:
9
10
0
11
13
Sum Reward: 43
Avg Reward: 8.6
Min Reward: 0
Max Reward: 13
Gini Coefficient: 0.26046511627906976
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-01-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -875.3458214216174
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 608
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.363
    dispatch_time_ms: 11.084
    learner:
      cur_lr: 0.0011575360549613833
      grad_gnorm: 18.969850540161133
      policy_entropy: 42.73750305175781
      policy_loss: 6.725423336029053
      var_gnorm: 26.21219825744629
      vf_explained_var: 0.0
      vf_loss: 4.6366777420043945
    num_steps_sampled: 3045000
    num_steps_trained: 3045000
    wait_time_ms: 70.823
  iterations_since_restore: 609
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5289.510903835297
  time_this_iter_s: 8.327768564224243
  time_total_s: 5289.510903835297
  timestamp: 1594861309
  timesteps_since_restore: 3045000
  timesteps_this_iter: 5000
  timesteps_total: 3045000
  training_iteration: 609
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5289 s, 609 iter, 3045000 ts, -875 rew

agent-1: -22.342795811567164
agent-2: -205.24146516828836
agent-3: -213.15623164007846
agent-4: -127.63169303823568
agent-5: -207.05208607065163
Extrinsic Rewards:
2
7
8
0
5
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.38181818181818183
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-01-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -876.48751673869
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 609
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.652
    dispatch_time_ms: 9.885
    learner:
      cur_lr: 0.0011572029907256365
      grad_gnorm: 37.519676208496094
      policy_entropy: 32.77542495727539
      policy_loss: 7.837385654449463
      var_gnorm: 26.24871826171875
      vf_explained_var: 0.0
      vf_loss: 15.605332374572754
    num_steps_sampled: 3050000
    num_steps_trained: 3050000
    wait_time_ms: 69.41
  iterations_since_restore: 610
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5297.999948501587
  time_this_iter_s: 8.489044666290283
  time_total_s: 5297.999948501587
  timestamp: 1594861318
  timesteps_since_restore: 3050000
  timesteps_this_iter: 5000
  timesteps_total: 3050000
  training_iteration: 610
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5297 s, 610 iter, 3050000 ts, -876 rew

agent-1: -58.69081515597237
agent-2: -80.54426502791422
agent-3: -190.61137832014413
agent-4: -148.92993082048335
agent-5: -116.62945510780592
Extrinsic Rewards:
13
9
20
12
25
Sum Reward: 79
Avg Reward: 15.8
Min Reward: 9
Max Reward: 25
Gini Coefficient: 0.20253164556962025
20:20 Ratio: 2.7777777777777777
Max-min Ratio: 2.7777777777777777
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-02-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -876.895668205998
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 610
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.58
    dispatch_time_ms: 8.783
    learner:
      cur_lr: 0.0011568700429052114
      grad_gnorm: 18.793697357177734
      policy_entropy: 50.72875213623047
      policy_loss: -4.389894485473633
      var_gnorm: 26.204769134521484
      vf_explained_var: 0.0
      vf_loss: 6.1329026222229
    num_steps_sampled: 3055000
    num_steps_trained: 3055000
    wait_time_ms: 72.873
  iterations_since_restore: 611
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5306.26940703392
  time_this_iter_s: 8.269458532333374
  time_total_s: 5306.26940703392
  timestamp: 1594861326
  timesteps_since_restore: 3055000
  timesteps_this_iter: 5000
  timesteps_total: 3055000
  training_iteration: 611
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5306 s, 611 iter, 3055000 ts, -877 rew

agent-1: -99.05530454340494
agent-2: -145.18226587218697
agent-3: -154.29560967328837
agent-4: -184.40541086997192
agent-5: -37.59429090099904
Extrinsic Rewards:
9
15
16
26
7
Sum Reward: 73
Avg Reward: 14.6
Min Reward: 7
Max Reward: 26
Gini Coefficient: 0.2465753424657534
20:20 Ratio: 3.7142857142857144
Max-min Ratio: 3.7142857142857144
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-02-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -876.4158311414453
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 611
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.69
    dispatch_time_ms: 7.495
    learner:
      cur_lr: 0.0011565369786694646
      grad_gnorm: 40.00000762939453
      policy_entropy: 37.128902435302734
      policy_loss: 40.62711715698242
      var_gnorm: 26.216934204101562
      vf_explained_var: 0.0
      vf_loss: 54.66903305053711
    num_steps_sampled: 3060000
    num_steps_trained: 3060000
    wait_time_ms: 72.539
  iterations_since_restore: 612
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5314.730352640152
  time_this_iter_s: 8.46094560623169
  time_total_s: 5314.730352640152
  timestamp: 1594861335
  timesteps_since_restore: 3060000
  timesteps_this_iter: 5000
  timesteps_total: 3060000
  training_iteration: 612
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5314 s, 612 iter, 3060000 ts, -876 rew

agent-1: -200.88083441049906
agent-2: -164.7906123122903
agent-3: -75.1959101585759
agent-4: -106.37006607010254
agent-5: -74.29783513341216
Extrinsic Rewards:
8
17
5
8
12
Sum Reward: 50
Avg Reward: 10.0
Min Reward: 5
Max Reward: 17
Gini Coefficient: 0.224
20:20 Ratio: 3.4
Max-min Ratio: 3.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-02-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -876.6209292672734
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 612
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.073
    dispatch_time_ms: 8.815
    learner:
      cur_lr: 0.0011562040308490396
      grad_gnorm: 9.73231029510498
      policy_entropy: 46.5986328125
      policy_loss: 1.7557029724121094
      var_gnorm: 26.215063095092773
      vf_explained_var: 0.0
      vf_loss: 5.510110855102539
    num_steps_sampled: 3065000
    num_steps_trained: 3065000
    wait_time_ms: 73.27
  iterations_since_restore: 613
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5323.073084592819
  time_this_iter_s: 8.342731952667236
  time_total_s: 5323.073084592819
  timestamp: 1594861343
  timesteps_since_restore: 3065000
  timesteps_this_iter: 5000
  timesteps_total: 3065000
  training_iteration: 613
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5323 s, 613 iter, 3065000 ts, -877 rew

agent-1: -149.4596069726862
agent-2: -199.63415521242445
agent-3: -110.06164176650121
agent-4: -16.953545299565803
agent-5: -208.8736833001553
Extrinsic Rewards:
4
6
4
1
9
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.3
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-02-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -863.2532752072783
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 613
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.872
    dispatch_time_ms: 6.492
    learner:
      cur_lr: 0.0011558709666132927
      grad_gnorm: 40.0
      policy_entropy: 48.529029846191406
      policy_loss: 25.304964065551758
      var_gnorm: 26.23124885559082
      vf_explained_var: 0.0
      vf_loss: 20.340356826782227
    num_steps_sampled: 3070000
    num_steps_trained: 3070000
    wait_time_ms: 73.14
  iterations_since_restore: 614
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5331.44836306572
  time_this_iter_s: 8.37527847290039
  time_total_s: 5331.44836306572
  timestamp: 1594861351
  timesteps_since_restore: 3070000
  timesteps_this_iter: 5000
  timesteps_total: 3070000
  training_iteration: 614
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5331 s, 614 iter, 3070000 ts, -863 rew

agent-1: -162.4645046023266
agent-2: -90.32822813231937
agent-3: -122.70830182091386
agent-4: -105.64210584094819
agent-5: -196.89067091544393
Extrinsic Rewards:
9
4
8
7
13
Sum Reward: 41
Avg Reward: 8.2
Min Reward: 4
Max Reward: 13
Gini Coefficient: 0.1951219512195122
20:20 Ratio: 3.25
Max-min Ratio: 3.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-02-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -849.6807427367646
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 614
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.642
    dispatch_time_ms: 6.99
    learner:
      cur_lr: 0.0011555380187928677
      grad_gnorm: 8.501667976379395
      policy_entropy: 40.795963287353516
      policy_loss: -2.944209098815918
      var_gnorm: 26.22638511657715
      vf_explained_var: 0.0
      vf_loss: 4.834144115447998
    num_steps_sampled: 3075000
    num_steps_trained: 3075000
    wait_time_ms: 79.208
  iterations_since_restore: 615
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5339.862673282623
  time_this_iter_s: 8.414310216903687
  time_total_s: 5339.862673282623
  timestamp: 1594861360
  timesteps_since_restore: 3075000
  timesteps_this_iter: 5000
  timesteps_total: 3075000
  training_iteration: 615
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5339 s, 615 iter, 3075000 ts, -850 rew

agent-1: -216.1829688156137
agent-2: -125.21481233787581
agent-3: -174.57531684966702
agent-4: -159.7385673479215
agent-5: -125.31555416045113
Extrinsic Rewards:
5
0
5
6
7
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.2608695652173913
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-02-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -838.8130401774036
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 615
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.639
    dispatch_time_ms: 6.681
    learner:
      cur_lr: 0.0011552049545571208
      grad_gnorm: 19.498565673828125
      policy_entropy: 49.36518859863281
      policy_loss: 2.320814609527588
      var_gnorm: 26.272735595703125
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.103476524353027
    num_steps_sampled: 3080000
    num_steps_trained: 3080000
    wait_time_ms: 74.569
  iterations_since_restore: 616
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5348.160226345062
  time_this_iter_s: 8.297553062438965
  time_total_s: 5348.160226345062
  timestamp: 1594861368
  timesteps_since_restore: 3080000
  timesteps_this_iter: 5000
  timesteps_total: 3080000
  training_iteration: 616
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5348 s, 616 iter, 3080000 ts, -839 rew

agent-1: -207.19774260666856
agent-2: -167.30685820994393
agent-3: -178.5578463436337
agent-4: -129.2299426912438
agent-5: -17.81407415667266
Extrinsic Rewards:
6
7
8
5
1
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.23703703703703705
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-02-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -827.2565229129742
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 616
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.681
    dispatch_time_ms: 6.948
    learner:
      cur_lr: 0.0011548720067366958
      grad_gnorm: 20.34371566772461
      policy_entropy: 54.5472526550293
      policy_loss: -1.3641505241394043
      var_gnorm: 26.22335433959961
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 9.316252708435059
    num_steps_sampled: 3085000
    num_steps_trained: 3085000
    wait_time_ms: 71.888
  iterations_since_restore: 617
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5356.557797431946
  time_this_iter_s: 8.397571086883545
  time_total_s: 5356.557797431946
  timestamp: 1594861377
  timesteps_since_restore: 3085000
  timesteps_this_iter: 5000
  timesteps_total: 3085000
  training_iteration: 617
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5356 s, 617 iter, 3085000 ts, -827 rew

agent-1: -101.66946451856123
agent-2: -135.01002544427672
agent-3: -160.31884726542344
agent-4: -81.83708734119992
agent-5: -254.98515637286687
Extrinsic Rewards:
5
0
9
3
7
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.36666666666666664
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-03-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -820.3286347809978
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 617
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.597
    dispatch_time_ms: 9.821
    learner:
      cur_lr: 0.001154538942500949
      grad_gnorm: 17.835590362548828
      policy_entropy: 42.01755905151367
      policy_loss: -5.347805500030518
      var_gnorm: 26.29132080078125
      vf_explained_var: 0.0
      vf_loss: 9.493629455566406
    num_steps_sampled: 3090000
    num_steps_trained: 3090000
    wait_time_ms: 70.64
  iterations_since_restore: 618
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5364.926911354065
  time_this_iter_s: 8.36911392211914
  time_total_s: 5364.926911354065
  timestamp: 1594861385
  timesteps_since_restore: 3090000
  timesteps_this_iter: 5000
  timesteps_total: 3090000
  training_iteration: 618
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5364 s, 618 iter, 3090000 ts, -820 rew

agent-1: -172.13635537342824
agent-2: -230.5613816649886
agent-3: -137.41081162222528
agent-4: -20.164279492272097
agent-5: -209.67524854692033
Extrinsic Rewards:
9
4
0
1
6
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.46
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-03-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -810.8788747834178
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 618
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.502
    dispatch_time_ms: 8.553
    learner:
      cur_lr: 0.0011542059946805239
      grad_gnorm: 7.381833076477051
      policy_entropy: 43.17610168457031
      policy_loss: -1.3282477855682373
      var_gnorm: 26.235483169555664
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.7109649181365967
    num_steps_sampled: 3095000
    num_steps_trained: 3095000
    wait_time_ms: 72.302
  iterations_since_restore: 619
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5373.219873428345
  time_this_iter_s: 8.292962074279785
  time_total_s: 5373.219873428345
  timestamp: 1594861393
  timesteps_since_restore: 3095000
  timesteps_this_iter: 5000
  timesteps_total: 3095000
  training_iteration: 619
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5373 s, 619 iter, 3095000 ts, -811 rew

agent-1: -156.89294157409154
agent-2: -51.59783559591555
agent-3: -77.85613796077038
agent-4: -158.33115660434484
agent-5: -167.22645871108963
Extrinsic Rewards:
19
13
13
14
16
Sum Reward: 75
Avg Reward: 15.0
Min Reward: 13
Max Reward: 19
Gini Coefficient: 0.08
20:20 Ratio: 1.4615384615384615
Max-min Ratio: 1.4615384615384615
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-03-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -795.4291655484288
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 619
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.864
    dispatch_time_ms: 6.693
    learner:
      cur_lr: 0.0011538730468600988
      grad_gnorm: 6.195815563201904
      policy_entropy: 43.614559173583984
      policy_loss: -0.9076218008995056
      var_gnorm: 26.23839569091797
      vf_explained_var: 0.0
      vf_loss: 3.700976610183716
    num_steps_sampled: 3100000
    num_steps_trained: 3100000
    wait_time_ms: 73.52
  iterations_since_restore: 620
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5381.612874031067
  time_this_iter_s: 8.393000602722168
  time_total_s: 5381.612874031067
  timestamp: 1594861402
  timesteps_since_restore: 3100000
  timesteps_this_iter: 5000
  timesteps_total: 3100000
  training_iteration: 620
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5381 s, 620 iter, 3100000 ts, -795 rew

agent-1: -149.2656567470638
agent-2: -181.14613727667984
agent-3: -178.49674168835668
agent-4: -169.40360996659754
agent-5: -27.851790458927784
Extrinsic Rewards:
8
9
12
1
2
Sum Reward: 32
Avg Reward: 6.4
Min Reward: 1
Max Reward: 12
Gini Coefficient: 0.3625
20:20 Ratio: 12.0
Max-min Ratio: 12.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-03-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -783.9249818506057
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 620
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.333
    dispatch_time_ms: 7.025
    learner:
      cur_lr: 0.001153539982624352
      grad_gnorm: 34.7235221862793
      policy_entropy: 42.009456634521484
      policy_loss: 8.239840507507324
      var_gnorm: 26.190568923950195
      vf_explained_var: 0.0
      vf_loss: 14.082037925720215
    num_steps_sampled: 3105000
    num_steps_trained: 3105000
    wait_time_ms: 73.541
  iterations_since_restore: 621
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5389.8602340221405
  time_this_iter_s: 8.247359991073608
  time_total_s: 5389.8602340221405
  timestamp: 1594861410
  timesteps_since_restore: 3105000
  timesteps_this_iter: 5000
  timesteps_total: 3105000
  training_iteration: 621
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5389 s, 621 iter, 3105000 ts, -784 rew

agent-1: -98.0590447791284
agent-2: -106.53073640086129
agent-3: -85.14679957636422
agent-4: -137.02987756900566
agent-5: -91.73546531838792
Extrinsic Rewards:
14
20
20
27
21
Sum Reward: 102
Avg Reward: 20.4
Min Reward: 14
Max Reward: 27
Gini Coefficient: 0.10588235294117647
20:20 Ratio: 1.9285714285714286
Max-min Ratio: 1.9285714285714286
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-03-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -782.3084123725885
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 621
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.804
    dispatch_time_ms: 7.978
    learner:
      cur_lr: 0.001153207034803927
      grad_gnorm: 23.15884780883789
      policy_entropy: 57.34519958496094
      policy_loss: -9.59048843383789
      var_gnorm: 26.206871032714844
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 4.008121967315674
    num_steps_sampled: 3110000
    num_steps_trained: 3110000
    wait_time_ms: 72.033
  iterations_since_restore: 622
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5398.176023483276
  time_this_iter_s: 8.315789461135864
  time_total_s: 5398.176023483276
  timestamp: 1594861418
  timesteps_since_restore: 3110000
  timesteps_this_iter: 5000
  timesteps_total: 3110000
  training_iteration: 622
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5398 s, 622 iter, 3110000 ts, -782 rew

agent-1: -77.1289151967566
agent-2: -132.00813013420546
agent-3: -158.42130216472557
agent-4: -169.41550537823656
agent-5: -55.73930386681529
Extrinsic Rewards:
19
11
21
18
13
Sum Reward: 82
Avg Reward: 16.4
Min Reward: 11
Max Reward: 21
Gini Coefficient: 0.12682926829268293
20:20 Ratio: 1.9090909090909092
Max-min Ratio: 1.9090909090909092
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-03-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -768.1434075734693
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 622
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.793
    dispatch_time_ms: 6.442
    learner:
      cur_lr: 0.00115287397056818
      grad_gnorm: 11.29811954498291
      policy_entropy: 61.24188995361328
      policy_loss: -0.6791649460792542
      var_gnorm: 26.22562026977539
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.153623104095459
    num_steps_sampled: 3115000
    num_steps_trained: 3115000
    wait_time_ms: 78.339
  iterations_since_restore: 623
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5406.595372438431
  time_this_iter_s: 8.419348955154419
  time_total_s: 5406.595372438431
  timestamp: 1594861427
  timesteps_since_restore: 3115000
  timesteps_this_iter: 5000
  timesteps_total: 3115000
  training_iteration: 623
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5406 s, 623 iter, 3115000 ts, -768 rew

agent-1: -137.04507635658234
agent-2: -45.98148132594176
agent-3: -153.44228340621737
agent-4: -74.01387324168041
agent-5: -251.33991285357436
Extrinsic Rewards:
5
1
3
3
7
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 1
Max Reward: 7
Gini Coefficient: 0.29473684210526313
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-03-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -765.4502100109978
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 623
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.223
    dispatch_time_ms: 9.778
    learner:
      cur_lr: 0.001152541022747755
      grad_gnorm: 22.722557067871094
      policy_entropy: 62.35476303100586
      policy_loss: 2.924203395843506
      var_gnorm: 26.23528289794922
      vf_explained_var: 0.0
      vf_loss: 7.7310686111450195
    num_steps_sampled: 3120000
    num_steps_trained: 3120000
    wait_time_ms: 72.857
  iterations_since_restore: 624
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5414.978273153305
  time_this_iter_s: 8.382900714874268
  time_total_s: 5414.978273153305
  timestamp: 1594861435
  timesteps_since_restore: 3120000
  timesteps_this_iter: 5000
  timesteps_total: 3120000
  training_iteration: 624
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5414 s, 624 iter, 3120000 ts, -765 rew

agent-1: -171.91575239555291
agent-2: -48.42700686023292
agent-3: -226.7121094114464
agent-4: -12.019251023072428
agent-5: -189.54891098773442
Extrinsic Rewards:
8
4
9
1
5
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.2962962962962963
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-04-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -754.21463712841
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 624
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.902
    dispatch_time_ms: 7.126
    learner:
      cur_lr: 0.0011522079585120082
      grad_gnorm: 36.30559539794922
      policy_entropy: 58.603790283203125
      policy_loss: -0.16151702404022217
      var_gnorm: 26.228696823120117
      vf_explained_var: 0.0
      vf_loss: 8.342151641845703
    num_steps_sampled: 3125000
    num_steps_trained: 3125000
    wait_time_ms: 72.09
  iterations_since_restore: 625
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5423.304170846939
  time_this_iter_s: 8.325897693634033
  time_total_s: 5423.304170846939
  timestamp: 1594861444
  timesteps_since_restore: 3125000
  timesteps_this_iter: 5000
  timesteps_total: 3125000
  training_iteration: 625
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5423 s, 625 iter, 3125000 ts, -754 rew

agent-1: -171.7278774199176
agent-2: -181.86551452196193
agent-3: -54.418519723649524
agent-4: -143.6679569289054
agent-5: -244.45798994317357
Extrinsic Rewards:
3
5
1
0
9
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.4888888888888889
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-04-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -748.9237321382624
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 625
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.556
    dispatch_time_ms: 6.818
    learner:
      cur_lr: 0.0011518750106915832
      grad_gnorm: 25.525367736816406
      policy_entropy: 40.6079216003418
      policy_loss: 10.032959938049316
      var_gnorm: 26.256221771240234
      vf_explained_var: 0.0
      vf_loss: 9.042028427124023
    num_steps_sampled: 3130000
    num_steps_trained: 3130000
    wait_time_ms: 70.552
  iterations_since_restore: 626
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5431.640334367752
  time_this_iter_s: 8.336163520812988
  time_total_s: 5431.640334367752
  timestamp: 1594861452
  timesteps_since_restore: 3130000
  timesteps_this_iter: 5000
  timesteps_total: 3130000
  training_iteration: 626
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5431 s, 626 iter, 3130000 ts, -749 rew

agent-1: -277.3615771027057
agent-2: -68.96763861020723
agent-3: -123.34466593587531
agent-4: -67.47483749294528
agent-5: -23.813236606861942
Extrinsic Rewards:
8
2
4
2
1
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.3764705882352941
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-04-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -733.1557698691073
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 626
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.176
    dispatch_time_ms: 7.965
    learner:
      cur_lr: 0.0011515419464558363
      grad_gnorm: 8.68628978729248
      policy_entropy: 47.70661163330078
      policy_loss: -1.9093468189239502
      var_gnorm: 26.233016967773438
      vf_explained_var: 0.0
      vf_loss: 5.907469749450684
    num_steps_sampled: 3135000
    num_steps_trained: 3135000
    wait_time_ms: 73.308
  iterations_since_restore: 627
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5439.978558063507
  time_this_iter_s: 8.338223695755005
  time_total_s: 5439.978558063507
  timestamp: 1594861460
  timesteps_since_restore: 3135000
  timesteps_this_iter: 5000
  timesteps_total: 3135000
  training_iteration: 627
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5439 s, 627 iter, 3135000 ts, -733 rew

agent-1: -89.7581468629109
agent-2: -142.536254339565
agent-3: -197.3044224232635
agent-4: -165.4721513361745
agent-5: -16.492002934836098
Extrinsic Rewards:
20
12
14
14
3
Sum Reward: 63
Avg Reward: 12.6
Min Reward: 3
Max Reward: 20
Gini Coefficient: 0.22857142857142856
20:20 Ratio: 6.666666666666667
Max-min Ratio: 6.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-04-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -725.1695709491498
  episode_reward_min: -2302.2595110547168
  episodes_this_iter: 1
  episodes_total: 627
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.61
    dispatch_time_ms: 7.117
    learner:
      cur_lr: 0.0011512089986354113
      grad_gnorm: 11.689735412597656
      policy_entropy: 48.369571685791016
      policy_loss: 2.1369025707244873
      var_gnorm: 26.237730026245117
      vf_explained_var: 0.0
      vf_loss: 5.836603164672852
    num_steps_sampled: 3140000
    num_steps_trained: 3140000
    wait_time_ms: 76.555
  iterations_since_restore: 628
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5448.410065174103
  time_this_iter_s: 8.431507110595703
  time_total_s: 5448.410065174103
  timestamp: 1594861469
  timesteps_since_restore: 3140000
  timesteps_this_iter: 5000
  timesteps_total: 3140000
  training_iteration: 628
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5448 s, 628 iter, 3140000 ts, -725 rew

agent-1: -97.52007427730153
agent-2: -210.74309781265666
agent-3: -76.51306885367352
agent-4: -54.78312470053351
agent-5: -206.5334960145468
Extrinsic Rewards:
9
8
6
6
6
Sum Reward: 35
Avg Reward: 7.0
Min Reward: 6
Max Reward: 9
Gini Coefficient: 0.09142857142857143
20:20 Ratio: 1.5
Max-min Ratio: 1.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-04-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -708.6079044551899
  episode_reward_min: -1738.302009359916
  episodes_this_iter: 1
  episodes_total: 628
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.577
    dispatch_time_ms: 6.947
    learner:
      cur_lr: 0.0011508760508149862
      grad_gnorm: 37.389122009277344
      policy_entropy: 54.31562042236328
      policy_loss: 10.827828407287598
      var_gnorm: 26.226375579833984
      vf_explained_var: 0.0
      vf_loss: 11.283287048339844
    num_steps_sampled: 3145000
    num_steps_trained: 3145000
    wait_time_ms: 78.874
  iterations_since_restore: 629
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5456.8222053050995
  time_this_iter_s: 8.412140130996704
  time_total_s: 5456.8222053050995
  timestamp: 1594861477
  timesteps_since_restore: 3145000
  timesteps_this_iter: 5000
  timesteps_total: 3145000
  training_iteration: 629
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5456 s, 629 iter, 3145000 ts, -709 rew

agent-1: -47.395835654748865
agent-2: -36.37280805224514
agent-3: -249.26124954709343
agent-4: -214.10719150320318
agent-5: -28.246989830834515
Extrinsic Rewards:
5
3
7
7
4
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 3
Max Reward: 7
Gini Coefficient: 0.16923076923076924
20:20 Ratio: 2.3333333333333335
Max-min Ratio: 2.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-04-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -705.0633951273098
  episode_reward_min: -1738.302009359916
  episodes_this_iter: 1
  episodes_total: 629
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.596
    dispatch_time_ms: 10.014
    learner:
      cur_lr: 0.0011505429865792394
      grad_gnorm: 40.0
      policy_entropy: 54.35098648071289
      policy_loss: -13.664315223693848
      var_gnorm: 26.260631561279297
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 7.902777194976807
    num_steps_sampled: 3150000
    num_steps_trained: 3150000
    wait_time_ms: 68.331
  iterations_since_restore: 630
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5465.177419900894
  time_this_iter_s: 8.355214595794678
  time_total_s: 5465.177419900894
  timestamp: 1594861486
  timesteps_since_restore: 3150000
  timesteps_this_iter: 5000
  timesteps_total: 3150000
  training_iteration: 630
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5465 s, 630 iter, 3150000 ts, -705 rew

agent-1: -156.64890203802122
agent-2: -139.8819517063011
agent-3: -241.51645362168378
agent-4: -106.56250104318958
agent-5: -156.63103811243175
Extrinsic Rewards:
2
0
7
5
7
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.3619047619047619
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-05-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -706.0218322220403
  episode_reward_min: -1738.302009359916
  episodes_this_iter: 1
  episodes_total: 630
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.789
    dispatch_time_ms: 11.024
    learner:
      cur_lr: 0.0011502100387588143
      grad_gnorm: 9.901668548583984
      policy_entropy: 54.95037841796875
      policy_loss: -2.6507530212402344
      var_gnorm: 26.226806640625
      vf_explained_var: 0.0
      vf_loss: 5.851981163024902
    num_steps_sampled: 3155000
    num_steps_trained: 3155000
    wait_time_ms: 68.891
  iterations_since_restore: 631
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5481.725159645081
  time_this_iter_s: 16.5477397441864
  time_total_s: 5481.725159645081
  timestamp: 1594861502
  timesteps_since_restore: 3155000
  timesteps_this_iter: 5000
  timesteps_total: 3155000
  training_iteration: 631
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5481 s, 631 iter, 3155000 ts, -706 rew

agent-1: -29.888262136677678
agent-2: -277.6942332925376
agent-3: -46.696747141185845
agent-4: -124.56452765397137
agent-5: -147.60959354138254
Extrinsic Rewards:
2
10
2
0
9
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 0
Max Reward: 10
Gini Coefficient: 0.46956521739130436
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-05-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -703.9007922325166
  episode_reward_min: -1738.302009359916
  episodes_this_iter: 1
  episodes_total: 631
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.569
    dispatch_time_ms: 8.584
    learner:
      cur_lr: 0.0011498769745230675
      grad_gnorm: 20.203630447387695
      policy_entropy: 58.725311279296875
      policy_loss: 0.22546005249023438
      var_gnorm: 26.247146606445312
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 5.880884170532227
    num_steps_sampled: 3160000
    num_steps_trained: 3160000
    wait_time_ms: 71.75
  iterations_since_restore: 632
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5490.02566409111
  time_this_iter_s: 8.300504446029663
  time_total_s: 5490.02566409111
  timestamp: 1594861511
  timesteps_since_restore: 3160000
  timesteps_this_iter: 5000
  timesteps_total: 3160000
  training_iteration: 632
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5490 s, 632 iter, 3160000 ts, -704 rew

agent-1: -115.115131422069
agent-2: -34.37350528691914
agent-3: -163.20042238048373
agent-4: -252.15368183904417
agent-5: -76.13693641811801
Extrinsic Rewards:
3
1
7
5
3
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 1
Max Reward: 7
Gini Coefficient: 0.29473684210526313
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-05-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -703.9248427087282
  episode_reward_min: -1738.302009359916
  episodes_this_iter: 1
  episodes_total: 632
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.901
    dispatch_time_ms: 8.125
    learner:
      cur_lr: 0.0011495440267026424
      grad_gnorm: 24.607210159301758
      policy_entropy: 57.362308502197266
      policy_loss: -8.169758796691895
      var_gnorm: 26.256412506103516
      vf_explained_var: 0.0
      vf_loss: 1.7974663972854614
    num_steps_sampled: 3165000
    num_steps_trained: 3165000
    wait_time_ms: 72.862
  iterations_since_restore: 633
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5498.425915956497
  time_this_iter_s: 8.400251865386963
  time_total_s: 5498.425915956497
  timestamp: 1594861519
  timesteps_since_restore: 3165000
  timesteps_this_iter: 5000
  timesteps_total: 3165000
  training_iteration: 633
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5498 s, 633 iter, 3165000 ts, -704 rew

agent-1: -133.9791531355926
agent-2: -203.40537926195213
agent-3: -198.6283331335899
agent-4: -168.2476330187597
agent-5: -132.58629605670785
Extrinsic Rewards:
0
5
6
5
3
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 0
Max Reward: 6
Gini Coefficient: 0.29473684210526313
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-05-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -705.3209182712267
  episode_reward_min: -1738.302009359916
  episodes_this_iter: 1
  episodes_total: 633
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.293
    dispatch_time_ms: 9.635
    learner:
      cur_lr: 0.0011492109624668956
      grad_gnorm: 20.71171760559082
      policy_entropy: 63.93738555908203
      policy_loss: -5.890986442565918
      var_gnorm: 26.391138076782227
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.8254568576812744
    num_steps_sampled: 3170000
    num_steps_trained: 3170000
    wait_time_ms: 70.148
  iterations_since_restore: 634
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5506.8839864730835
  time_this_iter_s: 8.458070516586304
  time_total_s: 5506.8839864730835
  timestamp: 1594861528
  timesteps_since_restore: 3170000
  timesteps_this_iter: 5000
  timesteps_total: 3170000
  training_iteration: 634
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5506 s, 634 iter, 3170000 ts, -705 rew

agent-1: -133.63019154916003
agent-2: -139.33563879586652
agent-3: -164.63532697068953
agent-4: -172.66011027273242
agent-5: -222.54809274479265
Extrinsic Rewards:
4
0
3
8
7
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.36363636363636365
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-05-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -706.0732675458319
  episode_reward_min: -1738.302009359916
  episodes_this_iter: 1
  episodes_total: 634
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.115
    dispatch_time_ms: 32.064
    learner:
      cur_lr: 0.0011488780146464705
      grad_gnorm: 11.466669082641602
      policy_entropy: 74.12275695800781
      policy_loss: -0.5026367902755737
      var_gnorm: 26.354284286499023
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 4.546053409576416
    num_steps_sampled: 3175000
    num_steps_trained: 3175000
    wait_time_ms: 59.59
  iterations_since_restore: 635
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5515.39152097702
  time_this_iter_s: 8.507534503936768
  time_total_s: 5515.39152097702
  timestamp: 1594861536
  timesteps_since_restore: 3175000
  timesteps_this_iter: 5000
  timesteps_total: 3175000
  training_iteration: 635
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5515 s, 635 iter, 3175000 ts, -706 rew

agent-1: -179.53189366856932
agent-2: -131.39130295238397
agent-3: -222.90011049998023
agent-4: -223.53489421760924
agent-5: -131.39130295238397
Extrinsic Rewards:
9
0
7
8
0
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.43333333333333335
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-05-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -709.1326773644769
  episode_reward_min: -1738.302009359916
  episodes_this_iter: 1
  episodes_total: 635
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.705
    dispatch_time_ms: 22.201
    learner:
      cur_lr: 0.0011485449504107237
      grad_gnorm: 22.897462844848633
      policy_entropy: 59.539119720458984
      policy_loss: -6.925603866577148
      var_gnorm: 26.425079345703125
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.3249971866607666
    num_steps_sampled: 3180000
    num_steps_trained: 3180000
    wait_time_ms: 26.035
  iterations_since_restore: 636
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5524.654715061188
  time_this_iter_s: 9.26319408416748
  time_total_s: 5524.654715061188
  timestamp: 1594861545
  timesteps_since_restore: 3180000
  timesteps_this_iter: 5000
  timesteps_total: 3180000
  training_iteration: 636
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5524 s, 636 iter, 3180000 ts, -709 rew

agent-1: -174.2493921745063
agent-2: -179.91250503277695
agent-3: -154.6373382387929
agent-4: -205.72155278296654
agent-5: -146.03336910166263
Extrinsic Rewards:
4
6
4
5
0
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 0
Max Reward: 6
Gini Coefficient: 0.2736842105263158
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-05-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -700.3551988441849
  episode_reward_min: -1574.529707629404
  episodes_this_iter: 1
  episodes_total: 636
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.909
    dispatch_time_ms: 26.587
    learner:
      cur_lr: 0.0011482120025902987
      grad_gnorm: 7.389288425445557
      policy_entropy: 47.14594650268555
      policy_loss: 0.487759530544281
      var_gnorm: 26.362035751342773
      vf_explained_var: 0.0
      vf_loss: 1.0959606170654297
    num_steps_sampled: 3185000
    num_steps_trained: 3185000
    wait_time_ms: 62.545
  iterations_since_restore: 637
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5533.41135764122
  time_this_iter_s: 8.756642580032349
  time_total_s: 5533.41135764122
  timestamp: 1594861554
  timesteps_since_restore: 3185000
  timesteps_this_iter: 5000
  timesteps_total: 3185000
  training_iteration: 637
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5533 s, 637 iter, 3185000 ts, -700 rew

agent-1: -160.78059687294692
agent-2: -148.11187007811063
agent-3: -89.40200054433208
agent-4: -172.11866021445255
agent-5: -184.49889230315372
Extrinsic Rewards:
3
2
2
4
4
Sum Reward: 15
Avg Reward: 3.0
Min Reward: 2
Max Reward: 4
Gini Coefficient: 0.16
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-06-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -700.5653267075302
  episode_reward_min: -1574.529707629404
  episodes_this_iter: 1
  episodes_total: 637
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.641
    dispatch_time_ms: 25.534
    learner:
      cur_lr: 0.0011478790547698736
      grad_gnorm: 9.800663948059082
      policy_entropy: 50.638301849365234
      policy_loss: -0.827498733997345
      var_gnorm: 26.337923049926758
      vf_explained_var: 0.0
      vf_loss: 3.49828839302063
    num_steps_sampled: 3190000
    num_steps_trained: 3190000
    wait_time_ms: 59.149
  iterations_since_restore: 638
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5542.327987670898
  time_this_iter_s: 8.916630029678345
  time_total_s: 5542.327987670898
  timestamp: 1594861563
  timesteps_since_restore: 3190000
  timesteps_this_iter: 5000
  timesteps_total: 3190000
  training_iteration: 638
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5542 s, 638 iter, 3190000 ts, -701 rew

agent-1: -200.06279931615492
agent-2: -74.74496059530107
agent-3: -148.3371370587515
agent-4: -181.05788327461678
agent-5: -70.92587270379543
Extrinsic Rewards:
8
7
8
13
3
Sum Reward: 39
Avg Reward: 7.8
Min Reward: 3
Max Reward: 13
Gini Coefficient: 0.2153846153846154
20:20 Ratio: 4.333333333333333
Max-min Ratio: 4.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-06-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -700.5162654357075
  episode_reward_min: -1574.529707629404
  episodes_this_iter: 1
  episodes_total: 638
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.521
    dispatch_time_ms: 39.6
    learner:
      cur_lr: 0.0011475459905341268
      grad_gnorm: 16.002233505249023
      policy_entropy: 51.13642120361328
      policy_loss: 2.0165112018585205
      var_gnorm: 26.31735610961914
      vf_explained_var: 0.0
      vf_loss: 7.711873531341553
    num_steps_sampled: 3195000
    num_steps_trained: 3195000
    wait_time_ms: 55.136
  iterations_since_restore: 639
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5551.320286273956
  time_this_iter_s: 8.992298603057861
  time_total_s: 5551.320286273956
  timestamp: 1594861572
  timesteps_since_restore: 3195000
  timesteps_this_iter: 5000
  timesteps_total: 3195000
  training_iteration: 639
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5551 s, 639 iter, 3195000 ts, -701 rew

agent-1: -221.28496432563693
agent-2: -67.2167847993861
agent-3: -145.04127913963563
agent-4: -189.72611311757774
agent-5: -82.8970617550736
Extrinsic Rewards:
6
2
4
6
2
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 2
Max Reward: 6
Gini Coefficient: 0.24
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-06-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -701.6443468666025
  episode_reward_min: -1574.529707629404
  episodes_this_iter: 1
  episodes_total: 639
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 4.252
    dispatch_time_ms: 28.241
    learner:
      cur_lr: 0.0011472130427137017
      grad_gnorm: 14.824372291564941
      policy_entropy: 51.86312484741211
      policy_loss: -4.351720809936523
      var_gnorm: 26.312973022460938
      vf_explained_var: 0.0
      vf_loss: 7.253742694854736
    num_steps_sampled: 3200000
    num_steps_trained: 3200000
    wait_time_ms: 55.353
  iterations_since_restore: 640
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5560.1599588394165
  time_this_iter_s: 8.839672565460205
  time_total_s: 5560.1599588394165
  timestamp: 1594861581
  timesteps_since_restore: 3200000
  timesteps_this_iter: 5000
  timesteps_total: 3200000
  training_iteration: 640
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5560 s, 640 iter, 3200000 ts, -702 rew

agent-1: -20.62189501683057
agent-2: -76.775838049344
agent-3: -237.37584136440077
agent-4: -177.99833080525568
agent-5: -116.76831301744627
Extrinsic Rewards:
2
9
9
5
4
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 2
Max Reward: 9
Gini Coefficient: 0.2620689655172414
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-06-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -700.666114394907
  episode_reward_min: -1574.529707629404
  episodes_this_iter: 1
  episodes_total: 640
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.543
    dispatch_time_ms: 22.211
    learner:
      cur_lr: 0.0011468799784779549
      grad_gnorm: 9.712890625
      policy_entropy: 54.558841705322266
      policy_loss: -6.445994853973389
      var_gnorm: 26.328622817993164
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.278423547744751
    num_steps_sampled: 3205000
    num_steps_trained: 3205000
    wait_time_ms: 63.903
  iterations_since_restore: 641
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5569.042605400085
  time_this_iter_s: 8.882646560668945
  time_total_s: 5569.042605400085
  timestamp: 1594861590
  timesteps_since_restore: 3205000
  timesteps_this_iter: 5000
  timesteps_total: 3205000
  training_iteration: 641
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5569 s, 641 iter, 3205000 ts, -701 rew

agent-1: -44.83699823056563
agent-2: -196.601186810386
agent-3: -98.76733431863816
agent-4: -130.4817845841066
agent-5: -208.47693912309168
Extrinsic Rewards:
1
8
1
7
1
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.4444444444444444
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-06-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -700.5068198576425
  episode_reward_min: -1574.529707629404
  episodes_this_iter: 1
  episodes_total: 641
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.831
    dispatch_time_ms: 28.286
    learner:
      cur_lr: 0.0011465470306575298
      grad_gnorm: 40.0
      policy_entropy: 58.50043487548828
      policy_loss: 18.12361717224121
      var_gnorm: 26.32498550415039
      vf_explained_var: 0.0
      vf_loss: 14.342691421508789
    num_steps_sampled: 3210000
    num_steps_trained: 3210000
    wait_time_ms: 55.45
  iterations_since_restore: 642
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5577.9517385959625
  time_this_iter_s: 8.909133195877075
  time_total_s: 5577.9517385959625
  timestamp: 1594861599
  timesteps_since_restore: 3210000
  timesteps_this_iter: 5000
  timesteps_total: 3210000
  training_iteration: 642
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5577 s, 642 iter, 3210000 ts, -701 rew

agent-1: -183.683566669826
agent-2: -75.50841001894679
agent-3: -114.29707733364108
agent-4: -187.42050953719664
agent-5: -168.4132343041726
Extrinsic Rewards:
6
4
3
4
3
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 3
Max Reward: 6
Gini Coefficient: 0.14
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-06-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -701.6256275015846
  episode_reward_min: -1574.529707629404
  episodes_this_iter: 1
  episodes_total: 642
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.887
    dispatch_time_ms: 7.403
    learner:
      cur_lr: 0.001146213966421783
      grad_gnorm: 12.069845199584961
      policy_entropy: 53.74589538574219
      policy_loss: -5.068027973175049
      var_gnorm: 26.307973861694336
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.3489575386047363
    num_steps_sampled: 3215000
    num_steps_trained: 3215000
    wait_time_ms: 73.795
  iterations_since_restore: 643
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5586.555177688599
  time_this_iter_s: 8.603439092636108
  time_total_s: 5586.555177688599
  timestamp: 1594861608
  timesteps_since_restore: 3215000
  timesteps_this_iter: 5000
  timesteps_total: 3215000
  training_iteration: 643
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5586 s, 643 iter, 3215000 ts, -702 rew

agent-1: -152.52866462506415
agent-2: -137.45618301940425
agent-3: -232.83740440056692
agent-4: -74.07751376416924
agent-5: -90.0538425068917
Extrinsic Rewards:
5
4
11
5
1
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 1
Max Reward: 11
Gini Coefficient: 0.3230769230769231
20:20 Ratio: 11.0
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-06-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -701.5584493446196
  episode_reward_min: -1574.529707629404
  episodes_this_iter: 1
  episodes_total: 643
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.373
    dispatch_time_ms: 8.497
    learner:
      cur_lr: 0.001145881018601358
      grad_gnorm: 18.13831329345703
      policy_entropy: 25.580537796020508
      policy_loss: -7.102762222290039
      var_gnorm: 26.300317764282227
      vf_explained_var: 0.0
      vf_loss: 6.026164531707764
    num_steps_sampled: 3220000
    num_steps_trained: 3220000
    wait_time_ms: 70.332
  iterations_since_restore: 644
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5594.904952049255
  time_this_iter_s: 8.349774360656738
  time_total_s: 5594.904952049255
  timestamp: 1594861616
  timesteps_since_restore: 3220000
  timesteps_this_iter: 5000
  timesteps_total: 3220000
  training_iteration: 644
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5594 s, 644 iter, 3220000 ts, -702 rew

agent-1: -125.17721161769745
agent-2: -265.9225818430171
agent-3: -8.786765263159596
agent-4: -123.29763003886546
agent-5: -30.085940124512614
Extrinsic Rewards:
4
15
1
4
4
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 1
Max Reward: 15
Gini Coefficient: 0.4
20:20 Ratio: 15.0
Max-min Ratio: 15.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-07-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -698.5653863552586
  episode_reward_min: -1574.529707629404
  episodes_this_iter: 1
  episodes_total: 644
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.697
    dispatch_time_ms: 6.446
    learner:
      cur_lr: 0.001145547954365611
      grad_gnorm: 11.63079833984375
      policy_entropy: 59.46756362915039
      policy_loss: -3.1915810108184814
      var_gnorm: 26.298274993896484
      vf_explained_var: 0.0
      vf_loss: 7.114355087280273
    num_steps_sampled: 3225000
    num_steps_trained: 3225000
    wait_time_ms: 74.959
  iterations_since_restore: 645
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5603.21378493309
  time_this_iter_s: 8.308832883834839
  time_total_s: 5603.21378493309
  timestamp: 1594861624
  timesteps_since_restore: 3225000
  timesteps_this_iter: 5000
  timesteps_total: 3225000
  training_iteration: 645
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5603 s, 645 iter, 3225000 ts, -699 rew

agent-1: -102.405367935
agent-2: -142.76309532068947
agent-3: -193.94321611398925
agent-4: -79.08737975326923
agent-5: -66.17283640478443
Extrinsic Rewards:
13
8
11
10
8
Sum Reward: 50
Avg Reward: 10.0
Min Reward: 8
Max Reward: 13
Gini Coefficient: 0.104
20:20 Ratio: 1.625
Max-min Ratio: 1.625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-07-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -689.494774861377
  episode_reward_min: -1574.529707629404
  episodes_this_iter: 1
  episodes_total: 645
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.537
    dispatch_time_ms: 7.471
    learner:
      cur_lr: 0.001145215006545186
      grad_gnorm: 20.54007339477539
      policy_entropy: 59.274234771728516
      policy_loss: 0.08208458125591278
      var_gnorm: 26.31817626953125
      vf_explained_var: 0.0
      vf_loss: 5.716813564300537
    num_steps_sampled: 3230000
    num_steps_trained: 3230000
    wait_time_ms: 74.322
  iterations_since_restore: 646
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5611.727558374405
  time_this_iter_s: 8.513773441314697
  time_total_s: 5611.727558374405
  timestamp: 1594861633
  timesteps_since_restore: 3230000
  timesteps_this_iter: 5000
  timesteps_total: 3230000
  training_iteration: 646
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5611 s, 646 iter, 3230000 ts, -689 rew

agent-1: -175.8730742798988
agent-2: -81.38343023116919
agent-3: -54.36516500454144
agent-4: -155.9047425434057
agent-5: -200.0695944645763
Extrinsic Rewards:
12
3
5
10
13
Sum Reward: 43
Avg Reward: 8.6
Min Reward: 3
Max Reward: 13
Gini Coefficient: 0.25116279069767444
20:20 Ratio: 4.333333333333333
Max-min Ratio: 4.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-07-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -687.7102039755588
  episode_reward_min: -1574.529707629404
  episodes_this_iter: 1
  episodes_total: 646
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.826
    dispatch_time_ms: 7.613
    learner:
      cur_lr: 0.0011448819423094392
      grad_gnorm: 40.0
      policy_entropy: 63.88442611694336
      policy_loss: -18.328720092773438
      var_gnorm: 26.327327728271484
      vf_explained_var: 0.0
      vf_loss: 4.1883368492126465
    num_steps_sampled: 3235000
    num_steps_trained: 3235000
    wait_time_ms: 71.984
  iterations_since_restore: 647
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5620.04927945137
  time_this_iter_s: 8.321721076965332
  time_total_s: 5620.04927945137
  timestamp: 1594861641
  timesteps_since_restore: 3235000
  timesteps_this_iter: 5000
  timesteps_total: 3235000
  training_iteration: 647
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5620 s, 647 iter, 3235000 ts, -688 rew

agent-1: -232.90781860859042
agent-2: -159.99848950426036
agent-3: -162.54319876163882
agent-4: -130.3578934446292
agent-5: -144.8634833677077
Extrinsic Rewards:
10
3
3
2
0
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 0
Max Reward: 10
Gini Coefficient: 0.4666666666666667
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-07-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -690.5901732508087
  episode_reward_min: -1574.529707629404
  episodes_this_iter: 1
  episodes_total: 647
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.596
    dispatch_time_ms: 7.162
    learner:
      cur_lr: 0.0011445489944890141
      grad_gnorm: 40.0
      policy_entropy: 68.01669311523438
      policy_loss: 26.17066764831543
      var_gnorm: 26.453371047973633
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 13.523263931274414
    num_steps_sampled: 3240000
    num_steps_trained: 3240000
    wait_time_ms: 75.229
  iterations_since_restore: 648
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5628.413838863373
  time_this_iter_s: 8.364559412002563
  time_total_s: 5628.413838863373
  timestamp: 1594861650
  timesteps_since_restore: 3240000
  timesteps_this_iter: 5000
  timesteps_total: 3240000
  training_iteration: 648
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5628 s, 648 iter, 3240000 ts, -691 rew

agent-1: -329.7492671527876
agent-2: -469.1359705428659
agent-3: -235.94222245883398
agent-4: -489.64354336532995
agent-5: -448.89124506593123
Extrinsic Rewards:
0
4
1
8
1
Sum Reward: 14
Avg Reward: 2.8
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.5428571428571428
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-07-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -704.143617350209
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 648
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.164
    dispatch_time_ms: 6.007
    learner:
      cur_lr: 0.0011442160466685891
      grad_gnorm: 22.30507469177246
      policy_entropy: 62.84883117675781
      policy_loss: 7.382521152496338
      var_gnorm: 26.358301162719727
      vf_explained_var: 0.0
      vf_loss: 6.109495639801025
    num_steps_sampled: 3245000
    num_steps_trained: 3245000
    wait_time_ms: 77.234
  iterations_since_restore: 649
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5636.779381990433
  time_this_iter_s: 8.365543127059937
  time_total_s: 5636.779381990433
  timestamp: 1594861658
  timesteps_since_restore: 3245000
  timesteps_this_iter: 5000
  timesteps_total: 3245000
  training_iteration: 649
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5636 s, 649 iter, 3245000 ts, -704 rew

agent-1: -200.09476232355166
agent-2: -7.043166736273432
agent-3: -79.45084669202552
agent-4: -224.06090085674128
agent-5: -128.3996161974017
Extrinsic Rewards:
7
1
8
7
6
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.20689655172413793
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-07-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -704.5244137514386
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 649
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 4.632
    dispatch_time_ms: 8.452
    learner:
      cur_lr: 0.0011438829824328423
      grad_gnorm: 34.86571502685547
      policy_entropy: 62.91526794433594
      policy_loss: -17.02845573425293
      var_gnorm: 26.365758895874023
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 6.234893798828125
    num_steps_sampled: 3250000
    num_steps_trained: 3250000
    wait_time_ms: 73.218
  iterations_since_restore: 650
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5645.151206254959
  time_this_iter_s: 8.371824264526367
  time_total_s: 5645.151206254959
  timestamp: 1594861666
  timesteps_since_restore: 3250000
  timesteps_this_iter: 5000
  timesteps_total: 3250000
  training_iteration: 650
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5645 s, 650 iter, 3250000 ts, -705 rew

agent-1: -204.62254644529088
agent-2: -100.1038226271017
agent-3: -150.0509025604535
agent-4: -227.96591407299033
agent-5: -157.09163564685875
Extrinsic Rewards:
5
2
0
6
3
Sum Reward: 16
Avg Reward: 3.2
Min Reward: 0
Max Reward: 6
Gini Coefficient: 0.375
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-07-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -705.4220828553589
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 650
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.965
    dispatch_time_ms: 6.57
    learner:
      cur_lr: 0.0011435500346124172
      grad_gnorm: 39.88208770751953
      policy_entropy: 58.986209869384766
      policy_loss: -16.665546417236328
      var_gnorm: 26.3313045501709
      vf_explained_var: 0.0
      vf_loss: 6.916234016418457
    num_steps_sampled: 3255000
    num_steps_trained: 3255000
    wait_time_ms: 72.747
  iterations_since_restore: 651
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5653.412116765976
  time_this_iter_s: 8.260910511016846
  time_total_s: 5653.412116765976
  timestamp: 1594861675
  timesteps_since_restore: 3255000
  timesteps_this_iter: 5000
  timesteps_total: 3255000
  training_iteration: 651
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5653 s, 651 iter, 3255000 ts, -705 rew

agent-1: -204.53579586825583
agent-2: -228.3746339413095
agent-3: -182.7249703711544
agent-4: -44.81525600627212
agent-5: -145.55305559299643
Extrinsic Rewards:
5
9
5
1
0
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.44
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-08-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -705.6669971138093
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 651
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.87
    dispatch_time_ms: 8.743
    learner:
      cur_lr: 0.0011432169703766704
      grad_gnorm: 18.434755325317383
      policy_entropy: 57.114723205566406
      policy_loss: 7.796396255493164
      var_gnorm: 26.354806900024414
      vf_explained_var: 0.0
      vf_loss: 7.472261905670166
    num_steps_sampled: 3260000
    num_steps_trained: 3260000
    wait_time_ms: 74.133
  iterations_since_restore: 652
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5661.826814889908
  time_this_iter_s: 8.414698123931885
  time_total_s: 5661.826814889908
  timestamp: 1594861683
  timesteps_since_restore: 3260000
  timesteps_this_iter: 5000
  timesteps_total: 3260000
  training_iteration: 652
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5661 s, 652 iter, 3260000 ts, -706 rew

agent-1: -168.1582064108646
agent-2: -93.45100977207218
agent-3: -124.71734536048362
agent-4: -207.61315620577787
agent-5: -21.649749289853336
Extrinsic Rewards:
7
9
17
10
6
Sum Reward: 49
Avg Reward: 9.8
Min Reward: 6
Max Reward: 17
Gini Coefficient: 0.20408163265306123
20:20 Ratio: 2.8333333333333335
Max-min Ratio: 2.8333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-08-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -704.855004800665
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 652
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.597
    dispatch_time_ms: 8.597
    learner:
      cur_lr: 0.0011428840225562453
      grad_gnorm: 27.967845916748047
      policy_entropy: 41.65916442871094
      policy_loss: 9.32256031036377
      var_gnorm: 26.32119369506836
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 10.356243133544922
    num_steps_sampled: 3265000
    num_steps_trained: 3265000
    wait_time_ms: 70.265
  iterations_since_restore: 653
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5670.117138624191
  time_this_iter_s: 8.290323734283447
  time_total_s: 5670.117138624191
  timestamp: 1594861691
  timesteps_since_restore: 3265000
  timesteps_this_iter: 5000
  timesteps_total: 3265000
  training_iteration: 653
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5670 s, 653 iter, 3265000 ts, -705 rew

agent-1: -36.59190355980649
agent-2: -125.86931301541739
agent-3: -25.178064679534558
agent-4: -251.67065222073538
agent-5: -228.76911214041826
Extrinsic Rewards:
4
0
2
6
9
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.41904761904761906
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-08-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -704.6695498625248
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 653
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.381
    dispatch_time_ms: 7.582
    learner:
      cur_lr: 0.0011425509583204985
      grad_gnorm: 40.0
      policy_entropy: 65.14359283447266
      policy_loss: 21.332319259643555
      var_gnorm: 26.381938934326172
      vf_explained_var: 0.0
      vf_loss: 12.451242446899414
    num_steps_sampled: 3270000
    num_steps_trained: 3270000
    wait_time_ms: 74.819
  iterations_since_restore: 654
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5678.445098161697
  time_this_iter_s: 8.327959537506104
  time_total_s: 5678.445098161697
  timestamp: 1594861700
  timesteps_since_restore: 3270000
  timesteps_this_iter: 5000
  timesteps_total: 3270000
  training_iteration: 654
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5678 s, 654 iter, 3270000 ts, -705 rew

agent-1: -162.37466032461896
agent-2: -146.0042802067512
agent-3: -74.92493775456258
agent-4: -252.6798603298209
agent-5: -150.0598531274051
Extrinsic Rewards:
5
0
2
9
1
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.5176470588235295
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-08-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -705.1493811114586
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 654
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.946
    dispatch_time_ms: 9.805
    learner:
      cur_lr: 0.0011422180105000734
      grad_gnorm: 18.696578979492188
      policy_entropy: 66.91795349121094
      policy_loss: 9.53760051727295
      var_gnorm: 26.35618019104004
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 7.39174747467041
    num_steps_sampled: 3275000
    num_steps_trained: 3275000
    wait_time_ms: 71.003
  iterations_since_restore: 655
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5686.778166055679
  time_this_iter_s: 8.333067893981934
  time_total_s: 5686.778166055679
  timestamp: 1594861708
  timesteps_since_restore: 3275000
  timesteps_this_iter: 5000
  timesteps_total: 3275000
  training_iteration: 655
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5686 s, 655 iter, 3275000 ts, -705 rew

agent-1: -68.62397995216816
agent-2: -253.5573142187261
agent-3: -47.83943303042394
agent-4: -107.38013979779792
agent-5: -109.89362793108462
Extrinsic Rewards:
8
6
4
1
5
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.26666666666666666
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-08-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -704.0743865675447
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 655
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.828
    dispatch_time_ms: 7.971
    learner:
      cur_lr: 0.0011418849462643266
      grad_gnorm: 12.541601181030273
      policy_entropy: 61.95173263549805
      policy_loss: -2.829261064529419
      var_gnorm: 26.340728759765625
      vf_explained_var: 0.0
      vf_loss: 3.9618029594421387
    num_steps_sampled: 3280000
    num_steps_trained: 3280000
    wait_time_ms: 71.927
  iterations_since_restore: 656
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5695.136492967606
  time_this_iter_s: 8.35832691192627
  time_total_s: 5695.136492967606
  timestamp: 1594861717
  timesteps_since_restore: 3280000
  timesteps_this_iter: 5000
  timesteps_total: 3280000
  training_iteration: 656
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5695 s, 656 iter, 3280000 ts, -704 rew

agent-1: -222.46195900339313
agent-2: -31.891528683843184
agent-3: -170.33734617808423
agent-4: -145.97224088158788
agent-5: -143.82733484455846
Extrinsic Rewards:
7
1
3
3
4
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 1
Max Reward: 7
Gini Coefficient: 0.28888888888888886
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-08-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -704.6175700402727
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 656
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.249
    dispatch_time_ms: 7.986
    learner:
      cur_lr: 0.0011415519984439015
      grad_gnorm: 17.03260040283203
      policy_entropy: 68.72605895996094
      policy_loss: 5.214846134185791
      var_gnorm: 26.314220428466797
      vf_explained_var: 0.0
      vf_loss: 8.964431762695312
    num_steps_sampled: 3285000
    num_steps_trained: 3285000
    wait_time_ms: 72.722
  iterations_since_restore: 657
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5703.527009963989
  time_this_iter_s: 8.390516996383667
  time_total_s: 5703.527009963989
  timestamp: 1594861725
  timesteps_since_restore: 3285000
  timesteps_this_iter: 5000
  timesteps_total: 3285000
  training_iteration: 657
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5703 s, 657 iter, 3285000 ts, -705 rew

agent-1: -102.8754100171137
agent-2: -279.55867809224725
agent-3: -28.687945899178718
agent-4: -76.73074673386748
agent-5: -33.988399083816226
Extrinsic Rewards:
5
11
2
2
1
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 1
Max Reward: 11
Gini Coefficient: 0.4380952380952381
20:20 Ratio: 11.0
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-08-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -703.8810860544592
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 657
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.683
    dispatch_time_ms: 10.383
    learner:
      cur_lr: 0.0011412190506234765
      grad_gnorm: 31.480144500732422
      policy_entropy: 64.4215316772461
      policy_loss: 11.744797706604004
      var_gnorm: 26.31063461303711
      vf_explained_var: 0.0
      vf_loss: 7.14613151550293
    num_steps_sampled: 3290000
    num_steps_trained: 3290000
    wait_time_ms: 70.133
  iterations_since_restore: 658
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5711.873194932938
  time_this_iter_s: 8.346184968948364
  time_total_s: 5711.873194932938
  timestamp: 1594861733
  timesteps_since_restore: 3290000
  timesteps_this_iter: 5000
  timesteps_total: 3290000
  training_iteration: 658
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5711 s, 658 iter, 3290000 ts, -704 rew

agent-1: -21.834535319890957
agent-2: -208.51569308240465
agent-3: -77.5630690480481
agent-4: -210.60136890900492
agent-5: -96.53387185691204
Extrinsic Rewards:
3
11
8
8
10
Sum Reward: 40
Avg Reward: 8.0
Min Reward: 3
Max Reward: 11
Gini Coefficient: 0.18
20:20 Ratio: 3.6666666666666665
Max-min Ratio: 3.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-09-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -703.686707426454
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 658
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.515
    dispatch_time_ms: 5.983
    learner:
      cur_lr: 0.0011408859863877296
      grad_gnorm: 40.0
      policy_entropy: 53.1986198425293
      policy_loss: -21.658281326293945
      var_gnorm: 26.300355911254883
      vf_explained_var: 0.0
      vf_loss: 8.315339088439941
    num_steps_sampled: 3295000
    num_steps_trained: 3295000
    wait_time_ms: 1098.304
  iterations_since_restore: 659
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5730.450799465179
  time_this_iter_s: 18.57760453224182
  time_total_s: 5730.450799465179
  timestamp: 1594861752
  timesteps_since_restore: 3295000
  timesteps_this_iter: 5000
  timesteps_total: 3295000
  training_iteration: 659
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5730 s, 659 iter, 3295000 ts, -704 rew

agent-1: -144.79715107398175
agent-2: -252.80404283578991
agent-3: -230.66974850378222
agent-4: -107.48901943690433
agent-5: -144.79715107398175
Extrinsic Rewards:
0
8
7
4
0
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.4842105263157895
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-09-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -705.3793026232523
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 659
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 4.319
    dispatch_time_ms: 12.384
    learner:
      cur_lr: 0.0011405530385673046
      grad_gnorm: 38.8822021484375
      policy_entropy: 56.12614440917969
      policy_loss: 19.571678161621094
      var_gnorm: 26.330106735229492
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 11.626946449279785
    num_steps_sampled: 3300000
    num_steps_trained: 3300000
    wait_time_ms: 71.121
  iterations_since_restore: 660
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5738.6834082603455
  time_this_iter_s: 8.232608795166016
  time_total_s: 5738.6834082603455
  timestamp: 1594861760
  timesteps_since_restore: 3300000
  timesteps_this_iter: 5000
  timesteps_total: 3300000
  training_iteration: 660
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5738 s, 660 iter, 3300000 ts, -705 rew

agent-1: -108.10950437480285
agent-2: -200.54386619901368
agent-3: -159.06383957547547
agent-4: -57.4994516370233
agent-5: -33.76634071513723
Extrinsic Rewards:
10
12
17
9
5
Sum Reward: 53
Avg Reward: 10.6
Min Reward: 5
Max Reward: 17
Gini Coefficient: 0.2037735849056604
20:20 Ratio: 3.4
Max-min Ratio: 3.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-09-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -704.0794433064158
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 660
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.953
    dispatch_time_ms: 15.837
    learner:
      cur_lr: 0.0011402199743315578
      grad_gnorm: 4.064833641052246
      policy_entropy: 52.00388717651367
      policy_loss: -0.01448836550116539
      var_gnorm: 26.32461166381836
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 7.020941257476807
    num_steps_sampled: 3305000
    num_steps_trained: 3305000
    wait_time_ms: 69.764
  iterations_since_restore: 661
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5747.581391096115
  time_this_iter_s: 8.897982835769653
  time_total_s: 5747.581391096115
  timestamp: 1594861769
  timesteps_since_restore: 3305000
  timesteps_this_iter: 5000
  timesteps_total: 3305000
  training_iteration: 661
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5747 s, 661 iter, 3305000 ts, -704 rew

agent-1: -137.11575317234488
agent-2: -146.22882025584485
agent-3: -180.1718628804855
agent-4: -222.55796196823263
agent-5: -17.07830519894634
Extrinsic Rewards:
3
5
4
9
1
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.32727272727272727
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-09-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -705.7057451061896
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 661
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.121
    dispatch_time_ms: 13.675
    learner:
      cur_lr: 0.0011398870265111327
      grad_gnorm: 28.977252960205078
      policy_entropy: 36.50251388549805
      policy_loss: -0.7170506715774536
      var_gnorm: 26.3563175201416
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 7.107664585113525
    num_steps_sampled: 3310000
    num_steps_trained: 3310000
    wait_time_ms: 45.72
  iterations_since_restore: 662
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5756.757808208466
  time_this_iter_s: 9.176417112350464
  time_total_s: 5756.757808208466
  timestamp: 1594861778
  timesteps_since_restore: 3310000
  timesteps_this_iter: 5000
  timesteps_total: 3310000
  training_iteration: 662
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5756 s, 662 iter, 3310000 ts, -706 rew

agent-1: -259.42514183985617
agent-2: -66.89487959293346
agent-3: -165.38690726365923
agent-4: -143.15385091752756
agent-5: -129.50603692610517
Extrinsic Rewards:
11
2
4
0
1
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 0
Max Reward: 11
Gini Coefficient: 0.5555555555555556
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-09-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -707.6789012063367
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 662
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.744
    dispatch_time_ms: 7.972
    learner:
      cur_lr: 0.0011395539622753859
      grad_gnorm: 16.20215606689453
      policy_entropy: 40.361900329589844
      policy_loss: 6.008383274078369
      var_gnorm: 26.3248233795166
      vf_explained_var: 0.0
      vf_loss: 5.1911163330078125
    num_steps_sampled: 3315000
    num_steps_trained: 3315000
    wait_time_ms: 72.903
  iterations_since_restore: 663
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5765.239932775497
  time_this_iter_s: 8.48212456703186
  time_total_s: 5765.239932775497
  timestamp: 1594861787
  timesteps_since_restore: 3315000
  timesteps_this_iter: 5000
  timesteps_total: 3315000
  training_iteration: 663
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5765 s, 663 iter, 3315000 ts, -708 rew

agent-1: -66.30147009516202
agent-2: -150.2677424767582
agent-3: -139.68094160665262
agent-4: -121.07510206376145
agent-5: -68.27814802519613
Extrinsic Rewards:
12
30
32
19
11
Sum Reward: 104
Avg Reward: 20.8
Min Reward: 11
Max Reward: 32
Gini Coefficient: 0.23076923076923078
20:20 Ratio: 2.909090909090909
Max-min Ratio: 2.909090909090909
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-09-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -706.4103350287822
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 663
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.477
    dispatch_time_ms: 5.206
    learner:
      cur_lr: 0.0011392210144549608
      grad_gnorm: 10.51095199584961
      policy_entropy: 49.94937515258789
      policy_loss: -1.6638143062591553
      var_gnorm: 26.322099685668945
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 8.01787281036377
    num_steps_sampled: 3320000
    num_steps_trained: 3320000
    wait_time_ms: 78.926
  iterations_since_restore: 664
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5773.651761054993
  time_this_iter_s: 8.41182827949524
  time_total_s: 5773.651761054993
  timestamp: 1594861795
  timesteps_since_restore: 3320000
  timesteps_this_iter: 5000
  timesteps_total: 3320000
  training_iteration: 664
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5773 s, 664 iter, 3320000 ts, -706 rew

agent-1: -51.583662526462696
agent-2: -85.54529213206735
agent-3: -222.31989699685744
agent-4: -225.6358952222548
agent-5: -82.36716944122443
Extrinsic Rewards:
2
4
5
6
1
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 1
Max Reward: 6
Gini Coefficient: 0.28888888888888886
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-10-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -706.3102893544424
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 664
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.705
    dispatch_time_ms: 9.397
    learner:
      cur_lr: 0.001138887950219214
      grad_gnorm: 19.649574279785156
      policy_entropy: 51.14311218261719
      policy_loss: 0.09795217216014862
      var_gnorm: 26.320341110229492
      vf_explained_var: 0.0
      vf_loss: 6.055812358856201
    num_steps_sampled: 3325000
    num_steps_trained: 3325000
    wait_time_ms: 71.747
  iterations_since_restore: 665
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5782.11567735672
  time_this_iter_s: 8.463916301727295
  time_total_s: 5782.11567735672
  timestamp: 1594861804
  timesteps_since_restore: 3325000
  timesteps_this_iter: 5000
  timesteps_total: 3325000
  training_iteration: 665
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5782 s, 665 iter, 3325000 ts, -706 rew

agent-1: -131.29034365928905
agent-2: -248.22851000627472
agent-3: -147.0838476340399
agent-4: -203.57104550401505
agent-5: -57.344253536497575
Extrinsic Rewards:
4
8
0
5
1
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.4444444444444444
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-10-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -708.0713530690865
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 665
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.51
    dispatch_time_ms: 6.918
    learner:
      cur_lr: 0.001138555002398789
      grad_gnorm: 40.00000762939453
      policy_entropy: 42.482967376708984
      policy_loss: 4.906048774719238
      var_gnorm: 26.35923194885254
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 15.260576248168945
    num_steps_sampled: 3330000
    num_steps_trained: 3330000
    wait_time_ms: 69.604
  iterations_since_restore: 666
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5790.4600241184235
  time_this_iter_s: 8.344346761703491
  time_total_s: 5790.4600241184235
  timestamp: 1594861812
  timesteps_since_restore: 3330000
  timesteps_this_iter: 5000
  timesteps_total: 3330000
  training_iteration: 666
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5790 s, 666 iter, 3330000 ts, -708 rew

agent-1: -247.29417294140185
agent-2: -99.273300986244
agent-3: -165.2793735589157
agent-4: -24.527262080459092
agent-5: -94.11997657198918
Extrinsic Rewards:
10
7
4
1
2
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 1
Max Reward: 10
Gini Coefficient: 0.38333333333333336
20:20 Ratio: 10.0
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-10-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -708.0224063090923
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 666
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.855
    dispatch_time_ms: 8.332
    learner:
      cur_lr: 0.001138222054578364
      grad_gnorm: 2.0990817546844482
      policy_entropy: 42.53850555419922
      policy_loss: 0.3235451579093933
      var_gnorm: 26.332305908203125
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 6.504767894744873
    num_steps_sampled: 3335000
    num_steps_trained: 3335000
    wait_time_ms: 69.612
  iterations_since_restore: 667
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5798.839808702469
  time_this_iter_s: 8.37978458404541
  time_total_s: 5798.839808702469
  timestamp: 1594861821
  timesteps_since_restore: 3335000
  timesteps_this_iter: 5000
  timesteps_total: 3335000
  training_iteration: 667
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5798 s, 667 iter, 3335000 ts, -708 rew

agent-1: -84.14151578476759
agent-2: -19.56746885641953
agent-3: -226.9887690074451
agent-4: -116.94648311772232
agent-5: -198.72469508722432
Extrinsic Rewards:
7
1
9
4
12
Sum Reward: 33
Avg Reward: 6.6
Min Reward: 1
Max Reward: 12
Gini Coefficient: 0.32727272727272727
20:20 Ratio: 12.0
Max-min Ratio: 12.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-10-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -708.1372572632854
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 667
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.789
    dispatch_time_ms: 7.237
    learner:
      cur_lr: 0.001137888990342617
      grad_gnorm: 19.760669708251953
      policy_entropy: 49.73978042602539
      policy_loss: -3.2517974376678467
      var_gnorm: 26.330408096313477
      vf_explained_var: 0.0
      vf_loss: 3.2097361087799072
    num_steps_sampled: 3340000
    num_steps_trained: 3340000
    wait_time_ms: 75.552
  iterations_since_restore: 668
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5807.203652858734
  time_this_iter_s: 8.363844156265259
  time_total_s: 5807.203652858734
  timestamp: 1594861829
  timesteps_since_restore: 3340000
  timesteps_this_iter: 5000
  timesteps_total: 3340000
  training_iteration: 668
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5807 s, 668 iter, 3340000 ts, -708 rew

agent-1: -30.800072539389404
agent-2: -239.520508951356
agent-3: -160.75530422402727
agent-4: -57.35961089211531
agent-5: -173.83179504418626
Extrinsic Rewards:
2
7
5
3
7
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 2
Max Reward: 7
Gini Coefficient: 0.23333333333333334
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-10-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -708.2414601347405
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 668
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.536
    dispatch_time_ms: 6.162
    learner:
      cur_lr: 0.001137556042522192
      grad_gnorm: 8.51164436340332
      policy_entropy: 52.11651611328125
      policy_loss: 1.3678114414215088
      var_gnorm: 26.339160919189453
      vf_explained_var: 0.0
      vf_loss: 4.353878498077393
    num_steps_sampled: 3345000
    num_steps_trained: 3345000
    wait_time_ms: 73.618
  iterations_since_restore: 669
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5815.605648994446
  time_this_iter_s: 8.40199613571167
  time_total_s: 5815.605648994446
  timestamp: 1594861837
  timesteps_since_restore: 3345000
  timesteps_this_iter: 5000
  timesteps_total: 3345000
  training_iteration: 669
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5815 s, 669 iter, 3345000 ts, -708 rew

agent-1: -84.02822378738522
agent-2: -70.40799690263069
agent-3: -223.8988862004466
agent-4: -202.96025980913447
agent-5: -109.82137717280594
Extrinsic Rewards:
4
4
6
6
2
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 2
Max Reward: 6
Gini Coefficient: 0.18181818181818182
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-10-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -709.912526984537
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 669
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.689
    dispatch_time_ms: 5.828
    learner:
      cur_lr: 0.0011372229782864451
      grad_gnorm: 40.0
      policy_entropy: 56.42263412475586
      policy_loss: 12.052444458007812
      var_gnorm: 26.348012924194336
      vf_explained_var: 0.0
      vf_loss: 17.350614547729492
    num_steps_sampled: 3350000
    num_steps_trained: 3350000
    wait_time_ms: 76.134
  iterations_since_restore: 670
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5824.048276424408
  time_this_iter_s: 8.442627429962158
  time_total_s: 5824.048276424408
  timestamp: 1594861846
  timesteps_since_restore: 3350000
  timesteps_this_iter: 5000
  timesteps_total: 3350000
  training_iteration: 670
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5824 s, 670 iter, 3350000 ts, -710 rew

agent-1: -77.7763935283339
agent-2: -181.47701666553075
agent-3: -172.69073647019107
agent-4: -215.47626443990393
agent-5: -59.11437178955492
Extrinsic Rewards:
2
4
4
8
1
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.3368421052631579
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-10-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -709.2603759691332
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 670
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.924
    dispatch_time_ms: 8.822
    learner:
      cur_lr: 0.00113689003046602
      grad_gnorm: 3.591402769088745
      policy_entropy: 57.81269836425781
      policy_loss: 3.205963134765625
      var_gnorm: 26.338359832763672
      vf_explained_var: 0.0
      vf_loss: 4.523992538452148
    num_steps_sampled: 3355000
    num_steps_trained: 3355000
    wait_time_ms: 72.14
  iterations_since_restore: 671
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5832.3958559036255
  time_this_iter_s: 8.34757947921753
  time_total_s: 5832.3958559036255
  timestamp: 1594861854
  timesteps_since_restore: 3355000
  timesteps_this_iter: 5000
  timesteps_total: 3355000
  training_iteration: 671
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5832 s, 671 iter, 3355000 ts, -709 rew

agent-1: -58.49669642610362
agent-2: -134.5491409190096
agent-3: -251.83554745105465
agent-4: -94.85705344477354
agent-5: -107.04183744982673
Extrinsic Rewards:
3
5
12
2
3
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 2
Max Reward: 12
Gini Coefficient: 0.352
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-11-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -709.2014097281118
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 671
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.72
    dispatch_time_ms: 6.814
    learner:
      cur_lr: 0.0011365569662302732
      grad_gnorm: 14.037435531616211
      policy_entropy: 54.4798469543457
      policy_loss: -0.48139306902885437
      var_gnorm: 26.33989715576172
      vf_explained_var: 0.0
      vf_loss: 3.8288440704345703
    num_steps_sampled: 3360000
    num_steps_trained: 3360000
    wait_time_ms: 70.696
  iterations_since_restore: 672
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5840.712970018387
  time_this_iter_s: 8.317114114761353
  time_total_s: 5840.712970018387
  timestamp: 1594861863
  timesteps_since_restore: 3360000
  timesteps_this_iter: 5000
  timesteps_total: 3360000
  training_iteration: 672
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5840 s, 672 iter, 3360000 ts, -709 rew

agent-1: -59.719521478894706
agent-2: -111.36681549020457
agent-3: -230.2293422331599
agent-4: -109.77479936584271
agent-5: -191.00459363172627
Extrinsic Rewards:
2
1
8
3
5
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.35789473684210527
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-11-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -709.8828609638264
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 672
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.827
    dispatch_time_ms: 40.291
    learner:
      cur_lr: 0.0011362240184098482
      grad_gnorm: 16.250398635864258
      policy_entropy: 51.094810485839844
      policy_loss: -5.55966329574585
      var_gnorm: 26.32147216796875
      vf_explained_var: 0.0
      vf_loss: 5.60232400894165
    num_steps_sampled: 3365000
    num_steps_trained: 3365000
    wait_time_ms: 58.19
  iterations_since_restore: 673
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5849.393007993698
  time_this_iter_s: 8.68003797531128
  time_total_s: 5849.393007993698
  timestamp: 1594861871
  timesteps_since_restore: 3365000
  timesteps_this_iter: 5000
  timesteps_total: 3365000
  training_iteration: 673
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5849 s, 673 iter, 3365000 ts, -710 rew

agent-1: -120.99276068990402
agent-2: -27.128177613035714
agent-3: -133.1293584857204
agent-4: -102.39237036199356
agent-5: -274.80990614164796
Extrinsic Rewards:
3
1
0
5
14
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 0
Max Reward: 14
Gini Coefficient: 0.5565217391304348
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-11-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -708.0275973536249
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 673
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.864
    dispatch_time_ms: 27.543
    learner:
      cur_lr: 0.0011358909541741014
      grad_gnorm: 31.66839027404785
      policy_entropy: 55.80419921875
      policy_loss: -13.316601753234863
      var_gnorm: 26.40105438232422
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 5.667294502258301
    num_steps_sampled: 3370000
    num_steps_trained: 3370000
    wait_time_ms: 50.948
  iterations_since_restore: 674
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5858.219959497452
  time_this_iter_s: 8.826951503753662
  time_total_s: 5858.219959497452
  timestamp: 1594861880
  timesteps_since_restore: 3370000
  timesteps_this_iter: 5000
  timesteps_total: 3370000
  training_iteration: 674
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5858 s, 674 iter, 3370000 ts, -708 rew

agent-1: -124.28829392652645
agent-2: -120.74449336658978
agent-3: -213.69936073135318
agent-4: -221.91166775441695
agent-5: -145.91479505628635
Extrinsic Rewards:
2
3
4
8
0
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.4235294117647059
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-11-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -709.4425507295432
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 674
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.307
    dispatch_time_ms: 41.124
    learner:
      cur_lr: 0.0011355580063536763
      grad_gnorm: 13.673284530639648
      policy_entropy: 58.71358871459961
      policy_loss: 9.216904640197754
      var_gnorm: 26.340909957885742
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 10.546160697937012
    num_steps_sampled: 3375000
    num_steps_trained: 3375000
    wait_time_ms: 48.089
  iterations_since_restore: 675
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5867.092393159866
  time_this_iter_s: 8.87243366241455
  time_total_s: 5867.092393159866
  timestamp: 1594861889
  timesteps_since_restore: 3375000
  timesteps_this_iter: 5000
  timesteps_total: 3375000
  training_iteration: 675
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5867 s, 675 iter, 3375000 ts, -709 rew

agent-1: -186.24074067292304
agent-2: -35.67055817329116
agent-3: -24.95611122444466
agent-4: -221.4762056579146
agent-5: -95.79593615269557
Extrinsic Rewards:
11
5
3
9
17
Sum Reward: 45
Avg Reward: 9.0
Min Reward: 3
Max Reward: 17
Gini Coefficient: 0.3022222222222222
20:20 Ratio: 5.666666666666667
Max-min Ratio: 5.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-11-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -708.3665065097044
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 675
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.014
    dispatch_time_ms: 27.139
    learner:
      cur_lr: 0.0011352249421179295
      grad_gnorm: 30.455793380737305
      policy_entropy: 56.2678108215332
      policy_loss: 9.324159622192383
      var_gnorm: 26.315107345581055
      vf_explained_var: 0.0
      vf_loss: 6.179858207702637
    num_steps_sampled: 3380000
    num_steps_trained: 3380000
    wait_time_ms: 61.739
  iterations_since_restore: 676
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5875.9363052845
  time_this_iter_s: 8.843912124633789
  time_total_s: 5875.9363052845
  timestamp: 1594861898
  timesteps_since_restore: 3380000
  timesteps_this_iter: 5000
  timesteps_total: 3380000
  training_iteration: 676
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5875 s, 676 iter, 3380000 ts, -708 rew

agent-1: -43.07072148527627
agent-2: -277.14056647440964
agent-3: -131.35583748310435
agent-4: -33.097557503047135
agent-5: -20.934692980975328
Extrinsic Rewards:
2
8
7
2
1
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.38
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-11-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -705.3721589396338
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 676
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.099
    dispatch_time_ms: 24.462
    learner:
      cur_lr: 0.0011348919942975044
      grad_gnorm: 15.324716567993164
      policy_entropy: 45.53544998168945
      policy_loss: -1.6772236824035645
      var_gnorm: 26.32907485961914
      vf_explained_var: 0.0
      vf_loss: 6.841236114501953
    num_steps_sampled: 3385000
    num_steps_trained: 3385000
    wait_time_ms: 59.279
  iterations_since_restore: 677
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5884.782435655594
  time_this_iter_s: 8.84613037109375
  time_total_s: 5884.782435655594
  timestamp: 1594861907
  timesteps_since_restore: 3385000
  timesteps_this_iter: 5000
  timesteps_total: 3385000
  training_iteration: 677
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5884 s, 677 iter, 3385000 ts, -705 rew

agent-1: -243.35194788047764
agent-2: -33.16552216150652
agent-3: -111.51314602873992
agent-4: -22.964351415422307
agent-5: -216.14084987147936
Extrinsic Rewards:
9
1
1
1
8
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.46
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-11-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -705.4748252900404
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 677
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.519
    dispatch_time_ms: 21.771
    learner:
      cur_lr: 0.0011345590464770794
      grad_gnorm: 27.326704025268555
      policy_entropy: 40.45827102661133
      policy_loss: -7.440436840057373
      var_gnorm: 26.334232330322266
      vf_explained_var: 0.0
      vf_loss: 6.726909637451172
    num_steps_sampled: 3390000
    num_steps_trained: 3390000
    wait_time_ms: 63.827
  iterations_since_restore: 678
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5893.645702123642
  time_this_iter_s: 8.863266468048096
  time_total_s: 5893.645702123642
  timestamp: 1594861916
  timesteps_since_restore: 3390000
  timesteps_this_iter: 5000
  timesteps_total: 3390000
  training_iteration: 678
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5893 s, 678 iter, 3390000 ts, -705 rew

agent-1: -31.088277906899595
agent-2: -65.45978163968564
agent-3: -138.31533556989794
agent-4: -219.4325261881788
agent-5: -209.23880179665935
Extrinsic Rewards:
3
5
2
10
5
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 2
Max Reward: 10
Gini Coefficient: 0.288
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-12-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -706.0927590643606
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 678
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.714
    dispatch_time_ms: 26.698
    learner:
      cur_lr: 0.0011342259822413325
      grad_gnorm: 9.567947387695312
      policy_entropy: 39.13195037841797
      policy_loss: -2.4038000106811523
      var_gnorm: 26.335792541503906
      vf_explained_var: 0.0
      vf_loss: 2.5017571449279785
    num_steps_sampled: 3395000
    num_steps_trained: 3395000
    wait_time_ms: 60.866
  iterations_since_restore: 679
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5902.565923452377
  time_this_iter_s: 8.920221328735352
  time_total_s: 5902.565923452377
  timestamp: 1594861925
  timesteps_since_restore: 3395000
  timesteps_this_iter: 5000
  timesteps_total: 3395000
  training_iteration: 679
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5902 s, 679 iter, 3395000 ts, -706 rew

agent-1: -98.23387202043868
agent-2: -158.44689902605643
agent-3: -105.99914616462138
agent-4: -116.53909278974182
agent-5: -232.26873801590853
Extrinsic Rewards:
2
5
2
3
6
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 2
Max Reward: 6
Gini Coefficient: 0.24444444444444444
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-12-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -707.3618452757111
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 679
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.736
    dispatch_time_ms: 6.635
    learner:
      cur_lr: 0.0011338930344209075
      grad_gnorm: 40.0
      policy_entropy: 37.761474609375
      policy_loss: 28.470657348632812
      var_gnorm: 26.339012145996094
      vf_explained_var: 0.0
      vf_loss: 23.525571823120117
    num_steps_sampled: 3400000
    num_steps_trained: 3400000
    wait_time_ms: 72.16
  iterations_since_restore: 680
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5910.942265987396
  time_this_iter_s: 8.376342535018921
  time_total_s: 5910.942265987396
  timestamp: 1594861933
  timesteps_since_restore: 3400000
  timesteps_this_iter: 5000
  timesteps_total: 3400000
  training_iteration: 680
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5910 s, 680 iter, 3400000 ts, -707 rew

agent-1: -82.93890930760884
agent-2: -21.941940910668016
agent-3: -212.93051937024384
agent-4: -210.24580801056155
agent-5: -117.28060501710667
Extrinsic Rewards:
6
3
8
8
10
Sum Reward: 35
Avg Reward: 7.0
Min Reward: 3
Max Reward: 10
Gini Coefficient: 0.18285714285714286
20:20 Ratio: 3.3333333333333335
Max-min Ratio: 3.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-12-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -707.4555169647388
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 680
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.049
    dispatch_time_ms: 6.875
    learner:
      cur_lr: 0.0011335599701851606
      grad_gnorm: 6.760928153991699
      policy_entropy: 38.359886169433594
      policy_loss: -0.37986499071121216
      var_gnorm: 26.3389949798584
      vf_explained_var: 0.0
      vf_loss: 3.293156623840332
    num_steps_sampled: 3405000
    num_steps_trained: 3405000
    wait_time_ms: 72.607
  iterations_since_restore: 681
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5919.320920944214
  time_this_iter_s: 8.378654956817627
  time_total_s: 5919.320920944214
  timestamp: 1594861942
  timesteps_since_restore: 3405000
  timesteps_this_iter: 5000
  timesteps_total: 3405000
  training_iteration: 681
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5919 s, 681 iter, 3405000 ts, -707 rew

agent-1: -169.59445306000126
agent-2: -88.14486376060987
agent-3: -171.9394276788814
agent-4: -91.85898769244533
agent-5: -168.91729989986456
Extrinsic Rewards:
13
2
14
9
13
Sum Reward: 51
Avg Reward: 10.2
Min Reward: 2
Max Reward: 14
Gini Coefficient: 0.2196078431372549
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-12-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -698.6147702093629
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 681
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.886
    dispatch_time_ms: 7.138
    learner:
      cur_lr: 0.0011332270223647356
      grad_gnorm: 39.999996185302734
      policy_entropy: 45.49836349487305
      policy_loss: 30.985437393188477
      var_gnorm: 26.352371215820312
      vf_explained_var: 0.0
      vf_loss: 6.83322811126709
    num_steps_sampled: 3410000
    num_steps_trained: 3410000
    wait_time_ms: 71.834
  iterations_since_restore: 682
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5927.713907003403
  time_this_iter_s: 8.392986059188843
  time_total_s: 5927.713907003403
  timestamp: 1594861950
  timesteps_since_restore: 3410000
  timesteps_this_iter: 5000
  timesteps_total: 3410000
  training_iteration: 682
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5927 s, 682 iter, 3410000 ts, -699 rew

agent-1: -173.5921761662721
agent-2: -200.9819787556059
agent-3: -64.77538644272893
agent-4: -91.01106711588034
agent-5: -162.45503664697156
Extrinsic Rewards:
1
7
4
3
7
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 1
Max Reward: 7
Gini Coefficient: 0.2909090909090909
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-12-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -693.1508818811002
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 682
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.117
    dispatch_time_ms: 6.928
    learner:
      cur_lr: 0.0011328939581289887
      grad_gnorm: 13.672966003417969
      policy_entropy: 51.16315841674805
      policy_loss: 2.9651098251342773
      var_gnorm: 26.338232040405273
      vf_explained_var: 0.0
      vf_loss: 7.20084810256958
    num_steps_sampled: 3415000
    num_steps_trained: 3415000
    wait_time_ms: 73.286
  iterations_since_restore: 683
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5936.131344795227
  time_this_iter_s: 8.41743779182434
  time_total_s: 5936.131344795227
  timestamp: 1594861959
  timesteps_since_restore: 3415000
  timesteps_this_iter: 5000
  timesteps_total: 3415000
  training_iteration: 683
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5936 s, 683 iter, 3415000 ts, -693 rew

W0715 21:12:46.187225 22529 client_connection.cc:255] [worker]ProcessMessage with type 8 took 121 ms.
W0715 21:12:46.194065 22529 node_manager.cc:250] Last heartbeat was sent 3305 ms ago 
agent-1: -229.69070847937897
agent-2: -191.94088462324234
agent-3: -49.328665163252445
agent-4: -94.77144681771988
agent-5: -124.37269378961375
Extrinsic Rewards:
9
4
1
3
3
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.34
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-12-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -693.6282566047597
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 683
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.852
    dispatch_time_ms: 9.799
    learner:
      cur_lr: 0.0011325610103085637
      grad_gnorm: 39.999996185302734
      policy_entropy: 51.74327850341797
      policy_loss: -3.216262102127075
      var_gnorm: 26.369140625
      vf_explained_var: 0.0
      vf_loss: 8.469106674194336
    num_steps_sampled: 3420000
    num_steps_trained: 3420000
    wait_time_ms: 70.256
  iterations_since_restore: 684
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5946.9769551754
  time_this_iter_s: 10.84561038017273
  time_total_s: 5946.9769551754
  timestamp: 1594861969
  timesteps_since_restore: 3420000
  timesteps_this_iter: 5000
  timesteps_total: 3420000
  training_iteration: 684
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5946 s, 684 iter, 3420000 ts, -694 rew

agent-1: -203.14152983641196
agent-2: -96.20661442051939
agent-3: -240.14591090176452
agent-4: -89.96200706694498
agent-5: -140.77542056015747
Extrinsic Rewards:
9
3
3
2
0
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.4470588235294118
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-12-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -694.3145164354364
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 684
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.846
    dispatch_time_ms: 5.928
    learner:
      cur_lr: 0.0011322279460728168
      grad_gnorm: 7.523412227630615
      policy_entropy: 58.48362350463867
      policy_loss: 0.8536482453346252
      var_gnorm: 26.326181411743164
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 6.920351505279541
    num_steps_sampled: 3425000
    num_steps_trained: 3425000
    wait_time_ms: 78.472
  iterations_since_restore: 685
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5955.352435350418
  time_this_iter_s: 8.37548017501831
  time_total_s: 5955.352435350418
  timestamp: 1594861978
  timesteps_since_restore: 3425000
  timesteps_this_iter: 5000
  timesteps_total: 3425000
  training_iteration: 685
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5955 s, 685 iter, 3425000 ts, -694 rew

agent-1: -123.6197712949272
agent-2: -43.71475871691248
agent-3: -253.90521410455403
agent-4: -160.12928852270883
agent-5: -33.03472073433815
Extrinsic Rewards:
9
1
11
6
2
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 1
Max Reward: 11
Gini Coefficient: 0.3724137931034483
20:20 Ratio: 11.0
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-13-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -694.47440587026
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 685
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.507
    dispatch_time_ms: 7.04
    learner:
      cur_lr: 0.0011318949982523918
      grad_gnorm: 29.006040573120117
      policy_entropy: 56.64082336425781
      policy_loss: -9.850919723510742
      var_gnorm: 26.356630325317383
      vf_explained_var: 0.0
      vf_loss: 9.871294975280762
    num_steps_sampled: 3430000
    num_steps_trained: 3430000
    wait_time_ms: 73.117
  iterations_since_restore: 686
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5963.658363580704
  time_this_iter_s: 8.305928230285645
  time_total_s: 5963.658363580704
  timestamp: 1594861986
  timesteps_since_restore: 3430000
  timesteps_this_iter: 5000
  timesteps_total: 3430000
  training_iteration: 686
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5963 s, 686 iter, 3430000 ts, -694 rew

agent-1: -152.35241600618545
agent-2: -148.02227668742964
agent-3: -269.40430696421294
agent-4: -135.39255112342735
agent-5: -46.17819983466747
Extrinsic Rewards:
0
3
9
2
1
Sum Reward: 15
Avg Reward: 3.0
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.5333333333333333
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-13-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -695.2159884686548
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 686
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.683
    dispatch_time_ms: 7.451
    learner:
      cur_lr: 0.0011315620504319668
      grad_gnorm: 12.029282569885254
      policy_entropy: 57.843074798583984
      policy_loss: -2.4221606254577637
      var_gnorm: 26.325336456298828
      vf_explained_var: 0.0
      vf_loss: 6.109655857086182
    num_steps_sampled: 3435000
    num_steps_trained: 3435000
    wait_time_ms: 74.572
  iterations_since_restore: 687
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5972.010936498642
  time_this_iter_s: 8.352572917938232
  time_total_s: 5972.010936498642
  timestamp: 1594861995
  timesteps_since_restore: 3435000
  timesteps_this_iter: 5000
  timesteps_total: 3435000
  training_iteration: 687
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5972 s, 687 iter, 3435000 ts, -695 rew

agent-1: -39.876438180623474
agent-2: -18.024655620051966
agent-3: -233.02283436152095
agent-4: -64.20074420137284
agent-5: -230.6749888500418
Extrinsic Rewards:
4
2
12
3
5
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 2
Max Reward: 12
Gini Coefficient: 0.3384615384615385
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-13-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -694.9065440386212
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 687
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.003
    dispatch_time_ms: 8.865
    learner:
      cur_lr: 0.00113122898619622
      grad_gnorm: 30.858301162719727
      policy_entropy: 50.18157958984375
      policy_loss: 1.5910217761993408
      var_gnorm: 26.350608825683594
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 9.930206298828125
    num_steps_sampled: 3440000
    num_steps_trained: 3440000
    wait_time_ms: 71.14
  iterations_since_restore: 688
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5990.26396894455
  time_this_iter_s: 18.253032445907593
  time_total_s: 5990.26396894455
  timestamp: 1594862013
  timesteps_since_restore: 3440000
  timesteps_this_iter: 5000
  timesteps_total: 3440000
  training_iteration: 688
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5990 s, 688 iter, 3440000 ts, -695 rew

agent-1: -186.07783959238358
agent-2: -143.80059471791725
agent-3: -117.96113238245294
agent-4: -109.32771318247262
agent-5: -246.12650575616541
Extrinsic Rewards:
6
0
3
3
5
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 0
Max Reward: 6
Gini Coefficient: 0.32941176470588235
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-13-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -448.23548572846266
  episode_reward_mean: -697.2183472924012
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 688
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.832
    dispatch_time_ms: 6.831
    learner:
      cur_lr: 0.0011308960383757949
      grad_gnorm: 20.09133529663086
      policy_entropy: 45.921363830566406
      policy_loss: 2.5768208503723145
      var_gnorm: 26.347578048706055
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 4.413490295410156
    num_steps_sampled: 3445000
    num_steps_trained: 3445000
    wait_time_ms: 74.783
  iterations_since_restore: 689
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 5998.620899438858
  time_this_iter_s: 8.356930494308472
  time_total_s: 5998.620899438858
  timestamp: 1594862021
  timesteps_since_restore: 3445000
  timesteps_this_iter: 5000
  timesteps_total: 3445000
  training_iteration: 689
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 5998 s, 689 iter, 3445000 ts, -697 rew

agent-1: -173.74504570110653
agent-2: -168.8067639953561
agent-3: -210.0415293742328
agent-4: -115.09802235222669
agent-5: -114.92951526956712
Extrinsic Rewards:
5
15
9
8
0
Sum Reward: 37
Avg Reward: 7.4
Min Reward: 0
Max Reward: 15
Gini Coefficient: 0.3675675675675676
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-13-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -505.59937592678995
  episode_reward_mean: -700.5622012020411
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 689
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.979
    dispatch_time_ms: 7.987
    learner:
      cur_lr: 0.001130562974140048
      grad_gnorm: 40.0
      policy_entropy: 61.03950500488281
      policy_loss: 42.91482925415039
      var_gnorm: 26.38763999938965
      vf_explained_var: 0.0
      vf_loss: 29.492862701416016
    num_steps_sampled: 3450000
    num_steps_trained: 3450000
    wait_time_ms: 70.917
  iterations_since_restore: 690
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6006.9715077877045
  time_this_iter_s: 8.350608348846436
  time_total_s: 6006.9715077877045
  timestamp: 1594862030
  timesteps_since_restore: 3450000
  timesteps_this_iter: 5000
  timesteps_total: 3450000
  training_iteration: 690
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6006 s, 690 iter, 3450000 ts, -701 rew

agent-1: -88.70444135584972
agent-2: -191.80824880569944
agent-3: -124.78474173211704
agent-4: -220.43878685412093
agent-5: -56.39597559946655
Extrinsic Rewards:
6
8
4
6
1
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.256
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-13-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -505.59937592678995
  episode_reward_mean: -702.1194072066057
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 690
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.998
    dispatch_time_ms: 7.294
    learner:
      cur_lr: 0.001130230026319623
      grad_gnorm: 12.216754913330078
      policy_entropy: 61.4374885559082
      policy_loss: -0.3960440456867218
      var_gnorm: 26.351228713989258
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 5.823082447052002
    num_steps_sampled: 3455000
    num_steps_trained: 3455000
    wait_time_ms: 75.156
  iterations_since_restore: 691
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6015.303156852722
  time_this_iter_s: 8.3316490650177
  time_total_s: 6015.303156852722
  timestamp: 1594862038
  timesteps_since_restore: 3455000
  timesteps_this_iter: 5000
  timesteps_total: 3455000
  training_iteration: 691
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6015 s, 691 iter, 3455000 ts, -702 rew

agent-1: -207.5701608438755
agent-2: -53.606531507172704
agent-3: -207.98938878131105
agent-4: -62.16059642357368
agent-5: -146.53149368284136
Extrinsic Rewards:
13
2
9
3
1
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 1
Max Reward: 13
Gini Coefficient: 0.44285714285714284
20:20 Ratio: 13.0
Max-min Ratio: 13.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-14-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -505.59937592678995
  episode_reward_mean: -701.5258494240509
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 691
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.873
    dispatch_time_ms: 5.749
    learner:
      cur_lr: 0.0011298969620838761
      grad_gnorm: 34.882938385009766
      policy_entropy: 61.307430267333984
      policy_loss: -17.912466049194336
      var_gnorm: 26.382225036621094
      vf_explained_var: 0.0
      vf_loss: 5.989973068237305
    num_steps_sampled: 3460000
    num_steps_trained: 3460000
    wait_time_ms: 73.907
  iterations_since_restore: 692
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6023.725573062897
  time_this_iter_s: 8.42241621017456
  time_total_s: 6023.725573062897
  timestamp: 1594862046
  timesteps_since_restore: 3460000
  timesteps_this_iter: 5000
  timesteps_total: 3460000
  training_iteration: 692
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6023 s, 692 iter, 3460000 ts, -702 rew

agent-1: -193.57301836370033
agent-2: -123.77773465725285
agent-3: -132.59163708320284
agent-4: -141.7580384214864
agent-5: -216.55904119152396
Extrinsic Rewards:
4
8
0
7
7
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.2923076923076923
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-14-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -505.59937592678995
  episode_reward_mean: -701.7278972390659
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 692
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.94
    dispatch_time_ms: 7.452
    learner:
      cur_lr: 0.001129564014263451
      grad_gnorm: 17.59480857849121
      policy_entropy: 60.33353805541992
      policy_loss: -6.995611190795898
      var_gnorm: 26.33766746520996
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 6.61899995803833
    num_steps_sampled: 3465000
    num_steps_trained: 3465000
    wait_time_ms: 72.79
  iterations_since_restore: 693
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6032.077803611755
  time_this_iter_s: 8.352230548858643
  time_total_s: 6032.077803611755
  timestamp: 1594862055
  timesteps_since_restore: 3465000
  timesteps_this_iter: 5000
  timesteps_total: 3465000
  training_iteration: 693
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6032 s, 693 iter, 3465000 ts, -702 rew

agent-1: -260.4617855357155
agent-2: -146.5536043947104
agent-3: -170.9291336458494
agent-4: -140.73165925324992
agent-5: -20.748777819516665
Extrinsic Rewards:
9
5
7
0
1
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.43636363636363634
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-14-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -505.59937592678995
  episode_reward_mean: -701.0178718076546
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 693
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.81
    dispatch_time_ms: 7.089
    learner:
      cur_lr: 0.0011292309500277042
      grad_gnorm: 34.38955307006836
      policy_entropy: 55.89012145996094
      policy_loss: 3.7763233184814453
      var_gnorm: 26.36471939086914
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 6.067469596862793
    num_steps_sampled: 3470000
    num_steps_trained: 3470000
    wait_time_ms: 72.796
  iterations_since_restore: 694
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6040.4695956707
  time_this_iter_s: 8.391792058944702
  time_total_s: 6040.4695956707
  timestamp: 1594862063
  timesteps_since_restore: 3470000
  timesteps_this_iter: 5000
  timesteps_total: 3470000
  training_iteration: 694
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6040 s, 694 iter, 3470000 ts, -701 rew

agent-1: -197.269509998946
agent-2: -133.3737953343043
agent-3: -75.63437815468774
agent-4: -22.324273861339435
agent-5: -232.22696385109117
Extrinsic Rewards:
7
6
2
1
4
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 1
Max Reward: 7
Gini Coefficient: 0.32
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-14-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -505.59937592678995
  episode_reward_mean: -701.3706975176849
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 694
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.964
    dispatch_time_ms: 7.782
    learner:
      cur_lr: 0.0011288980022072792
      grad_gnorm: 21.612905502319336
      policy_entropy: 54.61467742919922
      policy_loss: -2.234764575958252
      var_gnorm: 26.350759506225586
      vf_explained_var: 0.0
      vf_loss: 5.841139793395996
    num_steps_sampled: 3475000
    num_steps_trained: 3475000
    wait_time_ms: 73.951
  iterations_since_restore: 695
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6048.785036325455
  time_this_iter_s: 8.315440654754639
  time_total_s: 6048.785036325455
  timestamp: 1594862072
  timesteps_since_restore: 3475000
  timesteps_this_iter: 5000
  timesteps_total: 3475000
  training_iteration: 695
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6048 s, 695 iter, 3475000 ts, -701 rew

agent-1: -224.1983564716245
agent-2: -199.61351577308915
agent-3: -113.07031015077696
agent-4: -157.55746123161833
agent-5: -146.9943462423316
Extrinsic Rewards:
7
5
3
3
0
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.35555555555555557
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-14-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -505.59937592678995
  episode_reward_mean: -703.2435472646415
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 695
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.646
    dispatch_time_ms: 6.446
    learner:
      cur_lr: 0.0011285650543868542
      grad_gnorm: 33.68938446044922
      policy_entropy: 54.254093170166016
      policy_loss: 8.780121803283691
      var_gnorm: 26.431793212890625
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 8.522821426391602
    num_steps_sampled: 3480000
    num_steps_trained: 3480000
    wait_time_ms: 73.316
  iterations_since_restore: 696
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6057.114861965179
  time_this_iter_s: 8.329825639724731
  time_total_s: 6057.114861965179
  timestamp: 1594862080
  timesteps_since_restore: 3480000
  timesteps_this_iter: 5000
  timesteps_total: 3480000
  training_iteration: 696
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6057 s, 696 iter, 3480000 ts, -703 rew

agent-1: -113.2738346815666
agent-2: -143.23188410475814
agent-3: -231.05137207163716
agent-4: -148.00102208256956
agent-5: -187.52649541319974
Extrinsic Rewards:
4
0
3
5
5
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 0
Max Reward: 5
Gini Coefficient: 0.2823529411764706
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-14-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -505.59937592678995
  episode_reward_mean: -704.5688528559123
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 696
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.757
    dispatch_time_ms: 9.027
    learner:
      cur_lr: 0.0011282319901511073
      grad_gnorm: 27.64954376220703
      policy_entropy: 58.81537628173828
      policy_loss: -11.307832717895508
      var_gnorm: 26.365522384643555
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 3.6064281463623047
    num_steps_sampled: 3485000
    num_steps_trained: 3485000
    wait_time_ms: 70.775
  iterations_since_restore: 697
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6065.399694919586
  time_this_iter_s: 8.284832954406738
  time_total_s: 6065.399694919586
  timestamp: 1594862088
  timesteps_since_restore: 3485000
  timesteps_this_iter: 5000
  timesteps_total: 3485000
  training_iteration: 697
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6065 s, 697 iter, 3485000 ts, -705 rew

agent-1: -144.34128748668567
agent-2: -221.98803031736765
agent-3: -76.79448624075893
agent-4: -191.9472311720589
agent-5: -186.40900927466544
Extrinsic Rewards:
0
9
2
3
5
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.4421052631578947
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-14-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -505.59937592678995
  episode_reward_mean: -706.1300637268013
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 697
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.753
    dispatch_time_ms: 6.792
    learner:
      cur_lr: 0.0011278990423306823
      grad_gnorm: 40.0
      policy_entropy: 59.98876190185547
      policy_loss: 26.075714111328125
      var_gnorm: 26.426441192626953
      vf_explained_var: 0.0
      vf_loss: 12.019927978515625
    num_steps_sampled: 3490000
    num_steps_trained: 3490000
    wait_time_ms: 72.392
  iterations_since_restore: 698
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6073.8202612400055
  time_this_iter_s: 8.420566320419312
  time_total_s: 6073.8202612400055
  timestamp: 1594862097
  timesteps_since_restore: 3490000
  timesteps_this_iter: 5000
  timesteps_total: 3490000
  training_iteration: 698
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6073 s, 698 iter, 3490000 ts, -706 rew

agent-1: -137.30636136436098
agent-2: -134.29531340747147
agent-3: -146.96962605785413
agent-4: -93.4142572634123
agent-5: -257.5715486063995
Extrinsic Rewards:
0
3
5
2
11
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 0
Max Reward: 11
Gini Coefficient: 0.47619047619047616
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-15-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -505.59937592678995
  episode_reward_mean: -706.5354012481606
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 698
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.795
    dispatch_time_ms: 7.967
    learner:
      cur_lr: 0.0011275659780949354
      grad_gnorm: 12.410155296325684
      policy_entropy: 56.013240814208984
      policy_loss: 4.339170455932617
      var_gnorm: 26.359458923339844
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 6.729313373565674
    num_steps_sampled: 3495000
    num_steps_trained: 3495000
    wait_time_ms: 73.766
  iterations_since_restore: 699
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6082.193135738373
  time_this_iter_s: 8.37287449836731
  time_total_s: 6082.193135738373
  timestamp: 1594862105
  timesteps_since_restore: 3495000
  timesteps_this_iter: 5000
  timesteps_total: 3495000
  training_iteration: 699
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6082 s, 699 iter, 3495000 ts, -707 rew

agent-1: -43.18920945967216
agent-2: -54.84966878401595
agent-3: -220.82991909155263
agent-4: -171.78799790069786
agent-5: -171.09851248202787
Extrinsic Rewards:
4
3
10
5
3
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 3
Max Reward: 10
Gini Coefficient: 0.256
20:20 Ratio: 3.3333333333333335
Max-min Ratio: 3.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-15-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -505.59937592678995
  episode_reward_mean: -707.4885936524463
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 699
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.868
    dispatch_time_ms: 7.681
    learner:
      cur_lr: 0.0011272330302745104
      grad_gnorm: 32.05278778076172
      policy_entropy: 60.538551330566406
      policy_loss: -13.471468925476074
      var_gnorm: 26.380611419677734
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 6.730894565582275
    num_steps_sampled: 3500000
    num_steps_trained: 3500000
    wait_time_ms: 72.765
  iterations_since_restore: 700
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6090.499824047089
  time_this_iter_s: 8.30668830871582
  time_total_s: 6090.499824047089
  timestamp: 1594862113
  timesteps_since_restore: 3500000
  timesteps_this_iter: 5000
  timesteps_total: 3500000
  training_iteration: 700
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6090 s, 700 iter, 3500000 ts, -707 rew

agent-1: -175.55639033254656
agent-2: -141.60475500916814
agent-3: -244.6340700261134
agent-4: -121.05487160630662
agent-5: -115.97467296990186
Extrinsic Rewards:
5
0
7
5
2
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.35789473684210527
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-15-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -505.59937592678995
  episode_reward_mean: -707.4098337297894
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 700
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.566
    dispatch_time_ms: 8.297
    learner:
      cur_lr: 0.0011268999660387635
      grad_gnorm: 11.448463439941406
      policy_entropy: 53.51438903808594
      policy_loss: 3.941293954849243
      var_gnorm: 26.36135482788086
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 4.4563093185424805
    num_steps_sampled: 3505000
    num_steps_trained: 3505000
    wait_time_ms: 72.425
  iterations_since_restore: 701
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6098.915815830231
  time_this_iter_s: 8.41599178314209
  time_total_s: 6098.915815830231
  timestamp: 1594862122
  timesteps_since_restore: 3505000
  timesteps_this_iter: 5000
  timesteps_total: 3505000
  training_iteration: 701
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6098 s, 701 iter, 3505000 ts, -707 rew

agent-1: -181.09306313255556
agent-2: -60.32867514937594
agent-3: -224.83795197507317
agent-4: -138.13028667000856
agent-5: -73.30458621759622
Extrinsic Rewards:
9
3
10
2
6
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 2
Max Reward: 10
Gini Coefficient: 0.29333333333333333
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-15-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -505.59937592678995
  episode_reward_mean: -706.743068417987
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 701
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.426
    dispatch_time_ms: 5.777
    learner:
      cur_lr: 0.0011265670182183385
      grad_gnorm: 19.093067169189453
      policy_entropy: 52.21611022949219
      policy_loss: 4.623185157775879
      var_gnorm: 26.357467651367188
      vf_explained_var: 0.0
      vf_loss: 4.776992321014404
    num_steps_sampled: 3510000
    num_steps_trained: 3510000
    wait_time_ms: 76.675
  iterations_since_restore: 702
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6107.29018497467
  time_this_iter_s: 8.374369144439697
  time_total_s: 6107.29018497467
  timestamp: 1594862130
  timesteps_since_restore: 3510000
  timesteps_this_iter: 5000
  timesteps_total: 3510000
  training_iteration: 702
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6107 s, 702 iter, 3510000 ts, -707 rew

agent-1: -139.38401276184857
agent-2: -173.09920202335908
agent-3: -94.49818190229401
agent-4: -195.87279014588572
agent-5: -102.01668746270148
Extrinsic Rewards:
7
2
1
5
8
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.33043478260869563
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-15-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -505.59937592678995
  episode_reward_mean: -707.389227008105
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 702
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.095
    dispatch_time_ms: 6.179
    learner:
      cur_lr: 0.0011262339539825916
      grad_gnorm: 5.514901638031006
      policy_entropy: 61.403297424316406
      policy_loss: -0.6368542909622192
      var_gnorm: 26.34621810913086
      vf_explained_var: 0.0
      vf_loss: 4.77340030670166
    num_steps_sampled: 3515000
    num_steps_trained: 3515000
    wait_time_ms: 76.635
  iterations_since_restore: 703
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6115.6913805007935
  time_this_iter_s: 8.401195526123047
  time_total_s: 6115.6913805007935
  timestamp: 1594862139
  timesteps_since_restore: 3515000
  timesteps_this_iter: 5000
  timesteps_total: 3515000
  training_iteration: 703
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6115 s, 703 iter, 3515000 ts, -707 rew

agent-1: -69.68459266559789
agent-2: -146.41928197528208
agent-3: -174.19023223892728
agent-4: -49.03798992234828
agent-5: -234.84724477340245
Extrinsic Rewards:
3
5
7
2
10
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 2
Max Reward: 10
Gini Coefficient: 0.2962962962962963
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-15-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -505.59937592678995
  episode_reward_mean: -707.4434666855968
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 703
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.379
    dispatch_time_ms: 6.918
    learner:
      cur_lr: 0.0011259010061621666
      grad_gnorm: 25.641788482666016
      policy_entropy: 58.37253952026367
      policy_loss: 4.768890857696533
      var_gnorm: 26.34633445739746
      vf_explained_var: 0.0
      vf_loss: 12.244110107421875
    num_steps_sampled: 3520000
    num_steps_trained: 3520000
    wait_time_ms: 73.716
  iterations_since_restore: 704
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6124.046771764755
  time_this_iter_s: 8.355391263961792
  time_total_s: 6124.046771764755
  timestamp: 1594862147
  timesteps_since_restore: 3520000
  timesteps_this_iter: 5000
  timesteps_total: 3520000
  training_iteration: 704
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6124 s, 704 iter, 3520000 ts, -707 rew

agent-1: -81.6648008802365
agent-2: -196.4983731938529
agent-3: -205.79558707659734
agent-4: -49.40101241763421
agent-5: -139.57911938493078
Extrinsic Rewards:
7
11
5
4
4
Sum Reward: 31
Avg Reward: 6.2
Min Reward: 4
Max Reward: 11
Gini Coefficient: 0.21935483870967742
20:20 Ratio: 2.75
Max-min Ratio: 2.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-15-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -505.59937592678995
  episode_reward_mean: -707.6507151929301
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 704
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.659
    dispatch_time_ms: 9.59
    learner:
      cur_lr: 0.0011255679419264197
      grad_gnorm: 40.0
      policy_entropy: 56.172794342041016
      policy_loss: -3.6168248653411865
      var_gnorm: 26.32602882385254
      vf_explained_var: 0.0
      vf_loss: 12.060091972351074
    num_steps_sampled: 3525000
    num_steps_trained: 3525000
    wait_time_ms: 71.477
  iterations_since_restore: 705
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6132.383573293686
  time_this_iter_s: 8.336801528930664
  time_total_s: 6132.383573293686
  timestamp: 1594862155
  timesteps_since_restore: 3525000
  timesteps_this_iter: 5000
  timesteps_total: 3525000
  training_iteration: 705
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6132 s, 705 iter, 3525000 ts, -708 rew

agent-1: -34.0875676077462
agent-2: -37.96040191372943
agent-3: -251.42471689656327
agent-4: -148.16247473461573
agent-5: -244.07660436853388
Extrinsic Rewards:
1
1
9
0
6
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.5411764705882353
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-16-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -505.59937592678995
  episode_reward_mean: -707.2040724480902
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 705
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.795
    dispatch_time_ms: 9.178
    learner:
      cur_lr: 0.0011252349941059947
      grad_gnorm: 23.216663360595703
      policy_entropy: 47.124916076660156
      policy_loss: 7.717950344085693
      var_gnorm: 26.356050491333008
      vf_explained_var: 0.0
      vf_loss: 7.082103252410889
    num_steps_sampled: 3530000
    num_steps_trained: 3530000
    wait_time_ms: 70.939
  iterations_since_restore: 706
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6140.804773807526
  time_this_iter_s: 8.421200513839722
  time_total_s: 6140.804773807526
  timestamp: 1594862164
  timesteps_since_restore: 3530000
  timesteps_this_iter: 5000
  timesteps_total: 3530000
  training_iteration: 706
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6140 s, 706 iter, 3530000 ts, -707 rew

agent-1: -234.99842283609468
agent-2: -58.808958949428856
agent-3: -71.75440785241635
agent-4: -104.90672956582816
agent-5: -123.99479677501176
Extrinsic Rewards:
2
6
7
3
6
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 2
Max Reward: 7
Gini Coefficient: 0.21666666666666667
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-16-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -505.59937592678995
  episode_reward_mean: -706.3077187218883
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 706
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.732
    dispatch_time_ms: 5.908
    learner:
      cur_lr: 0.0011249020462855697
      grad_gnorm: 10.242691040039062
      policy_entropy: 51.28936004638672
      policy_loss: -2.7793807983398438
      var_gnorm: 26.372276306152344
      vf_explained_var: 0.0
      vf_loss: 0.8052162528038025
    num_steps_sampled: 3535000
    num_steps_trained: 3535000
    wait_time_ms: 77.344
  iterations_since_restore: 707
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6149.2024974823
  time_this_iter_s: 8.39772367477417
  time_total_s: 6149.2024974823
  timestamp: 1594862172
  timesteps_since_restore: 3535000
  timesteps_this_iter: 5000
  timesteps_total: 3535000
  training_iteration: 707
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6149 s, 707 iter, 3535000 ts, -706 rew

agent-1: -123.4212086687561
agent-2: -130.8494748760546
agent-3: -157.53642326932038
agent-4: -183.00466333084594
agent-5: -141.24551609479317
Extrinsic Rewards:
5
6
3
5
5
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 3
Max Reward: 6
Gini Coefficient: 0.1
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-16-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -505.59937592678995
  episode_reward_mean: -706.3700910363899
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 707
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.457
    dispatch_time_ms: 29.179
    learner:
      cur_lr: 0.0011245689820498228
      grad_gnorm: 29.343996047973633
      policy_entropy: 53.041419982910156
      policy_loss: 10.678141593933105
      var_gnorm: 26.415800094604492
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 8.791499137878418
    num_steps_sampled: 3540000
    num_steps_trained: 3540000
    wait_time_ms: 57.766
  iterations_since_restore: 708
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6157.801958322525
  time_this_iter_s: 8.59946084022522
  time_total_s: 6157.801958322525
  timestamp: 1594862181
  timesteps_since_restore: 3540000
  timesteps_this_iter: 5000
  timesteps_total: 3540000
  training_iteration: 708
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6157 s, 708 iter, 3540000 ts, -706 rew

agent-1: -176.71166952867435
agent-2: -127.56610463870429
agent-3: -92.4137401213165
agent-4: -179.96058248608955
agent-5: -217.04047747566457
Extrinsic Rewards:
6
0
9
7
9
Sum Reward: 31
Avg Reward: 6.2
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.2709677419354839
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-16-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -505.59937592678995
  episode_reward_mean: -706.9291199658737
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 708
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.826
    dispatch_time_ms: 22.398
    learner:
      cur_lr: 0.0011242360342293978
      grad_gnorm: 29.422119140625
      policy_entropy: 50.389442443847656
      policy_loss: -4.880315780639648
      var_gnorm: 26.350345611572266
      vf_explained_var: 0.0
      vf_loss: 11.046788215637207
    num_steps_sampled: 3545000
    num_steps_trained: 3545000
    wait_time_ms: 71.515
  iterations_since_restore: 709
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6166.620663642883
  time_this_iter_s: 8.818705320358276
  time_total_s: 6166.620663642883
  timestamp: 1594862190
  timesteps_since_restore: 3545000
  timesteps_this_iter: 5000
  timesteps_total: 3545000
  training_iteration: 709
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6166 s, 709 iter, 3545000 ts, -707 rew

agent-1: -106.7930928190607
agent-2: -113.88778726180345
agent-3: -30.604479138282763
agent-4: -26.54349272942615
agent-5: -249.202291598307
Extrinsic Rewards:
5
7
11
5
17
Sum Reward: 45
Avg Reward: 9.0
Min Reward: 5
Max Reward: 17
Gini Coefficient: 0.26666666666666666
20:20 Ratio: 3.4
Max-min Ratio: 3.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-16-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -505.59937592678995
  episode_reward_mean: -704.4451886840538
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 709
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.028
    dispatch_time_ms: 29.969
    learner:
      cur_lr: 0.001123902969993651
      grad_gnorm: 13.655608177185059
      policy_entropy: 47.560367584228516
      policy_loss: -3.4593849182128906
      var_gnorm: 26.335742950439453
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 10.99975299835205
    num_steps_sampled: 3550000
    num_steps_trained: 3550000
    wait_time_ms: 50.651
  iterations_since_restore: 710
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6175.665364742279
  time_this_iter_s: 9.044701099395752
  time_total_s: 6175.665364742279
  timestamp: 1594862199
  timesteps_since_restore: 3550000
  timesteps_this_iter: 5000
  timesteps_total: 3550000
  training_iteration: 710
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6175 s, 710 iter, 3550000 ts, -704 rew

agent-1: -9.10374341735005
agent-2: -114.46578691400774
agent-3: -197.00701507858622
agent-4: -250.3766884873394
agent-5: -9.210731969559589
Extrinsic Rewards:
1
6
3
12
1
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 1
Max Reward: 12
Gini Coefficient: 0.46956521739130436
20:20 Ratio: 12.0
Max-min Ratio: 12.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-16-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -505.59937592678995
  episode_reward_mean: -704.2927698983989
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 710
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.925
    dispatch_time_ms: 21.255
    learner:
      cur_lr: 0.0011235700221732259
      grad_gnorm: 15.503252029418945
      policy_entropy: 56.92613220214844
      policy_loss: 3.6099750995635986
      var_gnorm: 26.32221221923828
      vf_explained_var: 0.0
      vf_loss: 7.476851463317871
    num_steps_sampled: 3555000
    num_steps_trained: 3555000
    wait_time_ms: 68.88
  iterations_since_restore: 711
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6184.480634212494
  time_this_iter_s: 8.815269470214844
  time_total_s: 6184.480634212494
  timestamp: 1594862208
  timesteps_since_restore: 3555000
  timesteps_this_iter: 5000
  timesteps_total: 3555000
  training_iteration: 711
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6184 s, 711 iter, 3555000 ts, -704 rew

agent-1: -173.4760652318424
agent-2: -73.48767205877748
agent-3: -74.64231543159856
agent-4: -149.7836299626458
agent-5: -137.57813314082637
Extrinsic Rewards:
13
11
10
10
13
Sum Reward: 57
Avg Reward: 11.4
Min Reward: 10
Max Reward: 13
Gini Coefficient: 0.06315789473684211
20:20 Ratio: 1.3
Max-min Ratio: 1.3
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-16-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -505.59937592678995
  episode_reward_mean: -704.177119238057
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 711
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.997
    dispatch_time_ms: 36.164
    learner:
      cur_lr: 0.001123236957937479
      grad_gnorm: 13.948088645935059
      policy_entropy: 51.48704528808594
      policy_loss: -0.8923078775405884
      var_gnorm: 26.341835021972656
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 9.507253646850586
    num_steps_sampled: 3560000
    num_steps_trained: 3560000
    wait_time_ms: 49.369
  iterations_since_restore: 712
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6193.37469625473
  time_this_iter_s: 8.894062042236328
  time_total_s: 6193.37469625473
  timestamp: 1594862217
  timesteps_since_restore: 3560000
  timesteps_this_iter: 5000
  timesteps_total: 3560000
  training_iteration: 712
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6193 s, 712 iter, 3560000 ts, -704 rew

agent-1: -124.6865851794569
agent-2: -128.93430365193004
agent-3: -53.60652740803746
agent-4: -115.36319247390482
agent-5: -189.47154493363615
Extrinsic Rewards:
12
22
11
15
22
Sum Reward: 82
Avg Reward: 16.4
Min Reward: 11
Max Reward: 22
Gini Coefficient: 0.15609756097560976
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-17-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -505.59937592678995
  episode_reward_mean: -704.082388193678
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 712
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.671
    dispatch_time_ms: 30.627
    learner:
      cur_lr: 0.001122904010117054
      grad_gnorm: 17.759201049804688
      policy_entropy: 49.975250244140625
      policy_loss: -5.695814609527588
      var_gnorm: 26.359827041625977
      vf_explained_var: 0.0
      vf_loss: 1.320391058921814
    num_steps_sampled: 3565000
    num_steps_trained: 3565000
    wait_time_ms: 66.236
  iterations_since_restore: 713
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6202.367701053619
  time_this_iter_s: 8.99300479888916
  time_total_s: 6202.367701053619
  timestamp: 1594862226
  timesteps_since_restore: 3565000
  timesteps_this_iter: 5000
  timesteps_total: 3565000
  training_iteration: 713
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6202 s, 713 iter, 3565000 ts, -704 rew

agent-1: -155.75913308259157
agent-2: -227.93704887575842
agent-3: -82.88551423874489
agent-4: -100.60447845914665
agent-5: -102.31899133431898
Extrinsic Rewards:
3
7
1
10
4
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 1
Max Reward: 10
Gini Coefficient: 0.352
20:20 Ratio: 10.0
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-17-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -505.59937592678995
  episode_reward_mean: -703.9276135280705
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 713
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.101
    dispatch_time_ms: 28.954
    learner:
      cur_lr: 0.0011225709458813071
      grad_gnorm: 8.151789665222168
      policy_entropy: 49.55656433105469
      policy_loss: -0.12284941971302032
      var_gnorm: 26.367860794067383
      vf_explained_var: 0.0
      vf_loss: 7.371254920959473
    num_steps_sampled: 3570000
    num_steps_trained: 3570000
    wait_time_ms: 59.011
  iterations_since_restore: 714
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6211.227437257767
  time_this_iter_s: 8.859736204147339
  time_total_s: 6211.227437257767
  timestamp: 1594862235
  timesteps_since_restore: 3570000
  timesteps_this_iter: 5000
  timesteps_total: 3570000
  training_iteration: 714
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6211 s, 714 iter, 3570000 ts, -704 rew

agent-1: -107.49836040116183
agent-2: -155.79897759315557
agent-3: -114.48383831195811
agent-4: -165.87800331306727
agent-5: -189.23428927770308
Extrinsic Rewards:
5
4
2
6
8
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 2
Max Reward: 8
Gini Coefficient: 0.224
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-17-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -505.59937592678995
  episode_reward_mean: -704.4762101039213
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 714
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 4.249
    dispatch_time_ms: 27.552
    learner:
      cur_lr: 0.001122237998060882
      grad_gnorm: 6.665920257568359
      policy_entropy: 49.748069763183594
      policy_loss: -3.0558996200561523
      var_gnorm: 26.371559143066406
      vf_explained_var: 0.0
      vf_loss: 1.6525075435638428
    num_steps_sampled: 3575000
    num_steps_trained: 3575000
    wait_time_ms: 57.504
  iterations_since_restore: 715
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6220.161461830139
  time_this_iter_s: 8.934024572372437
  time_total_s: 6220.161461830139
  timestamp: 1594862244
  timesteps_since_restore: 3575000
  timesteps_this_iter: 5000
  timesteps_total: 3575000
  training_iteration: 715
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6220 s, 715 iter, 3575000 ts, -704 rew

agent-1: -210.97417264987052
agent-2: -62.65798963848005
agent-3: -216.53104634441655
agent-4: -141.60812229894856
agent-5: -179.2432566588251
Extrinsic Rewards:
7
1
6
0
7
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.38095238095238093
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-17-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -505.59937592678995
  episode_reward_mean: -704.5760837847108
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 715
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.569
    dispatch_time_ms: 5.998
    learner:
      cur_lr: 0.001121905050240457
      grad_gnorm: 11.516497611999512
      policy_entropy: 36.70713424682617
      policy_loss: 1.261905550956726
      var_gnorm: 26.409339904785156
      vf_explained_var: 0.0
      vf_loss: 1.7199571132659912
    num_steps_sampled: 3580000
    num_steps_trained: 3580000
    wait_time_ms: 78.767
  iterations_since_restore: 716
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6238.302807331085
  time_this_iter_s: 18.141345500946045
  time_total_s: 6238.302807331085
  timestamp: 1594862262
  timesteps_since_restore: 3580000
  timesteps_this_iter: 5000
  timesteps_total: 3580000
  training_iteration: 716
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6238 s, 716 iter, 3580000 ts, -705 rew

agent-1: -87.99791674735789
agent-2: -166.46235883113056
agent-3: -149.91469217881735
agent-4: -194.54910368483522
agent-5: -132.92616314982322
Extrinsic Rewards:
3
6
5
1
3
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 1
Max Reward: 6
Gini Coefficient: 0.26666666666666666
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-17-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -505.59937592678995
  episode_reward_mean: -704.8935214905489
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 716
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.31
    dispatch_time_ms: 6.208
    learner:
      cur_lr: 0.0011215719860047102
      grad_gnorm: 13.778794288635254
      policy_entropy: 32.40913391113281
      policy_loss: -5.245702266693115
      var_gnorm: 26.330480575561523
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 10.035040855407715
    num_steps_sampled: 3585000
    num_steps_trained: 3585000
    wait_time_ms: 69.063
  iterations_since_restore: 717
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6246.47935962677
  time_this_iter_s: 8.176552295684814
  time_total_s: 6246.47935962677
  timestamp: 1594862270
  timesteps_since_restore: 3585000
  timesteps_this_iter: 5000
  timesteps_total: 3585000
  training_iteration: 717
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6246 s, 717 iter, 3585000 ts, -705 rew

agent-1: -128.56954757007827
agent-2: -61.0521918917292
agent-3: -89.36741535203754
agent-4: -87.13596671186157
agent-5: -116.69618916600666
Extrinsic Rewards:
37
16
25
19
28
Sum Reward: 125
Avg Reward: 25.0
Min Reward: 16
Max Reward: 37
Gini Coefficient: 0.1632
20:20 Ratio: 2.3125
Max-min Ratio: 2.3125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-17-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -702.3835287880426
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 717
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.654
    dispatch_time_ms: 6.617
    learner:
      cur_lr: 0.0011212390381842852
      grad_gnorm: 19.388919830322266
      policy_entropy: 57.15027618408203
      policy_loss: -7.434377193450928
      var_gnorm: 26.327116012573242
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 5.6421709060668945
    num_steps_sampled: 3590000
    num_steps_trained: 3590000
    wait_time_ms: 72.614
  iterations_since_restore: 718
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6254.74239730835
  time_this_iter_s: 8.26303768157959
  time_total_s: 6254.74239730835
  timestamp: 1594862278
  timesteps_since_restore: 3590000
  timesteps_this_iter: 5000
  timesteps_total: 3590000
  training_iteration: 718
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6254 s, 718 iter, 3590000 ts, -702 rew

agent-1: -104.69390973633982
agent-2: -53.70743869054892
agent-3: -130.57733437683487
agent-4: -129.02128655438202
agent-5: -115.23602611920097
Extrinsic Rewards:
14
9
21
32
20
Sum Reward: 96
Avg Reward: 19.2
Min Reward: 9
Max Reward: 32
Gini Coefficient: 0.22083333333333333
20:20 Ratio: 3.5555555555555554
Max-min Ratio: 3.5555555555555554
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-18-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -700.0164079758177
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 718
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.538
    dispatch_time_ms: 7.222
    learner:
      cur_lr: 0.0011209059739485383
      grad_gnorm: 12.762412071228027
      policy_entropy: 57.95769500732422
      policy_loss: -3.727445363998413
      var_gnorm: 26.349355697631836
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 5.305412769317627
    num_steps_sampled: 3595000
    num_steps_trained: 3595000
    wait_time_ms: 74.057
  iterations_since_restore: 719
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6263.077442884445
  time_this_iter_s: 8.335045576095581
  time_total_s: 6263.077442884445
  timestamp: 1594862287
  timesteps_since_restore: 3595000
  timesteps_this_iter: 5000
  timesteps_total: 3595000
  training_iteration: 719
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6263 s, 719 iter, 3595000 ts, -700 rew

agent-1: -229.53297237589175
agent-2: -61.51781329346416
agent-3: -182.0810190744715
agent-4: -64.20943008595529
agent-5: -84.32958720703759
Extrinsic Rewards:
7
7
3
3
12
Sum Reward: 32
Avg Reward: 6.4
Min Reward: 3
Max Reward: 12
Gini Coefficient: 0.275
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-18-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -700.1140708917238
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 719
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.999
    dispatch_time_ms: 7.616
    learner:
      cur_lr: 0.0011205730261281133
      grad_gnorm: 16.60759735107422
      policy_entropy: 52.560523986816406
      policy_loss: -0.22163105010986328
      var_gnorm: 26.3555965423584
      vf_explained_var: 0.0
      vf_loss: 5.218594551086426
    num_steps_sampled: 3600000
    num_steps_trained: 3600000
    wait_time_ms: 73.715
  iterations_since_restore: 720
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6271.518537282944
  time_this_iter_s: 8.441094398498535
  time_total_s: 6271.518537282944
  timestamp: 1594862295
  timesteps_since_restore: 3600000
  timesteps_this_iter: 5000
  timesteps_total: 3600000
  training_iteration: 720
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6271 s, 720 iter, 3600000 ts, -700 rew

agent-1: -36.57254120142963
agent-2: -220.97590961491716
agent-3: -106.50088794334432
agent-4: -101.89456228178472
agent-5: -200.53469585886495
Extrinsic Rewards:
2
9
5
9
9
Sum Reward: 34
Avg Reward: 6.8
Min Reward: 2
Max Reward: 9
Gini Coefficient: 0.21176470588235294
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-18-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -699.7172174993508
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 720
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.628
    dispatch_time_ms: 6.299
    learner:
      cur_lr: 0.0011202399618923664
      grad_gnorm: 14.176512718200684
      policy_entropy: 47.0811767578125
      policy_loss: -3.049438714981079
      var_gnorm: 26.347902297973633
      vf_explained_var: 0.0
      vf_loss: 8.40023422241211
    num_steps_sampled: 3605000
    num_steps_trained: 3605000
    wait_time_ms: 78.726
  iterations_since_restore: 721
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6279.913370847702
  time_this_iter_s: 8.3948335647583
  time_total_s: 6279.913370847702
  timestamp: 1594862304
  timesteps_since_restore: 3605000
  timesteps_this_iter: 5000
  timesteps_total: 3605000
  training_iteration: 721
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6279 s, 721 iter, 3605000 ts, -700 rew

agent-1: -139.51795008257417
agent-2: -43.70877795139232
agent-3: -212.9626119489077
agent-4: -22.723089524740633
agent-5: -221.8252356769238
Extrinsic Rewards:
7
4
5
1
5
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 1
Max Reward: 7
Gini Coefficient: 0.23636363636363636
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-18-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -700.9395749147585
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 721
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.165
    dispatch_time_ms: 8.184
    learner:
      cur_lr: 0.0011199070140719414
      grad_gnorm: 40.0
      policy_entropy: 44.82374572753906
      policy_loss: 13.577927589416504
      var_gnorm: 26.381799697875977
      vf_explained_var: 0.0
      vf_loss: 16.537513732910156
    num_steps_sampled: 3610000
    num_steps_trained: 3610000
    wait_time_ms: 73.01
  iterations_since_restore: 722
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6288.337050437927
  time_this_iter_s: 8.42367959022522
  time_total_s: 6288.337050437927
  timestamp: 1594862312
  timesteps_since_restore: 3610000
  timesteps_this_iter: 5000
  timesteps_total: 3610000
  training_iteration: 722
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6288 s, 722 iter, 3610000 ts, -701 rew

agent-1: -264.2676599729671
agent-2: -115.52106174614177
agent-3: -113.01750766496768
agent-4: -121.43800606460513
agent-5: -145.86428619947065
Extrinsic Rewards:
10
3
4
3
0
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 0
Max Reward: 10
Gini Coefficient: 0.42
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-18-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -702.6135285638329
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 722
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.923
    dispatch_time_ms: 6.891
    learner:
      cur_lr: 0.0011195739498361945
      grad_gnorm: 15.179753303527832
      policy_entropy: 52.776424407958984
      policy_loss: -5.558485507965088
      var_gnorm: 26.360076904296875
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 3.951251745223999
    num_steps_sampled: 3615000
    num_steps_trained: 3615000
    wait_time_ms: 70.286
  iterations_since_restore: 723
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6296.630786895752
  time_this_iter_s: 8.293736457824707
  time_total_s: 6296.630786895752
  timestamp: 1594862320
  timesteps_since_restore: 3615000
  timesteps_this_iter: 5000
  timesteps_total: 3615000
  training_iteration: 723
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6296 s, 723 iter, 3615000 ts, -703 rew

agent-1: -67.69527225961187
agent-2: -64.2057093110071
agent-3: -223.769969563582
agent-4: -75.8458794154217
agent-5: -207.27900233763864
Extrinsic Rewards:
1
5
9
5
13
Sum Reward: 33
Avg Reward: 6.6
Min Reward: 1
Max Reward: 13
Gini Coefficient: 0.3393939393939394
20:20 Ratio: 13.0
Max-min Ratio: 13.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-18-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -702.3832606208651
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 723
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.762
    dispatch_time_ms: 6.643
    learner:
      cur_lr: 0.0011192410020157695
      grad_gnorm: 9.59643268585205
      policy_entropy: 49.63111114501953
      policy_loss: -4.012486457824707
      var_gnorm: 26.363773345947266
      vf_explained_var: 0.0
      vf_loss: 3.8613317012786865
    num_steps_sampled: 3620000
    num_steps_trained: 3620000
    wait_time_ms: 78.851
  iterations_since_restore: 724
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6305.08040189743
  time_this_iter_s: 8.449615001678467
  time_total_s: 6305.08040189743
  timestamp: 1594862329
  timesteps_since_restore: 3620000
  timesteps_this_iter: 5000
  timesteps_total: 3620000
  training_iteration: 724
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6305 s, 724 iter, 3620000 ts, -702 rew

agent-1: -182.53131992403854
agent-2: -40.93302413871515
agent-3: -93.50259503064518
agent-4: -173.93445609765683
agent-5: -159.58220063727288
Extrinsic Rewards:
18
4
8
19
15
Sum Reward: 64
Avg Reward: 12.8
Min Reward: 4
Max Reward: 19
Gini Coefficient: 0.25
20:20 Ratio: 4.75
Max-min Ratio: 4.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-18-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -702.4018662723682
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 724
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.08
    dispatch_time_ms: 5.577
    learner:
      cur_lr: 0.0011189080541953444
      grad_gnorm: 14.71181869506836
      policy_entropy: 49.46430206298828
      policy_loss: 4.267037868499756
      var_gnorm: 26.349761962890625
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 12.912332534790039
    num_steps_sampled: 3625000
    num_steps_trained: 3625000
    wait_time_ms: 75.578
  iterations_since_restore: 725
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6313.473918676376
  time_this_iter_s: 8.393516778945923
  time_total_s: 6313.473918676376
  timestamp: 1594862337
  timesteps_since_restore: 3625000
  timesteps_this_iter: 5000
  timesteps_total: 3625000
  training_iteration: 725
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6313 s, 725 iter, 3625000 ts, -702 rew

agent-1: -137.51919394199885
agent-2: -237.19003532325831
agent-3: -138.7791692377149
agent-4: -121.69105346896154
agent-5: -49.73143717606133
Extrinsic Rewards:
5
8
2
4
2
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 2
Max Reward: 8
Gini Coefficient: 0.2857142857142857
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-19-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -701.2895965784724
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 725
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.096
    dispatch_time_ms: 7.71
    learner:
      cur_lr: 0.0011185749899595976
      grad_gnorm: 11.461037635803223
      policy_entropy: 36.97157287597656
      policy_loss: 1.2410962581634521
      var_gnorm: 26.343019485473633
      vf_explained_var: 0.0
      vf_loss: 12.76420783996582
    num_steps_sampled: 3630000
    num_steps_trained: 3630000
    wait_time_ms: 73.018
  iterations_since_restore: 726
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6321.880300521851
  time_this_iter_s: 8.406381845474243
  time_total_s: 6321.880300521851
  timestamp: 1594862346
  timesteps_since_restore: 3630000
  timesteps_this_iter: 5000
  timesteps_total: 3630000
  training_iteration: 726
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6321 s, 726 iter, 3630000 ts, -701 rew

agent-1: -233.52555355414944
agent-2: -220.39912024661362
agent-3: -11.38852827891609
agent-4: -59.19076133832916
agent-5: -29.585046180974075
Extrinsic Rewards:
15
10
3
6
7
Sum Reward: 41
Avg Reward: 8.2
Min Reward: 3
Max Reward: 15
Gini Coefficient: 0.2731707317073171
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-19-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -701.2208671169765
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 726
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.84
    dispatch_time_ms: 9.294
    learner:
      cur_lr: 0.0011182420421391726
      grad_gnorm: 19.394460678100586
      policy_entropy: 49.998531341552734
      policy_loss: -9.639362335205078
      var_gnorm: 26.354833602905273
      vf_explained_var: 0.0
      vf_loss: 2.362666368484497
    num_steps_sampled: 3635000
    num_steps_trained: 3635000
    wait_time_ms: 71.072
  iterations_since_restore: 727
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6330.221904754639
  time_this_iter_s: 8.341604232788086
  time_total_s: 6330.221904754639
  timestamp: 1594862354
  timesteps_since_restore: 3635000
  timesteps_this_iter: 5000
  timesteps_total: 3635000
  training_iteration: 727
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6330 s, 727 iter, 3635000 ts, -701 rew

agent-1: -199.9590077408304
agent-2: -106.23244369773909
agent-3: -37.44809709020935
agent-4: -108.16791594115014
agent-5: -143.59783727537595
Extrinsic Rewards:
19
13
9
14
24
Sum Reward: 79
Avg Reward: 15.8
Min Reward: 9
Max Reward: 24
Gini Coefficient: 0.18227848101265823
20:20 Ratio: 2.6666666666666665
Max-min Ratio: 2.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-19-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -701.059290355462
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 727
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.737
    dispatch_time_ms: 36.953
    learner:
      cur_lr: 0.0011179089779034257
      grad_gnorm: 40.0
      policy_entropy: 50.48593521118164
      policy_loss: 10.587435722351074
      var_gnorm: 26.368803024291992
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.67918062210083
    num_steps_sampled: 3640000
    num_steps_trained: 3640000
    wait_time_ms: 69.021
  iterations_since_restore: 728
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6339.152845621109
  time_this_iter_s: 8.930940866470337
  time_total_s: 6339.152845621109
  timestamp: 1594862363
  timesteps_since_restore: 3640000
  timesteps_this_iter: 5000
  timesteps_total: 3640000
  training_iteration: 728
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6339 s, 728 iter, 3640000 ts, -701 rew

agent-1: -157.83253387504223
agent-2: -97.56250279811704
agent-3: -98.16385575765624
agent-4: -211.59261922103926
agent-5: -163.70302993821682
Extrinsic Rewards:
5
2
4
6
5
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 2
Max Reward: 6
Gini Coefficient: 0.16363636363636364
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-19-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -701.8869071547748
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 728
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.834
    dispatch_time_ms: 26.852
    learner:
      cur_lr: 0.0011175760300830007
      grad_gnorm: 16.136648178100586
      policy_entropy: 44.30844497680664
      policy_loss: -8.286301612854004
      var_gnorm: 26.351404190063477
      vf_explained_var: 0.0
      vf_loss: 3.87973952293396
    num_steps_sampled: 3645000
    num_steps_trained: 3645000
    wait_time_ms: 60.822
  iterations_since_restore: 729
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6347.829807281494
  time_this_iter_s: 8.676961660385132
  time_total_s: 6347.829807281494
  timestamp: 1594862372
  timesteps_since_restore: 3645000
  timesteps_this_iter: 5000
  timesteps_total: 3645000
  training_iteration: 729
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6347 s, 729 iter, 3645000 ts, -702 rew

agent-1: -87.64330028231117
agent-2: -82.97072848012083
agent-3: -140.611120890034
agent-4: -236.32040437298863
agent-5: -109.23119224962764
Extrinsic Rewards:
1
7
9
9
2
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.32857142857142857
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-19-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -702.7008338716445
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 729
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.551
    dispatch_time_ms: 43.408
    learner:
      cur_lr: 0.0011172429658472538
      grad_gnorm: 21.335783004760742
      policy_entropy: 41.7433967590332
      policy_loss: 6.720998287200928
      var_gnorm: 26.35073471069336
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 10.109208106994629
    num_steps_sampled: 3650000
    num_steps_trained: 3650000
    wait_time_ms: 37.655
  iterations_since_restore: 730
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6356.981528520584
  time_this_iter_s: 9.151721239089966
  time_total_s: 6356.981528520584
  timestamp: 1594862381
  timesteps_since_restore: 3650000
  timesteps_this_iter: 5000
  timesteps_total: 3650000
  training_iteration: 730
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6356 s, 730 iter, 3650000 ts, -703 rew

agent-1: -169.087124960715
agent-2: -214.88717379549317
agent-3: -29.504762629318343
agent-4: -133.69493452184315
agent-5: -35.833256986971925
Extrinsic Rewards:
13
25
8
5
8
Sum Reward: 59
Avg Reward: 11.8
Min Reward: 5
Max Reward: 25
Gini Coefficient: 0.3050847457627119
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-19-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -700.5184979353714
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 730
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.417
    dispatch_time_ms: 38.529
    learner:
      cur_lr: 0.0011169100180268288
      grad_gnorm: 8.459463119506836
      policy_entropy: 44.20341491699219
      policy_loss: -7.152770042419434
      var_gnorm: 26.347013473510742
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.774169683456421
    num_steps_sampled: 3655000
    num_steps_trained: 3655000
    wait_time_ms: 44.735
  iterations_since_restore: 731
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6365.772920370102
  time_this_iter_s: 8.791391849517822
  time_total_s: 6365.772920370102
  timestamp: 1594862390
  timesteps_since_restore: 3655000
  timesteps_this_iter: 5000
  timesteps_total: 3655000
  training_iteration: 731
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6365 s, 731 iter, 3655000 ts, -701 rew

agent-1: -143.35735856618794
agent-2: -277.514707863801
agent-3: -143.35735856618794
agent-4: -195.11019657159088
agent-5: -29.781808463824994
Extrinsic Rewards:
0
12
0
8
1
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 0
Max Reward: 12
Gini Coefficient: 0.6095238095238096
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-19-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -702.14517859803
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 731
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.751
    dispatch_time_ms: 25.086
    learner:
      cur_lr: 0.001116576953791082
      grad_gnorm: 23.613683700561523
      policy_entropy: 45.991188049316406
      policy_loss: 2.7180607318878174
      var_gnorm: 26.404409408569336
      vf_explained_var: 0.0
      vf_loss: 3.724543333053589
    num_steps_sampled: 3660000
    num_steps_trained: 3660000
    wait_time_ms: 72.655
  iterations_since_restore: 732
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6374.762751817703
  time_this_iter_s: 8.989831447601318
  time_total_s: 6374.762751817703
  timestamp: 1594862399
  timesteps_since_restore: 3660000
  timesteps_this_iter: 5000
  timesteps_total: 3660000
  training_iteration: 732
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6374 s, 732 iter, 3660000 ts, -702 rew

agent-1: -134.96611558009266
agent-2: -132.89853208994407
agent-3: -38.04924420798742
agent-4: -223.41934072561295
agent-5: -172.2344693636915
Extrinsic Rewards:
5
3
1
8
4
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.3047619047619048
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-20-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -702.7510588442367
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 732
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.242
    dispatch_time_ms: 48.152
    learner:
      cur_lr: 0.0011162440059706569
      grad_gnorm: 7.511508941650391
      policy_entropy: 44.01814651489258
      policy_loss: 1.12307870388031
      var_gnorm: 26.376522064208984
      vf_explained_var: 0.0
      vf_loss: 5.058358192443848
    num_steps_sampled: 3665000
    num_steps_trained: 3665000
    wait_time_ms: 41.973
  iterations_since_restore: 733
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6383.71716594696
  time_this_iter_s: 8.954414129257202
  time_total_s: 6383.71716594696
  timestamp: 1594862408
  timesteps_since_restore: 3665000
  timesteps_this_iter: 5000
  timesteps_total: 3665000
  training_iteration: 733
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6383 s, 733 iter, 3665000 ts, -703 rew

agent-1: -71.66076534128905
agent-2: -40.30787805127968
agent-3: -106.94202345570736
agent-4: -234.14093148169147
agent-5: -205.62685114267248
Extrinsic Rewards:
2
1
3
10
10
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 1
Max Reward: 10
Gini Coefficient: 0.4
20:20 Ratio: 10.0
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-20-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -700.9693753928971
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 733
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.067
    dispatch_time_ms: 26.604
    learner:
      cur_lr: 0.0011159110581502318
      grad_gnorm: 12.523906707763672
      policy_entropy: 45.515464782714844
      policy_loss: -0.3982945382595062
      var_gnorm: 26.37122344970703
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.067126750946045
    num_steps_sampled: 3670000
    num_steps_trained: 3670000
    wait_time_ms: 64.714
  iterations_since_restore: 734
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6392.449361562729
  time_this_iter_s: 8.732195615768433
  time_total_s: 6392.449361562729
  timestamp: 1594862417
  timesteps_since_restore: 3670000
  timesteps_this_iter: 5000
  timesteps_total: 3670000
  training_iteration: 734
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6392 s, 734 iter, 3670000 ts, -701 rew

agent-1: -63.565813106131415
agent-2: -205.08483247939895
agent-3: -160.45707945515323
agent-4: -204.35420533949105
agent-5: -53.62219952500304
Extrinsic Rewards:
4
6
3
10
3
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 3
Max Reward: 10
Gini Coefficient: 0.26153846153846155
20:20 Ratio: 3.3333333333333335
Max-min Ratio: 3.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-20-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -699.5121230886169
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 734
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.248
    dispatch_time_ms: 24.045
    learner:
      cur_lr: 0.001115577993914485
      grad_gnorm: 12.096001625061035
      policy_entropy: 47.884300231933594
      policy_loss: 4.425670623779297
      var_gnorm: 26.350399017333984
      vf_explained_var: 0.0
      vf_loss: 8.690807342529297
    num_steps_sampled: 3675000
    num_steps_trained: 3675000
    wait_time_ms: 64.282
  iterations_since_restore: 735
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6401.299510002136
  time_this_iter_s: 8.850148439407349
  time_total_s: 6401.299510002136
  timestamp: 1594862425
  timesteps_since_restore: 3675000
  timesteps_this_iter: 5000
  timesteps_total: 3675000
  training_iteration: 735
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6401 s, 735 iter, 3675000 ts, -700 rew

agent-1: -87.44982376358791
agent-2: -233.40982426257224
agent-3: -46.473547061264895
agent-4: -170.2303711239819
agent-5: -73.72693168846385
Extrinsic Rewards:
8
10
7
2
7
Sum Reward: 34
Avg Reward: 6.8
Min Reward: 2
Max Reward: 10
Gini Coefficient: 0.2
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-20-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -696.7375330247062
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 735
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.743
    dispatch_time_ms: 21.952
    learner:
      cur_lr: 0.00111524504609406
      grad_gnorm: 32.82477951049805
      policy_entropy: 40.624446868896484
      policy_loss: -10.408717155456543
      var_gnorm: 26.347572326660156
      vf_explained_var: 0.0
      vf_loss: 14.684706687927246
    num_steps_sampled: 3680000
    num_steps_trained: 3680000
    wait_time_ms: 63.167
  iterations_since_restore: 736
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6410.128858566284
  time_this_iter_s: 8.82934856414795
  time_total_s: 6410.128858566284
  timestamp: 1594862434
  timesteps_since_restore: 3680000
  timesteps_this_iter: 5000
  timesteps_total: 3680000
  training_iteration: 736
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6410 s, 736 iter, 3680000 ts, -697 rew

agent-1: -138.18693359105887
agent-2: -215.8745714835564
agent-3: -78.11948549470051
agent-4: -98.92393394337694
agent-5: -48.67474478534568
Extrinsic Rewards:
12
4
0
7
7
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 0
Max Reward: 12
Gini Coefficient: 0.36
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-20-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -693.9297881443791
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 736
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.072
    dispatch_time_ms: 22.397
    learner:
      cur_lr: 0.001114911981858313
      grad_gnorm: 33.48878479003906
      policy_entropy: 40.955810546875
      policy_loss: -6.28191614151001
      var_gnorm: 26.331926345825195
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 2.1704909801483154
    num_steps_sampled: 3685000
    num_steps_trained: 3685000
    wait_time_ms: 52.7
  iterations_since_restore: 737
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6418.907542705536
  time_this_iter_s: 8.778684139251709
  time_total_s: 6418.907542705536
  timestamp: 1594862443
  timesteps_since_restore: 3685000
  timesteps_this_iter: 5000
  timesteps_total: 3685000
  training_iteration: 737
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6418 s, 737 iter, 3685000 ts, -694 rew

agent-1: -86.14642215316228
agent-2: -150.38256408339961
agent-3: -160.03353370747558
agent-4: -107.07848284650858
agent-5: -123.85087461969914
Extrinsic Rewards:
9
15
22
8
14
Sum Reward: 68
Avg Reward: 13.6
Min Reward: 8
Max Reward: 22
Gini Coefficient: 0.2
20:20 Ratio: 2.75
Max-min Ratio: 2.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-20-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -692.6555867183519
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 737
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.874
    dispatch_time_ms: 31.648
    learner:
      cur_lr: 0.001114579034037888
      grad_gnorm: 32.49287033081055
      policy_entropy: 43.721065521240234
      policy_loss: -4.2045578956604
      var_gnorm: 26.380483627319336
      vf_explained_var: 0.0
      vf_loss: 12.815336227416992
    num_steps_sampled: 3690000
    num_steps_trained: 3690000
    wait_time_ms: 55.454
  iterations_since_restore: 738
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6427.799631357193
  time_this_iter_s: 8.892088651657104
  time_total_s: 6427.799631357193
  timestamp: 1594862452
  timesteps_since_restore: 3690000
  timesteps_this_iter: 5000
  timesteps_total: 3690000
  training_iteration: 738
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6427 s, 738 iter, 3690000 ts, -693 rew

agent-1: -119.49519024643192
agent-2: -229.7918109092392
agent-3: -220.81493637279348
agent-4: -9.773438934304306
agent-5: -120.67659611763659
Extrinsic Rewards:
0
6
7
1
12
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 0
Max Reward: 12
Gini Coefficient: 0.46153846153846156
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-21-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -692.9098199146699
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 738
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 4.224
    dispatch_time_ms: 51.547
    learner:
      cur_lr: 0.0011142459698021412
      grad_gnorm: 7.977945327758789
      policy_entropy: 43.472740173339844
      policy_loss: -0.39233410358428955
      var_gnorm: 26.376218795776367
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 2.880891799926758
    num_steps_sampled: 3695000
    num_steps_trained: 3695000
    wait_time_ms: 46.546
  iterations_since_restore: 739
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6436.931616783142
  time_this_iter_s: 9.131985425949097
  time_total_s: 6436.931616783142
  timestamp: 1594862461
  timesteps_since_restore: 3695000
  timesteps_this_iter: 5000
  timesteps_total: 3695000
  training_iteration: 739
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6436 s, 739 iter, 3695000 ts, -693 rew

agent-1: -166.1321494328739
agent-2: -176.7707498963122
agent-3: -175.71838260777744
agent-4: -53.860849675379335
agent-5: -153.74320022089918
Extrinsic Rewards:
7
2
4
4
5
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 2
Max Reward: 7
Gini Coefficient: 0.2
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-21-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -693.1104112016296
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 739
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.044
    dispatch_time_ms: 33.105
    learner:
      cur_lr: 0.0011139130219817162
      grad_gnorm: 6.192821979522705
      policy_entropy: 39.24229431152344
      policy_loss: -0.38550469279289246
      var_gnorm: 26.376371383666992
      vf_explained_var: 0.0
      vf_loss: 3.936553955078125
    num_steps_sampled: 3700000
    num_steps_trained: 3700000
    wait_time_ms: 54.865
  iterations_since_restore: 740
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6445.752415895462
  time_this_iter_s: 8.820799112319946
  time_total_s: 6445.752415895462
  timestamp: 1594862470
  timesteps_since_restore: 3700000
  timesteps_this_iter: 5000
  timesteps_total: 3700000
  training_iteration: 740
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6445 s, 740 iter, 3700000 ts, -693 rew

agent-1: -141.17729899618652
agent-2: -215.39351991702773
agent-3: -171.53023801708954
agent-4: -96.11815192935826
agent-5: -56.375140122054276
Extrinsic Rewards:
9
5
8
4
3
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 3
Max Reward: 9
Gini Coefficient: 0.2206896551724138
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-21-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -693.6209525089142
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 740
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.427
    dispatch_time_ms: 30.615
    learner:
      cur_lr: 0.0011135799577459693
      grad_gnorm: 10.982806205749512
      policy_entropy: 38.59339141845703
      policy_loss: -2.0245094299316406
      var_gnorm: 26.3461856842041
      vf_explained_var: 0.0
      vf_loss: 9.959866523742676
    num_steps_sampled: 3705000
    num_steps_trained: 3705000
    wait_time_ms: 53.025
  iterations_since_restore: 741
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6454.563716173172
  time_this_iter_s: 8.811300277709961
  time_total_s: 6454.563716173172
  timestamp: 1594862479
  timesteps_since_restore: 3705000
  timesteps_this_iter: 5000
  timesteps_total: 3705000
  training_iteration: 741
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6454 s, 741 iter, 3705000 ts, -694 rew

agent-1: -187.8035489374634
agent-2: -39.93293013617352
agent-3: -46.88772911126921
agent-4: -104.32473706176441
agent-5: -171.76423950129436
Extrinsic Rewards:
11
9
6
20
19
Sum Reward: 65
Avg Reward: 13.0
Min Reward: 6
Max Reward: 20
Gini Coefficient: 0.23384615384615384
20:20 Ratio: 3.3333333333333335
Max-min Ratio: 3.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-21-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -692.3364419257259
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 741
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.394
    dispatch_time_ms: 25.89
    learner:
      cur_lr: 0.0011132470099255443
      grad_gnorm: 10.678590774536133
      policy_entropy: 29.379356384277344
      policy_loss: -1.864789366722107
      var_gnorm: 26.34677505493164
      vf_explained_var: 0.0
      vf_loss: 4.67266321182251
    num_steps_sampled: 3710000
    num_steps_trained: 3710000
    wait_time_ms: 54.746
  iterations_since_restore: 742
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6463.515977859497
  time_this_iter_s: 8.952261686325073
  time_total_s: 6463.515977859497
  timestamp: 1594862488
  timesteps_since_restore: 3710000
  timesteps_this_iter: 5000
  timesteps_total: 3710000
  training_iteration: 742
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6463 s, 742 iter, 3710000 ts, -692 rew

agent-1: -50.683105863900565
agent-2: -159.51635928308616
agent-3: -223.25788598045813
agent-4: -174.84392970017456
agent-5: -73.10838612498976
Extrinsic Rewards:
2
5
10
6
5
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 2
Max Reward: 10
Gini Coefficient: 0.24285714285714285
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-21-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -691.8573106166141
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 742
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.102
    dispatch_time_ms: 40.319
    learner:
      cur_lr: 0.0011129139456897974
      grad_gnorm: 26.326066970825195
      policy_entropy: 35.620330810546875
      policy_loss: 5.700739860534668
      var_gnorm: 26.327943801879883
      vf_explained_var: 0.0
      vf_loss: 10.958969116210938
    num_steps_sampled: 3715000
    num_steps_trained: 3715000
    wait_time_ms: 33.541
  iterations_since_restore: 743
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6472.445869684219
  time_this_iter_s: 8.92989182472229
  time_total_s: 6472.445869684219
  timestamp: 1594862497
  timesteps_since_restore: 3715000
  timesteps_this_iter: 5000
  timesteps_total: 3715000
  training_iteration: 743
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6472 s, 743 iter, 3715000 ts, -692 rew

agent-1: -31.489844652775147
agent-2: -164.02905608934248
agent-3: -116.65663341571826
agent-4: -231.49383650780175
agent-5: -19.708597867159
Extrinsic Rewards:
7
7
11
18
5
Sum Reward: 48
Avg Reward: 9.6
Min Reward: 5
Max Reward: 18
Gini Coefficient: 0.25
20:20 Ratio: 3.6
Max-min Ratio: 3.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-21-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -690.621554218782
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 743
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.063
    dispatch_time_ms: 12.353
    learner:
      cur_lr: 0.0011125809978693724
      grad_gnorm: 40.0
      policy_entropy: 27.89424705505371
      policy_loss: 15.51474380493164
      var_gnorm: 26.33167266845703
      vf_explained_var: 0.0
      vf_loss: 15.670072555541992
    num_steps_sampled: 3720000
    num_steps_trained: 3720000
    wait_time_ms: 28.113
  iterations_since_restore: 744
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6481.692585945129
  time_this_iter_s: 9.246716260910034
  time_total_s: 6481.692585945129
  timestamp: 1594862506
  timesteps_since_restore: 3720000
  timesteps_this_iter: 5000
  timesteps_total: 3720000
  training_iteration: 744
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6481 s, 744 iter, 3720000 ts, -691 rew

agent-1: -34.55216427611478
agent-2: -211.9790807014939
agent-3: -62.26139349529004
agent-4: -34.2351891302605
agent-5: -210.9751824358473
Extrinsic Rewards:
8
9
6
12
10
Sum Reward: 45
Avg Reward: 9.0
Min Reward: 6
Max Reward: 12
Gini Coefficient: 0.12444444444444444
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-21-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -690.6288830302993
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 744
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.429
    dispatch_time_ms: 7.892
    learner:
      cur_lr: 0.0011122480500489473
      grad_gnorm: 9.624751091003418
      policy_entropy: 16.744375228881836
      policy_loss: -0.8859314918518066
      var_gnorm: 26.357999801635742
      vf_explained_var: 0.0
      vf_loss: 5.665584087371826
    num_steps_sampled: 3725000
    num_steps_trained: 3725000
    wait_time_ms: 74.663
  iterations_since_restore: 745
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6489.9978013038635
  time_this_iter_s: 8.30521535873413
  time_total_s: 6489.9978013038635
  timestamp: 1594862515
  timesteps_since_restore: 3725000
  timesteps_this_iter: 5000
  timesteps_total: 3725000
  training_iteration: 745
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6489 s, 745 iter, 3725000 ts, -691 rew

agent-1: -120.66500464057368
agent-2: -191.48987085344396
agent-3: -195.10727891597452
agent-4: -102.87128244920515
agent-5: -66.64536681435597
Extrinsic Rewards:
4
8
8
4
7
Sum Reward: 31
Avg Reward: 6.2
Min Reward: 4
Max Reward: 8
Gini Coefficient: 0.15483870967741936
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-22-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -691.5529521117575
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 745
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.592
    dispatch_time_ms: 8.651
    learner:
      cur_lr: 0.0011119149858132005
      grad_gnorm: 25.822465896606445
      policy_entropy: 14.841740608215332
      policy_loss: -5.332857608795166
      var_gnorm: 26.41109848022461
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 6.417964458465576
    num_steps_sampled: 3730000
    num_steps_trained: 3730000
    wait_time_ms: 69.745
  iterations_since_restore: 746
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6498.3196849823
  time_this_iter_s: 8.32188367843628
  time_total_s: 6498.3196849823
  timestamp: 1594862523
  timesteps_since_restore: 3730000
  timesteps_this_iter: 5000
  timesteps_total: 3730000
  training_iteration: 746
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6498 s, 746 iter, 3730000 ts, -692 rew

agent-1: -148.1127881570908
agent-2: -130.75971584335562
agent-3: -130.8560766189989
agent-4: -132.07441802327887
agent-5: -255.49698398795064
Extrinsic Rewards:
0
2
2
4
8
Sum Reward: 16
Avg Reward: 3.2
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.45
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-22-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -692.8499918728282
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 746
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.347
    dispatch_time_ms: 8.457
    learner:
      cur_lr: 0.0011115820379927754
      grad_gnorm: 14.451943397521973
      policy_entropy: 30.458866119384766
      policy_loss: -1.767836570739746
      var_gnorm: 26.337968826293945
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 6.48033332824707
    num_steps_sampled: 3735000
    num_steps_trained: 3735000
    wait_time_ms: 71.629
  iterations_since_restore: 747
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6506.60556769371
  time_this_iter_s: 8.285882711410522
  time_total_s: 6506.60556769371
  timestamp: 1594862531
  timesteps_since_restore: 3735000
  timesteps_this_iter: 5000
  timesteps_total: 3735000
  training_iteration: 747
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6506 s, 747 iter, 3735000 ts, -693 rew

agent-1: -60.231883593239274
agent-2: -90.13374755024442
agent-3: -144.57187488773855
agent-4: -188.60053411909544
agent-5: -135.0629884190937
Extrinsic Rewards:
14
15
19
27
11
Sum Reward: 86
Avg Reward: 17.2
Min Reward: 11
Max Reward: 27
Gini Coefficient: 0.17209302325581396
20:20 Ratio: 2.4545454545454546
Max-min Ratio: 2.4545454545454546
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-22-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -690.7292933216542
  episode_reward_min: -1973.3622485857954
  episodes_this_iter: 1
  episodes_total: 747
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.121
    dispatch_time_ms: 8.176
    learner:
      cur_lr: 0.0011112489737570286
      grad_gnorm: 17.615190505981445
      policy_entropy: 34.60380554199219
      policy_loss: 4.077125072479248
      var_gnorm: 26.338708877563477
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 6.3364410400390625
    num_steps_sampled: 3740000
    num_steps_trained: 3740000
    wait_time_ms: 72.642
  iterations_since_restore: 748
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6514.907461166382
  time_this_iter_s: 8.301893472671509
  time_total_s: 6514.907461166382
  timestamp: 1594862540
  timesteps_since_restore: 3740000
  timesteps_this_iter: 5000
  timesteps_total: 3740000
  training_iteration: 748
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6514 s, 748 iter, 3740000 ts, -691 rew

agent-1: -118.0996892266492
agent-2: -41.669484841281495
agent-3: -212.78502688967018
agent-4: -98.5940841592205
agent-5: -43.14942630554517
Extrinsic Rewards:
11
7
20
16
10
Sum Reward: 64
Avg Reward: 12.8
Min Reward: 7
Max Reward: 20
Gini Coefficient: 0.2
20:20 Ratio: 2.857142857142857
Max-min Ratio: 2.857142857142857
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-22-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -676.13864795002
  episode_reward_min: -880.5571129244336
  episodes_this_iter: 1
  episodes_total: 748
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.018
    dispatch_time_ms: 8.337
    learner:
      cur_lr: 0.0011109160259366035
      grad_gnorm: 16.86542510986328
      policy_entropy: 42.24608612060547
      policy_loss: -0.33406710624694824
      var_gnorm: 26.357973098754883
      vf_explained_var: 0.0
      vf_loss: 7.171458721160889
    num_steps_sampled: 3745000
    num_steps_trained: 3745000
    wait_time_ms: 74.183
  iterations_since_restore: 749
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6523.311151027679
  time_this_iter_s: 8.403689861297607
  time_total_s: 6523.311151027679
  timestamp: 1594862548
  timesteps_since_restore: 3745000
  timesteps_this_iter: 5000
  timesteps_total: 3745000
  training_iteration: 749
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6523 s, 749 iter, 3745000 ts, -676 rew

agent-1: -178.65768564725622
agent-2: -146.5223641909624
agent-3: -235.68388477981452
agent-4: -65.57621918683336
agent-5: -190.4906487896803
Extrinsic Rewards:
5
0
5
2
5
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 0
Max Reward: 5
Gini Coefficient: 0.3058823529411765
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-22-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -677.9174630479056
  episode_reward_min: -880.5571129244336
  episodes_this_iter: 1
  episodes_total: 749
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.504
    dispatch_time_ms: 6.935
    learner:
      cur_lr: 0.0011105829617008567
      grad_gnorm: 22.30030059814453
      policy_entropy: 44.710105895996094
      policy_loss: -3.8466503620147705
      var_gnorm: 26.452054977416992
      vf_explained_var: 0.0
      vf_loss: 6.805333137512207
    num_steps_sampled: 3750000
    num_steps_trained: 3750000
    wait_time_ms: 77.38
  iterations_since_restore: 750
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6531.633759975433
  time_this_iter_s: 8.322608947753906
  time_total_s: 6531.633759975433
  timestamp: 1594862557
  timesteps_since_restore: 3750000
  timesteps_this_iter: 5000
  timesteps_total: 3750000
  training_iteration: 750
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6531 s, 750 iter, 3750000 ts, -678 rew

agent-1: -206.65037424644737
agent-2: -157.92422959049472
agent-3: -63.5979909705042
agent-4: -146.91661625729665
agent-5: -235.41416734701875
Extrinsic Rewards:
3
4
2
0
7
Sum Reward: 16
Avg Reward: 3.2
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.4
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-22-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -677.6241486184965
  episode_reward_min: -880.5571129244336
  episodes_this_iter: 1
  episodes_total: 750
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.026
    dispatch_time_ms: 6.297
    learner:
      cur_lr: 0.0011102500138804317
      grad_gnorm: 6.119528293609619
      policy_entropy: 47.47149658203125
      policy_loss: 2.4769465923309326
      var_gnorm: 26.393430709838867
      vf_explained_var: 0.0
      vf_loss: 4.558074951171875
    num_steps_sampled: 3755000
    num_steps_trained: 3755000
    wait_time_ms: 77.976
  iterations_since_restore: 751
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6539.993372440338
  time_this_iter_s: 8.359612464904785
  time_total_s: 6539.993372440338
  timestamp: 1594862565
  timesteps_since_restore: 3755000
  timesteps_this_iter: 5000
  timesteps_total: 3755000
  training_iteration: 751
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6539 s, 751 iter, 3755000 ts, -678 rew

agent-1: -170.58250157832657
agent-2: -41.02512981329719
agent-3: -193.87137112659906
agent-4: -111.47205673291386
agent-5: -178.95165373580733
Extrinsic Rewards:
4
7
9
4
5
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 4
Max Reward: 9
Gini Coefficient: 0.1793103448275862
20:20 Ratio: 2.25
Max-min Ratio: 2.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-22-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -676.5231386305655
  episode_reward_min: -880.5571129244336
  episodes_this_iter: 1
  episodes_total: 751
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.958
    dispatch_time_ms: 6.559
    learner:
      cur_lr: 0.0011099169496446848
      grad_gnorm: 39.069488525390625
      policy_entropy: 52.91084289550781
      policy_loss: 12.461114883422852
      var_gnorm: 26.43419075012207
      vf_explained_var: 0.0
      vf_loss: 8.849385261535645
    num_steps_sampled: 3760000
    num_steps_trained: 3760000
    wait_time_ms: 76.546
  iterations_since_restore: 752
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6548.347697257996
  time_this_iter_s: 8.35432481765747
  time_total_s: 6548.347697257996
  timestamp: 1594862573
  timesteps_since_restore: 3760000
  timesteps_this_iter: 5000
  timesteps_total: 3760000
  training_iteration: 752
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6548 s, 752 iter, 3760000 ts, -677 rew

agent-1: -141.69286938645632
agent-2: -248.38094354813643
agent-3: -142.5543435860006
agent-4: -140.26423585702557
agent-5: -129.59771122355568
Extrinsic Rewards:
3
7
0
5
4
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.3368421052631579
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-23-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -678.3921449961869
  episode_reward_min: -880.5571129244336
  episodes_this_iter: 1
  episodes_total: 752
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.706
    dispatch_time_ms: 7.48
    learner:
      cur_lr: 0.0011095840018242598
      grad_gnorm: 7.492196083068848
      policy_entropy: 51.720237731933594
      policy_loss: 2.4101719856262207
      var_gnorm: 26.407541275024414
      vf_explained_var: 0.0
      vf_loss: 6.793618202209473
    num_steps_sampled: 3765000
    num_steps_trained: 3765000
    wait_time_ms: 73.858
  iterations_since_restore: 753
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6556.809606075287
  time_this_iter_s: 8.46190881729126
  time_total_s: 6556.809606075287
  timestamp: 1594862582
  timesteps_since_restore: 3765000
  timesteps_this_iter: 5000
  timesteps_total: 3765000
  training_iteration: 753
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6556 s, 753 iter, 3765000 ts, -678 rew

agent-1: -182.11836275395788
agent-2: -164.5157136801598
agent-3: -36.96958550012177
agent-4: -234.74777709321944
agent-5: -48.97852640775509
Extrinsic Rewards:
4
7
2
7
2
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 2
Max Reward: 7
Gini Coefficient: 0.2727272727272727
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-23-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -678.3846541943799
  episode_reward_min: -880.5571129244336
  episodes_this_iter: 1
  episodes_total: 753
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.028
    dispatch_time_ms: 8.398
    learner:
      cur_lr: 0.0011092510540038347
      grad_gnorm: 9.106609344482422
      policy_entropy: 51.01740646362305
      policy_loss: -1.939795732498169
      var_gnorm: 26.401363372802734
      vf_explained_var: 0.0
      vf_loss: 3.0514938831329346
    num_steps_sampled: 3770000
    num_steps_trained: 3770000
    wait_time_ms: 71.637
  iterations_since_restore: 754
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6565.152951955795
  time_this_iter_s: 8.343345880508423
  time_total_s: 6565.152951955795
  timestamp: 1594862590
  timesteps_since_restore: 3770000
  timesteps_this_iter: 5000
  timesteps_total: 3770000
  training_iteration: 754
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6565 s, 754 iter, 3770000 ts, -678 rew

agent-1: -163.27491165968297
agent-2: -91.77627670216498
agent-3: -117.72893651228739
agent-4: -237.20737288812134
agent-5: -89.6473500878976
Extrinsic Rewards:
4
2
2
7
2
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 2
Max Reward: 7
Gini Coefficient: 0.2823529411764706
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-23-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -677.5205667554493
  episode_reward_min: -880.5571129244336
  episodes_this_iter: 1
  episodes_total: 754
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.609
    dispatch_time_ms: 6.339
    learner:
      cur_lr: 0.0011089179897680879
      grad_gnorm: 9.399022102355957
      policy_entropy: 52.8922004699707
      policy_loss: -1.7256783246994019
      var_gnorm: 26.399307250976562
      vf_explained_var: 0.0
      vf_loss: 3.5094423294067383
    num_steps_sampled: 3775000
    num_steps_trained: 3775000
    wait_time_ms: 78.161
  iterations_since_restore: 755
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6573.530049800873
  time_this_iter_s: 8.377097845077515
  time_total_s: 6573.530049800873
  timestamp: 1594862599
  timesteps_since_restore: 3775000
  timesteps_this_iter: 5000
  timesteps_total: 3775000
  training_iteration: 755
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6573 s, 755 iter, 3775000 ts, -678 rew

agent-1: -186.87222300093848
agent-2: -129.3686438422029
agent-3: -160.72301708598457
agent-4: -29.6023347086732
agent-5: -183.12078957062727
Extrinsic Rewards:
7
7
6
6
13
Sum Reward: 39
Avg Reward: 7.8
Min Reward: 6
Max Reward: 13
Gini Coefficient: 0.15384615384615385
20:20 Ratio: 2.1666666666666665
Max-min Ratio: 2.1666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-23-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -678.5444918882316
  episode_reward_min: -880.5571129244336
  episodes_this_iter: 1
  episodes_total: 755
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.638
    dispatch_time_ms: 9.333
    learner:
      cur_lr: 0.0011085850419476628
      grad_gnorm: 5.44060754776001
      policy_entropy: 51.70829772949219
      policy_loss: 0.3240751624107361
      var_gnorm: 26.404895782470703
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 3.507312059402466
    num_steps_sampled: 3780000
    num_steps_trained: 3780000
    wait_time_ms: 73.573
  iterations_since_restore: 756
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6581.889916419983
  time_this_iter_s: 8.359866619110107
  time_total_s: 6581.889916419983
  timestamp: 1594862607
  timesteps_since_restore: 3780000
  timesteps_this_iter: 5000
  timesteps_total: 3780000
  training_iteration: 756
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6581 s, 756 iter, 3780000 ts, -679 rew

agent-1: -80.96925466237523
agent-2: -167.10638507675486
agent-3: -113.80344018525733
agent-4: -93.76238395172966
agent-5: -232.25160490542163
Extrinsic Rewards:
3
4
2
6
6
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 2
Max Reward: 6
Gini Coefficient: 0.20952380952380953
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-23-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -678.2785184801322
  episode_reward_min: -880.5571129244336
  episodes_this_iter: 1
  episodes_total: 756
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.838
    dispatch_time_ms: 7.505
    learner:
      cur_lr: 0.001108251977711916
      grad_gnorm: 14.193058013916016
      policy_entropy: 47.75214767456055
      policy_loss: 1.1178139448165894
      var_gnorm: 26.37842559814453
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 8.474498748779297
    num_steps_sampled: 3785000
    num_steps_trained: 3785000
    wait_time_ms: 73.231
  iterations_since_restore: 757
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6590.2770273685455
  time_this_iter_s: 8.387110948562622
  time_total_s: 6590.2770273685455
  timestamp: 1594862615
  timesteps_since_restore: 3785000
  timesteps_this_iter: 5000
  timesteps_total: 3785000
  training_iteration: 757
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6590 s, 757 iter, 3785000 ts, -678 rew

agent-1: -71.4620247861976
agent-2: -240.53823939950095
agent-3: -57.424622144391634
agent-4: -215.23128314860827
agent-5: -29.660526325882103
Extrinsic Rewards:
3
12
3
6
3
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 3
Max Reward: 12
Gini Coefficient: 0.3111111111111111
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-23-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -679.2032736399156
  episode_reward_min: -880.5571129244336
  episodes_this_iter: 1
  episodes_total: 757
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.793
    dispatch_time_ms: 8.419
    learner:
      cur_lr: 0.001107919029891491
      grad_gnorm: 9.064208030700684
      policy_entropy: 47.354454040527344
      policy_loss: -1.4433059692382812
      var_gnorm: 26.37470817565918
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 5.844586372375488
    num_steps_sampled: 3790000
    num_steps_trained: 3790000
    wait_time_ms: 72.738
  iterations_since_restore: 758
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6598.7125062942505
  time_this_iter_s: 8.435478925704956
  time_total_s: 6598.7125062942505
  timestamp: 1594862624
  timesteps_since_restore: 3790000
  timesteps_this_iter: 5000
  timesteps_total: 3790000
  training_iteration: 758
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6598 s, 758 iter, 3790000 ts, -679 rew

agent-1: -150.1452721855887
agent-2: -28.80596001873582
agent-3: -91.41066392448674
agent-4: -213.48136442695005
agent-5: -192.15557002701024
Extrinsic Rewards:
3
5
4
13
9
Sum Reward: 34
Avg Reward: 6.8
Min Reward: 3
Max Reward: 13
Gini Coefficient: 0.29411764705882354
20:20 Ratio: 4.333333333333333
Max-min Ratio: 4.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-23-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -679.8127765635809
  episode_reward_min: -880.5571129244336
  episodes_this_iter: 1
  episodes_total: 758
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.465
    dispatch_time_ms: 6.285
    learner:
      cur_lr: 0.001107585965655744
      grad_gnorm: 16.89076805114746
      policy_entropy: 54.17096710205078
      policy_loss: -0.5995197296142578
      var_gnorm: 26.38469123840332
      vf_explained_var: 0.0
      vf_loss: 5.846259593963623
    num_steps_sampled: 3795000
    num_steps_trained: 3795000
    wait_time_ms: 78.3
  iterations_since_restore: 759
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6607.097631454468
  time_this_iter_s: 8.385125160217285
  time_total_s: 6607.097631454468
  timestamp: 1594862632
  timesteps_since_restore: 3795000
  timesteps_this_iter: 5000
  timesteps_total: 3795000
  training_iteration: 759
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6607 s, 759 iter, 3795000 ts, -680 rew

agent-1: -166.17250215205468
agent-2: -237.29728503011265
agent-3: -65.04978118633753
agent-4: -28.645134234889667
agent-5: -176.96315017916208
Extrinsic Rewards:
6
8
2
1
5
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.32727272727272727
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-24-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -677.7484839621621
  episode_reward_min: -841.4339898694351
  episodes_this_iter: 1
  episodes_total: 759
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.516
    dispatch_time_ms: 6.289
    learner:
      cur_lr: 0.001107253017835319
      grad_gnorm: 40.0
      policy_entropy: 54.86185073852539
      policy_loss: 15.144439697265625
      var_gnorm: 26.41478729248047
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 16.65764617919922
    num_steps_sampled: 3800000
    num_steps_trained: 3800000
    wait_time_ms: 74.22
  iterations_since_restore: 760
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6615.506798744202
  time_this_iter_s: 8.409167289733887
  time_total_s: 6615.506798744202
  timestamp: 1594862641
  timesteps_since_restore: 3800000
  timesteps_this_iter: 5000
  timesteps_total: 3800000
  training_iteration: 760
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6615 s, 760 iter, 3800000 ts, -678 rew

agent-1: -110.4847678457171
agent-2: -154.85253812420203
agent-3: -180.01024783515246
agent-4: -231.56893167656122
agent-5: -73.35545724964982
Extrinsic Rewards:
0
6
4
16
6
Sum Reward: 32
Avg Reward: 6.4
Min Reward: 0
Max Reward: 16
Gini Coefficient: 0.425
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-24-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -679.6613733644606
  episode_reward_min: -841.4339898694351
  episodes_this_iter: 1
  episodes_total: 760
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.704
    dispatch_time_ms: 7.364
    learner:
      cur_lr: 0.0011069199535995722
      grad_gnorm: 7.6479291915893555
      policy_entropy: 42.340145111083984
      policy_loss: 1.4717445373535156
      var_gnorm: 26.395906448364258
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 4.6309380531311035
    num_steps_sampled: 3805000
    num_steps_trained: 3805000
    wait_time_ms: 72.771
  iterations_since_restore: 761
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6623.815998077393
  time_this_iter_s: 8.309199333190918
  time_total_s: 6623.815998077393
  timestamp: 1594862649
  timesteps_since_restore: 3805000
  timesteps_this_iter: 5000
  timesteps_total: 3805000
  training_iteration: 761
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6623 s, 761 iter, 3805000 ts, -680 rew

agent-1: -236.78848056712667
agent-2: -101.83823293153402
agent-3: -121.41687622740359
agent-4: -156.1586554498379
agent-5: -48.66075626276292
Extrinsic Rewards:
9
8
3
2
3
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 2
Max Reward: 9
Gini Coefficient: 0.304
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-24-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -679.2784763440884
  episode_reward_min: -841.4339898694351
  episodes_this_iter: 1
  episodes_total: 761
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.926
    dispatch_time_ms: 9.992
    learner:
      cur_lr: 0.0011065870057791471
      grad_gnorm: 10.466817855834961
      policy_entropy: 38.9634895324707
      policy_loss: 6.313088893890381
      var_gnorm: 26.38599967956543
      vf_explained_var: 0.0
      vf_loss: 5.084030628204346
    num_steps_sampled: 3810000
    num_steps_trained: 3810000
    wait_time_ms: 71.416
  iterations_since_restore: 762
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6632.286018371582
  time_this_iter_s: 8.470020294189453
  time_total_s: 6632.286018371582
  timestamp: 1594862658
  timesteps_since_restore: 3810000
  timesteps_this_iter: 5000
  timesteps_total: 3810000
  training_iteration: 762
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6632 s, 762 iter, 3810000 ts, -679 rew

agent-1: -44.14492138778534
agent-2: -75.60628820573258
agent-3: -238.51145615709916
agent-4: -47.29441406003766
agent-5: -223.0786377551033
Extrinsic Rewards:
2
2
11
2
8
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 2
Max Reward: 11
Gini Coefficient: 0.384
20:20 Ratio: 5.5
Max-min Ratio: 5.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-24-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -677.9211653543452
  episode_reward_min: -841.4339898694351
  episodes_this_iter: 1
  episodes_total: 762
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.618
    dispatch_time_ms: 6.545
    learner:
      cur_lr: 0.0011062540579587221
      grad_gnorm: 12.820037841796875
      policy_entropy: 50.54339599609375
      policy_loss: -2.4747185707092285
      var_gnorm: 26.384418487548828
      vf_explained_var: 0.0
      vf_loss: 6.1776275634765625
    num_steps_sampled: 3815000
    num_steps_trained: 3815000
    wait_time_ms: 77.209
  iterations_since_restore: 763
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6640.632029056549
  time_this_iter_s: 8.346010684967041
  time_total_s: 6640.632029056549
  timestamp: 1594862666
  timesteps_since_restore: 3815000
  timesteps_this_iter: 5000
  timesteps_total: 3815000
  training_iteration: 763
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6640 s, 763 iter, 3815000 ts, -678 rew

agent-1: -220.5354245623066
agent-2: -85.54442427165219
agent-3: -101.38884530123003
agent-4: -36.14767726025719
agent-5: -224.46097819268894
Extrinsic Rewards:
4
4
2
2
7
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 2
Max Reward: 7
Gini Coefficient: 0.25263157894736843
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-24-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -679.1459048075515
  episode_reward_min: -841.4339898694351
  episodes_this_iter: 1
  episodes_total: 763
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.255
    dispatch_time_ms: 7.863
    learner:
      cur_lr: 0.0011059209937229753
      grad_gnorm: 6.173656463623047
      policy_entropy: 33.51918411254883
      policy_loss: 1.9980852603912354
      var_gnorm: 26.3852481842041
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 8.051912307739258
    num_steps_sampled: 3820000
    num_steps_trained: 3820000
    wait_time_ms: 72.314
  iterations_since_restore: 764
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6648.949286222458
  time_this_iter_s: 8.317257165908813
  time_total_s: 6648.949286222458
  timestamp: 1594862674
  timesteps_since_restore: 3820000
  timesteps_this_iter: 5000
  timesteps_total: 3820000
  training_iteration: 764
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6648 s, 764 iter, 3820000 ts, -679 rew

agent-1: -68.06279321288116
agent-2: -105.68632597725775
agent-3: -41.86786358881078
agent-4: -185.9921142786254
agent-5: -240.80597821859538
Extrinsic Rewards:
7
4
2
4
12
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 2
Max Reward: 12
Gini Coefficient: 0.31724137931034485
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-24-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -678.8955363971244
  episode_reward_min: -841.4339898694351
  episodes_this_iter: 1
  episodes_total: 764
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.744
    dispatch_time_ms: 9.216
    learner:
      cur_lr: 0.0011055880459025502
      grad_gnorm: 13.497845649719238
      policy_entropy: 30.56545639038086
      policy_loss: -4.733094692230225
      var_gnorm: 26.402587890625
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.5737245082855225
    num_steps_sampled: 3825000
    num_steps_trained: 3825000
    wait_time_ms: 72.496
  iterations_since_restore: 765
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6657.344926834106
  time_this_iter_s: 8.39564061164856
  time_total_s: 6657.344926834106
  timestamp: 1594862683
  timesteps_since_restore: 3825000
  timesteps_this_iter: 5000
  timesteps_total: 3825000
  training_iteration: 765
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6657 s, 765 iter, 3825000 ts, -679 rew

agent-1: -176.8453946476189
agent-2: -119.0608210416537
agent-3: -36.14291359505182
agent-4: -154.2988099442928
agent-5: -187.03451076248413
Extrinsic Rewards:
10
5
6
1
11
Sum Reward: 33
Avg Reward: 6.6
Min Reward: 1
Max Reward: 11
Gini Coefficient: 0.30303030303030304
20:20 Ratio: 11.0
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-24-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -677.754180893634
  episode_reward_min: -841.4339898694351
  episodes_this_iter: 1
  episodes_total: 765
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.813
    dispatch_time_ms: 9.353
    learner:
      cur_lr: 0.0011052549816668034
      grad_gnorm: 28.119173049926758
      policy_entropy: 24.03306770324707
      policy_loss: 8.812027931213379
      var_gnorm: 26.418731689453125
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 10.045827865600586
    num_steps_sampled: 3830000
    num_steps_trained: 3830000
    wait_time_ms: 70.154
  iterations_since_restore: 766
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6665.7639265060425
  time_this_iter_s: 8.418999671936035
  time_total_s: 6665.7639265060425
  timestamp: 1594862691
  timesteps_since_restore: 3830000
  timesteps_this_iter: 5000
  timesteps_total: 3830000
  training_iteration: 766
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6665 s, 766 iter, 3830000 ts, -678 rew

agent-1: -117.9037044882298
agent-2: -160.37027260349996
agent-3: -155.94856556243425
agent-4: -165.1094048825636
agent-5: -126.62749544556794
Extrinsic Rewards:
2
4
10
9
7
Sum Reward: 32
Avg Reward: 6.4
Min Reward: 2
Max Reward: 10
Gini Coefficient: 0.2625
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-25-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -678.7088344620672
  episode_reward_min: -841.4339898694351
  episodes_this_iter: 1
  episodes_total: 766
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.275
    dispatch_time_ms: 9.198
    learner:
      cur_lr: 0.0011049220338463783
      grad_gnorm: 6.678086280822754
      policy_entropy: 49.076534271240234
      policy_loss: 0.6078458428382874
      var_gnorm: 26.405696868896484
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 6.975739002227783
    num_steps_sampled: 3835000
    num_steps_trained: 3835000
    wait_time_ms: 71.326
  iterations_since_restore: 767
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6691.353023290634
  time_this_iter_s: 25.589096784591675
  time_total_s: 6691.353023290634
  timestamp: 1594862717
  timesteps_since_restore: 3835000
  timesteps_this_iter: 5000
  timesteps_total: 3835000
  training_iteration: 767
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6691 s, 767 iter, 3835000 ts, -679 rew

agent-1: -211.17993504532802
agent-2: -30.969159073390085
agent-3: -113.52758698562099
agent-4: -218.24313901909852
agent-5: -69.37029218915355
Extrinsic Rewards:
7
5
1
11
5
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 1
Max Reward: 11
Gini Coefficient: 0.30344827586206896
20:20 Ratio: 11.0
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-25-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -678.6780462666574
  episode_reward_min: -841.4339898694351
  episodes_this_iter: 1
  episodes_total: 767
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.64
    dispatch_time_ms: 7.532
    learner:
      cur_lr: 0.0011045889696106315
      grad_gnorm: 9.670652389526367
      policy_entropy: 52.38459014892578
      policy_loss: -3.0240941047668457
      var_gnorm: 26.41379165649414
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.8255919814109802
    num_steps_sampled: 3840000
    num_steps_trained: 3840000
    wait_time_ms: 72.497
  iterations_since_restore: 768
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6699.709209442139
  time_this_iter_s: 8.356186151504517
  time_total_s: 6699.709209442139
  timestamp: 1594862725
  timesteps_since_restore: 3840000
  timesteps_this_iter: 5000
  timesteps_total: 3840000
  training_iteration: 768
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6699 s, 768 iter, 3840000 ts, -679 rew

agent-1: -118.3289170167757
agent-2: -180.0106224915444
agent-3: -168.76636246683066
agent-4: -132.1856924904281
agent-5: -132.1456570585427
Extrinsic Rewards:
6
8
7
8
6
Sum Reward: 35
Avg Reward: 7.0
Min Reward: 6
Max Reward: 8
Gini Coefficient: 0.06857142857142857
20:20 Ratio: 1.3333333333333333
Max-min Ratio: 1.3333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-25-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -679.3697458653879
  episode_reward_min: -841.4339898694351
  episodes_this_iter: 1
  episodes_total: 768
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.654
    dispatch_time_ms: 7.578
    learner:
      cur_lr: 0.0011042560217902064
      grad_gnorm: 16.856252670288086
      policy_entropy: 51.299739837646484
      policy_loss: 5.746359825134277
      var_gnorm: 26.378698348999023
      vf_explained_var: 0.0
      vf_loss: 7.305501461029053
    num_steps_sampled: 3845000
    num_steps_trained: 3845000
    wait_time_ms: 77.24
  iterations_since_restore: 769
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6708.122275590897
  time_this_iter_s: 8.413066148757935
  time_total_s: 6708.122275590897
  timestamp: 1594862734
  timesteps_since_restore: 3845000
  timesteps_this_iter: 5000
  timesteps_total: 3845000
  training_iteration: 769
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6708 s, 769 iter, 3845000 ts, -679 rew

agent-1: -29.088161059879067
agent-2: -267.5714257603406
agent-3: -162.02498147256495
agent-4: -55.67395917953083
agent-5: -84.8158203942498
Extrinsic Rewards:
1
10
4
1
2
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 1
Max Reward: 10
Gini Coefficient: 0.4666666666666667
20:20 Ratio: 10.0
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-25-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -678.4503219053294
  episode_reward_min: -841.4339898694351
  episodes_this_iter: 1
  episodes_total: 769
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.886
    dispatch_time_ms: 6.717
    learner:
      cur_lr: 0.0011039229575544596
      grad_gnorm: 17.736679077148438
      policy_entropy: 34.049522399902344
      policy_loss: -6.317385673522949
      var_gnorm: 26.376296997070312
      vf_explained_var: 0.0
      vf_loss: 8.759215354919434
    num_steps_sampled: 3850000
    num_steps_trained: 3850000
    wait_time_ms: 75.563
  iterations_since_restore: 770
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6716.582698345184
  time_this_iter_s: 8.46042275428772
  time_total_s: 6716.582698345184
  timestamp: 1594862742
  timesteps_since_restore: 3850000
  timesteps_this_iter: 5000
  timesteps_total: 3850000
  training_iteration: 770
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6716 s, 770 iter, 3850000 ts, -678 rew

agent-1: -177.03008331381574
agent-2: -52.169823407008835
agent-3: -78.46644598962936
agent-4: -41.46891852471404
agent-5: -243.95153086371363
Extrinsic Rewards:
6
4
5
4
15
Sum Reward: 34
Avg Reward: 6.8
Min Reward: 4
Max Reward: 15
Gini Coefficient: 0.2823529411764706
20:20 Ratio: 3.75
Max-min Ratio: 3.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-25-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -677.3158420973831
  episode_reward_min: -841.4339898694351
  episodes_this_iter: 1
  episodes_total: 770
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.446
    dispatch_time_ms: 8.443
    learner:
      cur_lr: 0.0011035900097340345
      grad_gnorm: 8.80278491973877
      policy_entropy: 38.10132598876953
      policy_loss: -5.183560848236084
      var_gnorm: 26.400901794433594
      vf_explained_var: 0.0
      vf_loss: 5.9988932609558105
    num_steps_sampled: 3855000
    num_steps_trained: 3855000
    wait_time_ms: 73.296
  iterations_since_restore: 771
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6724.990587472916
  time_this_iter_s: 8.407889127731323
  time_total_s: 6724.990587472916
  timestamp: 1594862751
  timesteps_since_restore: 3855000
  timesteps_this_iter: 5000
  timesteps_total: 3855000
  training_iteration: 771
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6724 s, 771 iter, 3855000 ts, -677 rew

agent-1: -303.99200714580934
agent-2: -630.6265398490033
agent-3: -443.84664449661716
agent-4: -472.3621401179529
agent-5: -528.9455542557947
Extrinsic Rewards:
-158
-398
-254
-249
-453
Sum Reward: -1512
Avg Reward: -302.4
Min Reward: -453
Max Reward: -158
Gini Coefficient: -0.1955026455026455
20:20 Ratio: 0.3487858719646799
Max-min Ratio: 0.3487858719646799
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-25-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -694.6457681991272
  episode_reward_min: -2379.7728858651935
  episodes_this_iter: 1
  episodes_total: 771
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.823
    dispatch_time_ms: 7.07
    learner:
      cur_lr: 0.0011032569454982877
      grad_gnorm: 40.0
      policy_entropy: 57.00970458984375
      policy_loss: -233.54734802246094
      var_gnorm: 26.64788055419922
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5739.71337890625
    num_steps_sampled: 3860000
    num_steps_trained: 3860000
    wait_time_ms: 76.974
  iterations_since_restore: 772
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6733.398225545883
  time_this_iter_s: 8.40763807296753
  time_total_s: 6733.398225545883
  timestamp: 1594862759
  timesteps_since_restore: 3860000
  timesteps_this_iter: 5000
  timesteps_total: 3860000
  training_iteration: 772
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6733 s, 772 iter, 3860000 ts, -695 rew

agent-1: -1237.3153258430727
agent-2: -1090.5234797139458
agent-3: -1449.0876079598447
agent-4: -2143.2535730680675
agent-5: -1244.668744685986
Extrinsic Rewards:
-1025
-991
-1332
-1929
-1097
Sum Reward: -6374
Avg Reward: -1274.8
Min Reward: -1929
Max Reward: -991
Gini Coefficient: -0.1369940382805146
20:20 Ratio: 0.5137376879212027
Max-min Ratio: 0.5137376879212027
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-26-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -759.273304789838
  episode_reward_min: -7164.848731270915
  episodes_this_iter: 1
  episodes_total: 772
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.499
    dispatch_time_ms: 6.657
    learner:
      cur_lr: 0.0011029239976778626
      grad_gnorm: 39.999996185302734
      policy_entropy: 55.90605926513672
      policy_loss: -499.6317443847656
      var_gnorm: 26.893720626831055
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 19089.921875
    num_steps_sampled: 3865000
    num_steps_trained: 3865000
    wait_time_ms: 76.697
  iterations_since_restore: 773
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6742.2983684539795
  time_this_iter_s: 8.900142908096313
  time_total_s: 6742.2983684539795
  timestamp: 1594862768
  timesteps_since_restore: 3865000
  timesteps_this_iter: 5000
  timesteps_total: 3865000
  training_iteration: 773
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6742 s, 773 iter, 3865000 ts, -759 rew

agent-1: -14457.72263125928
agent-2: -11104.623937672362
agent-3: -10055.760163512525
agent-4: -11845.26857487363
agent-5: -11447.947169153133
Extrinsic Rewards:
-14275
-10967
-9918
-11688
-11304
Sum Reward: -58152
Avg Reward: -11630.4
Min Reward: -14275
Max Reward: -9918
Gini Coefficient: -0.06489888567891045
20:20 Ratio: 0.6947810858143608
Max-min Ratio: 0.6947810858143608
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-26-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -1341.8020038216232
  episode_reward_min: -58911.32247647085
  episodes_this_iter: 1
  episodes_total: 773
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.964
    dispatch_time_ms: 8.98
    learner:
      cur_lr: 0.0011025910498574376
      grad_gnorm: 39.999996185302734
      policy_entropy: 55.06563186645508
      policy_loss: -3742.04345703125
      var_gnorm: 27.143131256103516
      vf_explained_var: 0.0
      vf_loss: 267386.625
    num_steps_sampled: 3870000
    num_steps_trained: 3870000
    wait_time_ms: 74.178
  iterations_since_restore: 774
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6750.927437543869
  time_this_iter_s: 8.629069089889526
  time_total_s: 6750.927437543869
  timestamp: 1594862777
  timesteps_since_restore: 3870000
  timesteps_this_iter: 5000
  timesteps_total: 3870000
  training_iteration: 774
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6750 s, 774 iter, 3870000 ts, -1.34e+03 rew

agent-1: -10766.520016281725
agent-2: -11187.222870095093
agent-3: -9140.675981816972
agent-4: -11582.018683737339
agent-5: -12138.45286437049
Extrinsic Rewards:
-10618
-11033
-9013
-11417
-11977
Sum Reward: -54058
Avg Reward: -10811.6
Min Reward: -11977
Max Reward: -9013
Gini Coefficient: -0.04977616633985719
20:20 Ratio: 0.7525256742089004
Max-min Ratio: 0.7525256742089004
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-26-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -1881.68532187629
  episode_reward_min: -58911.32247647085
  episodes_this_iter: 1
  episodes_total: 774
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.751
    dispatch_time_ms: 8.096
    learner:
      cur_lr: 0.0011022579856216908
      grad_gnorm: 40.000003814697266
      policy_entropy: 53.32572937011719
      policy_loss: -7802.95654296875
      var_gnorm: 27.440210342407227
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 642249.8125
    num_steps_sampled: 3875000
    num_steps_trained: 3875000
    wait_time_ms: 78.314
  iterations_since_restore: 775
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6759.614027500153
  time_this_iter_s: 8.68658995628357
  time_total_s: 6759.614027500153
  timestamp: 1594862785
  timesteps_since_restore: 3875000
  timesteps_this_iter: 5000
  timesteps_total: 3875000
  training_iteration: 775
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6759 s, 775 iter, 3875000 ts, -1.88e+03 rew

agent-1: -13056.924350666914
agent-2: -17437.798260865304
agent-3: -16917.704226999595
agent-4: -14878.067376497474
agent-5: -14233.440093154937
Extrinsic Rewards:
-12919
-17275
-16753
-14729
-14089
Sum Reward: -75765
Avg Reward: -15153.0
Min Reward: -17275
Max Reward: -12919
Gini Coefficient: -0.06005939417937042
20:20 Ratio: 0.7478437047756874
Max-min Ratio: 0.7478437047756874
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-26-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -2641.2832694393214
  episode_reward_min: -76523.93430818443
  episodes_this_iter: 1
  episodes_total: 775
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.845
    dispatch_time_ms: 7.28
    learner:
      cur_lr: 0.0011019250378012657
      grad_gnorm: 40.0
      policy_entropy: 40.858245849609375
      policy_loss: -1674.644775390625
      var_gnorm: 27.746179580688477
      vf_explained_var: 0.0
      vf_loss: 491450.84375
    num_steps_sampled: 3880000
    num_steps_trained: 3880000
    wait_time_ms: 77.004
  iterations_since_restore: 776
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6768.345141887665
  time_this_iter_s: 8.731114387512207
  time_total_s: 6768.345141887665
  timestamp: 1594862794
  timesteps_since_restore: 3880000
  timesteps_this_iter: 5000
  timesteps_total: 3880000
  training_iteration: 776
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6768 s, 776 iter, 3880000 ts, -2.64e+03 rew

agent-1: -16325.57398834351
agent-2: -15244.848140100707
agent-3: -16297.055774149323
agent-4: -19482.94441319849
agent-5: -12761.31567481097
Extrinsic Rewards:
-16183
-15101
-16140
-19306
-12627
Sum Reward: -79357
Avg Reward: -15871.4
Min Reward: -19306
Max Reward: -12627
Gini Coefficient: -0.07278500951396852
20:20 Ratio: 0.6540453744949757
Max-min Ratio: 0.6540453744949757
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-26-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -3437.344655586081
  episode_reward_min: -80111.73799060278
  episodes_this_iter: 1
  episodes_total: 776
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.874
    dispatch_time_ms: 8.513
    learner:
      cur_lr: 0.0011015919735655189
      grad_gnorm: 40.0
      policy_entropy: 41.67813491821289
      policy_loss: -3446.77294921875
      var_gnorm: 28.061426162719727
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 516915.375
    num_steps_sampled: 3885000
    num_steps_trained: 3885000
    wait_time_ms: 72.061
  iterations_since_restore: 777
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6776.705501794815
  time_this_iter_s: 8.360359907150269
  time_total_s: 6776.705501794815
  timestamp: 1594862803
  timesteps_since_restore: 3885000
  timesteps_this_iter: 5000
  timesteps_total: 3885000
  training_iteration: 777
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6776 s, 777 iter, 3885000 ts, -3.44e+03 rew

agent-1: -20843.604182912863
agent-2: -27772.305833676237
agent-3: -17486.52370333498
agent-4: -18634.498757916925
agent-5: -25776.65736397007
Extrinsic Rewards:
-20711
-27600
-17364
-18506
-25616
Sum Reward: -109797
Avg Reward: -21959.4
Min Reward: -27600
Max Reward: -17364
Gini Coefficient: -0.100483619771032
20:20 Ratio: 0.6291304347826087
Max-min Ratio: 0.6291304347826087
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-26-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -4536.209195830615
  episode_reward_min: -110513.5898418109
  episodes_this_iter: 1
  episodes_total: 777
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.968
    dispatch_time_ms: 7.787
    learner:
      cur_lr: 0.0011012590257450938
      grad_gnorm: 40.0
      policy_entropy: 29.70669174194336
      policy_loss: -2135.8359375
      var_gnorm: 28.392044067382812
      vf_explained_var: 0.0
      vf_loss: 505750.03125
    num_steps_sampled: 3890000
    num_steps_trained: 3890000
    wait_time_ms: 74.665
  iterations_since_restore: 778
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6785.133896827698
  time_this_iter_s: 8.42839503288269
  time_total_s: 6785.133896827698
  timestamp: 1594862811
  timesteps_since_restore: 3890000
  timesteps_this_iter: 5000
  timesteps_total: 3890000
  training_iteration: 778
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6785 s, 778 iter, 3890000 ts, -4.54e+03 rew

agent-1: -27717.836171414696
agent-2: -21881.843825996246
agent-3: -27147.058495264322
agent-4: -17507.392588060455
agent-5: -23148.0694630063
Extrinsic Rewards:
-27549
-21747
-26980
-17393
-23014
Sum Reward: -116683
Avg Reward: -23336.6
Min Reward: -27549
Max Reward: -17393
Gini Coefficient: -0.08757059725924085
20:20 Ratio: 0.6313477803187049
Max-min Ratio: 0.6313477803187049
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-27-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -5703.595854037023
  episode_reward_min: -117402.20054374219
  episodes_this_iter: 1
  episodes_total: 778
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.081
    dispatch_time_ms: 6.462
    learner:
      cur_lr: 0.001100925961509347
      grad_gnorm: 40.0
      policy_entropy: 34.30518341064453
      policy_loss: -3341.930908203125
      var_gnorm: 28.74036407470703
      vf_explained_var: 0.0
      vf_loss: 912776.5
    num_steps_sampled: 3895000
    num_steps_trained: 3895000
    wait_time_ms: 78.598
  iterations_since_restore: 779
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6793.644752264023
  time_this_iter_s: 8.510855436325073
  time_total_s: 6793.644752264023
  timestamp: 1594862820
  timesteps_since_restore: 3895000
  timesteps_this_iter: 5000
  timesteps_total: 3895000
  training_iteration: 779
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6793 s, 779 iter, 3895000 ts, -5.7e+03 rew

agent-1: -23760.015264523852
agent-2: -17412.536570399352
agent-3: -26557.80922263485
agent-4: -19406.550942587077
agent-5: -9947.560022265097
Extrinsic Rewards:
-23588
-17273
-26369
-19269
-9879
Sum Reward: -96378
Avg Reward: -19275.6
Min Reward: -26369
Max Reward: -9879
Gini Coefficient: -0.16308701155865446
20:20 Ratio: 0.3746444688839167
Max-min Ratio: 0.3746444688839167
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-27-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -6667.3256967809575
  episode_reward_min: -117402.20054374219
  episodes_this_iter: 1
  episodes_total: 779
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.704
    dispatch_time_ms: 6.078
    learner:
      cur_lr: 0.001100593013688922
      grad_gnorm: 40.0
      policy_entropy: 35.75894546508789
      policy_loss: -3537.15283203125
      var_gnorm: 29.089923858642578
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 560762.1875
    num_steps_sampled: 3900000
    num_steps_trained: 3900000
    wait_time_ms: 76.851
  iterations_since_restore: 780
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6802.065720081329
  time_this_iter_s: 8.420967817306519
  time_total_s: 6802.065720081329
  timestamp: 1594862828
  timesteps_since_restore: 3900000
  timesteps_this_iter: 5000
  timesteps_total: 3900000
  training_iteration: 780
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6802 s, 780 iter, 3900000 ts, -6.67e+03 rew

agent-1: -20705.189625422245
agent-2: -16455.298000385552
agent-3: -29012.961173797572
agent-4: -18818.05172870369
agent-5: -22854.004136798503
Extrinsic Rewards:
-20568
-16339
-28832
-18689
-22699
Sum Reward: -107127
Avg Reward: -21425.4
Min Reward: -28832
Max Reward: -16339
Gini Coefficient: -0.10826775696136362
20:20 Ratio: 0.5666967258601554
Max-min Ratio: 0.5666967258601554
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-27-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -7739.327365605867
  episode_reward_min: -117402.20054374219
  episodes_this_iter: 1
  episodes_total: 780
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.188
    dispatch_time_ms: 9.525
    learner:
      cur_lr: 0.001100259949453175
      grad_gnorm: 40.0
      policy_entropy: 36.14114761352539
      policy_loss: -2624.191162109375
      var_gnorm: 29.454242706298828
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 664733.25
    num_steps_sampled: 3905000
    num_steps_trained: 3905000
    wait_time_ms: 70.157
  iterations_since_restore: 781
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6810.396930217743
  time_this_iter_s: 8.331210136413574
  time_total_s: 6810.396930217743
  timestamp: 1594862837
  timesteps_since_restore: 3905000
  timesteps_this_iter: 5000
  timesteps_total: 3905000
  training_iteration: 781
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6810 s, 781 iter, 3905000 ts, -7.74e+03 rew

agent-1: -31691.717640063598
agent-2: -19807.062326835698
agent-3: -21835.323815178603
agent-4: -26361.897826700966
agent-5: -20128.1720169009
Extrinsic Rewards:
-31516
-19675
-21706
-26205
-20008
Sum Reward: -119110
Avg Reward: -23822.0
Min Reward: -31516
Max Reward: -19675
Gini Coefficient: -0.10034086138863235
20:20 Ratio: 0.6242860769133138
Max-min Ratio: 0.6242860769133138
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-27-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -8930.664551541748
  episode_reward_min: -119824.1736256799
  episodes_this_iter: 1
  episodes_total: 781
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.413
    dispatch_time_ms: 6.022
    learner:
      cur_lr: 0.00109992700163275
      grad_gnorm: 40.0
      policy_entropy: 28.25374984741211
      policy_loss: -4306.177734375
      var_gnorm: 29.829952239990234
      vf_explained_var: 0.0
      vf_loss: 893929.5
    num_steps_sampled: 3910000
    num_steps_trained: 3910000
    wait_time_ms: 78.895
  iterations_since_restore: 782
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6818.896924495697
  time_this_iter_s: 8.499994277954102
  time_total_s: 6818.896924495697
  timestamp: 1594862845
  timesteps_since_restore: 3910000
  timesteps_this_iter: 5000
  timesteps_total: 3910000
  training_iteration: 782
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6818 s, 782 iter, 3910000 ts, -8.93e+03 rew

agent-1: -26463.2081773831
agent-2: -15280.993197006928
agent-3: -23460.535313348006
agent-4: -26791.950888254185
agent-5: -20638.85423962763
Extrinsic Rewards:
-26291
-15189
-23305
-26635
-20510
Sum Reward: -111930
Avg Reward: -22386.0
Min Reward: -26635
Max Reward: -15189
Gini Coefficient: -0.10246761368712588
20:20 Ratio: 0.5702646893185658
Max-min Ratio: 0.5702646893185658
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-27-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -10050.091813246669
  episode_reward_min: -119824.1736256799
  episodes_this_iter: 1
  episodes_total: 782
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.793
    dispatch_time_ms: 6.899
    learner:
      cur_lr: 0.001099594053812325
      grad_gnorm: 40.000003814697266
      policy_entropy: 38.903160095214844
      policy_loss: -2013.9483642578125
      var_gnorm: 30.2081241607666
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 486793.6875
    num_steps_sampled: 3915000
    num_steps_trained: 3915000
    wait_time_ms: 73.455
  iterations_since_restore: 783
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6827.300557136536
  time_this_iter_s: 8.403632640838623
  time_total_s: 6827.300557136536
  timestamp: 1594862853
  timesteps_since_restore: 3915000
  timesteps_this_iter: 5000
  timesteps_total: 3915000
  training_iteration: 783
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6827 s, 783 iter, 3915000 ts, -1.01e+04 rew

agent-1: -20825.756664015145
agent-2: -27026.068307006415
agent-3: -17180.895603191835
agent-4: -17241.23643332346
agent-5: -15383.898157176107
Extrinsic Rewards:
-20671
-26847
-17046
-17117
-15270
Sum Reward: -96951
Avg Reward: -19390.2
Min Reward: -26847
Max Reward: -15270
Gini Coefficient: -0.1104846778269435
20:20 Ratio: 0.5687786344842999
Max-min Ratio: 0.5687786344842999
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-27-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -11019.769320905065
  episode_reward_min: -119824.1736256799
  episodes_this_iter: 1
  episodes_total: 783
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.542
    dispatch_time_ms: 6.661
    learner:
      cur_lr: 0.0010992609895765781
      grad_gnorm: 40.0
      policy_entropy: 48.8198356628418
      policy_loss: -43.652774810791016
      var_gnorm: 30.570261001586914
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 3426.890625
    num_steps_sampled: 3920000
    num_steps_trained: 3920000
    wait_time_ms: 73.954
  iterations_since_restore: 784
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6835.554544687271
  time_this_iter_s: 8.253987550735474
  time_total_s: 6835.554544687271
  timestamp: 1594862862
  timesteps_since_restore: 3920000
  timesteps_this_iter: 5000
  timesteps_total: 3920000
  training_iteration: 784
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6835 s, 784 iter, 3920000 ts, -1.1e+04 rew

agent-1: -20720.157409451414
agent-2: -13867.816090214948
agent-3: -22829.476504114962
agent-4: -21052.823787392896
agent-5: -20387.144682616643
Extrinsic Rewards:
-20564
-13754
-22670
-20911
-20230
Sum Reward: -98129
Avg Reward: -19625.8
Min Reward: -22670
Max Reward: -13754
Gini Coefficient: -0.0754639301327844
20:20 Ratio: 0.6067048963387737
Max-min Ratio: 0.6067048963387737
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-27-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -12000.641190815113
  episode_reward_min: -119824.1736256799
  episodes_this_iter: 1
  episodes_total: 784
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.927
    dispatch_time_ms: 7.865
    learner:
      cur_lr: 0.001098928041756153
      grad_gnorm: 40.0
      policy_entropy: 56.22285842895508
      policy_loss: -2128.76953125
      var_gnorm: 30.884204864501953
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 98176.7578125
    num_steps_sampled: 3925000
    num_steps_trained: 3925000
    wait_time_ms: 75.513
  iterations_since_restore: 785
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6844.048603773117
  time_this_iter_s: 8.494059085845947
  time_total_s: 6844.048603773117
  timestamp: 1594862870
  timesteps_since_restore: 3925000
  timesteps_this_iter: 5000
  timesteps_total: 3925000
  training_iteration: 785
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6844 s, 785 iter, 3925000 ts, -1.2e+04 rew

agent-1: -8247.988270555215
agent-2: -7199.510708983951
agent-3: -8067.779961695358
agent-4: -7399.440103913712
agent-5: -7592.294345566228
Extrinsic Rewards:
-8089
-7053
-7917
-7242
-7457
Sum Reward: -37758
Avg Reward: -7551.6
Min Reward: -8089
Max Reward: -7053
Gini Coefficient: -0.029101117643943006
20:20 Ratio: 0.871924836197305
Max-min Ratio: 0.871924836197305
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-27-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -12379.567287188525
  episode_reward_min: -119824.1736256799
  episodes_this_iter: 1
  episodes_total: 785
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.551
    dispatch_time_ms: 6.655
    learner:
      cur_lr: 0.0010985949775204062
      grad_gnorm: 40.0
      policy_entropy: 61.312889099121094
      policy_loss: -2975.46728515625
      var_gnorm: 31.25533103942871
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 150031.140625
    num_steps_sampled: 3930000
    num_steps_trained: 3930000
    wait_time_ms: 76.771
  iterations_since_restore: 786
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6852.595170974731
  time_this_iter_s: 8.54656720161438
  time_total_s: 6852.595170974731
  timestamp: 1594862879
  timesteps_since_restore: 3930000
  timesteps_this_iter: 5000
  timesteps_total: 3930000
  training_iteration: 786
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6852 s, 786 iter, 3930000 ts, -1.24e+04 rew

agent-1: -6717.8608884385385
agent-2: -6217.180974386001
agent-3: -7336.851079134759
agent-4: -9702.324240133577
agent-5: -7159.261643101411
Extrinsic Rewards:
-6582
-6077
-7184
-9520
-7022
Sum Reward: -36385
Avg Reward: -7277.0
Min Reward: -9520
Max Reward: -6077
Gini Coefficient: -0.08231963721313729
20:20 Ratio: 0.6383403361344537
Max-min Ratio: 0.6383403361344537
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-28-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -12743.388577934307
  episode_reward_min: -119824.1736256799
  episodes_this_iter: 1
  episodes_total: 786
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.716
    dispatch_time_ms: 8.048
    learner:
      cur_lr: 0.0010982620296999812
      grad_gnorm: 40.0
      policy_entropy: 56.36605453491211
      policy_loss: -1819.990234375
      var_gnorm: 31.64751625061035
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 53079.25
    num_steps_sampled: 3935000
    num_steps_trained: 3935000
    wait_time_ms: 74.118
  iterations_since_restore: 787
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6861.212680339813
  time_this_iter_s: 8.617509365081787
  time_total_s: 6861.212680339813
  timestamp: 1594862887
  timesteps_since_restore: 3935000
  timesteps_this_iter: 5000
  timesteps_total: 3935000
  training_iteration: 787
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6861 s, 787 iter, 3935000 ts, -1.27e+04 rew

agent-1: -16482.69059819064
agent-2: -13557.950270444524
agent-3: -15950.757611915331
agent-4: -15106.903420261195
agent-5: -14309.565627770344
Extrinsic Rewards:
-16326
-13418
-15790
-14959
-14157
Sum Reward: -74650
Avg Reward: -14930.0
Min Reward: -16326
Max Reward: -13418
Gini Coefficient: -0.03991426657736102
20:20 Ratio: 0.8218792110743599
Max-min Ratio: 0.8218792110743599
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-28-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -13491.609256607988
  episode_reward_min: -119824.1736256799
  episodes_this_iter: 1
  episodes_total: 787
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.624
    dispatch_time_ms: 9.06
    learner:
      cur_lr: 0.0010979289654642344
      grad_gnorm: 39.999996185302734
      policy_entropy: 63.11811828613281
      policy_loss: -2224.208740234375
      var_gnorm: 32.05514144897461
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 87184.7421875
    num_steps_sampled: 3940000
    num_steps_trained: 3940000
    wait_time_ms: 74.338
  iterations_since_restore: 788
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6869.82986831665
  time_this_iter_s: 8.617187976837158
  time_total_s: 6869.82986831665
  timestamp: 1594862896
  timesteps_since_restore: 3940000
  timesteps_this_iter: 5000
  timesteps_total: 3940000
  training_iteration: 788
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6869 s, 788 iter, 3940000 ts, -1.35e+04 rew

agent-1: -14095.037327860868
agent-2: -13951.522190214748
agent-3: -15275.484787186064
agent-4: -15203.095757235507
agent-5: -15753.075427332045
Extrinsic Rewards:
-13944
-13808
-15127
-15047
-15593
Sum Reward: -73519
Avg Reward: -14703.8
Min Reward: -15593
Max Reward: -13808
Gini Coefficient: -0.025859981773419118
20:20 Ratio: 0.885525556339383
Max-min Ratio: 0.885525556339383
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-28-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -14226.358473649965
  episode_reward_min: -119824.1736256799
  episodes_this_iter: 1
  episodes_total: 788
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.249
    dispatch_time_ms: 7.522
    learner:
      cur_lr: 0.0010975960176438093
      grad_gnorm: 40.0
      policy_entropy: 62.71332931518555
      policy_loss: -7491.51416015625
      var_gnorm: 32.43815612792969
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 615781.0625
    num_steps_sampled: 3945000
    num_steps_trained: 3945000
    wait_time_ms: 73.959
  iterations_since_restore: 789
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6878.259572982788
  time_this_iter_s: 8.429704666137695
  time_total_s: 6878.259572982788
  timestamp: 1594862905
  timesteps_since_restore: 3945000
  timesteps_this_iter: 5000
  timesteps_total: 3945000
  training_iteration: 789
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6878 s, 789 iter, 3945000 ts, -1.42e+04 rew

agent-1: -9850.9125098453
agent-2: -11197.638164114058
agent-3: -12239.602563871196
agent-4: -11348.958869599057
agent-5: -9989.049138714809
Extrinsic Rewards:
-9710
-11038
-12075
-11192
-9840
Sum Reward: -53855
Avg Reward: -10771.0
Min Reward: -12075
Max Reward: -9710
Gini Coefficient: -0.04517315012533655
20:20 Ratio: 0.8041407867494824
Max-min Ratio: 0.8041407867494824
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-28-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -14764.793877344486
  episode_reward_min: -119824.1736256799
  episodes_this_iter: 1
  episodes_total: 789
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.787
    dispatch_time_ms: 9.084
    learner:
      cur_lr: 0.0010972629534080625
      grad_gnorm: 40.000003814697266
      policy_entropy: 61.7909049987793
      policy_loss: -1412.1385498046875
      var_gnorm: 32.85826873779297
      vf_explained_var: 0.0
      vf_loss: 69348.3671875
    num_steps_sampled: 3950000
    num_steps_trained: 3950000
    wait_time_ms: 72.836
  iterations_since_restore: 790
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6886.862175941467
  time_this_iter_s: 8.6026029586792
  time_total_s: 6886.862175941467
  timestamp: 1594862913
  timesteps_since_restore: 3950000
  timesteps_this_iter: 5000
  timesteps_total: 3950000
  training_iteration: 790
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6886 s, 790 iter, 3950000 ts, -1.48e+04 rew

agent-1: -13541.128393855326
agent-2: -10012.040166537465
agent-3: -12026.827834314054
agent-4: -13246.563759664916
agent-5: -12094.479602325611
Extrinsic Rewards:
-13377
-9878
-11876
-13086
-11941
Sum Reward: -60158
Avg Reward: -12031.6
Min Reward: -13377
Max Reward: -9878
Gini Coefficient: -0.05457628245619868
20:20 Ratio: 0.7384316363908201
Max-min Ratio: 0.7384316363908201
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-28-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -15367.182952967989
  episode_reward_min: -119824.1736256799
  episodes_this_iter: 1
  episodes_total: 790
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.13
    dispatch_time_ms: 7.768
    learner:
      cur_lr: 0.0010969300055876374
      grad_gnorm: 40.0
      policy_entropy: 63.5367317199707
      policy_loss: -4787.7705078125
      var_gnorm: 33.28029251098633
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 223283.984375
    num_steps_sampled: 3955000
    num_steps_trained: 3955000
    wait_time_ms: 79.46
  iterations_since_restore: 791
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6895.495501756668
  time_this_iter_s: 8.633325815200806
  time_total_s: 6895.495501756668
  timestamp: 1594862922
  timesteps_since_restore: 3955000
  timesteps_this_iter: 5000
  timesteps_total: 3955000
  training_iteration: 791
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6895 s, 791 iter, 3955000 ts, -1.54e+04 rew

agent-1: -14099.131610800983
agent-2: -14136.628991755895
agent-3: -17254.11753435008
agent-4: -16260.833850423644
agent-5: -15464.238327534315
Extrinsic Rewards:
-13954
-13996
-17089
-16106
-15310
Sum Reward: -76455
Avg Reward: -15291.0
Min Reward: -17089
Max Reward: -13954
Gini Coefficient: -0.04384278333660323
20:20 Ratio: 0.8165486570308386
Max-min Ratio: 0.8165486570308386
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-28-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -16132.553874404253
  episode_reward_min: -119824.1736256799
  episodes_this_iter: 1
  episodes_total: 791
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.26
    dispatch_time_ms: 8.556
    learner:
      cur_lr: 0.0010965970577672124
      grad_gnorm: 40.0
      policy_entropy: 59.41987991333008
      policy_loss: -6906.244140625
      var_gnorm: 33.719825744628906
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 1082409.5
    num_steps_sampled: 3960000
    num_steps_trained: 3960000
    wait_time_ms: 73.637
  iterations_since_restore: 792
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6904.169529914856
  time_this_iter_s: 8.674028158187866
  time_total_s: 6904.169529914856
  timestamp: 1594862931
  timesteps_since_restore: 3960000
  timesteps_this_iter: 5000
  timesteps_total: 3960000
  training_iteration: 792
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6904 s, 792 iter, 3960000 ts, -1.61e+04 rew

agent-1: -15730.365320445047
agent-2: -14043.020310339758
agent-3: -13427.171456704049
agent-4: -14323.373744593218
agent-5: -14370.54656472109
Extrinsic Rewards:
-15564
-13892
-13283
-14177
-14212
Sum Reward: -71128
Avg Reward: -14225.6
Min Reward: -15564
Max Reward: -13283
Gini Coefficient: -0.027454729501743335
20:20 Ratio: 0.853443844769982
Max-min Ratio: 0.853443844769982
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-28-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -16843.41605367511
  episode_reward_min: -119824.1736256799
  episodes_this_iter: 1
  episodes_total: 792
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.701
    dispatch_time_ms: 6.267
    learner:
      cur_lr: 0.0010962639935314655
      grad_gnorm: 40.000003814697266
      policy_entropy: 50.203857421875
      policy_loss: -7982.68212890625
      var_gnorm: 34.161922454833984
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 858280.8125
    num_steps_sampled: 3965000
    num_steps_trained: 3965000
    wait_time_ms: 69.022
  iterations_since_restore: 793
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6912.368931770325
  time_this_iter_s: 8.19940185546875
  time_total_s: 6912.368931770325
  timestamp: 1594862939
  timesteps_since_restore: 3965000
  timesteps_this_iter: 5000
  timesteps_total: 3965000
  training_iteration: 793
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6912 s, 793 iter, 3965000 ts, -1.68e+04 rew

agent-1: -11650.411268799204
agent-2: -13585.903033608534
agent-3: -15454.610067058062
agent-4: -12204.063943320934
agent-5: -10833.56137747397
Extrinsic Rewards:
-11501
-13432
-15284
-12054
-10696
Sum Reward: -62967
Avg Reward: -12593.4
Min Reward: -15284
Max Reward: -10696
Gini Coefficient: -0.0705575936601712
20:20 Ratio: 0.6998168018843235
Max-min Ratio: 0.6998168018843235
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-29-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -17473.307300971228
  episode_reward_min: -119824.1736256799
  episodes_this_iter: 1
  episodes_total: 793
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.475
    dispatch_time_ms: 6.582
    learner:
      cur_lr: 0.0010959310457110405
      grad_gnorm: 40.0
      policy_entropy: 52.209083557128906
      policy_loss: -1462.2249755859375
      var_gnorm: 34.60892868041992
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 125641.40625
    num_steps_sampled: 3970000
    num_steps_trained: 3970000
    wait_time_ms: 73.453
  iterations_since_restore: 794
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6920.689225196838
  time_this_iter_s: 8.320293426513672
  time_total_s: 6920.689225196838
  timestamp: 1594862947
  timesteps_since_restore: 3970000
  timesteps_this_iter: 5000
  timesteps_total: 3970000
  training_iteration: 794
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6920 s, 794 iter, 3970000 ts, -1.75e+04 rew

agent-1: -10605.40088399975
agent-2: -11817.502756266687
agent-3: -10228.037436545577
agent-4: -10587.225273877988
agent-5: -10457.133744112822
Extrinsic Rewards:
-10454
-11655
-10085
-10436
-10308
Sum Reward: -52938
Avg Reward: -10587.6
Min Reward: -11655
Max Reward: -10085
Gini Coefficient: -0.024829045298273452
20:20 Ratio: 0.8652938652938653
Max-min Ratio: 0.8652938652938653
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-29-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -18003.652012707254
  episode_reward_min: -119824.1736256799
  episodes_this_iter: 1
  episodes_total: 794
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.637
    dispatch_time_ms: 7.152
    learner:
      cur_lr: 0.0010955979814752936
      grad_gnorm: 40.0
      policy_entropy: 57.35762023925781
      policy_loss: -1099.9698486328125
      var_gnorm: 35.0352897644043
      vf_explained_var: 0.0
      vf_loss: 39997.28125
    num_steps_sampled: 3975000
    num_steps_trained: 3975000
    wait_time_ms: 70.586
  iterations_since_restore: 795
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6928.958823680878
  time_this_iter_s: 8.269598484039307
  time_total_s: 6928.958823680878
  timestamp: 1594862955
  timesteps_since_restore: 3975000
  timesteps_this_iter: 5000
  timesteps_total: 3975000
  training_iteration: 795
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6928 s, 795 iter, 3975000 ts, -1.8e+04 rew

agent-1: -10869.176442721808
agent-2: -10782.900533972106
agent-3: -11715.43581843699
agent-4: -16430.0772405419
agent-5: -14365.675428479406
Extrinsic Rewards:
-10740
-10649
-11574
-16246
-14199
Sum Reward: -63408
Avg Reward: -12681.6
Min Reward: -16246
Max Reward: -10649
Gini Coefficient: -0.09243628564219027
20:20 Ratio: 0.6554844269358612
Max-min Ratio: 0.6554844269358612
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-29-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -18636.87032745008
  episode_reward_min: -119824.1736256799
  episodes_this_iter: 1
  episodes_total: 795
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.728
    dispatch_time_ms: 7.012
    learner:
      cur_lr: 0.0010952650336548686
      grad_gnorm: 40.0
      policy_entropy: 48.315364837646484
      policy_loss: -14855.244140625
      var_gnorm: 35.50345993041992
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 2455391.25
    num_steps_sampled: 3980000
    num_steps_trained: 3980000
    wait_time_ms: 77.117
  iterations_since_restore: 796
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6937.3521027565
  time_this_iter_s: 8.393279075622559
  time_total_s: 6937.3521027565
  timestamp: 1594862964
  timesteps_since_restore: 3980000
  timesteps_this_iter: 5000
  timesteps_total: 3980000
  training_iteration: 796
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6937 s, 796 iter, 3980000 ts, -1.86e+04 rew

agent-1: -14353.758541381821
agent-2: -14720.726545215979
agent-3: -14048.408927132621
agent-4: -15440.24636935845
agent-5: -12154.139466819437
Extrinsic Rewards:
-14203
-14566
-13904
-15283
-12005
Sum Reward: -69961
Avg Reward: -13992.2
Min Reward: -15283
Max Reward: -12005
Gini Coefficient: -0.04126870685095982
20:20 Ratio: 0.7855133154485376
Max-min Ratio: 0.7855133154485376
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-29-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -19335.812279865626
  episode_reward_min: -119824.1736256799
  episodes_this_iter: 1
  episodes_total: 796
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.62
    dispatch_time_ms: 9.503
    learner:
      cur_lr: 0.0010949319694191217
      grad_gnorm: 39.999996185302734
      policy_entropy: 55.75238037109375
      policy_loss: -9155.70703125
      var_gnorm: 35.97468566894531
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 1311496.875
    num_steps_sampled: 3985000
    num_steps_trained: 3985000
    wait_time_ms: 71.433
  iterations_since_restore: 797
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6945.773789167404
  time_this_iter_s: 8.42168641090393
  time_total_s: 6945.773789167404
  timestamp: 1594862972
  timesteps_since_restore: 3985000
  timesteps_this_iter: 5000
  timesteps_total: 3985000
  training_iteration: 797
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6945 s, 797 iter, 3985000 ts, -1.93e+04 rew

agent-1: -21079.38676017264
agent-2: -15783.526470168435
agent-3: -24729.950631005446
agent-4: -19326.192039489928
agent-5: -14760.549719057946
Extrinsic Rewards:
-20915
-15653
-24548
-19178
-14634
Sum Reward: -94928
Avg Reward: -18985.6
Min Reward: -24548
Max Reward: -14634
Gini Coefficient: -0.10572223158604416
20:20 Ratio: 0.596138178262995
Max-min Ratio: 0.596138178262995
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-29-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -20284.393535619656
  episode_reward_min: -119824.1736256799
  episodes_this_iter: 1
  episodes_total: 797
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.985
    dispatch_time_ms: 8.327
    learner:
      cur_lr: 0.0010945990215986967
      grad_gnorm: 40.0
      policy_entropy: 58.8978271484375
      policy_loss: -8390.3251953125
      var_gnorm: 36.452518463134766
      vf_explained_var: 0.0
      vf_loss: 586065.125
    num_steps_sampled: 3990000
    num_steps_trained: 3990000
    wait_time_ms: 71.859
  iterations_since_restore: 798
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6954.087603569031
  time_this_iter_s: 8.313814401626587
  time_total_s: 6954.087603569031
  timestamp: 1594862981
  timesteps_since_restore: 3990000
  timesteps_this_iter: 5000
  timesteps_total: 3990000
  training_iteration: 798
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6954 s, 798 iter, 3990000 ts, -2.03e+04 rew

agent-1: -17723.429832684687
agent-2: -18879.79833720857
agent-3: -17404.134114209373
agent-4: -14028.190530842772
agent-5: -16651.97071407775
Extrinsic Rewards:
-17561
-18715
-17248
-13896
-16505
Sum Reward: -83925
Avg Reward: -16785.0
Min Reward: -18715
Max Reward: -13896
Gini Coefficient: -0.05096931784331248
20:20 Ratio: 0.7425060112209457
Max-min Ratio: 0.7425060112209457
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-29-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -21123.57319984289
  episode_reward_min: -119824.1736256799
  episodes_this_iter: 1
  episodes_total: 798
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.748
    dispatch_time_ms: 8.481
    learner:
      cur_lr: 0.0010942659573629498
      grad_gnorm: 40.0
      policy_entropy: 56.59808349609375
      policy_loss: -2078.05224609375
      var_gnorm: 36.924713134765625
      vf_explained_var: 0.0
      vf_loss: 120956.703125
    num_steps_sampled: 3995000
    num_steps_trained: 3995000
    wait_time_ms: 71.288
  iterations_since_restore: 799
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6962.555734395981
  time_this_iter_s: 8.468130826950073
  time_total_s: 6962.555734395981
  timestamp: 1594862989
  timesteps_since_restore: 3995000
  timesteps_this_iter: 5000
  timesteps_total: 3995000
  training_iteration: 799
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6962 s, 799 iter, 3995000 ts, -2.11e+04 rew

agent-1: -15611.681391939594
agent-2: -12942.407051314236
agent-3: -12324.472417663537
agent-4: -15316.004968046642
agent-5: -14174.26576431502
Extrinsic Rewards:
-15449
-12799
-12197
-15158
-14015
Sum Reward: -69618
Avg Reward: -13923.6
Min Reward: -15449
Max Reward: -12197
Gini Coefficient: -0.05092361170961533
20:20 Ratio: 0.7895009385720758
Max-min Ratio: 0.7895009385720758
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-29-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -21820.643962698505
  episode_reward_min: -119824.1736256799
  episodes_this_iter: 1
  episodes_total: 799
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.834
    dispatch_time_ms: 6.482
    learner:
      cur_lr: 0.0010939330095425248
      grad_gnorm: 39.999996185302734
      policy_entropy: 54.72279357910156
      policy_loss: -9001.1787109375
      var_gnorm: 37.41181945800781
      vf_explained_var: 0.0
      vf_loss: 1299960.0
    num_steps_sampled: 4000000
    num_steps_trained: 4000000
    wait_time_ms: 74.36
  iterations_since_restore: 800
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6971.102348327637
  time_this_iter_s: 8.546613931655884
  time_total_s: 6971.102348327637
  timestamp: 1594862998
  timesteps_since_restore: 4000000
  timesteps_this_iter: 5000
  timesteps_total: 4000000
  training_iteration: 800
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6971 s, 800 iter, 4000000 ts, -2.18e+04 rew

agent-1: -18797.41351157641
agent-2: -14131.213774247988
agent-3: -12759.941979366287
agent-4: -18429.42968551064
agent-5: -15119.642207195518
Extrinsic Rewards:
-18625
-13975
-12630
-18273
-14985
Sum Reward: -78488
Avg Reward: -15697.6
Min Reward: -18625
Max Reward: -12630
Gini Coefficient: -0.08300886759759454
20:20 Ratio: 0.6781208053691276
Max-min Ratio: 0.6781208053691276
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-30-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -22605.032126678034
  episode_reward_min: -119824.1736256799
  episodes_this_iter: 1
  episodes_total: 800
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.488
    dispatch_time_ms: 6.917
    learner:
      cur_lr: 0.001093599945306778
      grad_gnorm: 40.0
      policy_entropy: 51.29961013793945
      policy_loss: -5272.794921875
      var_gnorm: 37.91667938232422
      vf_explained_var: 0.0
      vf_loss: 515402.1875
    num_steps_sampled: 4005000
    num_steps_trained: 4005000
    wait_time_ms: 75.318
  iterations_since_restore: 801
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6979.935315608978
  time_this_iter_s: 8.832967281341553
  time_total_s: 6979.935315608978
  timestamp: 1594863007
  timesteps_since_restore: 4005000
  timesteps_this_iter: 5000
  timesteps_total: 4005000
  training_iteration: 801
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6979 s, 801 iter, 4005000 ts, -2.26e+04 rew

agent-1: -17579.416932664524
agent-2: -21011.139156949463
agent-3: -22401.97917736236
agent-4: -22998.525816541038
agent-5: -23579.452962917178
Extrinsic Rewards:
-17459
-20859
-22243
-22846
-23414
Sum Reward: -106821
Avg Reward: -21364.2
Min Reward: -23414
Max Reward: -17459
Gini Coefficient: -0.052038456857733964
20:20 Ratio: 0.7456649867600581
Max-min Ratio: 0.7456649867600581
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-30-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -23673.96032151093
  episode_reward_min: -119824.1736256799
  episodes_this_iter: 1
  episodes_total: 801
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.954
    dispatch_time_ms: 8.683
    learner:
      cur_lr: 0.001093266997486353
      grad_gnorm: 40.0
      policy_entropy: 41.95568084716797
      policy_loss: -5188.916015625
      var_gnorm: 38.444862365722656
      vf_explained_var: 0.0
      vf_loss: 717608.25
    num_steps_sampled: 4010000
    num_steps_trained: 4010000
    wait_time_ms: 70.876
  iterations_since_restore: 802
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6988.291629314423
  time_this_iter_s: 8.356313705444336
  time_total_s: 6988.291629314423
  timestamp: 1594863015
  timesteps_since_restore: 4010000
  timesteps_this_iter: 5000
  timesteps_total: 4010000
  training_iteration: 802
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6988 s, 802 iter, 4010000 ts, -2.37e+04 rew

agent-1: -21829.118859486087
agent-2: -18986.64648092945
agent-3: -21675.77898648295
agent-4: -19744.077217507787
agent-5: -24699.467138898824
Extrinsic Rewards:
-21665
-18849
-21527
-19606
-24528
Sum Reward: -106175
Avg Reward: -21235.0
Min Reward: -24528
Max Reward: -18849
Gini Coefficient: -0.05054673887449965
20:20 Ratio: 0.7684686888454012
Max-min Ratio: 0.7684686888454012
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-30-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -24736.262499601027
  episode_reward_min: -119824.1736256799
  episodes_this_iter: 1
  episodes_total: 802
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.457
    dispatch_time_ms: 7.313
    learner:
      cur_lr: 0.0010929340496659279
      grad_gnorm: 40.0
      policy_entropy: 17.216838836669922
      policy_loss: -667.8226928710938
      var_gnorm: 38.94925308227539
      vf_explained_var: 0.0
      vf_loss: 64175.70703125
    num_steps_sampled: 4015000
    num_steps_trained: 4015000
    wait_time_ms: 76.685
  iterations_since_restore: 803
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 6996.78227519989
  time_this_iter_s: 8.49064588546753
  time_total_s: 6996.78227519989
  timestamp: 1594863024
  timesteps_since_restore: 4015000
  timesteps_this_iter: 5000
  timesteps_total: 4015000
  training_iteration: 803
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 6996 s, 803 iter, 4015000 ts, -2.47e+04 rew

agent-1: -28394.016444315326
agent-2: -35583.437923092475
agent-3: -33932.80895506439
agent-4: -17324.154676297774
agent-5: -37887.136562164604
Extrinsic Rewards:
-28256
-35420
-33774
-17225
-37725
Sum Reward: -152400
Avg Reward: -30480.0
Min Reward: -37725
Max Reward: -17225
Gini Coefficient: -0.12641469816272966
20:20 Ratio: 0.45659377070907886
Max-min Ratio: 0.45659377070907886
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-30-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -26260.736251794617
  episode_reward_min: -153121.55456093515
  episodes_this_iter: 1
  episodes_total: 803
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.104
    dispatch_time_ms: 8.225
    learner:
      cur_lr: 0.001092600985430181
      grad_gnorm: 40.0
      policy_entropy: 16.511831283569336
      policy_loss: -4335.82275390625
      var_gnorm: 39.42334747314453
      vf_explained_var: 0.0
      vf_loss: 1068206.625
    num_steps_sampled: 4020000
    num_steps_trained: 4020000
    wait_time_ms: 74.563
  iterations_since_restore: 804
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7005.332049608231
  time_this_iter_s: 8.549774408340454
  time_total_s: 7005.332049608231
  timestamp: 1594863032
  timesteps_since_restore: 4020000
  timesteps_this_iter: 5000
  timesteps_total: 4020000
  training_iteration: 804
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7005 s, 804 iter, 4020000 ts, -2.63e+04 rew

agent-1: -33894.24572912657
agent-2: -25784.483298304698
agent-3: -20062.084552000077
agent-4: -32201.757127703295
agent-5: -32051.346646310296
Extrinsic Rewards:
-33735
-25648
-19949
-32053
-31891
Sum Reward: -143276
Avg Reward: -28655.2
Min Reward: -33735
Max Reward: -19949
Gini Coefficient: -0.09485747787487088
20:20 Ratio: 0.5913443011708908
Max-min Ratio: 0.5913443011708908
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-30-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -27693.94603639953
  episode_reward_min: -153121.55456093515
  episodes_this_iter: 1
  episodes_total: 804
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.668
    dispatch_time_ms: 7.682
    learner:
      cur_lr: 0.001092268037609756
      grad_gnorm: 40.0
      policy_entropy: 15.092792510986328
      policy_loss: -3717.443115234375
      var_gnorm: 39.93886947631836
      vf_explained_var: 0.0
      vf_loss: 2742669.75
    num_steps_sampled: 4025000
    num_steps_trained: 4025000
    wait_time_ms: 73.621
  iterations_since_restore: 805
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7013.87221121788
  time_this_iter_s: 8.540161609649658
  time_total_s: 7013.87221121788
  timestamp: 1594863041
  timesteps_since_restore: 4025000
  timesteps_this_iter: 5000
  timesteps_total: 4025000
  training_iteration: 805
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7013 s, 805 iter, 4025000 ts, -2.77e+04 rew

agent-1: -20875.366107759488
agent-2: -19115.005125241278
agent-3: -13431.834400458776
agent-4: -21156.218950829065
agent-5: -33210.229783432595
Extrinsic Rewards:
-20740
-18973
-13332
-21035
-33016
Sum Reward: -107096
Avg Reward: -21419.2
Min Reward: -33016
Max Reward: -13332
Gini Coefficient: -0.15473967281691192
20:20 Ratio: 0.40380421613763023
Max-min Ratio: 0.40380421613763023
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-30-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -28764.67546242154
  episode_reward_min: -153121.55456093515
  episodes_this_iter: 1
  episodes_total: 805
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.591
    dispatch_time_ms: 8.571
    learner:
      cur_lr: 0.0010919349733740091
      grad_gnorm: 40.0
      policy_entropy: 13.61727523803711
      policy_loss: -19422.90234375
      var_gnorm: 40.44752883911133
      vf_explained_var: 0.0
      vf_loss: 9633368.0
    num_steps_sampled: 4030000
    num_steps_trained: 4030000
    wait_time_ms: 70.462
  iterations_since_restore: 806
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7022.337345123291
  time_this_iter_s: 8.465133905410767
  time_total_s: 7022.337345123291
  timestamp: 1594863049
  timesteps_since_restore: 4030000
  timesteps_this_iter: 5000
  timesteps_total: 4030000
  training_iteration: 806
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7022 s, 806 iter, 4030000 ts, -2.88e+04 rew

agent-1: -45452.77777912368
agent-2: -30545.66832002947
agent-3: -57405.0456661777
agent-4: -65874.21282940412
agent-5: -54787.81630223583
Extrinsic Rewards:
-45324
-30445
-57229
-65691
-54636
Sum Reward: -253325
Avg Reward: -50665.0
Min Reward: -65691
Max Reward: -30445
Gini Coefficient: -0.13010480607914734
20:20 Ratio: 0.4634577034905847
Max-min Ratio: 0.4634577034905847
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-30-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -31299.38603823145
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 806
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.905
    dispatch_time_ms: 9.674
    learner:
      cur_lr: 0.001091602025553584
      grad_gnorm: 40.0
      policy_entropy: 15.967490196228027
      policy_loss: -3492.804443359375
      var_gnorm: 40.97981643676758
      vf_explained_var: 0.0
      vf_loss: 986937.0625
    num_steps_sampled: 4035000
    num_steps_trained: 4035000
    wait_time_ms: 72.835
  iterations_since_restore: 807
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7030.779612064362
  time_this_iter_s: 8.442266941070557
  time_total_s: 7030.779612064362
  timestamp: 1594863058
  timesteps_since_restore: 4035000
  timesteps_this_iter: 5000
  timesteps_total: 4035000
  training_iteration: 807
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7030 s, 807 iter, 4035000 ts, -3.13e+04 rew

agent-1: -54352.105262788515
agent-2: -42690.402940784625
agent-3: -39426.604939565266
agent-4: -47948.415784801065
agent-5: -29001.024207451603
Extrinsic Rewards:
-54179
-42542
-39285
-47794
-28887
Sum Reward: -212687
Avg Reward: -42537.4
Min Reward: -54179
Max Reward: -28887
Gini Coefficient: -0.11113608260025296
20:20 Ratio: 0.533177061222983
Max-min Ratio: 0.533177061222983
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-31-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -33426.210996722955
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 807
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.87
    dispatch_time_ms: 7.963
    learner:
      cur_lr: 0.0010912689613178372
      grad_gnorm: 39.999996185302734
      policy_entropy: 15.642423629760742
      policy_loss: -5656.34912109375
      var_gnorm: 41.433353424072266
      vf_explained_var: 0.0
      vf_loss: 2105521.75
    num_steps_sampled: 4040000
    num_steps_trained: 4040000
    wait_time_ms: 74.262
  iterations_since_restore: 808
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7039.285895586014
  time_this_iter_s: 8.506283521652222
  time_total_s: 7039.285895586014
  timestamp: 1594863066
  timesteps_since_restore: 4040000
  timesteps_this_iter: 5000
  timesteps_total: 4040000
  training_iteration: 808
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7039 s, 808 iter, 4040000 ts, -3.34e+04 rew

agent-1: -37141.98060193897
agent-2: -32069.835227075244
agent-3: -16836.431172587876
agent-4: -21673.25302154655
agent-5: -11773.23352774497
Extrinsic Rewards:
-36940
-31888
-16730
-21543
-11690
Sum Reward: -118791
Avg Reward: -23758.2
Min Reward: -36940
Max Reward: -11690
Gini Coefficient: -0.22108745612041317
20:20 Ratio: 0.31645912290200323
Max-min Ratio: 0.31645912290200323
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-31-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -34613.221406489385
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 808
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.589
    dispatch_time_ms: 8.94
    learner:
      cur_lr: 0.0010909360134974122
      grad_gnorm: 40.0
      policy_entropy: 12.55202865600586
      policy_loss: -3820.552978515625
      var_gnorm: 41.93962478637695
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1596258.75
    num_steps_sampled: 4045000
    num_steps_trained: 4045000
    wait_time_ms: 75.985
  iterations_since_restore: 809
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7047.750211238861
  time_this_iter_s: 8.46431565284729
  time_total_s: 7047.750211238861
  timestamp: 1594863075
  timesteps_since_restore: 4045000
  timesteps_this_iter: 5000
  timesteps_total: 4045000
  training_iteration: 809
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7047 s, 809 iter, 4045000 ts, -3.46e+04 rew

agent-1: -22580.637746703138
agent-2: -21316.95935138997
agent-3: -37874.14218066344
agent-4: -25120.910176837515
agent-5: -26314.598638408475
Extrinsic Rewards:
-22449
-21201
-37688
-24983
-26184
Sum Reward: -132505
Avg Reward: -26501.0
Min Reward: -37688
Max Reward: -21201
Gini Coefficient: -0.11081544092675748
20:20 Ratio: 0.5625398004669921
Max-min Ratio: 0.5625398004669921
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-31-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -35940.023575993946
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 809
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.591
    dispatch_time_ms: 6.857
    learner:
      cur_lr: 0.0010906029492616653
      grad_gnorm: 40.0
      policy_entropy: 15.40085220336914
      policy_loss: -6558.7197265625
      var_gnorm: 42.4799690246582
      vf_explained_var: 0.0
      vf_loss: 2745528.75
    num_steps_sampled: 4050000
    num_steps_trained: 4050000
    wait_time_ms: 73.779
  iterations_since_restore: 810
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7056.349997997284
  time_this_iter_s: 8.599786758422852
  time_total_s: 7056.349997997284
  timestamp: 1594863083
  timesteps_since_restore: 4050000
  timesteps_this_iter: 5000
  timesteps_total: 4050000
  training_iteration: 810
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7056 s, 810 iter, 4050000 ts, -3.59e+04 rew

agent-1: -29974.12662024764
agent-2: -36344.062822570486
agent-3: -31327.646520243634
agent-4: -34479.54101257649
agent-5: -23806.154878245143
Extrinsic Rewards:
-29830
-36176
-31184
-34333
-23697
Sum Reward: -155220
Avg Reward: -31044.0
Min Reward: -36176
Max Reward: -23697
Gini Coefficient: -0.07592062878495039
20:20 Ratio: 0.6550475453339231
Max-min Ratio: 0.6550475453339231
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-31-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -37493.53725487411
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 810
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.601
    dispatch_time_ms: 6.42
    learner:
      cur_lr: 0.0010902700014412403
      grad_gnorm: 39.999996185302734
      policy_entropy: 12.75216293334961
      policy_loss: -7.51686429977417
      var_gnorm: 42.99513626098633
      vf_explained_var: 0.0
      vf_loss: 141904.671875
    num_steps_sampled: 4055000
    num_steps_trained: 4055000
    wait_time_ms: 75.327
  iterations_since_restore: 811
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7064.7521595954895
  time_this_iter_s: 8.402161598205566
  time_total_s: 7064.7521595954895
  timestamp: 1594863092
  timesteps_since_restore: 4055000
  timesteps_this_iter: 5000
  timesteps_total: 4055000
  training_iteration: 811
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7064 s, 811 iter, 4055000 ts, -3.75e+04 rew

agent-1: -19554.085508066168
agent-2: -11180.292426024609
agent-3: -21651.17286423615
agent-4: -35726.51007614969
agent-5: -23890.46210605411
Extrinsic Rewards:
-19436
-11095
-21536
-35536
-23727
Sum Reward: -111330
Avg Reward: -22266.0
Min Reward: -35536
Max Reward: -11095
Gini Coefficient: -0.19104643851612324
20:20 Ratio: 0.31221859522737505
Max-min Ratio: 0.31221859522737505
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-31-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -38607.47280652115
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 811
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.809
    dispatch_time_ms: 6.045
    learner:
      cur_lr: 0.0010899370536208153
      grad_gnorm: 40.000003814697266
      policy_entropy: 12.014172554016113
      policy_loss: -926.3887939453125
      var_gnorm: 43.4987907409668
      vf_explained_var: 0.0
      vf_loss: 283823.90625
    num_steps_sampled: 4060000
    num_steps_trained: 4060000
    wait_time_ms: 73.356
  iterations_since_restore: 812
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7073.2808957099915
  time_this_iter_s: 8.528736114501953
  time_total_s: 7073.2808957099915
  timestamp: 1594863100
  timesteps_since_restore: 4060000
  timesteps_this_iter: 5000
  timesteps_total: 4060000
  training_iteration: 812
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7073 s, 812 iter, 4060000 ts, -3.86e+04 rew

agent-1: -33686.78187562841
agent-2: -39106.22959545704
agent-3: -25745.723047731837
agent-4: -30366.415446306375
agent-5: -49135.52464344604
Extrinsic Rewards:
-33549
-38940
-25641
-30235
-48952
Sum Reward: -177317
Avg Reward: -35463.4
Min Reward: -48952
Max Reward: -25641
Gini Coefficient: -0.12480923994879227
20:20 Ratio: 0.5237988233371466
Max-min Ratio: 0.5237988233371466
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-31-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -40381.75893107039
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 812
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.542
    dispatch_time_ms: 7.116
    learner:
      cur_lr: 0.0010896039893850684
      grad_gnorm: 40.0
      policy_entropy: 10.74142074584961
      policy_loss: -364.0426025390625
      var_gnorm: 43.991546630859375
      vf_explained_var: 0.0
      vf_loss: 2229843.25
    num_steps_sampled: 4065000
    num_steps_trained: 4065000
    wait_time_ms: 77.256
  iterations_since_restore: 813
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7081.7933781147
  time_this_iter_s: 8.512482404708862
  time_total_s: 7081.7933781147
  timestamp: 1594863109
  timesteps_since_restore: 4065000
  timesteps_this_iter: 5000
  timesteps_total: 4065000
  training_iteration: 813
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7081 s, 813 iter, 4065000 ts, -4.04e+04 rew

agent-1: -20179.133754653987
agent-2: -22314.737204836645
agent-3: -31914.129403838346
agent-4: -24516.408273118817
agent-5: -36975.72123736334
Extrinsic Rewards:
-20061
-22202
-31754
-24395
-36788
Sum Reward: -135200
Avg Reward: -27040.0
Min Reward: -36788
Max Reward: -20061
Gini Coefficient: -0.12723668639053254
20:20 Ratio: 0.5453136892464934
Max-min Ratio: 0.5453136892464934
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-31-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -41734.065178148594
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 813
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.886
    dispatch_time_ms: 9.029
    learner:
      cur_lr: 0.0010892710415646434
      grad_gnorm: 40.000003814697266
      policy_entropy: 9.100383758544922
      policy_loss: -4867.4951171875
      var_gnorm: 44.538421630859375
      vf_explained_var: 0.0
      vf_loss: 2408156.0
    num_steps_sampled: 4070000
    num_steps_trained: 4070000
    wait_time_ms: 71.064
  iterations_since_restore: 814
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7090.354965686798
  time_this_iter_s: 8.561587572097778
  time_total_s: 7090.354965686798
  timestamp: 1594863118
  timesteps_since_restore: 4070000
  timesteps_this_iter: 5000
  timesteps_total: 4070000
  training_iteration: 814
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7090 s, 814 iter, 4070000 ts, -4.17e+04 rew

agent-1: -34410.48549069998
agent-2: -27271.88955323295
agent-3: -38543.515435482375
agent-4: -20784.79914462423
agent-5: -25179.98160227179
Extrinsic Rewards:
-34258
-27137
-38393
-20654
-25067
Sum Reward: -145509
Avg Reward: -29101.8
Min Reward: -38393
Max Reward: -20654
Gini Coefficient: -0.12279377907895732
20:20 Ratio: 0.5379626494413045
Max-min Ratio: 0.5379626494413045
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-32-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -43188.64295572273
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 814
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.286
    dispatch_time_ms: 7.543
    learner:
      cur_lr: 0.0010889379773288965
      grad_gnorm: 40.0
      policy_entropy: 6.741659641265869
      policy_loss: -78.6224136352539
      var_gnorm: 45.07899475097656
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 870515.375
    num_steps_sampled: 4075000
    num_steps_trained: 4075000
    wait_time_ms: 72.919
  iterations_since_restore: 815
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7098.918783187866
  time_this_iter_s: 8.563817501068115
  time_total_s: 7098.918783187866
  timestamp: 1594863126
  timesteps_since_restore: 4075000
  timesteps_this_iter: 5000
  timesteps_total: 4075000
  training_iteration: 815
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7098 s, 815 iter, 4075000 ts, -4.32e+04 rew

agent-1: -43050.40013115534
agent-2: -30717.631871085356
agent-3: -36056.6649722846
agent-4: -26083.845714526353
agent-5: -40084.81169774132
Extrinsic Rewards:
-42870
-30579
-35923
-25979
-39928
Sum Reward: -175279
Avg Reward: -35055.8
Min Reward: -42870
Max Reward: -25979
Gini Coefficient: -0.09842822015187216
20:20 Ratio: 0.6059948682062049
Max-min Ratio: 0.6059948682062049
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-32-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -44940.466353714764
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 815
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.439
    dispatch_time_ms: 8.67
    learner:
      cur_lr: 0.0010886050295084715
      grad_gnorm: 40.0
      policy_entropy: 4.947558403015137
      policy_loss: -303.63671875
      var_gnorm: 45.61592483520508
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 869209.3125
    num_steps_sampled: 4080000
    num_steps_trained: 4080000
    wait_time_ms: 74.395
  iterations_since_restore: 816
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7107.3916528224945
  time_this_iter_s: 8.472869634628296
  time_total_s: 7107.3916528224945
  timestamp: 1594863135
  timesteps_since_restore: 4080000
  timesteps_this_iter: 5000
  timesteps_total: 4080000
  training_iteration: 816
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7107 s, 816 iter, 4080000 ts, -4.49e+04 rew

agent-1: -16313.263306115747
agent-2: -34690.82902855693
agent-3: -33635.74386318697
agent-4: -20771.89771673518
agent-5: -27871.2384652566
Extrinsic Rewards:
-16220
-34527
-33476
-20682
-27717
Sum Reward: -132622
Avg Reward: -26524.4
Min Reward: -34527
Max Reward: -16220
Gini Coefficient: -0.14901901645277557
20:20 Ratio: 0.46977727575520606
Max-min Ratio: 0.46977727575520606
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-32-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -482.8213106917075
  episode_reward_mean: -46265.97757516736
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 816
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.426
    dispatch_time_ms: 5.645
    learner:
      cur_lr: 0.0010882719652727246
      grad_gnorm: 40.000003814697266
      policy_entropy: 6.086986064910889
      policy_loss: -1186.745361328125
      var_gnorm: 46.17014694213867
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 466856.0625
    num_steps_sampled: 4085000
    num_steps_trained: 4085000
    wait_time_ms: 76.314
  iterations_since_restore: 817
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7115.93487071991
  time_this_iter_s: 8.543217897415161
  time_total_s: 7115.93487071991
  timestamp: 1594863143
  timesteps_since_restore: 4085000
  timesteps_this_iter: 5000
  timesteps_total: 4085000
  training_iteration: 817
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7115 s, 817 iter, 4085000 ts, -4.63e+04 rew

agent-1: -28560.700814443597
agent-2: -37976.74627723141
agent-3: -28043.053041139643
agent-4: -36665.2467407065
agent-5: -24803.90717921841
Extrinsic Rewards:
-28425
-37829
-27928
-36528
-24679
Sum Reward: -155389
Avg Reward: -31077.8
Min Reward: -37829
Max Reward: -24679
Gini Coefficient: -0.08983904909613936
20:20 Ratio: 0.6523830923365672
Max-min Ratio: 0.6523830923365672
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-32-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -514.2977114223582
  episode_reward_mean: -47821.64590258784
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 817
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.856
    dispatch_time_ms: 8.344
    learner:
      cur_lr: 0.0010879390174522996
      grad_gnorm: 40.000003814697266
      policy_entropy: 9.323869705200195
      policy_loss: -341.1230163574219
      var_gnorm: 46.63996124267578
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 488306.09375
    num_steps_sampled: 4090000
    num_steps_trained: 4090000
    wait_time_ms: 73.284
  iterations_since_restore: 818
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7124.4622802734375
  time_this_iter_s: 8.527409553527832
  time_total_s: 7124.4622802734375
  timestamp: 1594863152
  timesteps_since_restore: 4090000
  timesteps_this_iter: 5000
  timesteps_total: 4090000
  training_iteration: 818
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7124 s, 818 iter, 4090000 ts, -4.78e+04 rew

agent-1: -18143.304302010954
agent-2: -9595.654425233664
agent-3: -52512.97313208976
agent-4: -25157.963800289246
agent-5: -12005.961271944336
Extrinsic Rewards:
-18031
-9529
-52279
-25023
-11936
Sum Reward: -116798
Avg Reward: -23359.6
Min Reward: -52279
Max Reward: -9529
Gini Coefficient: -0.33763249370708404
20:20 Ratio: 0.18227204039863043
Max-min Ratio: 0.18227204039863043
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-32-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -514.2977114223582
  episode_reward_mean: -48990.472111948744
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 818
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.766
    dispatch_time_ms: 7.593
    learner:
      cur_lr: 0.0010876059532165527
      grad_gnorm: 40.0
      policy_entropy: 7.429229259490967
      policy_loss: -3126.4658203125
      var_gnorm: 47.166622161865234
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2628835.0
    num_steps_sampled: 4095000
    num_steps_trained: 4095000
    wait_time_ms: 75.8
  iterations_since_restore: 819
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7133.022898197174
  time_this_iter_s: 8.560617923736572
  time_total_s: 7133.022898197174
  timestamp: 1594863160
  timesteps_since_restore: 4095000
  timesteps_this_iter: 5000
  timesteps_total: 4095000
  training_iteration: 819
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7133 s, 819 iter, 4095000 ts, -4.9e+04 rew

agent-1: -26299.227316647393
agent-2: -16341.431506773513
agent-3: -33833.48327433503
agent-4: -22639.623151169748
agent-5: -43012.05631275862
Extrinsic Rewards:
-26168
-16265
-33674
-22515
-42818
Sum Reward: -141440
Avg Reward: -28288.0
Min Reward: -42818
Max Reward: -16265
Gini Coefficient: -0.18174490950226244
20:20 Ratio: 0.3798636087626699
Max-min Ratio: 0.3798636087626699
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-32-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -514.2977114223582
  episode_reward_mean: -50405.513619345234
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 819
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.619
    dispatch_time_ms: 8.361
    learner:
      cur_lr: 0.0010872730053961277
      grad_gnorm: 40.0
      policy_entropy: 8.329986572265625
      policy_loss: -3175.61376953125
      var_gnorm: 47.69157028198242
      vf_explained_var: 0.0
      vf_loss: 1071306.625
    num_steps_sampled: 4100000
    num_steps_trained: 4100000
    wait_time_ms: 73.421
  iterations_since_restore: 820
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7141.527231693268
  time_this_iter_s: 8.50433349609375
  time_total_s: 7141.527231693268
  timestamp: 1594863169
  timesteps_since_restore: 4100000
  timesteps_this_iter: 5000
  timesteps_total: 4100000
  training_iteration: 820
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7141 s, 820 iter, 4100000 ts, -5.04e+04 rew

agent-1: -38867.69416459017
agent-2: -22940.235620869014
agent-3: -16756.5261543087
agent-4: -31222.163218011603
agent-5: -16436.36998086042
Extrinsic Rewards:
-38663
-22811
-16665
-31065
-16325
Sum Reward: -125529
Avg Reward: -25105.8
Min Reward: -38663
Max Reward: -16325
Gini Coefficient: -0.18824654064001148
20:20 Ratio: 0.4222383157023511
Max-min Ratio: 0.4222383157023511
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-32-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -514.2977114223582
  episode_reward_mean: -51661.07872476263
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 820
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.837
    dispatch_time_ms: 8.445
    learner:
      cur_lr: 0.0010869400575757027
      grad_gnorm: 39.999996185302734
      policy_entropy: 16.74016761779785
      policy_loss: -3089.10107421875
      var_gnorm: 48.250244140625
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1620542.875
    num_steps_sampled: 4105000
    num_steps_trained: 4105000
    wait_time_ms: 72.746
  iterations_since_restore: 821
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7149.844761610031
  time_this_iter_s: 8.317529916763306
  time_total_s: 7149.844761610031
  timestamp: 1594863177
  timesteps_since_restore: 4105000
  timesteps_this_iter: 5000
  timesteps_total: 4105000
  training_iteration: 821
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7149 s, 821 iter, 4105000 ts, -5.17e+04 rew

agent-1: -22999.37587475046
agent-2: -38838.66121850789
agent-3: -1044.8294178525825
agent-4: -47952.51164589496
agent-5: -35570.81226355281
Extrinsic Rewards:
-22907
-38661
-1038
-47749
-35401
Sum Reward: -145756
Avg Reward: -29151.2
Min Reward: -47749
Max Reward: -1038
Gini Coefficient: -0.29961305194983395
20:20 Ratio: 0.02173867515550064
Max-min Ratio: 0.02173867515550064
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-33-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -514.2977114223582
  episode_reward_mean: -53118.73325231637
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 821
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.726
    dispatch_time_ms: 9.138
    learner:
      cur_lr: 0.0010866069933399558
      grad_gnorm: 40.000003814697266
      policy_entropy: 11.402803421020508
      policy_loss: -1326.5234375
      var_gnorm: 48.80877685546875
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 625944.5
    num_steps_sampled: 4110000
    num_steps_trained: 4110000
    wait_time_ms: 71.655
  iterations_since_restore: 822
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7158.261800527573
  time_this_iter_s: 8.417038917541504
  time_total_s: 7158.261800527573
  timestamp: 1594863186
  timesteps_since_restore: 4110000
  timesteps_this_iter: 5000
  timesteps_total: 4110000
  training_iteration: 822
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7158 s, 822 iter, 4110000 ts, -5.31e+04 rew

agent-1: -22290.550389713244
agent-2: -44620.878606305465
agent-3: -51058.304197303354
agent-4: -26175.4974099737
agent-5: -24918.958170535043
Extrinsic Rewards:
-22184
-44433
-50851
-26075
-24799
Sum Reward: -168342
Avg Reward: -33668.4
Min Reward: -50851
Max Reward: -22184
Gini Coefficient: -0.18288484157251308
20:20 Ratio: 0.43625494090578354
Max-min Ratio: 0.43625494090578354
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-33-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -514.2977114223582
  episode_reward_mean: -54801.774054838206
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 822
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.567
    dispatch_time_ms: 8.623
    learner:
      cur_lr: 0.0010862740455195308
      grad_gnorm: 39.999996185302734
      policy_entropy: 13.299713134765625
      policy_loss: -602.1111450195312
      var_gnorm: 49.375022888183594
      vf_explained_var: 0.0
      vf_loss: 938757.4375
    num_steps_sampled: 4115000
    num_steps_trained: 4115000
    wait_time_ms: 71.786
  iterations_since_restore: 823
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7166.743280887604
  time_this_iter_s: 8.481480360031128
  time_total_s: 7166.743280887604
  timestamp: 1594863194
  timesteps_since_restore: 4115000
  timesteps_this_iter: 5000
  timesteps_total: 4115000
  training_iteration: 823
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7166 s, 823 iter, 4115000 ts, -5.48e+04 rew

agent-1: -39329.36502647132
agent-2: -31778.532310559414
agent-3: -22251.440552072596
agent-4: -3302.959983289497
agent-5: -34338.99061924695
Extrinsic Rewards:
-39135
-31622
-22129
-3283
-34171
Sum Reward: -130340
Avg Reward: -26068.0
Min Reward: -39135
Max Reward: -3283
Gini Coefficient: -0.25700782568666564
20:20 Ratio: 0.08388910182700907
Max-min Ratio: 0.08388910182700907
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-33-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -514.2977114223582
  episode_reward_mean: -56105.39898142574
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 823
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.503
    dispatch_time_ms: 8.482
    learner:
      cur_lr: 0.001085940981283784
      grad_gnorm: 40.000003814697266
      policy_entropy: 22.47649574279785
      policy_loss: -2673.280517578125
      var_gnorm: 49.98648452758789
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 1043200.75
    num_steps_sampled: 4120000
    num_steps_trained: 4120000
    wait_time_ms: 71.339
  iterations_since_restore: 824
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7175.204539060593
  time_this_iter_s: 8.461258172988892
  time_total_s: 7175.204539060593
  timestamp: 1594863203
  timesteps_since_restore: 4120000
  timesteps_this_iter: 5000
  timesteps_total: 4120000
  training_iteration: 824
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7175 s, 824 iter, 4120000 ts, -5.61e+04 rew

agent-1: -39581.99803793923
agent-2: -37252.8861342841
agent-3: -12431.894324078308
agent-4: -30027.527206195915
agent-5: -37705.74590755483
Extrinsic Rewards:
-39416
-37085
-12369
-29888
-37536
Sum Reward: -156294
Avg Reward: -31258.8
Min Reward: -39416
Max Reward: -12369
Gini Coefficient: -0.1580150229695318
20:20 Ratio: 0.3138065760097422
Max-min Ratio: 0.3138065760097422
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-33-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -514.2977114223582
  episode_reward_mean: -57668.89466156797
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 824
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.829
    dispatch_time_ms: 6.119
    learner:
      cur_lr: 0.0010856080334633589
      grad_gnorm: 40.0
      policy_entropy: 28.88608169555664
      policy_loss: -805.80517578125
      var_gnorm: 50.54408264160156
      vf_explained_var: 0.0
      vf_loss: 77027.0625
    num_steps_sampled: 4125000
    num_steps_trained: 4125000
    wait_time_ms: 75.281
  iterations_since_restore: 825
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7183.74133348465
  time_this_iter_s: 8.536794424057007
  time_total_s: 7183.74133348465
  timestamp: 1594863211
  timesteps_since_restore: 4125000
  timesteps_this_iter: 5000
  timesteps_total: 4125000
  training_iteration: 825
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7183 s, 825 iter, 4125000 ts, -5.77e+04 rew

agent-1: -33182.45640170865
agent-2: -18601.332673746612
agent-3: -31349.37495902348
agent-4: -19128.5670568701
agent-5: -28347.3746326155
Extrinsic Rewards:
-32999
-18490
-31178
-19018
-28192
Sum Reward: -129877
Avg Reward: -25975.4
Min Reward: -32999
Max Reward: -18490
Gini Coefficient: -0.12682153114100264
20:20 Ratio: 0.5603200096972636
Max-min Ratio: 0.5603200096972636
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-33-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -514.2977114223582
  episode_reward_mean: -58968.13660991614
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 825
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.719
    dispatch_time_ms: 7.349
    learner:
      cur_lr: 0.001085274969227612
      grad_gnorm: 40.0
      policy_entropy: 44.711368560791016
      policy_loss: -6229.14794921875
      var_gnorm: 51.10633850097656
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1009529.0
    num_steps_sampled: 4130000
    num_steps_trained: 4130000
    wait_time_ms: 75.954
  iterations_since_restore: 826
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7192.288902521133
  time_this_iter_s: 8.547569036483765
  time_total_s: 7192.288902521133
  timestamp: 1594863220
  timesteps_since_restore: 4130000
  timesteps_this_iter: 5000
  timesteps_total: 4130000
  training_iteration: 826
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7192 s, 826 iter, 4130000 ts, -5.9e+04 rew

agent-1: -29689.344579606674
agent-2: -27830.191809381173
agent-3: -21875.361710765224
agent-4: -20200.141984310198
agent-5: -14177.665605775604
Extrinsic Rewards:
-29509
-27653
-21726
-20061
-14079
Sum Reward: -113028
Avg Reward: -22605.6
Min Reward: -29509
Max Reward: -14079
Gini Coefficient: -0.13607955550836962
20:20 Ratio: 0.47710867870819074
Max-min Ratio: 0.47710867870819074
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-33-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -514.2977114223582
  episode_reward_mean: -60100.32277671853
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 826
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.623
    dispatch_time_ms: 5.715
    learner:
      cur_lr: 0.001084942021407187
      grad_gnorm: 40.0
      policy_entropy: 45.4022216796875
      policy_loss: -437.683837890625
      var_gnorm: 51.572105407714844
      vf_explained_var: 0.0
      vf_loss: 17650.46484375
    num_steps_sampled: 4135000
    num_steps_trained: 4135000
    wait_time_ms: 75.611
  iterations_since_restore: 827
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7200.6195957660675
  time_this_iter_s: 8.330693244934082
  time_total_s: 7200.6195957660675
  timestamp: 1594863228
  timesteps_since_restore: 4135000
  timesteps_this_iter: 5000
  timesteps_total: 4135000
  training_iteration: 827
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7200 s, 827 iter, 4135000 ts, -6.01e+04 rew

agent-1: -7134.751534543721
agent-2: -6615.715461923482
agent-3: -10762.5272289786
agent-4: -9191.699977423124
agent-5: -8440.135652516858
Extrinsic Rewards:
-7001
-6480
-10592
-9034
-8290
Sum Reward: -41397
Avg Reward: -8279.4
Min Reward: -10592
Max Reward: -6480
Gini Coefficient: -0.09910863106022176
20:20 Ratio: 0.6117824773413897
Max-min Ratio: 0.6117824773413897
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-33-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -514.2977114223582
  episode_reward_mean: -60515.817022254945
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 827
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.323
    dispatch_time_ms: 13.228
    learner:
      cur_lr: 0.0010846089571714401
      grad_gnorm: 40.0
      policy_entropy: 57.735023498535156
      policy_loss: -3704.565185546875
      var_gnorm: 51.939476013183594
      vf_explained_var: 0.0
      vf_loss: 212680.21875
    num_steps_sampled: 4140000
    num_steps_trained: 4140000
    wait_time_ms: 67.957
  iterations_since_restore: 828
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7209.138217449188
  time_this_iter_s: 8.518621683120728
  time_total_s: 7209.138217449188
  timestamp: 1594863237
  timesteps_since_restore: 4140000
  timesteps_this_iter: 5000
  timesteps_total: 4140000
  training_iteration: 828
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7209 s, 828 iter, 4140000 ts, -6.05e+04 rew

agent-1: -8244.709130345307
agent-2: -7426.963101708587
agent-3: -10470.874323656275
agent-4: -8876.246979738487
agent-5: -9434.553686241628
Extrinsic Rewards:
-8113
-7295
-10297
-8716
-9283
Sum Reward: -43704
Avg Reward: -8740.8
Min Reward: -10297
Max Reward: -7295
Gini Coefficient: -0.06565989383122826
20:20 Ratio: 0.7084587744003108
Max-min Ratio: 0.7084587744003108
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-34-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -514.2977114223582
  episode_reward_mean: -60953.06194905594
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 828
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.653
    dispatch_time_ms: 5.845
    learner:
      cur_lr: 0.001084276009351015
      grad_gnorm: 40.000003814697266
      policy_entropy: 40.94965744018555
      policy_loss: -3855.226318359375
      var_gnorm: 52.43495559692383
      vf_explained_var: 0.0
      vf_loss: 295912.21875
    num_steps_sampled: 4145000
    num_steps_trained: 4145000
    wait_time_ms: 78.872
  iterations_since_restore: 829
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7231.284957885742
  time_this_iter_s: 22.146740436553955
  time_total_s: 7231.284957885742
  timestamp: 1594863259
  timesteps_since_restore: 4145000
  timesteps_this_iter: 5000
  timesteps_total: 4145000
  training_iteration: 829
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7231 s, 829 iter, 4145000 ts, -6.1e+04 rew

agent-1: -20626.33933483098
agent-2: -20872.80155884699
agent-3: -18180.112663218253
agent-4: -18107.320813128423
agent-5: -17853.940972274664
Extrinsic Rewards:
-20466
-20702
-18045
-17956
-17715
Sum Reward: -94884
Avg Reward: -18976.8
Min Reward: -20702
Max Reward: -17715
Gini Coefficient: -0.03576577715947894
20:20 Ratio: 0.8557144237271761
Max-min Ratio: 0.8557144237271761
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-34-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -514.2977114223582
  episode_reward_mean: -61902.89933501619
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 829
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.783
    dispatch_time_ms: 10.67
    learner:
      cur_lr: 0.0010839429451152682
      grad_gnorm: 39.999996185302734
      policy_entropy: 26.45492935180664
      policy_loss: -8785.0634765625
      var_gnorm: 53.00680160522461
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2684478.0
    num_steps_sampled: 4150000
    num_steps_trained: 4150000
    wait_time_ms: 72.061
  iterations_since_restore: 830
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7239.87415099144
  time_this_iter_s: 8.589193105697632
  time_total_s: 7239.87415099144
  timestamp: 1594863268
  timesteps_since_restore: 4150000
  timesteps_this_iter: 5000
  timesteps_total: 4150000
  training_iteration: 830
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7239 s, 830 iter, 4150000 ts, -6.19e+04 rew

agent-1: -30091.776570963964
agent-2: -26319.952152687012
agent-3: -23472.265870221156
agent-4: -21448.564504790833
agent-5: -18536.26556857907
Extrinsic Rewards:
-29914
-26154
-23323
-21314
-18409
Sum Reward: -119114
Avg Reward: -23822.8
Min Reward: -29914
Max Reward: -18409
Gini Coefficient: -0.09352385110062629
20:20 Ratio: 0.6153974727552317
Max-min Ratio: 0.6153974727552317
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-34-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -514.2977114223582
  episode_reward_mean: -63095.75750915965
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 830
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.952
    dispatch_time_ms: 6.9
    learner:
      cur_lr: 0.0010836099972948432
      grad_gnorm: 40.0
      policy_entropy: 23.533315658569336
      policy_loss: -2617.004638671875
      var_gnorm: 53.566226959228516
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 526747.625
    num_steps_sampled: 4155000
    num_steps_trained: 4155000
    wait_time_ms: 73.328
  iterations_since_restore: 831
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7248.34681725502
  time_this_iter_s: 8.472666263580322
  time_total_s: 7248.34681725502
  timestamp: 1594863276
  timesteps_since_restore: 4155000
  timesteps_this_iter: 5000
  timesteps_total: 4155000
  training_iteration: 831
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7248 s, 831 iter, 4155000 ts, -6.31e+04 rew

agent-1: -27620.739966680983
agent-2: -30753.637710335828
agent-3: -20787.521637214824
agent-4: -34528.826512964624
agent-5: -20128.540143931958
Extrinsic Rewards:
-27474
-30590
-20676
-34337
-20010
Sum Reward: -133087
Avg Reward: -26617.4
Min Reward: -34337
Max Reward: -20010
Gini Coefficient: -0.11591815879838001
20:20 Ratio: 0.5827532981914553
Max-min Ratio: 0.5827532981914553
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-34-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -514.2977114223582
  episode_reward_mean: -64426.05895457063
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 831
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.84
    dispatch_time_ms: 5.839
    learner:
      cur_lr: 0.0010832770494744182
      grad_gnorm: 40.0
      policy_entropy: 24.426164627075195
      policy_loss: -4124.17041015625
      var_gnorm: 54.11929702758789
      vf_explained_var: 0.0
      vf_loss: 746974.5
    num_steps_sampled: 4160000
    num_steps_trained: 4160000
    wait_time_ms: 74.162
  iterations_since_restore: 832
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7256.80432343483
  time_this_iter_s: 8.45750617980957
  time_total_s: 7256.80432343483
  timestamp: 1594863285
  timesteps_since_restore: 4160000
  timesteps_this_iter: 5000
  timesteps_total: 4160000
  training_iteration: 832
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7256 s, 832 iter, 4160000 ts, -6.44e+04 rew

agent-1: -24709.159668639928
agent-2: -27685.963507423025
agent-3: -19336.272505878107
agent-4: -34125.259053379836
agent-5: -32253.39181507208
Extrinsic Rewards:
-24575
-27531
-19229
-33951
-32090
Sum Reward: -137376
Avg Reward: -27475.2
Min Reward: -33951
Max Reward: -19229
Gini Coefficient: -0.10761413929652923
20:20 Ratio: 0.5663750699537569
Max-min Ratio: 0.5663750699537569
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-34-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -514.2977114223582
  episode_reward_mean: -65800.14374305488
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 832
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.808
    dispatch_time_ms: 39.448
    learner:
      cur_lr: 0.0010829439852386713
      grad_gnorm: 40.000003814697266
      policy_entropy: 27.126384735107422
      policy_loss: -752.6634521484375
      var_gnorm: 54.65803527832031
      vf_explained_var: 0.0
      vf_loss: 315622.125
    num_steps_sampled: 4165000
    num_steps_trained: 4165000
    wait_time_ms: 49.111
  iterations_since_restore: 833
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7265.753997087479
  time_this_iter_s: 8.949673652648926
  time_total_s: 7265.753997087479
  timestamp: 1594863294
  timesteps_since_restore: 4165000
  timesteps_this_iter: 5000
  timesteps_total: 4165000
  training_iteration: 833
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7265 s, 833 iter, 4165000 ts, -6.58e+04 rew

agent-1: -29574.36966819305
agent-2: -16578.05963759194
agent-3: -32786.83960965297
agent-4: -27462.82596414692
agent-5: -26319.16784178814
Extrinsic Rewards:
-29419
-16483
-32615
-27299
-26173
Sum Reward: -131989
Avg Reward: -26397.8
Min Reward: -32615
Max Reward: -16483
Gini Coefficient: -0.10761502852510436
20:20 Ratio: 0.5053809596811283
Max-min Ratio: 0.5053809596811283
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-35-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -514.2977114223582
  episode_reward_mean: -67120.76958577387
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 833
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.772
    dispatch_time_ms: 26.712
    learner:
      cur_lr: 0.0010826110374182463
      grad_gnorm: 40.0
      policy_entropy: 19.8502254486084
      policy_loss: -1102.72900390625
      var_gnorm: 55.23455047607422
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1706831.5
    num_steps_sampled: 4170000
    num_steps_trained: 4170000
    wait_time_ms: 63.844
  iterations_since_restore: 834
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7274.801205158234
  time_this_iter_s: 9.047208070755005
  time_total_s: 7274.801205158234
  timestamp: 1594863303
  timesteps_since_restore: 4170000
  timesteps_this_iter: 5000
  timesteps_total: 4170000
  training_iteration: 834
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7274 s, 834 iter, 4170000 ts, -6.71e+04 rew

agent-1: -21674.286528330318
agent-2: -31791.80571758231
agent-3: -27173.48200219256
agent-4: -25665.62049751635
agent-5: -36539.718190973006
Extrinsic Rewards:
-21561
-31629
-27038
-25527
-36369
Sum Reward: -142124
Avg Reward: -28424.8
Min Reward: -36369
Max Reward: -21561
Gini Coefficient: -0.10052630097661197
20:20 Ratio: 0.5928400560917265
Max-min Ratio: 0.5928400560917265
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-35-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -514.2977114223582
  episode_reward_mean: -68542.34787384077
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 834
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.789
    dispatch_time_ms: 35.423
    learner:
      cur_lr: 0.0010822779731824994
      grad_gnorm: 40.0
      policy_entropy: 17.58170509338379
      policy_loss: -3460.262939453125
      var_gnorm: 55.7796630859375
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3172189.0
    num_steps_sampled: 4175000
    num_steps_trained: 4175000
    wait_time_ms: 49.345
  iterations_since_restore: 835
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7283.825197696686
  time_this_iter_s: 9.023992538452148
  time_total_s: 7283.825197696686
  timestamp: 1594863312
  timesteps_since_restore: 4175000
  timesteps_this_iter: 5000
  timesteps_total: 4175000
  training_iteration: 835
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7283 s, 835 iter, 4175000 ts, -6.85e+04 rew

agent-1: -20751.315057329008
agent-2: -23820.322811560967
agent-3: -33716.53206326762
agent-4: -38623.150873256025
agent-5: -30197.65757307923
Extrinsic Rewards:
-20647
-23708
-33548
-38441
-30046
Sum Reward: -146390
Avg Reward: -29278.0
Min Reward: -38441
Max Reward: -20647
Gini Coefficient: -0.12412869731539039
20:20 Ratio: 0.5371088161078016
Max-min Ratio: 0.5371088161078016
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-35-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -514.2977114223582
  episode_reward_mean: -70007.3247526467
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 835
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.682
    dispatch_time_ms: 13.407
    learner:
      cur_lr: 0.0010819450253620744
      grad_gnorm: 40.000003814697266
      policy_entropy: 29.878189086914062
      policy_loss: -2946.260009765625
      var_gnorm: 56.359275817871094
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 4334112.5
    num_steps_sampled: 4180000
    num_steps_trained: 4180000
    wait_time_ms: 76.834
  iterations_since_restore: 836
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7292.871928691864
  time_this_iter_s: 9.046730995178223
  time_total_s: 7292.871928691864
  timestamp: 1594863321
  timesteps_since_restore: 4180000
  timesteps_this_iter: 5000
  timesteps_total: 4180000
  training_iteration: 836
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7292 s, 836 iter, 4180000 ts, -7e+04 rew

agent-1: -26624.08126918002
agent-2: -24900.09571051667
agent-3: -33202.52337860626
agent-4: -36469.424244644004
agent-5: -30332.765158087645
Extrinsic Rewards:
-26504
-24769
-33043
-36307
-30194
Sum Reward: -150817
Avg Reward: -30163.4
Min Reward: -36307
Max Reward: -24769
Gini Coefficient: -0.07854552205653209
20:20 Ratio: 0.6822100421406341
Max-min Ratio: 0.6822100421406341
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-35-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -514.2977114223582
  episode_reward_mean: -71516.81585356407
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 836
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.225
    dispatch_time_ms: 29.746
    learner:
      cur_lr: 0.0010816119611263275
      grad_gnorm: 40.0
      policy_entropy: 43.149574279785156
      policy_loss: -43.4384880065918
      var_gnorm: 56.91499328613281
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 22830.34765625
    num_steps_sampled: 4185000
    num_steps_trained: 4185000
    wait_time_ms: 49.755
  iterations_since_restore: 837
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7302.116631746292
  time_this_iter_s: 9.2447030544281
  time_total_s: 7302.116631746292
  timestamp: 1594863330
  timesteps_since_restore: 4185000
  timesteps_this_iter: 5000
  timesteps_total: 4185000
  training_iteration: 837
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7302 s, 837 iter, 4185000 ts, -7.15e+04 rew

agent-1: -14699.639347988928
agent-2: -15309.126774853126
agent-3: -13964.741539016914
agent-4: -19382.568611788447
agent-5: -9780.014921775633
Extrinsic Rewards:
-14549
-15152
-13816
-19213
-9662
Sum Reward: -72392
Avg Reward: -14478.4
Min Reward: -19213
Max Reward: -9662
Gini Coefficient: -0.11292960548126865
20:20 Ratio: 0.5028886691302764
Max-min Ratio: 0.5028886691302764
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-35-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -514.2977114223582
  episode_reward_mean: -72241.9018467442
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 837
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.297
    dispatch_time_ms: 37.939
    learner:
      cur_lr: 0.0010812790133059025
      grad_gnorm: 40.000003814697266
      policy_entropy: 38.298763275146484
      policy_loss: -552.5029907226562
      var_gnorm: 56.927738189697266
      vf_explained_var: 0.0
      vf_loss: 33341.5625
    num_steps_sampled: 4190000
    num_steps_trained: 4190000
    wait_time_ms: 50.738
  iterations_since_restore: 838
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7310.831323862076
  time_this_iter_s: 8.714692115783691
  time_total_s: 7310.831323862076
  timestamp: 1594863339
  timesteps_since_restore: 4190000
  timesteps_this_iter: 5000
  timesteps_total: 4190000
  training_iteration: 838
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7310 s, 838 iter, 4190000 ts, -7.22e+04 rew

agent-1: -11712.832162543236
agent-2: -13678.649520005536
agent-3: -12155.395678782606
agent-4: -7199.55280403936
agent-5: -12022.348997527259
Extrinsic Rewards:
-11560
-13522
-11981
-7077
-11886
Sum Reward: -56026
Avg Reward: -11205.2
Min Reward: -13522
Max Reward: -7077
Gini Coefficient: -0.0950344482918645
20:20 Ratio: 0.5233693240644876
Max-min Ratio: 0.5233693240644876
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-35-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -514.2977114223582
  episode_reward_mean: -72802.58411864738
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 838
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.763
    dispatch_time_ms: 27.835
    learner:
      cur_lr: 0.0010809459490701556
      grad_gnorm: 40.0
      policy_entropy: 30.30365753173828
      policy_loss: 265.989990234375
      var_gnorm: 56.9752197265625
      vf_explained_var: 0.0
      vf_loss: 5850.42236328125
    num_steps_sampled: 4195000
    num_steps_trained: 4195000
    wait_time_ms: 54.014
  iterations_since_restore: 839
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7319.496054410934
  time_this_iter_s: 8.664730548858643
  time_total_s: 7319.496054410934
  timestamp: 1594863348
  timesteps_since_restore: 4195000
  timesteps_this_iter: 5000
  timesteps_total: 4195000
  training_iteration: 839
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7319 s, 839 iter, 4195000 ts, -7.28e+04 rew

agent-1: -2324.060388137771
agent-2: -2956.4655489824913
agent-3: -2956.2874074677597
agent-4: -3842.212631503287
agent-5: -2559.3293940618855
Extrinsic Rewards:
-2207
-2813
-2815
-3659
-2406
Sum Reward: -13900
Avg Reward: -2780.0
Min Reward: -3659
Max Reward: -2207
Gini Coefficient: -0.09533812949640287
20:20 Ratio: 0.603170265099754
Max-min Ratio: 0.603170265099754
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-35-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -514.2977114223582
  episode_reward_mean: -72941.70541903056
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 839
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.83
    dispatch_time_ms: 26.494
    learner:
      cur_lr: 0.0010806130012497306
      grad_gnorm: 40.0
      policy_entropy: 21.51113510131836
      policy_loss: 249.34274291992188
      var_gnorm: 56.568424224853516
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5993.29541015625
    num_steps_sampled: 4200000
    num_steps_trained: 4200000
    wait_time_ms: 58.674
  iterations_since_restore: 840
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7328.036557197571
  time_this_iter_s: 8.540502786636353
  time_total_s: 7328.036557197571
  timestamp: 1594863356
  timesteps_since_restore: 4200000
  timesteps_this_iter: 5000
  timesteps_total: 4200000
  training_iteration: 840
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7328 s, 840 iter, 4200000 ts, -7.29e+04 rew

agent-1: -2279.8922218299676
agent-2: -2059.0402353928466
agent-3: -1796.5021388042528
agent-4: -2392.105044801147
agent-5: -2790.4113584391903
Extrinsic Rewards:
-2135
-1924
-1665
-2239
-2624
Sum Reward: -10587
Avg Reward: -2117.4
Min Reward: -2624
Max Reward: -1665
Gini Coefficient: -0.08436762066685558
20:20 Ratio: 0.6345274390243902
Max-min Ratio: 0.6345274390243902
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-36-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -514.2977114223582
  episode_reward_mean: -73048.07898553343
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 840
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.127
    dispatch_time_ms: 7.93
    learner:
      cur_lr: 0.0010802800534293056
      grad_gnorm: 40.0
      policy_entropy: 39.323875427246094
      policy_loss: 34.28653335571289
      var_gnorm: 56.29505157470703
      vf_explained_var: 0.0
      vf_loss: 8394.21875
    num_steps_sampled: 4205000
    num_steps_trained: 4205000
    wait_time_ms: 71.341
  iterations_since_restore: 841
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7336.182345151901
  time_this_iter_s: 8.145787954330444
  time_total_s: 7336.182345151901
  timestamp: 1594863364
  timesteps_since_restore: 4205000
  timesteps_this_iter: 5000
  timesteps_total: 4205000
  training_iteration: 841
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7336 s, 841 iter, 4205000 ts, -7.3e+04 rew

agent-1: -2464.231438570081
agent-2: -2650.0368356897584
agent-3: -2701.6975385202772
agent-4: -3552.0765056205055
agent-5: -2119.8967759006846
Extrinsic Rewards:
-2326
-2510
-2543
-3358
-1994
Sum Reward: -12731
Avg Reward: -2546.2
Min Reward: -3358
Max Reward: -1994
Gini Coefficient: -0.09253004477260231
20:20 Ratio: 0.5938058368076236
Max-min Ratio: 0.5938058368076236
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-36-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -514.2977114223582
  episode_reward_mean: -73177.45124462897
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 841
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.758
    dispatch_time_ms: 7.342
    learner:
      cur_lr: 0.0010799469891935587
      grad_gnorm: 40.0
      policy_entropy: 45.98176956176758
      policy_loss: -270.3287353515625
      var_gnorm: 56.18910598754883
      vf_explained_var: 0.0
      vf_loss: 22213.40625
    num_steps_sampled: 4210000
    num_steps_trained: 4210000
    wait_time_ms: 72.084
  iterations_since_restore: 842
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7344.468945026398
  time_this_iter_s: 8.28659987449646
  time_total_s: 7344.468945026398
  timestamp: 1594863373
  timesteps_since_restore: 4210000
  timesteps_this_iter: 5000
  timesteps_total: 4210000
  training_iteration: 842
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7344 s, 842 iter, 4210000 ts, -7.32e+04 rew

agent-1: -2149.509988603288
agent-2: -2550.5596451135843
agent-3: -2528.1491205360903
agent-4: -2572.147211055245
agent-5: -1780.5935603985495
Extrinsic Rewards:
-2017
-2394
-2366
-2409
-1658
Sum Reward: -10844
Avg Reward: -2168.8
Min Reward: -2409
Max Reward: -1658
Gini Coefficient: -0.06931021763187016
20:20 Ratio: 0.6882523868825239
Max-min Ratio: 0.6882523868825239
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-36-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -514.2977114223582
  episode_reward_mean: -73286.44674321651
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 842
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.034
    dispatch_time_ms: 7.545
    learner:
      cur_lr: 0.0010796140413731337
      grad_gnorm: 40.0
      policy_entropy: 38.1732292175293
      policy_loss: 355.2127990722656
      var_gnorm: 55.858909606933594
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 5774.0146484375
    num_steps_sampled: 4215000
    num_steps_trained: 4215000
    wait_time_ms: 77.644
  iterations_since_restore: 843
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7352.9884123802185
  time_this_iter_s: 8.5194673538208
  time_total_s: 7352.9884123802185
  timestamp: 1594863381
  timesteps_since_restore: 4215000
  timesteps_this_iter: 5000
  timesteps_total: 4215000
  training_iteration: 843
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7352 s, 843 iter, 4215000 ts, -7.33e+04 rew

agent-1: -1225.4010677615013
agent-2: -1849.113957412487
agent-3: -1582.6954955852495
agent-4: -1539.7715921364077
agent-5: -1751.8394051984712
Extrinsic Rewards:
-1091
-1684
-1450
-1390
-1590
Sum Reward: -7205
Avg Reward: -1441.0
Min Reward: -1684
Max Reward: -1091
Gini Coefficient: -0.07694656488549619
20:20 Ratio: 0.6478622327790974
Max-min Ratio: 0.6478622327790974
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-36-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -514.2977114223582
  episode_reward_mean: -73360.30117871212
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 843
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.351
    dispatch_time_ms: 9.489
    learner:
      cur_lr: 0.0010792809771373868
      grad_gnorm: 40.0
      policy_entropy: 38.44438171386719
      policy_loss: 503.82196044921875
      var_gnorm: 55.47026824951172
      vf_explained_var: 0.0
      vf_loss: 5407.48193359375
    num_steps_sampled: 4220000
    num_steps_trained: 4220000
    wait_time_ms: 71.916
  iterations_since_restore: 844
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7361.263437986374
  time_this_iter_s: 8.275025606155396
  time_total_s: 7361.263437986374
  timestamp: 1594863390
  timesteps_since_restore: 4220000
  timesteps_this_iter: 5000
  timesteps_total: 4220000
  training_iteration: 844
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7361 s, 844 iter, 4220000 ts, -7.34e+04 rew

agent-1: -1352.374124308618
agent-2: -1821.260697357747
agent-3: -1658.2050827629582
agent-4: -1329.326570268782
agent-5: -1404.2087441410877
Extrinsic Rewards:
-1208
-1640
-1498
-1194
-1253
Sum Reward: -6793
Avg Reward: -1358.6
Min Reward: -1640
Max Reward: -1194
Gini Coefficient: -0.06960105991461799
20:20 Ratio: 0.7280487804878049
Max-min Ratio: 0.7280487804878049
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-36-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -514.2977114223582
  episode_reward_mean: -73430.41490080013
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 844
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.812
    dispatch_time_ms: 7.956
    learner:
      cur_lr: 0.0010789480293169618
      grad_gnorm: 40.0
      policy_entropy: 35.28663635253906
      policy_loss: 420.7428894042969
      var_gnorm: 55.053489685058594
      vf_explained_var: 0.0
      vf_loss: 5364.9482421875
    num_steps_sampled: 4225000
    num_steps_trained: 4225000
    wait_time_ms: 75.69
  iterations_since_restore: 845
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7369.688766717911
  time_this_iter_s: 8.425328731536865
  time_total_s: 7369.688766717911
  timestamp: 1594863398
  timesteps_since_restore: 4225000
  timesteps_this_iter: 5000
  timesteps_total: 4225000
  training_iteration: 845
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7369 s, 845 iter, 4225000 ts, -7.34e+04 rew

agent-1: -1214.3468587611535
agent-2: -1449.610576915371
agent-3: -1150.9645214096877
agent-4: -1479.1183307211131
agent-5: -1653.1231760370906
Extrinsic Rewards:
-1085
-1288
-981
-1322
-1483
Sum Reward: -6159
Avg Reward: -1231.8
Min Reward: -1483
Max Reward: -981
Gini Coefficient: -0.08059749959408995
20:20 Ratio: 0.6614969656102495
Max-min Ratio: 0.6614969656102495
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-36-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -514.2977114223582
  episode_reward_mean: -73493.11874740184
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 845
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.543
    dispatch_time_ms: 6.795
    learner:
      cur_lr: 0.001078614965081215
      grad_gnorm: 40.0
      policy_entropy: 31.283531188964844
      policy_loss: 373.8345642089844
      var_gnorm: 54.68809509277344
      vf_explained_var: 0.0
      vf_loss: 5285.8037109375
    num_steps_sampled: 4230000
    num_steps_trained: 4230000
    wait_time_ms: 73.312
  iterations_since_restore: 846
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7378.090963125229
  time_this_iter_s: 8.402196407318115
  time_total_s: 7378.090963125229
  timestamp: 1594863407
  timesteps_since_restore: 4230000
  timesteps_this_iter: 5000
  timesteps_total: 4230000
  training_iteration: 846
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7378 s, 846 iter, 4230000 ts, -7.35e+04 rew

agent-1: -1588.7162153131208
agent-2: -903.4436965063285
agent-3: -1258.6061008325
agent-4: -1556.0162315059133
agent-5: -1251.3578477221263
Extrinsic Rewards:
-1422
-801
-1072
-1382
-1081
Sum Reward: -5758
Avg Reward: -1151.6
Min Reward: -1422
Max Reward: -801
Gini Coefficient: -0.10781521361583883
20:20 Ratio: 0.5632911392405063
Max-min Ratio: 0.5632911392405063
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-36-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -514.2977114223582
  episode_reward_mean: -73550.72714849433
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 846
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.833
    dispatch_time_ms: 8.89
    learner:
      cur_lr: 0.0010782820172607899
      grad_gnorm: 39.999996185302734
      policy_entropy: 36.33273696899414
      policy_loss: 402.9381103515625
      var_gnorm: 54.177581787109375
      vf_explained_var: 0.0
      vf_loss: 5372.89404296875
    num_steps_sampled: 4235000
    num_steps_trained: 4235000
    wait_time_ms: 71.645
  iterations_since_restore: 847
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7386.448385953903
  time_this_iter_s: 8.357422828674316
  time_total_s: 7386.448385953903
  timestamp: 1594863415
  timesteps_since_restore: 4235000
  timesteps_this_iter: 5000
  timesteps_total: 4235000
  training_iteration: 847
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7386 s, 847 iter, 4235000 ts, -7.36e+04 rew

agent-1: -478.37479326878685
agent-2: -442.27632266249225
agent-3: -522.7444381531344
agent-4: -641.6210352548895
agent-5: -446.51082628845967
Extrinsic Rewards:
-371
-310
-403
-466
-308
Sum Reward: -1858
Avg Reward: -371.6
Min Reward: -466
Max Reward: -308
Gini Coefficient: -0.08805166846071044
20:20 Ratio: 0.6609442060085837
Max-min Ratio: 0.6609442060085837
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-37-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -514.2977114223582
  episode_reward_mean: -73569.85641236491
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 847
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.788
    dispatch_time_ms: 8.422
    learner:
      cur_lr: 0.001077948953025043
      grad_gnorm: 40.000003814697266
      policy_entropy: 37.7815055847168
      policy_loss: 454.2602233886719
      var_gnorm: 53.60636520385742
      vf_explained_var: 0.0
      vf_loss: 4364.05224609375
    num_steps_sampled: 4240000
    num_steps_trained: 4240000
    wait_time_ms: 73.618
  iterations_since_restore: 848
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7394.833667516708
  time_this_iter_s: 8.385281562805176
  time_total_s: 7394.833667516708
  timestamp: 1594863423
  timesteps_since_restore: 4240000
  timesteps_this_iter: 5000
  timesteps_total: 4240000
  training_iteration: 848
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7394 s, 848 iter, 4240000 ts, -7.36e+04 rew

agent-1: -580.4474984428138
agent-2: -533.1021320596016
agent-3: -886.0212295605388
agent-4: -904.2198437729089
agent-5: -869.0428549166836
Extrinsic Rewards:
-467
-406
-708
-753
-708
Sum Reward: -3042
Avg Reward: -608.4
Min Reward: -753
Max Reward: -406
Gini Coefficient: -0.12294543063773833
20:20 Ratio: 0.5391766268260292
Max-min Ratio: 0.5391766268260292
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-37-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -593.0868020989052
  episode_reward_mean: -73602.44177083821
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 848
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.737
    dispatch_time_ms: 7.875
    learner:
      cur_lr: 0.001077616005204618
      grad_gnorm: 40.0
      policy_entropy: 34.965972900390625
      policy_loss: 401.3282165527344
      var_gnorm: 53.11715316772461
      vf_explained_var: 0.0
      vf_loss: 5034.0263671875
    num_steps_sampled: 4245000
    num_steps_trained: 4245000
    wait_time_ms: 72.407
  iterations_since_restore: 849
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7403.159104585648
  time_this_iter_s: 8.325437068939209
  time_total_s: 7403.159104585648
  timestamp: 1594863432
  timesteps_since_restore: 4245000
  timesteps_this_iter: 5000
  timesteps_total: 4245000
  training_iteration: 849
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7403 s, 849 iter, 4245000 ts, -7.36e+04 rew

agent-1: -687.1581767144959
agent-2: -347.1666351493077
agent-3: -979.9764376772295
agent-4: -659.7014868515944
agent-5: -548.4355639859228
Extrinsic Rewards:
-559
-260
-774
-510
-413
Sum Reward: -2516
Avg Reward: -503.2
Min Reward: -774
Max Reward: -260
Gini Coefficient: -0.18664546899841017
20:20 Ratio: 0.3359173126614987
Max-min Ratio: 0.3359173126614987
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-37-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -593.0868020989052
  episode_reward_mean: -73626.49684581604
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 849
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.541
    dispatch_time_ms: 9.13
    learner:
      cur_lr: 0.001077283057384193
      grad_gnorm: 40.0
      policy_entropy: 49.563446044921875
      policy_loss: 390.73016357421875
      var_gnorm: 52.95419692993164
      vf_explained_var: 0.027517318725585938
      vf_loss: 2263.73193359375
    num_steps_sampled: 4250000
    num_steps_trained: 4250000
    wait_time_ms: 71.091
  iterations_since_restore: 850
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7411.566692829132
  time_this_iter_s: 8.407588243484497
  time_total_s: 7411.566692829132
  timestamp: 1594863440
  timesteps_since_restore: 4250000
  timesteps_this_iter: 5000
  timesteps_total: 4250000
  training_iteration: 850
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7411 s, 850 iter, 4250000 ts, -7.36e+04 rew

agent-1: -1046.961785888488
agent-2: -1001.90460332175
agent-3: -927.6432247746288
agent-4: -912.9553172388621
agent-5: -533.8456042320537
Extrinsic Rewards:
-912
-864
-764
-764
-422
Sum Reward: -3726
Avg Reward: -745.2
Min Reward: -912
Max Reward: -422
Gini Coefficient: -0.11594202898550725
20:20 Ratio: 0.46271929824561403
Max-min Ratio: 0.46271929824561403
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-37-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -593.0868020989052
  episode_reward_mean: -73662.62491738648
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 850
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.371
    dispatch_time_ms: 9.351
    learner:
      cur_lr: 0.001076949993148446
      grad_gnorm: 40.0
      policy_entropy: 70.28807830810547
      policy_loss: -88.30532836914062
      var_gnorm: 53.13121032714844
      vf_explained_var: 0.0
      vf_loss: 4969.66748046875
    num_steps_sampled: 4255000
    num_steps_trained: 4255000
    wait_time_ms: 71.657
  iterations_since_restore: 851
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7419.8723657131195
  time_this_iter_s: 8.305672883987427
  time_total_s: 7419.8723657131195
  timestamp: 1594863448
  timesteps_since_restore: 4255000
  timesteps_this_iter: 5000
  timesteps_total: 4255000
  training_iteration: 851
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7419 s, 851 iter, 4255000 ts, -7.37e+04 rew

agent-1: -4107.412463189102
agent-2: -3418.702557613558
agent-3: -4613.669142693542
agent-4: -4069.8167124166903
agent-5: -5027.126269830569
Extrinsic Rewards:
-3957
-3297
-4447
-3915
-4856
Sum Reward: -20472
Avg Reward: -4094.4
Min Reward: -4856
Max Reward: -3297
Gini Coefficient: -0.07131692067213756
20:20 Ratio: 0.6789538714991763
Max-min Ratio: 0.6789538714991763
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-37-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -593.0868020989052
  episode_reward_mean: -73868.03316171406
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 851
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.648
    dispatch_time_ms: 7.227
    learner:
      cur_lr: 0.001076617045328021
      grad_gnorm: 40.0
      policy_entropy: 73.251953125
      policy_loss: -1187.6572265625
      var_gnorm: 53.354183197021484
      vf_explained_var: 0.0
      vf_loss: 48649.15625
    num_steps_sampled: 4260000
    num_steps_trained: 4260000
    wait_time_ms: 74.262
  iterations_since_restore: 852
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7428.242676019669
  time_this_iter_s: 8.370310306549072
  time_total_s: 7428.242676019669
  timestamp: 1594863457
  timesteps_since_restore: 4260000
  timesteps_this_iter: 5000
  timesteps_total: 4260000
  training_iteration: 852
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7428 s, 852 iter, 4260000 ts, -7.39e+04 rew

agent-1: -3698.040079229178
agent-2: -3481.756030945009
agent-3: -5130.245737656856
agent-4: -4333.164181657989
agent-5: -3965.0652215733476
Extrinsic Rewards:
-3555
-3351
-4952
-4190
-3821
Sum Reward: -19869
Avg Reward: -3973.8
Min Reward: -4952
Max Reward: -3351
Gini Coefficient: -0.07724596104484373
20:20 Ratio: 0.6766962843295639
Max-min Ratio: 0.6766962843295639
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-37-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -593.0868020989052
  episode_reward_mean: -74066.09097318866
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 852
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.807
    dispatch_time_ms: 5.602
    learner:
      cur_lr: 0.0010762839810922742
      grad_gnorm: 39.999996185302734
      policy_entropy: 80.76431274414062
      policy_loss: -3390.27392578125
      var_gnorm: 53.6417236328125
      vf_explained_var: 0.0
      vf_loss: 75864.3359375
    num_steps_sampled: 4265000
    num_steps_trained: 4265000
    wait_time_ms: 77.106
  iterations_since_restore: 853
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7436.690288305283
  time_this_iter_s: 8.447612285614014
  time_total_s: 7436.690288305283
  timestamp: 1594863465
  timesteps_since_restore: 4265000
  timesteps_this_iter: 5000
  timesteps_total: 4265000
  training_iteration: 853
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7436 s, 853 iter, 4265000 ts, -7.41e+04 rew

agent-1: -8743.738191715021
agent-2: -6197.9094140106945
agent-3: -6212.642689778726
agent-4: -8544.420317431513
agent-5: -8695.617484521064
Extrinsic Rewards:
-8579
-6068
-6085
-8382
-8529
Sum Reward: -37643
Avg Reward: -7528.6
Min Reward: -8579
Max Reward: -6068
Gini Coefficient: -0.079334803283479
20:20 Ratio: 0.7073085441193613
Max-min Ratio: 0.7073085441193613
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-37-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -593.0868020989052
  episode_reward_mean: -74443.3609545089
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 853
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.664
    dispatch_time_ms: 9.27
    learner:
      cur_lr: 0.0010759510332718492
      grad_gnorm: 40.000003814697266
      policy_entropy: 78.4297866821289
      policy_loss: -212.53761291503906
      var_gnorm: 53.95964431762695
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 10111.2236328125
    num_steps_sampled: 4270000
    num_steps_trained: 4270000
    wait_time_ms: 71.364
  iterations_since_restore: 854
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7445.124946594238
  time_this_iter_s: 8.434658288955688
  time_total_s: 7445.124946594238
  timestamp: 1594863474
  timesteps_since_restore: 4270000
  timesteps_this_iter: 5000
  timesteps_total: 4270000
  training_iteration: 854
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7445 s, 854 iter, 4270000 ts, -7.44e+04 rew

agent-1: -6504.2605464592025
agent-2: -9754.151455159808
agent-3: -9022.004105976575
agent-4: -7844.427331390072
agent-5: -4608.863306489185
Extrinsic Rewards:
-6370
-9568
-8850
-7685
-4506
Sum Reward: -36979
Avg Reward: -7395.8
Min Reward: -9568
Max Reward: -4506
Gini Coefficient: -0.13633683982801048
20:20 Ratio: 0.4709448160535117
Max-min Ratio: 0.4709448160535117
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-38-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -593.0868020989052
  episode_reward_mean: -74813.70167348515
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 854
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.911
    dispatch_time_ms: 7.486
    learner:
      cur_lr: 0.0010756179690361023
      grad_gnorm: 40.000003814697266
      policy_entropy: 78.52619171142578
      policy_loss: -1481.09765625
      var_gnorm: 54.19691467285156
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 30972.8515625
    num_steps_sampled: 4275000
    num_steps_trained: 4275000
    wait_time_ms: 76.132
  iterations_since_restore: 855
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7453.45223903656
  time_this_iter_s: 8.327292442321777
  time_total_s: 7453.45223903656
  timestamp: 1594863482
  timesteps_since_restore: 4275000
  timesteps_this_iter: 5000
  timesteps_total: 4275000
  training_iteration: 855
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7453 s, 855 iter, 4275000 ts, -7.48e+04 rew

agent-1: -6258.658303114448
agent-2: -5539.59757668265
agent-3: -5344.227816054884
agent-4: -5172.34552696661
agent-5: -5011.71570642463
Extrinsic Rewards:
-6092
-5383
-5198
-5028
-4866
Sum Reward: -26567
Avg Reward: -5313.4
Min Reward: -6092
Max Reward: -4866
Gini Coefficient: -0.04226295780479542
20:20 Ratio: 0.798752462245568
Max-min Ratio: 0.798752462245568
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-38-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -593.0868020989052
  episode_reward_mean: -75080.07025269548
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 855
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.999
    dispatch_time_ms: 9.208
    learner:
      cur_lr: 0.0010752850212156773
      grad_gnorm: 39.999996185302734
      policy_entropy: 67.82068634033203
      policy_loss: -959.7259521484375
      var_gnorm: 54.43464660644531
      vf_explained_var: 0.0
      vf_loss: 32314.681640625
    num_steps_sampled: 4280000
    num_steps_trained: 4280000
    wait_time_ms: 71.596
  iterations_since_restore: 856
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7461.849023342133
  time_this_iter_s: 8.39678430557251
  time_total_s: 7461.849023342133
  timestamp: 1594863491
  timesteps_since_restore: 4280000
  timesteps_this_iter: 5000
  timesteps_total: 4280000
  training_iteration: 856
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7461 s, 856 iter, 4280000 ts, -7.51e+04 rew

agent-1: -6211.4988926434335
agent-2: -5056.929520203603
agent-3: -4924.5172976812655
agent-4: -3936.516583795316
agent-5: -4888.749888431445
Extrinsic Rewards:
-6040
-4902
-4776
-3816
-4740
Sum Reward: -24274
Avg Reward: -4854.8
Min Reward: -6040
Max Reward: -3816
Gini Coefficient: -0.07596605421438576
20:20 Ratio: 0.6317880794701987
Max-min Ratio: 0.6317880794701987
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-38-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -593.0868020989052
  episode_reward_mean: -75323.37344383523
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 856
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.524
    dispatch_time_ms: 9.68
    learner:
      cur_lr: 0.0010749519569799304
      grad_gnorm: 40.0
      policy_entropy: 70.67919921875
      policy_loss: -1616.4842529296875
      var_gnorm: 54.662166595458984
      vf_explained_var: 0.0
      vf_loss: 33068.77734375
    num_steps_sampled: 4285000
    num_steps_trained: 4285000
    wait_time_ms: 70.546
  iterations_since_restore: 857
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7470.143624544144
  time_this_iter_s: 8.294601202011108
  time_total_s: 7470.143624544144
  timestamp: 1594863499
  timesteps_since_restore: 4285000
  timesteps_this_iter: 5000
  timesteps_total: 4285000
  training_iteration: 857
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7470 s, 857 iter, 4285000 ts, -7.53e+04 rew

agent-1: -4046.6209613201822
agent-2: -5773.367405362949
agent-3: -5916.411650658926
agent-4: -6082.580490562089
agent-5: -4774.235427111415
Extrinsic Rewards:
-3926
-5614
-5753
-5906
-4640
Sum Reward: -25839
Avg Reward: -5167.8
Min Reward: -5906
Max Reward: -3926
Gini Coefficient: -0.07853245094624405
20:20 Ratio: 0.6647477141889604
Max-min Ratio: 0.6647477141889604
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-38-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -593.0868020989052
  episode_reward_mean: -75583.16243622733
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 857
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.764
    dispatch_time_ms: 6.493
    learner:
      cur_lr: 0.0010746190091595054
      grad_gnorm: 39.99999237060547
      policy_entropy: 60.875511169433594
      policy_loss: -83.0416030883789
      var_gnorm: 54.942726135253906
      vf_explained_var: 0.0
      vf_loss: 6946.095703125
    num_steps_sampled: 4290000
    num_steps_trained: 4290000
    wait_time_ms: 76.74
  iterations_since_restore: 858
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7478.902017116547
  time_this_iter_s: 8.758392572402954
  time_total_s: 7478.902017116547
  timestamp: 1594863508
  timesteps_since_restore: 4290000
  timesteps_this_iter: 5000
  timesteps_total: 4290000
  training_iteration: 858
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7478 s, 858 iter, 4290000 ts, -7.56e+04 rew

agent-1: -6026.238234482839
agent-2: -5097.066096544419
agent-3: -4741.079842323993
agent-4: -4961.405952633446
agent-5: -4439.715421227015
Extrinsic Rewards:
-5854
-4944
-4599
-4813
-4301
Sum Reward: -24511
Avg Reward: -4902.2
Min Reward: -5854
Max Reward: -4301
Gini Coefficient: -0.056317571702500915
20:20 Ratio: 0.7347113085070037
Max-min Ratio: 0.7347113085070037
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-38-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -593.0868020989052
  episode_reward_mean: -75829.05750339362
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 858
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.1
    dispatch_time_ms: 7.035
    learner:
      cur_lr: 0.0010742859449237585
      grad_gnorm: 40.0
      policy_entropy: 61.55614471435547
      policy_loss: -2290.549560546875
      var_gnorm: 55.21711349487305
      vf_explained_var: 0.0
      vf_loss: 101068.6640625
    num_steps_sampled: 4295000
    num_steps_trained: 4295000
    wait_time_ms: 73.647
  iterations_since_restore: 859
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7487.1617777347565
  time_this_iter_s: 8.259760618209839
  time_total_s: 7487.1617777347565
  timestamp: 1594863516
  timesteps_since_restore: 4295000
  timesteps_this_iter: 5000
  timesteps_total: 4295000
  training_iteration: 859
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7487 s, 859 iter, 4295000 ts, -7.58e+04 rew

agent-1: -6003.179362598366
agent-2: -6801.422107005506
agent-3: -6522.134485436805
agent-4: -6027.06384971745
agent-5: -6146.389812744269
Extrinsic Rewards:
-5859
-6642
-6362
-5874
-6001
Sum Reward: -30738
Avg Reward: -6147.6
Min Reward: -6642
Max Reward: -5859
Gini Coefficient: -0.026729130067018023
20:20 Ratio: 0.8821138211382114
Max-min Ratio: 0.8821138211382114
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-38-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -593.0868020989052
  episode_reward_mean: -76137.31812104082
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 859
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.957
    dispatch_time_ms: 8.232
    learner:
      cur_lr: 0.0010739529971033335
      grad_gnorm: 40.0
      policy_entropy: 58.00979232788086
      policy_loss: -4488.40771484375
      var_gnorm: 55.51622772216797
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 359874.96875
    num_steps_sampled: 4300000
    num_steps_trained: 4300000
    wait_time_ms: 72.117
  iterations_since_restore: 860
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7495.41117978096
  time_this_iter_s: 8.249402046203613
  time_total_s: 7495.41117978096
  timestamp: 1594863524
  timesteps_since_restore: 4300000
  timesteps_this_iter: 5000
  timesteps_total: 4300000
  training_iteration: 860
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7495 s, 860 iter, 4300000 ts, -7.61e+04 rew

agent-1: -6169.7628556166965
agent-2: -5288.816758870981
agent-3: -7413.568877025341
agent-4: -5092.554272379636
agent-5: -5104.966137775981
Extrinsic Rewards:
-6017
-5141
-7231
-4959
-4972
Sum Reward: -28320
Avg Reward: -5664.0
Min Reward: -7231
Max Reward: -4959
Gini Coefficient: -0.0789406779661017
20:20 Ratio: 0.6857972617895174
Max-min Ratio: 0.6857972617895174
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-38-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -593.0868020989052
  episode_reward_mean: -76420.51209063019
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 860
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.86
    dispatch_time_ms: 8.788
    learner:
      cur_lr: 0.0010736200492829084
      grad_gnorm: 40.0
      policy_entropy: 58.62726593017578
      policy_loss: -6742.58642578125
      var_gnorm: 55.87633514404297
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 404145.40625
    num_steps_sampled: 4305000
    num_steps_trained: 4305000
    wait_time_ms: 74.347
  iterations_since_restore: 861
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7503.846112728119
  time_this_iter_s: 8.434932947158813
  time_total_s: 7503.846112728119
  timestamp: 1594863533
  timesteps_since_restore: 4305000
  timesteps_this_iter: 5000
  timesteps_total: 4305000
  training_iteration: 861
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7503 s, 861 iter, 4305000 ts, -7.64e+04 rew

agent-1: -14056.80382795156
agent-2: -13220.847591772903
agent-3: -13868.366173696115
agent-4: -14164.445130604065
agent-5: -15231.15006205255
Extrinsic Rewards:
-13919
-13069
-13705
-14013
-15083
Sum Reward: -69789
Avg Reward: -13957.8
Min Reward: -15083
Max Reward: -13069
Gini Coefficient: -0.024852054048632305
20:20 Ratio: 0.866472187230657
Max-min Ratio: 0.866472187230657
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-39-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -593.0868020989052
  episode_reward_mean: -77119.27958847657
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 861
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.608
    dispatch_time_ms: 6.421
    learner:
      cur_lr: 0.0010732869850471616
      grad_gnorm: 39.999996185302734
      policy_entropy: 56.23482894897461
      policy_loss: -3843.661376953125
      var_gnorm: 56.240482330322266
      vf_explained_var: 0.0
      vf_loss: 448232.4375
    num_steps_sampled: 4310000
    num_steps_trained: 4310000
    wait_time_ms: 74.083
  iterations_since_restore: 862
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7512.282797336578
  time_this_iter_s: 8.436684608459473
  time_total_s: 7512.282797336578
  timestamp: 1594863541
  timesteps_since_restore: 4310000
  timesteps_this_iter: 5000
  timesteps_total: 4310000
  training_iteration: 862
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7512 s, 862 iter, 4310000 ts, -7.71e+04 rew

agent-1: -17011.547319299367
agent-2: -12517.59908441176
agent-3: -16067.851084237378
agent-4: -17442.716124878196
agent-5: -12678.876708819214
Extrinsic Rewards:
-16843
-12387
-15911
-17273
-12546
Sum Reward: -74960
Avg Reward: -14992.0
Min Reward: -17273
Max Reward: -12387
Gini Coefficient: -0.07507470651013874
20:20 Ratio: 0.717130782145545
Max-min Ratio: 0.717130782145545
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-39-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -593.0868020989052
  episode_reward_mean: -77870.17913451738
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 862
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.87
    dispatch_time_ms: 7.252
    learner:
      cur_lr: 0.0010729540372267365
      grad_gnorm: 40.0
      policy_entropy: 59.16926956176758
      policy_loss: -4472.40478515625
      var_gnorm: 56.60702896118164
      vf_explained_var: 0.0
      vf_loss: 429315.46875
    num_steps_sampled: 4315000
    num_steps_trained: 4315000
    wait_time_ms: 74.537
  iterations_since_restore: 863
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7520.690938949585
  time_this_iter_s: 8.408141613006592
  time_total_s: 7520.690938949585
  timestamp: 1594863550
  timesteps_since_restore: 4315000
  timesteps_this_iter: 5000
  timesteps_total: 4315000
  training_iteration: 863
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7520 s, 863 iter, 4315000 ts, -7.79e+04 rew

agent-1: -15584.562611562887
agent-2: -15423.879470611888
agent-3: -15771.036182100888
agent-4: -12780.772477475299
agent-5: -15881.757774765934
Extrinsic Rewards:
-15432
-15270
-15614
-12653
-15728
Sum Reward: -74697
Avg Reward: -14939.4
Min Reward: -15728
Max Reward: -12653
Gini Coefficient: -0.03477515830622381
20:20 Ratio: 0.8044888097660223
Max-min Ratio: 0.8044888097660223
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-39-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -593.0868020989052
  episode_reward_mean: -78617.91844618667
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 863
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.747
    dispatch_time_ms: 8.879
    learner:
      cur_lr: 0.0010726209729909897
      grad_gnorm: 40.0
      policy_entropy: 53.25963592529297
      policy_loss: -5933.966796875
      var_gnorm: 56.976505279541016
      vf_explained_var: 0.0
      vf_loss: 812599.5
    num_steps_sampled: 4320000
    num_steps_trained: 4320000
    wait_time_ms: 72.635
  iterations_since_restore: 864
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7529.006898164749
  time_this_iter_s: 8.315959215164185
  time_total_s: 7529.006898164749
  timestamp: 1594863558
  timesteps_since_restore: 4320000
  timesteps_this_iter: 5000
  timesteps_total: 4320000
  training_iteration: 864
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7529 s, 864 iter, 4320000 ts, -7.86e+04 rew

agent-1: -14682.06324240486
agent-2: -20155.70568733014
agent-3: -21435.203498631927
agent-4: -17461.83476542449
agent-5: -21711.478071350124
Extrinsic Rewards:
-14554
-19994
-21274
-17327
-21540
Sum Reward: -94689
Avg Reward: -18937.8
Min Reward: -21540
Max Reward: -14554
Gini Coefficient: -0.07569622659443019
20:20 Ratio: 0.6756731662024141
Max-min Ratio: 0.6756731662024141
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-39-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -593.0868020989052
  episode_reward_mean: -79565.95714808532
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 864
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.004
    dispatch_time_ms: 8.838
    learner:
      cur_lr: 0.0010722880251705647
      grad_gnorm: 40.0
      policy_entropy: 40.71654510498047
      policy_loss: -5216.6669921875
      var_gnorm: 57.347782135009766
      vf_explained_var: 0.0
      vf_loss: 511655.03125
    num_steps_sampled: 4325000
    num_steps_trained: 4325000
    wait_time_ms: 75.129
  iterations_since_restore: 865
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7537.44623208046
  time_this_iter_s: 8.43933391571045
  time_total_s: 7537.44623208046
  timestamp: 1594863567
  timesteps_since_restore: 4325000
  timesteps_this_iter: 5000
  timesteps_total: 4325000
  training_iteration: 865
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7537 s, 865 iter, 4325000 ts, -7.96e+04 rew

agent-1: -17050.281742644835
agent-2: -30193.848900495497
agent-3: -15310.761760321537
agent-4: -21039.165569883433
agent-5: -32949.80895935009
Extrinsic Rewards:
-16941
-30017
-15199
-20900
-32746
Sum Reward: -115803
Avg Reward: -23160.6
Min Reward: -32746
Max Reward: -15199
Gini Coefficient: -0.16638601763339464
20:20 Ratio: 0.46414829292127285
Max-min Ratio: 0.46414829292127285
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-39-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -593.0868020989052
  episode_reward_mean: -80724.66199291236
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 865
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.57
    dispatch_time_ms: 6.409
    learner:
      cur_lr: 0.0010719549609348178
      grad_gnorm: 40.0
      policy_entropy: 33.639793395996094
      policy_loss: -11200.9443359375
      var_gnorm: 57.72859573364258
      vf_explained_var: 0.0
      vf_loss: 4330575.5
    num_steps_sampled: 4330000
    num_steps_trained: 4330000
    wait_time_ms: 79.729
  iterations_since_restore: 866
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7545.984266281128
  time_this_iter_s: 8.538034200668335
  time_total_s: 7545.984266281128
  timestamp: 1594863575
  timesteps_since_restore: 4330000
  timesteps_this_iter: 5000
  timesteps_total: 4330000
  training_iteration: 866
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7545 s, 866 iter, 4330000 ts, -8.07e+04 rew

agent-1: -24981.580038694014
agent-2: -25923.163551983904
agent-3: -28612.272309383632
agent-4: -29302.410104615527
agent-5: -23834.411660063368
Extrinsic Rewards:
-24845
-25771
-28449
-29136
-23699
Sum Reward: -131900
Avg Reward: -26380.0
Min Reward: -29136
Max Reward: -23699
Gini Coefficient: -0.04390598938589841
20:20 Ratio: 0.8133923668314114
Max-min Ratio: 0.8133923668314114
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-39-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -593.0868020989052
  episode_reward_mean: -82043.94077512994
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 866
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.885
    dispatch_time_ms: 8.378
    learner:
      cur_lr: 0.0010716220131143928
      grad_gnorm: 40.0
      policy_entropy: 37.587066650390625
      policy_loss: -8999.9873046875
      var_gnorm: 58.098045349121094
      vf_explained_var: 0.0
      vf_loss: 2520735.5
    num_steps_sampled: 4335000
    num_steps_trained: 4335000
    wait_time_ms: 72.298
  iterations_since_restore: 867
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7554.421274662018
  time_this_iter_s: 8.437008380889893
  time_total_s: 7554.421274662018
  timestamp: 1594863584
  timesteps_since_restore: 4335000
  timesteps_this_iter: 5000
  timesteps_total: 4335000
  training_iteration: 867
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7554 s, 867 iter, 4335000 ts, -8.2e+04 rew

agent-1: -22901.388948022268
agent-2: -21215.506659822127
agent-3: -17536.43884641347
agent-4: -26374.266780267342
agent-5: -29145.497384630144
Extrinsic Rewards:
-22753
-21067
-17424
-26213
-28970
Sum Reward: -116427
Avg Reward: -23285.4
Min Reward: -28970
Max Reward: -17424
Gini Coefficient: -0.09701529713897979
20:20 Ratio: 0.601449775629962
Max-min Ratio: 0.601449775629962
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-39-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -593.0868020989052
  episode_reward_mean: -83209.23886019835
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 867
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.189
    dispatch_time_ms: 7.566
    learner:
      cur_lr: 0.001071288948878646
      grad_gnorm: 40.0
      policy_entropy: 26.534423828125
      policy_loss: -5152.2060546875
      var_gnorm: 58.47538757324219
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2040576.625
    num_steps_sampled: 4340000
    num_steps_trained: 4340000
    wait_time_ms: 74.256
  iterations_since_restore: 868
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7562.8847913742065
  time_this_iter_s: 8.46351671218872
  time_total_s: 7562.8847913742065
  timestamp: 1594863592
  timesteps_since_restore: 4340000
  timesteps_this_iter: 5000
  timesteps_total: 4340000
  training_iteration: 868
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7562 s, 868 iter, 4340000 ts, -8.32e+04 rew

agent-1: -28421.68782188721
agent-2: -13223.142302398679
agent-3: -29847.094093552816
agent-4: -24483.16020361593
agent-5: -22836.31818031231
Extrinsic Rewards:
-28243
-13135
-29674
-24325
-22693
Sum Reward: -118070
Avg Reward: -23614.0
Min Reward: -29674
Max Reward: -13135
Gini Coefficient: -0.1308647412551876
20:20 Ratio: 0.442643391521197
Max-min Ratio: 0.442643391521197
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-40-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -593.0868020989052
  episode_reward_mean: -84390.0385137008
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 868
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.461
    dispatch_time_ms: 5.547
    learner:
      cur_lr: 0.0010709560010582209
      grad_gnorm: 40.0
      policy_entropy: 26.92926025390625
      policy_loss: -1447.2781982421875
      var_gnorm: 58.848236083984375
      vf_explained_var: 0.0
      vf_loss: 3427522.0
    num_steps_sampled: 4345000
    num_steps_trained: 4345000
    wait_time_ms: 78.63
  iterations_since_restore: 869
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7571.449511051178
  time_this_iter_s: 8.564719676971436
  time_total_s: 7571.449511051178
  timestamp: 1594863601
  timesteps_since_restore: 4345000
  timesteps_this_iter: 5000
  timesteps_total: 4345000
  training_iteration: 869
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7571 s, 869 iter, 4345000 ts, -8.44e+04 rew

agent-1: -22685.04856433434
agent-2: -28832.130216753958
agent-3: -29319.97016138475
agent-4: -33873.23300135351
agent-5: -27910.347609388853
Extrinsic Rewards:
-22572
-28671
-29167
-33708
-27761
Sum Reward: -141879
Avg Reward: -28375.8
Min Reward: -33708
Max Reward: -22572
Gini Coefficient: -0.06675547473551406
20:20 Ratio: 0.6696333214667142
Max-min Ratio: 0.6696333214667142
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-40-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -593.0868020989052
  episode_reward_mean: -85810.25406575427
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 869
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.706
    dispatch_time_ms: 6.302
    learner:
      cur_lr: 0.0010706230532377958
      grad_gnorm: 39.999996185302734
      policy_entropy: 25.456464767456055
      policy_loss: -549.7403564453125
      var_gnorm: 59.23366928100586
      vf_explained_var: 0.0
      vf_loss: 211448.84375
    num_steps_sampled: 4350000
    num_steps_trained: 4350000
    wait_time_ms: 75.026
  iterations_since_restore: 870
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7580.010097503662
  time_this_iter_s: 8.56058645248413
  time_total_s: 7580.010097503662
  timestamp: 1594863609
  timesteps_since_restore: 4350000
  timesteps_this_iter: 5000
  timesteps_total: 4350000
  training_iteration: 870
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7580 s, 870 iter, 4350000 ts, -8.58e+04 rew

agent-1: -26315.114760860313
agent-2: -24151.395820002195
agent-3: -20718.872885678014
agent-4: -21290.848996891626
agent-5: -30454.21861189176
Extrinsic Rewards:
-26163
-24014
-20595
-21163
-30275
Sum Reward: -122210
Avg Reward: -24442.0
Min Reward: -30275
Max Reward: -20595
Gini Coefficient: -0.07973160952458883
20:20 Ratio: 0.6802642444260941
Max-min Ratio: 0.6802642444260941
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-40-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2379.7728858651935
  episode_reward_mean: -87033.62770848654
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 870
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.914
    dispatch_time_ms: 8.641
    learner:
      cur_lr: 0.001070289989002049
      grad_gnorm: 39.999996185302734
      policy_entropy: 31.32201385498047
      policy_loss: -2586.00390625
      var_gnorm: 59.61083221435547
      vf_explained_var: 0.0
      vf_loss: 412171.78125
    num_steps_sampled: 4355000
    num_steps_trained: 4355000
    wait_time_ms: 74.813
  iterations_since_restore: 871
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7588.555985927582
  time_this_iter_s: 8.545888423919678
  time_total_s: 7588.555985927582
  timestamp: 1594863618
  timesteps_since_restore: 4355000
  timesteps_this_iter: 5000
  timesteps_total: 4355000
  training_iteration: 871
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7588 s, 871 iter, 4355000 ts, -8.7e+04 rew

agent-1: -32413.532406216036
agent-2: -22900.387400647916
agent-3: -34934.47198031941
agent-4: -12655.79133001263
agent-5: -16064.173703384651
Extrinsic Rewards:
-32231
-22753
-34747
-12574
-15962
Sum Reward: -118267
Avg Reward: -23653.4
Min Reward: -34747
Max Reward: -12574
Gini Coefficient: -0.2050106961367076
20:20 Ratio: 0.36187296745042735
Max-min Ratio: 0.36187296745042735
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-40-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -88199.51354783369
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 871
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.585
    dispatch_time_ms: 6.18
    learner:
      cur_lr: 0.001069957041181624
      grad_gnorm: 40.0
      policy_entropy: 25.20854949951172
      policy_loss: -6957.7734375
      var_gnorm: 59.98228454589844
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 2818742.25
    num_steps_sampled: 4360000
    num_steps_trained: 4360000
    wait_time_ms: 76.627
  iterations_since_restore: 872
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7597.113230228424
  time_this_iter_s: 8.557244300842285
  time_total_s: 7597.113230228424
  timestamp: 1594863626
  timesteps_since_restore: 4360000
  timesteps_this_iter: 5000
  timesteps_total: 4360000
  training_iteration: 872
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7597 s, 872 iter, 4360000 ts, -8.82e+04 rew

agent-1: -39099.71415208269
agent-2: -24111.855640141395
agent-3: -32425.472283571347
agent-4: -30418.63978204571
agent-5: -54788.7451878849
Extrinsic Rewards:
-38946
-24004
-32285
-30292
-54584
Sum Reward: -180111
Avg Reward: -36022.2
Min Reward: -54584
Max Reward: -24004
Gini Coefficient: -0.15504661014596555
20:20 Ratio: 0.4397625677854316
Max-min Ratio: 0.4397625677854316
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-40-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -89936.30933097823
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 872
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.701
    dispatch_time_ms: 6.59
    learner:
      cur_lr: 0.001069623976945877
      grad_gnorm: 40.0
      policy_entropy: 22.44874382019043
      policy_loss: -844.62548828125
      var_gnorm: 60.37625503540039
      vf_explained_var: 0.0
      vf_loss: 443903.6875
    num_steps_sampled: 4365000
    num_steps_trained: 4365000
    wait_time_ms: 75.494
  iterations_since_restore: 873
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7605.60095334053
  time_this_iter_s: 8.487723112106323
  time_total_s: 7605.60095334053
  timestamp: 1594863635
  timesteps_since_restore: 4365000
  timesteps_this_iter: 5000
  timesteps_total: 4365000
  training_iteration: 873
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7605 s, 873 iter, 4365000 ts, -8.99e+04 rew

agent-1: -32144.86593825202
agent-2: -39658.350657591895
agent-3: -17071.022280177516
agent-4: -25443.28916226849
agent-5: -40248.74422640803
Extrinsic Rewards:
-31992
-39480
-16978
-25315
-40063
Sum Reward: -153828
Avg Reward: -30765.6
Min Reward: -40063
Max Reward: -16978
Gini Coefficient: -0.15688951296252956
20:20 Ratio: 0.42378254249556946
Max-min Ratio: 0.42378254249556946
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-40-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -90892.85882886051
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 873
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.058
    dispatch_time_ms: 7.568
    learner:
      cur_lr: 0.001069291029125452
      grad_gnorm: 40.0
      policy_entropy: 30.55278778076172
      policy_loss: -7715.18310546875
      var_gnorm: 60.76869583129883
      vf_explained_var: 0.0
      vf_loss: 2222219.0
    num_steps_sampled: 4370000
    num_steps_trained: 4370000
    wait_time_ms: 73.139
  iterations_since_restore: 874
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7614.10897397995
  time_this_iter_s: 8.508020639419556
  time_total_s: 7614.10897397995
  timestamp: 1594863644
  timesteps_since_restore: 4370000
  timesteps_this_iter: 5000
  timesteps_total: 4370000
  training_iteration: 874
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7614 s, 874 iter, 4370000 ts, -9.09e+04 rew

agent-1: -35108.75329994958
agent-2: -42240.71221034176
agent-3: -36797.5334340539
agent-4: -31165.570748092385
agent-5: -28163.880995498228
Extrinsic Rewards:
-34966
-42079
-36638
-31025
-28061
Sum Reward: -172769
Avg Reward: -34553.8
Min Reward: -42079
Max Reward: -28061
Gini Coefficient: -0.07790517974868176
20:20 Ratio: 0.6668647068609045
Max-min Ratio: 0.6668647068609045
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-40-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -92079.47443157685
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 874
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.35
    dispatch_time_ms: 7.07
    learner:
      cur_lr: 0.0010689579648897052
      grad_gnorm: 40.0
      policy_entropy: 27.360754013061523
      policy_loss: -6980.916015625
      var_gnorm: 61.15473937988281
      vf_explained_var: 0.0
      vf_loss: 2626686.25
    num_steps_sampled: 4375000
    num_steps_trained: 4375000
    wait_time_ms: 79.789
  iterations_since_restore: 875
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7622.629381656647
  time_this_iter_s: 8.520407676696777
  time_total_s: 7622.629381656647
  timestamp: 1594863652
  timesteps_since_restore: 4375000
  timesteps_this_iter: 5000
  timesteps_total: 4375000
  training_iteration: 875
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7622 s, 875 iter, 4375000 ts, -9.21e+04 rew

agent-1: -15683.480281713897
agent-2: -32377.84919666097
agent-3: -23054.05511099517
agent-4: -31959.6029847017
agent-5: -29752.87279869812
Extrinsic Rewards:
-15584
-32201
-22918
-31783
-29595
Sum Reward: -132081
Avg Reward: -26416.2
Min Reward: -32201
Max Reward: -15584
Gini Coefficient: -0.12749449201626276
20:20 Ratio: 0.48396012546194217
Max-min Ratio: 0.48396012546194217
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-41-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -92642.51369222268
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 875
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.495
    dispatch_time_ms: 9.449
    learner:
      cur_lr: 0.0010686250170692801
      grad_gnorm: 39.999996185302734
      policy_entropy: 47.53424835205078
      policy_loss: -5570.34423828125
      var_gnorm: 61.543601989746094
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 633200.4375
    num_steps_sampled: 4380000
    num_steps_trained: 4380000
    wait_time_ms: 69.348
  iterations_since_restore: 876
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7631.078425884247
  time_this_iter_s: 8.449044227600098
  time_total_s: 7631.078425884247
  timestamp: 1594863661
  timesteps_since_restore: 4380000
  timesteps_this_iter: 5000
  timesteps_total: 4380000
  training_iteration: 876
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7631 s, 876 iter, 4380000 ts, -9.26e+04 rew

agent-1: -44698.7608472187
agent-2: -27842.978558027437
agent-3: -36336.79634920282
agent-4: -36557.82016193642
agent-5: -32656.819046722605
Extrinsic Rewards:
-44520
-27726
-36182
-36401
-32518
Sum Reward: -177347
Avg Reward: -35469.4
Min Reward: -44520
Max Reward: -27726
Gini Coefficient: -0.08451453929302441
20:20 Ratio: 0.6227762803234501
Max-min Ratio: 0.6227762803234501
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-41-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -93622.32806194774
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 876
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.644
    dispatch_time_ms: 9.248
    learner:
      cur_lr: 0.0010682919528335333
      grad_gnorm: 40.0
      policy_entropy: 41.89141082763672
      policy_loss: -6227.90966796875
      var_gnorm: 61.92477798461914
      vf_explained_var: 0.0
      vf_loss: 589661.875
    num_steps_sampled: 4385000
    num_steps_trained: 4385000
    wait_time_ms: 67.635
  iterations_since_restore: 877
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7639.474682331085
  time_this_iter_s: 8.396256446838379
  time_total_s: 7639.474682331085
  timestamp: 1594863669
  timesteps_since_restore: 4385000
  timesteps_this_iter: 5000
  timesteps_total: 4385000
  training_iteration: 877
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7639 s, 877 iter, 4385000 ts, -9.36e+04 rew

agent-1: -23861.55904274736
agent-2: -18991.74428173159
agent-3: -14453.81938138361
agent-4: -27352.599972272503
agent-5: -29714.164007539493
Extrinsic Rewards:
-23708
-18859
-14356
-27182
-29532
Sum Reward: -113637
Avg Reward: -22727.4
Min Reward: -29532
Max Reward: -14356
Gini Coefficient: -0.1361352376426692
20:20 Ratio: 0.48611675470675875
Max-min Ratio: 0.48611675470675875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-41-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -93660.93103038639
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 877
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.925
    dispatch_time_ms: 8.751
    learner:
      cur_lr: 0.0010679590050131083
      grad_gnorm: 40.0
      policy_entropy: 43.955806732177734
      policy_loss: -2057.084716796875
      var_gnorm: 62.317840576171875
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 108607.484375
    num_steps_sampled: 4390000
    num_steps_trained: 4390000
    wait_time_ms: 72.154
  iterations_since_restore: 878
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7647.8879981040955
  time_this_iter_s: 8.413315773010254
  time_total_s: 7647.8879981040955
  timestamp: 1594863677
  timesteps_since_restore: 4390000
  timesteps_this_iter: 5000
  timesteps_total: 4390000
  training_iteration: 878
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7647 s, 878 iter, 4390000 ts, -9.37e+04 rew

agent-1: -22505.04739474576
agent-2: -24849.881176528837
agent-3: -19233.577155354087
agent-4: -32989.97727197178
agent-5: -27053.812006371212
Extrinsic Rewards:
-22368
-24719
-19118
-32799
-26893
Sum Reward: -125897
Avg Reward: -25179.4
Min Reward: -32799
Max Reward: -19118
Gini Coefficient: -0.10131138946916925
20:20 Ratio: 0.5828836245007469
Max-min Ratio: 0.5828836245007469
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-41-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -93753.2319749987
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 878
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.619
    dispatch_time_ms: 7.093
    learner:
      cur_lr: 0.0010676260571926832
      grad_gnorm: 39.999996185302734
      policy_entropy: 43.34626007080078
      policy_loss: -5534.3388671875
      var_gnorm: 62.71342468261719
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1887645.875
    num_steps_sampled: 4395000
    num_steps_trained: 4395000
    wait_time_ms: 74.243
  iterations_since_restore: 879
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7656.360478878021
  time_this_iter_s: 8.472480773925781
  time_total_s: 7656.360478878021
  timestamp: 1594863686
  timesteps_since_restore: 4395000
  timesteps_this_iter: 5000
  timesteps_total: 4395000
  training_iteration: 879
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7656 s, 879 iter, 4395000 ts, -9.38e+04 rew

agent-1: -19626.05462519983
agent-2: -20923.281021203446
agent-3: -29920.14613390674
agent-4: -24070.501087235578
agent-5: -24338.051021604813
Extrinsic Rewards:
-19496
-20782
-29736
-23927
-24189
Sum Reward: -118130
Avg Reward: -23626.0
Min Reward: -29736
Max Reward: -19496
Gini Coefficient: -0.08088377211546602
20:20 Ratio: 0.6556362658057573
Max-min Ratio: 0.6556362658057573
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-41-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -93971.16759366608
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 879
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.063
    dispatch_time_ms: 9.894
    learner:
      cur_lr: 0.0010672929929569364
      grad_gnorm: 39.999996185302734
      policy_entropy: 32.31906509399414
      policy_loss: -2552.071533203125
      var_gnorm: 63.10837173461914
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 384174.5625
    num_steps_sampled: 4400000
    num_steps_trained: 4400000
    wait_time_ms: 72.328
  iterations_since_restore: 880
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7664.768166780472
  time_this_iter_s: 8.407687902450562
  time_total_s: 7664.768166780472
  timestamp: 1594863694
  timesteps_since_restore: 4400000
  timesteps_this_iter: 5000
  timesteps_total: 4400000
  training_iteration: 880
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7664 s, 880 iter, 4400000 ts, -9.4e+04 rew

agent-1: -21335.40999510553
agent-2: -15355.015381673611
agent-3: -32252.461568506875
agent-4: -31709.493009105765
agent-5: -23301.785574675276
Extrinsic Rewards:
-21205
-15254
-32068
-31526
-23161
Sum Reward: -123214
Avg Reward: -24642.8
Min Reward: -32068
Max Reward: -15254
Gini Coefficient: -0.14267534533413412
20:20 Ratio: 0.4756766870400399
Max-min Ratio: 0.4756766870400399
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-41-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -94132.25420230566
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 880
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 4.053
    dispatch_time_ms: 6.071
    learner:
      cur_lr: 0.0010669600451365113
      grad_gnorm: 40.0
      policy_entropy: 48.71272659301758
      policy_loss: -6809.1513671875
      var_gnorm: 63.50057601928711
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1151683.75
    num_steps_sampled: 4405000
    num_steps_trained: 4405000
    wait_time_ms: 74.871
  iterations_since_restore: 881
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7673.275577068329
  time_this_iter_s: 8.507410287857056
  time_total_s: 7673.275577068329
  timestamp: 1594863703
  timesteps_since_restore: 4405000
  timesteps_this_iter: 5000
  timesteps_total: 4405000
  training_iteration: 881
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7673 s, 881 iter, 4405000 ts, -9.41e+04 rew

agent-1: -23281.000503253046
agent-2: -20452.249484450924
agent-3: -15520.647283486032
agent-4: -17793.834309081332
agent-5: -25034.2988965647
Extrinsic Rewards:
-23113
-20305
-15401
-17658
-24862
Sum Reward: -101339
Avg Reward: -20267.8
Min Reward: -24862
Max Reward: -15401
Gini Coefficient: -0.09621961929760507
20:20 Ratio: 0.6194594159761886
Max-min Ratio: 0.6194594159761886
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-41-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -93954.83277081723
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 881
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.229
    dispatch_time_ms: 7.172
    learner:
      cur_lr: 0.0010666269809007645
      grad_gnorm: 39.999996185302734
      policy_entropy: 53.67179489135742
      policy_loss: -5480.12890625
      var_gnorm: 63.898887634277344
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 840038.625
    num_steps_sampled: 4410000
    num_steps_trained: 4410000
    wait_time_ms: 72.654
  iterations_since_restore: 882
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7681.653604984283
  time_this_iter_s: 8.37802791595459
  time_total_s: 7681.653604984283
  timestamp: 1594863711
  timesteps_since_restore: 4410000
  timesteps_this_iter: 5000
  timesteps_total: 4410000
  training_iteration: 882
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7681 s, 882 iter, 4410000 ts, -9.4e+04 rew

agent-1: -17859.774690955182
agent-2: -15862.539375493732
agent-3: -19501.501729665873
agent-4: -22707.1421184827
agent-5: -18388.06840409147
Extrinsic Rewards:
-17714
-15738
-19346
-22541
-18245
Sum Reward: -93584
Avg Reward: -18716.8
Min Reward: -22541
Max Reward: -15738
Gini Coefficient: -0.06513079158830569
20:20 Ratio: 0.6981944013131627
Max-min Ratio: 0.6981944013131627
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-42-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -93771.66761584794
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 882
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.364
    dispatch_time_ms: 10.872
    learner:
      cur_lr: 0.0010662940330803394
      grad_gnorm: 40.0
      policy_entropy: 46.450714111328125
      policy_loss: -1014.607421875
      var_gnorm: 64.29159545898438
      vf_explained_var: 0.0
      vf_loss: 352159.0625
    num_steps_sampled: 4415000
    num_steps_trained: 4415000
    wait_time_ms: 71.917
  iterations_since_restore: 883
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7690.05205988884
  time_this_iter_s: 8.398454904556274
  time_total_s: 7690.05205988884
  timestamp: 1594863720
  timesteps_since_restore: 4415000
  timesteps_this_iter: 5000
  timesteps_total: 4415000
  training_iteration: 883
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7690 s, 883 iter, 4415000 ts, -9.38e+04 rew

agent-1: -18093.81908547274
agent-2: -25048.44785480072
agent-3: -28378.853345899628
agent-4: -19488.017814587343
agent-5: -25467.540330374748
Extrinsic Rewards:
-17978
-24887
-28202
-19352
-25309
Sum Reward: -115728
Avg Reward: -23145.6
Min Reward: -28202
Max Reward: -17978
Gini Coefficient: -0.09126572653117655
20:20 Ratio: 0.6374725196794554
Max-min Ratio: 0.6374725196794554
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-42-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -93959.85584851216
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 883
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.795
    dispatch_time_ms: 8.372
    learner:
      cur_lr: 0.0010659609688445926
      grad_gnorm: 40.0
      policy_entropy: 53.93270492553711
      policy_loss: -3151.693115234375
      var_gnorm: 64.695068359375
      vf_explained_var: 0.0
      vf_loss: 359902.34375
    num_steps_sampled: 4420000
    num_steps_trained: 4420000
    wait_time_ms: 73.542
  iterations_since_restore: 884
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7698.4513149261475
  time_this_iter_s: 8.39925503730774
  time_total_s: 7698.4513149261475
  timestamp: 1594863728
  timesteps_since_restore: 4420000
  timesteps_this_iter: 5000
  timesteps_total: 4420000
  training_iteration: 884
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7698 s, 884 iter, 4420000 ts, -9.4e+04 rew

agent-1: -19534.246382424953
agent-2: -25119.465083282837
agent-3: -25460.950386996414
agent-4: -17034.646922845186
agent-5: -27096.980918207082
Extrinsic Rewards:
-19404
-24966
-25298
-16921
-26919
Sum Reward: -113508
Avg Reward: -22701.6
Min Reward: -26919
Max Reward: -16921
Gini Coefficient: -0.09123586002748706
20:20 Ratio: 0.6285894721200639
Max-min Ratio: 0.6285894721200639
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-42-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -94113.74456071183
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 884
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.493
    dispatch_time_ms: 6.332
    learner:
      cur_lr: 0.0010656280210241675
      grad_gnorm: 40.0
      policy_entropy: 41.82796096801758
      policy_loss: -2215.46826171875
      var_gnorm: 65.09381103515625
      vf_explained_var: 0.0
      vf_loss: 379610.5
    num_steps_sampled: 4425000
    num_steps_trained: 4425000
    wait_time_ms: 78.198
  iterations_since_restore: 885
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7706.832311630249
  time_this_iter_s: 8.380996704101562
  time_total_s: 7706.832311630249
  timestamp: 1594863737
  timesteps_since_restore: 4425000
  timesteps_this_iter: 5000
  timesteps_total: 4425000
  training_iteration: 885
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7706 s, 885 iter, 4425000 ts, -9.41e+04 rew

agent-1: -32535.98129961705
agent-2: -17710.767638393987
agent-3: -35512.32756199426
agent-4: -29098.71394809593
agent-5: -39999.479588166694
Extrinsic Rewards:
-32375
-17610
-35359
-28950
-39821
Sum Reward: -154115
Avg Reward: -30823.0
Min Reward: -39821
Max Reward: -17610
Gini Coefficient: -0.13193005223372156
20:20 Ratio: 0.4422289746616107
Max-min Ratio: 0.4422289746616107
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-42-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -95277.24712716736
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 885
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.524
    dispatch_time_ms: 7.687
    learner:
      cur_lr: 0.0010652949567884207
      grad_gnorm: 39.999996185302734
      policy_entropy: 30.04452896118164
      policy_loss: -4546.88232421875
      var_gnorm: 65.51155090332031
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1515780.75
    num_steps_sampled: 4430000
    num_steps_trained: 4430000
    wait_time_ms: 78.022
  iterations_since_restore: 886
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7715.700199127197
  time_this_iter_s: 8.867887496948242
  time_total_s: 7715.700199127197
  timestamp: 1594863746
  timesteps_since_restore: 4430000
  timesteps_this_iter: 5000
  timesteps_total: 4430000
  training_iteration: 886
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7715 s, 886 iter, 4430000 ts, -9.53e+04 rew

agent-1: -15248.437511186188
agent-2: -19998.96090931374
agent-3: -27731.71410981694
agent-4: -16766.06069626271
agent-5: -18443.14993990357
Extrinsic Rewards:
-15125
-19865
-27538
-16634
-18291
Sum Reward: -97453
Avg Reward: -19490.6
Min Reward: -27538
Max Reward: -15125
Gini Coefficient: -0.11516115460786225
20:20 Ratio: 0.5492410487326603
Max-min Ratio: 0.5492410487326603
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-42-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -95887.79557058025
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 886
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.844
    dispatch_time_ms: 8.785
    learner:
      cur_lr: 0.0010649620089679956
      grad_gnorm: 40.0
      policy_entropy: 26.510181427001953
      policy_loss: -5174.73779296875
      var_gnorm: 65.92208862304688
      vf_explained_var: 0.0
      vf_loss: 1259034.625
    num_steps_sampled: 4435000
    num_steps_trained: 4435000
    wait_time_ms: 71.696
  iterations_since_restore: 887
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7724.236788749695
  time_this_iter_s: 8.536589622497559
  time_total_s: 7724.236788749695
  timestamp: 1594863754
  timesteps_since_restore: 4435000
  timesteps_this_iter: 5000
  timesteps_total: 4435000
  training_iteration: 887
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7724 s, 887 iter, 4435000 ts, -9.59e+04 rew

agent-1: -20370.089524330207
agent-2: -37876.94107760338
agent-3: -18615.735891608307
agent-4: -30362.771842015005
agent-5: -29075.0060639307
Extrinsic Rewards:
-20247
-37684
-18514
-30203
-28917
Sum Reward: -135565
Avg Reward: -27113.0
Min Reward: -37684
Max Reward: -18514
Gini Coefficient: -0.14250285840740604
20:20 Ratio: 0.49129604076000427
Max-min Ratio: 0.49129604076000427
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-42-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -96496.72233928928
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 887
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.63
    dispatch_time_ms: 8.856
    learner:
      cur_lr: 0.0010646289447322488
      grad_gnorm: 39.999996185302734
      policy_entropy: 23.306598663330078
      policy_loss: -1205.52685546875
      var_gnorm: 66.33171844482422
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1931238.875
    num_steps_sampled: 4440000
    num_steps_trained: 4440000
    wait_time_ms: 75.563
  iterations_since_restore: 888
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7732.6952130794525
  time_this_iter_s: 8.45842432975769
  time_total_s: 7732.6952130794525
  timestamp: 1594863763
  timesteps_since_restore: 4440000
  timesteps_this_iter: 5000
  timesteps_total: 4440000
  training_iteration: 888
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7732 s, 888 iter, 4440000 ts, -9.65e+04 rew

agent-1: -26959.71695805658
agent-2: -29324.417061159853
agent-3: -19431.393671607344
agent-4: -21647.744929201977
agent-5: -27081.79474694993
Extrinsic Rewards:
-26806
-29154
-19311
-21517
-26920
Sum Reward: -123708
Avg Reward: -24741.6
Min Reward: -29154
Max Reward: -19311
Gini Coefficient: -0.08112329032883887
20:20 Ratio: 0.6623790903478082
Max-min Ratio: 0.6623790903478082
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-42-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -96998.39085806075
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 888
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.578
    dispatch_time_ms: 5.526
    learner:
      cur_lr: 0.0010642959969118237
      grad_gnorm: 40.0
      policy_entropy: 24.870046615600586
      policy_loss: -519.9764404296875
      var_gnorm: 66.75184631347656
      vf_explained_var: 0.0
      vf_loss: 393477.6875
    num_steps_sampled: 4445000
    num_steps_trained: 4445000
    wait_time_ms: 77.878
  iterations_since_restore: 889
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7741.242563724518
  time_this_iter_s: 8.547350645065308
  time_total_s: 7741.242563724518
  timestamp: 1594863771
  timesteps_since_restore: 4445000
  timesteps_this_iter: 5000
  timesteps_total: 4445000
  training_iteration: 889
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7741 s, 889 iter, 4445000 ts, -9.7e+04 rew

agent-1: -17660.27936327766
agent-2: -40240.37047116768
agent-3: -38785.33402516951
agent-4: -35648.591909393326
agent-5: -45085.27463657831
Extrinsic Rewards:
-17574
-40071
-38626
-35497
-44915
Sum Reward: -176683
Avg Reward: -35336.6
Min Reward: -44915
Max Reward: -17574
Gini Coefficient: -0.1341521255582031
20:20 Ratio: 0.3912724034286987
Max-min Ratio: 0.3912724034286987
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-43-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -98226.32774965519
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 889
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.797
    dispatch_time_ms: 9.671
    learner:
      cur_lr: 0.0010639630490913987
      grad_gnorm: 40.000003814697266
      policy_entropy: 26.133682250976562
      policy_loss: -2923.712890625
      var_gnorm: 67.17684173583984
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 963421.4375
    num_steps_sampled: 4450000
    num_steps_trained: 4450000
    wait_time_ms: 75.091
  iterations_since_restore: 890
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7749.779926300049
  time_this_iter_s: 8.537362575531006
  time_total_s: 7749.779926300049
  timestamp: 1594863780
  timesteps_since_restore: 4450000
  timesteps_this_iter: 5000
  timesteps_total: 4450000
  training_iteration: 890
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7749 s, 890 iter, 4450000 ts, -9.82e+04 rew

agent-1: -25238.047110564512
agent-2: -19098.10349119597
agent-3: -39123.5693097389
agent-4: -43209.10446364149
agent-5: -39057.16797042666
Extrinsic Rewards:
-25114
-19019
-38946
-43034
-38886
Sum Reward: -164999
Avg Reward: -32999.8
Min Reward: -43034
Max Reward: -19019
Gini Coefficient: -0.14996939375390153
20:20 Ratio: 0.44195287447134823
Max-min Ratio: 0.44195287447134823
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-43-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -99274.37727554388
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 890
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.122
    dispatch_time_ms: 6.545
    learner:
      cur_lr: 0.0010636299848556519
      grad_gnorm: 40.0
      policy_entropy: 24.87504768371582
      policy_loss: -6316.744140625
      var_gnorm: 67.57865142822266
      vf_explained_var: 0.0
      vf_loss: 1701813.125
    num_steps_sampled: 4455000
    num_steps_trained: 4455000
    wait_time_ms: 74.367
  iterations_since_restore: 891
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7758.248270750046
  time_this_iter_s: 8.468344449996948
  time_total_s: 7758.248270750046
  timestamp: 1594863788
  timesteps_since_restore: 4455000
  timesteps_this_iter: 5000
  timesteps_total: 4455000
  training_iteration: 891
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7758 s, 891 iter, 4455000 ts, -9.93e+04 rew

agent-1: -40948.802654115374
agent-2: -27157.53441050307
agent-3: -27795.199904488385
agent-4: -7483.726417160686
agent-5: -16833.700781275096
Extrinsic Rewards:
-40734
-26989
-27627
-7433
-16729
Sum Reward: -119512
Avg Reward: -23902.4
Min Reward: -40734
Max Reward: -7433
Gini Coefficient: -0.25938817859294466
20:20 Ratio: 0.18247655521186232
Max-min Ratio: 0.18247655521186232
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-43-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -99704.41741407066
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 891
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.359
    dispatch_time_ms: 8.52
    learner:
      cur_lr: 0.0010632970370352268
      grad_gnorm: 40.0
      policy_entropy: 27.79134750366211
      policy_loss: 35.48003005981445
      var_gnorm: 67.99217224121094
      vf_explained_var: 0.0
      vf_loss: 38046.9609375
    num_steps_sampled: 4460000
    num_steps_trained: 4460000
    wait_time_ms: 71.859
  iterations_since_restore: 892
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7766.665454626083
  time_this_iter_s: 8.417183876037598
  time_total_s: 7766.665454626083
  timestamp: 1594863797
  timesteps_since_restore: 4460000
  timesteps_this_iter: 5000
  timesteps_total: 4460000
  training_iteration: 892
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7766 s, 892 iter, 4460000 ts, -9.97e+04 rew

agent-1: -32327.3791471752
agent-2: -17334.467198161958
agent-3: -23223.243217152045
agent-4: -33754.06896452794
agent-5: -29275.37609110248
Extrinsic Rewards:
-32169
-17226
-23088
-33582
-29124
Sum Reward: -135189
Avg Reward: -27037.8
Min Reward: -33582
Max Reward: -17226
Gini Coefficient: -0.1236579899252158
20:20 Ratio: 0.5129533678756477
Max-min Ratio: 0.5129533678756477
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-43-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -100344.61798628385
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 892
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.661
    dispatch_time_ms: 6.992
    learner:
      cur_lr: 0.00106296397279948
      grad_gnorm: 40.0
      policy_entropy: 22.342336654663086
      policy_loss: -3176.494140625
      var_gnorm: 68.38676452636719
      vf_explained_var: 0.0
      vf_loss: 1130211.625
    num_steps_sampled: 4465000
    num_steps_trained: 4465000
    wait_time_ms: 75.58
  iterations_since_restore: 893
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7775.155013799667
  time_this_iter_s: 8.489559173583984
  time_total_s: 7775.155013799667
  timestamp: 1594863805
  timesteps_since_restore: 4465000
  timesteps_this_iter: 5000
  timesteps_total: 4465000
  training_iteration: 893
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7775 s, 893 iter, 4465000 ts, -1e+05 rew

agent-1: -9173.323911600484
agent-2: -29181.78919860635
agent-3: -33686.456133244465
agent-4: -33577.25255286642
agent-5: -32112.15720764215
Extrinsic Rewards:
-9122
-29020
-33509
-33398
-31953
Sum Reward: -137002
Avg Reward: -27400.4
Min Reward: -33509
Max Reward: -9122
Gini Coefficient: -0.1551860556780193
20:20 Ratio: 0.272225372288042
Max-min Ratio: 0.272225372288042
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-43-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -101084.64227942083
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 893
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.734
    dispatch_time_ms: 7.974
    learner:
      cur_lr: 0.001062631024979055
      grad_gnorm: 39.999996185302734
      policy_entropy: 20.477519989013672
      policy_loss: -2673.306396484375
      var_gnorm: 68.82040405273438
      vf_explained_var: 0.0
      vf_loss: 2797585.25
    num_steps_sampled: 4470000
    num_steps_trained: 4470000
    wait_time_ms: 77.531
  iterations_since_restore: 894
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7783.731670856476
  time_this_iter_s: 8.576657056808472
  time_total_s: 7783.731670856476
  timestamp: 1594863814
  timesteps_since_restore: 4470000
  timesteps_this_iter: 5000
  timesteps_total: 4470000
  training_iteration: 894
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7783 s, 894 iter, 4470000 ts, -1.01e+05 rew

agent-1: -19668.212577464623
agent-2: -37118.39729202419
agent-3: -13455.743739651765
agent-4: -31528.906164975404
agent-5: -38040.83219201891
Extrinsic Rewards:
-19556
-36925
-13376
-31367
-37859
Sum Reward: -139083
Avg Reward: -27816.6
Min Reward: -37859
Max Reward: -13376
Gini Coefficient: -0.1907781684317997
20:20 Ratio: 0.3533109696505454
Max-min Ratio: 0.3533109696505454
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-43-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -101945.81019813416
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 894
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.83
    dispatch_time_ms: 7.169
    learner:
      cur_lr: 0.001062297960743308
      grad_gnorm: 40.0
      policy_entropy: 32.36908721923828
      policy_loss: -1234.62548828125
      var_gnorm: 69.2403793334961
      vf_explained_var: 0.0
      vf_loss: 290117.21875
    num_steps_sampled: 4475000
    num_steps_trained: 4475000
    wait_time_ms: 74.832
  iterations_since_restore: 895
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7792.140276670456
  time_this_iter_s: 8.408605813980103
  time_total_s: 7792.140276670456
  timestamp: 1594863822
  timesteps_since_restore: 4475000
  timesteps_this_iter: 5000
  timesteps_total: 4475000
  training_iteration: 895
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7792 s, 895 iter, 4475000 ts, -1.02e+05 rew

agent-1: -18101.140323677875
agent-2: -19251.363499707448
agent-3: -30966.396700898626
agent-4: -19004.098988155412
agent-5: -30784.044095726516
Extrinsic Rewards:
-17978
-19119
-30777
-18889
-30608
Sum Reward: -117371
Avg Reward: -23474.2
Min Reward: -30777
Max Reward: -17978
Gini Coefficient: -0.1271762189978785
20:20 Ratio: 0.5841375052799168
Max-min Ratio: 0.5841375052799168
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-43-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -102485.24797957428
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 895
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.696
    dispatch_time_ms: 10.8
    learner:
      cur_lr: 0.001061965012922883
      grad_gnorm: 40.0
      policy_entropy: 29.450645446777344
      policy_loss: -4064.29638671875
      var_gnorm: 69.6734848022461
      vf_explained_var: 0.0
      vf_loss: 872608.375
    num_steps_sampled: 4480000
    num_steps_trained: 4480000
    wait_time_ms: 71.13
  iterations_since_restore: 896
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7800.530236005783
  time_this_iter_s: 8.389959335327148
  time_total_s: 7800.530236005783
  timestamp: 1594863831
  timesteps_since_restore: 4480000
  timesteps_this_iter: 5000
  timesteps_total: 4480000
  training_iteration: 896
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7800 s, 896 iter, 4480000 ts, -1.02e+05 rew

agent-1: -31593.224801618293
agent-2: -30105.56208869584
agent-3: -20423.17444889207
agent-4: -38173.41660190646
agent-5: -25469.95680866867
Extrinsic Rewards:
-31431
-29946
-20311
-37991
-25339
Sum Reward: -145018
Avg Reward: -29003.6
Min Reward: -37991
Max Reward: -20311
Gini Coefficient: -0.11433615137431215
20:20 Ratio: 0.5346266220947067
Max-min Ratio: 0.5346266220947067
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-43-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -103235.72852857303
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 896
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.634
    dispatch_time_ms: 7.927
    learner:
      cur_lr: 0.0010616319486871362
      grad_gnorm: 40.0
      policy_entropy: 28.620166778564453
      policy_loss: -2521.301025390625
      var_gnorm: 70.08413696289062
      vf_explained_var: 0.0
      vf_loss: 932220.0
    num_steps_sampled: 4485000
    num_steps_trained: 4485000
    wait_time_ms: 73.24
  iterations_since_restore: 897
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7808.99117565155
  time_this_iter_s: 8.460939645767212
  time_total_s: 7808.99117565155
  timestamp: 1594863839
  timesteps_since_restore: 4485000
  timesteps_this_iter: 5000
  timesteps_total: 4485000
  training_iteration: 897
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7808 s, 897 iter, 4485000 ts, -1.03e+05 rew

agent-1: -19918.35112676788
agent-2: -29535.044838962076
agent-3: -13025.681235533819
agent-4: -21896.12604758587
agent-5: -22254.945256179013
Extrinsic Rewards:
-19789
-29339
-12936
-21744
-22099
Sum Reward: -105907
Avg Reward: -21181.4
Min Reward: -29339
Max Reward: -12936
Gini Coefficient: -0.13262957122758648
20:20 Ratio: 0.44091482327277687
Max-min Ratio: 0.44091482327277687
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-44-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -103345.23395742435
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 897
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 4.079
    dispatch_time_ms: 7.397
    learner:
      cur_lr: 0.0010612990008667111
      grad_gnorm: 40.0
      policy_entropy: 23.588802337646484
      policy_loss: -2255.81396484375
      var_gnorm: 70.49757385253906
      vf_explained_var: 0.0
      vf_loss: 1622580.25
    num_steps_sampled: 4490000
    num_steps_trained: 4490000
    wait_time_ms: 74.477
  iterations_since_restore: 898
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7817.443322181702
  time_this_iter_s: 8.452146530151367
  time_total_s: 7817.443322181702
  timestamp: 1594863848
  timesteps_since_restore: 4490000
  timesteps_this_iter: 5000
  timesteps_total: 4490000
  training_iteration: 898
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7817 s, 898 iter, 4490000 ts, -1.03e+05 rew

agent-1: -18572.958373975704
agent-2: -23849.681033585115
agent-3: -30879.477119899737
agent-4: -17266.233713647947
agent-5: -31612.63768647767
Extrinsic Rewards:
-18463
-23699
-30702
-17148
-31438
Sum Reward: -121450
Avg Reward: -24290.0
Min Reward: -31438
Max Reward: -17148
Gini Coefficient: -0.13443886372993002
20:20 Ratio: 0.5454545454545454
Max-min Ratio: 0.5454545454545454
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-44-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -103720.16860140998
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 898
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.119
    dispatch_time_ms: 7.904
    learner:
      cur_lr: 0.001060966053046286
      grad_gnorm: 40.0
      policy_entropy: 35.051597595214844
      policy_loss: -434.8529968261719
      var_gnorm: 70.92638397216797
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 78587.3984375
    num_steps_sampled: 4495000
    num_steps_trained: 4495000
    wait_time_ms: 72.921
  iterations_since_restore: 899
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7825.851336479187
  time_this_iter_s: 8.408014297485352
  time_total_s: 7825.851336479187
  timestamp: 1594863856
  timesteps_since_restore: 4495000
  timesteps_this_iter: 5000
  timesteps_total: 4495000
  training_iteration: 899
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7825 s, 899 iter, 4495000 ts, -1.04e+05 rew

agent-1: -2096.5093722668357
agent-2: -31088.972088530805
agent-3: -12775.229422464923
agent-4: -16667.277013717685
agent-5: -33188.817839082396
Extrinsic Rewards:
-2079
-30875
-12664
-16533
-32970
Sum Reward: -95121
Avg Reward: -19024.2
Min Reward: -32970
Max Reward: -2079
Gini Coefficient: -0.33638418435466405
20:20 Ratio: 0.06305732484076433
Max-min Ratio: 0.06305732484076433
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-44-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -103974.6483428378
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 899
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.947
    dispatch_time_ms: 6.918
    learner:
      cur_lr: 0.0010606329888105392
      grad_gnorm: 40.0
      policy_entropy: 44.58970642089844
      policy_loss: -3224.74560546875
      var_gnorm: 71.34387969970703
      vf_explained_var: 0.0
      vf_loss: 369094.9375
    num_steps_sampled: 4500000
    num_steps_trained: 4500000
    wait_time_ms: 77.97
  iterations_since_restore: 900
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7834.164613008499
  time_this_iter_s: 8.313276529312134
  time_total_s: 7834.164613008499
  timestamp: 1594863865
  timesteps_since_restore: 4500000
  timesteps_this_iter: 5000
  timesteps_total: 4500000
  training_iteration: 900
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7834 s, 900 iter, 4500000 ts, -1.04e+05 rew

agent-1: -27168.409602493914
agent-2: -25563.990445216896
agent-3: -30780.50241207314
agent-4: -30541.316290857
agent-5: -25369.01229416584
Extrinsic Rewards:
-27020
-25422
-30619
-30375
-25244
Sum Reward: -138680
Avg Reward: -27736.0
Min Reward: -30619
Max Reward: -25244
Gini Coefficient: -0.04529276031150851
20:20 Ratio: 0.824455403507626
Max-min Ratio: 0.824455403507626
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-44-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -104576.50424170689
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 900
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.456
    dispatch_time_ms: 7.352
    learner:
      cur_lr: 0.0010603000409901142
      grad_gnorm: 40.000003814697266
      policy_entropy: 43.221588134765625
      policy_loss: -4310.67919921875
      var_gnorm: 71.75648498535156
      vf_explained_var: 0.0
      vf_loss: 339386.75
    num_steps_sampled: 4505000
    num_steps_trained: 4505000
    wait_time_ms: 70.791
  iterations_since_restore: 901
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7842.328014612198
  time_this_iter_s: 8.16340160369873
  time_total_s: 7842.328014612198
  timestamp: 1594863873
  timesteps_since_restore: 4505000
  timesteps_this_iter: 5000
  timesteps_total: 4505000
  training_iteration: 901
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7842 s, 901 iter, 4505000 ts, -1.05e+05 rew

agent-1: -18072.68318676987
agent-2: -18670.536250286335
agent-3: -12502.91477536773
agent-4: -23888.02037137668
agent-5: -13018.127466400878
Extrinsic Rewards:
-17909
-18502
-12383
-23698
-12905
Sum Reward: -85397
Avg Reward: -17079.4
Min Reward: -23698
Max Reward: -12383
Gini Coefficient: -0.13221541740342166
20:20 Ratio: 0.5225335471347793
Max-min Ratio: 0.5225335471347793
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-44-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -104362.32192174457
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 901
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.864
    dispatch_time_ms: 6.659
    learner:
      cur_lr: 0.0010599669767543674
      grad_gnorm: 39.999996185302734
      policy_entropy: 43.558082580566406
      policy_loss: -1185.4996337890625
      var_gnorm: 72.18307495117188
      vf_explained_var: 0.0
      vf_loss: 73820.046875
    num_steps_sampled: 4510000
    num_steps_trained: 4510000
    wait_time_ms: 72.943
  iterations_since_restore: 902
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7850.522806882858
  time_this_iter_s: 8.1947922706604
  time_total_s: 7850.522806882858
  timestamp: 1594863881
  timesteps_since_restore: 4510000
  timesteps_this_iter: 5000
  timesteps_total: 4510000
  training_iteration: 902
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7850 s, 902 iter, 4510000 ts, -1.04e+05 rew

agent-1: -9498.22292290562
agent-2: -19968.107938954523
agent-3: -17528.77630750771
agent-4: -11921.251628880045
agent-5: -15248.490306679396
Extrinsic Rewards:
-9397
-19776
-17359
-11802
-15091
Sum Reward: -73425
Avg Reward: -14685.0
Min Reward: -19776
Max Reward: -9397
Gini Coefficient: -0.1433571671773919
20:20 Ratio: 0.475171925566343
Max-min Ratio: 0.475171925566343
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-44-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -104034.61952596079
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 902
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.664
    dispatch_time_ms: 8.462
    learner:
      cur_lr: 0.0010596340289339423
      grad_gnorm: 40.0
      policy_entropy: 40.43778991699219
      policy_loss: -5011.4111328125
      var_gnorm: 72.60794067382812
      vf_explained_var: 0.0
      vf_loss: 682712.375
    num_steps_sampled: 4515000
    num_steps_trained: 4515000
    wait_time_ms: 70.617
  iterations_since_restore: 903
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7858.779561519623
  time_this_iter_s: 8.256754636764526
  time_total_s: 7858.779561519623
  timestamp: 1594863889
  timesteps_since_restore: 4515000
  timesteps_this_iter: 5000
  timesteps_total: 4515000
  training_iteration: 903
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7858 s, 903 iter, 4515000 ts, -1.04e+05 rew

agent-1: -19207.83983894784
agent-2: -12161.42527121975
agent-3: -20586.027561711548
agent-4: -13018.959111819266
agent-5: -27458.49083435973
Extrinsic Rewards:
-19055
-12050
-20438
-12904
-27252
Sum Reward: -91699
Avg Reward: -18339.8
Min Reward: -27252
Max Reward: -12050
Gini Coefficient: -0.16548926378695514
20:20 Ratio: 0.44216938206370177
Max-min Ratio: 0.44216938206370177
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-44-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -103427.73140653204
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 903
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.922
    dispatch_time_ms: 9.518
    learner:
      cur_lr: 0.0010593009646981955
      grad_gnorm: 40.0
      policy_entropy: 40.87562561035156
      policy_loss: -2564.233154296875
      var_gnorm: 73.03382873535156
      vf_explained_var: 0.0
      vf_loss: 394743.8125
    num_steps_sampled: 4520000
    num_steps_trained: 4520000
    wait_time_ms: 70.488
  iterations_since_restore: 904
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7867.080402851105
  time_this_iter_s: 8.300841331481934
  time_total_s: 7867.080402851105
  timestamp: 1594863898
  timesteps_since_restore: 4520000
  timesteps_this_iter: 5000
  timesteps_total: 4520000
  training_iteration: 904
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7867 s, 904 iter, 4520000 ts, -1.03e+05 rew

agent-1: -10955.181458756046
agent-2: -21331.586386655996
agent-3: -23401.16742243372
agent-4: -20137.708818032403
agent-5: -19327.6971771192
Extrinsic Rewards:
-10860
-21159
-23228
-19976
-19182
Sum Reward: -94405
Avg Reward: -18881.0
Min Reward: -23228
Max Reward: -10860
Gini Coefficient: -0.11318468301467083
20:20 Ratio: 0.4675391768555192
Max-min Ratio: 0.4675391768555192
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-45-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -102939.32564562754
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 904
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.994
    dispatch_time_ms: 6.507
    learner:
      cur_lr: 0.0010589680168777704
      grad_gnorm: 40.0
      policy_entropy: 40.49606704711914
      policy_loss: -8307.58203125
      var_gnorm: 73.47136688232422
      vf_explained_var: 0.0
      vf_loss: 2810201.5
    num_steps_sampled: 4525000
    num_steps_trained: 4525000
    wait_time_ms: 74.336
  iterations_since_restore: 905
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7875.4843916893005
  time_this_iter_s: 8.4039888381958
  time_total_s: 7875.4843916893005
  timestamp: 1594863906
  timesteps_since_restore: 4525000
  timesteps_this_iter: 5000
  timesteps_total: 4525000
  training_iteration: 905
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7875 s, 905 iter, 4525000 ts, -1.03e+05 rew

agent-1: -21361.307370137387
agent-2: -18700.532500051482
agent-3: -28284.857977136926
agent-4: -30889.449410549165
agent-5: -39728.99562398304
Extrinsic Rewards:
-21238
-18587
-28134
-30732
-39527
Sum Reward: -138218
Avg Reward: -27643.6
Min Reward: -39527
Max Reward: -18587
Gini Coefficient: -0.1486752810777178
20:20 Ratio: 0.47023553520378475
Max-min Ratio: 0.47023553520378475
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-45-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -103251.09053076891
  episode_reward_min: -254065.5208969701
  episodes_this_iter: 1
  episodes_total: 905
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.864
    dispatch_time_ms: 7.877
    learner:
      cur_lr: 0.0010586349526420236
      grad_gnorm: 40.0
      policy_entropy: 45.75119400024414
      policy_loss: -7109.7802734375
      var_gnorm: 73.91413879394531
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 909472.75
    num_steps_sampled: 4530000
    num_steps_trained: 4530000
    wait_time_ms: 72.753
  iterations_since_restore: 906
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7883.7516322135925
  time_this_iter_s: 8.267240524291992
  time_total_s: 7883.7516322135925
  timestamp: 1594863914
  timesteps_since_restore: 4530000
  timesteps_this_iter: 5000
  timesteps_total: 4530000
  training_iteration: 906
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7883 s, 906 iter, 4530000 ts, -1.03e+05 rew

agent-1: -29385.85395246021
agent-2: -21658.10184027307
agent-3: -31497.247587048867
agent-4: -22805.184353500987
agent-5: -24067.30852784993
Extrinsic Rewards:
-29213
-21535
-31323
-22667
-23923
Sum Reward: -128661
Avg Reward: -25732.2
Min Reward: -31323
Max Reward: -21535
Gini Coefficient: -0.08121186684387655
20:20 Ratio: 0.6875139673722185
Max-min Ratio: 0.6875139673722185
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-45-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -102004.57228441053
  episode_reward_min: -213418.55313539036
  episodes_this_iter: 1
  episodes_total: 906
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.578
    dispatch_time_ms: 6.201
    learner:
      cur_lr: 0.0010583020048215985
      grad_gnorm: 40.0
      policy_entropy: 45.31050491333008
      policy_loss: -2830.475341796875
      var_gnorm: 74.343994140625
      vf_explained_var: 0.0
      vf_loss: 228602.546875
    num_steps_sampled: 4535000
    num_steps_trained: 4535000
    wait_time_ms: 71.952
  iterations_since_restore: 907
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7892.00950884819
  time_this_iter_s: 8.257876634597778
  time_total_s: 7892.00950884819
  timestamp: 1594863923
  timesteps_since_restore: 4535000
  timesteps_this_iter: 5000
  timesteps_total: 4535000
  training_iteration: 907
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7892 s, 907 iter, 4535000 ts, -1.02e+05 rew

agent-1: -12619.724301266806
agent-2: -16141.621007310076
agent-3: -21470.56138178236
agent-4: -16641.805695017087
agent-5: -17644.838735470137
Extrinsic Rewards:
-12500
-15999
-21282
-16489
-17497
Sum Reward: -83767
Avg Reward: -16753.4
Min Reward: -21282
Max Reward: -12500
Gini Coefficient: -0.0910239115642198
20:20 Ratio: 0.5873508128935251
Max-min Ratio: 0.5873508128935251
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-45-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -100715.5722642651
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 907
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.687
    dispatch_time_ms: 8.078
    learner:
      cur_lr: 0.0010579690570011735
      grad_gnorm: 40.0
      policy_entropy: 46.25834655761719
      policy_loss: 59.982261657714844
      var_gnorm: 74.78278350830078
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 18439.240234375
    num_steps_sampled: 4540000
    num_steps_trained: 4540000
    wait_time_ms: 72.085
  iterations_since_restore: 908
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7900.2782328128815
  time_this_iter_s: 8.268723964691162
  time_total_s: 7900.2782328128815
  timestamp: 1594863931
  timesteps_since_restore: 4540000
  timesteps_this_iter: 5000
  timesteps_total: 4540000
  training_iteration: 908
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7900 s, 908 iter, 4540000 ts, -1.01e+05 rew

agent-1: -12909.18027703071
agent-2: -17322.263092893543
agent-3: -18853.483356156292
agent-4: -21609.157065139018
agent-5: -17834.888908940215
Extrinsic Rewards:
-12789
-17172
-18705
-21426
-17687
Sum Reward: -87779
Avg Reward: -17555.8
Min Reward: -21426
Max Reward: -12789
Gini Coefficient: -0.08570159149682725
20:20 Ratio: 0.5968916269952395
Max-min Ratio: 0.5968916269952395
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-45-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -100405.91465575775
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 908
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.512
    dispatch_time_ms: 8.73
    learner:
      cur_lr: 0.0010576359927654266
      grad_gnorm: 40.000003814697266
      policy_entropy: 44.58194351196289
      policy_loss: -3442.044677734375
      var_gnorm: 75.1342544555664
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 489298.65625
    num_steps_sampled: 4545000
    num_steps_trained: 4545000
    wait_time_ms: 71.276
  iterations_since_restore: 909
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7908.505833387375
  time_this_iter_s: 8.227600574493408
  time_total_s: 7908.505833387375
  timestamp: 1594863939
  timesteps_since_restore: 4545000
  timesteps_this_iter: 5000
  timesteps_total: 4545000
  training_iteration: 909
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7908 s, 909 iter, 4545000 ts, -1e+05 rew

agent-1: -7869.687499018184
agent-2: -10482.847343345376
agent-3: -8987.032845848023
agent-4: -9222.794905445693
agent-5: -8612.556219946067
Extrinsic Rewards:
-7734
-10323
-8836
-9071
-8461
Sum Reward: -44425
Avg Reward: -8885.0
Min Reward: -10323
Max Reward: -7734
Gini Coefficient: -0.05211480022509848
20:20 Ratio: 0.7492008137169428
Max-min Ratio: 0.7492008137169428
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-45-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -99525.59136295374
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 909
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.418
    dispatch_time_ms: 5.127
    learner:
      cur_lr: 0.0010573030449450016
      grad_gnorm: 40.0
      policy_entropy: 41.193824768066406
      policy_loss: -397.6180725097656
      var_gnorm: 75.54615020751953
      vf_explained_var: 0.0
      vf_loss: 65769.5234375
    num_steps_sampled: 4550000
    num_steps_trained: 4550000
    wait_time_ms: 73.871
  iterations_since_restore: 910
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7916.578528404236
  time_this_iter_s: 8.072695016860962
  time_total_s: 7916.578528404236
  timestamp: 1594863947
  timesteps_since_restore: 4550000
  timesteps_this_iter: 5000
  timesteps_total: 4550000
  training_iteration: 910
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7916 s, 910 iter, 4550000 ts, -9.95e+04 rew

agent-1: -7274.308740396656
agent-2: -12368.365407225923
agent-3: -6533.950317123731
agent-4: -10277.196043856029
agent-5: -8234.064971602504
Extrinsic Rewards:
-7163
-12171
-6419
-10107
-8095
Sum Reward: -43955
Avg Reward: -8791.0
Min Reward: -12171
Max Reward: -6419
Gini Coefficient: -0.13147992264816288
20:20 Ratio: 0.5274011995727549
Max-min Ratio: 0.5274011995727549
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-45-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -98413.15489921697
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 910
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.531
    dispatch_time_ms: 6.142
    learner:
      cur_lr: 0.0010569699807092547
      grad_gnorm: 40.0
      policy_entropy: 38.94008255004883
      policy_loss: -982.15576171875
      var_gnorm: 75.95906829833984
      vf_explained_var: 0.0
      vf_loss: 115565.03125
    num_steps_sampled: 4555000
    num_steps_trained: 4555000
    wait_time_ms: 72.108
  iterations_since_restore: 911
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7924.6862535476685
  time_this_iter_s: 8.107725143432617
  time_total_s: 7924.6862535476685
  timestamp: 1594863955
  timesteps_since_restore: 4555000
  timesteps_this_iter: 5000
  timesteps_total: 4555000
  training_iteration: 911
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7924 s, 911 iter, 4555000 ts, -9.84e+04 rew

agent-1: -9599.515817888045
agent-2: -15217.128507714882
agent-3: -14988.826124739411
agent-4: -17909.07943027
agent-5: -7884.796645471358
Extrinsic Rewards:
-9476
-15058
-14827
-17724
-7779
Sum Reward: -64864
Avg Reward: -12972.8
Min Reward: -17724
Max Reward: -7779
Gini Coefficient: -0.15707942772570302
20:20 Ratio: 0.4388964116452268
Max-min Ratio: 0.4388964116452268
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-46-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -97949.12313467251
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 911
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.546
    dispatch_time_ms: 7.984
    learner:
      cur_lr: 0.0010566370328888297
      grad_gnorm: 40.000003814697266
      policy_entropy: 42.20902633666992
      policy_loss: -812.0823364257812
      var_gnorm: 76.41341400146484
      vf_explained_var: 0.0
      vf_loss: 120655.421875
    num_steps_sampled: 4560000
    num_steps_trained: 4560000
    wait_time_ms: 70.781
  iterations_since_restore: 912
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7932.856878519058
  time_this_iter_s: 8.17062497138977
  time_total_s: 7932.856878519058
  timestamp: 1594863964
  timesteps_since_restore: 4560000
  timesteps_this_iter: 5000
  timesteps_total: 4560000
  training_iteration: 912
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7932 s, 912 iter, 4560000 ts, -9.79e+04 rew

agent-1: -13416.749950864327
agent-2: -18549.53583814757
agent-3: -15782.470814653238
agent-4: -25272.74831979056
agent-5: -14606.551262580482
Extrinsic Rewards:
-13278
-18384
-15667
-25071
-14472
Sum Reward: -86872
Avg Reward: -17374.4
Min Reward: -25071
Max Reward: -13278
Gini Coefficient: -0.12661386868035732
20:20 Ratio: 0.5296158908699294
Max-min Ratio: 0.5296158908699294
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-46-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -97044.99695044715
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 912
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.651
    dispatch_time_ms: 10.605
    learner:
      cur_lr: 0.0010563039686530828
      grad_gnorm: 40.0
      policy_entropy: 41.10563659667969
      policy_loss: -2871.056396484375
      var_gnorm: 76.8545913696289
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 464644.34375
    num_steps_sampled: 4565000
    num_steps_trained: 4565000
    wait_time_ms: 70.234
  iterations_since_restore: 913
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7941.062023639679
  time_this_iter_s: 8.205145120620728
  time_total_s: 7941.062023639679
  timestamp: 1594863972
  timesteps_since_restore: 4565000
  timesteps_this_iter: 5000
  timesteps_total: 4565000
  training_iteration: 913
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7941 s, 913 iter, 4565000 ts, -9.7e+04 rew

agent-1: -26295.216280668334
agent-2: -20793.848183090475
agent-3: -16745.20098406522
agent-4: -21428.328875408934
agent-5: -15843.606723195806
Extrinsic Rewards:
-26097
-20648
-16633
-21283
-15713
Sum Reward: -100374
Avg Reward: -20074.8
Min Reward: -26097
Max Reward: -15713
Gini Coefficient: -0.10129316356825473
20:20 Ratio: 0.6020998582212514
Max-min Ratio: 0.6020998582212514
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-46-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -96697.05766217332
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 913
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.974
    dispatch_time_ms: 68.242
    learner:
      cur_lr: 0.0010559710208326578
      grad_gnorm: 40.0
      policy_entropy: 29.960216522216797
      policy_loss: -3625.424560546875
      var_gnorm: 77.306884765625
      vf_explained_var: 0.0
      vf_loss: 1166263.125
    num_steps_sampled: 4570000
    num_steps_trained: 4570000
    wait_time_ms: 55.966
  iterations_since_restore: 914
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7953.303477048874
  time_this_iter_s: 12.241453409194946
  time_total_s: 7953.303477048874
  timestamp: 1594863984
  timesteps_since_restore: 4570000
  timesteps_this_iter: 5000
  timesteps_total: 4570000
  training_iteration: 914
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7953 s, 914 iter, 4570000 ts, -9.67e+04 rew

agent-1: -20164.196301008364
agent-2: -25984.43072357574
agent-3: -22736.17438328719
agent-4: -16261.718621746715
agent-5: -12606.454834179494
Extrinsic Rewards:
-20008
-25800
-22570
-16127
-12504
Sum Reward: -97009
Avg Reward: -19401.8
Min Reward: -25800
Max Reward: -12504
Gini Coefficient: -0.13621416569596637
20:20 Ratio: 0.4846511627906977
Max-min Ratio: 0.4846511627906977
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-46-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -96212.6806985482
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 914
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.934
    dispatch_time_ms: 20.751
    learner:
      cur_lr: 0.001055637956596911
      grad_gnorm: 40.000003814697266
      policy_entropy: 24.494043350219727
      policy_loss: -3574.947021484375
      var_gnorm: 77.75885772705078
      vf_explained_var: 0.0
      vf_loss: 1080650.25
    num_steps_sampled: 4575000
    num_steps_trained: 4575000
    wait_time_ms: 67.996
  iterations_since_restore: 915
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7962.135837554932
  time_this_iter_s: 8.83236050605774
  time_total_s: 7962.135837554932
  timestamp: 1594863993
  timesteps_since_restore: 4575000
  timesteps_this_iter: 5000
  timesteps_total: 4575000
  training_iteration: 915
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7962 s, 915 iter, 4575000 ts, -9.62e+04 rew

agent-1: -31929.55115951723
agent-2: -34685.75059225927
agent-3: -27377.627934326658
agent-4: -10114.456359922831
agent-5: -34591.67288928655
Extrinsic Rewards:
-31758
-34513
-27230
-10058
-34411
Sum Reward: -137970
Avg Reward: -27594.0
Min Reward: -34513
Max Reward: -10058
Gini Coefficient: -0.1626179604261796
20:20 Ratio: 0.29142641903051025
Max-min Ratio: 0.29142641903051025
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-46-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -95839.7377440334
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 915
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.474
    dispatch_time_ms: 29.054
    learner:
      cur_lr: 0.001055305008776486
      grad_gnorm: 39.999996185302734
      policy_entropy: 14.796977996826172
      policy_loss: -2453.880126953125
      var_gnorm: 78.21940612792969
      vf_explained_var: 0.0
      vf_loss: 817419.8125
    num_steps_sampled: 4580000
    num_steps_trained: 4580000
    wait_time_ms: 57.801
  iterations_since_restore: 916
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7971.050193309784
  time_this_iter_s: 8.914355754852295
  time_total_s: 7971.050193309784
  timestamp: 1594864002
  timesteps_since_restore: 4580000
  timesteps_this_iter: 5000
  timesteps_total: 4580000
  training_iteration: 916
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7971 s, 916 iter, 4580000 ts, -9.58e+04 rew

agent-1: -17099.600132037056
agent-2: -23829.681352272022
agent-3: -42208.13384989786
agent-4: -38885.276754355116
agent-5: -28361.11534118622
Extrinsic Rewards:
-17010
-23703
-42016
-38704
-28225
Sum Reward: -149658
Avg Reward: -29931.6
Min Reward: -42016
Max Reward: -17010
Gini Coefficient: -0.17376418233572546
20:20 Ratio: 0.40484577303884234
Max-min Ratio: 0.40484577303884234
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-46-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -96010.74609453237
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 916
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.506
    dispatch_time_ms: 24.273
    learner:
      cur_lr: 0.001054971944540739
      grad_gnorm: 40.000003814697266
      policy_entropy: 22.805356979370117
      policy_loss: -149.30992126464844
      var_gnorm: 78.65361022949219
      vf_explained_var: 0.0
      vf_loss: 388425.8125
    num_steps_sampled: 4585000
    num_steps_trained: 4585000
    wait_time_ms: 64.822
  iterations_since_restore: 917
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7980.054363250732
  time_this_iter_s: 9.004169940948486
  time_total_s: 7980.054363250732
  timestamp: 1594864011
  timesteps_since_restore: 4585000
  timesteps_this_iter: 5000
  timesteps_total: 4585000
  training_iteration: 917
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7980 s, 917 iter, 4585000 ts, -9.6e+04 rew

agent-1: -39303.11212778665
agent-2: -8585.629565199451
agent-3: -7560.868257476217
agent-4: -43462.456866596054
agent-5: -28994.11770115515
Extrinsic Rewards:
-39095
-8537
-7517
-43252
-28839
Sum Reward: -127240
Avg Reward: -25448.0
Min Reward: -43252
Max Reward: -7517
Gini Coefficient: -0.32074190506130146
20:20 Ratio: 0.1737954314251364
Max-min Ratio: 0.1737954314251364
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-47-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -95729.3113991871
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 917
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.866
    dispatch_time_ms: 18.867
    learner:
      cur_lr: 0.001054638996720314
      grad_gnorm: 40.000003814697266
      policy_entropy: 22.337522506713867
      policy_loss: -1966.5950927734375
      var_gnorm: 79.1058349609375
      vf_explained_var: 0.0
      vf_loss: 1324049.0
    num_steps_sampled: 4590000
    num_steps_trained: 4590000
    wait_time_ms: 69.126
  iterations_since_restore: 918
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7988.998692750931
  time_this_iter_s: 8.944329500198364
  time_total_s: 7988.998692750931
  timestamp: 1594864020
  timesteps_since_restore: 4590000
  timesteps_this_iter: 5000
  timesteps_total: 4590000
  training_iteration: 918
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7988 s, 918 iter, 4590000 ts, -9.57e+04 rew

agent-1: -31628.719712813938
agent-2: -7707.095296265909
agent-3: -24203.26358199337
agent-4: -20684.56744147428
agent-5: -16030.294363294932
Extrinsic Rewards:
-31421
-7651
-24033
-20523
-15919
Sum Reward: -99547
Avg Reward: -19909.4
Min Reward: -31421
Max Reward: -7651
Gini Coefficient: -0.2236290395491577
20:20 Ratio: 0.2434995703510391
Max-min Ratio: 0.2434995703510391
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-47-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -95557.69223382982
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 918
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.097
    dispatch_time_ms: 21.487
    learner:
      cur_lr: 0.001054306048899889
      grad_gnorm: 39.999996185302734
      policy_entropy: 27.398014068603516
      policy_loss: -950.9186401367188
      var_gnorm: 79.5273208618164
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 386368.34375
    num_steps_sampled: 4595000
    num_steps_trained: 4595000
    wait_time_ms: 82.594
  iterations_since_restore: 919
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 7998.103164434433
  time_this_iter_s: 9.104471683502197
  time_total_s: 7998.103164434433
  timestamp: 1594864029
  timesteps_since_restore: 4595000
  timesteps_this_iter: 5000
  timesteps_total: 4595000
  training_iteration: 919
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 7998 s, 919 iter, 4595000 ts, -9.56e+04 rew

agent-1: -18496.05773699355
agent-2: -43117.21197187816
agent-3: -54712.015368324894
agent-4: -8649.5403260631
agent-5: -23719.808736322746
Extrinsic Rewards:
-18394
-42920
-54486
-8601
-23592
Sum Reward: -147993
Avg Reward: -29598.6
Min Reward: -54486
Max Reward: -8601
Gini Coefficient: -0.3143283803963701
20:20 Ratio: 0.15785706419997797
Max-min Ratio: 0.15785706419997797
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-47-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -95623.38035960881
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 919
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.227
    dispatch_time_ms: 43.604
    learner:
      cur_lr: 0.0010539729846641421
      grad_gnorm: 40.0
      policy_entropy: 28.42317771911621
      policy_loss: -5237.4326171875
      var_gnorm: 79.98870086669922
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 931145.125
    num_steps_sampled: 4600000
    num_steps_trained: 4600000
    wait_time_ms: 51.506
  iterations_since_restore: 920
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8006.9436049461365
  time_this_iter_s: 8.840440511703491
  time_total_s: 8006.9436049461365
  timestamp: 1594864038
  timesteps_since_restore: 4600000
  timesteps_this_iter: 5000
  timesteps_total: 4600000
  training_iteration: 920
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8006 s, 920 iter, 4600000 ts, -9.56e+04 rew

agent-1: -22752.89703625465
agent-2: -16269.19749634442
agent-3: -17920.687190358796
agent-4: -23924.347067925417
agent-5: -12506.051575961264
Extrinsic Rewards:
-22583
-16137
-17783
-23739
-12413
Sum Reward: -92655
Avg Reward: -18531.0
Min Reward: -23739
Max Reward: -12413
Gini Coefficient: -0.12561869300091738
20:20 Ratio: 0.5228948144403723
Max-min Ratio: 0.5228948144403723
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-47-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -95294.88227189086
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 920
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.67
    dispatch_time_ms: 26.762
    learner:
      cur_lr: 0.001053640036843717
      grad_gnorm: 40.0
      policy_entropy: 30.695959091186523
      policy_loss: -8916.626953125
      var_gnorm: 80.44896697998047
      vf_explained_var: 0.0
      vf_loss: 2299022.5
    num_steps_sampled: 4605000
    num_steps_trained: 4605000
    wait_time_ms: 60.327
  iterations_since_restore: 921
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8015.760656118393
  time_this_iter_s: 8.81705117225647
  time_total_s: 8015.760656118393
  timestamp: 1594864047
  timesteps_since_restore: 4605000
  timesteps_this_iter: 5000
  timesteps_total: 4605000
  training_iteration: 921
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8015 s, 921 iter, 4605000 ts, -9.53e+04 rew

agent-1: -35858.20778968147
agent-2: -32666.504076701545
agent-3: -34659.354905889624
agent-4: -5297.723853314405
agent-5: -29317.67266651328
Extrinsic Rewards:
-35680
-32494
-34478
-5263
-29163
Sum Reward: -137078
Avg Reward: -27415.6
Min Reward: -35680
Max Reward: -5263
Gini Coefficient: -0.19302586848363706
20:20 Ratio: 0.14750560538116592
Max-min Ratio: 0.14750560538116592
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-47-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -95208.81500060628
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 921
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.151
    dispatch_time_ms: 28.747
    learner:
      cur_lr: 0.0010533069726079702
      grad_gnorm: 40.0
      policy_entropy: 33.87882614135742
      policy_loss: -5297.1357421875
      var_gnorm: 80.91474151611328
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 1515398.5
    num_steps_sampled: 4610000
    num_steps_trained: 4610000
    wait_time_ms: 57.407
  iterations_since_restore: 922
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8024.719798326492
  time_this_iter_s: 8.959142208099365
  time_total_s: 8024.719798326492
  timestamp: 1594864056
  timesteps_since_restore: 4610000
  timesteps_this_iter: 5000
  timesteps_total: 4610000
  training_iteration: 922
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8024 s, 922 iter, 4610000 ts, -9.52e+04 rew

agent-1: -41880.31425196254
agent-2: -17800.35432878739
agent-3: -39319.42066383297
agent-4: -40338.12533814521
agent-5: -28499.984827224853
Extrinsic Rewards:
-41697
-17706
-39152
-40168
-28374
Sum Reward: -167097
Avg Reward: -33419.4
Min Reward: -41697
Max Reward: -17706
Gini Coefficient: -0.14309293404429763
20:20 Ratio: 0.4246348658176847
Max-min Ratio: 0.4246348658176847
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-47-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -95196.5551069675
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 922
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.821
    dispatch_time_ms: 29.697
    learner:
      cur_lr: 0.0010529740247875452
      grad_gnorm: 40.0
      policy_entropy: 31.33315658569336
      policy_loss: -5584.88720703125
      var_gnorm: 81.36900329589844
      vf_explained_var: 0.0
      vf_loss: 607311.0
    num_steps_sampled: 4615000
    num_steps_trained: 4615000
    wait_time_ms: 57.663
  iterations_since_restore: 923
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8033.602658510208
  time_this_iter_s: 8.88286018371582
  time_total_s: 8033.602658510208
  timestamp: 1594864065
  timesteps_since_restore: 4615000
  timesteps_this_iter: 5000
  timesteps_total: 4615000
  training_iteration: 923
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8033 s, 923 iter, 4615000 ts, -9.52e+04 rew

agent-1: -18461.151423137766
agent-2: -26740.33759688095
agent-3: -9701.126739849651
agent-4: -7299.713526307964
agent-5: -31744.405358176307
Extrinsic Rewards:
-18329
-26550
-9623
-7237
-31534
Sum Reward: -93273
Avg Reward: -18654.6
Min Reward: -31534
Max Reward: -7237
Gini Coefficient: -0.28098592304311
20:20 Ratio: 0.22949831927443395
Max-min Ratio: 0.22949831927443395
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-47-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -94826.00956849463
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 923
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.63
    dispatch_time_ms: 21.892
    learner:
      cur_lr: 0.0010526409605517983
      grad_gnorm: 40.0
      policy_entropy: 22.76340675354004
      policy_loss: -6755.47412109375
      var_gnorm: 81.82014465332031
      vf_explained_var: 0.0
      vf_loss: 2749541.25
    num_steps_sampled: 4620000
    num_steps_trained: 4620000
    wait_time_ms: 56.722
  iterations_since_restore: 924
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8042.732305765152
  time_this_iter_s: 9.129647254943848
  time_total_s: 8042.732305765152
  timestamp: 1594864074
  timesteps_since_restore: 4620000
  timesteps_this_iter: 5000
  timesteps_total: 4620000
  training_iteration: 924
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8042 s, 924 iter, 4620000 ts, -9.48e+04 rew

agent-1: -12575.134273457134
agent-2: -23436.879274131803
agent-3: -37710.66684180993
agent-4: -32485.588894854984
agent-5: -16411.404093934354
Extrinsic Rewards:
-12500
-23296
-37502
-32295
-16306
Sum Reward: -121899
Avg Reward: -24379.8
Min Reward: -37502
Max Reward: -12500
Gini Coefficient: -0.21654976661006242
20:20 Ratio: 0.33331555650365313
Max-min Ratio: 0.33331555650365313
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-48-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -94482.20578617601
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 924
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.941
    dispatch_time_ms: 9.369
    learner:
      cur_lr: 0.0010523080127313733
      grad_gnorm: 40.000003814697266
      policy_entropy: 21.192501068115234
      policy_loss: -650.0767822265625
      var_gnorm: 82.28093719482422
      vf_explained_var: 0.0
      vf_loss: 246664.140625
    num_steps_sampled: 4625000
    num_steps_trained: 4625000
    wait_time_ms: 71.923
  iterations_since_restore: 925
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8051.14471244812
  time_this_iter_s: 8.41240668296814
  time_total_s: 8051.14471244812
  timestamp: 1594864082
  timesteps_since_restore: 4625000
  timesteps_this_iter: 5000
  timesteps_total: 4625000
  training_iteration: 925
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8051 s, 925 iter, 4625000 ts, -9.45e+04 rew

agent-1: -53552.6506582064
agent-2: -44067.83543542101
agent-3: -3358.2615003819856
agent-4: -15562.181631096639
agent-5: -49376.635753138966
Extrinsic Rewards:
-53347
-43877
-3343
-15486
-49168
Sum Reward: -165221
Avg Reward: -33044.2
Min Reward: -53347
Max Reward: -3343
Gini Coefficient: -0.32366345682449565
20:20 Ratio: 0.06266519204453859
Max-min Ratio: 0.06266519204453859
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-48-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -94835.29037871883
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 925
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.519
    dispatch_time_ms: 7.846
    learner:
      cur_lr: 0.0010519749484956264
      grad_gnorm: 39.999996185302734
      policy_entropy: 23.430192947387695
      policy_loss: -542.650634765625
      var_gnorm: 82.68714141845703
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 169875.046875
    num_steps_sampled: 4630000
    num_steps_trained: 4630000
    wait_time_ms: 77.177
  iterations_since_restore: 926
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8059.583645105362
  time_this_iter_s: 8.438932657241821
  time_total_s: 8059.583645105362
  timestamp: 1594864091
  timesteps_since_restore: 4630000
  timesteps_this_iter: 5000
  timesteps_total: 4630000
  training_iteration: 926
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8059 s, 926 iter, 4630000 ts, -9.48e+04 rew

agent-1: -17434.67390800561
agent-2: -19559.778226141992
agent-3: -21724.822606232145
agent-4: -30479.413727191786
agent-5: -12839.910763769194
Extrinsic Rewards:
-17320
-19409
-21569
-30283
-12732
Sum Reward: -101313
Avg Reward: -20262.6
Min Reward: -30283
Max Reward: -12732
Gini Coefficient: -0.1553640697639987
20:20 Ratio: 0.420433906812403
Max-min Ratio: 0.420433906812403
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-48-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -94717.94931413382
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 926
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.395
    dispatch_time_ms: 36.118
    learner:
      cur_lr: 0.0010516420006752014
      grad_gnorm: 40.000003814697266
      policy_entropy: 30.22679901123047
      policy_loss: -4300.78466796875
      var_gnorm: 83.1379165649414
      vf_explained_var: 0.0
      vf_loss: 1000195.75
    num_steps_sampled: 4635000
    num_steps_trained: 4635000
    wait_time_ms: 36.741
  iterations_since_restore: 927
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8068.461596488953
  time_this_iter_s: 8.877951383590698
  time_total_s: 8068.461596488953
  timestamp: 1594864100
  timesteps_since_restore: 4635000
  timesteps_this_iter: 5000
  timesteps_total: 4635000
  training_iteration: 927
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8068 s, 927 iter, 4635000 ts, -9.47e+04 rew

agent-1: -18283.36665723551
agent-2: -22272.357612029657
agent-3: -16416.32382578053
agent-4: -35988.080080406035
agent-5: -22048.67152897982
Extrinsic Rewards:
-18168
-22132
-16301
-35772
-21913
Sum Reward: -114286
Avg Reward: -22857.2
Min Reward: -35772
Max Reward: -16301
Gini Coefficient: -0.15017062457343858
20:20 Ratio: 0.45569160237056916
Max-min Ratio: 0.45569160237056916
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-48-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -95446.58901262427
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 927
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.143
    dispatch_time_ms: 40.082
    learner:
      cur_lr: 0.0010513090528547764
      grad_gnorm: 40.0
      policy_entropy: 23.278940200805664
      policy_loss: 207.25656127929688
      var_gnorm: 83.60746002197266
      vf_explained_var: 0.0
      vf_loss: 4937.93505859375
    num_steps_sampled: 4640000
    num_steps_trained: 4640000
    wait_time_ms: 55.494
  iterations_since_restore: 928
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8077.504359722137
  time_this_iter_s: 9.042763233184814
  time_total_s: 8077.504359722137
  timestamp: 1594864109
  timesteps_since_restore: 4640000
  timesteps_this_iter: 5000
  timesteps_total: 4640000
  training_iteration: 928
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8077 s, 928 iter, 4640000 ts, -9.54e+04 rew

agent-1: -26106.024011761234
agent-2: -26038.6587200138
agent-3: -30756.654720427287
agent-4: -10686.47500023973
agent-5: -26061.993214151145
Extrinsic Rewards:
-25953
-25876
-30575
-10612
-25902
Sum Reward: -118918
Avg Reward: -23783.6
Min Reward: -30575
Max Reward: -10612
Gini Coefficient: -0.13455658520997663
20:20 Ratio: 0.34708094848732624
Max-min Ratio: 0.34708094848732624
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-48-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -96198.55359707332
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 928
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.68
    dispatch_time_ms: 23.606
    learner:
      cur_lr: 0.0010509759886190295
      grad_gnorm: 39.999996185302734
      policy_entropy: 25.721027374267578
      policy_loss: -2861.869384765625
      var_gnorm: 84.0595474243164
      vf_explained_var: 0.0
      vf_loss: 556222.4375
    num_steps_sampled: 4645000
    num_steps_trained: 4645000
    wait_time_ms: 51.327
  iterations_since_restore: 929
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8086.292565345764
  time_this_iter_s: 8.788205623626709
  time_total_s: 8086.292565345764
  timestamp: 1594864118
  timesteps_since_restore: 4645000
  timesteps_this_iter: 5000
  timesteps_total: 4645000
  training_iteration: 929
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8086 s, 929 iter, 4645000 ts, -9.62e+04 rew

agent-1: -19001.655626054944
agent-2: -40858.64007634775
agent-3: -4000.756851320356
agent-4: -38136.34288930232
agent-5: -30198.124823489805
Extrinsic Rewards:
-18890
-40660
-3972
-37939
-30025
Sum Reward: -131486
Avg Reward: -26297.2
Min Reward: -40660
Max Reward: -3972
Gini Coefficient: -0.2811706189252088
20:20 Ratio: 0.09768814559763896
Max-min Ratio: 0.09768814559763896
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-48-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -96564.10364631546
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 929
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.073
    dispatch_time_ms: 22.915
    learner:
      cur_lr: 0.0010506430407986045
      grad_gnorm: 40.0
      policy_entropy: 18.78667449951172
      policy_loss: -4131.755859375
      var_gnorm: 84.51399230957031
      vf_explained_var: 0.0
      vf_loss: 695673.3125
    num_steps_sampled: 4650000
    num_steps_trained: 4650000
    wait_time_ms: 68.08
  iterations_since_restore: 930
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8095.278424024582
  time_this_iter_s: 8.985858678817749
  time_total_s: 8095.278424024582
  timestamp: 1594864127
  timesteps_since_restore: 4650000
  timesteps_this_iter: 5000
  timesteps_total: 4650000
  training_iteration: 930
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8095 s, 930 iter, 4650000 ts, -9.66e+04 rew

agent-1: -16334.795774144548
agent-2: -21003.276790527136
agent-3: -19829.095093973523
agent-4: -31944.168032317768
agent-5: -14511.459689556004
Extrinsic Rewards:
-16213
-20843
-19702
-31735
-14394
Sum Reward: -102887
Avg Reward: -20577.4
Min Reward: -31735
Max Reward: -14394
Gini Coefficient: -0.15283563521144555
20:20 Ratio: 0.4535686150937451
Max-min Ratio: 0.4535686150937451
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-48-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -96401.6433534482
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 930
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.802
    dispatch_time_ms: 29.866
    learner:
      cur_lr: 0.0010503099765628576
      grad_gnorm: 40.0
      policy_entropy: 16.896329879760742
      policy_loss: -629.774169921875
      var_gnorm: 84.8950424194336
      vf_explained_var: 0.0
      vf_loss: 1422874.5
    num_steps_sampled: 4655000
    num_steps_trained: 4655000
    wait_time_ms: 61.842
  iterations_since_restore: 931
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8104.3450038433075
  time_this_iter_s: 9.066579818725586
  time_total_s: 8104.3450038433075
  timestamp: 1594864136
  timesteps_since_restore: 4655000
  timesteps_this_iter: 5000
  timesteps_total: 4655000
  training_iteration: 931
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8104 s, 931 iter, 4655000 ts, -9.64e+04 rew

agent-1: -13430.861862584576
agent-2: -15591.55706794538
agent-3: -3134.5116343835293
agent-4: -49443.99120779323
agent-5: -48469.24544923738
Extrinsic Rewards:
-13342
-15503
-3108
-49211
-48248
Sum Reward: -129412
Avg Reward: -25882.4
Min Reward: -49211
Max Reward: -3108
Gini Coefficient: -0.39289092201650544
20:20 Ratio: 0.06315661132673589
Max-min Ratio: 0.06315661132673589
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-49-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -96364.15236595638
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 931
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.872
    dispatch_time_ms: 51.768
    learner:
      cur_lr: 0.0010499770287424326
      grad_gnorm: 39.999996185302734
      policy_entropy: 10.810577392578125
      policy_loss: -159.1439971923828
      var_gnorm: 85.32936096191406
      vf_explained_var: 0.0
      vf_loss: 825212.3125
    num_steps_sampled: 4660000
    num_steps_trained: 4660000
    wait_time_ms: 43.848
  iterations_since_restore: 932
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8113.391185760498
  time_this_iter_s: 9.046181917190552
  time_total_s: 8113.391185760498
  timestamp: 1594864145
  timesteps_since_restore: 4660000
  timesteps_this_iter: 5000
  timesteps_total: 4660000
  training_iteration: 932
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8113 s, 932 iter, 4660000 ts, -9.64e+04 rew

agent-1: -25377.201664330027
agent-2: -43334.78496796901
agent-3: -28027.2519157964
agent-4: -10790.446471262529
agent-5: -11265.192483984743
Extrinsic Rewards:
-25253
-43101
-27851
-10724
-11179
Sum Reward: -118108
Avg Reward: -23621.6
Min Reward: -43101
Max Reward: -10724
Gini Coefficient: -0.2757679412063535
20:20 Ratio: 0.24881093246096378
Max-min Ratio: 0.24881093246096378
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-49-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -96171.00067548588
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 932
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.797
    dispatch_time_ms: 36.013
    learner:
      cur_lr: 0.0010496439645066857
      grad_gnorm: 40.00000762939453
      policy_entropy: 10.150594711303711
      policy_loss: 63.35019302368164
      var_gnorm: 85.7710952758789
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 187250.453125
    num_steps_sampled: 4665000
    num_steps_trained: 4665000
    wait_time_ms: 48.532
  iterations_since_restore: 933
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8122.280132293701
  time_this_iter_s: 8.888946533203125
  time_total_s: 8122.280132293701
  timestamp: 1594864154
  timesteps_since_restore: 4665000
  timesteps_this_iter: 5000
  timesteps_total: 4665000
  training_iteration: 933
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8122 s, 933 iter, 4665000 ts, -9.62e+04 rew

agent-1: -22032.23493390691
agent-2: -32825.60950776194
agent-3: -31710.164725365372
agent-4: -23088.724582897026
agent-5: -1903.8957173194829
Extrinsic Rewards:
-21893
-32634
-31525
-22938
-1888
Sum Reward: -110878
Avg Reward: -22175.6
Min Reward: -32634
Max Reward: -1888
Gini Coefficient: -0.2565847147315067
20:20 Ratio: 0.05785377213948643
Max-min Ratio: 0.05785377213948643
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-49-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -95959.39434294467
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 933
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.006
    dispatch_time_ms: 7.874
    learner:
      cur_lr: 0.0010493110166862607
      grad_gnorm: 40.0
      policy_entropy: 22.96756362915039
      policy_loss: 261.1229248046875
      var_gnorm: 86.16777038574219
      vf_explained_var: 0.0
      vf_loss: 5216.88037109375
    num_steps_sampled: 4670000
    num_steps_trained: 4670000
    wait_time_ms: 73.843
  iterations_since_restore: 934
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8131.001386165619
  time_this_iter_s: 8.721253871917725
  time_total_s: 8131.001386165619
  timestamp: 1594864163
  timesteps_since_restore: 4670000
  timesteps_this_iter: 5000
  timesteps_total: 4670000
  training_iteration: 934
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8131 s, 934 iter, 4670000 ts, -9.6e+04 rew

agent-1: -7704.7139454446515
agent-2: -27964.62130968764
agent-3: -9629.298645249433
agent-4: -952.0357973207225
agent-5: -30452.743926195944
Extrinsic Rewards:
-7632
-27739
-9531
-941
-30232
Sum Reward: -76075
Avg Reward: -15215.0
Min Reward: -30232
Max Reward: -941
Gini Coefficient: -0.4137443312520539
20:20 Ratio: 0.031125959248478434
Max-min Ratio: 0.031125959248478434
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-49-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -95297.9793498177
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 934
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.907
    dispatch_time_ms: 6.486
    learner:
      cur_lr: 0.0010489779524505138
      grad_gnorm: 40.0
      policy_entropy: 26.861751556396484
      policy_loss: -1175.1099853515625
      var_gnorm: 86.54016876220703
      vf_explained_var: 0.0
      vf_loss: 482087.78125
    num_steps_sampled: 4675000
    num_steps_trained: 4675000
    wait_time_ms: 77.432
  iterations_since_restore: 935
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8139.49574136734
  time_this_iter_s: 8.494355201721191
  time_total_s: 8139.49574136734
  timestamp: 1594864171
  timesteps_since_restore: 4675000
  timesteps_this_iter: 5000
  timesteps_total: 4675000
  training_iteration: 935
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8139 s, 935 iter, 4675000 ts, -9.53e+04 rew

agent-1: -13892.439073613354
agent-2: -37674.07003721487
agent-3: -17971.53747725304
agent-4: -35000.224759447934
agent-5: -5229.686453497195
Extrinsic Rewards:
-13795
-37450
-17847
-34787
-5189
Sum Reward: -109068
Avg Reward: -21813.6
Min Reward: -37450
Max Reward: -5189
Gini Coefficient: -0.31361719294385154
20:20 Ratio: 0.1385580774365821
Max-min Ratio: 0.1385580774365821
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-49-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -94924.56914404305
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 935
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.327
    dispatch_time_ms: 7.651
    learner:
      cur_lr: 0.0010486450046300888
      grad_gnorm: 40.0
      policy_entropy: 33.20379638671875
      policy_loss: -509.0866394042969
      var_gnorm: 86.97994995117188
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 103706.109375
    num_steps_sampled: 4680000
    num_steps_trained: 4680000
    wait_time_ms: 74.663
  iterations_since_restore: 936
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8147.914772510529
  time_this_iter_s: 8.419031143188477
  time_total_s: 8147.914772510529
  timestamp: 1594864180
  timesteps_since_restore: 4680000
  timesteps_this_iter: 5000
  timesteps_total: 4680000
  training_iteration: 936
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8147 s, 936 iter, 4680000 ts, -9.49e+04 rew

agent-1: -16628.62198011073
agent-2: -11605.812234800609
agent-3: -16048.821880106301
agent-4: -21152.61171430311
agent-5: -10855.768987599613
Extrinsic Rewards:
-16484
-11475
-15891
-20970
-10759
Sum Reward: -75579
Avg Reward: -15115.8
Min Reward: -20970
Max Reward: -10759
Gini Coefficient: -0.13459294248402334
20:20 Ratio: 0.5130662851692894
Max-min Ratio: 0.5130662851692894
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-49-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -94172.1966144019
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 936
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.808
    dispatch_time_ms: 6.638
    learner:
      cur_lr: 0.0010483120568096638
      grad_gnorm: 40.0
      policy_entropy: 22.8824405670166
      policy_loss: -2619.2744140625
      var_gnorm: 87.44855499267578
      vf_explained_var: 0.0
      vf_loss: 1655041.375
    num_steps_sampled: 4685000
    num_steps_trained: 4685000
    wait_time_ms: 76.944
  iterations_since_restore: 937
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8156.18390917778
  time_this_iter_s: 8.269136667251587
  time_total_s: 8156.18390917778
  timestamp: 1594864188
  timesteps_since_restore: 4685000
  timesteps_this_iter: 5000
  timesteps_total: 4685000
  training_iteration: 937
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8156 s, 937 iter, 4685000 ts, -9.42e+04 rew

agent-1: -48296.81472414175
agent-2: -13673.843090306009
agent-3: -40303.016157017126
agent-4: -21699.60701790123
agent-5: -40895.001582848534
Extrinsic Rewards:
-48098
-13611
-40126
-21598
-40710
Sum Reward: -164143
Avg Reward: -32828.6
Min Reward: -48098
Max Reward: -13611
Gini Coefficient: -0.2146567322395716
20:20 Ratio: 0.28298473949020747
Max-min Ratio: 0.28298473949020747
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-49-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -95089.5185281698
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 937
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.015
    dispatch_time_ms: 7.137
    learner:
      cur_lr: 0.001047978992573917
      grad_gnorm: 40.0
      policy_entropy: 19.72871971130371
      policy_loss: -1323.3748779296875
      var_gnorm: 87.92789459228516
      vf_explained_var: 0.0
      vf_loss: 669544.3125
    num_steps_sampled: 4690000
    num_steps_trained: 4690000
    wait_time_ms: 74.333
  iterations_since_restore: 938
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8164.608976602554
  time_this_iter_s: 8.42506742477417
  time_total_s: 8164.608976602554
  timestamp: 1594864196
  timesteps_since_restore: 4690000
  timesteps_this_iter: 5000
  timesteps_total: 4690000
  training_iteration: 938
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8164 s, 938 iter, 4690000 ts, -9.51e+04 rew

agent-1: -20878.04787277407
agent-2: -15079.09175167725
agent-3: -20563.999510089074
agent-4: -26742.80470213651
agent-5: -27747.59486671249
Extrinsic Rewards:
-20735
-14967
-20439
-26567
-27567
Sum Reward: -110275
Avg Reward: -22055.0
Min Reward: -27567
Max Reward: -14967
Gini Coefficient: -0.1136359102244389
20:20 Ratio: 0.5429317662422461
Max-min Ratio: 0.5429317662422461
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-50-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -95631.94612357471
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 938
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.963
    dispatch_time_ms: 8.335
    learner:
      cur_lr: 0.0010476460447534919
      grad_gnorm: 40.000003814697266
      policy_entropy: 15.5587739944458
      policy_loss: -2487.292724609375
      var_gnorm: 88.388671875
      vf_explained_var: 0.0
      vf_loss: 1332391.0
    num_steps_sampled: 4695000
    num_steps_trained: 4695000
    wait_time_ms: 72.854
  iterations_since_restore: 939
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8173.072557449341
  time_this_iter_s: 8.463580846786499
  time_total_s: 8173.072557449341
  timestamp: 1594864205
  timesteps_since_restore: 4695000
  timesteps_this_iter: 5000
  timesteps_total: 4695000
  training_iteration: 939
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8173 s, 939 iter, 4695000 ts, -9.56e+04 rew

agent-1: -33421.59696955182
agent-2: -22821.15013025015
agent-3: -15963.809387792984
agent-4: -25456.79036042691
agent-5: -11958.474827080336
Extrinsic Rewards:
-33220
-22672
-15843
-25307
-11863
Sum Reward: -108905
Avg Reward: -21781.0
Min Reward: -33220
Max Reward: -11863
Gini Coefficient: -0.19164592993893761
20:20 Ratio: 0.3571041541240217
Max-min Ratio: 0.3571041541240217
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-50-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -96581.78078662422
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 939
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.604
    dispatch_time_ms: 6.086
    learner:
      cur_lr: 0.001047312980517745
      grad_gnorm: 40.0
      policy_entropy: 15.66887378692627
      policy_loss: -4175.11376953125
      var_gnorm: 88.86640167236328
      vf_explained_var: 0.0
      vf_loss: 1998797.875
    num_steps_sampled: 4700000
    num_steps_trained: 4700000
    wait_time_ms: 78.822
  iterations_since_restore: 940
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8181.603013515472
  time_this_iter_s: 8.530456066131592
  time_total_s: 8181.603013515472
  timestamp: 1594864213
  timesteps_since_restore: 4700000
  timesteps_this_iter: 5000
  timesteps_total: 4700000
  training_iteration: 940
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8181 s, 940 iter, 4700000 ts, -9.66e+04 rew

agent-1: -49037.92972808517
agent-2: -44828.634182051464
agent-3: -18283.335354278566
agent-4: -1568.7936769117857
agent-5: -16223.152605087304
Extrinsic Rewards:
-48804
-44607
-18183
-1562
-16116
Sum Reward: -129272
Avg Reward: -25854.4
Min Reward: -48804
Max Reward: -1562
Gini Coefficient: -0.3805155021969181
20:20 Ratio: 0.03200557331366281
Max-min Ratio: 0.03200557331366281
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-50-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -97768.01973209565
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 940
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.462
    dispatch_time_ms: 6.536
    learner:
      cur_lr: 0.00104698003269732
      grad_gnorm: 40.0
      policy_entropy: 13.860334396362305
      policy_loss: -2689.14990234375
      var_gnorm: 89.34650421142578
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1230414.75
    num_steps_sampled: 4705000
    num_steps_trained: 4705000
    wait_time_ms: 75.213
  iterations_since_restore: 941
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8190.043617248535
  time_this_iter_s: 8.440603733062744
  time_total_s: 8190.043617248535
  timestamp: 1594864222
  timesteps_since_restore: 4705000
  timesteps_this_iter: 5000
  timesteps_total: 4705000
  training_iteration: 941
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8190 s, 941 iter, 4705000 ts, -9.78e+04 rew

agent-1: -32244.65218344084
agent-2: -19590.081723688625
agent-3: -30633.807108090536
agent-4: -29775.807347160975
agent-5: -32958.47258640511
Extrinsic Rewards:
-32077
-19481
-30480
-29628
-32791
Sum Reward: -144457
Avg Reward: -28891.4
Min Reward: -32791
Max Reward: -19481
Gini Coefficient: -0.08049177263822452
20:20 Ratio: 0.5940959409594095
Max-min Ratio: 0.5940959409594095
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-50-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -99085.16855064053
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 941
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.412
    dispatch_time_ms: 9.999
    learner:
      cur_lr: 0.0010466469684615731
      grad_gnorm: 40.0
      policy_entropy: 21.232023239135742
      policy_loss: -3887.784423828125
      var_gnorm: 89.81782531738281
      vf_explained_var: 0.0
      vf_loss: 929655.5
    num_steps_sampled: 4710000
    num_steps_trained: 4710000
    wait_time_ms: 26.98
  iterations_since_restore: 942
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8207.430724859238
  time_this_iter_s: 17.387107610702515
  time_total_s: 8207.430724859238
  timestamp: 1594864239
  timesteps_since_restore: 4710000
  timesteps_this_iter: 5000
  timesteps_total: 4710000
  training_iteration: 942
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8207 s, 942 iter, 4710000 ts, -9.91e+04 rew

agent-1: -41272.990711697006
agent-2: -33644.45693868265
agent-3: -19925.883302709273
agent-4: -9173.70631496245
agent-5: -40007.63715906006
Extrinsic Rewards:
-41077
-33475
-19816
-9122
-39818
Sum Reward: -143308
Avg Reward: -28661.6
Min Reward: -41077
Max Reward: -9122
Gini Coefficient: -0.2342144192927122
20:20 Ratio: 0.22207074518587044
Max-min Ratio: 0.22207074518587044
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-50-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -100409.60569965455
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 942
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.72
    dispatch_time_ms: 6.717
    learner:
      cur_lr: 0.001046314020641148
      grad_gnorm: 39.999996185302734
      policy_entropy: 21.850175857543945
      policy_loss: -1314.3948974609375
      var_gnorm: 90.27110290527344
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 775493.5625
    num_steps_sampled: 4715000
    num_steps_trained: 4715000
    wait_time_ms: 74.443
  iterations_since_restore: 943
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8215.600750207901
  time_this_iter_s: 8.17002534866333
  time_total_s: 8215.600750207901
  timestamp: 1594864247
  timesteps_since_restore: 4715000
  timesteps_this_iter: 5000
  timesteps_total: 4715000
  training_iteration: 943
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8215 s, 943 iter, 4715000 ts, -1e+05 rew

agent-1: -24834.28698424127
agent-2: -12659.82991716026
agent-3: -25297.06331044251
agent-4: -31848.49456776392
agent-5: -29938.11446326303
Extrinsic Rewards:
-24688
-12573
-25142
-31681
-29764
Sum Reward: -123848
Avg Reward: -24769.6
Min Reward: -31681
Max Reward: -12573
Gini Coefficient: -0.13982300884955753
20:20 Ratio: 0.3968624727754806
Max-min Ratio: 0.3968624727754806
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-50-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -101575.89537690232
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 943
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.995
    dispatch_time_ms: 53.528
    learner:
      cur_lr: 0.0010459809564054012
      grad_gnorm: 40.0
      policy_entropy: 24.19991683959961
      policy_loss: -1556.548828125
      var_gnorm: 90.70138549804688
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 367435.5
    num_steps_sampled: 4720000
    num_steps_trained: 4720000
    wait_time_ms: 52.084
  iterations_since_restore: 944
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8224.944550037384
  time_this_iter_s: 9.343799829483032
  time_total_s: 8224.944550037384
  timestamp: 1594864257
  timesteps_since_restore: 4720000
  timesteps_this_iter: 5000
  timesteps_total: 4720000
  training_iteration: 944
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8224 s, 944 iter, 4720000 ts, -1.02e+05 rew

agent-1: -10741.012960602318
agent-2: -25654.227530163284
agent-3: -10176.084202625489
agent-4: -21718.610358241316
agent-5: -27511.656383123216
Extrinsic Rewards:
-10653
-25472
-10083
-21573
-27315
Sum Reward: -95096
Avg Reward: -19019.2
Min Reward: -27315
Max Reward: -10083
Gini Coefficient: -0.20729788844956676
20:20 Ratio: 0.3691378363536518
Max-min Ratio: 0.3691378363536518
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-51-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -102458.2575390615
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 944
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.349
    dispatch_time_ms: 32.28
    learner:
      cur_lr: 0.0010456480085849762
      grad_gnorm: 39.999996185302734
      policy_entropy: 26.948989868164062
      policy_loss: -1701.8372802734375
      var_gnorm: 91.14264678955078
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 868378.1875
    num_steps_sampled: 4725000
    num_steps_trained: 4725000
    wait_time_ms: 62.857
  iterations_since_restore: 945
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8233.86103105545
  time_this_iter_s: 8.916481018066406
  time_total_s: 8233.86103105545
  timestamp: 1594864266
  timesteps_since_restore: 4725000
  timesteps_this_iter: 5000
  timesteps_total: 4725000
  training_iteration: 945
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8233 s, 945 iter, 4725000 ts, -1.02e+05 rew

agent-1: -19940.68927112534
agent-2: -16227.903236612508
agent-3: -15036.591644942577
agent-4: -3690.782047692874
agent-5: -24860.316208948014
Extrinsic Rewards:
-19776
-16075
-14895
-3653
-24658
Sum Reward: -79057
Avg Reward: -15811.4
Min Reward: -24658
Max Reward: -3653
Gini Coefficient: -0.2372516032735874
20:20 Ratio: 0.14814664611890666
Max-min Ratio: 0.14814664611890666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-51-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -103186.34872851627
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 945
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.592
    dispatch_time_ms: 7.243
    learner:
      cur_lr: 0.0010453149443492293
      grad_gnorm: 39.999996185302734
      policy_entropy: 40.91008377075195
      policy_loss: -3320.8720703125
      var_gnorm: 91.58997344970703
      vf_explained_var: 0.0
      vf_loss: 385883.1875
    num_steps_sampled: 4730000
    num_steps_trained: 4730000
    wait_time_ms: 73.241
  iterations_since_restore: 946
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8242.270335674286
  time_this_iter_s: 8.40930461883545
  time_total_s: 8242.270335674286
  timestamp: 1594864274
  timesteps_since_restore: 4730000
  timesteps_this_iter: 5000
  timesteps_total: 4730000
  training_iteration: 946
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8242 s, 946 iter, 4730000 ts, -1.03e+05 rew

agent-1: -2710.5957090045677
agent-2: -25363.058599554344
agent-3: -29975.322181262014
agent-4: -26701.758496366354
agent-5: -26979.951953132375
Extrinsic Rewards:
-2690
-25191
-29788
-26531
-26803
Sum Reward: -111003
Avg Reward: -22200.6
Min Reward: -29788
Max Reward: -2690
Gini Coefficient: -0.20110447465383818
20:20 Ratio: 0.09030482073318115
Max-min Ratio: 0.09030482073318115
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-51-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2531.5274156277546
  episode_reward_mean: -104238.07419699067
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 946
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.921
    dispatch_time_ms: 8.265
    learner:
      cur_lr: 0.0010449819965288043
      grad_gnorm: 39.999996185302734
      policy_entropy: 43.75796890258789
      policy_loss: -492.52783203125
      var_gnorm: 92.0356674194336
      vf_explained_var: 0.0
      vf_loss: 60601.70703125
    num_steps_sampled: 4735000
    num_steps_trained: 4735000
    wait_time_ms: 71.726
  iterations_since_restore: 947
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8250.683265924454
  time_this_iter_s: 8.412930250167847
  time_total_s: 8250.683265924454
  timestamp: 1594864283
  timesteps_since_restore: 4735000
  timesteps_this_iter: 5000
  timesteps_total: 4735000
  training_iteration: 947
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8250 s, 947 iter, 4735000 ts, -1.04e+05 rew

agent-1: -29583.69313124616
agent-2: -28898.097571919665
agent-3: -26166.22697288613
agent-4: -18035.617062547826
agent-5: -17894.49215076152
Extrinsic Rewards:
-29411
-28723
-26004
-17912
-17782
Sum Reward: -119832
Avg Reward: -23966.4
Min Reward: -29411
Max Reward: -17782
Gini Coefficient: -0.113722544896188
20:20 Ratio: 0.6046037196967121
Max-min Ratio: 0.6046037196967121
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-51-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -3222.438300378524
  episode_reward_mean: -105418.54019172798
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 947
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.776
    dispatch_time_ms: 7.335
    learner:
      cur_lr: 0.0010446490487083793
      grad_gnorm: 39.999996185302734
      policy_entropy: 52.596187591552734
      policy_loss: -2651.010009765625
      var_gnorm: 92.43201446533203
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 117124.3046875
    num_steps_sampled: 4740000
    num_steps_trained: 4740000
    wait_time_ms: 72.778
  iterations_since_restore: 948
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8259.030839920044
  time_this_iter_s: 8.34757399559021
  time_total_s: 8259.030839920044
  timestamp: 1594864291
  timesteps_since_restore: 4740000
  timesteps_this_iter: 5000
  timesteps_total: 4740000
  training_iteration: 948
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8259 s, 948 iter, 4740000 ts, -1.05e+05 rew

agent-1: -17367.335996942784
agent-2: -5417.49178532463
agent-3: -19230.407219998677
agent-4: -13467.785458948525
agent-5: -11127.452756378309
Extrinsic Rewards:
-17180
-5360
-19030
-13318
-10998
Sum Reward: -65886
Avg Reward: -13177.2
Min Reward: -19030
Max Reward: -5360
Gini Coefficient: -0.2035151625535015
20:20 Ratio: 0.2816605359957961
Max-min Ratio: 0.2816605359957961
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-51-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -3222.438300378524
  episode_reward_mean: -106046.91658831641
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 948
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.595
    dispatch_time_ms: 7.773
    learner:
      cur_lr: 0.0010443159844726324
      grad_gnorm: 40.0
      policy_entropy: 54.81548309326172
      policy_loss: -3153.27978515625
      var_gnorm: 92.66663360595703
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 112328.71875
    num_steps_sampled: 4745000
    num_steps_trained: 4745000
    wait_time_ms: 69.517
  iterations_since_restore: 949
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8267.365507602692
  time_this_iter_s: 8.334667682647705
  time_total_s: 8267.365507602692
  timestamp: 1594864299
  timesteps_since_restore: 4745000
  timesteps_this_iter: 5000
  timesteps_total: 4745000
  training_iteration: 949
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8267 s, 949 iter, 4745000 ts, -1.06e+05 rew

agent-1: -13130.242449009455
agent-2: -9112.288194942848
agent-3: -2985.5279898516683
agent-4: -8936.978292927879
agent-5: -11318.68372087851
Extrinsic Rewards:
-12930
-8957
-2931
-8784
-11153
Sum Reward: -44755
Avg Reward: -8951.0
Min Reward: -12930
Max Reward: -2931
Gini Coefficient: -0.1999061557367892
20:20 Ratio: 0.22668213457076566
Max-min Ratio: 0.22668213457076566
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-51-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4423.310535455772
  episode_reward_mean: -106469.52941178874
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 949
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.644
    dispatch_time_ms: 9.156
    learner:
      cur_lr: 0.0010439830366522074
      grad_gnorm: 40.0
      policy_entropy: 55.128089904785156
      policy_loss: -1201.011962890625
      var_gnorm: 93.00933074951172
      vf_explained_var: 0.0
      vf_loss: 55652.73828125
    num_steps_sampled: 4750000
    num_steps_trained: 4750000
    wait_time_ms: 68.171
  iterations_since_restore: 950
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8275.349796056747
  time_this_iter_s: 7.984288454055786
  time_total_s: 8275.349796056747
  timestamp: 1594864307
  timesteps_since_restore: 4750000
  timesteps_this_iter: 5000
  timesteps_total: 4750000
  training_iteration: 950
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8275 s, 950 iter, 4750000 ts, -1.06e+05 rew

agent-1: -8514.374871147324
agent-2: -4797.966969036475
agent-3: -7904.383025066881
agent-4: -4550.678967916958
agent-5: -7023.537020873365
Extrinsic Rewards:
-8336
-4674
-7727
-4445
-6870
Sum Reward: -32052
Avg Reward: -6410.4
Min Reward: -8336
Max Reward: -4445
Gini Coefficient: -0.13521777112192687
20:20 Ratio: 0.5332293666026872
Max-min Ratio: 0.5332293666026872
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-51-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -20608.271251062433
  episode_reward_mean: -106753.2057149746
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 950
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.787
    dispatch_time_ms: 7.091
    learner:
      cur_lr: 0.0010436499724164605
      grad_gnorm: 40.0
      policy_entropy: 51.315670013427734
      policy_loss: -55.657318115234375
      var_gnorm: 92.92799377441406
      vf_explained_var: 0.0
      vf_loss: 38487.4921875
    num_steps_sampled: 4755000
    num_steps_trained: 4755000
    wait_time_ms: 72.104
  iterations_since_restore: 951
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8283.498210906982
  time_this_iter_s: 8.148414850234985
  time_total_s: 8283.498210906982
  timestamp: 1594864316
  timesteps_since_restore: 4755000
  timesteps_this_iter: 5000
  timesteps_total: 4755000
  training_iteration: 951
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8283 s, 951 iter, 4755000 ts, -1.07e+05 rew

agent-1: -7700.611791964091
agent-2: -3343.7394936225414
agent-3: -1759.569224098349
agent-4: -4327.6344098256395
agent-5: -4762.324180732885
Extrinsic Rewards:
-7475
-3228
-1682
-4183
-4605
Sum Reward: -21173
Avg Reward: -4234.6
Min Reward: -7475
Max Reward: -1682
Gini Coefficient: -0.244896802531526
20:20 Ratio: 0.22501672240802675
Max-min Ratio: 0.22501672240802675
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-52-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -20608.271251062433
  episode_reward_mean: -106759.77723451957
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 951
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.784
    dispatch_time_ms: 12.181
    learner:
      cur_lr: 0.0010433170245960355
      grad_gnorm: 40.0
      policy_entropy: 47.730369567871094
      policy_loss: -141.34410095214844
      var_gnorm: 92.95932006835938
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 67065.7421875
    num_steps_sampled: 4760000
    num_steps_trained: 4760000
    wait_time_ms: 64.781
  iterations_since_restore: 952
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8291.595613241196
  time_this_iter_s: 8.097402334213257
  time_total_s: 8291.595613241196
  timestamp: 1594864324
  timesteps_since_restore: 4760000
  timesteps_this_iter: 5000
  timesteps_total: 4760000
  training_iteration: 952
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8291 s, 952 iter, 4760000 ts, -1.07e+05 rew

agent-1: -2275.7412260072037
agent-2: -4178.766908043513
agent-3: -3414.6458835991316
agent-4: -7675.437684118585
agent-5: -2363.0198048397706
Extrinsic Rewards:
-2176
-4016
-3310
-7453
-2254
Sum Reward: -19209
Avg Reward: -3841.8
Min Reward: -7453
Max Reward: -2176
Gini Coefficient: -0.25646311624759227
20:20 Ratio: 0.29196296793237625
Max-min Ratio: 0.29196296793237625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-52-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -19907.61150660824
  episode_reward_mean: -106752.77063707502
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 952
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.713
    dispatch_time_ms: 9.669
    learner:
      cur_lr: 0.0010429839603602886
      grad_gnorm: 40.0
      policy_entropy: 53.666900634765625
      policy_loss: -315.1123046875
      var_gnorm: 93.06920623779297
      vf_explained_var: 0.0
      vf_loss: 22179.75
    num_steps_sampled: 4765000
    num_steps_trained: 4765000
    wait_time_ms: 69.415
  iterations_since_restore: 953
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8299.781947851181
  time_this_iter_s: 8.186334609985352
  time_total_s: 8299.781947851181
  timestamp: 1594864332
  timesteps_since_restore: 4765000
  timesteps_this_iter: 5000
  timesteps_total: 4765000
  training_iteration: 953
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8299 s, 953 iter, 4765000 ts, -1.07e+05 rew

agent-1: -2529.7375440103424
agent-2: -5718.420269337816
agent-3: -5694.549227103083
agent-4: -4660.668995766008
agent-5: -3015.1041829237547
Extrinsic Rewards:
-2425
-5530
-5511
-4503
-2908
Sum Reward: -20877
Avg Reward: -4175.4
Min Reward: -5530
Max Reward: -2425
Gini Coefficient: -0.16885567849786848
20:20 Ratio: 0.4385171790235081
Max-min Ratio: 0.4385171790235081
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-52-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -19907.61150660824
  episode_reward_mean: -106585.01215829187
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 953
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.619
    dispatch_time_ms: 7.456
    learner:
      cur_lr: 0.0010426510125398636
      grad_gnorm: 40.0
      policy_entropy: 47.99048614501953
      policy_loss: 519.64599609375
      var_gnorm: 93.1998062133789
      vf_explained_var: 0.0
      vf_loss: 14263.9892578125
    num_steps_sampled: 4770000
    num_steps_trained: 4770000
    wait_time_ms: 72.136
  iterations_since_restore: 954
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8307.985842704773
  time_this_iter_s: 8.203894853591919
  time_total_s: 8307.985842704773
  timestamp: 1594864340
  timesteps_since_restore: 4770000
  timesteps_this_iter: 5000
  timesteps_total: 4770000
  training_iteration: 954
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8307 s, 954 iter, 4770000 ts, -1.07e+05 rew

agent-1: -7784.4779426816585
agent-2: -7807.099713976404
agent-3: -3286.9595754869256
agent-4: -7574.238056326679
agent-5: -6616.442140578063
Extrinsic Rewards:
-7607
-7629
-3215
-7410
-6468
Sum Reward: -32329
Avg Reward: -6465.8
Min Reward: -7629
Max Reward: -3215
Gini Coefficient: -0.12331962015527854
20:20 Ratio: 0.4214182723817014
Max-min Ratio: 0.4214182723817014
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-52-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -19907.61150660824
  episode_reward_mean: -106538.3672651276
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 954
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.839
    dispatch_time_ms: 6.849
    learner:
      cur_lr: 0.0010423179483041167
      grad_gnorm: 40.0
      policy_entropy: 52.40622329711914
      policy_loss: 838.9686889648438
      var_gnorm: 93.42095184326172
      vf_explained_var: 0.0
      vf_loss: 10662.349609375
    num_steps_sampled: 4775000
    num_steps_trained: 4775000
    wait_time_ms: 71.501
  iterations_since_restore: 955
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8316.090320825577
  time_this_iter_s: 8.104478120803833
  time_total_s: 8316.090320825577
  timestamp: 1594864348
  timesteps_since_restore: 4775000
  timesteps_this_iter: 5000
  timesteps_total: 4775000
  training_iteration: 955
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8316 s, 955 iter, 4775000 ts, -1.07e+05 rew

agent-1: -9229.092588687718
agent-2: -11298.804447929635
agent-3: -10791.734098959185
agent-4: -8020.520399804426
agent-5: -466.2103789456626
Extrinsic Rewards:
-9054
-11101
-10607
-7873
-455
Sum Reward: -39090
Avg Reward: -7818.0
Min Reward: -11101
Max Reward: -455
Gini Coefficient: -0.24585315937579943
20:20 Ratio: 0.04098729844158184
Max-min Ratio: 0.04098729844158184
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-52-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -19907.61150660824
  episode_reward_mean: -106663.16543497844
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 955
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.243
    dispatch_time_ms: 6.998
    learner:
      cur_lr: 0.0010419850004836917
      grad_gnorm: 40.0
      policy_entropy: 45.62873077392578
      policy_loss: -984.1121826171875
      var_gnorm: 93.56556701660156
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 107507.65625
    num_steps_sampled: 4780000
    num_steps_trained: 4780000
    wait_time_ms: 73.24
  iterations_since_restore: 956
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8324.22544836998
  time_this_iter_s: 8.135127544403076
  time_total_s: 8324.22544836998
  timestamp: 1594864357
  timesteps_since_restore: 4780000
  timesteps_this_iter: 5000
  timesteps_total: 4780000
  training_iteration: 956
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8324 s, 956 iter, 4780000 ts, -1.07e+05 rew

agent-1: -6051.6409248253585
agent-2: -4879.0071985780905
agent-3: -2918.1832635573664
agent-4: -7110.156668205419
agent-5: -2477.4963338076195
Extrinsic Rewards:
-5868
-4725
-2831
-6916
-2386
Sum Reward: -22726
Avg Reward: -4545.2
Min Reward: -6916
Max Reward: -2386
Gini Coefficient: -0.21291912347091438
20:20 Ratio: 0.3449971081550029
Max-min Ratio: 0.3449971081550029
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-52-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -19907.61150660824
  episode_reward_mean: -106647.34815704064
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 956
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.846
    dispatch_time_ms: 9.654
    learner:
      cur_lr: 0.0010416520526632667
      grad_gnorm: 39.999996185302734
      policy_entropy: 37.645362854003906
      policy_loss: -1368.8343505859375
      var_gnorm: 93.49962615966797
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 72534.8125
    num_steps_sampled: 4785000
    num_steps_trained: 4785000
    wait_time_ms: 70.266
  iterations_since_restore: 957
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8332.353410959244
  time_this_iter_s: 8.127962589263916
  time_total_s: 8332.353410959244
  timestamp: 1594864365
  timesteps_since_restore: 4785000
  timesteps_this_iter: 5000
  timesteps_total: 4785000
  training_iteration: 957
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8332 s, 957 iter, 4785000 ts, -1.07e+05 rew

agent-1: -4120.305817192166
agent-2: -4398.003623544366
agent-3: -3298.4715553018023
agent-4: -4284.46863082253
agent-5: -2709.1851706201824
Extrinsic Rewards:
-3959
-4243
-3163
-4128
-2597
Sum Reward: -18090
Avg Reward: -3618.0
Min Reward: -4243
Max Reward: -2597
Gini Coefficient: -0.09412935323383084
20:20 Ratio: 0.6120669337732736
Max-min Ratio: 0.6120669337732736
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-52-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -106569.5203456653
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 957
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.696
    dispatch_time_ms: 36.317
    learner:
      cur_lr: 0.0010413189884275198
      grad_gnorm: 40.0
      policy_entropy: 42.69697570800781
      policy_loss: -888.6981201171875
      var_gnorm: 93.61290740966797
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 180025.40625
    num_steps_sampled: 4790000
    num_steps_trained: 4790000
    wait_time_ms: 47.972
  iterations_since_restore: 958
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8340.565372943878
  time_this_iter_s: 8.2119619846344
  time_total_s: 8340.565372943878
  timestamp: 1594864373
  timesteps_since_restore: 4790000
  timesteps_this_iter: 5000
  timesteps_total: 4790000
  training_iteration: 958
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8340 s, 958 iter, 4790000 ts, -1.07e+05 rew

agent-1: -7972.610653584996
agent-2: -1669.2273071993097
agent-3: -8523.424463385189
agent-4: -5874.114336044763
agent-5: -7783.025362981782
Extrinsic Rewards:
-7786
-1630
-8350
-5740
-7602
Sum Reward: -31108
Avg Reward: -6221.6
Min Reward: -8350
Max Reward: -1630
Gini Coefficient: -0.19912562684839913
20:20 Ratio: 0.19520958083832335
Max-min Ratio: 0.19520958083832335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-53-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -106635.08931142515
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 958
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.008
    dispatch_time_ms: 32.494
    learner:
      cur_lr: 0.0010409860406070948
      grad_gnorm: 40.0
      policy_entropy: 38.004905700683594
      policy_loss: 347.2772521972656
      var_gnorm: 93.70155334472656
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 14460.7880859375
    num_steps_sampled: 4795000
    num_steps_trained: 4795000
    wait_time_ms: 54.408
  iterations_since_restore: 959
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8349.23519873619
  time_this_iter_s: 8.669825792312622
  time_total_s: 8349.23519873619
  timestamp: 1594864382
  timesteps_since_restore: 4795000
  timesteps_this_iter: 5000
  timesteps_total: 4795000
  training_iteration: 959
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8349 s, 959 iter, 4795000 ts, -1.07e+05 rew

agent-1: -7636.8381869940185
agent-2: -7210.760151921596
agent-3: -1495.079983931671
agent-4: -5402.230110086249
agent-5: -2777.7354374305132
Extrinsic Rewards:
-7432
-7023
-1450
-5246
-2683
Sum Reward: -23834
Avg Reward: -4766.8
Min Reward: -7432
Max Reward: -1450
Gini Coefficient: -0.2736259125618864
20:20 Ratio: 0.19510226049515608
Max-min Ratio: 0.19510226049515608
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-53-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -106565.31385395375
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 959
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 4.115
    dispatch_time_ms: 40.515
    learner:
      cur_lr: 0.001040652976371348
      grad_gnorm: 40.000003814697266
      policy_entropy: 38.86970138549805
      policy_loss: 441.8543395996094
      var_gnorm: 93.65663146972656
      vf_explained_var: 0.0
      vf_loss: 10953.009765625
    num_steps_sampled: 4800000
    num_steps_trained: 4800000
    wait_time_ms: 47.952
  iterations_since_restore: 960
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8358.09015083313
  time_this_iter_s: 8.854952096939087
  time_total_s: 8358.09015083313
  timestamp: 1594864391
  timesteps_since_restore: 4800000
  timesteps_this_iter: 5000
  timesteps_total: 4800000
  training_iteration: 960
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8358 s, 960 iter, 4800000 ts, -1.07e+05 rew

agent-1: -3052.985923656819
agent-2: -5295.8161925518825
agent-3: -6043.377916945833
agent-4: -5628.961261630281
agent-5: -2047.8166465649392
Extrinsic Rewards:
-2950
-5137
-5855
-5456
-1976
Sum Reward: -21374
Avg Reward: -4274.8
Min Reward: -5855
Max Reward: -1976
Gini Coefficient: -0.19208384017965752
20:20 Ratio: 0.3374893253629377
Max-min Ratio: 0.3374893253629377
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-53-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -106495.30674435057
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 960
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.338
    dispatch_time_ms: 24.596
    learner:
      cur_lr: 0.0010403200285509229
      grad_gnorm: 40.0
      policy_entropy: 33.54917907714844
      policy_loss: -621.6053466796875
      var_gnorm: 93.78243255615234
      vf_explained_var: 0.0
      vf_loss: 282520.4375
    num_steps_sampled: 4805000
    num_steps_trained: 4805000
    wait_time_ms: 58.794
  iterations_since_restore: 961
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8366.633051156998
  time_this_iter_s: 8.542900323867798
  time_total_s: 8366.633051156998
  timestamp: 1594864399
  timesteps_since_restore: 4805000
  timesteps_this_iter: 5000
  timesteps_total: 4805000
  training_iteration: 961
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8366 s, 961 iter, 4805000 ts, -1.06e+05 rew

agent-1: -6479.774261748765
agent-2: -6726.015179022323
agent-3: -6957.284316023524
agent-4: -5243.170122280061
agent-5: -10018.635873378504
Extrinsic Rewards:
-6327
-6595
-6831
-5146
-9820
Sum Reward: -34719
Avg Reward: -6943.8
Min Reward: -9820
Max Reward: -5146
Gini Coefficient: -0.11350557331720383
20:20 Ratio: 0.5240325865580449
Max-min Ratio: 0.5240325865580449
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-53-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -106144.13941401434
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 961
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.805
    dispatch_time_ms: 5.918
    learner:
      cur_lr: 0.001039986964315176
      grad_gnorm: 40.000003814697266
      policy_entropy: 44.050689697265625
      policy_loss: -3423.911376953125
      var_gnorm: 94.23278045654297
      vf_explained_var: 0.0
      vf_loss: 860942.0
    num_steps_sampled: 4810000
    num_steps_trained: 4810000
    wait_time_ms: 70.768
  iterations_since_restore: 962
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8375.215123414993
  time_this_iter_s: 8.582072257995605
  time_total_s: 8375.215123414993
  timestamp: 1594864408
  timesteps_since_restore: 4810000
  timesteps_this_iter: 5000
  timesteps_total: 4810000
  training_iteration: 962
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8375 s, 962 iter, 4810000 ts, -1.06e+05 rew

agent-1: -12001.446031743822
agent-2: -22530.025155626354
agent-3: -14778.17749521341
agent-4: -2432.376997335063
agent-5: -4502.635904529046
Extrinsic Rewards:
-11831
-22315
-14594
-2387
-4419
Sum Reward: -55546
Avg Reward: -11109.2
Min Reward: -22315
Max Reward: -2387
Gini Coefficient: -0.3602851690490764
20:20 Ratio: 0.10696840690118754
Max-min Ratio: 0.10696840690118754
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-53-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -105949.40012664236
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 962
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.275
    dispatch_time_ms: 9.487
    learner:
      cur_lr: 0.001039654016494751
      grad_gnorm: 39.999996185302734
      policy_entropy: 40.73874282836914
      policy_loss: -412.7130126953125
      var_gnorm: 94.58505249023438
      vf_explained_var: 0.0
      vf_loss: 42027.1484375
    num_steps_sampled: 4815000
    num_steps_trained: 4815000
    wait_time_ms: 70.545
  iterations_since_restore: 963
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8383.463839292526
  time_this_iter_s: 8.248715877532959
  time_total_s: 8383.463839292526
  timestamp: 1594864416
  timesteps_since_restore: 4815000
  timesteps_this_iter: 5000
  timesteps_total: 4815000
  training_iteration: 963
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8383 s, 963 iter, 4815000 ts, -1.06e+05 rew

agent-1: -4113.185990368636
agent-2: -9676.070878786037
agent-3: -3682.958729683915
agent-4: -9487.565777955999
agent-5: -10693.057180065
Extrinsic Rewards:
-4031
-9507
-3606
-9306
-10508
Sum Reward: -36958
Avg Reward: -7391.6
Min Reward: -10508
Max Reward: -3606
Gini Coefficient: -0.20866930028681205
20:20 Ratio: 0.3431671107727446
Max-min Ratio: 0.3431671107727446
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-53-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -105571.50842704579
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 963
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.977
    dispatch_time_ms: 7.963
    learner:
      cur_lr: 0.0010393209522590041
      grad_gnorm: 40.0
      policy_entropy: 40.93232727050781
      policy_loss: -5986.08740234375
      var_gnorm: 94.97457885742188
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 766780.125
    num_steps_sampled: 4820000
    num_steps_trained: 4820000
    wait_time_ms: 74.587
  iterations_since_restore: 964
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8391.730493068695
  time_this_iter_s: 8.266653776168823
  time_total_s: 8391.730493068695
  timestamp: 1594864424
  timesteps_since_restore: 4820000
  timesteps_this_iter: 5000
  timesteps_total: 4820000
  training_iteration: 964
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8391 s, 964 iter, 4820000 ts, -1.06e+05 rew

agent-1: -10224.850713657072
agent-2: -11329.303271321689
agent-3: -9471.889707335176
agent-4: -8608.460433857603
agent-5: -19824.20708635887
Extrinsic Rewards:
-10099
-11218
-9373
-8496
-19608
Sum Reward: -58794
Avg Reward: -11758.8
Min Reward: -19608
Max Reward: -8496
Gini Coefficient: -0.16375140320440862
20:20 Ratio: 0.43329253365973075
Max-min Ratio: 0.43329253365973075
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-53-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -105211.63268651966
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 964
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.606
    dispatch_time_ms: 8.236
    learner:
      cur_lr: 0.001038988004438579
      grad_gnorm: 39.999996185302734
      policy_entropy: 41.8117790222168
      policy_loss: -1613.4267578125
      var_gnorm: 95.41011047363281
      vf_explained_var: 0.0
      vf_loss: 155641.6875
    num_steps_sampled: 4825000
    num_steps_trained: 4825000
    wait_time_ms: 74.295
  iterations_since_restore: 965
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8400.079663991928
  time_this_iter_s: 8.349170923233032
  time_total_s: 8400.079663991928
  timestamp: 1594864433
  timesteps_since_restore: 4825000
  timesteps_this_iter: 5000
  timesteps_total: 4825000
  training_iteration: 965
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8400 s, 965 iter, 4825000 ts, -1.05e+05 rew

agent-1: -16819.480039190286
agent-2: -7764.355881492101
agent-3: -17446.076066852907
agent-4: -12506.41983446052
agent-5: -18904.73962348169
Extrinsic Rewards:
-16670
-7685
-17270
-12372
-18748
Sum Reward: -72745
Avg Reward: -14549.0
Min Reward: -18748
Max Reward: -7685
Gini Coefficient: -0.14859577977867894
20:20 Ratio: 0.4099103904416471
Max-min Ratio: 0.4099103904416471
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-54-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -104780.60473164752
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 965
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.87
    dispatch_time_ms: 8.036
    learner:
      cur_lr: 0.001038655056618154
      grad_gnorm: 40.000003814697266
      policy_entropy: 41.397769927978516
      policy_loss: -1131.3392333984375
      var_gnorm: 95.87168884277344
      vf_explained_var: 0.0
      vf_loss: 130443.5390625
    num_steps_sampled: 4830000
    num_steps_trained: 4830000
    wait_time_ms: 73.052
  iterations_since_restore: 966
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8408.362402915955
  time_this_iter_s: 8.28273892402649
  time_total_s: 8408.362402915955
  timestamp: 1594864441
  timesteps_since_restore: 4830000
  timesteps_this_iter: 5000
  timesteps_total: 4830000
  training_iteration: 966
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8408 s, 966 iter, 4830000 ts, -1.05e+05 rew

agent-1: -26253.241364893132
agent-2: -1556.115084134606
agent-3: -22884.612485710782
agent-4: -17932.15217491444
agent-5: -7872.537384141015
Extrinsic Rewards:
-26056
-1533
-22697
-17765
-7782
Sum Reward: -75833
Avg Reward: -15166.6
Min Reward: -26056
Max Reward: -1533
Gini Coefficient: -0.33737818627774185
20:20 Ratio: 0.05883481731654897
Max-min Ratio: 0.05883481731654897
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-54-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -104219.05293993805
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 966
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.944
    dispatch_time_ms: 9.473
    learner:
      cur_lr: 0.0010383219923824072
      grad_gnorm: 40.000003814697266
      policy_entropy: 39.884117126464844
      policy_loss: -1846.4091796875
      var_gnorm: 96.29043579101562
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 157134.796875
    num_steps_sampled: 4835000
    num_steps_trained: 4835000
    wait_time_ms: 73.801
  iterations_since_restore: 967
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8416.690123319626
  time_this_iter_s: 8.327720403671265
  time_total_s: 8416.690123319626
  timestamp: 1594864449
  timesteps_since_restore: 4835000
  timesteps_this_iter: 5000
  timesteps_total: 4835000
  training_iteration: 967
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8416 s, 967 iter, 4835000 ts, -1.04e+05 rew

agent-1: -9486.191235764916
agent-2: -9465.965251557256
agent-3: -7421.362570399752
agent-4: -17472.08162447826
agent-5: -7655.251117437105
Extrinsic Rewards:
-9366
-9340
-7328
-17256
-7554
Sum Reward: -50844
Avg Reward: -10168.8
Min Reward: -17256
Max Reward: -7328
Gini Coefficient: -0.17046652505703722
20:20 Ratio: 0.4246638850254984
Max-min Ratio: 0.4246638850254984
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-54-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -103562.33047174285
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 967
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.998
    dispatch_time_ms: 8.242
    learner:
      cur_lr: 0.0010379890445619822
      grad_gnorm: 40.000003814697266
      policy_entropy: 40.52717208862305
      policy_loss: -3225.00634765625
      var_gnorm: 96.44205474853516
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 399343.5
    num_steps_sampled: 4840000
    num_steps_trained: 4840000
    wait_time_ms: 72.305
  iterations_since_restore: 968
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8425.006706476212
  time_this_iter_s: 8.316583156585693
  time_total_s: 8425.006706476212
  timestamp: 1594864458
  timesteps_since_restore: 4840000
  timesteps_this_iter: 5000
  timesteps_total: 4840000
  training_iteration: 968
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8425 s, 968 iter, 4840000 ts, -1.04e+05 rew

agent-1: -561.3799027730627
agent-2: -13728.406584842192
agent-3: -8305.935055662572
agent-4: -8242.698970117426
agent-5: -9180.81394533474
Extrinsic Rewards:
-544
-13512
-8186
-8109
-9012
Sum Reward: -39363
Avg Reward: -7872.6
Min Reward: -13512
Max Reward: -544
Gini Coefficient: -0.2727332774432843
20:20 Ratio: 0.04026050917702783
Max-min Ratio: 0.04026050917702783
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-54-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -102774.4087903125
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 968
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.418
    dispatch_time_ms: 7.706
    learner:
      cur_lr: 0.0010376559803262353
      grad_gnorm: 40.0
      policy_entropy: 39.59416198730469
      policy_loss: -4288.23388671875
      var_gnorm: 96.92967987060547
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1110429.75
    num_steps_sampled: 4845000
    num_steps_trained: 4845000
    wait_time_ms: 72.648
  iterations_since_restore: 969
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8433.27807879448
  time_this_iter_s: 8.271372318267822
  time_total_s: 8433.27807879448
  timestamp: 1594864466
  timesteps_since_restore: 4845000
  timesteps_this_iter: 5000
  timesteps_total: 4845000
  training_iteration: 969
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8433 s, 969 iter, 4845000 ts, -1.03e+05 rew

agent-1: -31368.902434123112
agent-2: -18533.73722659859
agent-3: -591.4921747431606
agent-4: -17631.69432827657
agent-5: -29834.65365452538
Extrinsic Rewards:
-31176
-18397
-586
-17485
-29639
Sum Reward: -97283
Avg Reward: -19456.6
Min Reward: -31176
Max Reward: -586
Gini Coefficient: -0.30152853016457143
20:20 Ratio: 0.018796510136002052
Max-min Ratio: 0.018796510136002052
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-54-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -102327.806292963
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 969
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.835
    dispatch_time_ms: 9.003
    learner:
      cur_lr: 0.0010373230325058103
      grad_gnorm: 40.0
      policy_entropy: 38.97019577026367
      policy_loss: -3301.422607421875
      var_gnorm: 97.39093017578125
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 251394.1875
    num_steps_sampled: 4850000
    num_steps_trained: 4850000
    wait_time_ms: 71.455
  iterations_since_restore: 970
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8441.63979268074
  time_this_iter_s: 8.361713886260986
  time_total_s: 8441.63979268074
  timestamp: 1594864474
  timesteps_since_restore: 4850000
  timesteps_this_iter: 5000
  timesteps_total: 4850000
  training_iteration: 970
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8441 s, 970 iter, 4850000 ts, -1.02e+05 rew

agent-1: -20995.101839947056
agent-2: -23938.031607811772
agent-3: -10077.475383168008
agent-4: -6706.397974841725
agent-5: -12896.402374356023
Extrinsic Rewards:
-20812
-23723
-9975
-6639
-12775
Sum Reward: -73924
Avg Reward: -14784.8
Min Reward: -23723
Max Reward: -6639
Gini Coefficient: -0.2435203722742276
20:20 Ratio: 0.27985499304472455
Max-min Ratio: 0.27985499304472455
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-54-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -101844.635874011
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 970
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.815
    dispatch_time_ms: 9.487
    learner:
      cur_lr: 0.0010369899682700634
      grad_gnorm: 40.0
      policy_entropy: 39.00883483886719
      policy_loss: -3428.805419921875
      var_gnorm: 97.73311614990234
      vf_explained_var: 0.0
      vf_loss: 825884.875
    num_steps_sampled: 4855000
    num_steps_trained: 4855000
    wait_time_ms: 71.27
  iterations_since_restore: 971
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8450.335330724716
  time_this_iter_s: 8.69553804397583
  time_total_s: 8450.335330724716
  timestamp: 1594864483
  timesteps_since_restore: 4855000
  timesteps_this_iter: 5000
  timesteps_total: 4855000
  training_iteration: 971
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8450 s, 971 iter, 4855000 ts, -1.02e+05 rew

agent-1: -15336.53263572206
agent-2: -11622.06402875342
agent-3: -5636.898794592534
agent-4: -16287.021267050868
agent-5: -14293.43684849342
Extrinsic Rewards:
-15174
-11481
-5565
-16117
-14135
Sum Reward: -62472
Avg Reward: -12494.4
Min Reward: -16117
Max Reward: -5565
Gini Coefficient: -0.1587719298245614
20:20 Ratio: 0.3452875845380654
Max-min Ratio: 0.3452875845380654
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-54-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -101286.71184155131
  episode_reward_min: -180844.42704572537
  episodes_this_iter: 1
  episodes_total: 971
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.098
    dispatch_time_ms: 6.536
    learner:
      cur_lr: 0.0010366570204496384
      grad_gnorm: 40.0
      policy_entropy: 38.06857681274414
      policy_loss: -3559.79833984375
      var_gnorm: 98.09561157226562
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 524907.6875
    num_steps_sampled: 4860000
    num_steps_trained: 4860000
    wait_time_ms: 75.36
  iterations_since_restore: 972
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8458.601084470749
  time_this_iter_s: 8.265753746032715
  time_total_s: 8458.601084470749
  timestamp: 1594864492
  timesteps_since_restore: 4860000
  timesteps_this_iter: 5000
  timesteps_total: 4860000
  training_iteration: 972
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8458 s, 972 iter, 4860000 ts, -1.01e+05 rew

agent-1: -13279.638163403759
agent-2: -3835.9711884321864
agent-3: -13424.415022535663
agent-4: -5771.425542913168
agent-5: -4181.6584596591465
Extrinsic Rewards:
-13107
-3760
-13223
-5669
-4091
Sum Reward: -39850
Avg Reward: -7970.0
Min Reward: -13223
Max Reward: -3760
Gini Coefficient: -0.2804717691342534
20:20 Ratio: 0.28435302125085077
Max-min Ratio: 0.28435302125085077
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-55-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -99883.19865486347
  episode_reward_min: -178093.1749631076
  episodes_this_iter: 1
  episodes_total: 972
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.632
    dispatch_time_ms: 8.223
    learner:
      cur_lr: 0.0010363239562138915
      grad_gnorm: 39.999996185302734
      policy_entropy: 36.22996520996094
      policy_loss: -1370.8714599609375
      var_gnorm: 98.48966979980469
      vf_explained_var: 0.0
      vf_loss: 181041.03125
    num_steps_sampled: 4865000
    num_steps_trained: 4865000
    wait_time_ms: 72.028
  iterations_since_restore: 973
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8466.810464382172
  time_this_iter_s: 8.20937991142273
  time_total_s: 8466.810464382172
  timestamp: 1594864500
  timesteps_since_restore: 4865000
  timesteps_this_iter: 5000
  timesteps_total: 4865000
  training_iteration: 973
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8466 s, 973 iter, 4865000 ts, -9.99e+04 rew

agent-1: -13770.561687907586
agent-2: -10969.558651808667
agent-3: -13001.099578382324
agent-4: -13401.114566607692
agent-5: -6453.991748627321
Extrinsic Rewards:
-13604
-10843
-12829
-13228
-6376
Sum Reward: -56880
Avg Reward: -11376.0
Min Reward: -13604
Max Reward: -6376
Gini Coefficient: -0.11843178621659635
20:20 Ratio: 0.46868568068215233
Max-min Ratio: 0.46868568068215233
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-55-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -98913.49919454986
  episode_reward_min: -178093.1749631076
  episodes_this_iter: 1
  episodes_total: 973
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.118
    dispatch_time_ms: 7.362
    learner:
      cur_lr: 0.0010359910083934665
      grad_gnorm: 40.0
      policy_entropy: 29.746042251586914
      policy_loss: -142.53829956054688
      var_gnorm: 98.8235855102539
      vf_explained_var: 0.0
      vf_loss: 19741.53515625
    num_steps_sampled: 4870000
    num_steps_trained: 4870000
    wait_time_ms: 70.267
  iterations_since_restore: 974
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8474.998535633087
  time_this_iter_s: 8.188071250915527
  time_total_s: 8474.998535633087
  timestamp: 1594864508
  timesteps_since_restore: 4870000
  timesteps_this_iter: 5000
  timesteps_total: 4870000
  training_iteration: 974
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8474 s, 974 iter, 4870000 ts, -9.89e+04 rew

agent-1: -9522.467306501045
agent-2: -10669.239791025038
agent-3: -11730.905646333524
agent-4: -15525.696005762284
agent-5: -1496.6718082359366
Extrinsic Rewards:
-9386
-10534
-11571
-15334
-1473
Sum Reward: -48298
Avg Reward: -9659.6
Min Reward: -15334
Max Reward: -1473
Gini Coefficient: -0.2476872748353969
20:20 Ratio: 0.09606104082431198
Max-min Ratio: 0.09606104082431198
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-55-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -97668.18449324908
  episode_reward_min: -178093.1749631076
  episodes_this_iter: 1
  episodes_total: 974
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.564
    dispatch_time_ms: 8.068
    learner:
      cur_lr: 0.0010356579441577196
      grad_gnorm: 40.0
      policy_entropy: 37.486671447753906
      policy_loss: -739.2689819335938
      var_gnorm: 99.18017578125
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 118372.1640625
    num_steps_sampled: 4875000
    num_steps_trained: 4875000
    wait_time_ms: 75.034
  iterations_since_restore: 975
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8483.35851931572
  time_this_iter_s: 8.359983682632446
  time_total_s: 8483.35851931572
  timestamp: 1594864516
  timesteps_since_restore: 4875000
  timesteps_this_iter: 5000
  timesteps_total: 4875000
  training_iteration: 975
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8483 s, 975 iter, 4875000 ts, -9.77e+04 rew

agent-1: -4778.24887386523
agent-2: -7043.807417702281
agent-3: -13562.851049966743
agent-4: -14145.52710551328
agent-5: -19827.247111253575
Extrinsic Rewards:
-4725
-6945
-13429
-13984
-19603
Sum Reward: -58686
Avg Reward: -11737.2
Min Reward: -19603
Max Reward: -4725
Gini Coefficient: -0.2507923525201922
20:20 Ratio: 0.24103453553027598
Max-min Ratio: 0.24103453553027598
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-55-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -96933.48270510437
  episode_reward_min: -178093.1749631076
  episodes_this_iter: 1
  episodes_total: 975
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.45
    dispatch_time_ms: 7.452
    learner:
      cur_lr: 0.0010353249963372946
      grad_gnorm: 40.0
      policy_entropy: 35.83187484741211
      policy_loss: -4089.96923828125
      var_gnorm: 99.3701171875
      vf_explained_var: 0.0
      vf_loss: 467219.46875
    num_steps_sampled: 4880000
    num_steps_trained: 4880000
    wait_time_ms: 76.493
  iterations_since_restore: 976
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8491.616049051285
  time_this_iter_s: 8.257529735565186
  time_total_s: 8491.616049051285
  timestamp: 1594864525
  timesteps_since_restore: 4880000
  timesteps_this_iter: 5000
  timesteps_total: 4880000
  training_iteration: 976
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8491 s, 976 iter, 4880000 ts, -9.69e+04 rew

agent-1: -12187.301357552893
agent-2: -3658.8726585733343
agent-3: -6714.439227042795
agent-4: -14782.945607730322
agent-5: -6241.835599175112
Extrinsic Rewards:
-12015
-3599
-6602
-14579
-6126
Sum Reward: -42921
Avg Reward: -8584.2
Min Reward: -14579
Max Reward: -3599
Gini Coefficient: -0.2595372894387363
20:20 Ratio: 0.24686192468619247
Max-min Ratio: 0.24686192468619247
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-55-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -95588.40489997406
  episode_reward_min: -177419.85040558683
  episodes_this_iter: 1
  episodes_total: 976
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.047
    dispatch_time_ms: 8.168
    learner:
      cur_lr: 0.0010349920485168695
      grad_gnorm: 40.0
      policy_entropy: 37.87105178833008
      policy_loss: -4551.88818359375
      var_gnorm: 99.80083465576172
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 595931.5
    num_steps_sampled: 4885000
    num_steps_trained: 4885000
    wait_time_ms: 72.253
  iterations_since_restore: 977
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8499.842475175858
  time_this_iter_s: 8.226426124572754
  time_total_s: 8499.842475175858
  timestamp: 1594864533
  timesteps_since_restore: 4885000
  timesteps_this_iter: 5000
  timesteps_total: 4885000
  training_iteration: 977
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8499 s, 977 iter, 4885000 ts, -9.56e+04 rew

agent-1: -15514.431801858234
agent-2: -16684.742699779486
agent-3: -27584.598323696253
agent-4: -11170.175345370768
agent-5: -21778.112784022087
Extrinsic Rewards:
-15402
-16546
-27386
-11059
-21602
Sum Reward: -91995
Avg Reward: -18399.0
Min Reward: -27386
Max Reward: -11059
Gini Coefficient: -0.16893961628349366
20:20 Ratio: 0.40381946980208866
Max-min Ratio: 0.40381946980208866
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-55-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -95371.98664266456
  episode_reward_min: -177419.85040558683
  episodes_this_iter: 1
  episodes_total: 977
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.751
    dispatch_time_ms: 7.859
    learner:
      cur_lr: 0.0010346589842811227
      grad_gnorm: 40.0
      policy_entropy: 38.35084915161133
      policy_loss: -1551.0069580078125
      var_gnorm: 100.19620513916016
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 278583.59375
    num_steps_sampled: 4890000
    num_steps_trained: 4890000
    wait_time_ms: 73.277
  iterations_since_restore: 978
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8508.152312994003
  time_this_iter_s: 8.309837818145752
  time_total_s: 8508.152312994003
  timestamp: 1594864541
  timesteps_since_restore: 4890000
  timesteps_this_iter: 5000
  timesteps_total: 4890000
  training_iteration: 978
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8508 s, 978 iter, 4890000 ts, -9.54e+04 rew

agent-1: -17519.624559050422
agent-2: -13892.015964053076
agent-3: -17906.05644012757
agent-4: -497.8616263791533
agent-5: -2329.734591380549
Extrinsic Rewards:
-17359
-13717
-17681
-486
-2303
Sum Reward: -51546
Avg Reward: -10309.2
Min Reward: -17681
Max Reward: -486
Gini Coefficient: -0.3837038761494587
20:20 Ratio: 0.027487133080708104
Max-min Ratio: 0.027487133080708104
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-55-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -94627.11662442477
  episode_reward_min: -177419.85040558683
  episodes_this_iter: 1
  episodes_total: 978
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.695
    dispatch_time_ms: 8.13
    learner:
      cur_lr: 0.0010343260364606977
      grad_gnorm: 39.999996185302734
      policy_entropy: 37.84164047241211
      policy_loss: -2859.909912109375
      var_gnorm: 100.38533020019531
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 535149.4375
    num_steps_sampled: 4895000
    num_steps_trained: 4895000
    wait_time_ms: 73.425
  iterations_since_restore: 979
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8516.47379231453
  time_this_iter_s: 8.321479320526123
  time_total_s: 8516.47379231453
  timestamp: 1594864550
  timesteps_since_restore: 4895000
  timesteps_this_iter: 5000
  timesteps_total: 4895000
  training_iteration: 979
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8516 s, 979 iter, 4895000 ts, -9.46e+04 rew

agent-1: -9446.31675075142
agent-2: -4679.780440430932
agent-3: -8952.898814350878
agent-4: -3715.587187374686
agent-5: -11197.779230876298
Extrinsic Rewards:
-9317
-4571
-8822
-3661
-11028
Sum Reward: -37399
Avg Reward: -7479.8
Min Reward: -11028
Max Reward: -3661
Gini Coefficient: -0.2083478167865451
20:20 Ratio: 0.33197315923104825
Max-min Ratio: 0.33197315923104825
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-55-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -93818.2599097711
  episode_reward_min: -177419.85040558683
  episodes_this_iter: 1
  episodes_total: 979
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.41
    dispatch_time_ms: 7.088
    learner:
      cur_lr: 0.0010339929722249508
      grad_gnorm: 40.0
      policy_entropy: 38.77589416503906
      policy_loss: -674.1561279296875
      var_gnorm: 100.69283294677734
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 101292.4296875
    num_steps_sampled: 4900000
    num_steps_trained: 4900000
    wait_time_ms: 71.846
  iterations_since_restore: 980
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8524.714112997055
  time_this_iter_s: 8.240320682525635
  time_total_s: 8524.714112997055
  timestamp: 1594864558
  timesteps_since_restore: 4900000
  timesteps_this_iter: 5000
  timesteps_total: 4900000
  training_iteration: 980
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8524 s, 980 iter, 4900000 ts, -9.38e+04 rew

agent-1: -3835.4985200073015
agent-2: -24257.523297236672
agent-3: -7406.616560148435
agent-4: -21288.6259178943
agent-5: -8278.339446126223
Extrinsic Rewards:
-3795
-24069
-7326
-21100
-8185
Sum Reward: -64475
Avg Reward: -12895.0
Min Reward: -24069
Max Reward: -3795
Gini Coefficient: -0.33701124466847615
20:20 Ratio: 0.15767169388009472
Max-min Ratio: 0.15767169388009472
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-56-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -93229.38429189456
  episode_reward_min: -177419.85040558683
  episodes_this_iter: 1
  episodes_total: 980
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.821
    dispatch_time_ms: 8.023
    learner:
      cur_lr: 0.0010336600244045258
      grad_gnorm: 40.0
      policy_entropy: 39.207916259765625
      policy_loss: -2169.523681640625
      var_gnorm: 101.17993927001953
      vf_explained_var: 0.0
      vf_loss: 272622.75
    num_steps_sampled: 4905000
    num_steps_trained: 4905000
    wait_time_ms: 72.903
  iterations_since_restore: 981
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8533.039566993713
  time_this_iter_s: 8.325453996658325
  time_total_s: 8533.039566993713
  timestamp: 1594864566
  timesteps_since_restore: 4905000
  timesteps_this_iter: 5000
  timesteps_total: 4905000
  training_iteration: 981
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8533 s, 981 iter, 4905000 ts, -9.32e+04 rew

agent-1: -4661.563301573724
agent-2: -5671.688227819978
agent-3: -9742.267428243365
agent-4: -25805.93730191668
agent-5: -24080.428779119058
Extrinsic Rewards:
-4614
-5613
-9649
-25595
-23867
Sum Reward: -69338
Avg Reward: -13867.6
Min Reward: -25595
Max Reward: -4614
Gini Coefficient: -0.34737661888142146
20:20 Ratio: 0.18026958390310607
Max-min Ratio: 0.18026958390310607
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-56-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -92908.18283751294
  episode_reward_min: -177419.85040558683
  episodes_this_iter: 1
  episodes_total: 981
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.355
    dispatch_time_ms: 6.192
    learner:
      cur_lr: 0.001033326960168779
      grad_gnorm: 40.000003814697266
      policy_entropy: 38.7099494934082
      policy_loss: -966.0411376953125
      var_gnorm: 101.64586639404297
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 163865.125
    num_steps_sampled: 4910000
    num_steps_trained: 4910000
    wait_time_ms: 72.418
  iterations_since_restore: 982
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8541.355648040771
  time_this_iter_s: 8.316081047058105
  time_total_s: 8541.355648040771
  timestamp: 1594864575
  timesteps_since_restore: 4910000
  timesteps_this_iter: 5000
  timesteps_total: 4910000
  training_iteration: 982
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8541 s, 982 iter, 4910000 ts, -9.29e+04 rew

agent-1: -11740.572302011318
agent-2: -16343.5918208511
agent-3: -5757.668425031929
agent-4: -13662.042451798236
agent-5: -27857.71594477752
Extrinsic Rewards:
-11632
-16188
-5699
-13529
-27649
Sum Reward: -74697
Avg Reward: -14939.4
Min Reward: -27649
Max Reward: -5699
Gini Coefficient: -0.2594803004136712
20:20 Ratio: 0.2061195703280408
Max-min Ratio: 0.2061195703280408
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-56-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -92718.60848377075
  episode_reward_min: -177419.85040558683
  episodes_this_iter: 1
  episodes_total: 982
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.042
    dispatch_time_ms: 8.248
    learner:
      cur_lr: 0.0010329940123483539
      grad_gnorm: 40.000003814697266
      policy_entropy: 40.16120147705078
      policy_loss: -4218.4853515625
      var_gnorm: 102.03845977783203
      vf_explained_var: 0.0
      vf_loss: 996365.375
    num_steps_sampled: 4915000
    num_steps_trained: 4915000
    wait_time_ms: 72.494
  iterations_since_restore: 983
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8549.628071308136
  time_this_iter_s: 8.272423267364502
  time_total_s: 8549.628071308136
  timestamp: 1594864583
  timesteps_since_restore: 4915000
  timesteps_this_iter: 5000
  timesteps_total: 4915000
  training_iteration: 983
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8549 s, 983 iter, 4915000 ts, -9.27e+04 rew

agent-1: -9858.148451072562
agent-2: -11773.22204173811
agent-3: -25284.985231579754
agent-4: -15932.332283780635
agent-5: -10668.768571930257
Extrinsic Rewards:
-9772
-11674
-25066
-15796
-10537
Sum Reward: -72845
Avg Reward: -14569.0
Min Reward: -25066
Max Reward: -9772
Gini Coefficient: -0.19683986546777404
20:20 Ratio: 0.3898507939040932
Max-min Ratio: 0.3898507939040932
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-56-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -92289.01626526039
  episode_reward_min: -177419.85040558683
  episodes_this_iter: 1
  episodes_total: 983
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.723
    dispatch_time_ms: 6.412
    learner:
      cur_lr: 0.001032660948112607
      grad_gnorm: 40.0
      policy_entropy: 35.66573715209961
      policy_loss: -6412.6376953125
      var_gnorm: 102.53889465332031
      vf_explained_var: 0.0
      vf_loss: 1924079.375
    num_steps_sampled: 4920000
    num_steps_trained: 4920000
    wait_time_ms: 75.184
  iterations_since_restore: 984
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8558.029144763947
  time_this_iter_s: 8.401073455810547
  time_total_s: 8558.029144763947
  timestamp: 1594864591
  timesteps_since_restore: 4920000
  timesteps_this_iter: 5000
  timesteps_total: 4920000
  training_iteration: 984
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8558 s, 984 iter, 4920000 ts, -9.23e+04 rew

agent-1: -17083.289558441782
agent-2: -11667.223658980582
agent-3: -6170.765238111362
agent-4: -15478.11066951749
agent-5: -15434.124648685154
Extrinsic Rewards:
-16902
-11550
-6116
-15350
-15275
Sum Reward: -65193
Avg Reward: -13038.6
Min Reward: -16902
Max Reward: -6116
Gini Coefficient: -0.15567315509333823
20:20 Ratio: 0.36185066855993375
Max-min Ratio: 0.36185066855993375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-56-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -91804.88850606018
  episode_reward_min: -177419.85040558683
  episodes_this_iter: 1
  episodes_total: 984
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.814
    dispatch_time_ms: 7.107
    learner:
      cur_lr: 0.001032328000292182
      grad_gnorm: 39.99999237060547
      policy_entropy: 39.11686325073242
      policy_loss: -4049.257568359375
      var_gnorm: 102.94669342041016
      vf_explained_var: 0.0
      vf_loss: 735671.375
    num_steps_sampled: 4925000
    num_steps_trained: 4925000
    wait_time_ms: 78.207
  iterations_since_restore: 985
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8566.478080511093
  time_this_iter_s: 8.448935747146606
  time_total_s: 8566.478080511093
  timestamp: 1594864600
  timesteps_since_restore: 4925000
  timesteps_this_iter: 5000
  timesteps_total: 4925000
  training_iteration: 985
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8566 s, 985 iter, 4925000 ts, -9.18e+04 rew

agent-1: -14522.092894208388
agent-2: -4803.289013081463
agent-3: -23182.01607001204
agent-4: -20154.92698566912
agent-5: -18920.018700232533
Extrinsic Rewards:
-14398
-4764
-23002
-19982
-18761
Sum Reward: -80907
Avg Reward: -16181.4
Min Reward: -23002
Max Reward: -4764
Gini Coefficient: -0.20794245244540027
20:20 Ratio: 0.20711242500652116
Max-min Ratio: 0.20711242500652116
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-56-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -91072.13924232952
  episode_reward_min: -177419.85040558683
  episodes_this_iter: 1
  episodes_total: 985
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.77
    dispatch_time_ms: 6.739
    learner:
      cur_lr: 0.001031995052471757
      grad_gnorm: 39.999996185302734
      policy_entropy: 37.64341354370117
      policy_loss: 168.4020538330078
      var_gnorm: 103.26765441894531
      vf_explained_var: 0.0
      vf_loss: 60442.9921875
    num_steps_sampled: 4930000
    num_steps_trained: 4930000
    wait_time_ms: 69.329
  iterations_since_restore: 986
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8574.91009235382
  time_this_iter_s: 8.432011842727661
  time_total_s: 8574.91009235382
  timestamp: 1594864608
  timesteps_since_restore: 4930000
  timesteps_this_iter: 5000
  timesteps_total: 4930000
  training_iteration: 986
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8574 s, 986 iter, 4930000 ts, -9.11e+04 rew

agent-1: -13141.549671672157
agent-2: -14003.933113040053
agent-3: -14483.941023859297
agent-4: -10143.524740041938
agent-5: -5707.520197006195
Extrinsic Rewards:
-12998
-13856
-14321
-10031
-5625
Sum Reward: -56831
Avg Reward: -11366.2
Min Reward: -14321
Max Reward: -5625
Gini Coefficient: -0.1493339902517992
20:20 Ratio: 0.3927798338104881
Max-min Ratio: 0.3927798338104881
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-56-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -90665.06069812091
  episode_reward_min: -177419.85040558683
  episodes_this_iter: 1
  episodes_total: 986
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.078
    dispatch_time_ms: 6.981
    learner:
      cur_lr: 0.00103166198823601
      grad_gnorm: 40.0
      policy_entropy: 39.29593276977539
      policy_loss: -3532.03515625
      var_gnorm: 103.66014862060547
      vf_explained_var: 0.0
      vf_loss: 573389.1875
    num_steps_sampled: 4935000
    num_steps_trained: 4935000
    wait_time_ms: 75.717
  iterations_since_restore: 987
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8583.271704673767
  time_this_iter_s: 8.361612319946289
  time_total_s: 8583.271704673767
  timestamp: 1594864617
  timesteps_since_restore: 4935000
  timesteps_this_iter: 5000
  timesteps_total: 4935000
  training_iteration: 987
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8583 s, 987 iter, 4935000 ts, -9.07e+04 rew

agent-1: -15905.118054578068
agent-2: -4981.682969894215
agent-3: -13907.28628056922
agent-4: -13538.544347720164
agent-5: -19505.598039884262
Extrinsic Rewards:
-15757
-4914
-13759
-13409
-19339
Sum Reward: -67178
Avg Reward: -13435.6
Min Reward: -19339
Max Reward: -4914
Gini Coefficient: -0.1857631962844979
20:20 Ratio: 0.2540979368116242
Max-min Ratio: 0.2540979368116242
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-57-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -89980.43755105248
  episode_reward_min: -177419.85040558683
  episodes_this_iter: 1
  episodes_total: 987
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.386
    dispatch_time_ms: 7.786
    learner:
      cur_lr: 0.001031329040415585
      grad_gnorm: 40.0
      policy_entropy: 38.8263053894043
      policy_loss: -968.31982421875
      var_gnorm: 104.1410140991211
      vf_explained_var: 0.0
      vf_loss: 89807.5390625
    num_steps_sampled: 4940000
    num_steps_trained: 4940000
    wait_time_ms: 71.609
  iterations_since_restore: 988
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8591.552975177765
  time_this_iter_s: 8.281270503997803
  time_total_s: 8591.552975177765
  timestamp: 1594864625
  timesteps_since_restore: 4940000
  timesteps_this_iter: 5000
  timesteps_total: 4940000
  training_iteration: 988
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8591 s, 988 iter, 4940000 ts, -9e+04 rew

agent-1: -11872.32973717692
agent-2: -14389.902498288835
agent-3: -13856.967101961654
agent-4: -21525.275707368655
agent-5: -28601.044229987547
Extrinsic Rewards:
-11780
-14272
-13752
-21349
-28390
Sum Reward: -89543
Avg Reward: -17908.6
Min Reward: -28390
Max Reward: -11780
Gini Coefficient: -0.1823347442011101
20:20 Ratio: 0.4149348362099331
Max-min Ratio: 0.4149348362099331
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-57-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -89638.44207013058
  episode_reward_min: -177419.85040558683
  episodes_this_iter: 1
  episodes_total: 988
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.885
    dispatch_time_ms: 8.588
    learner:
      cur_lr: 0.0010309959761798382
      grad_gnorm: 39.999996185302734
      policy_entropy: 39.49382400512695
      policy_loss: -5557.3447265625
      var_gnorm: 104.50200653076172
      vf_explained_var: 0.0
      vf_loss: 516069.625
    num_steps_sampled: 4945000
    num_steps_trained: 4945000
    wait_time_ms: 70.309
  iterations_since_restore: 989
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8599.760792016983
  time_this_iter_s: 8.20781683921814
  time_total_s: 8599.760792016983
  timestamp: 1594864633
  timesteps_since_restore: 4945000
  timesteps_this_iter: 5000
  timesteps_total: 4945000
  training_iteration: 989
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8599 s, 989 iter, 4945000 ts, -8.96e+04 rew

agent-1: -2370.778428118904
agent-2: -3718.193390259677
agent-3: -18850.730939208544
agent-4: -20204.799141928
agent-5: -7990.813180338866
Extrinsic Rewards:
-2332
-3662
-18626
-19976
-7899
Sum Reward: -52495
Avg Reward: -10499.0
Min Reward: -19976
Max Reward: -2332
Gini Coefficient: -0.38290884846175827
20:20 Ratio: 0.11674008810572688
Max-min Ratio: 0.11674008810572688
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-57-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -88395.59671687326
  episode_reward_min: -167838.19940995352
  episodes_this_iter: 1
  episodes_total: 989
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.452
    dispatch_time_ms: 6.95
    learner:
      cur_lr: 0.0010306630283594131
      grad_gnorm: 40.000003814697266
      policy_entropy: 41.547698974609375
      policy_loss: -1109.232666015625
      var_gnorm: 104.91543579101562
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 152491.546875
    num_steps_sampled: 4950000
    num_steps_trained: 4950000
    wait_time_ms: 77.369
  iterations_since_restore: 990
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8608.064327001572
  time_this_iter_s: 8.303534984588623
  time_total_s: 8608.064327001572
  timestamp: 1594864642
  timesteps_since_restore: 4950000
  timesteps_this_iter: 5000
  timesteps_total: 4950000
  training_iteration: 990
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8608 s, 990 iter, 4950000 ts, -8.84e+04 rew

agent-1: -15317.838726872536
agent-2: -10725.140625940961
agent-3: -6702.222891187177
agent-4: -11890.100016430839
agent-5: -12233.597822425656
Extrinsic Rewards:
-15133
-10594
-6612
-11735
-12084
Sum Reward: -56158
Avg Reward: -11231.6
Min Reward: -15133
Max Reward: -6612
Gini Coefficient: -0.1319990028134905
20:20 Ratio: 0.43692592347849074
Max-min Ratio: 0.43692592347849074
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-57-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -87307.02579424616
  episode_reward_min: -167838.19940995352
  episodes_this_iter: 1
  episodes_total: 990
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.563
    dispatch_time_ms: 6.802
    learner:
      cur_lr: 0.0010303299641236663
      grad_gnorm: 40.0
      policy_entropy: 42.03143310546875
      policy_loss: -3557.19677734375
      var_gnorm: 105.19894409179688
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 620100.3125
    num_steps_sampled: 4955000
    num_steps_trained: 4955000
    wait_time_ms: 75.691
  iterations_since_restore: 991
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8616.361598968506
  time_this_iter_s: 8.297271966934204
  time_total_s: 8616.361598968506
  timestamp: 1594864650
  timesteps_since_restore: 4955000
  timesteps_this_iter: 5000
  timesteps_total: 4955000
  training_iteration: 991
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8616 s, 991 iter, 4955000 ts, -8.73e+04 rew

agent-1: -18470.18879722646
agent-2: -17399.1781395924
agent-3: -16425.266110405308
agent-4: -9154.5301064066
agent-5: -1200.0382758182166
Extrinsic Rewards:
-18283
-17225
-16246
-9056
-1179
Sum Reward: -61989
Avg Reward: -12397.8
Min Reward: -18283
Max Reward: -1179
Gini Coefficient: -0.2734485150591234
20:20 Ratio: 0.06448613466061369
Max-min Ratio: 0.06448613466061369
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-57-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -86731.32816686522
  episode_reward_min: -167838.19940995352
  episodes_this_iter: 1
  episodes_total: 991
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.731
    dispatch_time_ms: 10.174
    learner:
      cur_lr: 0.0010299970163032413
      grad_gnorm: 40.0
      policy_entropy: 43.296165466308594
      policy_loss: -3929.86865234375
      var_gnorm: 105.60816955566406
      vf_explained_var: 0.0
      vf_loss: 574058.625
    num_steps_sampled: 4960000
    num_steps_trained: 4960000
    wait_time_ms: 70.534
  iterations_since_restore: 992
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8624.685371398926
  time_this_iter_s: 8.323772430419922
  time_total_s: 8624.685371398926
  timestamp: 1594864658
  timesteps_since_restore: 4960000
  timesteps_this_iter: 5000
  timesteps_total: 4960000
  training_iteration: 992
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8624 s, 992 iter, 4960000 ts, -8.67e+04 rew

agent-1: -8437.187864532974
agent-2: -7558.384866172551
agent-3: -13326.944325478553
agent-4: -15116.544092555629
agent-5: -10923.323849599547
Extrinsic Rewards:
-8306
-7446
-13168
-14993
-10812
Sum Reward: -54725
Avg Reward: -10945.0
Min Reward: -14993
Max Reward: -7446
Gini Coefficient: -0.14586386477843763
20:20 Ratio: 0.4966317614886947
Max-min Ratio: 0.4966317614886947
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-57-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -85925.80667066741
  episode_reward_min: -167838.19940995352
  episodes_this_iter: 1
  episodes_total: 992
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.703
    dispatch_time_ms: 9.327
    learner:
      cur_lr: 0.0010296639520674944
      grad_gnorm: 40.0
      policy_entropy: 42.803829193115234
      policy_loss: -385.63201904296875
      var_gnorm: 106.09584045410156
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 119455.265625
    num_steps_sampled: 4965000
    num_steps_trained: 4965000
    wait_time_ms: 71.25
  iterations_since_restore: 993
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8633.078701496124
  time_this_iter_s: 8.393330097198486
  time_total_s: 8633.078701496124
  timestamp: 1594864667
  timesteps_since_restore: 4965000
  timesteps_this_iter: 5000
  timesteps_total: 4965000
  training_iteration: 993
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8633 s, 993 iter, 4965000 ts, -8.59e+04 rew

agent-1: -19762.350166614393
agent-2: -20303.59801945981
agent-3: -21498.290900208412
agent-4: -16175.771931171037
agent-5: -21419.224460314323
Extrinsic Rewards:
-19614
-20146
-21335
-16061
-21270
Sum Reward: -98426
Avg Reward: -19685.2
Min Reward: -21335
Max Reward: -16061
Gini Coefficient: -0.04959665129132546
20:20 Ratio: 0.7528005624560581
Max-min Ratio: 0.7528005624560581
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-57-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -85540.0892354055
  episode_reward_min: -167838.19940995352
  episodes_this_iter: 1
  episodes_total: 993
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.197
    dispatch_time_ms: 6.634
    learner:
      cur_lr: 0.0010293310042470694
      grad_gnorm: 40.0
      policy_entropy: 44.82402038574219
      policy_loss: 53.848968505859375
      var_gnorm: 106.53758239746094
      vf_explained_var: 0.0
      vf_loss: 46664.8828125
    num_steps_sampled: 4970000
    num_steps_trained: 4970000
    wait_time_ms: 71.025
  iterations_since_restore: 994
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8641.388478040695
  time_this_iter_s: 8.309776544570923
  time_total_s: 8641.388478040695
  timestamp: 1594864675
  timesteps_since_restore: 4970000
  timesteps_this_iter: 5000
  timesteps_total: 4970000
  training_iteration: 994
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8641 s, 994 iter, 4970000 ts, -8.55e+04 rew

agent-1: -8833.420525986776
agent-2: -22550.210311012583
agent-3: -16032.700189518187
agent-4: -15193.074593470574
agent-5: -6617.673631969907
Extrinsic Rewards:
-8742
-22335
-15867
-15058
-6548
Sum Reward: -68550
Avg Reward: -13710.0
Min Reward: -22335
Max Reward: -6548
Gini Coefficient: -0.22581473377097008
20:20 Ratio: 0.29317215133199015
Max-min Ratio: 0.29317215133199015
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-58-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -84834.23910826372
  episode_reward_min: -167838.19940995352
  episodes_this_iter: 1
  episodes_total: 994
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.746
    dispatch_time_ms: 6.833
    learner:
      cur_lr: 0.0010289980564266443
      grad_gnorm: 40.0
      policy_entropy: 43.81932830810547
      policy_loss: -12718.8798828125
      var_gnorm: 107.00523376464844
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2170252.0
    num_steps_sampled: 4975000
    num_steps_trained: 4975000
    wait_time_ms: 75.003
  iterations_since_restore: 995
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8649.715130090714
  time_this_iter_s: 8.32665205001831
  time_total_s: 8649.715130090714
  timestamp: 1594864683
  timesteps_since_restore: 4975000
  timesteps_this_iter: 5000
  timesteps_total: 4975000
  training_iteration: 995
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8649 s, 995 iter, 4975000 ts, -8.48e+04 rew

agent-1: -19623.65466425111
agent-2: -24317.96698878917
agent-3: -16843.841487431277
agent-4: -12709.628900985766
agent-5: -15418.22106744313
Extrinsic Rewards:
-19485
-24134
-16710
-12585
-15294
Sum Reward: -88208
Avg Reward: -17641.6
Min Reward: -24134
Max Reward: -12585
Gini Coefficient: -0.12374841284237258
20:20 Ratio: 0.5214634954835502
Max-min Ratio: 0.5214634954835502
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-58-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -84542.30180327107
  episode_reward_min: -167838.19940995352
  episodes_this_iter: 1
  episodes_total: 995
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.417
    dispatch_time_ms: 8.383
    learner:
      cur_lr: 0.0010286649921908975
      grad_gnorm: 40.0
      policy_entropy: 48.52762985229492
      policy_loss: -722.4000244140625
      var_gnorm: 107.49617767333984
      vf_explained_var: 0.0
      vf_loss: 112008.078125
    num_steps_sampled: 4980000
    num_steps_trained: 4980000
    wait_time_ms: 71.358
  iterations_since_restore: 996
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8658.041059970856
  time_this_iter_s: 8.325929880142212
  time_total_s: 8658.041059970856
  timestamp: 1594864692
  timesteps_since_restore: 4980000
  timesteps_this_iter: 5000
  timesteps_total: 4980000
  training_iteration: 996
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8658 s, 996 iter, 4980000 ts, -8.45e+04 rew

agent-1: -18746.979269322113
agent-2: -20727.70705211308
agent-3: -21855.683701390997
agent-4: -8450.408187189707
agent-5: -14147.761481506817
Extrinsic Rewards:
-18582
-20563
-21677
-8379
-14017
Sum Reward: -83218
Avg Reward: -16643.6
Min Reward: -21677
Max Reward: -8379
Gini Coefficient: -0.15930207407051358
20:20 Ratio: 0.38653872768372005
Max-min Ratio: 0.38653872768372005
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-58-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -83923.93385268848
  episode_reward_min: -167838.19940995352
  episodes_this_iter: 1
  episodes_total: 996
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.484
    dispatch_time_ms: 7.541
    learner:
      cur_lr: 0.0010283320443704724
      grad_gnorm: 40.0
      policy_entropy: 45.13156509399414
      policy_loss: -11099.353515625
      var_gnorm: 107.86691284179688
      vf_explained_var: 0.0
      vf_loss: 1731381.125
    num_steps_sampled: 4985000
    num_steps_trained: 4985000
    wait_time_ms: 72.708
  iterations_since_restore: 997
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8666.362041950226
  time_this_iter_s: 8.320981979370117
  time_total_s: 8666.362041950226
  timestamp: 1594864700
  timesteps_since_restore: 4985000
  timesteps_this_iter: 5000
  timesteps_total: 4985000
  training_iteration: 997
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8666 s, 997 iter, 4985000 ts, -8.39e+04 rew

agent-1: -7457.759658754776
agent-2: -3485.892968874199
agent-3: -19970.172425938028
agent-4: -20169.31113379129
agent-5: -8326.217189388151
Extrinsic Rewards:
-7363
-3424
-19755
-19962
-8249
Sum Reward: -58753
Avg Reward: -11750.6
Min Reward: -19962
Max Reward: -3424
Gini Coefficient: -0.30955355471209983
20:20 Ratio: 0.17152589920849615
Max-min Ratio: 0.17152589920849615
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-58-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -83451.72590140568
  episode_reward_min: -167838.19940995352
  episodes_this_iter: 1
  episodes_total: 997
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.426
    dispatch_time_ms: 6.255
    learner:
      cur_lr: 0.0010279989801347256
      grad_gnorm: 40.0
      policy_entropy: 49.33856201171875
      policy_loss: -11262.623046875
      var_gnorm: 108.35494232177734
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 4015599.75
    num_steps_sampled: 4990000
    num_steps_trained: 4990000
    wait_time_ms: 74.467
  iterations_since_restore: 998
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8674.81205701828
  time_this_iter_s: 8.4500150680542
  time_total_s: 8674.81205701828
  timestamp: 1594864709
  timesteps_since_restore: 4990000
  timesteps_this_iter: 5000
  timesteps_total: 4990000
  training_iteration: 998
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8674 s, 998 iter, 4990000 ts, -8.35e+04 rew

agent-1: -39537.16436941629
agent-2: -26321.723576864304
agent-3: -1392.2018435504172
agent-4: -24472.904180352958
agent-5: -24443.813941833672
Extrinsic Rewards:
-39313
-26166
-1377
-24320
-24283
Sum Reward: -115459
Avg Reward: -23091.8
Min Reward: -39313
Max Reward: -1377
Gini Coefficient: -0.26937700828865657
20:20 Ratio: 0.035026581537913666
Max-min Ratio: 0.035026581537913666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-58-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -83391.59410124998
  episode_reward_min: -167838.19940995352
  episodes_this_iter: 1
  episodes_total: 998
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.476
    dispatch_time_ms: 8.582
    learner:
      cur_lr: 0.0010276660323143005
      grad_gnorm: 40.0
      policy_entropy: 51.22611618041992
      policy_loss: -1877.8526611328125
      var_gnorm: 108.81465911865234
      vf_explained_var: 0.0
      vf_loss: 203420.921875
    num_steps_sampled: 4995000
    num_steps_trained: 4995000
    wait_time_ms: 69.878
  iterations_since_restore: 999
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8694.738801956177
  time_this_iter_s: 19.92674493789673
  time_total_s: 8694.738801956177
  timestamp: 1594864729
  timesteps_since_restore: 4995000
  timesteps_this_iter: 5000
  timesteps_total: 4995000
  training_iteration: 999
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8694 s, 999 iter, 4995000 ts, -8.34e+04 rew

agent-1: -6538.242835698732
agent-2: -22531.23508146028
agent-3: -22464.886494635008
agent-4: -18794.08245994774
agent-5: -10793.636631187734
Extrinsic Rewards:
-6485
-22351
-22278
-18618
-10683
Sum Reward: -80415
Avg Reward: -16083.0
Min Reward: -22351
Max Reward: -6485
Gini Coefficient: -0.21551700553379344
20:20 Ratio: 0.2901436177352244
Max-min Ratio: 0.2901436177352244
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-58-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -83244.64687891865
  episode_reward_min: -167838.19940995352
  episodes_this_iter: 1
  episodes_total: 999
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 4.271
    dispatch_time_ms: 12.867
    learner:
      cur_lr: 0.0010273329680785537
      grad_gnorm: 39.999996185302734
      policy_entropy: 45.62429428100586
      policy_loss: -7716.16162109375
      var_gnorm: 109.31581115722656
      vf_explained_var: 0.0
      vf_loss: 1168559.75
    num_steps_sampled: 5000000
    num_steps_trained: 5000000
    wait_time_ms: 66.338
  iterations_since_restore: 1000
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8703.096241235733
  time_this_iter_s: 8.357439279556274
  time_total_s: 8703.096241235733
  timestamp: 1594864737
  timesteps_since_restore: 5000000
  timesteps_this_iter: 5000
  timesteps_total: 5000000
  training_iteration: 1000
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8703 s, 1000 iter, 5000000 ts, -8.32e+04 rew

agent-1: -22825.26207105359
agent-2: -11661.696208782534
agent-3: -14576.563408586337
agent-4: -23556.38603802081
agent-5: -37205.902982378284
Extrinsic Rewards:
-22667
-11586
-14484
-23393
-36984
Sum Reward: -109114
Avg Reward: -21822.8
Min Reward: -36984
Max Reward: -11586
Gini Coefficient: -0.21887200542551827
20:20 Ratio: 0.31327060350421804
Max-min Ratio: 0.31327060350421804
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-59-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -82948.6726755588
  episode_reward_min: -167838.19940995352
  episodes_this_iter: 1
  episodes_total: 1000
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.649
    dispatch_time_ms: 7.889
    learner:
      cur_lr: 0.0010270000202581286
      grad_gnorm: 39.999996185302734
      policy_entropy: 38.84407424926758
      policy_loss: -8153.8583984375
      var_gnorm: 109.8221206665039
      vf_explained_var: 0.0
      vf_loss: 2490165.25
    num_steps_sampled: 5005000
    num_steps_trained: 5005000
    wait_time_ms: 76.481
  iterations_since_restore: 1001
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8711.55484032631
  time_this_iter_s: 8.458599090576172
  time_total_s: 8711.55484032631
  timestamp: 1594864745
  timesteps_since_restore: 5005000
  timesteps_this_iter: 5000
  timesteps_total: 5005000
  training_iteration: 1001
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8711 s, 1001 iter, 5005000 ts, -8.29e+04 rew

agent-1: -24913.567982930388
agent-2: -20009.18936054896
agent-3: -24781.775151515092
agent-4: -29911.647737162908
agent-5: -14129.678240937414
Extrinsic Rewards:
-24755
-19874
-24619
-29729
-14026
Sum Reward: -113003
Avg Reward: -22600.6
Min Reward: -29729
Max Reward: -14026
Gini Coefficient: -0.1284461474474129
20:20 Ratio: 0.4717952167916849
Max-min Ratio: 0.4717952167916849
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-59-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -83224.60843978774
  episode_reward_min: -167838.19940995352
  episodes_this_iter: 1
  episodes_total: 1001
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.936
    dispatch_time_ms: 9.925
    learner:
      cur_lr: 0.0010266669560223818
      grad_gnorm: 40.0
      policy_entropy: 41.84237289428711
      policy_loss: -4042.410400390625
      var_gnorm: 110.31575775146484
      vf_explained_var: 0.0
      vf_loss: 525572.0625
    num_steps_sampled: 5010000
    num_steps_trained: 5010000
    wait_time_ms: 70.853
  iterations_since_restore: 1002
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8719.924825429916
  time_this_iter_s: 8.369985103607178
  time_total_s: 8719.924825429916
  timestamp: 1594864754
  timesteps_since_restore: 5010000
  timesteps_this_iter: 5000
  timesteps_total: 5010000
  training_iteration: 1002
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8719 s, 1002 iter, 5010000 ts, -8.32e+04 rew

agent-1: -18736.129752879544
agent-2: -9156.27977273552
agent-3: -10952.033634225963
agent-4: -32027.572452592878
agent-5: -32118.52476985268
Extrinsic Rewards:
-18596
-9081
-10867
-31820
-31917
Sum Reward: -102281
Avg Reward: -20456.2
Min Reward: -31917
Max Reward: -9081
Gini Coefficient: -0.2605567016356899
20:20 Ratio: 0.28451922173136573
Max-min Ratio: 0.28451922173136573
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-59-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -83512.86535256132
  episode_reward_min: -167838.19940995352
  episodes_this_iter: 1
  episodes_total: 1002
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.161
    dispatch_time_ms: 7.398
    learner:
      cur_lr: 0.0010263340082019567
      grad_gnorm: 40.0
      policy_entropy: 46.213775634765625
      policy_loss: -301.3976745605469
      var_gnorm: 110.73570251464844
      vf_explained_var: 0.0
      vf_loss: 143450.28125
    num_steps_sampled: 5015000
    num_steps_trained: 5015000
    wait_time_ms: 73.463
  iterations_since_restore: 1003
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8728.322560310364
  time_this_iter_s: 8.397734880447388
  time_total_s: 8728.322560310364
  timestamp: 1594864762
  timesteps_since_restore: 5015000
  timesteps_this_iter: 5000
  timesteps_total: 5015000
  training_iteration: 1003
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8728 s, 1003 iter, 5015000 ts, -8.35e+04 rew

agent-1: -9575.542619948048
agent-2: -29683.807451087458
agent-3: -22338.782016517758
agent-4: -20210.820078903762
agent-5: -36890.68780722613
Extrinsic Rewards:
-9507
-29512
-22192
-20074
-36687
Sum Reward: -117972
Avg Reward: -23594.4
Min Reward: -36687
Max Reward: -9507
Gini Coefficient: -0.21631573593734107
20:20 Ratio: 0.25913811431842343
Max-min Ratio: 0.25913811431842343
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-59-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -83775.53432611757
  episode_reward_min: -167838.19940995352
  episodes_this_iter: 1
  episodes_total: 1003
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.591
    dispatch_time_ms: 8.978
    learner:
      cur_lr: 0.0010260009439662099
      grad_gnorm: 40.0
      policy_entropy: 54.95646286010742
      policy_loss: -184.73216247558594
      var_gnorm: 111.18151092529297
      vf_explained_var: 0.0
      vf_loss: 31565.88671875
    num_steps_sampled: 5020000
    num_steps_trained: 5020000
    wait_time_ms: 72.219
  iterations_since_restore: 1004
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8736.614941120148
  time_this_iter_s: 8.292380809783936
  time_total_s: 8736.614941120148
  timestamp: 1594864771
  timesteps_since_restore: 5020000
  timesteps_this_iter: 5000
  timesteps_total: 5020000
  training_iteration: 1004
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8736 s, 1004 iter, 5020000 ts, -8.38e+04 rew

agent-1: -16167.634814965655
agent-2: -20387.20744474332
agent-3: -6715.892101103344
agent-4: -22830.221151383055
agent-5: -2499.0064044150463
Extrinsic Rewards:
-15993
-20183
-6641
-22622
-2471
Sum Reward: -67910
Avg Reward: -13582.0
Min Reward: -22622
Max Reward: -2471
Gini Coefficient: -0.3171491680164924
20:20 Ratio: 0.10922995314295818
Max-min Ratio: 0.10922995314295818
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-59-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -83510.0005326537
  episode_reward_min: -167838.19940995352
  episodes_this_iter: 1
  episodes_total: 1004
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.329
    dispatch_time_ms: 8.831
    learner:
      cur_lr: 0.0010256679961457849
      grad_gnorm: 40.0
      policy_entropy: 52.79254150390625
      policy_loss: -4579.150390625
      var_gnorm: 111.6285400390625
      vf_explained_var: 0.0
      vf_loss: 585913.6875
    num_steps_sampled: 5025000
    num_steps_trained: 5025000
    wait_time_ms: 73.672
  iterations_since_restore: 1005
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8744.936201095581
  time_this_iter_s: 8.32125997543335
  time_total_s: 8744.936201095581
  timestamp: 1594864779
  timesteps_since_restore: 5025000
  timesteps_this_iter: 5000
  timesteps_total: 5025000
  training_iteration: 1005
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8744 s, 1005 iter, 5025000 ts, -8.35e+04 rew

agent-1: -7420.014962465422
agent-2: -18215.716396214513
agent-3: -15885.36015132708
agent-4: -17089.57182928466
agent-5: -30036.24694562605
Extrinsic Rewards:
-7347
-18059
-15747
-16947
-29817
Sum Reward: -87917
Avg Reward: -17583.4
Min Reward: -29817
Max Reward: -7347
Gini Coefficient: -0.21498458773616025
20:20 Ratio: 0.24640305865781265
Max-min Ratio: 0.24640305865781265
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-59-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -83006.8182066843
  episode_reward_min: -167838.19940995352
  episodes_this_iter: 1
  episodes_total: 1005
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.624
    dispatch_time_ms: 10.611
    learner:
      cur_lr: 0.0010253350483253598
      grad_gnorm: 40.0
      policy_entropy: 57.18430709838867
      policy_loss: -2901.56884765625
      var_gnorm: 112.1068115234375
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 263953.84375
    num_steps_sampled: 5030000
    num_steps_trained: 5030000
    wait_time_ms: 72.144
  iterations_since_restore: 1006
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8753.262610197067
  time_this_iter_s: 8.326409101486206
  time_total_s: 8753.262610197067
  timestamp: 1594864787
  timesteps_since_restore: 5030000
  timesteps_this_iter: 5000
  timesteps_total: 5030000
  training_iteration: 1006
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8753 s, 1006 iter, 5030000 ts, -8.3e+04 rew

agent-1: -19053.153544707526
agent-2: -20805.40292002977
agent-3: -18623.947539635647
agent-4: -3463.9201216295673
agent-5: -14469.657960127273
Extrinsic Rewards:
-18875
-20613
-18454
-3426
-14324
Sum Reward: -75692
Avg Reward: -15138.4
Min Reward: -20613
Max Reward: -3426
Gini Coefficient: -0.2057020556994134
20:20 Ratio: 0.16620579246106826
Max-min Ratio: 0.16620579246106826
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-59-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -82476.84206493427
  episode_reward_min: -167838.19940995352
  episodes_this_iter: 1
  episodes_total: 1006
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.551
    dispatch_time_ms: 5.774
    learner:
      cur_lr: 0.001025001984089613
      grad_gnorm: 39.999996185302734
      policy_entropy: 54.56588363647461
      policy_loss: -3226.80029296875
      var_gnorm: 112.55455017089844
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 222067.421875
    num_steps_sampled: 5035000
    num_steps_trained: 5035000
    wait_time_ms: 72.816
  iterations_since_restore: 1007
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8761.543345689774
  time_this_iter_s: 8.280735492706299
  time_total_s: 8761.543345689774
  timestamp: 1594864796
  timesteps_since_restore: 5035000
  timesteps_this_iter: 5000
  timesteps_total: 5035000
  training_iteration: 1007
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8761 s, 1007 iter, 5035000 ts, -8.25e+04 rew

agent-1: -14799.760103757431
agent-2: -15458.26081672082
agent-3: -15252.730459192868
agent-4: -19274.114717309254
agent-5: -14914.57495824497
Extrinsic Rewards:
-14662
-15305
-15098
-19106
-14778
Sum Reward: -78949
Avg Reward: -15789.8
Min Reward: -19106
Max Reward: -14662
Gini Coefficient: -0.04770168083192947
20:20 Ratio: 0.7674029100806029
Max-min Ratio: 0.7674029100806029
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-00-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -82428.65096427807
  episode_reward_min: -167838.19940995352
  episodes_this_iter: 1
  episodes_total: 1007
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.479
    dispatch_time_ms: 7.929
    learner:
      cur_lr: 0.001024669036269188
      grad_gnorm: 40.0
      policy_entropy: 51.11872100830078
      policy_loss: -4084.828369140625
      var_gnorm: 113.02476501464844
      vf_explained_var: -0.022634506225585938
      vf_loss: 420827.3125
    num_steps_sampled: 5040000
    num_steps_trained: 5040000
    wait_time_ms: 73.09
  iterations_since_restore: 1008
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8769.865060806274
  time_this_iter_s: 8.321715116500854
  time_total_s: 8769.865060806274
  timestamp: 1594864804
  timesteps_since_restore: 5040000
  timesteps_this_iter: 5000
  timesteps_total: 5040000
  training_iteration: 1008
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8769 s, 1008 iter, 5040000 ts, -8.24e+04 rew

agent-1: -12512.302813873186
agent-2: -15298.403326274938
agent-3: -11662.97260556697
agent-4: -11367.956199128386
agent-5: -18367.406270051044
Extrinsic Rewards:
-12370
-15144
-11529
-11235
-18178
Sum Reward: -68456
Avg Reward: -13691.2
Min Reward: -18178
Max Reward: -11235
Gini Coefficient: -0.10226130653266331
20:20 Ratio: 0.6180547915062163
Max-min Ratio: 0.6180547915062163
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-00-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -82235.4516494254
  episode_reward_min: -167838.19940995352
  episodes_this_iter: 1
  episodes_total: 1008
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.925
    dispatch_time_ms: 6.544
    learner:
      cur_lr: 0.001024335972033441
      grad_gnorm: 40.000003814697266
      policy_entropy: 53.34421157836914
      policy_loss: -1720.0057373046875
      var_gnorm: 113.4925765991211
      vf_explained_var: 0.0
      vf_loss: 131622.03125
    num_steps_sampled: 5045000
    num_steps_trained: 5045000
    wait_time_ms: 73.142
  iterations_since_restore: 1009
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8778.246345281601
  time_this_iter_s: 8.381284475326538
  time_total_s: 8778.246345281601
  timestamp: 1594864812
  timesteps_since_restore: 5045000
  timesteps_this_iter: 5000
  timesteps_total: 5045000
  training_iteration: 1009
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8778 s, 1009 iter, 5045000 ts, -8.22e+04 rew

agent-1: -10588.259934995813
agent-2: -22190.475429953356
agent-3: -24222.401009932382
agent-4: -23854.02180822213
agent-5: -6938.761554475135
Extrinsic Rewards:
-10486
-22007
-24028
-23665
-6878
Sum Reward: -87064
Avg Reward: -17412.8
Min Reward: -24028
Max Reward: -6878
Gini Coefficient: -0.2181337866397133
20:20 Ratio: 0.286249375728317
Max-min Ratio: 0.286249375728317
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-00-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -82661.64165866516
  episode_reward_min: -167838.19940995352
  episodes_this_iter: 1
  episodes_total: 1009
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.189
    dispatch_time_ms: 7.052
    learner:
      cur_lr: 0.001024003024213016
      grad_gnorm: 39.999996185302734
      policy_entropy: 56.82631301879883
      policy_loss: -1202.70556640625
      var_gnorm: 113.99594116210938
      vf_explained_var: 0.0
      vf_loss: 127064.015625
    num_steps_sampled: 5050000
    num_steps_trained: 5050000
    wait_time_ms: 75.43
  iterations_since_restore: 1010
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8786.584978818893
  time_this_iter_s: 8.33863353729248
  time_total_s: 8786.584978818893
  timestamp: 1594864821
  timesteps_since_restore: 5050000
  timesteps_this_iter: 5000
  timesteps_total: 5050000
  training_iteration: 1010
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8786 s, 1010 iter, 5050000 ts, -8.27e+04 rew

agent-1: -14932.26627074763
agent-2: -12616.885354116057
agent-3: -19590.02171336236
agent-4: -16866.132574161194
agent-5: -17622.890781084483
Extrinsic Rewards:
-14797
-12492
-19418
-16710
-17460
Sum Reward: -80877
Avg Reward: -16175.4
Min Reward: -19418
Max Reward: -12492
Gini Coefficient: -0.08167958752179236
20:20 Ratio: 0.6433206303429807
Max-min Ratio: 0.6433206303429807
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-00-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -83031.04477079783
  episode_reward_min: -167838.19940995352
  episodes_this_iter: 1
  episodes_total: 1010
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.12
    dispatch_time_ms: 29.503
    learner:
      cur_lr: 0.0010236699599772692
      grad_gnorm: 40.0
      policy_entropy: 55.6098747253418
      policy_loss: -920.6383666992188
      var_gnorm: 114.3470687866211
      vf_explained_var: 0.0
      vf_loss: 32207.44140625
    num_steps_sampled: 5055000
    num_steps_trained: 5055000
    wait_time_ms: 57.057
  iterations_since_restore: 1011
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8795.282618761063
  time_this_iter_s: 8.69763994216919
  time_total_s: 8795.282618761063
  timestamp: 1594864830
  timesteps_since_restore: 5055000
  timesteps_this_iter: 5000
  timesteps_total: 5055000
  training_iteration: 1011
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8795 s, 1011 iter, 5055000 ts, -8.3e+04 rew

agent-1: -11273.52651693476
agent-2: -10531.390120868444
agent-3: -10246.255932356788
agent-4: -6713.552304733831
agent-5: -7114.979525893686
Extrinsic Rewards:
-11097
-10358
-10077
-6595
-6995
Sum Reward: -45122
Avg Reward: -9024.4
Min Reward: -11097
Max Reward: -6595
Gini Coefficient: -0.10963166526306459
20:20 Ratio: 0.5943047670541588
Max-min Ratio: 0.5943047670541588
agent-1: -2454.5238232676297
agent-2: -13863.53318978442
agent-3: -8680.57334555855
agent-4: -7757.792985751227
agent-5: -15728.537744082427
Extrinsic Rewards:
-2415
-13660
-8541
-7638
-15519
Sum Reward: -47773
Avg Reward: -9554.6
Min Reward: -15519
Max Reward: -2415
Gini Coefficient: -0.2698595440939443
20:20 Ratio: 0.15561569688768606
Max-min Ratio: 0.15561569688768606
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-00-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -82833.84834954487
  episode_reward_min: -167838.19940995352
  episodes_this_iter: 1
  episodes_total: 1011
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.411
    dispatch_time_ms: 42.276
    learner:
      cur_lr: 0.0010233370121568441
      grad_gnorm: 40.000003814697266
      policy_entropy: 57.43680953979492
      policy_loss: 1014.1011962890625
      var_gnorm: 114.69660949707031
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 17752.0078125
    num_steps_sampled: 5060000
    num_steps_trained: 5060000
    wait_time_ms: 43.689
  iterations_since_restore: 1012
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8804.35495877266
  time_this_iter_s: 9.07234001159668
  time_total_s: 8804.35495877266
  timestamp: 1594864839
  timesteps_since_restore: 5060000
  timesteps_this_iter: 5000
  timesteps_total: 5060000
  training_iteration: 1012
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8804 s, 1012 iter, 5060000 ts, -8.28e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-00-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -82442.41739856896
  episode_reward_min: -167838.19940995352
  episodes_this_iter: 1
  episodes_total: 1012
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.229
    dispatch_time_ms: 44.716
    learner:
      cur_lr: 0.0010230039479210973
      grad_gnorm: 40.000003814697266
      policy_entropy: 48.554569244384766
      policy_loss: -342.09063720703125
      var_gnorm: 114.96813201904297
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 25284.521484375
    num_steps_sampled: 5065000
    num_steps_trained: 5065000
    wait_time_ms: 33.915
  iterations_since_restore: 1013
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8812.737963914871
  time_this_iter_s: 8.383005142211914
  time_total_s: 8812.737963914871
  timestamp: 1594864847
  timesteps_since_restore: 5065000
  timesteps_this_iter: 5000
  timesteps_total: 5065000
  training_iteration: 1013
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8812 s, 1013 iter, 5065000 ts, -8.24e+04 rew

agent-1: -8303.984221679404
agent-2: -4558.129644575861
agent-3: -8989.10021314882
agent-4: -9055.37106567701
agent-5: -306.7611376258769
Extrinsic Rewards:
-8120
-4423
-8816
-8850
-296
Sum Reward: -30505
Avg Reward: -6101.0
Min Reward: -8850
Max Reward: -296
Gini Coefficient: -0.2819341091624324
20:20 Ratio: 0.03344632768361582
Max-min Ratio: 0.03344632768361582
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-00-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -81743.48885093172
  episode_reward_min: -167838.19940995352
  episodes_this_iter: 1
  episodes_total: 1013
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.985
    dispatch_time_ms: 39.897
    learner:
      cur_lr: 0.0010226710001006722
      grad_gnorm: 40.0
      policy_entropy: 35.48697280883789
      policy_loss: 843.4965209960938
      var_gnorm: 114.77919006347656
      vf_explained_var: 0.0
      vf_loss: 17489.576171875
    num_steps_sampled: 5070000
    num_steps_trained: 5070000
    wait_time_ms: 49.041
  iterations_since_restore: 1014
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8821.525566577911
  time_this_iter_s: 8.787602663040161
  time_total_s: 8821.525566577911
  timestamp: 1594864856
  timesteps_since_restore: 5070000
  timesteps_this_iter: 5000
  timesteps_total: 5070000
  training_iteration: 1014
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8821 s, 1014 iter, 5070000 ts, -8.17e+04 rew

agent-1: -5475.901417240877
agent-2: -7451.299736737572
agent-3: -11498.825440653478
agent-4: -1389.4324271208782
agent-5: -7797.371647145624
Extrinsic Rewards:
-5360
-7283
-11277
-1361
-7626
Sum Reward: -32907
Avg Reward: -6581.4
Min Reward: -11277
Max Reward: -1361
Gini Coefficient: -0.26861154161728507
20:20 Ratio: 0.12068812627471845
Max-min Ratio: 0.12068812627471845
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-01-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -18810.43479748111
  episode_reward_mean: -81102.08740898274
  episode_reward_min: -167838.19940995352
  episodes_this_iter: 1
  episodes_total: 1014
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.758
    dispatch_time_ms: 37.288
    learner:
      cur_lr: 0.0010223380522802472
      grad_gnorm: 40.0
      policy_entropy: 31.061935424804688
      policy_loss: 619.195556640625
      var_gnorm: 114.37637329101562
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 21391.505859375
    num_steps_sampled: 5075000
    num_steps_trained: 5075000
    wait_time_ms: 45.856
  iterations_since_restore: 1015
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8830.291103124619
  time_this_iter_s: 8.765536546707153
  time_total_s: 8830.291103124619
  timestamp: 1594864865
  timesteps_since_restore: 5075000
  timesteps_this_iter: 5000
  timesteps_total: 5075000
  training_iteration: 1015
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8830 s, 1015 iter, 5075000 ts, -8.11e+04 rew

agent-1: -3514.066828443162
agent-2: -3781.023374206659
agent-3: -1651.4412731570956
agent-4: -2002.4628817344574
agent-5: -3135.054106826805
Extrinsic Rewards:
-3343
-3588
-1550
-1881
-2982
Sum Reward: -13344
Avg Reward: -2668.8
Min Reward: -3588
Max Reward: -1550
Gini Coefficient: -0.1660071942446043
20:20 Ratio: 0.4319955406911929
Max-min Ratio: 0.4319955406911929
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-01-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14084.048464368167
  episode_reward_mean: -79855.93730427329
  episode_reward_min: -167838.19940995352
  episodes_this_iter: 1
  episodes_total: 1015
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.06
    dispatch_time_ms: 32.134
    learner:
      cur_lr: 0.0010220049880445004
      grad_gnorm: 40.0
      policy_entropy: 27.1830997467041
      policy_loss: -878.4945068359375
      var_gnorm: 113.9040756225586
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 64598.984375
    num_steps_sampled: 5080000
    num_steps_trained: 5080000
    wait_time_ms: 43.718
  iterations_since_restore: 1016
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8838.492428779602
  time_this_iter_s: 8.20132565498352
  time_total_s: 8838.492428779602
  timestamp: 1594864873
  timesteps_since_restore: 5080000
  timesteps_this_iter: 5000
  timesteps_total: 5080000
  training_iteration: 1016
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8838 s, 1016 iter, 5080000 ts, -7.99e+04 rew

agent-1: -2497.0553937345408
agent-2: -2235.9678663920236
agent-3: -1959.9890291593233
agent-4: -2373.191591530688
agent-5: -951.4209630905763
Extrinsic Rewards:
-2326
-2079
-1826
-2202
-877
Sum Reward: -9310
Avg Reward: -1862.0
Min Reward: -2326
Max Reward: -877
Gini Coefficient: -0.14066595059076262
20:20 Ratio: 0.3770421324161651
Max-min Ratio: 0.3770421324161651
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-01-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10017.624843907162
  episode_reward_mean: -78452.27547841489
  episode_reward_min: -167838.19940995352
  episodes_this_iter: 1
  episodes_total: 1016
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.014
    dispatch_time_ms: 45.755
    learner:
      cur_lr: 0.0010216720402240753
      grad_gnorm: 40.0
      policy_entropy: 26.514835357666016
      policy_loss: 425.6460266113281
      var_gnorm: 113.46873474121094
      vf_explained_var: 0.0
      vf_loss: 16759.54296875
    num_steps_sampled: 5085000
    num_steps_trained: 5085000
    wait_time_ms: 26.772
  iterations_since_restore: 1017
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8847.002769708633
  time_this_iter_s: 8.510340929031372
  time_total_s: 8847.002769708633
  timestamp: 1594864881
  timesteps_since_restore: 5085000
  timesteps_this_iter: 5000
  timesteps_total: 5085000
  training_iteration: 1017
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8847 s, 1017 iter, 5085000 ts, -7.85e+04 rew

agent-1: -99.6903959672381
agent-2: -4080.2374521273
agent-3: -1577.8000628806474
agent-4: -4840.34156831739
agent-5: -4171.205851567842
Extrinsic Rewards:
-88
-3887
-1490
-4624
-3995
Sum Reward: -14084
Avg Reward: -2816.8
Min Reward: -4624
Max Reward: -88
Gini Coefficient: -0.328798636750923
20:20 Ratio: 0.01903114186851211
Max-min Ratio: 0.01903114186851211
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-01-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10017.624843907162
  episode_reward_mean: -77320.90638654135
  episode_reward_min: -167838.19940995352
  episodes_this_iter: 1
  episodes_total: 1017
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.804
    dispatch_time_ms: 30.944
    learner:
      cur_lr: 0.0010213389759883285
      grad_gnorm: 40.000003814697266
      policy_entropy: 23.63509750366211
      policy_loss: -218.57313537597656
      var_gnorm: 113.06100463867188
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 15564.576171875
    num_steps_sampled: 5090000
    num_steps_trained: 5090000
    wait_time_ms: 29.622
  iterations_since_restore: 1018
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8855.512974739075
  time_this_iter_s: 8.510205030441284
  time_total_s: 8855.512974739075
  timestamp: 1594864890
  timesteps_since_restore: 5090000
  timesteps_this_iter: 5000
  timesteps_total: 5090000
  training_iteration: 1018
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8855 s, 1018 iter, 5090000 ts, -7.73e+04 rew

agent-1: -3199.9515303226153
agent-2: -1008.5513564852725
agent-3: -1917.47637089081
agent-4: -2180.514230833186
agent-5: -1381.8109187181012
Extrinsic Rewards:
-2987
-932
-1780
-2027
-1259
Sum Reward: -8985
Avg Reward: -1797.0
Min Reward: -2987
Max Reward: -932
Gini Coefficient: -0.21716193656093488
20:20 Ratio: 0.3120187479075996
Max-min Ratio: 0.3120187479075996
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-01-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -9688.30440724999
  episode_reward_mean: -76415.25002665543
  episode_reward_min: -167838.19940995352
  episodes_this_iter: 1
  episodes_total: 1018
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.925
    dispatch_time_ms: 38.323
    learner:
      cur_lr: 0.0010210060281679034
      grad_gnorm: 40.000003814697266
      policy_entropy: 19.204261779785156
      policy_loss: -197.93138122558594
      var_gnorm: 112.54535675048828
      vf_explained_var: 0.0
      vf_loss: 54641.76171875
    num_steps_sampled: 5095000
    num_steps_trained: 5095000
    wait_time_ms: 32.406
  iterations_since_restore: 1019
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8863.845146656036
  time_this_iter_s: 8.33217191696167
  time_total_s: 8863.845146656036
  timestamp: 1594864898
  timesteps_since_restore: 5095000
  timesteps_this_iter: 5000
  timesteps_total: 5095000
  training_iteration: 1019
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8863 s, 1019 iter, 5095000 ts, -7.64e+04 rew

agent-1: -1194.0595818340485
agent-2: -1006.1529505160012
agent-3: -1764.050991249631
agent-4: -3070.185276546498
agent-5: -1313.578280765027
Extrinsic Rewards:
-1090
-906
-1601
-2841
-1200
Sum Reward: -7638
Avg Reward: -1527.6
Min Reward: -2841
Max Reward: -906
Gini Coefficient: -0.2294317884262896
20:20 Ratio: 0.31890179514255546
Max-min Ratio: 0.31890179514255546
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-01-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -8348.027080911177
  episode_reward_mean: -75011.78395606871
  episode_reward_min: -167838.19940995352
  episodes_this_iter: 1
  episodes_total: 1019
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.539
    dispatch_time_ms: 24.308
    learner:
      cur_lr: 0.0010206729639321566
      grad_gnorm: 40.0
      policy_entropy: 16.815624237060547
      policy_loss: 548.5551147460938
      var_gnorm: 112.07487487792969
      vf_explained_var: 0.0
      vf_loss: 17409.095703125
    num_steps_sampled: 5100000
    num_steps_trained: 5100000
    wait_time_ms: 51.693
  iterations_since_restore: 1020
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8872.255121946335
  time_this_iter_s: 8.409975290298462
  time_total_s: 8872.255121946335
  timestamp: 1594864907
  timesteps_since_restore: 5100000
  timesteps_this_iter: 5000
  timesteps_total: 5100000
  training_iteration: 1020
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8872 s, 1020 iter, 5100000 ts, -7.5e+04 rew

agent-1: -2287.2878035867902
agent-2: -2167.1903860104435
agent-3: -1518.4798988849227
agent-4: -917.9859806254932
agent-5: -1854.5552761876925
Extrinsic Rewards:
-2103
-1996
-1402
-850
-1701
Sum Reward: -8052
Avg Reward: -1610.4
Min Reward: -2103
Max Reward: -850
Gini Coefficient: -0.15399900645802286
20:20 Ratio: 0.4041844983357109
Max-min Ratio: 0.4041844983357109
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-01-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -8348.027080911177
  episode_reward_mean: -74165.50714585322
  episode_reward_min: -167838.19940995352
  episodes_this_iter: 1
  episodes_total: 1020
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.172
    dispatch_time_ms: 19.428
    learner:
      cur_lr: 0.0010203400161117315
      grad_gnorm: 40.0
      policy_entropy: 13.57496452331543
      policy_loss: 72.26493835449219
      var_gnorm: 111.57997131347656
      vf_explained_var: 0.0
      vf_loss: 19770.58984375
    num_steps_sampled: 5105000
    num_steps_trained: 5105000
    wait_time_ms: 57.261
  iterations_since_restore: 1021
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8880.52673983574
  time_this_iter_s: 8.271617889404297
  time_total_s: 8880.52673983574
  timestamp: 1594864915
  timesteps_since_restore: 5105000
  timesteps_this_iter: 5000
  timesteps_total: 5105000
  training_iteration: 1021
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8880 s, 1021 iter, 5105000 ts, -7.42e+04 rew

agent-1: -2003.762365148257
agent-2: -483.44912702627425
agent-3: -773.2516366134222
agent-4: -1431.5890836137191
agent-5: -1314.6704563828778
Extrinsic Rewards:
-1775
-386
-678
-1279
-1135
Sum Reward: -5253
Avg Reward: -1050.6
Min Reward: -1775
Max Reward: -386
Gini Coefficient: -0.2573005901389682
20:20 Ratio: 0.21746478873239436
Max-min Ratio: 0.21746478873239436
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-02-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6006.722668784555
  episode_reward_mean: -72847.57973962007
  episode_reward_min: -167838.19940995352
  episodes_this_iter: 1
  episodes_total: 1021
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.699
    dispatch_time_ms: 26.888
    learner:
      cur_lr: 0.0010200069518759847
      grad_gnorm: 40.0
      policy_entropy: 10.843138694763184
      policy_loss: 208.0474090576172
      var_gnorm: 111.06968688964844
      vf_explained_var: 0.0
      vf_loss: 14716.4248046875
    num_steps_sampled: 5110000
    num_steps_trained: 5110000
    wait_time_ms: 53.476
  iterations_since_restore: 1022
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8888.948644638062
  time_this_iter_s: 8.421904802322388
  time_total_s: 8888.948644638062
  timestamp: 1594864924
  timesteps_since_restore: 5110000
  timesteps_this_iter: 5000
  timesteps_total: 5110000
  training_iteration: 1022
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8888 s, 1022 iter, 5110000 ts, -7.28e+04 rew

agent-1: -1063.9686488896316
agent-2: -1114.600638149639
agent-3: -1117.708284906549
agent-4: -967.9843317162816
agent-5: -1303.649037504178
Extrinsic Rewards:
-932
-981
-989
-831
-1134
Sum Reward: -4867
Avg Reward: -973.4
Min Reward: -1134
Max Reward: -831
Gini Coefficient: -0.054489418532977195
20:20 Ratio: 0.7328042328042328
Max-min Ratio: 0.7328042328042328
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-02-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -5567.910941166251
  episode_reward_mean: -71224.8768549322
  episode_reward_min: -165917.56497824454
  episodes_this_iter: 1
  episodes_total: 1022
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.96
    dispatch_time_ms: 31.442
    learner:
      cur_lr: 0.0010196740040555596
      grad_gnorm: 40.0
      policy_entropy: 9.72642993927002
      policy_loss: 534.0623168945312
      var_gnorm: 110.55225372314453
      vf_explained_var: 0.0
      vf_loss: 19016.34765625
    num_steps_sampled: 5115000
    num_steps_trained: 5115000
    wait_time_ms: 47.395
  iterations_since_restore: 1023
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8897.50583076477
  time_this_iter_s: 8.557186126708984
  time_total_s: 8897.50583076477
  timestamp: 1594864932
  timesteps_since_restore: 5115000
  timesteps_this_iter: 5000
  timesteps_total: 5115000
  training_iteration: 1023
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8897 s, 1023 iter, 5115000 ts, -7.12e+04 rew

agent-1: -857.3278479410815
agent-2: -1039.4477071342485
agent-3: -878.4687442096683
agent-4: -1136.6250828847742
agent-5: -835.0649282486094
Extrinsic Rewards:
-729
-874
-720
-969
-673
Sum Reward: -3965
Avg Reward: -793.0
Min Reward: -969
Max Reward: -673
Gini Coefficient: -0.07525851197982346
20:20 Ratio: 0.6945304437564499
Max-min Ratio: 0.6945304437564499
agent-1: -752.5383907112389
agent-2: -644.364993666613
agent-3: -1098.9168587303336
agent-4: -924.743972612177
agent-5: -772.0992783704655
Extrinsic Rewards:
-622
-530
-924
-777
-627
Sum Reward: -3480
Avg Reward: -696.0
Min Reward: -924
Max Reward: -530
Gini Coefficient: -0.10839080459770115
20:20 Ratio: 0.5735930735930735
Max-min Ratio: 0.5735930735930735
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-02-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4192.663494090841
  episode_reward_mean: -69148.60875275187
  episode_reward_min: -165917.56497824454
  episodes_this_iter: 2
  episodes_total: 1024
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 4.265
    dispatch_time_ms: 40.037
    learner:
      cur_lr: 0.0010193410562351346
      grad_gnorm: 40.000003814697266
      policy_entropy: 11.279504776000977
      policy_loss: 208.54046630859375
      var_gnorm: 110.02661895751953
      vf_explained_var: 0.0
      vf_loss: 18977.82421875
    num_steps_sampled: 5120000
    num_steps_trained: 5120000
    wait_time_ms: 38.512
  iterations_since_restore: 1024
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8906.230625867844
  time_this_iter_s: 8.72479510307312
  time_total_s: 8906.230625867844
  timestamp: 1594864941
  timesteps_since_restore: 5120000
  timesteps_this_iter: 5000
  timesteps_total: 5120000
  training_iteration: 1024
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8906 s, 1024 iter, 5120000 ts, -6.91e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-02-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4192.663494090841
  episode_reward_mean: -69148.60875275187
  episode_reward_min: -165917.56497824454
  episodes_this_iter: 0
  episodes_total: 1024
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.979
    dispatch_time_ms: 38.854
    learner:
      cur_lr: 0.0010190079919993877
      grad_gnorm: 40.0
      policy_entropy: 10.917716979980469
      policy_loss: 145.23228454589844
      var_gnorm: 109.49681854248047
      vf_explained_var: 0.0
      vf_loss: 18756.130859375
    num_steps_sampled: 5125000
    num_steps_trained: 5125000
    wait_time_ms: 44.691
  iterations_since_restore: 1025
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8914.368145227432
  time_this_iter_s: 8.137519359588623
  time_total_s: 8914.368145227432
  timestamp: 1594864949
  timesteps_since_restore: 5125000
  timesteps_this_iter: 5000
  timesteps_total: 5125000
  training_iteration: 1025
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8914 s, 1025 iter, 5125000 ts, -6.91e+04 rew

agent-1: -1168.3667505762937
agent-2: -745.6583753470077
agent-3: -737.4329674450333
agent-4: -654.1251724344247
agent-5: -1009.336230189462
Extrinsic Rewards:
-986
-631
-627
-536
-869
Sum Reward: -3649
Avg Reward: -729.8
Min Reward: -986
Max Reward: -536
Gini Coefficient: -0.12518498218690052
20:20 Ratio: 0.5436105476673428
Max-min Ratio: 0.5436105476673428
agent-1: -745.7883174555262
agent-2: -532.2418122703036
agent-3: -1002.6208688625009
agent-4: -1061.454139294668
agent-5: -690.0624789627391
Extrinsic Rewards:
-578
-426
-816
-881
-582
Sum Reward: -3283
Avg Reward: -656.6
Min Reward: -881
Max Reward: -426
Gini Coefficient: -0.13987206823027717
20:20 Ratio: 0.48354143019296253
Max-min Ratio: 0.48354143019296253
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-02-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -66552.5179817844
  episode_reward_min: -164868.28257221455
  episodes_this_iter: 2
  episodes_total: 1026
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.961
    dispatch_time_ms: 45.59
    learner:
      cur_lr: 0.0010186750441789627
      grad_gnorm: 39.99999237060547
      policy_entropy: 12.752206802368164
      policy_loss: 104.67063903808594
      var_gnorm: 108.99069213867188
      vf_explained_var: -0.2808035612106323
      vf_loss: 17513.09765625
    num_steps_sampled: 5130000
    num_steps_trained: 5130000
    wait_time_ms: 62.416
  iterations_since_restore: 1026
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8923.157892465591
  time_this_iter_s: 8.78974723815918
  time_total_s: 8923.157892465591
  timestamp: 1594864958
  timesteps_since_restore: 5130000
  timesteps_this_iter: 5000
  timesteps_total: 5130000
  training_iteration: 1026
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8923 s, 1026 iter, 5130000 ts, -6.66e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-02-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -66552.5179817844
  episode_reward_min: -164868.28257221455
  episodes_this_iter: 0
  episodes_total: 1026
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.568
    dispatch_time_ms: 8.602
    learner:
      cur_lr: 0.0010183419799432158
      grad_gnorm: 39.999996185302734
      policy_entropy: 14.885778427124023
      policy_loss: 583.2225341796875
      var_gnorm: 108.50850677490234
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 13914.2060546875
    num_steps_sampled: 5135000
    num_steps_trained: 5135000
    wait_time_ms: 64.301
  iterations_since_restore: 1027
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8933.758912801743
  time_this_iter_s: 10.601020336151123
  time_total_s: 8933.758912801743
  timestamp: 1594864969
  timesteps_since_restore: 5135000
  timesteps_this_iter: 5000
  timesteps_total: 5135000
  training_iteration: 1027
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8933 s, 1027 iter, 5135000 ts, -6.66e+04 rew

agent-1: -2040.8025880248374
agent-2: -2322.9431233334994
agent-3: -1486.704076883161
agent-4: -3391.5991295292606
agent-5: -2193.035258832734
Extrinsic Rewards:
-1909
-2167
-1402
-3197
-2052
Sum Reward: -10727
Avg Reward: -2145.4
Min Reward: -3197
Max Reward: -1402
Gini Coefficient: -0.14348839377272304
20:20 Ratio: 0.4385361276196434
Max-min Ratio: 0.4385361276196434
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-02-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -65516.78082650613
  episode_reward_min: -164868.28257221455
  episodes_this_iter: 1
  episodes_total: 1027
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 4.456
    dispatch_time_ms: 10.436
    learner:
      cur_lr: 0.0010180090321227908
      grad_gnorm: 40.0
      policy_entropy: 20.45623779296875
      policy_loss: 178.01913452148438
      var_gnorm: 108.27427673339844
      vf_explained_var: 0.0
      vf_loss: 18257.634765625
    num_steps_sampled: 5140000
    num_steps_trained: 5140000
    wait_time_ms: 65.158
  iterations_since_restore: 1028
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8941.601853847504
  time_this_iter_s: 7.842941045761108
  time_total_s: 8941.601853847504
  timestamp: 1594864977
  timesteps_since_restore: 5140000
  timesteps_this_iter: 5000
  timesteps_total: 5140000
  training_iteration: 1028
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8941 s, 1028 iter, 5140000 ts, -6.55e+04 rew

agent-1: -2127.9798731559454
agent-2: -2655.631528586129
agent-3: -2927.3122992655485
agent-4: -3468.615781932088
agent-5: -2394.483298067462
Extrinsic Rewards:
-2005
-2505
-2754
-3258
-2258
Sum Reward: -12780
Avg Reward: -2556.0
Min Reward: -3258
Max Reward: -2005
Gini Coefficient: -0.09395931142410016
20:20 Ratio: 0.6154082259054635
Max-min Ratio: 0.6154082259054635
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-03-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -64456.022997650274
  episode_reward_min: -164868.28257221455
  episodes_this_iter: 1
  episodes_total: 1028
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.16
    dispatch_time_ms: 8.491
    learner:
      cur_lr: 0.001017675967887044
      grad_gnorm: 40.000003814697266
      policy_entropy: 20.333330154418945
      policy_loss: -758.1144409179688
      var_gnorm: 107.90660858154297
      vf_explained_var: 0.0
      vf_loss: 48073.93359375
    num_steps_sampled: 5145000
    num_steps_trained: 5145000
    wait_time_ms: 68.506
  iterations_since_restore: 1029
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8949.596596479416
  time_this_iter_s: 7.9947426319122314
  time_total_s: 8949.596596479416
  timestamp: 1594864985
  timesteps_since_restore: 5145000
  timesteps_this_iter: 5000
  timesteps_total: 5145000
  training_iteration: 1029
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8949 s, 1029 iter, 5145000 ts, -6.45e+04 rew

agent-1: -2192.6751005847245
agent-2: -1876.1889851446567
agent-3: -2580.5547191052965
agent-4: -2026.4533877943354
agent-5: -1862.8665842393982
Extrinsic Rewards:
-2034
-1743
-2421
-1884
-1731
Sum Reward: -9813
Avg Reward: -1962.6
Min Reward: -2421
Max Reward: -1731
Gini Coefficient: -0.06811372668908591
20:20 Ratio: 0.7149938042131351
Max-min Ratio: 0.7149938042131351
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-03-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -63239.45518275381
  episode_reward_min: -164868.28257221455
  episodes_this_iter: 1
  episodes_total: 1029
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.969
    dispatch_time_ms: 10.4
    learner:
      cur_lr: 0.001017343020066619
      grad_gnorm: 40.0
      policy_entropy: 12.048895835876465
      policy_loss: 173.22702026367188
      var_gnorm: 107.559814453125
      vf_explained_var: 0.0
      vf_loss: 16494.455078125
    num_steps_sampled: 5150000
    num_steps_trained: 5150000
    wait_time_ms: 66.131
  iterations_since_restore: 1030
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8957.485122203827
  time_this_iter_s: 7.888525724411011
  time_total_s: 8957.485122203827
  timestamp: 1594864993
  timesteps_since_restore: 5150000
  timesteps_this_iter: 5000
  timesteps_total: 5150000
  training_iteration: 1030
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8957 s, 1030 iter, 5150000 ts, -6.32e+04 rew

agent-1: -2847.6223319002397
agent-2: -1752.7195873809421
agent-3: -1701.3392353036131
agent-4: -2537.0337310292307
agent-5: -3569.6236133392035
Extrinsic Rewards:
-2683
-1633
-1602
-2395
-3374
Sum Reward: -11687
Avg Reward: -2337.4
Min Reward: -3374
Max Reward: -1602
Gini Coefficient: -0.1572345340977154
20:20 Ratio: 0.4748073503260225
Max-min Ratio: 0.4748073503260225
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-03-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -62327.31061393814
  episode_reward_min: -164868.28257221455
  episodes_this_iter: 1
  episodes_total: 1030
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.665
    dispatch_time_ms: 7.871
    learner:
      cur_lr: 0.001017009955830872
      grad_gnorm: 40.0
      policy_entropy: 11.672382354736328
      policy_loss: 292.4312744140625
      var_gnorm: 107.06987762451172
      vf_explained_var: 0.0
      vf_loss: 16044.5673828125
    num_steps_sampled: 5155000
    num_steps_trained: 5155000
    wait_time_ms: 69.755
  iterations_since_restore: 1031
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8965.273104429245
  time_this_iter_s: 7.787982225418091
  time_total_s: 8965.273104429245
  timestamp: 1594865000
  timesteps_since_restore: 5155000
  timesteps_this_iter: 5000
  timesteps_total: 5155000
  training_iteration: 1031
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8965 s, 1031 iter, 5155000 ts, -6.23e+04 rew

agent-1: -326.6311464911842
agent-2: -1911.7556096824524
agent-3: -2513.5834029719135
agent-4: -345.1807565070558
agent-5: -2204.9533436533875
Extrinsic Rewards:
-292
-1734
-2286
-291
-2004
Sum Reward: -6607
Avg Reward: -1321.4
Min Reward: -2286
Max Reward: -291
Gini Coefficient: -0.345209626154079
20:20 Ratio: 0.1272965879265092
Max-min Ratio: 0.1272965879265092
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-03-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -61099.62998431175
  episode_reward_min: -164868.28257221455
  episodes_this_iter: 1
  episodes_total: 1031
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.033
    dispatch_time_ms: 7.918
    learner:
      cur_lr: 0.001016677008010447
      grad_gnorm: 40.000003814697266
      policy_entropy: 11.567293167114258
      policy_loss: 200.37057495117188
      var_gnorm: 106.55447387695312
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 14975.9677734375
    num_steps_sampled: 5160000
    num_steps_trained: 5160000
    wait_time_ms: 66.114
  iterations_since_restore: 1032
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8973.191814422607
  time_this_iter_s: 7.918709993362427
  time_total_s: 8973.191814422607
  timestamp: 1594865008
  timesteps_since_restore: 5160000
  timesteps_this_iter: 5000
  timesteps_total: 5160000
  training_iteration: 1032
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8973 s, 1032 iter, 5160000 ts, -6.11e+04 rew

agent-1: -1031.3095906329927
agent-2: -2012.5072880892155
agent-3: -218.30592744558984
agent-4: -838.3332152290078
agent-5: -1517.9951233527215
Extrinsic Rewards:
-884
-1785
-187
-733
-1340
Sum Reward: -4929
Avg Reward: -985.8
Min Reward: -1785
Max Reward: -187
Gini Coefficient: -0.30862243862852506
20:20 Ratio: 0.10476190476190476
Max-min Ratio: 0.10476190476190476
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-03-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -59967.86572072582
  episode_reward_min: -164868.28257221455
  episodes_this_iter: 1
  episodes_total: 1032
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.122
    dispatch_time_ms: 6.953
    learner:
      cur_lr: 0.0010163439437747002
      grad_gnorm: 40.0
      policy_entropy: 9.816845893859863
      policy_loss: 429.8440856933594
      var_gnorm: 106.07342529296875
      vf_explained_var: 0.0
      vf_loss: 15406.9970703125
    num_steps_sampled: 5165000
    num_steps_trained: 5165000
    wait_time_ms: 69.754
  iterations_since_restore: 1033
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8981.065001487732
  time_this_iter_s: 7.873187065124512
  time_total_s: 8981.065001487732
  timestamp: 1594865016
  timesteps_since_restore: 5165000
  timesteps_this_iter: 5000
  timesteps_total: 5165000
  training_iteration: 1033
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8981 s, 1033 iter, 5165000 ts, -6e+04 rew

agent-1: -80.40390185319146
agent-2: -453.8024398803341
agent-3: -1601.3081683261662
agent-4: -2174.431711935712
agent-5: -3135.1201710863284
Extrinsic Rewards:
-45
-395
-1451
-1981
-2893
Sum Reward: -6765
Avg Reward: -1353.0
Min Reward: -2893
Max Reward: -45
Gini Coefficient: -0.4305691056910569
20:20 Ratio: 0.015554787417905289
Max-min Ratio: 0.015554787417905289
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-03-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -58926.71008998414
  episode_reward_min: -164868.28257221455
  episodes_this_iter: 1
  episodes_total: 1033
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.435
    dispatch_time_ms: 12.9
    learner:
      cur_lr: 0.0010160109959542751
      grad_gnorm: 40.0
      policy_entropy: 13.127606391906738
      policy_loss: 7.843757629394531
      var_gnorm: 105.60274505615234
      vf_explained_var: -0.4851505756378174
      vf_loss: 13876.978515625
    num_steps_sampled: 5170000
    num_steps_trained: 5170000
    wait_time_ms: 64.427
  iterations_since_restore: 1034
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8988.886533498764
  time_this_iter_s: 7.8215320110321045
  time_total_s: 8988.886533498764
  timestamp: 1594865024
  timesteps_since_restore: 5170000
  timesteps_this_iter: 5000
  timesteps_total: 5170000
  training_iteration: 1034
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8988 s, 1034 iter, 5170000 ts, -5.89e+04 rew

agent-1: -1289.3598939584558
agent-2: -1321.316306293945
agent-3: -1061.3468221845608
agent-4: -1002.3572275900887
agent-5: -2069.1562946529552
Extrinsic Rewards:
-1141
-1184
-944
-885
-1877
Sum Reward: -6031
Avg Reward: -1206.2
Min Reward: -1877
Max Reward: -885
Gini Coefficient: -0.14750455977449842
20:20 Ratio: 0.4714970697922216
Max-min Ratio: 0.4714970697922216
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-03-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -58227.11131919195
  episode_reward_min: -164868.28257221455
  episodes_this_iter: 1
  episodes_total: 1034
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.147
    dispatch_time_ms: 9.461
    learner:
      cur_lr: 0.00101567804813385
      grad_gnorm: 40.0
      policy_entropy: 11.748170852661133
      policy_loss: 155.12071228027344
      var_gnorm: 105.10452270507812
      vf_explained_var: 0.0
      vf_loss: 15207.201171875
    num_steps_sampled: 5175000
    num_steps_trained: 5175000
    wait_time_ms: 66.335
  iterations_since_restore: 1035
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 8996.715841770172
  time_this_iter_s: 7.829308271408081
  time_total_s: 8996.715841770172
  timestamp: 1594865032
  timesteps_since_restore: 5175000
  timesteps_this_iter: 5000
  timesteps_total: 5175000
  training_iteration: 1035
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 8996 s, 1035 iter, 5175000 ts, -5.82e+04 rew

agent-1: -637.2673926975071
agent-2: -1232.271108649276
agent-3: -1022.1603629311909
agent-4: -192.37420596312043
agent-5: -1479.7844755593492
Extrinsic Rewards:
-541
-1051
-881
-149
-1289
Sum Reward: -3911
Avg Reward: -782.2
Min Reward: -1289
Max Reward: -149
Gini Coefficient: -0.285349015597034
20:20 Ratio: 0.11559348332040341
Max-min Ratio: 0.11559348332040341
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-04-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -57175.07031663969
  episode_reward_min: -164868.28257221455
  episodes_this_iter: 1
  episodes_total: 1035
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.505
    dispatch_time_ms: 8.608
    learner:
      cur_lr: 0.0010153449838981032
      grad_gnorm: 40.0
      policy_entropy: 14.443161010742188
      policy_loss: 240.4607391357422
      var_gnorm: 104.59230041503906
      vf_explained_var: 0.0
      vf_loss: 16502.587890625
    num_steps_sampled: 5180000
    num_steps_trained: 5180000
    wait_time_ms: 69.8
  iterations_since_restore: 1036
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9004.625921010971
  time_this_iter_s: 7.91007924079895
  time_total_s: 9004.625921010971
  timestamp: 1594865040
  timesteps_since_restore: 5180000
  timesteps_this_iter: 5000
  timesteps_total: 5180000
  training_iteration: 1036
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9004 s, 1036 iter, 5180000 ts, -5.72e+04 rew

agent-1: -610.884754004222
agent-2: -1146.3432224809635
agent-3: -1208.2033835524624
agent-4: -634.5223017848955
agent-5: -1885.393554607537
Extrinsic Rewards:
-532
-991
-1042
-544
-1692
Sum Reward: -4801
Avg Reward: -960.2
Min Reward: -1692
Max Reward: -532
Gini Coefficient: -0.23478441991251822
20:20 Ratio: 0.3144208037825059
Max-min Ratio: 0.3144208037825059
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-04-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -56467.007420834794
  episode_reward_min: -164868.28257221455
  episodes_this_iter: 1
  episodes_total: 1036
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.563
    dispatch_time_ms: 7.441
    learner:
      cur_lr: 0.0010150120360776782
      grad_gnorm: 39.999996185302734
      policy_entropy: 15.77047348022461
      policy_loss: 283.187255859375
      var_gnorm: 104.10216522216797
      vf_explained_var: 0.0
      vf_loss: 20076.224609375
    num_steps_sampled: 5185000
    num_steps_trained: 5185000
    wait_time_ms: 70.499
  iterations_since_restore: 1037
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9012.485184907913
  time_this_iter_s: 7.859263896942139
  time_total_s: 9012.485184907913
  timestamp: 1594865048
  timesteps_since_restore: 5185000
  timesteps_this_iter: 5000
  timesteps_total: 5185000
  training_iteration: 1037
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9012 s, 1037 iter, 5185000 ts, -5.65e+04 rew

agent-1: -1546.742239751856
agent-2: -1789.9415085768696
agent-3: -1738.2963332415975
agent-4: -1889.009165774346
agent-5: -3225.3708332665374
Extrinsic Rewards:
-1400
-1656
-1590
-1792
-3042
Sum Reward: -9480
Avg Reward: -1896.0
Min Reward: -3042
Max Reward: -1400
Gini Coefficient: -0.14708860759493672
20:20 Ratio: 0.46022353714661407
Max-min Ratio: 0.46022353714661407
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-04-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -54920.21819591876
  episode_reward_min: -145202.82094878572
  episodes_this_iter: 1
  episodes_total: 1037
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.722
    dispatch_time_ms: 23.947
    learner:
      cur_lr: 0.0010146789718419313
      grad_gnorm: 40.0
      policy_entropy: 31.0323429107666
      policy_loss: 50.89368438720703
      var_gnorm: 103.8447036743164
      vf_explained_var: 0.0
      vf_loss: 52752.796875
    num_steps_sampled: 5190000
    num_steps_trained: 5190000
    wait_time_ms: 57.595
  iterations_since_restore: 1038
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9021.024588108063
  time_this_iter_s: 8.539403200149536
  time_total_s: 9021.024588108063
  timestamp: 1594865056
  timesteps_since_restore: 5190000
  timesteps_this_iter: 5000
  timesteps_total: 5190000
  training_iteration: 1038
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9021 s, 1038 iter, 5190000 ts, -5.49e+04 rew

agent-1: -2850.954181201095
agent-2: -1406.5609968468311
agent-3: -1989.9635855331317
agent-4: -3765.01387018779
agent-5: -3314.526811083849
Extrinsic Rewards:
-2695
-1344
-1858
-3596
-3134
Sum Reward: -12627
Avg Reward: -2525.4
Min Reward: -3596
Max Reward: -1344
Gini Coefficient: -0.18309970697711253
20:20 Ratio: 0.37374860956618466
Max-min Ratio: 0.37374860956618466
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-04-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -53943.3730033334
  episode_reward_min: -145202.82094878572
  episodes_this_iter: 1
  episodes_total: 1038
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.822
    dispatch_time_ms: 24.366
    learner:
      cur_lr: 0.0010143460240215063
      grad_gnorm: 40.0
      policy_entropy: 40.04194641113281
      policy_loss: -42.51823425292969
      var_gnorm: 104.10289001464844
      vf_explained_var: 0.0
      vf_loss: 14126.4912109375
    num_steps_sampled: 5195000
    num_steps_trained: 5195000
    wait_time_ms: 60.402
  iterations_since_restore: 1039
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9029.603645324707
  time_this_iter_s: 8.579057216644287
  time_total_s: 9029.603645324707
  timestamp: 1594865065
  timesteps_since_restore: 5195000
  timesteps_this_iter: 5000
  timesteps_total: 5195000
  training_iteration: 1039
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9029 s, 1039 iter, 5195000 ts, -5.39e+04 rew

agent-1: -5473.170676470127
agent-2: -11510.487046386072
agent-3: -13714.84689518921
agent-4: -5023.102946868134
agent-5: -5659.203259622605
Extrinsic Rewards:
-5368
-11312
-13500
-4922
-5556
Sum Reward: -40658
Avg Reward: -8131.6
Min Reward: -13500
Max Reward: -4922
Gini Coefficient: -0.227261547542919
20:20 Ratio: 0.3645925925925926
Max-min Ratio: 0.3645925925925926
agent-1: -14819.29315158001
agent-2: -14059.085098514737
agent-3: -11714.794751120364
agent-4: -12158.326644860786
agent-5: -10785.278520197486
Extrinsic Rewards:
-14667
-13890
-11577
-12007
-10639
Sum Reward: -62780
Avg Reward: -12556.0
Min Reward: -14667
Max Reward: -10639
Gini Coefficient: -0.06606562599553999
20:20 Ratio: 0.7253698779573191
Max-min Ratio: 0.7253698779573191
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-04-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -52596.91222102633
  episode_reward_min: -145202.82094878572
  episodes_this_iter: 2
  episodes_total: 1040
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.721
    dispatch_time_ms: 6.921
    learner:
      cur_lr: 0.0010140129597857594
      grad_gnorm: 40.0
      policy_entropy: 37.215240478515625
      policy_loss: 17677.291015625
      var_gnorm: 104.54863739013672
      vf_explained_var: 0.0
      vf_loss: 3902204.75
    num_steps_sampled: 5200000
    num_steps_trained: 5200000
    wait_time_ms: 71.071
  iterations_since_restore: 1040
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9037.846063137054
  time_this_iter_s: 8.242417812347412
  time_total_s: 9037.846063137054
  timestamp: 1594865073
  timesteps_since_restore: 5200000
  timesteps_this_iter: 5000
  timesteps_total: 5200000
  training_iteration: 1040
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9037 s, 1040 iter, 5200000 ts, -5.26e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-04-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -52596.912221026316
  episode_reward_min: -145202.82094878572
  episodes_this_iter: 0
  episodes_total: 1040
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.787
    dispatch_time_ms: 8.661
    learner:
      cur_lr: 0.0010136800119653344
      grad_gnorm: 40.0
      policy_entropy: 35.51224136352539
      policy_loss: -4093.64404296875
      var_gnorm: 104.96214294433594
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 505594.03125
    num_steps_sampled: 5205000
    num_steps_trained: 5205000
    wait_time_ms: 69.984
  iterations_since_restore: 1041
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9046.007871866226
  time_this_iter_s: 8.161808729171753
  time_total_s: 9046.007871866226
  timestamp: 1594865081
  timesteps_since_restore: 5205000
  timesteps_this_iter: 5000
  timesteps_total: 5205000
  training_iteration: 1041
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9046 s, 1041 iter, 5205000 ts, -5.26e+04 rew

agent-1: -24013.0382254568
agent-2: -20544.653994019674
agent-3: -16747.431837397886
agent-4: -19776.28873405657
agent-5: -16391.011232242174
Extrinsic Rewards:
-23842
-20384
-16616
-19619
-16259
Sum Reward: -96720
Avg Reward: -19344.0
Min Reward: -23842
Max Reward: -16259
Gini Coefficient: -0.07830438378825476
20:20 Ratio: 0.6819478231691972
Max-min Ratio: 0.6819478231691972
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-04-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -52119.608251770194
  episode_reward_min: -144024.67442711102
  episodes_this_iter: 1
  episodes_total: 1041
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.663
    dispatch_time_ms: 9.448
    learner:
      cur_lr: 0.0010133469477295876
      grad_gnorm: 40.0
      policy_entropy: 34.83487319946289
      policy_loss: -978.3212890625
      var_gnorm: 105.454345703125
      vf_explained_var: 0.0
      vf_loss: 96028.296875
    num_steps_sampled: 5210000
    num_steps_trained: 5210000
    wait_time_ms: 73.665
  iterations_since_restore: 1042
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9054.375385284424
  time_this_iter_s: 8.367513418197632
  time_total_s: 9054.375385284424
  timestamp: 1594865090
  timesteps_since_restore: 5210000
  timesteps_this_iter: 5000
  timesteps_total: 5210000
  training_iteration: 1042
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9054 s, 1042 iter, 5210000 ts, -5.21e+04 rew

agent-1: -25584.475979915398
agent-2: -13734.101618593704
agent-3: -20350.977848660063
agent-4: -33621.55944216498
agent-5: -7042.187226815586
Extrinsic Rewards:
-25401
-13627
-20188
-33411
-6990
Sum Reward: -99617
Avg Reward: -19923.4
Min Reward: -33411
Max Reward: -6990
Gini Coefficient: -0.2594577230793941
20:20 Ratio: 0.20921253479393015
Max-min Ratio: 0.20921253479393015
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-04-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -51682.69452866058
  episode_reward_min: -124577.78924287125
  episodes_this_iter: 1
  episodes_total: 1042
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.884
    dispatch_time_ms: 6.528
    learner:
      cur_lr: 0.0010130139999091625
      grad_gnorm: 40.0
      policy_entropy: 35.611942291259766
      policy_loss: -1576.417236328125
      var_gnorm: 105.9211654663086
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 481174.78125
    num_steps_sampled: 5215000
    num_steps_trained: 5215000
    wait_time_ms: 77.049
  iterations_since_restore: 1043
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9062.74570441246
  time_this_iter_s: 8.370319128036499
  time_total_s: 9062.74570441246
  timestamp: 1594865098
  timesteps_since_restore: 5215000
  timesteps_this_iter: 5000
  timesteps_total: 5215000
  training_iteration: 1043
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9062 s, 1043 iter, 5215000 ts, -5.17e+04 rew

agent-1: -23397.197872230354
agent-2: -26555.390053282954
agent-3: -21332.912978031014
agent-4: -13209.309271492655
agent-5: -32104.351002816802
Extrinsic Rewards:
-23237
-26382
-21190
-13130
-31921
Sum Reward: -115860
Avg Reward: -23172.0
Min Reward: -31921
Max Reward: -13130
Gini Coefficient: -0.14767477990678404
20:20 Ratio: 0.41132796591585474
Max-min Ratio: 0.41132796591585474
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-05-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -51602.90824801042
  episode_reward_min: -120578.126889361
  episodes_this_iter: 1
  episodes_total: 1043
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.852
    dispatch_time_ms: 7.346
    learner:
      cur_lr: 0.0010126810520887375
      grad_gnorm: 40.0
      policy_entropy: 31.063114166259766
      policy_loss: -5333.73388671875
      var_gnorm: 106.36324310302734
      vf_explained_var: 0.0
      vf_loss: 943162.25
    num_steps_sampled: 5220000
    num_steps_trained: 5220000
    wait_time_ms: 75.873
  iterations_since_restore: 1044
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9071.05024766922
  time_this_iter_s: 8.304543256759644
  time_total_s: 9071.05024766922
  timestamp: 1594865107
  timesteps_since_restore: 5220000
  timesteps_this_iter: 5000
  timesteps_total: 5220000
  training_iteration: 1044
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9071 s, 1044 iter, 5220000 ts, -5.16e+04 rew

agent-1: -16977.29517696776
agent-2: -19824.596338639843
agent-3: -11188.624244069457
agent-4: -11883.176763320223
agent-5: -17454.681449359006
Extrinsic Rewards:
-16816
-19646
-11083
-11763
-17286
Sum Reward: -76594
Avg Reward: -15318.8
Min Reward: -19646
Max Reward: -11083
Gini Coefficient: -0.11828080528500927
20:20 Ratio: 0.5641351929145882
Max-min Ratio: 0.5641351929145882
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-05-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -51418.17607338643
  episode_reward_min: -120578.126889361
  episodes_this_iter: 1
  episodes_total: 1044
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.354
    dispatch_time_ms: 10.434
    learner:
      cur_lr: 0.0010123479878529906
      grad_gnorm: 39.99999237060547
      policy_entropy: 38.62730407714844
      policy_loss: -3500.931396484375
      var_gnorm: 106.80724334716797
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 315878.59375
    num_steps_sampled: 5225000
    num_steps_trained: 5225000
    wait_time_ms: 71.591
  iterations_since_restore: 1045
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9079.299185276031
  time_this_iter_s: 8.248937606811523
  time_total_s: 9079.299185276031
  timestamp: 1594865115
  timesteps_since_restore: 5225000
  timesteps_this_iter: 5000
  timesteps_total: 5225000
  training_iteration: 1045
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9079 s, 1045 iter, 5225000 ts, -5.14e+04 rew

agent-1: -21974.459259262683
agent-2: -8894.847800976955
agent-3: -16632.214884966328
agent-4: -6080.768429422525
agent-5: -14662.824207408356
Extrinsic Rewards:
-21761
-8800
-16463
-6001
-14517
Sum Reward: -67542
Avg Reward: -13508.4
Min Reward: -21761
Max Reward: -6001
Gini Coefficient: -0.2320511681620325
20:20 Ratio: 0.2757685768117274
Max-min Ratio: 0.2757685768117274
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-05-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -51303.06439511357
  episode_reward_min: -120578.126889361
  episodes_this_iter: 1
  episodes_total: 1045
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.581
    dispatch_time_ms: 5.739
    learner:
      cur_lr: 0.0010120150400325656
      grad_gnorm: 39.999996185302734
      policy_entropy: 36.67798614501953
      policy_loss: -4353.94921875
      var_gnorm: 107.20433807373047
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 340700.65625
    num_steps_sampled: 5230000
    num_steps_trained: 5230000
    wait_time_ms: 77.579
  iterations_since_restore: 1046
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9087.561027765274
  time_this_iter_s: 8.261842489242554
  time_total_s: 9087.561027765274
  timestamp: 1594865123
  timesteps_since_restore: 5230000
  timesteps_this_iter: 5000
  timesteps_total: 5230000
  training_iteration: 1046
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9087 s, 1046 iter, 5230000 ts, -5.13e+04 rew

agent-1: -24358.59628800696
agent-2: -25126.75339280775
agent-3: -4963.169128427645
agent-4: -12767.665519578106
agent-5: -14034.212924475469
Extrinsic Rewards:
-24150
-24924
-4915
-12641
-13913
Sum Reward: -80543
Avg Reward: -16108.6
Min Reward: -24924
Max Reward: -4915
Gini Coefficient: -0.25589809170256883
20:20 Ratio: 0.19719948643877389
Max-min Ratio: 0.19719948643877389
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-05-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -50998.261498253334
  episode_reward_min: -120578.126889361
  episodes_this_iter: 1
  episodes_total: 1046
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.681
    dispatch_time_ms: 19.739
    learner:
      cur_lr: 0.0010116819757968187
      grad_gnorm: 40.0
      policy_entropy: 38.01123809814453
      policy_loss: -2207.6416015625
      var_gnorm: 107.65202331542969
      vf_explained_var: 0.0
      vf_loss: 223338.265625
    num_steps_sampled: 5235000
    num_steps_trained: 5235000
    wait_time_ms: 63.417
  iterations_since_restore: 1047
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9096.036520719528
  time_this_iter_s: 8.47549295425415
  time_total_s: 9096.036520719528
  timestamp: 1594865132
  timesteps_since_restore: 5235000
  timesteps_this_iter: 5000
  timesteps_total: 5235000
  training_iteration: 1047
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9096 s, 1047 iter, 5235000 ts, -5.1e+04 rew

agent-1: -18383.949249018344
agent-2: -19451.874327152065
agent-3: -13751.530980595475
agent-4: -15835.872679970058
agent-5: -11618.997896670186
Extrinsic Rewards:
-18220
-19271
-13613
-15693
-11517
Sum Reward: -78314
Avg Reward: -15662.8
Min Reward: -19271
Max Reward: -11517
Gini Coefficient: -0.1027402507853002
20:20 Ratio: 0.5976337501945929
Max-min Ratio: 0.5976337501945929
agent-1: -17302.612245546246
agent-2: -5079.933607939199
agent-3: -13724.842480639225
agent-4: -16450.969375220135
agent-5: -27654.841187386
Extrinsic Rewards:
-17141
-5028
-13589
-16294
-27434
Sum Reward: -79486
Avg Reward: -15897.2
Min Reward: -27434
Max Reward: -5028
Gini Coefficient: -0.24338374053292403
20:20 Ratio: 0.18327622658015602
Max-min Ratio: 0.18327622658015602
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-05-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -50718.929737485174
  episode_reward_min: -118699.63997368302
  episodes_this_iter: 2
  episodes_total: 1048
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.851
    dispatch_time_ms: 31.017
    learner:
      cur_lr: 0.0010113490279763937
      grad_gnorm: 40.0
      policy_entropy: 39.40714645385742
      policy_loss: -2766.505615234375
      var_gnorm: 108.10356903076172
      vf_explained_var: -0.18911194801330566
      vf_loss: 263158.71875
    num_steps_sampled: 5240000
    num_steps_trained: 5240000
    wait_time_ms: 41.268
  iterations_since_restore: 1048
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9104.814182043076
  time_this_iter_s: 8.777661323547363
  time_total_s: 9104.814182043076
  timestamp: 1594865140
  timesteps_since_restore: 5240000
  timesteps_this_iter: 5000
  timesteps_total: 5240000
  training_iteration: 1048
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9104 s, 1048 iter, 5240000 ts, -5.07e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-05-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -50718.929737485174
  episode_reward_min: -118699.63997368302
  episodes_this_iter: 0
  episodes_total: 1048
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.744
    dispatch_time_ms: 31.316
    learner:
      cur_lr: 0.0010110159637406468
      grad_gnorm: 40.0
      policy_entropy: 39.042945861816406
      policy_loss: -7493.00732421875
      var_gnorm: 108.54938507080078
      vf_explained_var: 0.0
      vf_loss: 1159834.125
    num_steps_sampled: 5245000
    num_steps_trained: 5245000
    wait_time_ms: 54.627
  iterations_since_restore: 1049
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9113.57859826088
  time_this_iter_s: 8.764416217803955
  time_total_s: 9113.57859826088
  timestamp: 1594865149
  timesteps_since_restore: 5245000
  timesteps_this_iter: 5000
  timesteps_total: 5245000
  training_iteration: 1049
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9113 s, 1049 iter, 5245000 ts, -5.07e+04 rew

agent-1: -13842.52543852472
agent-2: -24733.38048477797
agent-3: -10921.309435670439
agent-4: -12756.442568939767
agent-5: -14989.445783694926
Extrinsic Rewards:
-13706
-24527
-10808
-12629
-14845
Sum Reward: -76515
Avg Reward: -15303.0
Min Reward: -24527
Max Reward: -10808
Gini Coefficient: -0.15502319806573875
20:20 Ratio: 0.4406572348840054
Max-min Ratio: 0.4406572348840054
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-05-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -51036.52356812514
  episode_reward_min: -118699.63997368302
  episodes_this_iter: 1
  episodes_total: 1049
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.92
    dispatch_time_ms: 33.6
    learner:
      cur_lr: 0.0010106830159202218
      grad_gnorm: 40.0
      policy_entropy: 36.43122100830078
      policy_loss: -942.6973266601562
      var_gnorm: 109.00560760498047
      vf_explained_var: 0.0
      vf_loss: 186651.0625
    num_steps_sampled: 5250000
    num_steps_trained: 5250000
    wait_time_ms: 59.144
  iterations_since_restore: 1050
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9122.530412197113
  time_this_iter_s: 8.95181393623352
  time_total_s: 9122.530412197113
  timestamp: 1594865158
  timesteps_since_restore: 5250000
  timesteps_this_iter: 5000
  timesteps_total: 5250000
  training_iteration: 1050
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9122 s, 1050 iter, 5250000 ts, -5.1e+04 rew

agent-1: -10357.836718467306
agent-2: -23342.320274451005
agent-3: -19358.348473495444
agent-4: -22339.083927024167
agent-5: -22805.803179656126
Extrinsic Rewards:
-10265
-23168
-19201
-22167
-22648
Sum Reward: -97449
Avg Reward: -19489.8
Min Reward: -23168
Max Reward: -10265
Gini Coefficient: -0.12007511621463535
20:20 Ratio: 0.44306802486187846
Max-min Ratio: 0.44306802486187846
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-06-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -51690.64808531568
  episode_reward_min: -118699.63997368302
  episodes_this_iter: 1
  episodes_total: 1050
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.053
    dispatch_time_ms: 25.435
    learner:
      cur_lr: 0.001010349951684475
      grad_gnorm: 40.0
      policy_entropy: 29.196067810058594
      policy_loss: -3801.854736328125
      var_gnorm: 109.48373413085938
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 2156878.75
    num_steps_sampled: 5255000
    num_steps_trained: 5255000
    wait_time_ms: 57.298
  iterations_since_restore: 1051
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9131.433188438416
  time_this_iter_s: 8.90277624130249
  time_total_s: 9131.433188438416
  timestamp: 1594865167
  timesteps_since_restore: 5255000
  timesteps_this_iter: 5000
  timesteps_total: 5255000
  training_iteration: 1051
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9131 s, 1051 iter, 5255000 ts, -5.17e+04 rew

agent-1: -35213.217666029326
agent-2: -22386.2600261315
agent-3: -58429.082297842884
agent-4: -4003.6580514999796
agent-5: -42296.64499714229
Extrinsic Rewards:
-35044
-22280
-58201
-3986
-42114
Sum Reward: -161625
Avg Reward: -32325.0
Min Reward: -58201
Max Reward: -3986
Gini Coefficient: -0.31743604021655064
20:20 Ratio: 0.06848679575952303
Max-min Ratio: 0.06848679575952303
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-06-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -53094.99792469969
  episode_reward_min: -162328.86303864562
  episodes_this_iter: 1
  episodes_total: 1051
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.473
    dispatch_time_ms: 31.075
    learner:
      cur_lr: 0.00101001700386405
      grad_gnorm: 39.999996185302734
      policy_entropy: 25.682353973388672
      policy_loss: -430.9955139160156
      var_gnorm: 109.9817886352539
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 377701.59375
    num_steps_sampled: 5260000
    num_steps_trained: 5260000
    wait_time_ms: 52.98
  iterations_since_restore: 1052
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9140.28186416626
  time_this_iter_s: 8.848675727844238
  time_total_s: 9140.28186416626
  timestamp: 1594865176
  timesteps_since_restore: 5260000
  timesteps_this_iter: 5000
  timesteps_total: 5260000
  training_iteration: 1052
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9140 s, 1052 iter, 5260000 ts, -5.31e+04 rew

agent-1: -30285.854942261238
agent-2: -18822.898049307554
agent-3: -25965.46601767158
agent-4: -12744.811408596543
agent-5: -38718.01665599165
Extrinsic Rewards:
-30107
-18715
-25803
-12666
-38509
Sum Reward: -125800
Avg Reward: -25160.0
Min Reward: -38509
Max Reward: -12666
Gini Coefficient: -0.20056597774244833
20:20 Ratio: 0.3289101249058662
Max-min Ratio: 0.3289101249058662
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-06-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -54161.2922803719
  episode_reward_min: -162328.86303864562
  episodes_this_iter: 1
  episodes_total: 1052
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.387
    dispatch_time_ms: 21.991
    learner:
      cur_lr: 0.0010096840560436249
      grad_gnorm: 40.0
      policy_entropy: 34.305912017822266
      policy_loss: -1214.0931396484375
      var_gnorm: 110.41645050048828
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 97462.9453125
    num_steps_sampled: 5265000
    num_steps_trained: 5265000
    wait_time_ms: 79.308
  iterations_since_restore: 1053
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9149.411116600037
  time_this_iter_s: 9.129252433776855
  time_total_s: 9149.411116600037
  timestamp: 1594865185
  timesteps_since_restore: 5265000
  timesteps_this_iter: 5000
  timesteps_total: 5265000
  training_iteration: 1053
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9149 s, 1053 iter, 5265000 ts, -5.42e+04 rew

agent-1: -16884.78029145637
agent-2: -9160.170825148789
agent-3: -13411.105409532542
agent-4: -26483.14456156726
agent-5: -23701.24396789425
Extrinsic Rewards:
-16760
-9086
-13285
-26289
-23520
Sum Reward: -88940
Avg Reward: -17788.0
Min Reward: -26289
Max Reward: -9086
Gini Coefficient: -0.20076905779176973
20:20 Ratio: 0.3456198409981361
Max-min Ratio: 0.3456198409981361
agent-1: -20161.618458617308
agent-2: -17898.582078834104
agent-3: -10106.839498245423
agent-4: -19991.282170060276
agent-5: -14473.051696410272
Extrinsic Rewards:
-19987
-17741
-10013
-19815
-14336
Sum Reward: -81892
Avg Reward: -16378.4
Min Reward: -19987
Max Reward: -10013
Gini Coefficient: -0.12419772383138768
20:20 Ratio: 0.5009756341622055
Max-min Ratio: 0.5009756341622055
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-06-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -54841.51192873647
  episode_reward_min: -162328.86303864562
  episodes_this_iter: 1
  episodes_total: 1053
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.166
    dispatch_time_ms: 33.706
    learner:
      cur_lr: 0.001009350991807878
      grad_gnorm: 40.0
      policy_entropy: 30.312490463256836
      policy_loss: -1655.197021484375
      var_gnorm: 110.84288024902344
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 330597.78125
    num_steps_sampled: 5270000
    num_steps_trained: 5270000
    wait_time_ms: 63.095
  iterations_since_restore: 1054
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9158.362164020538
  time_this_iter_s: 8.951047420501709
  time_total_s: 9158.362164020538
  timestamp: 1594865194
  timesteps_since_restore: 5270000
  timesteps_this_iter: 5000
  timesteps_total: 5270000
  training_iteration: 1054
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9158 s, 1054 iter, 5270000 ts, -5.48e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-06-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -55337.133493467656
  episode_reward_min: -162328.86303864562
  episodes_this_iter: 1
  episodes_total: 1054
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.463
    dispatch_time_ms: 24.937
    learner:
      cur_lr: 0.001009018043987453
      grad_gnorm: 40.0
      policy_entropy: 34.55261993408203
      policy_loss: -3320.037109375
      var_gnorm: 111.31767272949219
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 554564.625
    num_steps_sampled: 5275000
    num_steps_trained: 5275000
    wait_time_ms: 64.755
  iterations_since_restore: 1055
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9167.215423345566
  time_this_iter_s: 8.853259325027466
  time_total_s: 9167.215423345566
  timestamp: 1594865203
  timesteps_since_restore: 5275000
  timesteps_this_iter: 5000
  timesteps_total: 5275000
  training_iteration: 1055
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9167 s, 1055 iter, 5275000 ts, -5.53e+04 rew

agent-1: -14352.561254823439
agent-2: -35101.38354293684
agent-3: -42108.33645391188
agent-4: -29156.02983228928
agent-5: -15947.139344148707
Extrinsic Rewards:
-14263
-34912
-41901
-28999
-15856
Sum Reward: -135931
Avg Reward: -27186.2
Min Reward: -41901
Max Reward: -14263
Gini Coefficient: -0.21873450500621638
20:20 Ratio: 0.3403976038758025
Max-min Ratio: 0.3403976038758025
agent-1: -26913.19425099141
agent-2: -15524.613962108308
agent-3: -22303.75202728255
agent-4: -29730.948402664246
agent-5: -18626.74111924945
Extrinsic Rewards:
-26740
-15415
-22159
-29545
-18494
Sum Reward: -112353
Avg Reward: -22470.6
Min Reward: -29545
Max Reward: -15415
Gini Coefficient: -0.12996893718903813
20:20 Ratio: 0.5217464884075139
Max-min Ratio: 0.5217464884075139
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-06-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -57202.352032338706
  episode_reward_min: -162328.86303864562
  episodes_this_iter: 2
  episodes_total: 1056
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.989
    dispatch_time_ms: 24.372
    learner:
      cur_lr: 0.0010086849797517061
      grad_gnorm: 39.999996185302734
      policy_entropy: 20.869182586669922
      policy_loss: -164.7140350341797
      var_gnorm: 111.82228088378906
      vf_explained_var: 0.0
      vf_loss: 153616.03125
    num_steps_sampled: 5280000
    num_steps_trained: 5280000
    wait_time_ms: 57.489
  iterations_since_restore: 1056
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9179.855821371078
  time_this_iter_s: 12.640398025512695
  time_total_s: 9179.855821371078
  timestamp: 1594865216
  timesteps_since_restore: 5280000
  timesteps_this_iter: 5000
  timesteps_total: 5280000
  training_iteration: 1056
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9179 s, 1056 iter, 5280000 ts, -5.72e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-07-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -57202.352032338706
  episode_reward_min: -162328.86303864562
  episodes_this_iter: 0
  episodes_total: 1056
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.66
    dispatch_time_ms: 6.468
    learner:
      cur_lr: 0.001008352031931281
      grad_gnorm: 40.000003814697266
      policy_entropy: 27.003074645996094
      policy_loss: -622.968505859375
      var_gnorm: 112.3039779663086
      vf_explained_var: 0.0
      vf_loss: 179438.21875
    num_steps_sampled: 5285000
    num_steps_trained: 5285000
    wait_time_ms: 78.168
  iterations_since_restore: 1057
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9188.461689472198
  time_this_iter_s: 8.605868101119995
  time_total_s: 9188.461689472198
  timestamp: 1594865224
  timesteps_since_restore: 5285000
  timesteps_this_iter: 5000
  timesteps_total: 5285000
  training_iteration: 1057
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9188 s, 1057 iter, 5285000 ts, -5.72e+04 rew

agent-1: -31860.863365981546
agent-2: -20445.12353339116
agent-3: -40943.93257348436
agent-4: -26354.57825776881
agent-5: -10586.66861786636
Extrinsic Rewards:
-31682
-20328
-40731
-26205
-10520
Sum Reward: -129466
Avg Reward: -25893.2
Min Reward: -40731
Max Reward: -10520
Gini Coefficient: -0.2217601532448674
20:20 Ratio: 0.2582799342024502
Max-min Ratio: 0.2582799342024502
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-07-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -58316.15934784882
  episode_reward_min: -162328.86303864562
  episodes_this_iter: 1
  episodes_total: 1057
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.953
    dispatch_time_ms: 9.596
    learner:
      cur_lr: 0.0010080189676955342
      grad_gnorm: 40.0
      policy_entropy: 33.8227653503418
      policy_loss: -1309.7349853515625
      var_gnorm: 112.76229858398438
      vf_explained_var: -0.22684884071350098
      vf_loss: 288723.34375
    num_steps_sampled: 5290000
    num_steps_trained: 5290000
    wait_time_ms: 71.193
  iterations_since_restore: 1058
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9196.869639158249
  time_this_iter_s: 8.407949686050415
  time_total_s: 9196.869639158249
  timestamp: 1594865233
  timesteps_since_restore: 5290000
  timesteps_this_iter: 5000
  timesteps_total: 5290000
  training_iteration: 1058
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9196 s, 1058 iter, 5290000 ts, -5.83e+04 rew

agent-1: -17401.731776067674
agent-2: -20623.469215050613
agent-3: -26245.457625501625
agent-4: -18649.578645579437
agent-5: -21635.67611359238
Extrinsic Rewards:
-17268
-20476
-26074
-18516
-21487
Sum Reward: -103821
Avg Reward: -20764.2
Min Reward: -26074
Max Reward: -17268
Gini Coefficient: -0.07930187534313868
20:20 Ratio: 0.6622689269003605
Max-min Ratio: 0.6622689269003605
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-07-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -59043.49446037478
  episode_reward_min: -162328.86303864562
  episodes_this_iter: 1
  episodes_total: 1058
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.929
    dispatch_time_ms: 7.589
    learner:
      cur_lr: 0.0010076860198751092
      grad_gnorm: 40.0
      policy_entropy: 41.977081298828125
      policy_loss: -5112.0732421875
      var_gnorm: 113.23509216308594
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 1468688.0
    num_steps_sampled: 5295000
    num_steps_trained: 5295000
    wait_time_ms: 75.167
  iterations_since_restore: 1059
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9205.342341184616
  time_this_iter_s: 8.472702026367188
  time_total_s: 9205.342341184616
  timestamp: 1594865241
  timesteps_since_restore: 5295000
  timesteps_this_iter: 5000
  timesteps_total: 5295000
  training_iteration: 1059
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9205 s, 1059 iter, 5295000 ts, -5.9e+04 rew

agent-1: -23877.811932639732
agent-2: -31694.970387281835
agent-3: -21465.893164198642
agent-4: -34199.33907405156
agent-5: -22840.7773119544
Extrinsic Rewards:
-23743
-31532
-21335
-34013
-22714
Sum Reward: -133337
Avg Reward: -26667.4
Min Reward: -34013
Max Reward: -21335
Gini Coefficient: -0.10251918072253013
20:20 Ratio: 0.6272601652309411
Max-min Ratio: 0.6272601652309411
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-07-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -60139.055940372404
  episode_reward_min: -162328.86303864562
  episodes_this_iter: 1
  episodes_total: 1059
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.872
    dispatch_time_ms: 6.726
    learner:
      cur_lr: 0.0010073529556393623
      grad_gnorm: 39.999996185302734
      policy_entropy: 39.41252136230469
      policy_loss: 796.16552734375
      var_gnorm: 113.7286376953125
      vf_explained_var: 0.0
      vf_loss: 16895.833984375
    num_steps_sampled: 5300000
    num_steps_trained: 5300000
    wait_time_ms: 75.182
  iterations_since_restore: 1060
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9213.837527990341
  time_this_iter_s: 8.495186805725098
  time_total_s: 9213.837527990341
  timestamp: 1594865250
  timesteps_since_restore: 5300000
  timesteps_this_iter: 5000
  timesteps_total: 5300000
  training_iteration: 1060
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9213 s, 1060 iter, 5300000 ts, -6.01e+04 rew

agent-1: -18437.902481319914
agent-2: -18597.129070454743
agent-3: -23289.553802304355
agent-4: -22849.401076914623
agent-5: -19611.624098781333
Extrinsic Rewards:
-18296
-18461
-23125
-22686
-19468
Sum Reward: -102036
Avg Reward: -20407.2
Min Reward: -23125
Max Reward: -18296
Gini Coefficient: -0.0544239288094398
20:20 Ratio: 0.7911783783783783
Max-min Ratio: 0.7911783783783783
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-07-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -60946.22246625666
  episode_reward_min: -162328.86303864562
  episodes_this_iter: 1
  episodes_total: 1060
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.959
    dispatch_time_ms: 7.851
    learner:
      cur_lr: 0.0010070200078189373
      grad_gnorm: 40.0
      policy_entropy: 33.57639694213867
      policy_loss: -9260.4970703125
      var_gnorm: 114.19052124023438
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 3914141.25
    num_steps_sampled: 5305000
    num_steps_trained: 5305000
    wait_time_ms: 75.48
  iterations_since_restore: 1061
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9222.243143558502
  time_this_iter_s: 8.40561556816101
  time_total_s: 9222.243143558502
  timestamp: 1594865258
  timesteps_since_restore: 5305000
  timesteps_this_iter: 5000
  timesteps_total: 5305000
  training_iteration: 1061
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9222 s, 1061 iter, 5305000 ts, -6.09e+04 rew

agent-1: -32234.66094681
agent-2: -25462.028754475417
agent-3: -28009.617785242768
agent-4: -22809.96420443654
agent-5: -28538.71760010732
Extrinsic Rewards:
-32061
-25310
-27870
-22678
-28388
Sum Reward: -136307
Avg Reward: -27261.4
Min Reward: -32061
Max Reward: -22678
Gini Coefficient: -0.06410235717901502
20:20 Ratio: 0.7073391347743364
Max-min Ratio: 0.7073391347743364
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-07-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -61962.52356164285
  episode_reward_min: -162328.86303864562
  episodes_this_iter: 1
  episodes_total: 1061
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.992
    dispatch_time_ms: 6.176
    learner:
      cur_lr: 0.0010066869435831904
      grad_gnorm: 40.0
      policy_entropy: 29.20631980895996
      policy_loss: -2559.6923828125
      var_gnorm: 114.69015502929688
      vf_explained_var: 0.0
      vf_loss: 1359144.125
    num_steps_sampled: 5310000
    num_steps_trained: 5310000
    wait_time_ms: 75.783
  iterations_since_restore: 1062
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9230.701493740082
  time_this_iter_s: 8.45835018157959
  time_total_s: 9230.701493740082
  timestamp: 1594865267
  timesteps_since_restore: 5310000
  timesteps_this_iter: 5000
  timesteps_total: 5310000
  training_iteration: 1062
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9230 s, 1062 iter, 5310000 ts, -6.2e+04 rew

agent-1: -27094.553049789316
agent-2: -30052.337139113748
agent-3: -23765.220202894092
agent-4: -23492.379726581054
agent-5: -21616.38570643035
Extrinsic Rewards:
-26926
-29881
-23626
-23353
-21483
Sum Reward: -125269
Avg Reward: -25053.8
Min Reward: -29881
Max Reward: -21483
Gini Coefficient: -0.06504083212925783
20:20 Ratio: 0.718951842307821
Max-min Ratio: 0.718951842307821
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-07-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -62660.28570404645
  episode_reward_min: -162328.86303864562
  episodes_this_iter: 1
  episodes_total: 1062
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.616
    dispatch_time_ms: 6.724
    learner:
      cur_lr: 0.0010063539957627654
      grad_gnorm: 40.0
      policy_entropy: 28.39226722717285
      policy_loss: -2583.170654296875
      var_gnorm: 115.15660858154297
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 696480.8125
    num_steps_sampled: 5315000
    num_steps_trained: 5315000
    wait_time_ms: 77.663
  iterations_since_restore: 1063
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9239.083229064941
  time_this_iter_s: 8.38173532485962
  time_total_s: 9239.083229064941
  timestamp: 1594865275
  timesteps_since_restore: 5315000
  timesteps_this_iter: 5000
  timesteps_total: 5315000
  training_iteration: 1063
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9239 s, 1063 iter, 5315000 ts, -6.27e+04 rew

agent-1: -27301.62060199072
agent-2: -21807.15191482811
agent-3: -41890.227410801526
agent-4: -37877.931997134125
agent-5: -38994.73458350394
Extrinsic Rewards:
-27174
-21704
-41707
-37716
-38828
Sum Reward: -167129
Avg Reward: -33425.8
Min Reward: -41707
Max Reward: -21704
Gini Coefficient: -0.12364101981104417
20:20 Ratio: 0.5203922602920373
Max-min Ratio: 0.5203922602920373
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-08-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -63962.473983560434
  episode_reward_min: -167871.66650825876
  episodes_this_iter: 1
  episodes_total: 1063
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.575
    dispatch_time_ms: 8.63
    learner:
      cur_lr: 0.0010060210479423404
      grad_gnorm: 40.0
      policy_entropy: 29.239683151245117
      policy_loss: -7228.90380859375
      var_gnorm: 115.65032196044922
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 835840.375
    num_steps_sampled: 5320000
    num_steps_trained: 5320000
    wait_time_ms: 75.799
  iterations_since_restore: 1064
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9247.60607624054
  time_this_iter_s: 8.522847175598145
  time_total_s: 9247.60607624054
  timestamp: 1594865284
  timesteps_since_restore: 5320000
  timesteps_this_iter: 5000
  timesteps_total: 5320000
  training_iteration: 1064
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9247 s, 1064 iter, 5320000 ts, -6.4e+04 rew

agent-1: -27185.33814984477
agent-2: -24656.02765612875
agent-3: -13809.87237822432
agent-4: -29617.8668749222
agent-5: -28091.819501188984
Extrinsic Rewards:
-27027
-24508
-13720
-29443
-27922
Sum Reward: -122620
Avg Reward: -24524.0
Min Reward: -29443
Max Reward: -13720
Gini Coefficient: -0.11371717501223291
20:20 Ratio: 0.46598512379852597
Max-min Ratio: 0.46598512379852597
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-08-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -64601.49611703821
  episode_reward_min: -167871.66650825876
  episodes_this_iter: 1
  episodes_total: 1064
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.926
    dispatch_time_ms: 7.303
    learner:
      cur_lr: 0.0010056879837065935
      grad_gnorm: 40.0
      policy_entropy: 17.903440475463867
      policy_loss: -4425.10546875
      var_gnorm: 116.1143798828125
      vf_explained_var: 0.0
      vf_loss: 1878847.5
    num_steps_sampled: 5325000
    num_steps_trained: 5325000
    wait_time_ms: 75.023
  iterations_since_restore: 1065
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9256.044833183289
  time_this_iter_s: 8.438756942749023
  time_total_s: 9256.044833183289
  timestamp: 1594865292
  timesteps_since_restore: 5325000
  timesteps_this_iter: 5000
  timesteps_total: 5325000
  training_iteration: 1065
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9256 s, 1065 iter, 5325000 ts, -6.46e+04 rew

agent-1: -16206.474284405958
agent-2: -24461.07734385821
agent-3: -25596.517245124913
agent-4: -18078.132384170483
agent-5: -23195.172082168618
Extrinsic Rewards:
-16094
-24297
-25431
-17954
-23042
Sum Reward: -106818
Avg Reward: -21363.6
Min Reward: -25431
Max Reward: -16094
Gini Coefficient: -0.09368084030781329
20:20 Ratio: 0.6328496716605717
Max-min Ratio: 0.6328496716605717
agent-1: -44636.69405093536
agent-2: -45404.881092240255
agent-3: -39877.87092902401
agent-4: -28902.43836016903
agent-5: -47199.44082848554
Extrinsic Rewards:
-44480
-45240
-39738
-28786
-47032
Sum Reward: -205276
Avg Reward: -41055.2
Min Reward: -47032
Max Reward: -28786
Gini Coefficient: -0.08182934195911845
20:20 Ratio: 0.6120513692804899
Max-min Ratio: 0.6120513692804899
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-08-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -66237.68580365131
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 2
  episodes_total: 1066
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.347
    dispatch_time_ms: 6.691
    learner:
      cur_lr: 0.0010053550358861685
      grad_gnorm: 40.0
      policy_entropy: 16.116464614868164
      policy_loss: 4593.59228515625
      var_gnorm: 116.58121490478516
      vf_explained_var: 0.0
      vf_loss: 3294202.75
    num_steps_sampled: 5330000
    num_steps_trained: 5330000
    wait_time_ms: 77.043
  iterations_since_restore: 1066
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9264.588308095932
  time_this_iter_s: 8.543474912643433
  time_total_s: 9264.588308095932
  timestamp: 1594865301
  timesteps_since_restore: 5330000
  timesteps_this_iter: 5000
  timesteps_total: 5330000
  training_iteration: 1066
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9264 s, 1066 iter, 5330000 ts, -6.62e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-08-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -66237.68580365133
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 0
  episodes_total: 1066
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.917
    dispatch_time_ms: 41.283
    learner:
      cur_lr: 0.0010050219716504216
      grad_gnorm: 40.000003814697266
      policy_entropy: 10.451055526733398
      policy_loss: -67.44097137451172
      var_gnorm: 117.02338409423828
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 394221.125
    num_steps_sampled: 5335000
    num_steps_trained: 5335000
    wait_time_ms: 41.314
  iterations_since_restore: 1067
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9273.206553697586
  time_this_iter_s: 8.618245601654053
  time_total_s: 9273.206553697586
  timestamp: 1594865310
  timesteps_since_restore: 5335000
  timesteps_this_iter: 5000
  timesteps_total: 5335000
  training_iteration: 1067
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9273 s, 1067 iter, 5335000 ts, -6.62e+04 rew

agent-1: -21211.824170088046
agent-2: -21866.461783937273
agent-3: -33018.141061431925
agent-4: -30453.642414059388
agent-5: -20507.63881476961
Extrinsic Rewards:
-21087
-21745
-32839
-30293
-20384
Sum Reward: -126348
Avg Reward: -25269.6
Min Reward: -32839
Max Reward: -20384
Gini Coefficient: -0.10800645835311995
20:20 Ratio: 0.620725357044977
Max-min Ratio: 0.620725357044977
agent-1: -23151.46231267101
agent-2: -38904.63359316692
agent-3: -41615.67019398016
agent-4: -38898.68584601938
agent-5: -25912.466939121296
Extrinsic Rewards:
-23047
-38730
-41448
-38740
-25795
Sum Reward: -167760
Avg Reward: -33552.0
Min Reward: -41448
Max Reward: -23047
Gini Coefficient: -0.11861468764902242
20:20 Ratio: 0.5560461300907161
Max-min Ratio: 0.5560461300907161
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-08-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -68277.8912123601
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 2
  episodes_total: 1068
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.675
    dispatch_time_ms: 20.769
    learner:
      cur_lr: 0.0010046890238299966
      grad_gnorm: 40.0
      policy_entropy: 13.036578178405762
      policy_loss: 5018.57177734375
      var_gnorm: 117.49870300292969
      vf_explained_var: 0.0
      vf_loss: 3346555.0
    num_steps_sampled: 5340000
    num_steps_trained: 5340000
    wait_time_ms: 67.659
  iterations_since_restore: 1068
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9282.26261639595
  time_this_iter_s: 9.056062698364258
  time_total_s: 9282.26261639595
  timestamp: 1594865319
  timesteps_since_restore: 5340000
  timesteps_this_iter: 5000
  timesteps_total: 5340000
  training_iteration: 1068
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9282 s, 1068 iter, 5340000 ts, -6.83e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-08-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -68277.8912123601
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 0
  episodes_total: 1068
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.831
    dispatch_time_ms: 33.035
    learner:
      cur_lr: 0.0010043559595942497
      grad_gnorm: 40.0
      policy_entropy: 20.362506866455078
      policy_loss: -6855.18359375
      var_gnorm: 117.94751739501953
      vf_explained_var: 0.0
      vf_loss: 1373334.25
    num_steps_sampled: 5345000
    num_steps_trained: 5345000
    wait_time_ms: 61.899
  iterations_since_restore: 1069
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9291.467077255249
  time_this_iter_s: 9.204460859298706
  time_total_s: 9291.467077255249
  timestamp: 1594865328
  timesteps_since_restore: 5345000
  timesteps_this_iter: 5000
  timesteps_total: 5345000
  training_iteration: 1069
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9291 s, 1069 iter, 5345000 ts, -6.83e+04 rew

agent-1: -26694.260185696363
agent-2: -33134.10160639325
agent-3: -16534.670524652553
agent-4: -38702.02846059783
agent-5: -19347.524376011508
Extrinsic Rewards:
-26555
-32954
-16453
-38510
-19252
Sum Reward: -133724
Avg Reward: -26744.8
Min Reward: -38510
Max Reward: -16453
Gini Coefficient: -0.17294128204361223
20:20 Ratio: 0.4272396780057128
Max-min Ratio: 0.4272396780057128
agent-1: -24611.70511532463
agent-2: -33595.58039272322
agent-3: -26215.355672328686
agent-4: -13994.00416942375
agent-5: -16363.924438668533
Extrinsic Rewards:
-24458
-33396
-26056
-13898
-16255
Sum Reward: -114063
Avg Reward: -22812.6
Min Reward: -33396
Max Reward: -13898
Gini Coefficient: -0.17112297589928374
20:20 Ratio: 0.4161576236675051
Max-min Ratio: 0.4161576236675051
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-08-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -69044.08387179441
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 2
  episodes_total: 1070
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.851
    dispatch_time_ms: 35.034
    learner:
      cur_lr: 0.0010040230117738247
      grad_gnorm: 39.999996185302734
      policy_entropy: 26.844905853271484
      policy_loss: 9938.255859375
      var_gnorm: 118.43260955810547
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 4326432.0
    num_steps_sampled: 5350000
    num_steps_trained: 5350000
    wait_time_ms: 52.455
  iterations_since_restore: 1070
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9300.577381134033
  time_this_iter_s: 9.11030387878418
  time_total_s: 9300.577381134033
  timestamp: 1594865337
  timesteps_since_restore: 5350000
  timesteps_this_iter: 5000
  timesteps_total: 5350000
  training_iteration: 1070
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9300 s, 1070 iter, 5350000 ts, -6.9e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-09-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -69044.0838717944
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 0
  episodes_total: 1070
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.838
    dispatch_time_ms: 19.377
    learner:
      cur_lr: 0.0010036899475380778
      grad_gnorm: 40.0
      policy_entropy: 26.501388549804688
      policy_loss: -3208.9697265625
      var_gnorm: 118.88699340820312
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 810296.4375
    num_steps_sampled: 5355000
    num_steps_trained: 5355000
    wait_time_ms: 71.092
  iterations_since_restore: 1071
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9309.576662778854
  time_this_iter_s: 8.999281644821167
  time_total_s: 9309.576662778854
  timestamp: 1594865346
  timesteps_since_restore: 5355000
  timesteps_this_iter: 5000
  timesteps_total: 5355000
  training_iteration: 1071
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9309 s, 1071 iter, 5355000 ts, -6.9e+04 rew

agent-1: -31016.402236641334
agent-2: -34157.57797935518
agent-3: -16293.908895866936
agent-4: -14457.232695226256
agent-5: -26276.401000437145
Extrinsic Rewards:
-30836
-33964
-16194
-14364
-26116
Sum Reward: -121474
Avg Reward: -24294.8
Min Reward: -33964
Max Reward: -14364
Gini Coefficient: -0.17729555295783458
20:20 Ratio: 0.4229183841714757
Max-min Ratio: 0.4229183841714757
agent-1: -10633.18575670118
agent-2: -26191.00097148496
agent-3: -32092.106344338088
agent-4: -12328.294653406669
agent-5: -35141.10790529794
Extrinsic Rewards:
-10559
-26023
-31905
-12245
-34933
Sum Reward: -115665
Avg Reward: -23133.0
Min Reward: -34933
Max Reward: -10559
Gini Coefficient: -0.2365728612804219
20:20 Ratio: 0.3022643345833453
Max-min Ratio: 0.3022643345833453
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-09-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -70393.2654366664
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 2
  episodes_total: 1072
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.737
    dispatch_time_ms: 28.375
    learner:
      cur_lr: 0.0010033569997176528
      grad_gnorm: 40.000003814697266
      policy_entropy: 32.21063995361328
      policy_loss: 13502.814453125
      var_gnorm: 119.36124420166016
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 5704121.0
    num_steps_sampled: 5360000
    num_steps_trained: 5360000
    wait_time_ms: 53.753
  iterations_since_restore: 1072
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9318.574651479721
  time_this_iter_s: 8.9979887008667
  time_total_s: 9318.574651479721
  timestamp: 1594865355
  timesteps_since_restore: 5360000
  timesteps_this_iter: 5000
  timesteps_total: 5360000
  training_iteration: 1072
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9318 s, 1072 iter, 5360000 ts, -7.04e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-09-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -70393.2654366664
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 0
  episodes_total: 1072
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.705
    dispatch_time_ms: 26.607
    learner:
      cur_lr: 0.0010030240518972278
      grad_gnorm: 40.0
      policy_entropy: 34.97748565673828
      policy_loss: -3142.283935546875
      var_gnorm: 119.81681060791016
      vf_explained_var: 0.0
      vf_loss: 803718.5625
    num_steps_sampled: 5365000
    num_steps_trained: 5365000
    wait_time_ms: 64.644
  iterations_since_restore: 1073
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9327.504843950272
  time_this_iter_s: 8.930192470550537
  time_total_s: 9327.504843950272
  timestamp: 1594865364
  timesteps_since_restore: 5365000
  timesteps_this_iter: 5000
  timesteps_total: 5365000
  training_iteration: 1073
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9327 s, 1073 iter, 5365000 ts, -7.04e+04 rew

agent-1: -14083.032542653493
agent-2: -20201.152725911077
agent-3: -28141.594004512073
agent-4: -25895.6769583179
agent-5: -24579.73964994172
Extrinsic Rewards:
-13962
-20079
-27960
-25734
-24429
Sum Reward: -112164
Avg Reward: -22432.8
Min Reward: -27960
Max Reward: -13962
Gini Coefficient: -0.12000641917192682
20:20 Ratio: 0.4993562231759657
Max-min Ratio: 0.4993562231759657
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-09-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -70946.31413314643
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1073
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.441
    dispatch_time_ms: 27.65
    learner:
      cur_lr: 0.001002690987661481
      grad_gnorm: 40.0
      policy_entropy: 27.281742095947266
      policy_loss: 20.444122314453125
      var_gnorm: 120.05769348144531
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 35286.4921875
    num_steps_sampled: 5370000
    num_steps_trained: 5370000
    wait_time_ms: 55.236
  iterations_since_restore: 1074
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9336.245645999908
  time_this_iter_s: 8.74080204963684
  time_total_s: 9336.245645999908
  timestamp: 1594865373
  timesteps_since_restore: 5370000
  timesteps_this_iter: 5000
  timesteps_total: 5370000
  training_iteration: 1074
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9336 s, 1074 iter, 5370000 ts, -7.09e+04 rew

agent-1: -16030.803455717585
agent-2: -18017.545451370155
agent-3: -10849.47317145568
agent-4: -17038.10283449977
agent-5: -13091.875477729049
Extrinsic Rewards:
-15877
-17848
-10721
-16871
-12968
Sum Reward: -74285
Avg Reward: -14857.0
Min Reward: -17848
Max Reward: -10721
Gini Coefficient: -0.09776940162886182
20:20 Ratio: 0.6006835499775885
Max-min Ratio: 0.6006835499775885
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-09-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -71207.14233147557
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1074
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.82
    dispatch_time_ms: 36.951
    learner:
      cur_lr: 0.0010023580398410559
      grad_gnorm: 40.0
      policy_entropy: 23.105575561523438
      policy_loss: 613.0360717773438
      var_gnorm: 119.82452392578125
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 17552.888671875
    num_steps_sampled: 5375000
    num_steps_trained: 5375000
    wait_time_ms: 44.085
  iterations_since_restore: 1075
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9345.134249448776
  time_this_iter_s: 8.888603448867798
  time_total_s: 9345.134249448776
  timestamp: 1594865382
  timesteps_since_restore: 5375000
  timesteps_this_iter: 5000
  timesteps_total: 5375000
  training_iteration: 1075
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9345 s, 1075 iter, 5375000 ts, -7.12e+04 rew

agent-1: -7776.495409104827
agent-2: -2027.9337484523826
agent-3: -6094.239796178378
agent-4: -7105.111519563466
agent-5: -4308.06094860459
Extrinsic Rewards:
-7580
-1971
-5931
-6915
-4190
Sum Reward: -26587
Avg Reward: -5317.4
Min Reward: -7580
Max Reward: -1971
Gini Coefficient: -0.20977169293263626
20:20 Ratio: 0.2600263852242744
Max-min Ratio: 0.2600263852242744
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-09-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -70886.6839301116
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1075
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.566
    dispatch_time_ms: 6.242
    learner:
      cur_lr: 0.001002024975605309
      grad_gnorm: 39.999996185302734
      policy_entropy: 29.335350036621094
      policy_loss: 499.38067626953125
      var_gnorm: 119.75154113769531
      vf_explained_var: -0.41187334060668945
      vf_loss: 13981.4423828125
    num_steps_sampled: 5380000
    num_steps_trained: 5380000
    wait_time_ms: 72.18
  iterations_since_restore: 1076
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9352.719593524933
  time_this_iter_s: 7.585344076156616
  time_total_s: 9352.719593524933
  timestamp: 1594865389
  timesteps_since_restore: 5380000
  timesteps_this_iter: 5000
  timesteps_total: 5380000
  training_iteration: 1076
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9352 s, 1076 iter, 5380000 ts, -7.09e+04 rew

agent-1: -4583.115615613598
agent-2: -3056.8482216198217
agent-3: -3177.9255315326386
agent-4: -5667.84223559206
agent-5: -4181.318879950439
Extrinsic Rewards:
-4411
-2946
-3080
-5474
-4028
Sum Reward: -19939
Avg Reward: -3987.8
Min Reward: -5474
Max Reward: -2946
Gini Coefficient: -0.1281307989367571
20:20 Ratio: 0.5381804895871392
Max-min Ratio: 0.5381804895871392
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-09-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -70657.50049045394
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1076
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.714
    dispatch_time_ms: 7.978
    learner:
      cur_lr: 0.001001692027784884
      grad_gnorm: 40.0
      policy_entropy: 30.84606170654297
      policy_loss: 305.8571472167969
      var_gnorm: 119.61846923828125
      vf_explained_var: 0.0
      vf_loss: 19559.0
    num_steps_sampled: 5385000
    num_steps_trained: 5385000
    wait_time_ms: 69.708
  iterations_since_restore: 1077
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9360.65911245346
  time_this_iter_s: 7.939518928527832
  time_total_s: 9360.65911245346
  timestamp: 1594865397
  timesteps_since_restore: 5385000
  timesteps_this_iter: 5000
  timesteps_total: 5385000
  training_iteration: 1077
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9360 s, 1077 iter, 5385000 ts, -7.07e+04 rew

agent-1: -5468.403678997383
agent-2: -6368.635491604783
agent-3: -7354.7459629733285
agent-4: -6010.1472414324235
agent-5: -7216.8223961485155
Extrinsic Rewards:
-5342
-6215
-7178
-5871
-7056
Sum Reward: -31662
Avg Reward: -6332.4
Min Reward: -7178
Max Reward: -5342
Gini Coefficient: -0.0613606215652833
20:20 Ratio: 0.7442184452493731
Max-min Ratio: 0.7442184452493731
agent-1: -8049.633937958221
agent-2: -5701.8062600968515
agent-3: -4694.705456122835
agent-4: -6679.456971653915
agent-5: -5961.3743243064
Extrinsic Rewards:
-7863
-5561
-4563
-6522
-5819
Sum Reward: -30328
Avg Reward: -6065.6
Min Reward: -7863
Max Reward: -4563
Gini Coefficient: -0.09972302822474281
20:20 Ratio: 0.5803128576879054
Max-min Ratio: 0.5803128576879054
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-10-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -69843.78426630971
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 2
  episodes_total: 1078
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.703
    dispatch_time_ms: 7.107
    learner:
      cur_lr: 0.0010013589635491371
      grad_gnorm: 40.0
      policy_entropy: 34.59064865112305
      policy_loss: 13768.505859375
      var_gnorm: 119.7923583984375
      vf_explained_var: 0.0
      vf_loss: 5794996.0
    num_steps_sampled: 5390000
    num_steps_trained: 5390000
    wait_time_ms: 70.857
  iterations_since_restore: 1078
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9368.735518693924
  time_this_iter_s: 8.076406240463257
  time_total_s: 9368.735518693924
  timestamp: 1594865406
  timesteps_since_restore: 5390000
  timesteps_this_iter: 5000
  timesteps_total: 5390000
  training_iteration: 1078
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9368 s, 1078 iter, 5390000 ts, -6.98e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-10-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -69843.7842663097
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 0
  episodes_total: 1078
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.583
    dispatch_time_ms: 6.257
    learner:
      cur_lr: 0.001001026015728712
      grad_gnorm: 40.0
      policy_entropy: 27.835874557495117
      policy_loss: 519.1395874023438
      var_gnorm: 119.83142852783203
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 12811.103515625
    num_steps_sampled: 5395000
    num_steps_trained: 5395000
    wait_time_ms: 70.879
  iterations_since_restore: 1079
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9376.714273929596
  time_this_iter_s: 7.978755235671997
  time_total_s: 9376.714273929596
  timestamp: 1594865414
  timesteps_since_restore: 5395000
  timesteps_this_iter: 5000
  timesteps_total: 5395000
  training_iteration: 1079
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9376 s, 1079 iter, 5395000 ts, -6.98e+04 rew

agent-1: -8235.938611134825
agent-2: -10256.400117924635
agent-3: -7155.8278258791015
agent-4: -8472.457090896805
agent-5: -3479.5127436905645
Extrinsic Rewards:
-8072
-10065
-7007
-8300
-3417
Sum Reward: -36861
Avg Reward: -7372.2
Min Reward: -10065
Max Reward: -3417
Gini Coefficient: -0.15831366484902742
20:20 Ratio: 0.33949329359165425
Max-min Ratio: 0.33949329359165425
agent-1: -11015.490200044367
agent-2: -4171.071808087728
agent-3: -8951.007906250805
agent-4: -8500.344696739607
agent-5: -5259.052264069941
Extrinsic Rewards:
-10821
-4071
-8789
-8344
-5126
Sum Reward: -37151
Avg Reward: -7430.2
Min Reward: -10821
Max Reward: -4071
Gini Coefficient: -0.18479179564480094
20:20 Ratio: 0.37621291932353756
Max-min Ratio: 0.37621291932353756
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-10-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -69568.16563730492
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 2
  episodes_total: 1080
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.461
    dispatch_time_ms: 8.439
    learner:
      cur_lr: 0.0010006929514929652
      grad_gnorm: 40.0
      policy_entropy: 40.19739532470703
      policy_loss: 14846.9765625
      var_gnorm: 119.998046875
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 4761372.5
    num_steps_sampled: 5400000
    num_steps_trained: 5400000
    wait_time_ms: 69.466
  iterations_since_restore: 1080
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9384.732576608658
  time_this_iter_s: 8.01830267906189
  time_total_s: 9384.732576608658
  timestamp: 1594865422
  timesteps_since_restore: 5400000
  timesteps_this_iter: 5000
  timesteps_total: 5400000
  training_iteration: 1080
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9384 s, 1080 iter, 5400000 ts, -6.96e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-10-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -69568.16563730492
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 0
  episodes_total: 1080
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.61
    dispatch_time_ms: 6.85
    learner:
      cur_lr: 0.0010003600036725402
      grad_gnorm: 40.0
      policy_entropy: 38.2738037109375
      policy_loss: -2789.885009765625
      var_gnorm: 120.46248626708984
      vf_explained_var: 0.0
      vf_loss: 363768.1875
    num_steps_sampled: 5405000
    num_steps_trained: 5405000
    wait_time_ms: 72.42
  iterations_since_restore: 1081
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9392.85486650467
  time_this_iter_s: 8.122289896011353
  time_total_s: 9392.85486650467
  timestamp: 1594865430
  timesteps_since_restore: 5405000
  timesteps_this_iter: 5000
  timesteps_total: 5405000
  training_iteration: 1081
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9392 s, 1081 iter, 5405000 ts, -6.96e+04 rew

agent-1: -27903.90881429359
agent-2: -11780.574038290755
agent-3: -27389.932652891355
agent-4: -21573.55104915613
agent-5: -21255.255046727154
Extrinsic Rewards:
-27722
-11692
-27210
-21425
-21113
Sum Reward: -109162
Avg Reward: -21832.4
Min Reward: -27722
Max Reward: -11692
Gini Coefficient: -0.13981788534471704
20:20 Ratio: 0.42175889185484455
Max-min Ratio: 0.42175889185484455
agent-1: -19134.234504686403
agent-2: -14922.479683218931
agent-3: -24565.729686278744
agent-4: -12737.320060367585
agent-5: -18393.037225091783
Extrinsic Rewards:
-18988
-14781
-24386
-12616
-18245
Sum Reward: -89016
Avg Reward: -17803.2
Min Reward: -24386
Max Reward: -12616
Gini Coefficient: -0.12468320301968186
20:20 Ratio: 0.5173460182071681
Max-min Ratio: 0.5173460182071681
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-10-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -70111.4911050835
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 2
  episodes_total: 1082
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.224
    dispatch_time_ms: 7.009
    learner:
      cur_lr: 0.0010000270558521152
      grad_gnorm: 40.0
      policy_entropy: 32.985958099365234
      policy_loss: 14329.857421875
      var_gnorm: 120.9554443359375
      vf_explained_var: 0.0
      vf_loss: 4903357.5
    num_steps_sampled: 5410000
    num_steps_trained: 5410000
    wait_time_ms: 72.903
  iterations_since_restore: 1082
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9401.215512514114
  time_this_iter_s: 8.36064600944519
  time_total_s: 9401.215512514114
  timestamp: 1594865438
  timesteps_since_restore: 5410000
  timesteps_this_iter: 5000
  timesteps_total: 5410000
  training_iteration: 1082
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9401 s, 1082 iter, 5410000 ts, -7.01e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-10-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -70111.49110508352
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 0
  episodes_total: 1082
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.895
    dispatch_time_ms: 9.913
    learner:
      cur_lr: 0.0009996939916163683
      grad_gnorm: 39.999996185302734
      policy_entropy: 38.860084533691406
      policy_loss: -2954.320068359375
      var_gnorm: 121.42794799804688
      vf_explained_var: 0.0
      vf_loss: 310792.46875
    num_steps_sampled: 5415000
    num_steps_trained: 5415000
    wait_time_ms: 71.622
  iterations_since_restore: 1083
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9409.556197404861
  time_this_iter_s: 8.34068489074707
  time_total_s: 9409.556197404861
  timestamp: 1594865447
  timesteps_since_restore: 5415000
  timesteps_this_iter: 5000
  timesteps_total: 5415000
  training_iteration: 1083
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9409 s, 1083 iter, 5415000 ts, -7.01e+04 rew

agent-1: -20809.03510409627
agent-2: -14439.810938423503
agent-3: -15648.895306030287
agent-4: -12704.491648712738
agent-5: -13009.832756777621
Extrinsic Rewards:
-20619
-14304
-15495
-12578
-12887
Sum Reward: -75883
Avg Reward: -15176.6
Min Reward: -20619
Max Reward: -12578
Gini Coefficient: -0.09852009013876625
20:20 Ratio: 0.6100198845724817
Max-min Ratio: 0.6100198845724817
agent-1: -18341.208089685097
agent-2: -28537.53769043128
agent-3: -17859.56033989225
agent-4: -5071.574587730547
agent-5: -22203.165631934517
Extrinsic Rewards:
-18190
-28326
-17706
-5026
-22029
Sum Reward: -91277
Avg Reward: -18255.4
Min Reward: -28326
Max Reward: -5026
Gini Coefficient: -0.22315807925326206
20:20 Ratio: 0.1774341594294994
Max-min Ratio: 0.1774341594294994
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-11-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -70404.23252248229
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 2
  episodes_total: 1084
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.804
    dispatch_time_ms: 33.204
    learner:
      cur_lr: 0.0009993610437959433
      grad_gnorm: 40.000003814697266
      policy_entropy: 36.89934158325195
      policy_loss: 17041.02734375
      var_gnorm: 121.87933349609375
      vf_explained_var: 0.0
      vf_loss: 4617377.0
    num_steps_sampled: 5420000
    num_steps_trained: 5420000
    wait_time_ms: 42.021
  iterations_since_restore: 1084
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9425.706777572632
  time_this_iter_s: 16.150580167770386
  time_total_s: 9425.706777572632
  timestamp: 1594865463
  timesteps_since_restore: 5420000
  timesteps_this_iter: 5000
  timesteps_total: 5420000
  training_iteration: 1084
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9425 s, 1084 iter, 5420000 ts, -7.04e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-11-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -70404.23252248227
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 0
  episodes_total: 1084
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.314
    dispatch_time_ms: 51.256
    learner:
      cur_lr: 0.0009990279795601964
      grad_gnorm: 40.00000762939453
      policy_entropy: 37.16452407836914
      policy_loss: -1228.6163330078125
      var_gnorm: 122.21746826171875
      vf_explained_var: 0.0
      vf_loss: 126964.2578125
    num_steps_sampled: 5425000
    num_steps_trained: 5425000
    wait_time_ms: 30.744
  iterations_since_restore: 1085
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9434.207215547562
  time_this_iter_s: 8.50043797492981
  time_total_s: 9434.207215547562
  timestamp: 1594865471
  timesteps_since_restore: 5425000
  timesteps_this_iter: 5000
  timesteps_total: 5425000
  training_iteration: 1085
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9434 s, 1085 iter, 5425000 ts, -7.04e+04 rew

agent-1: -14755.998769787348
agent-2: -6570.541172692344
agent-3: -11310.477602559242
agent-4: -19395.393557649622
agent-5: -7854.387008508228
Extrinsic Rewards:
-14584
-6480
-11161
-19182
-7744
Sum Reward: -59151
Avg Reward: -11830.2
Min Reward: -19182
Max Reward: -6480
Gini Coefficient: -0.2180453415834052
20:20 Ratio: 0.33781670315921175
Max-min Ratio: 0.33781670315921175
agent-1: -9333.366800526228
agent-2: -17068.70123433052
agent-3: -8952.036450187556
agent-4: -3247.7481541948214
agent-5: -11267.87079682351
Extrinsic Rewards:
-9192
-16847
-8819
-3197
-11100
Sum Reward: -49155
Avg Reward: -9831.0
Min Reward: -16847
Max Reward: -3197
Gini Coefficient: -0.2407161021259282
20:20 Ratio: 0.18976672404582418
Max-min Ratio: 0.18976672404582418
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-11-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -70111.16961386664
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 2
  episodes_total: 1086
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.589
    dispatch_time_ms: 63.617
    learner:
      cur_lr: 0.0009986950317397714
      grad_gnorm: 40.0
      policy_entropy: 30.52916717529297
      policy_loss: 36.6907844543457
      var_gnorm: 122.5990982055664
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 50227.57421875
    num_steps_sampled: 5430000
    num_steps_trained: 5430000
    wait_time_ms: 38.744
  iterations_since_restore: 1086
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9443.024677753448
  time_this_iter_s: 8.81746220588684
  time_total_s: 9443.024677753448
  timestamp: 1594865480
  timesteps_since_restore: 5430000
  timesteps_this_iter: 5000
  timesteps_total: 5430000
  training_iteration: 1086
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9443 s, 1086 iter, 5430000 ts, -7.01e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-11-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -70111.16961386664
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 0
  episodes_total: 1086
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.934
    dispatch_time_ms: 28.185
    learner:
      cur_lr: 0.0009983619675040245
      grad_gnorm: 39.999996185302734
      policy_entropy: 28.78424644470215
      policy_loss: 48.24775695800781
      var_gnorm: 122.47396850585938
      vf_explained_var: 0.0
      vf_loss: 47474.88671875
    num_steps_sampled: 5435000
    num_steps_trained: 5435000
    wait_time_ms: 60.904
  iterations_since_restore: 1087
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9451.443567752838
  time_this_iter_s: 8.418889999389648
  time_total_s: 9451.443567752838
  timestamp: 1594865489
  timesteps_since_restore: 5435000
  timesteps_this_iter: 5000
  timesteps_total: 5435000
  training_iteration: 1087
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9451 s, 1087 iter, 5435000 ts, -7.01e+04 rew

agent-1: -7205.053892034407
agent-2: -7567.53672701638
agent-3: -4543.567320113872
agent-4: -7389.15021749953
agent-5: -10309.450880098546
Extrinsic Rewards:
-7047
-7409
-4454
-7257
-10115
Sum Reward: -36282
Avg Reward: -7256.4
Min Reward: -10115
Max Reward: -4454
Gini Coefficient: -0.12881318560167576
20:20 Ratio: 0.4403361344537815
Max-min Ratio: 0.4403361344537815
agent-1: -8775.239896786812
agent-2: -4056.558061676514
agent-3: -4450.996073392685
agent-4: -8724.548942715603
agent-5: -3916.4868037318697
Extrinsic Rewards:
-8567
-3954
-4345
-8518
-3817
Sum Reward: -29201
Avg Reward: -5840.2
Min Reward: -8567
Max Reward: -3817
Gini Coefficient: -0.19265093661175986
20:20 Ratio: 0.445546865880705
Max-min Ratio: 0.445546865880705
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-11-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -69199.71801234299
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 2
  episodes_total: 1088
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.087
    dispatch_time_ms: 29.057
    learner:
      cur_lr: 0.0009980290196835995
      grad_gnorm: 39.999996185302734
      policy_entropy: 38.75230026245117
      policy_loss: -1997.9688720703125
      var_gnorm: 122.68875885009766
      vf_explained_var: -0.4930295944213867
      vf_loss: 123467.796875
    num_steps_sampled: 5440000
    num_steps_trained: 5440000
    wait_time_ms: 56.648
  iterations_since_restore: 1088
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9459.953932762146
  time_this_iter_s: 8.510365009307861
  time_total_s: 9459.953932762146
  timestamp: 1594865497
  timesteps_since_restore: 5440000
  timesteps_this_iter: 5000
  timesteps_total: 5440000
  training_iteration: 1088
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9459 s, 1088 iter, 5440000 ts, -6.92e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-11-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -69199.71801234299
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 0
  episodes_total: 1088
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.902
    dispatch_time_ms: 29.849
    learner:
      cur_lr: 0.0009976959554478526
      grad_gnorm: 40.0
      policy_entropy: 36.682342529296875
      policy_loss: -2824.38671875
      var_gnorm: 123.03775787353516
      vf_explained_var: 0.0
      vf_loss: 230572.46875
    num_steps_sampled: 5445000
    num_steps_trained: 5445000
    wait_time_ms: 53.205
  iterations_since_restore: 1089
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9468.570926427841
  time_this_iter_s: 8.61699366569519
  time_total_s: 9468.570926427841
  timestamp: 1594865506
  timesteps_since_restore: 5445000
  timesteps_this_iter: 5000
  timesteps_total: 5445000
  training_iteration: 1089
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9468 s, 1089 iter, 5445000 ts, -6.92e+04 rew

agent-1: -11311.8943377661
agent-2: -8940.070967398196
agent-3: -9569.20036869894
agent-4: -15107.880122284278
agent-5: -12526.626004658316
Extrinsic Rewards:
-11164
-8824
-9430
-14924
-12365
Sum Reward: -56707
Avg Reward: -11341.4
Min Reward: -14924
Max Reward: -8824
Gini Coefficient: -0.10675930661117675
20:20 Ratio: 0.591262396140445
Max-min Ratio: 0.591262396140445
agent-1: -11881.111915433023
agent-2: -8170.360981804153
agent-3: -10321.935296394313
agent-4: -10182.065374493608
agent-5: -10089.000985950448
Extrinsic Rewards:
-11710
-8043
-10167
-10027
-9941
Sum Reward: -49888
Avg Reward: -9977.6
Min Reward: -11710
Max Reward: -8043
Gini Coefficient: -0.06061577934573444
20:20 Ratio: 0.6868488471391972
Max-min Ratio: 0.6868488471391972
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-11-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -69180.6773242647
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 2
  episodes_total: 1090
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.446
    dispatch_time_ms: 36.517
    learner:
      cur_lr: 0.0009973630076274276
      grad_gnorm: 40.0
      policy_entropy: 39.275848388671875
      policy_loss: 19793.65234375
      var_gnorm: 123.46458435058594
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5988412.0
    num_steps_sampled: 5450000
    num_steps_trained: 5450000
    wait_time_ms: 48.174
  iterations_since_restore: 1090
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9477.206735610962
  time_this_iter_s: 8.635809183120728
  time_total_s: 9477.206735610962
  timestamp: 1594865515
  timesteps_since_restore: 5450000
  timesteps_this_iter: 5000
  timesteps_total: 5450000
  training_iteration: 1090
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9477 s, 1090 iter, 5450000 ts, -6.92e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-12-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -69180.67732426472
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 0
  episodes_total: 1090
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.786
    dispatch_time_ms: 24.618
    learner:
      cur_lr: 0.0009970299433916807
      grad_gnorm: 40.0
      policy_entropy: 38.080631256103516
      policy_loss: -1427.897216796875
      var_gnorm: 123.90396118164062
      vf_explained_var: 0.0
      vf_loss: 223400.953125
    num_steps_sampled: 5455000
    num_steps_trained: 5455000
    wait_time_ms: 57.019
  iterations_since_restore: 1091
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9485.921085357666
  time_this_iter_s: 8.714349746704102
  time_total_s: 9485.921085357666
  timestamp: 1594865523
  timesteps_since_restore: 5455000
  timesteps_this_iter: 5000
  timesteps_total: 5455000
  training_iteration: 1091
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9485 s, 1091 iter, 5455000 ts, -6.92e+04 rew

agent-1: -16764.97583510581
agent-2: -11206.297406782709
agent-3: -15241.237710369536
agent-4: -16155.924831043689
agent-5: -10412.511855217514
Extrinsic Rewards:
-16580
-11078
-15069
-15996
-10328
Sum Reward: -69051
Avg Reward: -13810.2
Min Reward: -16580
Max Reward: -10328
Gini Coefficient: -0.1009225065531274
20:20 Ratio: 0.6229191797346201
Max-min Ratio: 0.6229191797346201
agent-1: -18614.441014852866
agent-2: -3241.5957751205588
agent-3: -24106.218186657254
agent-4: -14689.621666565641
agent-5: -15529.072098027118
Extrinsic Rewards:
-18434
-3208
-23894
-14538
-15382
Sum Reward: -75456
Avg Reward: -15091.2
Min Reward: -23894
Max Reward: -3208
Gini Coefficient: -0.23997031382527564
20:20 Ratio: 0.1342596467732485
Max-min Ratio: 0.1342596467732485
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-12-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -69460.18042378424
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 2
  episodes_total: 1092
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.777
    dispatch_time_ms: 40.794
    learner:
      cur_lr: 0.0009966969955712557
      grad_gnorm: 40.0
      policy_entropy: 38.628177642822266
      policy_loss: -2949.522216796875
      var_gnorm: 124.41172790527344
      vf_explained_var: 0.0
      vf_loss: 290649.21875
    num_steps_sampled: 5460000
    num_steps_trained: 5460000
    wait_time_ms: 44.515
  iterations_since_restore: 1092
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9494.722505569458
  time_this_iter_s: 8.801420211791992
  time_total_s: 9494.722505569458
  timestamp: 1594865532
  timesteps_since_restore: 5460000
  timesteps_this_iter: 5000
  timesteps_total: 5460000
  training_iteration: 1092
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9494 s, 1092 iter, 5460000 ts, -6.95e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-12-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -69460.18042378426
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 0
  episodes_total: 1092
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.72
    dispatch_time_ms: 28.812
    learner:
      cur_lr: 0.0009963640477508307
      grad_gnorm: 40.0
      policy_entropy: 37.08795928955078
      policy_loss: -1355.421142578125
      var_gnorm: 124.79542541503906
      vf_explained_var: 0.0
      vf_loss: 176784.0625
    num_steps_sampled: 5465000
    num_steps_trained: 5465000
    wait_time_ms: 55.675
  iterations_since_restore: 1093
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9503.400434732437
  time_this_iter_s: 8.677929162979126
  time_total_s: 9503.400434732437
  timestamp: 1594865541
  timesteps_since_restore: 5465000
  timesteps_this_iter: 5000
  timesteps_total: 5465000
  training_iteration: 1093
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9503 s, 1093 iter, 5465000 ts, -6.95e+04 rew

agent-1: -12931.633197392786
agent-2: -7320.076966699457
agent-3: -8441.630766861404
agent-4: -7507.109505807517
agent-5: -9601.383400101355
Extrinsic Rewards:
-12732
-7200
-8293
-7386
-9445
Sum Reward: -45056
Avg Reward: -9011.2
Min Reward: -12732
Max Reward: -7200
Gini Coefficient: -0.11650390625
20:20 Ratio: 0.5655042412818096
Max-min Ratio: 0.5655042412818096
agent-1: -13438.958253946379
agent-2: -10416.243141906667
agent-3: -10430.33207373975
agent-4: -19376.709853114935
agent-5: -19063.414992166257
Extrinsic Rewards:
-13297
-10304
-10311
-19186
-18876
Sum Reward: -71974
Avg Reward: -14394.8
Min Reward: -19186
Max Reward: -10304
Gini Coefficient: -0.1463250618278823
20:20 Ratio: 0.5370582716564162
Max-min Ratio: 0.5370582716564162
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-12-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -68961.59219800435
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 2
  episodes_total: 1094
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.757
    dispatch_time_ms: 20.922
    learner:
      cur_lr: 0.0009960309835150838
      grad_gnorm: 40.000003814697266
      policy_entropy: 37.843326568603516
      policy_loss: 16614.73046875
      var_gnorm: 125.11021423339844
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 5687907.0
    num_steps_sampled: 5470000
    num_steps_trained: 5470000
    wait_time_ms: 55.222
  iterations_since_restore: 1094
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9512.055955648422
  time_this_iter_s: 8.655520915985107
  time_total_s: 9512.055955648422
  timestamp: 1594865550
  timesteps_since_restore: 5470000
  timesteps_this_iter: 5000
  timesteps_total: 5470000
  training_iteration: 1094
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9512 s, 1094 iter, 5470000 ts, -6.9e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-12-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -68961.59219800435
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 0
  episodes_total: 1094
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.901
    dispatch_time_ms: 39.4
    learner:
      cur_lr: 0.0009956980356946588
      grad_gnorm: 40.0
      policy_entropy: 36.74422836303711
      policy_loss: -3482.337646484375
      var_gnorm: 125.59272003173828
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 506714.1875
    num_steps_sampled: 5475000
    num_steps_trained: 5475000
    wait_time_ms: 48.007
  iterations_since_restore: 1095
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9520.878856897354
  time_this_iter_s: 8.822901248931885
  time_total_s: 9520.878856897354
  timestamp: 1594865558
  timesteps_since_restore: 5475000
  timesteps_this_iter: 5000
  timesteps_total: 5475000
  training_iteration: 1095
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9520 s, 1095 iter, 5475000 ts, -6.9e+04 rew

agent-1: -575.6347365809779
agent-2: -33214.32801426463
agent-3: -24662.231446212696
agent-4: -28782.83106002176
agent-5: -32300.36502276533
Extrinsic Rewards:
-571
-33019
-24501
-28612
-32106
Sum Reward: -118809
Avg Reward: -23761.8
Min Reward: -33019
Max Reward: -571
Gini Coefficient: -0.24409261924601672
20:20 Ratio: 0.01729307368484812
Max-min Ratio: 0.01729307368484812
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-12-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -69267.8129697138
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1095
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.828
    dispatch_time_ms: 7.916
    learner:
      cur_lr: 0.000995364971458912
      grad_gnorm: 40.0
      policy_entropy: 36.086856842041016
      policy_loss: -1805.6685791015625
      var_gnorm: 126.09249877929688
      vf_explained_var: -0.135886549949646
      vf_loss: 326036.125
    num_steps_sampled: 5480000
    num_steps_trained: 5480000
    wait_time_ms: 71.687
  iterations_since_restore: 1096
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9529.028532743454
  time_this_iter_s: 8.149675846099854
  time_total_s: 9529.028532743454
  timestamp: 1594865567
  timesteps_since_restore: 5480000
  timesteps_this_iter: 5000
  timesteps_total: 5480000
  training_iteration: 1096
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9529 s, 1096 iter, 5480000 ts, -6.93e+04 rew

agent-1: -20285.52653890872
agent-2: -8162.115339551787
agent-3: -33117.84753209622
agent-4: -24744.082877757803
agent-5: -7595.82266834828
Extrinsic Rewards:
-20131
-8100
-32891
-24557
-7529
Sum Reward: -93208
Avg Reward: -18641.6
Min Reward: -32891
Max Reward: -7529
Gini Coefficient: -0.28830572483048666
20:20 Ratio: 0.22890760390380346
Max-min Ratio: 0.22890760390380346
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-12-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -69367.58152236522
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1096
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.675
    dispatch_time_ms: 5.701
    learner:
      cur_lr: 0.0009950320236384869
      grad_gnorm: 40.0
      policy_entropy: 32.96089553833008
      policy_loss: -1192.2843017578125
      var_gnorm: 126.52827453613281
      vf_explained_var: 0.0
      vf_loss: 248686.84375
    num_steps_sampled: 5485000
    num_steps_trained: 5485000
    wait_time_ms: 76.313
  iterations_since_restore: 1097
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9537.343649148941
  time_this_iter_s: 8.31511640548706
  time_total_s: 9537.343649148941
  timestamp: 1594865575
  timesteps_since_restore: 5485000
  timesteps_this_iter: 5000
  timesteps_total: 5485000
  training_iteration: 1097
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9537 s, 1097 iter, 5485000 ts, -6.94e+04 rew

agent-1: -31173.80832949743
agent-2: -18492.554636833585
agent-3: -11377.518738665576
agent-4: -34946.28100953844
agent-5: -5773.905655684681
Extrinsic Rewards:
-30961
-18354
-11279
-34731
-5730
Sum Reward: -101055
Avg Reward: -20211.0
Min Reward: -34731
Max Reward: -5730
Gini Coefficient: -0.3074919598238583
20:20 Ratio: 0.16498229247646196
Max-min Ratio: 0.16498229247646196
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-13-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -69791.12867229995
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1097
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.293
    dispatch_time_ms: 7.867
    learner:
      cur_lr: 0.00099469895940274
      grad_gnorm: 40.0
      policy_entropy: 33.05424499511719
      policy_loss: -893.6699829101562
      var_gnorm: 127.01200103759766
      vf_explained_var: 0.0
      vf_loss: 385934.0625
    num_steps_sampled: 5490000
    num_steps_trained: 5490000
    wait_time_ms: 70.829
  iterations_since_restore: 1098
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9545.714164495468
  time_this_iter_s: 8.3705153465271
  time_total_s: 9545.714164495468
  timestamp: 1594865583
  timesteps_since_restore: 5490000
  timesteps_this_iter: 5000
  timesteps_total: 5490000
  training_iteration: 1098
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9545 s, 1098 iter, 5490000 ts, -6.98e+04 rew

agent-1: -19963.710675138296
agent-2: -21998.151403711367
agent-3: -11979.851768788038
agent-4: -6888.266710238797
agent-5: -16603.858247468634
Extrinsic Rewards:
-19789
-21800
-11852
-6826
-16439
Sum Reward: -76706
Avg Reward: -15341.2
Min Reward: -21800
Max Reward: -6826
Gini Coefficient: -0.19755951294553228
20:20 Ratio: 0.31311926605504586
Max-min Ratio: 0.31311926605504586
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-13-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -69403.78898123321
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1098
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.674
    dispatch_time_ms: 6.735
    learner:
      cur_lr: 0.000994366011582315
      grad_gnorm: 39.999996185302734
      policy_entropy: 28.573753356933594
      policy_loss: -8146.78369140625
      var_gnorm: 127.45001983642578
      vf_explained_var: 0.0
      vf_loss: 4654427.5
    num_steps_sampled: 5495000
    num_steps_trained: 5495000
    wait_time_ms: 74.561
  iterations_since_restore: 1099
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9554.05577492714
  time_this_iter_s: 8.341610431671143
  time_total_s: 9554.05577492714
  timestamp: 1594865592
  timesteps_since_restore: 5495000
  timesteps_this_iter: 5000
  timesteps_total: 5495000
  training_iteration: 1099
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9554 s, 1099 iter, 5495000 ts, -6.94e+04 rew

agent-1: -19378.394194224973
agent-2: -37382.654935428
agent-3: -47885.894853882026
agent-4: -22516.758907672658
agent-5: -43675.56957986712
Extrinsic Rewards:
-19278
-37222
-47692
-22422
-43485
Sum Reward: -170099
Avg Reward: -34019.8
Min Reward: -47692
Max Reward: -19278
Gini Coefficient: -0.18316627375822314
20:20 Ratio: 0.40421873689507676
Max-min Ratio: 0.40421873689507676
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-13-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -70300.96087091467
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1099
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.16
    dispatch_time_ms: 7.168
    learner:
      cur_lr: 0.000994032947346568
      grad_gnorm: 40.0
      policy_entropy: 31.281818389892578
      policy_loss: -441.01251220703125
      var_gnorm: 127.8741226196289
      vf_explained_var: 0.0
      vf_loss: 69854.265625
    num_steps_sampled: 5500000
    num_steps_trained: 5500000
    wait_time_ms: 76.381
  iterations_since_restore: 1100
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9562.446365594864
  time_this_iter_s: 8.39059066772461
  time_total_s: 9562.446365594864
  timestamp: 1594865600
  timesteps_since_restore: 5500000
  timesteps_this_iter: 5000
  timesteps_total: 5500000
  training_iteration: 1100
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9562 s, 1100 iter, 5500000 ts, -7.03e+04 rew

agent-1: -9520.004639910872
agent-2: -15641.324241249971
agent-3: -15659.143243621813
agent-4: -14509.434493357847
agent-5: -8075.498110243521
Extrinsic Rewards:
-9403
-15465
-15483
-14346
-7991
Sum Reward: -62688
Avg Reward: -12537.6
Min Reward: -15483
Max Reward: -7991
Gini Coefficient: -0.1342904543134252
20:20 Ratio: 0.5161144481043726
Max-min Ratio: 0.5161144481043726
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-13-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -69836.75681111029
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1100
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.623
    dispatch_time_ms: 7.687
    learner:
      cur_lr: 0.000993699999526143
      grad_gnorm: 40.000003814697266
      policy_entropy: 33.13190460205078
      policy_loss: -5859.07763671875
      var_gnorm: 128.36126708984375
      vf_explained_var: 0.0
      vf_loss: 1447081.25
    num_steps_sampled: 5505000
    num_steps_trained: 5505000
    wait_time_ms: 74.755
  iterations_since_restore: 1101
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9570.80179810524
  time_this_iter_s: 8.355432510375977
  time_total_s: 9570.80179810524
  timestamp: 1594865609
  timesteps_since_restore: 5505000
  timesteps_this_iter: 5000
  timesteps_total: 5505000
  training_iteration: 1101
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9570 s, 1101 iter, 5505000 ts, -6.98e+04 rew

agent-1: -37251.18660100648
agent-2: -35221.40945084698
agent-3: -32060.592947577683
agent-4: -15172.096635962556
agent-5: -15206.889880643916
Extrinsic Rewards:
-37063
-35035
-31885
-15071
-15124
Sum Reward: -134178
Avg Reward: -26835.6
Min Reward: -37063
Max Reward: -15071
Gini Coefficient: -0.1904783198437896
20:20 Ratio: 0.40663195100234734
Max-min Ratio: 0.40663195100234734
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-13-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -70048.41998153973
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1101
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.716
    dispatch_time_ms: 6.56
    learner:
      cur_lr: 0.000993367051705718
      grad_gnorm: 39.999996185302734
      policy_entropy: 35.12442398071289
      policy_loss: -8336.876953125
      var_gnorm: 128.88174438476562
      vf_explained_var: 0.0
      vf_loss: 973128.8125
    num_steps_sampled: 5510000
    num_steps_trained: 5510000
    wait_time_ms: 74.894
  iterations_since_restore: 1102
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9579.063404083252
  time_this_iter_s: 8.261605978012085
  time_total_s: 9579.063404083252
  timestamp: 1594865617
  timesteps_since_restore: 5510000
  timesteps_this_iter: 5000
  timesteps_total: 5510000
  training_iteration: 1102
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9579 s, 1102 iter, 5510000 ts, -7e+04 rew

agent-1: -35619.16933538416
agent-2: -15141.030487092867
agent-3: -25517.259571062204
agent-4: -19864.570574882855
agent-5: -16983.196175235764
Extrinsic Rewards:
-35408
-15029
-25342
-19730
-16879
Sum Reward: -112388
Avg Reward: -22477.6
Min Reward: -35408
Max Reward: -15029
Gini Coefficient: -0.17518240381535397
20:20 Ratio: 0.42445210122006327
Max-min Ratio: 0.42445210122006327
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-13-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -70149.76683915345
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1102
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.359
    dispatch_time_ms: 6.958
    learner:
      cur_lr: 0.0009930339874699712
      grad_gnorm: 39.999996185302734
      policy_entropy: 30.096113204956055
      policy_loss: -1819.733154296875
      var_gnorm: 129.38360595703125
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 656259.6875
    num_steps_sampled: 5515000
    num_steps_trained: 5515000
    wait_time_ms: 76.905
  iterations_since_restore: 1103
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9587.403951406479
  time_this_iter_s: 8.340547323226929
  time_total_s: 9587.403951406479
  timestamp: 1594865625
  timesteps_since_restore: 5515000
  timesteps_this_iter: 5000
  timesteps_total: 5515000
  training_iteration: 1103
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9587 s, 1103 iter, 5515000 ts, -7.01e+04 rew

agent-1: -11856.789926682955
agent-2: -34240.51691885681
agent-3: -17460.747573388213
agent-4: -28551.974443168565
agent-5: -19617.986638013765
Extrinsic Rewards:
-11765
-34033
-17350
-28367
-19476
Sum Reward: -110991
Avg Reward: -22198.2
Min Reward: -34033
Max Reward: -11765
Gini Coefficient: -0.2002072240091539
20:20 Ratio: 0.34569388534657536
Max-min Ratio: 0.34569388534657536
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-13-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -70080.05059441771
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1103
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.534
    dispatch_time_ms: 9.594
    learner:
      cur_lr: 0.0009927010396495461
      grad_gnorm: 40.000003814697266
      policy_entropy: 29.281618118286133
      policy_loss: -5447.83251953125
      var_gnorm: 129.85678100585938
      vf_explained_var: 0.0
      vf_loss: 1527276.875
    num_steps_sampled: 5520000
    num_steps_trained: 5520000
    wait_time_ms: 72.755
  iterations_since_restore: 1104
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9595.820292949677
  time_this_iter_s: 8.416341543197632
  time_total_s: 9595.820292949677
  timestamp: 1594865634
  timesteps_since_restore: 5520000
  timesteps_this_iter: 5000
  timesteps_total: 5520000
  training_iteration: 1104
  
agent-1: -14287.612252493547
agent-2: -29062.25697435924
agent-3: -30508.9980495029
agent-4: -34153.920737997025
agent-5: -12927.665955210463
Extrinsic Rewards:
-14190
-28893
-30332
-33959
-12838
Sum Reward: -120212
Avg Reward: -24042.4
Min Reward: -33959
Max Reward: -12838
Gini Coefficient: -0.19427012278308323
20:20 Ratio: 0.37804411201743277
Max-min Ratio: 0.37804411201743277
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9595 s, 1104 iter, 5520000 ts, -7.01e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-14-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -70603.45551494724
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1104
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.775
    dispatch_time_ms: 7.405
    learner:
      cur_lr: 0.0009923679754137993
      grad_gnorm: 40.0
      policy_entropy: 32.835758209228516
      policy_loss: -1538.3095703125
      var_gnorm: 130.34266662597656
      vf_explained_var: 0.0
      vf_loss: 397234.53125
    num_steps_sampled: 5525000
    num_steps_trained: 5525000
    wait_time_ms: 76.911
  iterations_since_restore: 1105
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9604.028901815414
  time_this_iter_s: 8.208608865737915
  time_total_s: 9604.028901815414
  timestamp: 1594865642
  timesteps_since_restore: 5525000
  timesteps_this_iter: 5000
  timesteps_total: 5525000
  training_iteration: 1105
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9604 s, 1105 iter, 5525000 ts, -7.06e+04 rew

agent-1: -18419.99345068768
agent-2: -7609.181902475653
agent-3: -29398.67741378562
agent-4: -23309.261024176638
agent-5: -7054.630252491643
Extrinsic Rewards:
-18263
-7547
-29172
-23122
-6998
Sum Reward: -85102
Avg Reward: -17020.4
Min Reward: -29172
Max Reward: -6998
Gini Coefficient: -0.2816526051091631
20:20 Ratio: 0.23988756341697517
Max-min Ratio: 0.23988756341697517
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-14-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -70574.90385253423
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1105
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.053
    dispatch_time_ms: 6.091
    learner:
      cur_lr: 0.0009920350275933743
      grad_gnorm: 40.000003814697266
      policy_entropy: 31.367488861083984
      policy_loss: -3523.765625
      var_gnorm: 130.80340576171875
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1151118.375
    num_steps_sampled: 5530000
    num_steps_trained: 5530000
    wait_time_ms: 74.96
  iterations_since_restore: 1106
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9612.292027950287
  time_this_iter_s: 8.263126134872437
  time_total_s: 9612.292027950287
  timestamp: 1594865650
  timesteps_since_restore: 5530000
  timesteps_this_iter: 5000
  timesteps_total: 5530000
  training_iteration: 1106
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9612 s, 1106 iter, 5530000 ts, -7.06e+04 rew

agent-1: -14298.320445554024
agent-2: -22762.204216160364
agent-3: -37123.569974363956
agent-4: -2765.804351139023
agent-5: -30559.013361722384
Extrinsic Rewards:
-14192
-22604
-36904
-2749
-30361
Sum Reward: -106810
Avg Reward: -21362.0
Min Reward: -36904
Max Reward: -2749
Gini Coefficient: -0.3163711262990357
20:20 Ratio: 0.07449057012789942
Max-min Ratio: 0.07449057012789942
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-14-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -70885.83215516232
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1106
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.676
    dispatch_time_ms: 8.575
    learner:
      cur_lr: 0.0009917019633576274
      grad_gnorm: 40.0
      policy_entropy: 29.41211700439453
      policy_loss: -2766.952880859375
      var_gnorm: 131.22108459472656
      vf_explained_var: 0.0
      vf_loss: 637086.3125
    num_steps_sampled: 5535000
    num_steps_trained: 5535000
    wait_time_ms: 72.505
  iterations_since_restore: 1107
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9620.62219452858
  time_this_iter_s: 8.330166578292847
  time_total_s: 9620.62219452858
  timestamp: 1594865659
  timesteps_since_restore: 5535000
  timesteps_this_iter: 5000
  timesteps_total: 5535000
  training_iteration: 1107
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9620 s, 1107 iter, 5535000 ts, -7.09e+04 rew

agent-1: -38426.04124316619
agent-2: -35502.455492526184
agent-3: -24317.39121560714
agent-4: -18942.268523391213
agent-5: -19100.592147971976
Extrinsic Rewards:
-38237
-35315
-24184
-18826
-18988
Sum Reward: -135550
Avg Reward: -27110.0
Min Reward: -38237
Max Reward: -18826
Gini Coefficient: -0.16274142382884543
20:20 Ratio: 0.4923503412924654
Max-min Ratio: 0.4923503412924654
agent-1: -9902.870195432095
agent-2: -23346.71575948578
agent-3: -20453.332985193207
agent-4: -15211.860346503876
agent-5: -17570.637009772294
Extrinsic Rewards:
-9822
-23171
-20285
-15077
-17417
Sum Reward: -85772
Avg Reward: -17154.4
Min Reward: -23171
Max Reward: -9822
Gini Coefficient: -0.1487944783845544
20:20 Ratio: 0.42389193388287083
Max-min Ratio: 0.42389193388287083
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-14-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -71624.48898165162
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 2
  episodes_total: 1108
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.72
    dispatch_time_ms: 7.289
    learner:
      cur_lr: 0.0009913690155372024
      grad_gnorm: 40.0
      policy_entropy: 24.135761260986328
      policy_loss: 10907.578125
      var_gnorm: 131.71969604492188
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 7166592.5
    num_steps_sampled: 5540000
    num_steps_trained: 5540000
    wait_time_ms: 80.126
  iterations_since_restore: 1108
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9629.111456871033
  time_this_iter_s: 8.489262342453003
  time_total_s: 9629.111456871033
  timestamp: 1594865667
  timesteps_since_restore: 5540000
  timesteps_this_iter: 5000
  timesteps_total: 5540000
  training_iteration: 1108
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9629 s, 1108 iter, 5540000 ts, -7.16e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-14-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -71624.48898165162
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 0
  episodes_total: 1108
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.209
    dispatch_time_ms: 8.499
    learner:
      cur_lr: 0.0009910359513014555
      grad_gnorm: 39.999996185302734
      policy_entropy: 24.111509323120117
      policy_loss: -3368.167724609375
      var_gnorm: 132.20704650878906
      vf_explained_var: 0.0
      vf_loss: 709641.9375
    num_steps_sampled: 5545000
    num_steps_trained: 5545000
    wait_time_ms: 72.278
  iterations_since_restore: 1109
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9637.45922756195
  time_this_iter_s: 8.347770690917969
  time_total_s: 9637.45922756195
  timestamp: 1594865676
  timesteps_since_restore: 5545000
  timesteps_this_iter: 5000
  timesteps_total: 5545000
  training_iteration: 1109
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9637 s, 1109 iter, 5545000 ts, -7.16e+04 rew

agent-1: -38887.76438735945
agent-2: -21424.48022684852
agent-3: -13687.051638094721
agent-4: -50103.30091828347
agent-5: -29570.502060696184
Extrinsic Rewards:
-38709
-21318
-13612
-49887
-29417
Sum Reward: -152943
Avg Reward: -30588.6
Min Reward: -49887
Max Reward: -13612
Gini Coefficient: -0.23522750305669432
20:20 Ratio: 0.2728566560426564
Max-min Ratio: 0.2728566560426564
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-14-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -72283.28077658867
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1109
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.971
    dispatch_time_ms: 7.266
    learner:
      cur_lr: 0.0009907030034810305
      grad_gnorm: 40.0
      policy_entropy: 28.75507926940918
      policy_loss: -1794.8521728515625
      var_gnorm: 132.6907501220703
      vf_explained_var: -0.06114482879638672
      vf_loss: 696798.1875
    num_steps_sampled: 5550000
    num_steps_trained: 5550000
    wait_time_ms: 68.674
  iterations_since_restore: 1110
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9645.764001607895
  time_this_iter_s: 8.304774045944214
  time_total_s: 9645.764001607895
  timestamp: 1594865684
  timesteps_since_restore: 5550000
  timesteps_this_iter: 5000
  timesteps_total: 5550000
  training_iteration: 1110
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9645 s, 1110 iter, 5550000 ts, -7.23e+04 rew

agent-1: -12239.071863569663
agent-2: -23867.907755224656
agent-3: -26026.507198629508
agent-4: -33271.27784843365
agent-5: -27504.126719018306
Extrinsic Rewards:
-12155
-23718
-25864
-33081
-27342
Sum Reward: -122160
Avg Reward: -24432.0
Min Reward: -33081
Max Reward: -12155
Gini Coefficient: -0.1489063523248199
20:20 Ratio: 0.36743145612285
Max-min Ratio: 0.36743145612285
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-14-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -72696.0877235027
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1110
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.773
    dispatch_time_ms: 7.064
    learner:
      cur_lr: 0.0009903700556606054
      grad_gnorm: 40.000003814697266
      policy_entropy: 26.84149932861328
      policy_loss: -917.947998046875
      var_gnorm: 133.15090942382812
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 156030.375
    num_steps_sampled: 5555000
    num_steps_trained: 5555000
    wait_time_ms: 75.309
  iterations_since_restore: 1111
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9654.165645599365
  time_this_iter_s: 8.401643991470337
  time_total_s: 9654.165645599365
  timestamp: 1594865692
  timesteps_since_restore: 5555000
  timesteps_this_iter: 5000
  timesteps_total: 5555000
  training_iteration: 1111
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9654 s, 1111 iter, 5555000 ts, -7.27e+04 rew

agent-1: -34133.46696590148
agent-2: -25604.509741963797
agent-3: -20674.62427894082
agent-4: -7905.387793950702
agent-5: -36147.75016386137
Extrinsic Rewards:
-33937
-25449
-20541
-7856
-35959
Sum Reward: -123742
Avg Reward: -24748.4
Min Reward: -35959
Max Reward: -7856
Gini Coefficient: -0.2249907064699132
20:20 Ratio: 0.2184710364581885
Max-min Ratio: 0.2184710364581885
agent-1: -26105.777774711005
agent-2: -19851.697984960414
agent-3: -23981.024457789827
agent-4: -18420.994142510895
agent-5: -26283.030153191285
Extrinsic Rewards:
-25936
-19716
-23826
-18291
-26114
Sum Reward: -113883
Avg Reward: -22776.6
Min Reward: -26114
Max Reward: -18291
Gini Coefficient: -0.07680162974280622
20:20 Ratio: 0.7004288887186949
Max-min Ratio: 0.7004288887186949
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-15-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -74143.52370318821
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 2
  episodes_total: 1112
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.259
    dispatch_time_ms: 33.419
    learner:
      cur_lr: 0.0009900369914248586
      grad_gnorm: 40.0
      policy_entropy: 27.31308937072754
      policy_loss: -795.1630859375
      var_gnorm: 133.65626525878906
      vf_explained_var: 0.0
      vf_loss: 182183.421875
    num_steps_sampled: 5560000
    num_steps_trained: 5560000
    wait_time_ms: 32.636
  iterations_since_restore: 1112
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9674.28401875496
  time_this_iter_s: 20.118373155593872
  time_total_s: 9674.28401875496
  timestamp: 1594865712
  timesteps_since_restore: 5560000
  timesteps_this_iter: 5000
  timesteps_total: 5560000
  training_iteration: 1112
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9674 s, 1112 iter, 5560000 ts, -7.41e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-15-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -74143.52370318821
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 0
  episodes_total: 1112
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.823
    dispatch_time_ms: 36.387
    learner:
      cur_lr: 0.0009897040436044335
      grad_gnorm: 40.0
      policy_entropy: 36.20318603515625
      policy_loss: -904.5844116210938
      var_gnorm: 134.01768493652344
      vf_explained_var: 0.0
      vf_loss: 391712.0625
    num_steps_sampled: 5565000
    num_steps_trained: 5565000
    wait_time_ms: 55.908
  iterations_since_restore: 1113
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9682.965576410294
  time_this_iter_s: 8.681557655334473
  time_total_s: 9682.965576410294
  timestamp: 1594865721
  timesteps_since_restore: 5565000
  timesteps_this_iter: 5000
  timesteps_total: 5565000
  training_iteration: 1113
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9682 s, 1113 iter, 5565000 ts, -7.41e+04 rew

agent-1: -11182.043443562981
agent-2: -3324.1329214978973
agent-3: -15335.289424288128
agent-4: -13339.013563359531
agent-5: -7839.44214388348
Extrinsic Rewards:
-11024
-3272
-15133
-13159
-7730
Sum Reward: -50318
Avg Reward: -10063.6
Min Reward: -15133
Max Reward: -3272
Gini Coefficient: -0.2317341706745101
20:20 Ratio: 0.21621621621621623
Max-min Ratio: 0.21621621621621623
agent-1: -17702.12630713993
agent-2: -14189.911611675507
agent-3: -9044.182069782511
agent-4: -23697.101321759466
agent-5: -26507.623755960125
Extrinsic Rewards:
-17548
-14062
-8966
-23524
-26304
Sum Reward: -90404
Avg Reward: -18080.8
Min Reward: -26304
Max Reward: -8966
Gini Coefficient: -0.1952922437060307
20:20 Ratio: 0.34086070559610704
Max-min Ratio: 0.34086070559610704
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-15-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -74916.87059930126
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 2
  episodes_total: 1114
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.682
    dispatch_time_ms: 45.602
    learner:
      cur_lr: 0.0009893709793686867
      grad_gnorm: 40.0
      policy_entropy: 37.38580322265625
      policy_loss: -2269.63916015625
      var_gnorm: 134.43557739257812
      vf_explained_var: 0.0
      vf_loss: 215153.1875
    num_steps_sampled: 5570000
    num_steps_trained: 5570000
    wait_time_ms: 41.502
  iterations_since_restore: 1114
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9692.065948009491
  time_this_iter_s: 9.100371599197388
  time_total_s: 9692.065948009491
  timestamp: 1594865730
  timesteps_since_restore: 5570000
  timesteps_this_iter: 5000
  timesteps_total: 5570000
  training_iteration: 1114
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9692 s, 1114 iter, 5570000 ts, -7.49e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-15-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -74916.87059930124
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 0
  episodes_total: 1114
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.076
    dispatch_time_ms: 27.986
    learner:
      cur_lr: 0.0009890380315482616
      grad_gnorm: 40.0
      policy_entropy: 38.492835998535156
      policy_loss: -1758.8619384765625
      var_gnorm: 134.8688507080078
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 185056.625
    num_steps_sampled: 5575000
    num_steps_trained: 5575000
    wait_time_ms: 47.027
  iterations_since_restore: 1115
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9700.463803052902
  time_this_iter_s: 8.397855043411255
  time_total_s: 9700.463803052902
  timestamp: 1594865739
  timesteps_since_restore: 5575000
  timesteps_this_iter: 5000
  timesteps_total: 5575000
  training_iteration: 1115
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9700 s, 1115 iter, 5575000 ts, -7.49e+04 rew

agent-1: -9396.888842815437
agent-2: -16696.807560080408
agent-3: -5412.434121459437
agent-4: -12818.792845769034
agent-5: -11461.735560259041
Extrinsic Rewards:
-9268
-16501
-5338
-12647
-11323
Sum Reward: -55077
Avg Reward: -11015.4
Min Reward: -16501
Max Reward: -5338
Gini Coefficient: -0.18668409680992065
20:20 Ratio: 0.32349554572450157
Max-min Ratio: 0.32349554572450157
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-15-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -75333.89670396139
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1115
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.121
    dispatch_time_ms: 7.781
    learner:
      cur_lr: 0.0009887049673125148
      grad_gnorm: 40.0
      policy_entropy: 38.465633392333984
      policy_loss: -3540.6416015625
      var_gnorm: 135.2359161376953
      vf_explained_var: 0.0
      vf_loss: 759812.1875
    num_steps_sampled: 5580000
    num_steps_trained: 5580000
    wait_time_ms: 73.626
  iterations_since_restore: 1116
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9708.757482528687
  time_this_iter_s: 8.293679475784302
  time_total_s: 9708.757482528687
  timestamp: 1594865747
  timesteps_since_restore: 5580000
  timesteps_this_iter: 5000
  timesteps_total: 5580000
  training_iteration: 1116
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9708 s, 1116 iter, 5580000 ts, -7.53e+04 rew

agent-1: -16719.621198162833
agent-2: -8872.168980940392
agent-3: -19578.437383024288
agent-4: -13929.086898521775
agent-5: -14053.653878077825
Extrinsic Rewards:
-16551
-8780
-19390
-13782
-13902
Sum Reward: -72405
Avg Reward: -14481.0
Min Reward: -19390
Max Reward: -8780
Gini Coefficient: -0.13252675920171259
20:20 Ratio: 0.4528107271789582
Max-min Ratio: 0.4528107271789582
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-15-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -75965.2501389096
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1116
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.497
    dispatch_time_ms: 5.246
    learner:
      cur_lr: 0.0009883720194920897
      grad_gnorm: 40.0
      policy_entropy: 39.600502014160156
      policy_loss: -4551.3388671875
      var_gnorm: 135.71388244628906
      vf_explained_var: 0.0
      vf_loss: 975432.375
    num_steps_sampled: 5585000
    num_steps_trained: 5585000
    wait_time_ms: 73.314
  iterations_since_restore: 1117
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9716.934963226318
  time_this_iter_s: 8.177480697631836
  time_total_s: 9716.934963226318
  timestamp: 1594865755
  timesteps_since_restore: 5585000
  timesteps_this_iter: 5000
  timesteps_total: 5585000
  training_iteration: 1117
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9716 s, 1117 iter, 5585000 ts, -7.6e+04 rew

agent-1: -19259.019615756588
agent-2: -19709.496171803814
agent-3: -24313.41163348989
agent-4: -26430.7017659606
agent-5: -11973.82506606498
Extrinsic Rewards:
-19116
-19568
-24140
-26244
-11882
Sum Reward: -100950
Avg Reward: -20190.0
Min Reward: -26244
Max Reward: -11882
Gini Coefficient: -0.13372164437840514
20:20 Ratio: 0.4527511050144795
Max-min Ratio: 0.4527511050144795
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-16-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -76834.42192813176
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1117
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.723
    dispatch_time_ms: 5.603
    learner:
      cur_lr: 0.0009880389552563429
      grad_gnorm: 39.999996185302734
      policy_entropy: 40.298309326171875
      policy_loss: -2923.7333984375
      var_gnorm: 136.18093872070312
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 624885.0
    num_steps_sampled: 5590000
    num_steps_trained: 5590000
    wait_time_ms: 70.035
  iterations_since_restore: 1118
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9725.158879995346
  time_this_iter_s: 8.22391676902771
  time_total_s: 9725.158879995346
  timestamp: 1594865764
  timesteps_since_restore: 5590000
  timesteps_this_iter: 5000
  timesteps_total: 5590000
  training_iteration: 1118
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9725 s, 1118 iter, 5590000 ts, -7.68e+04 rew

agent-1: -30965.803150855423
agent-2: -13380.470748689515
agent-3: -10905.482945177468
agent-4: -15047.342002583013
agent-5: -18521.612903410412
Extrinsic Rewards:
-30741
-13256
-10812
-14918
-18362
Sum Reward: -88089
Avg Reward: -17617.8
Min Reward: -30741
Max Reward: -10812
Gini Coefficient: -0.20417532268501176
20:20 Ratio: 0.35171269639894603
Max-min Ratio: 0.35171269639894603
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-16-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -77625.74600156641
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1118
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.9
    dispatch_time_ms: 7.567
    learner:
      cur_lr: 0.0009877060074359179
      grad_gnorm: 40.000003814697266
      policy_entropy: 33.624351501464844
      policy_loss: -3536.846923828125
      var_gnorm: 136.60462951660156
      vf_explained_var: 0.0
      vf_loss: 959838.0
    num_steps_sampled: 5595000
    num_steps_trained: 5595000
    wait_time_ms: 73.54
  iterations_since_restore: 1119
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9733.39478135109
  time_this_iter_s: 8.235901355743408
  time_total_s: 9733.39478135109
  timestamp: 1594865772
  timesteps_since_restore: 5595000
  timesteps_this_iter: 5000
  timesteps_total: 5595000
  training_iteration: 1119
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9733 s, 1119 iter, 5595000 ts, -7.76e+04 rew

agent-1: -14599.297416398642
agent-2: -27258.665717695636
agent-3: -11359.516489981814
agent-4: -31686.650495108515
agent-5: -15251.098695973998
Extrinsic Rewards:
-14482
-27065
-11253
-31478
-15143
Sum Reward: -99421
Avg Reward: -19884.2
Min Reward: -31478
Max Reward: -11253
Gini Coefficient: -0.21336739722996148
20:20 Ratio: 0.35748776923565667
Max-min Ratio: 0.35748776923565667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-16-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -78543.81801890889
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1119
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.038
    dispatch_time_ms: 7.804
    learner:
      cur_lr: 0.000987372943200171
      grad_gnorm: 39.999996185302734
      policy_entropy: 32.80702590942383
      policy_loss: -5280.6552734375
      var_gnorm: 137.0751190185547
      vf_explained_var: 0.0
      vf_loss: 1014141.6875
    num_steps_sampled: 5600000
    num_steps_trained: 5600000
    wait_time_ms: 72.47
  iterations_since_restore: 1120
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9741.69487786293
  time_this_iter_s: 8.30009651184082
  time_total_s: 9741.69487786293
  timestamp: 1594865780
  timesteps_since_restore: 5600000
  timesteps_this_iter: 5000
  timesteps_total: 5600000
  training_iteration: 1120
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9741 s, 1120 iter, 5600000 ts, -7.85e+04 rew

agent-1: -3775.2560649485636
agent-2: -24279.989653292596
agent-3: -13364.970233377331
agent-4: -21549.073293660244
agent-5: -25470.668841077393
Extrinsic Rewards:
-3744
-24099
-13245
-21370
-25272
Sum Reward: -87730
Avg Reward: -17546.0
Min Reward: -25272
Max Reward: -3744
Gini Coefficient: -0.24579961244728143
20:20 Ratio: 0.14814814814814814
Max-min Ratio: 0.14814814814814814
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-16-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -79340.76260631949
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1120
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.352
    dispatch_time_ms: 9.489
    learner:
      cur_lr: 0.000987039995379746
      grad_gnorm: 40.0
      policy_entropy: 25.851774215698242
      policy_loss: -4419.16064453125
      var_gnorm: 137.54286193847656
      vf_explained_var: 0.0
      vf_loss: 665248.5625
    num_steps_sampled: 5605000
    num_steps_trained: 5605000
    wait_time_ms: 74.279
  iterations_since_restore: 1121
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9750.046599388123
  time_this_iter_s: 8.35172152519226
  time_total_s: 9750.046599388123
  timestamp: 1594865789
  timesteps_since_restore: 5605000
  timesteps_this_iter: 5000
  timesteps_total: 5605000
  training_iteration: 1121
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9750 s, 1121 iter, 5605000 ts, -7.93e+04 rew

agent-1: -17108.833298675247
agent-2: -37141.513673611815
agent-3: -27747.707365269114
agent-4: -45010.71105100483
agent-5: -36916.650800121126
Extrinsic Rewards:
-17023
-36969
-27613
-44818
-36761
Sum Reward: -163184
Avg Reward: -32636.8
Min Reward: -44818
Max Reward: -17023
Gini Coefficient: -0.15919698009608785
20:20 Ratio: 0.37982507028426077
Max-min Ratio: 0.37982507028426077
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-16-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -80919.94954151848
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1121
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.169
    dispatch_time_ms: 8.871
    learner:
      cur_lr: 0.000986707047559321
      grad_gnorm: 40.0
      policy_entropy: 20.929073333740234
      policy_loss: -1246.4735107421875
      var_gnorm: 138.05357360839844
      vf_explained_var: 0.0
      vf_loss: 498081.375
    num_steps_sampled: 5610000
    num_steps_trained: 5610000
    wait_time_ms: 72.179
  iterations_since_restore: 1122
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9758.53549194336
  time_this_iter_s: 8.488892555236816
  time_total_s: 9758.53549194336
  timestamp: 1594865797
  timesteps_since_restore: 5610000
  timesteps_this_iter: 5000
  timesteps_total: 5610000
  training_iteration: 1122
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9758 s, 1122 iter, 5610000 ts, -8.09e+04 rew

agent-1: -28298.106858838306
agent-2: -26471.618249661096
agent-3: -27240.31378601933
agent-4: -22877.33551115892
agent-5: -27679.785830874564
Extrinsic Rewards:
-28141
-26314
-27133
-22730
-27518
Sum Reward: -131836
Avg Reward: -26367.2
Min Reward: -28141
Max Reward: -22730
Gini Coefficient: -0.03648775751691496
20:20 Ratio: 0.8077182758253083
Max-min Ratio: 0.8077182758253083
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-16-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -82189.94203447233
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1122
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.301
    dispatch_time_ms: 8.773
    learner:
      cur_lr: 0.000986373983323574
      grad_gnorm: 40.0
      policy_entropy: 22.934141159057617
      policy_loss: -406.1820068359375
      var_gnorm: 138.43710327148438
      vf_explained_var: 0.0
      vf_loss: 847176.875
    num_steps_sampled: 5615000
    num_steps_trained: 5615000
    wait_time_ms: 71.748
  iterations_since_restore: 1123
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9767.020444869995
  time_this_iter_s: 8.484952926635742
  time_total_s: 9767.020444869995
  timestamp: 1594865806
  timesteps_since_restore: 5615000
  timesteps_this_iter: 5000
  timesteps_total: 5615000
  training_iteration: 1123
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9767 s, 1123 iter, 5615000 ts, -8.22e+04 rew

agent-1: -22467.607053438787
agent-2: -25327.319781022492
agent-3: -15636.07293774466
agent-4: -5690.6226406412325
agent-5: -19454.237155326733
Extrinsic Rewards:
-22291
-25139
-15505
-5636
-19298
Sum Reward: -87869
Avg Reward: -17573.8
Min Reward: -25139
Max Reward: -5636
Gini Coefficient: -0.2084557693839693
20:20 Ratio: 0.22419348422769403
Max-min Ratio: 0.22419348422769403
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-16-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -83028.2312870499
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1123
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.6
    dispatch_time_ms: 36.143
    learner:
      cur_lr: 0.000986041035503149
      grad_gnorm: 40.0
      policy_entropy: 29.467538833618164
      policy_loss: -2905.091552734375
      var_gnorm: 138.8480224609375
      vf_explained_var: 0.0
      vf_loss: 554741.75
    num_steps_sampled: 5620000
    num_steps_trained: 5620000
    wait_time_ms: 53.007
  iterations_since_restore: 1124
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9775.94572877884
  time_this_iter_s: 8.925283908843994
  time_total_s: 9775.94572877884
  timestamp: 1594865815
  timesteps_since_restore: 5620000
  timesteps_this_iter: 5000
  timesteps_total: 5620000
  training_iteration: 1124
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9775 s, 1124 iter, 5620000 ts, -8.3e+04 rew

agent-1: -18729.527824942335
agent-2: -19956.664250402468
agent-3: -26256.85781202609
agent-4: -20676.791032225738
agent-5: -23646.787429433436
Extrinsic Rewards:
-18603
-19818
-26087
-20533
-23485
Sum Reward: -108526
Avg Reward: -21705.2
Min Reward: -26087
Max Reward: -18603
Gini Coefficient: -0.06868400199030647
20:20 Ratio: 0.7131138114769808
Max-min Ratio: 0.7131138114769808
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-17-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -84078.97093559928
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1124
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.658
    dispatch_time_ms: 40.37
    learner:
      cur_lr: 0.0009857079712674022
      grad_gnorm: 40.0
      policy_entropy: 32.015228271484375
      policy_loss: -439.5625
      var_gnorm: 139.2519073486328
      vf_explained_var: 0.0
      vf_loss: 105950.9609375
    num_steps_sampled: 5625000
    num_steps_trained: 5625000
    wait_time_ms: 43.359
  iterations_since_restore: 1125
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9784.790481567383
  time_this_iter_s: 8.844752788543701
  time_total_s: 9784.790481567383
  timestamp: 1594865823
  timesteps_since_restore: 5625000
  timesteps_this_iter: 5000
  timesteps_total: 5625000
  training_iteration: 1125
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9784 s, 1125 iter, 5625000 ts, -8.41e+04 rew

agent-1: -27918.98541726916
agent-2: -10102.940526161254
agent-3: -16469.262265614747
agent-4: -15042.583719325345
agent-5: -9304.650884278359
Extrinsic Rewards:
-27696
-10000
-16318
-14901
-9205
Sum Reward: -78120
Avg Reward: -15624.0
Min Reward: -27696
Max Reward: -9205
Gini Coefficient: -0.22171018945212492
20:20 Ratio: 0.33235846331600233
Max-min Ratio: 0.33235846331600233
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-17-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4032.1676168457348
  episode_reward_mean: -84824.20596876586
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1125
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.928
    dispatch_time_ms: 39.019
    learner:
      cur_lr: 0.0009853750234469771
      grad_gnorm: 40.0
      policy_entropy: 29.56554412841797
      policy_loss: -2818.147705078125
      var_gnorm: 139.7179412841797
      vf_explained_var: 0.0
      vf_loss: 806738.875
    num_steps_sampled: 5630000
    num_steps_trained: 5630000
    wait_time_ms: 48.539
  iterations_since_restore: 1126
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9793.671391487122
  time_this_iter_s: 8.88090991973877
  time_total_s: 9793.671391487122
  timestamp: 1594865832
  timesteps_since_restore: 5630000
  timesteps_this_iter: 5000
  timesteps_total: 5630000
  training_iteration: 1126
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9793 s, 1126 iter, 5630000 ts, -8.48e+04 rew

agent-1: -28769.738370593586
agent-2: -26442.78641199686
agent-3: -39057.03705674401
agent-4: -12589.747310209803
agent-5: -3331.865608350208
Extrinsic Rewards:
-28583
-26265
-38833
-12498
-3309
Sum Reward: -109488
Avg Reward: -21897.6
Min Reward: -38833
Max Reward: -3309
Gini Coefficient: -0.31832894929124655
20:20 Ratio: 0.08521103185435068
Max-min Ratio: 0.08521103185435068
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-17-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4563.857545800465
  episode_reward_mean: -85885.79604017634
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1126
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.074
    dispatch_time_ms: 32.249
    learner:
      cur_lr: 0.0009850419592112303
      grad_gnorm: 40.000003814697266
      policy_entropy: 32.52488327026367
      policy_loss: -1689.0155029296875
      var_gnorm: 140.12420654296875
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 374853.4375
    num_steps_sampled: 5635000
    num_steps_trained: 5635000
    wait_time_ms: 71.276
  iterations_since_restore: 1127
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9802.743411302567
  time_this_iter_s: 9.072019815444946
  time_total_s: 9802.743411302567
  timestamp: 1594865841
  timesteps_since_restore: 5635000
  timesteps_this_iter: 5000
  timesteps_total: 5635000
  training_iteration: 1127
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9802 s, 1127 iter, 5635000 ts, -8.59e+04 rew

agent-1: -32290.007381506864
agent-2: -17474.441463144114
agent-3: -30323.914154344726
agent-4: -9524.384066592796
agent-5: -18872.561347205967
Extrinsic Rewards:
-32093
-17351
-30135
-9449
-18741
Sum Reward: -107769
Avg Reward: -21553.8
Min Reward: -32093
Max Reward: -9449
Gini Coefficient: -0.21554250294611624
20:20 Ratio: 0.294425575670707
Max-min Ratio: 0.294425575670707
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-17-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4563.857545800465
  episode_reward_mean: -86856.29828253822
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1127
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.872
    dispatch_time_ms: 40.334
    learner:
      cur_lr: 0.0009847090113908052
      grad_gnorm: 40.000003814697266
      policy_entropy: 22.662559509277344
      policy_loss: -2523.201416015625
      var_gnorm: 140.60382080078125
      vf_explained_var: 0.0
      vf_loss: 496934.4375
    num_steps_sampled: 5640000
    num_steps_trained: 5640000
    wait_time_ms: 49.768
  iterations_since_restore: 1128
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9811.577142953873
  time_this_iter_s: 8.833731651306152
  time_total_s: 9811.577142953873
  timestamp: 1594865850
  timesteps_since_restore: 5640000
  timesteps_this_iter: 5000
  timesteps_total: 5640000
  training_iteration: 1128
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9811 s, 1128 iter, 5640000 ts, -8.69e+04 rew

agent-1: -8990.595893643243
agent-2: -17630.983955950363
agent-3: -26177.225310858423
agent-4: -12376.032769609035
agent-5: -30110.258247084428
Extrinsic Rewards:
-8917
-17488
-25983
-12282
-29908
Sum Reward: -94578
Avg Reward: -18915.6
Min Reward: -29908
Max Reward: -8917
Gini Coefficient: -0.2355008564359576
20:20 Ratio: 0.2981476528019259
Max-min Ratio: 0.2981476528019259
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-17-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4563.857545800465
  episode_reward_mean: -87673.40901649962
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1128
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.103
    dispatch_time_ms: 22.842
    learner:
      cur_lr: 0.0009843759471550584
      grad_gnorm: 40.0
      policy_entropy: 12.636293411254883
      policy_loss: -560.578125
      var_gnorm: 140.93040466308594
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 542695.8125
    num_steps_sampled: 5645000
    num_steps_trained: 5645000
    wait_time_ms: 68.054
  iterations_since_restore: 1129
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9820.574340581894
  time_this_iter_s: 8.99719762802124
  time_total_s: 9820.574340581894
  timestamp: 1594865859
  timesteps_since_restore: 5645000
  timesteps_this_iter: 5000
  timesteps_total: 5645000
  training_iteration: 1129
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9820 s, 1129 iter, 5645000 ts, -8.77e+04 rew

agent-1: -5627.8689430008935
agent-2: -22060.93705754959
agent-3: -12756.538374928303
agent-4: -15028.378065972971
agent-5: -21241.92478037103
Extrinsic Rewards:
-5560
-21885
-12626
-14881
-21067
Sum Reward: -76019
Avg Reward: -15203.8
Min Reward: -21885
Max Reward: -5560
Gini Coefficient: -0.2162143674607664
20:20 Ratio: 0.25405528901073793
Max-min Ratio: 0.25405528901073793
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-17-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4563.857545800465
  episode_reward_mean: -88335.17810094915
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1129
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.252
    dispatch_time_ms: 26.996
    learner:
      cur_lr: 0.0009840429993346334
      grad_gnorm: 40.0
      policy_entropy: 19.401893615722656
      policy_loss: -2316.47705078125
      var_gnorm: 141.29568481445312
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 485422.125
    num_steps_sampled: 5650000
    num_steps_trained: 5650000
    wait_time_ms: 66.966
  iterations_since_restore: 1130
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9829.75615811348
  time_this_iter_s: 9.181817531585693
  time_total_s: 9829.75615811348
  timestamp: 1594865869
  timesteps_since_restore: 5650000
  timesteps_this_iter: 5000
  timesteps_total: 5650000
  training_iteration: 1130
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9829 s, 1130 iter, 5650000 ts, -8.83e+04 rew

agent-1: -16325.857041813539
agent-2: -18750.831989074963
agent-3: -17035.51439979659
agent-4: -15681.26169487914
agent-5: -20329.881137065036
Extrinsic Rewards:
-16196
-18581
-16910
-15576
-20155
Sum Reward: -87418
Avg Reward: -17483.6
Min Reward: -20155
Max Reward: -15576
Gini Coefficient: -0.05281749754055229
20:20 Ratio: 0.7728107169436864
Max-min Ratio: 0.7728107169436864
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-17-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4563.857545800465
  episode_reward_mean: -89092.32817858591
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1130
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 4.135
    dispatch_time_ms: 31.405
    learner:
      cur_lr: 0.0009837100515142083
      grad_gnorm: 40.0
      policy_entropy: 36.67379379272461
      policy_loss: -1727.867919921875
      var_gnorm: 141.71705627441406
      vf_explained_var: 0.0
      vf_loss: 412967.1875
    num_steps_sampled: 5655000
    num_steps_trained: 5655000
    wait_time_ms: 60.435
  iterations_since_restore: 1131
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9838.693511009216
  time_this_iter_s: 8.937352895736694
  time_total_s: 9838.693511009216
  timestamp: 1594865878
  timesteps_since_restore: 5655000
  timesteps_this_iter: 5000
  timesteps_total: 5655000
  training_iteration: 1131
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9838 s, 1131 iter, 5655000 ts, -8.91e+04 rew

agent-1: -23409.015589154507
agent-2: -19558.049222316808
agent-3: -27860.922881901693
agent-4: -14159.095673894526
agent-5: -21494.433626570913
Extrinsic Rewards:
-23250
-19421
-27678
-14059
-21335
Sum Reward: -105743
Avg Reward: -21148.6
Min Reward: -27678
Max Reward: -14059
Gini Coefficient: -0.1175188901393
20:20 Ratio: 0.5079485511958957
Max-min Ratio: 0.5079485511958957
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-18-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4563.857545800465
  episode_reward_mean: -90084.12230593126
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1131
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.402
    dispatch_time_ms: 6.055
    learner:
      cur_lr: 0.0009833769872784615
      grad_gnorm: 40.0
      policy_entropy: 40.42667770385742
      policy_loss: -1023.8449096679688
      var_gnorm: 142.20281982421875
      vf_explained_var: 0.0
      vf_loss: 139248.640625
    num_steps_sampled: 5660000
    num_steps_trained: 5660000
    wait_time_ms: 76.608
  iterations_since_restore: 1132
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9847.304786205292
  time_this_iter_s: 8.61127519607544
  time_total_s: 9847.304786205292
  timestamp: 1594865886
  timesteps_since_restore: 5660000
  timesteps_this_iter: 5000
  timesteps_total: 5660000
  training_iteration: 1132
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9847 s, 1132 iter, 5660000 ts, -9.01e+04 rew

agent-1: -17308.379744822763
agent-2: -24759.097291327216
agent-3: -26964.759801296972
agent-4: -29040.1165136159
agent-5: -14193.504010561344
Extrinsic Rewards:
-17182
-24601
-26790
-28858
-14095
Sum Reward: -111526
Avg Reward: -22305.2
Min Reward: -28858
Max Reward: -14095
Gini Coefficient: -0.14035830209995875
20:20 Ratio: 0.4884260863538707
Max-min Ratio: 0.4884260863538707
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-18-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4563.857545800465
  episode_reward_mean: -91150.59636810001
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1132
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.692
    dispatch_time_ms: 7.398
    learner:
      cur_lr: 0.0009830440394580364
      grad_gnorm: 40.0
      policy_entropy: 35.74851608276367
      policy_loss: -6031.4453125
      var_gnorm: 142.61474609375
      vf_explained_var: 0.0
      vf_loss: 1360267.875
    num_steps_sampled: 5665000
    num_steps_trained: 5665000
    wait_time_ms: 69.705
  iterations_since_restore: 1133
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9855.570704936981
  time_this_iter_s: 8.265918731689453
  time_total_s: 9855.570704936981
  timestamp: 1594865894
  timesteps_since_restore: 5665000
  timesteps_this_iter: 5000
  timesteps_total: 5665000
  training_iteration: 1133
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9855 s, 1133 iter, 5665000 ts, -9.12e+04 rew

agent-1: -28635.56184889051
agent-2: -23758.933642588116
agent-3: -10466.558828964005
agent-4: -31930.06974966757
agent-5: -23714.618689426134
Extrinsic Rewards:
-28452
-23593
-10400
-31746
-23576
Sum Reward: -117767
Avg Reward: -23553.4
Min Reward: -31746
Max Reward: -10400
Gini Coefficient: -0.16156648297061146
20:20 Ratio: 0.3276003276003276
Max-min Ratio: 0.3276003276003276
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-18-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4563.857545800465
  episode_reward_mean: -92261.20313176455
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1133
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.641
    dispatch_time_ms: 10.035
    learner:
      cur_lr: 0.0009827109752222896
      grad_gnorm: 40.0
      policy_entropy: 34.51715850830078
      policy_loss: -1063.2606201171875
      var_gnorm: 143.1221923828125
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 312536.5625
    num_steps_sampled: 5670000
    num_steps_trained: 5670000
    wait_time_ms: 72.977
  iterations_since_restore: 1134
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9863.957727193832
  time_this_iter_s: 8.387022256851196
  time_total_s: 9863.957727193832
  timestamp: 1594865903
  timesteps_since_restore: 5670000
  timesteps_this_iter: 5000
  timesteps_total: 5670000
  training_iteration: 1134
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9863 s, 1134 iter, 5670000 ts, -9.23e+04 rew

agent-1: -23321.735306354632
agent-2: -21651.348650879718
agent-3: -31883.71964230758
agent-4: -23956.15268963313
agent-5: -17609.005859275137
Extrinsic Rewards:
-23184
-21522
-31681
-23790
-17502
Sum Reward: -117679
Avg Reward: -23535.8
Min Reward: -31681
Max Reward: -17502
Gini Coefficient: -0.1041001368128553
20:20 Ratio: 0.5524446829329882
Max-min Ratio: 0.5524446829329882
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-18-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4563.857545800465
  episode_reward_mean: -93377.98738780226
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1134
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.889
    dispatch_time_ms: 7.715
    learner:
      cur_lr: 0.0009823780274018645
      grad_gnorm: 39.999996185302734
      policy_entropy: 40.04994201660156
      policy_loss: -1601.0631103515625
      var_gnorm: 143.4730682373047
      vf_explained_var: 0.0
      vf_loss: 216365.125
    num_steps_sampled: 5675000
    num_steps_trained: 5675000
    wait_time_ms: 70.214
  iterations_since_restore: 1135
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9872.286138057709
  time_this_iter_s: 8.328410863876343
  time_total_s: 9872.286138057709
  timestamp: 1594865911
  timesteps_since_restore: 5675000
  timesteps_this_iter: 5000
  timesteps_total: 5675000
  training_iteration: 1135
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9872 s, 1135 iter, 5675000 ts, -9.34e+04 rew

agent-1: -14118.140507253016
agent-2: -9278.151959769462
agent-3: -22241.39796904076
agent-4: -18612.36518274652
agent-5: -11199.273671566078
Extrinsic Rewards:
-13969
-9187
-22041
-18447
-11080
Sum Reward: -74724
Avg Reward: -14944.8
Min Reward: -22041
Max Reward: -9187
Gini Coefficient: -0.1770515497029067
20:20 Ratio: 0.41681411914159977
Max-min Ratio: 0.41681411914159977
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-18-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -5485.347216430107
  episode_reward_mean: -94086.84210524801
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1135
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.855
    dispatch_time_ms: 10.769
    learner:
      cur_lr: 0.0009820449631661177
      grad_gnorm: 40.0
      policy_entropy: 41.987361907958984
      policy_loss: -2573.001220703125
      var_gnorm: 143.7179412841797
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 369816.34375
    num_steps_sampled: 5680000
    num_steps_trained: 5680000
    wait_time_ms: 62.543
  iterations_since_restore: 1136
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9880.469882249832
  time_this_iter_s: 8.183744192123413
  time_total_s: 9880.469882249832
  timestamp: 1594865919
  timesteps_since_restore: 5680000
  timesteps_this_iter: 5000
  timesteps_total: 5680000
  training_iteration: 1136
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9880 s, 1136 iter, 5680000 ts, -9.41e+04 rew

agent-1: -11894.076284690216
agent-2: -14443.372391626886
agent-3: -14193.559139286463
agent-4: -7360.582732361372
agent-5: -12788.803656328077
Extrinsic Rewards:
-11735
-14272
-14023
-7279
-12641
Sum Reward: -59950
Avg Reward: -11990.0
Min Reward: -14272
Max Reward: -7279
Gini Coefficient: -0.10858381984987489
20:20 Ratio: 0.5100196188340808
Max-min Ratio: 0.5100196188340808
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-18-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10189.360080611197
  episode_reward_mean: -94638.79257512663
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1136
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.639
    dispatch_time_ms: 6.865
    learner:
      cur_lr: 0.0009817120153456926
      grad_gnorm: 40.0
      policy_entropy: 38.77538299560547
      policy_loss: -544.965576171875
      var_gnorm: 143.9685516357422
      vf_explained_var: 0.0
      vf_loss: 32084.1953125
    num_steps_sampled: 5685000
    num_steps_trained: 5685000
    wait_time_ms: 69.796
  iterations_since_restore: 1137
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9889.817714691162
  time_this_iter_s: 9.347832441329956
  time_total_s: 9889.817714691162
  timestamp: 1594865929
  timesteps_since_restore: 5685000
  timesteps_this_iter: 5000
  timesteps_total: 5685000
  training_iteration: 1137
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9889 s, 1137 iter, 5685000 ts, -9.46e+04 rew

agent-1: -7662.441972838075
agent-2: -4960.255063155941
agent-3: -8135.474778473611
agent-4: -7089.971324040993
agent-5: -4005.7812333549746
Extrinsic Rewards:
-7485
-4839
-7953
-6932
-3911
Sum Reward: -31120
Avg Reward: -6224.0
Min Reward: -7953
Max Reward: -3911
Gini Coefficient: -0.13791773778920308
20:20 Ratio: 0.49176411417075316
Max-min Ratio: 0.49176411417075316
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-18-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -13327.0194448526
  episode_reward_mean: -94855.43821803917
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1137
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.491
    dispatch_time_ms: 7.822
    learner:
      cur_lr: 0.0009813789511099458
      grad_gnorm: 40.000003814697266
      policy_entropy: 25.435958862304688
      policy_loss: 692.81396484375
      var_gnorm: 143.7195587158203
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 32789.6328125
    num_steps_sampled: 5690000
    num_steps_trained: 5690000
    wait_time_ms: 68.298
  iterations_since_restore: 1138
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9897.780322790146
  time_this_iter_s: 7.962608098983765
  time_total_s: 9897.780322790146
  timestamp: 1594865937
  timesteps_since_restore: 5690000
  timesteps_this_iter: 5000
  timesteps_total: 5690000
  training_iteration: 1138
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9897 s, 1138 iter, 5690000 ts, -9.49e+04 rew

agent-1: -8167.62141926475
agent-2: -5541.553489630669
agent-3: -6383.6479755964765
agent-4: -6242.844989107038
agent-5: -5348.293629347261
Extrinsic Rewards:
-7988
-5416
-6227
-6085
-5213
Sum Reward: -30929
Avg Reward: -6185.8
Min Reward: -7988
Max Reward: -5213
Gini Coefficient: -0.08226583465356138
20:20 Ratio: 0.6526039058587881
Max-min Ratio: 0.6526039058587881
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-19-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -20667.050484308544
  episode_reward_mean: -95039.00763862008
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1138
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.495
    dispatch_time_ms: 9.011
    learner:
      cur_lr: 0.0009810460032895207
      grad_gnorm: 39.99999237060547
      policy_entropy: 19.759798049926758
      policy_loss: 317.2594909667969
      var_gnorm: 143.28591918945312
      vf_explained_var: 0.0
      vf_loss: 35507.6484375
    num_steps_sampled: 5695000
    num_steps_trained: 5695000
    wait_time_ms: 69.923
  iterations_since_restore: 1139
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9905.739389419556
  time_this_iter_s: 7.95906662940979
  time_total_s: 9905.739389419556
  timestamp: 1594865945
  timesteps_since_restore: 5695000
  timesteps_this_iter: 5000
  timesteps_total: 5695000
  training_iteration: 1139
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9905 s, 1139 iter, 5695000 ts, -9.5e+04 rew

agent-1: -2031.6959987474654
agent-2: -4230.126186446632
agent-3: -6021.333924939639
agent-4: -4449.278672879074
agent-5: -3874.8245894676425
Extrinsic Rewards:
-1932
-4092
-5818
-4292
-3736
Sum Reward: -19870
Avg Reward: -3974.0
Min Reward: -5818
Max Reward: -1932
Gini Coefficient: -0.16764972320080523
20:20 Ratio: 0.3320728772774149
Max-min Ratio: 0.3320728772774149
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-19-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -20607.2593724804
  episode_reward_mean: -94831.27212409953
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1139
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.263
    dispatch_time_ms: 11.921
    learner:
      cur_lr: 0.0009807130554690957
      grad_gnorm: 39.999996185302734
      policy_entropy: 26.39684295654297
      policy_loss: 611.1563110351562
      var_gnorm: 142.9690399169922
      vf_explained_var: 0.0
      vf_loss: 26983.912109375
    num_steps_sampled: 5700000
    num_steps_trained: 5700000
    wait_time_ms: 106.904
  iterations_since_restore: 1140
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9914.109785795212
  time_this_iter_s: 8.370396375656128
  time_total_s: 9914.109785795212
  timestamp: 1594865953
  timesteps_since_restore: 5700000
  timesteps_this_iter: 5000
  timesteps_total: 5700000
  training_iteration: 1140
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9914 s, 1140 iter, 5700000 ts, -9.48e+04 rew

agent-1: -405.5821133485939
agent-2: -2032.873178378052
agent-3: -3103.0194318445115
agent-4: -5296.096243326937
agent-5: -3826.1346794934584
Extrinsic Rewards:
-379
-1931
-2941
-5083
-3637
Sum Reward: -13971
Avg Reward: -2794.2
Min Reward: -5083
Max Reward: -379
Gini Coefficient: -0.31820198983608905
20:20 Ratio: 0.07456226637812316
Max-min Ratio: 0.07456226637812316
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-19-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -94342.5413989007
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1140
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.21
    dispatch_time_ms: 9.802
    learner:
      cur_lr: 0.0009803799912333488
      grad_gnorm: 40.0
      policy_entropy: 36.72662353515625
      policy_loss: 401.8771667480469
      var_gnorm: 142.704345703125
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 34729.8359375
    num_steps_sampled: 5705000
    num_steps_trained: 5705000
    wait_time_ms: 67.566
  iterations_since_restore: 1141
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9921.881890296936
  time_this_iter_s: 7.772104501724243
  time_total_s: 9921.881890296936
  timestamp: 1594865961
  timesteps_since_restore: 5705000
  timesteps_this_iter: 5000
  timesteps_total: 5705000
  training_iteration: 1141
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9921 s, 1141 iter, 5705000 ts, -9.43e+04 rew

agent-1: -7746.0762141407195
agent-2: -6879.757199587823
agent-3: -6466.009298360292
agent-4: -3142.162471844995
agent-5: -3095.3132582888143
Extrinsic Rewards:
-7542
-6705
-6293
-3043
-3007
Sum Reward: -26590
Avg Reward: -5318.0
Min Reward: -7542
Max Reward: -3007
Gini Coefficient: -0.19153065062053404
20:20 Ratio: 0.3987006099177937
Max-min Ratio: 0.3987006099177937
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-19-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -93641.11034309123
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1141
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.564
    dispatch_time_ms: 8.949
    learner:
      cur_lr: 0.0009800470434129238
      grad_gnorm: 40.0
      policy_entropy: 38.75664520263672
      policy_loss: 192.6650390625
      var_gnorm: 142.5979766845703
      vf_explained_var: 0.0
      vf_loss: 34374.2890625
    num_steps_sampled: 5710000
    num_steps_trained: 5710000
    wait_time_ms: 68.178
  iterations_since_restore: 1142
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9929.913440227509
  time_this_iter_s: 8.03154993057251
  time_total_s: 9929.913440227509
  timestamp: 1594865969
  timesteps_since_restore: 5710000
  timesteps_this_iter: 5000
  timesteps_total: 5710000
  training_iteration: 1142
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9929 s, 1142 iter, 5710000 ts, -9.36e+04 rew

agent-1: -6782.977807677756
agent-2: -5889.473093747027
agent-3: -4459.168203282937
agent-4: -6005.221977667013
agent-5: -4197.430324332172
Extrinsic Rewards:
-6613
-5730
-4322
-5843
-4069
Sum Reward: -26577
Avg Reward: -5315.4
Min Reward: -6613
Max Reward: -4069
Gini Coefficient: -0.09946946607969297
20:20 Ratio: 0.6153031906850144
Max-min Ratio: 0.6153031906850144
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-19-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -92911.1200359968
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1142
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.507
    dispatch_time_ms: 5.703
    learner:
      cur_lr: 0.000979713979177177
      grad_gnorm: 39.999996185302734
      policy_entropy: 44.969032287597656
      policy_loss: -2251.9765625
      var_gnorm: 142.61965942382812
      vf_explained_var: 0.0
      vf_loss: 156424.75
    num_steps_sampled: 5715000
    num_steps_trained: 5715000
    wait_time_ms: 69.188
  iterations_since_restore: 1143
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9938.05284667015
  time_this_iter_s: 8.139406442642212
  time_total_s: 9938.05284667015
  timestamp: 1594865977
  timesteps_since_restore: 5715000
  timesteps_this_iter: 5000
  timesteps_total: 5715000
  training_iteration: 1143
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9938 s, 1143 iter, 5715000 ts, -9.29e+04 rew

agent-1: -7035.964478264134
agent-2: -5569.321788036212
agent-3: -9423.63488034403
agent-4: -6504.346979411977
agent-5: -7568.899184772216
Extrinsic Rewards:
-6894
-5442
-9241
-6373
-7405
Sum Reward: -35355
Avg Reward: -7071.0
Min Reward: -9241
Max Reward: -5442
Gini Coefficient: -0.09763824070145666
20:20 Ratio: 0.5888973054864192
Max-min Ratio: 0.5888973054864192
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-19-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -92106.15009732655
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1143
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.963
    dispatch_time_ms: 7.995
    learner:
      cur_lr: 0.000979381031356752
      grad_gnorm: 40.0
      policy_entropy: 44.174591064453125
      policy_loss: 523.2819213867188
      var_gnorm: 142.67926025390625
      vf_explained_var: 0.0
      vf_loss: 74035.09375
    num_steps_sampled: 5720000
    num_steps_trained: 5720000
    wait_time_ms: 68.956
  iterations_since_restore: 1144
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9946.145154714584
  time_this_iter_s: 8.092308044433594
  time_total_s: 9946.145154714584
  timestamp: 1594865985
  timesteps_since_restore: 5720000
  timesteps_this_iter: 5000
  timesteps_total: 5720000
  training_iteration: 1144
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9946 s, 1144 iter, 5720000 ts, -9.21e+04 rew

agent-1: -8714.181203209697
agent-2: -8060.060832428125
agent-3: -8265.945875269403
agent-4: -6113.977536777615
agent-5: -6046.342412097645
Extrinsic Rewards:
-8546
-7898
-8101
-5987
-5917
Sum Reward: -36449
Avg Reward: -7289.8
Min Reward: -8546
Max Reward: -5917
Gini Coefficient: -0.08090208236165601
20:20 Ratio: 0.6923706997425696
Max-min Ratio: 0.6923706997425696
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-19-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -91704.87143620079
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1144
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.783
    dispatch_time_ms: 8.603
    learner:
      cur_lr: 0.000979047967121005
      grad_gnorm: 39.999996185302734
      policy_entropy: 40.28022003173828
      policy_loss: -45.24214172363281
      var_gnorm: 142.49935913085938
      vf_explained_var: 0.0
      vf_loss: 55278.87890625
    num_steps_sampled: 5725000
    num_steps_trained: 5725000
    wait_time_ms: 68.899
  iterations_since_restore: 1145
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9954.150909423828
  time_this_iter_s: 8.005754709243774
  time_total_s: 9954.150909423828
  timestamp: 1594865993
  timesteps_since_restore: 5725000
  timesteps_this_iter: 5000
  timesteps_total: 5725000
  training_iteration: 1145
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9954 s, 1145 iter, 5725000 ts, -9.17e+04 rew

agent-1: -5681.221862614429
agent-2: -6330.644980254376
agent-3: -4636.522133963835
agent-4: -4451.250105373255
agent-5: -4889.452095008716
Extrinsic Rewards:
-5518
-6154
-4503
-4324
-4749
Sum Reward: -25248
Avg Reward: -5049.6
Min Reward: -6154
Max Reward: -4324
Gini Coefficient: -0.07406527249683144
20:20 Ratio: 0.7026324341891452
Max-min Ratio: 0.7026324341891452
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-20-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -91282.31120215257
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1145
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.675
    dispatch_time_ms: 8.059
    learner:
      cur_lr: 0.00097871501930058
      grad_gnorm: 39.999996185302734
      policy_entropy: 33.11473846435547
      policy_loss: -1758.9052734375
      var_gnorm: 142.33860778808594
      vf_explained_var: 0.0
      vf_loss: 67402.921875
    num_steps_sampled: 5730000
    num_steps_trained: 5730000
    wait_time_ms: 69.003
  iterations_since_restore: 1146
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9962.11820936203
  time_this_iter_s: 7.967299938201904
  time_total_s: 9962.11820936203
  timestamp: 1594866001
  timesteps_since_restore: 5730000
  timesteps_this_iter: 5000
  timesteps_total: 5730000
  training_iteration: 1146
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9962 s, 1146 iter, 5730000 ts, -9.13e+04 rew

agent-1: -5421.354730897889
agent-2: -4622.932070870914
agent-3: -6134.041759778463
agent-4: -5889.218802879357
agent-5: -5692.19732773112
Extrinsic Rewards:
-5276
-4489
-5970
-5733
-5539
Sum Reward: -27007
Avg Reward: -5401.4
Min Reward: -5970
Max Reward: -4489
Gini Coefficient: -0.050638723293960825
20:20 Ratio: 0.7519262981574539
Max-min Ratio: 0.7519262981574539
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-20-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -90747.40467654118
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1146
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.71
    dispatch_time_ms: 6.284
    learner:
      cur_lr: 0.0009783819550648332
      grad_gnorm: 39.999996185302734
      policy_entropy: 30.13086700439453
      policy_loss: 122.30867767333984
      var_gnorm: 142.06585693359375
      vf_explained_var: 0.0
      vf_loss: 18820.5703125
    num_steps_sampled: 5735000
    num_steps_trained: 5735000
    wait_time_ms: 72.363
  iterations_since_restore: 1147
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9970.16705751419
  time_this_iter_s: 8.048848152160645
  time_total_s: 9970.16705751419
  timestamp: 1594866010
  timesteps_since_restore: 5735000
  timesteps_this_iter: 5000
  timesteps_total: 5735000
  training_iteration: 1147
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9970 s, 1147 iter, 5735000 ts, -9.07e+04 rew

agent-1: -6339.711773877788
agent-2: -5998.290619669221
agent-3: -2931.575785664306
agent-4: -6927.440751721971
agent-5: -5358.695312746331
Extrinsic Rewards:
-6155
-5841
-2836
-6751
-5225
Sum Reward: -26808
Avg Reward: -5361.6
Min Reward: -6751
Max Reward: -2836
Gini Coefficient: -0.13070725156669652
20:20 Ratio: 0.4200859131980447
Max-min Ratio: 0.4200859131980447
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-20-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -90232.53956764392
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1147
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.28
    dispatch_time_ms: 9.019
    learner:
      cur_lr: 0.0009780490072444081
      grad_gnorm: 40.0
      policy_entropy: 46.806339263916016
      policy_loss: -190.76699829101562
      var_gnorm: 142.12127685546875
      vf_explained_var: 0.0
      vf_loss: 35906.94921875
    num_steps_sampled: 5740000
    num_steps_trained: 5740000
    wait_time_ms: 70.115
  iterations_since_restore: 1148
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9978.242068529129
  time_this_iter_s: 8.075011014938354
  time_total_s: 9978.242068529129
  timestamp: 1594866018
  timesteps_since_restore: 5740000
  timesteps_this_iter: 5000
  timesteps_total: 5740000
  training_iteration: 1148
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9978 s, 1148 iter, 5740000 ts, -9.02e+04 rew

agent-1: -4837.656662389997
agent-2: -8479.534309718305
agent-3: -6011.589637830003
agent-4: -10783.248232340182
agent-5: -9434.598885132562
Extrinsic Rewards:
-4729
-8312
-5898
-10590
-9264
Sum Reward: -38793
Avg Reward: -7758.6
Min Reward: -10590
Max Reward: -4729
Gini Coefficient: -0.15557445930966926
20:20 Ratio: 0.4465533522190746
Max-min Ratio: 0.4465533522190746
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-20-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -89825.87385595073
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1148
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.078
    dispatch_time_ms: 8.098
    learner:
      cur_lr: 0.0009777159430086613
      grad_gnorm: 40.0
      policy_entropy: 49.0587158203125
      policy_loss: -883.37255859375
      var_gnorm: 142.44842529296875
      vf_explained_var: 0.0
      vf_loss: 84163.4765625
    num_steps_sampled: 5745000
    num_steps_trained: 5745000
    wait_time_ms: 72.117
  iterations_since_restore: 1149
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9986.3955347538
  time_this_iter_s: 8.15346622467041
  time_total_s: 9986.3955347538
  timestamp: 1594866026
  timesteps_since_restore: 5745000
  timesteps_this_iter: 5000
  timesteps_total: 5745000
  training_iteration: 1149
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9986 s, 1149 iter, 5745000 ts, -8.98e+04 rew

agent-1: -19546.74176363962
agent-2: -19483.00652860228
agent-3: -18278.105520866204
agent-4: -10977.306838268669
agent-5: -12424.934700051406
Extrinsic Rewards:
-19367
-19314
-18106
-10871
-12293
Sum Reward: -79951
Avg Reward: -15990.2
Min Reward: -19367
Max Reward: -10871
Gini Coefficient: -0.12013858488324099
20:20 Ratio: 0.5613156400061962
Max-min Ratio: 0.5613156400061962
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-20-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -89860.54377234894
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1149
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.716
    dispatch_time_ms: 9.717
    learner:
      cur_lr: 0.0009773829951882362
      grad_gnorm: 40.0
      policy_entropy: 51.81764602661133
      policy_loss: -3139.02783203125
      var_gnorm: 142.8729705810547
      vf_explained_var: 0.0
      vf_loss: 157092.65625
    num_steps_sampled: 5750000
    num_steps_trained: 5750000
    wait_time_ms: 71.018
  iterations_since_restore: 1150
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 9994.630025863647
  time_this_iter_s: 8.234491109848022
  time_total_s: 9994.630025863647
  timestamp: 1594866034
  timesteps_since_restore: 5750000
  timesteps_this_iter: 5000
  timesteps_total: 5750000
  training_iteration: 1150
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 9994 s, 1150 iter, 5750000 ts, -8.99e+04 rew

agent-1: -14994.893557327217
agent-2: -14277.216616547157
agent-3: -14622.99665593632
agent-4: -13027.636031555558
agent-5: -9967.46589624526
Extrinsic Rewards:
-14830
-14122
-14461
-12877
-9854
Sum Reward: -66144
Avg Reward: -13228.8
Min Reward: -14830
Max Reward: -9854
Gini Coefficient: -0.06976294146105468
20:20 Ratio: 0.6644639244774107
Max-min Ratio: 0.6644639244774107
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-20-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -89547.41193419411
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1150
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 4.189
    dispatch_time_ms: 7.689
    learner:
      cur_lr: 0.0009770500473678112
      grad_gnorm: 40.000003814697266
      policy_entropy: 48.809513092041016
      policy_loss: 1507.0076904296875
      var_gnorm: 143.25982666015625
      vf_explained_var: 0.0
      vf_loss: 26117.6875
    num_steps_sampled: 5755000
    num_steps_trained: 5755000
    wait_time_ms: 69.418
  iterations_since_restore: 1151
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10002.96831703186
  time_this_iter_s: 8.33829116821289
  time_total_s: 10002.96831703186
  timestamp: 1594866042
  timesteps_since_restore: 5755000
  timesteps_this_iter: 5000
  timesteps_total: 5755000
  training_iteration: 1151
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10002 s, 1151 iter, 5755000 ts, -8.95e+04 rew

agent-1: -15829.197651519824
agent-2: -12529.383992377565
agent-3: -13131.825537433126
agent-4: -8727.08088486098
agent-5: -16784.61463114754
Extrinsic Rewards:
-15657
-12389
-12978
-8626
-16602
Sum Reward: -66252
Avg Reward: -13250.4
Min Reward: -16602
Max Reward: -8626
Gini Coefficient: -0.11604177987079635
20:20 Ratio: 0.5195759547042526
Max-min Ratio: 0.5195759547042526
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-20-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -88594.14433078104
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1151
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.566
    dispatch_time_ms: 8.274
    learner:
      cur_lr: 0.0009767169831320643
      grad_gnorm: 40.000003814697266
      policy_entropy: 45.9041862487793
      policy_loss: -3211.549072265625
      var_gnorm: 143.65234375
      vf_explained_var: 0.0
      vf_loss: 234440.171875
    num_steps_sampled: 5760000
    num_steps_trained: 5760000
    wait_time_ms: 69.669
  iterations_since_restore: 1152
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10011.151240587234
  time_this_iter_s: 8.182923555374146
  time_total_s: 10011.151240587234
  timestamp: 1594866051
  timesteps_since_restore: 5760000
  timesteps_this_iter: 5000
  timesteps_total: 5760000
  training_iteration: 1152
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10011 s, 1152 iter, 5760000 ts, -8.86e+04 rew

agent-1: -12492.492628114514
agent-2: -11577.560454960374
agent-3: -14347.270705079878
agent-4: -16971.22625014491
agent-5: -8729.735371263994
Extrinsic Rewards:
-12344
-11437
-14187
-16780
-8628
Sum Reward: -63376
Avg Reward: -12675.2
Min Reward: -16780
Max Reward: -8628
Gini Coefficient: -0.12026003534460995
20:20 Ratio: 0.5141835518474375
Max-min Ratio: 0.5141835518474375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-20-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -87969.9567141384
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1152
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.635
    dispatch_time_ms: 8.145
    learner:
      cur_lr: 0.0009763839771039784
      grad_gnorm: 40.0
      policy_entropy: 43.28998947143555
      policy_loss: -509.8901062011719
      var_gnorm: 143.98150634765625
      vf_explained_var: 0.0
      vf_loss: 52968.74609375
    num_steps_sampled: 5765000
    num_steps_trained: 5765000
    wait_time_ms: 70.376
  iterations_since_restore: 1153
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10019.27500295639
  time_this_iter_s: 8.123762369155884
  time_total_s: 10019.27500295639
  timestamp: 1594866059
  timesteps_since_restore: 5765000
  timesteps_this_iter: 5000
  timesteps_total: 5765000
  training_iteration: 1153
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10019 s, 1153 iter, 5765000 ts, -8.8e+04 rew

agent-1: -10672.781787754997
agent-2: -24833.456359520573
agent-3: -7526.55638041526
agent-4: -19812.28747713369
agent-5: -21440.197438230163
Extrinsic Rewards:
-10570
-24641
-7441
-19642
-21265
Sum Reward: -83559
Avg Reward: -16711.8
Min Reward: -24641
Max Reward: -7441
Gini Coefficient: -0.21587142019411434
20:20 Ratio: 0.30197638082870015
Max-min Ratio: 0.30197638082870015
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-21-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -87916.40505801294
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1153
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.732
    dispatch_time_ms: 8.718
    learner:
      cur_lr: 0.0009760509710758924
      grad_gnorm: 40.0
      policy_entropy: 38.353302001953125
      policy_loss: -8941.5595703125
      var_gnorm: 144.41041564941406
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2469549.0
    num_steps_sampled: 5770000
    num_steps_trained: 5770000
    wait_time_ms: 73.717
  iterations_since_restore: 1154
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10027.543773174286
  time_this_iter_s: 8.268770217895508
  time_total_s: 10027.543773174286
  timestamp: 1594866067
  timesteps_since_restore: 5770000
  timesteps_this_iter: 5000
  timesteps_total: 5770000
  training_iteration: 1154
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10027 s, 1154 iter, 5770000 ts, -8.79e+04 rew

agent-1: -16026.954018931187
agent-2: -4693.939535269007
agent-3: -9357.310339069056
agent-4: -18433.095599965884
agent-5: -18732.361506576846
Extrinsic Rewards:
-15859
-4636
-9235
-18247
-18551
Sum Reward: -66528
Avg Reward: -13305.6
Min Reward: -18551
Max Reward: -4636
Gini Coefficient: -0.22151274651274652
20:20 Ratio: 0.2499056654627783
Max-min Ratio: 0.2499056654627783
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-21-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -87762.52792898942
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1154
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.539
    dispatch_time_ms: 7.736
    learner:
      cur_lr: 0.0009757180232554674
      grad_gnorm: 39.999996185302734
      policy_entropy: 41.210411071777344
      policy_loss: -2896.777587890625
      var_gnorm: 144.8740997314453
      vf_explained_var: 0.0
      vf_loss: 281062.125
    num_steps_sampled: 5775000
    num_steps_trained: 5775000
    wait_time_ms: 71.999
  iterations_since_restore: 1155
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10035.889627695084
  time_this_iter_s: 8.34585452079773
  time_total_s: 10035.889627695084
  timestamp: 1594866076
  timesteps_since_restore: 5775000
  timesteps_this_iter: 5000
  timesteps_total: 5775000
  training_iteration: 1155
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10035 s, 1155 iter, 5775000 ts, -8.78e+04 rew

agent-1: -20475.379983256054
agent-2: -14718.00978368469
agent-3: -14435.49552402448
agent-4: -19183.783155998135
agent-5: -20151.75497121329
Extrinsic Rewards:
-20312
-14599
-14314
-19027
-19979
Sum Reward: -88231
Avg Reward: -17646.2
Min Reward: -20312
Max Reward: -14314
Gini Coefficient: -0.07877503371830763
20:20 Ratio: 0.7047065773926743
Max-min Ratio: 0.7047065773926743
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-21-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -87285.51765889008
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1155
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.62
    dispatch_time_ms: 9.235
    learner:
      cur_lr: 0.0009753850172273815
      grad_gnorm: 40.0
      policy_entropy: 35.672367095947266
      policy_loss: -3104.23828125
      var_gnorm: 145.34097290039062
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 472764.53125
    num_steps_sampled: 5780000
    num_steps_trained: 5780000
    wait_time_ms: 71.646
  iterations_since_restore: 1156
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10044.202311992645
  time_this_iter_s: 8.312684297561646
  time_total_s: 10044.202311992645
  timestamp: 1594866084
  timesteps_since_restore: 5780000
  timesteps_this_iter: 5000
  timesteps_total: 5780000
  training_iteration: 1156
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10044 s, 1156 iter, 5780000 ts, -8.73e+04 rew

agent-1: -12420.447125239132
agent-2: -14166.284195607484
agent-3: -18698.168551876384
agent-4: -16674.38510623436
agent-5: -19695.63154584025
Extrinsic Rewards:
-12301
-14035
-18531
-16523
-19522
Sum Reward: -80912
Avg Reward: -16182.4
Min Reward: -19522
Max Reward: -12301
Gini Coefficient: -0.09362270120624877
20:20 Ratio: 0.6301096199159922
Max-min Ratio: 0.6301096199159922
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-21-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -86971.07432651511
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1156
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.797
    dispatch_time_ms: 5.799
    learner:
      cur_lr: 0.0009750520111992955
      grad_gnorm: 40.000003814697266
      policy_entropy: 33.61824035644531
      policy_loss: -2053.42578125
      var_gnorm: 145.8301239013672
      vf_explained_var: 0.0
      vf_loss: 491385.875
    num_steps_sampled: 5785000
    num_steps_trained: 5785000
    wait_time_ms: 77.526
  iterations_since_restore: 1157
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10052.564529180527
  time_this_iter_s: 8.36221718788147
  time_total_s: 10052.564529180527
  timestamp: 1594866092
  timesteps_since_restore: 5785000
  timesteps_this_iter: 5000
  timesteps_total: 5785000
  training_iteration: 1157
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10052 s, 1157 iter, 5785000 ts, -8.7e+04 rew

agent-1: -21411.762117527145
agent-2: -23586.451071002528
agent-3: -34881.36919342759
agent-4: -19820.36204981814
agent-5: -18997.97184496913
Extrinsic Rewards:
-21278
-23442
-34690
-19686
-18868
Sum Reward: -117964
Avg Reward: -23592.8
Min Reward: -34690
Max Reward: -18868
Gini Coefficient: -0.12003662134210437
20:20 Ratio: 0.5439031421158835
Max-min Ratio: 0.5439031421158835
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-21-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -86856.14182579762
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1157
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.696
    dispatch_time_ms: 7.722
    learner:
      cur_lr: 0.0009747190051712096
      grad_gnorm: 40.0
      policy_entropy: 36.31404113769531
      policy_loss: -5051.83447265625
      var_gnorm: 146.3427734375
      vf_explained_var: 0.0
      vf_loss: 1181407.75
    num_steps_sampled: 5790000
    num_steps_trained: 5790000
    wait_time_ms: 70.381
  iterations_since_restore: 1158
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10060.874809980392
  time_this_iter_s: 8.310280799865723
  time_total_s: 10060.874809980392
  timestamp: 1594866101
  timesteps_since_restore: 5790000
  timesteps_this_iter: 5000
  timesteps_total: 5790000
  training_iteration: 1158
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10060 s, 1158 iter, 5790000 ts, -8.69e+04 rew

agent-1: -19931.036533632032
agent-2: -21635.999281944256
agent-3: -34852.914850351146
agent-4: -23166.2031030211
agent-5: -27511.29229845542
Extrinsic Rewards:
-19820
-21493
-34658
-23034
-27350
Sum Reward: -126355
Avg Reward: -25271.0
Min Reward: -34658
Max Reward: -19820
Gini Coefficient: -0.11248624906018757
20:20 Ratio: 0.5718737376651856
Max-min Ratio: 0.5718737376651856
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-21-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -87081.55715271374
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1158
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.336
    dispatch_time_ms: 6.516
    learner:
      cur_lr: 0.0009743859991431236
      grad_gnorm: 40.0
      policy_entropy: 30.527772903442383
      policy_loss: -1544.4241943359375
      var_gnorm: 146.8435821533203
      vf_explained_var: 0.0
      vf_loss: 128137.2734375
    num_steps_sampled: 5795000
    num_steps_trained: 5795000
    wait_time_ms: 73.191
  iterations_since_restore: 1159
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10079.398468017578
  time_this_iter_s: 18.52365803718567
  time_total_s: 10079.398468017578
  timestamp: 1594866119
  timesteps_since_restore: 5795000
  timesteps_this_iter: 5000
  timesteps_total: 5795000
  training_iteration: 1159
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10079 s, 1159 iter, 5795000 ts, -8.71e+04 rew

agent-1: -29506.48322433884
agent-2: -5528.4241176160485
agent-3: -31102.653035616462
agent-4: -45694.93252610034
agent-5: -48840.06526205338
Extrinsic Rewards:
-29366
-5508
-30952
-45499
-48629
Sum Reward: -159954
Avg Reward: -31990.8
Min Reward: -48629
Max Reward: -5508
Gini Coefficient: -0.25601110319216774
20:20 Ratio: 0.11326574677661477
Max-min Ratio: 0.11326574677661477
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-22-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -87347.49481566974
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1159
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.534
    dispatch_time_ms: 10.638
    learner:
      cur_lr: 0.0009740529931150377
      grad_gnorm: 40.0
      policy_entropy: 30.032634735107422
      policy_loss: -3701.170654296875
      var_gnorm: 147.36891174316406
      vf_explained_var: 0.0
      vf_loss: 1342379.125
    num_steps_sampled: 5800000
    num_steps_trained: 5800000
    wait_time_ms: 70.876
  iterations_since_restore: 1160
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10087.786443471909
  time_this_iter_s: 8.387975454330444
  time_total_s: 10087.786443471909
  timestamp: 1594866128
  timesteps_since_restore: 5800000
  timesteps_this_iter: 5000
  timesteps_total: 5800000
  training_iteration: 1160
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10087 s, 1160 iter, 5800000 ts, -8.73e+04 rew

agent-1: -33399.83380669012
agent-2: -35457.66392923448
agent-3: -17542.647662603285
agent-4: -19689.093833432224
agent-5: -30242.475341043322
Extrinsic Rewards:
-33227
-35273
-17442
-19574
-30075
Sum Reward: -135591
Avg Reward: -27118.2
Min Reward: -35273
Max Reward: -17442
Gini Coefficient: -0.14548163226172828
20:20 Ratio: 0.4944858673773141
Max-min Ratio: 0.4944858673773141
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-22-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -87682.95585610201
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1160
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.94
    dispatch_time_ms: 6.659
    learner:
      cur_lr: 0.0009737199870869517
      grad_gnorm: 40.0
      policy_entropy: 29.454973220825195
      policy_loss: -2719.15625
      var_gnorm: 147.85830688476562
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1042239.75
    num_steps_sampled: 5805000
    num_steps_trained: 5805000
    wait_time_ms: 74.156
  iterations_since_restore: 1161
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10096.122202396393
  time_this_iter_s: 8.335758924484253
  time_total_s: 10096.122202396393
  timestamp: 1594866136
  timesteps_since_restore: 5805000
  timesteps_this_iter: 5000
  timesteps_total: 5805000
  training_iteration: 1161
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10096 s, 1161 iter, 5805000 ts, -8.77e+04 rew

agent-1: -21591.22297571551
agent-2: -41550.56672234654
agent-3: -45351.8761656813
agent-4: -37359.596497799765
agent-5: -48360.012116855905
Extrinsic Rewards:
-21500
-41396
-45185
-37210
-48178
Sum Reward: -193469
Avg Reward: -38693.8
Min Reward: -48178
Max Reward: -21500
Gini Coefficient: -0.12680274359199664
20:20 Ratio: 0.4462617792353356
Max-min Ratio: 0.4462617792353356
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-22-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -88254.53870797528
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1161
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.501
    dispatch_time_ms: 8.157
    learner:
      cur_lr: 0.0009733869810588658
      grad_gnorm: 39.999996185302734
      policy_entropy: 34.91295623779297
      policy_loss: -469.0382080078125
      var_gnorm: 148.35845947265625
      vf_explained_var: 0.0
      vf_loss: 58676.98828125
    num_steps_sampled: 5810000
    num_steps_trained: 5810000
    wait_time_ms: 73.697
  iterations_since_restore: 1162
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10104.490686655045
  time_this_iter_s: 8.368484258651733
  time_total_s: 10104.490686655045
  timestamp: 1594866144
  timesteps_since_restore: 5810000
  timesteps_this_iter: 5000
  timesteps_total: 5810000
  training_iteration: 1162
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10104 s, 1162 iter, 5810000 ts, -8.83e+04 rew

agent-1: -30743.99151425198
agent-2: -21218.66535687886
agent-3: -11051.100780327435
agent-4: -19486.903741983413
agent-5: -29080.81183505629
Extrinsic Rewards:
-30556
-21068
-10978
-19358
-28892
Sum Reward: -110852
Avg Reward: -22170.4
Min Reward: -30556
Max Reward: -10978
Gini Coefficient: -0.1756937177497925
20:20 Ratio: 0.3592747741851028
Max-min Ratio: 0.3592747741851028
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-22-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -88110.14468201216
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1162
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.293
    dispatch_time_ms: 7.859
    learner:
      cur_lr: 0.0009730539750307798
      grad_gnorm: 40.000003814697266
      policy_entropy: 33.726051330566406
      policy_loss: -1330.8873291015625
      var_gnorm: 148.78433227539062
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 320320.1875
    num_steps_sampled: 5815000
    num_steps_trained: 5815000
    wait_time_ms: 75.036
  iterations_since_restore: 1163
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10112.966504573822
  time_this_iter_s: 8.475817918777466
  time_total_s: 10112.966504573822
  timestamp: 1594866153
  timesteps_since_restore: 5815000
  timesteps_this_iter: 5000
  timesteps_total: 5815000
  training_iteration: 1163
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10112 s, 1163 iter, 5815000 ts, -8.81e+04 rew

agent-1: -19149.417371753676
agent-2: -15953.235289187585
agent-3: -21939.240566272667
agent-4: -21561.14929244133
agent-5: -30944.40713687334
Extrinsic Rewards:
-19015
-15836
-21785
-21419
-30755
Sum Reward: -108810
Avg Reward: -21762.0
Min Reward: -30755
Max Reward: -15836
Gini Coefficient: -0.11987133535520632
20:20 Ratio: 0.5149081450170704
Max-min Ratio: 0.5149081450170704
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-22-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -87526.90251349485
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1163
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.122
    dispatch_time_ms: 6.758
    learner:
      cur_lr: 0.0009727210272103548
      grad_gnorm: 40.0
      policy_entropy: 32.033016204833984
      policy_loss: -290.35137939453125
      var_gnorm: 149.25587463378906
      vf_explained_var: 0.0
      vf_loss: 68930.1953125
    num_steps_sampled: 5820000
    num_steps_trained: 5820000
    wait_time_ms: 76.14
  iterations_since_restore: 1164
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10121.35105252266
  time_this_iter_s: 8.38454794883728
  time_total_s: 10121.35105252266
  timestamp: 1594866161
  timesteps_since_restore: 5820000
  timesteps_this_iter: 5000
  timesteps_total: 5820000
  training_iteration: 1164
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10121 s, 1164 iter, 5820000 ts, -8.75e+04 rew

agent-1: -21793.999944939125
agent-2: -21216.915434795214
agent-3: -11392.999783488167
agent-4: -29519.285262022
agent-5: -19530.185709901398
Extrinsic Rewards:
-21636
-21065
-11322
-29325
-19381
Sum Reward: -102729
Avg Reward: -20545.8
Min Reward: -29325
Max Reward: -11322
Gini Coefficient: -0.14897838000953967
20:20 Ratio: 0.38608695652173913
Max-min Ratio: 0.38608695652173913
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-22-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -87327.82712924326
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1164
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.951
    dispatch_time_ms: 10.583
    learner:
      cur_lr: 0.0009723880211822689
      grad_gnorm: 40.0
      policy_entropy: 36.258460998535156
      policy_loss: -1879.4932861328125
      var_gnorm: 149.60191345214844
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 472768.90625
    num_steps_sampled: 5825000
    num_steps_trained: 5825000
    wait_time_ms: 71.185
  iterations_since_restore: 1165
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10129.719233512878
  time_this_iter_s: 8.368180990219116
  time_total_s: 10129.719233512878
  timestamp: 1594866170
  timesteps_since_restore: 5825000
  timesteps_this_iter: 5000
  timesteps_total: 5825000
  training_iteration: 1165
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10129 s, 1165 iter, 5825000 ts, -8.73e+04 rew

agent-1: -18347.505313205365
agent-2: -9505.195761669438
agent-3: -15841.579435909032
agent-4: -20759.519337877377
agent-5: -21682.07154174028
Extrinsic Rewards:
-18204
-9408
-15705
-20581
-21501
Sum Reward: -85399
Avg Reward: -17079.8
Min Reward: -21501
Max Reward: -9408
Gini Coefficient: -0.13612337380999778
20:20 Ratio: 0.43756104367238735
Max-min Ratio: 0.43756104367238735
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-22-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -87113.81210974997
  episode_reward_min: -206021.32526085404
  episodes_this_iter: 1
  episodes_total: 1165
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 5.336
    dispatch_time_ms: 10.873
    learner:
      cur_lr: 0.0009720550151541829
      grad_gnorm: 40.000003814697266
      policy_entropy: 39.739173889160156
      policy_loss: -2764.64892578125
      var_gnorm: 150.07623291015625
      vf_explained_var: 0.0
      vf_loss: 209734.953125
    num_steps_sampled: 5830000
    num_steps_trained: 5830000
    wait_time_ms: 69.296
  iterations_since_restore: 1166
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10138.069333553314
  time_this_iter_s: 8.350100040435791
  time_total_s: 10138.069333553314
  timestamp: 1594866178
  timesteps_since_restore: 5830000
  timesteps_this_iter: 5000
  timesteps_total: 5830000
  training_iteration: 1166
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10138 s, 1166 iter, 5830000 ts, -8.71e+04 rew

agent-1: -22113.380673477724
agent-2: -12722.34754374122
agent-3: -13926.438713461379
agent-4: -16566.709311432107
agent-5: -20613.34206080927
Extrinsic Rewards:
-21938
-12604
-13796
-16424
-20445
Sum Reward: -85207
Avg Reward: -17041.4
Min Reward: -21938
Max Reward: -12604
Gini Coefficient: -0.118849390308308
20:20 Ratio: 0.5745282158811195
Max-min Ratio: 0.5745282158811195
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-23-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -85913.02104017064
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1166
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 4.263
    dispatch_time_ms: 8.234
    learner:
      cur_lr: 0.000971722009126097
      grad_gnorm: 40.0
      policy_entropy: 41.16176986694336
      policy_loss: -10309.84375
      var_gnorm: 150.4626007080078
      vf_explained_var: 0.0
      vf_loss: 830374.1875
    num_steps_sampled: 5835000
    num_steps_trained: 5835000
    wait_time_ms: 70.564
  iterations_since_restore: 1167
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10146.281642198563
  time_this_iter_s: 8.212308645248413
  time_total_s: 10146.281642198563
  timestamp: 1594866186
  timesteps_since_restore: 5835000
  timesteps_this_iter: 5000
  timesteps_total: 5835000
  training_iteration: 1167
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10146 s, 1167 iter, 5835000 ts, -8.59e+04 rew

agent-1: -17640.748683911363
agent-2: -24830.63978737338
agent-3: -29916.99279794603
agent-4: -15328.605564496787
agent-5: -14593.8274594787
Extrinsic Rewards:
-17501
-24660
-29728
-15207
-14473
Sum Reward: -101569
Avg Reward: -20313.8
Min Reward: -29728
Max Reward: -14473
Gini Coefficient: -0.15738266597091632
20:20 Ratio: 0.48684741657696445
Max-min Ratio: 0.48684741657696445
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-23-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -85251.29999425313
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1167
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.735
    dispatch_time_ms: 7.988
    learner:
      cur_lr: 0.000971389003098011
      grad_gnorm: 39.999996185302734
      policy_entropy: 33.26689910888672
      policy_loss: -2758.4267578125
      var_gnorm: 150.96119689941406
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1392938.375
    num_steps_sampled: 5840000
    num_steps_trained: 5840000
    wait_time_ms: 71.735
  iterations_since_restore: 1168
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10154.60005235672
  time_this_iter_s: 8.318410158157349
  time_total_s: 10154.60005235672
  timestamp: 1594866195
  timesteps_since_restore: 5840000
  timesteps_this_iter: 5000
  timesteps_total: 5840000
  training_iteration: 1168
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10154 s, 1168 iter, 5840000 ts, -8.53e+04 rew

agent-1: -17792.09655198205
agent-2: -23378.040546481065
agent-3: -17120.55103931123
agent-4: -24365.89555238155
agent-5: -16175.237124274681
Extrinsic Rewards:
-17656
-23210
-16994
-24188
-16042
Sum Reward: -98090
Avg Reward: -19618.0
Min Reward: -24188
Max Reward: -16042
Gini Coefficient: -0.09178509532062391
20:20 Ratio: 0.6632214321150984
Max-min Ratio: 0.6632214321150984
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-23-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -84969.04111995456
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1168
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.144
    dispatch_time_ms: 7.186
    learner:
      cur_lr: 0.0009710559970699251
      grad_gnorm: 40.0
      policy_entropy: 26.893768310546875
      policy_loss: -2205.189208984375
      var_gnorm: 151.46011352539062
      vf_explained_var: 0.0
      vf_loss: 507739.90625
    num_steps_sampled: 5845000
    num_steps_trained: 5845000
    wait_time_ms: 73.449
  iterations_since_restore: 1169
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10173.585169792175
  time_this_iter_s: 18.985117435455322
  time_total_s: 10173.585169792175
  timestamp: 1594866214
  timesteps_since_restore: 5845000
  timesteps_this_iter: 5000
  timesteps_total: 5845000
  training_iteration: 1169
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10173 s, 1169 iter, 5845000 ts, -8.5e+04 rew

agent-1: -22600.095122571565
agent-2: -24543.790188531995
agent-3: -39265.593669924776
agent-4: -20575.537030702333
agent-5: -25288.91955951318
Extrinsic Rewards:
-22464
-24403
-39068
-20446
-25147
Sum Reward: -131528
Avg Reward: -26305.6
Min Reward: -39068
Max Reward: -20446
Gini Coefficient: -0.12142509579709264
20:20 Ratio: 0.5233439131770247
Max-min Ratio: 0.5233439131770247
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-23-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -85143.97477778232
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1169
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.661
    dispatch_time_ms: 5.924
    learner:
      cur_lr: 0.0009707229910418391
      grad_gnorm: 40.0
      policy_entropy: 30.11842155456543
      policy_loss: -1573.62451171875
      var_gnorm: 151.97250366210938
      vf_explained_var: 0.0
      vf_loss: 512693.5625
    num_steps_sampled: 5850000
    num_steps_trained: 5850000
    wait_time_ms: 78.517
  iterations_since_restore: 1170
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10181.95246219635
  time_this_iter_s: 8.367292404174805
  time_total_s: 10181.95246219635
  timestamp: 1594866222
  timesteps_since_restore: 5850000
  timesteps_this_iter: 5000
  timesteps_total: 5850000
  training_iteration: 1170
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10181 s, 1170 iter, 5850000 ts, -8.51e+04 rew

agent-1: -34667.55512605311
agent-2: -11637.624287109371
agent-3: -34532.380574198665
agent-4: -23487.52402337775
agent-5: -41945.62538405146
Extrinsic Rewards:
-34505
-11566
-34360
-23349
-41754
Sum Reward: -145534
Avg Reward: -29106.8
Min Reward: -41754
Max Reward: -11566
Gini Coefficient: -0.19660560418871192
20:20 Ratio: 0.2770034008717728
Max-min Ratio: 0.2770034008717728
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-23-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -85262.5560201967
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1170
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.664
    dispatch_time_ms: 7.782
    learner:
      cur_lr: 0.0009703899850137532
      grad_gnorm: 40.0
      policy_entropy: 38.30489730834961
      policy_loss: -3606.37109375
      var_gnorm: 152.39332580566406
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 381725.0625
    num_steps_sampled: 5855000
    num_steps_trained: 5855000
    wait_time_ms: 73.478
  iterations_since_restore: 1171
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10190.370108127594
  time_this_iter_s: 8.417645931243896
  time_total_s: 10190.370108127594
  timestamp: 1594866231
  timesteps_since_restore: 5855000
  timesteps_this_iter: 5000
  timesteps_total: 5855000
  training_iteration: 1171
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10190 s, 1171 iter, 5855000 ts, -8.53e+04 rew

agent-1: -24326.517926652163
agent-2: -19082.67760087126
agent-3: -22862.50130933051
agent-4: -21119.91316169336
agent-5: -19707.02548557706
Extrinsic Rewards:
-24147
-18953
-22704
-21001
-19561
Sum Reward: -106366
Avg Reward: -21273.2
Min Reward: -24147
Max Reward: -18953
Gini Coefficient: -0.05088468119511874
20:20 Ratio: 0.7849008158363358
Max-min Ratio: 0.7849008158363358
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-23-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -85111.52714696268
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1171
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.794
    dispatch_time_ms: 8.996
    learner:
      cur_lr: 0.0009700569789856672
      grad_gnorm: 40.000003814697266
      policy_entropy: 34.6898307800293
      policy_loss: -590.017822265625
      var_gnorm: 152.83462524414062
      vf_explained_var: 0.0
      vf_loss: 145478.90625
    num_steps_sampled: 5860000
    num_steps_trained: 5860000
    wait_time_ms: 73.302
  iterations_since_restore: 1172
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10198.745720148087
  time_this_iter_s: 8.375612020492554
  time_total_s: 10198.745720148087
  timestamp: 1594866239
  timesteps_since_restore: 5860000
  timesteps_this_iter: 5000
  timesteps_total: 5860000
  training_iteration: 1172
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10198 s, 1172 iter, 5860000 ts, -8.51e+04 rew

agent-1: -15596.29673604942
agent-2: -22167.88412739364
agent-3: -18887.54599987364
agent-4: -21493.70286364088
agent-5: -19708.180103206825
Extrinsic Rewards:
-15479
-22000
-18735
-21330
-19555
Sum Reward: -97099
Avg Reward: -19419.8
Min Reward: -22000
Max Reward: -15479
Gini Coefficient: -0.0644167293175007
20:20 Ratio: 0.703590909090909
Max-min Ratio: 0.703590909090909
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-24-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -84926.20628895203
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1172
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.852
    dispatch_time_ms: 9.022
    learner:
      cur_lr: 0.0009697239729575813
      grad_gnorm: 40.000003814697266
      policy_entropy: 26.87885284423828
      policy_loss: -7686.26611328125
      var_gnorm: 153.2895965576172
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1364271.375
    num_steps_sampled: 5865000
    num_steps_trained: 5865000
    wait_time_ms: 78.611
  iterations_since_restore: 1173
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10207.22896528244
  time_this_iter_s: 8.483245134353638
  time_total_s: 10207.22896528244
  timestamp: 1594866248
  timesteps_since_restore: 5865000
  timesteps_this_iter: 5000
  timesteps_total: 5865000
  training_iteration: 1173
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10207 s, 1173 iter, 5865000 ts, -8.49e+04 rew

agent-1: -31987.941504159768
agent-2: -36082.511301786406
agent-3: -26379.09985573762
agent-4: -21048.75158632261
agent-5: -23136.85974372391
Extrinsic Rewards:
-31816
-35903
-26228
-20926
-23011
Sum Reward: -137884
Avg Reward: -27576.8
Min Reward: -35903
Max Reward: -20926
Gini Coefficient: -0.11243944184967074
20:20 Ratio: 0.5828482299529287
Max-min Ratio: 0.5828482299529287
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-24-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -85183.54597005599
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1173
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.592
    dispatch_time_ms: 5.827
    learner:
      cur_lr: 0.0009693910251371562
      grad_gnorm: 39.999996185302734
      policy_entropy: 26.481258392333984
      policy_loss: -983.3764038085938
      var_gnorm: 153.7586669921875
      vf_explained_var: 0.0
      vf_loss: 235021.390625
    num_steps_sampled: 5870000
    num_steps_trained: 5870000
    wait_time_ms: 73.643
  iterations_since_restore: 1174
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10215.630175113678
  time_this_iter_s: 8.401209831237793
  time_total_s: 10215.630175113678
  timestamp: 1594866256
  timesteps_since_restore: 5870000
  timesteps_this_iter: 5000
  timesteps_total: 5870000
  training_iteration: 1174
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10215 s, 1174 iter, 5870000 ts, -8.52e+04 rew

agent-1: -25442.235420579174
agent-2: -23929.94369871738
agent-3: -16570.238024331316
agent-4: -14813.496791068774
agent-5: -31668.274000087655
Extrinsic Rewards:
-25278
-23775
-16455
-14705
-31479
Sum Reward: -111692
Avg Reward: -22338.4
Min Reward: -31479
Max Reward: -14705
Gini Coefficient: -0.15174229130107797
20:20 Ratio: 0.4671368213729788
Max-min Ratio: 0.4671368213729788
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-24-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -85557.5098454961
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1174
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.809
    dispatch_time_ms: 6.207
    learner:
      cur_lr: 0.0009690580191090703
      grad_gnorm: 40.0
      policy_entropy: 27.258480072021484
      policy_loss: -1899.4921875
      var_gnorm: 154.20559692382812
      vf_explained_var: 0.0
      vf_loss: 349696.53125
    num_steps_sampled: 5875000
    num_steps_trained: 5875000
    wait_time_ms: 77.352
  iterations_since_restore: 1175
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10224.182086229324
  time_this_iter_s: 8.551911115646362
  time_total_s: 10224.182086229324
  timestamp: 1594866265
  timesteps_since_restore: 5875000
  timesteps_this_iter: 5000
  timesteps_total: 5875000
  training_iteration: 1175
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10224 s, 1175 iter, 5875000 ts, -8.56e+04 rew

agent-1: -30582.171610830097
agent-2: -18981.39107186045
agent-3: -20114.401768590607
agent-4: -29799.949813154955
agent-5: -30206.127540681995
Extrinsic Rewards:
-30416
-18876
-19995
-29634
-30033
Sum Reward: -128954
Avg Reward: -25790.8
Min Reward: -30416
Max Reward: -18876
Gini Coefficient: -0.10272810459543713
20:20 Ratio: 0.6205944239873751
Max-min Ratio: 0.6205944239873751
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-24-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -86581.23184932824
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1175
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.582
    dispatch_time_ms: 7.284
    learner:
      cur_lr: 0.0009687250130809844
      grad_gnorm: 40.0
      policy_entropy: 26.36905860900879
      policy_loss: -3751.3115234375
      var_gnorm: 154.65989685058594
      vf_explained_var: 0.0
      vf_loss: 1463199.875
    num_steps_sampled: 5880000
    num_steps_trained: 5880000
    wait_time_ms: 72.648
  iterations_since_restore: 1176
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10232.66725230217
  time_this_iter_s: 8.485166072845459
  time_total_s: 10232.66725230217
  timestamp: 1594866273
  timesteps_since_restore: 5880000
  timesteps_this_iter: 5000
  timesteps_total: 5880000
  training_iteration: 1176
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10232 s, 1176 iter, 5880000 ts, -8.66e+04 rew

agent-1: -30751.288934749165
agent-2: -27703.202410772963
agent-3: -32903.380143626186
agent-4: -13789.379157563726
agent-5: -18692.239429611436
Extrinsic Rewards:
-30579
-27537
-32720
-13699
-18577
Sum Reward: -123112
Avg Reward: -24622.4
Min Reward: -32720
Max Reward: -13699
Gini Coefficient: -0.1625966599519137
20:20 Ratio: 0.4186735941320293
Max-min Ratio: 0.4186735941320293
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-24-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -87612.9562452484
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1176
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.987
    dispatch_time_ms: 8.087
    learner:
      cur_lr: 0.0009683920070528984
      grad_gnorm: 40.000003814697266
      policy_entropy: 23.763978958129883
      policy_loss: -1397.171875
      var_gnorm: 155.1239013671875
      vf_explained_var: 0.0
      vf_loss: 776164.3125
    num_steps_sampled: 5885000
    num_steps_trained: 5885000
    wait_time_ms: 72.242
  iterations_since_restore: 1177
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10241.091473817825
  time_this_iter_s: 8.424221515655518
  time_total_s: 10241.091473817825
  timestamp: 1594866282
  timesteps_since_restore: 5885000
  timesteps_this_iter: 5000
  timesteps_total: 5885000
  training_iteration: 1177
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10241 s, 1177 iter, 5885000 ts, -8.76e+04 rew

agent-1: -17227.04834038867
agent-2: -29444.706793085457
agent-3: -32917.49986128587
agent-4: -20592.91346838915
agent-5: -36678.190163285406
Extrinsic Rewards:
-17130
-29279
-32746
-20476
-36492
Sum Reward: -136123
Avg Reward: -27224.6
Min Reward: -36492
Max Reward: -17130
Gini Coefficient: -0.14984682970548696
20:20 Ratio: 0.4694179546201907
Max-min Ratio: 0.4694179546201907
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-24-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -88657.37228380117
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1177
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.861
    dispatch_time_ms: 7.535
    learner:
      cur_lr: 0.0009680590010248125
      grad_gnorm: 40.0
      policy_entropy: 21.193262100219727
      policy_loss: -1641.44580078125
      var_gnorm: 155.6183624267578
      vf_explained_var: -0.07456588745117188
      vf_loss: 671206.0625
    num_steps_sampled: 5890000
    num_steps_trained: 5890000
    wait_time_ms: 76.266
  iterations_since_restore: 1178
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10249.500574111938
  time_this_iter_s: 8.40910029411316
  time_total_s: 10249.500574111938
  timestamp: 1594866290
  timesteps_since_restore: 5890000
  timesteps_this_iter: 5000
  timesteps_total: 5890000
  training_iteration: 1178
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10249 s, 1178 iter, 5890000 ts, -8.87e+04 rew

agent-1: -22210.789964163003
agent-2: -29756.00874132102
agent-3: -20486.44261626906
agent-4: -36311.00443629683
agent-5: -19071.315572056006
Extrinsic Rewards:
-22076
-29591
-20360
-36115
-18951
Sum Reward: -127093
Avg Reward: -25418.6
Min Reward: -36115
Max Reward: -18951
Gini Coefficient: -0.13709330962366142
20:20 Ratio: 0.5247404125709539
Max-min Ratio: 0.5247404125709539
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-24-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -89624.85812760086
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1178
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.745
    dispatch_time_ms: 7.126
    learner:
      cur_lr: 0.0009677259949967265
      grad_gnorm: 40.000003814697266
      policy_entropy: 17.93211555480957
      policy_loss: -5990.15087890625
      var_gnorm: 156.0367431640625
      vf_explained_var: 0.0
      vf_loss: 2907665.75
    num_steps_sampled: 5895000
    num_steps_trained: 5895000
    wait_time_ms: 75.622
  iterations_since_restore: 1179
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10258.058132886887
  time_this_iter_s: 8.55755877494812
  time_total_s: 10258.058132886887
  timestamp: 1594866299
  timesteps_since_restore: 5895000
  timesteps_this_iter: 5000
  timesteps_total: 5895000
  training_iteration: 1179
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10258 s, 1179 iter, 5895000 ts, -8.96e+04 rew

agent-1: -12412.625879569585
agent-2: -29419.738017693868
agent-3: -33090.952365841076
agent-4: -33997.82028704373
agent-5: -41274.43349343587
Extrinsic Rewards:
-12350
-29275
-32923
-33833
-41087
Sum Reward: -149468
Avg Reward: -29893.6
Min Reward: -41087
Max Reward: -12350
Gini Coefficient: -0.16600743971953863
20:20 Ratio: 0.30058169250614547
Max-min Ratio: 0.30058169250614547
agent-1: -27674.013935161936
agent-2: -19735.247568916137
agent-3: -9767.492605075708
agent-4: -15917.90346632711
agent-5: -27776.99042196962
Extrinsic Rewards:
-27497
-19592
-9692
-15791
-27594
Sum Reward: -100166
Avg Reward: -20033.2
Min Reward: -27594
Max Reward: -9692
Gini Coefficient: -0.18972505640636544
20:20 Ratio: 0.3512357758933101
Max-min Ratio: 0.3512357758933101
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-25-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -91380.55927536402
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 2
  episodes_total: 1180
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.725
    dispatch_time_ms: 16.395
    learner:
      cur_lr: 0.0009673929889686406
      grad_gnorm: 40.0
      policy_entropy: 21.299827575683594
      policy_loss: -774.3902587890625
      var_gnorm: 156.46658325195312
      vf_explained_var: -0.09480798244476318
      vf_loss: 479194.125
    num_steps_sampled: 5900000
    num_steps_trained: 5900000
    wait_time_ms: 69.046
  iterations_since_restore: 1180
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10266.582085132599
  time_this_iter_s: 8.52395224571228
  time_total_s: 10266.582085132599
  timestamp: 1594866307
  timesteps_since_restore: 5900000
  timesteps_this_iter: 5000
  timesteps_total: 5900000
  training_iteration: 1180
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10266 s, 1180 iter, 5900000 ts, -9.14e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-25-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -91380.55927536402
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 0
  episodes_total: 1180
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.913
    dispatch_time_ms: 35.98
    learner:
      cur_lr: 0.0009670599829405546
      grad_gnorm: 40.0
      policy_entropy: 19.934728622436523
      policy_loss: -1927.62353515625
      var_gnorm: 156.9446258544922
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 810901.0
    num_steps_sampled: 5905000
    num_steps_trained: 5905000
    wait_time_ms: 47.886
  iterations_since_restore: 1181
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10275.36521077156
  time_this_iter_s: 8.783125638961792
  time_total_s: 10275.36521077156
  timestamp: 1594866316
  timesteps_since_restore: 5905000
  timesteps_this_iter: 5000
  timesteps_total: 5905000
  training_iteration: 1181
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10275 s, 1181 iter, 5905000 ts, -9.14e+04 rew

agent-1: -26811.223952769145
agent-2: -18040.96345746553
agent-3: -30290.63464329848
agent-4: -36607.429548059685
agent-5: -12628.191382639143
Extrinsic Rewards:
-26649
-17924
-30117
-36410
-12546
Sum Reward: -123646
Avg Reward: -24729.2
Min Reward: -36410
Max Reward: -12546
Gini Coefficient: -0.19384695016417838
20:20 Ratio: 0.3445756660258171
Max-min Ratio: 0.3445756660258171
agent-1: -31105.822660231446
agent-2: -22810.792612676174
agent-3: -26338.965325522116
agent-4: -43538.66638809632
agent-5: -20291.802912076375
Extrinsic Rewards:
-30943
-22694
-26193
-43338
-20177
Sum Reward: -143345
Avg Reward: -28669.0
Min Reward: -43338
Max Reward: -20177
Gini Coefficient: -0.15227876800725523
20:20 Ratio: 0.4655729382989524
Max-min Ratio: 0.4655729382989524
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-25-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -91726.8156936099
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1181
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.413
    dispatch_time_ms: 38.409
    learner:
      cur_lr: 0.0009667269769124687
      grad_gnorm: 40.0
      policy_entropy: 27.609142303466797
      policy_loss: -954.2898559570312
      var_gnorm: 157.44602966308594
      vf_explained_var: -0.08032476902008057
      vf_loss: 436698.8125
    num_steps_sampled: 5910000
    num_steps_trained: 5910000
    wait_time_ms: 46.114
  iterations_since_restore: 1182
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10284.382244586945
  time_this_iter_s: 9.017033815383911
  time_total_s: 10284.382244586945
  timestamp: 1594866325
  timesteps_since_restore: 5910000
  timesteps_this_iter: 5000
  timesteps_total: 5910000
  training_iteration: 1182
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10284 s, 1182 iter, 5910000 ts, -9.17e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-25-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -92068.64397658236
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1182
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.686
    dispatch_time_ms: 23.815
    learner:
      cur_lr: 0.0009663940290920436
      grad_gnorm: 40.000003814697266
      policy_entropy: 30.878047943115234
      policy_loss: -2426.523681640625
      var_gnorm: 157.8181610107422
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 478798.46875
    num_steps_sampled: 5915000
    num_steps_trained: 5915000
    wait_time_ms: 59.561
  iterations_since_restore: 1183
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10293.289971590042
  time_this_iter_s: 8.907727003097534
  time_total_s: 10293.289971590042
  timestamp: 1594866334
  timesteps_since_restore: 5915000
  timesteps_this_iter: 5000
  timesteps_total: 5915000
  training_iteration: 1183
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10293 s, 1183 iter, 5915000 ts, -9.21e+04 rew

agent-1: -12140.55951512011
agent-2: -11246.038624452376
agent-3: -18804.52134167272
agent-4: -19209.5444906032
agent-5: -16727.091968886132
Extrinsic Rewards:
-12008
-11134
-18647
-19039
-16578
Sum Reward: -77406
Avg Reward: -15481.2
Min Reward: -19039
Max Reward: -11134
Gini Coefficient: -0.11600651112316875
20:20 Ratio: 0.5847996218288776
Max-min Ratio: 0.5847996218288776
agent-1: -30219.99180104993
agent-2: -23917.588906990357
agent-3: -20247.227104617585
agent-4: -28001.6900648608
agent-5: -24377.271836259504
Extrinsic Rewards:
-30046
-23780
-20134
-27838
-24227
Sum Reward: -126025
Avg Reward: -25205.0
Min Reward: -30046
Max Reward: -20134
Gini Coefficient: -0.07580083316802222
20:20 Ratio: 0.6701058377155029
Max-min Ratio: 0.6701058377155029
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-25-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -92431.30811219032
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 2
  episodes_total: 1184
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.579
    dispatch_time_ms: 30.86
    learner:
      cur_lr: 0.0009660610230639577
      grad_gnorm: 40.0
      policy_entropy: 26.359760284423828
      policy_loss: -4690.60400390625
      var_gnorm: 158.26751708984375
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1803216.375
    num_steps_sampled: 5920000
    num_steps_trained: 5920000
    wait_time_ms: 78.735
  iterations_since_restore: 1184
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10302.444809913635
  time_this_iter_s: 9.15483832359314
  time_total_s: 10302.444809913635
  timestamp: 1594866343
  timesteps_since_restore: 5920000
  timesteps_this_iter: 5000
  timesteps_total: 5920000
  training_iteration: 1184
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10302 s, 1184 iter, 5920000 ts, -9.24e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-25-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -92431.30811219035
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 0
  episodes_total: 1184
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.566
    dispatch_time_ms: 26.993
    learner:
      cur_lr: 0.0009657280170358717
      grad_gnorm: 39.999996185302734
      policy_entropy: 30.70237159729004
      policy_loss: -489.4227294921875
      var_gnorm: 158.7272186279297
      vf_explained_var: 0.0
      vf_loss: 74747.1875
    num_steps_sampled: 5925000
    num_steps_trained: 5925000
    wait_time_ms: 59.607
  iterations_since_restore: 1185
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10311.152388095856
  time_this_iter_s: 8.707578182220459
  time_total_s: 10311.152388095856
  timestamp: 1594866352
  timesteps_since_restore: 5925000
  timesteps_this_iter: 5000
  timesteps_total: 5925000
  training_iteration: 1185
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10311 s, 1185 iter, 5925000 ts, -9.24e+04 rew

agent-1: -8748.877314637213
agent-2: -29638.145585951348
agent-3: -18492.04743865544
agent-4: -26706.179069133923
agent-5: -26849.915544766096
Extrinsic Rewards:
-8681
-29444
-18355
-26555
-26676
Sum Reward: -109711
Avg Reward: -21942.2
Min Reward: -29444
Max Reward: -8681
Gini Coefficient: -0.1817392968799847
20:20 Ratio: 0.2948308653715528
Max-min Ratio: 0.2948308653715528
agent-1: -30573.54292202304
agent-2: -13215.033867906976
agent-3: -40924.83872813747
agent-4: -21036.886705510617
agent-5: -21722.47785722953
Extrinsic Rewards:
-30408
-13119
-40715
-20912
-21592
Sum Reward: -126746
Avg Reward: -25349.2
Min Reward: -40715
Max Reward: -13119
Gini Coefficient: -0.2041500323481609
20:20 Ratio: 0.3222153997298293
Max-min Ratio: 0.3222153997298293
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-26-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -93712.82234705726
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 2
  episodes_total: 1186
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.366
    dispatch_time_ms: 56.469
    learner:
      cur_lr: 0.0009653950110077858
      grad_gnorm: 40.0
      policy_entropy: 31.70400047302246
      policy_loss: -1702.1513671875
      var_gnorm: 159.19842529296875
      vf_explained_var: 0.0
      vf_loss: 289705.21875
    num_steps_sampled: 5930000
    num_steps_trained: 5930000
    wait_time_ms: 45.61
  iterations_since_restore: 1186
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10320.310098409653
  time_this_iter_s: 9.157710313796997
  time_total_s: 10320.310098409653
  timestamp: 1594866361
  timesteps_since_restore: 5930000
  timesteps_this_iter: 5000
  timesteps_total: 5930000
  training_iteration: 1186
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10320 s, 1186 iter, 5930000 ts, -9.37e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-26-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -93712.82234705726
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 0
  episodes_total: 1186
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.817
    dispatch_time_ms: 36.25
    learner:
      cur_lr: 0.0009650620049796999
      grad_gnorm: 40.0
      policy_entropy: 29.27461051940918
      policy_loss: -4431.89306640625
      var_gnorm: 159.56228637695312
      vf_explained_var: 0.0
      vf_loss: 964309.1875
    num_steps_sampled: 5935000
    num_steps_trained: 5935000
    wait_time_ms: 35.621
  iterations_since_restore: 1187
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10329.249216079712
  time_this_iter_s: 8.939117670059204
  time_total_s: 10329.249216079712
  timestamp: 1594866370
  timesteps_since_restore: 5935000
  timesteps_this_iter: 5000
  timesteps_total: 5935000
  training_iteration: 1187
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10329 s, 1187 iter, 5935000 ts, -9.37e+04 rew

agent-1: -26247.81685011319
agent-2: -18280.86143138014
agent-3: -24081.495650369885
agent-4: -20790.23583444708
agent-5: -16581.3193064793
Extrinsic Rewards:
-26060
-18144
-23920
-20653
-16459
Sum Reward: -105236
Avg Reward: -21047.2
Min Reward: -26060
Max Reward: -16459
Gini Coefficient: -0.09494089475084572
20:20 Ratio: 0.6315809669992325
Max-min Ratio: 0.6315809669992325
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-26-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -94402.49204741752
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1187
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.727
    dispatch_time_ms: 23.242
    learner:
      cur_lr: 0.0009647289989516139
      grad_gnorm: 40.0
      policy_entropy: 28.557462692260742
      policy_loss: -1154.6378173828125
      var_gnorm: 160.0330352783203
      vf_explained_var: 0.0
      vf_loss: 311130.90625
    num_steps_sampled: 5940000
    num_steps_trained: 5940000
    wait_time_ms: 60.13
  iterations_since_restore: 1188
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10338.001749038696
  time_this_iter_s: 8.752532958984375
  time_total_s: 10338.001749038696
  timestamp: 1594866379
  timesteps_since_restore: 5940000
  timesteps_this_iter: 5000
  timesteps_total: 5940000
  training_iteration: 1188
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10338 s, 1188 iter, 5940000 ts, -9.44e+04 rew

agent-1: -17285.14328995469
agent-2: -23663.799949399283
agent-3: -25720.21162232441
agent-4: -5634.447006063109
agent-5: -10351.96920634119
Extrinsic Rewards:
-17127
-23469
-25516
-5573
-10252
Sum Reward: -81937
Avg Reward: -16387.4
Min Reward: -25516
Max Reward: -5573
Gini Coefficient: -0.25923819519875024
20:20 Ratio: 0.2184119767988713
Max-min Ratio: 0.2184119767988713
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-26-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -94929.80946037531
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1188
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.534
    dispatch_time_ms: 7.685
    learner:
      cur_lr: 0.000964395992923528
      grad_gnorm: 40.00000762939453
      policy_entropy: 36.99449157714844
      policy_loss: -3776.761962890625
      var_gnorm: 160.49429321289062
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 307310.53125
    num_steps_sampled: 5945000
    num_steps_trained: 5945000
    wait_time_ms: 71.589
  iterations_since_restore: 1189
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10346.38119316101
  time_this_iter_s: 8.379444122314453
  time_total_s: 10346.38119316101
  timestamp: 1594866387
  timesteps_since_restore: 5945000
  timesteps_this_iter: 5000
  timesteps_total: 5945000
  training_iteration: 1189
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10346 s, 1189 iter, 5945000 ts, -9.49e+04 rew

agent-1: -17011.21676486013
agent-2: -39645.901324893086
agent-3: -20778.35281079978
agent-4: -23866.883093167577
agent-5: -34526.03557938693
Extrinsic Rewards:
-16905
-39445
-20651
-23737
-34350
Sum Reward: -135088
Avg Reward: -27017.6
Min Reward: -39445
Max Reward: -16905
Gini Coefficient: -0.17404654743574557
20:20 Ratio: 0.42857142857142855
Max-min Ratio: 0.42857142857142855
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-26-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -95781.64861056562
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1189
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.756
    dispatch_time_ms: 9.624
    learner:
      cur_lr: 0.000964062986895442
      grad_gnorm: 40.0
      policy_entropy: 38.65336990356445
      policy_loss: -1945.8779296875
      var_gnorm: 160.9793243408203
      vf_explained_var: 0.0
      vf_loss: 207146.21875
    num_steps_sampled: 5950000
    num_steps_trained: 5950000
    wait_time_ms: 73.579
  iterations_since_restore: 1190
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10354.761004209518
  time_this_iter_s: 8.37981104850769
  time_total_s: 10354.761004209518
  timestamp: 1594866396
  timesteps_since_restore: 5950000
  timesteps_this_iter: 5000
  timesteps_total: 5950000
  training_iteration: 1190
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10354 s, 1190 iter, 5950000 ts, -9.58e+04 rew

agent-1: -12597.711785343316
agent-2: -12030.555180530324
agent-3: -16980.633257166395
agent-4: -24684.673789876426
agent-5: -25469.001912309544
Extrinsic Rewards:
-12486
-11933
-16836
-24501
-25275
Sum Reward: -91031
Avg Reward: -18206.2
Min Reward: -25275
Max Reward: -11933
Gini Coefficient: -0.17004756621370742
20:20 Ratio: 0.47212660731948564
Max-min Ratio: 0.47212660731948564
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-26-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -96124.71765180984
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1190
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.617
    dispatch_time_ms: 6.985
    learner:
      cur_lr: 0.0009637299808673561
      grad_gnorm: 40.0
      policy_entropy: 33.98511505126953
      policy_loss: -3493.8193359375
      var_gnorm: 161.3081817626953
      vf_explained_var: 0.0
      vf_loss: 732803.5
    num_steps_sampled: 5955000
    num_steps_trained: 5955000
    wait_time_ms: 73.015
  iterations_since_restore: 1191
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10363.105092048645
  time_this_iter_s: 8.344087839126587
  time_total_s: 10363.105092048645
  timestamp: 1594866404
  timesteps_since_restore: 5955000
  timesteps_this_iter: 5000
  timesteps_total: 5955000
  training_iteration: 1191
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10363 s, 1191 iter, 5955000 ts, -9.61e+04 rew

agent-1: -12533.414882668432
agent-2: -20523.957366395105
agent-3: -29955.502698479053
agent-4: -16913.167170164284
agent-5: -25105.28667241908
Extrinsic Rewards:
-12435
-20372
-29786
-16773
-24930
Sum Reward: -104296
Avg Reward: -20859.2
Min Reward: -29786
Max Reward: -12435
Gini Coefficient: -0.16437447265475186
20:20 Ratio: 0.4174780098032633
Max-min Ratio: 0.4174780098032633
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-26-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -96477.22146332591
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1191
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.91
    dispatch_time_ms: 9.242
    learner:
      cur_lr: 0.0009633969748392701
      grad_gnorm: 40.0
      policy_entropy: 34.57449722290039
      policy_loss: -1563.526123046875
      var_gnorm: 161.7357940673828
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 329664.34375
    num_steps_sampled: 5960000
    num_steps_trained: 5960000
    wait_time_ms: 72.643
  iterations_since_restore: 1192
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10371.491893053055
  time_this_iter_s: 8.38680100440979
  time_total_s: 10371.491893053055
  timestamp: 1594866412
  timesteps_since_restore: 5960000
  timesteps_this_iter: 5000
  timesteps_total: 5960000
  training_iteration: 1192
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10371 s, 1192 iter, 5960000 ts, -9.65e+04 rew

agent-1: -13672.42103573194
agent-2: -19577.297078563664
agent-3: -10063.097345125776
agent-4: -20070.76279274914
agent-5: -18295.31884244351
Extrinsic Rewards:
-13549
-19394
-9964
-19890
-18132
Sum Reward: -80929
Avg Reward: -16185.8
Min Reward: -19890
Max Reward: -9964
Gini Coefficient: -0.1270100952686923
20:20 Ratio: 0.5009552538964304
Max-min Ratio: 0.5009552538964304
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-27-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -96532.20094685983
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1192
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.518
    dispatch_time_ms: 5.844
    learner:
      cur_lr: 0.0009630640270188451
      grad_gnorm: 40.0
      policy_entropy: 38.42174530029297
      policy_loss: -4509.734375
      var_gnorm: 162.16358947753906
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 767094.3125
    num_steps_sampled: 5965000
    num_steps_trained: 5965000
    wait_time_ms: 74.002
  iterations_since_restore: 1193
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10379.823150157928
  time_this_iter_s: 8.331257104873657
  time_total_s: 10379.823150157928
  timestamp: 1594866421
  timesteps_since_restore: 5965000
  timesteps_this_iter: 5000
  timesteps_total: 5965000
  training_iteration: 1193
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10379 s, 1193 iter, 5965000 ts, -9.65e+04 rew

agent-1: -18532.059863554663
agent-2: -18604.86626375439
agent-3: -4853.387842831212
agent-4: -7560.985532036842
agent-5: -21018.005336643222
Extrinsic Rewards:
-18345
-18420
-4795
-7465
-20823
Sum Reward: -69848
Avg Reward: -13969.6
Min Reward: -20823
Max Reward: -4795
Gini Coefficient: -0.24631199175352195
20:20 Ratio: 0.23027421601114154
Max-min Ratio: 0.23027421601114154
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-27-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -96779.87565687939
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1193
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.409
    dispatch_time_ms: 7.203
    learner:
      cur_lr: 0.0009627310209907591
      grad_gnorm: 40.000003814697266
      policy_entropy: 36.02354431152344
      policy_loss: 72.42906188964844
      var_gnorm: 162.38949584960938
      vf_explained_var: 0.0
      vf_loss: 96514.0
    num_steps_sampled: 5970000
    num_steps_trained: 5970000
    wait_time_ms: 73.87
  iterations_since_restore: 1194
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10387.92874956131
  time_this_iter_s: 8.105599403381348
  time_total_s: 10387.92874956131
  timestamp: 1594866429
  timesteps_since_restore: 5970000
  timesteps_this_iter: 5000
  timesteps_total: 5970000
  training_iteration: 1194
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10387 s, 1194 iter, 5970000 ts, -9.68e+04 rew

agent-1: -20308.5069482077
agent-2: -6138.296015308985
agent-3: -9273.21354910787
agent-4: -22898.274805546684
agent-5: -27432.088762308373
Extrinsic Rewards:
-20159
-6072
-9184
-22707
-27220
Sum Reward: -85342
Avg Reward: -17068.4
Min Reward: -27220
Max Reward: -6072
Gini Coefficient: -0.26162499121183
20:20 Ratio: 0.2230712711241734
Max-min Ratio: 0.2230712711241734
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-27-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -96913.12287453545
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1194
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.628
    dispatch_time_ms: 8.433
    learner:
      cur_lr: 0.0009623980149626732
      grad_gnorm: 40.0
      policy_entropy: 34.990718841552734
      policy_loss: -526.2689819335938
      var_gnorm: 162.49368286132812
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 92647.8125
    num_steps_sampled: 5975000
    num_steps_trained: 5975000
    wait_time_ms: 71.708
  iterations_since_restore: 1195
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10395.991999387741
  time_this_iter_s: 8.063249826431274
  time_total_s: 10395.991999387741
  timestamp: 1594866437
  timesteps_since_restore: 5975000
  timesteps_this_iter: 5000
  timesteps_total: 5975000
  training_iteration: 1195
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10395 s, 1195 iter, 5975000 ts, -9.69e+04 rew

agent-1: -8704.326060154022
agent-2: -10927.682715807432
agent-3: -8083.39034116043
agent-4: -3486.3924109682844
agent-5: -7526.143487370707
Extrinsic Rewards:
-8540
-10728
-7931
-3409
-7374
Sum Reward: -37982
Avg Reward: -7596.4
Min Reward: -10728
Max Reward: -3409
Gini Coefficient: -0.1664367331894055
20:20 Ratio: 0.31776659209545116
Max-min Ratio: 0.31776659209545116
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-27-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -96105.04832189163
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1195
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.597
    dispatch_time_ms: 8.226
    learner:
      cur_lr: 0.0009620650089345872
      grad_gnorm: 40.0
      policy_entropy: 33.63426971435547
      policy_loss: 676.164794921875
      var_gnorm: 162.4748077392578
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 30240.697265625
    num_steps_sampled: 5980000
    num_steps_trained: 5980000
    wait_time_ms: 69.79
  iterations_since_restore: 1196
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10404.017046928406
  time_this_iter_s: 8.025047540664673
  time_total_s: 10404.017046928406
  timestamp: 1594866445
  timesteps_since_restore: 5980000
  timesteps_this_iter: 5000
  timesteps_total: 5980000
  training_iteration: 1196
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10404 s, 1196 iter, 5980000 ts, -9.61e+04 rew

agent-1: -12885.679266204079
agent-2: -9267.71386562437
agent-3: -8938.505594172602
agent-4: -7202.072640893629
agent-5: -5902.604296098467
Extrinsic Rewards:
-12684
-9117
-8782
-7071
-5800
Sum Reward: -43454
Avg Reward: -8690.8
Min Reward: -12684
Max Reward: -5800
Gini Coefficient: -0.1455700280756662
20:20 Ratio: 0.45726900031535794
Max-min Ratio: 0.45726900031535794
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-27-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -95607.96012895493
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1196
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.499
    dispatch_time_ms: 6.33
    learner:
      cur_lr: 0.0009617320029065013
      grad_gnorm: 40.000003814697266
      policy_entropy: 33.251312255859375
      policy_loss: -1456.83154296875
      var_gnorm: 162.5990447998047
      vf_explained_var: 0.0
      vf_loss: 142769.421875
    num_steps_sampled: 5985000
    num_steps_trained: 5985000
    wait_time_ms: 72.806
  iterations_since_restore: 1197
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10412.459260463715
  time_this_iter_s: 8.442213535308838
  time_total_s: 10412.459260463715
  timestamp: 1594866454
  timesteps_since_restore: 5985000
  timesteps_this_iter: 5000
  timesteps_total: 5985000
  training_iteration: 1197
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10412 s, 1197 iter, 5985000 ts, -9.56e+04 rew

agent-1: -3971.0218034991126
agent-2: -10571.067396596534
agent-3: -10035.179327715387
agent-4: -10234.124136967737
agent-5: -7174.893601297804
Extrinsic Rewards:
-3898
-10389
-9856
-10057
-7040
Sum Reward: -41240
Avg Reward: -8248.0
Min Reward: -10389
Max Reward: -3898
Gini Coefficient: -0.15517943743937923
20:20 Ratio: 0.37520454326691693
Max-min Ratio: 0.37520454326691693
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-27-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -95010.18230791349
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1197
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.777
    dispatch_time_ms: 5.692
    learner:
      cur_lr: 0.0009613989968784153
      grad_gnorm: 40.0
      policy_entropy: 23.488126754760742
      policy_loss: 412.8719482421875
      var_gnorm: 162.50653076171875
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 29358.765625
    num_steps_sampled: 5990000
    num_steps_trained: 5990000
    wait_time_ms: 72.846
  iterations_since_restore: 1198
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10420.400474071503
  time_this_iter_s: 7.941213607788086
  time_total_s: 10420.400474071503
  timestamp: 1594866462
  timesteps_since_restore: 5990000
  timesteps_this_iter: 5000
  timesteps_total: 5990000
  training_iteration: 1198
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10420 s, 1198 iter, 5990000 ts, -9.5e+04 rew

agent-1: -4289.561591538434
agent-2: -10465.042147570242
agent-3: -10864.243138522375
agent-4: -12187.28570421269
agent-5: -4031.2707679244395
Extrinsic Rewards:
-4204
-10283
-10678
-11992
-3946
Sum Reward: -41103
Avg Reward: -8220.6
Min Reward: -11992
Max Reward: -3946
Gini Coefficient: -0.21960440843734033
20:20 Ratio: 0.3290527018012008
Max-min Ratio: 0.3290527018012008
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-27-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -94654.21795335771
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1198
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.079
    dispatch_time_ms: 7.65
    learner:
      cur_lr: 0.0009610659908503294
      grad_gnorm: 40.0
      policy_entropy: 31.51700782775879
      policy_loss: 464.96612548828125
      var_gnorm: 162.20265197753906
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 54680.2265625
    num_steps_sampled: 5995000
    num_steps_trained: 5995000
    wait_time_ms: 70.185
  iterations_since_restore: 1199
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10428.354422569275
  time_this_iter_s: 7.953948497772217
  time_total_s: 10428.354422569275
  timestamp: 1594866470
  timesteps_since_restore: 5995000
  timesteps_this_iter: 5000
  timesteps_total: 5995000
  training_iteration: 1199
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10428 s, 1199 iter, 5995000 ts, -9.47e+04 rew

agent-1: -3542.791299298349
agent-2: -4242.302832889364
agent-3: -9645.373461854071
agent-4: -8572.299878241136
agent-5: -11418.659688212969
Extrinsic Rewards:
-3455
-4153
-9465
-8407
-11211
Sum Reward: -36691
Avg Reward: -7338.2
Min Reward: -11211
Max Reward: -3455
Gini Coefficient: -0.22702025019759614
20:20 Ratio: 0.3081794665953082
Max-min Ratio: 0.3081794665953082
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-27-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -93320.03950025192
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1199
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.22
    dispatch_time_ms: 8.546
    learner:
      cur_lr: 0.0009607329848222435
      grad_gnorm: 39.999996185302734
      policy_entropy: 33.0907096862793
      policy_loss: -669.1605224609375
      var_gnorm: 162.19837951660156
      vf_explained_var: 0.0
      vf_loss: 76048.75
    num_steps_sampled: 6000000
    num_steps_trained: 6000000
    wait_time_ms: 67.445
  iterations_since_restore: 1200
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10436.355612277985
  time_this_iter_s: 8.001189708709717
  time_total_s: 10436.355612277985
  timestamp: 1594866478
  timesteps_since_restore: 6000000
  timesteps_this_iter: 5000
  timesteps_total: 6000000
  training_iteration: 1200
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10436 s, 1200 iter, 6000000 ts, -9.33e+04 rew

agent-1: -2879.8831826877686
agent-2: -6725.214816001975
agent-3: -4561.560191475917
agent-4: -8001.602725295623
agent-5: -7623.798759096658
Extrinsic Rewards:
-2806
-6571
-4434
-7809
-7435
Sum Reward: -29055
Avg Reward: -5811.0
Min Reward: -7809
Max Reward: -2806
Gini Coefficient: -0.17906728618138015
20:20 Ratio: 0.3593289793827635
Max-min Ratio: 0.3593289793827635
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-28-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -92983.90604971367
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1200
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.509
    dispatch_time_ms: 6.097
    learner:
      cur_lr: 0.0009603999787941575
      grad_gnorm: 40.0
      policy_entropy: 20.95391273498535
      policy_loss: 1221.6085205078125
      var_gnorm: 161.97271728515625
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 36026.39453125
    num_steps_sampled: 6005000
    num_steps_trained: 6005000
    wait_time_ms: 69.295
  iterations_since_restore: 1201
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10444.4260597229
  time_this_iter_s: 8.070447444915771
  time_total_s: 10444.4260597229
  timestamp: 1594866486
  timesteps_since_restore: 6005000
  timesteps_this_iter: 5000
  timesteps_total: 6005000
  training_iteration: 1201
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10444 s, 1201 iter, 6005000 ts, -9.3e+04 rew

agent-1: -3528.6266204210674
agent-2: -8068.478109339487
agent-3: -8294.21608531363
agent-4: -10557.298207134096
agent-5: -1756.4116397886414
Extrinsic Rewards:
-3447
-7906
-8103
-10346
-1698
Sum Reward: -31500
Avg Reward: -6300.0
Min Reward: -10346
Max Reward: -1698
Gini Coefficient: -0.27875555555555553
20:20 Ratio: 0.16412139957471486
Max-min Ratio: 0.16412139957471486
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-28-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -91956.83460117326
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1201
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.204
    dispatch_time_ms: 8.667
    learner:
      cur_lr: 0.0009600669727660716
      grad_gnorm: 39.999996185302734
      policy_entropy: 31.202030181884766
      policy_loss: 273.8218994140625
      var_gnorm: 161.94920349121094
      vf_explained_var: 0.0
      vf_loss: 78694.8984375
    num_steps_sampled: 6010000
    num_steps_trained: 6010000
    wait_time_ms: 66.361
  iterations_since_restore: 1202
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10452.386189937592
  time_this_iter_s: 7.960130214691162
  time_total_s: 10452.386189937592
  timestamp: 1594866494
  timesteps_since_restore: 6010000
  timesteps_this_iter: 5000
  timesteps_total: 6010000
  training_iteration: 1202
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10452 s, 1202 iter, 6010000 ts, -9.2e+04 rew

agent-1: -4521.845405267168
agent-2: -4892.721700263814
agent-3: -8269.633703136593
agent-4: -8757.864075489822
agent-5: -9146.565517443943
Extrinsic Rewards:
-4420
-4779
-8105
-8574
-8956
Sum Reward: -34834
Avg Reward: -6966.8
Min Reward: -8956
Max Reward: -4420
Gini Coefficient: -0.14775219613021762
20:20 Ratio: 0.4935238945958017
Max-min Ratio: 0.4935238945958017
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-28-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -91181.46864375268
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1202
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.48
    dispatch_time_ms: 8.759
    learner:
      cur_lr: 0.0009597340249456465
      grad_gnorm: 40.000003814697266
      policy_entropy: 36.3223876953125
      policy_loss: -2000.314208984375
      var_gnorm: 162.04234313964844
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 327747.40625
    num_steps_sampled: 6015000
    num_steps_trained: 6015000
    wait_time_ms: 70.868
  iterations_since_restore: 1203
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10460.474898576736
  time_this_iter_s: 8.088708639144897
  time_total_s: 10460.474898576736
  timestamp: 1594866502
  timesteps_since_restore: 6015000
  timesteps_this_iter: 5000
  timesteps_total: 6015000
  training_iteration: 1203
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10460 s, 1203 iter, 6015000 ts, -9.12e+04 rew

agent-1: -21748.433447113133
agent-2: -19616.59306692323
agent-3: -12516.414547444178
agent-4: -13941.725362693283
agent-5: -13959.178397318265
Extrinsic Rewards:
-21555
-19437
-12395
-13817
-13824
Sum Reward: -81028
Avg Reward: -16205.6
Min Reward: -21555
Max Reward: -12395
Gini Coefficient: -0.11818136940316927
20:20 Ratio: 0.5750405938297379
Max-min Ratio: 0.5750405938297379
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-28-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -90882.01193696652
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1203
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.939
    dispatch_time_ms: 6.877
    learner:
      cur_lr: 0.0009594010189175606
      grad_gnorm: 40.0
      policy_entropy: 38.298580169677734
      policy_loss: -3700.431640625
      var_gnorm: 162.39068603515625
      vf_explained_var: 0.0
      vf_loss: 273751.09375
    num_steps_sampled: 6020000
    num_steps_trained: 6020000
    wait_time_ms: 71.293
  iterations_since_restore: 1204
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10468.654411554337
  time_this_iter_s: 8.179512977600098
  time_total_s: 10468.654411554337
  timestamp: 1594866510
  timesteps_since_restore: 6020000
  timesteps_this_iter: 5000
  timesteps_total: 6020000
  training_iteration: 1204
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10468 s, 1204 iter, 6020000 ts, -9.09e+04 rew

agent-1: -12387.867737085948
agent-2: -14074.526386066573
agent-3: -3811.571468636446
agent-4: -9096.972650549074
agent-5: -5306.645563065806
Extrinsic Rewards:
-12204
-13861
-3747
-8949
-5200
Sum Reward: -43961
Avg Reward: -8792.2
Min Reward: -13861
Max Reward: -3747
Gini Coefficient: -0.2477832624371602
20:20 Ratio: 0.27032681624702404
Max-min Ratio: 0.27032681624702404
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-28-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -90119.3832353249
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1204
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.169
    dispatch_time_ms: 6.384
    learner:
      cur_lr: 0.0009590680128894746
      grad_gnorm: 39.999996185302734
      policy_entropy: 39.33330154418945
      policy_loss: -887.2531127929688
      var_gnorm: 162.5473175048828
      vf_explained_var: 0.0
      vf_loss: 95332.1484375
    num_steps_sampled: 6025000
    num_steps_trained: 6025000
    wait_time_ms: 72.121
  iterations_since_restore: 1205
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10476.794494867325
  time_this_iter_s: 8.140083312988281
  time_total_s: 10476.794494867325
  timestamp: 1594866518
  timesteps_since_restore: 6025000
  timesteps_this_iter: 5000
  timesteps_total: 6025000
  training_iteration: 1205
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10476 s, 1205 iter, 6025000 ts, -9.01e+04 rew

agent-1: -18068.73292884133
agent-2: -17022.772922092234
agent-3: -6932.058040346314
agent-4: -18456.985720348945
agent-5: -27510.376339760318
Extrinsic Rewards:
-17920
-16862
-6858
-18328
-27296
Sum Reward: -87264
Avg Reward: -17452.8
Min Reward: -27296
Max Reward: -6858
Gini Coefficient: -0.1940869086908691
20:20 Ratio: 0.25124560375146543
Max-min Ratio: 0.25124560375146543
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-28-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -90141.37505440266
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1205
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.545
    dispatch_time_ms: 8.096
    learner:
      cur_lr: 0.0009587350068613887
      grad_gnorm: 40.0
      policy_entropy: 40.43940734863281
      policy_loss: 999.1986694335938
      var_gnorm: 163.014892578125
      vf_explained_var: -1.0
      vf_loss: 37749.8828125
    num_steps_sampled: 6030000
    num_steps_trained: 6030000
    wait_time_ms: 71.849
  iterations_since_restore: 1206
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10484.985664844513
  time_this_iter_s: 8.19116997718811
  time_total_s: 10484.985664844513
  timestamp: 1594866526
  timesteps_since_restore: 6030000
  timesteps_this_iter: 5000
  timesteps_total: 6030000
  training_iteration: 1206
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10484 s, 1206 iter, 6030000 ts, -9.01e+04 rew

agent-1: -10368.742137885698
agent-2: -15203.558398050392
agent-3: -16948.879491398548
agent-4: -13994.162901483902
agent-5: -5838.1867218332145
Extrinsic Rewards:
-10263
-15018
-16767
-13818
-5772
Sum Reward: -61638
Avg Reward: -12327.6
Min Reward: -16767
Max Reward: -5772
Gini Coefficient: -0.17356176384697752
20:20 Ratio: 0.3442476292717839
Max-min Ratio: 0.3442476292717839
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-28-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -89689.82122741977
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1206
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.812
    dispatch_time_ms: 6.982
    learner:
      cur_lr: 0.0009584020008333027
      grad_gnorm: 40.0
      policy_entropy: 38.048763275146484
      policy_loss: -3873.133544921875
      var_gnorm: 163.3874969482422
      vf_explained_var: 0.0
      vf_loss: 738237.375
    num_steps_sampled: 6035000
    num_steps_trained: 6035000
    wait_time_ms: 74.505
  iterations_since_restore: 1207
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10493.292202949524
  time_this_iter_s: 8.306538105010986
  time_total_s: 10493.292202949524
  timestamp: 1594866535
  timesteps_since_restore: 6035000
  timesteps_this_iter: 5000
  timesteps_total: 6035000
  training_iteration: 1207
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10493 s, 1207 iter, 6035000 ts, -8.97e+04 rew

agent-1: -21440.986176756942
agent-2: -25626.797685084923
agent-3: -22766.43606083939
agent-4: -14521.565072263971
agent-5: -24114.05629511539
Extrinsic Rewards:
-21303
-25450
-22603
-14416
-23948
Sum Reward: -107720
Avg Reward: -21544.0
Min Reward: -25450
Max Reward: -14416
Gini Coefficient: -0.091767545488303
20:20 Ratio: 0.5664440078585462
Max-min Ratio: 0.5664440078585462
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-29-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -89411.63215409374
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1207
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.889
    dispatch_time_ms: 8.619
    learner:
      cur_lr: 0.0009580689948052168
      grad_gnorm: 40.0
      policy_entropy: 40.153167724609375
      policy_loss: -4646.3701171875
      var_gnorm: 163.9107666015625
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 689636.0
    num_steps_sampled: 6040000
    num_steps_trained: 6040000
    wait_time_ms: 70.811
  iterations_since_restore: 1208
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10501.618676185608
  time_this_iter_s: 8.326473236083984
  time_total_s: 10501.618676185608
  timestamp: 1594866543
  timesteps_since_restore: 6040000
  timesteps_this_iter: 5000
  timesteps_total: 6040000
  training_iteration: 1208
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10501 s, 1208 iter, 6040000 ts, -8.94e+04 rew

agent-1: -28739.688602404196
agent-2: -36410.765234763865
agent-3: -21729.261371634006
agent-4: -18008.245579671227
agent-5: -15706.19368042641
Extrinsic Rewards:
-28580
-36206
-21595
-17887
-15591
Sum Reward: -119859
Avg Reward: -23971.8
Min Reward: -36206
Max Reward: -15591
Gini Coefficient: -0.17328027098507412
20:20 Ratio: 0.4306192343810418
Max-min Ratio: 0.4306192343810418
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-29-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -89752.71953581886
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1208
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.296
    dispatch_time_ms: 29.077
    learner:
      cur_lr: 0.0009577359887771308
      grad_gnorm: 40.00000762939453
      policy_entropy: 35.43435287475586
      policy_loss: -4723.75390625
      var_gnorm: 164.3784942626953
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 331413.15625
    num_steps_sampled: 6045000
    num_steps_trained: 6045000
    wait_time_ms: 54.294
  iterations_since_restore: 1209
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10510.584638595581
  time_this_iter_s: 8.965962409973145
  time_total_s: 10510.584638595581
  timestamp: 1594866552
  timesteps_since_restore: 6045000
  timesteps_this_iter: 5000
  timesteps_total: 6045000
  training_iteration: 1209
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10510 s, 1209 iter, 6045000 ts, -8.98e+04 rew

agent-1: -23392.300534926653
agent-2: -17810.535336788245
agent-3: -32296.977821329016
agent-4: -20445.100730040824
agent-5: -24243.869316237626
Extrinsic Rewards:
-23246
-17690
-32102
-20309
-24094
Sum Reward: -117441
Avg Reward: -23488.2
Min Reward: -32102
Max Reward: -17690
Gini Coefficient: -0.11106513057620422
20:20 Ratio: 0.5510560089714036
Max-min Ratio: 0.5510560089714036
agent-1: -20212.82453513557
agent-2: -25730.8539922847
agent-3: -28466.315501888133
agent-4: -34207.90353799794
agent-5: -30407.207536253936
Extrinsic Rewards:
-20098
-25583
-28311
-34030
-30252
Sum Reward: -138274
Avg Reward: -27654.8
Min Reward: -34030
Max Reward: -20098
Gini Coefficient: -0.09411169127963319
20:20 Ratio: 0.5905965324713488
Max-min Ratio: 0.5905965324713488
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-29-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -89559.03851808609
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 2
  episodes_total: 1210
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.664
    dispatch_time_ms: 29.674
    learner:
      cur_lr: 0.0009574029827490449
      grad_gnorm: 40.0
      policy_entropy: 39.136268615722656
      policy_loss: 18962.51171875
      var_gnorm: 164.8964385986328
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 7273849.5
    num_steps_sampled: 6050000
    num_steps_trained: 6050000
    wait_time_ms: 50.556
  iterations_since_restore: 1210
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10519.55017709732
  time_this_iter_s: 8.965538501739502
  time_total_s: 10519.55017709732
  timestamp: 1594866561
  timesteps_since_restore: 6050000
  timesteps_this_iter: 5000
  timesteps_total: 6050000
  training_iteration: 1210
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10519 s, 1210 iter, 6050000 ts, -8.96e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-29-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -89559.03851808612
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 0
  episodes_total: 1210
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.771
    dispatch_time_ms: 20.838
    learner:
      cur_lr: 0.000957069976720959
      grad_gnorm: 40.0
      policy_entropy: 42.64218521118164
      policy_loss: -2903.266357421875
      var_gnorm: 165.38014221191406
      vf_explained_var: 0.0
      vf_loss: 309752.625
    num_steps_sampled: 6055000
    num_steps_trained: 6055000
    wait_time_ms: 67.57
  iterations_since_restore: 1211
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10528.482582569122
  time_this_iter_s: 8.932405471801758
  time_total_s: 10528.482582569122
  timestamp: 1594866570
  timesteps_since_restore: 6055000
  timesteps_this_iter: 5000
  timesteps_total: 6055000
  training_iteration: 1211
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10528 s, 1211 iter, 6055000 ts, -8.96e+04 rew

agent-1: -18168.043132337883
agent-2: -23707.524604973383
agent-3: -24847.97338074333
agent-4: -19020.365905069346
agent-5: -16353.779101837274
Extrinsic Rewards:
-18035
-23552
-24674
-18870
-16221
Sum Reward: -101352
Avg Reward: -20270.4
Min Reward: -24674
Max Reward: -16221
Gini Coefficient: -0.08849554029520877
20:20 Ratio: 0.6574126611007538
Max-min Ratio: 0.6574126611007538
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-29-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -89335.35798988953
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1211
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.516
    dispatch_time_ms: 8.249
    learner:
      cur_lr: 0.0009567370289005339
      grad_gnorm: 39.999996185302734
      policy_entropy: 44.43748092651367
      policy_loss: -1816.4378662109375
      var_gnorm: 165.870849609375
      vf_explained_var: -0.09426605701446533
      vf_loss: 515035.96875
    num_steps_sampled: 6060000
    num_steps_trained: 6060000
    wait_time_ms: 74.83
  iterations_since_restore: 1212
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10537.35974740982
  time_this_iter_s: 8.877164840698242
  time_total_s: 10537.35974740982
  timestamp: 1594866579
  timesteps_since_restore: 6060000
  timesteps_this_iter: 5000
  timesteps_total: 6060000
  training_iteration: 1212
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10537 s, 1212 iter, 6060000 ts, -8.93e+04 rew

agent-1: -26468.615536102527
agent-2: -27895.076382603245
agent-3: -29542.076488237875
agent-4: -26211.81554358501
agent-5: -28090.431737183048
Extrinsic Rewards:
-26326
-27737
-29377
-26073
-27937
Sum Reward: -137450
Avg Reward: -27490.0
Min Reward: -29377
Max Reward: -26073
Gini Coefficient: -0.023918515823935976
20:20 Ratio: 0.8875310617149471
Max-min Ratio: 0.8875310617149471
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-29-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -89571.01290163503
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1212
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.619
    dispatch_time_ms: 6.423
    learner:
      cur_lr: 0.000956404022872448
      grad_gnorm: 39.999996185302734
      policy_entropy: 51.857757568359375
      policy_loss: -2370.624755859375
      var_gnorm: 166.31251525878906
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 257077.4375
    num_steps_sampled: 6065000
    num_steps_trained: 6065000
    wait_time_ms: 73.691
  iterations_since_restore: 1213
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10545.787702322006
  time_this_iter_s: 8.427954912185669
  time_total_s: 10545.787702322006
  timestamp: 1594866587
  timesteps_since_restore: 6065000
  timesteps_this_iter: 5000
  timesteps_total: 6065000
  training_iteration: 1213
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10545 s, 1213 iter, 6065000 ts, -8.96e+04 rew

agent-1: -22007.641348255762
agent-2: -17618.367847267113
agent-3: -18076.425216923595
agent-4: -22053.490711824026
agent-5: -20343.08050743829
Extrinsic Rewards:
-21848
-17473
-17936
-21890
-20198
Sum Reward: -99345
Avg Reward: -19869.0
Min Reward: -21890
Max Reward: -17473
Gini Coefficient: -0.05132014696260506
20:20 Ratio: 0.7982183645500228
Max-min Ratio: 0.7982183645500228
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-29-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -90061.80374298619
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1213
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.892
    dispatch_time_ms: 9.56
    learner:
      cur_lr: 0.000956071016844362
      grad_gnorm: 39.999996185302734
      policy_entropy: 42.45956039428711
      policy_loss: -10021.658203125
      var_gnorm: 166.74913024902344
      vf_explained_var: -0.12780940532684326
      vf_loss: 1100616.875
    num_steps_sampled: 6070000
    num_steps_trained: 6070000
    wait_time_ms: 69.633
  iterations_since_restore: 1214
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10554.169572591782
  time_this_iter_s: 8.38187026977539
  time_total_s: 10554.169572591782
  timestamp: 1594866596
  timesteps_since_restore: 6070000
  timesteps_this_iter: 5000
  timesteps_total: 6070000
  training_iteration: 1214
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10554 s, 1214 iter, 6070000 ts, -9.01e+04 rew

agent-1: -17073.303209351005
agent-2: -21418.34463200615
agent-3: -16085.276424128044
agent-4: -18506.375167023525
agent-5: -25065.959098942898
Extrinsic Rewards:
-16935
-21260
-15954
-18368
-24886
Sum Reward: -97403
Avg Reward: -19480.6
Min Reward: -24886
Max Reward: -15954
Gini Coefficient: -0.09112245002720655
20:20 Ratio: 0.6410833400305392
Max-min Ratio: 0.6410833400305392
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-30-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -90131.88687763755
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1214
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.615
    dispatch_time_ms: 7.495
    learner:
      cur_lr: 0.0009557380108162761
      grad_gnorm: 40.0
      policy_entropy: 38.30105209350586
      policy_loss: -6550.89453125
      var_gnorm: 167.1877899169922
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 804205.125
    num_steps_sampled: 6075000
    num_steps_trained: 6075000
    wait_time_ms: 74.815
  iterations_since_restore: 1215
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10562.592156410217
  time_this_iter_s: 8.422583818435669
  time_total_s: 10562.592156410217
  timestamp: 1594866604
  timesteps_since_restore: 6075000
  timesteps_this_iter: 5000
  timesteps_total: 6075000
  training_iteration: 1215
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10562 s, 1215 iter, 6075000 ts, -9.01e+04 rew

agent-1: -24599.866674463457
agent-2: -16219.955247333864
agent-3: -24666.348077605347
agent-4: -25498.147455288632
agent-5: -29916.850089952328
Extrinsic Rewards:
-24444
-16111
-24507
-25342
-29737
Sum Reward: -120141
Avg Reward: -24028.2
Min Reward: -29737
Max Reward: -16111
Gini Coefficient: -0.09372320856327149
20:20 Ratio: 0.5417829639842621
Max-min Ratio: 0.5417829639842621
agent-1: -29894.929473470165
agent-2: -29763.62396895973
agent-3: -28652.10345749416
agent-4: -17269.927863930818
agent-5: -23920.751070481165
Extrinsic Rewards:
-29727
-29598
-28486
-17154
-23787
Sum Reward: -128752
Avg Reward: -25750.4
Min Reward: -29727
Max Reward: -17154
Gini Coefficient: -0.09617559338884056
20:20 Ratio: 0.577051165607024
Max-min Ratio: 0.577051165607024
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-30-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -91346.51563873625
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 2
  episodes_total: 1216
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.492
    dispatch_time_ms: 8.073
    learner:
      cur_lr: 0.0009554050047881901
      grad_gnorm: 39.999996185302734
      policy_entropy: 34.065704345703125
      policy_loss: -4200.96240234375
      var_gnorm: 167.65684509277344
      vf_explained_var: -0.08957922458648682
      vf_loss: 1349674.25
    num_steps_sampled: 6080000
    num_steps_trained: 6080000
    wait_time_ms: 74.658
  iterations_since_restore: 1216
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10571.152326583862
  time_this_iter_s: 8.56017017364502
  time_total_s: 10571.152326583862
  timestamp: 1594866613
  timesteps_since_restore: 6080000
  timesteps_this_iter: 5000
  timesteps_total: 6080000
  training_iteration: 1216
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10571 s, 1216 iter, 6080000 ts, -9.13e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-30-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -91346.51563873622
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 0
  episodes_total: 1216
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.76
    dispatch_time_ms: 6.44
    learner:
      cur_lr: 0.0009550719987601042
      grad_gnorm: 40.000003814697266
      policy_entropy: 33.906436920166016
      policy_loss: -4273.4970703125
      var_gnorm: 168.10055541992188
      vf_explained_var: 0.0
      vf_loss: 846680.75
    num_steps_sampled: 6085000
    num_steps_trained: 6085000
    wait_time_ms: 75.089
  iterations_since_restore: 1217
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10579.618506669998
  time_this_iter_s: 8.466180086135864
  time_total_s: 10579.618506669998
  timestamp: 1594866621
  timesteps_since_restore: 6085000
  timesteps_this_iter: 5000
  timesteps_total: 6085000
  training_iteration: 1217
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10579 s, 1217 iter, 6085000 ts, -9.13e+04 rew

agent-1: -27401.32753330275
agent-2: -25499.459949746404
agent-3: -21973.210182306408
agent-4: -31938.81673065816
agent-5: -16205.004660261673
Extrinsic Rewards:
-27234
-25340
-21846
-31758
-16105
Sum Reward: -122283
Avg Reward: -24456.6
Min Reward: -31758
Max Reward: -16105
Gini Coefficient: -0.12002976701585666
20:20 Ratio: 0.5071163171484351
Max-min Ratio: 0.5071163171484351
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-30-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -91559.82928676822
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1217
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.536
    dispatch_time_ms: 7.239
    learner:
      cur_lr: 0.0009547389927320182
      grad_gnorm: 40.0
      policy_entropy: 33.7487907409668
      policy_loss: -3896.925537109375
      var_gnorm: 168.58763122558594
      vf_explained_var: -0.10443758964538574
      vf_loss: 1120964.375
    num_steps_sampled: 6090000
    num_steps_trained: 6090000
    wait_time_ms: 72.717
  iterations_since_restore: 1218
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10588.07318854332
  time_this_iter_s: 8.454681873321533
  time_total_s: 10588.07318854332
  timestamp: 1594866630
  timesteps_since_restore: 6090000
  timesteps_this_iter: 5000
  timesteps_total: 6090000
  training_iteration: 1218
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10588 s, 1218 iter, 6090000 ts, -9.16e+04 rew

agent-1: -21175.718079901857
agent-2: -30010.426027203
agent-3: -31562.712386245115
agent-4: -25265.164345615114
agent-5: -31692.625045963086
Extrinsic Rewards:
-21055
-29849
-31395
-25127
-31524
Sum Reward: -138950
Avg Reward: -27790.0
Min Reward: -31524
Max Reward: -21055
Gini Coefficient: -0.0783188197193235
20:20 Ratio: 0.66790381931227
Max-min Ratio: 0.66790381931227
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-30-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -92068.68862811032
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1218
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.602
    dispatch_time_ms: 7.66
    learner:
      cur_lr: 0.0009544059867039323
      grad_gnorm: 39.999996185302734
      policy_entropy: 30.771228790283203
      policy_loss: -3559.01953125
      var_gnorm: 169.04049682617188
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 782849.5
    num_steps_sampled: 6095000
    num_steps_trained: 6095000
    wait_time_ms: 71.216
  iterations_since_restore: 1219
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10596.527408123016
  time_this_iter_s: 8.454219579696655
  time_total_s: 10596.527408123016
  timestamp: 1594866638
  timesteps_since_restore: 6095000
  timesteps_this_iter: 5000
  timesteps_total: 6095000
  training_iteration: 1219
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10596 s, 1219 iter, 6095000 ts, -9.21e+04 rew

agent-1: -24148.182770513606
agent-2: -18762.606315709883
agent-3: -23035.22366739113
agent-4: -21928.461329488247
agent-5: -33530.66087838048
Extrinsic Rewards:
-23994
-18647
-22883
-21794
-33339
Sum Reward: -120657
Avg Reward: -24131.4
Min Reward: -33339
Max Reward: -18647
Gini Coefficient: -0.10470673064969294
20:20 Ratio: 0.5593149164642011
Max-min Ratio: 0.5593149164642011
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-30-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -92281.18768957358
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1219
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.042
    dispatch_time_ms: 6.927
    learner:
      cur_lr: 0.0009540729806758463
      grad_gnorm: 39.999996185302734
      policy_entropy: 30.003957748413086
      policy_loss: 589.55126953125
      var_gnorm: 169.5153045654297
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 203638.859375
    num_steps_sampled: 6100000
    num_steps_trained: 6100000
    wait_time_ms: 74.169
  iterations_since_restore: 1220
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10604.985517263412
  time_this_iter_s: 8.458109140396118
  time_total_s: 10604.985517263412
  timestamp: 1594866647
  timesteps_since_restore: 6100000
  timesteps_this_iter: 5000
  timesteps_total: 6100000
  training_iteration: 1220
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10604 s, 1220 iter, 6100000 ts, -9.23e+04 rew

agent-1: -34147.96452376965
agent-2: -12896.6870465719
agent-3: -32801.13497120387
agent-4: -28466.17034501398
agent-5: -24382.9538262936
Extrinsic Rewards:
-33964
-12815
-32622
-28312
-24243
Sum Reward: -131956
Avg Reward: -26391.2
Min Reward: -33964
Max Reward: -12815
Gini Coefficient: -0.15361787262420806
20:20 Ratio: 0.3773112707572724
Max-min Ratio: 0.3773112707572724
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-30-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -92723.73721583857
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1220
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.579
    dispatch_time_ms: 10.663
    learner:
      cur_lr: 0.0009537399746477604
      grad_gnorm: 40.0
      policy_entropy: 40.31719970703125
      policy_loss: -2749.1552734375
      var_gnorm: 169.9629669189453
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 340281.25
    num_steps_sampled: 6105000
    num_steps_trained: 6105000
    wait_time_ms: 69.729
  iterations_since_restore: 1221
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10613.399580001831
  time_this_iter_s: 8.414062738418579
  time_total_s: 10613.399580001831
  timestamp: 1594866655
  timesteps_since_restore: 6105000
  timesteps_this_iter: 5000
  timesteps_total: 6105000
  training_iteration: 1221
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10613 s, 1221 iter, 6105000 ts, -9.27e+04 rew

agent-1: -21770.262976464666
agent-2: -17518.441586574707
agent-3: -23445.82506742942
agent-4: -20724.10699028807
agent-5: -13054.236640476012
Extrinsic Rewards:
-21602
-17391
-23278
-20561
-12940
Sum Reward: -95772
Avg Reward: -19154.4
Min Reward: -23278
Max Reward: -12940
Gini Coefficient: -0.10394269723927661
20:20 Ratio: 0.5558896812440931
Max-min Ratio: 0.5558896812440931
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-31-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -92049.61178656407
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1221
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.613
    dispatch_time_ms: 9.737
    learner:
      cur_lr: 0.0009534070268273354
      grad_gnorm: 39.999996185302734
      policy_entropy: 46.793968200683594
      policy_loss: -761.560791015625
      var_gnorm: 170.36630249023438
      vf_explained_var: 0.0
      vf_loss: 179776.4375
    num_steps_sampled: 6110000
    num_steps_trained: 6110000
    wait_time_ms: 71.382
  iterations_since_restore: 1222
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10621.812595367432
  time_this_iter_s: 8.413015365600586
  time_total_s: 10621.812595367432
  timestamp: 1594866664
  timesteps_since_restore: 6110000
  timesteps_this_iter: 5000
  timesteps_total: 6110000
  training_iteration: 1222
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10621 s, 1222 iter, 6110000 ts, -9.2e+04 rew

agent-1: -35785.70916890729
agent-2: -21515.87351465288
agent-3: -21925.764394896316
agent-4: -23686.216672725124
agent-5: -23644.698464581714
Extrinsic Rewards:
-35588
-21389
-21794
-23553
-23497
Sum Reward: -125821
Avg Reward: -25164.2
Min Reward: -35588
Max Reward: -21389
Gini Coefficient: -0.09587270805350458
20:20 Ratio: 0.6010171968079128
Max-min Ratio: 0.6010171968079128
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-31-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -91989.5228063562
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1222
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.925
    dispatch_time_ms: 8.262
    learner:
      cur_lr: 0.0009530740207992494
      grad_gnorm: 39.999996185302734
      policy_entropy: 47.5675048828125
      policy_loss: -5705.1103515625
      var_gnorm: 170.76646423339844
      vf_explained_var: 0.0
      vf_loss: 728786.3125
    num_steps_sampled: 6115000
    num_steps_trained: 6115000
    wait_time_ms: 71.236
  iterations_since_restore: 1223
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10630.167082071304
  time_this_iter_s: 8.35448670387268
  time_total_s: 10630.167082071304
  timestamp: 1594866672
  timesteps_since_restore: 6115000
  timesteps_this_iter: 5000
  timesteps_total: 6115000
  training_iteration: 1223
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10630 s, 1223 iter, 6115000 ts, -9.2e+04 rew

agent-1: -25086.25382853926
agent-2: -24167.439317756995
agent-3: -19923.91255019819
agent-4: -16545.516602125186
agent-5: -12130.942306309882
Extrinsic Rewards:
-24905
-23986
-19772
-16412
-12028
Sum Reward: -97103
Avg Reward: -19420.6
Min Reward: -24905
Max Reward: -12028
Gini Coefficient: -0.13728927015643183
20:20 Ratio: 0.48295522987351935
Max-min Ratio: 0.48295522987351935
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-31-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -92082.30485672373
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1223
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.876
    dispatch_time_ms: 8.85
    learner:
      cur_lr: 0.0009527410147711635
      grad_gnorm: 40.0
      policy_entropy: 40.239784240722656
      policy_loss: -7776.51220703125
      var_gnorm: 171.21969604492188
      vf_explained_var: 0.0
      vf_loss: 851733.8125
    num_steps_sampled: 6120000
    num_steps_trained: 6120000
    wait_time_ms: 73.84
  iterations_since_restore: 1224
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10638.547969341278
  time_this_iter_s: 8.380887269973755
  time_total_s: 10638.547969341278
  timestamp: 1594866681
  timesteps_since_restore: 6120000
  timesteps_this_iter: 5000
  timesteps_total: 6120000
  training_iteration: 1224
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10638 s, 1224 iter, 6120000 ts, -9.21e+04 rew

agent-1: -16477.327817168232
agent-2: -24314.62495281806
agent-3: -17683.684825107866
agent-4: -21989.3308517552
agent-5: -20871.004723615188
Extrinsic Rewards:
-16348
-24134
-17557
-21841
-20720
Sum Reward: -100600
Avg Reward: -20120.0
Min Reward: -24134
Max Reward: -16348
Gini Coefficient: -0.07895029821073558
20:20 Ratio: 0.6773846026352863
Max-min Ratio: 0.6773846026352863
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-31-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -92002.99830493805
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1224
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 4.096
    dispatch_time_ms: 8.932
    learner:
      cur_lr: 0.0009524080087430775
      grad_gnorm: 40.0
      policy_entropy: 40.14591979980469
      policy_loss: -857.8009033203125
      var_gnorm: 171.6156768798828
      vf_explained_var: 0.0
      vf_loss: 84788.6875
    num_steps_sampled: 6125000
    num_steps_trained: 6125000
    wait_time_ms: 56.572
  iterations_since_restore: 1225
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10658.396394729614
  time_this_iter_s: 19.84842538833618
  time_total_s: 10658.396394729614
  timestamp: 1594866701
  timesteps_since_restore: 6125000
  timesteps_this_iter: 5000
  timesteps_total: 6125000
  training_iteration: 1225
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10658 s, 1225 iter, 6125000 ts, -9.2e+04 rew

agent-1: -16360.450458424175
agent-2: -23038.12570549077
agent-3: -24456.517255399183
agent-4: -17635.857630204962
agent-5: -25970.217339565897
Extrinsic Rewards:
-16241
-22869
-24281
-17534
-25790
Sum Reward: -106715
Avg Reward: -21343.0
Min Reward: -25790
Max Reward: -16241
Gini Coefficient: -0.09687485358197066
20:20 Ratio: 0.629740209383482
Max-min Ratio: 0.629740209383482
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-31-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -92289.22576070244
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1225
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.421
    dispatch_time_ms: 8.157
    learner:
      cur_lr: 0.0009520750027149916
      grad_gnorm: 40.000003814697266
      policy_entropy: 41.4140739440918
      policy_loss: -2023.600830078125
      var_gnorm: 172.08460998535156
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 306757.21875
    num_steps_sampled: 6130000
    num_steps_trained: 6130000
    wait_time_ms: 74.417
  iterations_since_restore: 1226
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10666.892898321152
  time_this_iter_s: 8.496503591537476
  time_total_s: 10666.892898321152
  timestamp: 1594866709
  timesteps_since_restore: 6130000
  timesteps_this_iter: 5000
  timesteps_total: 6130000
  training_iteration: 1226
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10666 s, 1226 iter, 6130000 ts, -9.23e+04 rew

agent-1: -26510.774327908468
agent-2: -24138.93097869691
agent-3: -26073.84962540669
agent-4: -31217.45930984323
agent-5: -17123.060218692142
Extrinsic Rewards:
-26348
-23993
-25921
-31041
-17010
Sum Reward: -124313
Avg Reward: -24862.6
Min Reward: -31041
Max Reward: -17010
Gini Coefficient: -0.09787230619484688
20:20 Ratio: 0.5479849231661351
Max-min Ratio: 0.5479849231661351
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-31-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -92437.95475772895
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1226
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.434
    dispatch_time_ms: 8.289
    learner:
      cur_lr: 0.0009517419966869056
      grad_gnorm: 40.0
      policy_entropy: 42.59834671020508
      policy_loss: -7309.38427734375
      var_gnorm: 172.46218872070312
      vf_explained_var: 0.0
      vf_loss: 1645499.375
    num_steps_sampled: 6135000
    num_steps_trained: 6135000
    wait_time_ms: 71.016
  iterations_since_restore: 1227
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10675.390844583511
  time_this_iter_s: 8.49794626235962
  time_total_s: 10675.390844583511
  timestamp: 1594866718
  timesteps_since_restore: 6135000
  timesteps_this_iter: 5000
  timesteps_total: 6135000
  training_iteration: 1227
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10675 s, 1227 iter, 6135000 ts, -9.24e+04 rew

agent-1: -16915.049052228624
agent-2: -14530.561917464276
agent-3: -15073.808920642903
agent-4: -24521.535935044583
agent-5: -24725.244633101014
Extrinsic Rewards:
-16788
-14404
-14951
-24336
-24543
Sum Reward: -95022
Avg Reward: -19004.4
Min Reward: -24543
Max Reward: -14404
Gini Coefficient: -0.12486792532255687
20:20 Ratio: 0.5868883184614758
Max-min Ratio: 0.5868883184614758
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-32-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -92310.76367818583
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1227
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.634
    dispatch_time_ms: 9.051
    learner:
      cur_lr: 0.0009514089906588197
      grad_gnorm: 40.0
      policy_entropy: 36.958858489990234
      policy_loss: -8379.9423828125
      var_gnorm: 172.93922424316406
      vf_explained_var: 0.0
      vf_loss: 3083254.75
    num_steps_sampled: 6140000
    num_steps_trained: 6140000
    wait_time_ms: 73.582
  iterations_since_restore: 1228
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10683.83049249649
  time_this_iter_s: 8.439647912979126
  time_total_s: 10683.83049249649
  timestamp: 1594866726
  timesteps_since_restore: 6140000
  timesteps_this_iter: 5000
  timesteps_total: 6140000
  training_iteration: 1228
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10683 s, 1228 iter, 6140000 ts, -9.23e+04 rew

agent-1: -32067.526522606608
agent-2: -18077.801580389336
agent-3: -27608.69859703945
agent-4: -24176.69824337991
agent-5: -22009.978570396903
Extrinsic Rewards:
-31884
-17959
-27439
-24031
-21879
Sum Reward: -123192
Avg Reward: -24638.4
Min Reward: -31884
Max Reward: -17959
Gini Coefficient: -0.1084810701993636
20:20 Ratio: 0.563260569564672
Max-min Ratio: 0.563260569564672
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-32-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -92597.31975155251
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1228
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.136
    dispatch_time_ms: 35.526
    learner:
      cur_lr: 0.0009510759846307337
      grad_gnorm: 39.999996185302734
      policy_entropy: 31.25860595703125
      policy_loss: -6766.7119140625
      var_gnorm: 173.38394165039062
      vf_explained_var: 0.0
      vf_loss: 2970039.25
    num_steps_sampled: 6145000
    num_steps_trained: 6145000
    wait_time_ms: 36.298
  iterations_since_restore: 1229
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10693.926649093628
  time_this_iter_s: 10.096156597137451
  time_total_s: 10693.926649093628
  timestamp: 1594866736
  timesteps_since_restore: 6145000
  timesteps_this_iter: 5000
  timesteps_total: 6145000
  training_iteration: 1229
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10693 s, 1229 iter, 6145000 ts, -9.26e+04 rew

agent-1: -33431.050726334746
agent-2: -26974.22386598282
agent-3: -27591.03630653412
agent-4: -23959.41376347695
agent-5: -14989.18921656934
Extrinsic Rewards:
-33244
-26818
-27427
-23821
-14897
Sum Reward: -126207
Avg Reward: -25241.4
Min Reward: -33244
Max Reward: -14897
Gini Coefficient: -0.1277266712622913
20:20 Ratio: 0.44811093731199614
Max-min Ratio: 0.44811093731199614
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-32-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -93099.61241812326
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1229
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.991
    dispatch_time_ms: 34.174
    learner:
      cur_lr: 0.0009507429786026478
      grad_gnorm: 39.999996185302734
      policy_entropy: 28.37281608581543
      policy_loss: -2446.08642578125
      var_gnorm: 173.88067626953125
      vf_explained_var: 0.0
      vf_loss: 483738.03125
    num_steps_sampled: 6150000
    num_steps_trained: 6150000
    wait_time_ms: 61.119
  iterations_since_restore: 1230
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10702.661439657211
  time_this_iter_s: 8.734790563583374
  time_total_s: 10702.661439657211
  timestamp: 1594866745
  timesteps_since_restore: 6150000
  timesteps_this_iter: 5000
  timesteps_total: 6150000
  training_iteration: 1230
  
agent-1: -26448.074248007557
agent-2: -13396.075714758199
agent-3: -39838.60033586233
agent-4: -28232.073477208018
agent-5: -25907.72420055985
Extrinsic Rewards:
-26299
-13302
-39642
-28084
-25764
Sum Reward: -133091
Avg Reward: -26618.2
Min Reward: -39642
Max Reward: -13302
Gini Coefficient: -0.16530043353795523
20:20 Ratio: 0.33555320115029513
Max-min Ratio: 0.33555320115029513
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10702 s, 1230 iter, 6150000 ts, -9.31e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-32-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -93556.60443526092
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1230
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.415
    dispatch_time_ms: 32.766
    learner:
      cur_lr: 0.0009504099725745618
      grad_gnorm: 40.0
      policy_entropy: 27.130638122558594
      policy_loss: -2625.794677734375
      var_gnorm: 174.2989501953125
      vf_explained_var: 0.0
      vf_loss: 1171006.0
    num_steps_sampled: 6155000
    num_steps_trained: 6155000
    wait_time_ms: 54.66
  iterations_since_restore: 1231
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10711.642141819
  time_this_iter_s: 8.98070216178894
  time_total_s: 10711.642141819
  timestamp: 1594866754
  timesteps_since_restore: 6155000
  timesteps_this_iter: 5000
  timesteps_total: 6155000
  training_iteration: 1231
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10711 s, 1231 iter, 6155000 ts, -9.36e+04 rew

agent-1: -33341.605098175845
agent-2: -19505.89109826598
agent-3: -28002.51544950162
agent-4: -28438.426985113932
agent-5: -20719.10893746531
Extrinsic Rewards:
-33173
-19379
-27838
-28285
-20591
Sum Reward: -129266
Avg Reward: -25853.2
Min Reward: -33173
Max Reward: -19379
Gini Coefficient: -0.10917642690266582
20:20 Ratio: 0.5841799053447081
Max-min Ratio: 0.5841799053447081
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-32-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -93791.86474100775
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1231
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.572
    dispatch_time_ms: 26.46
    learner:
      cur_lr: 0.0009500770247541368
      grad_gnorm: 40.0
      policy_entropy: 27.537206649780273
      policy_loss: -2785.076416015625
      var_gnorm: 174.793212890625
      vf_explained_var: 0.0
      vf_loss: 433894.46875
    num_steps_sampled: 6160000
    num_steps_trained: 6160000
    wait_time_ms: 63.658
  iterations_since_restore: 1232
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10720.637513399124
  time_this_iter_s: 8.995371580123901
  time_total_s: 10720.637513399124
  timestamp: 1594866763
  timesteps_since_restore: 6160000
  timesteps_this_iter: 5000
  timesteps_total: 6160000
  training_iteration: 1232
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10720 s, 1232 iter, 6160000 ts, -9.38e+04 rew

agent-1: -45126.94347284871
agent-2: -48869.315890849466
agent-3: -31947.3795445536
agent-4: -17067.54303941309
agent-5: -31149.59062259949
Extrinsic Rewards:
-44946
-48673
-31809
-16994
-31009
Sum Reward: -173431
Avg Reward: -34686.2
Min Reward: -48673
Max Reward: -16994
Gini Coefficient: -0.17827262715431497
20:20 Ratio: 0.34914634396893557
Max-min Ratio: 0.34914634396893557
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-32-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -94410.81389309413
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1232
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.742
    dispatch_time_ms: 43.353
    learner:
      cur_lr: 0.0009497440187260509
      grad_gnorm: 40.0
      policy_entropy: 23.364578247070312
      policy_loss: 76.810302734375
      var_gnorm: 175.25547790527344
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 193905.046875
    num_steps_sampled: 6165000
    num_steps_trained: 6165000
    wait_time_ms: 46.109
  iterations_since_restore: 1233
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10729.593711137772
  time_this_iter_s: 8.956197738647461
  time_total_s: 10729.593711137772
  timestamp: 1594866772
  timesteps_since_restore: 6165000
  timesteps_this_iter: 5000
  timesteps_total: 6165000
  training_iteration: 1233
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10729 s, 1233 iter, 6165000 ts, -9.44e+04 rew

agent-1: -34336.36493568657
agent-2: -25537.713667089334
agent-3: -25821.22480864152
agent-4: -27315.610190959665
agent-5: -22054.030670292486
Extrinsic Rewards:
-34162
-25401
-25680
-27161
-21933
Sum Reward: -134337
Avg Reward: -26867.4
Min Reward: -34162
Max Reward: -21933
Gini Coefficient: -0.0780663555089067
20:20 Ratio: 0.6420291552016861
Max-min Ratio: 0.6420291552016861
agent-1: -29856.946108364056
agent-2: -39445.197613563134
agent-3: -18149.431507911828
agent-4: -41988.28279228841
agent-5: -24526.867547664227
Extrinsic Rewards:
-29710
-39259
-18070
-41793
-24412
Sum Reward: -153244
Avg Reward: -30648.8
Min Reward: -41793
Max Reward: -18070
Gini Coefficient: -0.16259820939155856
20:20 Ratio: 0.43236905701911804
Max-min Ratio: 0.43236905701911804
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-33-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -94931.8535424389
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 2
  episodes_total: 1234
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.04
    dispatch_time_ms: 40.222
    learner:
      cur_lr: 0.0009494110126979649
      grad_gnorm: 40.0
      policy_entropy: 24.523021697998047
      policy_loss: -1599.5435791015625
      var_gnorm: 175.75404357910156
      vf_explained_var: -0.07138168811798096
      vf_loss: 565370.9375
    num_steps_sampled: 6170000
    num_steps_trained: 6170000
    wait_time_ms: 46.88
  iterations_since_restore: 1234
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10738.617824316025
  time_this_iter_s: 9.024113178253174
  time_total_s: 10738.617824316025
  timestamp: 1594866781
  timesteps_since_restore: 6170000
  timesteps_this_iter: 5000
  timesteps_total: 6170000
  training_iteration: 1234
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10738 s, 1234 iter, 6170000 ts, -9.49e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-33-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -94931.8535424389
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 0
  episodes_total: 1234
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.495
    dispatch_time_ms: 33.966
    learner:
      cur_lr: 0.000949078006669879
      grad_gnorm: 40.0
      policy_entropy: 31.84444808959961
      policy_loss: -4096.7158203125
      var_gnorm: 176.18020629882812
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 443134.59375
    num_steps_sampled: 6175000
    num_steps_trained: 6175000
    wait_time_ms: 61.004
  iterations_since_restore: 1235
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10747.658287763596
  time_this_iter_s: 9.0404634475708
  time_total_s: 10747.658287763596
  timestamp: 1594866790
  timesteps_since_restore: 6175000
  timesteps_this_iter: 5000
  timesteps_total: 6175000
  training_iteration: 1235
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10747 s, 1235 iter, 6175000 ts, -9.49e+04 rew

agent-1: -23318.55012494693
agent-2: -22049.26786236576
agent-3: -46903.086451635216
agent-4: -43732.906652786456
agent-5: -34131.98321810397
Extrinsic Rewards:
-23216
-21944
-46705
-43544
-33987
Sum Reward: -169396
Avg Reward: -33879.2
Min Reward: -46705
Max Reward: -21944
Gini Coefficient: -0.16493895959762922
20:20 Ratio: 0.4698426292688149
Max-min Ratio: 0.4698426292688149
agent-1: -23656.078947384576
agent-2: -17578.954161399608
agent-3: -22448.697015130067
agent-4: -16462.536463595992
agent-5: -17495.643364217256
Extrinsic Rewards:
-23481
-17439
-22288
-16343
-17354
Sum Reward: -96905
Avg Reward: -19381.0
Min Reward: -23481
Max Reward: -16343
Gini Coefficient: -0.07929415406841753
20:20 Ratio: 0.6960095396277841
Max-min Ratio: 0.6960095396277841
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-33-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -95878.71819263352
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1235
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 4.507
    dispatch_time_ms: 38.139
    learner:
      cur_lr: 0.000948745000641793
      grad_gnorm: 40.0
      policy_entropy: 37.74177169799805
      policy_loss: -917.921630859375
      var_gnorm: 176.64114379882812
      vf_explained_var: -0.15015697479248047
      vf_loss: 229612.265625
    num_steps_sampled: 6180000
    num_steps_trained: 6180000
    wait_time_ms: 36.588
  iterations_since_restore: 1236
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10756.502876758575
  time_this_iter_s: 8.844588994979858
  time_total_s: 10756.502876758575
  timestamp: 1594866799
  timesteps_since_restore: 6180000
  timesteps_this_iter: 5000
  timesteps_total: 6180000
  training_iteration: 1236
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10756 s, 1236 iter, 6180000 ts, -9.59e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-33-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -96248.33335010787
  episode_reward_min: -194213.27447839858
  episodes_this_iter: 1
  episodes_total: 1236
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.821
    dispatch_time_ms: 46.338
    learner:
      cur_lr: 0.0009484119946137071
      grad_gnorm: 40.0
      policy_entropy: 27.76136016845703
      policy_loss: 133.06666564941406
      var_gnorm: 177.0308380126953
      vf_explained_var: 0.0
      vf_loss: 100529.875
    num_steps_sampled: 6185000
    num_steps_trained: 6185000
    wait_time_ms: 54.028
  iterations_since_restore: 1237
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10765.623623132706
  time_this_iter_s: 9.120746374130249
  time_total_s: 10765.623623132706
  timestamp: 1594866808
  timesteps_since_restore: 6185000
  timesteps_this_iter: 5000
  timesteps_total: 6185000
  training_iteration: 1237
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10765 s, 1237 iter, 6185000 ts, -9.62e+04 rew

agent-1: -32287.14086752813
agent-2: -14328.083548879595
agent-3: -25798.791462223006
agent-4: -16064.350207414913
agent-5: -22521.219853608847
Extrinsic Rewards:
-32088
-14228
-25638
-15941
-22378
Sum Reward: -110273
Avg Reward: -22054.6
Min Reward: -32088
Max Reward: -14228
Gini Coefficient: -0.1647438629582944
20:20 Ratio: 0.44340563450511095
Max-min Ratio: 0.44340563450511095
agent-1: -37007.686555644046
agent-2: -52743.8911253257
agent-3: -44549.52068713569
agent-4: -29948.22197887728
agent-5: -36587.48161908836
Extrinsic Rewards:
-36852
-52554
-44399
-29838
-36447
Sum Reward: -200090
Avg Reward: -40018.0
Min Reward: -52554
Max Reward: -29838
Gini Coefficient: -0.10671997601079514
20:20 Ratio: 0.567758876584085
Max-min Ratio: 0.567758876584085
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-33-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -98731.31837041704
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 2
  episodes_total: 1238
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.681
    dispatch_time_ms: 45.159
    learner:
      cur_lr: 0.0009480789885856211
      grad_gnorm: 40.0
      policy_entropy: 32.613162994384766
      policy_loss: 21169.08203125
      var_gnorm: 177.4945068359375
      vf_explained_var: 0.0
      vf_loss: 12382514.0
    num_steps_sampled: 6190000
    num_steps_trained: 6190000
    wait_time_ms: 44.697
  iterations_since_restore: 1238
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10774.751725435257
  time_this_iter_s: 9.12810230255127
  time_total_s: 10774.751725435257
  timestamp: 1594866817
  timesteps_since_restore: 6190000
  timesteps_this_iter: 5000
  timesteps_total: 6190000
  training_iteration: 1238
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10774 s, 1238 iter, 6190000 ts, -9.87e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-33-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -14663.705646391547
  episode_reward_mean: -98731.31837041705
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 0
  episodes_total: 1238
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.677
    dispatch_time_ms: 25.24
    learner:
      cur_lr: 0.0009477459825575352
      grad_gnorm: 40.0
      policy_entropy: 30.895124435424805
      policy_loss: -4754.2060546875
      var_gnorm: 177.95892333984375
      vf_explained_var: 0.0
      vf_loss: 1872070.125
    num_steps_sampled: 6195000
    num_steps_trained: 6195000
    wait_time_ms: 64.004
  iterations_since_restore: 1239
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10783.736538648605
  time_this_iter_s: 8.984813213348389
  time_total_s: 10783.736538648605
  timestamp: 1594866826
  timesteps_since_restore: 6195000
  timesteps_this_iter: 5000
  timesteps_total: 6195000
  training_iteration: 1239
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10783 s, 1239 iter, 6195000 ts, -9.87e+04 rew

agent-1: -40221.436980942504
agent-2: -41915.14317083256
agent-3: -13353.62680184978
agent-4: -37934.84798471738
agent-5: -25301.341311062435
Extrinsic Rewards:
-40039
-41736
-13281
-37757
-25173
Sum Reward: -157986
Avg Reward: -31597.2
Min Reward: -41736
Max Reward: -13281
Gini Coefficient: -0.18172749484131506
20:20 Ratio: 0.31821449108683153
Max-min Ratio: 0.31821449108683153
agent-1: -32843.302130253556
agent-2: -12334.785050732686
agent-3: -29493.01689696351
agent-4: -21032.10285731896
agent-5: -17745.6659154034
Extrinsic Rewards:
-32647
-12249
-29303
-20891
-17625
Sum Reward: -112715
Avg Reward: -22543.0
Min Reward: -32647
Max Reward: -12249
Gini Coefficient: -0.18621833828682963
20:20 Ratio: 0.3751952706221092
Max-min Ratio: 0.3751952706221092
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-33-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -25989.091177214406
  episode_reward_mean: -101100.3614112291
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 2
  episodes_total: 1240
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.664
    dispatch_time_ms: 24.385
    learner:
      cur_lr: 0.0009474129765294492
      grad_gnorm: 40.0
      policy_entropy: 38.1274299621582
      policy_loss: -7228.1865234375
      var_gnorm: 178.43841552734375
      vf_explained_var: -0.0780860185623169
      vf_loss: 1569194.875
    num_steps_sampled: 6200000
    num_steps_trained: 6200000
    wait_time_ms: 61.534
  iterations_since_restore: 1240
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10792.766803741455
  time_this_iter_s: 9.030265092849731
  time_total_s: 10792.766803741455
  timestamp: 1594866835
  timesteps_since_restore: 6200000
  timesteps_this_iter: 5000
  timesteps_total: 6200000
  training_iteration: 1240
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10792 s, 1240 iter, 6200000 ts, -1.01e+05 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-34-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -25989.091177214406
  episode_reward_mean: -101100.36141122907
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 0
  episodes_total: 1240
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.699
    dispatch_time_ms: 30.833
    learner:
      cur_lr: 0.0009470800287090242
      grad_gnorm: 39.999996185302734
      policy_entropy: 40.62023162841797
      policy_loss: -2666.26220703125
      var_gnorm: 178.7992706298828
      vf_explained_var: 0.0
      vf_loss: 422754.09375
    num_steps_sampled: 6205000
    num_steps_trained: 6205000
    wait_time_ms: 55.37
  iterations_since_restore: 1241
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10801.51074051857
  time_this_iter_s: 8.743936777114868
  time_total_s: 10801.51074051857
  timestamp: 1594866844
  timesteps_since_restore: 6205000
  timesteps_this_iter: 5000
  timesteps_total: 6205000
  training_iteration: 1241
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10801 s, 1241 iter, 6205000 ts, -1.01e+05 rew

agent-1: -12098.811437932261
agent-2: -15926.639268459783
agent-3: -19745.15064884542
agent-4: -4612.673927976493
agent-5: -18054.971214635305
Extrinsic Rewards:
-11962
-15765
-19557
-4551
-17874
Sum Reward: -69709
Avg Reward: -13941.8
Min Reward: -19557
Max Reward: -4551
Gini Coefficient: -0.20613694071066863
20:20 Ratio: 0.23270440251572327
Max-min Ratio: 0.23270440251572327
agent-1: -12299.226193205863
agent-2: -16949.160024033794
agent-3: -19869.462193654464
agent-4: -14492.125610319956
agent-5: -15608.806002363795
Extrinsic Rewards:
-12175
-16787
-19686
-14356
-15470
Sum Reward: -78474
Avg Reward: -15694.8
Min Reward: -19686
Max Reward: -12175
Gini Coefficient: -0.08896194918062034
20:20 Ratio: 0.6184598191608249
Max-min Ratio: 0.6184598191608249
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-34-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -25989.091177214406
  episode_reward_mean: -102050.29577795404
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 2
  episodes_total: 1242
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 4.457
    dispatch_time_ms: 34.66
    learner:
      cur_lr: 0.0009467470226809382
      grad_gnorm: 40.0
      policy_entropy: 43.046146392822266
      policy_loss: 30975.158203125
      var_gnorm: 179.08349609375
      vf_explained_var: 0.0
      vf_loss: 14712517.0
    num_steps_sampled: 6210000
    num_steps_trained: 6210000
    wait_time_ms: 34.982
  iterations_since_restore: 1242
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10810.470833778381
  time_this_iter_s: 8.960093259811401
  time_total_s: 10810.470833778381
  timestamp: 1594866853
  timesteps_since_restore: 6210000
  timesteps_this_iter: 5000
  timesteps_total: 6210000
  training_iteration: 1242
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10810 s, 1242 iter, 6210000 ts, -1.02e+05 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-34-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -25989.091177214406
  episode_reward_mean: -102050.29577795404
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 0
  episodes_total: 1242
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.533
    dispatch_time_ms: 17.676
    learner:
      cur_lr: 0.0009464140166528523
      grad_gnorm: 39.999996185302734
      policy_entropy: 40.80759048461914
      policy_loss: -48.99517822265625
      var_gnorm: 179.22357177734375
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 26523.42578125
    num_steps_sampled: 6215000
    num_steps_trained: 6215000
    wait_time_ms: 62.071
  iterations_since_restore: 1243
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10818.98968076706
  time_this_iter_s: 8.518846988677979
  time_total_s: 10818.98968076706
  timestamp: 1594866862
  timesteps_since_restore: 6215000
  timesteps_this_iter: 5000
  timesteps_total: 6215000
  training_iteration: 1243
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10818 s, 1243 iter, 6215000 ts, -1.02e+05 rew

agent-1: -10204.855701262237
agent-2: -9977.715738801959
agent-3: -11912.3602111845
agent-4: -13876.895952576526
agent-5: -11358.832108044176
Extrinsic Rewards:
-10066
-9845
-11751
-13699
-11208
Sum Reward: -56569
Avg Reward: -11313.8
Min Reward: -13699
Max Reward: -9845
Gini Coefficient: -0.0664180027930492
20:20 Ratio: 0.7186655960289072
Max-min Ratio: 0.7186655960289072
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-34-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -25989.091177214406
  episode_reward_mean: -102262.58070196446
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 1
  episodes_total: 1243
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.823
    dispatch_time_ms: 39.389
    learner:
      cur_lr: 0.0009460810106247663
      grad_gnorm: 40.000003814697266
      policy_entropy: 37.2802848815918
      policy_loss: -625.70751953125
      var_gnorm: 179.2734375
      vf_explained_var: 0.0
      vf_loss: 62064.859375
    num_steps_sampled: 6220000
    num_steps_trained: 6220000
    wait_time_ms: 47.733
  iterations_since_restore: 1244
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10827.610410451889
  time_this_iter_s: 8.620729684829712
  time_total_s: 10827.610410451889
  timestamp: 1594866870
  timesteps_since_restore: 6220000
  timesteps_this_iter: 5000
  timesteps_total: 6220000
  training_iteration: 1244
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10827 s, 1244 iter, 6220000 ts, -1.02e+05 rew

agent-1: -11193.252141096358
agent-2: -9431.41341587313
agent-3: -6476.332724519841
agent-4: -12808.36405115872
agent-5: -5305.738741382996
Extrinsic Rewards:
-11020
-9271
-6364
-12608
-5212
Sum Reward: -44475
Avg Reward: -8895.0
Min Reward: -12608
Max Reward: -5212
Gini Coefficient: -0.17491174817313096
20:20 Ratio: 0.41338832487309646
Max-min Ratio: 0.41338832487309646
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-34-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -25989.091177214406
  episode_reward_mean: -102342.72663410695
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 1
  episodes_total: 1244
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.941
    dispatch_time_ms: 6.804
    learner:
      cur_lr: 0.0009457480045966804
      grad_gnorm: 40.0
      policy_entropy: 40.21756362915039
      policy_loss: -1800.5870361328125
      var_gnorm: 179.27328491210938
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 254412.859375
    num_steps_sampled: 6225000
    num_steps_trained: 6225000
    wait_time_ms: 71.94
  iterations_since_restore: 1245
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10836.124683618546
  time_this_iter_s: 8.514273166656494
  time_total_s: 10836.124683618546
  timestamp: 1594866879
  timesteps_since_restore: 6225000
  timesteps_this_iter: 5000
  timesteps_total: 6225000
  training_iteration: 1245
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10836 s, 1245 iter, 6225000 ts, -1.02e+05 rew

agent-1: -19810.645147814303
agent-2: -22170.745060376197
agent-3: -15896.40048062101
agent-4: -18548.89488676581
agent-5: -5409.899723140443
Extrinsic Rewards:
-19635
-21977
-15746
-18403
-5336
Sum Reward: -81097
Avg Reward: -16219.4
Min Reward: -21977
Max Reward: -5336
Gini Coefficient: -0.18334093739595791
20:20 Ratio: 0.24279929016699275
Max-min Ratio: 0.24279929016699275
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-34-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -27555.71424367956
  episode_reward_mean: -102901.20157532199
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 1
  episodes_total: 1245
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.721
    dispatch_time_ms: 7.352
    learner:
      cur_lr: 0.0009454149985685945
      grad_gnorm: 40.0
      policy_entropy: 39.00591278076172
      policy_loss: -2071.0703125
      var_gnorm: 179.72569274902344
      vf_explained_var: 0.0
      vf_loss: 278052.78125
    num_steps_sampled: 6230000
    num_steps_trained: 6230000
    wait_time_ms: 74.719
  iterations_since_restore: 1246
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10844.460397481918
  time_this_iter_s: 8.335713863372803
  time_total_s: 10844.460397481918
  timestamp: 1594866887
  timesteps_since_restore: 6230000
  timesteps_this_iter: 5000
  timesteps_total: 6230000
  training_iteration: 1246
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10844 s, 1246 iter, 6230000 ts, -1.03e+05 rew

agent-1: -15128.320776700657
agent-2: -11477.274963724796
agent-3: -13493.401991479359
agent-4: -14027.85716564314
agent-5: -15045.161116935615
Extrinsic Rewards:
-14961
-11336
-13341
-13883
-14903
Sum Reward: -68424
Avg Reward: -13684.8
Min Reward: -14961
Max Reward: -11336
Gini Coefficient: -0.05151408862387467
20:20 Ratio: 0.7577033620747277
Max-min Ratio: 0.7577033620747277
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-34-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -27555.71424367956
  episode_reward_mean: -103315.32428854523
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 1
  episodes_total: 1246
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.985
    dispatch_time_ms: 9.65
    learner:
      cur_lr: 0.0009450819925405085
      grad_gnorm: 40.0
      policy_entropy: 42.97063064575195
      policy_loss: -3141.859375
      var_gnorm: 180.0261993408203
      vf_explained_var: 0.0
      vf_loss: 366698.625
    num_steps_sampled: 6235000
    num_steps_trained: 6235000
    wait_time_ms: 70.681
  iterations_since_restore: 1247
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10852.706128120422
  time_this_iter_s: 8.245730638504028
  time_total_s: 10852.706128120422
  timestamp: 1594866896
  timesteps_since_restore: 6235000
  timesteps_this_iter: 5000
  timesteps_total: 6235000
  training_iteration: 1247
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10852 s, 1247 iter, 6235000 ts, -1.03e+05 rew

agent-1: -14716.342953211933
agent-2: -7685.789170445703
agent-3: -23171.632928429288
agent-4: -18815.954678037808
agent-5: -18823.405347849006
Extrinsic Rewards:
-14585
-7631
-22978
-18642
-18647
Sum Reward: -82483
Avg Reward: -16496.6
Min Reward: -22978
Max Reward: -7631
Gini Coefficient: -0.16854867063516119
20:20 Ratio: 0.33210026982330926
Max-min Ratio: 0.33210026982330926
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-35-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -29792.059674557902
  episode_reward_mean: -103871.8983968882
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 1
  episodes_total: 1247
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.812
    dispatch_time_ms: 8.098
    learner:
      cur_lr: 0.0009447489865124226
      grad_gnorm: 40.000003814697266
      policy_entropy: 40.42724609375
      policy_loss: -1189.0780029296875
      var_gnorm: 180.47740173339844
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 139680.015625
    num_steps_sampled: 6240000
    num_steps_trained: 6240000
    wait_time_ms: 76.446
  iterations_since_restore: 1248
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10861.048506975174
  time_this_iter_s: 8.342378854751587
  time_total_s: 10861.048506975174
  timestamp: 1594866904
  timesteps_since_restore: 6240000
  timesteps_this_iter: 5000
  timesteps_total: 6240000
  training_iteration: 1248
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10861 s, 1248 iter, 6240000 ts, -1.04e+05 rew

agent-1: -22398.556003584185
agent-2: -23612.483201423172
agent-3: -15561.77910567778
agent-4: -17959.823518569912
agent-5: -10809.284053647558
Extrinsic Rewards:
-22213
-23432
-15421
-17811
-10735
Sum Reward: -89612
Avg Reward: -17922.4
Min Reward: -23432
Max Reward: -10735
Gini Coefficient: -0.14366825871535063
20:20 Ratio: 0.4581341754865142
Max-min Ratio: 0.4581341754865142
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-35-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -29792.059674557902
  episode_reward_mean: -104379.8513784431
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 1
  episodes_total: 1248
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.751
    dispatch_time_ms: 8.369
    learner:
      cur_lr: 0.0009444159804843366
      grad_gnorm: 40.0
      policy_entropy: 44.52001953125
      policy_loss: -382.0852355957031
      var_gnorm: 180.72950744628906
      vf_explained_var: 0.0
      vf_loss: 46328.39453125
    num_steps_sampled: 6245000
    num_steps_trained: 6245000
    wait_time_ms: 77.17
  iterations_since_restore: 1249
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10869.410970211029
  time_this_iter_s: 8.362463235855103
  time_total_s: 10869.410970211029
  timestamp: 1594866912
  timesteps_since_restore: 6245000
  timesteps_this_iter: 5000
  timesteps_total: 6245000
  training_iteration: 1249
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10869 s, 1249 iter, 6245000 ts, -1.04e+05 rew

agent-1: -17328.392424436646
agent-2: -12658.999588648861
agent-3: -17607.16747649845
agent-4: -17311.378104101976
agent-5: -18642.67951743904
Extrinsic Rewards:
-17166
-12540
-17451
-17159
-18476
Sum Reward: -82792
Avg Reward: -16558.4
Min Reward: -18476
Max Reward: -12540
Gini Coefficient: -0.058768963184848776
20:20 Ratio: 0.6787183373024465
Max-min Ratio: 0.6787183373024465
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-35-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -29792.059674557902
  episode_reward_mean: -104408.23659604005
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 1
  episodes_total: 1249
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.145
    dispatch_time_ms: 8.15
    learner:
      cur_lr: 0.0009440829744562507
      grad_gnorm: 40.0
      policy_entropy: 46.42104721069336
      policy_loss: -1347.325439453125
      var_gnorm: 181.16665649414062
      vf_explained_var: 0.0
      vf_loss: 197977.296875
    num_steps_sampled: 6250000
    num_steps_trained: 6250000
    wait_time_ms: 70.605
  iterations_since_restore: 1250
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10877.75760269165
  time_this_iter_s: 8.346632480621338
  time_total_s: 10877.75760269165
  timestamp: 1594866921
  timesteps_since_restore: 6250000
  timesteps_this_iter: 5000
  timesteps_total: 6250000
  training_iteration: 1250
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10877 s, 1250 iter, 6250000 ts, -1.04e+05 rew

agent-1: -19399.225479880122
agent-2: -15306.088716702396
agent-3: -16158.320334147673
agent-4: -15771.160235023588
agent-5: -16511.517987166262
Extrinsic Rewards:
-19224
-15168
-16011
-15633
-16360
Sum Reward: -82396
Avg Reward: -16479.2
Min Reward: -19224
Max Reward: -15168
Gini Coefficient: -0.042909849992718095
20:20 Ratio: 0.7890137328339576
Max-min Ratio: 0.7890137328339576
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-35-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -29792.059674557902
  episode_reward_mean: -104570.79763599313
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 1
  episodes_total: 1250
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.221
    dispatch_time_ms: 7.379
    learner:
      cur_lr: 0.0009437500266358256
      grad_gnorm: 40.0
      policy_entropy: 43.904258728027344
      policy_loss: -5483.1103515625
      var_gnorm: 181.54290771484375
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 681660.3125
    num_steps_sampled: 6255000
    num_steps_trained: 6255000
    wait_time_ms: 73.036
  iterations_since_restore: 1251
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10886.126954078674
  time_this_iter_s: 8.369351387023926
  time_total_s: 10886.126954078674
  timestamp: 1594866929
  timesteps_since_restore: 6255000
  timesteps_this_iter: 5000
  timesteps_total: 6255000
  training_iteration: 1251
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10886 s, 1251 iter, 6255000 ts, -1.05e+05 rew

agent-1: -23782.46779844117
agent-2: -24055.50336611499
agent-3: -18646.43118434589
agent-4: -15119.00043930138
agent-5: -9868.893703469843
Extrinsic Rewards:
-23602
-23871
-18489
-14982
-9786
Sum Reward: -90730
Avg Reward: -18146.0
Min Reward: -23871
Max Reward: -9786
Gini Coefficient: -0.1621955251846137
20:20 Ratio: 0.40995350006283776
Max-min Ratio: 0.40995350006283776
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-35-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -29792.059674557902
  episode_reward_mean: -104815.49957393648
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 1
  episodes_total: 1251
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.819
    dispatch_time_ms: 7.647
    learner:
      cur_lr: 0.0009434170206077397
      grad_gnorm: 40.00000762939453
      policy_entropy: 43.17009735107422
      policy_loss: -1781.8662109375
      var_gnorm: 181.9789581298828
      vf_explained_var: 0.0
      vf_loss: 270696.3125
    num_steps_sampled: 6260000
    num_steps_trained: 6260000
    wait_time_ms: 69.067
  iterations_since_restore: 1252
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10894.369056224823
  time_this_iter_s: 8.242102146148682
  time_total_s: 10894.369056224823
  timestamp: 1594866937
  timesteps_since_restore: 6260000
  timesteps_this_iter: 5000
  timesteps_total: 6260000
  training_iteration: 1252
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10894 s, 1252 iter, 6260000 ts, -1.05e+05 rew

agent-1: -24031.463370985806
agent-2: -17010.519186435522
agent-3: -20515.617803027333
agent-4: -20242.50688337359
agent-5: -20231.878687251497
Extrinsic Rewards:
-23856
-16878
-20357
-20099
-20078
Sum Reward: -101268
Avg Reward: -20253.6
Min Reward: -23856
Max Reward: -16878
Gini Coefficient: -0.05622704111861595
20:20 Ratio: 0.7074949698189135
Max-min Ratio: 0.7074949698189135
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-35-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -29792.059674557902
  episode_reward_mean: -105194.63657915159
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 1
  episodes_total: 1252
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.519
    dispatch_time_ms: 7.274
    learner:
      cur_lr: 0.0009430840145796537
      grad_gnorm: 40.0
      policy_entropy: 46.314266204833984
      policy_loss: -2376.9453125
      var_gnorm: 182.38995361328125
      vf_explained_var: 0.0
      vf_loss: 574107.125
    num_steps_sampled: 6265000
    num_steps_trained: 6265000
    wait_time_ms: 73.404
  iterations_since_restore: 1253
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10902.668967485428
  time_this_iter_s: 8.299911260604858
  time_total_s: 10902.668967485428
  timestamp: 1594866946
  timesteps_since_restore: 6265000
  timesteps_this_iter: 5000
  timesteps_total: 6265000
  training_iteration: 1253
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10902 s, 1253 iter, 6265000 ts, -1.05e+05 rew

agent-1: -20136.149505254158
agent-2: -17316.550417932067
agent-3: -19261.45017409144
agent-4: -19076.637510255674
agent-5: -14135.012141787847
Extrinsic Rewards:
-19975
-17164
-19103
-18917
-14011
Sum Reward: -89170
Avg Reward: -17834.0
Min Reward: -19975
Max Reward: -14011
Gini Coefficient: -0.062204777391499384
20:20 Ratio: 0.7014267834793492
Max-min Ratio: 0.7014267834793492
agent-1: -16654.395204770488
agent-2: -16948.975442740295
agent-3: -18304.158791592035
agent-4: -13062.104480284548
agent-5: -13755.705377784298
Extrinsic Rewards:
-16495
-16785
-18129
-12940
-13620
Sum Reward: -77969
Avg Reward: -15593.8
Min Reward: -18129
Max Reward: -12940
Gini Coefficient: -0.06947889545845144
20:20 Ratio: 0.7137735120525126
Max-min Ratio: 0.7137735120525126
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-35-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -29792.059674557902
  episode_reward_mean: -105365.85856518784
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 2
  episodes_total: 1254
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.361
    dispatch_time_ms: 30.041
    learner:
      cur_lr: 0.0009427510085515678
      grad_gnorm: 40.0
      policy_entropy: 50.29877471923828
      policy_loss: -171.61683654785156
      var_gnorm: 182.71669006347656
      vf_explained_var: -0.438470721244812
      vf_loss: 125626.6484375
    num_steps_sampled: 6270000
    num_steps_trained: 6270000
    wait_time_ms: 64.547
  iterations_since_restore: 1254
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10913.849195241928
  time_this_iter_s: 11.180227756500244
  time_total_s: 10913.849195241928
  timestamp: 1594866957
  timesteps_since_restore: 6270000
  timesteps_this_iter: 5000
  timesteps_total: 6270000
  training_iteration: 1254
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10913 s, 1254 iter, 6270000 ts, -1.05e+05 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-36-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -29792.059674557902
  episode_reward_mean: -105365.85856518784
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 0
  episodes_total: 1254
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.197
    dispatch_time_ms: 81.587
    learner:
      cur_lr: 0.0009424180025234818
      grad_gnorm: 40.0
      policy_entropy: 54.18415832519531
      policy_loss: -5622.71826171875
      var_gnorm: 183.1126251220703
      vf_explained_var: 0.0
      vf_loss: 519741.625
    num_steps_sampled: 6275000
    num_steps_trained: 6275000
    wait_time_ms: 42.139
  iterations_since_restore: 1255
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10923.344922065735
  time_this_iter_s: 9.495726823806763
  time_total_s: 10923.344922065735
  timestamp: 1594866967
  timesteps_since_restore: 6275000
  timesteps_this_iter: 5000
  timesteps_total: 6275000
  training_iteration: 1255
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10923 s, 1255 iter, 6275000 ts, -1.05e+05 rew

agent-1: -18809.980232190446
agent-2: -13968.927276428478
agent-3: -17968.01973383551
agent-4: -13432.973588178234
agent-5: -18568.049729766477
Extrinsic Rewards:
-18638
-13838
-17803
-13306
-18400
Sum Reward: -81985
Avg Reward: -16397.0
Min Reward: -18638
Max Reward: -13306
Gini Coefficient: -0.07428675977312924
20:20 Ratio: 0.7139178023393068
Max-min Ratio: 0.7139178023393068
agent-1: -18050.68386380272
agent-2: -17402.91080458814
agent-3: -16112.600729284297
agent-4: -15086.533847391129
agent-5: -15794.051482228188
Extrinsic Rewards:
-17892
-17244
-15964
-14947
-15643
Sum Reward: -81690
Avg Reward: -16338.0
Min Reward: -17892
Max Reward: -14947
Gini Coefficient: -0.036680132207124495
20:20 Ratio: 0.8354012966689023
Max-min Ratio: 0.8354012966689023
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-36-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -29792.059674557902
  episode_reward_mean: -105311.61247863506
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 2
  episodes_total: 1256
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.724
    dispatch_time_ms: 23.815
    learner:
      cur_lr: 0.0009420849964953959
      grad_gnorm: 40.00000762939453
      policy_entropy: 55.84503173828125
      policy_loss: 30539.49609375
      var_gnorm: 183.42047119140625
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 9234409.0
    num_steps_sampled: 6280000
    num_steps_trained: 6280000
    wait_time_ms: 67.889
  iterations_since_restore: 1256
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10932.206409931183
  time_this_iter_s: 8.861487865447998
  time_total_s: 10932.206409931183
  timestamp: 1594866975
  timesteps_since_restore: 6280000
  timesteps_this_iter: 5000
  timesteps_total: 6280000
  training_iteration: 1256
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10932 s, 1256 iter, 6280000 ts, -1.05e+05 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-36-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -29792.059674557902
  episode_reward_mean: -105311.61247863507
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 0
  episodes_total: 1256
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.098
    dispatch_time_ms: 23.247
    learner:
      cur_lr: 0.00094175199046731
      grad_gnorm: 40.0
      policy_entropy: 48.94449234008789
      policy_loss: -1862.94873046875
      var_gnorm: 183.7925567626953
      vf_explained_var: 0.0
      vf_loss: 156491.859375
    num_steps_sampled: 6285000
    num_steps_trained: 6285000
    wait_time_ms: 67.955
  iterations_since_restore: 1257
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10941.085674524307
  time_this_iter_s: 8.87926459312439
  time_total_s: 10941.085674524307
  timestamp: 1594866984
  timesteps_since_restore: 6285000
  timesteps_this_iter: 5000
  timesteps_total: 6285000
  training_iteration: 1257
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10941 s, 1257 iter, 6285000 ts, -1.05e+05 rew

agent-1: -21916.416605153037
agent-2: -16321.577480688164
agent-3: -21702.053468573726
agent-4: -24924.084044714895
agent-5: -16036.383302645574
Extrinsic Rewards:
-21756
-16193
-21548
-24745
-15904
Sum Reward: -100146
Avg Reward: -20029.2
Min Reward: -24745
Max Reward: -15904
Gini Coefficient: -0.09284444710722345
20:20 Ratio: 0.6427157001414427
Max-min Ratio: 0.6427157001414427
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-36-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -29792.059674557902
  episode_reward_mean: -105133.63846488539
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 1
  episodes_total: 1257
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.852
    dispatch_time_ms: 20.445
    learner:
      cur_lr: 0.000941418984439224
      grad_gnorm: 40.0
      policy_entropy: 44.27173614501953
      policy_loss: -9288.962890625
      var_gnorm: 184.27955627441406
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 895124.6875
    num_steps_sampled: 6290000
    num_steps_trained: 6290000
    wait_time_ms: 72.101
  iterations_since_restore: 1258
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10950.115371227264
  time_this_iter_s: 9.029696702957153
  time_total_s: 10950.115371227264
  timestamp: 1594866993
  timesteps_since_restore: 6290000
  timesteps_this_iter: 5000
  timesteps_total: 6290000
  training_iteration: 1258
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10950 s, 1258 iter, 6290000 ts, -1.05e+05 rew

agent-1: -25112.05352923611
agent-2: -27275.448312262437
agent-3: -20293.57572078092
agent-4: -22080.98276630229
agent-5: -23722.5175329606
Extrinsic Rewards:
-24962
-27108
-20158
-21928
-23565
Sum Reward: -117721
Avg Reward: -23544.2
Min Reward: -27108
Max Reward: -20158
Gini Coefficient: -0.05753943646418226
20:20 Ratio: 0.743618120112144
Max-min Ratio: 0.743618120112144
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-36-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -29792.059674557902
  episode_reward_mean: -105047.50978282678
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 1
  episodes_total: 1258
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.15
    dispatch_time_ms: 33.274
    learner:
      cur_lr: 0.0009410859784111381
      grad_gnorm: 40.0
      policy_entropy: 41.81966781616211
      policy_loss: -3144.8720703125
      var_gnorm: 184.71157836914062
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 536197.375
    num_steps_sampled: 6295000
    num_steps_trained: 6295000
    wait_time_ms: 59.001
  iterations_since_restore: 1259
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10959.260357618332
  time_this_iter_s: 9.144986391067505
  time_total_s: 10959.260357618332
  timestamp: 1594867003
  timesteps_since_restore: 6295000
  timesteps_this_iter: 5000
  timesteps_total: 6295000
  training_iteration: 1259
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10959 s, 1259 iter, 6295000 ts, -1.05e+05 rew

agent-1: -19761.492802860255
agent-2: -25826.96868231155
agent-3: -20539.149838353213
agent-4: -19318.26157360822
agent-5: -21082.378354536704
Extrinsic Rewards:
-19622
-25643
-20396
-19177
-20939
Sum Reward: -105777
Avg Reward: -21155.4
Min Reward: -25643
Max Reward: -19177
Gini Coefficient: -0.05388316930901803
20:20 Ratio: 0.7478454159029755
Max-min Ratio: 0.7478454159029755
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-36-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -29792.059674557902
  episode_reward_mean: -104506.06671368622
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 1
  episodes_total: 1259
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.793
    dispatch_time_ms: 34.302
    learner:
      cur_lr: 0.0009407529723830521
      grad_gnorm: 40.0
      policy_entropy: 45.31782150268555
      policy_loss: -11775.0400390625
      var_gnorm: 185.19677734375
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 1704742.5
    num_steps_sampled: 6300000
    num_steps_trained: 6300000
    wait_time_ms: 54.911
  iterations_since_restore: 1260
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10968.371457576752
  time_this_iter_s: 9.1110999584198
  time_total_s: 10968.371457576752
  timestamp: 1594867012
  timesteps_since_restore: 6300000
  timesteps_this_iter: 5000
  timesteps_total: 6300000
  training_iteration: 1260
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10968 s, 1260 iter, 6300000 ts, -1.05e+05 rew

agent-1: -23254.595827590485
agent-2: -27701.98160696634
agent-3: -25011.36114131281
agent-4: -20598.27365352759
agent-5: -26812.64409518066
Extrinsic Rewards:
-23111
-27536
-24856
-20477
-26648
Sum Reward: -122628
Avg Reward: -24525.6
Min Reward: -27536
Max Reward: -20477
Gini Coefficient: -0.05758880516684607
20:20 Ratio: 0.7436446833236491
Max-min Ratio: 0.7436446833236491
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-37-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -29792.059674557902
  episode_reward_mean: -104376.53813120193
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 1
  episodes_total: 1260
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.595
    dispatch_time_ms: 22.27
    learner:
      cur_lr: 0.0009404200245626271
      grad_gnorm: 40.0
      policy_entropy: 41.710235595703125
      policy_loss: -1852.122802734375
      var_gnorm: 185.63250732421875
      vf_explained_var: 0.0
      vf_loss: 224940.34375
    num_steps_sampled: 6305000
    num_steps_trained: 6305000
    wait_time_ms: 64.802
  iterations_since_restore: 1261
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10977.290475606918
  time_this_iter_s: 8.919018030166626
  time_total_s: 10977.290475606918
  timestamp: 1594867021
  timesteps_since_restore: 6305000
  timesteps_this_iter: 5000
  timesteps_total: 6305000
  training_iteration: 1261
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10977 s, 1261 iter, 6305000 ts, -1.04e+05 rew

W0715 22:37:04.160881 22529 client_connection.cc:255] [worker]ProcessMessage with type 8 took 101 ms.
W0715 22:37:04.166929 22529 node_manager.cc:250] Last heartbeat was sent 559 ms ago 
agent-1: -23531.133089512463
agent-2: -22028.680487651498
agent-3: -20051.19730760982
agent-4: -17305.73278052258
agent-5: -20494.21741469502
Extrinsic Rewards:
-23364
-21868
-19906
-17175
-20344
Sum Reward: -102657
Avg Reward: -20531.4
Min Reward: -23364
Max Reward: -17175
Gini Coefficient: -0.055875390864724275
20:20 Ratio: 0.7351052901900359
Max-min Ratio: 0.7351052901900359
agent-1: -18252.526509116702
agent-2: -26440.11775772509
agent-3: -25234.519744097415
agent-4: -24833.451605399165
agent-5: -26664.220567259585
Extrinsic Rewards:
-18132
-26273
-25075
-24682
-26503
Sum Reward: -120665
Avg Reward: -24133.0
Min Reward: -26503
Max Reward: -18132
Gini Coefficient: -0.060773215099656074
20:20 Ratio: 0.684148964268196
Max-min Ratio: 0.684148964268196
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-37-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -29792.059674557902
  episode_reward_mean: -103468.51499721786
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 1
  episodes_total: 1261
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.728
    dispatch_time_ms: 48.367
    learner:
      cur_lr: 0.0009400870185345411
      grad_gnorm: 40.0
      policy_entropy: 53.843536376953125
      policy_loss: -4693.84033203125
      var_gnorm: 186.10975646972656
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 489509.21875
    num_steps_sampled: 6310000
    num_steps_trained: 6310000
    wait_time_ms: 33.924
  iterations_since_restore: 1262
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10987.05337715149
  time_this_iter_s: 9.762901544570923
  time_total_s: 10987.05337715149
  timestamp: 1594867031
  timesteps_since_restore: 6310000
  timesteps_this_iter: 5000
  timesteps_total: 6310000
  training_iteration: 1262
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10987 s, 1262 iter, 6310000 ts, -1.03e+05 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-37-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -29792.059674557902
  episode_reward_mean: -103566.94862676886
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 1
  episodes_total: 1262
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.624
    dispatch_time_ms: 25.379
    learner:
      cur_lr: 0.0009397540125064552
      grad_gnorm: 40.0
      policy_entropy: 55.19756317138672
      policy_loss: -2938.4599609375
      var_gnorm: 186.43927001953125
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 217229.234375
    num_steps_sampled: 6315000
    num_steps_trained: 6315000
    wait_time_ms: 56.441
  iterations_since_restore: 1263
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 10995.869906187057
  time_this_iter_s: 8.816529035568237
  time_total_s: 10995.869906187057
  timestamp: 1594867039
  timesteps_since_restore: 6315000
  timesteps_this_iter: 5000
  timesteps_total: 6315000
  training_iteration: 1263
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 10995 s, 1263 iter, 6315000 ts, -1.04e+05 rew

agent-1: -16723.225245265
agent-2: -17920.239671256564
agent-3: -14080.098792769948
agent-4: -18140.56851047075
agent-5: -19162.73775155382
Extrinsic Rewards:
-16575
-17754
-13954
-17990
-18999
Sum Reward: -85272
Avg Reward: -17054.4
Min Reward: -18999
Max Reward: -13954
Gini Coefficient: -0.05396847734309035
20:20 Ratio: 0.7344597084057055
Max-min Ratio: 0.7344597084057055
agent-1: -13621.075437039346
agent-2: -15514.130810845378
agent-3: -20368.312974039927
agent-4: -20601.056354151504
agent-5: -14324.520946141323
Extrinsic Rewards:
-13497
-15369
-20189
-20422
-14191
Sum Reward: -83668
Avg Reward: -16733.6
Min Reward: -20422
Max Reward: -13497
Gini Coefficient: -0.09488932447291677
20:20 Ratio: 0.660904906473411
Max-min Ratio: 0.660904906473411
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-37-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -29792.059674557902
  episode_reward_mean: -103141.49993378748
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 2
  episodes_total: 1264
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.619
    dispatch_time_ms: 5.946
    learner:
      cur_lr: 0.0009394210064783692
      grad_gnorm: 40.000003814697266
      policy_entropy: 50.45967483520508
      policy_loss: 41130.80859375
      var_gnorm: 186.88844299316406
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 16801608.0
    num_steps_sampled: 6320000
    num_steps_trained: 6320000
    wait_time_ms: 77.317
  iterations_since_restore: 1264
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11004.547829389572
  time_this_iter_s: 8.677923202514648
  time_total_s: 11004.547829389572
  timestamp: 1594867048
  timesteps_since_restore: 6320000
  timesteps_this_iter: 5000
  timesteps_total: 6320000
  training_iteration: 1264
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11004 s, 1264 iter, 6320000 ts, -1.03e+05 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-37-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -29792.059674557902
  episode_reward_mean: -103141.49993378748
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 0
  episodes_total: 1264
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.007
    dispatch_time_ms: 7.245
    learner:
      cur_lr: 0.0009390880004502833
      grad_gnorm: 39.999996185302734
      policy_entropy: 52.56962585449219
      policy_loss: -4141.35693359375
      var_gnorm: 187.30450439453125
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 262137.4375
    num_steps_sampled: 6325000
    num_steps_trained: 6325000
    wait_time_ms: 75.276
  iterations_since_restore: 1265
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11012.853373289108
  time_this_iter_s: 8.305543899536133
  time_total_s: 11012.853373289108
  timestamp: 1594867056
  timesteps_since_restore: 6325000
  timesteps_this_iter: 5000
  timesteps_total: 6325000
  training_iteration: 1265
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11012 s, 1265 iter, 6325000 ts, -1.03e+05 rew

agent-1: -15727.038414438062
agent-2: -11056.567639492476
agent-3: -17372.598589865014
agent-4: -19657.049397109047
agent-5: -24321.437464084895
Extrinsic Rewards:
-15589
-10964
-17215
-19481
-24139
Sum Reward: -87388
Avg Reward: -17477.6
Min Reward: -24139
Max Reward: -10964
Gini Coefficient: -0.1384263285576967
20:20 Ratio: 0.4542027424499772
Max-min Ratio: 0.4542027424499772
agent-1: -17445.824077994777
agent-2: -19280.253412515118
agent-3: -16680.179290765776
agent-4: -17110.030786071482
agent-5: -24139.457144196167
Extrinsic Rewards:
-17307
-19124
-16547
-16969
-23956
Sum Reward: -93903
Avg Reward: -18780.6
Min Reward: -23956
Max Reward: -16547
Gini Coefficient: -0.0723001395056601
20:20 Ratio: 0.6907246618801135
Max-min Ratio: 0.6907246618801135
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-37-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -29792.059674557902
  episode_reward_mean: -103248.62339901958
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 2
  episodes_total: 1266
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.941
    dispatch_time_ms: 23.279
    learner:
      cur_lr: 0.0009387549944221973
      grad_gnorm: 40.0
      policy_entropy: 48.46270751953125
      policy_loss: -2505.05615234375
      var_gnorm: 187.7021484375
      vf_explained_var: -0.41477787494659424
      vf_loss: 234076.296875
    num_steps_sampled: 6330000
    num_steps_trained: 6330000
    wait_time_ms: 59.906
  iterations_since_restore: 1266
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11021.586002349854
  time_this_iter_s: 8.73262906074524
  time_total_s: 11021.586002349854
  timestamp: 1594867065
  timesteps_since_restore: 6330000
  timesteps_this_iter: 5000
  timesteps_total: 6330000
  training_iteration: 1266
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11021 s, 1266 iter, 6330000 ts, -1.03e+05 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-37-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -29792.059674557902
  episode_reward_mean: -103248.62339901953
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 0
  episodes_total: 1266
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.411
    dispatch_time_ms: 27.807
    learner:
      cur_lr: 0.0009384219883941114
      grad_gnorm: 40.0
      policy_entropy: 47.84149169921875
      policy_loss: -8525.6455078125
      var_gnorm: 188.067138671875
      vf_explained_var: 0.0
      vf_loss: 1626957.625
    num_steps_sampled: 6335000
    num_steps_trained: 6335000
    wait_time_ms: 55.003
  iterations_since_restore: 1267
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11030.68369102478
  time_this_iter_s: 9.097688674926758
  time_total_s: 11030.68369102478
  timestamp: 1594867074
  timesteps_since_restore: 6335000
  timesteps_this_iter: 5000
  timesteps_total: 6335000
  training_iteration: 1267
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11030 s, 1267 iter, 6335000 ts, -1.03e+05 rew

agent-1: -22011.838960003337
agent-2: -17257.64437182549
agent-3: -22573.45203093852
agent-4: -17207.503119543802
agent-5: -20037.86473955538
Extrinsic Rewards:
-21840
-17130
-22415
-17071
-19883
Sum Reward: -98339
Avg Reward: -19667.8
Min Reward: -22415
Max Reward: -17071
Gini Coefficient: -0.06263232288308809
20:20 Ratio: 0.7615882221726522
Max-min Ratio: 0.7615882221726522
agent-1: -22479.704849007998
agent-2: -23776.913199407063
agent-3: -29183.19005182197
agent-4: -24964.799168181533
agent-5: -30713.910733202953
Extrinsic Rewards:
-22338
-23632
-29010
-24828
-30548
Sum Reward: -130356
Avg Reward: -26071.2
Min Reward: -30548
Max Reward: -22338
Gini Coefficient: -0.06688760011046672
20:20 Ratio: 0.7312426345423596
Max-min Ratio: 0.7312426345423596
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-38-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -29792.059674557902
  episode_reward_mean: -103539.26526017804
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 2
  episodes_total: 1268
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.847
    dispatch_time_ms: 29.684
    learner:
      cur_lr: 0.0009380889823660254
      grad_gnorm: 40.000003814697266
      policy_entropy: 48.30506134033203
      policy_loss: 343.73748779296875
      var_gnorm: 188.55859375
      vf_explained_var: -0.6933821439743042
      vf_loss: 55850.4453125
    num_steps_sampled: 6340000
    num_steps_trained: 6340000
    wait_time_ms: 57.329
  iterations_since_restore: 1268
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11039.680568933487
  time_this_iter_s: 8.996877908706665
  time_total_s: 11039.680568933487
  timestamp: 1594867083
  timesteps_since_restore: 6340000
  timesteps_this_iter: 5000
  timesteps_total: 6340000
  training_iteration: 1268
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11039 s, 1268 iter, 6340000 ts, -1.04e+05 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-38-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -29792.059674557902
  episode_reward_mean: -103539.26526017806
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 0
  episodes_total: 1268
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.132
    dispatch_time_ms: 29.665
    learner:
      cur_lr: 0.0009377559763379395
      grad_gnorm: 40.0
      policy_entropy: 46.9108772277832
      policy_loss: -4063.052001953125
      var_gnorm: 188.98968505859375
      vf_explained_var: 0.0
      vf_loss: 360107.15625
    num_steps_sampled: 6345000
    num_steps_trained: 6345000
    wait_time_ms: 34.426
  iterations_since_restore: 1269
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11048.542845010757
  time_this_iter_s: 8.862276077270508
  time_total_s: 11048.542845010757
  timestamp: 1594867092
  timesteps_since_restore: 6345000
  timesteps_this_iter: 5000
  timesteps_total: 6345000
  training_iteration: 1269
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11048 s, 1269 iter, 6345000 ts, -1.04e+05 rew

agent-1: -18133.246541905188
agent-2: -26802.33040151546
agent-3: -22005.938839116647
agent-4: -15147.43238681125
agent-5: -25945.604185373235
Extrinsic Rewards:
-18009
-26622
-21852
-15033
-25766
Sum Reward: -107282
Avg Reward: -21456.4
Min Reward: -26622
Max Reward: -15033
Gini Coefficient: -0.1153408773139949
20:20 Ratio: 0.5646833446022087
Max-min Ratio: 0.5646833446022087
agent-1: -27518.658761648636
agent-2: -26219.97231918573
agent-3: -20362.833102504814
agent-4: -28793.220569007914
agent-5: -25674.54614769915
Extrinsic Rewards:
-27356
-26069
-20238
-28629
-25520
Sum Reward: -127812
Avg Reward: -25562.4
Min Reward: -28629
Max Reward: -20238
Gini Coefficient: -0.058266829405689606
20:20 Ratio: 0.7069055852457299
Max-min Ratio: 0.7069055852457299
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-38-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -29792.059674557902
  episode_reward_mean: -103119.85664306539
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 2
  episodes_total: 1270
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.845
    dispatch_time_ms: 37.256
    learner:
      cur_lr: 0.0009374230285175145
      grad_gnorm: 40.000003814697266
      policy_entropy: 38.94169998168945
      policy_loss: 23629.857421875
      var_gnorm: 189.49058532714844
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 12141184.0
    num_steps_sampled: 6350000
    num_steps_trained: 6350000
    wait_time_ms: 47.693
  iterations_since_restore: 1270
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11057.544622659683
  time_this_iter_s: 9.001777648925781
  time_total_s: 11057.544622659683
  timestamp: 1594867101
  timesteps_since_restore: 6350000
  timesteps_this_iter: 5000
  timesteps_total: 6350000
  training_iteration: 1270
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11057 s, 1270 iter, 6350000 ts, -1.03e+05 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-38-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -29792.059674557902
  episode_reward_mean: -103119.8566430654
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 0
  episodes_total: 1270
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.466
    dispatch_time_ms: 38.784
    learner:
      cur_lr: 0.0009370900224894285
      grad_gnorm: 39.99999237060547
      policy_entropy: 32.898216247558594
      policy_loss: -60.45396423339844
      var_gnorm: 189.89501953125
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 155508.71875
    num_steps_sampled: 6355000
    num_steps_trained: 6355000
    wait_time_ms: 48.678
  iterations_since_restore: 1271
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11066.559802293777
  time_this_iter_s: 9.015179634094238
  time_total_s: 11066.559802293777
  timestamp: 1594867110
  timesteps_since_restore: 6355000
  timesteps_this_iter: 5000
  timesteps_total: 6355000
  training_iteration: 1271
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11066 s, 1271 iter, 6355000 ts, -1.03e+05 rew

agent-1: -45454.247056080065
agent-2: -36360.04076952933
agent-3: -24790.127462621596
agent-4: -25832.619326596385
agent-5: -38015.64910224189
Extrinsic Rewards:
-45269
-36207
-24667
-25715
-37851
Sum Reward: -169709
Avg Reward: -33941.8
Min Reward: -45269
Max Reward: -24667
Gini Coefficient: -0.1257210872729201
20:20 Ratio: 0.5448982747575604
Max-min Ratio: 0.5448982747575604
agent-1: -23990.247971856705
agent-2: -24531.088644152034
agent-3: -28827.885107684775
agent-4: -18848.740106330763
agent-5: -7527.864385675181
Extrinsic Rewards:
-23818
-24358
-28632
-18714
-7472
Sum Reward: -102994
Avg Reward: -20598.8
Min Reward: -28632
Max Reward: -7472
Gini Coefficient: -0.18627881235800145
20:20 Ratio: 0.2609667504889634
Max-min Ratio: 0.2609667504889634
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-38-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -29792.059674557902
  episode_reward_mean: -103812.11928925019
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 2
  episodes_total: 1272
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.149
    dispatch_time_ms: 33.042
    learner:
      cur_lr: 0.0009367570164613426
      grad_gnorm: 40.0
      policy_entropy: 29.042024612426758
      policy_loss: 385.2816467285156
      var_gnorm: 190.35142517089844
      vf_explained_var: -0.36962437629699707
      vf_loss: 35890.64453125
    num_steps_sampled: 6360000
    num_steps_trained: 6360000
    wait_time_ms: 59.847
  iterations_since_restore: 1272
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11075.56862783432
  time_this_iter_s: 9.008825540542603
  time_total_s: 11075.56862783432
  timestamp: 1594867119
  timesteps_since_restore: 6360000
  timesteps_this_iter: 5000
  timesteps_total: 6360000
  training_iteration: 1272
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11075 s, 1272 iter, 6360000 ts, -1.04e+05 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-38-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -29792.059674557902
  episode_reward_mean: -103812.11928925019
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 0
  episodes_total: 1272
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.786
    dispatch_time_ms: 27.753
    learner:
      cur_lr: 0.0009364240104332566
      grad_gnorm: 40.0
      policy_entropy: 39.86118698120117
      policy_loss: -326.40679931640625
      var_gnorm: 190.7283477783203
      vf_explained_var: 0.0
      vf_loss: 160281.140625
    num_steps_sampled: 6365000
    num_steps_trained: 6365000
    wait_time_ms: 64.513
  iterations_since_restore: 1273
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11084.55011844635
  time_this_iter_s: 8.98149061203003
  time_total_s: 11084.55011844635
  timestamp: 1594867128
  timesteps_since_restore: 6365000
  timesteps_this_iter: 5000
  timesteps_total: 6365000
  training_iteration: 1273
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11084 s, 1273 iter, 6365000 ts, -1.04e+05 rew

agent-1: -15743.639686006138
agent-2: -22765.98874243496
agent-3: -10478.39998408746
agent-4: -33068.54848182339
agent-5: -27117.17190112107
Extrinsic Rewards:
-15632
-22608
-10408
-32865
-26931
Sum Reward: -108444
Avg Reward: -21688.8
Min Reward: -32865
Max Reward: -10408
Gini Coefficient: -0.20734388255689573
20:20 Ratio: 0.316689487296516
Max-min Ratio: 0.316689487296516
agent-1: -21264.955937227718
agent-2: -17554.114134226205
agent-3: -22347.977402001346
agent-4: -19797.390740098614
agent-5: -18688.97202870312
Extrinsic Rewards:
-21114
-17427
-22191
-19652
-18536
Sum Reward: -98920
Avg Reward: -19784.0
Min Reward: -22191
Max Reward: -17427
Gini Coefficient: -0.048952689041649816
20:20 Ratio: 0.7853183723130999
Max-min Ratio: 0.7853183723130999
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-38-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -29792.059674557902
  episode_reward_mean: -103389.79736036234
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 2
  episodes_total: 1274
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.566
    dispatch_time_ms: 6.077
    learner:
      cur_lr: 0.0009360910044051707
      grad_gnorm: 40.0
      policy_entropy: 40.18885803222656
      policy_loss: 35869.21484375
      var_gnorm: 191.1380157470703
      vf_explained_var: 0.0
      vf_loss: 13681829.0
    num_steps_sampled: 6370000
    num_steps_trained: 6370000
    wait_time_ms: 76.762
  iterations_since_restore: 1274
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11092.985766887665
  time_this_iter_s: 8.435648441314697
  time_total_s: 11092.985766887665
  timestamp: 1594867137
  timesteps_since_restore: 6370000
  timesteps_this_iter: 5000
  timesteps_total: 6370000
  training_iteration: 1274
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11092 s, 1274 iter, 6370000 ts, -1.03e+05 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-39-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -29792.059674557902
  episode_reward_mean: -103389.79736036234
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 0
  episodes_total: 1274
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.717
    dispatch_time_ms: 7.356
    learner:
      cur_lr: 0.0009357579983770847
      grad_gnorm: 40.000003814697266
      policy_entropy: 35.5302619934082
      policy_loss: -5389.53515625
      var_gnorm: 191.61953735351562
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1138088.875
    num_steps_sampled: 6375000
    num_steps_trained: 6375000
    wait_time_ms: 75.07
  iterations_since_restore: 1275
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11101.525080442429
  time_this_iter_s: 8.539313554763794
  time_total_s: 11101.525080442429
  timestamp: 1594867145
  timesteps_since_restore: 6375000
  timesteps_this_iter: 5000
  timesteps_total: 6375000
  training_iteration: 1275
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11101 s, 1275 iter, 6375000 ts, -1.03e+05 rew

agent-1: -31177.662302905548
agent-2: -22856.94326845091
agent-3: -32552.88049464564
agent-4: -31144.653948053572
agent-5: -27751.931415379622
Extrinsic Rewards:
-31023
-22738
-32389
-30980
-27609
Sum Reward: -144739
Avg Reward: -28947.8
Min Reward: -32389
Max Reward: -22738
Gini Coefficient: -0.06277782767602375
20:20 Ratio: 0.7020284664546605
Max-min Ratio: 0.7020284664546605
agent-1: -25594.26533184575
agent-2: -37336.57877463158
agent-3: -39627.11904995696
agent-4: -30679.471742285703
agent-5: -14378.178969016055
Extrinsic Rewards:
-25456
-37160
-39442
-30521
-14296
Sum Reward: -146875
Avg Reward: -29375.0
Min Reward: -39442
Max Reward: -14296
Gini Coefficient: -0.16884017021276596
20:20 Ratio: 0.36245626489528926
Max-min Ratio: 0.36245626489528926
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-39-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -29792.059674557902
  episode_reward_mean: -103785.55889451962
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 2
  episodes_total: 1276
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.88
    dispatch_time_ms: 7.877
    learner:
      cur_lr: 0.0009354249923489988
      grad_gnorm: 40.0
      policy_entropy: 41.98860549926758
      policy_loss: -2377.048583984375
      var_gnorm: 192.10910034179688
      vf_explained_var: -0.2827615737915039
      vf_loss: 380571.59375
    num_steps_sampled: 6380000
    num_steps_trained: 6380000
    wait_time_ms: 74.028
  iterations_since_restore: 1276
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11110.075762271881
  time_this_iter_s: 8.550681829452515
  time_total_s: 11110.075762271881
  timestamp: 1594867154
  timesteps_since_restore: 6380000
  timesteps_this_iter: 5000
  timesteps_total: 6380000
  training_iteration: 1276
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11110 s, 1276 iter, 6380000 ts, -1.04e+05 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-39-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -29792.059674557902
  episode_reward_mean: -103785.55889451964
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 0
  episodes_total: 1276
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 4.355
    dispatch_time_ms: 6.975
    learner:
      cur_lr: 0.0009350919863209128
      grad_gnorm: 40.0
      policy_entropy: 40.01359176635742
      policy_loss: -2616.76611328125
      var_gnorm: 192.5368194580078
      vf_explained_var: 0.0
      vf_loss: 278311.875
    num_steps_sampled: 6385000
    num_steps_trained: 6385000
    wait_time_ms: 73.24
  iterations_since_restore: 1277
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11118.491356134415
  time_this_iter_s: 8.41559386253357
  time_total_s: 11118.491356134415
  timestamp: 1594867162
  timesteps_since_restore: 6385000
  timesteps_this_iter: 5000
  timesteps_total: 6385000
  training_iteration: 1277
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11118 s, 1277 iter, 6385000 ts, -1.04e+05 rew

agent-1: -23129.65638462951
agent-2: -31438.110530676393
agent-3: -29123.77364027026
agent-4: -20972.77744790159
agent-5: -35012.389873153996
Extrinsic Rewards:
-23000
-31275
-28972
-20853
-34832
Sum Reward: -138932
Avg Reward: -27786.4
Min Reward: -34832
Max Reward: -20853
Gini Coefficient: -0.10431865948809489
20:20 Ratio: 0.5986736334405145
Max-min Ratio: 0.5986736334405145
agent-1: -36085.33535200055
agent-2: -33269.860114517636
agent-3: -30568.521198713857
agent-4: -26596.466016151524
agent-5: -14559.174797627531
Extrinsic Rewards:
-35896
-33106
-30409
-26456
-14470
Sum Reward: -140337
Avg Reward: -28067.4
Min Reward: -35896
Max Reward: -14470
Gini Coefficient: -0.1410946507335913
20:20 Ratio: 0.4031089815021172
Max-min Ratio: 0.4031089815021172
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-39-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -29792.059674557902
  episode_reward_mean: -103946.16034851065
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 2
  episodes_total: 1278
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.666
    dispatch_time_ms: 6.347
    learner:
      cur_lr: 0.0009347589802928269
      grad_gnorm: 40.0
      policy_entropy: 40.25881576538086
      policy_loss: 31960.380859375
      var_gnorm: 193.03053283691406
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 14104730.0
    num_steps_sampled: 6390000
    num_steps_trained: 6390000
    wait_time_ms: 75.198
  iterations_since_restore: 1278
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11126.929926633835
  time_this_iter_s: 8.438570499420166
  time_total_s: 11126.929926633835
  timestamp: 1594867171
  timesteps_since_restore: 6390000
  timesteps_this_iter: 5000
  timesteps_total: 6390000
  training_iteration: 1278
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11126 s, 1278 iter, 6390000 ts, -1.04e+05 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-39-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -29792.059674557902
  episode_reward_mean: -103946.16034851065
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 0
  episodes_total: 1278
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.357
    dispatch_time_ms: 6.798
    learner:
      cur_lr: 0.0009344259742647409
      grad_gnorm: 40.000003814697266
      policy_entropy: 38.91268539428711
      policy_loss: -3830.15625
      var_gnorm: 193.5104522705078
      vf_explained_var: 0.0
      vf_loss: 1118560.375
    num_steps_sampled: 6395000
    num_steps_trained: 6395000
    wait_time_ms: 76.857
  iterations_since_restore: 1279
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11135.45871090889
  time_this_iter_s: 8.528784275054932
  time_total_s: 11135.45871090889
  timestamp: 1594867179
  timesteps_since_restore: 6395000
  timesteps_this_iter: 5000
  timesteps_total: 6395000
  training_iteration: 1279
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11135 s, 1279 iter, 6395000 ts, -1.04e+05 rew

agent-1: -33671.3439531939
agent-2: -22613.372770951715
agent-3: -22812.478125470578
agent-4: -36446.42935649652
agent-5: -36928.783881519244
Extrinsic Rewards:
-33504
-22489
-22709
-36277
-36752
Sum Reward: -151731
Avg Reward: -30346.2
Min Reward: -36752
Max Reward: -22489
Gini Coefficient: -0.1109700720353784
20:20 Ratio: 0.6119122768828907
Max-min Ratio: 0.6119122768828907
agent-1: -30148.968395024935
agent-2: -26320.19964402535
agent-3: -26694.46480765854
agent-4: -31933.360293882015
agent-5: -14734.713544047147
Extrinsic Rewards:
-29985
-26164
-26542
-31762
-14645
Sum Reward: -129098
Avg Reward: -25819.6
Min Reward: -31762
Max Reward: -14645
Gini Coefficient: -0.11791042463864661
20:20 Ratio: 0.46108557395629995
Max-min Ratio: 0.46108557395629995
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-39-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -29792.059674557902
  episode_reward_mean: -104258.52931582302
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 2
  episodes_total: 1280
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.764
    dispatch_time_ms: 6.821
    learner:
      cur_lr: 0.0009340930264443159
      grad_gnorm: 39.99999237060547
      policy_entropy: 50.40008544921875
      policy_loss: -940.6928100585938
      var_gnorm: 193.95640563964844
      vf_explained_var: -0.1095501184463501
      vf_loss: 118132.6796875
    num_steps_sampled: 6400000
    num_steps_trained: 6400000
    wait_time_ms: 78.508
  iterations_since_restore: 1280
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11144.031427621841
  time_this_iter_s: 8.57271671295166
  time_total_s: 11144.031427621841
  timestamp: 1594867188
  timesteps_since_restore: 6400000
  timesteps_this_iter: 5000
  timesteps_total: 6400000
  training_iteration: 1280
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11144 s, 1280 iter, 6400000 ts, -1.04e+05 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-39-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -29792.059674557902
  episode_reward_mean: -104258.52931582302
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 0
  episodes_total: 1280
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.802
    dispatch_time_ms: 9.046
    learner:
      cur_lr: 0.00093376002041623
      grad_gnorm: 39.999996185302734
      policy_entropy: 44.16980743408203
      policy_loss: -3484.33837890625
      var_gnorm: 194.32766723632812
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 742194.5625
    num_steps_sampled: 6405000
    num_steps_trained: 6405000
    wait_time_ms: 73.736
  iterations_since_restore: 1281
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11152.48669719696
  time_this_iter_s: 8.455269575119019
  time_total_s: 11152.48669719696
  timestamp: 1594867197
  timesteps_since_restore: 6405000
  timesteps_this_iter: 5000
  timesteps_total: 6405000
  training_iteration: 1281
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11152 s, 1281 iter, 6405000 ts, -1.04e+05 rew

agent-1: -26560.643078856116
agent-2: -30026.978011209165
agent-3: -22350.254186938553
agent-4: -22946.991361003224
agent-5: -22143.91181160934
Extrinsic Rewards:
-26405
-29849
-22209
-22815
-22000
Sum Reward: -123278
Avg Reward: -24655.6
Min Reward: -29849
Max Reward: -22000
Gini Coefficient: -0.06455004136991191
20:20 Ratio: 0.7370431170223458
Max-min Ratio: 0.7370431170223458
agent-1: -32523.03096794602
agent-2: -30734.22862086854
agent-3: -27358.867045215273
agent-4: -28129.506806981935
agent-5: -25347.625299726205
Extrinsic Rewards:
-32357
-30577
-27219
-27982
-25205
Sum Reward: -143340
Avg Reward: -28668.0
Min Reward: -32357
Max Reward: -25205
Gini Coefficient: -0.04928700990651597
20:20 Ratio: 0.7789659115492784
Max-min Ratio: 0.7789659115492784
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-40-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -29792.059674557902
  episode_reward_mean: -104255.10475889822
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 2
  episodes_total: 1282
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.334
    dispatch_time_ms: 10.558
    learner:
      cur_lr: 0.000933427014388144
      grad_gnorm: 40.0
      policy_entropy: 48.9041748046875
      policy_loss: 33816.0078125
      var_gnorm: 194.79812622070312
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 15447608.0
    num_steps_sampled: 6410000
    num_steps_trained: 6410000
    wait_time_ms: 75.279
  iterations_since_restore: 1282
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11163.81420302391
  time_this_iter_s: 11.327505826950073
  time_total_s: 11163.81420302391
  timestamp: 1594867208
  timesteps_since_restore: 6410000
  timesteps_this_iter: 5000
  timesteps_total: 6410000
  training_iteration: 1282
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11163 s, 1282 iter, 6410000 ts, -1.04e+05 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-40-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -29792.059674557902
  episode_reward_mean: -104255.10475889819
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 0
  episodes_total: 1282
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 4.15
    dispatch_time_ms: 30.29
    learner:
      cur_lr: 0.0009330940083600581
      grad_gnorm: 39.999996185302734
      policy_entropy: 42.24309539794922
      policy_loss: -1942.4620361328125
      var_gnorm: 195.2434539794922
      vf_explained_var: 0.0
      vf_loss: 304305.90625
    num_steps_sampled: 6415000
    num_steps_trained: 6415000
    wait_time_ms: 66.987
  iterations_since_restore: 1283
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11172.582196235657
  time_this_iter_s: 8.767993211746216
  time_total_s: 11172.582196235657
  timestamp: 1594867217
  timesteps_since_restore: 6415000
  timesteps_this_iter: 5000
  timesteps_total: 6415000
  training_iteration: 1283
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11172 s, 1283 iter, 6415000 ts, -1.04e+05 rew

agent-1: -26503.77229887698
agent-2: -31270.198919779177
agent-3: -35238.08609195888
agent-4: -26956.5992719671
agent-5: -29182.889526140705
Extrinsic Rewards:
-26368
-31111
-35069
-26814
-29034
Sum Reward: -148396
Avg Reward: -29679.2
Min Reward: -35069
Max Reward: -26368
Gini Coefficient: -0.058489447154909835
20:20 Ratio: 0.7518891328523768
Max-min Ratio: 0.7518891328523768
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-40-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -29792.059674557902
  episode_reward_mean: -104478.98252284764
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 1
  episodes_total: 1283
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.715
    dispatch_time_ms: 36.068
    learner:
      cur_lr: 0.0009327610023319721
      grad_gnorm: 40.0
      policy_entropy: 47.34528350830078
      policy_loss: -3733.9365234375
      var_gnorm: 195.6995849609375
      vf_explained_var: 0.0
      vf_loss: 387246.875
    num_steps_sampled: 6420000
    num_steps_trained: 6420000
    wait_time_ms: 55.841
  iterations_since_restore: 1284
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11181.682216405869
  time_this_iter_s: 9.100020170211792
  time_total_s: 11181.682216405869
  timestamp: 1594867226
  timesteps_since_restore: 6420000
  timesteps_this_iter: 5000
  timesteps_total: 6420000
  training_iteration: 1284
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11181 s, 1284 iter, 6420000 ts, -1.04e+05 rew

agent-1: -17403.468880614655
agent-2: -29297.37629613037
agent-3: -27747.42270470557
agent-4: -27650.725940936718
agent-5: -27944.857925910954
Extrinsic Rewards:
-17290
-29140
-27586
-27494
-27779
Sum Reward: -129289
Avg Reward: -25857.8
Min Reward: -29140
Max Reward: -17290
Gini Coefficient: -0.0742058489121271
20:20 Ratio: 0.5933424845573095
Max-min Ratio: 0.5933424845573095
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-40-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -29792.059674557902
  episode_reward_mean: -104998.14348092329
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 1
  episodes_total: 1284
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.976
    dispatch_time_ms: 6.832
    learner:
      cur_lr: 0.0009324279963038862
      grad_gnorm: 40.000003814697266
      policy_entropy: 58.495765686035156
      policy_loss: -4873.17919921875
      var_gnorm: 196.0940704345703
      vf_explained_var: 0.0
      vf_loss: 422611.46875
    num_steps_sampled: 6425000
    num_steps_trained: 6425000
    wait_time_ms: 74.84
  iterations_since_restore: 1285
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11190.618911504745
  time_this_iter_s: 8.936695098876953
  time_total_s: 11190.618911504745
  timestamp: 1594867235
  timesteps_since_restore: 6425000
  timesteps_this_iter: 5000
  timesteps_total: 6425000
  training_iteration: 1285
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11190 s, 1285 iter, 6425000 ts, -1.05e+05 rew

agent-1: -22299.88655132582
agent-2: -17850.55493844443
agent-3: -21587.75155304375
agent-4: -15417.173668716063
agent-5: -22032.125589587125
Extrinsic Rewards:
-22133
-17716
-21427
-15292
-21867
Sum Reward: -98435
Avg Reward: -19687.0
Min Reward: -22133
Max Reward: -15292
Gini Coefficient: -0.07246609437700005
20:20 Ratio: 0.6909140197894547
Max-min Ratio: 0.6909140197894547
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-40-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -29792.059674557902
  episode_reward_mean: -104715.2906031264
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 1
  episodes_total: 1285
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.491
    dispatch_time_ms: 6.933
    learner:
      cur_lr: 0.0009320949902758002
      grad_gnorm: 40.0
      policy_entropy: 56.11347961425781
      policy_loss: -1534.4114990234375
      var_gnorm: 196.45162963867188
      vf_explained_var: 0.0
      vf_loss: 183282.8125
    num_steps_sampled: 6430000
    num_steps_trained: 6430000
    wait_time_ms: 79.394
  iterations_since_restore: 1286
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11199.100591659546
  time_this_iter_s: 8.481680154800415
  time_total_s: 11199.100591659546
  timestamp: 1594867243
  timesteps_since_restore: 6430000
  timesteps_this_iter: 5000
  timesteps_total: 6430000
  training_iteration: 1286
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11199 s, 1286 iter, 6430000 ts, -1.05e+05 rew

agent-1: -26119.144443297722
agent-2: -20880.32348364922
agent-3: -24704.894603825014
agent-4: -21577.396115018404
agent-5: -12528.225156567369
Extrinsic Rewards:
-25946
-20727
-24535
-21429
-12437
Sum Reward: -105074
Avg Reward: -21014.8
Min Reward: -25946
Max Reward: -12437
Gini Coefficient: -0.11734967737023431
20:20 Ratio: 0.47934170970477147
Max-min Ratio: 0.47934170970477147
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-40-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -29792.059674557902
  episode_reward_mean: -104669.03879161853
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 1
  episodes_total: 1286
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.226
    dispatch_time_ms: 5.822
    learner:
      cur_lr: 0.0009317619842477143
      grad_gnorm: 40.0
      policy_entropy: 51.9122200012207
      policy_loss: -400.10491943359375
      var_gnorm: 196.83750915527344
      vf_explained_var: 0.0
      vf_loss: 168574.390625
    num_steps_sampled: 6435000
    num_steps_trained: 6435000
    wait_time_ms: 78.243
  iterations_since_restore: 1287
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11207.719698429108
  time_this_iter_s: 8.619106769561768
  time_total_s: 11207.719698429108
  timestamp: 1594867252
  timesteps_since_restore: 6435000
  timesteps_this_iter: 5000
  timesteps_total: 6435000
  training_iteration: 1287
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11207 s, 1287 iter, 6435000 ts, -1.05e+05 rew

agent-1: -26330.311969285205
agent-2: -16828.33078144697
agent-3: -19828.94327477814
agent-4: -25026.32444949872
agent-5: -27082.30110572544
Extrinsic Rewards:
-26162
-16705
-19699
-24867
-26913
Sum Reward: -114346
Avg Reward: -22869.2
Min Reward: -26913
Max Reward: -16705
Gini Coefficient: -0.09402690080982282
20:20 Ratio: 0.6207037491175268
Max-min Ratio: 0.6207037491175268
agent-1: -17203.659683791255
agent-2: -19358.40170994135
agent-3: -22545.511334461677
agent-4: -18159.72637088929
agent-5: -23461.183367967544
Extrinsic Rewards:
-17069
-19209
-22385
-18015
-23291
Sum Reward: -99969
Avg Reward: -19993.8
Min Reward: -23291
Max Reward: -17069
Gini Coefficient: -0.06727685582530585
20:20 Ratio: 0.7328581855652397
Max-min Ratio: 0.7328581855652397
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-41-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -29792.059674557902
  episode_reward_mean: -104940.91273062765
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 2
  episodes_total: 1288
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.033
    dispatch_time_ms: 6.875
    learner:
      cur_lr: 0.0009314289782196283
      grad_gnorm: 40.0
      policy_entropy: 58.37208938598633
      policy_loss: 57801.43359375
      var_gnorm: 197.2896270751953
      vf_explained_var: 0.0
      vf_loss: 17071696.0
    num_steps_sampled: 6440000
    num_steps_trained: 6440000
    wait_time_ms: 77.107
  iterations_since_restore: 1288
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11216.497644424438
  time_this_iter_s: 8.77794599533081
  time_total_s: 11216.497644424438
  timestamp: 1594867261
  timesteps_since_restore: 6440000
  timesteps_this_iter: 5000
  timesteps_total: 6440000
  training_iteration: 1288
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11216 s, 1288 iter, 6440000 ts, -1.05e+05 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-41-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -29792.059674557902
  episode_reward_mean: -104940.91273062768
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 0
  episodes_total: 1288
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.89
    dispatch_time_ms: 8.97
    learner:
      cur_lr: 0.0009310959721915424
      grad_gnorm: 40.0
      policy_entropy: 57.43461608886719
      policy_loss: -9836.4736328125
      var_gnorm: 197.71444702148438
      vf_explained_var: 0.0
      vf_loss: 1201650.375
    num_steps_sampled: 6445000
    num_steps_trained: 6445000
    wait_time_ms: 72.764
  iterations_since_restore: 1289
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11224.887704372406
  time_this_iter_s: 8.39005994796753
  time_total_s: 11224.887704372406
  timestamp: 1594867269
  timesteps_since_restore: 6445000
  timesteps_this_iter: 5000
  timesteps_total: 6445000
  training_iteration: 1289
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11224 s, 1289 iter, 6445000 ts, -1.05e+05 rew

agent-1: -30512.06012874813
agent-2: -20668.389376719315
agent-3: -21228.886527504303
agent-4: -19898.33530069033
agent-5: -19393.010539875053
Extrinsic Rewards:
-30320
-20531
-21080
-19763
-19254
Sum Reward: -110948
Avg Reward: -22189.6
Min Reward: -30320
Max Reward: -19254
Gini Coefficient: -0.08454050546201825
20:20 Ratio: 0.6350263852242745
Max-min Ratio: 0.6350263852242745
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-41-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -29792.059674557902
  episode_reward_mean: -104699.63565363197
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 1
  episodes_total: 1289
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.375
    dispatch_time_ms: 7.384
    learner:
      cur_lr: 0.0009307630243711174
      grad_gnorm: 39.999996185302734
      policy_entropy: 54.80271530151367
      policy_loss: -3169.507568359375
      var_gnorm: 198.10716247558594
      vf_explained_var: -0.12902188301086426
      vf_loss: 506558.1875
    num_steps_sampled: 6450000
    num_steps_trained: 6450000
    wait_time_ms: 76.718
  iterations_since_restore: 1290
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11233.517033338547
  time_this_iter_s: 8.629328966140747
  time_total_s: 11233.517033338547
  timestamp: 1594867278
  timesteps_since_restore: 6450000
  timesteps_this_iter: 5000
  timesteps_total: 6450000
  training_iteration: 1290
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11233 s, 1290 iter, 6450000 ts, -1.05e+05 rew

agent-1: -16853.470190748707
agent-2: -19362.437192273374
agent-3: -23016.07611458411
agent-4: -18596.940769156925
agent-5: -22807.785952269813
Extrinsic Rewards:
-16722
-19218
-22842
-18453
-22640
Sum Reward: -99875
Avg Reward: -19975.0
Min Reward: -22842
Max Reward: -16722
Gini Coefficient: -0.06579023779724656
20:20 Ratio: 0.7320724980299448
Max-min Ratio: 0.7320724980299448
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-41-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -29792.059674557902
  episode_reward_mean: -104788.37699657002
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 1
  episodes_total: 1290
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.487
    dispatch_time_ms: 9.262
    learner:
      cur_lr: 0.0009304300183430314
      grad_gnorm: 40.0
      policy_entropy: 52.303306579589844
      policy_loss: -3484.211181640625
      var_gnorm: 198.50762939453125
      vf_explained_var: 0.0
      vf_loss: 314790.71875
    num_steps_sampled: 6455000
    num_steps_trained: 6455000
    wait_time_ms: 73.648
  iterations_since_restore: 1291
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11242.126153469086
  time_this_iter_s: 8.60912013053894
  time_total_s: 11242.126153469086
  timestamp: 1594867287
  timesteps_since_restore: 6455000
  timesteps_this_iter: 5000
  timesteps_total: 6455000
  training_iteration: 1291
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11242 s, 1291 iter, 6455000 ts, -1.05e+05 rew

agent-1: -23713.841602761542
agent-2: -20752.467153834754
agent-3: -16537.319603128366
agent-4: -20751.17797172371
agent-5: -24630.058825512388
Extrinsic Rewards:
-23547
-20605
-16414
-20605
-24457
Sum Reward: -105628
Avg Reward: -21125.6
Min Reward: -24457
Max Reward: -16414
Gini Coefficient: -0.07205665164539705
20:20 Ratio: 0.6711370977634216
Max-min Ratio: 0.6711370977634216
agent-1: -17935.763447354882
agent-2: -25313.029263253036
agent-3: -26239.76631060264
agent-4: -25809.347284771582
agent-5: -21101.554699793836
Extrinsic Rewards:
-17814
-25147
-26069
-25643
-20965
Sum Reward: -115638
Avg Reward: -23127.6
Min Reward: -26069
Max Reward: -17814
Gini Coefficient: -0.07329078676559608
20:20 Ratio: 0.6833403659518968
Max-min Ratio: 0.6833403659518968
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-41-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -29792.059674557902
  episode_reward_mean: -105149.11799934998
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 2
  episodes_total: 1292
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.908
    dispatch_time_ms: 7.402
    learner:
      cur_lr: 0.0009300970123149455
      grad_gnorm: 40.0
      policy_entropy: 57.685028076171875
      policy_loss: -520.330322265625
      var_gnorm: 198.93930053710938
      vf_explained_var: -0.16463613510131836
      vf_loss: 152571.109375
    num_steps_sampled: 6460000
    num_steps_trained: 6460000
    wait_time_ms: 74.871
  iterations_since_restore: 1292
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11250.777486801147
  time_this_iter_s: 8.651333332061768
  time_total_s: 11250.777486801147
  timestamp: 1594867295
  timesteps_since_restore: 6460000
  timesteps_this_iter: 5000
  timesteps_total: 6460000
  training_iteration: 1292
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11250 s, 1292 iter, 6460000 ts, -1.05e+05 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-41-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -29792.059674557902
  episode_reward_mean: -105149.11799934997
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 0
  episodes_total: 1292
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.662
    dispatch_time_ms: 7.675
    learner:
      cur_lr: 0.0009297640062868595
      grad_gnorm: 40.0
      policy_entropy: 50.478172302246094
      policy_loss: 1400.3099365234375
      var_gnorm: 199.30445861816406
      vf_explained_var: 0.0
      vf_loss: 31302.26953125
    num_steps_sampled: 6465000
    num_steps_trained: 6465000
    wait_time_ms: 71.594
  iterations_since_restore: 1293
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11259.158510923386
  time_this_iter_s: 8.38102412223816
  time_total_s: 11259.158510923386
  timestamp: 1594867304
  timesteps_since_restore: 6465000
  timesteps_this_iter: 5000
  timesteps_total: 6465000
  training_iteration: 1293
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11259 s, 1293 iter, 6465000 ts, -1.05e+05 rew

agent-1: -11499.377177773707
agent-2: -23366.232079078964
agent-3: -25225.92741942195
agent-4: -25786.714974661456
agent-5: -21946.463698513264
Extrinsic Rewards:
-11406
-23208
-25058
-25608
-21794
Sum Reward: -107074
Avg Reward: -21414.8
Min Reward: -25608
Max Reward: -11406
Gini Coefficient: -0.11830322954218578
20:20 Ratio: 0.4454076850984067
Max-min Ratio: 0.4454076850984067
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-41-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -29792.059674557902
  episode_reward_mean: -105521.67210445626
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 1
  episodes_total: 1293
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.629
    dispatch_time_ms: 8.166
    learner:
      cur_lr: 0.0009294310002587736
      grad_gnorm: 40.0
      policy_entropy: 57.12023162841797
      policy_loss: -5031.01416015625
      var_gnorm: 199.76507568359375
      vf_explained_var: 0.0
      vf_loss: 341913.9375
    num_steps_sampled: 6470000
    num_steps_trained: 6470000
    wait_time_ms: 76.597
  iterations_since_restore: 1294
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11267.63939332962
  time_this_iter_s: 8.480882406234741
  time_total_s: 11267.63939332962
  timestamp: 1594867312
  timesteps_since_restore: 6470000
  timesteps_this_iter: 5000
  timesteps_total: 6470000
  training_iteration: 1294
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11267 s, 1294 iter, 6470000 ts, -1.06e+05 rew

agent-1: -21805.71610073607
agent-2: -19483.9193932661
agent-3: -25076.512077936266
agent-4: -26681.360028673273
agent-5: -25174.020281109264
Extrinsic Rewards:
-21670
-19354
-24917
-26513
-25015
Sum Reward: -117469
Avg Reward: -23493.8
Min Reward: -26513
Max Reward: -19354
Gini Coefficient: -0.060145229805310334
20:20 Ratio: 0.7299815185003583
Max-min Ratio: 0.7299815185003583
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-42-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -29792.059674557902
  episode_reward_mean: -105843.38358246867
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 1
  episodes_total: 1294
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.84
    dispatch_time_ms: 10.452
    learner:
      cur_lr: 0.0009290979942306876
      grad_gnorm: 40.0
      policy_entropy: 51.991722106933594
      policy_loss: -2214.53076171875
      var_gnorm: 200.1759033203125
      vf_explained_var: 0.0
      vf_loss: 338806.53125
    num_steps_sampled: 6475000
    num_steps_trained: 6475000
    wait_time_ms: 71.166
  iterations_since_restore: 1295
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11276.250213384628
  time_this_iter_s: 8.610820055007935
  time_total_s: 11276.250213384628
  timestamp: 1594867321
  timesteps_since_restore: 6475000
  timesteps_this_iter: 5000
  timesteps_total: 6475000
  training_iteration: 1295
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11276 s, 1295 iter, 6475000 ts, -1.06e+05 rew

agent-1: -22440.290684415246
agent-2: -26020.07425011258
agent-3: -18423.991235350102
agent-4: -24907.619680217696
agent-5: -11753.213032756908
Extrinsic Rewards:
-22279
-25834
-18291
-24740
-11657
Sum Reward: -102801
Avg Reward: -20560.2
Min Reward: -25834
Max Reward: -11657
Gini Coefficient: -0.13541891615840312
20:20 Ratio: 0.4512270651079972
Max-min Ratio: 0.4512270651079972
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-42-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -29792.059674557902
  episode_reward_mean: -106491.55612114257
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 1
  episodes_total: 1295
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.934
    dispatch_time_ms: 9.034
    learner:
      cur_lr: 0.0009287649882026017
      grad_gnorm: 40.0
      policy_entropy: 50.2889404296875
      policy_loss: -1228.4964599609375
      var_gnorm: 200.59564208984375
      vf_explained_var: 0.0
      vf_loss: 198034.296875
    num_steps_sampled: 6480000
    num_steps_trained: 6480000
    wait_time_ms: 75.413
  iterations_since_restore: 1296
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11284.818559885025
  time_this_iter_s: 8.568346500396729
  time_total_s: 11284.818559885025
  timestamp: 1594867329
  timesteps_since_restore: 6480000
  timesteps_this_iter: 5000
  timesteps_total: 6480000
  training_iteration: 1296
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11284 s, 1296 iter, 6480000 ts, -1.06e+05 rew

agent-1: -27153.14092110745
agent-2: -24965.851087321735
agent-3: -27169.08372617106
agent-4: -22196.891003413715
agent-5: -22107.183442471265
Extrinsic Rewards:
-26991
-24815
-27003
-22055
-21973
Sum Reward: -122837
Avg Reward: -24567.4
Min Reward: -27003
Max Reward: -21973
Gini Coefficient: -0.048832192254776655
20:20 Ratio: 0.8137244009924823
Max-min Ratio: 0.8137244009924823
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-42-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -29792.059674557902
  episode_reward_mean: -107285.51186631748
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 1
  episodes_total: 1296
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.681
    dispatch_time_ms: 8.544
    learner:
      cur_lr: 0.0009284319821745157
      grad_gnorm: 40.0
      policy_entropy: 52.94355392456055
      policy_loss: -1708.732421875
      var_gnorm: 201.0203399658203
      vf_explained_var: 0.0
      vf_loss: 362285.8125
    num_steps_sampled: 6485000
    num_steps_trained: 6485000
    wait_time_ms: 71.665
  iterations_since_restore: 1297
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11293.34119963646
  time_this_iter_s: 8.522639751434326
  time_total_s: 11293.34119963646
  timestamp: 1594867338
  timesteps_since_restore: 6485000
  timesteps_this_iter: 5000
  timesteps_total: 6485000
  training_iteration: 1297
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11293 s, 1297 iter, 6485000 ts, -1.07e+05 rew

agent-1: -26832.65970794929
agent-2: -26072.668817574497
agent-3: -21252.236147420652
agent-4: -19989.963356500484
agent-5: -26749.019054106422
Extrinsic Rewards:
-26668
-25913
-21114
-19859
-26582
Sum Reward: -120136
Avg Reward: -24027.2
Min Reward: -26668
Max Reward: -19859
Gini Coefficient: -0.06354797895718187
20:20 Ratio: 0.7446752662366881
Max-min Ratio: 0.7446752662366881
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-42-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -29792.059674557902
  episode_reward_mean: -108074.61447449223
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 1
  episodes_total: 1297
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.871
    dispatch_time_ms: 8.65
    learner:
      cur_lr: 0.0009280989761464298
      grad_gnorm: 40.0
      policy_entropy: 55.03200912475586
      policy_loss: -4275.38232421875
      var_gnorm: 201.4964599609375
      vf_explained_var: 0.0
      vf_loss: 425485.625
    num_steps_sampled: 6490000
    num_steps_trained: 6490000
    wait_time_ms: 72.3
  iterations_since_restore: 1298
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11301.915316343307
  time_this_iter_s: 8.574116706848145
  time_total_s: 11301.915316343307
  timestamp: 1594867347
  timesteps_since_restore: 6490000
  timesteps_this_iter: 5000
  timesteps_total: 6490000
  training_iteration: 1298
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11301 s, 1298 iter, 6490000 ts, -1.08e+05 rew

agent-1: -29718.672990721174
agent-2: -29489.92048827157
agent-3: -13174.079073853847
agent-4: -26015.75109157801
agent-5: -26767.739435225005
Extrinsic Rewards:
-29541
-29321
-13094
-25862
-26605
Sum Reward: -124423
Avg Reward: -24884.6
Min Reward: -29541
Max Reward: -13094
Gini Coefficient: -0.11686906761611598
20:20 Ratio: 0.44324836667682205
Max-min Ratio: 0.44324836667682205
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-42-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -29792.059674557902
  episode_reward_mean: -108907.90207179105
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 1
  episodes_total: 1298
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.869
    dispatch_time_ms: 7.246
    learner:
      cur_lr: 0.0009277660283260047
      grad_gnorm: 39.999996185302734
      policy_entropy: 59.898258209228516
      policy_loss: -4853.87451171875
      var_gnorm: 201.9011993408203
      vf_explained_var: 0.0
      vf_loss: 685684.4375
    num_steps_sampled: 6495000
    num_steps_trained: 6495000
    wait_time_ms: 75.468
  iterations_since_restore: 1299
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11310.359663009644
  time_this_iter_s: 8.44434666633606
  time_total_s: 11310.359663009644
  timestamp: 1594867355
  timesteps_since_restore: 6495000
  timesteps_this_iter: 5000
  timesteps_total: 6495000
  training_iteration: 1299
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11310 s, 1299 iter, 6495000 ts, -1.09e+05 rew

agent-1: -14210.941759492542
agent-2: -19470.62242211497
agent-3: -18624.369436040146
agent-4: -22484.07185019127
agent-5: -24495.877624860328
Extrinsic Rewards:
-14093
-19316
-18478
-22317
-24323
Sum Reward: -98527
Avg Reward: -19705.4
Min Reward: -24323
Max Reward: -14093
Gini Coefficient: -0.09864910126158312
20:20 Ratio: 0.5794104345681043
Max-min Ratio: 0.5794104345681043
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-42-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -29792.059674557902
  episode_reward_mean: -109526.5466311131
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 1
  episodes_total: 1299
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.914
    dispatch_time_ms: 8.095
    learner:
      cur_lr: 0.0009274330222979188
      grad_gnorm: 40.0
      policy_entropy: 64.18604278564453
      policy_loss: 257.2796630859375
      var_gnorm: 202.30552673339844
      vf_explained_var: 0.0
      vf_loss: 37603.046875
    num_steps_sampled: 6500000
    num_steps_trained: 6500000
    wait_time_ms: 75.837
  iterations_since_restore: 1300
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11318.95602607727
  time_this_iter_s: 8.596363067626953
  time_total_s: 11318.95602607727
  timestamp: 1594867364
  timesteps_since_restore: 6500000
  timesteps_this_iter: 5000
  timesteps_total: 6500000
  training_iteration: 1300
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11318 s, 1300 iter, 6500000 ts, -1.1e+05 rew

agent-1: -21129.52525529115
agent-2: -22339.73570894889
agent-3: -20125.752810606384
agent-4: -17796.864267433248
agent-5: -20602.247838081617
Extrinsic Rewards:
-20973
-22177
-19979
-17659
-20445
Sum Reward: -101233
Avg Reward: -20246.6
Min Reward: -22177
Max Reward: -17659
Gini Coefficient: -0.039631345509863386
20:20 Ratio: 0.7962754204806782
Max-min Ratio: 0.7962754204806782
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-42-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -32205.03066199693
  episode_reward_mean: -110248.56729317113
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 1
  episodes_total: 1300
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.21
    dispatch_time_ms: 5.757
    learner:
      cur_lr: 0.0009271000162698328
      grad_gnorm: 39.999996185302734
      policy_entropy: 63.25897979736328
      policy_loss: -639.9213256835938
      var_gnorm: 202.52783203125
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 102360.515625
    num_steps_sampled: 6505000
    num_steps_trained: 6505000
    wait_time_ms: 77.587
  iterations_since_restore: 1301
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11327.312096118927
  time_this_iter_s: 8.356070041656494
  time_total_s: 11327.312096118927
  timestamp: 1594867372
  timesteps_since_restore: 6505000
  timesteps_this_iter: 5000
  timesteps_total: 6505000
  training_iteration: 1301
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11327 s, 1301 iter, 6505000 ts, -1.1e+05 rew

agent-1: -15420.530351254518
agent-2: -16062.987378659309
agent-3: -18527.733398663946
agent-4: -7946.506825628262
agent-5: -14750.046229639756
Extrinsic Rewards:
-15266
-15905
-18339
-7870
-14580
Sum Reward: -71960
Avg Reward: -14392.0
Min Reward: -18339
Max Reward: -7870
Gini Coefficient: -0.1237520844913841
20:20 Ratio: 0.4291400839740444
Max-min Ratio: 0.4291400839740444
agent-1: -13917.745829094792
agent-2: -15111.408632649589
agent-3: -16551.68332736956
agent-4: -17211.479892020594
agent-5: -15382.045333190825
Extrinsic Rewards:
-13775
-14962
-16390
-17054
-15238
Sum Reward: -77419
Avg Reward: -15483.8
Min Reward: -17054
Max Reward: -13775
Gini Coefficient: -0.04126118911378344
20:20 Ratio: 0.8077283921660607
Max-min Ratio: 0.8077283921660607
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-43-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -44677.58380540387
  episode_reward_mean: -111079.45235451688
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 2
  episodes_total: 1302
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.286
    dispatch_time_ms: 8.681
    learner:
      cur_lr: 0.0009267670102417469
      grad_gnorm: 39.999996185302734
      policy_entropy: 65.16007995605469
      policy_loss: 59126.58984375
      var_gnorm: 202.87225341796875
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 17831444.0
    num_steps_sampled: 6510000
    num_steps_trained: 6510000
    wait_time_ms: 74.544
  iterations_since_restore: 1302
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11335.68587732315
  time_this_iter_s: 8.373781204223633
  time_total_s: 11335.68587732315
  timestamp: 1594867381
  timesteps_since_restore: 6510000
  timesteps_this_iter: 5000
  timesteps_total: 6510000
  training_iteration: 1302
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11335 s, 1302 iter, 6510000 ts, -1.11e+05 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-43-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -44677.58380540387
  episode_reward_mean: -111079.45235451688
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 0
  episodes_total: 1302
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.652
    dispatch_time_ms: 8.361
    learner:
      cur_lr: 0.000926434004213661
      grad_gnorm: 40.0
      policy_entropy: 62.420997619628906
      policy_loss: -2851.929443359375
      var_gnorm: 203.20675659179688
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 257607.84375
    num_steps_sampled: 6515000
    num_steps_trained: 6515000
    wait_time_ms: 72.599
  iterations_since_restore: 1303
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11344.01862502098
  time_this_iter_s: 8.3327476978302
  time_total_s: 11344.01862502098
  timestamp: 1594867389
  timesteps_since_restore: 6515000
  timesteps_this_iter: 5000
  timesteps_total: 6515000
  training_iteration: 1303
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11344 s, 1303 iter, 6515000 ts, -1.11e+05 rew

agent-1: -17480.004073498054
agent-2: -14306.941454119384
agent-3: -20458.15247647338
agent-4: -12197.828208467
agent-5: -21059.170336725256
Extrinsic Rewards:
-17331
-14170
-20283
-12084
-20883
Sum Reward: -84751
Avg Reward: -16950.2
Min Reward: -20883
Max Reward: -12084
Gini Coefficient: -0.11190900402355135
20:20 Ratio: 0.5786524924579802
Max-min Ratio: 0.5786524924579802
agent-1: -19574.287284587106
agent-2: -20093.778238291434
agent-3: -20737.88106782612
agent-4: -17931.942707941056
agent-5: -20444.35339542491
Extrinsic Rewards:
-19421
-19943
-20583
-17789
-20285
Sum Reward: -98021
Avg Reward: -19604.2
Min Reward: -20583
Max Reward: -17789
Gini Coefficient: -0.026329051937850054
20:20 Ratio: 0.8642569110430938
Max-min Ratio: 0.8642569110430938
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-43-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -45215.10107403114
  episode_reward_mean: -111657.69646068144
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 2
  episodes_total: 1304
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.537
    dispatch_time_ms: 9.173
    learner:
      cur_lr: 0.000926100998185575
      grad_gnorm: 40.0
      policy_entropy: 72.07844543457031
      policy_loss: 55800.83984375
      var_gnorm: 203.56698608398438
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 15548250.0
    num_steps_sampled: 6520000
    num_steps_trained: 6520000
    wait_time_ms: 73.611
  iterations_since_restore: 1304
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11352.519730567932
  time_this_iter_s: 8.501105546951294
  time_total_s: 11352.519730567932
  timestamp: 1594867397
  timesteps_since_restore: 6520000
  timesteps_this_iter: 5000
  timesteps_total: 6520000
  training_iteration: 1304
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11352 s, 1304 iter, 6520000 ts, -1.12e+05 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-43-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -45215.10107403114
  episode_reward_mean: -111657.69646068149
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 0
  episodes_total: 1304
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.675
    dispatch_time_ms: 5.628
    learner:
      cur_lr: 0.0009257679921574891
      grad_gnorm: 40.0
      policy_entropy: 72.72144317626953
      policy_loss: -5875.607421875
      var_gnorm: 203.8773956298828
      vf_explained_var: 0.0
      vf_loss: 401348.21875
    num_steps_sampled: 6525000
    num_steps_trained: 6525000
    wait_time_ms: 79.294
  iterations_since_restore: 1305
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11360.920379161835
  time_this_iter_s: 8.400648593902588
  time_total_s: 11360.920379161835
  timestamp: 1594867406
  timesteps_since_restore: 6525000
  timesteps_this_iter: 5000
  timesteps_total: 6525000
  training_iteration: 1305
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11360 s, 1305 iter, 6525000 ts, -1.12e+05 rew

agent-1: -16064.333426694327
agent-2: -16720.60655689227
agent-3: -17510.71782557165
agent-4: -15699.134851448189
agent-5: -16761.597589876754
Extrinsic Rewards:
-15921
-16564
-17351
-15551
-16606
Sum Reward: -81993
Avg Reward: -16398.6
Min Reward: -17351
Max Reward: -15551
Gini Coefficient: -0.02090422353127706
20:20 Ratio: 0.8962595815803124
Max-min Ratio: 0.8962595815803124
agent-1: -15624.681112377817
agent-2: -15013.48101350203
agent-3: -13482.556566257435
agent-4: -9324.929012986657
agent-5: -15978.118872295294
Extrinsic Rewards:
-15454
-14847
-13338
-9225
-15807
Sum Reward: -68671
Avg Reward: -13734.2
Min Reward: -15807
Max Reward: -9225
Gini Coefficient: -0.0890040919747783
20:20 Ratio: 0.5836022015562725
Max-min Ratio: 0.5836022015562725
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-43-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -45215.10107403114
  episode_reward_mean: -111676.05347294008
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 2
  episodes_total: 1306
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.905
    dispatch_time_ms: 7.756
    learner:
      cur_lr: 0.0009254349861294031
      grad_gnorm: 40.0
      policy_entropy: 73.2296142578125
      policy_loss: 201.72756958007812
      var_gnorm: 204.05020141601562
      vf_explained_var: -0.5233016014099121
      vf_loss: 41390.375
    num_steps_sampled: 6530000
    num_steps_trained: 6530000
    wait_time_ms: 75.043
  iterations_since_restore: 1306
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11369.468232393265
  time_this_iter_s: 8.547853231430054
  time_total_s: 11369.468232393265
  timestamp: 1594867415
  timesteps_since_restore: 6530000
  timesteps_this_iter: 5000
  timesteps_total: 6530000
  training_iteration: 1306
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11369 s, 1306 iter, 6530000 ts, -1.12e+05 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-43-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -45215.10107403114
  episode_reward_mean: -111676.05347294007
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 0
  episodes_total: 1306
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.677
    dispatch_time_ms: 8.433
    learner:
      cur_lr: 0.0009251019801013172
      grad_gnorm: 39.999996185302734
      policy_entropy: 70.00950622558594
      policy_loss: 525.1647338867188
      var_gnorm: 204.26988220214844
      vf_explained_var: 0.0
      vf_loss: 79754.09375
    num_steps_sampled: 6535000
    num_steps_trained: 6535000
    wait_time_ms: 73.092
  iterations_since_restore: 1307
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11377.933584451675
  time_this_iter_s: 8.465352058410645
  time_total_s: 11377.933584451675
  timestamp: 1594867423
  timesteps_since_restore: 6535000
  timesteps_this_iter: 5000
  timesteps_total: 6535000
  training_iteration: 1307
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11377 s, 1307 iter, 6535000 ts, -1.12e+05 rew

agent-1: -18197.53972491202
agent-2: -14660.225368129288
agent-3: -19795.13613088501
agent-4: -15785.436861993037
agent-5: -17939.51858056225
Extrinsic Rewards:
-18049
-14525
-19624
-15643
-17777
Sum Reward: -85618
Avg Reward: -17123.6
Min Reward: -19624
Max Reward: -14525
Gini Coefficient: -0.058884813940993715
20:20 Ratio: 0.7401651039543417
Max-min Ratio: 0.7401651039543417
agent-1: -15210.379987952054
agent-2: -12537.093856658965
agent-3: -14154.392680502257
agent-4: -17187.895309919764
agent-5: -12154.434811407755
Extrinsic Rewards:
-15045
-12403
-13997
-17011
-12023
Sum Reward: -70479
Avg Reward: -14095.8
Min Reward: -17011
Max Reward: -12023
Gini Coefficient: -0.0716128208402503
20:20 Ratio: 0.7067779671976956
Max-min Ratio: 0.7067779671976956
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-43-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -45215.10107403114
  episode_reward_mean: -110961.63404847968
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 2
  episodes_total: 1308
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.918
    dispatch_time_ms: 10.29
    learner:
      cur_lr: 0.0009247689740732312
      grad_gnorm: 40.0
      policy_entropy: 68.49658203125
      policy_loss: 49345.4296875
      var_gnorm: 204.57066345214844
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 18682738.0
    num_steps_sampled: 6540000
    num_steps_trained: 6540000
    wait_time_ms: 74.232
  iterations_since_restore: 1308
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11386.42723274231
  time_this_iter_s: 8.493648290634155
  time_total_s: 11386.42723274231
  timestamp: 1594867432
  timesteps_since_restore: 6540000
  timesteps_this_iter: 5000
  timesteps_total: 6540000
  training_iteration: 1308
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11386 s, 1308 iter, 6540000 ts, -1.11e+05 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-44-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -45215.10107403114
  episode_reward_mean: -110961.63404847968
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 0
  episodes_total: 1308
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.98
    dispatch_time_ms: 7.451
    learner:
      cur_lr: 0.0009244360262528062
      grad_gnorm: 40.000003814697266
      policy_entropy: 55.34446716308594
      policy_loss: 558.1834106445312
      var_gnorm: 204.9300994873047
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 499282.53125
    num_steps_sampled: 6545000
    num_steps_trained: 6545000
    wait_time_ms: 71.955
  iterations_since_restore: 1309
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11394.79414653778
  time_this_iter_s: 8.366913795471191
  time_total_s: 11394.79414653778
  timestamp: 1594867440
  timesteps_since_restore: 6545000
  timesteps_this_iter: 5000
  timesteps_total: 6545000
  training_iteration: 1309
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11394 s, 1309 iter, 6545000 ts, -1.11e+05 rew

agent-1: -21465.562720386155
agent-2: -16261.523108283902
agent-3: -28378.85784280084
agent-4: -24568.915107483885
agent-5: -24758.082177523338
Extrinsic Rewards:
-21320
-16151
-28209
-24410
-24596
Sum Reward: -114686
Avg Reward: -22937.2
Min Reward: -28209
Max Reward: -16151
Gini Coefficient: -0.09553738032541025
20:20 Ratio: 0.5725477684426956
Max-min Ratio: 0.5725477684426956
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-44-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -45215.10107403114
  episode_reward_mean: -110725.71240700886
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 1
  episodes_total: 1309
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.076
    dispatch_time_ms: 12.913
    learner:
      cur_lr: 0.0009241030202247202
      grad_gnorm: 40.0
      policy_entropy: 39.508846282958984
      policy_loss: 1048.53173828125
      var_gnorm: 205.3489990234375
      vf_explained_var: 0.0
      vf_loss: 129834.4609375
    num_steps_sampled: 6550000
    num_steps_trained: 6550000
    wait_time_ms: 74.656
  iterations_since_restore: 1310
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11406.463412284851
  time_this_iter_s: 11.669265747070312
  time_total_s: 11406.463412284851
  timestamp: 1594867452
  timesteps_since_restore: 6550000
  timesteps_this_iter: 5000
  timesteps_total: 6550000
  training_iteration: 1310
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11406 s, 1310 iter, 6550000 ts, -1.11e+05 rew

agent-1: -17978.077486553822
agent-2: -25320.119856286863
agent-3: -25598.86014873737
agent-4: -21051.672995596356
agent-5: -20594.600037698794
Extrinsic Rewards:
-17853
-25155
-25431
-20902
-20445
Sum Reward: -109786
Avg Reward: -21957.2
Min Reward: -25431
Max Reward: -17853
Gini Coefficient: -0.07238081358278833
20:20 Ratio: 0.7020172230742008
Max-min Ratio: 0.7020172230742008
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-44-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -45215.10107403114
  episode_reward_mean: -110649.25787486437
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 1
  episodes_total: 1310
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.468
    dispatch_time_ms: 6.712
    learner:
      cur_lr: 0.0009237700141966343
      grad_gnorm: 40.00000762939453
      policy_entropy: 44.55540466308594
      policy_loss: -3956.728515625
      var_gnorm: 205.76351928710938
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 576387.25
    num_steps_sampled: 6555000
    num_steps_trained: 6555000
    wait_time_ms: 76.57
  iterations_since_restore: 1311
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11414.918885231018
  time_this_iter_s: 8.455472946166992
  time_total_s: 11414.918885231018
  timestamp: 1594867460
  timesteps_since_restore: 6555000
  timesteps_this_iter: 5000
  timesteps_total: 6555000
  training_iteration: 1311
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11414 s, 1311 iter, 6555000 ts, -1.11e+05 rew

agent-1: -23329.43930408455
agent-2: -31751.44347380928
agent-3: -29583.470006751857
agent-4: -19633.06570375979
agent-5: -33886.64530986938
Extrinsic Rewards:
-23210
-31584
-29413
-19531
-33714
Sum Reward: -137452
Avg Reward: -27490.4
Min Reward: -33714
Max Reward: -19531
Gini Coefficient: -0.10691732386578587
20:20 Ratio: 0.5793142314765379
Max-min Ratio: 0.5793142314765379
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-44-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -45215.10107403114
  episode_reward_mean: -111010.1216515975
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 1
  episodes_total: 1311
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.49
    dispatch_time_ms: 7.585
    learner:
      cur_lr: 0.0009234370081685483
      grad_gnorm: 39.99999237060547
      policy_entropy: 49.57868194580078
      policy_loss: -1348.5379638671875
      var_gnorm: 206.19105529785156
      vf_explained_var: 0.0
      vf_loss: 483229.15625
    num_steps_sampled: 6560000
    num_steps_trained: 6560000
    wait_time_ms: 75.076
  iterations_since_restore: 1312
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11423.382422447205
  time_this_iter_s: 8.463537216186523
  time_total_s: 11423.382422447205
  timestamp: 1594867469
  timesteps_since_restore: 6560000
  timesteps_this_iter: 5000
  timesteps_total: 6560000
  training_iteration: 1312
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11423 s, 1312 iter, 6560000 ts, -1.11e+05 rew

agent-1: -21082.770130840046
agent-2: -20915.861651099633
agent-3: -20652.30929592893
agent-4: -22977.58349865798
agent-5: -23156.17230603064
Extrinsic Rewards:
-20939
-20770
-20517
-22820
-22997
Sum Reward: -108043
Avg Reward: -21608.6
Min Reward: -22997
Max Reward: -20517
Gini Coefficient: -0.025952629971400274
20:20 Ratio: 0.8921598469365569
Max-min Ratio: 0.8921598469365569
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-44-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -45215.10107403114
  episode_reward_mean: -110715.88846354594
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 1
  episodes_total: 1312
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.936
    dispatch_time_ms: 7.387
    learner:
      cur_lr: 0.0009231040021404624
      grad_gnorm: 40.0
      policy_entropy: 37.43587112426758
      policy_loss: -613.7008666992188
      var_gnorm: 206.66188049316406
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 354352.15625
    num_steps_sampled: 6565000
    num_steps_trained: 6565000
    wait_time_ms: 76.165
  iterations_since_restore: 1313
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11431.909771442413
  time_this_iter_s: 8.52734899520874
  time_total_s: 11431.909771442413
  timestamp: 1594867477
  timesteps_since_restore: 6565000
  timesteps_this_iter: 5000
  timesteps_total: 6565000
  training_iteration: 1313
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11431 s, 1313 iter, 6565000 ts, -1.11e+05 rew

agent-1: -18678.626509178433
agent-2: -24611.61780477953
agent-3: -26073.171275235516
agent-4: -25237.233905208785
agent-5: -30789.13695491206
Extrinsic Rewards:
-18564
-24469
-25910
-25097
-30618
Sum Reward: -124658
Avg Reward: -24931.6
Min Reward: -30618
Max Reward: -18564
Gini Coefficient: -0.08198110029039452
20:20 Ratio: 0.6063100137174211
Max-min Ratio: 0.6063100137174211
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-44-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -45215.10107403114
  episode_reward_mean: -110968.79627172202
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 1
  episodes_total: 1313
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.215
    dispatch_time_ms: 6.916
    learner:
      cur_lr: 0.0009227709961123765
      grad_gnorm: 40.0
      policy_entropy: 31.733755111694336
      policy_loss: -3369.837890625
      var_gnorm: 207.08395385742188
      vf_explained_var: -0.19426369667053223
      vf_loss: 773647.5
    num_steps_sampled: 6570000
    num_steps_trained: 6570000
    wait_time_ms: 73.343
  iterations_since_restore: 1314
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11440.467894077301
  time_this_iter_s: 8.558122634887695
  time_total_s: 11440.467894077301
  timestamp: 1594867486
  timesteps_since_restore: 6570000
  timesteps_this_iter: 5000
  timesteps_total: 6570000
  training_iteration: 1314
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11440 s, 1314 iter, 6570000 ts, -1.11e+05 rew

agent-1: -18324.1272344238
agent-2: -22675.693928367175
agent-3: -30520.513420571642
agent-4: -31885.29490309453
agent-5: -23660.55461321129
Extrinsic Rewards:
-18214
-22536
-30350
-31704
-23520
Sum Reward: -126324
Avg Reward: -25264.8
Min Reward: -31704
Max Reward: -18214
Gini Coefficient: -0.11017383870048447
20:20 Ratio: 0.5745016401715872
Max-min Ratio: 0.5745016401715872
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-44-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -45215.10107403114
  episode_reward_mean: -111257.96552740417
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 1
  episodes_total: 1314
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.75
    dispatch_time_ms: 8.397
    learner:
      cur_lr: 0.0009224379900842905
      grad_gnorm: 39.99999237060547
      policy_entropy: 30.495370864868164
      policy_loss: -3008.3486328125
      var_gnorm: 207.4365692138672
      vf_explained_var: 0.0
      vf_loss: 1289108.875
    num_steps_sampled: 6575000
    num_steps_trained: 6575000
    wait_time_ms: 72.843
  iterations_since_restore: 1315
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11449.038976430893
  time_this_iter_s: 8.571082353591919
  time_total_s: 11449.038976430893
  timestamp: 1594867494
  timesteps_since_restore: 6575000
  timesteps_this_iter: 5000
  timesteps_total: 6575000
  training_iteration: 1315
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11449 s, 1315 iter, 6575000 ts, -1.11e+05 rew

agent-1: -22382.36369435579
agent-2: -22742.320735167534
agent-3: -34021.118063931506
agent-4: -24092.203698468908
agent-5: -22434.22113423831
Extrinsic Rewards:
-22237
-22611
-33830
-23954
-22309
Sum Reward: -124941
Avg Reward: -24988.2
Min Reward: -33830
Max Reward: -22237
Gini Coefficient: -0.07949672245299781
20:20 Ratio: 0.6573159917233224
Max-min Ratio: 0.6573159917233224
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-45-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -45215.10107403114
  episode_reward_mean: -111305.67612521938
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 1
  episodes_total: 1315
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.672
    dispatch_time_ms: 7.829
    learner:
      cur_lr: 0.0009221049840562046
      grad_gnorm: 40.0
      policy_entropy: 26.48113250732422
      policy_loss: -8621.8369140625
      var_gnorm: 207.9242706298828
      vf_explained_var: 0.0
      vf_loss: 3077442.5
    num_steps_sampled: 6580000
    num_steps_trained: 6580000
    wait_time_ms: 75.548
  iterations_since_restore: 1316
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11457.65835762024
  time_this_iter_s: 8.619381189346313
  time_total_s: 11457.65835762024
  timestamp: 1594867503
  timesteps_since_restore: 6580000
  timesteps_this_iter: 5000
  timesteps_total: 6580000
  training_iteration: 1316
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11457 s, 1316 iter, 6580000 ts, -1.11e+05 rew

agent-1: -24517.05825421962
agent-2: -29230.177862799315
agent-3: -24979.30552579505
agent-4: -38420.37567180676
agent-5: -34181.37543966816
Extrinsic Rewards:
-24397
-29085
-24862
-38251
-34017
Sum Reward: -150612
Avg Reward: -30122.4
Min Reward: -38251
Max Reward: -24397
Gini Coefficient: -0.09790189360741508
20:20 Ratio: 0.6378133904995947
Max-min Ratio: 0.6378133904995947
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-45-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -45215.10107403114
  episode_reward_mean: -111523.9456944189
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 1
  episodes_total: 1316
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.934
    dispatch_time_ms: 9.592
    learner:
      cur_lr: 0.0009217719780281186
      grad_gnorm: 40.0
      policy_entropy: 24.61054801940918
      policy_loss: -7039.59228515625
      var_gnorm: 208.40037536621094
      vf_explained_var: 0.0
      vf_loss: 1463866.875
    num_steps_sampled: 6585000
    num_steps_trained: 6585000
    wait_time_ms: 74.681
  iterations_since_restore: 1317
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11466.188977003098
  time_this_iter_s: 8.530619382858276
  time_total_s: 11466.188977003098
  timestamp: 1594867512
  timesteps_since_restore: 6585000
  timesteps_this_iter: 5000
  timesteps_total: 6585000
  training_iteration: 1317
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11466 s, 1317 iter, 6585000 ts, -1.12e+05 rew

agent-1: -24891.039471670356
agent-2: -41144.03192218025
agent-3: -33090.56826126492
agent-4: -30342.32058531431
agent-5: -33426.95033316512
Extrinsic Rewards:
-24779
-40965
-32937
-30211
-33275
Sum Reward: -162167
Avg Reward: -32433.4
Min Reward: -40965
Max Reward: -24779
Gini Coefficient: -0.08740619238192728
20:20 Ratio: 0.6048822165263029
Max-min Ratio: 0.6048822165263029
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-45-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -45215.10107403114
  episode_reward_mean: -111922.7166095921
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 1
  episodes_total: 1317
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.009
    dispatch_time_ms: 9.245
    learner:
      cur_lr: 0.0009214389720000327
      grad_gnorm: 39.999996185302734
      policy_entropy: 18.846725463867188
      policy_loss: -1499.0703125
      var_gnorm: 208.86532592773438
      vf_explained_var: 0.0
      vf_loss: 3553109.75
    num_steps_sampled: 6590000
    num_steps_trained: 6590000
    wait_time_ms: 74.573
  iterations_since_restore: 1318
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11474.71606206894
  time_this_iter_s: 8.527085065841675
  time_total_s: 11474.71606206894
  timestamp: 1594867520
  timesteps_since_restore: 6590000
  timesteps_this_iter: 5000
  timesteps_total: 6590000
  training_iteration: 1318
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11474 s, 1318 iter, 6590000 ts, -1.12e+05 rew

agent-1: -31014.493273042353
agent-2: -39545.632445662355
agent-3: -25908.189514753914
agent-4: -38902.543382780255
agent-5: -15701.146123104174
Extrinsic Rewards:
-30860
-39366
-25782
-38726
-15622
Sum Reward: -150356
Avg Reward: -30071.2
Min Reward: -39366
Max Reward: -15622
Gini Coefficient: -0.16077043816010003
20:20 Ratio: 0.3968399126149469
Max-min Ratio: 0.3968399126149469
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-45-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -45215.10107403114
  episode_reward_mean: -112036.37019813621
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 1
  episodes_total: 1318
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.949
    dispatch_time_ms: 7.606
    learner:
      cur_lr: 0.0009211060241796076
      grad_gnorm: 39.999996185302734
      policy_entropy: 23.356651306152344
      policy_loss: -5106.84228515625
      var_gnorm: 209.3607635498047
      vf_explained_var: 0.0
      vf_loss: 1441190.125
    num_steps_sampled: 6595000
    num_steps_trained: 6595000
    wait_time_ms: 75.124
  iterations_since_restore: 1319
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11483.185550928116
  time_this_iter_s: 8.469488859176636
  time_total_s: 11483.185550928116
  timestamp: 1594867529
  timesteps_since_restore: 6595000
  timesteps_this_iter: 5000
  timesteps_total: 6595000
  training_iteration: 1319
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11483 s, 1319 iter, 6595000 ts, -1.12e+05 rew

agent-1: -48141.84491678838
agent-2: -31742.685583889648
agent-3: -22359.72933687258
agent-4: -35261.03644170785
agent-5: -21445.501760125502
Extrinsic Rewards:
-47935
-31593
-22255
-35098
-21343
Sum Reward: -158224
Avg Reward: -31644.8
Min Reward: -47935
Max Reward: -21343
Gini Coefficient: -0.166920315502073
20:20 Ratio: 0.4452487743819756
Max-min Ratio: 0.4452487743819756
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-45-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -45215.10107403114
  episode_reward_mean: -112411.82682891525
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 1
  episodes_total: 1319
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.641
    dispatch_time_ms: 8.108
    learner:
      cur_lr: 0.0009207730181515217
      grad_gnorm: 40.0
      policy_entropy: 30.0059814453125
      policy_loss: -6781.85595703125
      var_gnorm: 209.80258178710938
      vf_explained_var: 0.0
      vf_loss: 1752996.875
    num_steps_sampled: 6600000
    num_steps_trained: 6600000
    wait_time_ms: 76.084
  iterations_since_restore: 1320
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11491.83966588974
  time_this_iter_s: 8.654114961624146
  time_total_s: 11491.83966588974
  timestamp: 1594867537
  timesteps_since_restore: 6600000
  timesteps_this_iter: 5000
  timesteps_total: 6600000
  training_iteration: 1320
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11491 s, 1320 iter, 6600000 ts, -1.12e+05 rew

agent-1: -21539.407071615467
agent-2: -40853.656436067075
agent-3: -32119.80515883122
agent-4: -29240.25232917241
agent-5: -32888.36214904297
Extrinsic Rewards:
-21440
-40672
-31978
-29098
-32743
Sum Reward: -155931
Avg Reward: -31186.2
Min Reward: -40672
Max Reward: -21440
Gini Coefficient: -0.1080195727597463
20:20 Ratio: 0.5271439811172305
Max-min Ratio: 0.5271439811172305
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-45-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -45215.10107403114
  episode_reward_mean: -112651.29255323399
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 1
  episodes_total: 1320
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.967
    dispatch_time_ms: 8.402
    learner:
      cur_lr: 0.0009204400121234357
      grad_gnorm: 40.0
      policy_entropy: 20.30397605895996
      policy_loss: -2523.612548828125
      var_gnorm: 210.25245666503906
      vf_explained_var: 0.0
      vf_loss: 1883555.25
    num_steps_sampled: 6605000
    num_steps_trained: 6605000
    wait_time_ms: 72.562
  iterations_since_restore: 1321
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11500.329473018646
  time_this_iter_s: 8.48980712890625
  time_total_s: 11500.329473018646
  timestamp: 1594867546
  timesteps_since_restore: 6605000
  timesteps_this_iter: 5000
  timesteps_total: 6605000
  training_iteration: 1321
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11500 s, 1321 iter, 6605000 ts, -1.13e+05 rew

agent-1: -36193.589729747575
agent-2: -40038.34346620152
agent-3: -33830.66079928726
agent-4: -36276.46420098245
agent-5: -42962.25837928961
Extrinsic Rewards:
-36044
-39887
-33696
-36133
-42799
Sum Reward: -188559
Avg Reward: -37711.8
Min Reward: -42799
Max Reward: -33696
Gini Coefficient: -0.04677368887191807
20:20 Ratio: 0.7873081146755765
Max-min Ratio: 0.7873081146755765
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-45-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -45215.10107403114
  episode_reward_mean: -113579.17698637674
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 1
  episodes_total: 1321
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.058
    dispatch_time_ms: 6.497
    learner:
      cur_lr: 0.0009201070060953498
      grad_gnorm: 40.0
      policy_entropy: 17.733572006225586
      policy_loss: -3343.249755859375
      var_gnorm: 210.7507781982422
      vf_explained_var: 0.0
      vf_loss: 3881057.25
    num_steps_sampled: 6610000
    num_steps_trained: 6610000
    wait_time_ms: 74.592
  iterations_since_restore: 1322
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11508.894156455994
  time_this_iter_s: 8.564683437347412
  time_total_s: 11508.894156455994
  timestamp: 1594867555
  timesteps_since_restore: 6610000
  timesteps_this_iter: 5000
  timesteps_total: 6610000
  training_iteration: 1322
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11508 s, 1322 iter, 6610000 ts, -1.14e+05 rew

agent-1: -35052.096681518415
agent-2: -55523.96363930247
agent-3: -34125.43479076998
agent-4: -19849.946114167535
agent-5: -31181.494606331195
Extrinsic Rewards:
-34898
-55326
-33976
-19760
-31045
Sum Reward: -175005
Avg Reward: -35001.0
Min Reward: -55326
Max Reward: -19760
Gini Coefficient: -0.1713893888746036
20:20 Ratio: 0.3571557676318548
Max-min Ratio: 0.3571557676318548
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-46-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -45215.10107403114
  episode_reward_mean: -114070.92372254001
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 1
  episodes_total: 1322
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.12
    dispatch_time_ms: 7.502
    learner:
      cur_lr: 0.0009197740000672638
      grad_gnorm: 40.0
      policy_entropy: 13.780357360839844
      policy_loss: -305.8166198730469
      var_gnorm: 211.23655700683594
      vf_explained_var: 0.0
      vf_loss: 1853493.375
    num_steps_sampled: 6615000
    num_steps_trained: 6615000
    wait_time_ms: 75.276
  iterations_since_restore: 1323
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11517.422332525253
  time_this_iter_s: 8.528176069259644
  time_total_s: 11517.422332525253
  timestamp: 1594867563
  timesteps_since_restore: 6615000
  timesteps_this_iter: 5000
  timesteps_total: 6615000
  training_iteration: 1323
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11517 s, 1323 iter, 6615000 ts, -1.14e+05 rew

agent-1: -35438.34150173181
agent-2: -19420.44669660461
agent-3: -40366.40687991975
agent-4: -28829.25935193297
agent-5: -21207.821352437524
Extrinsic Rewards:
-35272
-19323
-40180
-28688
-21100
Sum Reward: -144563
Avg Reward: -28912.6
Min Reward: -40180
Max Reward: -19323
Gini Coefficient: -0.1546343116841792
20:20 Ratio: 0.4809109009457441
Max-min Ratio: 0.4809109009457441
agent-1: -45460.70333422754
agent-2: -31903.45621594666
agent-3: -31759.548404198547
agent-4: -37949.88495434789
agent-5: -25901.69696025651
Extrinsic Rewards:
-45280
-31776
-31628
-37781
-25786
Sum Reward: -172251
Avg Reward: -34450.2
Min Reward: -45280
Max Reward: -25786
Gini Coefficient: -0.10482609680059912
20:20 Ratio: 0.5694787985865725
Max-min Ratio: 0.5694787985865725
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-46-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -45215.10107403114
  episode_reward_mean: -114545.00583431698
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 1
  episodes_total: 1323
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.746
    dispatch_time_ms: 28.212
    learner:
      cur_lr: 0.0009194409940391779
      grad_gnorm: 40.000003814697266
      policy_entropy: 19.762939453125
      policy_loss: -2001.921875
      var_gnorm: 211.7098846435547
      vf_explained_var: -0.1761019229888916
      vf_loss: 678684.1875
    num_steps_sampled: 6620000
    num_steps_trained: 6620000
    wait_time_ms: 39.909
  iterations_since_restore: 1324
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11526.718935966492
  time_this_iter_s: 9.296603441238403
  time_total_s: 11526.718935966492
  timestamp: 1594867572
  timesteps_since_restore: 6620000
  timesteps_this_iter: 5000
  timesteps_total: 6620000
  training_iteration: 1324
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11526 s, 1324 iter, 6620000 ts, -1.15e+05 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-46-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -45215.10107403114
  episode_reward_mean: -115261.39900130212
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 1
  episodes_total: 1324
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.313
    dispatch_time_ms: 25.603
    learner:
      cur_lr: 0.000919107988011092
      grad_gnorm: 40.0
      policy_entropy: 22.47773551940918
      policy_loss: -1720.2757568359375
      var_gnorm: 212.14950561523438
      vf_explained_var: 0.0
      vf_loss: 1576814.625
    num_steps_sampled: 6625000
    num_steps_trained: 6625000
    wait_time_ms: 64.07
  iterations_since_restore: 1325
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11535.757963895798
  time_this_iter_s: 9.03902792930603
  time_total_s: 11535.757963895798
  timestamp: 1594867581
  timesteps_since_restore: 6625000
  timesteps_this_iter: 5000
  timesteps_total: 6625000
  training_iteration: 1325
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11535 s, 1325 iter, 6625000 ts, -1.15e+05 rew

agent-1: -28253.382113207288
agent-2: -37020.20114271935
agent-3: -21783.34331548744
agent-4: -10212.326880623168
agent-5: -34607.601287092155
Extrinsic Rewards:
-28098
-36831
-21657
-10148
-34425
Sum Reward: -131159
Avg Reward: -26231.8
Min Reward: -36831
Max Reward: -10148
Gini Coefficient: -0.20169107724212598
20:20 Ratio: 0.27552876652819636
Max-min Ratio: 0.27552876652819636
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-46-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -45215.10107403114
  episode_reward_mean: -115505.55586480256
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 1
  episodes_total: 1325
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.207
    dispatch_time_ms: 6.898
    learner:
      cur_lr: 0.000918774981983006
      grad_gnorm: 39.999996185302734
      policy_entropy: 21.736764907836914
      policy_loss: 75.65433502197266
      var_gnorm: 212.60166931152344
      vf_explained_var: 0.0
      vf_loss: 819558.4375
    num_steps_sampled: 6630000
    num_steps_trained: 6630000
    wait_time_ms: 76.019
  iterations_since_restore: 1326
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11544.509215831757
  time_this_iter_s: 8.751251935958862
  time_total_s: 11544.509215831757
  timestamp: 1594867590
  timesteps_since_restore: 6630000
  timesteps_this_iter: 5000
  timesteps_total: 6630000
  training_iteration: 1326
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11544 s, 1326 iter, 6630000 ts, -1.16e+05 rew

agent-1: -35403.36225898738
agent-2: -42349.27213597155
agent-3: -41165.35384388713
agent-4: -40230.931751483666
agent-5: -29298.72984523309
Extrinsic Rewards:
-35258
-42189
-41012
-40072
-29183
Sum Reward: -187714
Avg Reward: -37542.8
Min Reward: -42189
Max Reward: -29183
Gini Coefficient: -0.06769020957413938
20:20 Ratio: 0.6917205906752945
Max-min Ratio: 0.6917205906752945
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-46-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -45215.10107403114
  episode_reward_mean: -116139.39161855273
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 1
  episodes_total: 1326
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.769
    dispatch_time_ms: 6.499
    learner:
      cur_lr: 0.00091844197595492
      grad_gnorm: 40.0
      policy_entropy: 24.129451751708984
      policy_loss: -2704.349609375
      var_gnorm: 213.00787353515625
      vf_explained_var: 0.0
      vf_loss: 746171.6875
    num_steps_sampled: 6635000
    num_steps_trained: 6635000
    wait_time_ms: 77.459
  iterations_since_restore: 1327
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11552.96049618721
  time_this_iter_s: 8.451280355453491
  time_total_s: 11552.96049618721
  timestamp: 1594867599
  timesteps_since_restore: 6635000
  timesteps_this_iter: 5000
  timesteps_total: 6635000
  training_iteration: 1327
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11552 s, 1327 iter, 6635000 ts, -1.16e+05 rew

agent-1: -33997.20624414062
agent-2: -23431.106341177074
agent-3: -25542.077508565453
agent-4: -26720.125249980247
agent-5: -26679.79970338864
Extrinsic Rewards:
-33812
-23290
-25407
-26588
-26551
Sum Reward: -135648
Avg Reward: -27129.6
Min Reward: -33812
Max Reward: -23290
Gini Coefficient: -0.06553727294173153
20:20 Ratio: 0.6888087069679404
Max-min Ratio: 0.6888087069679404
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-46-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -45215.10107403114
  episode_reward_mean: -116545.43276444043
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 1
  episodes_total: 1327
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.843
    dispatch_time_ms: 7.128
    learner:
      cur_lr: 0.000918109028134495
      grad_gnorm: 40.0
      policy_entropy: 31.82635498046875
      policy_loss: -2045.6414794921875
      var_gnorm: 213.44371032714844
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 456303.6875
    num_steps_sampled: 6640000
    num_steps_trained: 6640000
    wait_time_ms: 74.285
  iterations_since_restore: 1328
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11561.445043802261
  time_this_iter_s: 8.48454761505127
  time_total_s: 11561.445043802261
  timestamp: 1594867607
  timesteps_since_restore: 6640000
  timesteps_this_iter: 5000
  timesteps_total: 6640000
  training_iteration: 1328
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11561 s, 1328 iter, 6640000 ts, -1.17e+05 rew

agent-1: -22224.385769719378
agent-2: -24437.34852236882
agent-3: -23582.38872591459
agent-4: -23718.839787930945
agent-5: -31043.97664732971
Extrinsic Rewards:
-22095
-24296
-23436
-23583
-30878
Sum Reward: -124288
Avg Reward: -24857.6
Min Reward: -30878
Max Reward: -22095
Gini Coefficient: -0.059300978372811536
20:20 Ratio: 0.7155580024612993
Max-min Ratio: 0.7155580024612993
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-46-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -45215.10107403114
  episode_reward_mean: -116556.09512383492
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 1
  episodes_total: 1328
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.732
    dispatch_time_ms: 8.755
    learner:
      cur_lr: 0.0009177760221064091
      grad_gnorm: 40.0
      policy_entropy: 38.96913146972656
      policy_loss: -3752.887451171875
      var_gnorm: 213.88514709472656
      vf_explained_var: 0.0
      vf_loss: 1596814.0
    num_steps_sampled: 6645000
    num_steps_trained: 6645000
    wait_time_ms: 74.39
  iterations_since_restore: 1329
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11569.915222883224
  time_this_iter_s: 8.470179080963135
  time_total_s: 11569.915222883224
  timestamp: 1594867616
  timesteps_since_restore: 6645000
  timesteps_this_iter: 5000
  timesteps_total: 6645000
  training_iteration: 1329
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11569 s, 1329 iter, 6645000 ts, -1.17e+05 rew

agent-1: -30685.959188036344
agent-2: -32227.47262901172
agent-3: -27463.779156492186
agent-4: -29741.13273330256
agent-5: -36611.94508163348
Extrinsic Rewards:
-30532
-32082
-27342
-29591
-36441
Sum Reward: -155988
Avg Reward: -31197.6
Min Reward: -36441
Max Reward: -27342
Gini Coefficient: -0.05305279893325127
20:20 Ratio: 0.7503087182020252
Max-min Ratio: 0.7503087182020252
agent-1: -33796.815340366935
agent-2: -19695.30310190162
agent-3: -32541.46820351098
agent-4: -28678.50123844462
agent-5: -30324.474934812206
Extrinsic Rewards:
-33633
-19593
-32378
-28516
-30178
Sum Reward: -144298
Avg Reward: -28859.6
Min Reward: -33633
Max Reward: -19593
Gini Coefficient: -0.08854453977186101
20:20 Ratio: 0.5825528498795826
Max-min Ratio: 0.5825528498795826
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-47-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -45215.10107403114
  episode_reward_mean: -116966.08902135713
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 2
  episodes_total: 1330
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.617
    dispatch_time_ms: 7.35
    learner:
      cur_lr: 0.0009174430160783231
      grad_gnorm: 40.0
      policy_entropy: 34.786434173583984
      policy_loss: 24399.404296875
      var_gnorm: 214.37127685546875
      vf_explained_var: 0.0
      vf_loss: 17837084.0
    num_steps_sampled: 6650000
    num_steps_trained: 6650000
    wait_time_ms: 77.262
  iterations_since_restore: 1330
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11578.469335079193
  time_this_iter_s: 8.554112195968628
  time_total_s: 11578.469335079193
  timestamp: 1594867624
  timesteps_since_restore: 6650000
  timesteps_this_iter: 5000
  timesteps_total: 6650000
  training_iteration: 1330
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11578 s, 1330 iter, 6650000 ts, -1.17e+05 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-47-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -45215.10107403114
  episode_reward_mean: -116966.08902135713
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 0
  episodes_total: 1330
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.351
    dispatch_time_ms: 7.696
    learner:
      cur_lr: 0.0009171100100502372
      grad_gnorm: 40.0
      policy_entropy: 37.8519287109375
      policy_loss: -221.8937225341797
      var_gnorm: 214.7977294921875
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 191305.8125
    num_steps_sampled: 6655000
    num_steps_trained: 6655000
    wait_time_ms: 73.868
  iterations_since_restore: 1331
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11586.938763141632
  time_this_iter_s: 8.469428062438965
  time_total_s: 11586.938763141632
  timestamp: 1594867633
  timesteps_since_restore: 6655000
  timesteps_this_iter: 5000
  timesteps_total: 6655000
  training_iteration: 1331
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11586 s, 1331 iter, 6655000 ts, -1.17e+05 rew

agent-1: -29328.64011887802
agent-2: -28676.42976413457
agent-3: -24969.832846065543
agent-4: -28150.930588163686
agent-5: -30865.524446209598
Extrinsic Rewards:
-29172
-28527
-24838
-28000
-30703
Sum Reward: -141240
Avg Reward: -28248.0
Min Reward: -30703
Max Reward: -24838
Gini Coefficient: -0.03653922401585953
20:20 Ratio: 0.8089763215320979
Max-min Ratio: 0.8089763215320979
agent-1: -34389.30062606439
agent-2: -19671.590870688473
agent-3: -22653.399715846343
agent-4: -23944.43858753519
agent-5: -27840.176164876622
Extrinsic Rewards:
-34199
-19555
-22521
-23799
-27685
Sum Reward: -127759
Avg Reward: -25551.8
Min Reward: -34199
Max Reward: -19555
Gini Coefficient: -0.10786559068245681
20:20 Ratio: 0.5718003450393286
Max-min Ratio: 0.5718003450393286
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-47-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -45215.10107403114
  episode_reward_mean: -116629.3084572539
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 2
  episodes_total: 1332
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.447
    dispatch_time_ms: 7.387
    learner:
      cur_lr: 0.0009167770040221512
      grad_gnorm: 40.0
      policy_entropy: 28.289051055908203
      policy_loss: 17585.29296875
      var_gnorm: 215.19931030273438
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 19281732.0
    num_steps_sampled: 6660000
    num_steps_trained: 6660000
    wait_time_ms: 75.603
  iterations_since_restore: 1332
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11595.472310304642
  time_this_iter_s: 8.533547163009644
  time_total_s: 11595.472310304642
  timestamp: 1594867641
  timesteps_since_restore: 6660000
  timesteps_this_iter: 5000
  timesteps_total: 6660000
  training_iteration: 1332
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11595 s, 1332 iter, 6660000 ts, -1.17e+05 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-47-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -45215.10107403114
  episode_reward_mean: -116629.3084572539
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 0
  episodes_total: 1332
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.118
    dispatch_time_ms: 7.316
    learner:
      cur_lr: 0.0009164439979940653
      grad_gnorm: 39.999996185302734
      policy_entropy: 21.890663146972656
      policy_loss: -3284.485595703125
      var_gnorm: 215.6478729248047
      vf_explained_var: 0.0
      vf_loss: 1354068.25
    num_steps_sampled: 6665000
    num_steps_trained: 6665000
    wait_time_ms: 74.368
  iterations_since_restore: 1333
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11603.989852428436
  time_this_iter_s: 8.517542123794556
  time_total_s: 11603.989852428436
  timestamp: 1594867650
  timesteps_since_restore: 6665000
  timesteps_this_iter: 5000
  timesteps_total: 6665000
  training_iteration: 1333
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11603 s, 1333 iter, 6665000 ts, -1.17e+05 rew

agent-1: -22324.41896420345
agent-2: -38749.571621930496
agent-3: -42372.41716088688
agent-4: -54814.796086803006
agent-5: -28867.575031242195
Extrinsic Rewards:
-22234
-38598
-42224
-54612
-28735
Sum Reward: -186403
Avg Reward: -37280.6
Min Reward: -54612
Max Reward: -22234
Gini Coefficient: -0.16790502298782745
20:20 Ratio: 0.4071266388339559
Max-min Ratio: 0.4071266388339559
agent-1: -34587.17031170163
agent-2: -42494.005851591704
agent-3: -39715.75878948959
agent-4: -25144.374054656157
agent-5: -47895.90064376727
Extrinsic Rewards:
-34443
-42330
-39566
-25029
-47730
Sum Reward: -189098
Avg Reward: -37819.6
Min Reward: -47730
Max Reward: -25029
Gini Coefficient: -0.11272250367534295
20:20 Ratio: 0.52438717787555
Max-min Ratio: 0.52438717787555
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-47-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -45215.10107403114
  episode_reward_mean: -117508.65164399201
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 2
  episodes_total: 1334
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.963
    dispatch_time_ms: 8.183
    learner:
      cur_lr: 0.0009161109919659793
      grad_gnorm: 40.000003814697266
      policy_entropy: 27.344987869262695
      policy_loss: 9655.4130859375
      var_gnorm: 216.15037536621094
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 13532060.0
    num_steps_sampled: 6670000
    num_steps_trained: 6670000
    wait_time_ms: 72.936
  iterations_since_restore: 1334
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11612.46760892868
  time_this_iter_s: 8.47775650024414
  time_total_s: 11612.46760892868
  timestamp: 1594867658
  timesteps_since_restore: 6670000
  timesteps_this_iter: 5000
  timesteps_total: 6670000
  training_iteration: 1334
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11612 s, 1334 iter, 6670000 ts, -1.18e+05 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-47-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -45215.10107403114
  episode_reward_mean: -117508.65164399201
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 0
  episodes_total: 1334
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.016
    dispatch_time_ms: 6.857
    learner:
      cur_lr: 0.0009157779859378934
      grad_gnorm: 39.999996185302734
      policy_entropy: 25.066349029541016
      policy_loss: -5339.27978515625
      var_gnorm: 216.5563201904297
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 796333.375
    num_steps_sampled: 6675000
    num_steps_trained: 6675000
    wait_time_ms: 74.492
  iterations_since_restore: 1335
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11621.00646018982
  time_this_iter_s: 8.538851261138916
  time_total_s: 11621.00646018982
  timestamp: 1594867667
  timesteps_since_restore: 6675000
  timesteps_this_iter: 5000
  timesteps_total: 6675000
  training_iteration: 1335
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11621 s, 1335 iter, 6675000 ts, -1.18e+05 rew

agent-1: -22079.38677798949
agent-2: -25439.74594453061
agent-3: -34509.40812636759
agent-4: -30972.61952780384
agent-5: -31217.069514016992
Extrinsic Rewards:
-21966
-25301
-34347
-30816
-31062
Sum Reward: -143492
Avg Reward: -28698.4
Min Reward: -34347
Max Reward: -21966
Gini Coefficient: -0.08508627658684804
20:20 Ratio: 0.6395318368416456
Max-min Ratio: 0.6395318368416456
agent-1: -39684.88430911027
agent-2: -41750.741720661004
agent-3: -21742.330030881065
agent-4: -35564.77319372147
agent-5: -29870.21198191983
Extrinsic Rewards:
-39516
-41577
-21655
-35411
-29732
Sum Reward: -167891
Avg Reward: -33578.2
Min Reward: -41577
Max Reward: -21655
Gini Coefficient: -0.11823861910406157
20:20 Ratio: 0.5208408495081415
Max-min Ratio: 0.5208408495081415
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-47-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -45215.10107403114
  episode_reward_mean: -117959.18631264636
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 2
  episodes_total: 1336
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.112
    dispatch_time_ms: 9.474
    learner:
      cur_lr: 0.0009154449799098074
      grad_gnorm: 39.999996185302734
      policy_entropy: 25.701391220092773
      policy_loss: 12893.8916015625
      var_gnorm: 217.03738403320312
      vf_explained_var: 0.0
      vf_loss: 9503601.0
    num_steps_sampled: 6680000
    num_steps_trained: 6680000
    wait_time_ms: 72.634
  iterations_since_restore: 1336
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11629.492778539658
  time_this_iter_s: 8.486318349838257
  time_total_s: 11629.492778539658
  timestamp: 1594867676
  timesteps_since_restore: 6680000
  timesteps_this_iter: 5000
  timesteps_total: 6680000
  training_iteration: 1336
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11629 s, 1336 iter, 6680000 ts, -1.18e+05 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-48-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -45215.10107403114
  episode_reward_mean: -117959.18631264634
  episode_reward_min: -200836.80196607107
  episodes_this_iter: 0
  episodes_total: 1336
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.237
    dispatch_time_ms: 8.917
    learner:
      cur_lr: 0.0009151119738817215
      grad_gnorm: 40.0
      policy_entropy: 31.319217681884766
      policy_loss: -1352.3338623046875
      var_gnorm: 217.4320831298828
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 631219.6875
    num_steps_sampled: 6685000
    num_steps_trained: 6685000
    wait_time_ms: 73.245
  iterations_since_restore: 1337
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11638.00437259674
  time_this_iter_s: 8.51159405708313
  time_total_s: 11638.00437259674
  timestamp: 1594867684
  timesteps_since_restore: 6685000
  timesteps_this_iter: 5000
  timesteps_total: 6685000
  training_iteration: 1337
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11638 s, 1337 iter, 6685000 ts, -1.18e+05 rew

agent-1: -27743.278049239663
agent-2: -27787.521680390946
agent-3: -23433.75754192556
agent-4: -16158.80025353903
agent-5: -25812.880508735816
Extrinsic Rewards:
-27581
-27629
-23285
-16056
-25660
Sum Reward: -120211
Avg Reward: -24042.2
Min Reward: -27629
Max Reward: -16056
Gini Coefficient: -0.09131277503722621
20:20 Ratio: 0.5811285243765608
Max-min Ratio: 0.5811285243765608
agent-1: -21969.77031050154
agent-2: -35709.51942171319
agent-3: -33454.290539601825
agent-4: -38995.65068476184
agent-5: -23753.657711242395
Extrinsic Rewards:
-21860
-35540
-33288
-38816
-23640
Sum Reward: -153144
Avg Reward: -30628.8
Min Reward: -38816
Max Reward: -21860
Gini Coefficient: -0.11965731599017917
20:20 Ratio: 0.5631698268755152
Max-min Ratio: 0.5631698268755152
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-48-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -45215.10107403114
  episode_reward_mean: -117589.01370060562
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 2
  episodes_total: 1338
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.452
    dispatch_time_ms: 906.442
    learner:
      cur_lr: 0.0009147790260612965
      grad_gnorm: 40.0
      policy_entropy: 31.3796329498291
      policy_loss: 24619.734375
      var_gnorm: 217.85848999023438
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 20345376.0
    num_steps_sampled: 6690000
    num_steps_trained: 6690000
    wait_time_ms: 61.498
  iterations_since_restore: 1338
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11655.306364536285
  time_this_iter_s: 17.301991939544678
  time_total_s: 11655.306364536285
  timestamp: 1594867701
  timesteps_since_restore: 6690000
  timesteps_this_iter: 5000
  timesteps_total: 6690000
  training_iteration: 1338
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11655 s, 1338 iter, 6690000 ts, -1.18e+05 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-48-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -45215.10107403114
  episode_reward_mean: -117589.01370060563
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 0
  episodes_total: 1338
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.462
    dispatch_time_ms: 7.995
    learner:
      cur_lr: 0.0009144460200332105
      grad_gnorm: 40.000003814697266
      policy_entropy: 31.776832580566406
      policy_loss: -2987.025146484375
      var_gnorm: 218.271728515625
      vf_explained_var: 0.0
      vf_loss: 489260.90625
    num_steps_sampled: 6695000
    num_steps_trained: 6695000
    wait_time_ms: 74.801
  iterations_since_restore: 1339
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11663.245425462723
  time_this_iter_s: 7.939060926437378
  time_total_s: 11663.245425462723
  timestamp: 1594867709
  timesteps_since_restore: 6695000
  timesteps_this_iter: 5000
  timesteps_total: 6695000
  training_iteration: 1339
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11663 s, 1339 iter, 6695000 ts, -1.18e+05 rew

agent-1: -32000.218964259813
agent-2: -37219.701338779734
agent-3: -29044.057659868104
agent-4: -28227.961567015653
agent-5: -26937.679934160846
Extrinsic Rewards:
-31846
-37039
-28915
-28100
-26800
Sum Reward: -152700
Avg Reward: -30540.0
Min Reward: -37039
Max Reward: -26800
Gini Coefficient: -0.06345514079895219
20:20 Ratio: 0.7235616512324847
Max-min Ratio: 0.7235616512324847
agent-1: -28437.326635664518
agent-2: -21894.776909227738
agent-3: -33780.89748678166
agent-4: -37280.23094078521
agent-5: -29563.32015086582
Extrinsic Rewards:
-28296
-21777
-33626
-37107
-29414
Sum Reward: -150220
Avg Reward: -30044.0
Min Reward: -37107
Max Reward: -21777
Gini Coefficient: -0.09583277859139928
20:20 Ratio: 0.586870401810979
Max-min Ratio: 0.586870401810979
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-48-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -45215.10107403114
  episode_reward_mean: -117911.12272547897
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 2
  episodes_total: 1340
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.626
    dispatch_time_ms: 6.113
    learner:
      cur_lr: 0.0009141130140051246
      grad_gnorm: 40.0
      policy_entropy: 29.65194320678711
      policy_loss: -3152.4853515625
      var_gnorm: 218.6736297607422
      vf_explained_var: -0.05453968048095703
      vf_loss: 897139.6875
    num_steps_sampled: 6700000
    num_steps_trained: 6700000
    wait_time_ms: 76.424
  iterations_since_restore: 1340
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11671.758988380432
  time_this_iter_s: 8.51356291770935
  time_total_s: 11671.758988380432
  timestamp: 1594867718
  timesteps_since_restore: 6700000
  timesteps_this_iter: 5000
  timesteps_total: 6700000
  training_iteration: 1340
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11671 s, 1340 iter, 6700000 ts, -1.18e+05 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-48-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -45215.10107403114
  episode_reward_mean: -117911.12272547896
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 0
  episodes_total: 1340
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.289
    dispatch_time_ms: 7.004
    learner:
      cur_lr: 0.0009137800079770386
      grad_gnorm: 40.000003814697266
      policy_entropy: 16.777393341064453
      policy_loss: -362.3516540527344
      var_gnorm: 219.11199951171875
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 360763.4375
    num_steps_sampled: 6705000
    num_steps_trained: 6705000
    wait_time_ms: 76.171
  iterations_since_restore: 1341
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11680.261496305466
  time_this_iter_s: 8.50250792503357
  time_total_s: 11680.261496305466
  timestamp: 1594867726
  timesteps_since_restore: 6705000
  timesteps_this_iter: 5000
  timesteps_total: 6705000
  training_iteration: 1341
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11680 s, 1341 iter, 6705000 ts, -1.18e+05 rew

agent-1: -19258.63071428388
agent-2: -40751.879286364965
agent-3: -26311.41840299287
agent-4: -26842.88743082845
agent-5: -28027.051195768523
Extrinsic Rewards:
-19162
-40558
-26173
-26699
-27902
Sum Reward: -140494
Avg Reward: -28098.8
Min Reward: -40558
Max Reward: -19162
Gini Coefficient: -0.12675559098609193
20:20 Ratio: 0.47245919424034716
Max-min Ratio: 0.47245919424034716
agent-1: -18282.949060658837
agent-2: -32217.840498248792
agent-3: -37480.31136533918
agent-4: -15894.903630459869
agent-5: -27946.188518322022
Extrinsic Rewards:
-18174
-32056
-37300
-15801
-27789
Sum Reward: -131120
Avg Reward: -26224.0
Min Reward: -37300
Max Reward: -15801
Gini Coefficient: -0.17352043929225136
20:20 Ratio: 0.42361930294906164
Max-min Ratio: 0.42361930294906164
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-48-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -45215.10107403114
  episode_reward_mean: -118530.85359554556
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1341
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.704
    dispatch_time_ms: 6.538
    learner:
      cur_lr: 0.0009134470019489527
      grad_gnorm: 40.000003814697266
      policy_entropy: 18.5236873626709
      policy_loss: 756.4819946289062
      var_gnorm: 219.55206298828125
      vf_explained_var: -1.0
      vf_loss: 61892.078125
    num_steps_sampled: 6710000
    num_steps_trained: 6710000
    wait_time_ms: 78.082
  iterations_since_restore: 1342
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11688.807406663895
  time_this_iter_s: 8.545910358428955
  time_total_s: 11688.807406663895
  timestamp: 1594867735
  timesteps_since_restore: 6710000
  timesteps_this_iter: 5000
  timesteps_total: 6710000
  training_iteration: 1342
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11688 s, 1342 iter, 6710000 ts, -1.19e+05 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-49-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -45215.10107403114
  episode_reward_mean: -119144.69306129737
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1342
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.962
    dispatch_time_ms: 6.548
    learner:
      cur_lr: 0.0009131139959208667
      grad_gnorm: 40.0
      policy_entropy: 27.54024314880371
      policy_loss: -2803.72998046875
      var_gnorm: 219.9382781982422
      vf_explained_var: 0.0
      vf_loss: 298488.125
    num_steps_sampled: 6715000
    num_steps_trained: 6715000
    wait_time_ms: 79.871
  iterations_since_restore: 1343
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11697.381597042084
  time_this_iter_s: 8.574190378189087
  time_total_s: 11697.381597042084
  timestamp: 1594867744
  timesteps_since_restore: 6715000
  timesteps_this_iter: 5000
  timesteps_total: 6715000
  training_iteration: 1343
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11697 s, 1343 iter, 6715000 ts, -1.19e+05 rew

agent-1: -20367.276014216277
agent-2: -25089.143731014898
agent-3: -28517.61541601305
agent-4: -20554.06160694905
agent-5: -18286.869165384986
Extrinsic Rewards:
-20239
-24936
-28341
-20432
-18161
Sum Reward: -112109
Avg Reward: -22421.8
Min Reward: -28341
Max Reward: -18161
Gini Coefficient: -0.08940227814002444
20:20 Ratio: 0.640803076814509
Max-min Ratio: 0.640803076814509
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-49-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -45215.10107403114
  episode_reward_mean: -119699.53612351445
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1343
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.567
    dispatch_time_ms: 5.875
    learner:
      cur_lr: 0.0009127809898927808
      grad_gnorm: 40.0
      policy_entropy: 49.149513244628906
      policy_loss: -754.4352416992188
      var_gnorm: 220.37432861328125
      vf_explained_var: -0.29791855812072754
      vf_loss: 170096.15625
    num_steps_sampled: 6720000
    num_steps_trained: 6720000
    wait_time_ms: 73.956
  iterations_since_restore: 1344
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11705.879580974579
  time_this_iter_s: 8.497983932495117
  time_total_s: 11705.879580974579
  timestamp: 1594867752
  timesteps_since_restore: 6720000
  timesteps_this_iter: 5000
  timesteps_total: 6720000
  training_iteration: 1344
  
agent-1: -40357.0073488636
agent-2: -28280.079611740377
agent-3: -34206.64100916399
agent-4: -23001.641834864073
agent-5: -21683.64373580421
Extrinsic Rewards:
-40177
-28135
-34043
-22882
-21560
Sum Reward: -146797
Avg Reward: -29359.4
Min Reward: -40177
Max Reward: -21560
Gini Coefficient: -0.13186917988787236
20:20 Ratio: 0.5366254324613585
Max-min Ratio: 0.5366254324613585
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11705 s, 1344 iter, 6720000 ts, -1.2e+05 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-49-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -69172.01601448357
  episode_reward_mean: -120722.67524817848
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1344
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.695
    dispatch_time_ms: 7.382
    learner:
      cur_lr: 0.0009124479838646948
      grad_gnorm: 40.0
      policy_entropy: 51.50743103027344
      policy_loss: 1273.521728515625
      var_gnorm: 220.7610626220703
      vf_explained_var: 0.0
      vf_loss: 52139.984375
    num_steps_sampled: 6725000
    num_steps_trained: 6725000
    wait_time_ms: 78.472
  iterations_since_restore: 1345
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11714.339339017868
  time_this_iter_s: 8.459758043289185
  time_total_s: 11714.339339017868
  timestamp: 1594867761
  timesteps_since_restore: 6725000
  timesteps_this_iter: 5000
  timesteps_total: 6725000
  training_iteration: 1345
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11714 s, 1345 iter, 6725000 ts, -1.21e+05 rew

agent-1: -22934.184644801764
agent-2: -19520.069906331464
agent-3: -23351.411375057487
agent-4: -23585.34596345935
agent-5: -19131.445476011322
Extrinsic Rewards:
-22782
-19388
-23195
-23423
-18988
Sum Reward: -107776
Avg Reward: -21555.2
Min Reward: -23423
Max Reward: -18988
Gini Coefficient: -0.047049435866983375
20:20 Ratio: 0.8106561926311745
Max-min Ratio: 0.8106561926311745
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-49-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -69172.01601448357
  episode_reward_mean: -120989.53396884791
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1345
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.827
    dispatch_time_ms: 7.064
    learner:
      cur_lr: 0.0009121149778366089
      grad_gnorm: 40.0
      policy_entropy: 53.96101379394531
      policy_loss: 51.37208557128906
      var_gnorm: 221.0407257080078
      vf_explained_var: 0.0
      vf_loss: 111891.953125
    num_steps_sampled: 6730000
    num_steps_trained: 6730000
    wait_time_ms: 75.139
  iterations_since_restore: 1346
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11722.70026087761
  time_this_iter_s: 8.360921859741211
  time_total_s: 11722.70026087761
  timestamp: 1594867769
  timesteps_since_restore: 6730000
  timesteps_this_iter: 5000
  timesteps_total: 6730000
  training_iteration: 1346
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11722 s, 1346 iter, 6730000 ts, -1.21e+05 rew

agent-1: -19204.462170860756
agent-2: -23418.403575644836
agent-3: -18135.73550960944
agent-4: -12483.533539137099
agent-5: -13189.585358063692
Extrinsic Rewards:
-19042
-23229
-17980
-12370
-13064
Sum Reward: -85685
Avg Reward: -17137.0
Min Reward: -23229
Max Reward: -12370
Gini Coefficient: -0.12929217482639901
20:20 Ratio: 0.5325240001721986
Max-min Ratio: 0.5325240001721986
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-49-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -69423.76657741933
  episode_reward_mean: -121162.13101023623
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1346
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.891
    dispatch_time_ms: 7.217
    learner:
      cur_lr: 0.0009117819718085229
      grad_gnorm: 39.999996185302734
      policy_entropy: 59.61058044433594
      policy_loss: -1901.9796142578125
      var_gnorm: 221.29608154296875
      vf_explained_var: 0.0
      vf_loss: 303433.15625
    num_steps_sampled: 6735000
    num_steps_trained: 6735000
    wait_time_ms: 71.254
  iterations_since_restore: 1347
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11730.912839651108
  time_this_iter_s: 8.212578773498535
  time_total_s: 11730.912839651108
  timestamp: 1594867777
  timesteps_since_restore: 6735000
  timesteps_this_iter: 5000
  timesteps_total: 6735000
  training_iteration: 1347
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11730 s, 1347 iter, 6735000 ts, -1.21e+05 rew

agent-1: -22613.073730933796
agent-2: -17874.31479110999
agent-3: -18529.795350481672
agent-4: -21595.815652978283
agent-5: -12203.81019487449
Extrinsic Rewards:
-22444
-17718
-18385
-21423
-12100
Sum Reward: -92070
Avg Reward: -18414.0
Min Reward: -22444
Max Reward: -12100
Gini Coefficient: -0.10597588791137179
20:20 Ratio: 0.5391195865264659
Max-min Ratio: 0.5391195865264659
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-49-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -69423.76657741933
  episode_reward_mean: -121258.16785666026
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1347
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.458
    dispatch_time_ms: 6.964
    learner:
      cur_lr: 0.0009114490239880979
      grad_gnorm: 40.000003814697266
      policy_entropy: 57.04713821411133
      policy_loss: -3427.947021484375
      var_gnorm: 221.625244140625
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 420653.46875
    num_steps_sampled: 6740000
    num_steps_trained: 6740000
    wait_time_ms: 70.295
  iterations_since_restore: 1348
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11739.191580533981
  time_this_iter_s: 8.278740882873535
  time_total_s: 11739.191580533981
  timestamp: 1594867786
  timesteps_since_restore: 6740000
  timesteps_this_iter: 5000
  timesteps_total: 6740000
  training_iteration: 1348
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11739 s, 1348 iter, 6740000 ts, -1.21e+05 rew

agent-1: -17406.107841722765
agent-2: -22344.05574764581
agent-3: -14110.228224537073
agent-4: -15601.288918984732
agent-5: -17876.444754475116
Extrinsic Rewards:
-17249
-22162
-13978
-15467
-17722
Sum Reward: -86578
Avg Reward: -17315.6
Min Reward: -22162
Max Reward: -13978
Gini Coefficient: -0.08604033357203908
20:20 Ratio: 0.6307192491652378
Max-min Ratio: 0.6307192491652378
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-49-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -69423.76657741933
  episode_reward_mean: -121228.12985270491
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1348
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.178
    dispatch_time_ms: 9.314
    learner:
      cur_lr: 0.000911116017960012
      grad_gnorm: 40.0
      policy_entropy: 57.416622161865234
      policy_loss: -1108.2236328125
      var_gnorm: 221.81488037109375
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 55981.7578125
    num_steps_sampled: 6745000
    num_steps_trained: 6745000
    wait_time_ms: 70.159
  iterations_since_restore: 1349
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11747.43895983696
  time_this_iter_s: 8.247379302978516
  time_total_s: 11747.43895983696
  timestamp: 1594867794
  timesteps_since_restore: 6745000
  timesteps_this_iter: 5000
  timesteps_total: 6745000
  training_iteration: 1349
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11747 s, 1349 iter, 6745000 ts, -1.21e+05 rew

agent-1: -15552.104156088062
agent-2: -20136.918063051126
agent-3: -16586.88663621476
agent-4: -16334.31716011934
agent-5: -10567.664008561003
Extrinsic Rewards:
-15401
-19953
-16440
-16177
-10464
Sum Reward: -78435
Avg Reward: -15687.0
Min Reward: -19953
Max Reward: -10464
Gini Coefficient: -0.10208197870848473
20:20 Ratio: 0.5244324161780184
Max-min Ratio: 0.5244324161780184
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-50-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -69423.76657741933
  episode_reward_mean: -121184.42258183399
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1349
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.72
    dispatch_time_ms: 8.36
    learner:
      cur_lr: 0.000910783011931926
      grad_gnorm: 40.0
      policy_entropy: 60.990238189697266
      policy_loss: -6291.5322265625
      var_gnorm: 222.16415405273438
      vf_explained_var: 0.0
      vf_loss: 910239.125
    num_steps_sampled: 6750000
    num_steps_trained: 6750000
    wait_time_ms: 73.145
  iterations_since_restore: 1350
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11755.805475473404
  time_this_iter_s: 8.366515636444092
  time_total_s: 11755.805475473404
  timestamp: 1594867802
  timesteps_since_restore: 6750000
  timesteps_this_iter: 5000
  timesteps_total: 6750000
  training_iteration: 1350
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11755 s, 1350 iter, 6750000 ts, -1.21e+05 rew

agent-1: -14152.781535557519
agent-2: -18581.566188504687
agent-3: -14511.071848620079
agent-4: -19611.32743382201
agent-5: -20840.76773325044
Extrinsic Rewards:
-14027
-18420
-14391
-19440
-20673
Sum Reward: -86951
Avg Reward: -17390.2
Min Reward: -20673
Max Reward: -14027
Gini Coefficient: -0.0843739577463169
20:20 Ratio: 0.6785178735548784
Max-min Ratio: 0.6785178735548784
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-50-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -69423.76657741933
  episode_reward_mean: -121229.93460170233
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1350
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.513
    dispatch_time_ms: 7.789
    learner:
      cur_lr: 0.0009104500059038401
      grad_gnorm: 39.999996185302734
      policy_entropy: 55.20909118652344
      policy_loss: 651.9727783203125
      var_gnorm: 222.4611053466797
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 57485.9375
    num_steps_sampled: 6755000
    num_steps_trained: 6755000
    wait_time_ms: 75.145
  iterations_since_restore: 1351
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11764.17044711113
  time_this_iter_s: 8.36497163772583
  time_total_s: 11764.17044711113
  timestamp: 1594867811
  timesteps_since_restore: 6755000
  timesteps_this_iter: 5000
  timesteps_total: 6755000
  training_iteration: 1351
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11764 s, 1351 iter, 6755000 ts, -1.21e+05 rew

agent-1: -19809.127537195323
agent-2: -16249.136360450762
agent-3: -20546.465927478712
agent-4: -20649.586183161427
agent-5: -10815.720861586855
Extrinsic Rewards:
-19644
-16107
-20374
-20481
-10715
Sum Reward: -87321
Avg Reward: -17464.2
Min Reward: -20481
Max Reward: -10715
Gini Coefficient: -0.10901844917030268
20:20 Ratio: 0.5231678140715785
Max-min Ratio: 0.5231678140715785
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-50-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -69423.76657741933
  episode_reward_mean: -121195.91200548435
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1351
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.616
    dispatch_time_ms: 32.375
    learner:
      cur_lr: 0.0009101169998757541
      grad_gnorm: 40.0
      policy_entropy: 57.01212692260742
      policy_loss: 1029.455078125
      var_gnorm: 222.7015380859375
      vf_explained_var: -0.7753034830093384
      vf_loss: 63412.58203125
    num_steps_sampled: 6760000
    num_steps_trained: 6760000
    wait_time_ms: 54.502
  iterations_since_restore: 1352
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11772.664464712143
  time_this_iter_s: 8.494017601013184
  time_total_s: 11772.664464712143
  timestamp: 1594867819
  timesteps_since_restore: 6760000
  timesteps_this_iter: 5000
  timesteps_total: 6760000
  training_iteration: 1352
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11772 s, 1352 iter, 6760000 ts, -1.21e+05 rew

agent-1: -11826.644577286259
agent-2: -17046.210130885956
agent-3: -13572.938592360944
agent-4: -15301.976702804823
agent-5: -18611.12916941119
Extrinsic Rewards:
-11709
-16877
-13436
-15148
-18431
Sum Reward: -75601
Avg Reward: -15120.2
Min Reward: -18431
Max Reward: -11709
Gini Coefficient: -0.08933744262642028
20:20 Ratio: 0.6352883728500895
Max-min Ratio: 0.6352883728500895
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-50-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -69423.76657741933
  episode_reward_mean: -120939.18113790109
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1352
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.222
    dispatch_time_ms: 39.871
    learner:
      cur_lr: 0.0009097839938476682
      grad_gnorm: 40.0
      policy_entropy: 52.4114990234375
      policy_loss: 54.244850158691406
      var_gnorm: 222.89442443847656
      vf_explained_var: 0.0
      vf_loss: 164907.21875
    num_steps_sampled: 6765000
    num_steps_trained: 6765000
    wait_time_ms: 60.03
  iterations_since_restore: 1353
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11781.628084659576
  time_this_iter_s: 8.963619947433472
  time_total_s: 11781.628084659576
  timestamp: 1594867828
  timesteps_since_restore: 6765000
  timesteps_this_iter: 5000
  timesteps_total: 6765000
  training_iteration: 1353
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11781 s, 1353 iter, 6765000 ts, -1.21e+05 rew

agent-1: -15862.364533025277
agent-2: -12873.001030899473
agent-3: -13949.03955398213
agent-4: -14280.60628245955
agent-5: -16895.110635905196
Extrinsic Rewards:
-15703
-12725
-13821
-14135
-16724
Sum Reward: -73108
Avg Reward: -14621.6
Min Reward: -16724
Max Reward: -12725
Gini Coefficient: -0.05405701154456421
20:20 Ratio: 0.7608825639799092
Max-min Ratio: 0.7608825639799092
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-50-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -69423.76657741933
  episode_reward_mean: -120890.5289652921
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1353
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.829
    dispatch_time_ms: 30.513
    learner:
      cur_lr: 0.0009094509878195822
      grad_gnorm: 39.999996185302734
      policy_entropy: 50.81093215942383
      policy_loss: -1427.25439453125
      var_gnorm: 223.13926696777344
      vf_explained_var: 0.0
      vf_loss: 104304.7421875
    num_steps_sampled: 6770000
    num_steps_trained: 6770000
    wait_time_ms: 53.796
  iterations_since_restore: 1354
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11790.274757623672
  time_this_iter_s: 8.64667296409607
  time_total_s: 11790.274757623672
  timestamp: 1594867837
  timesteps_since_restore: 6770000
  timesteps_this_iter: 5000
  timesteps_total: 6770000
  training_iteration: 1354
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11790 s, 1354 iter, 6770000 ts, -1.21e+05 rew

agent-1: -13989.892340660648
agent-2: -12729.914398333874
agent-3: -13925.08826046117
agent-4: -15554.512323699983
agent-5: -21665.29160639695
Extrinsic Rewards:
-13846
-12598
-13789
-15411
-21473
Sum Reward: -77117
Avg Reward: -15423.4
Min Reward: -21473
Max Reward: -12598
Gini Coefficient: -0.10048108717922119
20:20 Ratio: 0.5866902621897266
Max-min Ratio: 0.5866902621897266
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-50-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -69423.76657741933
  episode_reward_mean: -120769.91795709443
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1354
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 4.007
    dispatch_time_ms: 35.63
    learner:
      cur_lr: 0.0009091179817914963
      grad_gnorm: 40.0
      policy_entropy: 47.35133361816406
      policy_loss: 1364.1533203125
      var_gnorm: 223.3289031982422
      vf_explained_var: 0.0
      vf_loss: 61303.6328125
    num_steps_sampled: 6775000
    num_steps_trained: 6775000
    wait_time_ms: 48.104
  iterations_since_restore: 1355
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11799.123139858246
  time_this_iter_s: 8.848382234573364
  time_total_s: 11799.123139858246
  timestamp: 1594867846
  timesteps_since_restore: 6775000
  timesteps_this_iter: 5000
  timesteps_total: 6775000
  training_iteration: 1355
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11799 s, 1355 iter, 6775000 ts, -1.21e+05 rew

agent-1: -8944.612409845216
agent-2: -11885.104115392965
agent-3: -15104.220780007596
agent-4: -11843.19891945003
agent-5: -10185.585448751399
Extrinsic Rewards:
-8826
-11730
-14919
-11689
-10049
Sum Reward: -57213
Avg Reward: -11442.6
Min Reward: -14919
Max Reward: -8826
Gini Coefficient: -0.09694999388250922
20:20 Ratio: 0.5915946108988538
Max-min Ratio: 0.5915946108988538
agent-1: -15248.922566473426
agent-2: -10130.532662662079
agent-3: -15970.001029353578
agent-4: -18623.493860306447
agent-5: -9670.03518645874
Extrinsic Rewards:
-15086
-10007
-15804
-18429
-9566
Sum Reward: -68892
Avg Reward: -13778.4
Min Reward: -18429
Max Reward: -9566
Gini Coefficient: -0.1365789932067584
20:20 Ratio: 0.5190731998480655
Max-min Ratio: 0.5190731998480655
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-50-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -57962.72167344744
  episode_reward_mean: -120394.02771400448
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 2
  episodes_total: 1356
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.686
    dispatch_time_ms: 18.611
    learner:
      cur_lr: 0.0009087849757634103
      grad_gnorm: 40.0
      policy_entropy: 47.991878509521484
      policy_loss: 2006.6798095703125
      var_gnorm: 223.30816650390625
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 62472.87890625
    num_steps_sampled: 6780000
    num_steps_trained: 6780000
    wait_time_ms: 74.553
  iterations_since_restore: 1356
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11807.878501415253
  time_this_iter_s: 8.755361557006836
  time_total_s: 11807.878501415253
  timestamp: 1594867855
  timesteps_since_restore: 6780000
  timesteps_this_iter: 5000
  timesteps_total: 6780000
  training_iteration: 1356
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11807 s, 1356 iter, 6780000 ts, -1.2e+05 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-51-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -57962.72167344744
  episode_reward_mean: -120394.02771400448
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 0
  episodes_total: 1356
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.284
    dispatch_time_ms: 36.377
    learner:
      cur_lr: 0.0009084520279429853
      grad_gnorm: 40.0
      policy_entropy: 40.370079040527344
      policy_loss: 488.3348693847656
      var_gnorm: 223.13021850585938
      vf_explained_var: 0.0
      vf_loss: 32008.76171875
    num_steps_sampled: 6785000
    num_steps_trained: 6785000
    wait_time_ms: 52.365
  iterations_since_restore: 1357
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11816.409155607224
  time_this_iter_s: 8.530654191970825
  time_total_s: 11816.409155607224
  timestamp: 1594867863
  timesteps_since_restore: 6785000
  timesteps_this_iter: 5000
  timesteps_total: 6785000
  training_iteration: 1357
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11816 s, 1357 iter, 6785000 ts, -1.2e+05 rew

agent-1: -8033.978294561652
agent-2: -6319.1613032709565
agent-3: -8235.41721571415
agent-4: -10201.196860400254
agent-5: -4901.963668814678
Extrinsic Rewards:
-7880
-6183
-8066
-10012
-4813
Sum Reward: -36954
Avg Reward: -7390.8
Min Reward: -10012
Max Reward: -4813
Gini Coefficient: -0.13293283541700493
20:20 Ratio: 0.4807231322413104
Max-min Ratio: 0.4807231322413104
Result for A3C_harvest_env_0:
agent-1: -5760.91686009407
agent-2: -7541.545698344813
agent-3: -9264.656962160736
agent-4: -7532.249201393589
agent-5: -5422.859674362119
Extrinsic Rewards:
-5637
-7379
-9078
-7379
-5302
Sum Reward: -34775
Avg Reward: -6955.0
Min Reward: -9078
Max Reward: -5302
Gini Coefficient: -0.10690438533429188
20:20 Ratio: 0.5840493500771095
Max-min Ratio: 0.5840493500771095
  custom_metrics: {}
  date: 2020-07-15_22-51-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -37691.71734276172
  episode_reward_mean: -119761.93973841432
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1357
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 4.495
    dispatch_time_ms: 13.645
    learner:
      cur_lr: 0.0009081190219148993
      grad_gnorm: 40.0
      policy_entropy: 39.975528717041016
      policy_loss: 766.1292724609375
      var_gnorm: 222.77598571777344
      vf_explained_var: -0.9257456064224243
      vf_loss: 66438.96875
    num_steps_sampled: 6790000
    num_steps_trained: 6790000
    wait_time_ms: 51.267
  iterations_since_restore: 1358
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11824.939798355103
  time_this_iter_s: 8.530642747879028
  time_total_s: 11824.939798355103
  timestamp: 1594867872
  timesteps_since_restore: 6790000
  timesteps_this_iter: 5000
  timesteps_total: 6790000
  training_iteration: 1358
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11824 s, 1358 iter, 6790000 ts, -1.2e+05 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-51-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -35522.228396355255
  episode_reward_mean: -118932.31624376247
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1358
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.072
    dispatch_time_ms: 7.094
    learner:
      cur_lr: 0.0009077860158868134
      grad_gnorm: 40.0
      policy_entropy: 36.40327453613281
      policy_loss: 1223.4688720703125
      var_gnorm: 222.3854217529297
      vf_explained_var: 0.0
      vf_loss: 76050.3203125
    num_steps_sampled: 6795000
    num_steps_trained: 6795000
    wait_time_ms: 70.473
  iterations_since_restore: 1359
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11833.020169496536
  time_this_iter_s: 8.080371141433716
  time_total_s: 11833.020169496536
  timestamp: 1594867880
  timesteps_since_restore: 6795000
  timesteps_this_iter: 5000
  timesteps_total: 6795000
  training_iteration: 1359
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11833 s, 1359 iter, 6795000 ts, -1.19e+05 rew

agent-1: -3551.0809325600126
agent-2: -5934.540349177657
agent-3: -5883.589418954228
agent-4: -6867.790398160801
agent-5: -4559.6886908407305
Extrinsic Rewards:
-3448
-5780
-5728
-6681
-4416
Sum Reward: -26053
Avg Reward: -5210.6
Min Reward: -6681
Max Reward: -3448
Gini Coefficient: -0.12021648178712624
20:20 Ratio: 0.5160904056279
Max-min Ratio: 0.5160904056279
agent-1: -5422.01990894099
agent-2: -6757.2313145975595
agent-3: -5429.177711050721
agent-4: -4875.131508728932
agent-5: -6701.31316959607
Extrinsic Rewards:
-5277
-6582
-5283
-4749
-6535
Sum Reward: -28426
Avg Reward: -5685.2
Min Reward: -6582
Max Reward: -4749
Gini Coefficient: -0.0692886793780342
20:20 Ratio: 0.7215132178669098
Max-min Ratio: 0.7215132178669098
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-51-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -26796.68978969337
  episode_reward_mean: -117193.06080202611
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 2
  episodes_total: 1360
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.444
    dispatch_time_ms: 6.523
    learner:
      cur_lr: 0.0009074530098587275
      grad_gnorm: 40.0
      policy_entropy: 35.47683334350586
      policy_loss: 43777.6015625
      var_gnorm: 221.92031860351562
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 23379788.0
    num_steps_sampled: 6800000
    num_steps_trained: 6800000
    wait_time_ms: 70.496
  iterations_since_restore: 1360
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11840.971778869629
  time_this_iter_s: 7.951609373092651
  time_total_s: 11840.971778869629
  timestamp: 1594867888
  timesteps_since_restore: 6800000
  timesteps_this_iter: 5000
  timesteps_total: 6800000
  training_iteration: 1360
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11840 s, 1360 iter, 6800000 ts, -1.17e+05 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-51-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -26796.68978969337
  episode_reward_mean: -117193.06080202611
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 0
  episodes_total: 1360
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.714
    dispatch_time_ms: 9.41
    learner:
      cur_lr: 0.0009071200038306415
      grad_gnorm: 40.0
      policy_entropy: 31.867460250854492
      policy_loss: 635.6455078125
      var_gnorm: 221.4307861328125
      vf_explained_var: 0.0
      vf_loss: 56948.421875
    num_steps_sampled: 6805000
    num_steps_trained: 6805000
    wait_time_ms: 69.615
  iterations_since_restore: 1361
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11849.040775060654
  time_this_iter_s: 8.06899619102478
  time_total_s: 11849.040775060654
  timestamp: 1594867896
  timesteps_since_restore: 6805000
  timesteps_this_iter: 5000
  timesteps_total: 6805000
  training_iteration: 1361
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11849 s, 1361 iter, 6805000 ts, -1.17e+05 rew

agent-1: -3759.456051869118
agent-2: -2294.1054094193373
agent-3: -2651.1710200993844
agent-4: -3052.428057599982
agent-5: -3306.017291370645
Extrinsic Rewards:
-3582
-2171
-2518
-2906
-3162
Sum Reward: -14339
Avg Reward: -2867.8
Min Reward: -3582
Max Reward: -2171
Gini Coefficient: -0.09668735616151754
20:20 Ratio: 0.6060859854829704
Max-min Ratio: 0.6060859854829704
agent-1: -4044.4192926610644
agent-2: -3591.6930260512368
agent-3: -5156.070525554436
agent-4: -4927.4118369575235
agent-5: -4397.232089645116
Extrinsic Rewards:
-3909
-3464
-4969
-4764
-4246
Sum Reward: -21352
Avg Reward: -4270.4
Min Reward: -4969
Max Reward: -3464
Gini Coefficient: -0.07240539527913076
20:20 Ratio: 0.6971221573757295
Max-min Ratio: 0.6971221573757295
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-51-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -15063.177830358487
  episode_reward_mean: -115316.50287540248
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 2
  episodes_total: 1362
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 4.023
    dispatch_time_ms: 7.95
    learner:
      cur_lr: 0.0009067869978025556
      grad_gnorm: 40.0
      policy_entropy: 34.7697868347168
      policy_loss: 753.6827392578125
      var_gnorm: 220.93551635742188
      vf_explained_var: -0.3268343210220337
      vf_loss: 46532.99609375
    num_steps_sampled: 6810000
    num_steps_trained: 6810000
    wait_time_ms: 69.423
  iterations_since_restore: 1362
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11857.052016019821
  time_this_iter_s: 8.01124095916748
  time_total_s: 11857.052016019821
  timestamp: 1594867904
  timesteps_since_restore: 6810000
  timesteps_this_iter: 5000
  timesteps_total: 6810000
  training_iteration: 1362
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11857 s, 1362 iter, 6810000 ts, -1.15e+05 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-51-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -15063.177830358487
  episode_reward_mean: -115316.5028754025
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 0
  episodes_total: 1362
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.503
    dispatch_time_ms: 8.314
    learner:
      cur_lr: 0.0009064539917744696
      grad_gnorm: 40.0
      policy_entropy: 37.1579704284668
      policy_loss: 1588.37060546875
      var_gnorm: 220.43731689453125
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 75713.6640625
    num_steps_sampled: 6815000
    num_steps_trained: 6815000
    wait_time_ms: 69.011
  iterations_since_restore: 1363
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11864.947831392288
  time_this_iter_s: 7.895815372467041
  time_total_s: 11864.947831392288
  timestamp: 1594867912
  timesteps_since_restore: 6815000
  timesteps_this_iter: 5000
  timesteps_total: 6815000
  training_iteration: 1363
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11864 s, 1363 iter, 6815000 ts, -1.15e+05 rew

agent-1: -4167.2239093818
agent-2: -6407.181023042638
agent-3: -6041.776714347942
agent-4: -6205.409848803149
agent-5: -5932.546630294601
Extrinsic Rewards:
-4047
-6252
-5880
-6049
-5779
Sum Reward: -28007
Avg Reward: -5601.4
Min Reward: -6252
Max Reward: -4047
Gini Coefficient: -0.06684043274895562
20:20 Ratio: 0.6473128598848369
Max-min Ratio: 0.6473128598848369
agent-1: -5961.549614279728
agent-2: -7011.69707869737
agent-3: -6820.779051982914
agent-4: -6818.805621155125
agent-5: -4334.8857600203255
Extrinsic Rewards:
-5825
-6848
-6670
-6647
-4230
Sum Reward: -30220
Avg Reward: -6044.0
Min Reward: -6848
Max Reward: -4230
Gini Coefficient: -0.08048974189278624
20:20 Ratio: 0.6176985981308412
Max-min Ratio: 0.6176985981308412
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-52-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -15063.177830358487
  episode_reward_mean: -114208.96176298721
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 2
  episodes_total: 1364
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.934
    dispatch_time_ms: 6.968
    learner:
      cur_lr: 0.0009061209857463837
      grad_gnorm: 40.0
      policy_entropy: 46.74856185913086
      policy_loss: 46716.55078125
      var_gnorm: 220.1481170654297
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 25356494.0
    num_steps_sampled: 6820000
    num_steps_trained: 6820000
    wait_time_ms: 71.924
  iterations_since_restore: 1364
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11873.083755016327
  time_this_iter_s: 8.135923624038696
  time_total_s: 11873.083755016327
  timestamp: 1594867920
  timesteps_since_restore: 6820000
  timesteps_this_iter: 5000
  timesteps_total: 6820000
  training_iteration: 1364
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11873 s, 1364 iter, 6820000 ts, -1.14e+05 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-52-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -15063.177830358487
  episode_reward_mean: -114208.9617629872
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 0
  episodes_total: 1364
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 4.47
    dispatch_time_ms: 6.628
    learner:
      cur_lr: 0.0009057879797182977
      grad_gnorm: 40.0
      policy_entropy: 47.04900360107422
      policy_loss: 1235.57470703125
      var_gnorm: 219.94284057617188
      vf_explained_var: 0.0
      vf_loss: 73586.171875
    num_steps_sampled: 6825000
    num_steps_trained: 6825000
    wait_time_ms: 71.501
  iterations_since_restore: 1365
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11881.174158096313
  time_this_iter_s: 8.090403079986572
  time_total_s: 11881.174158096313
  timestamp: 1594867928
  timesteps_since_restore: 6825000
  timesteps_this_iter: 5000
  timesteps_total: 6825000
  training_iteration: 1365
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11881 s, 1365 iter, 6825000 ts, -1.14e+05 rew

agent-1: -8125.043124426336
agent-2: -8280.596238715269
agent-3: -5400.151841007968
agent-4: -6734.5076718689
agent-5: -7169.645088720591
Extrinsic Rewards:
-7963
-8115
-5283
-6581
-7010
Sum Reward: -34952
Avg Reward: -6990.4
Min Reward: -8115
Max Reward: -5283
Gini Coefficient: -0.08063630121309225
20:20 Ratio: 0.6510166358595194
Max-min Ratio: 0.6510166358595194
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-52-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -15063.177830358487
  episode_reward_mean: -113619.50375551917
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1365
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.86
    dispatch_time_ms: 8.099
    learner:
      cur_lr: 0.0009054549736902118
      grad_gnorm: 40.0
      policy_entropy: 42.301979064941406
      policy_loss: 1701.5673828125
      var_gnorm: 219.5921173095703
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 57294.67578125
    num_steps_sampled: 6830000
    num_steps_trained: 6830000
    wait_time_ms: 68.588
  iterations_since_restore: 1366
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11889.261375904083
  time_this_iter_s: 8.087217807769775
  time_total_s: 11889.261375904083
  timestamp: 1594867936
  timesteps_since_restore: 6830000
  timesteps_this_iter: 5000
  timesteps_total: 6830000
  training_iteration: 1366
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11889 s, 1366 iter, 6830000 ts, -1.14e+05 rew

agent-1: -5421.088791721062
agent-2: -6254.548435393838
agent-3: -8314.136911650328
agent-4: -6487.857123647928
agent-5: -6400.48069131322
Extrinsic Rewards:
-5297
-6107
-8136
-6341
-6259
Sum Reward: -32140
Avg Reward: -6428.0
Min Reward: -8136
Max Reward: -5297
Gini Coefficient: -0.07357809583074051
20:20 Ratio: 0.6510570304818093
Max-min Ratio: 0.6510570304818093
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-52-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -15063.177830358487
  episode_reward_mean: -113066.9379600065
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1366
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.132
    dispatch_time_ms: 8.591
    learner:
      cur_lr: 0.0009051220258697867
      grad_gnorm: 39.999996185302734
      policy_entropy: 51.5529670715332
      policy_loss: 1110.0958251953125
      var_gnorm: 219.28187561035156
      vf_explained_var: 0.0
      vf_loss: 79127.421875
    num_steps_sampled: 6835000
    num_steps_trained: 6835000
    wait_time_ms: 71.859
  iterations_since_restore: 1367
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11897.855764627457
  time_this_iter_s: 8.594388723373413
  time_total_s: 11897.855764627457
  timestamp: 1594867945
  timesteps_since_restore: 6835000
  timesteps_this_iter: 5000
  timesteps_total: 6835000
  training_iteration: 1367
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11897 s, 1367 iter, 6835000 ts, -1.13e+05 rew

agent-1: -5989.087441561347
agent-2: -5942.207259930411
agent-3: -8574.889080197649
agent-4: -7792.304888963486
agent-5: -6333.72673623633
Extrinsic Rewards:
-5852
-5805
-8396
-7625
-6195
Sum Reward: -33873
Avg Reward: -6774.6
Min Reward: -8396
Max Reward: -5805
Gini Coefficient: -0.0821303102766215
20:20 Ratio: 0.6914006669842783
Max-min Ratio: 0.6914006669842783
agent-1: -6780.465349013337
agent-2: -9078.521725487695
agent-3: -8240.698047619426
agent-4: -7178.8826703586155
agent-5: -7681.109904985461
Extrinsic Rewards:
-6654
-8909
-8087
-7039
-7532
Sum Reward: -38221
Avg Reward: -7644.2
Min Reward: -8909
Max Reward: -6654
Gini Coefficient: -0.05816697626959002
20:20 Ratio: 0.7468851722976765
Max-min Ratio: 0.7468851722976765
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-52-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -15063.177830358487
  episode_reward_mean: -111500.78867881517
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 2
  episodes_total: 1368
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.577
    dispatch_time_ms: 8.66
    learner:
      cur_lr: 0.0009047890198417008
      grad_gnorm: 40.0
      policy_entropy: 51.44163131713867
      policy_loss: -501.6835021972656
      var_gnorm: 219.06495666503906
      vf_explained_var: -0.7748138904571533
      vf_loss: 64439.84375
    num_steps_sampled: 6840000
    num_steps_trained: 6840000
    wait_time_ms: 70.336
  iterations_since_restore: 1368
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11906.00624370575
  time_this_iter_s: 8.150479078292847
  time_total_s: 11906.00624370575
  timestamp: 1594867953
  timesteps_since_restore: 6840000
  timesteps_this_iter: 5000
  timesteps_total: 6840000
  training_iteration: 1368
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11906 s, 1368 iter, 6840000 ts, -1.12e+05 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-52-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -15063.177830358487
  episode_reward_mean: -111500.78867881518
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 0
  episodes_total: 1368
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.548
    dispatch_time_ms: 7.976
    learner:
      cur_lr: 0.0009044560138136148
      grad_gnorm: 39.999996185302734
      policy_entropy: 51.9739875793457
      policy_loss: -945.6389770507812
      var_gnorm: 218.8976593017578
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 42819.93359375
    num_steps_sampled: 6845000
    num_steps_trained: 6845000
    wait_time_ms: 66.377
  iterations_since_restore: 1369
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11914.074580907822
  time_this_iter_s: 8.068337202072144
  time_total_s: 11914.074580907822
  timestamp: 1594867961
  timesteps_since_restore: 6845000
  timesteps_this_iter: 5000
  timesteps_total: 6845000
  training_iteration: 1369
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11914 s, 1369 iter, 6845000 ts, -1.12e+05 rew

agent-1: -6600.381391965507
agent-2: -7157.641469253368
agent-3: -5613.232955157008
agent-4: -9047.687213068064
agent-5: -7794.180024948993
Extrinsic Rewards:
-6464
-7005
-5487
-8869
-7631
Sum Reward: -35456
Avg Reward: -7091.2
Min Reward: -8869
Max Reward: -5487
Gini Coefficient: -0.08947427797833934
20:20 Ratio: 0.6186717781035066
Max-min Ratio: 0.6186717781035066
agent-1: -7529.948039255676
agent-2: -9143.53820819834
agent-3: -8691.211230739447
agent-4: -6850.672450410653
agent-5: -6715.922465783186
Extrinsic Rewards:
-7372
-8972
-8526
-6727
-6578
Sum Reward: -38175
Avg Reward: -7635.0
Min Reward: -8972
Max Reward: -6578
Gini Coefficient: -0.06901899148657499
20:20 Ratio: 0.7331698617922425
Max-min Ratio: 0.7331698617922425
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-52-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -15063.177830358487
  episode_reward_mean: -109886.19500075531
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 2
  episodes_total: 1370
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.096
    dispatch_time_ms: 8.822
    learner:
      cur_lr: 0.0009041230077855289
      grad_gnorm: 40.0
      policy_entropy: 45.93433380126953
      policy_loss: 53305.3125
      var_gnorm: 218.57061767578125
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 24946320.0
    num_steps_sampled: 6850000
    num_steps_trained: 6850000
    wait_time_ms: 69.438
  iterations_since_restore: 1370
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11922.216653585434
  time_this_iter_s: 8.142072677612305
  time_total_s: 11922.216653585434
  timestamp: 1594867970
  timesteps_since_restore: 6850000
  timesteps_this_iter: 5000
  timesteps_total: 6850000
  training_iteration: 1370
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11922 s, 1370 iter, 6850000 ts, -1.1e+05 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-52-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -15063.177830358487
  episode_reward_mean: -109886.19500075531
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 0
  episodes_total: 1370
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.125
    dispatch_time_ms: 7.803
    learner:
      cur_lr: 0.000903790001757443
      grad_gnorm: 40.000003814697266
      policy_entropy: 52.040157318115234
      policy_loss: 1082.4033203125
      var_gnorm: 218.16006469726562
      vf_explained_var: 0.0
      vf_loss: 46765.84375
    num_steps_sampled: 6855000
    num_steps_trained: 6855000
    wait_time_ms: 69.248
  iterations_since_restore: 1371
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11930.412331342697
  time_this_iter_s: 8.195677757263184
  time_total_s: 11930.412331342697
  timestamp: 1594867978
  timesteps_since_restore: 6855000
  timesteps_this_iter: 5000
  timesteps_total: 6855000
  training_iteration: 1371
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11930 s, 1371 iter, 6855000 ts, -1.1e+05 rew

agent-1: -5098.6180064524215
agent-2: -5960.893664393938
agent-3: -7725.718120607477
agent-4: -6336.27275065052
agent-5: -5427.737552074763
Extrinsic Rewards:
-4973
-5811
-7546
-6171
-5289
Sum Reward: -29790
Avg Reward: -5958.0
Min Reward: -7546
Max Reward: -4973
Gini Coefficient: -0.08093991272239007
20:20 Ratio: 0.6590246488205672
Max-min Ratio: 0.6590246488205672
agent-1: -6522.581894339854
agent-2: -5106.264905514821
agent-3: -4402.435808885485
agent-4: -6240.650042648182
agent-5: -5093.872956702304
Extrinsic Rewards:
-6351
-4970
-4278
-6079
-4954
Sum Reward: -26632
Avg Reward: -5326.4
Min Reward: -6351
Max Reward: -4278
Gini Coefficient: -0.07916791829378192
20:20 Ratio: 0.6735947094945678
Max-min Ratio: 0.6735947094945678
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-53-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -15063.177830358487
  episode_reward_mean: -107723.5603584503
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 2
  episodes_total: 1372
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.972
    dispatch_time_ms: 7.991
    learner:
      cur_lr: 0.000903456995729357
      grad_gnorm: 40.000003814697266
      policy_entropy: 55.37548828125
      policy_loss: 55121.4375
      var_gnorm: 217.79385375976562
      vf_explained_var: 0.0
      vf_loss: 24921700.0
    num_steps_sampled: 6860000
    num_steps_trained: 6860000
    wait_time_ms: 71.676
  iterations_since_restore: 1372
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11938.538532972336
  time_this_iter_s: 8.126201629638672
  time_total_s: 11938.538532972336
  timestamp: 1594867986
  timesteps_since_restore: 6860000
  timesteps_this_iter: 5000
  timesteps_total: 6860000
  training_iteration: 1372
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11938 s, 1372 iter, 6860000 ts, -1.08e+05 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-53-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -15063.177830358487
  episode_reward_mean: -107723.5603584503
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 0
  episodes_total: 1372
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.135
    dispatch_time_ms: 7.292
    learner:
      cur_lr: 0.0009031239897012711
      grad_gnorm: 40.0
      policy_entropy: 53.424835205078125
      policy_loss: -975.848876953125
      var_gnorm: 217.5651092529297
      vf_explained_var: 0.0
      vf_loss: 110999.65625
    num_steps_sampled: 6865000
    num_steps_trained: 6865000
    wait_time_ms: 72.01
  iterations_since_restore: 1373
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11946.736763715744
  time_this_iter_s: 8.198230743408203
  time_total_s: 11946.736763715744
  timestamp: 1594867994
  timesteps_since_restore: 6865000
  timesteps_this_iter: 5000
  timesteps_total: 6865000
  training_iteration: 1373
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11946 s, 1373 iter, 6865000 ts, -1.08e+05 rew

agent-1: -9848.82817442878
agent-2: -6349.773138966857
agent-3: -7801.93782943659
agent-4: -9395.488719228282
agent-5: -7823.137714150356
Extrinsic Rewards:
-9676
-6232
-7650
-9228
-7683
Sum Reward: -40469
Avg Reward: -8093.8
Min Reward: -9676
Max Reward: -6232
Gini Coefficient: -0.083678865304307
20:20 Ratio: 0.6440677966101694
Max-min Ratio: 0.6440677966101694
agent-1: -7857.360384207607
agent-2: -5633.886627547763
agent-3: -8791.905674802423
agent-4: -7612.428113268617
agent-5: -8124.681280376628
Extrinsic Rewards:
-7702
-5519
-8619
-7457
-7971
Sum Reward: -37268
Avg Reward: -7453.6
Min Reward: -8619
Max Reward: -5519
Gini Coefficient: -0.07206182247504561
20:20 Ratio: 0.6403295045828983
Max-min Ratio: 0.6403295045828983
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-53-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -15063.177830358487
  episode_reward_mean: -106427.68304463715
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 2
  episodes_total: 1374
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.022
    dispatch_time_ms: 6.577
    learner:
      cur_lr: 0.0009027909836731851
      grad_gnorm: 40.000003814697266
      policy_entropy: 52.38969039916992
      policy_loss: 39059.87890625
      var_gnorm: 217.25991821289062
      vf_explained_var: 4.172325134277344e-07
      vf_loss: 23709732.0
    num_steps_sampled: 6870000
    num_steps_trained: 6870000
    wait_time_ms: 72.794
  iterations_since_restore: 1374
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11954.902375459671
  time_this_iter_s: 8.165611743927002
  time_total_s: 11954.902375459671
  timestamp: 1594868002
  timesteps_since_restore: 6870000
  timesteps_this_iter: 5000
  timesteps_total: 6870000
  training_iteration: 1374
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11954 s, 1374 iter, 6870000 ts, -1.06e+05 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-53-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -15063.177830358487
  episode_reward_mean: -106427.68304463715
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 0
  episodes_total: 1374
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.635
    dispatch_time_ms: 7.184
    learner:
      cur_lr: 0.0009024579776450992
      grad_gnorm: 40.000003814697266
      policy_entropy: 61.57407760620117
      policy_loss: 939.788818359375
      var_gnorm: 216.99472045898438
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 118721.2421875
    num_steps_sampled: 6875000
    num_steps_trained: 6875000
    wait_time_ms: 73.919
  iterations_since_restore: 1375
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11963.138250112534
  time_this_iter_s: 8.235874652862549
  time_total_s: 11963.138250112534
  timestamp: 1594868011
  timesteps_since_restore: 6875000
  timesteps_this_iter: 5000
  timesteps_total: 6875000
  training_iteration: 1375
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11963 s, 1375 iter, 6875000 ts, -1.06e+05 rew

agent-1: -8757.278873193854
agent-2: -7503.424012799113
agent-3: -6375.656923564694
agent-4: -7177.870416447514
agent-5: -7900.513164633705
Extrinsic Rewards:
-8588
-7345
-6246
-7035
-7748
Sum Reward: -36962
Avg Reward: -7392.4
Min Reward: -8588
Max Reward: -6246
Gini Coefficient: -0.05840593041502083
20:20 Ratio: 0.7272938984629715
Max-min Ratio: 0.7272938984629715
agent-1: -7507.339258262224
agent-2: -5969.858911773349
agent-3: -8857.913287484162
agent-4: -7879.933132829521
agent-5: -8846.193270325566
Extrinsic Rewards:
-7354
-5859
-8693
-7725
-8675
Sum Reward: -38306
Avg Reward: -7661.2
Min Reward: -8693
Max Reward: -5859
Gini Coefficient: -0.07298073408865452
20:20 Ratio: 0.6739905671229726
Max-min Ratio: 0.6739905671229726
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-53-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -15063.177830358487
  episode_reward_mean: -104264.44600417858
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 2
  episodes_total: 1376
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.998
    dispatch_time_ms: 7.855
    learner:
      cur_lr: 0.0009021249716170132
      grad_gnorm: 40.0
      policy_entropy: 70.82951354980469
      policy_loss: 60862.6875
      var_gnorm: 216.76742553710938
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 21168478.0
    num_steps_sampled: 6880000
    num_steps_trained: 6880000
    wait_time_ms: 73.964
  iterations_since_restore: 1376
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11971.537415981293
  time_this_iter_s: 8.399165868759155
  time_total_s: 11971.537415981293
  timestamp: 1594868019
  timesteps_since_restore: 6880000
  timesteps_this_iter: 5000
  timesteps_total: 6880000
  training_iteration: 1376
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11971 s, 1376 iter, 6880000 ts, -1.04e+05 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-53-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -15063.177830358487
  episode_reward_mean: -104264.44600417856
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 0
  episodes_total: 1376
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.1
    dispatch_time_ms: 8.755
    learner:
      cur_lr: 0.0009017920237965882
      grad_gnorm: 39.999996185302734
      policy_entropy: 70.31944274902344
      policy_loss: 1010.0810546875
      var_gnorm: 216.61851501464844
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 37117.1484375
    num_steps_sampled: 6885000
    num_steps_trained: 6885000
    wait_time_ms: 70.369
  iterations_since_restore: 1377
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11979.866829633713
  time_this_iter_s: 8.329413652420044
  time_total_s: 11979.866829633713
  timestamp: 1594868027
  timesteps_since_restore: 6885000
  timesteps_this_iter: 5000
  timesteps_total: 6885000
  training_iteration: 1377
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11979 s, 1377 iter, 6885000 ts, -1.04e+05 rew

agent-1: -8179.844336462438
agent-2: -7763.364079298661
agent-3: -9421.283312546097
agent-4: -7766.1641056269045
agent-5: -9472.729784790488
Extrinsic Rewards:
-8036
-7620
-9253
-7631
-9306
Sum Reward: -41846
Avg Reward: -8369.2
Min Reward: -9306
Max Reward: -7620
Gini Coefficient: -0.047736940209339
20:20 Ratio: 0.8188265635074146
Max-min Ratio: 0.8188265635074146
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-53-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -15063.177830358487
  episode_reward_mean: -103293.7127815995
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1377
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.919
    dispatch_time_ms: 8.259
    learner:
      cur_lr: 0.0009014590177685022
      grad_gnorm: 40.0
      policy_entropy: 76.62520599365234
      policy_loss: 168.19595336914062
      var_gnorm: 216.35272216796875
      vf_explained_var: 0.0
      vf_loss: 77726.6328125
    num_steps_sampled: 6890000
    num_steps_trained: 6890000
    wait_time_ms: 73.924
  iterations_since_restore: 1378
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11988.342664003372
  time_this_iter_s: 8.475834369659424
  time_total_s: 11988.342664003372
  timestamp: 1594868036
  timesteps_since_restore: 6890000
  timesteps_this_iter: 5000
  timesteps_total: 6890000
  training_iteration: 1378
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11988 s, 1378 iter, 6890000 ts, -1.03e+05 rew

agent-1: -6755.874466684826
agent-2: -8541.421703381047
agent-3: -7458.821722739043
agent-4: -7523.673679202849
agent-5: -7519.777781278559
Extrinsic Rewards:
-6619
-8377
-7306
-7374
-7367
Sum Reward: -37043
Avg Reward: -7408.6
Min Reward: -8377
Max Reward: -6619
Gini Coefficient: -0.03870096914396782
20:20 Ratio: 0.7901396681389519
Max-min Ratio: 0.7901396681389519
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-54-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -15063.177830358487
  episode_reward_mean: -102260.91490034225
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1378
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.38
    dispatch_time_ms: 7.474
    learner:
      cur_lr: 0.0009011260117404163
      grad_gnorm: 40.000003814697266
      policy_entropy: 75.7647933959961
      policy_loss: 1926.9208984375
      var_gnorm: 216.12619018554688
      vf_explained_var: 0.0
      vf_loss: 59791.25
    num_steps_sampled: 6895000
    num_steps_trained: 6895000
    wait_time_ms: 74.061
  iterations_since_restore: 1379
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 11996.671909570694
  time_this_iter_s: 8.329245567321777
  time_total_s: 11996.671909570694
  timestamp: 1594868044
  timesteps_since_restore: 6895000
  timesteps_this_iter: 5000
  timesteps_total: 6895000
  training_iteration: 1379
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 11996 s, 1379 iter, 6895000 ts, -1.02e+05 rew

agent-1: -7175.9296134325805
agent-2: -8234.918737497359
agent-3: -4694.601120890465
agent-4: -8687.070879660152
agent-5: -6285.709086416834
Extrinsic Rewards:
-7020
-8057
-4585
-8508
-6157
Sum Reward: -34327
Avg Reward: -6865.4
Min Reward: -8508
Max Reward: -4585
Gini Coefficient: -0.11356658024295743
20:20 Ratio: 0.5389045604137283
Max-min Ratio: 0.5389045604137283
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-54-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -15063.177830358487
  episode_reward_mean: -101313.38012787484
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1379
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.851
    dispatch_time_ms: 7.326
    learner:
      cur_lr: 0.0009007930057123303
      grad_gnorm: 40.0
      policy_entropy: 77.49108123779297
      policy_loss: 3859.699462890625
      var_gnorm: 215.8656768798828
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 70882.296875
    num_steps_sampled: 6900000
    num_steps_trained: 6900000
    wait_time_ms: 74.141
  iterations_since_restore: 1380
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12005.160643339157
  time_this_iter_s: 8.488733768463135
  time_total_s: 12005.160643339157
  timestamp: 1594868053
  timesteps_since_restore: 6900000
  timesteps_this_iter: 5000
  timesteps_total: 6900000
  training_iteration: 1380
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12005 s, 1380 iter, 6900000 ts, -1.01e+05 rew

agent-1: -6994.209482090367
agent-2: -7746.798375745004
agent-3: -9193.134051697107
agent-4: -7557.850139732591
agent-5: -8925.7096411353
Extrinsic Rewards:
-6855
-7606
-9024
-7413
-8751
Sum Reward: -39649
Avg Reward: -7929.8
Min Reward: -9024
Max Reward: -6855
Gini Coefficient: -0.05726247824661404
20:20 Ratio: 0.7596409574468085
Max-min Ratio: 0.7596409574468085
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-54-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -15063.177830358487
  episode_reward_mean: -100192.83306390254
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1380
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.337
    dispatch_time_ms: 9.056
    learner:
      cur_lr: 0.0009004599996842444
      grad_gnorm: 40.0
      policy_entropy: 75.39430236816406
      policy_loss: -91.1138916015625
      var_gnorm: 215.6805877685547
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 34022.53515625
    num_steps_sampled: 6905000
    num_steps_trained: 6905000
    wait_time_ms: 72.268
  iterations_since_restore: 1381
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12013.507062196732
  time_this_iter_s: 8.346418857574463
  time_total_s: 12013.507062196732
  timestamp: 1594868061
  timesteps_since_restore: 6905000
  timesteps_this_iter: 5000
  timesteps_total: 6905000
  training_iteration: 1381
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12013 s, 1381 iter, 6905000 ts, -1e+05 rew

agent-1: -7177.93987267655
agent-2: -9713.86033291503
agent-3: -7939.628161925274
agent-4: -7537.177628080457
agent-5: -8021.258964278927
Extrinsic Rewards:
-7042
-9541
-7793
-7390
-7866
Sum Reward: -39632
Avg Reward: -7926.4
Min Reward: -9541
Max Reward: -7042
Gini Coefficient: -0.05524828421477594
20:20 Ratio: 0.7380777696258254
Max-min Ratio: 0.7380777696258254
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-54-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -15063.177830358487
  episode_reward_mean: -99356.44392900512
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1381
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.187
    dispatch_time_ms: 6.326
    learner:
      cur_lr: 0.0009001269936561584
      grad_gnorm: 40.0
      policy_entropy: 70.63693237304688
      policy_loss: 888.244873046875
      var_gnorm: 215.47525024414062
      vf_explained_var: 0.0
      vf_loss: 72466.6796875
    num_steps_sampled: 6910000
    num_steps_trained: 6910000
    wait_time_ms: 76.614
  iterations_since_restore: 1382
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12022.0118329525
  time_this_iter_s: 8.504770755767822
  time_total_s: 12022.0118329525
  timestamp: 1594868070
  timesteps_since_restore: 6910000
  timesteps_this_iter: 5000
  timesteps_total: 6910000
  training_iteration: 1382
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12022 s, 1382 iter, 6910000 ts, -9.94e+04 rew

agent-1: -7948.662661631753
agent-2: -9216.50243176463
agent-3: -7848.517349618576
agent-4: -8703.20878849925
agent-5: -6288.64503873718
Extrinsic Rewards:
-7794
-9047
-7701
-8542
-6164
Sum Reward: -39248
Avg Reward: -7849.6
Min Reward: -9047
Max Reward: -6164
Gini Coefficient: -0.06733591520587036
20:20 Ratio: 0.681330827898751
Max-min Ratio: 0.681330827898751
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-54-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -15063.177830358487
  episode_reward_mean: -98315.56670430028
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1382
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.192
    dispatch_time_ms: 8.61
    learner:
      cur_lr: 0.0008997939876280725
      grad_gnorm: 40.0
      policy_entropy: 69.80470275878906
      policy_loss: 1254.0440673828125
      var_gnorm: 215.0953826904297
      vf_explained_var: 0.0
      vf_loss: 74394.5546875
    num_steps_sampled: 6915000
    num_steps_trained: 6915000
    wait_time_ms: 72.524
  iterations_since_restore: 1383
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12030.453482627869
  time_this_iter_s: 8.441649675369263
  time_total_s: 12030.453482627869
  timestamp: 1594868078
  timesteps_since_restore: 6915000
  timesteps_this_iter: 5000
  timesteps_total: 6915000
  training_iteration: 1383
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12030 s, 1383 iter, 6915000 ts, -9.83e+04 rew

agent-1: -5856.572502553269
agent-2: -5269.952771998359
agent-3: -6252.382410098239
agent-4: -5037.3073954323345
agent-5: -5597.645354571224
Extrinsic Rewards:
-5705
-5124
-6076
-4890
-5445
Sum Reward: -27240
Avg Reward: -5448.0
Min Reward: -6076
Max Reward: -4890
Gini Coefficient: -0.04336270190895741
20:20 Ratio: 0.804805793285056
Max-min Ratio: 0.804805793285056
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-54-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -15063.177830358487
  episode_reward_mean: -97104.18984755955
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1383
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.552
    dispatch_time_ms: 9.046
    learner:
      cur_lr: 0.0008994609815999866
      grad_gnorm: 40.0
      policy_entropy: 70.01393127441406
      policy_loss: 3318.406982421875
      var_gnorm: 214.67724609375
      vf_explained_var: 0.0
      vf_loss: 71117.1171875
    num_steps_sampled: 6920000
    num_steps_trained: 6920000
    wait_time_ms: 70.531
  iterations_since_restore: 1384
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12038.830093383789
  time_this_iter_s: 8.37661075592041
  time_total_s: 12038.830093383789
  timestamp: 1594868087
  timesteps_since_restore: 6920000
  timesteps_this_iter: 5000
  timesteps_total: 6920000
  training_iteration: 1384
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12038 s, 1384 iter, 6920000 ts, -9.71e+04 rew

agent-1: -4488.786398320726
agent-2: -4737.041872155264
agent-3: -4246.451196543541
agent-4: -5764.535385139008
agent-5: -5665.749968487115
Extrinsic Rewards:
-4353
-4593
-4110
-5592
-5498
Sum Reward: -24146
Avg Reward: -4829.2
Min Reward: -5592
Max Reward: -4110
Gini Coefficient: -0.06806924542367265
20:20 Ratio: 0.7349785407725322
Max-min Ratio: 0.7349785407725322
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-54-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -15063.177830358487
  episode_reward_mean: -96052.77697828306
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1384
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.33
    dispatch_time_ms: 8.539
    learner:
      cur_lr: 0.0008991279755719006
      grad_gnorm: 40.0
      policy_entropy: 70.1270980834961
      policy_loss: 1114.7056884765625
      var_gnorm: 214.1998748779297
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 81256.7578125
    num_steps_sampled: 6925000
    num_steps_trained: 6925000
    wait_time_ms: 66.516
  iterations_since_restore: 1385
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12047.223010778427
  time_this_iter_s: 8.392917394638062
  time_total_s: 12047.223010778427
  timestamp: 1594868095
  timesteps_since_restore: 6925000
  timesteps_this_iter: 5000
  timesteps_total: 6925000
  training_iteration: 1385
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12047 s, 1385 iter, 6925000 ts, -9.61e+04 rew

agent-1: -4724.404782293463
agent-2: -4435.449502692955
agent-3: -4885.632470738134
agent-4: -4880.268051556597
agent-5: -4076.4730880996676
Extrinsic Rewards:
-4573
-4291
-4721
-4723
-3939
Sum Reward: -22247
Avg Reward: -4449.4
Min Reward: -4723
Max Reward: -3939
Gini Coefficient: -0.03592394480154627
20:20 Ratio: 0.8340038111369892
Max-min Ratio: 0.8340038111369892
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-55-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -15063.177830358487
  episode_reward_mean: -95290.92433422567
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1385
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.263
    dispatch_time_ms: 8.11
    learner:
      cur_lr: 0.0008987950277514756
      grad_gnorm: 40.000003814697266
      policy_entropy: 74.76362609863281
      policy_loss: 2502.763427734375
      var_gnorm: 213.8181610107422
      vf_explained_var: 0.0
      vf_loss: 54950.22265625
    num_steps_sampled: 6930000
    num_steps_trained: 6930000
    wait_time_ms: 76.65
  iterations_since_restore: 1386
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12055.663874149323
  time_this_iter_s: 8.440863370895386
  time_total_s: 12055.663874149323
  timestamp: 1594868104
  timesteps_since_restore: 6930000
  timesteps_this_iter: 5000
  timesteps_total: 6930000
  training_iteration: 1386
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12055 s, 1386 iter, 6930000 ts, -9.53e+04 rew

agent-1: -5536.7003970140495
agent-2: -4412.9615807793525
agent-3: -5695.431240403361
agent-4: -5643.139541868971
agent-5: -4583.632638403652
Extrinsic Rewards:
-5362
-4273
-5523
-5475
-4453
Sum Reward: -25086
Avg Reward: -5017.2
Min Reward: -5523
Max Reward: -4273
Gini Coefficient: -0.05615881368093757
20:20 Ratio: 0.7736737280463516
Max-min Ratio: 0.7736737280463516
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-55-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -15063.177830358487
  episode_reward_mean: -94491.5431501868
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1386
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.68
    dispatch_time_ms: 6.381
    learner:
      cur_lr: 0.0008984620217233896
      grad_gnorm: 40.0
      policy_entropy: 75.6981430053711
      policy_loss: 1238.14111328125
      var_gnorm: 213.435546875
      vf_explained_var: 0.0
      vf_loss: 24417.146484375
    num_steps_sampled: 6935000
    num_steps_trained: 6935000
    wait_time_ms: 78.172
  iterations_since_restore: 1387
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12064.015035629272
  time_this_iter_s: 8.351161479949951
  time_total_s: 12064.015035629272
  timestamp: 1594868112
  timesteps_since_restore: 6935000
  timesteps_this_iter: 5000
  timesteps_total: 6935000
  training_iteration: 1387
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12064 s, 1387 iter, 6935000 ts, -9.45e+04 rew

agent-1: -5410.2159041019495
agent-2: -6518.682844428305
agent-3: -6149.345301076706
agent-4: -5446.382975463009
agent-5: -6129.856617728358
Extrinsic Rewards:
-5265
-6366
-5997
-5302
-5963
Sum Reward: -28893
Avg Reward: -5778.6
Min Reward: -6366
Max Reward: -5265
Gini Coefficient: -0.04010660021458485
20:20 Ratio: 0.8270499528746466
Max-min Ratio: 0.8270499528746466
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-55-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -15063.177830358487
  episode_reward_mean: -93780.80316194426
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1387
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.963
    dispatch_time_ms: 6.617
    learner:
      cur_lr: 0.0008981290156953037
      grad_gnorm: 40.0
      policy_entropy: 75.16871643066406
      policy_loss: 1653.5107421875
      var_gnorm: 213.163818359375
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 44388.1171875
    num_steps_sampled: 6940000
    num_steps_trained: 6940000
    wait_time_ms: 75.567
  iterations_since_restore: 1388
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12072.476601600647
  time_this_iter_s: 8.461565971374512
  time_total_s: 12072.476601600647
  timestamp: 1594868120
  timesteps_since_restore: 6940000
  timesteps_this_iter: 5000
  timesteps_total: 6940000
  training_iteration: 1388
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12072 s, 1388 iter, 6940000 ts, -9.38e+04 rew

agent-1: -8150.402202101754
agent-2: -6542.154256091819
agent-3: -6517.047364917942
agent-4: -7023.661587161386
agent-5: -6709.518804321073
Extrinsic Rewards:
-7977
-6395
-6370
-6872
-6563
Sum Reward: -34177
Avg Reward: -6835.4
Min Reward: -7977
Max Reward: -6370
Gini Coefficient: -0.043198642361822276
20:20 Ratio: 0.7985458192302871
Max-min Ratio: 0.7985458192302871
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-55-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -15063.177830358487
  episode_reward_mean: -92979.26888828287
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1388
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.993
    dispatch_time_ms: 9.817
    learner:
      cur_lr: 0.0008977960096672177
      grad_gnorm: 40.0
      policy_entropy: 73.84468078613281
      policy_loss: 4151.53515625
      var_gnorm: 212.75733947753906
      vf_explained_var: 0.0
      vf_loss: 79365.6640625
    num_steps_sampled: 6945000
    num_steps_trained: 6945000
    wait_time_ms: 72.335
  iterations_since_restore: 1389
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12080.860694646835
  time_this_iter_s: 8.384093046188354
  time_total_s: 12080.860694646835
  timestamp: 1594868129
  timesteps_since_restore: 6945000
  timesteps_this_iter: 5000
  timesteps_total: 6945000
  training_iteration: 1389
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12080 s, 1389 iter, 6945000 ts, -9.3e+04 rew

agent-1: -5989.290002649358
agent-2: -5489.76886867212
agent-3: -4105.960067443527
agent-4: -4626.0390324710825
agent-5: -5289.426641835589
Extrinsic Rewards:
-5817
-5329
-3976
-4483
-5129
Sum Reward: -24734
Avg Reward: -4946.8
Min Reward: -5817
Max Reward: -3976
Gini Coefficient: -0.0732271367348589
20:20 Ratio: 0.6835138387484958
Max-min Ratio: 0.6835138387484958
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-55-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -15063.177830358487
  episode_reward_mean: -92117.26691567819
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1389
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.981
    dispatch_time_ms: 8.06
    learner:
      cur_lr: 0.0008974630036391318
      grad_gnorm: 40.0
      policy_entropy: 74.49699401855469
      policy_loss: 1657.1300048828125
      var_gnorm: 212.32229614257812
      vf_explained_var: 0.0
      vf_loss: 42097.11328125
    num_steps_sampled: 6950000
    num_steps_trained: 6950000
    wait_time_ms: 72.895
  iterations_since_restore: 1390
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12089.290355920792
  time_this_iter_s: 8.429661273956299
  time_total_s: 12089.290355920792
  timestamp: 1594868137
  timesteps_since_restore: 6950000
  timesteps_this_iter: 5000
  timesteps_total: 6950000
  training_iteration: 1390
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12089 s, 1390 iter, 6950000 ts, -9.21e+04 rew

agent-1: -5094.959763349243
agent-2: -4169.582959699943
agent-3: -4235.006097570599
agent-4: -4240.212475528989
agent-5: -3206.3209681923327
Extrinsic Rewards:
-4919
-4020
-4081
-4078
-3089
Sum Reward: -20187
Avg Reward: -4037.4
Min Reward: -4919
Max Reward: -3089
Gini Coefficient: -0.07373061871501461
20:20 Ratio: 0.6279731652774955
Max-min Ratio: 0.6279731652774955
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-55-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -15063.177830358487
  episode_reward_mean: -91320.36063613128
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1390
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.804
    dispatch_time_ms: 5.998
    learner:
      cur_lr: 0.0008971299976110458
      grad_gnorm: 40.0
      policy_entropy: 74.31352233886719
      policy_loss: 1956.765380859375
      var_gnorm: 211.84506225585938
      vf_explained_var: 0.0
      vf_loss: 48770.9375
    num_steps_sampled: 6955000
    num_steps_trained: 6955000
    wait_time_ms: 74.733
  iterations_since_restore: 1391
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12097.733888626099
  time_this_iter_s: 8.443532705307007
  time_total_s: 12097.733888626099
  timestamp: 1594868146
  timesteps_since_restore: 6955000
  timesteps_this_iter: 5000
  timesteps_total: 6955000
  training_iteration: 1391
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12097 s, 1391 iter, 6955000 ts, -9.13e+04 rew

agent-1: -3608.7907582839616
agent-2: -3196.9643918316274
agent-3: -4065.1562278345305
agent-4: -4460.8772197999815
agent-5: -4619.6512372545385
Extrinsic Rewards:
-3466
-3067
-3920
-4302
-4446
Sum Reward: -19201
Avg Reward: -3840.2
Min Reward: -4446
Max Reward: -3067
Gini Coefficient: -0.07487110046351753
20:20 Ratio: 0.6898335582546109
Max-min Ratio: 0.6898335582546109
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-55-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -15063.177830358487
  episode_reward_mean: -90355.8804244236
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1391
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 4.567
    dispatch_time_ms: 7.587
    learner:
      cur_lr: 0.0008967969915829599
      grad_gnorm: 40.000003814697266
      policy_entropy: 75.94032287597656
      policy_loss: 1733.3624267578125
      var_gnorm: 211.3848114013672
      vf_explained_var: 0.0
      vf_loss: 40823.70703125
    num_steps_sampled: 6960000
    num_steps_trained: 6960000
    wait_time_ms: 72.34
  iterations_since_restore: 1392
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12106.118535041809
  time_this_iter_s: 8.38464641571045
  time_total_s: 12106.118535041809
  timestamp: 1594868154
  timesteps_since_restore: 6960000
  timesteps_this_iter: 5000
  timesteps_total: 6960000
  training_iteration: 1392
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12106 s, 1392 iter, 6960000 ts, -9.04e+04 rew

agent-1: -4411.5500901658925
agent-2: -5439.967797696376
agent-3: -3998.8844805274084
agent-4: -4264.482863891298
agent-5: -4161.700192914306
Extrinsic Rewards:
-4256
-5261
-3864
-4123
-4015
Sum Reward: -21519
Avg Reward: -4303.8
Min Reward: -5261
Max Reward: -3864
Gini Coefficient: -0.05641526093219945
20:20 Ratio: 0.7344611290629158
Max-min Ratio: 0.7344611290629158
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-56-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -15063.177830358487
  episode_reward_mean: -89514.79762710593
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1392
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 4.042
    dispatch_time_ms: 4.653
    learner:
      cur_lr: 0.0008964639855548739
      grad_gnorm: 40.000003814697266
      policy_entropy: 71.91822814941406
      policy_loss: 1834.4149169921875
      var_gnorm: 210.99571228027344
      vf_explained_var: 0.0
      vf_loss: 57923.49609375
    num_steps_sampled: 6965000
    num_steps_trained: 6965000
    wait_time_ms: 78.49
  iterations_since_restore: 1393
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12114.597281217575
  time_this_iter_s: 8.478746175765991
  time_total_s: 12114.597281217575
  timestamp: 1594868163
  timesteps_since_restore: 6965000
  timesteps_this_iter: 5000
  timesteps_total: 6965000
  training_iteration: 1393
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12114 s, 1393 iter, 6965000 ts, -8.95e+04 rew

agent-1: -3360.076226713537
agent-2: -4774.742199241878
agent-3: -4226.251689548202
agent-4: -4730.139834780115
agent-5: -5107.557998051392
Extrinsic Rewards:
-3236
-4605
-4082
-4570
-4936
Sum Reward: -21429
Avg Reward: -4285.8
Min Reward: -4936
Max Reward: -3236
Gini Coefficient: -0.07322786877595781
20:20 Ratio: 0.6555915721231766
Max-min Ratio: 0.6555915721231766
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-56-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -15063.177830358487
  episode_reward_mean: -88658.53815309482
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1393
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.517
    dispatch_time_ms: 7.069
    learner:
      cur_lr: 0.000896130979526788
      grad_gnorm: 40.0
      policy_entropy: 71.87437438964844
      policy_loss: 2131.97802734375
      var_gnorm: 210.57171630859375
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 76089.140625
    num_steps_sampled: 6970000
    num_steps_trained: 6970000
    wait_time_ms: 72.133
  iterations_since_restore: 1394
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12123.038485050201
  time_this_iter_s: 8.441203832626343
  time_total_s: 12123.038485050201
  timestamp: 1594868171
  timesteps_since_restore: 6970000
  timesteps_this_iter: 5000
  timesteps_total: 6970000
  training_iteration: 1394
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12123 s, 1394 iter, 6970000 ts, -8.87e+04 rew

agent-1: -4537.282926163265
agent-2: -3757.1002327261544
agent-3: -4578.446220947523
agent-4: -4323.868440965205
agent-5: -5041.244698480466
Extrinsic Rewards:
-4384
-3625
-4421
-4171
-4877
Sum Reward: -21478
Avg Reward: -4295.6
Min Reward: -4877
Max Reward: -3625
Gini Coefficient: -0.05128969177763293
20:20 Ratio: 0.7432848062333401
Max-min Ratio: 0.7432848062333401
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-56-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -15063.177830358487
  episode_reward_mean: -87698.70229947042
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1394
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.733
    dispatch_time_ms: 8.371
    learner:
      cur_lr: 0.000895797973498702
      grad_gnorm: 40.0
      policy_entropy: 70.74188995361328
      policy_loss: 89.08460235595703
      var_gnorm: 210.1468963623047
      vf_explained_var: 0.0
      vf_loss: 53488.6484375
    num_steps_sampled: 6975000
    num_steps_trained: 6975000
    wait_time_ms: 73.222
  iterations_since_restore: 1395
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12142.071047067642
  time_this_iter_s: 19.032562017440796
  time_total_s: 12142.071047067642
  timestamp: 1594868190
  timesteps_since_restore: 6975000
  timesteps_this_iter: 5000
  timesteps_total: 6975000
  training_iteration: 1395
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12142 s, 1395 iter, 6975000 ts, -8.77e+04 rew

agent-1: -4520.353306854608
agent-2: -3654.545345056739
agent-3: -4514.111642403747
agent-4: -4654.217642992477
agent-5: -4361.2829345164
Extrinsic Rewards:
-4361
-3525
-4361
-4494
-4205
Sum Reward: -20946
Avg Reward: -4189.2
Min Reward: -4494
Max Reward: -3525
Gini Coefficient: -0.03998854196505299
20:20 Ratio: 0.7843791722296395
Max-min Ratio: 0.7843791722296395
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-56-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -15063.177830358487
  episode_reward_mean: -86880.29551936014
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1395
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.202
    dispatch_time_ms: 8.343
    learner:
      cur_lr: 0.000895465025678277
      grad_gnorm: 40.0
      policy_entropy: 67.64592742919922
      policy_loss: 1026.2137451171875
      var_gnorm: 209.67193603515625
      vf_explained_var: -1.0
      vf_loss: 47042.890625
    num_steps_sampled: 6980000
    num_steps_trained: 6980000
    wait_time_ms: 73.767
  iterations_since_restore: 1396
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12150.488670349121
  time_this_iter_s: 8.417623281478882
  time_total_s: 12150.488670349121
  timestamp: 1594868199
  timesteps_since_restore: 6980000
  timesteps_this_iter: 5000
  timesteps_total: 6980000
  training_iteration: 1396
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12150 s, 1396 iter, 6980000 ts, -8.69e+04 rew

agent-1: -3666.9019156635295
agent-2: -3381.709196782457
agent-3: -4535.693339362123
agent-4: -3811.2628952177192
agent-5: -3143.272232074195
Extrinsic Rewards:
-3515
-3243
-4361
-3657
-3012
Sum Reward: -17788
Avg Reward: -3557.6
Min Reward: -4361
Max Reward: -3012
Gini Coefficient: -0.06997976163705869
20:20 Ratio: 0.690667278147214
Max-min Ratio: 0.690667278147214
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-56-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -15063.177830358487
  episode_reward_mean: -85829.76241334627
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1396
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.186
    dispatch_time_ms: 10.107
    learner:
      cur_lr: 0.0008951320196501911
      grad_gnorm: 40.0
      policy_entropy: 64.70012664794922
      policy_loss: 2759.561767578125
      var_gnorm: 209.19264221191406
      vf_explained_var: 0.0
      vf_loss: 56768.296875
    num_steps_sampled: 6985000
    num_steps_trained: 6985000
    wait_time_ms: 70.293
  iterations_since_restore: 1397
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12158.895832061768
  time_this_iter_s: 8.407161712646484
  time_total_s: 12158.895832061768
  timestamp: 1594868207
  timesteps_since_restore: 6985000
  timesteps_this_iter: 5000
  timesteps_total: 6985000
  training_iteration: 1397
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12158 s, 1397 iter, 6985000 ts, -8.58e+04 rew

agent-1: -4221.178636591675
agent-2: -3224.321742196799
agent-3: -2808.642696776224
agent-4: -4156.74197564328
agent-5: -3341.9724665509743
Extrinsic Rewards:
-4046
-3082
-2682
-3991
-3199
Sum Reward: -17000
Avg Reward: -3400.0
Min Reward: -4046
Max Reward: -2682
Gini Coefficient: -0.0855764705882353
20:20 Ratio: 0.6628769154720712
Max-min Ratio: 0.6628769154720712
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-56-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -15063.177830358487
  episode_reward_mean: -84798.32551768834
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1397
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.001
    dispatch_time_ms: 6.662
    learner:
      cur_lr: 0.0008947990136221051
      grad_gnorm: 40.0
      policy_entropy: 69.76438903808594
      policy_loss: 2392.572509765625
      var_gnorm: 208.70712280273438
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 46810.546875
    num_steps_sampled: 6990000
    num_steps_trained: 6990000
    wait_time_ms: 74.464
  iterations_since_restore: 1398
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12167.34427022934
  time_this_iter_s: 8.448438167572021
  time_total_s: 12167.34427022934
  timestamp: 1594868216
  timesteps_since_restore: 6990000
  timesteps_this_iter: 5000
  timesteps_total: 6990000
  training_iteration: 1398
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12167 s, 1398 iter, 6990000 ts, -8.48e+04 rew

agent-1: -3489.0284068599613
agent-2: -3491.79926438607
agent-3: -3622.5310860089808
agent-4: -2835.56617186741
agent-5: -3203.5088561383463
Extrinsic Rewards:
-3330
-3348
-3449
-2690
-3049
Sum Reward: -15866
Avg Reward: -3173.2
Min Reward: -3449
Max Reward: -2690
Gini Coefficient: -0.04580864742216059
20:20 Ratio: 0.779936213395187
Max-min Ratio: 0.779936213395187
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-57-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -15063.177830358487
  episode_reward_mean: -83713.08822474447
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1398
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.888
    dispatch_time_ms: 5.613
    learner:
      cur_lr: 0.0008944660075940192
      grad_gnorm: 40.0
      policy_entropy: 67.28584289550781
      policy_loss: 3594.72119140625
      var_gnorm: 208.26084899902344
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 61034.4296875
    num_steps_sampled: 6995000
    num_steps_trained: 6995000
    wait_time_ms: 78.336
  iterations_since_restore: 1399
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12175.754135847092
  time_this_iter_s: 8.409865617752075
  time_total_s: 12175.754135847092
  timestamp: 1594868224
  timesteps_since_restore: 6995000
  timesteps_this_iter: 5000
  timesteps_total: 6995000
  training_iteration: 1399
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12175 s, 1399 iter, 6995000 ts, -8.37e+04 rew

agent-1: -4191.43380460417
agent-2: -3764.634710875369
agent-3: -4061.5813789875156
agent-4: -5082.952047386529
agent-5: -4173.5574541453825
Extrinsic Rewards:
-4035
-3630
-3920
-4907
-4024
Sum Reward: -20516
Avg Reward: -4103.2
Min Reward: -4907
Max Reward: -3630
Gini Coefficient: -0.05203743419769936
20:20 Ratio: 0.7397595272060322
Max-min Ratio: 0.7397595272060322
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-57-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -15063.177830358487
  episode_reward_mean: -82932.97098777747
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1399
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.43
    dispatch_time_ms: 8.708
    learner:
      cur_lr: 0.0008941330015659332
      grad_gnorm: 40.0
      policy_entropy: 62.11762237548828
      policy_loss: 3427.70361328125
      var_gnorm: 207.82821655273438
      vf_explained_var: 0.0
      vf_loss: 78912.5625
    num_steps_sampled: 7000000
    num_steps_trained: 7000000
    wait_time_ms: 69.818
  iterations_since_restore: 1400
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12184.211904525757
  time_this_iter_s: 8.457768678665161
  time_total_s: 12184.211904525757
  timestamp: 1594868233
  timesteps_since_restore: 7000000
  timesteps_this_iter: 5000
  timesteps_total: 7000000
  training_iteration: 1400
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12184 s, 1400 iter, 7000000 ts, -8.29e+04 rew

agent-1: -3770.967692783438
agent-2: -4375.910352454593
agent-3: -3347.9352613284864
agent-4: -3970.7540238344154
agent-5: -4094.963606008108
Extrinsic Rewards:
-3624
-4212
-3219
-3817
-3937
Sum Reward: -18809
Avg Reward: -3761.8
Min Reward: -4212
Max Reward: -3219
Gini Coefficient: -0.04889148811739061
20:20 Ratio: 0.7642450142450142
Max-min Ratio: 0.7642450142450142
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-57-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -15063.177830358487
  episode_reward_mean: -82108.63503833795
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1400
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.663
    dispatch_time_ms: 5.855
    learner:
      cur_lr: 0.0008937999955378473
      grad_gnorm: 40.0
      policy_entropy: 64.30802154541016
      policy_loss: 1660.758056640625
      var_gnorm: 207.33694458007812
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 40769.48046875
    num_steps_sampled: 7005000
    num_steps_trained: 7005000
    wait_time_ms: 72.047
  iterations_since_restore: 1401
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12192.589908123016
  time_this_iter_s: 8.378003597259521
  time_total_s: 12192.589908123016
  timestamp: 1594868241
  timesteps_since_restore: 7005000
  timesteps_this_iter: 5000
  timesteps_total: 7005000
  training_iteration: 1401
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12192 s, 1401 iter, 7005000 ts, -8.21e+04 rew

agent-1: -4420.402893880119
agent-2: -3548.435278219282
agent-3: -4150.2401240510435
agent-4: -3919.654169541645
agent-5: -4031.1072823893624
Extrinsic Rewards:
-4265
-3406
-3996
-3762
-3886
Sum Reward: -19315
Avg Reward: -3863.0
Min Reward: -4265
Max Reward: -3406
Gini Coefficient: -0.04042454051255501
20:20 Ratio: 0.7985932004689332
Max-min Ratio: 0.7985932004689332
agent-1: -3231.9011604844723
agent-2: -3877.747954326601
agent-3: -3848.180353642121
agent-4: -3882.9989949830265
agent-5: -3289.94900519592
Extrinsic Rewards:
-3097
-3688
-3682
-3701
-3156
Sum Reward: -17324
Avg Reward: -3464.8
Min Reward: -3701
Max Reward: -3097
Gini Coefficient: -0.040175479104132994
20:20 Ratio: 0.8368008646311808
Max-min Ratio: 0.8368008646311808
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-57-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -15063.177830358487
  episode_reward_mean: -81582.2553939803
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1401
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.88
    dispatch_time_ms: 8.853
    learner:
      cur_lr: 0.0008934669895097613
      grad_gnorm: 39.999996185302734
      policy_entropy: 61.516563415527344
      policy_loss: 2404.10302734375
      var_gnorm: 206.88755798339844
      vf_explained_var: -1.0
      vf_loss: 51023.078125
    num_steps_sampled: 7010000
    num_steps_trained: 7010000
    wait_time_ms: 71.464
  iterations_since_restore: 1402
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12201.062898874283
  time_this_iter_s: 8.47299075126648
  time_total_s: 12201.062898874283
  timestamp: 1594868250
  timesteps_since_restore: 7010000
  timesteps_this_iter: 5000
  timesteps_total: 7010000
  training_iteration: 1402
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12201 s, 1402 iter, 7010000 ts, -8.16e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-57-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -15063.177830358487
  episode_reward_mean: -80981.81953852337
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1402
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.403
    dispatch_time_ms: 7.954
    learner:
      cur_lr: 0.0008931339834816754
      grad_gnorm: 40.0
      policy_entropy: 64.9932632446289
      policy_loss: 1921.7620849609375
      var_gnorm: 206.43775939941406
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 42834.8671875
    num_steps_sampled: 7015000
    num_steps_trained: 7015000
    wait_time_ms: 72.844
  iterations_since_restore: 1403
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12209.41850399971
  time_this_iter_s: 8.355605125427246
  time_total_s: 12209.41850399971
  timestamp: 1594868258
  timesteps_since_restore: 7015000
  timesteps_this_iter: 5000
  timesteps_total: 7015000
  training_iteration: 1403
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12209 s, 1403 iter, 7015000 ts, -8.1e+04 rew

agent-1: -4269.96003959006
agent-2: -4169.946067756385
agent-3: -3454.397019686887
agent-4: -4545.798864998524
agent-5: -3809.38249537696
Extrinsic Rewards:
-4110
-4020
-3319
-4385
-3666
Sum Reward: -19500
Avg Reward: -3900.0
Min Reward: -4385
Max Reward: -3319
Gini Coefficient: -0.05284102564102564
20:20 Ratio: 0.7568985176738883
Max-min Ratio: 0.7568985176738883
agent-1: -6007.21937320232
agent-2: -4832.017295071208
agent-3: -3610.354696114365
agent-4: -3905.165631436371
agent-5: -4653.631759227189
Extrinsic Rewards:
-5814
-4670
-3488
-3774
-4498
Sum Reward: -22244
Avg Reward: -4448.8
Min Reward: -5814
Max Reward: -3488
Gini Coefficient: -0.09976622909548642
20:20 Ratio: 0.5999312005503956
Max-min Ratio: 0.5999312005503956
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-57-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -15063.177830358487
  episode_reward_mean: -79571.55487851443
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 2
  episodes_total: 1404
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.753
    dispatch_time_ms: 7.652
    learner:
      cur_lr: 0.0008928009774535894
      grad_gnorm: 40.0
      policy_entropy: 69.46612548828125
      policy_loss: 59184.8046875
      var_gnorm: 206.02365112304688
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 21573358.0
    num_steps_sampled: 7020000
    num_steps_trained: 7020000
    wait_time_ms: 75.776
  iterations_since_restore: 1404
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12217.863260269165
  time_this_iter_s: 8.444756269454956
  time_total_s: 12217.863260269165
  timestamp: 1594868266
  timesteps_since_restore: 7020000
  timesteps_this_iter: 5000
  timesteps_total: 7020000
  training_iteration: 1404
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12217 s, 1404 iter, 7020000 ts, -7.96e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-57-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -15063.177830358487
  episode_reward_mean: -79571.55487851443
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 0
  episodes_total: 1404
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.878
    dispatch_time_ms: 7.028
    learner:
      cur_lr: 0.0008924679714255035
      grad_gnorm: 40.0
      policy_entropy: 64.98577117919922
      policy_loss: 2000.101318359375
      var_gnorm: 205.55116271972656
      vf_explained_var: 0.0
      vf_loss: 54422.35546875
    num_steps_sampled: 7025000
    num_steps_trained: 7025000
    wait_time_ms: 75.027
  iterations_since_restore: 1405
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12226.256717681885
  time_this_iter_s: 8.393457412719727
  time_total_s: 12226.256717681885
  timestamp: 1594868275
  timesteps_since_restore: 7025000
  timesteps_this_iter: 5000
  timesteps_total: 7025000
  training_iteration: 1405
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12226 s, 1405 iter, 7025000 ts, -7.96e+04 rew

agent-1: -3226.4872033710726
agent-2: -3162.5291858500104
agent-3: -2516.0396801725383
agent-4: -3012.0578508692142
agent-5: -3135.320638287866
Extrinsic Rewards:
-3077
-3018
-2391
-2853
-2975
Sum Reward: -14314
Avg Reward: -2862.8
Min Reward: -3077
Max Reward: -2391
Gini Coefficient: -0.042950957104932234
20:20 Ratio: 0.7770555736106597
Max-min Ratio: 0.7770555736106597
agent-1: -2977.460580084059
agent-2: -2673.596182347746
agent-3: -2038.0848075348433
agent-4: -2424.3536355419897
agent-5: -2153.452315968175
Extrinsic Rewards:
-2815
-2523
-1905
-2268
-2019
Sum Reward: -11530
Avg Reward: -2306.0
Min Reward: -2815
Max Reward: -1905
Gini Coefficient: -0.0806244579358196
20:20 Ratio: 0.6767317939609236
Max-min Ratio: 0.6767317939609236
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-58-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12266.947521476692
  episode_reward_mean: -78322.94713103567
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 2
  episodes_total: 1406
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.735
    dispatch_time_ms: 6.011
    learner:
      cur_lr: 0.0008921350236050785
      grad_gnorm: 40.000003814697266
      policy_entropy: 61.610008239746094
      policy_loss: 61062.73046875
      var_gnorm: 205.06045532226562
      vf_explained_var: 3.5762786865234375e-07
      vf_loss: 21614970.0
    num_steps_sampled: 7030000
    num_steps_trained: 7030000
    wait_time_ms: 77.752
  iterations_since_restore: 1406
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12234.706971883774
  time_this_iter_s: 8.450254201889038
  time_total_s: 12234.706971883774
  timestamp: 1594868283
  timesteps_since_restore: 7030000
  timesteps_this_iter: 5000
  timesteps_total: 7030000
  training_iteration: 1406
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12234 s, 1406 iter, 7030000 ts, -7.83e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-58-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12266.947521476692
  episode_reward_mean: -78322.94713103567
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 0
  episodes_total: 1406
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.39
    dispatch_time_ms: 6.786
    learner:
      cur_lr: 0.0008918020175769925
      grad_gnorm: 40.0
      policy_entropy: 60.26963424682617
      policy_loss: 2116.291015625
      var_gnorm: 204.5730743408203
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 58052.9609375
    num_steps_sampled: 7035000
    num_steps_trained: 7035000
    wait_time_ms: 75.9
  iterations_since_restore: 1407
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12243.01293706894
  time_this_iter_s: 8.305965185165405
  time_total_s: 12243.01293706894
  timestamp: 1594868292
  timesteps_since_restore: 7035000
  timesteps_this_iter: 5000
  timesteps_total: 7035000
  training_iteration: 1407
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12243 s, 1407 iter, 7035000 ts, -7.83e+04 rew

agent-1: -2604.5932029289415
agent-2: -1988.3941965525894
agent-3: -2923.593360626162
agent-4: -2486.1199843293957
agent-5: -2397.875078529347
Extrinsic Rewards:
-2446
-1868
-2746
-2314
-2256
Sum Reward: -11630
Avg Reward: -2326.0
Min Reward: -2746
Max Reward: -1868
Gini Coefficient: -0.06693035253654342
20:20 Ratio: 0.6802621995630007
Max-min Ratio: 0.6802621995630007
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-58-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12266.947521476692
  episode_reward_mean: -77734.51092280094
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1407
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.464
    dispatch_time_ms: 6.226
    learner:
      cur_lr: 0.0008914690115489066
      grad_gnorm: 40.0
      policy_entropy: 61.99012756347656
      policy_loss: 3009.2490234375
      var_gnorm: 204.09381103515625
      vf_explained_var: 0.0
      vf_loss: 77351.125
    num_steps_sampled: 7040000
    num_steps_trained: 7040000
    wait_time_ms: 78.031
  iterations_since_restore: 1408
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12251.43111205101
  time_this_iter_s: 8.418174982070923
  time_total_s: 12251.43111205101
  timestamp: 1594868300
  timesteps_since_restore: 7040000
  timesteps_this_iter: 5000
  timesteps_total: 7040000
  training_iteration: 1408
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12251 s, 1408 iter, 7040000 ts, -7.77e+04 rew

agent-1: -2193.817874275366
agent-2: -2366.9433976609203
agent-3: -2629.9781194093594
agent-4: -2827.3199202819683
agent-5: -2103.4326166640094
Extrinsic Rewards:
-2057
-2217
-2463
-2666
-1964
Sum Reward: -11367
Avg Reward: -2273.4
Min Reward: -2666
Max Reward: -1964
Gini Coefficient: -0.06369314682853876
20:20 Ratio: 0.7366841710427607
Max-min Ratio: 0.7366841710427607
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-58-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12121.49192829153
  episode_reward_mean: -76991.94727541904
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1408
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.143
    dispatch_time_ms: 8.429
    learner:
      cur_lr: 0.0008911360055208206
      grad_gnorm: 40.000003814697266
      policy_entropy: 61.36585235595703
      policy_loss: 3352.329345703125
      var_gnorm: 203.62448120117188
      vf_explained_var: 0.0
      vf_loss: 76649.9375
    num_steps_sampled: 7045000
    num_steps_trained: 7045000
    wait_time_ms: 72.928
  iterations_since_restore: 1409
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12259.763174533844
  time_this_iter_s: 8.332062482833862
  time_total_s: 12259.763174533844
  timestamp: 1594868308
  timesteps_since_restore: 7045000
  timesteps_this_iter: 5000
  timesteps_total: 7045000
  training_iteration: 1409
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12259 s, 1409 iter, 7045000 ts, -7.7e+04 rew

agent-1: -3000.011756405608
agent-2: -2501.9464067632
agent-3: -2684.147790911611
agent-4: -2274.7250329989965
agent-5: -2552.498212683984
Extrinsic Rewards:
-2812
-2368
-2529
-2127
-2409
Sum Reward: -12245
Avg Reward: -2449.0
Min Reward: -2812
Max Reward: -2127
Gini Coefficient: -0.05001224989791752
20:20 Ratio: 0.7564011379800853
Max-min Ratio: 0.7564011379800853
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-58-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12121.49192829153
  episode_reward_mean: -75967.75115785189
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1409
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.835
    dispatch_time_ms: 7.213
    learner:
      cur_lr: 0.0008908029994927347
      grad_gnorm: 40.0
      policy_entropy: 65.08159637451172
      policy_loss: 2377.902587890625
      var_gnorm: 203.15505981445312
      vf_explained_var: 0.0
      vf_loss: 63239.5
    num_steps_sampled: 7050000
    num_steps_trained: 7050000
    wait_time_ms: 72.891
  iterations_since_restore: 1410
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12268.10671210289
  time_this_iter_s: 8.34353756904602
  time_total_s: 12268.10671210289
  timestamp: 1594868317
  timesteps_since_restore: 7050000
  timesteps_this_iter: 5000
  timesteps_total: 7050000
  training_iteration: 1410
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12268 s, 1410 iter, 7050000 ts, -7.6e+04 rew

agent-1: -2581.3695590787324
agent-2: -1954.2121388549212
agent-3: -1841.2471939419877
agent-4: -2675.502799445505
agent-5: -2775.5121511078187
Extrinsic Rewards:
-2427
-1823
-1708
-2511
-2613
Sum Reward: -11082
Avg Reward: -2216.4
Min Reward: -2613
Max Reward: -1708
Gini Coefficient: -0.09016423028334236
20:20 Ratio: 0.6536548029085343
Max-min Ratio: 0.6536548029085343
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-58-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -11827.843842428914
  episode_reward_mean: -74980.59629102744
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1410
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.078
    dispatch_time_ms: 9.271
    learner:
      cur_lr: 0.0008904699934646487
      grad_gnorm: 40.0
      policy_entropy: 67.39451599121094
      policy_loss: 2098.904296875
      var_gnorm: 202.68870544433594
      vf_explained_var: 0.0
      vf_loss: 50069.4765625
    num_steps_sampled: 7055000
    num_steps_trained: 7055000
    wait_time_ms: 68.682
  iterations_since_restore: 1411
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12276.468827009201
  time_this_iter_s: 8.362114906311035
  time_total_s: 12276.468827009201
  timestamp: 1594868325
  timesteps_since_restore: 7055000
  timesteps_this_iter: 5000
  timesteps_total: 7055000
  training_iteration: 1411
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12276 s, 1411 iter, 7055000 ts, -7.5e+04 rew

agent-1: -3048.265724994723
agent-2: -2777.246119512732
agent-3: -3450.640103722745
agent-4: -2987.3978734410425
agent-5: -2944.0321608561094
Extrinsic Rewards:
-2894
-2640
-3285
-2829
-2796
Sum Reward: -14444
Avg Reward: -2888.8
Min Reward: -3285
Max Reward: -2640
Gini Coefficient: -0.038438105787870394
20:20 Ratio: 0.8036529680365296
Max-min Ratio: 0.8036529680365296
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-58-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -11827.843842428914
  episode_reward_mean: -73750.83147286996
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1411
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.497
    dispatch_time_ms: 9.264
    learner:
      cur_lr: 0.0008901369874365628
      grad_gnorm: 40.0
      policy_entropy: 64.50199890136719
      policy_loss: 2556.56787109375
      var_gnorm: 202.22752380371094
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 52423.0625
    num_steps_sampled: 7060000
    num_steps_trained: 7060000
    wait_time_ms: 72.834
  iterations_since_restore: 1412
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12284.89564538002
  time_this_iter_s: 8.426818370819092
  time_total_s: 12284.89564538002
  timestamp: 1594868334
  timesteps_since_restore: 7060000
  timesteps_this_iter: 5000
  timesteps_total: 7060000
  training_iteration: 1412
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12284 s, 1412 iter, 7060000 ts, -7.38e+04 rew

agent-1: -2420.3336358458787
agent-2: -3201.1750738112937
agent-3: -3348.286560038812
agent-4: -2727.321019448879
agent-5: -2878.946777584665
Extrinsic Rewards:
-2284
-3038
-3176
-2585
-2732
Sum Reward: -13815
Avg Reward: -2763.0
Min Reward: -3176
Max Reward: -2284
Gini Coefficient: -0.06477017734346724
20:20 Ratio: 0.7191435768261965
Max-min Ratio: 0.7191435768261965
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-59-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -11827.843842428914
  episode_reward_mean: -72808.74513471169
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1412
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.422
    dispatch_time_ms: 9.549
    learner:
      cur_lr: 0.0008898039814084768
      grad_gnorm: 40.0
      policy_entropy: 65.83562469482422
      policy_loss: 2089.948486328125
      var_gnorm: 201.79129028320312
      vf_explained_var: 0.0
      vf_loss: 54333.38671875
    num_steps_sampled: 7065000
    num_steps_trained: 7065000
    wait_time_ms: 72.64
  iterations_since_restore: 1413
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12293.279832601547
  time_this_iter_s: 8.3841872215271
  time_total_s: 12293.279832601547
  timestamp: 1594868342
  timesteps_since_restore: 7065000
  timesteps_this_iter: 5000
  timesteps_total: 7065000
  training_iteration: 1413
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12293 s, 1413 iter, 7065000 ts, -7.28e+04 rew

agent-1: -3649.890343556125
agent-2: -2967.3671330885577
agent-3: -4015.2003926768557
agent-4: -2673.2119211706386
agent-5: -2940.3656871837848
Extrinsic Rewards:
-3478
-2830
-3837
-2541
-2788
Sum Reward: -15474
Avg Reward: -3094.8
Min Reward: -3837
Max Reward: -2541
Gini Coefficient: -0.08483908491663436
20:20 Ratio: 0.6622361219702892
Max-min Ratio: 0.6622361219702892
agent-1: -2769.0673154595497
agent-2: -3540.4403693734776
agent-3: -3265.112745680264
agent-4: -3430.1103931972298
agent-5: -4071.1785169364384
Extrinsic Rewards:
-2644
-3380
-3116
-3283
-3893
Sum Reward: -16316
Avg Reward: -3263.2
Min Reward: -3893
Max Reward: -2644
Gini Coefficient: -0.06771267467516548
20:20 Ratio: 0.6791677369637812
Max-min Ratio: 0.6791677369637812
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-59-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -11827.843842428914
  episode_reward_mean: -70617.40487740509
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 2
  episodes_total: 1414
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.988
    dispatch_time_ms: 7.801
    learner:
      cur_lr: 0.0008894709753803909
      grad_gnorm: 40.0
      policy_entropy: 65.59976959228516
      policy_loss: 56562.49609375
      var_gnorm: 201.32806396484375
      vf_explained_var: 1.6987323760986328e-05
      vf_loss: 21581554.0
    num_steps_sampled: 7070000
    num_steps_trained: 7070000
    wait_time_ms: 71.031
  iterations_since_restore: 1414
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12301.718258142471
  time_this_iter_s: 8.438425540924072
  time_total_s: 12301.718258142471
  timestamp: 1594868351
  timesteps_since_restore: 7070000
  timesteps_this_iter: 5000
  timesteps_total: 7070000
  training_iteration: 1414
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12301 s, 1414 iter, 7070000 ts, -7.06e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-59-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -11827.843842428914
  episode_reward_mean: -70617.40487740509
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 0
  episodes_total: 1414
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.928
    dispatch_time_ms: 23.168
    learner:
      cur_lr: 0.0008891380275599658
      grad_gnorm: 40.0
      policy_entropy: 63.201351165771484
      policy_loss: 2471.733642578125
      var_gnorm: 200.8534698486328
      vf_explained_var: 0.0
      vf_loss: 73893.9375
    num_steps_sampled: 7075000
    num_steps_trained: 7075000
    wait_time_ms: 70.029
  iterations_since_restore: 1415
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12310.475707530975
  time_this_iter_s: 8.757449388504028
  time_total_s: 12310.475707530975
  timestamp: 1594868359
  timesteps_since_restore: 7075000
  timesteps_this_iter: 5000
  timesteps_total: 7075000
  training_iteration: 1415
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12310 s, 1415 iter, 7075000 ts, -7.06e+04 rew

agent-1: -3043.995954622512
agent-2: -2768.6352353492875
agent-3: -2855.3710762481446
agent-4: -2710.4775976021747
agent-5: -2358.757726060834
Extrinsic Rewards:
-2871
-2619
-2677
-2569
-2220
Sum Reward: -12956
Avg Reward: -2591.2
Min Reward: -2871
Max Reward: -2220
Gini Coefficient: -0.04353195430688484
20:20 Ratio: 0.7732497387669801
Max-min Ratio: 0.7732497387669801
agent-1: -2225.806218547516
agent-2: -2211.480049616706
agent-3: -2371.4017467204526
agent-4: -1573.9446182204806
agent-5: -2211.6178291971673
Extrinsic Rewards:
-2070
-2063
-2207
-1461
-2058
Sum Reward: -9859
Avg Reward: -1971.8
Min Reward: -2207
Max Reward: -1461
Gini Coefficient: -0.06102038746323157
20:20 Ratio: 0.6619845944721341
Max-min Ratio: 0.6619845944721341
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-59-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -11827.843842428914
  episode_reward_mean: -69498.0549800423
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1415
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.591
    dispatch_time_ms: 21.844
    learner:
      cur_lr: 0.0008888050215318799
      grad_gnorm: 40.0
      policy_entropy: 60.529624938964844
      policy_loss: 1547.09130859375
      var_gnorm: 200.37051391601562
      vf_explained_var: -0.19228756427764893
      vf_loss: 44657.453125
    num_steps_sampled: 7080000
    num_steps_trained: 7080000
    wait_time_ms: 59.569
  iterations_since_restore: 1416
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12319.478856563568
  time_this_iter_s: 9.003149032592773
  time_total_s: 12319.478856563568
  timestamp: 1594868368
  timesteps_since_restore: 7080000
  timesteps_this_iter: 5000
  timesteps_total: 7080000
  training_iteration: 1416
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12319 s, 1416 iter, 7080000 ts, -6.95e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-59-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -68090.71455712244
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1416
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.605
    dispatch_time_ms: 27.4
    learner:
      cur_lr: 0.000888472015503794
      grad_gnorm: 40.000003814697266
      policy_entropy: 58.543251037597656
      policy_loss: 2595.409912109375
      var_gnorm: 199.8986053466797
      vf_explained_var: 0.0
      vf_loss: 72881.1953125
    num_steps_sampled: 7085000
    num_steps_trained: 7085000
    wait_time_ms: 65.095
  iterations_since_restore: 1417
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12328.496923685074
  time_this_iter_s: 9.018067121505737
  time_total_s: 12328.496923685074
  timestamp: 1594868377
  timesteps_since_restore: 7085000
  timesteps_this_iter: 5000
  timesteps_total: 7085000
  training_iteration: 1417
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12328 s, 1417 iter, 7085000 ts, -6.81e+04 rew

agent-1: -3245.482926689345
agent-2: -2995.352535023178
agent-3: -2926.8387208032555
agent-4: -2732.671255277465
agent-5: -2823.6851486250075
Extrinsic Rewards:
-3082
-2843
-2783
-2593
-2679
Sum Reward: -13980
Avg Reward: -2796.0
Min Reward: -3082
Max Reward: -2593
Gini Coefficient: -0.03267525035765379
20:20 Ratio: 0.8413367942894224
Max-min Ratio: 0.8413367942894224
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-59-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -66609.00575725066
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1417
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.922
    dispatch_time_ms: 19.475
    learner:
      cur_lr: 0.000888139009475708
      grad_gnorm: 40.0
      policy_entropy: 60.89419174194336
      policy_loss: 1258.69873046875
      var_gnorm: 199.44601440429688
      vf_explained_var: -0.20469367504119873
      vf_loss: 42923.76171875
    num_steps_sampled: 7090000
    num_steps_trained: 7090000
    wait_time_ms: 65.106
  iterations_since_restore: 1418
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12337.362745046616
  time_this_iter_s: 8.865821361541748
  time_total_s: 12337.362745046616
  timestamp: 1594868386
  timesteps_since_restore: 7090000
  timesteps_this_iter: 5000
  timesteps_total: 7090000
  training_iteration: 1418
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12337 s, 1418 iter, 7090000 ts, -6.66e+04 rew

agent-1: -2795.455227103396
agent-2: -2881.098425967255
agent-3: -2990.7889995575124
agent-4: -2583.7126625572464
agent-5: -2513.9114770377973
Extrinsic Rewards:
-2637
-2731
-2829
-2446
-2374
Sum Reward: -13017
Avg Reward: -2603.4
Min Reward: -2829
Max Reward: -2374
Gini Coefficient: -0.03672121072443727
20:20 Ratio: 0.8391657829621775
Max-min Ratio: 0.8391657829621775
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-59-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -65235.935377779475
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1418
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.15
    dispatch_time_ms: 36.128
    learner:
      cur_lr: 0.0008878060034476221
      grad_gnorm: 40.0
      policy_entropy: 61.47673416137695
      policy_loss: 2422.55517578125
      var_gnorm: 199.0238494873047
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 67399.7421875
    num_steps_sampled: 7095000
    num_steps_trained: 7095000
    wait_time_ms: 33.475
  iterations_since_restore: 1419
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12346.329999923706
  time_this_iter_s: 8.967254877090454
  time_total_s: 12346.329999923706
  timestamp: 1594868395
  timesteps_since_restore: 7095000
  timesteps_this_iter: 5000
  timesteps_total: 7095000
  training_iteration: 1419
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12346 s, 1419 iter, 7095000 ts, -6.52e+04 rew

agent-1: -5420.5480341075245
agent-2: -4891.523377622937
agent-3: -4321.834522530969
agent-4: -4535.006979093455
agent-5: -4323.069215180111
Extrinsic Rewards:
-5243
-4738
-4184
-4383
-4174
Sum Reward: -22722
Avg Reward: -4544.4
Min Reward: -5243
Max Reward: -4174
Gini Coefficient: -0.04739019452512983
20:20 Ratio: 0.7961090978447454
Max-min Ratio: 0.7961090978447454
agent-1: -5207.47301169629
agent-2: -4570.313178871904
agent-3: -3647.0803173745185
agent-4: -5211.323083566983
agent-5: -3963.2859306879654
Extrinsic Rewards:
-5040
-4401
-3527
-5032
-3831
Sum Reward: -21831
Avg Reward: -4366.2
Min Reward: -5040
Max Reward: -3527
Gini Coefficient: -0.07744949841967844
20:20 Ratio: 0.6998015873015873
Max-min Ratio: 0.6998015873015873
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-00-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -62540.92714244566
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 2
  episodes_total: 1420
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.735
    dispatch_time_ms: 27.895
    learner:
      cur_lr: 0.0008874729974195361
      grad_gnorm: 40.000003814697266
      policy_entropy: 65.35857391357422
      policy_loss: 1576.3189697265625
      var_gnorm: 198.6565399169922
      vf_explained_var: -0.7277059555053711
      vf_loss: 41526.98828125
    num_steps_sampled: 7100000
    num_steps_trained: 7100000
    wait_time_ms: 70.755
  iterations_since_restore: 1420
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12355.503756284714
  time_this_iter_s: 9.17375636100769
  time_total_s: 12355.503756284714
  timestamp: 1594868405
  timesteps_since_restore: 7100000
  timesteps_this_iter: 5000
  timesteps_total: 7100000
  training_iteration: 1420
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12355 s, 1420 iter, 7100000 ts, -6.25e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-00-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -62540.927142445675
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 0
  episodes_total: 1420
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 4.271
    dispatch_time_ms: 51.454
    learner:
      cur_lr: 0.0008871399913914502
      grad_gnorm: 40.0
      policy_entropy: 68.73542022705078
      policy_loss: 765.1798095703125
      var_gnorm: 198.4841766357422
      vf_explained_var: 0.0
      vf_loss: 51106.19921875
    num_steps_sampled: 7105000
    num_steps_trained: 7105000
    wait_time_ms: 44.277
  iterations_since_restore: 1421
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12364.543575763702
  time_this_iter_s: 9.039819478988647
  time_total_s: 12364.543575763702
  timestamp: 1594868414
  timesteps_since_restore: 7105000
  timesteps_this_iter: 5000
  timesteps_total: 7105000
  training_iteration: 1421
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12364 s, 1421 iter, 7105000 ts, -6.25e+04 rew

agent-1: -5955.762220811928
agent-2: -6742.738095364849
agent-3: -6284.815977773163
agent-4: -6285.229444918941
agent-5: -6192.51964689284
Extrinsic Rewards:
-5812
-6578
-6134
-6136
-6038
Sum Reward: -30698
Avg Reward: -6139.6
Min Reward: -6578
Max Reward: -5812
Gini Coefficient: -0.021239168675483745
20:20 Ratio: 0.8835512313773183
Max-min Ratio: 0.8835512313773183
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-00-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -60962.5246305482
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1421
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.2
    dispatch_time_ms: 28.8
    learner:
      cur_lr: 0.0008868069853633642
      grad_gnorm: 40.000003814697266
      policy_entropy: 60.75210189819336
      policy_loss: 1262.8427734375
      var_gnorm: 198.23410034179688
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 33292.875
    num_steps_sampled: 7110000
    num_steps_trained: 7110000
    wait_time_ms: 53.746
  iterations_since_restore: 1422
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12373.289771318436
  time_this_iter_s: 8.746195554733276
  time_total_s: 12373.289771318436
  timestamp: 1594868422
  timesteps_since_restore: 7110000
  timesteps_this_iter: 5000
  timesteps_total: 7110000
  training_iteration: 1422
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12373 s, 1422 iter, 7110000 ts, -6.1e+04 rew

agent-1: -7657.963816387982
agent-2: -9890.222868017958
agent-3: -7251.957263457549
agent-4: -6905.3218253579125
agent-5: -6912.874774306165
Extrinsic Rewards:
-7507
-9713
-7106
-6765
-6776
Sum Reward: -37867
Avg Reward: -7573.4
Min Reward: -9713
Max Reward: -6765
Gini Coefficient: -0.07000290490400612
20:20 Ratio: 0.6964892412231031
Max-min Ratio: 0.6964892412231031
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-00-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -59591.378677702574
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1422
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.069
    dispatch_time_ms: 8.642
    learner:
      cur_lr: 0.0008864739793352783
      grad_gnorm: 40.0
      policy_entropy: 65.27734375
      policy_loss: 2867.451416015625
      var_gnorm: 197.9319305419922
      vf_explained_var: 0.0
      vf_loss: 66693.8828125
    num_steps_sampled: 7115000
    num_steps_trained: 7115000
    wait_time_ms: 51.19
  iterations_since_restore: 1423
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12392.556566953659
  time_this_iter_s: 19.26679563522339
  time_total_s: 12392.556566953659
  timestamp: 1594868442
  timesteps_since_restore: 7115000
  timesteps_this_iter: 5000
  timesteps_total: 7115000
  training_iteration: 1423
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12392 s, 1423 iter, 7115000 ts, -5.96e+04 rew

agent-1: -5987.468645542297
agent-2: -6946.789928473059
agent-3: -7812.774086210744
agent-4: -6529.706015573312
agent-5: -6893.477752839873
Extrinsic Rewards:
-5849
-6788
-7640
-6387
-6743
Sum Reward: -33407
Avg Reward: -6681.4
Min Reward: -7640
Max Reward: -5849
Gini Coefficient: -0.04769060376567785
20:20 Ratio: 0.7655759162303665
Max-min Ratio: 0.7655759162303665
agent-1: -5126.620774143849
agent-2: -6533.646189216159
agent-3: -5826.53146449346
agent-4: -5801.308235256039
agent-5: -6453.075655098316
Extrinsic Rewards:
-4988
-6372
-5679
-5646
-6287
Sum Reward: -28972
Avg Reward: -5794.4
Min Reward: -6372
Max Reward: -4988
Gini Coefficient: -0.04706613281789314
20:20 Ratio: 0.7827997489014438
Max-min Ratio: 0.7827997489014438
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-00-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -57048.117008655005
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 2
  episodes_total: 1424
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.722
    dispatch_time_ms: 7.647
    learner:
      cur_lr: 0.0008861409733071923
      grad_gnorm: 40.0
      policy_entropy: 65.27581024169922
      policy_loss: 64117.8515625
      var_gnorm: 197.65533447265625
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 18204240.0
    num_steps_sampled: 7120000
    num_steps_trained: 7120000
    wait_time_ms: 75.595
  iterations_since_restore: 1424
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12401.021939516068
  time_this_iter_s: 8.465372562408447
  time_total_s: 12401.021939516068
  timestamp: 1594868450
  timesteps_since_restore: 7120000
  timesteps_this_iter: 5000
  timesteps_total: 7120000
  training_iteration: 1424
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12401 s, 1424 iter, 7120000 ts, -5.7e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-00-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -57048.117008655
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 0
  episodes_total: 1424
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.86
    dispatch_time_ms: 10.255
    learner:
      cur_lr: 0.0008858080254867673
      grad_gnorm: 40.0
      policy_entropy: 67.06495666503906
      policy_loss: 513.9835205078125
      var_gnorm: 197.54750061035156
      vf_explained_var: 0.0
      vf_loss: 35710.83203125
    num_steps_sampled: 7125000
    num_steps_trained: 7125000
    wait_time_ms: 68.893
  iterations_since_restore: 1425
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12409.4670855999
  time_this_iter_s: 8.445146083831787
  time_total_s: 12409.4670855999
  timestamp: 1594868459
  timesteps_since_restore: 7125000
  timesteps_this_iter: 5000
  timesteps_total: 7125000
  training_iteration: 1425
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12409 s, 1425 iter, 7125000 ts, -5.7e+04 rew

agent-1: -7556.724347870776
agent-2: -9134.386167831417
agent-3: -10153.352220916528
agent-4: -10102.688709407445
agent-5: -10111.254127867478
Extrinsic Rewards:
-7431
-8981
-9996
-9939
-9947
Sum Reward: -46294
Avg Reward: -9258.8
Min Reward: -9996
Max Reward: -7431
Gini Coefficient: -0.05267205253380568
20:20 Ratio: 0.7433973589435774
Max-min Ratio: 0.7433973589435774
agent-1: -8803.14582638619
agent-2: -6819.321380232472
agent-3: -7282.601327559984
agent-4: -8369.519317617987
agent-5: -7550.592947468633
Extrinsic Rewards:
-8633
-6683
-7137
-8206
-7405
Sum Reward: -38064
Avg Reward: -7612.8
Min Reward: -8633
Max Reward: -6683
Gini Coefficient: -0.05221731820092476
20:20 Ratio: 0.7741225529943241
Max-min Ratio: 0.7741225529943241
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-01-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -54703.707826639664
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 2
  episodes_total: 1426
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.613
    dispatch_time_ms: 5.366
    learner:
      cur_lr: 0.0008854750194586813
      grad_gnorm: 40.000003814697266
      policy_entropy: 60.08282470703125
      policy_loss: 52967.64453125
      var_gnorm: 197.42205810546875
      vf_explained_var: 0.0
      vf_loss: 18203788.0
    num_steps_sampled: 7130000
    num_steps_trained: 7130000
    wait_time_ms: 76.262
  iterations_since_restore: 1426
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12417.961122989655
  time_this_iter_s: 8.494037389755249
  time_total_s: 12417.961122989655
  timestamp: 1594868467
  timesteps_since_restore: 7130000
  timesteps_this_iter: 5000
  timesteps_total: 7130000
  training_iteration: 1426
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12417 s, 1426 iter, 7130000 ts, -5.47e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-01-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -54703.70782663967
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 0
  episodes_total: 1426
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.726
    dispatch_time_ms: 6.585
    learner:
      cur_lr: 0.0008851420134305954
      grad_gnorm: 40.0
      policy_entropy: 64.03584289550781
      policy_loss: -1141.03662109375
      var_gnorm: 197.26121520996094
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 72264.5703125
    num_steps_sampled: 7135000
    num_steps_trained: 7135000
    wait_time_ms: 73.441
  iterations_since_restore: 1427
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12426.260048151016
  time_this_iter_s: 8.298925161361694
  time_total_s: 12426.260048151016
  timestamp: 1594868476
  timesteps_since_restore: 7135000
  timesteps_this_iter: 5000
  timesteps_total: 7135000
  training_iteration: 1427
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12426 s, 1427 iter, 7135000 ts, -5.47e+04 rew

agent-1: -7910.615780497298
agent-2: -6678.902420898795
agent-3: -8219.176408546602
agent-4: -7700.516072077793
agent-5: -9724.072343540314
Extrinsic Rewards:
-7756
-6549
-8062
-7550
-9540
Sum Reward: -39457
Avg Reward: -7891.4
Min Reward: -9540
Max Reward: -6549
Gini Coefficient: -0.06583369237397674
20:20 Ratio: 0.6864779874213837
Max-min Ratio: 0.6864779874213837
agent-1: -6512.460939477609
agent-2: -8222.778768068503
agent-3: -9298.005156303787
agent-4: -6603.462840494767
agent-5: -6463.345112065997
Extrinsic Rewards:
-6380
-8063
-9116
-6472
-6323
Sum Reward: -36354
Avg Reward: -7270.8
Min Reward: -9116
Max Reward: -6323
Gini Coefficient: -0.07998019475160918
20:20 Ratio: 0.6936156208863536
Max-min Ratio: 0.6936156208863536
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-01-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -52863.268640054244
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 2
  episodes_total: 1428
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.954
    dispatch_time_ms: 8.388
    learner:
      cur_lr: 0.0008848090074025095
      grad_gnorm: 40.0
      policy_entropy: 59.82517623901367
      policy_loss: 53482.25
      var_gnorm: 197.07180786132812
      vf_explained_var: -3.5762786865234375e-07
      vf_loss: 20135832.0
    num_steps_sampled: 7140000
    num_steps_trained: 7140000
    wait_time_ms: 73.589
  iterations_since_restore: 1428
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12434.756082057953
  time_this_iter_s: 8.496033906936646
  time_total_s: 12434.756082057953
  timestamp: 1594868484
  timesteps_since_restore: 7140000
  timesteps_this_iter: 5000
  timesteps_total: 7140000
  training_iteration: 1428
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12434 s, 1428 iter, 7140000 ts, -5.29e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-01-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -52863.26864005423
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 0
  episodes_total: 1428
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.446
    dispatch_time_ms: 7.731
    learner:
      cur_lr: 0.0008844760013744235
      grad_gnorm: 39.999996185302734
      policy_entropy: 53.53031921386719
      policy_loss: 824.41162109375
      var_gnorm: 196.70306396484375
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 36215.33984375
    num_steps_sampled: 7145000
    num_steps_trained: 7145000
    wait_time_ms: 72.388
  iterations_since_restore: 1429
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12442.958387374878
  time_this_iter_s: 8.202305316925049
  time_total_s: 12442.958387374878
  timestamp: 1594868492
  timesteps_since_restore: 7145000
  timesteps_this_iter: 5000
  timesteps_total: 7145000
  training_iteration: 1429
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12442 s, 1429 iter, 7145000 ts, -5.29e+04 rew

agent-1: -5680.667430975615
agent-2: -5973.912574479859
agent-3: -5578.079382062114
agent-4: -5178.026226984076
agent-5: -4230.222399340322
Extrinsic Rewards:
-5527
-5809
-5417
-5027
-4104
Sum Reward: -25884
Avg Reward: -5176.8
Min Reward: -5809
Max Reward: -4104
Gini Coefficient: -0.060423427600061815
20:20 Ratio: 0.7064899294198658
Max-min Ratio: 0.7064899294198658
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-01-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -51679.312092002285
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1429
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.692
    dispatch_time_ms: 6.986
    learner:
      cur_lr: 0.0008841429953463376
      grad_gnorm: 40.0
      policy_entropy: 48.80841827392578
      policy_loss: 578.6859741210938
      var_gnorm: 196.32920837402344
      vf_explained_var: -0.1626758575439453
      vf_loss: 53486.02734375
    num_steps_sampled: 7150000
    num_steps_trained: 7150000
    wait_time_ms: 72.85
  iterations_since_restore: 1430
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12451.274179458618
  time_this_iter_s: 8.315792083740234
  time_total_s: 12451.274179458618
  timestamp: 1594868501
  timesteps_since_restore: 7150000
  timesteps_this_iter: 5000
  timesteps_total: 7150000
  training_iteration: 1430
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12451 s, 1430 iter, 7150000 ts, -5.17e+04 rew

agent-1: -3247.9448618007236
agent-2: -3984.4749083694974
agent-3: -4994.873172667502
agent-4: -4635.395240814725
agent-5: -4997.081627669545
Extrinsic Rewards:
-3118
-3840
-4831
-4480
-4832
Sum Reward: -21101
Avg Reward: -4220.2
Min Reward: -4832
Max Reward: -3118
Gini Coefficient: -0.08376854177527131
20:20 Ratio: 0.6452814569536424
Max-min Ratio: 0.6452814569536424
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-01-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -50330.60690223074
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1430
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.835
    dispatch_time_ms: 7.976
    learner:
      cur_lr: 0.0008838099893182516
      grad_gnorm: 40.0
      policy_entropy: 58.117122650146484
      policy_loss: 1887.0943603515625
      var_gnorm: 195.9783172607422
      vf_explained_var: 0.0
      vf_loss: 32314.974609375
    num_steps_sampled: 7155000
    num_steps_trained: 7155000
    wait_time_ms: 73.291
  iterations_since_restore: 1431
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12459.533502101898
  time_this_iter_s: 8.25932264328003
  time_total_s: 12459.533502101898
  timestamp: 1594868509
  timesteps_since_restore: 7155000
  timesteps_this_iter: 5000
  timesteps_total: 7155000
  training_iteration: 1431
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12459 s, 1431 iter, 7155000 ts, -5.03e+04 rew

agent-1: -4995.842394662781
agent-2: -4794.920453719299
agent-3: -3985.080144817168
agent-4: -5841.897767968305
agent-5: -5801.212152938231
Extrinsic Rewards:
-4853
-4649
-3862
-5667
-5630
Sum Reward: -24661
Avg Reward: -4932.2
Min Reward: -5667
Max Reward: -3862
Gini Coefficient: -0.07446575564656746
20:20 Ratio: 0.6814893241574025
Max-min Ratio: 0.6814893241574025
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-01-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -49164.882853737276
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1431
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.518
    dispatch_time_ms: 8.232
    learner:
      cur_lr: 0.0008834769832901657
      grad_gnorm: 40.0
      policy_entropy: 58.027442932128906
      policy_loss: 2210.128173828125
      var_gnorm: 195.63787841796875
      vf_explained_var: -0.39904868602752686
      vf_loss: 45760.77734375
    num_steps_sampled: 7160000
    num_steps_trained: 7160000
    wait_time_ms: 74.425
  iterations_since_restore: 1432
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12467.941839456558
  time_this_iter_s: 8.408337354660034
  time_total_s: 12467.941839456558
  timestamp: 1594868517
  timesteps_since_restore: 7160000
  timesteps_this_iter: 5000
  timesteps_total: 7160000
  training_iteration: 1432
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12467 s, 1432 iter, 7160000 ts, -4.92e+04 rew

agent-1: -6153.461727085213
agent-2: -4926.501239390558
agent-3: -6819.154850962978
agent-4: -5150.237651697171
agent-5: -6745.717228189621
Extrinsic Rewards:
-5997
-4800
-6648
-5013
-6578
Sum Reward: -29036
Avg Reward: -5807.2
Min Reward: -6648
Max Reward: -4800
Gini Coefficient: -0.07247554759608761
20:20 Ratio: 0.7220216606498195
Max-min Ratio: 0.7220216606498195
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-02-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -48177.844521060426
  episode_reward_min: -189837.20965120647
  episodes_this_iter: 1
  episodes_total: 1432
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.802
    dispatch_time_ms: 7.298
    learner:
      cur_lr: 0.0008831439772620797
      grad_gnorm: 40.0
      policy_entropy: 58.76811981201172
      policy_loss: 1546.0013427734375
      var_gnorm: 195.3251953125
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 47035.88671875
    num_steps_sampled: 7165000
    num_steps_trained: 7165000
    wait_time_ms: 74.807
  iterations_since_restore: 1433
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12476.251807689667
  time_this_iter_s: 8.30996823310852
  time_total_s: 12476.251807689667
  timestamp: 1594868526
  timesteps_since_restore: 7165000
  timesteps_this_iter: 5000
  timesteps_total: 7165000
  training_iteration: 1433
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12476 s, 1433 iter, 7165000 ts, -4.82e+04 rew

agent-1: -6678.086941474946
agent-2: -6499.142643056304
agent-3: -6181.306401193208
agent-4: -6815.89496233035
agent-5: -6532.655113434603
Extrinsic Rewards:
-6541
-6350
-6031
-6654
-6375
Sum Reward: -31951
Avg Reward: -6390.2
Min Reward: -6654
Max Reward: -6031
Gini Coefficient: -0.017990047259866672
20:20 Ratio: 0.9063721070033063
Max-min Ratio: 0.9063721070033063
agent-1: -4131.7570691264455
agent-2: -5899.63625064307
agent-3: -6662.84889534636
agent-4: -7073.62317258949
agent-5: -6628.454588868923
Extrinsic Rewards:
-4030
-5747
-6501
-6897
-6464
Sum Reward: -29639
Avg Reward: -5927.8
Min Reward: -6897
Max Reward: -4030
Gini Coefficient: -0.08756030905226223
20:20 Ratio: 0.5843120197187183
Max-min Ratio: 0.5843120197187183
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-02-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -45039.218696278345
  episode_reward_min: -168612.9412362941
  episodes_this_iter: 2
  episodes_total: 1434
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.859
    dispatch_time_ms: 6.195
    learner:
      cur_lr: 0.0008828109712339938
      grad_gnorm: 40.0
      policy_entropy: 65.78288269042969
      policy_loss: 65937.640625
      var_gnorm: 195.07273864746094
      vf_explained_var: 0.0
      vf_loss: 17594770.0
    num_steps_sampled: 7170000
    num_steps_trained: 7170000
    wait_time_ms: 72.279
  iterations_since_restore: 1434
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12484.563500881195
  time_this_iter_s: 8.31169319152832
  time_total_s: 12484.563500881195
  timestamp: 1594868534
  timesteps_since_restore: 7170000
  timesteps_this_iter: 5000
  timesteps_total: 7170000
  training_iteration: 1434
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12484 s, 1434 iter, 7170000 ts, -4.5e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-02-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -45039.21869627833
  episode_reward_min: -168612.9412362941
  episodes_this_iter: 0
  episodes_total: 1434
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.583
    dispatch_time_ms: 6.846
    learner:
      cur_lr: 0.0008824780234135687
      grad_gnorm: 40.0
      policy_entropy: 73.21723937988281
      policy_loss: 865.7646484375
      var_gnorm: 194.8555908203125
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 25668.80859375
    num_steps_sampled: 7175000
    num_steps_trained: 7175000
    wait_time_ms: 72.831
  iterations_since_restore: 1435
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12492.882749557495
  time_this_iter_s: 8.319248676300049
  time_total_s: 12492.882749557495
  timestamp: 1594868542
  timesteps_since_restore: 7175000
  timesteps_this_iter: 5000
  timesteps_total: 7175000
  training_iteration: 1435
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12492 s, 1435 iter, 7175000 ts, -4.5e+04 rew

agent-1: -10103.597810128702
agent-2: -8959.583383114916
agent-3: -11426.101305376784
agent-4: -7428.421840162874
agent-5: -7717.50064339682
Extrinsic Rewards:
-9945
-8813
-11240
-7305
-7579
Sum Reward: -44882
Avg Reward: -8976.4
Min Reward: -11240
Max Reward: -7305
Gini Coefficient: -0.09122588119959003
20:20 Ratio: 0.6499110320284698
Max-min Ratio: 0.6499110320284698
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-02-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -43809.441333737195
  episode_reward_min: -153882.88866782116
  episodes_this_iter: 1
  episodes_total: 1435
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.041
    dispatch_time_ms: 7.168
    learner:
      cur_lr: 0.0008821450173854828
      grad_gnorm: 40.0
      policy_entropy: 74.51714324951172
      policy_loss: 1587.4166259765625
      var_gnorm: 194.92396545410156
      vf_explained_var: -0.9211527109146118
      vf_loss: 40731.23828125
    num_steps_sampled: 7180000
    num_steps_trained: 7180000
    wait_time_ms: 74.907
  iterations_since_restore: 1436
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12501.3070602417
  time_this_iter_s: 8.424310684204102
  time_total_s: 12501.3070602417
  timestamp: 1594868551
  timesteps_since_restore: 7180000
  timesteps_this_iter: 5000
  timesteps_total: 7180000
  training_iteration: 1436
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12501 s, 1436 iter, 7180000 ts, -4.38e+04 rew

agent-1: -9078.548175439104
agent-2: -9404.930191301997
agent-3: -10681.403911733603
agent-4: -9107.102381591047
agent-5: -8563.354803479608
Extrinsic Rewards:
-8934
-9253
-10512
-8954
-8425
Sum Reward: -46078
Avg Reward: -9215.6
Min Reward: -10512
Max Reward: -8425
Gini Coefficient: -0.03900342896827119
20:20 Ratio: 0.80146499238965
Max-min Ratio: 0.80146499238965
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-02-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -42835.61242946557
  episode_reward_min: -153882.88866782116
  episodes_this_iter: 1
  episodes_total: 1436
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.685
    dispatch_time_ms: 7.452
    learner:
      cur_lr: 0.0008818120113573968
      grad_gnorm: 40.0
      policy_entropy: 73.74797821044922
      policy_loss: -2984.353515625
      var_gnorm: 194.89093017578125
      vf_explained_var: 0.0
      vf_loss: 320814.84375
    num_steps_sampled: 7185000
    num_steps_trained: 7185000
    wait_time_ms: 71.011
  iterations_since_restore: 1437
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12509.559779882431
  time_this_iter_s: 8.252719640731812
  time_total_s: 12509.559779882431
  timestamp: 1594868559
  timesteps_since_restore: 7185000
  timesteps_this_iter: 5000
  timesteps_total: 7185000
  training_iteration: 1437
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12509 s, 1437 iter, 7185000 ts, -4.28e+04 rew

agent-1: -11960.874107609077
agent-2: -12758.482033163085
agent-3: -10949.058158249714
agent-4: -8350.89714226034
agent-5: -9864.329263243453
Extrinsic Rewards:
-11795
-12586
-10789
-8234
-9718
Sum Reward: -53122
Avg Reward: -10624.4
Min Reward: -12586
Max Reward: -8234
Gini Coefficient: -0.08117917247091601
20:20 Ratio: 0.6542189734625775
Max-min Ratio: 0.6542189734625775
Result for A3C_harvest_env_0:
agent-1: -14185.352195371092
agent-2: -11087.7670107397
agent-3: -12486.482849732576
agent-4: -11178.342225872819
agent-5: -13868.478935700516
Extrinsic Rewards:
-14014
-10961
-12325
-11040
-13713
Sum Reward: -62053
Avg Reward: -12410.6
Min Reward: -14014
Max Reward: -10961
Gini Coefficient: -0.05659033406926337
20:20 Ratio: 0.7821464250035679
Max-min Ratio: 0.7821464250035679
  custom_metrics: {}
  date: 2020-07-15_23-02-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -42165.08645617251
  episode_reward_min: -153882.88866782116
  episodes_this_iter: 1
  episodes_total: 1437
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.227
    dispatch_time_ms: 6.457
    learner:
      cur_lr: 0.0008814790053293109
      grad_gnorm: 40.0
      policy_entropy: 71.99422454833984
      policy_loss: 981.5321655273438
      var_gnorm: 195.0989532470703
      vf_explained_var: -1.0
      vf_loss: 35696.07421875
    num_steps_sampled: 7190000
    num_steps_trained: 7190000
    wait_time_ms: 78.153
  iterations_since_restore: 1438
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12517.908539772034
  time_this_iter_s: 8.348759889602661
  time_total_s: 12517.908539772034
  timestamp: 1594868568
  timesteps_since_restore: 7190000
  timesteps_this_iter: 5000
  timesteps_total: 7190000
  training_iteration: 1438
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12517 s, 1438 iter, 7190000 ts, -4.22e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-02-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -41254.32180166846
  episode_reward_min: -153429.61946408424
  episodes_this_iter: 1
  episodes_total: 1438
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.428
    dispatch_time_ms: 8.554
    learner:
      cur_lr: 0.000881145999301225
      grad_gnorm: 40.00000762939453
      policy_entropy: 73.36857604980469
      policy_loss: 427.78118896484375
      var_gnorm: 195.1048583984375
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 81769.0703125
    num_steps_sampled: 7195000
    num_steps_trained: 7195000
    wait_time_ms: 74.368
  iterations_since_restore: 1439
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12526.261143684387
  time_this_iter_s: 8.352603912353516
  time_total_s: 12526.261143684387
  timestamp: 1594868576
  timesteps_since_restore: 7195000
  timesteps_this_iter: 5000
  timesteps_total: 7195000
  training_iteration: 1439
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12526 s, 1439 iter, 7195000 ts, -4.13e+04 rew

agent-1: -9283.794103510769
agent-2: -8781.46632189005
agent-3: -9131.977541076409
agent-4: -10117.157869150407
agent-5: -10774.375634469208
Extrinsic Rewards:
-9134
-8642
-8983
-9958
-10606
Sum Reward: -47323
Avg Reward: -9464.6
Min Reward: -10606
Max Reward: -8642
Gini Coefficient: -0.04144285019969148
20:20 Ratio: 0.8148217989817085
Max-min Ratio: 0.8148217989817085
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-03-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -40225.64399513618
  episode_reward_min: -153429.61946408424
  episodes_this_iter: 1
  episodes_total: 1439
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.607
    dispatch_time_ms: 7.186
    learner:
      cur_lr: 0.000880812993273139
      grad_gnorm: 40.0
      policy_entropy: 75.94991302490234
      policy_loss: 967.2132568359375
      var_gnorm: 195.10079956054688
      vf_explained_var: -0.7331452369689941
      vf_loss: 66389.0625
    num_steps_sampled: 7200000
    num_steps_trained: 7200000
    wait_time_ms: 77.468
  iterations_since_restore: 1440
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12534.770596265793
  time_this_iter_s: 8.50945258140564
  time_total_s: 12534.770596265793
  timestamp: 1594868585
  timesteps_since_restore: 7200000
  timesteps_this_iter: 5000
  timesteps_total: 7200000
  training_iteration: 1440
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12534 s, 1440 iter, 7200000 ts, -4.02e+04 rew

agent-1: -10192.220859767682
agent-2: -7349.027463511061
agent-3: -9221.559361656318
agent-4: -12070.343430908166
agent-5: -10355.796624692248
Extrinsic Rewards:
-10041
-7223
-9072
-11888
-10200
Sum Reward: -48424
Avg Reward: -9684.8
Min Reward: -11888
Max Reward: -7223
Gini Coefficient: -0.0863869155790517
20:20 Ratio: 0.6075874831763123
Max-min Ratio: 0.6075874831763123
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-03-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -39183.23727790069
  episode_reward_min: -147529.01354043648
  episodes_this_iter: 1
  episodes_total: 1440
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.633
    dispatch_time_ms: 8.97
    learner:
      cur_lr: 0.000880479987245053
      grad_gnorm: 40.0
      policy_entropy: 72.79197692871094
      policy_loss: 928.5870971679688
      var_gnorm: 194.95179748535156
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 54934.53125
    num_steps_sampled: 7205000
    num_steps_trained: 7205000
    wait_time_ms: 69.882
  iterations_since_restore: 1441
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12543.196484327316
  time_this_iter_s: 8.425888061523438
  time_total_s: 12543.196484327316
  timestamp: 1594868593
  timesteps_since_restore: 7205000
  timesteps_this_iter: 5000
  timesteps_total: 7205000
  training_iteration: 1441
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12543 s, 1441 iter, 7205000 ts, -3.92e+04 rew

agent-1: -8071.481787659361
agent-2: -7769.836867607644
agent-3: -6749.644340859785
agent-4: -6791.875940715377
agent-5: -7371.516967296093
Extrinsic Rewards:
-7913
-7612
-6608
-6650
-7217
Sum Reward: -36000
Avg Reward: -7200.0
Min Reward: -7913
Max Reward: -6608
Gini Coefficient: -0.03968888888888889
20:20 Ratio: 0.835081511436876
Max-min Ratio: 0.835081511436876
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-03-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -38138.862166639694
  episode_reward_min: -147529.01354043648
  episodes_this_iter: 1
  episodes_total: 1441
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.876
    dispatch_time_ms: 6.898
    learner:
      cur_lr: 0.0008801469812169671
      grad_gnorm: 39.999996185302734
      policy_entropy: 74.15988159179688
      policy_loss: -48.47576141357422
      var_gnorm: 194.7288360595703
      vf_explained_var: -0.24330174922943115
      vf_loss: 69009.7421875
    num_steps_sampled: 7210000
    num_steps_trained: 7210000
    wait_time_ms: 72.481
  iterations_since_restore: 1442
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12551.645552158356
  time_this_iter_s: 8.449067831039429
  time_total_s: 12551.645552158356
  timestamp: 1594868602
  timesteps_since_restore: 7210000
  timesteps_this_iter: 5000
  timesteps_total: 7210000
  training_iteration: 1442
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12551 s, 1442 iter, 7210000 ts, -3.81e+04 rew

agent-1: -7842.759690687882
agent-2: -6795.9412104980065
agent-3: -8099.605090846723
agent-4: -7702.894185608219
agent-5: -7039.534395734783
Extrinsic Rewards:
-7691
-6655
-7933
-7549
-6894
Sum Reward: -36722
Avg Reward: -7344.4
Min Reward: -7933
Max Reward: -6655
Gini Coefficient: -0.03652306519252764
20:20 Ratio: 0.8389007941510147
Max-min Ratio: 0.8389007941510147
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-03-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -37195.44758164317
  episode_reward_min: -147529.01354043648
  episodes_this_iter: 1
  episodes_total: 1442
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.889
    dispatch_time_ms: 26.601
    learner:
      cur_lr: 0.0008798139751888812
      grad_gnorm: 40.0
      policy_entropy: 77.84748840332031
      policy_loss: -1204.5865478515625
      var_gnorm: 194.52828979492188
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 25459.609375
    num_steps_sampled: 7215000
    num_steps_trained: 7215000
    wait_time_ms: 64.451
  iterations_since_restore: 1443
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12560.226866483688
  time_this_iter_s: 8.581314325332642
  time_total_s: 12560.226866483688
  timestamp: 1594868610
  timesteps_since_restore: 7215000
  timesteps_this_iter: 5000
  timesteps_total: 7215000
  training_iteration: 1443
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12560 s, 1443 iter, 7215000 ts, -3.72e+04 rew

agent-1: -7444.584371340398
agent-2: -8567.808508759676
agent-3: -7046.0259079242
agent-4: -7250.296443536059
agent-5: -8875.045078453977
Extrinsic Rewards:
-7295
-8405
-6909
-7108
-8708
Sum Reward: -38425
Avg Reward: -7685.0
Min Reward: -8708
Max Reward: -6909
Gini Coefficient: -0.05095640858815875
20:20 Ratio: 0.7934083601286174
Max-min Ratio: 0.7934083601286174
agent-1: -7668.52318917613
agent-2: -8399.317448378806
agent-3: -7187.474738108158
agent-4: -7080.7323390462525
agent-5: -7820.107393685522
Extrinsic Rewards:
-7517
-8239
-7049
-6934
-7663
Sum Reward: -37402
Avg Reward: -7480.4
Min Reward: -8239
Max Reward: -6934
Gini Coefficient: -0.034479439602160315
20:20 Ratio: 0.8416069911397014
Max-min Ratio: 0.8416069911397014
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-03-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -35365.40694108712
  episode_reward_min: -108522.45736566155
  episodes_this_iter: 2
  episodes_total: 1444
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.601
    dispatch_time_ms: 38.097
    learner:
      cur_lr: 0.0008794810273684561
      grad_gnorm: 39.999996185302734
      policy_entropy: 75.12196350097656
      policy_loss: 57765.71484375
      var_gnorm: 194.34561157226562
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 19044844.0
    num_steps_sampled: 7220000
    num_steps_trained: 7220000
    wait_time_ms: 64.008
  iterations_since_restore: 1444
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12569.535096168518
  time_this_iter_s: 9.308229684829712
  time_total_s: 12569.535096168518
  timestamp: 1594868619
  timesteps_since_restore: 7220000
  timesteps_this_iter: 5000
  timesteps_total: 7220000
  training_iteration: 1444
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12569 s, 1444 iter, 7220000 ts, -3.54e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-03-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -35365.40694108712
  episode_reward_min: -108522.45736566155
  episodes_this_iter: 0
  episodes_total: 1444
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.826
    dispatch_time_ms: 18.708
    learner:
      cur_lr: 0.0008791480213403702
      grad_gnorm: 40.000003814697266
      policy_entropy: 70.37830352783203
      policy_loss: 1020.8644409179688
      var_gnorm: 194.1011505126953
      vf_explained_var: 0.0
      vf_loss: 35113.734375
    num_steps_sampled: 7225000
    num_steps_trained: 7225000
    wait_time_ms: 65.866
  iterations_since_restore: 1445
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12578.384162425995
  time_this_iter_s: 8.849066257476807
  time_total_s: 12578.384162425995
  timestamp: 1594868628
  timesteps_since_restore: 7225000
  timesteps_this_iter: 5000
  timesteps_total: 7225000
  training_iteration: 1445
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12578 s, 1445 iter, 7225000 ts, -3.54e+04 rew

agent-1: -6555.416362467312
agent-2: -6162.851946713744
agent-3: -8902.895744724887
agent-4: -7132.96084695124
agent-5: -6116.56789584567
Extrinsic Rewards:
-6414
-6027
-8720
-6974
-5976
Sum Reward: -34111
Avg Reward: -6822.2
Min Reward: -8720
Max Reward: -5976
Gini Coefficient: -0.07545952918413415
20:20 Ratio: 0.6853211009174311
Max-min Ratio: 0.6853211009174311
agent-1: -5123.86973130474
agent-2: -6564.1446199986385
agent-3: -6082.012870233531
agent-4: -6832.7368329478095
agent-5: -6420.599417752299
Extrinsic Rewards:
-4991
-6416
-5927
-6665
-6266
Sum Reward: -30265
Avg Reward: -6053.0
Min Reward: -6665
Max Reward: -4991
Gini Coefficient: -0.050712043614736496
20:20 Ratio: 0.7488372093023256
Max-min Ratio: 0.7488372093023256
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-03-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -34074.80572858675
  episode_reward_min: -92816.80972037806
  episodes_this_iter: 2
  episodes_total: 1446
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.5
    dispatch_time_ms: 28.353
    learner:
      cur_lr: 0.0008788150153122842
      grad_gnorm: 40.000003814697266
      policy_entropy: 73.28890991210938
      policy_loss: 64000.79296875
      var_gnorm: 193.78623962402344
      vf_explained_var: 0.0
      vf_loss: 18541618.0
    num_steps_sampled: 7230000
    num_steps_trained: 7230000
    wait_time_ms: 62.584
  iterations_since_restore: 1446
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12587.492858171463
  time_this_iter_s: 9.10869574546814
  time_total_s: 12587.492858171463
  timestamp: 1594868637
  timesteps_since_restore: 7230000
  timesteps_this_iter: 5000
  timesteps_total: 7230000
  training_iteration: 1446
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12587 s, 1446 iter, 7230000 ts, -3.41e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-04-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -34074.80572858675
  episode_reward_min: -92816.80972037806
  episodes_this_iter: 0
  episodes_total: 1446
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.274
    dispatch_time_ms: 28.959
    learner:
      cur_lr: 0.0008784820092841983
      grad_gnorm: 40.0
      policy_entropy: 72.46736907958984
      policy_loss: -347.4866943359375
      var_gnorm: 193.65968322753906
      vf_explained_var: 0.0
      vf_loss: 57459.05859375
    num_steps_sampled: 7235000
    num_steps_trained: 7235000
    wait_time_ms: 54.059
  iterations_since_restore: 1447
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12596.501852989197
  time_this_iter_s: 9.008994817733765
  time_total_s: 12596.501852989197
  timestamp: 1594868647
  timesteps_since_restore: 7235000
  timesteps_this_iter: 5000
  timesteps_total: 7235000
  training_iteration: 1447
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12596 s, 1447 iter, 7235000 ts, -3.41e+04 rew

agent-1: -6388.532001274301
agent-2: -7202.976299631693
agent-3: -7797.045890164458
agent-4: -8553.827072381948
agent-5: -9563.408317816371
Extrinsic Rewards:
-6259
-7064
-7645
-8392
-9385
Sum Reward: -38745
Avg Reward: -7749.0
Min Reward: -9385
Max Reward: -6259
Gini Coefficient: -0.07825525874306362
20:20 Ratio: 0.6669152903569526
Max-min Ratio: 0.6669152903569526
agent-1: -7403.8691776615115
agent-2: -7588.647952647401
agent-3: -8443.507435781037
agent-4: -7609.04509579679
agent-5: -7218.833598104871
Extrinsic Rewards:
-7255
-7432
-8277
-7461
-7068
Sum Reward: -37493
Avg Reward: -7498.6
Min Reward: -8277
Max Reward: -7068
Gini Coefficient: -0.027994558984343745
20:20 Ratio: 0.8539325842696629
Max-min Ratio: 0.8539325842696629
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-04-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -33050.95330492192
  episode_reward_min: -88070.03686987318
  episodes_this_iter: 2
  episodes_total: 1448
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.843
    dispatch_time_ms: 40.007
    learner:
      cur_lr: 0.0008781490032561123
      grad_gnorm: 40.0
      policy_entropy: 69.71258544921875
      policy_loss: 72068.09375
      var_gnorm: 193.4571533203125
      vf_explained_var: 0.0
      vf_loss: 18940808.0
    num_steps_sampled: 7240000
    num_steps_trained: 7240000
    wait_time_ms: 56.456
  iterations_since_restore: 1448
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12605.465241909027
  time_this_iter_s: 8.963388919830322
  time_total_s: 12605.465241909027
  timestamp: 1594868656
  timesteps_since_restore: 7240000
  timesteps_this_iter: 5000
  timesteps_total: 7240000
  training_iteration: 1448
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12605 s, 1448 iter, 7240000 ts, -3.31e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-04-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -33050.95330492192
  episode_reward_min: -88070.03686987318
  episodes_this_iter: 0
  episodes_total: 1448
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.86
    dispatch_time_ms: 37.699
    learner:
      cur_lr: 0.0008778159972280264
      grad_gnorm: 40.0
      policy_entropy: 70.14794921875
      policy_loss: 1853.84814453125
      var_gnorm: 193.11044311523438
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 34483.125
    num_steps_sampled: 7245000
    num_steps_trained: 7245000
    wait_time_ms: 51.503
  iterations_since_restore: 1449
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12614.186160087585
  time_this_iter_s: 8.72091817855835
  time_total_s: 12614.186160087585
  timestamp: 1594868664
  timesteps_since_restore: 7245000
  timesteps_this_iter: 5000
  timesteps_total: 7245000
  training_iteration: 1449
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12614 s, 1449 iter, 7245000 ts, -3.31e+04 rew

agent-1: -5505.472570236841
agent-2: -6137.260567376819
agent-3: -8126.512432651921
agent-4: -6462.120492580124
agent-5: -5603.11688050589
Extrinsic Rewards:
-5374
-5996
-7945
-6309
-5464
Sum Reward: -31088
Avg Reward: -6217.6
Min Reward: -7945
Max Reward: -5374
Gini Coefficient: -0.07703293875450334
20:20 Ratio: 0.6764002517306482
Max-min Ratio: 0.6764002517306482
agent-1: -4752.790758992785
agent-2: -5885.694140473655
agent-3: -4805.278762383392
agent-4: -5971.63964692168
agent-5: -5862.130509328322
Extrinsic Rewards:
-4618
-5729
-4663
-5804
-5706
Sum Reward: -26520
Avg Reward: -5304.0
Min Reward: -5804
Max Reward: -4618
Gini Coefficient: -0.0518552036199095
20:20 Ratio: 0.79565816678153
Max-min Ratio: 0.79565816678153
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-04-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -31973.319424898542
  episode_reward_min: -88070.03686987318
  episodes_this_iter: 2
  episodes_total: 1450
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.813
    dispatch_time_ms: 22.874
    learner:
      cur_lr: 0.0008774829911999404
      grad_gnorm: 40.0
      policy_entropy: 72.7608642578125
      policy_loss: 60711.23046875
      var_gnorm: 192.796630859375
      vf_explained_var: 0.0
      vf_loss: 18508646.0
    num_steps_sampled: 7250000
    num_steps_trained: 7250000
    wait_time_ms: 64.16
  iterations_since_restore: 1450
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12623.088124275208
  time_this_iter_s: 8.90196418762207
  time_total_s: 12623.088124275208
  timestamp: 1594868673
  timesteps_since_restore: 7250000
  timesteps_this_iter: 5000
  timesteps_total: 7250000
  training_iteration: 1450
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12623 s, 1450 iter, 7250000 ts, -3.2e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-04-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -31973.319424898542
  episode_reward_min: -88070.03686987318
  episodes_this_iter: 0
  episodes_total: 1450
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.729
    dispatch_time_ms: 35.301
    learner:
      cur_lr: 0.0008771499851718545
      grad_gnorm: 39.999996185302734
      policy_entropy: 72.24630737304688
      policy_loss: -1518.9169921875
      var_gnorm: 192.68421936035156
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 73668.34375
    num_steps_sampled: 7255000
    num_steps_trained: 7255000
    wait_time_ms: 54.283
  iterations_since_restore: 1451
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12632.012137651443
  time_this_iter_s: 8.924013376235962
  time_total_s: 12632.012137651443
  timestamp: 1594868682
  timesteps_since_restore: 7255000
  timesteps_this_iter: 5000
  timesteps_total: 7255000
  training_iteration: 1451
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12632 s, 1451 iter, 7255000 ts, -3.2e+04 rew

agent-1: -11328.790150105437
agent-2: -9278.886994101409
agent-3: -9023.49221344333
agent-4: -9453.290962464367
agent-5: -10989.546643772224
Extrinsic Rewards:
-11167
-9133
-8879
-9303
-10835
Sum Reward: -49317
Avg Reward: -9863.4
Min Reward: -11167
Max Reward: -8879
Gini Coefficient: -0.050919561206074986
20:20 Ratio: 0.7951105937136205
Max-min Ratio: 0.7951105937136205
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-04-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -31593.35912583867
  episode_reward_min: -77864.69892955256
  episodes_this_iter: 1
  episodes_total: 1451
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.851
    dispatch_time_ms: 7.452
    learner:
      cur_lr: 0.0008768169791437685
      grad_gnorm: 40.0
      policy_entropy: 65.01145935058594
      policy_loss: 169.54623413085938
      var_gnorm: 192.80947875976562
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 37490.43359375
    num_steps_sampled: 7260000
    num_steps_trained: 7260000
    wait_time_ms: 75.177
  iterations_since_restore: 1452
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12642.590930700302
  time_this_iter_s: 10.578793048858643
  time_total_s: 12642.590930700302
  timestamp: 1594868693
  timesteps_since_restore: 7260000
  timesteps_this_iter: 5000
  timesteps_total: 7260000
  training_iteration: 1452
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12642 s, 1452 iter, 7260000 ts, -3.16e+04 rew

agent-1: -11394.885762694053
agent-2: -9634.595513985556
agent-3: -9677.631419051811
agent-4: -10672.09482067059
agent-5: -10311.45681187562
Extrinsic Rewards:
-11234
-9486
-9539
-10522
-10158
Sum Reward: -50939
Avg Reward: -10187.8
Min Reward: -11234
Max Reward: -9486
Gini Coefficient: -0.035171479612870295
20:20 Ratio: 0.8444009257610824
Max-min Ratio: 0.8444009257610824
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-05-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -31346.67677739396
  episode_reward_min: -77864.69892955256
  episodes_this_iter: 1
  episodes_total: 1452
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.705
    dispatch_time_ms: 8.48
    learner:
      cur_lr: 0.0008764839731156826
      grad_gnorm: 40.0
      policy_entropy: 62.06956481933594
      policy_loss: -761.991943359375
      var_gnorm: 192.86734008789062
      vf_explained_var: 0.0
      vf_loss: 77054.59375
    num_steps_sampled: 7265000
    num_steps_trained: 7265000
    wait_time_ms: 70.896
  iterations_since_restore: 1453
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12650.751808643341
  time_this_iter_s: 8.16087794303894
  time_total_s: 12650.751808643341
  timestamp: 1594868701
  timesteps_since_restore: 7265000
  timesteps_this_iter: 5000
  timesteps_total: 7265000
  training_iteration: 1453
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12650 s, 1453 iter, 7265000 ts, -3.13e+04 rew

agent-1: -17313.32144951103
agent-2: -14104.596006576794
agent-3: -13779.396970761663
agent-4: -14160.961956887782
agent-5: -11091.814258005832
Extrinsic Rewards:
-17140
-13946
-13635
-14004
-10977
Sum Reward: -69702
Avg Reward: -13940.4
Min Reward: -17140
Max Reward: -10977
Gini Coefficient: -0.07285300278327739
20:20 Ratio: 0.6404317386231039
Max-min Ratio: 0.6404317386231039
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-05-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -31312.576463448684
  episode_reward_min: -77864.69892955256
  episodes_this_iter: 1
  episodes_total: 1453
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.718
    dispatch_time_ms: 6.985
    learner:
      cur_lr: 0.0008761510252952576
      grad_gnorm: 40.0
      policy_entropy: 56.315574645996094
      policy_loss: -168.3347930908203
      var_gnorm: 193.2101287841797
      vf_explained_var: 0.0
      vf_loss: 78710.3671875
    num_steps_sampled: 7270000
    num_steps_trained: 7270000
    wait_time_ms: 75.29
  iterations_since_restore: 1454
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12659.110965967178
  time_this_iter_s: 8.35915732383728
  time_total_s: 12659.110965967178
  timestamp: 1594868709
  timesteps_since_restore: 7270000
  timesteps_this_iter: 5000
  timesteps_total: 7270000
  training_iteration: 1454
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12659 s, 1454 iter, 7270000 ts, -3.13e+04 rew

agent-1: -11131.379197764323
agent-2: -7589.4159387321515
agent-3: -10709.384586045035
agent-4: -17887.28742596417
agent-5: -13370.588023183767
Extrinsic Rewards:
-10990
-7481
-10578
-17686
-13209
Sum Reward: -59944
Avg Reward: -11988.8
Min Reward: -17686
Max Reward: -7481
Gini Coefficient: -0.15375016682236756
20:20 Ratio: 0.4229899355422368
Max-min Ratio: 0.4229899355422368
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-05-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -31140.81002587005
  episode_reward_min: -70450.0906417432
  episodes_this_iter: 1
  episodes_total: 1454
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 4.019
    dispatch_time_ms: 7.815
    learner:
      cur_lr: 0.0008758180192671716
      grad_gnorm: 40.0
      policy_entropy: 52.79789733886719
      policy_loss: -142.21255493164062
      var_gnorm: 193.36434936523438
      vf_explained_var: 0.0
      vf_loss: 34836.46484375
    num_steps_sampled: 7275000
    num_steps_trained: 7275000
    wait_time_ms: 70.945
  iterations_since_restore: 1455
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12667.26628780365
  time_this_iter_s: 8.155321836471558
  time_total_s: 12667.26628780365
  timestamp: 1594868718
  timesteps_since_restore: 7275000
  timesteps_this_iter: 5000
  timesteps_total: 7275000
  training_iteration: 1455
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12667 s, 1455 iter, 7275000 ts, -3.11e+04 rew

agent-1: -8023.849546282824
agent-2: -14005.755442005555
agent-3: -14388.585479618965
agent-4: -10580.920356402112
agent-5: -8900.575386104474
Extrinsic Rewards:
-7917
-13821
-14204
-10437
-8774
Sum Reward: -55153
Avg Reward: -11030.6
Min Reward: -14204
Max Reward: -7917
Gini Coefficient: -0.12779721864631116
20:20 Ratio: 0.5573782033230076
Max-min Ratio: 0.5573782033230076
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-05-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -31003.37703492165
  episode_reward_min: -70450.0906417432
  episodes_this_iter: 1
  episodes_total: 1455
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.999
    dispatch_time_ms: 6.266
    learner:
      cur_lr: 0.0008754850132390857
      grad_gnorm: 39.999996185302734
      policy_entropy: 58.042579650878906
      policy_loss: 1070.4967041015625
      var_gnorm: 193.57089233398438
      vf_explained_var: 0.0
      vf_loss: 108890.4140625
    num_steps_sampled: 7280000
    num_steps_trained: 7280000
    wait_time_ms: 71.689
  iterations_since_restore: 1456
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12675.486516952515
  time_this_iter_s: 8.220229148864746
  time_total_s: 12675.486516952515
  timestamp: 1594868726
  timesteps_since_restore: 7280000
  timesteps_this_iter: 5000
  timesteps_total: 7280000
  training_iteration: 1456
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12675 s, 1456 iter, 7280000 ts, -3.1e+04 rew

agent-1: -12329.715357034147
agent-2: -14354.805737569028
agent-3: -11206.048305703924
agent-4: -10207.579914819957
agent-5: -12780.664131365605
Extrinsic Rewards:
-12178
-14185
-11076
-10073
-12624
Sum Reward: -60136
Avg Reward: -12027.2
Min Reward: -14185
Max Reward: -10073
Gini Coefficient: -0.064999334841027
20:20 Ratio: 0.7101163200563976
Max-min Ratio: 0.7101163200563976
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-05-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -31032.5379526521
  episode_reward_min: -70450.0906417432
  episodes_this_iter: 1
  episodes_total: 1456
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.793
    dispatch_time_ms: 6.786
    learner:
      cur_lr: 0.0008751520072109997
      grad_gnorm: 40.0
      policy_entropy: 56.95710754394531
      policy_loss: 78.03667449951172
      var_gnorm: 193.70071411132812
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 42164.34375
    num_steps_sampled: 7285000
    num_steps_trained: 7285000
    wait_time_ms: 71.316
  iterations_since_restore: 1457
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12683.626173257828
  time_this_iter_s: 8.13965630531311
  time_total_s: 12683.626173257828
  timestamp: 1594868734
  timesteps_since_restore: 7285000
  timesteps_this_iter: 5000
  timesteps_total: 7285000
  training_iteration: 1457
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12683 s, 1457 iter, 7285000 ts, -3.1e+04 rew

agent-1: -10270.284905297347
agent-2: -8585.250825472827
agent-3: -11016.645761165813
agent-4: -11974.77832949855
agent-5: -13494.288786687126
Extrinsic Rewards:
-10132
-8465
-10863
-11808
-13321
Sum Reward: -54589
Avg Reward: -10917.8
Min Reward: -13321
Max Reward: -8465
Gini Coefficient: -0.08344538276942241
20:20 Ratio: 0.6354628030928609
Max-min Ratio: 0.6354628030928609
agent-1: -9468.746474263444
agent-2: -8501.061514051424
agent-3: -10949.750368433832
agent-4: -10548.933316563272
agent-5: -6205.3493101644235
Extrinsic Rewards:
-9312
-8358
-10770
-10379
-6098
Sum Reward: -44917
Avg Reward: -8983.4
Min Reward: -10770
Max Reward: -6098
Gini Coefficient: -0.10120889640893203
20:20 Ratio: 0.5662024141132777
Max-min Ratio: 0.5662024141132777
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-05-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -31310.549391176915
  episode_reward_min: -70450.0906417432
  episodes_this_iter: 2
  episodes_total: 1458
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.567
    dispatch_time_ms: 5.751
    learner:
      cur_lr: 0.0008748190011829138
      grad_gnorm: 40.0
      policy_entropy: 53.25156021118164
      policy_loss: 49564.80078125
      var_gnorm: 193.69692993164062
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 19096442.0
    num_steps_sampled: 7290000
    num_steps_trained: 7290000
    wait_time_ms: 73.194
  iterations_since_restore: 1458
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12691.786700725555
  time_this_iter_s: 8.160527467727661
  time_total_s: 12691.786700725555
  timestamp: 1594868742
  timesteps_since_restore: 7290000
  timesteps_this_iter: 5000
  timesteps_total: 7290000
  training_iteration: 1458
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12691 s, 1458 iter, 7290000 ts, -3.13e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-05-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -31310.549391176915
  episode_reward_min: -70450.0906417432
  episodes_this_iter: 0
  episodes_total: 1458
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 4.486
    dispatch_time_ms: 6.934
    learner:
      cur_lr: 0.0008744859951548278
      grad_gnorm: 40.0
      policy_entropy: 53.55894470214844
      policy_loss: 179.9818572998047
      var_gnorm: 193.84056091308594
      vf_explained_var: 0.0
      vf_loss: 57555.73046875
    num_steps_sampled: 7295000
    num_steps_trained: 7295000
    wait_time_ms: 70.234
  iterations_since_restore: 1459
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12699.98307967186
  time_this_iter_s: 8.196378946304321
  time_total_s: 12699.98307967186
  timestamp: 1594868750
  timesteps_since_restore: 7295000
  timesteps_this_iter: 5000
  timesteps_total: 7295000
  training_iteration: 1459
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12699 s, 1459 iter, 7295000 ts, -3.13e+04 rew

agent-1: -11633.076997113323
agent-2: -11263.143938349136
agent-3: -12798.709831133745
agent-4: -10714.5343962573
agent-5: -8329.851917462503
Extrinsic Rewards:
-11491
-11105
-12617
-10575
-8214
Sum Reward: -54002
Avg Reward: -10800.4
Min Reward: -12617
Max Reward: -8214
Gini Coefficient: -0.0720121476982334
20:20 Ratio: 0.6510263929618768
Max-min Ratio: 0.6510263929618768
agent-1: -13114.570157242879
agent-2: -9311.437543536482
agent-3: -14248.151495137601
agent-4: -15536.66389121967
agent-5: -8708.291832069903
Extrinsic Rewards:
-12954
-9190
-14072
-15356
-8601
Sum Reward: -60173
Avg Reward: -12034.6
Min Reward: -15356
Max Reward: -8601
Gini Coefficient: -0.12226081465108936
20:20 Ratio: 0.5601067986454806
Max-min Ratio: 0.5601067986454806
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-05-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -31907.31807714606
  episode_reward_min: -70450.0906417432
  episodes_this_iter: 2
  episodes_total: 1460
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.704
    dispatch_time_ms: 9.724
    learner:
      cur_lr: 0.0008741529891267419
      grad_gnorm: 40.0
      policy_entropy: 57.00447082519531
      policy_loss: 49572.203125
      var_gnorm: 193.9571075439453
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 18672716.0
    num_steps_sampled: 7300000
    num_steps_trained: 7300000
    wait_time_ms: 70.365
  iterations_since_restore: 1460
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12708.15372467041
  time_this_iter_s: 8.170644998550415
  time_total_s: 12708.15372467041
  timestamp: 1594868759
  timesteps_since_restore: 7300000
  timesteps_this_iter: 5000
  timesteps_total: 7300000
  training_iteration: 1460
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12708 s, 1460 iter, 7300000 ts, -3.19e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-06-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -31907.318077146054
  episode_reward_min: -70450.0906417432
  episodes_this_iter: 0
  episodes_total: 1460
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.778
    dispatch_time_ms: 8.935
    learner:
      cur_lr: 0.0008738199830986559
      grad_gnorm: 40.0
      policy_entropy: 56.335838317871094
      policy_loss: -5709.02587890625
      var_gnorm: 194.14773559570312
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 396037.875
    num_steps_sampled: 7305000
    num_steps_trained: 7305000
    wait_time_ms: 72.619
  iterations_since_restore: 1461
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12716.445246458054
  time_this_iter_s: 8.291521787643433
  time_total_s: 12716.445246458054
  timestamp: 1594868767
  timesteps_since_restore: 7305000
  timesteps_this_iter: 5000
  timesteps_total: 7305000
  training_iteration: 1461
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12716 s, 1461 iter, 7305000 ts, -3.19e+04 rew

agent-1: -14144.879687249924
agent-2: -12861.180401475942
agent-3: -13844.42044294653
agent-4: -11464.089246315802
agent-5: -13032.802537044463
Extrinsic Rewards:
-13981
-12707
-13690
-11333
-12882
Sum Reward: -64593
Avg Reward: -12918.6
Min Reward: -13981
Max Reward: -11333
Gini Coefficient: -0.03888347034508383
20:20 Ratio: 0.8106001001358987
Max-min Ratio: 0.8106001001358987
agent-1: -13662.352449672999
agent-2: -13268.55599065133
agent-3: -13657.768262757558
agent-4: -12759.561007598306
agent-5: -9085.035343636275
Extrinsic Rewards:
-13503
-13105
-13499
-12597
-8981
Sum Reward: -61685
Avg Reward: -12337.0
Min Reward: -13503
Max Reward: -8981
Gini Coefficient: -0.06449542028045716
20:20 Ratio: 0.665111456713323
Max-min Ratio: 0.665111456713323
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-06-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -32813.324484827266
  episode_reward_min: -70450.0906417432
  episodes_this_iter: 2
  episodes_total: 1462
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.992
    dispatch_time_ms: 6.146
    learner:
      cur_lr: 0.00087348697707057
      grad_gnorm: 40.0
      policy_entropy: 54.59418487548828
      policy_loss: 46625.98828125
      var_gnorm: 194.4095001220703
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 17661666.0
    num_steps_sampled: 7310000
    num_steps_trained: 7310000
    wait_time_ms: 72.416
  iterations_since_restore: 1462
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12724.74320268631
  time_this_iter_s: 8.297956228256226
  time_total_s: 12724.74320268631
  timestamp: 1594868775
  timesteps_since_restore: 7310000
  timesteps_this_iter: 5000
  timesteps_total: 7310000
  training_iteration: 1462
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12724 s, 1462 iter, 7310000 ts, -3.28e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-06-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -32813.324484827266
  episode_reward_min: -70450.0906417432
  episodes_this_iter: 0
  episodes_total: 1462
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.324
    dispatch_time_ms: 7.142
    learner:
      cur_lr: 0.000873153971042484
      grad_gnorm: 40.0
      policy_entropy: 52.905582427978516
      policy_loss: -4297.91064453125
      var_gnorm: 194.7313690185547
      vf_explained_var: 0.0
      vf_loss: 475727.28125
    num_steps_sampled: 7315000
    num_steps_trained: 7315000
    wait_time_ms: 70.263
  iterations_since_restore: 1463
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12732.991875171661
  time_this_iter_s: 8.248672485351562
  time_total_s: 12732.991875171661
  timestamp: 1594868784
  timesteps_since_restore: 7315000
  timesteps_this_iter: 5000
  timesteps_total: 7315000
  training_iteration: 1463
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12732 s, 1463 iter, 7315000 ts, -3.28e+04 rew

agent-1: -17211.616471558387
agent-2: -16053.504376472709
agent-3: -11689.5740275122
agent-4: -13254.210543254225
agent-5: -19843.411340195482
Extrinsic Rewards:
-17043
-15896
-11568
-13123
-19662
Sum Reward: -77292
Avg Reward: -15458.4
Min Reward: -19662
Max Reward: -11568
Gini Coefficient: -0.10406251617243699
20:20 Ratio: 0.5883429966432713
Max-min Ratio: 0.5883429966432713
agent-1: -13013.314011450586
agent-2: -14489.007691634744
agent-3: -10226.845822433494
agent-4: -14053.569429152365
agent-5: -19468.972686295743
Extrinsic Rewards:
-12874
-14332
-10120
-13905
-19276
Sum Reward: -70507
Avg Reward: -14101.4
Min Reward: -19276
Max Reward: -10120
Gini Coefficient: -0.11215907640376133
20:20 Ratio: 0.5250051877982984
Max-min Ratio: 0.5250051877982984
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-06-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -33709.34619630681
  episode_reward_min: -78052.3167589934
  episodes_this_iter: 2
  episodes_total: 1464
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.281
    dispatch_time_ms: 8.968
    learner:
      cur_lr: 0.000872821023222059
      grad_gnorm: 40.0
      policy_entropy: 52.857994079589844
      policy_loss: 43165.37109375
      var_gnorm: 194.959716796875
      vf_explained_var: 0.0
      vf_loss: 16739179.0
    num_steps_sampled: 7320000
    num_steps_trained: 7320000
    wait_time_ms: 71.026
  iterations_since_restore: 1464
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12741.223196744919
  time_this_iter_s: 8.231321573257446
  time_total_s: 12741.223196744919
  timestamp: 1594868792
  timesteps_since_restore: 7320000
  timesteps_this_iter: 5000
  timesteps_total: 7320000
  training_iteration: 1464
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12741 s, 1464 iter, 7320000 ts, -3.37e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-06-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -33709.346196306826
  episode_reward_min: -78052.3167589934
  episodes_this_iter: 0
  episodes_total: 1464
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.794
    dispatch_time_ms: 7.877
    learner:
      cur_lr: 0.0008724880171939731
      grad_gnorm: 39.999996185302734
      policy_entropy: 49.00529861450195
      policy_loss: 32.29161071777344
      var_gnorm: 195.12879943847656
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 40925.17578125
    num_steps_sampled: 7325000
    num_steps_trained: 7325000
    wait_time_ms: 70.61
  iterations_since_restore: 1465
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12749.382743120193
  time_this_iter_s: 8.159546375274658
  time_total_s: 12749.382743120193
  timestamp: 1594868800
  timesteps_since_restore: 7325000
  timesteps_this_iter: 5000
  timesteps_total: 7325000
  training_iteration: 1465
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12749 s, 1465 iter, 7325000 ts, -3.37e+04 rew

agent-1: -19777.51027261562
agent-2: -10869.86624508717
agent-3: -11182.83917534703
agent-4: -18113.081979916395
agent-5: -14360.280680322641
Extrinsic Rewards:
-19593
-10764
-11062
-17937
-14203
Sum Reward: -73559
Avg Reward: -14711.8
Min Reward: -19593
Max Reward: -10764
Gini Coefficient: -0.13340583749099363
20:20 Ratio: 0.5493798805695912
Max-min Ratio: 0.5493798805695912
agent-1: -13716.168221950527
agent-2: -9978.099590429298
agent-3: -7403.476781938817
agent-4: -10469.576628534
agent-5: -11261.650259975957
Extrinsic Rewards:
-13528
-9834
-7289
-10330
-11102
Sum Reward: -52083
Avg Reward: -10416.6
Min Reward: -13528
Max Reward: -7289
Gini Coefficient: -0.10556995564771615
20:20 Ratio: 0.5388083973979894
Max-min Ratio: 0.5388083973979894
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-06-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -34294.79113548334
  episode_reward_min: -78052.3167589934
  episodes_this_iter: 2
  episodes_total: 1466
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.081
    dispatch_time_ms: 7.134
    learner:
      cur_lr: 0.0008721550111658871
      grad_gnorm: 40.000003814697266
      policy_entropy: 51.569087982177734
      policy_loss: 40957.5703125
      var_gnorm: 195.34979248046875
      vf_explained_var: 0.0
      vf_loss: 17769098.0
    num_steps_sampled: 7330000
    num_steps_trained: 7330000
    wait_time_ms: 71.648
  iterations_since_restore: 1466
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12757.611281633377
  time_this_iter_s: 8.228538513183594
  time_total_s: 12757.611281633377
  timestamp: 1594868808
  timesteps_since_restore: 7330000
  timesteps_this_iter: 5000
  timesteps_total: 7330000
  training_iteration: 1466
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12757 s, 1466 iter, 7330000 ts, -3.43e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-06-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -34294.79113548334
  episode_reward_min: -78052.3167589934
  episodes_this_iter: 0
  episodes_total: 1466
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.179
    dispatch_time_ms: 8.078
    learner:
      cur_lr: 0.0008718220051378012
      grad_gnorm: 40.000003814697266
      policy_entropy: 51.11894226074219
      policy_loss: -2551.705322265625
      var_gnorm: 195.58010864257812
      vf_explained_var: 0.0
      vf_loss: 103846.890625
    num_steps_sampled: 7335000
    num_steps_trained: 7335000
    wait_time_ms: 72.015
  iterations_since_restore: 1467
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12765.935948133469
  time_this_iter_s: 8.324666500091553
  time_total_s: 12765.935948133469
  timestamp: 1594868817
  timesteps_since_restore: 7335000
  timesteps_this_iter: 5000
  timesteps_total: 7335000
  training_iteration: 1467
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12765 s, 1467 iter, 7335000 ts, -3.43e+04 rew

agent-1: -13173.204893437616
agent-2: -15569.594237896876
agent-3: -12040.676783584806
agent-4: -16186.235582091946
agent-5: -13964.262852651373
Extrinsic Rewards:
-13033
-15405
-11905
-16017
-13818
Sum Reward: -70178
Avg Reward: -14035.6
Min Reward: -16017
Max Reward: -11905
Gini Coefficient: -0.06039499558266123
20:20 Ratio: 0.7432727726790286
Max-min Ratio: 0.7432727726790286
agent-1: -14878.240635172322
agent-2: -19532.63164827861
agent-3: -15589.867177765876
agent-4: -16642.71505506083
agent-5: -19774.30955752055
Extrinsic Rewards:
-14739
-19369
-15461
-16508
-19597
Sum Reward: -85674
Avg Reward: -17134.8
Min Reward: -19597
Max Reward: -14739
Gini Coefficient: -0.06360856269113149
20:20 Ratio: 0.7521049140174516
Max-min Ratio: 0.7521049140174516
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-07-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -35132.389588674414
  episode_reward_min: -86417.76407379833
  episodes_this_iter: 2
  episodes_total: 1468
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.904
    dispatch_time_ms: 10.255
    learner:
      cur_lr: 0.0008714889991097152
      grad_gnorm: 40.0
      policy_entropy: 53.01421356201172
      policy_loss: -1841.948486328125
      var_gnorm: 195.92237854003906
      vf_explained_var: -0.8299268484115601
      vf_loss: 112196.8359375
    num_steps_sampled: 7340000
    num_steps_trained: 7340000
    wait_time_ms: 71.627
  iterations_since_restore: 1468
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12774.251836061478
  time_this_iter_s: 8.315887928009033
  time_total_s: 12774.251836061478
  timestamp: 1594868825
  timesteps_since_restore: 7340000
  timesteps_this_iter: 5000
  timesteps_total: 7340000
  training_iteration: 1468
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12774 s, 1468 iter, 7340000 ts, -3.51e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-07-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -35132.389588674414
  episode_reward_min: -86417.76407379833
  episodes_this_iter: 0
  episodes_total: 1468
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.05
    dispatch_time_ms: 7.44
    learner:
      cur_lr: 0.0008711559930816293
      grad_gnorm: 40.0
      policy_entropy: 52.9058837890625
      policy_loss: -5891.73046875
      var_gnorm: 196.3377227783203
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 368194.78125
    num_steps_sampled: 7345000
    num_steps_trained: 7345000
    wait_time_ms: 72.654
  iterations_since_restore: 1469
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12782.57436132431
  time_this_iter_s: 8.322525262832642
  time_total_s: 12782.57436132431
  timestamp: 1594868833
  timesteps_since_restore: 7345000
  timesteps_this_iter: 5000
  timesteps_total: 7345000
  training_iteration: 1469
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12782 s, 1469 iter, 7345000 ts, -3.51e+04 rew

agent-1: -29423.687730853442
agent-2: -14933.46659957404
agent-3: -20568.205967134974
agent-4: -20199.053941321337
agent-5: -24489.273852956496
Extrinsic Rewards:
-29230
-14832
-20422
-20055
-24328
Sum Reward: -108867
Avg Reward: -21773.4
Min Reward: -29230
Max Reward: -14832
Gini Coefficient: -0.12150238364242608
20:20 Ratio: 0.5074238795757783
Max-min Ratio: 0.5074238795757783
agent-1: -21052.449831536225
agent-2: -21536.517181437048
agent-3: -21106.738251503615
agent-4: -25862.89275360663
agent-5: -11950.97206229264
Extrinsic Rewards:
-20898
-21376
-20950
-25678
-11857
Sum Reward: -100759
Avg Reward: -20151.8
Min Reward: -25678
Max Reward: -11857
Gini Coefficient: -0.11163270774819123
20:20 Ratio: 0.46175714619518654
Max-min Ratio: 0.46175714619518654
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-07-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -36492.17801590879
  episode_reward_min: -109613.68809184067
  episodes_this_iter: 2
  episodes_total: 1470
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.159
    dispatch_time_ms: 9.071
    learner:
      cur_lr: 0.0008708229870535433
      grad_gnorm: 39.999996185302734
      policy_entropy: 55.265132904052734
      policy_loss: -1087.9266357421875
      var_gnorm: 196.8246307373047
      vf_explained_var: -0.42869091033935547
      vf_loss: 119291.359375
    num_steps_sampled: 7350000
    num_steps_trained: 7350000
    wait_time_ms: 72.638
  iterations_since_restore: 1470
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12790.92638874054
  time_this_iter_s: 8.352027416229248
  time_total_s: 12790.92638874054
  timestamp: 1594868842
  timesteps_since_restore: 7350000
  timesteps_this_iter: 5000
  timesteps_total: 7350000
  training_iteration: 1470
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12790 s, 1470 iter, 7350000 ts, -3.65e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-07-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -36492.17801590879
  episode_reward_min: -109613.68809184067
  episodes_this_iter: 0
  episodes_total: 1470
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.049
    dispatch_time_ms: 6.586
    learner:
      cur_lr: 0.0008704899810254574
      grad_gnorm: 40.0
      policy_entropy: 48.497535705566406
      policy_loss: -4922.7646484375
      var_gnorm: 197.1780242919922
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1175030.625
    num_steps_sampled: 7355000
    num_steps_trained: 7355000
    wait_time_ms: 75.798
  iterations_since_restore: 1471
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12799.03517127037
  time_this_iter_s: 8.108782529830933
  time_total_s: 12799.03517127037
  timestamp: 1594868850
  timesteps_since_restore: 7355000
  timesteps_this_iter: 5000
  timesteps_total: 7355000
  training_iteration: 1471
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12799 s, 1471 iter, 7355000 ts, -3.65e+04 rew

agent-1: -27685.837779952675
agent-2: -19180.179725889415
agent-3: -22676.72059863783
agent-4: -20162.616081126318
agent-5: -13984.116773000045
Extrinsic Rewards:
-27502
-19045
-22499
-20022
-13882
Sum Reward: -102950
Avg Reward: -20590.0
Min Reward: -27502
Max Reward: -13882
Gini Coefficient: -0.11925789218067023
20:20 Ratio: 0.5047632899425496
Max-min Ratio: 0.5047632899425496
agent-1: -17577.689164539494
agent-2: -25556.313572633942
agent-3: -23144.294485146867
agent-4: -28711.75689862941
agent-5: -20665.406204201325
Extrinsic Rewards:
-17463
-25393
-22985
-28526
-20539
Sum Reward: -114906
Avg Reward: -22981.2
Min Reward: -28526
Max Reward: -17463
Gini Coefficient: -0.09392024785476824
20:20 Ratio: 0.6121783635981211
Max-min Ratio: 0.6121783635981211
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-07-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -38106.476871723666
  episode_reward_min: -115655.46032515135
  episodes_this_iter: 2
  episodes_total: 1472
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.972
    dispatch_time_ms: 37.859
    learner:
      cur_lr: 0.0008701569749973714
      grad_gnorm: 40.0
      policy_entropy: 47.2146110534668
      policy_loss: -2702.3583984375
      var_gnorm: 197.6272735595703
      vf_explained_var: -0.36888277530670166
      vf_loss: 490348.71875
    num_steps_sampled: 7360000
    num_steps_trained: 7360000
    wait_time_ms: 54.224
  iterations_since_restore: 1472
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12808.115310668945
  time_this_iter_s: 9.080139398574829
  time_total_s: 12808.115310668945
  timestamp: 1594868859
  timesteps_since_restore: 7360000
  timesteps_this_iter: 5000
  timesteps_total: 7360000
  training_iteration: 1472
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12808 s, 1472 iter, 7360000 ts, -3.81e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-07-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -38106.476871723666
  episode_reward_min: -115655.46032515135
  episodes_this_iter: 0
  episodes_total: 1472
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.901
    dispatch_time_ms: 38.596
    learner:
      cur_lr: 0.0008698240271769464
      grad_gnorm: 40.0
      policy_entropy: 46.658287048339844
      policy_loss: 1193.6785888671875
      var_gnorm: 198.0682830810547
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 138382.90625
    num_steps_sampled: 7365000
    num_steps_trained: 7365000
    wait_time_ms: 52.176
  iterations_since_restore: 1473
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12817.295585155487
  time_this_iter_s: 9.180274486541748
  time_total_s: 12817.295585155487
  timestamp: 1594868868
  timesteps_since_restore: 7365000
  timesteps_this_iter: 5000
  timesteps_total: 7365000
  training_iteration: 1473
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12817 s, 1473 iter, 7365000 ts, -3.81e+04 rew

agent-1: -29663.42453123791
agent-2: -27125.134370349293
agent-3: -21737.420813685923
agent-4: -29896.433872339545
agent-5: -30714.147740513563
Extrinsic Rewards:
-29501
-26985
-21611
-29736
-30547
Sum Reward: -138380
Avg Reward: -27676.0
Min Reward: -30547
Max Reward: -21611
Gini Coefficient: -0.059612660789131376
20:20 Ratio: 0.7074671817199725
Max-min Ratio: 0.7074671817199725
agent-1: -17735.882785774713
agent-2: -26708.330673516833
agent-3: -9456.112678919173
agent-4: -20996.154849240807
agent-5: -35491.43153993855
Extrinsic Rewards:
-17611
-26532
-9384
-20853
-35279
Sum Reward: -109659
Avg Reward: -21931.8
Min Reward: -35279
Max Reward: -9384
Gini Coefficient: -0.22145377944354772
20:20 Ratio: 0.265993934068426
Max-min Ratio: 0.265993934068426
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-07-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -39809.32733371469
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 2
  episodes_total: 1474
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.578
    dispatch_time_ms: 86.964
    learner:
      cur_lr: 0.0008694910211488605
      grad_gnorm: 40.0
      policy_entropy: 40.20879364013672
      policy_loss: 30919.802734375
      var_gnorm: 198.53350830078125
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 12977672.0
    num_steps_sampled: 7370000
    num_steps_trained: 7370000
    wait_time_ms: 191.827
  iterations_since_restore: 1474
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12828.062581777573
  time_this_iter_s: 10.766996622085571
  time_total_s: 12828.062581777573
  timestamp: 1594868879
  timesteps_since_restore: 7370000
  timesteps_this_iter: 5000
  timesteps_total: 7370000
  training_iteration: 1474
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12828 s, 1474 iter, 7370000 ts, -3.98e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-08-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -39809.32733371469
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 0
  episodes_total: 1474
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.469
    dispatch_time_ms: 33.38
    learner:
      cur_lr: 0.0008691580151207745
      grad_gnorm: 40.0
      policy_entropy: 29.50543975830078
      policy_loss: -5209.01611328125
      var_gnorm: 198.88465881347656
      vf_explained_var: 0.0
      vf_loss: 713095.625
    num_steps_sampled: 7375000
    num_steps_trained: 7375000
    wait_time_ms: 57.648
  iterations_since_restore: 1475
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12836.302838802338
  time_this_iter_s: 8.240257024765015
  time_total_s: 12836.302838802338
  timestamp: 1594868887
  timesteps_since_restore: 7375000
  timesteps_this_iter: 5000
  timesteps_total: 7375000
  training_iteration: 1475
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12836 s, 1475 iter, 7375000 ts, -3.98e+04 rew

agent-1: -10228.096068592387
agent-2: -25803.26443478098
agent-3: -26950.53536656992
agent-4: -16543.40886368916
agent-5: -32253.97869241178
Extrinsic Rewards:
-10150
-25643
-26777
-16433
-32060
Sum Reward: -111063
Avg Reward: -22212.6
Min Reward: -32060
Max Reward: -10150
Gini Coefficient: -0.1950748674175918
20:20 Ratio: 0.3165938864628821
Max-min Ratio: 0.3165938864628821
agent-1: -33956.9310059683
agent-2: -21932.04527056011
agent-3: -30375.521754608482
agent-4: -20705.09358869725
agent-5: -27701.051397742987
Extrinsic Rewards:
-33777
-21806
-30209
-20582
-27562
Sum Reward: -133936
Avg Reward: -26787.2
Min Reward: -33777
Max Reward: -20582
Gini Coefficient: -0.10390932982917214
20:20 Ratio: 0.6093495573911242
Max-min Ratio: 0.6093495573911242
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-08-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -41506.06678563776
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 2
  episodes_total: 1476
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.693
    dispatch_time_ms: 6.705
    learner:
      cur_lr: 0.0008688250090926886
      grad_gnorm: 40.0
      policy_entropy: 38.83243179321289
      policy_loss: 28191.744140625
      var_gnorm: 199.2941131591797
      vf_explained_var: 0.0
      vf_loss: 17030668.0
    num_steps_sampled: 7380000
    num_steps_trained: 7380000
    wait_time_ms: 73.261
  iterations_since_restore: 1476
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12844.885003566742
  time_this_iter_s: 8.582164764404297
  time_total_s: 12844.885003566742
  timestamp: 1594868896
  timesteps_since_restore: 7380000
  timesteps_this_iter: 5000
  timesteps_total: 7380000
  training_iteration: 1476
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12844 s, 1476 iter, 7380000 ts, -4.15e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-08-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -41506.06678563776
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 0
  episodes_total: 1476
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.032
    dispatch_time_ms: 9.27
    learner:
      cur_lr: 0.0008684920030646026
      grad_gnorm: 40.00000762939453
      policy_entropy: 42.40153121948242
      policy_loss: -370.2470703125
      var_gnorm: 199.6274871826172
      vf_explained_var: 0.0
      vf_loss: 166670.984375
    num_steps_sampled: 7385000
    num_steps_trained: 7385000
    wait_time_ms: 74.012
  iterations_since_restore: 1477
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12853.303363084793
  time_this_iter_s: 8.418359518051147
  time_total_s: 12853.303363084793
  timestamp: 1594868904
  timesteps_since_restore: 7385000
  timesteps_this_iter: 5000
  timesteps_total: 7385000
  training_iteration: 1477
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12853 s, 1477 iter, 7385000 ts, -4.15e+04 rew

agent-1: -23052.641534757862
agent-2: -17044.74073622855
agent-3: -13821.494949672491
agent-4: -12162.256581351876
agent-5: -23836.05554253748
Extrinsic Rewards:
-22871
-16900
-13696
-12053
-23661
Sum Reward: -89181
Avg Reward: -17836.2
Min Reward: -23661
Max Reward: -12053
Gini Coefficient: -0.14528206680795236
20:20 Ratio: 0.5094036600312751
Max-min Ratio: 0.5094036600312751
agent-1: -20417.617925483624
agent-2: -15099.534917236335
agent-3: -23750.295548025482
agent-4: -17000.915374230197
agent-5: -33096.15350747259
Extrinsic Rewards:
-20273
-14991
-23586
-16881
-32900
Sum Reward: -108631
Avg Reward: -21726.2
Min Reward: -32900
Max Reward: -14991
Gini Coefficient: -0.15657777245905866
20:20 Ratio: 0.4556534954407295
Max-min Ratio: 0.4556534954407295
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-08-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -42694.85430208763
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 2
  episodes_total: 1478
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.758
    dispatch_time_ms: 8.914
    learner:
      cur_lr: 0.0008681589970365167
      grad_gnorm: 40.0
      policy_entropy: 41.80113983154297
      policy_loss: -2143.332763671875
      var_gnorm: 200.05601501464844
      vf_explained_var: -0.049694180488586426
      vf_loss: 1023980.0
    num_steps_sampled: 7390000
    num_steps_trained: 7390000
    wait_time_ms: 71.558
  iterations_since_restore: 1478
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12861.839853525162
  time_this_iter_s: 8.536490440368652
  time_total_s: 12861.839853525162
  timestamp: 1594868913
  timesteps_since_restore: 7390000
  timesteps_this_iter: 5000
  timesteps_total: 7390000
  training_iteration: 1478
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12861 s, 1478 iter, 7390000 ts, -4.27e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-08-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -42694.85430208763
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 0
  episodes_total: 1478
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.371
    dispatch_time_ms: 6.377
    learner:
      cur_lr: 0.0008678259910084307
      grad_gnorm: 39.999996185302734
      policy_entropy: 40.07569122314453
      policy_loss: -652.7626953125
      var_gnorm: 200.47225952148438
      vf_explained_var: 0.0
      vf_loss: 113811.1796875
    num_steps_sampled: 7395000
    num_steps_trained: 7395000
    wait_time_ms: 71.469
  iterations_since_restore: 1479
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12870.207359552383
  time_this_iter_s: 8.36750602722168
  time_total_s: 12870.207359552383
  timestamp: 1594868921
  timesteps_since_restore: 7395000
  timesteps_this_iter: 5000
  timesteps_total: 7395000
  training_iteration: 1479
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12870 s, 1479 iter, 7395000 ts, -4.27e+04 rew

agent-1: -32518.168240673123
agent-2: -31168.429067511937
agent-3: -25665.652196282907
agent-4: -29684.308944540448
agent-5: -7205.429290963452
Extrinsic Rewards:
-32330
-30990
-25512
-29518
-7156
Sum Reward: -125506
Avg Reward: -25101.2
Min Reward: -32330
Max Reward: -7156
Gini Coefficient: -0.17792296782623937
20:20 Ratio: 0.22134240643365297
Max-min Ratio: 0.22134240643365297
agent-1: -25834.61161551815
agent-2: -17553.09875545375
agent-3: -21107.7403040774
agent-4: -25009.158492377617
agent-5: -21030.11609347729
Extrinsic Rewards:
-25670
-17420
-20966
-24853
-20880
Sum Reward: -109789
Avg Reward: -21957.8
Min Reward: -25670
Max Reward: -17420
Gini Coefficient: -0.0745903505815701
20:20 Ratio: 0.678613167121153
Max-min Ratio: 0.678613167121153
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-08-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -44307.66212081341
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 2
  episodes_total: 1480
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.608
    dispatch_time_ms: 8.765
    learner:
      cur_lr: 0.0008674929849803448
      grad_gnorm: 40.0
      policy_entropy: 45.86050033569336
      policy_loss: -812.0559692382812
      var_gnorm: 200.86732482910156
      vf_explained_var: -0.5847436189651489
      vf_loss: 121890.578125
    num_steps_sampled: 7400000
    num_steps_trained: 7400000
    wait_time_ms: 72.131
  iterations_since_restore: 1480
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12879.983512878418
  time_this_iter_s: 9.776153326034546
  time_total_s: 12879.983512878418
  timestamp: 1594868931
  timesteps_since_restore: 7400000
  timesteps_this_iter: 5000
  timesteps_total: 7400000
  training_iteration: 1480
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12879 s, 1480 iter, 7400000 ts, -4.43e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-09-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -44307.6621208134
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 0
  episodes_total: 1480
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.988
    dispatch_time_ms: 8.548
    learner:
      cur_lr: 0.0008671599789522588
      grad_gnorm: 40.0
      policy_entropy: 55.213111877441406
      policy_loss: -3478.203125
      var_gnorm: 201.2498779296875
      vf_explained_var: 0.0
      vf_loss: 120294.3984375
    num_steps_sampled: 7405000
    num_steps_trained: 7405000
    wait_time_ms: 71.803
  iterations_since_restore: 1481
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12888.262402296066
  time_this_iter_s: 8.278889417648315
  time_total_s: 12888.262402296066
  timestamp: 1594868940
  timesteps_since_restore: 7405000
  timesteps_this_iter: 5000
  timesteps_total: 7405000
  training_iteration: 1481
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12888 s, 1481 iter, 7405000 ts, -4.43e+04 rew

agent-1: -16287.400184974364
agent-2: -3743.6104350579026
agent-3: -18255.367150935104
agent-4: -22142.551852216737
agent-5: -19285.806581121393
Extrinsic Rewards:
-16127
-3710
-18098
-21946
-19118
Sum Reward: -78999
Avg Reward: -15799.8
Min Reward: -21946
Max Reward: -3710
Gini Coefficient: -0.19981518753401942
20:20 Ratio: 0.16905130775539962
Max-min Ratio: 0.16905130775539962
agent-1: -26769.158739049184
agent-2: -16468.28309432891
agent-3: -23871.316683496927
agent-4: -18381.58102588991
agent-5: -17450.78493219316
Extrinsic Rewards:
-26586
-16342
-23697
-18248
-17321
Sum Reward: -102194
Avg Reward: -20438.8
Min Reward: -26586
Max Reward: -16342
Gini Coefficient: -0.10514903027575004
20:20 Ratio: 0.6146844203716242
Max-min Ratio: 0.6146844203716242
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-09-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -45330.266715304766
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 2
  episodes_total: 1482
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.885
    dispatch_time_ms: 7.21
    learner:
      cur_lr: 0.0008668269729241729
      grad_gnorm: 40.0
      policy_entropy: 54.867767333984375
      policy_loss: 37191.08984375
      var_gnorm: 201.53622436523438
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 12729468.0
    num_steps_sampled: 7410000
    num_steps_trained: 7410000
    wait_time_ms: 74.745
  iterations_since_restore: 1482
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12896.47166109085
  time_this_iter_s: 8.209258794784546
  time_total_s: 12896.47166109085
  timestamp: 1594868948
  timesteps_since_restore: 7410000
  timesteps_this_iter: 5000
  timesteps_total: 7410000
  training_iteration: 1482
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12896 s, 1482 iter, 7410000 ts, -4.53e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-09-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -45330.26671530476
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 0
  episodes_total: 1482
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.906
    dispatch_time_ms: 10.89
    learner:
      cur_lr: 0.0008664940251037478
      grad_gnorm: 39.999996185302734
      policy_entropy: 56.16893768310547
      policy_loss: -2155.77734375
      var_gnorm: 201.8196563720703
      vf_explained_var: 0.0
      vf_loss: 275816.125
    num_steps_sampled: 7415000
    num_steps_trained: 7415000
    wait_time_ms: 69.4
  iterations_since_restore: 1483
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12904.72329735756
  time_this_iter_s: 8.251636266708374
  time_total_s: 12904.72329735756
  timestamp: 1594868956
  timesteps_since_restore: 7415000
  timesteps_this_iter: 5000
  timesteps_total: 7415000
  training_iteration: 1483
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12904 s, 1483 iter, 7415000 ts, -4.53e+04 rew

agent-1: -22619.40449577206
agent-2: -28023.322731073684
agent-3: -15570.920859920738
agent-4: -16327.464983182315
agent-5: -18664.07656384331
Extrinsic Rewards:
-22456
-27834
-15467
-16199
-18523
Sum Reward: -100479
Avg Reward: -20095.8
Min Reward: -27834
Max Reward: -15467
Gini Coefficient: -0.12337304312343873
20:20 Ratio: 0.5556872889272113
Max-min Ratio: 0.5556872889272113
agent-1: -10798.718265044277
agent-2: -15385.71850515178
agent-3: -15477.215575295
agent-4: -9668.53230362165
agent-5: -17729.527050737564
Extrinsic Rewards:
-10682
-15227
-15312
-9555
-17546
Sum Reward: -68322
Avg Reward: -13664.4
Min Reward: -17546
Max Reward: -9555
Gini Coefficient: -0.12067562424987559
20:20 Ratio: 0.5445685626353585
Max-min Ratio: 0.5445685626353585
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-09-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -46503.7514760882
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 2
  episodes_total: 1484
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.662
    dispatch_time_ms: 9.469
    learner:
      cur_lr: 0.0008661610190756619
      grad_gnorm: 39.999996185302734
      policy_entropy: 54.90801239013672
      policy_loss: 48705.69921875
      var_gnorm: 202.1839141845703
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 18631164.0
    num_steps_sampled: 7420000
    num_steps_trained: 7420000
    wait_time_ms: 69.142
  iterations_since_restore: 1484
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12913.025327444077
  time_this_iter_s: 8.302030086517334
  time_total_s: 12913.025327444077
  timestamp: 1594868964
  timesteps_since_restore: 7420000
  timesteps_this_iter: 5000
  timesteps_total: 7420000
  training_iteration: 1484
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12913 s, 1484 iter, 7420000 ts, -4.65e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-09-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -46503.75147608818
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 0
  episodes_total: 1484
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.393
    dispatch_time_ms: 7.25
    learner:
      cur_lr: 0.000865828013047576
      grad_gnorm: 39.999996185302734
      policy_entropy: 51.06008529663086
      policy_loss: -1821.5816650390625
      var_gnorm: 202.41946411132812
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 250576.71875
    num_steps_sampled: 7425000
    num_steps_trained: 7425000
    wait_time_ms: 70.423
  iterations_since_restore: 1485
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12921.2270321846
  time_this_iter_s: 8.201704740524292
  time_total_s: 12921.2270321846
  timestamp: 1594868973
  timesteps_since_restore: 7425000
  timesteps_this_iter: 5000
  timesteps_total: 7425000
  training_iteration: 1485
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12921 s, 1485 iter, 7425000 ts, -4.65e+04 rew

agent-1: -15597.017866961549
agent-2: -26474.845612276575
agent-3: -15615.736438608728
agent-4: -19606.722692930827
agent-5: -15232.60837394099
Extrinsic Rewards:
-15472
-26278
-15476
-19443
-15104
Sum Reward: -91773
Avg Reward: -18354.6
Min Reward: -26278
Max Reward: -15104
Gini Coefficient: -0.11471347782027394
20:20 Ratio: 0.5747773803181369
Max-min Ratio: 0.5747773803181369
agent-1: -22738.599509482476
agent-2: -3566.0138584117785
agent-3: -10837.678832061767
agent-4: -13751.727191426826
agent-5: -17595.27179795884
Extrinsic Rewards:
-22520
-3523
-10708
-13600
-17413
Sum Reward: -67764
Avg Reward: -13552.8
Min Reward: -22520
Max Reward: -3523
Gini Coefficient: -0.2638510123369341
20:20 Ratio: 0.15643872113676732
Max-min Ratio: 0.15643872113676732
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-09-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -47625.17276489029
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 2
  episodes_total: 1486
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.089
    dispatch_time_ms: 8.407
    learner:
      cur_lr: 0.00086549500701949
      grad_gnorm: 40.000003814697266
      policy_entropy: 54.55271530151367
      policy_loss: -3904.92041015625
      var_gnorm: 202.7075653076172
      vf_explained_var: -0.19226539134979248
      vf_loss: 281596.0
    num_steps_sampled: 7430000
    num_steps_trained: 7430000
    wait_time_ms: 72.74
  iterations_since_restore: 1486
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12929.549831151962
  time_this_iter_s: 8.32279896736145
  time_total_s: 12929.549831151962
  timestamp: 1594868981
  timesteps_since_restore: 7430000
  timesteps_this_iter: 5000
  timesteps_total: 7430000
  training_iteration: 1486
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12929 s, 1486 iter, 7430000 ts, -4.76e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-09-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -47625.172764890296
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 0
  episodes_total: 1486
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.33
    dispatch_time_ms: 8.081
    learner:
      cur_lr: 0.0008651620009914041
      grad_gnorm: 40.0
      policy_entropy: 58.441837310791016
      policy_loss: 1406.2681884765625
      var_gnorm: 203.01077270507812
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 76849.40625
    num_steps_sampled: 7435000
    num_steps_trained: 7435000
    wait_time_ms: 71.012
  iterations_since_restore: 1487
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12937.713300466537
  time_this_iter_s: 8.163469314575195
  time_total_s: 12937.713300466537
  timestamp: 1594868989
  timesteps_since_restore: 7435000
  timesteps_this_iter: 5000
  timesteps_total: 7435000
  training_iteration: 1487
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12937 s, 1487 iter, 7435000 ts, -4.76e+04 rew

agent-1: -16674.953852874856
agent-2: -13962.99384155753
agent-3: -12725.967541208767
agent-4: -8474.303230629364
agent-5: -16802.006677559057
Extrinsic Rewards:
-16499
-13817
-12580
-8370
-16631
Sum Reward: -67897
Avg Reward: -13579.4
Min Reward: -16631
Max Reward: -8370
Gini Coefficient: -0.12042358277979881
20:20 Ratio: 0.5032770128074079
Max-min Ratio: 0.5032770128074079
agent-1: -14041.116572762437
agent-2: -6497.998339847214
agent-3: -15219.470762511004
agent-4: -10440.611146428462
agent-5: -17449.824389107078
Extrinsic Rewards:
-13883
-6413
-15044
-10318
-17260
Sum Reward: -62918
Avg Reward: -12583.6
Min Reward: -17260
Max Reward: -6413
Gini Coefficient: -0.16796465240471725
20:20 Ratio: 0.3715527230590962
Max-min Ratio: 0.3715527230590962
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-09-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -48302.09254986122
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 2
  episodes_total: 1488
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.939
    dispatch_time_ms: 8.349
    learner:
      cur_lr: 0.0008648289949633181
      grad_gnorm: 40.0
      policy_entropy: 58.845863342285156
      policy_loss: 46204.30859375
      var_gnorm: 203.11123657226562
      vf_explained_var: 0.0
      vf_loss: 18275484.0
    num_steps_sampled: 7440000
    num_steps_trained: 7440000
    wait_time_ms: 70.38
  iterations_since_restore: 1488
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12945.871210575104
  time_this_iter_s: 8.157910108566284
  time_total_s: 12945.871210575104
  timestamp: 1594868997
  timesteps_since_restore: 7440000
  timesteps_this_iter: 5000
  timesteps_total: 7440000
  training_iteration: 1488
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12945 s, 1488 iter, 7440000 ts, -4.83e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-10-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -48302.09254986122
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 0
  episodes_total: 1488
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.185
    dispatch_time_ms: 8.544
    learner:
      cur_lr: 0.0008644959889352322
      grad_gnorm: 40.0
      policy_entropy: 58.06968307495117
      policy_loss: 1311.10205078125
      var_gnorm: 203.1212921142578
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 60753.6640625
    num_steps_sampled: 7445000
    num_steps_trained: 7445000
    wait_time_ms: 71.03
  iterations_since_restore: 1489
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12953.922934532166
  time_this_iter_s: 8.051723957061768
  time_total_s: 12953.922934532166
  timestamp: 1594869006
  timesteps_since_restore: 7445000
  timesteps_this_iter: 5000
  timesteps_total: 7445000
  training_iteration: 1489
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12953 s, 1489 iter, 7445000 ts, -4.83e+04 rew

agent-1: -7325.958551074817
agent-2: -6647.447484577382
agent-3: -4631.893297091248
agent-4: -10170.56121565077
agent-5: -12722.551975840895
Extrinsic Rewards:
-7185
-6527
-4549
-9990
-12513
Sum Reward: -40764
Avg Reward: -8152.8
Min Reward: -12513
Max Reward: -4549
Gini Coefficient: -0.1902757334903346
20:20 Ratio: 0.3635419164069368
Max-min Ratio: 0.3635419164069368
agent-1: -5045.715405100442
agent-2: -7460.464626717393
agent-3: -7323.221246130574
agent-4: -6172.846881466393
agent-5: -6942.974470542595
Extrinsic Rewards:
-4933
-7288
-7153
-6039
-6784
Sum Reward: -32197
Avg Reward: -6439.4
Min Reward: -7288
Max Reward: -4933
Gini Coefficient: -0.07235456719570146
20:20 Ratio: 0.6768660812294183
Max-min Ratio: 0.6768660812294183
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-10-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -48582.06323262901
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 2
  episodes_total: 1490
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.053
    dispatch_time_ms: 34.424
    learner:
      cur_lr: 0.0008641629829071462
      grad_gnorm: 40.0
      policy_entropy: 47.12029266357422
      policy_loss: 1007.4851684570312
      var_gnorm: 202.72779846191406
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 36553.8515625
    num_steps_sampled: 7450000
    num_steps_trained: 7450000
    wait_time_ms: 54.815
  iterations_since_restore: 1490
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12962.215317249298
  time_this_iter_s: 8.292382717132568
  time_total_s: 12962.215317249298
  timestamp: 1594869014
  timesteps_since_restore: 7450000
  timesteps_this_iter: 5000
  timesteps_total: 7450000
  training_iteration: 1490
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12962 s, 1490 iter, 7450000 ts, -4.86e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-10-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -48582.06323262902
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 0
  episodes_total: 1490
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.174
    dispatch_time_ms: 29.243
    learner:
      cur_lr: 0.0008638299768790603
      grad_gnorm: 40.0
      policy_entropy: 42.87228012084961
      policy_loss: 1090.4893798828125
      var_gnorm: 202.23843383789062
      vf_explained_var: 0.0
      vf_loss: 54410.18359375
    num_steps_sampled: 7455000
    num_steps_trained: 7455000
    wait_time_ms: 68.013
  iterations_since_restore: 1491
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12970.795141458511
  time_this_iter_s: 8.579824209213257
  time_total_s: 12970.795141458511
  timestamp: 1594869022
  timesteps_since_restore: 7455000
  timesteps_this_iter: 5000
  timesteps_total: 7455000
  training_iteration: 1491
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12970 s, 1491 iter, 7455000 ts, -4.86e+04 rew

agent-1: -2012.424712494909
agent-2: -4474.993490667991
agent-3: -5563.28038021013
agent-4: -2884.552348038291
agent-5: -1434.2405901007248
Extrinsic Rewards:
-1911
-4288
-5359
-2753
-1360
Sum Reward: -15671
Avg Reward: -3134.2
Min Reward: -5359
Max Reward: -1360
Gini Coefficient: -0.2648203688341523
20:20 Ratio: 0.2537786900541146
Max-min Ratio: 0.2537786900541146
agent-1: -4286.680588661213
agent-2: -3621.9413811883196
agent-3: -2888.1736532846235
agent-4: -4353.569455067861
agent-5: -2832.009485417089
Extrinsic Rewards:
-4120
-3465
-2766
-4182
-2714
Sum Reward: -17247
Avg Reward: -3449.4
Min Reward: -4182
Max Reward: -2714
Gini Coefficient: -0.0994955644459906
20:20 Ratio: 0.6489717838354854
Max-min Ratio: 0.6489717838354854
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-10-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -48503.30164087833
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 2
  episodes_total: 1492
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.62
    dispatch_time_ms: 7.282
    learner:
      cur_lr: 0.0008634970290586352
      grad_gnorm: 39.999996185302734
      policy_entropy: 42.776092529296875
      policy_loss: 1401.31201171875
      var_gnorm: 201.78387451171875
      vf_explained_var: -0.7352937459945679
      vf_loss: 52561.54296875
    num_steps_sampled: 7460000
    num_steps_trained: 7460000
    wait_time_ms: 70.073
  iterations_since_restore: 1492
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12979.010149717331
  time_this_iter_s: 8.21500825881958
  time_total_s: 12979.010149717331
  timestamp: 1594869031
  timesteps_since_restore: 7460000
  timesteps_this_iter: 5000
  timesteps_total: 7460000
  training_iteration: 1492
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12979 s, 1492 iter, 7460000 ts, -4.85e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-10-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -48503.30164087834
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 0
  episodes_total: 1492
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.2
    dispatch_time_ms: 8.209
    learner:
      cur_lr: 0.0008631640230305493
      grad_gnorm: 40.0
      policy_entropy: 39.42844772338867
      policy_loss: 1693.035888671875
      var_gnorm: 201.28504943847656
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 62283.97265625
    num_steps_sampled: 7465000
    num_steps_trained: 7465000
    wait_time_ms: 69.531
  iterations_since_restore: 1493
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12986.903246879578
  time_this_iter_s: 7.893097162246704
  time_total_s: 12986.903246879578
  timestamp: 1594869039
  timesteps_since_restore: 7465000
  timesteps_this_iter: 5000
  timesteps_total: 7465000
  training_iteration: 1493
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12986 s, 1493 iter, 7465000 ts, -4.85e+04 rew

agent-1: -2813.79952923075
agent-2: -1367.5118745174816
agent-3: -2162.2930862548983
agent-4: -3590.309144027882
agent-5: -3376.582305291459
Extrinsic Rewards:
-2664
-1273
-2034
-3416
-3186
Sum Reward: -12573
Avg Reward: -2514.6
Min Reward: -3416
Max Reward: -1273
Gini Coefficient: -0.17300564702139506
20:20 Ratio: 0.37265807962529274
Max-min Ratio: 0.37265807962529274
agent-1: -3330.682257460856
agent-2: -1542.3140745667802
agent-3: -1596.227818343583
agent-4: -1834.4198960938982
agent-5: -2432.1082973213042
Extrinsic Rewards:
-3149
-1420
-1470
-1711
-2269
Sum Reward: -10019
Avg Reward: -2003.8
Min Reward: -3149
Max Reward: -1420
Gini Coefficient: -0.16995708154506436
20:20 Ratio: 0.450936805335027
Max-min Ratio: 0.450936805335027
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-10-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -48299.39701903325
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 2
  episodes_total: 1494
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.657
    dispatch_time_ms: 6.831
    learner:
      cur_lr: 0.0008628310170024633
      grad_gnorm: 40.0
      policy_entropy: 35.326087951660156
      policy_loss: 37448.93359375
      var_gnorm: 200.79103088378906
      vf_explained_var: 3.5762786865234375e-07
      vf_loss: 21210176.0
    num_steps_sampled: 7470000
    num_steps_trained: 7470000
    wait_time_ms: 71.997
  iterations_since_restore: 1494
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 12994.810711622238
  time_this_iter_s: 7.9074647426605225
  time_total_s: 12994.810711622238
  timestamp: 1594869047
  timesteps_since_restore: 7470000
  timesteps_this_iter: 5000
  timesteps_total: 7470000
  training_iteration: 1494
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 12994 s, 1494 iter, 7470000 ts, -4.83e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-10-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -48299.39701903323
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 0
  episodes_total: 1494
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.965
    dispatch_time_ms: 8.779
    learner:
      cur_lr: 0.0008624980109743774
      grad_gnorm: 40.0
      policy_entropy: 38.22064208984375
      policy_loss: 298.4181213378906
      var_gnorm: 200.29800415039062
      vf_explained_var: 0.0
      vf_loss: 77724.3125
    num_steps_sampled: 7475000
    num_steps_trained: 7475000
    wait_time_ms: 66.992
  iterations_since_restore: 1495
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13002.698383331299
  time_this_iter_s: 7.887671709060669
  time_total_s: 13002.698383331299
  timestamp: 1594869054
  timesteps_since_restore: 7475000
  timesteps_this_iter: 5000
  timesteps_total: 7475000
  training_iteration: 1495
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13002 s, 1495 iter, 7475000 ts, -4.83e+04 rew

agent-1: -2371.4114431420776
agent-2: -3925.4439090521228
agent-3: -2719.8959745203592
agent-4: -2208.449835641935
agent-5: -3215.406778853104
Extrinsic Rewards:
-2237
-3735
-2576
-2090
-3057
Sum Reward: -13695
Avg Reward: -2739.0
Min Reward: -3735
Max Reward: -2090
Gini Coefficient: -0.12004381161007667
20:20 Ratio: 0.5595716198125836
Max-min Ratio: 0.5595716198125836
agent-1: -3698.1194219264003
agent-2: -4451.668366139423
agent-3: -4567.871472097876
agent-4: -3183.088537517798
agent-5: -3761.463807584523
Extrinsic Rewards:
-3569
-4292
-4397
-3020
-3633
Sum Reward: -18911
Avg Reward: -3782.2
Min Reward: -4397
Max Reward: -3020
Gini Coefficient: -0.07354449791126857
20:20 Ratio: 0.6868319308619514
Max-min Ratio: 0.6868319308619514
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-11-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -48237.99170998875
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 2
  episodes_total: 1496
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.006
    dispatch_time_ms: 7.252
    learner:
      cur_lr: 0.0008621650049462914
      grad_gnorm: 40.0
      policy_entropy: 56.28032684326172
      policy_loss: 1097.1993408203125
      var_gnorm: 199.90542602539062
      vf_explained_var: -0.9567462205886841
      vf_loss: 37514.4140625
    num_steps_sampled: 7480000
    num_steps_trained: 7480000
    wait_time_ms: 69.856
  iterations_since_restore: 1496
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13010.675080776215
  time_this_iter_s: 7.9766974449157715
  time_total_s: 13010.675080776215
  timestamp: 1594869062
  timesteps_since_restore: 7480000
  timesteps_this_iter: 5000
  timesteps_total: 7480000
  training_iteration: 1496
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13010 s, 1496 iter, 7480000 ts, -4.82e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-11-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -48237.99170998876
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 0
  episodes_total: 1496
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.028
    dispatch_time_ms: 7.968
    learner:
      cur_lr: 0.0008618319989182055
      grad_gnorm: 40.0
      policy_entropy: 50.79212951660156
      policy_loss: 771.0931396484375
      var_gnorm: 199.4749755859375
      vf_explained_var: 0.0
      vf_loss: 27530.873046875
    num_steps_sampled: 7485000
    num_steps_trained: 7485000
    wait_time_ms: 70.294
  iterations_since_restore: 1497
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13018.63278579712
  time_this_iter_s: 7.957705020904541
  time_total_s: 13018.63278579712
  timestamp: 1594869070
  timesteps_since_restore: 7485000
  timesteps_this_iter: 5000
  timesteps_total: 7485000
  training_iteration: 1497
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13018 s, 1497 iter, 7485000 ts, -4.82e+04 rew

agent-1: -5376.828276132113
agent-2: -3635.823519351504
agent-3: -5186.588131463796
agent-4: -2707.037979310296
agent-5: -5443.388754712755
Extrinsic Rewards:
-5204
-3515
-5016
-2609
-5276
Sum Reward: -21620
Avg Reward: -4324.0
Min Reward: -5276
Max Reward: -2609
Gini Coefficient: -0.12993524514338575
20:20 Ratio: 0.49450341167551176
Max-min Ratio: 0.49450341167551176
agent-1: -5417.340165570596
agent-2: -2192.898036906175
agent-3: -2115.7422432331614
agent-4: -6425.587772234486
agent-5: -5449.239655822412
Extrinsic Rewards:
-5236
-2123
-2032
-6227
-5277
Sum Reward: -20895
Avg Reward: -4179.0
Min Reward: -6227
Max Reward: -2032
Gini Coefficient: -0.22099066762383346
20:20 Ratio: 0.32632086076762484
Max-min Ratio: 0.32632086076762484
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-11-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -48333.54354230593
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 2
  episodes_total: 1498
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.533
    dispatch_time_ms: 10.29
    learner:
      cur_lr: 0.0008614989928901196
      grad_gnorm: 40.0
      policy_entropy: 58.38185119628906
      policy_loss: 1278.279296875
      var_gnorm: 199.09661865234375
      vf_explained_var: -1.0
      vf_loss: 59319.0078125
    num_steps_sampled: 7490000
    num_steps_trained: 7490000
    wait_time_ms: 65.734
  iterations_since_restore: 1498
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13026.593394756317
  time_this_iter_s: 7.960608959197998
  time_total_s: 13026.593394756317
  timestamp: 1594869078
  timesteps_since_restore: 7490000
  timesteps_this_iter: 5000
  timesteps_total: 7490000
  training_iteration: 1498
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13026 s, 1498 iter, 7490000 ts, -4.83e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-11-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -48333.54354230593
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 0
  episodes_total: 1498
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.0
    dispatch_time_ms: 9.753
    learner:
      cur_lr: 0.0008611659868620336
      grad_gnorm: 40.0
      policy_entropy: 64.29298400878906
      policy_loss: 1990.6533203125
      var_gnorm: 198.7353973388672
      vf_explained_var: 0.0
      vf_loss: 58506.953125
    num_steps_sampled: 7495000
    num_steps_trained: 7495000
    wait_time_ms: 70.463
  iterations_since_restore: 1499
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13034.60248541832
  time_this_iter_s: 8.009090662002563
  time_total_s: 13034.60248541832
  timestamp: 1594869087
  timesteps_since_restore: 7495000
  timesteps_this_iter: 5000
  timesteps_total: 7495000
  training_iteration: 1499
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13034 s, 1499 iter, 7495000 ts, -4.83e+04 rew

agent-1: -4292.741442376285
agent-2: -6314.68584349222
agent-3: -4675.251431007892
agent-4: -4690.543649128355
agent-5: -1857.5416480208244
Extrinsic Rewards:
-4141
-6117
-4518
-4539
-1791
Sum Reward: -21106
Avg Reward: -4221.2
Min Reward: -6117
Max Reward: -1791
Gini Coefficient: -0.1715152089453236
20:20 Ratio: 0.2927905836194213
Max-min Ratio: 0.2927905836194213
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-11-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -48339.1095884862
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1499
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.861
    dispatch_time_ms: 9.155
    learner:
      cur_lr: 0.0008608329808339477
      grad_gnorm: 40.000003814697266
      policy_entropy: 65.00230407714844
      policy_loss: 1197.5057373046875
      var_gnorm: 198.3424530029297
      vf_explained_var: -1.0
      vf_loss: 49941.08203125
    num_steps_sampled: 7500000
    num_steps_trained: 7500000
    wait_time_ms: 68.058
  iterations_since_restore: 1500
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13042.610192775726
  time_this_iter_s: 8.007707357406616
  time_total_s: 13042.610192775726
  timestamp: 1594869095
  timesteps_since_restore: 7500000
  timesteps_this_iter: 5000
  timesteps_total: 7500000
  training_iteration: 1500
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13042 s, 1500 iter, 7500000 ts, -4.83e+04 rew

agent-1: -5173.078301539065
agent-2: -5069.903717108295
agent-3: -4895.022396759524
agent-4: -5031.254479937493
agent-5: -4660.098826025866
Extrinsic Rewards:
-5021
-4918
-4755
-4878
-4523
Sum Reward: -24095
Avg Reward: -4819.0
Min Reward: -5021
Max Reward: -4523
Gini Coefficient: -0.019240506329113925
20:20 Ratio: 0.900816570404302
Max-min Ratio: 0.900816570404302
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-11-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -48391.7978563358
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1500
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.569
    dispatch_time_ms: 7.683
    learner:
      cur_lr: 0.0008604999748058617
      grad_gnorm: 40.0
      policy_entropy: 62.14297103881836
      policy_loss: 2233.127685546875
      var_gnorm: 197.89739990234375
      vf_explained_var: 0.0
      vf_loss: 47340.01953125
    num_steps_sampled: 7505000
    num_steps_trained: 7505000
    wait_time_ms: 75.4
  iterations_since_restore: 1501
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13050.659353733063
  time_this_iter_s: 8.049160957336426
  time_total_s: 13050.659353733063
  timestamp: 1594869103
  timesteps_since_restore: 7505000
  timesteps_this_iter: 5000
  timesteps_total: 7505000
  training_iteration: 1501
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13050 s, 1501 iter, 7505000 ts, -4.84e+04 rew

agent-1: -3009.5699003654718
agent-2: -3360.5586427687736
agent-3: -2295.7040473468087
agent-4: -4526.586580645519
agent-5: -5713.910458926884
Extrinsic Rewards:
-2885
-3227
-2202
-4354
-5512
Sum Reward: -18180
Avg Reward: -3636.0
Min Reward: -5512
Max Reward: -2202
Gini Coefficient: -0.17797579757975798
20:20 Ratio: 0.3994920174165457
Max-min Ratio: 0.3994920174165457
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-11-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -48380.16275515553
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1501
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.865
    dispatch_time_ms: 7.139
    learner:
      cur_lr: 0.0008601670269854367
      grad_gnorm: 40.000003814697266
      policy_entropy: 58.18881607055664
      policy_loss: 2915.8134765625
      var_gnorm: 197.4698028564453
      vf_explained_var: 0.0
      vf_loss: 64467.06640625
    num_steps_sampled: 7510000
    num_steps_trained: 7510000
    wait_time_ms: 69.471
  iterations_since_restore: 1502
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13058.61305308342
  time_this_iter_s: 7.953699350357056
  time_total_s: 13058.61305308342
  timestamp: 1594869111
  timesteps_since_restore: 7510000
  timesteps_this_iter: 5000
  timesteps_total: 7510000
  training_iteration: 1502
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13058 s, 1502 iter, 7510000 ts, -4.84e+04 rew

agent-1: -3562.7842243963396
agent-2: -3568.221271268846
agent-3: -3586.275551928872
agent-4: -1777.1786822804256
agent-5: -4242.017229888156
Extrinsic Rewards:
-3410
-3417
-3430
-1689
-4064
Sum Reward: -16010
Avg Reward: -3202.0
Min Reward: -4064
Max Reward: -1689
Gini Coefficient: -0.11917551530293566
20:20 Ratio: 0.4156003937007874
Max-min Ratio: 0.4156003937007874
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-11-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -48366.21975006684
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1502
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.906
    dispatch_time_ms: 9.597
    learner:
      cur_lr: 0.0008598340209573507
      grad_gnorm: 39.999996185302734
      policy_entropy: 61.10840606689453
      policy_loss: 2606.30126953125
      var_gnorm: 197.0790252685547
      vf_explained_var: 0.0
      vf_loss: 67810.171875
    num_steps_sampled: 7515000
    num_steps_trained: 7515000
    wait_time_ms: 68.65
  iterations_since_restore: 1503
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13066.60062122345
  time_this_iter_s: 7.987568140029907
  time_total_s: 13066.60062122345
  timestamp: 1594869119
  timesteps_since_restore: 7515000
  timesteps_this_iter: 5000
  timesteps_total: 7515000
  training_iteration: 1503
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13066 s, 1503 iter, 7515000 ts, -4.84e+04 rew

agent-1: -4277.614071443223
agent-2: -3183.455069968259
agent-3: -4785.189476652875
agent-4: -2305.1781963527324
agent-5: -4372.330613843179
Extrinsic Rewards:
-4110
-3057
-4604
-2213
-4208
Sum Reward: -18192
Avg Reward: -3638.4
Min Reward: -4604
Max Reward: -2213
Gini Coefficient: -0.13045294635004398
20:20 Ratio: 0.4806689834926151
Max-min Ratio: 0.4806689834926151
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-12-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -48352.962579475374
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1503
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.429
    dispatch_time_ms: 9.034
    learner:
      cur_lr: 0.0008595010149292648
      grad_gnorm: 39.999996185302734
      policy_entropy: 60.05674362182617
      policy_loss: 1365.62841796875
      var_gnorm: 196.6712646484375
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 49579.55859375
    num_steps_sampled: 7520000
    num_steps_trained: 7520000
    wait_time_ms: 69.892
  iterations_since_restore: 1504
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13074.617664337158
  time_this_iter_s: 8.017043113708496
  time_total_s: 13074.617664337158
  timestamp: 1594869127
  timesteps_since_restore: 7520000
  timesteps_this_iter: 5000
  timesteps_total: 7520000
  training_iteration: 1504
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13074 s, 1504 iter, 7520000 ts, -4.84e+04 rew

agent-1: -3552.0000368020724
agent-2: -4861.861409675295
agent-3: -4891.3228778462235
agent-4: -5697.740030170252
agent-5: -3234.0515516463124
Extrinsic Rewards:
-3435
-4701
-4724
-5513
-3120
Sum Reward: -21493
Avg Reward: -4298.6
Min Reward: -5513
Max Reward: -3120
Gini Coefficient: -0.11306006606802214
20:20 Ratio: 0.5659350625793579
Max-min Ratio: 0.5659350625793579
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-12-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -48345.248450986255
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1504
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.893
    dispatch_time_ms: 6.884
    learner:
      cur_lr: 0.0008591680089011788
      grad_gnorm: 40.0
      policy_entropy: 62.28193664550781
      policy_loss: 1857.824462890625
      var_gnorm: 196.27432250976562
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 46231.01953125
    num_steps_sampled: 7525000
    num_steps_trained: 7525000
    wait_time_ms: 70.752
  iterations_since_restore: 1505
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13082.61893606186
  time_this_iter_s: 8.001271724700928
  time_total_s: 13082.61893606186
  timestamp: 1594869135
  timesteps_since_restore: 7525000
  timesteps_this_iter: 5000
  timesteps_total: 7525000
  training_iteration: 1505
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13082 s, 1505 iter, 7525000 ts, -4.83e+04 rew

agent-1: -6271.9092189312305
agent-2: -5078.041327388674
agent-3: -3760.0791243206786
agent-4: -5716.324642671532
agent-5: -5047.780045460412
Extrinsic Rewards:
-6114
-4934
-3641
-5540
-4885
Sum Reward: -25114
Avg Reward: -5022.8
Min Reward: -6114
Max Reward: -3641
Gini Coefficient: -0.08920920602054631
20:20 Ratio: 0.5955184821720642
Max-min Ratio: 0.5955184821720642
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-12-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -48481.32031935921
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1505
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.967
    dispatch_time_ms: 9.741
    learner:
      cur_lr: 0.0008588350028730929
      grad_gnorm: 40.0
      policy_entropy: 66.79299926757812
      policy_loss: 521.1766357421875
      var_gnorm: 195.9644775390625
      vf_explained_var: -0.6282632350921631
      vf_loss: 62424.04296875
    num_steps_sampled: 7530000
    num_steps_trained: 7530000
    wait_time_ms: 69.037
  iterations_since_restore: 1506
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13090.691554307938
  time_this_iter_s: 8.072618246078491
  time_total_s: 13090.691554307938
  timestamp: 1594869143
  timesteps_since_restore: 7530000
  timesteps_this_iter: 5000
  timesteps_total: 7530000
  training_iteration: 1506
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13090 s, 1506 iter, 7530000 ts, -4.85e+04 rew

agent-1: -3727.7105495644087
agent-2: -5662.734004772731
agent-3: -4641.967410872239
agent-4: -6943.936911130734
agent-5: -4831.300387089863
Extrinsic Rewards:
-3611
-5501
-4503
-6759
-4688
Sum Reward: -25062
Avg Reward: -5012.4
Min Reward: -6759
Max Reward: -3611
Gini Coefficient: -0.11641529008060011
20:20 Ratio: 0.5342506287912413
Max-min Ratio: 0.5342506287912413
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-12-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -48588.87246640801
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1506
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.299
    dispatch_time_ms: 8.068
    learner:
      cur_lr: 0.0008585019968450069
      grad_gnorm: 40.000003814697266
      policy_entropy: 67.00254821777344
      policy_loss: 318.899658203125
      var_gnorm: 195.63015747070312
      vf_explained_var: 0.0
      vf_loss: 21644.833984375
    num_steps_sampled: 7535000
    num_steps_trained: 7535000
    wait_time_ms: 72.174
  iterations_since_restore: 1507
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13098.779654979706
  time_this_iter_s: 8.088100671768188
  time_total_s: 13098.779654979706
  timestamp: 1594869151
  timesteps_since_restore: 7535000
  timesteps_this_iter: 5000
  timesteps_total: 7535000
  training_iteration: 1507
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13098 s, 1507 iter, 7535000 ts, -4.86e+04 rew

agent-1: -5634.495087863924
agent-2: -4917.796042860681
agent-3: -3227.0720422948557
agent-4: -3183.9152099623457
agent-5: -3709.372056285948
Extrinsic Rewards:
-5448
-4740
-3114
-3065
-3573
Sum Reward: -19940
Avg Reward: -3988.0
Min Reward: -5448
Max Reward: -3065
Gini Coefficient: -0.1282246740220662
20:20 Ratio: 0.5625917767988252
Max-min Ratio: 0.5625917767988252
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-12-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -48671.593212571024
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1507
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.718
    dispatch_time_ms: 26.658
    learner:
      cur_lr: 0.000858168990816921
      grad_gnorm: 39.99999237060547
      policy_entropy: 66.14751434326172
      policy_loss: 2982.6494140625
      var_gnorm: 195.20838928222656
      vf_explained_var: 0.0
      vf_loss: 68413.90625
    num_steps_sampled: 7540000
    num_steps_trained: 7540000
    wait_time_ms: 60.065
  iterations_since_restore: 1508
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13111.596114397049
  time_this_iter_s: 12.81645941734314
  time_total_s: 13111.596114397049
  timestamp: 1594869164
  timesteps_since_restore: 7540000
  timesteps_this_iter: 5000
  timesteps_total: 7540000
  training_iteration: 1508
  
agent-1: -4803.226012565536
agent-2: -6319.550054420359
agent-3: -2907.8635530385045
agent-4: -5024.448539480886
agent-5: -4109.955593899011
Extrinsic Rewards:
-4644
-6127
-2809
-4863
-3965
Sum Reward: -22408
Avg Reward: -4481.6
Min Reward: -6127
Max Reward: -2809
Gini Coefficient: -0.13448768297036773
20:20 Ratio: 0.45846254284315324
Max-min Ratio: 0.45846254284315324
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13111 s, 1508 iter, 7540000 ts, -4.87e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-12-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -48782.02873082215
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1508
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 4.173
    dispatch_time_ms: 31.399
    learner:
      cur_lr: 0.000857835984788835
      grad_gnorm: 40.0
      policy_entropy: 60.39896774291992
      policy_loss: 593.499267578125
      var_gnorm: 194.80479431152344
      vf_explained_var: 0.0
      vf_loss: 62784.9765625
    num_steps_sampled: 7545000
    num_steps_trained: 7545000
    wait_time_ms: 51.81
  iterations_since_restore: 1509
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13120.187849760056
  time_this_iter_s: 8.591735363006592
  time_total_s: 13120.187849760056
  timestamp: 1594869172
  timesteps_since_restore: 7545000
  timesteps_this_iter: 5000
  timesteps_total: 7545000
  training_iteration: 1509
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13120 s, 1509 iter, 7545000 ts, -4.88e+04 rew

agent-1: -1953.823715524615
agent-2: -2399.0199724289914
agent-3: -5434.728875418634
agent-4: -3262.689423356329
agent-5: -5019.222180147942
Extrinsic Rewards:
-1873
-2304
-5234
-3124
-4830
Sum Reward: -17365
Avg Reward: -3473.0
Min Reward: -5234
Max Reward: -1873
Gini Coefficient: -0.2130262021307227
20:20 Ratio: 0.35785250286587694
Max-min Ratio: 0.35785250286587694
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-13-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -48832.59028049328
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1509
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.192
    dispatch_time_ms: 9.009
    learner:
      cur_lr: 0.0008575029787607491
      grad_gnorm: 40.000003814697266
      policy_entropy: 45.87725830078125
      policy_loss: 1392.5189208984375
      var_gnorm: 194.36309814453125
      vf_explained_var: -0.2905421257019043
      vf_loss: 46878.796875
    num_steps_sampled: 7550000
    num_steps_trained: 7550000
    wait_time_ms: 66.599
  iterations_since_restore: 1510
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13128.140425920486
  time_this_iter_s: 7.952576160430908
  time_total_s: 13128.140425920486
  timestamp: 1594869180
  timesteps_since_restore: 7550000
  timesteps_this_iter: 5000
  timesteps_total: 7550000
  training_iteration: 1510
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13128 s, 1510 iter, 7550000 ts, -4.88e+04 rew

agent-1: -5962.400079012515
agent-2: -4026.873888051854
agent-3: -1482.8604711892262
agent-4: -3455.2209806247206
agent-5: -5530.449886129396
Extrinsic Rewards:
-5754
-3881
-1424
-3312
-5356
Sum Reward: -19727
Avg Reward: -3945.4
Min Reward: -5754
Max Reward: -1424
Gini Coefficient: -0.217042631925787
20:20 Ratio: 0.24748001390337157
Max-min Ratio: 0.24748001390337157
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-13-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -48918.889895119064
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1510
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.913
    dispatch_time_ms: 7.128
    learner:
      cur_lr: 0.0008571699727326632
      grad_gnorm: 40.0
      policy_entropy: 52.029014587402344
      policy_loss: 1831.108642578125
      var_gnorm: 193.88662719726562
      vf_explained_var: 0.0
      vf_loss: 43974.25390625
    num_steps_sampled: 7555000
    num_steps_trained: 7555000
    wait_time_ms: 72.871
  iterations_since_restore: 1511
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13136.140525102615
  time_this_iter_s: 8.000099182128906
  time_total_s: 13136.140525102615
  timestamp: 1594869188
  timesteps_since_restore: 7555000
  timesteps_this_iter: 5000
  timesteps_total: 7555000
  training_iteration: 1511
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13136 s, 1511 iter, 7555000 ts, -4.89e+04 rew

agent-1: -2207.1394553597715
agent-2: -1864.8574416438864
agent-3: -3111.1179908457816
agent-4: -2518.5058092847094
agent-5: -2742.8122184300173
Extrinsic Rewards:
-2097
-1739
-2933
-2378
-2583
Sum Reward: -11730
Avg Reward: -2346.0
Min Reward: -2933
Max Reward: -1739
Gini Coefficient: -0.09800511508951407
20:20 Ratio: 0.59290828503239
Max-min Ratio: 0.59290828503239
agent-1: -1500.7259341257763
agent-2: -3188.0673332580186
agent-3: -2015.9694965399237
agent-4: -2916.0468866453507
agent-5: -1822.0994919989482
Extrinsic Rewards:
-1397
-2996
-1880
-2737
-1687
Sum Reward: -10697
Avg Reward: -2139.4
Min Reward: -2996
Max Reward: -1397
Gini Coefficient: -0.15884827521735065
20:20 Ratio: 0.46628838451268356
Max-min Ratio: 0.46628838451268356
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-13-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -48859.9268652078
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 2
  episodes_total: 1512
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.448
    dispatch_time_ms: 7.618
    learner:
      cur_lr: 0.0008568370249122381
      grad_gnorm: 40.0
      policy_entropy: 51.22660446166992
      policy_loss: 993.0372314453125
      var_gnorm: 193.4254150390625
      vf_explained_var: -0.5651934146881104
      vf_loss: 47152.1640625
    num_steps_sampled: 7560000
    num_steps_trained: 7560000
    wait_time_ms: 68.468
  iterations_since_restore: 1512
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13144.125010490417
  time_this_iter_s: 7.984485387802124
  time_total_s: 13144.125010490417
  timestamp: 1594869197
  timesteps_since_restore: 7560000
  timesteps_this_iter: 5000
  timesteps_total: 7560000
  training_iteration: 1512
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13144 s, 1512 iter, 7560000 ts, -4.89e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-13-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -48859.92686520782
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 0
  episodes_total: 1512
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.96
    dispatch_time_ms: 8.089
    learner:
      cur_lr: 0.0008565040188841522
      grad_gnorm: 40.0
      policy_entropy: 53.40410232543945
      policy_loss: 1509.3787841796875
      var_gnorm: 192.9721221923828
      vf_explained_var: 0.0
      vf_loss: 33871.83984375
    num_steps_sampled: 7565000
    num_steps_trained: 7565000
    wait_time_ms: 69.794
  iterations_since_restore: 1513
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13152.06584906578
  time_this_iter_s: 7.940838575363159
  time_total_s: 13152.06584906578
  timestamp: 1594869204
  timesteps_since_restore: 7565000
  timesteps_this_iter: 5000
  timesteps_total: 7565000
  training_iteration: 1513
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13152 s, 1513 iter, 7565000 ts, -4.89e+04 rew

agent-1: -2082.675748095688
agent-2: -3383.1797167114855
agent-3: -2252.630042916787
agent-4: -2456.7551182240763
agent-5: -1991.671060160722
Extrinsic Rewards:
-1960
-3206
-2107
-2308
-1862
Sum Reward: -11443
Avg Reward: -2288.6
Min Reward: -3206
Max Reward: -1862
Gini Coefficient: -0.10612601590492003
20:20 Ratio: 0.5807860262008734
Max-min Ratio: 0.5807860262008734
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-13-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -48810.83688866243
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1513
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.558
    dispatch_time_ms: 6.738
    learner:
      cur_lr: 0.0008561710128560662
      grad_gnorm: 40.000003814697266
      policy_entropy: 58.18998718261719
      policy_loss: 2243.514404296875
      var_gnorm: 192.51654052734375
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 54863.16015625
    num_steps_sampled: 7570000
    num_steps_trained: 7570000
    wait_time_ms: 70.031
  iterations_since_restore: 1514
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13160.095792293549
  time_this_iter_s: 8.029943227767944
  time_total_s: 13160.095792293549
  timestamp: 1594869213
  timesteps_since_restore: 7570000
  timesteps_this_iter: 5000
  timesteps_total: 7570000
  training_iteration: 1514
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13160 s, 1514 iter, 7570000 ts, -4.88e+04 rew

agent-1: -4204.076963179758
agent-2: -5668.216889753846
agent-3: -1455.568697296563
agent-4: -2951.486377986346
agent-5: -2340.3771024811304
Extrinsic Rewards:
-4021
-5455
-1380
-2822
-2222
Sum Reward: -15900
Avg Reward: -3180.0
Min Reward: -5455
Max Reward: -1380
Gini Coefficient: -0.2502893081761006
20:20 Ratio: 0.2529789184234647
Max-min Ratio: 0.2529789184234647
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-13-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -48814.57379419264
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1514
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.549
    dispatch_time_ms: 6.551
    learner:
      cur_lr: 0.0008558380068279803
      grad_gnorm: 39.99999237060547
      policy_entropy: 43.29214096069336
      policy_loss: 495.8839416503906
      var_gnorm: 192.09559631347656
      vf_explained_var: 0.0
      vf_loss: 60151.640625
    num_steps_sampled: 7575000
    num_steps_trained: 7575000
    wait_time_ms: 74.406
  iterations_since_restore: 1515
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13168.111299276352
  time_this_iter_s: 8.015506982803345
  time_total_s: 13168.111299276352
  timestamp: 1594869221
  timesteps_since_restore: 7575000
  timesteps_this_iter: 5000
  timesteps_total: 7575000
  training_iteration: 1515
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13168 s, 1515 iter, 7575000 ts, -4.88e+04 rew

agent-1: -3424.281453173117
agent-2: -4522.844424356252
agent-3: -127.6236340161578
agent-4: -8561.766668828426
agent-5: -5599.496726531548
Extrinsic Rewards:
-3299
-4379
-119
-8325
-5415
Sum Reward: -21537
Avg Reward: -4307.4
Min Reward: -8325
Max Reward: -119
Gini Coefficient: -0.34411477921716116
20:20 Ratio: 0.014294294294294295
Max-min Ratio: 0.014294294294294295
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-13-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10594.250462302429
  episode_reward_mean: -48899.56154736288
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1515
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.476
    dispatch_time_ms: 7.527
    learner:
      cur_lr: 0.0008555050007998943
      grad_gnorm: 40.0
      policy_entropy: 42.40640640258789
      policy_loss: 566.3611450195312
      var_gnorm: 191.68673706054688
      vf_explained_var: 0.0
      vf_loss: 26053.50390625
    num_steps_sampled: 7580000
    num_steps_trained: 7580000
    wait_time_ms: 69.849
  iterations_since_restore: 1516
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13176.002914190292
  time_this_iter_s: 7.89161491394043
  time_total_s: 13176.002914190292
  timestamp: 1594869229
  timesteps_since_restore: 7580000
  timesteps_this_iter: 5000
  timesteps_total: 7580000
  training_iteration: 1516
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13176 s, 1516 iter, 7580000 ts, -4.89e+04 rew

agent-1: -5196.97176366479
agent-2: -3852.033891277249
agent-3: -2213.5606808307784
agent-4: -4274.786750333508
agent-5: -2931.7868377371155
Extrinsic Rewards:
-5005
-3691
-2111
-4102
-2807
Sum Reward: -17716
Avg Reward: -3543.2
Min Reward: -5005
Max Reward: -2111
Gini Coefficient: -0.15992323323549335
20:20 Ratio: 0.4217782217782218
Max-min Ratio: 0.4217782217782218
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-13-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10735.752343786366
  episode_reward_mean: -48978.310441978276
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1516
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.193
    dispatch_time_ms: 6.446
    learner:
      cur_lr: 0.0008551719947718084
      grad_gnorm: 40.0
      policy_entropy: 41.982669830322266
      policy_loss: -116.76466369628906
      var_gnorm: 191.2742156982422
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 34732.16796875
    num_steps_sampled: 7585000
    num_steps_trained: 7585000
    wait_time_ms: 69.844
  iterations_since_restore: 1517
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13183.905091285706
  time_this_iter_s: 7.902177095413208
  time_total_s: 13183.905091285706
  timestamp: 1594869237
  timesteps_since_restore: 7585000
  timesteps_this_iter: 5000
  timesteps_total: 7585000
  training_iteration: 1517
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13183 s, 1517 iter, 7585000 ts, -4.9e+04 rew

agent-1: -4510.880715109396
agent-2: -2638.205258864368
agent-3: -3713.036913481348
agent-4: -1795.5404052513395
agent-5: -636.0418274304197
Extrinsic Rewards:
-4292
-2503
-3514
-1697
-599
Sum Reward: -12605
Avg Reward: -2521.0
Min Reward: -4292
Max Reward: -599
Gini Coefficient: -0.29204284014280046
20:20 Ratio: 0.13956197576887233
Max-min Ratio: 0.13956197576887233
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-14-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10735.752343786366
  episode_reward_mean: -48964.00718731547
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1517
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.677
    dispatch_time_ms: 7.697
    learner:
      cur_lr: 0.0008548389887437224
      grad_gnorm: 40.0
      policy_entropy: 32.65753936767578
      policy_loss: 1889.64599609375
      var_gnorm: 190.8351287841797
      vf_explained_var: 0.0
      vf_loss: 53936.41796875
    num_steps_sampled: 7590000
    num_steps_trained: 7590000
    wait_time_ms: 69.632
  iterations_since_restore: 1518
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13191.947174549103
  time_this_iter_s: 8.042083263397217
  time_total_s: 13191.947174549103
  timestamp: 1594869245
  timesteps_since_restore: 7590000
  timesteps_this_iter: 5000
  timesteps_total: 7590000
  training_iteration: 1518
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13191 s, 1518 iter, 7590000 ts, -4.9e+04 rew

agent-1: -3892.5126949627866
agent-2: -3800.314547717907
agent-3: -3353.1375459365827
agent-4: -2901.140628881502
agent-5: -1554.0312316785405
Extrinsic Rewards:
-3719
-3614
-3195
-2767
-1478
Sum Reward: -14773
Avg Reward: -2954.6
Min Reward: -3719
Max Reward: -1478
Gini Coefficient: -0.14429025925675218
20:20 Ratio: 0.3974186609303576
Max-min Ratio: 0.3974186609303576
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-14-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -10735.752343786366
  episode_reward_mean: -48981.368885885
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1518
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.285
    dispatch_time_ms: 7.624
    learner:
      cur_lr: 0.0008545059827156365
      grad_gnorm: 40.000003814697266
      policy_entropy: 28.579906463623047
      policy_loss: 989.966796875
      var_gnorm: 190.3613739013672
      vf_explained_var: 0.0
      vf_loss: 38643.1875
    num_steps_sampled: 7595000
    num_steps_trained: 7595000
    wait_time_ms: 72.628
  iterations_since_restore: 1519
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13199.821482896805
  time_this_iter_s: 7.874308347702026
  time_total_s: 13199.821482896805
  timestamp: 1594869252
  timesteps_since_restore: 7595000
  timesteps_this_iter: 5000
  timesteps_total: 7595000
  training_iteration: 1519
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13199 s, 1519 iter, 7595000 ts, -4.9e+04 rew

agent-1: -1880.4555486719782
agent-2: -1430.5710855715445
agent-3: -1711.2438792544822
agent-4: -1596.2906789377216
agent-5: -448.35011824823215
Extrinsic Rewards:
-1703
-1298
-1538
-1440
-396
Sum Reward: -6375
Avg Reward: -1275.0
Min Reward: -1703
Max Reward: -396
Gini Coefficient: -0.17907450980392156
20:20 Ratio: 0.23253082795067528
Max-min Ratio: 0.23253082795067528
agent-1: -527.2014473635434
agent-2: -227.33052616268557
agent-3: -2624.902659597045
agent-4: -2149.53904921006
agent-5: -1593.218116181836
Extrinsic Rewards:
-444
-197
-2401
-1950
-1444
Sum Reward: -6436
Avg Reward: -1287.2
Min Reward: -2401
Max Reward: -197
Gini Coefficient: -0.3675574891236793
20:20 Ratio: 0.08204914618908787
Max-min Ratio: 0.08204914618908787
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-14-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -7066.911310683941
  episode_reward_mean: -48662.34534046966
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 2
  episodes_total: 1520
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.842
    dispatch_time_ms: 24.074
    learner:
      cur_lr: 0.0008541729766875505
      grad_gnorm: 40.000003814697266
      policy_entropy: 25.605039596557617
      policy_loss: 24209.064453125
      var_gnorm: 189.89503479003906
      vf_explained_var: -1.3113021850585938e-06
      vf_loss: 19059152.0
    num_steps_sampled: 7600000
    num_steps_trained: 7600000
    wait_time_ms: 56.095
  iterations_since_restore: 1520
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13208.14913225174
  time_this_iter_s: 8.327649354934692
  time_total_s: 13208.14913225174
  timestamp: 1594869261
  timesteps_since_restore: 7600000
  timesteps_this_iter: 5000
  timesteps_total: 7600000
  training_iteration: 1520
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13208 s, 1520 iter, 7600000 ts, -4.87e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-14-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -7066.911310683941
  episode_reward_mean: -48662.34534046966
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 0
  episodes_total: 1520
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.645
    dispatch_time_ms: 33.047
    learner:
      cur_lr: 0.0008538400288671255
      grad_gnorm: 39.999996185302734
      policy_entropy: 24.359872817993164
      policy_loss: 1155.728515625
      var_gnorm: 189.427490234375
      vf_explained_var: 0.0
      vf_loss: 54211.3515625
    num_steps_sampled: 7605000
    num_steps_trained: 7605000
    wait_time_ms: 48.059
  iterations_since_restore: 1521
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13216.59455704689
  time_this_iter_s: 8.445424795150757
  time_total_s: 13216.59455704689
  timestamp: 1594869269
  timesteps_since_restore: 7605000
  timesteps_this_iter: 5000
  timesteps_total: 7605000
  training_iteration: 1521
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13216 s, 1521 iter, 7605000 ts, -4.87e+04 rew

agent-1: -2431.4448919527217
agent-2: -1159.2109980701473
agent-3: -441.41415036539524
agent-4: -1867.8526982415967
agent-5: -1506.806414408121
Extrinsic Rewards:
-2236
-1034
-390
-1691
-1343
Sum Reward: -6694
Avg Reward: -1338.8
Min Reward: -2236
Max Reward: -390
Gini Coefficient: -0.25987451449058857
20:20 Ratio: 0.1744186046511628
Max-min Ratio: 0.1744186046511628
agent-1: -803.9156884750738
agent-2: -1171.3445184626678
agent-3: -1651.2979968695247
agent-4: -1280.3199283980339
agent-5: -1609.596101339026
Extrinsic Rewards:
-689
-1030
-1486
-1139
-1433
Sum Reward: -5777
Avg Reward: -1155.4
Min Reward: -1486
Max Reward: -689
Gini Coefficient: -0.1382724597541977
20:20 Ratio: 0.4636608344549125
Max-min Ratio: 0.4636608344549125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-14-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -7066.911310683941
  episode_reward_mean: -48421.80197814243
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1521
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.721
    dispatch_time_ms: 38.195
    learner:
      cur_lr: 0.0008535070228390396
      grad_gnorm: 40.0
      policy_entropy: 23.602310180664062
      policy_loss: 727.2799072265625
      var_gnorm: 188.95968627929688
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 41563.43359375
    num_steps_sampled: 7610000
    num_steps_trained: 7610000
    wait_time_ms: 68.219
  iterations_since_restore: 1522
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13225.322637081146
  time_this_iter_s: 8.728080034255981
  time_total_s: 13225.322637081146
  timestamp: 1594869278
  timesteps_since_restore: 7610000
  timesteps_this_iter: 5000
  timesteps_total: 7610000
  training_iteration: 1522
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13225 s, 1522 iter, 7610000 ts, -4.84e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-14-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6516.474233544297
  episode_reward_mean: -48100.78331500259
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1522
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.445
    dispatch_time_ms: 42.757
    learner:
      cur_lr: 0.0008531740168109536
      grad_gnorm: 39.999996185302734
      policy_entropy: 23.656166076660156
      policy_loss: 787.75390625
      var_gnorm: 188.49620056152344
      vf_explained_var: 0.0
      vf_loss: 64961.9765625
    num_steps_sampled: 7615000
    num_steps_trained: 7615000
    wait_time_ms: 37.542
  iterations_since_restore: 1523
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13233.772012472153
  time_this_iter_s: 8.44937539100647
  time_total_s: 13233.772012472153
  timestamp: 1594869287
  timesteps_since_restore: 7615000
  timesteps_this_iter: 5000
  timesteps_total: 7615000
  training_iteration: 1523
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13233 s, 1523 iter, 7615000 ts, -4.81e+04 rew

agent-1: -1060.6765012513147
agent-2: -1967.5916147613973
agent-3: -1485.3665148138389
agent-4: -1282.2866092674142
agent-5: -1956.081785728131
Extrinsic Rewards:
-949
-1799
-1331
-1150
-1791
Sum Reward: -7020
Avg Reward: -1404.0
Min Reward: -1799
Max Reward: -949
Gini Coefficient: -0.1333903133903134
20:20 Ratio: 0.5275152862701501
Max-min Ratio: 0.5275152862701501
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-14-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6516.474233544297
  episode_reward_mean: -47836.60118097442
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1523
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.172
    dispatch_time_ms: 46.467
    learner:
      cur_lr: 0.0008528410107828677
      grad_gnorm: 40.0
      policy_entropy: 23.136310577392578
      policy_loss: 550.9189453125
      var_gnorm: 188.03489685058594
      vf_explained_var: 0.0
      vf_loss: 65128.62109375
    num_steps_sampled: 7620000
    num_steps_trained: 7620000
    wait_time_ms: 39.665
  iterations_since_restore: 1524
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13242.20185661316
  time_this_iter_s: 8.42984414100647
  time_total_s: 13242.20185661316
  timestamp: 1594869295
  timesteps_since_restore: 7620000
  timesteps_this_iter: 5000
  timesteps_total: 7620000
  training_iteration: 1524
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13242 s, 1524 iter, 7620000 ts, -4.78e+04 rew

agent-1: -2465.014434883628
agent-2: -632.0949488849238
agent-3: -971.2916854119726
agent-4: -416.39995884846627
agent-5: -2395.6141691598077
Extrinsic Rewards:
-2244
-544
-852
-342
-2184
Sum Reward: -6166
Avg Reward: -1233.2
Min Reward: -2244
Max Reward: -342
Gini Coefficient: -0.3531625040544924
20:20 Ratio: 0.15240641711229946
Max-min Ratio: 0.15240641711229946
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-15-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6516.474233544297
  episode_reward_mean: -47607.99350976423
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1524
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.52
    dispatch_time_ms: 25.047
    learner:
      cur_lr: 0.0008525080047547817
      grad_gnorm: 40.0
      policy_entropy: 26.565189361572266
      policy_loss: 1651.916015625
      var_gnorm: 187.57469177246094
      vf_explained_var: 0.0
      vf_loss: 64601.859375
    num_steps_sampled: 7625000
    num_steps_trained: 7625000
    wait_time_ms: 69.602
  iterations_since_restore: 1525
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13250.735475063324
  time_this_iter_s: 8.533618450164795
  time_total_s: 13250.735475063324
  timestamp: 1594869304
  timesteps_since_restore: 7625000
  timesteps_this_iter: 5000
  timesteps_total: 7625000
  training_iteration: 1525
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13250 s, 1525 iter, 7625000 ts, -4.76e+04 rew

agent-1: -1751.000874428023
agent-2: -1559.5951126056307
agent-3: -1662.8802015734386
agent-4: -1399.9657106462425
agent-5: -1628.9329433043429
Extrinsic Rewards:
-1597
-1408
-1505
-1270
-1503
Sum Reward: -7283
Avg Reward: -1456.6
Min Reward: -1597
Max Reward: -1270
Gini Coefficient: -0.04124673898118907
20:20 Ratio: 0.7952410770194114
Max-min Ratio: 0.7952410770194114
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-15-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6516.474233544297
  episode_reward_mean: -47217.433202450884
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1525
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.693
    dispatch_time_ms: 34.042
    learner:
      cur_lr: 0.0008521749987266958
      grad_gnorm: 40.0
      policy_entropy: 30.155948638916016
      policy_loss: 848.930419921875
      var_gnorm: 187.12103271484375
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 42097.23828125
    num_steps_sampled: 7630000
    num_steps_trained: 7630000
    wait_time_ms: 51.289
  iterations_since_restore: 1526
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13259.151726961136
  time_this_iter_s: 8.41625189781189
  time_total_s: 13259.151726961136
  timestamp: 1594869312
  timesteps_since_restore: 7630000
  timesteps_this_iter: 5000
  timesteps_total: 7630000
  training_iteration: 1526
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13259 s, 1526 iter, 7630000 ts, -4.72e+04 rew

agent-1: -1474.7797195061066
agent-2: -1201.6628485868212
agent-3: -2516.6760712211926
agent-4: -1950.4796904330028
agent-5: -2019.026358146809
Extrinsic Rewards:
-1360
-1111
-2299
-1769
-1848
Sum Reward: -8387
Avg Reward: -1677.4
Min Reward: -2299
Max Reward: -1111
Gini Coefficient: -0.13659234529629188
20:20 Ratio: 0.48325358851674644
Max-min Ratio: 0.48325358851674644
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-15-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6516.474233544297
  episode_reward_mean: -46920.80764133717
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1526
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.659
    dispatch_time_ms: 26.31
    learner:
      cur_lr: 0.0008518419926986098
      grad_gnorm: 40.0
      policy_entropy: 36.33021545410156
      policy_loss: 777.6659545898438
      var_gnorm: 186.707763671875
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 41455.15234375
    num_steps_sampled: 7635000
    num_steps_trained: 7635000
    wait_time_ms: 54.659
  iterations_since_restore: 1527
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13267.604952812195
  time_this_iter_s: 8.45322585105896
  time_total_s: 13267.604952812195
  timestamp: 1594869321
  timesteps_since_restore: 7635000
  timesteps_this_iter: 5000
  timesteps_total: 7635000
  training_iteration: 1527
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13267 s, 1527 iter, 7635000 ts, -4.69e+04 rew

agent-1: -5008.9969149880435
agent-2: -3416.992039162857
agent-3: -5668.809003038561
agent-4: -1779.684932515527
agent-5: -3301.639231850817
Extrinsic Rewards:
-4819
-3278
-5464
-1697
-3169
Sum Reward: -18427
Avg Reward: -3685.4
Min Reward: -5464
Max Reward: -1697
Gini Coefficient: -0.19935963531774029
20:20 Ratio: 0.3105783308931186
Max-min Ratio: 0.3105783308931186
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-15-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6516.474233544297
  episode_reward_mean: -46741.56833438862
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1527
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.805
    dispatch_time_ms: 7.324
    learner:
      cur_lr: 0.0008515089866705239
      grad_gnorm: 39.999996185302734
      policy_entropy: 43.76320266723633
      policy_loss: 1554.1888427734375
      var_gnorm: 186.32754516601562
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 52473.10546875
    num_steps_sampled: 7640000
    num_steps_trained: 7640000
    wait_time_ms: 70.544
  iterations_since_restore: 1528
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13275.91750073433
  time_this_iter_s: 8.3125479221344
  time_total_s: 13275.91750073433
  timestamp: 1594869329
  timesteps_since_restore: 7640000
  timesteps_this_iter: 5000
  timesteps_total: 7640000
  training_iteration: 1528
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13275 s, 1528 iter, 7640000 ts, -4.67e+04 rew

agent-1: -5717.625722085367
agent-2: -3960.9773820681976
agent-3: -3045.1488385266944
agent-4: -2939.6332912408734
agent-5: -3452.226851219005
Extrinsic Rewards:
-5517
-3813
-2915
-2814
-3319
Sum Reward: -18378
Avg Reward: -3675.6
Min Reward: -5517
Max Reward: -2814
Gini Coefficient: -0.13720753074328002
20:20 Ratio: 0.5100598151169113
Max-min Ratio: 0.5100598151169113
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-15-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6516.474233544297
  episode_reward_mean: -46530.391624984404
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1528
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.167
    dispatch_time_ms: 9.463
    learner:
      cur_lr: 0.0008511759806424379
      grad_gnorm: 39.999996185302734
      policy_entropy: 47.29259490966797
      policy_loss: 1306.9478759765625
      var_gnorm: 185.94175720214844
      vf_explained_var: 0.0
      vf_loss: 86974.7890625
    num_steps_sampled: 7645000
    num_steps_trained: 7645000
    wait_time_ms: 68.667
  iterations_since_restore: 1529
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13283.92065834999
  time_this_iter_s: 8.003157615661621
  time_total_s: 13283.92065834999
  timestamp: 1594869337
  timesteps_since_restore: 7645000
  timesteps_this_iter: 5000
  timesteps_total: 7645000
  training_iteration: 1529
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13283 s, 1529 iter, 7645000 ts, -4.65e+04 rew

agent-1: -5510.735546684724
agent-2: -3177.1674234052552
agent-3: -2600.4936114574675
agent-4: -2424.490642906897
agent-5: -5532.541687053434
Extrinsic Rewards:
-5311
-3044
-2498
-2320
-5354
Sum Reward: -18527
Avg Reward: -3705.4
Min Reward: -5354
Max Reward: -2320
Gini Coefficient: -0.1917417822637232
20:20 Ratio: 0.4333208815838625
Max-min Ratio: 0.4333208815838625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-15-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6516.474233544297
  episode_reward_mean: -46456.43683396107
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1529
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.494
    dispatch_time_ms: 9.419
    learner:
      cur_lr: 0.000850842974614352
      grad_gnorm: 40.0
      policy_entropy: 34.562862396240234
      policy_loss: 758.4107666015625
      var_gnorm: 185.5546112060547
      vf_explained_var: 0.0
      vf_loss: 54041.1640625
    num_steps_sampled: 7650000
    num_steps_trained: 7650000
    wait_time_ms: 67.207
  iterations_since_restore: 1530
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13291.986380338669
  time_this_iter_s: 8.065721988677979
  time_total_s: 13291.986380338669
  timestamp: 1594869345
  timesteps_since_restore: 7650000
  timesteps_this_iter: 5000
  timesteps_total: 7650000
  training_iteration: 1530
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13291 s, 1530 iter, 7650000 ts, -4.65e+04 rew

agent-1: -5657.7646655770195
agent-2: -2718.3855096966713
agent-3: -2322.488371654724
agent-4: -4577.678298567867
agent-5: -4054.66754228654
Extrinsic Rewards:
-5464
-2616
-2230
-4411
-3915
Sum Reward: -18636
Avg Reward: -3727.2
Min Reward: -5464
Max Reward: -2230
Gini Coefficient: -0.1773556557201116
20:20 Ratio: 0.4081259150805271
Max-min Ratio: 0.4081259150805271
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-15-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6516.474233544297
  episode_reward_mean: -46431.14897972568
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1530
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.067
    dispatch_time_ms: 6.795
    learner:
      cur_lr: 0.000850510026793927
      grad_gnorm: 40.0
      policy_entropy: 32.87618637084961
      policy_loss: 1046.572509765625
      var_gnorm: 185.115966796875
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 45956.921875
    num_steps_sampled: 7655000
    num_steps_trained: 7655000
    wait_time_ms: 69.508
  iterations_since_restore: 1531
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13299.821570634842
  time_this_iter_s: 7.835190296173096
  time_total_s: 13299.821570634842
  timestamp: 1594869353
  timesteps_since_restore: 7655000
  timesteps_this_iter: 5000
  timesteps_total: 7655000
  training_iteration: 1531
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13299 s, 1531 iter, 7655000 ts, -4.64e+04 rew

agent-1: -1902.1352705764466
agent-2: -2334.4015150565187
agent-3: -2938.171168281603
agent-4: -3852.7591874847476
agent-5: -3052.8012300384266
Extrinsic Rewards:
-1799
-2208
-2792
-3663
-2895
Sum Reward: -13357
Avg Reward: -2671.4
Min Reward: -3663
Max Reward: -1799
Gini Coefficient: -0.1322153178108857
20:20 Ratio: 0.4911274911274911
Max-min Ratio: 0.4911274911274911
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-16-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6516.474233544297
  episode_reward_mean: -46317.76213429899
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1531
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.614
    dispatch_time_ms: 6.504
    learner:
      cur_lr: 0.000850177020765841
      grad_gnorm: 40.000003814697266
      policy_entropy: 28.448381423950195
      policy_loss: -443.50830078125
      var_gnorm: 184.68641662597656
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 47171.19921875
    num_steps_sampled: 7660000
    num_steps_trained: 7660000
    wait_time_ms: 68.296
  iterations_since_restore: 1532
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13307.786525249481
  time_this_iter_s: 7.964954614639282
  time_total_s: 13307.786525249481
  timestamp: 1594869361
  timesteps_since_restore: 7660000
  timesteps_this_iter: 5000
  timesteps_total: 7660000
  training_iteration: 1532
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13307 s, 1532 iter, 7660000 ts, -4.63e+04 rew

agent-1: -3503.60635328747
agent-2: -417.5572045748618
agent-3: -5644.20858189728
agent-4: -4689.077464925728
agent-5: -4267.456009849774
Extrinsic Rewards:
-3362
-393
-5439
-4497
-4105
Sum Reward: -17796
Avg Reward: -3559.2
Min Reward: -5439
Max Reward: -393
Gini Coefficient: -0.2523488424365026
20:20 Ratio: 0.07225592939878654
Max-min Ratio: 0.07225592939878654
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-16-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6516.474233544297
  episode_reward_mean: -46205.0304634711
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1532
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.104
    dispatch_time_ms: 7.051
    learner:
      cur_lr: 0.0008498440147377551
      grad_gnorm: 40.0
      policy_entropy: 21.9105224609375
      policy_loss: 612.4176025390625
      var_gnorm: 184.23733520507812
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 61861.0390625
    num_steps_sampled: 7665000
    num_steps_trained: 7665000
    wait_time_ms: 72.191
  iterations_since_restore: 1533
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13315.653940677643
  time_this_iter_s: 7.867415428161621
  time_total_s: 13315.653940677643
  timestamp: 1594869369
  timesteps_since_restore: 7665000
  timesteps_this_iter: 5000
  timesteps_total: 7665000
  training_iteration: 1533
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13315 s, 1533 iter, 7665000 ts, -4.62e+04 rew

agent-1: -1176.9649950193525
agent-2: -1238.8775363012219
agent-3: -837.0412294496896
agent-4: -1383.8421284923677
agent-5: -2087.02242755456
Extrinsic Rewards:
-1050
-1103
-748
-1243
-1885
Sum Reward: -6029
Avg Reward: -1205.8
Min Reward: -1885
Max Reward: -748
Gini Coefficient: -0.16367556808757672
20:20 Ratio: 0.396816976127321
Max-min Ratio: 0.396816976127321
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-16-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6516.474233544297
  episode_reward_mean: -45968.30474687353
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1533
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.667
    dispatch_time_ms: 7.494
    learner:
      cur_lr: 0.0008495110087096691
      grad_gnorm: 40.0
      policy_entropy: 20.316818237304688
      policy_loss: 721.1378784179688
      var_gnorm: 183.77597045898438
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 40427.43359375
    num_steps_sampled: 7670000
    num_steps_trained: 7670000
    wait_time_ms: 68.122
  iterations_since_restore: 1534
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13323.573998451233
  time_this_iter_s: 7.920057773590088
  time_total_s: 13323.573998451233
  timestamp: 1594869377
  timesteps_since_restore: 7670000
  timesteps_this_iter: 5000
  timesteps_total: 7670000
  training_iteration: 1534
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13323 s, 1534 iter, 7670000 ts, -4.6e+04 rew

agent-1: -60.37804559686462
agent-2: -1429.3924406151457
agent-3: -1746.6018816529654
agent-4: -2967.4851286852863
agent-5: -2842.75377919278
Extrinsic Rewards:
-54
-1310
-1595
-2753
-2650
Sum Reward: -8362
Avg Reward: -1672.4
Min Reward: -2753
Max Reward: -54
Gini Coefficient: -0.32231523558957187
20:20 Ratio: 0.01961496549219034
Max-min Ratio: 0.01961496549219034
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-16-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6516.474233544297
  episode_reward_mean: -45731.699999016055
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1534
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.771
    dispatch_time_ms: 7.444
    learner:
      cur_lr: 0.0008491780026815832
      grad_gnorm: 40.0
      policy_entropy: 22.745939254760742
      policy_loss: 477.09246826171875
      var_gnorm: 183.32159423828125
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 61261.08984375
    num_steps_sampled: 7675000
    num_steps_trained: 7675000
    wait_time_ms: 64.085
  iterations_since_restore: 1535
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13331.379001379013
  time_this_iter_s: 7.805002927780151
  time_total_s: 13331.379001379013
  timestamp: 1594869385
  timesteps_since_restore: 7675000
  timesteps_this_iter: 5000
  timesteps_total: 7675000
  training_iteration: 1535
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13331 s, 1535 iter, 7675000 ts, -4.57e+04 rew

agent-1: -1115.8280273027406
agent-2: -2295.5268430264646
agent-3: -637.9221605057734
agent-4: -1567.4963103635102
agent-5: -742.4176547017131
Extrinsic Rewards:
-991
-2086
-549
-1397
-645
Sum Reward: -5668
Avg Reward: -1133.6
Min Reward: -2086
Max Reward: -549
Gini Coefficient: -0.2700070571630205
20:20 Ratio: 0.26318312559923296
Max-min Ratio: 0.26318312559923296
agent-1: -532.4297261371978
agent-2: -1932.59560061237
agent-3: -1390.6456013677846
agent-4: -339.4902988709586
agent-5: -2559.9881150468345
Extrinsic Rewards:
-469
-1748
-1250
-294
-2342
Sum Reward: -6103
Avg Reward: -1220.6
Min Reward: -2342
Max Reward: -294
Gini Coefficient: -0.3522857611010978
20:20 Ratio: 0.125533731853117
Max-min Ratio: 0.125533731853117
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-16-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -44938.137957938154
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 2
  episodes_total: 1536
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.383
    dispatch_time_ms: 746.506
    learner:
      cur_lr: 0.0008488449966534972
      grad_gnorm: 40.0
      policy_entropy: 22.112747192382812
      policy_loss: 1587.291015625
      var_gnorm: 182.86474609375
      vf_explained_var: 0.0
      vf_loss: 60600.42578125
    num_steps_sampled: 7680000
    num_steps_trained: 7680000
    wait_time_ms: 92.371
  iterations_since_restore: 1536
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13346.919092655182
  time_this_iter_s: 15.540091276168823
  time_total_s: 13346.919092655182
  timestamp: 1594869400
  timesteps_since_restore: 7680000
  timesteps_this_iter: 5000
  timesteps_total: 7680000
  training_iteration: 1536
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13346 s, 1536 iter, 7680000 ts, -4.49e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-16-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -44938.13795793815
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 0
  episodes_total: 1536
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.933
    dispatch_time_ms: 34.329
    learner:
      cur_lr: 0.0008485119906254113
      grad_gnorm: 40.000003814697266
      policy_entropy: 25.72890281677246
      policy_loss: 1974.4473876953125
      var_gnorm: 182.4084930419922
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 52093.0703125
    num_steps_sampled: 7685000
    num_steps_trained: 7685000
    wait_time_ms: 48.222
  iterations_since_restore: 1537
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13354.840178251266
  time_this_iter_s: 7.921085596084595
  time_total_s: 13354.840178251266
  timestamp: 1594869408
  timesteps_since_restore: 7685000
  timesteps_this_iter: 5000
  timesteps_total: 7685000
  training_iteration: 1537
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13354 s, 1537 iter, 7685000 ts, -4.49e+04 rew

agent-1: -770.2877707037766
agent-2: -2466.965818967228
agent-3: -2195.0662265972005
agent-4: -1749.928030530487
agent-5: -1442.4862960348007
Extrinsic Rewards:
-680
-2272
-2020
-1616
-1309
Sum Reward: -7897
Avg Reward: -1579.4
Min Reward: -2272
Max Reward: -680
Gini Coefficient: -0.19729011016841838
20:20 Ratio: 0.2992957746478873
Max-min Ratio: 0.2992957746478873
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-16-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -44485.548892321225
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1537
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.06
    dispatch_time_ms: 27.922
    learner:
      cur_lr: 0.0008481789845973253
      grad_gnorm: 40.0
      policy_entropy: 27.062273025512695
      policy_loss: 1498.61865234375
      var_gnorm: 181.96824645996094
      vf_explained_var: 0.0
      vf_loss: 51711.2578125
    num_steps_sampled: 7690000
    num_steps_trained: 7690000
    wait_time_ms: 58.124
  iterations_since_restore: 1538
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13363.29331612587
  time_this_iter_s: 8.453137874603271
  time_total_s: 13363.29331612587
  timestamp: 1594869417
  timesteps_since_restore: 7690000
  timesteps_this_iter: 5000
  timesteps_total: 7690000
  training_iteration: 1538
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13363 s, 1538 iter, 7690000 ts, -4.45e+04 rew

agent-1: -1303.8916426257376
agent-2: -2590.26333425841
agent-3: -2781.8663733825288
agent-4: -1043.938994882104
agent-5: -3660.0492809834554
Extrinsic Rewards:
-1208
-2421
-2618
-973
-3456
Sum Reward: -10676
Avg Reward: -2135.2
Min Reward: -3456
Max Reward: -973
Gini Coefficient: -0.2388909704008992
20:20 Ratio: 0.28153935185185186
Max-min Ratio: 0.28153935185185186
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-17-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -43971.28475640838
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1538
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 6.739
    dispatch_time_ms: 40.614
    learner:
      cur_lr: 0.0008478459785692394
      grad_gnorm: 40.0
      policy_entropy: 33.64289093017578
      policy_loss: 763.43115234375
      var_gnorm: 181.52244567871094
      vf_explained_var: 0.0
      vf_loss: 32331.1328125
    num_steps_sampled: 7695000
    num_steps_trained: 7695000
    wait_time_ms: 36.913
  iterations_since_restore: 1539
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13372.02179646492
  time_this_iter_s: 8.728480339050293
  time_total_s: 13372.02179646492
  timestamp: 1594869425
  timesteps_since_restore: 7695000
  timesteps_this_iter: 5000
  timesteps_total: 7695000
  training_iteration: 1539
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13372 s, 1539 iter, 7695000 ts, -4.4e+04 rew

agent-1: -4053.885498321876
agent-2: -3091.578738843559
agent-3: -2430.257333124059
agent-4: -1451.1486643674843
agent-5: -4141.086055087304
Extrinsic Rewards:
-3865
-2946
-2303
-1369
-3955
Sum Reward: -14438
Avg Reward: -2887.6
Min Reward: -3955
Max Reward: -1369
Gini Coefficient: -0.18656323590525004
20:20 Ratio: 0.3461441213653603
Max-min Ratio: 0.3461441213653603
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-17-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -43642.07660460486
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1539
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.301
    dispatch_time_ms: 27.825
    learner:
      cur_lr: 0.0008475129725411534
      grad_gnorm: 40.0
      policy_entropy: 34.71893310546875
      policy_loss: 976.7322998046875
      var_gnorm: 181.1060028076172
      vf_explained_var: 0.0
      vf_loss: 18725.42578125
    num_steps_sampled: 7700000
    num_steps_trained: 7700000
    wait_time_ms: 57.212
  iterations_since_restore: 1540
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13380.40525507927
  time_this_iter_s: 8.383458614349365
  time_total_s: 13380.40525507927
  timestamp: 1594869434
  timesteps_since_restore: 7700000
  timesteps_this_iter: 5000
  timesteps_total: 7700000
  training_iteration: 1540
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13380 s, 1540 iter, 7700000 ts, -4.36e+04 rew

agent-1: -3333.5846587813685
agent-2: -3934.3106160166394
agent-3: -3049.204197369335
agent-4: -2361.6639183978455
agent-5: -3270.717247823569
Extrinsic Rewards:
-3178
-3767
-2904
-2244
-3122
Sum Reward: -15215
Avg Reward: -3043.0
Min Reward: -3767
Max Reward: -2244
Gini Coefficient: -0.0872822872165626
20:20 Ratio: 0.5956994956198567
Max-min Ratio: 0.5956994956198567
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-17-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -43309.68193358339
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1540
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.688
    dispatch_time_ms: 38.319
    learner:
      cur_lr: 0.0008471800247207284
      grad_gnorm: 40.0
      policy_entropy: 32.74772644042969
      policy_loss: 1177.2255859375
      var_gnorm: 180.6698455810547
      vf_explained_var: 0.0
      vf_loss: 43908.0546875
    num_steps_sampled: 7705000
    num_steps_trained: 7705000
    wait_time_ms: 246.528
  iterations_since_restore: 1541
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13390.965225219727
  time_this_iter_s: 10.559970140457153
  time_total_s: 13390.965225219727
  timestamp: 1594869444
  timesteps_since_restore: 7705000
  timesteps_this_iter: 5000
  timesteps_total: 7705000
  training_iteration: 1541
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13390 s, 1541 iter, 7705000 ts, -4.33e+04 rew

agent-1: -3782.283561232581
agent-2: -4263.601586133113
agent-3: -2419.86195058586
agent-4: -4166.583900254608
agent-5: -4315.064464728168
Extrinsic Rewards:
-3649
-4093
-2306
-4008
-4147
Sum Reward: -18203
Avg Reward: -3640.6
Min Reward: -4147
Max Reward: -2306
Gini Coefficient: -0.09066637367466901
20:20 Ratio: 0.5560646250301423
Max-min Ratio: 0.5560646250301423
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-17-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -43131.61232917136
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1541
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.649
    dispatch_time_ms: 50.547
    learner:
      cur_lr: 0.0008468470186926425
      grad_gnorm: 40.000003814697266
      policy_entropy: 40.79093933105469
      policy_loss: 519.260498046875
      var_gnorm: 180.3270263671875
      vf_explained_var: 0.0
      vf_loss: 30130.58203125
    num_steps_sampled: 7710000
    num_steps_trained: 7710000
    wait_time_ms: 57.923
  iterations_since_restore: 1542
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13399.21011352539
  time_this_iter_s: 8.244888305664062
  time_total_s: 13399.21011352539
  timestamp: 1594869453
  timesteps_since_restore: 7710000
  timesteps_this_iter: 5000
  timesteps_total: 7710000
  training_iteration: 1542
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13399 s, 1542 iter, 7710000 ts, -4.31e+04 rew

agent-1: -4268.895741553254
agent-2: -2294.716714125619
agent-3: -4064.4898851498815
agent-4: -4892.821718397018
agent-5: -3182.41793098566
Extrinsic Rewards:
-4095
-2204
-3915
-4698
-3055
Sum Reward: -17967
Avg Reward: -3593.4
Min Reward: -4698
Max Reward: -2204
Gini Coefficient: -0.1342015918072021
20:20 Ratio: 0.4691358024691358
Max-min Ratio: 0.4691358024691358
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-17-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -42943.83840333971
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1542
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.638
    dispatch_time_ms: 38.95
    learner:
      cur_lr: 0.0008465140126645565
      grad_gnorm: 40.0
      policy_entropy: 44.35968017578125
      policy_loss: 285.0759582519531
      var_gnorm: 180.04754638671875
      vf_explained_var: 0.0
      vf_loss: 28345.427734375
    num_steps_sampled: 7715000
    num_steps_trained: 7715000
    wait_time_ms: 36.391
  iterations_since_restore: 1543
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13407.536138772964
  time_this_iter_s: 8.326025247573853
  time_total_s: 13407.536138772964
  timestamp: 1594869461
  timesteps_since_restore: 7715000
  timesteps_this_iter: 5000
  timesteps_total: 7715000
  training_iteration: 1543
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13407 s, 1543 iter, 7715000 ts, -4.29e+04 rew

agent-1: -3989.49257720205
agent-2: -6938.045990366365
agent-3: -6504.574925341484
agent-4: -5549.868890652541
agent-5: -2488.307037900171
Extrinsic Rewards:
-3863
-6761
-6334
-5381
-2401
Sum Reward: -24740
Avg Reward: -4948.0
Min Reward: -6761
Max Reward: -2401
Gini Coefficient: -0.18093775262732417
20:20 Ratio: 0.3551249815116107
Max-min Ratio: 0.3551249815116107
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-17-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -42816.97974647037
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1543
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.123
    dispatch_time_ms: 25.427
    learner:
      cur_lr: 0.0008461810066364706
      grad_gnorm: 40.0
      policy_entropy: 44.80404281616211
      policy_loss: 961.9950561523438
      var_gnorm: 179.81076049804688
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 62481.69140625
    num_steps_sampled: 7720000
    num_steps_trained: 7720000
    wait_time_ms: 54.497
  iterations_since_restore: 1544
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13416.152281045914
  time_this_iter_s: 8.616142272949219
  time_total_s: 13416.152281045914
  timestamp: 1594869470
  timesteps_since_restore: 7720000
  timesteps_this_iter: 5000
  timesteps_total: 7720000
  training_iteration: 1544
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13416 s, 1544 iter, 7720000 ts, -4.28e+04 rew

agent-1: -11026.315067428903
agent-2: -2722.5456244507504
agent-3: -5927.277157673649
agent-4: -4397.030439535153
agent-5: -10141.886243999386
Extrinsic Rewards:
-10817
-2659
-5783
-4299
-9939
Sum Reward: -33497
Avg Reward: -6699.4
Min Reward: -10817
Max Reward: -2659
Gini Coefficient: -0.26218467325432127
20:20 Ratio: 0.24581676989923268
Max-min Ratio: 0.24581676989923268
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-17-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -42767.29268870111
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1544
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.171
    dispatch_time_ms: 30.493
    learner:
      cur_lr: 0.0008458480006083846
      grad_gnorm: 40.0
      policy_entropy: 34.23366165161133
      policy_loss: -324.409423828125
      var_gnorm: 179.59429931640625
      vf_explained_var: 0.0
      vf_loss: 61717.22265625
    num_steps_sampled: 7725000
    num_steps_trained: 7725000
    wait_time_ms: 48.603
  iterations_since_restore: 1545
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13424.656015872955
  time_this_iter_s: 8.503734827041626
  time_total_s: 13424.656015872955
  timestamp: 1594869478
  timesteps_since_restore: 7725000
  timesteps_this_iter: 5000
  timesteps_total: 7725000
  training_iteration: 1545
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13424 s, 1545 iter, 7725000 ts, -4.28e+04 rew

agent-1: -7365.478985071974
agent-2: -5496.420259837375
agent-3: -7359.245966122798
agent-4: -6279.774045274772
agent-5: -9910.873052760413
Extrinsic Rewards:
-7207
-5382
-7202
-6151
-9718
Sum Reward: -35660
Avg Reward: -7132.0
Min Reward: -9718
Max Reward: -5382
Gini Coefficient: -0.10911946158160404
20:20 Ratio: 0.5538176579543116
Max-min Ratio: 0.5538176579543116
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-18-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -42782.70368382477
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1545
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.476
    dispatch_time_ms: 58.483
    learner:
      cur_lr: 0.0008455149945802987
      grad_gnorm: 40.0
      policy_entropy: 36.93235778808594
      policy_loss: 607.2578125
      var_gnorm: 179.4196319580078
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 38264.7890625
    num_steps_sampled: 7730000
    num_steps_trained: 7730000
    wait_time_ms: 47.171
  iterations_since_restore: 1546
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13433.705396175385
  time_this_iter_s: 9.0493803024292
  time_total_s: 13433.705396175385
  timestamp: 1594869487
  timesteps_since_restore: 7730000
  timesteps_this_iter: 5000
  timesteps_total: 7730000
  training_iteration: 1546
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13433 s, 1546 iter, 7730000 ts, -4.28e+04 rew

agent-1: -6317.609654459923
agent-2: -7932.847867758006
agent-3: -3537.242732454187
agent-4: -4406.465503006675
agent-5: -6578.521798706607
Extrinsic Rewards:
-6155
-7740
-3438
-4289
-6412
Sum Reward: -28034
Avg Reward: -5606.8
Min Reward: -7740
Max Reward: -3438
Gini Coefficient: -0.1530570022116002
20:20 Ratio: 0.4441860465116279
Max-min Ratio: 0.4441860465116279
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-18-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -42760.19692466626
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1546
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 4.489
    dispatch_time_ms: 40.163
    learner:
      cur_lr: 0.0008451819885522127
      grad_gnorm: 40.0
      policy_entropy: 41.20737075805664
      policy_loss: -61.33142852783203
      var_gnorm: 179.1680908203125
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 167321.421875
    num_steps_sampled: 7735000
    num_steps_trained: 7735000
    wait_time_ms: 34.587
  iterations_since_restore: 1547
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13442.528967618942
  time_this_iter_s: 8.82357144355774
  time_total_s: 13442.528967618942
  timestamp: 1594869496
  timesteps_since_restore: 7735000
  timesteps_this_iter: 5000
  timesteps_total: 7735000
  training_iteration: 1547
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13442 s, 1547 iter, 7735000 ts, -4.28e+04 rew

agent-1: -7230.521744737883
agent-2: -9517.600118641345
agent-3: -5521.961319543654
agent-4: -11129.81679445518
agent-5: -8850.878513575917
Extrinsic Rewards:
-7102
-9359
-5404
-10937
-8704
Sum Reward: -41506
Avg Reward: -8301.2
Min Reward: -10937
Max Reward: -5404
Gini Coefficient: -0.12839589456945985
20:20 Ratio: 0.49410258754685926
Max-min Ratio: 0.49410258754685926
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-18-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -42800.06567697587
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1547
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.94
    dispatch_time_ms: 8.052
    learner:
      cur_lr: 0.0008448489825241268
      grad_gnorm: 40.0
      policy_entropy: 42.97107696533203
      policy_loss: -1000.8262939453125
      var_gnorm: 179.13055419921875
      vf_explained_var: 0.0
      vf_loss: 78108.1796875
    num_steps_sampled: 7740000
    num_steps_trained: 7740000
    wait_time_ms: 70.283
  iterations_since_restore: 1548
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13450.7569937706
  time_this_iter_s: 8.228026151657104
  time_total_s: 13450.7569937706
  timestamp: 1594869504
  timesteps_since_restore: 7740000
  timesteps_this_iter: 5000
  timesteps_total: 7740000
  training_iteration: 1548
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13450 s, 1548 iter, 7740000 ts, -4.28e+04 rew

agent-1: -4512.312705283619
agent-2: -6871.406648904172
agent-3: -8837.186841145136
agent-4: -7517.503408358559
agent-5: -5073.403435192838
Extrinsic Rewards:
-4393
-6722
-8652
-7344
-4951
Sum Reward: -32062
Avg Reward: -6412.4
Min Reward: -8652
Max Reward: -4393
Gini Coefficient: -0.13612376021458425
20:20 Ratio: 0.5077438742487286
Max-min Ratio: 0.5077438742487286
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-18-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -42733.12591155204
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1548
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.992
    dispatch_time_ms: 8.301
    learner:
      cur_lr: 0.0008445159764960408
      grad_gnorm: 39.999996185302734
      policy_entropy: 43.962398529052734
      policy_loss: 693.8255004882812
      var_gnorm: 179.15115356445312
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 40554.11328125
    num_steps_sampled: 7745000
    num_steps_trained: 7745000
    wait_time_ms: 72.219
  iterations_since_restore: 1549
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13458.833853960037
  time_this_iter_s: 8.076860189437866
  time_total_s: 13458.833853960037
  timestamp: 1594869512
  timesteps_since_restore: 7745000
  timesteps_this_iter: 5000
  timesteps_total: 7745000
  training_iteration: 1549
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13458 s, 1549 iter, 7745000 ts, -4.27e+04 rew

agent-1: -7149.191000116455
agent-2: -7483.692878574015
agent-3: -7122.076488344057
agent-4: -6805.846659344372
agent-5: -10248.036723267676
Extrinsic Rewards:
-7017
-7332
-6988
-6667
-10060
Sum Reward: -38064
Avg Reward: -7612.8
Min Reward: -10060
Max Reward: -6667
Gini Coefficient: -0.07492643968053804
20:20 Ratio: 0.6627236580516899
Max-min Ratio: 0.6627236580516899
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-18-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -42848.439010867514
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1549
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.528
    dispatch_time_ms: 6.533
    learner:
      cur_lr: 0.0008441830286756158
      grad_gnorm: 40.0
      policy_entropy: 34.869102478027344
      policy_loss: 292.0594787597656
      var_gnorm: 178.98330688476562
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 44119.80078125
    num_steps_sampled: 7750000
    num_steps_trained: 7750000
    wait_time_ms: 72.036
  iterations_since_restore: 1550
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13466.88982796669
  time_this_iter_s: 8.055974006652832
  time_total_s: 13466.88982796669
  timestamp: 1594869521
  timesteps_since_restore: 7750000
  timesteps_this_iter: 5000
  timesteps_total: 7750000
  training_iteration: 1550
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13466 s, 1550 iter, 7750000 ts, -4.28e+04 rew

agent-1: -13365.387651185076
agent-2: -10697.91643007191
agent-3: -4160.282187979607
agent-4: -8668.591566632256
agent-5: -4288.22078480799
Extrinsic Rewards:
-13151
-10513
-4083
-8508
-4212
Sum Reward: -40467
Avg Reward: -8093.4
Min Reward: -13151
Max Reward: -4083
Gini Coefficient: -0.24154990486075073
20:20 Ratio: 0.31047068663979926
Max-min Ratio: 0.31047068663979926
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-18-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -42941.898167640764
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1550
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.664
    dispatch_time_ms: 8.511
    learner:
      cur_lr: 0.0008438500226475298
      grad_gnorm: 40.0
      policy_entropy: 28.803312301635742
      policy_loss: 579.2261352539062
      var_gnorm: 178.56553649902344
      vf_explained_var: 0.0
      vf_loss: 67070.0546875
    num_steps_sampled: 7755000
    num_steps_trained: 7755000
    wait_time_ms: 68.904
  iterations_since_restore: 1551
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13474.845337867737
  time_this_iter_s: 7.955509901046753
  time_total_s: 13474.845337867737
  timestamp: 1594869529
  timesteps_since_restore: 7755000
  timesteps_this_iter: 5000
  timesteps_total: 7755000
  training_iteration: 1551
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13474 s, 1551 iter, 7755000 ts, -4.29e+04 rew

agent-1: -2793.1622236622775
agent-2: -4497.165938659432
agent-3: -2272.311901090548
agent-4: -1417.9446961981187
agent-5: -3008.644655217173
Extrinsic Rewards:
-2645
-4297
-2148
-1349
-2856
Sum Reward: -13295
Avg Reward: -2659.0
Min Reward: -4297
Max Reward: -1349
Gini Coefficient: -0.19869123730725838
20:20 Ratio: 0.3139399581103095
Max-min Ratio: 0.3139399581103095
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-18-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -42581.05039215017
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1551
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.492
    dispatch_time_ms: 9.794
    learner:
      cur_lr: 0.0008435170166194439
      grad_gnorm: 40.0
      policy_entropy: 29.65224266052246
      policy_loss: 841.843505859375
      var_gnorm: 178.12037658691406
      vf_explained_var: 0.0
      vf_loss: 43348.0859375
    num_steps_sampled: 7760000
    num_steps_trained: 7760000
    wait_time_ms: 66.602
  iterations_since_restore: 1552
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13482.701208114624
  time_this_iter_s: 7.855870246887207
  time_total_s: 13482.701208114624
  timestamp: 1594869536
  timesteps_since_restore: 7760000
  timesteps_this_iter: 5000
  timesteps_total: 7760000
  training_iteration: 1552
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13482 s, 1552 iter, 7760000 ts, -4.26e+04 rew

agent-1: -5677.681499699981
agent-2: -2327.7613357187943
agent-3: -4461.556486613118
agent-4: -2354.3160593078173
agent-5: -784.3889481068301
Extrinsic Rewards:
-5450
-2204
-4269
-2241
-746
Sum Reward: -14910
Avg Reward: -2982.0
Min Reward: -5450
Max Reward: -746
Gini Coefficient: -0.30779342723004693
20:20 Ratio: 0.13688073394495412
Max-min Ratio: 0.13688073394495412
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-19-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -42220.20079216185
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1552
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.706
    dispatch_time_ms: 7.901
    learner:
      cur_lr: 0.000843184010591358
      grad_gnorm: 39.99999237060547
      policy_entropy: 36.84156036376953
      policy_loss: 1237.558349609375
      var_gnorm: 177.7025909423828
      vf_explained_var: 0.0
      vf_loss: 37371.19140625
    num_steps_sampled: 7765000
    num_steps_trained: 7765000
    wait_time_ms: 69.372
  iterations_since_restore: 1553
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13490.666629076004
  time_this_iter_s: 7.965420961380005
  time_total_s: 13490.666629076004
  timestamp: 1594869544
  timesteps_since_restore: 7765000
  timesteps_this_iter: 5000
  timesteps_total: 7765000
  training_iteration: 1553
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13490 s, 1553 iter, 7765000 ts, -4.22e+04 rew

agent-1: -2303.077319035741
agent-2: -813.7512773356963
agent-3: -3580.0701434290186
agent-4: -3634.0466994989347
agent-5: -4197.711704873764
Extrinsic Rewards:
-2176
-762
-3409
-3462
-4003
Sum Reward: -13812
Avg Reward: -2762.4
Min Reward: -4003
Max Reward: -762
Gini Coefficient: -0.22496379959455545
20:20 Ratio: 0.19035723207594304
Max-min Ratio: 0.19035723207594304
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-19-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -41660.986457186154
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1553
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.751
    dispatch_time_ms: 6.339
    learner:
      cur_lr: 0.000842851004563272
      grad_gnorm: 40.000003814697266
      policy_entropy: 33.62403106689453
      policy_loss: 540.4735107421875
      var_gnorm: 177.2714080810547
      vf_explained_var: 0.0
      vf_loss: 31090.818359375
    num_steps_sampled: 7770000
    num_steps_trained: 7770000
    wait_time_ms: 69.217
  iterations_since_restore: 1554
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13498.604132175446
  time_this_iter_s: 7.937503099441528
  time_total_s: 13498.604132175446
  timestamp: 1594869552
  timesteps_since_restore: 7770000
  timesteps_this_iter: 5000
  timesteps_total: 7770000
  training_iteration: 1554
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13498 s, 1554 iter, 7770000 ts, -4.17e+04 rew

agent-1: -5368.707593445934
agent-2: -2894.3981027772456
agent-3: -3329.4996236442876
agent-4: -2575.7505175112237
agent-5: -4285.930949592912
Extrinsic Rewards:
-5166
-2760
-3191
-2445
-4115
Sum Reward: -17677
Avg Reward: -3535.4
Min Reward: -5166
Max Reward: -2445
Gini Coefficient: -0.1538043785710245
20:20 Ratio: 0.4732868757259001
Max-min Ratio: 0.4732868757259001
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-19-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -41238.64877333897
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1554
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.913
    dispatch_time_ms: 7.994
    learner:
      cur_lr: 0.000842517998535186
      grad_gnorm: 40.0
      policy_entropy: 33.99235153198242
      policy_loss: 547.0037841796875
      var_gnorm: 176.86256408691406
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 85040.21875
    num_steps_sampled: 7775000
    num_steps_trained: 7775000
    wait_time_ms: 68.689
  iterations_since_restore: 1555
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13506.545645236969
  time_this_iter_s: 7.9415130615234375
  time_total_s: 13506.545645236969
  timestamp: 1594869560
  timesteps_since_restore: 7775000
  timesteps_this_iter: 5000
  timesteps_total: 7775000
  training_iteration: 1555
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13506 s, 1555 iter, 7775000 ts, -4.12e+04 rew

W0715 23:19:24.992144 22529 client_connection.cc:255] [worker]ProcessMessage with type 8 took 318 ms.
W0715 23:19:25.069602 22529 node_manager.cc:250] Last heartbeat was sent 509 ms ago 
agent-1: -8185.329345379848
agent-2: -8146.860665511916
agent-3: -1240.5962723421906
agent-4: -4814.075316607918
agent-5: -7469.855721611834
Extrinsic Rewards:
-8001
-7950
-1200
-4689
-7297
Sum Reward: -29137
Avg Reward: -5827.4
Min Reward: -8001
Max Reward: -1200
Gini Coefficient: -0.23149946803033944
20:20 Ratio: 0.14998125234345708
Max-min Ratio: 0.14998125234345708
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-19-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -40978.219084449374
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1555
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.558
    dispatch_time_ms: 9.455
    learner:
      cur_lr: 0.0008421849925071001
      grad_gnorm: 39.99999237060547
      policy_entropy: 35.95004653930664
      policy_loss: -39.65637969970703
      var_gnorm: 176.78578186035156
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 64746.046875
    num_steps_sampled: 7780000
    num_steps_trained: 7780000
    wait_time_ms: 67.341
  iterations_since_restore: 1556
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13514.71637058258
  time_this_iter_s: 8.170725345611572
  time_total_s: 13514.71637058258
  timestamp: 1594869569
  timesteps_since_restore: 7780000
  timesteps_this_iter: 5000
  timesteps_total: 7780000
  training_iteration: 1556
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13514 s, 1556 iter, 7780000 ts, -4.1e+04 rew

agent-1: -4638.587298040991
agent-2: -7732.470422789112
agent-3: -2546.2518001508492
agent-4: -6921.100152922425
agent-5: -5667.643063305468
Extrinsic Rewards:
-4510
-7541
-2460
-6742
-5507
Sum Reward: -26760
Avg Reward: -5352.0
Min Reward: -7541
Max Reward: -2460
Gini Coefficient: -0.18526158445440957
20:20 Ratio: 0.32621668213764754
Max-min Ratio: 0.32621668213764754
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-19-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -40644.49147735653
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1556
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.558
    dispatch_time_ms: 7.902
    learner:
      cur_lr: 0.0008418519864790142
      grad_gnorm: 40.000003814697266
      policy_entropy: 29.817867279052734
      policy_loss: 518.8590698242188
      var_gnorm: 176.44503784179688
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 26264.685546875
    num_steps_sampled: 7785000
    num_steps_trained: 7785000
    wait_time_ms: 70.362
  iterations_since_restore: 1557
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13522.669159889221
  time_this_iter_s: 7.952789306640625
  time_total_s: 13522.669159889221
  timestamp: 1594869577
  timesteps_since_restore: 7785000
  timesteps_this_iter: 5000
  timesteps_total: 7785000
  training_iteration: 1557
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13522 s, 1557 iter, 7785000 ts, -4.06e+04 rew

agent-1: -5574.664943060346
agent-2: -2505.4982797397765
agent-3: -2065.7068211277533
agent-4: -5614.9322060589975
agent-5: -8770.826595079132
Extrinsic Rewards:
-5395
-2422
-1999
-5442
-8550
Sum Reward: -23808
Avg Reward: -4761.6
Min Reward: -8550
Max Reward: -1999
Gini Coefficient: -0.270866935483871
20:20 Ratio: 0.2338011695906433
Max-min Ratio: 0.2338011695906433
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-19-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -40433.06935597243
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1557
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.762
    dispatch_time_ms: 8.618
    learner:
      cur_lr: 0.0008415189804509282
      grad_gnorm: 40.0
      policy_entropy: 36.73805618286133
      policy_loss: 161.92578125
      var_gnorm: 176.115966796875
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 33439.421875
    num_steps_sampled: 7790000
    num_steps_trained: 7790000
    wait_time_ms: 71.03
  iterations_since_restore: 1558
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13530.647725343704
  time_this_iter_s: 7.978565454483032
  time_total_s: 13530.647725343704
  timestamp: 1594869585
  timesteps_since_restore: 7790000
  timesteps_this_iter: 5000
  timesteps_total: 7790000
  training_iteration: 1558
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13530 s, 1558 iter, 7790000 ts, -4.04e+04 rew

agent-1: -5221.278312854758
agent-2: -4909.738202169904
agent-3: -4249.662996980645
agent-4: -5619.136946469389
agent-5: -1922.8910969654403
Extrinsic Rewards:
-5049
-4770
-4103
-5426
-1863
Sum Reward: -21211
Avg Reward: -4242.2
Min Reward: -5426
Max Reward: -1863
Gini Coefficient: -0.15222290321059828
20:20 Ratio: 0.3433468485071876
Max-min Ratio: 0.3433468485071876
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-19-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -40098.88394544562
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1558
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.651
    dispatch_time_ms: 7.929
    learner:
      cur_lr: 0.0008411859744228423
      grad_gnorm: 40.0
      policy_entropy: 32.835899353027344
      policy_loss: 887.9290161132812
      var_gnorm: 175.87625122070312
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 41223.3359375
    num_steps_sampled: 7795000
    num_steps_trained: 7795000
    wait_time_ms: 68.762
  iterations_since_restore: 1559
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13538.599869012833
  time_this_iter_s: 7.952143669128418
  time_total_s: 13538.599869012833
  timestamp: 1594869593
  timesteps_since_restore: 7795000
  timesteps_this_iter: 5000
  timesteps_total: 7795000
  training_iteration: 1559
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13538 s, 1559 iter, 7795000 ts, -4.01e+04 rew

agent-1: -9005.300194703203
agent-2: -6128.499421306849
agent-3: -2684.8508153717576
agent-4: -6871.4343191043545
agent-5: -336.1742544770792
Extrinsic Rewards:
-8775
-5953
-2603
-6688
-327
Sum Reward: -24346
Avg Reward: -4869.2
Min Reward: -8775
Max Reward: -327
Gini Coefficient: -0.34471371067115747
20:20 Ratio: 0.037264957264957266
Max-min Ratio: 0.037264957264957266
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-20-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -39739.955386303176
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1559
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.818
    dispatch_time_ms: 8.036
    learner:
      cur_lr: 0.0008408530266024172
      grad_gnorm: 40.0
      policy_entropy: 38.92800521850586
      policy_loss: 1176.81103515625
      var_gnorm: 175.56439208984375
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 38642.46484375
    num_steps_sampled: 7800000
    num_steps_trained: 7800000
    wait_time_ms: 68.71
  iterations_since_restore: 1560
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13546.59822678566
  time_this_iter_s: 7.998357772827148
  time_total_s: 13546.59822678566
  timestamp: 1594869601
  timesteps_since_restore: 7800000
  timesteps_this_iter: 5000
  timesteps_total: 7800000
  training_iteration: 1560
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13546 s, 1560 iter, 7800000 ts, -3.97e+04 rew

agent-1: -7029.949149432083
agent-2: -5341.857003392847
agent-3: -8823.163013646776
agent-4: -763.8941891953948
agent-5: -7943.795992345819
Extrinsic Rewards:
-6858
-5209
-8621
-741
-7758
Sum Reward: -29187
Avg Reward: -5837.4
Min Reward: -8621
Max Reward: -741
Gini Coefficient: -0.25091993010586905
20:20 Ratio: 0.08595290569539496
Max-min Ratio: 0.08595290569539496
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-20-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -39491.58880898015
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1560
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.998
    dispatch_time_ms: 8.111
    learner:
      cur_lr: 0.0008405200205743313
      grad_gnorm: 40.000003814697266
      policy_entropy: 44.040103912353516
      policy_loss: -14.842357635498047
      var_gnorm: 175.37222290039062
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 22185.767578125
    num_steps_sampled: 7805000
    num_steps_trained: 7805000
    wait_time_ms: 69.088
  iterations_since_restore: 1561
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13554.644771814346
  time_this_iter_s: 8.046545028686523
  time_total_s: 13554.644771814346
  timestamp: 1594869609
  timesteps_since_restore: 7805000
  timesteps_this_iter: 5000
  timesteps_total: 7805000
  training_iteration: 1561
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13554 s, 1561 iter, 7805000 ts, -3.95e+04 rew

agent-1: -4544.808894450716
agent-2: -5166.54478693079
agent-3: -4913.933697065996
agent-4: -7092.156052477445
agent-5: -6776.62530438003
Extrinsic Rewards:
-4417
-5020
-4777
-6917
-6611
Sum Reward: -27742
Avg Reward: -5548.4
Min Reward: -6917
Max Reward: -4417
Gini Coefficient: -0.09853651503136039
20:20 Ratio: 0.6385716351019228
Max-min Ratio: 0.6385716351019228
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-20-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -39152.19676579004
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1561
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.67
    dispatch_time_ms: 9.053
    learner:
      cur_lr: 0.0008401870145462453
      grad_gnorm: 40.0
      policy_entropy: 40.75151062011719
      policy_loss: 1174.10693359375
      var_gnorm: 175.03016662597656
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 47769.97265625
    num_steps_sampled: 7810000
    num_steps_trained: 7810000
    wait_time_ms: 67.021
  iterations_since_restore: 1562
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13562.630831003189
  time_this_iter_s: 7.986059188842773
  time_total_s: 13562.630831003189
  timestamp: 1594869617
  timesteps_since_restore: 7810000
  timesteps_this_iter: 5000
  timesteps_total: 7810000
  training_iteration: 1562
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13562 s, 1562 iter, 7810000 ts, -3.92e+04 rew

agent-1: -5485.387414965181
agent-2: -1829.0877305869842
agent-3: -6913.348157809725
agent-4: -4399.326659567
agent-5: -4193.805168001519
Extrinsic Rewards:
-5311
-1764
-6707
-4252
-4051
Sum Reward: -22085
Avg Reward: -4417.0
Min Reward: -6707
Max Reward: -1764
Gini Coefficient: -0.20187457550373555
20:20 Ratio: 0.26300879677948413
Max-min Ratio: 0.26300879677948413
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-20-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -38726.932593949015
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1562
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.918
    dispatch_time_ms: 7.529
    learner:
      cur_lr: 0.0008398540085181594
      grad_gnorm: 40.000003814697266
      policy_entropy: 44.160308837890625
      policy_loss: 600.6956787109375
      var_gnorm: 174.6261749267578
      vf_explained_var: 0.0
      vf_loss: 35460.64453125
    num_steps_sampled: 7815000
    num_steps_trained: 7815000
    wait_time_ms: 66.824
  iterations_since_restore: 1563
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13570.64990067482
  time_this_iter_s: 8.01906967163086
  time_total_s: 13570.64990067482
  timestamp: 1594869625
  timesteps_since_restore: 7815000
  timesteps_this_iter: 5000
  timesteps_total: 7815000
  training_iteration: 1563
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13570 s, 1563 iter, 7815000 ts, -3.87e+04 rew

agent-1: -6008.456735973331
agent-2: -1766.695604694843
agent-3: -6684.698307051671
agent-4: -9354.796380383215
agent-5: -5296.515049694108
Extrinsic Rewards:
-5840
-1697
-6544
-9144
-5178
Sum Reward: -28403
Avg Reward: -5680.6
Min Reward: -9144
Max Reward: -1697
Gini Coefficient: -0.22898989543358095
20:20 Ratio: 0.185586176727909
Max-min Ratio: 0.185586176727909
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-20-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -38237.52104713705
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1563
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.403
    dispatch_time_ms: 9.388
    learner:
      cur_lr: 0.0008395210024900734
      grad_gnorm: 40.0
      policy_entropy: 57.47534942626953
      policy_loss: -981.307861328125
      var_gnorm: 174.46522521972656
      vf_explained_var: 0.0
      vf_loss: 194976.875
    num_steps_sampled: 7820000
    num_steps_trained: 7820000
    wait_time_ms: 70.5
  iterations_since_restore: 1564
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13578.75530719757
  time_this_iter_s: 8.105406522750854
  time_total_s: 13578.75530719757
  timestamp: 1594869633
  timesteps_since_restore: 7820000
  timesteps_this_iter: 5000
  timesteps_total: 7820000
  training_iteration: 1564
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13578 s, 1564 iter, 7820000 ts, -3.82e+04 rew

agent-1: -7292.069417331146
agent-2: -6290.889258177871
agent-3: -7758.730861052215
agent-4: -4426.1189366727485
agent-5: -5824.235809248899
Extrinsic Rewards:
-7114
-6151
-7598
-4315
-5679
Sum Reward: -30857
Avg Reward: -6171.4
Min Reward: -7598
Max Reward: -4315
Gini Coefficient: -0.10371714683864278
20:20 Ratio: 0.5679126085812056
Max-min Ratio: 0.5679126085812056
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-20-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -37840.92439355222
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1564
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.379
    dispatch_time_ms: 22.76
    learner:
      cur_lr: 0.0008391879964619875
      grad_gnorm: 39.999996185302734
      policy_entropy: 58.54324722290039
      policy_loss: -883.9439086914062
      var_gnorm: 174.6992950439453
      vf_explained_var: 0.0
      vf_loss: 57894.07421875
    num_steps_sampled: 7825000
    num_steps_trained: 7825000
    wait_time_ms: 74.478
  iterations_since_restore: 1565
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13591.224443674088
  time_this_iter_s: 12.469136476516724
  time_total_s: 13591.224443674088
  timestamp: 1594869645
  timesteps_since_restore: 7825000
  timesteps_this_iter: 5000
  timesteps_total: 7825000
  training_iteration: 1565
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13591 s, 1565 iter, 7825000 ts, -3.78e+04 rew

agent-1: -13473.149943187762
agent-2: -15417.221983755613
agent-3: -11147.443566042117
agent-4: -19590.15214189004
agent-5: -10052.723833721911
Extrinsic Rewards:
-13317
-15246
-11028
-19403
-9936
Sum Reward: -68930
Avg Reward: -13786.0
Min Reward: -19403
Max Reward: -9936
Gini Coefficient: -0.13435079065718844
20:20 Ratio: 0.5120857599340308
Max-min Ratio: 0.5120857599340308
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-20-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -38009.44159340991
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1565
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.156
    dispatch_time_ms: 32.48
    learner:
      cur_lr: 0.0008388549904339015
      grad_gnorm: 39.999996185302734
      policy_entropy: 54.45298385620117
      policy_loss: -1379.15234375
      var_gnorm: 174.98806762695312
      vf_explained_var: 0.0
      vf_loss: 193078.28125
    num_steps_sampled: 7830000
    num_steps_trained: 7830000
    wait_time_ms: 54.911
  iterations_since_restore: 1566
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13600.128576993942
  time_this_iter_s: 8.904133319854736
  time_total_s: 13600.128576993942
  timestamp: 1594869654
  timesteps_since_restore: 7830000
  timesteps_this_iter: 5000
  timesteps_total: 7830000
  training_iteration: 1566
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13600 s, 1566 iter, 7830000 ts, -3.8e+04 rew

agent-1: -19546.495173062285
agent-2: -10171.084839619056
agent-3: -24158.823194543857
agent-4: -12968.545851209563
agent-5: -16022.108772338206
Extrinsic Rewards:
-19366
-10068
-23963
-12849
-15875
Sum Reward: -82121
Avg Reward: -16424.2
Min Reward: -23963
Max Reward: -10068
Gini Coefficient: -0.16710463827766345
20:20 Ratio: 0.4201477277469432
Max-min Ratio: 0.4201477277469432
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-21-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -38095.07638818475
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1566
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.393
    dispatch_time_ms: 37.378
    learner:
      cur_lr: 0.0008385219844058156
      grad_gnorm: 40.000003814697266
      policy_entropy: 56.36172866821289
      policy_loss: -3985.274658203125
      var_gnorm: 175.3343505859375
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 431372.75
    num_steps_sampled: 7835000
    num_steps_trained: 7835000
    wait_time_ms: 49.919
  iterations_since_restore: 1567
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13609.142493009567
  time_this_iter_s: 9.013916015625
  time_total_s: 13609.142493009567
  timestamp: 1594869663
  timesteps_since_restore: 7835000
  timesteps_this_iter: 5000
  timesteps_total: 7835000
  training_iteration: 1567
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13609 s, 1567 iter, 7835000 ts, -3.81e+04 rew

agent-1: -20980.75967720297
agent-2: -11491.997204430449
agent-3: -18193.751511383667
agent-4: -21779.520803800377
agent-5: -19639.72869834701
Extrinsic Rewards:
-20815
-11396
-18046
-21603
-19477
Sum Reward: -91337
Avg Reward: -18267.4
Min Reward: -21603
Max Reward: -11396
Gini Coefficient: -0.10152731094737072
20:20 Ratio: 0.5275193260195343
Max-min Ratio: 0.5275193260195343
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-21-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -38306.59422363977
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1567
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.689
    dispatch_time_ms: 7.593
    learner:
      cur_lr: 0.0008381889783777297
      grad_gnorm: 40.0
      policy_entropy: 54.88827133178711
      policy_loss: -7094.15478515625
      var_gnorm: 175.74513244628906
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 386073.15625
    num_steps_sampled: 7840000
    num_steps_trained: 7840000
    wait_time_ms: 73.573
  iterations_since_restore: 1568
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13617.783003807068
  time_this_iter_s: 8.64051079750061
  time_total_s: 13617.783003807068
  timestamp: 1594869672
  timesteps_since_restore: 7840000
  timesteps_this_iter: 5000
  timesteps_total: 7840000
  training_iteration: 1568
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13617 s, 1568 iter, 7840000 ts, -3.83e+04 rew

agent-1: -23990.86458902646
agent-2: -27909.13993337902
agent-3: -16595.29984560787
agent-4: -26739.776049348682
agent-5: -12762.669780558987
Extrinsic Rewards:
-23818
-27731
-16473
-26558
-12676
Sum Reward: -107256
Avg Reward: -21451.2
Min Reward: -27731
Max Reward: -12676
Gini Coefficient: -0.149903035727605
20:20 Ratio: 0.4571057661101295
Max-min Ratio: 0.4571057661101295
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-21-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -38522.39408488099
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1568
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.567
    dispatch_time_ms: 6.2
    learner:
      cur_lr: 0.0008378559723496437
      grad_gnorm: 40.000003814697266
      policy_entropy: 49.264339447021484
      policy_loss: -2312.856689453125
      var_gnorm: 176.15545654296875
      vf_explained_var: 0.0
      vf_loss: 208169.359375
    num_steps_sampled: 7845000
    num_steps_trained: 7845000
    wait_time_ms: 75.291
  iterations_since_restore: 1569
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13626.20518040657
  time_this_iter_s: 8.422176599502563
  time_total_s: 13626.20518040657
  timestamp: 1594869681
  timesteps_since_restore: 7845000
  timesteps_this_iter: 5000
  timesteps_total: 7845000
  training_iteration: 1569
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13626 s, 1569 iter, 7845000 ts, -3.85e+04 rew

agent-1: -30798.471345235594
agent-2: -26867.555226030057
agent-3: -15336.534924601146
agent-4: -33249.36178704769
agent-5: -15618.413040412766
Extrinsic Rewards:
-30619
-26703
-15241
-33062
-15516
Sum Reward: -121141
Avg Reward: -24228.2
Min Reward: -33062
Max Reward: -15241
Gini Coefficient: -0.16755681396059138
20:20 Ratio: 0.460982396709213
Max-min Ratio: 0.460982396709213
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-21-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -38644.960567195856
  episode_reward_min: -139136.56132812618
  episodes_this_iter: 1
  episodes_total: 1569
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.719
    dispatch_time_ms: 7.243
    learner:
      cur_lr: 0.0008375230245292187
      grad_gnorm: 40.0
      policy_entropy: 46.02315139770508
      policy_loss: -293.0304260253906
      var_gnorm: 176.5875701904297
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 242175.546875
    num_steps_sampled: 7850000
    num_steps_trained: 7850000
    wait_time_ms: 75.238
  iterations_since_restore: 1570
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13634.655659198761
  time_this_iter_s: 8.450478792190552
  time_total_s: 13634.655659198761
  timestamp: 1594869689
  timesteps_since_restore: 7850000
  timesteps_this_iter: 5000
  timesteps_total: 7850000
  training_iteration: 1570
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13634 s, 1570 iter, 7850000 ts, -3.86e+04 rew

agent-1: -26278.399789891515
agent-2: -37383.08001212104
agent-3: -28801.969295388342
agent-4: -26253.01290248957
agent-5: -22624.073665460237
Extrinsic Rewards:
-26143
-37195
-28646
-26112
-22499
Sum Reward: -140595
Avg Reward: -28119.0
Min Reward: -37195
Max Reward: -22499
Gini Coefficient: -0.09083111063693589
20:20 Ratio: 0.6048931307971501
Max-min Ratio: 0.6048931307971501
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-21-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -39043.2702230456
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1570
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.721
    dispatch_time_ms: 6.465
    learner:
      cur_lr: 0.0008371900185011327
      grad_gnorm: 40.0
      policy_entropy: 50.19037628173828
      policy_loss: -1805.1207275390625
      var_gnorm: 176.90924072265625
      vf_explained_var: 0.0
      vf_loss: 345167.375
    num_steps_sampled: 7855000
    num_steps_trained: 7855000
    wait_time_ms: 77.847
  iterations_since_restore: 1571
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13643.06445145607
  time_this_iter_s: 8.40879225730896
  time_total_s: 13643.06445145607
  timestamp: 1594869697
  timesteps_since_restore: 7855000
  timesteps_this_iter: 5000
  timesteps_total: 7855000
  training_iteration: 1571
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13643 s, 1571 iter, 7855000 ts, -3.9e+04 rew

agent-1: -17106.821433625526
agent-2: -17266.808945472032
agent-3: -14983.674380369433
agent-4: -25566.97498904502
agent-5: -23689.34514751072
Extrinsic Rewards:
-16962
-17135
-14864
-25387
-23534
Sum Reward: -97882
Avg Reward: -19576.4
Min Reward: -25387
Max Reward: -14864
Gini Coefficient: -0.11286242618663288
20:20 Ratio: 0.5854965139638397
Max-min Ratio: 0.5854965139638397
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-21-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -38872.85186875431
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1571
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.713
    dispatch_time_ms: 7.283
    learner:
      cur_lr: 0.0008368570124730468
      grad_gnorm: 40.0
      policy_entropy: 57.64413833618164
      policy_loss: 1124.2203369140625
      var_gnorm: 177.231689453125
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 46257.671875
    num_steps_sampled: 7860000
    num_steps_trained: 7860000
    wait_time_ms: 73.384
  iterations_since_restore: 1572
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13651.422667264938
  time_this_iter_s: 8.358215808868408
  time_total_s: 13651.422667264938
  timestamp: 1594869706
  timesteps_since_restore: 7860000
  timesteps_this_iter: 5000
  timesteps_total: 7860000
  training_iteration: 1572
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13651 s, 1572 iter, 7860000 ts, -3.89e+04 rew

agent-1: -8304.402174362944
agent-2: -9466.299199608198
agent-3: -21190.385057183747
agent-4: -23922.30675337594
agent-5: -21408.032840640248
Extrinsic Rewards:
-8214
-9376
-21015
-23731
-21231
Sum Reward: -83567
Avg Reward: -16713.4
Min Reward: -23731
Max Reward: -8214
Gini Coefficient: -0.20529156245886535
20:20 Ratio: 0.34612953520711304
Max-min Ratio: 0.34612953520711304
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-21-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -38678.871419419964
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1572
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.88
    dispatch_time_ms: 9.581
    learner:
      cur_lr: 0.0008365240064449608
      grad_gnorm: 40.0
      policy_entropy: 57.491539001464844
      policy_loss: -1845.35498046875
      var_gnorm: 177.2833251953125
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 153596.53125
    num_steps_sampled: 7865000
    num_steps_trained: 7865000
    wait_time_ms: 68.187
  iterations_since_restore: 1573
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13659.54671549797
  time_this_iter_s: 8.124048233032227
  time_total_s: 13659.54671549797
  timestamp: 1594869714
  timesteps_since_restore: 7865000
  timesteps_this_iter: 5000
  timesteps_total: 7865000
  training_iteration: 1573
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13659 s, 1573 iter, 7865000 ts, -3.87e+04 rew

agent-1: -11773.372041965697
agent-2: -6577.885737514829
agent-3: -15233.985622198888
agent-4: -11844.94276254636
agent-5: -5185.469670123305
Extrinsic Rewards:
-11603
-6498
-15022
-11670
-5110
Sum Reward: -49903
Avg Reward: -9980.6
Min Reward: -15022
Max Reward: -5110
Gini Coefficient: -0.20035669198244593
20:20 Ratio: 0.3401677539608574
Max-min Ratio: 0.3401677539608574
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-22-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -38081.148852489554
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1573
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.704
    dispatch_time_ms: 6.499
    learner:
      cur_lr: 0.0008361910004168749
      grad_gnorm: 40.000003814697266
      policy_entropy: 48.93875503540039
      policy_loss: -2846.71533203125
      var_gnorm: 177.51254272460938
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 267734.8125
    num_steps_sampled: 7870000
    num_steps_trained: 7870000
    wait_time_ms: 79.735
  iterations_since_restore: 1574
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13667.911228179932
  time_this_iter_s: 8.36451268196106
  time_total_s: 13667.911228179932
  timestamp: 1594869722
  timesteps_since_restore: 7870000
  timesteps_this_iter: 5000
  timesteps_total: 7870000
  training_iteration: 1574
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13667 s, 1574 iter, 7870000 ts, -3.81e+04 rew

agent-1: -3595.642130228449
agent-2: -7231.640124140625
agent-3: -22633.810261895513
agent-4: -21043.863336840317
agent-5: -26943.62349801762
Extrinsic Rewards:
-3559
-7164
-22450
-20847
-26734
Sum Reward: -80754
Avg Reward: -16150.8
Min Reward: -26734
Max Reward: -3559
Gini Coefficient: -0.3053025237139956
20:20 Ratio: 0.13312635595122316
Max-min Ratio: 0.13312635595122316
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-22-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -37504.26903271952
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1574
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.214
    dispatch_time_ms: 8.396
    learner:
      cur_lr: 0.0008358579943887889
      grad_gnorm: 40.0
      policy_entropy: 42.6795768737793
      policy_loss: -485.78125
      var_gnorm: 177.7939453125
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 116342.5703125
    num_steps_sampled: 7875000
    num_steps_trained: 7875000
    wait_time_ms: 70.678
  iterations_since_restore: 1575
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13676.334442853928
  time_this_iter_s: 8.423214673995972
  time_total_s: 13676.334442853928
  timestamp: 1594869731
  timesteps_since_restore: 7875000
  timesteps_this_iter: 5000
  timesteps_total: 7875000
  training_iteration: 1575
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13676 s, 1575 iter, 7875000 ts, -3.75e+04 rew

agent-1: -28354.976860234
agent-2: -13113.447449390871
agent-3: -29061.155187424458
agent-4: -25897.34591774816
agent-5: -16241.651800123633
Extrinsic Rewards:
-28185
-13012
-28873
-25733
-16125
Sum Reward: -111928
Avg Reward: -22385.6
Min Reward: -28873
Max Reward: -13012
Gini Coefficient: -0.15646487027374742
20:20 Ratio: 0.45066324940255603
Max-min Ratio: 0.45066324940255603
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-22-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -37284.24837469296
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1575
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.792
    dispatch_time_ms: 6.221
    learner:
      cur_lr: 0.000835524988360703
      grad_gnorm: 40.0
      policy_entropy: 39.30604934692383
      policy_loss: -2858.900634765625
      var_gnorm: 178.2154541015625
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 418151.25
    num_steps_sampled: 7880000
    num_steps_trained: 7880000
    wait_time_ms: 72.992
  iterations_since_restore: 1576
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13684.759580135345
  time_this_iter_s: 8.425137281417847
  time_total_s: 13684.759580135345
  timestamp: 1594869739
  timesteps_since_restore: 7880000
  timesteps_this_iter: 5000
  timesteps_total: 7880000
  training_iteration: 1576
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13684 s, 1576 iter, 7880000 ts, -3.73e+04 rew

agent-1: -16210.284030443532
agent-2: -21299.61667597359
agent-3: -24880.290527086847
agent-4: -11750.417537639916
agent-5: -19209.600887352495
Extrinsic Rewards:
-16072
-21137
-24701
-11647
-19050
Sum Reward: -92607
Avg Reward: -18521.4
Min Reward: -24701
Max Reward: -11647
Gini Coefficient: -0.13464640901875669
20:20 Ratio: 0.47151937168535685
Max-min Ratio: 0.47151937168535685
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-22-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -37099.957637017484
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1576
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.884
    dispatch_time_ms: 9.472
    learner:
      cur_lr: 0.000835191982332617
      grad_gnorm: 40.000003814697266
      policy_entropy: 44.221248626708984
      policy_loss: -625.6652221679688
      var_gnorm: 178.55148315429688
      vf_explained_var: 0.0
      vf_loss: 245092.625
    num_steps_sampled: 7885000
    num_steps_trained: 7885000
    wait_time_ms: 74.562
  iterations_since_restore: 1577
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13693.162853479385
  time_this_iter_s: 8.403273344039917
  time_total_s: 13693.162853479385
  timestamp: 1594869748
  timesteps_since_restore: 7885000
  timesteps_this_iter: 5000
  timesteps_total: 7885000
  training_iteration: 1577
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13693 s, 1577 iter, 7885000 ts, -3.71e+04 rew

agent-1: -20025.931683048388
agent-2: -29106.871437251066
agent-3: -29828.361521087536
agent-4: -9318.623365495665
agent-5: -19095.614210133386
Extrinsic Rewards:
-19882
-28923
-29634
-9244
-18963
Sum Reward: -106646
Avg Reward: -21329.2
Min Reward: -29634
Max Reward: -9244
Gini Coefficient: -0.1903118729253793
20:20 Ratio: 0.31193898899912265
Max-min Ratio: 0.31193898899912265
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-22-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -37274.539765742156
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1577
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.567
    dispatch_time_ms: 8.139
    learner:
      cur_lr: 0.0008348589763045311
      grad_gnorm: 39.999996185302734
      policy_entropy: 45.85935592651367
      policy_loss: -1671.8115234375
      var_gnorm: 178.95680236816406
      vf_explained_var: 0.0
      vf_loss: 177172.625
    num_steps_sampled: 7890000
    num_steps_trained: 7890000
    wait_time_ms: 75.997
  iterations_since_restore: 1578
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13701.53199839592
  time_this_iter_s: 8.369144916534424
  time_total_s: 13701.53199839592
  timestamp: 1594869756
  timesteps_since_restore: 7890000
  timesteps_this_iter: 5000
  timesteps_total: 7890000
  training_iteration: 1578
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13701 s, 1578 iter, 7890000 ts, -3.73e+04 rew

agent-1: -29321.395170019387
agent-2: -33090.06696122571
agent-3: -3408.644986755575
agent-4: -6634.436829666127
agent-5: -28585.387286766254
Extrinsic Rewards:
-29125
-32888
-3379
-6584
-28385
Sum Reward: -100361
Avg Reward: -20072.2
Min Reward: -32888
Max Reward: -3379
Gini Coefficient: -0.32506252428732274
20:20 Ratio: 0.10274264169301874
Max-min Ratio: 0.10274264169301874
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-22-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -37191.293905362
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1578
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.521
    dispatch_time_ms: 6.867
    learner:
      cur_lr: 0.0008345260284841061
      grad_gnorm: 40.000003814697266
      policy_entropy: 52.430973052978516
      policy_loss: -3443.17822265625
      var_gnorm: 179.28665161132812
      vf_explained_var: 0.0
      vf_loss: 555557.625
    num_steps_sampled: 7895000
    num_steps_trained: 7895000
    wait_time_ms: 76.279
  iterations_since_restore: 1579
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13709.894986867905
  time_this_iter_s: 8.362988471984863
  time_total_s: 13709.894986867905
  timestamp: 1594869765
  timesteps_since_restore: 7895000
  timesteps_this_iter: 5000
  timesteps_total: 7895000
  training_iteration: 1579
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13709 s, 1579 iter, 7895000 ts, -3.72e+04 rew

agent-1: -15603.375455307872
agent-2: -13477.848342992334
agent-3: -22773.21809826637
agent-4: -5065.420985958169
agent-5: -20552.819526766445
Extrinsic Rewards:
-15448
-13348
-22573
-5009
-20374
Sum Reward: -76752
Avg Reward: -15350.4
Min Reward: -22573
Max Reward: -5009
Gini Coefficient: -0.21968938920158432
20:20 Ratio: 0.2219022726265893
Max-min Ratio: 0.2219022726265893
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-22-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -36703.6008520552
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1579
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.466
    dispatch_time_ms: 8.798
    learner:
      cur_lr: 0.0008341930224560201
      grad_gnorm: 39.999996185302734
      policy_entropy: 52.2523307800293
      policy_loss: -4808.7060546875
      var_gnorm: 179.63987731933594
      vf_explained_var: 0.0
      vf_loss: 495211.375
    num_steps_sampled: 7900000
    num_steps_trained: 7900000
    wait_time_ms: 73.392
  iterations_since_restore: 1580
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13718.295862197876
  time_this_iter_s: 8.400875329971313
  time_total_s: 13718.295862197876
  timestamp: 1594869773
  timesteps_since_restore: 7900000
  timesteps_this_iter: 5000
  timesteps_total: 7900000
  training_iteration: 1580
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13718 s, 1580 iter, 7900000 ts, -3.67e+04 rew

agent-1: -23261.33486322908
agent-2: -27874.68660305675
agent-3: -7916.94784358306
agent-4: -35254.55480031331
agent-5: -19549.60604761362
Extrinsic Rewards:
-23110
-27696
-7858
-35046
-19417
Sum Reward: -113127
Avg Reward: -22625.4
Min Reward: -35046
Max Reward: -7858
Gini Coefficient: -0.22153862473149646
20:20 Ratio: 0.22421959710095304
Max-min Ratio: 0.22421959710095304
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-23-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -36736.82490102411
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1580
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.487
    dispatch_time_ms: 8.535
    learner:
      cur_lr: 0.0008338600164279342
      grad_gnorm: 39.999996185302734
      policy_entropy: 52.867916107177734
      policy_loss: 312.49310302734375
      var_gnorm: 179.82940673828125
      vf_explained_var: 0.0
      vf_loss: 75914.953125
    num_steps_sampled: 7905000
    num_steps_trained: 7905000
    wait_time_ms: 72.663
  iterations_since_restore: 1581
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13726.501895666122
  time_this_iter_s: 8.20603346824646
  time_total_s: 13726.501895666122
  timestamp: 1594869781
  timesteps_since_restore: 7905000
  timesteps_this_iter: 5000
  timesteps_total: 7905000
  training_iteration: 1581
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13726 s, 1581 iter, 7905000 ts, -3.67e+04 rew

agent-1: -19171.062199477732
agent-2: -14803.059525550962
agent-3: -9465.461576776132
agent-4: -16199.682769441924
agent-5: -18179.855627122386
Extrinsic Rewards:
-18986
-14690
-9364
-16042
-18017
Sum Reward: -77099
Avg Reward: -15419.8
Min Reward: -18986
Max Reward: -9364
Gini Coefficient: -0.11710138912307552
20:20 Ratio: 0.49320551985673655
Max-min Ratio: 0.49320551985673655
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-23-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -36485.60487325821
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1581
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.829
    dispatch_time_ms: 6.291
    learner:
      cur_lr: 0.0008335270103998482
      grad_gnorm: 40.0
      policy_entropy: 53.10078430175781
      policy_loss: 492.86114501953125
      var_gnorm: 180.16909790039062
      vf_explained_var: 0.0
      vf_loss: 157651.921875
    num_steps_sampled: 7910000
    num_steps_trained: 7910000
    wait_time_ms: 72.3
  iterations_since_restore: 1582
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13734.883538007736
  time_this_iter_s: 8.38164234161377
  time_total_s: 13734.883538007736
  timestamp: 1594869790
  timesteps_since_restore: 7910000
  timesteps_this_iter: 5000
  timesteps_total: 7910000
  training_iteration: 1582
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13734 s, 1582 iter, 7910000 ts, -3.65e+04 rew

agent-1: -25217.156105034883
agent-2: -8141.926094456263
agent-3: -19336.37624542491
agent-4: -12635.933693865314
agent-5: -18713.68727709842
Extrinsic Rewards:
-25013
-8061
-19180
-12527
-18537
Sum Reward: -83318
Avg Reward: -16663.6
Min Reward: -25013
Max Reward: -8061
Gini Coefficient: -0.19470942653448234
20:20 Ratio: 0.3222724183424619
Max-min Ratio: 0.3222724183424619
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-23-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -36528.90830537397
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1582
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.875
    dispatch_time_ms: 7.286
    learner:
      cur_lr: 0.0008331940043717623
      grad_gnorm: 39.999996185302734
      policy_entropy: 49.29945755004883
      policy_loss: -2700.31103515625
      var_gnorm: 180.49278259277344
      vf_explained_var: 0.0
      vf_loss: 138899.390625
    num_steps_sampled: 7915000
    num_steps_trained: 7915000
    wait_time_ms: 74.114
  iterations_since_restore: 1583
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13743.283864974976
  time_this_iter_s: 8.40032696723938
  time_total_s: 13743.283864974976
  timestamp: 1594869798
  timesteps_since_restore: 7915000
  timesteps_this_iter: 5000
  timesteps_total: 7915000
  training_iteration: 1583
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13743 s, 1583 iter, 7915000 ts, -3.65e+04 rew

agent-1: -24611.89943750997
agent-2: -16009.442322592431
agent-3: -10052.45035736433
agent-4: -22513.879506938785
agent-5: -26377.177772765608
Extrinsic Rewards:
-24442
-15894
-9965
-22356
-26189
Sum Reward: -98846
Avg Reward: -19769.2
Min Reward: -26189
Max Reward: -9965
Gini Coefficient: -0.1658984683244643
20:20 Ratio: 0.38050326472946655
Max-min Ratio: 0.38050326472946655
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-23-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -36833.95968234717
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1583
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.356
    dispatch_time_ms: 7.422
    learner:
      cur_lr: 0.0008328609983436763
      grad_gnorm: 39.999996185302734
      policy_entropy: 51.46495819091797
      policy_loss: -3378.36572265625
      var_gnorm: 180.86012268066406
      vf_explained_var: 0.0
      vf_loss: 420685.875
    num_steps_sampled: 7920000
    num_steps_trained: 7920000
    wait_time_ms: 80.711
  iterations_since_restore: 1584
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13751.694687366486
  time_this_iter_s: 8.41082239151001
  time_total_s: 13751.694687366486
  timestamp: 1594869807
  timesteps_since_restore: 7920000
  timesteps_this_iter: 5000
  timesteps_total: 7920000
  training_iteration: 1584
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13751 s, 1584 iter, 7920000 ts, -3.68e+04 rew

agent-1: -15473.391089328848
agent-2: -27991.650629443477
agent-3: -21531.83366711493
agent-4: -32091.837694670055
agent-5: -20762.76146271537
Extrinsic Rewards:
-15372
-27821
-21395
-31899
-20633
Sum Reward: -117120
Avg Reward: -23424.0
Min Reward: -31899
Max Reward: -15372
Gini Coefficient: -0.13743852459016392
20:20 Ratio: 0.4818959842001317
Max-min Ratio: 0.4818959842001317
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-23-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -37000.42253144199
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1584
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.688
    dispatch_time_ms: 7.701
    learner:
      cur_lr: 0.0008325279923155904
      grad_gnorm: 40.000003814697266
      policy_entropy: 51.5699462890625
      policy_loss: -6650.29736328125
      var_gnorm: 181.2285919189453
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 630903.3125
    num_steps_sampled: 7925000
    num_steps_trained: 7925000
    wait_time_ms: 75.39
  iterations_since_restore: 1585
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13759.991057872772
  time_this_iter_s: 8.296370506286621
  time_total_s: 13759.991057872772
  timestamp: 1594869815
  timesteps_since_restore: 7925000
  timesteps_this_iter: 5000
  timesteps_total: 7925000
  training_iteration: 1585
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13759 s, 1585 iter, 7925000 ts, -3.7e+04 rew

agent-1: -18477.860658002293
agent-2: -20476.70468572489
agent-3: -23743.21168586146
agent-4: -23318.468760157994
agent-5: -23265.018348640904
Extrinsic Rewards:
-18351
-20333
-23569
-23162
-23115
Sum Reward: -108530
Avg Reward: -21706.0
Min Reward: -23569
Max Reward: -18351
Gini Coefficient: -0.04888970791486225
20:20 Ratio: 0.7786074928932072
Max-min Ratio: 0.7786074928932072
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-23-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -37408.34226093244
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1585
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.663
    dispatch_time_ms: 9.439
    learner:
      cur_lr: 0.0008321949862875044
      grad_gnorm: 40.0
      policy_entropy: 45.964317321777344
      policy_loss: -8400.9951171875
      var_gnorm: 181.63192749023438
      vf_explained_var: 0.0
      vf_loss: 1925559.625
    num_steps_sampled: 7930000
    num_steps_trained: 7930000
    wait_time_ms: 71.732
  iterations_since_restore: 1586
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13768.448028802872
  time_this_iter_s: 8.456970930099487
  time_total_s: 13768.448028802872
  timestamp: 1594869823
  timesteps_since_restore: 7930000
  timesteps_this_iter: 5000
  timesteps_total: 7930000
  training_iteration: 1586
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13768 s, 1586 iter, 7930000 ts, -3.74e+04 rew

agent-1: -24154.855620556777
agent-2: -34094.96967303726
agent-3: -12059.623715646232
agent-4: -26443.96986403841
agent-5: -23601.957742668274
Extrinsic Rewards:
-24005
-33898
-11972
-26305
-23445
Sum Reward: -119625
Avg Reward: -23925.0
Min Reward: -33898
Max Reward: -11972
Gini Coefficient: -0.15619477533960294
20:20 Ratio: 0.35317717859460734
Max-min Ratio: 0.35317717859460734
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-23-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -37686.626717244726
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1586
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.554
    dispatch_time_ms: 7.574
    learner:
      cur_lr: 0.0008318619802594185
      grad_gnorm: 40.0
      policy_entropy: 47.263916015625
      policy_loss: -3299.595703125
      var_gnorm: 181.95895385742188
      vf_explained_var: 0.0
      vf_loss: 905392.75
    num_steps_sampled: 7935000
    num_steps_trained: 7935000
    wait_time_ms: 74.402
  iterations_since_restore: 1587
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13776.858106136322
  time_this_iter_s: 8.410077333450317
  time_total_s: 13776.858106136322
  timestamp: 1594869832
  timesteps_since_restore: 7935000
  timesteps_this_iter: 5000
  timesteps_total: 7935000
  training_iteration: 1587
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13776 s, 1587 iter, 7935000 ts, -3.77e+04 rew

agent-1: -10336.28408906193
agent-2: -25312.321978100925
agent-3: -20270.911361606348
agent-4: -24108.45201072927
agent-5: -21894.688418801386
Extrinsic Rewards:
-10258
-25136
-20118
-23941
-21738
Sum Reward: -101191
Avg Reward: -20238.2
Min Reward: -25136
Max Reward: -10258
Gini Coefficient: -0.13273512466523701
20:20 Ratio: 0.4080999363462763
Max-min Ratio: 0.4080999363462763
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-24-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -38019.45104438943
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1587
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.2
    dispatch_time_ms: 8.555
    learner:
      cur_lr: 0.0008315289742313325
      grad_gnorm: 39.999996185302734
      policy_entropy: 51.725982666015625
      policy_loss: -5175.79541015625
      var_gnorm: 182.36343383789062
      vf_explained_var: 0.0
      vf_loss: 670989.875
    num_steps_sampled: 7940000
    num_steps_trained: 7940000
    wait_time_ms: 71.713
  iterations_since_restore: 1588
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13785.232790470123
  time_this_iter_s: 8.37468433380127
  time_total_s: 13785.232790470123
  timestamp: 1594869840
  timesteps_since_restore: 7940000
  timesteps_this_iter: 5000
  timesteps_total: 7940000
  training_iteration: 1588
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13785 s, 1588 iter, 7940000 ts, -3.8e+04 rew

agent-1: -22991.837914157157
agent-2: -26045.15528895365
agent-3: -28036.020488380564
agent-4: -28941.20906503468
agent-5: -2537.2117344060725
Extrinsic Rewards:
-22845
-25897
-27847
-28754
-2518
Sum Reward: -107861
Avg Reward: -21572.2
Min Reward: -28754
Max Reward: -2518
Gini Coefficient: -0.21314098701106055
20:20 Ratio: 0.08757042498435
Max-min Ratio: 0.08757042498435
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-24-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -38468.47517719219
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1588
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.908
    dispatch_time_ms: 8.787
    learner:
      cur_lr: 0.0008311960264109075
      grad_gnorm: 40.0
      policy_entropy: 54.332252502441406
      policy_loss: -1064.5482177734375
      var_gnorm: 182.4786834716797
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 109303.578125
    num_steps_sampled: 7945000
    num_steps_trained: 7945000
    wait_time_ms: 69.415
  iterations_since_restore: 1589
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13793.518790245056
  time_this_iter_s: 8.285999774932861
  time_total_s: 13793.518790245056
  timestamp: 1594869849
  timesteps_since_restore: 7945000
  timesteps_this_iter: 5000
  timesteps_total: 7945000
  training_iteration: 1589
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13793 s, 1589 iter, 7945000 ts, -3.85e+04 rew

agent-1: -11796.707069013502
agent-2: -15627.74161541555
agent-3: -19895.00782528104
agent-4: -12241.404290115703
agent-5: -7103.220578685345
Extrinsic Rewards:
-11666
-15474
-19692
-12105
-7012
Sum Reward: -65949
Avg Reward: -13189.8
Min Reward: -19692
Max Reward: -7012
Gini Coefficient: -0.17691246266054073
20:20 Ratio: 0.35608368880763763
Max-min Ratio: 0.35608368880763763
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-24-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -38720.131865734955
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1589
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.792
    dispatch_time_ms: 7.281
    learner:
      cur_lr: 0.0008308630203828216
      grad_gnorm: 40.0
      policy_entropy: 46.9727897644043
      policy_loss: 575.2610473632812
      var_gnorm: 182.675537109375
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 53515.1640625
    num_steps_sampled: 7950000
    num_steps_trained: 7950000
    wait_time_ms: 73.33
  iterations_since_restore: 1590
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13801.898992061615
  time_this_iter_s: 8.380201816558838
  time_total_s: 13801.898992061615
  timestamp: 1594869857
  timesteps_since_restore: 7950000
  timesteps_this_iter: 5000
  timesteps_total: 7950000
  training_iteration: 1590
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13801 s, 1590 iter, 7950000 ts, -3.87e+04 rew

agent-1: -12248.651845716153
agent-2: -9651.324544164701
agent-3: -17239.612395754073
agent-4: -12095.520295412589
agent-5: -14598.756678195548
Extrinsic Rewards:
-12111
-9541
-17049
-11956
-14449
Sum Reward: -65106
Avg Reward: -13021.2
Min Reward: -17049
Max Reward: -9541
Gini Coefficient: -0.1075722667649679
20:20 Ratio: 0.5596222652354976
Max-min Ratio: 0.5596222652354976
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-24-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -39049.018297027804
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1590
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.723
    dispatch_time_ms: 6.693
    learner:
      cur_lr: 0.0008305300143547356
      grad_gnorm: 40.000003814697266
      policy_entropy: 44.33052062988281
      policy_loss: -1640.1689453125
      var_gnorm: 182.94692993164062
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 176693.71875
    num_steps_sampled: 7955000
    num_steps_trained: 7955000
    wait_time_ms: 78.867
  iterations_since_restore: 1591
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13810.49382853508
  time_this_iter_s: 8.594836473464966
  time_total_s: 13810.49382853508
  timestamp: 1594869866
  timesteps_since_restore: 7955000
  timesteps_this_iter: 5000
  timesteps_total: 7955000
  training_iteration: 1591
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13810 s, 1591 iter, 7955000 ts, -3.9e+04 rew

agent-1: -27789.547485914565
agent-2: -19020.36960789988
agent-3: -12175.495447012298
agent-4: -15057.029910170922
agent-5: -22140.210003527263
Extrinsic Rewards:
-27595
-18871
-12072
-14944
-21985
Sum Reward: -95467
Avg Reward: -19093.4
Min Reward: -27595
Max Reward: -12072
Gini Coefficient: -0.15958184503545728
20:20 Ratio: 0.43747055626019204
Max-min Ratio: 0.43747055626019204
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-24-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -39847.14990635793
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1591
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.6
    dispatch_time_ms: 9.598
    learner:
      cur_lr: 0.0008301970083266497
      grad_gnorm: 39.99999237060547
      policy_entropy: 46.78955841064453
      policy_loss: 58.54161834716797
      var_gnorm: 183.3236083984375
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 50153.65625
    num_steps_sampled: 7960000
    num_steps_trained: 7960000
    wait_time_ms: 73.01
  iterations_since_restore: 1592
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13818.997652769089
  time_this_iter_s: 8.503824234008789
  time_total_s: 13818.997652769089
  timestamp: 1594869874
  timesteps_since_restore: 7960000
  timesteps_this_iter: 5000
  timesteps_total: 7960000
  training_iteration: 1592
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13818 s, 1592 iter, 7960000 ts, -3.98e+04 rew

agent-1: -22184.62083161274
agent-2: -23412.67122120868
agent-3: -12003.11330966243
agent-4: -16259.02764836141
agent-5: -14006.85178767635
Extrinsic Rewards:
-22012
-23222
-11897
-16131
-13891
Sum Reward: -87153
Avg Reward: -17430.6
Min Reward: -23222
Max Reward: -11897
Gini Coefficient: -0.14122749647172214
20:20 Ratio: 0.5123159073292567
Max-min Ratio: 0.5123159073292567
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-24-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -40545.98900870696
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1592
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.377
    dispatch_time_ms: 10.741
    learner:
      cur_lr: 0.0008298640022985637
      grad_gnorm: 39.999996185302734
      policy_entropy: 41.89277648925781
      policy_loss: -7394.9228515625
      var_gnorm: 183.68429565429688
      vf_explained_var: 0.0
      vf_loss: 2979826.0
    num_steps_sampled: 7965000
    num_steps_trained: 7965000
    wait_time_ms: 71.936
  iterations_since_restore: 1593
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13833.137315034866
  time_this_iter_s: 14.139662265777588
  time_total_s: 13833.137315034866
  timestamp: 1594869888
  timesteps_since_restore: 7965000
  timesteps_this_iter: 5000
  timesteps_total: 7965000
  training_iteration: 1593
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13833 s, 1593 iter, 7965000 ts, -4.05e+04 rew

agent-1: -24207.390172050542
agent-2: -6821.510563973317
agent-3: -19581.676599907336
agent-4: -38325.26876371631
agent-5: -33301.65433692349
Extrinsic Rewards:
-24054
-6784
-19450
-38116
-33114
Sum Reward: -121518
Avg Reward: -24303.6
Min Reward: -38116
Max Reward: -6784
Gini Coefficient: -0.251248374726378
20:20 Ratio: 0.17798299926540034
Max-min Ratio: 0.17798299926540034
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-24-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -41635.259053679445
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1593
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.772
    dispatch_time_ms: 8.238
    learner:
      cur_lr: 0.0008295309962704778
      grad_gnorm: 40.000003814697266
      policy_entropy: 38.444129943847656
      policy_loss: -10461.8681640625
      var_gnorm: 184.10890197753906
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 5923978.0
    num_steps_sampled: 7970000
    num_steps_trained: 7970000
    wait_time_ms: 75.303
  iterations_since_restore: 1594
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13841.641692638397
  time_this_iter_s: 8.504377603530884
  time_total_s: 13841.641692638397
  timestamp: 1594869897
  timesteps_since_restore: 7970000
  timesteps_this_iter: 5000
  timesteps_total: 7970000
  training_iteration: 1594
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13841 s, 1594 iter, 7970000 ts, -4.16e+04 rew

agent-1: -29200.566058470442
agent-2: -24707.78512165476
agent-3: -32080.540903957488
agent-4: -18212.39305217969
agent-5: -35446.40390278763
Extrinsic Rewards:
-29032
-24572
-31912
-18125
-35280
Sum Reward: -138921
Avg Reward: -27784.2
Min Reward: -35280
Max Reward: -18125
Gini Coefficient: -0.11992427350796496
20:20 Ratio: 0.5137471655328798
Max-min Ratio: 0.5137471655328798
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-25-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -42924.37842063208
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1594
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.614
    dispatch_time_ms: 6.017
    learner:
      cur_lr: 0.0008291979902423918
      grad_gnorm: 40.0
      policy_entropy: 35.56730270385742
      policy_loss: -3008.060546875
      var_gnorm: 184.42437744140625
      vf_explained_var: 0.0
      vf_loss: 994895.8125
    num_steps_sampled: 7975000
    num_steps_trained: 7975000
    wait_time_ms: 75.989
  iterations_since_restore: 1595
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13850.070594072342
  time_this_iter_s: 8.428901433944702
  time_total_s: 13850.070594072342
  timestamp: 1594869905
  timesteps_since_restore: 7975000
  timesteps_this_iter: 5000
  timesteps_total: 7975000
  training_iteration: 1595
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13850 s, 1595 iter, 7975000 ts, -4.29e+04 rew

agent-1: -33102.839345462475
agent-2: -8775.39290466377
agent-3: -33523.079162256974
agent-4: -24392.56475717742
agent-5: -30189.95619655908
Extrinsic Rewards:
-32918
-8722
-33358
-24250
-30022
Sum Reward: -129270
Avg Reward: -25854.0
Min Reward: -33358
Max Reward: -8722
Gini Coefficient: -0.1792836698383229
20:20 Ratio: 0.2614665147790635
Max-min Ratio: 0.2614665147790635
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-25-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -44079.81066488118
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1595
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.787
    dispatch_time_ms: 11.773
    learner:
      cur_lr: 0.0008288649842143059
      grad_gnorm: 40.0
      policy_entropy: 37.44611358642578
      policy_loss: -1066.1146240234375
      var_gnorm: 184.79986572265625
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 313606.71875
    num_steps_sampled: 7980000
    num_steps_trained: 7980000
    wait_time_ms: 72.338
  iterations_since_restore: 1596
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13858.619397878647
  time_this_iter_s: 8.548803806304932
  time_total_s: 13858.619397878647
  timestamp: 1594869914
  timesteps_since_restore: 7980000
  timesteps_this_iter: 5000
  timesteps_total: 7980000
  training_iteration: 1596
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13858 s, 1596 iter, 7980000 ts, -4.41e+04 rew

agent-1: -4691.259389621795
agent-2: -22589.655114732635
agent-3: -12178.80448995468
agent-4: -13950.18542183245
agent-5: -27243.83572428122
Extrinsic Rewards:
-4637
-22403
-12065
-13837
-27029
Sum Reward: -79971
Avg Reward: -15994.2
Min Reward: -27029
Max Reward: -4637
Gini Coefficient: -0.27570994485500994
20:20 Ratio: 0.17155647637722446
Max-min Ratio: 0.17155647637722446
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-25-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -44689.72595023275
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1596
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.693
    dispatch_time_ms: 8.191
    learner:
      cur_lr: 0.0008285319781862199
      grad_gnorm: 40.000003814697266
      policy_entropy: 35.634605407714844
      policy_loss: -2037.794189453125
      var_gnorm: 185.13787841796875
      vf_explained_var: 0.0
      vf_loss: 520046.65625
    num_steps_sampled: 7985000
    num_steps_trained: 7985000
    wait_time_ms: 73.987
  iterations_since_restore: 1597
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13867.05585694313
  time_this_iter_s: 8.436459064483643
  time_total_s: 13867.05585694313
  timestamp: 1594869922
  timesteps_since_restore: 7985000
  timesteps_this_iter: 5000
  timesteps_total: 7985000
  training_iteration: 1597
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13867 s, 1597 iter, 7985000 ts, -4.47e+04 rew

agent-1: -11248.207192020962
agent-2: -16233.038622517626
agent-3: -35379.60321732425
agent-4: -30593.227562296117
agent-5: -10281.207224164917
Extrinsic Rewards:
-11161
-16118
-35165
-30403
-10200
Sum Reward: -103047
Avg Reward: -20609.4
Min Reward: -35165
Max Reward: -10200
Gini Coefficient: -0.26850660378273994
20:20 Ratio: 0.2900611403384047
Max-min Ratio: 0.2900611403384047
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-25-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -45503.58212180629
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1597
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.519
    dispatch_time_ms: 8.918
    learner:
      cur_lr: 0.000828198972158134
      grad_gnorm: 40.0
      policy_entropy: 31.694536209106445
      policy_loss: -922.7928466796875
      var_gnorm: 185.52442932128906
      vf_explained_var: 0.0
      vf_loss: 241572.671875
    num_steps_sampled: 7990000
    num_steps_trained: 7990000
    wait_time_ms: 73.742
  iterations_since_restore: 1598
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13875.539695739746
  time_this_iter_s: 8.4838387966156
  time_total_s: 13875.539695739746
  timestamp: 1594869931
  timesteps_since_restore: 7990000
  timesteps_this_iter: 5000
  timesteps_total: 7990000
  training_iteration: 1598
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13875 s, 1598 iter, 7990000 ts, -4.55e+04 rew

agent-1: -23199.46798757013
agent-2: -25958.653201362955
agent-3: -17127.385444294105
agent-4: -17943.102609290818
agent-5: -17378.82870526004
Extrinsic Rewards:
-23035
-25796
-17014
-17805
-17245
Sum Reward: -100895
Avg Reward: -20179.0
Min Reward: -25796
Max Reward: -17014
Gini Coefficient: -0.0925873432776649
20:20 Ratio: 0.659559621646767
Max-min Ratio: 0.659559621646767
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-25-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -46303.64842254641
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1598
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.697
    dispatch_time_ms: 7.756
    learner:
      cur_lr: 0.000827866024337709
      grad_gnorm: 40.0
      policy_entropy: 39.04790496826172
      policy_loss: -1440.9027099609375
      var_gnorm: 185.85400390625
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 383567.03125
    num_steps_sampled: 7995000
    num_steps_trained: 7995000
    wait_time_ms: 74.751
  iterations_since_restore: 1599
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13883.987450361252
  time_this_iter_s: 8.447754621505737
  time_total_s: 13883.987450361252
  timestamp: 1594869939
  timesteps_since_restore: 7995000
  timesteps_this_iter: 5000
  timesteps_total: 7995000
  training_iteration: 1599
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13883 s, 1599 iter, 7995000 ts, -4.63e+04 rew

agent-1: -32261.546262040218
agent-2: -21147.555104589603
agent-3: -10974.787036575799
agent-4: -30256.9549070179
agent-5: -18897.16691943055
Extrinsic Rewards:
-32062
-20997
-10893
-30083
-18773
Sum Reward: -112808
Avg Reward: -22561.6
Min Reward: -32062
Max Reward: -10893
Gini Coefficient: -0.190227643429544
20:20 Ratio: 0.3397479882727216
Max-min Ratio: 0.3397479882727216
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-25-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -47220.72088470267
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1599
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.961
    dispatch_time_ms: 7.616
    learner:
      cur_lr: 0.000827533018309623
      grad_gnorm: 40.0
      policy_entropy: 35.40251541137695
      policy_loss: -5917.04248046875
      var_gnorm: 186.2960662841797
      vf_explained_var: 0.0
      vf_loss: 1284326.875
    num_steps_sampled: 8000000
    num_steps_trained: 8000000
    wait_time_ms: 78.334
  iterations_since_restore: 1600
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13892.459873199463
  time_this_iter_s: 8.47242283821106
  time_total_s: 13892.459873199463
  timestamp: 1594869948
  timesteps_since_restore: 8000000
  timesteps_this_iter: 5000
  timesteps_total: 8000000
  training_iteration: 1600
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13892 s, 1600 iter, 8000000 ts, -4.72e+04 rew

agent-1: -22447.151617716496
agent-2: -26034.213947945165
agent-3: -30920.14462321869
agent-4: -18149.311223221684
agent-5: -27395.202672672636
Extrinsic Rewards:
-22310
-25890
-30741
-18048
-27222
Sum Reward: -124211
Avg Reward: -24842.2
Min Reward: -30741
Max Reward: -18048
Gini Coefficient: -0.09756945842155687
20:20 Ratio: 0.5870986630233239
Max-min Ratio: 0.5870986630233239
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-25-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -48221.887548336716
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1600
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.547
    dispatch_time_ms: 7.08
    learner:
      cur_lr: 0.0008272000122815371
      grad_gnorm: 40.0
      policy_entropy: 44.61443328857422
      policy_loss: -6991.2978515625
      var_gnorm: 186.6522216796875
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1117680.5
    num_steps_sampled: 8005000
    num_steps_trained: 8005000
    wait_time_ms: 74.297
  iterations_since_restore: 1601
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13900.929730892181
  time_this_iter_s: 8.469857692718506
  time_total_s: 13900.929730892181
  timestamp: 1594869956
  timesteps_since_restore: 8005000
  timesteps_this_iter: 5000
  timesteps_total: 8005000
  training_iteration: 1601
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13900 s, 1601 iter, 8005000 ts, -4.82e+04 rew

agent-1: -17377.227604547934
agent-2: -29654.25947112788
agent-3: -31144.828890774785
agent-4: -11121.796901675452
agent-5: -35097.845222957774
Extrinsic Rewards:
-17270
-29478
-30976
-11050
-34908
Sum Reward: -123682
Avg Reward: -24736.4
Min Reward: -34908
Max Reward: -11050
Gini Coefficient: -0.19864491195161785
20:20 Ratio: 0.3165463504067835
Max-min Ratio: 0.3165463504067835
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-26-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -49276.78383294702
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1601
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.665
    dispatch_time_ms: 7.858
    learner:
      cur_lr: 0.0008268670062534511
      grad_gnorm: 40.0
      policy_entropy: 43.629241943359375
      policy_loss: 775.7874755859375
      var_gnorm: 187.08230590820312
      vf_explained_var: 0.0
      vf_loss: 108778.9140625
    num_steps_sampled: 8010000
    num_steps_trained: 8010000
    wait_time_ms: 73.914
  iterations_since_restore: 1602
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13909.38562130928
  time_this_iter_s: 8.455890417098999
  time_total_s: 13909.38562130928
  timestamp: 1594869965
  timesteps_since_restore: 8010000
  timesteps_this_iter: 5000
  timesteps_total: 8010000
  training_iteration: 1602
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13909 s, 1602 iter, 8010000 ts, -4.93e+04 rew

agent-1: -31766.338572606022
agent-2: -16780.421884159936
agent-3: -21735.950969453657
agent-4: -33999.52736884729
agent-5: -31929.29684754976
Extrinsic Rewards:
-31600
-16685
-21612
-33820
-31765
Sum Reward: -135482
Avg Reward: -27096.4
Min Reward: -33820
Max Reward: -16685
Gini Coefficient: -0.1311554302416557
20:20 Ratio: 0.4933471318746304
Max-min Ratio: 0.4933471318746304
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-26-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -50471.53441977556
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1602
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.109
    dispatch_time_ms: 8.797
    learner:
      cur_lr: 0.0008265340002253652
      grad_gnorm: 40.0
      policy_entropy: 44.20995330810547
      policy_loss: -2265.26806640625
      var_gnorm: 187.3952178955078
      vf_explained_var: 0.0
      vf_loss: 654940.1875
    num_steps_sampled: 8015000
    num_steps_trained: 8015000
    wait_time_ms: 72.079
  iterations_since_restore: 1603
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13917.805975198746
  time_this_iter_s: 8.420353889465332
  time_total_s: 13917.805975198746
  timestamp: 1594869973
  timesteps_since_restore: 8015000
  timesteps_this_iter: 5000
  timesteps_total: 8015000
  training_iteration: 1603
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13917 s, 1603 iter, 8015000 ts, -5.05e+04 rew

agent-1: -26982.889195798365
agent-2: -17946.47703931864
agent-3: -12697.354605832263
agent-4: -20812.636276317935
agent-5: -25478.59756241394
Extrinsic Rewards:
-26801
-17809
-12607
-20674
-25305
Sum Reward: -103196
Avg Reward: -20639.2
Min Reward: -26801
Max Reward: -12607
Gini Coefficient: -0.1390906624287763
20:20 Ratio: 0.4703928957874706
Max-min Ratio: 0.4703928957874706
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-26-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -51321.47629228977
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1603
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.834
    dispatch_time_ms: 6.22
    learner:
      cur_lr: 0.0008262009941972792
      grad_gnorm: 39.999996185302734
      policy_entropy: 42.821144104003906
      policy_loss: -2173.87060546875
      var_gnorm: 187.82376098632812
      vf_explained_var: 0.0
      vf_loss: 388011.03125
    num_steps_sampled: 8020000
    num_steps_trained: 8020000
    wait_time_ms: 79.564
  iterations_since_restore: 1604
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13926.382260084152
  time_this_iter_s: 8.576284885406494
  time_total_s: 13926.382260084152
  timestamp: 1594869982
  timesteps_since_restore: 8020000
  timesteps_this_iter: 5000
  timesteps_total: 8020000
  training_iteration: 1604
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13926 s, 1604 iter, 8020000 ts, -5.13e+04 rew

agent-1: -28498.95331804854
agent-2: -27865.643451441054
agent-3: -28709.064927082887
agent-4: -12604.281544943722
agent-5: -23389.155560213425
Extrinsic Rewards:
-28330
-27712
-28543
-12515
-23233
Sum Reward: -120333
Avg Reward: -24066.6
Min Reward: -28543
Max Reward: -12515
Gini Coefficient: -0.12350061911528841
20:20 Ratio: 0.4384612689626178
Max-min Ratio: 0.4384612689626178
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-26-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -52309.77752124567
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1604
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.863
    dispatch_time_ms: 9.347
    learner:
      cur_lr: 0.0008258679881691933
      grad_gnorm: 40.0
      policy_entropy: 52.15700149536133
      policy_loss: -4208.958984375
      var_gnorm: 188.1049346923828
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 668096.3125
    num_steps_sampled: 8025000
    num_steps_trained: 8025000
    wait_time_ms: 71.684
  iterations_since_restore: 1605
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13934.80192399025
  time_this_iter_s: 8.419663906097412
  time_total_s: 13934.80192399025
  timestamp: 1594869990
  timesteps_since_restore: 8025000
  timesteps_this_iter: 5000
  timesteps_total: 8025000
  training_iteration: 1605
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13934 s, 1605 iter, 8025000 ts, -5.23e+04 rew

agent-1: -14815.444042307272
agent-2: -23114.54308197303
agent-3: -19263.782997044615
agent-4: -11918.218962614696
agent-5: -13405.13903772841
Extrinsic Rewards:
-14687
-22916
-19107
-11803
-13272
Sum Reward: -81785
Avg Reward: -16357.0
Min Reward: -22916
Max Reward: -11803
Gini Coefficient: -0.13724277067921992
20:20 Ratio: 0.5150549834176994
Max-min Ratio: 0.5150549834176994
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-26-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -52876.20745887462
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1605
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.938
    dispatch_time_ms: 6.172
    learner:
      cur_lr: 0.0008255349821411073
      grad_gnorm: 40.0
      policy_entropy: 54.53496551513672
      policy_loss: -3633.80322265625
      var_gnorm: 188.4112091064453
      vf_explained_var: 0.0
      vf_loss: 285861.59375
    num_steps_sampled: 8030000
    num_steps_trained: 8030000
    wait_time_ms: 78.156
  iterations_since_restore: 1606
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13943.20313334465
  time_this_iter_s: 8.401209354400635
  time_total_s: 13943.20313334465
  timestamp: 1594869999
  timesteps_since_restore: 8030000
  timesteps_this_iter: 5000
  timesteps_total: 8030000
  training_iteration: 1606
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13943 s, 1606 iter, 8030000 ts, -5.29e+04 rew

agent-1: -15522.84454806463
agent-2: -29373.10206161148
agent-3: -20513.77736165769
agent-4: -13642.883046316078
agent-5: -11168.738052967534
Extrinsic Rewards:
-15391
-29162
-20354
-13525
-11066
Sum Reward: -89498
Avg Reward: -17899.6
Min Reward: -29162
Max Reward: -11066
Gini Coefficient: -0.19227692238932714
20:20 Ratio: 0.37946642891434057
Max-min Ratio: 0.37946642891434057
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-26-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -53520.3444169465
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1606
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.983
    dispatch_time_ms: 9.577
    learner:
      cur_lr: 0.0008252019761130214
      grad_gnorm: 40.0
      policy_entropy: 54.02851867675781
      policy_loss: 1690.3035888671875
      var_gnorm: 188.51788330078125
      vf_explained_var: 0.0
      vf_loss: 52767.125
    num_steps_sampled: 8035000
    num_steps_trained: 8035000
    wait_time_ms: 70.288
  iterations_since_restore: 1607
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13951.53127193451
  time_this_iter_s: 8.328138589859009
  time_total_s: 13951.53127193451
  timestamp: 1594870007
  timesteps_since_restore: 8035000
  timesteps_this_iter: 5000
  timesteps_total: 8035000
  training_iteration: 1607
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13951 s, 1607 iter, 8035000 ts, -5.35e+04 rew

agent-1: -10674.801709816338
agent-2: -10950.822366173768
agent-3: -15206.132939495428
agent-4: -18414.702816827805
agent-5: -12042.865339365502
Extrinsic Rewards:
-10542
-10838
-15054
-18225
-11902
Sum Reward: -66561
Avg Reward: -13312.2
Min Reward: -18225
Max Reward: -10542
Gini Coefficient: -0.11767852045492105
20:20 Ratio: 0.5784362139917696
Max-min Ratio: 0.5784362139917696
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-26-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -53986.51116427061
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1607
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.492
    dispatch_time_ms: 6.543
    learner:
      cur_lr: 0.0008248690282925963
      grad_gnorm: 40.0
      policy_entropy: 57.144264221191406
      policy_loss: 643.0328369140625
      var_gnorm: 188.69273376464844
      vf_explained_var: 0.0
      vf_loss: 11594.1884765625
    num_steps_sampled: 8040000
    num_steps_trained: 8040000
    wait_time_ms: 76.717
  iterations_since_restore: 1608
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13959.850027799606
  time_this_iter_s: 8.318755865097046
  time_total_s: 13959.850027799606
  timestamp: 1594870016
  timesteps_since_restore: 8040000
  timesteps_this_iter: 5000
  timesteps_total: 8040000
  training_iteration: 1608
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13959 s, 1608 iter, 8040000 ts, -5.4e+04 rew

agent-1: -9045.533982839052
agent-2: -14000.200707530936
agent-3: -6930.726023589999
agent-4: -12933.238339899211
agent-5: -14316.357969141938
Extrinsic Rewards:
-8927
-13832
-6837
-12772
-14140
Sum Reward: -56508
Avg Reward: -11301.6
Min Reward: -14140
Max Reward: -6837
Gini Coefficient: -0.1381114178523395
20:20 Ratio: 0.48352192362093355
Max-min Ratio: 0.48352192362093355
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-27-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -54327.12129696657
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1608
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.734
    dispatch_time_ms: 8.629
    learner:
      cur_lr: 0.0008245360222645104
      grad_gnorm: 40.0
      policy_entropy: 56.12568664550781
      policy_loss: 167.14236450195312
      var_gnorm: 188.83999633789062
      vf_explained_var: 0.0
      vf_loss: 72947.828125
    num_steps_sampled: 8045000
    num_steps_trained: 8045000
    wait_time_ms: 72.405
  iterations_since_restore: 1609
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13968.132767915726
  time_this_iter_s: 8.282740116119385
  time_total_s: 13968.132767915726
  timestamp: 1594870024
  timesteps_since_restore: 8045000
  timesteps_this_iter: 5000
  timesteps_total: 8045000
  training_iteration: 1609
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13968 s, 1609 iter, 8045000 ts, -5.43e+04 rew

agent-1: -7175.810927448849
agent-2: -11138.94622587005
agent-3: -10525.489370984233
agent-4: -8824.287714239621
agent-5: -13236.132287553517
Extrinsic Rewards:
-7075
-10982
-10366
-8682
-13058
Sum Reward: -50163
Avg Reward: -10032.6
Min Reward: -13058
Max Reward: -7075
Gini Coefficient: -0.11375715168550525
20:20 Ratio: 0.5418134476948997
Max-min Ratio: 0.5418134476948997
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-27-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -54655.43312055877
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1609
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.26
    dispatch_time_ms: 8.318
    learner:
      cur_lr: 0.0008242030162364244
      grad_gnorm: 39.999996185302734
      policy_entropy: 53.61895751953125
      policy_loss: -1274.1644287109375
      var_gnorm: 189.0491485595703
      vf_explained_var: 0.0
      vf_loss: 267066.40625
    num_steps_sampled: 8050000
    num_steps_trained: 8050000
    wait_time_ms: 72.719
  iterations_since_restore: 1610
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13976.427854776382
  time_this_iter_s: 8.295086860656738
  time_total_s: 13976.427854776382
  timestamp: 1594870032
  timesteps_since_restore: 8050000
  timesteps_this_iter: 5000
  timesteps_total: 8050000
  training_iteration: 1610
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13976 s, 1610 iter, 8050000 ts, -5.47e+04 rew

agent-1: -12689.510765154495
agent-2: -7935.1246894143305
agent-3: -22816.80099758841
agent-4: -17630.72746999715
agent-5: -20392.310958432154
Extrinsic Rewards:
-12568
-7851
-22625
-17474
-20211
Sum Reward: -80729
Avg Reward: -16145.8
Min Reward: -22625
Max Reward: -7851
Gini Coefficient: -0.18427578689194712
20:20 Ratio: 0.34700552486187847
Max-min Ratio: 0.34700552486187847
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-27-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -55265.49981631456
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1610
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.855
    dispatch_time_ms: 9.87
    learner:
      cur_lr: 0.0008238700102083385
      grad_gnorm: 40.0
      policy_entropy: 58.19160461425781
      policy_loss: 852.8089599609375
      var_gnorm: 189.20465087890625
      vf_explained_var: 0.0
      vf_loss: 62545.00390625
    num_steps_sampled: 8055000
    num_steps_trained: 8055000
    wait_time_ms: 70.433
  iterations_since_restore: 1611
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13984.606290578842
  time_this_iter_s: 8.178435802459717
  time_total_s: 13984.606290578842
  timestamp: 1594870040
  timesteps_since_restore: 8055000
  timesteps_this_iter: 5000
  timesteps_total: 8055000
  training_iteration: 1611
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13984 s, 1611 iter, 8055000 ts, -5.53e+04 rew

agent-1: -17227.924179738584
agent-2: -16235.956191322093
agent-3: -3254.244316365694
agent-4: -8050.015435722579
agent-5: -8236.02956376692
Extrinsic Rewards:
-17018
-16029
-3208
-7932
-8115
Sum Reward: -52302
Avg Reward: -10460.4
Min Reward: -17018
Max Reward: -3208
Gini Coefficient: -0.27315972620549883
20:20 Ratio: 0.18850628746033612
Max-min Ratio: 0.18850628746033612
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-27-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -55671.097184028076
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1611
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.05
    dispatch_time_ms: 8.204
    learner:
      cur_lr: 0.0008235370041802526
      grad_gnorm: 40.0
      policy_entropy: 58.54574203491211
      policy_loss: 1918.9173583984375
      var_gnorm: 189.2141571044922
      vf_explained_var: 0.0
      vf_loss: 37076.12890625
    num_steps_sampled: 8060000
    num_steps_trained: 8060000
    wait_time_ms: 71.255
  iterations_since_restore: 1612
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 13992.887803077698
  time_this_iter_s: 8.28151249885559
  time_total_s: 13992.887803077698
  timestamp: 1594870049
  timesteps_since_restore: 8060000
  timesteps_this_iter: 5000
  timesteps_total: 8060000
  training_iteration: 1612
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 13992 s, 1612 iter, 8060000 ts, -5.57e+04 rew

agent-1: -16611.562865142416
agent-2: -6465.269866468595
agent-3: -13187.808437209103
agent-4: -8004.157558833851
agent-5: -4719.601346751655
Extrinsic Rewards:
-16393
-6361
-13006
-7873
-4639
Sum Reward: -48272
Avg Reward: -9654.4
Min Reward: -16393
Max Reward: -4639
Gini Coefficient: -0.24985913158766987
20:20 Ratio: 0.28298664063929724
Max-min Ratio: 0.28298664063929724
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-27-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -56046.55209334644
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1612
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.762
    dispatch_time_ms: 5.529
    learner:
      cur_lr: 0.0008232039981521666
      grad_gnorm: 40.0
      policy_entropy: 57.59894943237305
      policy_loss: -1835.290283203125
      var_gnorm: 189.19073486328125
      vf_explained_var: 0.0
      vf_loss: 103799.6640625
    num_steps_sampled: 8065000
    num_steps_trained: 8065000
    wait_time_ms: 74.061
  iterations_since_restore: 1613
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14001.118031740189
  time_this_iter_s: 8.230228662490845
  time_total_s: 14001.118031740189
  timestamp: 1594870057
  timesteps_since_restore: 8065000
  timesteps_this_iter: 5000
  timesteps_total: 8065000
  training_iteration: 1613
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14001 s, 1613 iter, 8065000 ts, -5.6e+04 rew

agent-1: -8640.349263332198
agent-2: -14354.844157911348
agent-3: -9540.077713432944
agent-4: -5644.7039734827185
agent-5: -9905.294987725578
Extrinsic Rewards:
-8509
-14154
-9388
-5535
-9752
Sum Reward: -47338
Avg Reward: -9467.6
Min Reward: -14154
Max Reward: -5535
Gini Coefficient: -0.15616206852845493
20:20 Ratio: 0.3910555320050869
Max-min Ratio: 0.3910555320050869
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-27-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -56405.73567744421
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1613
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.628
    dispatch_time_ms: 6.01
    learner:
      cur_lr: 0.0008228709921240807
      grad_gnorm: 40.000003814697266
      policy_entropy: 57.01641845703125
      policy_loss: 1843.440185546875
      var_gnorm: 189.13980102539062
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 51878.0390625
    num_steps_sampled: 8070000
    num_steps_trained: 8070000
    wait_time_ms: 73.161
  iterations_since_restore: 1614
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14009.329003810883
  time_this_iter_s: 8.21097207069397
  time_total_s: 14009.329003810883
  timestamp: 1594870065
  timesteps_since_restore: 8070000
  timesteps_this_iter: 5000
  timesteps_total: 8070000
  training_iteration: 1614
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14009 s, 1614 iter, 8070000 ts, -5.64e+04 rew

agent-1: -10480.895712424894
agent-2: -4229.370367798346
agent-3: -6313.588111127351
agent-4: -11909.463419704363
agent-5: -6500.93270036006
Extrinsic Rewards:
-10286
-4141
-6187
-11707
-6396
Sum Reward: -38717
Avg Reward: -7743.4
Min Reward: -11707
Max Reward: -4141
Gini Coefficient: -0.1986827491799468
20:20 Ratio: 0.35371999658324077
Max-min Ratio: 0.35371999658324077
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-27-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -56633.88092025137
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1614
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.004
    dispatch_time_ms: 8.004
    learner:
      cur_lr: 0.0008225379860959947
      grad_gnorm: 40.0
      policy_entropy: 54.83470916748047
      policy_loss: 365.8526611328125
      var_gnorm: 188.8619842529297
      vf_explained_var: 0.0
      vf_loss: 35828.984375
    num_steps_sampled: 8075000
    num_steps_trained: 8075000
    wait_time_ms: 69.224
  iterations_since_restore: 1615
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14017.47893357277
  time_this_iter_s: 8.149929761886597
  time_total_s: 14017.47893357277
  timestamp: 1594870073
  timesteps_since_restore: 8075000
  timesteps_this_iter: 5000
  timesteps_total: 8075000
  training_iteration: 1615
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14017 s, 1615 iter, 8075000 ts, -5.66e+04 rew

agent-1: -2916.6106033984865
agent-2: -8544.433046953267
agent-3: -4484.01195260923
agent-4: -5051.600656192999
agent-5: -5682.650701931645
Extrinsic Rewards:
-2820
-8351
-4357
-4905
-5535
Sum Reward: -25968
Avg Reward: -5193.6
Min Reward: -8351
Max Reward: -2820
Gini Coefficient: -0.18853974121996303
20:20 Ratio: 0.3376841096874626
Max-min Ratio: 0.3376841096874626
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-28-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -56678.313860793176
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1615
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.175
    dispatch_time_ms: 8.589
    learner:
      cur_lr: 0.0008222049800679088
      grad_gnorm: 40.0
      policy_entropy: 48.875675201416016
      policy_loss: 1290.015380859375
      var_gnorm: 188.52142333984375
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 43705.80078125
    num_steps_sampled: 8080000
    num_steps_trained: 8080000
    wait_time_ms: 69.983
  iterations_since_restore: 1616
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14025.588032245636
  time_this_iter_s: 8.109098672866821
  time_total_s: 14025.588032245636
  timestamp: 1594870082
  timesteps_since_restore: 8080000
  timesteps_this_iter: 5000
  timesteps_total: 8080000
  training_iteration: 1616
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14025 s, 1616 iter, 8080000 ts, -5.67e+04 rew

agent-1: -5803.004431558972
agent-2: -2931.965473753206
agent-3: -2784.528105856507
agent-4: -5431.235464341308
agent-5: -7607.479975833419
Extrinsic Rewards:
-5628
-2844
-2704
-5265
-7401
Sum Reward: -23842
Avg Reward: -4768.4
Min Reward: -7401
Max Reward: -2704
Gini Coefficient: -0.20431171881553561
20:20 Ratio: 0.36535603296851776
Max-min Ratio: 0.36535603296851776
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-28-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -56739.204596068186
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1616
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.256
    dispatch_time_ms: 45.371
    learner:
      cur_lr: 0.0008218719740398228
      grad_gnorm: 40.0
      policy_entropy: 46.27321243286133
      policy_loss: -636.217041015625
      var_gnorm: 188.16372680664062
      vf_explained_var: 0.0
      vf_loss: 121500.59375
    num_steps_sampled: 8085000
    num_steps_trained: 8085000
    wait_time_ms: 43.189
  iterations_since_restore: 1617
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14033.906994819641
  time_this_iter_s: 8.318962574005127
  time_total_s: 14033.906994819641
  timestamp: 1594870090
  timesteps_since_restore: 8085000
  timesteps_this_iter: 5000
  timesteps_total: 8085000
  training_iteration: 1617
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14033 s, 1617 iter, 8085000 ts, -5.67e+04 rew

agent-1: -8159.153658674708
agent-2: -5458.102534031703
agent-3: -3199.0424874902933
agent-4: -3924.910889034329
agent-5: -8567.164435158174
Extrinsic Rewards:
-7965
-5320
-3107
-3818
-8370
Sum Reward: -28580
Avg Reward: -5716.0
Min Reward: -8370
Max Reward: -3107
Gini Coefficient: -0.20536039188243527
20:20 Ratio: 0.3712066905615293
Max-min Ratio: 0.3712066905615293
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-28-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -56899.351284910714
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1617
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.223
    dispatch_time_ms: 21.236
    learner:
      cur_lr: 0.0008215390262193978
      grad_gnorm: 40.0
      policy_entropy: 44.59480667114258
      policy_loss: -1530.203857421875
      var_gnorm: 187.8797607421875
      vf_explained_var: 0.0
      vf_loss: 162745.921875
    num_steps_sampled: 8090000
    num_steps_trained: 8090000
    wait_time_ms: 64.442
  iterations_since_restore: 1618
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14042.59674501419
  time_this_iter_s: 8.68975019454956
  time_total_s: 14042.59674501419
  timestamp: 1594870099
  timesteps_since_restore: 8090000
  timesteps_this_iter: 5000
  timesteps_total: 8090000
  training_iteration: 1618
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14042 s, 1618 iter, 8090000 ts, -5.69e+04 rew

agent-1: -6497.428846595897
agent-2: -9624.82880714398
agent-3: -1966.1712402390149
agent-4: -2673.268483868306
agent-5: -6230.789440141034
Extrinsic Rewards:
-6321
-9403
-1911
-2602
-6059
Sum Reward: -26296
Avg Reward: -5259.2
Min Reward: -9403
Max Reward: -1911
Gini Coefficient: -0.28449954365682995
20:20 Ratio: 0.2032330107412528
Max-min Ratio: 0.2032330107412528
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-28-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -57014.264786598826
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1618
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.699
    dispatch_time_ms: 19.696
    learner:
      cur_lr: 0.0008212060201913118
      grad_gnorm: 40.000003814697266
      policy_entropy: 47.1290168762207
      policy_loss: -898.561279296875
      var_gnorm: 187.6912078857422
      vf_explained_var: 0.0
      vf_loss: 123267.9765625
    num_steps_sampled: 8095000
    num_steps_trained: 8095000
    wait_time_ms: 62.074
  iterations_since_restore: 1619
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14051.267169237137
  time_this_iter_s: 8.670424222946167
  time_total_s: 14051.267169237137
  timestamp: 1594870107
  timesteps_since_restore: 8095000
  timesteps_this_iter: 5000
  timesteps_total: 8095000
  training_iteration: 1619
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14051 s, 1619 iter, 8095000 ts, -5.7e+04 rew

agent-1: -11417.213794872996
agent-2: -3087.6238201532524
agent-3: -10230.669562893065
agent-4: -7171.989224321136
agent-5: -8117.478650397426
Extrinsic Rewards:
-11231
-3026
-10045
-7029
-7963
Sum Reward: -39294
Avg Reward: -7858.8
Min Reward: -11231
Max Reward: -3026
Gini Coefficient: -0.1977502926655469
20:20 Ratio: 0.26943281987356427
Max-min Ratio: 0.26943281987356427
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-28-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -57343.845424018364
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1619
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.945
    dispatch_time_ms: 46.641
    learner:
      cur_lr: 0.0008208730141632259
      grad_gnorm: 40.0
      policy_entropy: 50.48143768310547
      policy_loss: 1747.9715576171875
      var_gnorm: 187.49533081054688
      vf_explained_var: 0.0
      vf_loss: 50529.46875
    num_steps_sampled: 8100000
    num_steps_trained: 8100000
    wait_time_ms: 45.851
  iterations_since_restore: 1620
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14060.070533275604
  time_this_iter_s: 8.803364038467407
  time_total_s: 14060.070533275604
  timestamp: 1594870116
  timesteps_since_restore: 8100000
  timesteps_this_iter: 5000
  timesteps_total: 8100000
  training_iteration: 1620
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14060 s, 1620 iter, 8100000 ts, -5.73e+04 rew

agent-1: -4901.020716954241
agent-2: -3341.918149381746
agent-3: -6432.57580545732
agent-4: -6466.282379676851
agent-5: -8988.74120613017
Extrinsic Rewards:
-4769
-3249
-6276
-6315
-8787
Sum Reward: -29396
Avg Reward: -5879.2
Min Reward: -8787
Max Reward: -3249
Gini Coefficient: -0.1717512586746496
20:20 Ratio: 0.3697507681802663
Max-min Ratio: 0.3697507681802663
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-28-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -57573.92888860921
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1620
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.815
    dispatch_time_ms: 8.753
    learner:
      cur_lr: 0.0008205400081351399
      grad_gnorm: 40.0
      policy_entropy: 47.246212005615234
      policy_loss: 1349.7999267578125
      var_gnorm: 187.2294464111328
      vf_explained_var: 0.0
      vf_loss: 41896.09375
    num_steps_sampled: 8105000
    num_steps_trained: 8105000
    wait_time_ms: 57.819
  iterations_since_restore: 1621
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14068.900035858154
  time_this_iter_s: 8.829502582550049
  time_total_s: 14068.900035858154
  timestamp: 1594870125
  timesteps_since_restore: 8105000
  timesteps_this_iter: 5000
  timesteps_total: 8105000
  training_iteration: 1621
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14068 s, 1621 iter, 8105000 ts, -5.76e+04 rew

agent-1: -6501.119113917585
agent-2: -3717.9874607295246
agent-3: -4772.359306355137
agent-4: -3441.850927291955
agent-5: -5137.449805104809
Extrinsic Rewards:
-6308
-3602
-4621
-3324
-4982
Sum Reward: -22837
Avg Reward: -4567.4
Min Reward: -6308
Max Reward: -3324
Gini Coefficient: -0.12870341988877698
20:20 Ratio: 0.5269499048826887
Max-min Ratio: 0.5269499048826887
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-28-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -57735.56926321282
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1621
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.392
    dispatch_time_ms: 8.272
    learner:
      cur_lr: 0.000820207002107054
      grad_gnorm: 40.000003814697266
      policy_entropy: 48.9355354309082
      policy_loss: 1360.95849609375
      var_gnorm: 186.8846435546875
      vf_explained_var: 0.0
      vf_loss: 44598.44140625
    num_steps_sampled: 8110000
    num_steps_trained: 8110000
    wait_time_ms: 70.618
  iterations_since_restore: 1622
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14076.990061759949
  time_this_iter_s: 8.090025901794434
  time_total_s: 14076.990061759949
  timestamp: 1594870133
  timesteps_since_restore: 8110000
  timesteps_this_iter: 5000
  timesteps_total: 8110000
  training_iteration: 1622
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14076 s, 1622 iter, 8110000 ts, -5.77e+04 rew

agent-1: -163.01709875116393
agent-2: -4330.527767068324
agent-3: -6928.422783809832
agent-4: -6352.583430907846
agent-5: -8336.9736542076
Extrinsic Rewards:
-155
-4197
-6751
-6170
-8125
Sum Reward: -25398
Avg Reward: -5079.6
Min Reward: -8125
Max Reward: -155
Gini Coefficient: -0.2912670288999134
20:20 Ratio: 0.019076923076923078
Max-min Ratio: 0.019076923076923078
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-29-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -57931.51976822482
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1622
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.55
    dispatch_time_ms: 8.583
    learner:
      cur_lr: 0.000819873996078968
      grad_gnorm: 40.0
      policy_entropy: 47.73233413696289
      policy_loss: 1579.814697265625
      var_gnorm: 186.43919372558594
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 39851.85546875
    num_steps_sampled: 8115000
    num_steps_trained: 8115000
    wait_time_ms: 70.444
  iterations_since_restore: 1623
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14085.141860723495
  time_this_iter_s: 8.151798963546753
  time_total_s: 14085.141860723495
  timestamp: 1594870141
  timesteps_since_restore: 8115000
  timesteps_this_iter: 5000
  timesteps_total: 8115000
  training_iteration: 1623
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14085 s, 1623 iter, 8115000 ts, -5.79e+04 rew

agent-1: -1569.6773178204912
agent-2: -4117.58002839649
agent-3: -2974.351941083726
agent-4: -2875.2766161696995
agent-5: -654.987686474651
Extrinsic Rewards:
-1463
-3912
-2812
-2715
-613
Sum Reward: -11515
Avg Reward: -2303.0
Min Reward: -3912
Max Reward: -613
Gini Coefficient: -0.27605731654363874
20:20 Ratio: 0.15669734151329243
Max-min Ratio: 0.15669734151329243
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-29-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -57975.91847386605
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1623
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.99
    dispatch_time_ms: 7.939
    learner:
      cur_lr: 0.0008195409900508821
      grad_gnorm: 40.0
      policy_entropy: 49.467918395996094
      policy_loss: 1205.473388671875
      var_gnorm: 186.03973388671875
      vf_explained_var: 0.0
      vf_loss: 60054.0078125
    num_steps_sampled: 8120000
    num_steps_trained: 8120000
    wait_time_ms: 68.899
  iterations_since_restore: 1624
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14093.155691623688
  time_this_iter_s: 8.01383090019226
  time_total_s: 14093.155691623688
  timestamp: 1594870149
  timesteps_since_restore: 8120000
  timesteps_this_iter: 5000
  timesteps_total: 8120000
  training_iteration: 1624
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14093 s, 1624 iter, 8120000 ts, -5.8e+04 rew

agent-1: -2373.4966720476586
agent-2: -3812.236424633402
agent-3: -4081.3428686662746
agent-4: -4344.915570460406
agent-5: -5266.58475503483
Extrinsic Rewards:
-2269
-3660
-3934
-4209
-5075
Sum Reward: -19147
Avg Reward: -3829.4
Min Reward: -5075
Max Reward: -2269
Gini Coefficient: -0.12870945840079387
20:20 Ratio: 0.4470935960591133
Max-min Ratio: 0.4470935960591133
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-29-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -58105.90008480258
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1624
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.085
    dispatch_time_ms: 9.601
    learner:
      cur_lr: 0.0008192079840227962
      grad_gnorm: 40.0
      policy_entropy: 44.985923767089844
      policy_loss: 1477.14404296875
      var_gnorm: 185.60958862304688
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 38510.4609375
    num_steps_sampled: 8125000
    num_steps_trained: 8125000
    wait_time_ms: 65.172
  iterations_since_restore: 1625
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14101.283823013306
  time_this_iter_s: 8.12813138961792
  time_total_s: 14101.283823013306
  timestamp: 1594870158
  timesteps_since_restore: 8125000
  timesteps_this_iter: 5000
  timesteps_total: 8125000
  training_iteration: 1625
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14101 s, 1625 iter, 8125000 ts, -5.81e+04 rew

agent-1: -1864.0978186469215
agent-2: -2182.132691266333
agent-3: -2880.8687235285697
agent-4: -4094.924413396256
agent-5: -2886.9118073686527
Extrinsic Rewards:
-1754
-2069
-2720
-3912
-2748
Sum Reward: -13203
Avg Reward: -2640.6
Min Reward: -3912
Max Reward: -1754
Gini Coefficient: -0.15132924335378323
20:20 Ratio: 0.4483640081799591
Max-min Ratio: 0.4483640081799591
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-29-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -58164.96569091907
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1625
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.662
    dispatch_time_ms: 8.092
    learner:
      cur_lr: 0.0008188749779947102
      grad_gnorm: 40.000003814697266
      policy_entropy: 46.82406997680664
      policy_loss: 561.2766723632812
      var_gnorm: 185.2166748046875
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 48121.1484375
    num_steps_sampled: 8130000
    num_steps_trained: 8130000
    wait_time_ms: 72.235
  iterations_since_restore: 1626
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14109.450650930405
  time_this_iter_s: 8.166827917098999
  time_total_s: 14109.450650930405
  timestamp: 1594870166
  timesteps_since_restore: 8130000
  timesteps_this_iter: 5000
  timesteps_total: 8130000
  training_iteration: 1626
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14109 s, 1626 iter, 8130000 ts, -5.82e+04 rew

agent-1: -1358.042074248993
agent-2: -6865.494786233003
agent-3: -5638.461074180263
agent-4: -5796.463766957437
agent-5: -2770.7501640315154
Extrinsic Rewards:
-1307
-6665
-5459
-5611
-2677
Sum Reward: -21719
Avg Reward: -4343.8
Min Reward: -6665
Max Reward: -1307
Gini Coefficient: -0.25139278972328377
20:20 Ratio: 0.19609902475618904
Max-min Ratio: 0.19609902475618904
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-29-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -58297.631562696646
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1626
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.946
    dispatch_time_ms: 6.232
    learner:
      cur_lr: 0.0008185419719666243
      grad_gnorm: 40.0
      policy_entropy: 48.940284729003906
      policy_loss: 328.03045654296875
      var_gnorm: 184.8022003173828
      vf_explained_var: 0.0
      vf_loss: 34441.078125
    num_steps_sampled: 8135000
    num_steps_trained: 8135000
    wait_time_ms: 74.383
  iterations_since_restore: 1627
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14117.549265146255
  time_this_iter_s: 8.09861421585083
  time_total_s: 14117.549265146255
  timestamp: 1594870174
  timesteps_since_restore: 8135000
  timesteps_this_iter: 5000
  timesteps_total: 8135000
  training_iteration: 1627
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14117 s, 1627 iter, 8135000 ts, -5.83e+04 rew

agent-1: -2008.3434495132337
agent-2: -4189.122889791525
agent-3: -8719.22119454696
agent-4: -2346.196127621918
agent-5: -6221.675218879705
Extrinsic Rewards:
-1927
-4050
-8495
-2270
-6030
Sum Reward: -22772
Avg Reward: -4554.4
Min Reward: -8495
Max Reward: -1927
Gini Coefficient: -0.29678552608466535
20:20 Ratio: 0.2268393172454385
Max-min Ratio: 0.2268393172454385
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-29-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -58340.71593028463
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1627
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.631
    dispatch_time_ms: 6.865
    learner:
      cur_lr: 0.0008182090241461992
      grad_gnorm: 40.0
      policy_entropy: 53.837677001953125
      policy_loss: -216.559814453125
      var_gnorm: 184.482421875
      vf_explained_var: 0.0
      vf_loss: 121627.7734375
    num_steps_sampled: 8140000
    num_steps_trained: 8140000
    wait_time_ms: 72.53
  iterations_since_restore: 1628
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14125.652906417847
  time_this_iter_s: 8.103641271591187
  time_total_s: 14125.652906417847
  timestamp: 1594870182
  timesteps_since_restore: 8140000
  timesteps_this_iter: 5000
  timesteps_total: 8140000
  training_iteration: 1628
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14125 s, 1628 iter, 8140000 ts, -5.83e+04 rew

agent-1: -3028.6017197502165
agent-2: -5670.816270784401
agent-3: -2526.060685165632
agent-4: -3448.799338094571
agent-5: -4640.409523344888
Extrinsic Rewards:
-2903
-5468
-2413
-3307
-4478
Sum Reward: -18569
Avg Reward: -3713.8
Min Reward: -5468
Max Reward: -2413
Gini Coefficient: -0.16554472507943346
20:20 Ratio: 0.44129480614484273
Max-min Ratio: 0.44129480614484273
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-29-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -58342.706684804616
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1628
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.549
    dispatch_time_ms: 7.352
    learner:
      cur_lr: 0.0008178760181181133
      grad_gnorm: 40.000003814697266
      policy_entropy: 55.70509719848633
      policy_loss: 1682.3153076171875
      var_gnorm: 184.20216369628906
      vf_explained_var: 0.0
      vf_loss: 40777.31640625
    num_steps_sampled: 8145000
    num_steps_trained: 8145000
    wait_time_ms: 71.606
  iterations_since_restore: 1629
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14133.745475292206
  time_this_iter_s: 8.09256887435913
  time_total_s: 14133.745475292206
  timestamp: 1594870190
  timesteps_since_restore: 8145000
  timesteps_this_iter: 5000
  timesteps_total: 8145000
  training_iteration: 1629
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14133 s, 1629 iter, 8145000 ts, -5.83e+04 rew

agent-1: -6426.9064444416945
agent-2: -7157.101476807116
agent-3: -5012.358967243123
agent-4: -5026.498637398276
agent-5: -3308.6565621969517
Extrinsic Rewards:
-6251
-6972
-4872
-4875
-3211
Sum Reward: -26181
Avg Reward: -5236.2
Min Reward: -6972
Max Reward: -3211
Gini Coefficient: -0.13599174974217945
20:20 Ratio: 0.46055651176133106
Max-min Ratio: 0.46055651176133106
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-29-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -58419.56761657041
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1629
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.483
    dispatch_time_ms: 7.242
    learner:
      cur_lr: 0.0008175430120900273
      grad_gnorm: 39.99999237060547
      policy_entropy: 51.02524185180664
      policy_loss: 1777.9417724609375
      var_gnorm: 183.85792541503906
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 39401.55078125
    num_steps_sampled: 8150000
    num_steps_trained: 8150000
    wait_time_ms: 72.079
  iterations_since_restore: 1630
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14141.878876209259
  time_this_iter_s: 8.133400917053223
  time_total_s: 14141.878876209259
  timestamp: 1594870198
  timesteps_since_restore: 8150000
  timesteps_this_iter: 5000
  timesteps_total: 8150000
  training_iteration: 1630
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14141 s, 1630 iter, 8150000 ts, -5.84e+04 rew

agent-1: -4427.842576623061
agent-2: -4573.459304022883
agent-3: -3885.506085974899
agent-4: -2985.9426827431207
agent-5: -2636.7708986087714
Extrinsic Rewards:
-4257
-4405
-3720
-2881
-2519
Sum Reward: -17782
Avg Reward: -3556.4
Min Reward: -4405
Max Reward: -2519
Gini Coefficient: -0.11580249690698459
20:20 Ratio: 0.571850170261067
Max-min Ratio: 0.571850170261067
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-30-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -58411.35298817232
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1630
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.743
    dispatch_time_ms: 7.309
    learner:
      cur_lr: 0.0008172100060619414
      grad_gnorm: 40.0
      policy_entropy: 52.22749710083008
      policy_loss: 1788.875732421875
      var_gnorm: 183.5838165283203
      vf_explained_var: 0.0
      vf_loss: 50367.81640625
    num_steps_sampled: 8155000
    num_steps_trained: 8155000
    wait_time_ms: 71.822
  iterations_since_restore: 1631
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14150.077307462692
  time_this_iter_s: 8.198431253433228
  time_total_s: 14150.077307462692
  timestamp: 1594870207
  timesteps_since_restore: 8155000
  timesteps_this_iter: 5000
  timesteps_total: 8155000
  training_iteration: 1631
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14150 s, 1631 iter, 8155000 ts, -5.84e+04 rew

agent-1: -6135.795653217821
agent-2: -7886.134928053813
agent-3: -7247.446752014386
agent-4: -7051.703809046895
agent-5: -5989.409212541643
Extrinsic Rewards:
-6002
-7713
-7086
-6905
-5850
Sum Reward: -33556
Avg Reward: -6711.2
Min Reward: -7713
Max Reward: -5850
Gini Coefficient: -0.057336988914054116
20:20 Ratio: 0.7584597432905484
Max-min Ratio: 0.7584597432905484
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-30-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -58613.655208006676
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1631
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.233
    dispatch_time_ms: 7.943
    learner:
      cur_lr: 0.0008168770000338554
      grad_gnorm: 40.0
      policy_entropy: 46.77608871459961
      policy_loss: 1041.2783203125
      var_gnorm: 183.4495849609375
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 68210.6484375
    num_steps_sampled: 8160000
    num_steps_trained: 8160000
    wait_time_ms: 71.521
  iterations_since_restore: 1632
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14158.223922252655
  time_this_iter_s: 8.146614789962769
  time_total_s: 14158.223922252655
  timestamp: 1594870215
  timesteps_since_restore: 8160000
  timesteps_this_iter: 5000
  timesteps_total: 8160000
  training_iteration: 1632
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14158 s, 1632 iter, 8160000 ts, -5.86e+04 rew

agent-1: -5934.8118261485
agent-2: -7407.8153874925065
agent-3: -6116.830505014283
agent-4: -7832.904020687871
agent-5: -3893.7083658135925
Extrinsic Rewards:
-5785
-7236
-5963
-7651
-3795
Sum Reward: -30430
Avg Reward: -6086.0
Min Reward: -7651
Max Reward: -3795
Gini Coefficient: -0.12044692737430168
20:20 Ratio: 0.4960135929943798
Max-min Ratio: 0.4960135929943798
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-30-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -58740.2968529129
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1632
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.528
    dispatch_time_ms: 8.146
    learner:
      cur_lr: 0.0008165439940057695
      grad_gnorm: 39.999996185302734
      policy_entropy: 49.059776306152344
      policy_loss: -328.6466064453125
      var_gnorm: 183.08248901367188
      vf_explained_var: 0.0
      vf_loss: 52627.26953125
    num_steps_sampled: 8165000
    num_steps_trained: 8165000
    wait_time_ms: 70.28
  iterations_since_restore: 1633
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14166.346490383148
  time_this_iter_s: 8.122568130493164
  time_total_s: 14166.346490383148
  timestamp: 1594870223
  timesteps_since_restore: 8165000
  timesteps_this_iter: 5000
  timesteps_total: 8165000
  training_iteration: 1633
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14166 s, 1633 iter, 8165000 ts, -5.87e+04 rew

agent-1: -7651.838186971811
agent-2: -8857.56888729869
agent-3: -2922.243511338173
agent-4: -5014.526505089342
agent-5: -4524.882044788047
Extrinsic Rewards:
-7466
-8649
-2839
-4900
-4395
Sum Reward: -28249
Avg Reward: -5649.8
Min Reward: -8649
Max Reward: -2839
Gini Coefficient: -0.20802152288576586
20:20 Ratio: 0.3282460400046248
Max-min Ratio: 0.3282460400046248
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-30-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -58962.769961099584
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1633
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.565
    dispatch_time_ms: 8.501
    learner:
      cur_lr: 0.0008162109879776835
      grad_gnorm: 39.999996185302734
      policy_entropy: 55.81365203857422
      policy_loss: 2458.9580078125
      var_gnorm: 182.8185577392578
      vf_explained_var: 0.0
      vf_loss: 57754.3125
    num_steps_sampled: 8170000
    num_steps_trained: 8170000
    wait_time_ms: 71.829
  iterations_since_restore: 1634
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14174.482246160507
  time_this_iter_s: 8.135755777359009
  time_total_s: 14174.482246160507
  timestamp: 1594870231
  timesteps_since_restore: 8170000
  timesteps_this_iter: 5000
  timesteps_total: 8170000
  training_iteration: 1634
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14174 s, 1634 iter, 8170000 ts, -5.9e+04 rew

agent-1: -5610.826815268405
agent-2: -2256.4494260865827
agent-3: -3774.985354798214
agent-4: -5667.722944582279
agent-5: -7275.379860980805
Extrinsic Rewards:
-5455
-2187
-3641
-5495
-7089
Sum Reward: -23867
Avg Reward: -4773.4
Min Reward: -7089
Max Reward: -2187
Gini Coefficient: -0.1953827460510328
20:20 Ratio: 0.3085061362674566
Max-min Ratio: 0.3085061362674566
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-30-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6359.190995900226
  episode_reward_mean: -59118.15749235933
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1634
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.587
    dispatch_time_ms: 9.036
    learner:
      cur_lr: 0.0008158779819495976
      grad_gnorm: 40.0
      policy_entropy: 61.95237731933594
      policy_loss: -1662.353271484375
      var_gnorm: 182.65103149414062
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 93338.9453125
    num_steps_sampled: 8175000
    num_steps_trained: 8175000
    wait_time_ms: 72.691
  iterations_since_restore: 1635
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14182.665992975235
  time_this_iter_s: 8.183746814727783
  time_total_s: 14182.665992975235
  timestamp: 1594870239
  timesteps_since_restore: 8175000
  timesteps_this_iter: 5000
  timesteps_total: 8175000
  training_iteration: 1635
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14182 s, 1635 iter, 8175000 ts, -5.91e+04 rew

agent-1: -6397.586159741044
agent-2: -5931.16426847481
agent-3: -5647.2583889285415
agent-4: -6976.374243468897
agent-5: -4035.92771692196
Extrinsic Rewards:
-6240
-5769
-5501
-6808
-3931
Sum Reward: -28249
Avg Reward: -5649.8
Min Reward: -6808
Max Reward: -3931
Gini Coefficient: -0.09193953768274983
20:20 Ratio: 0.5774089306698003
Max-min Ratio: 0.5774089306698003
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-30-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6755.149342035144
  episode_reward_mean: -59344.44869017565
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1635
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.179
    dispatch_time_ms: 12.026
    learner:
      cur_lr: 0.0008155449759215117
      grad_gnorm: 39.999996185302734
      policy_entropy: 60.275962829589844
      policy_loss: -1007.3065795898438
      var_gnorm: 182.4397430419922
      vf_explained_var: 0.0
      vf_loss: 81751.875
    num_steps_sampled: 8180000
    num_steps_trained: 8180000
    wait_time_ms: 65.414
  iterations_since_restore: 1636
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14190.860047578812
  time_this_iter_s: 8.19405460357666
  time_total_s: 14190.860047578812
  timestamp: 1594870248
  timesteps_since_restore: 8180000
  timesteps_this_iter: 5000
  timesteps_total: 8180000
  training_iteration: 1636
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14190 s, 1636 iter, 8180000 ts, -5.93e+04 rew

agent-1: -10179.466246719112
agent-2: -8569.15172206548
agent-3: -6416.7676569578825
agent-4: -4426.1078337904655
agent-5: -9115.541992156863
Extrinsic Rewards:
-9992
-8420
-6272
-4335
-8939
Sum Reward: -37958
Avg Reward: -7591.6
Min Reward: -9992
Max Reward: -4335
Gini Coefficient: -0.14733126086727436
20:20 Ratio: 0.4338470776621297
Max-min Ratio: 0.4338470776621297
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-30-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -8624.734142833458
  episode_reward_mean: -59663.96755127222
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1636
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.165
    dispatch_time_ms: 8.38
    learner:
      cur_lr: 0.0008152120281010866
      grad_gnorm: 40.000003814697266
      policy_entropy: 50.816246032714844
      policy_loss: 1749.9488525390625
      var_gnorm: 182.1662139892578
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 51483.70703125
    num_steps_sampled: 8185000
    num_steps_trained: 8185000
    wait_time_ms: 69.712
  iterations_since_restore: 1637
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14198.99594426155
  time_this_iter_s: 8.135896682739258
  time_total_s: 14198.99594426155
  timestamp: 1594870256
  timesteps_since_restore: 8185000
  timesteps_this_iter: 5000
  timesteps_total: 8185000
  training_iteration: 1637
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14198 s, 1637 iter, 8185000 ts, -5.97e+04 rew

agent-1: -4257.368283194402
agent-2: -6574.908917212425
agent-3: -6848.130562817576
agent-4: -6688.56236782413
agent-5: -5311.091848244089
Extrinsic Rewards:
-4143
-6409
-6680
-6529
-5182
Sum Reward: -28943
Avg Reward: -5788.6
Min Reward: -6680
Max Reward: -4143
Gini Coefficient: -0.08873993711778323
20:20 Ratio: 0.6202095808383233
Max-min Ratio: 0.6202095808383233
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-31-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -11380.009626132265
  episode_reward_mean: -59874.52082963681
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1637
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.839
    dispatch_time_ms: 8.817
    learner:
      cur_lr: 0.0008148790220730007
      grad_gnorm: 40.0
      policy_entropy: 58.90498733520508
      policy_loss: 1400.2945556640625
      var_gnorm: 181.95387268066406
      vf_explained_var: 0.0
      vf_loss: 41494.3984375
    num_steps_sampled: 8190000
    num_steps_trained: 8190000
    wait_time_ms: 71.442
  iterations_since_restore: 1638
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14207.164011955261
  time_this_iter_s: 8.168067693710327
  time_total_s: 14207.164011955261
  timestamp: 1594870264
  timesteps_since_restore: 8190000
  timesteps_this_iter: 5000
  timesteps_total: 8190000
  training_iteration: 1638
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14207 s, 1638 iter, 8190000 ts, -5.99e+04 rew

agent-1: -4702.344582103879
agent-2: -6182.2682670077775
agent-3: -7204.395418811285
agent-4: -5781.722583593866
agent-5: -6251.179682282359
Extrinsic Rewards:
-4578
-6025
-7032
-5636
-6098
Sum Reward: -29369
Avg Reward: -5873.8
Min Reward: -7032
Max Reward: -4578
Gini Coefficient: -0.07313834315094146
20:20 Ratio: 0.6510238907849829
Max-min Ratio: 0.6510238907849829
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-31-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -60061.93983871348
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1638
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 4.17
    dispatch_time_ms: 8.595
    learner:
      cur_lr: 0.0008145460160449147
      grad_gnorm: 40.0
      policy_entropy: 60.37902069091797
      policy_loss: -1359.99560546875
      var_gnorm: 181.7073516845703
      vf_explained_var: 0.0
      vf_loss: 68280.984375
    num_steps_sampled: 8195000
    num_steps_trained: 8195000
    wait_time_ms: 66.298
  iterations_since_restore: 1639
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14215.260794639587
  time_this_iter_s: 8.096782684326172
  time_total_s: 14215.260794639587
  timestamp: 1594870272
  timesteps_since_restore: 8195000
  timesteps_this_iter: 5000
  timesteps_total: 8195000
  training_iteration: 1639
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14215 s, 1639 iter, 8195000 ts, -6.01e+04 rew

agent-1: -7530.319784107537
agent-2: -8245.641941994983
agent-3: -4315.171791732961
agent-4: -5432.7731978016745
agent-5: -7009.523181373559
Extrinsic Rewards:
-7365
-8055
-4204
-5304
-6858
Sum Reward: -31786
Avg Reward: -6357.2
Min Reward: -8055
Max Reward: -4204
Gini Coefficient: -0.12285912036745737
20:20 Ratio: 0.5219118559900683
Max-min Ratio: 0.5219118559900683
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-31-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -60235.59457478613
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1639
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.114
    dispatch_time_ms: 7.454
    learner:
      cur_lr: 0.0008142130100168288
      grad_gnorm: 40.0
      policy_entropy: 58.002872467041016
      policy_loss: -205.40567016601562
      var_gnorm: 181.56304931640625
      vf_explained_var: 0.0
      vf_loss: 55098.95703125
    num_steps_sampled: 8200000
    num_steps_trained: 8200000
    wait_time_ms: 69.197
  iterations_since_restore: 1640
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14223.510510444641
  time_this_iter_s: 8.249715805053711
  time_total_s: 14223.510510444641
  timestamp: 1594870280
  timesteps_since_restore: 8200000
  timesteps_this_iter: 5000
  timesteps_total: 8200000
  training_iteration: 1640
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14223 s, 1640 iter, 8200000 ts, -6.02e+04 rew

agent-1: -9186.746944409217
agent-2: -9327.985063553577
agent-3: -4309.105907461
agent-4: -5832.805820990864
agent-5: -6705.051831254905
Extrinsic Rewards:
-8996
-9145
-4210
-5706
-6575
Sum Reward: -34632
Avg Reward: -6926.4
Min Reward: -9145
Max Reward: -4210
Gini Coefficient: -0.151998151998152
20:20 Ratio: 0.46036085292509565
Max-min Ratio: 0.46036085292509565
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-31-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -60429.71672407894
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1640
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.926
    dispatch_time_ms: 7.696
    learner:
      cur_lr: 0.0008138800039887428
      grad_gnorm: 40.0
      policy_entropy: 60.611572265625
      policy_loss: 923.9811401367188
      var_gnorm: 181.50152587890625
      vf_explained_var: 0.0
      vf_loss: 32032.150390625
    num_steps_sampled: 8205000
    num_steps_trained: 8205000
    wait_time_ms: 67.935
  iterations_since_restore: 1641
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14231.744256019592
  time_this_iter_s: 8.233745574951172
  time_total_s: 14231.744256019592
  timestamp: 1594870289
  timesteps_since_restore: 8205000
  timesteps_this_iter: 5000
  timesteps_total: 8205000
  training_iteration: 1641
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14231 s, 1641 iter, 8205000 ts, -6.04e+04 rew

agent-1: -9764.50681407933
agent-2: -10420.486543897881
agent-3: -10823.97231544182
agent-4: -7358.394778157657
agent-5: -10518.639383403686
Extrinsic Rewards:
-9611
-10251
-10664
-7249
-10368
Sum Reward: -48143
Avg Reward: -9628.6
Min Reward: -10664
Max Reward: -7249
Gini Coefficient: -0.06303720167002472
20:20 Ratio: 0.6797636909227307
Max-min Ratio: 0.6797636909227307
agent-1: -9002.156574594352
agent-2: -5239.226433623121
agent-3: -9852.660301588561
agent-4: -9837.734995998377
agent-5: -7796.326792452984
Extrinsic Rewards:
-8841
-5148
-9679
-9655
-7654
Sum Reward: -40977
Avg Reward: -8195.4
Min Reward: -9679
Max Reward: -5148
Gini Coefficient: -0.10799228835688313
20:20 Ratio: 0.5318731273891931
Max-min Ratio: 0.5318731273891931
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-31-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -60959.35039887986
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 2
  episodes_total: 1642
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.049
    dispatch_time_ms: 7.624
    learner:
      cur_lr: 0.0008135469979606569
      grad_gnorm: 40.0
      policy_entropy: 59.19415283203125
      policy_loss: -262.6575927734375
      var_gnorm: 181.50608825683594
      vf_explained_var: -0.573894739151001
      vf_loss: 51925.046875
    num_steps_sampled: 8210000
    num_steps_trained: 8210000
    wait_time_ms: 71.309
  iterations_since_restore: 1642
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14240.00929760933
  time_this_iter_s: 8.265041589736938
  time_total_s: 14240.00929760933
  timestamp: 1594870297
  timesteps_since_restore: 8210000
  timesteps_this_iter: 5000
  timesteps_total: 8210000
  training_iteration: 1642
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14240 s, 1642 iter, 8210000 ts, -6.1e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-31-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -60959.35039887986
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 0
  episodes_total: 1642
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.449
    dispatch_time_ms: 7.403
    learner:
      cur_lr: 0.0008132139919325709
      grad_gnorm: 40.0
      policy_entropy: 59.25442886352539
      policy_loss: 1397.5277099609375
      var_gnorm: 181.42276000976562
      vf_explained_var: 0.0
      vf_loss: 41843.50390625
    num_steps_sampled: 8215000
    num_steps_trained: 8215000
    wait_time_ms: 73.57
  iterations_since_restore: 1643
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14248.227969646454
  time_this_iter_s: 8.218672037124634
  time_total_s: 14248.227969646454
  timestamp: 1594870305
  timesteps_since_restore: 8215000
  timesteps_this_iter: 5000
  timesteps_total: 8215000
  training_iteration: 1643
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14248 s, 1643 iter, 8215000 ts, -6.1e+04 rew

agent-1: -9076.3202329003
agent-2: -7868.924112901247
agent-3: -11392.38520903656
agent-4: -9066.82454279629
agent-5: -7076.177228737644
Extrinsic Rewards:
-8920
-7748
-11210
-8915
-6946
Sum Reward: -43739
Avg Reward: -8747.8
Min Reward: -11210
Max Reward: -6946
Gini Coefficient: -0.0887080180159583
20:20 Ratio: 0.6196253345227476
Max-min Ratio: 0.6196253345227476
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-31-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -61149.45381792895
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1643
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.744
    dispatch_time_ms: 7.058
    learner:
      cur_lr: 0.000812880985904485
      grad_gnorm: 40.0
      policy_entropy: 57.85091018676758
      policy_loss: -1632.3154296875
      var_gnorm: 181.21356201171875
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 68171.2578125
    num_steps_sampled: 8220000
    num_steps_trained: 8220000
    wait_time_ms: 70.63
  iterations_since_restore: 1644
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14256.316267728806
  time_this_iter_s: 8.088298082351685
  time_total_s: 14256.316267728806
  timestamp: 1594870313
  timesteps_since_restore: 8220000
  timesteps_this_iter: 5000
  timesteps_total: 8220000
  training_iteration: 1644
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14256 s, 1644 iter, 8220000 ts, -6.11e+04 rew

agent-1: -6076.985351539527
agent-2: -7242.775298444943
agent-3: -5928.839758209799
agent-4: -5226.965967640174
agent-5: -3305.0970948555882
Extrinsic Rewards:
-5910
-7060
-5785
-5092
-3216
Sum Reward: -27063
Avg Reward: -5412.6
Min Reward: -7060
Max Reward: -3216
Gini Coefficient: -0.12572146473044377
20:20 Ratio: 0.4555240793201133
Max-min Ratio: 0.4555240793201133
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-32-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -61085.10990730498
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1644
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.749
    dispatch_time_ms: 6.541
    learner:
      cur_lr: 0.000812547979876399
      grad_gnorm: 40.0
      policy_entropy: 60.760162353515625
      policy_loss: 1640.4271240234375
      var_gnorm: 181.08526611328125
      vf_explained_var: 0.0
      vf_loss: 35843.28515625
    num_steps_sampled: 8225000
    num_steps_trained: 8225000
    wait_time_ms: 73.523
  iterations_since_restore: 1645
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14264.531126022339
  time_this_iter_s: 8.214858293533325
  time_total_s: 14264.531126022339
  timestamp: 1594870322
  timesteps_since_restore: 8225000
  timesteps_this_iter: 5000
  timesteps_total: 8225000
  training_iteration: 1645
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14264 s, 1645 iter, 8225000 ts, -6.11e+04 rew

agent-1: -9703.126593459454
agent-2: -6622.236772537087
agent-3: -7395.33406758023
agent-4: -4026.731619960992
agent-5: -8477.71219283546
Extrinsic Rewards:
-9510
-6501
-7239
-3923
-8316
Sum Reward: -35489
Avg Reward: -7097.8
Min Reward: -9510
Max Reward: -3923
Gini Coefficient: -0.14640029304855026
20:20 Ratio: 0.4125131440588854
Max-min Ratio: 0.4125131440588854
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-32-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -61083.24339667804
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1645
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.7
    dispatch_time_ms: 7.449
    learner:
      cur_lr: 0.0008122149738483131
      grad_gnorm: 40.000003814697266
      policy_entropy: 60.997257232666016
      policy_loss: -261.07037353515625
      var_gnorm: 180.96902465820312
      vf_explained_var: 0.0
      vf_loss: 35521.21875
    num_steps_sampled: 8230000
    num_steps_trained: 8230000
    wait_time_ms: 76.414
  iterations_since_restore: 1646
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14272.797209501266
  time_this_iter_s: 8.266083478927612
  time_total_s: 14272.797209501266
  timestamp: 1594870330
  timesteps_since_restore: 8230000
  timesteps_this_iter: 5000
  timesteps_total: 8230000
  training_iteration: 1646
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14272 s, 1646 iter, 8230000 ts, -6.11e+04 rew

agent-1: -7467.109063971549
agent-2: -7852.845141645127
agent-3: -9210.259173832786
agent-4: -9720.855665374158
agent-5: -6071.075155872366
Extrinsic Rewards:
-7324
-7707
-9044
-9546
-5957
Sum Reward: -39578
Avg Reward: -7915.6
Min Reward: -9546
Max Reward: -5957
Gini Coefficient: -0.08992874829450705
20:20 Ratio: 0.624031007751938
Max-min Ratio: 0.624031007751938
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-32-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -61198.737963121144
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1646
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.092
    dispatch_time_ms: 6.911
    learner:
      cur_lr: 0.0008118820260278881
      grad_gnorm: 40.0
      policy_entropy: 56.78554153442383
      policy_loss: 2109.437744140625
      var_gnorm: 180.6865997314453
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 55878.578125
    num_steps_sampled: 8235000
    num_steps_trained: 8235000
    wait_time_ms: 71.903
  iterations_since_restore: 1647
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14280.886456251144
  time_this_iter_s: 8.08924674987793
  time_total_s: 14280.886456251144
  timestamp: 1594870338
  timesteps_since_restore: 8235000
  timesteps_this_iter: 5000
  timesteps_total: 8235000
  training_iteration: 1647
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14280 s, 1647 iter, 8235000 ts, -6.12e+04 rew

W0715 23:32:36.854488 22529 node_manager.cc:250] Last heartbeat was sent 2251 ms ago 
W0715 23:32:41.030117 22529 node_manager.cc:250] Last heartbeat was sent 1080 ms ago 
agent-1: -8047.539290671622
agent-2: -4922.483566206859
agent-3: -2895.0212956833825
agent-4: -6448.091713925697
agent-5: -7977.514808918673
Extrinsic Rewards:
-7874
-4787
-2809
-6308
-7793
Sum Reward: -29571
Avg Reward: -5914.2
Min Reward: -7874
Max Reward: -2809
Gini Coefficient: -0.17768759933718847
20:20 Ratio: 0.35674371348742695
Max-min Ratio: 0.35674371348742695
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-33-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -61079.13668496566
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1647
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.863
    dispatch_time_ms: 7.766
    learner:
      cur_lr: 0.0008115490199998021
      grad_gnorm: 40.0
      policy_entropy: 57.838401794433594
      policy_loss: 976.4033813476562
      var_gnorm: 180.53907775878906
      vf_explained_var: 0.0
      vf_loss: 38486.1875
    num_steps_sampled: 8240000
    num_steps_trained: 8240000
    wait_time_ms: 71.033
  iterations_since_restore: 1648
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14339.103514671326
  time_this_iter_s: 58.217058420181274
  time_total_s: 14339.103514671326
  timestamp: 1594870396
  timesteps_since_restore: 8240000
  timesteps_this_iter: 5000
  timesteps_total: 8240000
  training_iteration: 1648
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14339 s, 1648 iter, 8240000 ts, -6.11e+04 rew

agent-1: -6769.254335894704
agent-2: -6353.591082163474
agent-3: -7152.185309409719
agent-4: -6113.7592179578505
agent-5: -3743.5623347892442
Extrinsic Rewards:
-6603
-6191
-6981
-5966
-3655
Sum Reward: -29396
Avg Reward: -5879.2
Min Reward: -6981
Max Reward: -3655
Gini Coefficient: -0.09918356238944075
20:20 Ratio: 0.5235639593181493
Max-min Ratio: 0.5235639593181493
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-33-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -61052.34207737898
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1648
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.957
    dispatch_time_ms: 10.123
    learner:
      cur_lr: 0.0008112160139717162
      grad_gnorm: 40.0
      policy_entropy: 57.307701110839844
      policy_loss: 1639.5728759765625
      var_gnorm: 180.35096740722656
      vf_explained_var: 0.0
      vf_loss: 40197.359375
    num_steps_sampled: 8245000
    num_steps_trained: 8245000
    wait_time_ms: 68.373
  iterations_since_restore: 1649
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14347.298922300339
  time_this_iter_s: 8.195407629013062
  time_total_s: 14347.298922300339
  timestamp: 1594870405
  timesteps_since_restore: 8245000
  timesteps_this_iter: 5000
  timesteps_total: 8245000
  training_iteration: 1649
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14347 s, 1649 iter, 8245000 ts, -6.11e+04 rew

agent-1: -8951.418711515526
agent-2: -3424.825185425268
agent-3: -6816.287176760468
agent-4: -7586.288749476526
agent-5: -9273.30442904323
Extrinsic Rewards:
-8776
-3342
-6675
-7426
-9098
Sum Reward: -35317
Avg Reward: -7063.4
Min Reward: -9098
Max Reward: -3342
Gini Coefficient: -0.15418070617549623
20:20 Ratio: 0.36733347988568915
Max-min Ratio: 0.36733347988568915
agent-1: -9645.539463231702
agent-2: -2109.9991365954866
agent-3: -9519.777784083455
agent-4: -5618.985327590472
agent-5: -5264.940148411668
Extrinsic Rewards:
-9447
-2054
-9314
-5489
-5134
Sum Reward: -31438
Avg Reward: -6287.6
Min Reward: -9447
Max Reward: -2054
Gini Coefficient: -0.24131306062726637
20:20 Ratio: 0.21742352069440035
Max-min Ratio: 0.21742352069440035
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-33-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -60934.56331479708
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 2
  episodes_total: 1650
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.921
    dispatch_time_ms: 9.485
    learner:
      cur_lr: 0.0008108830079436302
      grad_gnorm: 39.999996185302734
      policy_entropy: 56.317779541015625
      policy_loss: 43303.8671875
      var_gnorm: 180.1317901611328
      vf_explained_var: 0.0
      vf_loss: 15120007.0
    num_steps_sampled: 8250000
    num_steps_trained: 8250000
    wait_time_ms: 69.293
  iterations_since_restore: 1650
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14367.745408296585
  time_this_iter_s: 20.446485996246338
  time_total_s: 14367.745408296585
  timestamp: 1594870425
  timesteps_since_restore: 8250000
  timesteps_this_iter: 5000
  timesteps_total: 8250000
  training_iteration: 1650
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14367 s, 1650 iter, 8250000 ts, -6.09e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-33-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -60934.56331479709
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 0
  episodes_total: 1650
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.529
    dispatch_time_ms: 6.982
    learner:
      cur_lr: 0.0008105500019155443
      grad_gnorm: 39.999996185302734
      policy_entropy: 51.97508239746094
      policy_loss: 1229.0289306640625
      var_gnorm: 179.7803955078125
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 57346.5390625
    num_steps_sampled: 8255000
    num_steps_trained: 8255000
    wait_time_ms: 74.502
  iterations_since_restore: 1651
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14375.894113779068
  time_this_iter_s: 8.14870548248291
  time_total_s: 14375.894113779068
  timestamp: 1594870433
  timesteps_since_restore: 8255000
  timesteps_this_iter: 5000
  timesteps_total: 8255000
  training_iteration: 1651
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14375 s, 1651 iter, 8255000 ts, -6.09e+04 rew

agent-1: -1868.5616962646723
agent-2: -6000.5520674693025
agent-3: -3982.987191876246
agent-4: -7468.275586720834
agent-5: -5749.89608864542
Extrinsic Rewards:
-1811
-5836
-3851
-7277
-5571
Sum Reward: -24346
Avg Reward: -4869.2
Min Reward: -7277
Max Reward: -1811
Gini Coefficient: -0.21222377392590158
20:20 Ratio: 0.24886629105400576
Max-min Ratio: 0.24886629105400576
agent-1: -3637.150993335158
agent-2: -5597.248952258009
agent-3: -6980.762652394136
agent-4: -3557.4755242566293
agent-5: -8309.609525342821
Extrinsic Rewards:
-3532
-5444
-6804
-3465
-8115
Sum Reward: -27360
Avg Reward: -5472.0
Min Reward: -8115
Max Reward: -3465
Gini Coefficient: -0.18380116959064327
20:20 Ratio: 0.4269870609981516
Max-min Ratio: 0.4269870609981516
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-34-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -61170.13918013998
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 2
  episodes_total: 1652
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.44
    dispatch_time_ms: 6.922
    learner:
      cur_lr: 0.0008102169958874583
      grad_gnorm: 39.999996185302734
      policy_entropy: 48.99837112426758
      policy_loss: -716.8949584960938
      var_gnorm: 179.51791381835938
      vf_explained_var: -0.1554933786392212
      vf_loss: 115566.2265625
    num_steps_sampled: 8260000
    num_steps_trained: 8260000
    wait_time_ms: 77.51
  iterations_since_restore: 1652
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14384.0961663723
  time_this_iter_s: 8.202052593231201
  time_total_s: 14384.0961663723
  timestamp: 1594870441
  timesteps_since_restore: 8260000
  timesteps_this_iter: 5000
  timesteps_total: 8260000
  training_iteration: 1652
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14384 s, 1652 iter, 8260000 ts, -6.12e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-34-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -61170.13918013997
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 0
  episodes_total: 1652
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.908
    dispatch_time_ms: 6.271
    learner:
      cur_lr: 0.0008098839898593724
      grad_gnorm: 40.000003814697266
      policy_entropy: 47.04846954345703
      policy_loss: 2134.74365234375
      var_gnorm: 179.2406768798828
      vf_explained_var: 0.0
      vf_loss: 54854.60546875
    num_steps_sampled: 8265000
    num_steps_trained: 8265000
    wait_time_ms: 72.898
  iterations_since_restore: 1653
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14392.161301374435
  time_this_iter_s: 8.06513500213623
  time_total_s: 14392.161301374435
  timestamp: 1594870450
  timesteps_since_restore: 8265000
  timesteps_this_iter: 5000
  timesteps_total: 8265000
  training_iteration: 1653
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14392 s, 1653 iter, 8265000 ts, -6.12e+04 rew

agent-1: -4313.935987358674
agent-2: -3275.188862939699
agent-3: -6438.947178139508
agent-4: -6784.416249031442
agent-5: -4269.985132270307
Extrinsic Rewards:
-4194
-3176
-6251
-6587
-4146
Sum Reward: -24354
Avg Reward: -4870.8
Min Reward: -6587
Max Reward: -3176
Gini Coefficient: -0.1466206783279954
20:20 Ratio: 0.48216183391528766
Max-min Ratio: 0.48216183391528766
agent-1: -6917.288038156958
agent-2: -6452.508819322644
agent-3: -2272.956187360431
agent-4: -5160.298662568277
agent-5: -3723.2804685821507
Extrinsic Rewards:
-6721
-6264
-2206
-5001
-3601
Sum Reward: -23793
Avg Reward: -4758.6
Min Reward: -6721
Max Reward: -2206
Gini Coefficient: -0.1965788257050393
20:20 Ratio: 0.3282249665228389
Max-min Ratio: 0.3282249665228389
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-34-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -61336.39779668583
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 2
  episodes_total: 1654
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.383
    dispatch_time_ms: 6.165
    learner:
      cur_lr: 0.0008095509838312864
      grad_gnorm: 40.0
      policy_entropy: 47.536258697509766
      policy_loss: 39591.91015625
      var_gnorm: 178.91688537597656
      vf_explained_var: -8.344650268554688e-07
      vf_loss: 16761796.0
    num_steps_sampled: 8270000
    num_steps_trained: 8270000
    wait_time_ms: 74.651
  iterations_since_restore: 1654
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14400.319340705872
  time_this_iter_s: 8.158039331436157
  time_total_s: 14400.319340705872
  timestamp: 1594870458
  timesteps_since_restore: 8270000
  timesteps_this_iter: 5000
  timesteps_total: 8270000
  training_iteration: 1654
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14400 s, 1654 iter, 8270000 ts, -6.13e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-34-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -61336.39779668584
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 0
  episodes_total: 1654
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.077
    dispatch_time_ms: 7.8
    learner:
      cur_lr: 0.0008092179778032005
      grad_gnorm: 40.00000762939453
      policy_entropy: 51.21800994873047
      policy_loss: 616.630615234375
      var_gnorm: 178.56666564941406
      vf_explained_var: 0.0
      vf_loss: 70598.515625
    num_steps_sampled: 8275000
    num_steps_trained: 8275000
    wait_time_ms: 70.536
  iterations_since_restore: 1655
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14408.437388658524
  time_this_iter_s: 8.118047952651978
  time_total_s: 14408.437388658524
  timestamp: 1594870466
  timesteps_since_restore: 8275000
  timesteps_this_iter: 5000
  timesteps_total: 8275000
  training_iteration: 1655
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14408 s, 1655 iter, 8275000 ts, -6.13e+04 rew

agent-1: -5934.530892516062
agent-2: -5933.865349798756
agent-3: -5329.971984326512
agent-4: -8186.725441423987
agent-5: -5891.244678767713
Extrinsic Rewards:
-5781
-5811
-5204
-7989
-5755
Sum Reward: -30540
Avg Reward: -6108.0
Min Reward: -7989
Max Reward: -5204
Gini Coefficient: -0.07368696791093647
20:20 Ratio: 0.6513956690449368
Max-min Ratio: 0.6513956690449368
agent-1: -6866.602209085241
agent-2: -4604.301848699348
agent-3: -5157.011203931782
agent-4: -4562.374168459814
agent-5: -6143.662488858923
Extrinsic Rewards:
-6696
-4469
-5013
-4449
-5985
Sum Reward: -26612
Avg Reward: -5322.4
Min Reward: -6696
Max Reward: -4449
Gini Coefficient: -0.09033518713362393
20:20 Ratio: 0.6644265232974911
Max-min Ratio: 0.6644265232974911
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-34-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -61348.87299875788
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 2
  episodes_total: 1656
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.464
    dispatch_time_ms: 9.245
    learner:
      cur_lr: 0.0008088849717751145
      grad_gnorm: 40.0
      policy_entropy: 48.63222122192383
      policy_loss: 31396.994140625
      var_gnorm: 178.37399291992188
      vf_explained_var: 0.0
      vf_loss: 15689620.0
    num_steps_sampled: 8280000
    num_steps_trained: 8280000
    wait_time_ms: 68.304
  iterations_since_restore: 1656
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14416.633259296417
  time_this_iter_s: 8.195870637893677
  time_total_s: 14416.633259296417
  timestamp: 1594870474
  timesteps_since_restore: 8280000
  timesteps_this_iter: 5000
  timesteps_total: 8280000
  training_iteration: 1656
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14416 s, 1656 iter, 8280000 ts, -6.13e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-34-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -61348.872998757884
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 0
  episodes_total: 1656
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.778
    dispatch_time_ms: 7.005
    learner:
      cur_lr: 0.0008085520239546895
      grad_gnorm: 40.0
      policy_entropy: 52.980613708496094
      policy_loss: 474.9808654785156
      var_gnorm: 178.2794647216797
      vf_explained_var: 0.0
      vf_loss: 62902.91015625
    num_steps_sampled: 8285000
    num_steps_trained: 8285000
    wait_time_ms: 76.277
  iterations_since_restore: 1657
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14424.891484498978
  time_this_iter_s: 8.258225202560425
  time_total_s: 14424.891484498978
  timestamp: 1594870482
  timesteps_since_restore: 8285000
  timesteps_this_iter: 5000
  timesteps_total: 8285000
  training_iteration: 1657
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14424 s, 1657 iter, 8285000 ts, -6.13e+04 rew

agent-1: -2134.4082856111813
agent-2: -9190.984060660834
agent-3: -9754.07916269804
agent-4: -10808.76612084376
agent-5: -6655.288966831864
Extrinsic Rewards:
-2085
-9040
-9568
-10626
-6521
Sum Reward: -37840
Avg Reward: -7568.0
Min Reward: -10626
Max Reward: -2085
Gini Coefficient: -0.21278012684989428
20:20 Ratio: 0.19621682665160925
Max-min Ratio: 0.19621682665160925
agent-1: -11928.58390796053
agent-2: -9643.095880873232
agent-3: -6059.067343008784
agent-4: -6126.642117268494
agent-5: -12386.28932720175
Extrinsic Rewards:
-11746
-9484
-5957
-6020
-12205
Sum Reward: -45412
Avg Reward: -9082.4
Min Reward: -12205
Max Reward: -5957
Gini Coefficient: -0.16050383158636483
20:20 Ratio: 0.4880786562884064
Max-min Ratio: 0.4880786562884064
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-34-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -61731.20168648241
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 2
  episodes_total: 1658
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.759
    dispatch_time_ms: 9.004
    learner:
      cur_lr: 0.0008082190179266036
      grad_gnorm: 39.999996185302734
      policy_entropy: 52.78104782104492
      policy_loss: 39842.95703125
      var_gnorm: 178.2283172607422
      vf_explained_var: 0.0
      vf_loss: 14773771.0
    num_steps_sampled: 8290000
    num_steps_trained: 8290000
    wait_time_ms: 71.589
  iterations_since_restore: 1658
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14433.140389919281
  time_this_iter_s: 8.248905420303345
  time_total_s: 14433.140389919281
  timestamp: 1594870491
  timesteps_since_restore: 8290000
  timesteps_this_iter: 5000
  timesteps_total: 8290000
  training_iteration: 1658
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14433 s, 1658 iter, 8290000 ts, -6.17e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-34-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -61731.20168648241
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 0
  episodes_total: 1658
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.528
    dispatch_time_ms: 9.076
    learner:
      cur_lr: 0.0008078860118985176
      grad_gnorm: 40.000003814697266
      policy_entropy: 53.47049331665039
      policy_loss: 2260.585205078125
      var_gnorm: 178.2050018310547
      vf_explained_var: 0.0
      vf_loss: 45567.75
    num_steps_sampled: 8295000
    num_steps_trained: 8295000
    wait_time_ms: 71.517
  iterations_since_restore: 1659
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14441.441722393036
  time_this_iter_s: 8.301332473754883
  time_total_s: 14441.441722393036
  timestamp: 1594870499
  timesteps_since_restore: 8295000
  timesteps_this_iter: 5000
  timesteps_total: 8295000
  training_iteration: 1659
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14441 s, 1659 iter, 8295000 ts, -6.17e+04 rew

agent-1: -3743.5061351180884
agent-2: -15176.400901233099
agent-3: -15497.310076122101
agent-4: -18181.00431876455
agent-5: -10695.172285526345
Extrinsic Rewards:
-3671
-14992
-15333
-18002
-10578
Sum Reward: -62576
Avg Reward: -12515.2
Min Reward: -18002
Max Reward: -3671
Gini Coefficient: -0.2136090513935055
20:20 Ratio: 0.2039217864681702
Max-min Ratio: 0.2039217864681702
agent-1: -6950.718522482947
agent-2: -7492.723242495733
agent-3: -14454.847243663873
agent-4: -7463.567044911011
agent-5: -12062.723953141809
Extrinsic Rewards:
-6852
-7376
-14253
-7346
-11883
Sum Reward: -47710
Avg Reward: -9542.0
Min Reward: -14253
Max Reward: -6852
Gini Coefficient: -0.16213791657933346
20:20 Ratio: 0.48074089665333614
Max-min Ratio: 0.48074089665333614
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-35-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -62299.092240187245
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 2
  episodes_total: 1660
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.57
    dispatch_time_ms: 9.218
    learner:
      cur_lr: 0.0008075530058704317
      grad_gnorm: 40.0
      policy_entropy: 50.03760528564453
      policy_loss: -1459.83203125
      var_gnorm: 178.3716278076172
      vf_explained_var: -0.170562744140625
      vf_loss: 238897.3125
    num_steps_sampled: 8300000
    num_steps_trained: 8300000
    wait_time_ms: 70.629
  iterations_since_restore: 1660
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14449.707875728607
  time_this_iter_s: 8.266153335571289
  time_total_s: 14449.707875728607
  timestamp: 1594870507
  timesteps_since_restore: 8300000
  timesteps_this_iter: 5000
  timesteps_total: 8300000
  training_iteration: 1660
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14449 s, 1660 iter, 8300000 ts, -6.23e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-35-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -62299.092240187245
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 0
  episodes_total: 1660
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.674
    dispatch_time_ms: 8.12
    learner:
      cur_lr: 0.0008072199998423457
      grad_gnorm: 40.0
      policy_entropy: 50.082149505615234
      policy_loss: 1750.95068359375
      var_gnorm: 178.70741271972656
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 44921.0859375
    num_steps_sampled: 8305000
    num_steps_trained: 8305000
    wait_time_ms: 74.152
  iterations_since_restore: 1661
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14457.873264789581
  time_this_iter_s: 8.165389060974121
  time_total_s: 14457.873264789581
  timestamp: 1594870516
  timesteps_since_restore: 8305000
  timesteps_this_iter: 5000
  timesteps_total: 8305000
  training_iteration: 1661
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14457 s, 1661 iter, 8305000 ts, -6.23e+04 rew

agent-1: -11638.4210694965
agent-2: -16369.671663008612
agent-3: -17107.397699507972
agent-4: -7818.025552901009
agent-5: -14400.448195716297
Extrinsic Rewards:
-11508
-16201
-16924
-7734
-14252
Sum Reward: -66619
Avg Reward: -13323.8
Min Reward: -16924
Max Reward: -7734
Gini Coefficient: -0.13853705399360544
20:20 Ratio: 0.4569841645001182
Max-min Ratio: 0.4569841645001182
agent-1: -10684.11308796891
agent-2: -8266.295186145506
agent-3: -24218.426209893445
agent-4: -20946.868181189628
agent-5: -19460.14189302294
Extrinsic Rewards:
-10592
-8179
-24024
-20763
-19300
Sum Reward: -82858
Avg Reward: -16571.6
Min Reward: -24024
Max Reward: -8179
Gini Coefficient: -0.2020854956672862
20:20 Ratio: 0.3404512154512154
Max-min Ratio: 0.3404512154512154
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-35-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -63295.040088913396
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 2
  episodes_total: 1662
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.54
    dispatch_time_ms: 6.123
    learner:
      cur_lr: 0.0008068869938142598
      grad_gnorm: 40.0
      policy_entropy: 45.950103759765625
      policy_loss: 30403.48046875
      var_gnorm: 178.97903442382812
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 13363540.0
    num_steps_sampled: 8310000
    num_steps_trained: 8310000
    wait_time_ms: 77.177
  iterations_since_restore: 1662
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14466.198996305466
  time_this_iter_s: 8.3257315158844
  time_total_s: 14466.198996305466
  timestamp: 1594870524
  timesteps_since_restore: 8310000
  timesteps_this_iter: 5000
  timesteps_total: 8310000
  training_iteration: 1662
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14466 s, 1662 iter, 8310000 ts, -6.33e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-35-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -63295.040088913396
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 0
  episodes_total: 1662
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.698
    dispatch_time_ms: 7.615
    learner:
      cur_lr: 0.0008065539877861738
      grad_gnorm: 39.999996185302734
      policy_entropy: 44.68812561035156
      policy_loss: -367.5340576171875
      var_gnorm: 179.0094451904297
      vf_explained_var: 0.0
      vf_loss: 100869.1953125
    num_steps_sampled: 8315000
    num_steps_trained: 8315000
    wait_time_ms: 76.427
  iterations_since_restore: 1663
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14474.432153701782
  time_this_iter_s: 8.233157396316528
  time_total_s: 14474.432153701782
  timestamp: 1594870532
  timesteps_since_restore: 8315000
  timesteps_this_iter: 5000
  timesteps_total: 8315000
  training_iteration: 1663
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14474 s, 1663 iter, 8315000 ts, -6.33e+04 rew

agent-1: -6739.746279799566
agent-2: -9998.022692066861
agent-3: -9524.010335798368
agent-4: -8680.595715830343
agent-5: -4972.29869196312
Extrinsic Rewards:
-6612
-9839
-9358
-8528
-4876
Sum Reward: -39213
Avg Reward: -7842.6
Min Reward: -9839
Max Reward: -4876
Gini Coefficient: -0.1292632545329355
20:20 Ratio: 0.4955788189856693
Max-min Ratio: 0.4955788189856693
agent-1: -9415.771592665422
agent-2: -9656.285801197466
agent-3: -10544.93342956057
agent-4: -9713.035856630411
agent-5: -11237.186415123891
Extrinsic Rewards:
-9278
-9513
-10384
-9582
-11082
Sum Reward: -49839
Avg Reward: -9967.8
Min Reward: -11082
Max Reward: -9278
Gini Coefficient: -0.035947751760669354
20:20 Ratio: 0.8372134993683451
Max-min Ratio: 0.8372134993683451
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-35-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -63592.826893416954
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 2
  episodes_total: 1664
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.998
    dispatch_time_ms: 9.284
    learner:
      cur_lr: 0.0008062209817580879
      grad_gnorm: 40.0
      policy_entropy: 37.02286148071289
      policy_loss: 35199.0703125
      var_gnorm: 178.98484802246094
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 13295620.0
    num_steps_sampled: 8320000
    num_steps_trained: 8320000
    wait_time_ms: 69.472
  iterations_since_restore: 1664
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14482.593622922897
  time_this_iter_s: 8.161469221115112
  time_total_s: 14482.593622922897
  timestamp: 1594870540
  timesteps_since_restore: 8320000
  timesteps_this_iter: 5000
  timesteps_total: 8320000
  training_iteration: 1664
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14482 s, 1664 iter, 8320000 ts, -6.36e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-35-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -63592.826893416954
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 0
  episodes_total: 1664
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.791
    dispatch_time_ms: 8.497
    learner:
      cur_lr: 0.0008058879757300019
      grad_gnorm: 40.0
      policy_entropy: 36.52360916137695
      policy_loss: -1367.6636962890625
      var_gnorm: 178.66842651367188
      vf_explained_var: 0.0
      vf_loss: 222270.859375
    num_steps_sampled: 8325000
    num_steps_trained: 8325000
    wait_time_ms: 72.943
  iterations_since_restore: 1665
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14490.749712228775
  time_this_iter_s: 8.156089305877686
  time_total_s: 14490.749712228775
  timestamp: 1594870549
  timesteps_since_restore: 8325000
  timesteps_this_iter: 5000
  timesteps_total: 8325000
  training_iteration: 1665
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14490 s, 1665 iter, 8325000 ts, -6.36e+04 rew

agent-1: -5227.727639000374
agent-2: -5468.618621971118
agent-3: -7260.466694244164
agent-4: -1560.2379865927253
agent-5: -6347.128400577156
Extrinsic Rewards:
-5083
-5315
-7070
-1508
-6180
Sum Reward: -25156
Avg Reward: -5031.2
Min Reward: -7070
Max Reward: -1508
Gini Coefficient: -0.19432342184767054
20:20 Ratio: 0.21329561527581328
Max-min Ratio: 0.21329561527581328
agent-1: -833.5931345304878
agent-2: -2326.133441474803
agent-3: -6590.799424539616
agent-4: -8176.397251213262
agent-5: -7718.060734661059
Extrinsic Rewards:
-809
-2257
-6413
-7970
-7516
Sum Reward: -24965
Avg Reward: -4993.0
Min Reward: -7970
Max Reward: -809
Gini Coefficient: -0.31373522932104947
20:20 Ratio: 0.1015056461731493
Max-min Ratio: 0.1015056461731493
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-35-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -62582.441033711286
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 2
  episodes_total: 1666
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.184
    dispatch_time_ms: 7.46
    learner:
      cur_lr: 0.0008055550279095769
      grad_gnorm: 40.0
      policy_entropy: 36.221500396728516
      policy_loss: 32296.78515625
      var_gnorm: 178.36758422851562
      vf_explained_var: 2.980232238769531e-07
      vf_loss: 15275843.0
    num_steps_sampled: 8330000
    num_steps_trained: 8330000
    wait_time_ms: 69.926
  iterations_since_restore: 1666
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14498.829286575317
  time_this_iter_s: 8.079574346542358
  time_total_s: 14498.829286575317
  timestamp: 1594870557
  timesteps_since_restore: 8330000
  timesteps_this_iter: 5000
  timesteps_total: 8330000
  training_iteration: 1666
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14498 s, 1666 iter, 8330000 ts, -6.26e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-36-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -62582.441033711286
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 0
  episodes_total: 1666
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.555
    dispatch_time_ms: 8.717
    learner:
      cur_lr: 0.000805222021881491
      grad_gnorm: 40.0
      policy_entropy: 31.321290969848633
      policy_loss: 1668.8045654296875
      var_gnorm: 178.06332397460938
      vf_explained_var: 0.0
      vf_loss: 57201.18359375
    num_steps_sampled: 8335000
    num_steps_trained: 8335000
    wait_time_ms: 69.912
  iterations_since_restore: 1667
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14506.954087018967
  time_this_iter_s: 8.124800443649292
  time_total_s: 14506.954087018967
  timestamp: 1594870565
  timesteps_since_restore: 8335000
  timesteps_this_iter: 5000
  timesteps_total: 8335000
  training_iteration: 1667
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14506 s, 1667 iter, 8335000 ts, -6.26e+04 rew

agent-1: -2676.714972587846
agent-2: -6251.403170741381
agent-3: -6475.888323888108
agent-4: -1586.0493809762174
agent-5: -5115.761141269525
Extrinsic Rewards:
-2585
-6078
-6274
-1521
-4958
Sum Reward: -21416
Avg Reward: -4283.2
Min Reward: -6274
Max Reward: -1521
Gini Coefficient: -0.24279043705640643
20:20 Ratio: 0.24242907236212943
Max-min Ratio: 0.24242907236212943
agent-1: -2359.7306339534034
agent-2: -5258.654495093582
agent-3: -8081.100508277978
agent-4: -3704.410659781302
agent-5: -2038.4371023934732
Extrinsic Rewards:
-2272
-5081
-7868
-3580
-1950
Sum Reward: -20751
Avg Reward: -4150.2
Min Reward: -7868
Max Reward: -1950
Gini Coefficient: -0.2822996482097248
20:20 Ratio: 0.2478393492628368
Max-min Ratio: 0.2478393492628368
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-36-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -61017.08745667005
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 2
  episodes_total: 1668
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.633
    dispatch_time_ms: 8.419
    learner:
      cur_lr: 0.000804889015853405
      grad_gnorm: 40.0
      policy_entropy: 32.72356033325195
      policy_loss: 30441.619140625
      var_gnorm: 177.67340087890625
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 15235106.0
    num_steps_sampled: 8340000
    num_steps_trained: 8340000
    wait_time_ms: 71.624
  iterations_since_restore: 1668
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14515.119378328323
  time_this_iter_s: 8.16529130935669
  time_total_s: 14515.119378328323
  timestamp: 1594870573
  timesteps_since_restore: 8340000
  timesteps_this_iter: 5000
  timesteps_total: 8340000
  training_iteration: 1668
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14515 s, 1668 iter, 8340000 ts, -6.1e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-36-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -61017.08745667005
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 0
  episodes_total: 1668
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.413
    dispatch_time_ms: 8.27
    learner:
      cur_lr: 0.000804556009825319
      grad_gnorm: 40.00000762939453
      policy_entropy: 43.1541748046875
      policy_loss: 1737.2076416015625
      var_gnorm: 177.43789672851562
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 39490.12890625
    num_steps_sampled: 8345000
    num_steps_trained: 8345000
    wait_time_ms: 72.249
  iterations_since_restore: 1669
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14523.242514133453
  time_this_iter_s: 8.123135805130005
  time_total_s: 14523.242514133453
  timestamp: 1594870581
  timesteps_since_restore: 8345000
  timesteps_this_iter: 5000
  timesteps_total: 8345000
  training_iteration: 1669
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14523 s, 1669 iter, 8345000 ts, -6.1e+04 rew

agent-1: -3492.269470334568
agent-2: -8849.458566098801
agent-3: -7091.6380982390065
agent-4: -7195.096162888299
agent-5: -10947.400525891471
Extrinsic Rewards:
-3423
-8665
-6960
-7062
-10753
Sum Reward: -36863
Avg Reward: -7372.6
Min Reward: -10753
Max Reward: -3423
Gini Coefficient: -0.17757643165233433
20:20 Ratio: 0.31832976843671534
Max-min Ratio: 0.31832976843671534
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-36-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -60174.14272167129
  episode_reward_min: -141340.5356653507
  episodes_this_iter: 1
  episodes_total: 1669
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.473
    dispatch_time_ms: 15.95
    learner:
      cur_lr: 0.0008042230037972331
      grad_gnorm: 40.0
      policy_entropy: 40.41309356689453
      policy_loss: -1125.111572265625
      var_gnorm: 177.34320068359375
      vf_explained_var: 0.0
      vf_loss: 123967.0859375
    num_steps_sampled: 8350000
    num_steps_trained: 8350000
    wait_time_ms: 67.733
  iterations_since_restore: 1670
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14531.639435768127
  time_this_iter_s: 8.396921634674072
  time_total_s: 14531.639435768127
  timestamp: 1594870590
  timesteps_since_restore: 8350000
  timesteps_this_iter: 5000
  timesteps_total: 8350000
  training_iteration: 1670
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14531 s, 1670 iter, 8350000 ts, -6.02e+04 rew

agent-1: -9262.814512769932
agent-2: -4480.418043000212
agent-3: -5120.443722213576
agent-4: -3298.406592261566
agent-5: -10529.37731537853
Extrinsic Rewards:
-9066
-4374
-4991
-3215
-10324
Sum Reward: -31970
Avg Reward: -6394.0
Min Reward: -10324
Max Reward: -3215
Gini Coefficient: -0.2365968095089146
20:20 Ratio: 0.3114103060829136
Max-min Ratio: 0.3114103060829136
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-36-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -59087.65196687402
  episode_reward_min: -139647.68903904976
  episodes_this_iter: 1
  episodes_total: 1670
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.772
    dispatch_time_ms: 17.222
    learner:
      cur_lr: 0.0008038899977691472
      grad_gnorm: 40.0
      policy_entropy: 36.06148147583008
      policy_loss: 572.5670166015625
      var_gnorm: 177.3160400390625
      vf_explained_var: 0.0
      vf_loss: 40871.71484375
    num_steps_sampled: 8355000
    num_steps_trained: 8355000
    wait_time_ms: 67.987
  iterations_since_restore: 1671
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14540.122689962387
  time_this_iter_s: 8.483254194259644
  time_total_s: 14540.122689962387
  timestamp: 1594870598
  timesteps_since_restore: 8355000
  timesteps_this_iter: 5000
  timesteps_total: 8355000
  training_iteration: 1671
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14540 s, 1671 iter, 8355000 ts, -5.91e+04 rew

agent-1: -8263.667043243116
agent-2: -3723.2515509603195
agent-3: -8755.09956559696
agent-4: -6221.891774003019
agent-5: -11596.068596260036
Extrinsic Rewards:
-8105
-3648
-8591
-6098
-11392
Sum Reward: -37834
Avg Reward: -7566.8
Min Reward: -11392
Max Reward: -3648
Gini Coefficient: -0.19010413913411217
20:20 Ratio: 0.3202247191011236
Max-min Ratio: 0.3202247191011236
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-36-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -58487.11550321444
  episode_reward_min: -139647.68903904976
  episodes_this_iter: 1
  episodes_total: 1671
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.352
    dispatch_time_ms: 23.785
    learner:
      cur_lr: 0.0008035569917410612
      grad_gnorm: 40.0
      policy_entropy: 33.02165985107422
      policy_loss: 79.7467041015625
      var_gnorm: 177.10763549804688
      vf_explained_var: -0.18483614921569824
      vf_loss: 44632.54296875
    num_steps_sampled: 8360000
    num_steps_trained: 8360000
    wait_time_ms: 58.844
  iterations_since_restore: 1672
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14548.59254860878
  time_this_iter_s: 8.469858646392822
  time_total_s: 14548.59254860878
  timestamp: 1594870607
  timesteps_since_restore: 8360000
  timesteps_this_iter: 5000
  timesteps_total: 8360000
  training_iteration: 1672
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14548 s, 1672 iter, 8360000 ts, -5.85e+04 rew

agent-1: -9806.518980724552
agent-2: -10105.329179895274
agent-3: -3471.083578187007
agent-4: -4501.9717749298425
agent-5: -6535.929472402513
Extrinsic Rewards:
-9607
-9915
-3388
-4408
-6394
Sum Reward: -33712
Avg Reward: -6742.4
Min Reward: -9915
Max Reward: -3388
Gini Coefficient: -0.21657570004746085
20:20 Ratio: 0.3417044881492688
Max-min Ratio: 0.3417044881492688
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-36-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -57988.40957282411
  episode_reward_min: -139647.68903904976
  episodes_this_iter: 1
  episodes_total: 1672
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.115
    dispatch_time_ms: 15.021
    learner:
      cur_lr: 0.0008032239857129753
      grad_gnorm: 40.0
      policy_entropy: 29.823688507080078
      policy_loss: 411.9775390625
      var_gnorm: 176.69261169433594
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 30013.955078125
    num_steps_sampled: 8365000
    num_steps_trained: 8365000
    wait_time_ms: 66.96
  iterations_since_restore: 1673
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14556.978859186172
  time_this_iter_s: 8.386310577392578
  time_total_s: 14556.978859186172
  timestamp: 1594870615
  timesteps_since_restore: 8365000
  timesteps_this_iter: 5000
  timesteps_total: 8365000
  training_iteration: 1673
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14556 s, 1673 iter, 8365000 ts, -5.8e+04 rew

agent-1: -5289.800547202862
agent-2: -3061.284533301525
agent-3: -5201.7813063396525
agent-4: -2878.7138767326533
agent-5: -5002.071026013781
Extrinsic Rewards:
-5125
-2936
-5029
-2825
-4830
Sum Reward: -20745
Avg Reward: -4149.0
Min Reward: -5125
Max Reward: -2825
Gini Coefficient: -0.1290527838033261
20:20 Ratio: 0.551219512195122
Max-min Ratio: 0.551219512195122
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-37-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -57696.589527376535
  episode_reward_min: -139647.68903904976
  episodes_this_iter: 1
  episodes_total: 1673
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.891
    dispatch_time_ms: 35.674
    learner:
      cur_lr: 0.0008028909796848893
      grad_gnorm: 40.00000762939453
      policy_entropy: 42.69869613647461
      policy_loss: 190.25067138671875
      var_gnorm: 176.3650665283203
      vf_explained_var: -0.46507394313812256
      vf_loss: 72026.890625
    num_steps_sampled: 8370000
    num_steps_trained: 8370000
    wait_time_ms: 53.903
  iterations_since_restore: 1674
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14565.54517030716
  time_this_iter_s: 8.566311120986938
  time_total_s: 14565.54517030716
  timestamp: 1594870624
  timesteps_since_restore: 8370000
  timesteps_this_iter: 5000
  timesteps_total: 8370000
  training_iteration: 1674
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14565 s, 1674 iter, 8370000 ts, -5.77e+04 rew

agent-1: -4429.703745034631
agent-2: -4632.614729927836
agent-3: -4696.807998497124
agent-4: -4235.369984355691
agent-5: -2345.147546275662
Extrinsic Rewards:
-4286
-4476
-4538
-4103
-2239
Sum Reward: -19642
Avg Reward: -3928.4
Min Reward: -4538
Max Reward: -2239
Gini Coefficient: -0.101232053762346
20:20 Ratio: 0.49338915821947993
Max-min Ratio: 0.49338915821947993
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-37-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -57085.50017390622
  episode_reward_min: -139647.68903904976
  episodes_this_iter: 1
  episodes_total: 1674
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.21
    dispatch_time_ms: 41.809
    learner:
      cur_lr: 0.0008025579736568034
      grad_gnorm: 40.0
      policy_entropy: 40.553611755371094
      policy_loss: -1788.920654296875
      var_gnorm: 176.36471557617188
      vf_explained_var: 0.0
      vf_loss: 260058.9375
    num_steps_sampled: 8375000
    num_steps_trained: 8375000
    wait_time_ms: 35.079
  iterations_since_restore: 1675
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14574.792795181274
  time_this_iter_s: 9.24762487411499
  time_total_s: 14574.792795181274
  timestamp: 1594870633
  timesteps_since_restore: 8375000
  timesteps_this_iter: 5000
  timesteps_total: 8375000
  training_iteration: 1675
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14574 s, 1675 iter, 8375000 ts, -5.71e+04 rew

agent-1: -7558.446351049509
agent-2: -2065.6459312682764
agent-3: -16177.831381677106
agent-4: -18699.626744129255
agent-5: -16030.245558959296
Extrinsic Rewards:
-7454
-2029
-15991
-18495
-15859
Sum Reward: -59828
Avg Reward: -11965.6
Min Reward: -18495
Max Reward: -2029
Gini Coefficient: -0.2772547970849769
20:20 Ratio: 0.10970532576371993
Max-min Ratio: 0.10970532576371993
agent-1: -21540.576802709336
agent-2: -13245.736079166192
agent-3: -3167.608571343637
agent-4: -10206.807149284716
agent-5: -4049.9029026563585
Extrinsic Rewards:
-21305
-13072
-3109
-10048
-4005
Sum Reward: -51539
Avg Reward: -10307.8
Min Reward: -21305
Max Reward: -3109
Gini Coefficient: -0.35281243330293566
20:20 Ratio: 0.14592818587186107
Max-min Ratio: 0.14592818587186107
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-37-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -56152.73657989448
  episode_reward_min: -139647.68903904976
  episodes_this_iter: 2
  episodes_total: 1676
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.898
    dispatch_time_ms: 24.293
    learner:
      cur_lr: 0.0008022250258363783
      grad_gnorm: 40.0
      policy_entropy: 44.54106903076172
      policy_loss: 34921.171875
      var_gnorm: 176.57827758789062
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 13064623.0
    num_steps_sampled: 8380000
    num_steps_trained: 8380000
    wait_time_ms: 63.328
  iterations_since_restore: 1676
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14583.365035533905
  time_this_iter_s: 8.572240352630615
  time_total_s: 14583.365035533905
  timestamp: 1594870642
  timesteps_since_restore: 8380000
  timesteps_this_iter: 5000
  timesteps_total: 8380000
  training_iteration: 1676
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14583 s, 1676 iter, 8380000 ts, -5.62e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-37-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -56152.73657989447
  episode_reward_min: -139647.68903904976
  episodes_this_iter: 0
  episodes_total: 1676
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.407
    dispatch_time_ms: 35.419
    learner:
      cur_lr: 0.0008018920198082924
      grad_gnorm: 40.0
      policy_entropy: 46.532779693603516
      policy_loss: -2845.8935546875
      var_gnorm: 176.79061889648438
      vf_explained_var: 0.0
      vf_loss: 139220.28125
    num_steps_sampled: 8385000
    num_steps_trained: 8385000
    wait_time_ms: 55.472
  iterations_since_restore: 1677
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14592.247433185577
  time_this_iter_s: 8.882397651672363
  time_total_s: 14592.247433185577
  timestamp: 1594870650
  timesteps_since_restore: 8385000
  timesteps_this_iter: 5000
  timesteps_total: 8385000
  training_iteration: 1677
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14592 s, 1677 iter, 8385000 ts, -5.62e+04 rew

agent-1: -9181.430515452988
agent-2: -10744.830972927217
agent-3: -13213.592291157162
agent-4: -10240.431007943082
agent-5: -10592.122829509444
Extrinsic Rewards:
-9058
-10598
-13046
-10109
-10440
Sum Reward: -53251
Avg Reward: -10650.2
Min Reward: -13046
Max Reward: -9058
Gini Coefficient: -0.06358566036318566
20:20 Ratio: 0.6943124329296336
Max-min Ratio: 0.6943124329296336
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-37-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -55618.70663389421
  episode_reward_min: -139647.68903904976
  episodes_this_iter: 1
  episodes_total: 1677
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.845
    dispatch_time_ms: 7.56
    learner:
      cur_lr: 0.0008015590137802064
      grad_gnorm: 40.0
      policy_entropy: 45.529319763183594
      policy_loss: -3385.74560546875
      var_gnorm: 176.92892456054688
      vf_explained_var: 0.0
      vf_loss: 410575.65625
    num_steps_sampled: 8390000
    num_steps_trained: 8390000
    wait_time_ms: 71.237
  iterations_since_restore: 1678
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14603.714726924896
  time_this_iter_s: 11.467293739318848
  time_total_s: 14603.714726924896
  timestamp: 1594870662
  timesteps_since_restore: 8390000
  timesteps_this_iter: 5000
  timesteps_total: 8390000
  training_iteration: 1678
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14603 s, 1678 iter, 8390000 ts, -5.56e+04 rew

agent-1: -16086.089161334708
agent-2: -13164.316492561104
agent-3: -17188.546385192723
agent-4: -18374.110399461508
agent-5: -5256.665168213775
Extrinsic Rewards:
-15920
-13020
-17015
-18193
-5199
Sum Reward: -69347
Avg Reward: -13869.4
Min Reward: -18193
Max Reward: -5199
Gini Coefficient: -0.1729447560817339
20:20 Ratio: 0.2857692519100753
Max-min Ratio: 0.2857692519100753
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-37-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -55309.00459761752
  episode_reward_min: -139647.68903904976
  episodes_this_iter: 1
  episodes_total: 1678
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.708
    dispatch_time_ms: 7.347
    learner:
      cur_lr: 0.0008012260077521205
      grad_gnorm: 40.0
      policy_entropy: 46.287445068359375
      policy_loss: -1155.1402587890625
      var_gnorm: 177.10162353515625
      vf_explained_var: 0.0
      vf_loss: 161273.546875
    num_steps_sampled: 8395000
    num_steps_trained: 8395000
    wait_time_ms: 73.267
  iterations_since_restore: 1679
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14612.021714925766
  time_this_iter_s: 8.306988000869751
  time_total_s: 14612.021714925766
  timestamp: 1594870670
  timesteps_since_restore: 8395000
  timesteps_this_iter: 5000
  timesteps_total: 8395000
  training_iteration: 1679
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14612 s, 1679 iter, 8395000 ts, -5.53e+04 rew

agent-1: -5628.899202827043
agent-2: -6114.828459023628
agent-3: -20041.75426508494
agent-4: -7860.714417883802
agent-5: -19579.12994366091
Extrinsic Rewards:
-5556
-6035
-19831
-7755
-19378
Sum Reward: -58555
Avg Reward: -11711.0
Min Reward: -19831
Max Reward: -5556
Gini Coefficient: -0.2861788062505337
20:20 Ratio: 0.28016741465382483
Max-min Ratio: 0.28016741465382483
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-37-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -55126.53103640942
  episode_reward_min: -139647.68903904976
  episodes_this_iter: 1
  episodes_total: 1679
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.619
    dispatch_time_ms: 10.513
    learner:
      cur_lr: 0.0008008930017240345
      grad_gnorm: 40.000003814697266
      policy_entropy: 46.93415069580078
      policy_loss: -539.4195556640625
      var_gnorm: 177.26951599121094
      vf_explained_var: 0.0
      vf_loss: 125598.140625
    num_steps_sampled: 8400000
    num_steps_trained: 8400000
    wait_time_ms: 71.357
  iterations_since_restore: 1680
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14620.361668348312
  time_this_iter_s: 8.339953422546387
  time_total_s: 14620.361668348312
  timestamp: 1594870679
  timesteps_since_restore: 8400000
  timesteps_this_iter: 5000
  timesteps_total: 8400000
  training_iteration: 1680
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14620 s, 1680 iter, 8400000 ts, -5.51e+04 rew

agent-1: -11066.88522551483
agent-2: -14334.233094908644
agent-3: -8120.746036152226
agent-4: -16629.163427529198
agent-5: -12220.777966817297
Extrinsic Rewards:
-10939
-14174
-8005
-16445
-12096
Sum Reward: -61659
Avg Reward: -12331.8
Min Reward: -16445
Max Reward: -8005
Gini Coefficient: -0.13049189899284777
20:20 Ratio: 0.48677409546974765
Max-min Ratio: 0.48677409546974765
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-38-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -54611.677792340684
  episode_reward_min: -139647.68903904976
  episodes_this_iter: 1
  episodes_total: 1680
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.176
    dispatch_time_ms: 26.542
    learner:
      cur_lr: 0.0008005599956959486
      grad_gnorm: 40.0
      policy_entropy: 41.7076301574707
      policy_loss: 259.2082214355469
      var_gnorm: 177.25048828125
      vf_explained_var: 0.0
      vf_loss: 68311.46875
    num_steps_sampled: 8405000
    num_steps_trained: 8405000
    wait_time_ms: 56.814
  iterations_since_restore: 1681
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14628.485842466354
  time_this_iter_s: 8.124174118041992
  time_total_s: 14628.485842466354
  timestamp: 1594870687
  timesteps_since_restore: 8405000
  timesteps_this_iter: 5000
  timesteps_total: 8405000
  training_iteration: 1681
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14628 s, 1681 iter, 8405000 ts, -5.46e+04 rew

agent-1: -5965.620392024998
agent-2: -6517.540917778472
agent-3: -8807.62964391763
agent-4: -4372.790245591871
agent-5: -9799.641248110654
Extrinsic Rewards:
-5834
-6381
-8634
-4272
-9629
Sum Reward: -34750
Avg Reward: -6950.0
Min Reward: -9629
Max Reward: -4272
Gini Coefficient: -0.1555568345323741
20:20 Ratio: 0.44365977775469934
Max-min Ratio: 0.44365977775469934
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-38-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -54188.11879983122
  episode_reward_min: -139647.68903904976
  episodes_this_iter: 1
  episodes_total: 1681
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.2
    dispatch_time_ms: 18.929
    learner:
      cur_lr: 0.0008002269896678627
      grad_gnorm: 40.00000762939453
      policy_entropy: 47.50297164916992
      policy_loss: -2439.425048828125
      var_gnorm: 177.29676818847656
      vf_explained_var: 0.0
      vf_loss: 271346.875
    num_steps_sampled: 8410000
    num_steps_trained: 8410000
    wait_time_ms: 71.068
  iterations_since_restore: 1682
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14637.24960064888
  time_this_iter_s: 8.763758182525635
  time_total_s: 14637.24960064888
  timestamp: 1594870696
  timesteps_since_restore: 8410000
  timesteps_this_iter: 5000
  timesteps_total: 8410000
  training_iteration: 1682
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14637 s, 1682 iter, 8410000 ts, -5.42e+04 rew

agent-1: -14287.00067068266
agent-2: -10298.992346619449
agent-3: -11619.70313857351
agent-4: -11126.738540550012
agent-5: -9576.040483279117
Extrinsic Rewards:
-14106
-10164
-11469
-10980
-9442
Sum Reward: -56161
Avg Reward: -11232.2
Min Reward: -14106
Max Reward: -9442
Gini Coefficient: -0.07573226972454195
20:20 Ratio: 0.6693605557918616
Max-min Ratio: 0.6693605557918616
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-38-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -53916.75275746947
  episode_reward_min: -139647.68903904976
  episodes_this_iter: 1
  episodes_total: 1682
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.856
    dispatch_time_ms: 14.99
    learner:
      cur_lr: 0.0007998939836397767
      grad_gnorm: 40.000003814697266
      policy_entropy: 53.72972869873047
      policy_loss: -385.2658386230469
      var_gnorm: 177.3353271484375
      vf_explained_var: 0.0
      vf_loss: 86421.890625
    num_steps_sampled: 8415000
    num_steps_trained: 8415000
    wait_time_ms: 69.819
  iterations_since_restore: 1683
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14646.024972200394
  time_this_iter_s: 8.775371551513672
  time_total_s: 14646.024972200394
  timestamp: 1594870705
  timesteps_since_restore: 8415000
  timesteps_this_iter: 5000
  timesteps_total: 8415000
  training_iteration: 1683
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14646 s, 1683 iter, 8415000 ts, -5.39e+04 rew

agent-1: -7030.062031041603
agent-2: -12066.811309367416
agent-3: -9081.070934227171
agent-4: -16108.508924062757
agent-5: -3589.0821809084
Extrinsic Rewards:
-6927
-11890
-8936
-15888
-3529
Sum Reward: -47170
Avg Reward: -9434.0
Min Reward: -15888
Max Reward: -3529
Gini Coefficient: -0.2516938732245071
20:20 Ratio: 0.2221173212487412
Max-min Ratio: 0.2221173212487412
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-38-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -53399.85961729384
  episode_reward_min: -139647.68903904976
  episodes_this_iter: 1
  episodes_total: 1683
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.564
    dispatch_time_ms: 22.875
    learner:
      cur_lr: 0.0007995609776116908
      grad_gnorm: 40.0
      policy_entropy: 58.071041107177734
      policy_loss: 287.28912353515625
      var_gnorm: 177.46517944335938
      vf_explained_var: 0.0
      vf_loss: 52756.96875
    num_steps_sampled: 8420000
    num_steps_trained: 8420000
    wait_time_ms: 63.588
  iterations_since_restore: 1684
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14654.787825345993
  time_this_iter_s: 8.762853145599365
  time_total_s: 14654.787825345993
  timestamp: 1594870714
  timesteps_since_restore: 8420000
  timesteps_this_iter: 5000
  timesteps_total: 8420000
  training_iteration: 1684
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14654 s, 1684 iter, 8420000 ts, -5.34e+04 rew

agent-1: -12932.631639028828
agent-2: -14713.987850456366
agent-3: -9269.522125126408
agent-4: -2567.0292715261835
agent-5: -11336.93087664349
Extrinsic Rewards:
-12772
-14514
-9140
-2516
-11172
Sum Reward: -50114
Avg Reward: -10022.8
Min Reward: -14514
Max Reward: -2516
Gini Coefficient: -0.22052121163746657
20:20 Ratio: 0.17334986909191125
Max-min Ratio: 0.17334986909191125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-38-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -52729.54588948892
  episode_reward_min: -139647.68903904976
  episodes_this_iter: 1
  episodes_total: 1684
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.637
    dispatch_time_ms: 14.507
    learner:
      cur_lr: 0.0007992279715836048
      grad_gnorm: 40.0
      policy_entropy: 57.60607147216797
      policy_loss: 979.6989135742188
      var_gnorm: 177.35696411132812
      vf_explained_var: 0.0
      vf_loss: 45898.08984375
    num_steps_sampled: 8425000
    num_steps_trained: 8425000
    wait_time_ms: 70.905
  iterations_since_restore: 1685
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14663.443274259567
  time_this_iter_s: 8.655448913574219
  time_total_s: 14663.443274259567
  timestamp: 1594870722
  timesteps_since_restore: 8425000
  timesteps_this_iter: 5000
  timesteps_total: 8425000
  training_iteration: 1685
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14663 s, 1685 iter, 8425000 ts, -5.27e+04 rew

agent-1: -9466.388296993437
agent-2: -9462.362178557052
agent-3: -6804.243513353693
agent-4: -3729.132263596442
agent-5: -6382.1390010412215
Extrinsic Rewards:
-9281
-9276
-6667
-3628
-6257
Sum Reward: -35109
Avg Reward: -7021.8
Min Reward: -9281
Max Reward: -3628
Gini Coefficient: -0.16320601555156797
20:20 Ratio: 0.3909061523542722
Max-min Ratio: 0.3909061523542722
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-38-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -51995.17590064047
  episode_reward_min: -139647.68903904976
  episodes_this_iter: 1
  episodes_total: 1685
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.053
    dispatch_time_ms: 12.888
    learner:
      cur_lr: 0.0007988950237631798
      grad_gnorm: 40.000003814697266
      policy_entropy: 60.28175354003906
      policy_loss: 147.26275634765625
      var_gnorm: 177.4271240234375
      vf_explained_var: 0.0
      vf_loss: 44653.26953125
    num_steps_sampled: 8430000
    num_steps_trained: 8430000
    wait_time_ms: 71.026
  iterations_since_restore: 1686
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14672.214005708694
  time_this_iter_s: 8.770731449127197
  time_total_s: 14672.214005708694
  timestamp: 1594870731
  timesteps_since_restore: 8430000
  timesteps_this_iter: 5000
  timesteps_total: 8430000
  training_iteration: 1686
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14672 s, 1686 iter, 8430000 ts, -5.2e+04 rew

agent-1: -13270.879324997799
agent-2: -9390.646007405416
agent-3: -10074.75174414171
agent-4: -12504.684749001233
agent-5: -9242.273077904623
Extrinsic Rewards:
-13091
-9257
-9932
-12340
-9116
Sum Reward: -53736
Avg Reward: -10747.2
Min Reward: -13091
Max Reward: -9116
Gini Coefficient: -0.08212743784427572
20:20 Ratio: 0.6963562753036437
Max-min Ratio: 0.6963562753036437
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-39-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -51336.454483515496
  episode_reward_min: -139647.68903904976
  episodes_this_iter: 1
  episodes_total: 1686
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.212
    dispatch_time_ms: 16.932
    learner:
      cur_lr: 0.0007985620177350938
      grad_gnorm: 40.0
      policy_entropy: 59.18407440185547
      policy_loss: 1207.8597412109375
      var_gnorm: 177.32882690429688
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 52762.85546875
    num_steps_sampled: 8435000
    num_steps_trained: 8435000
    wait_time_ms: 60.943
  iterations_since_restore: 1687
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14681.046732902527
  time_this_iter_s: 8.832727193832397
  time_total_s: 14681.046732902527
  timestamp: 1594870740
  timesteps_since_restore: 8435000
  timesteps_this_iter: 5000
  timesteps_total: 8435000
  training_iteration: 1687
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14681 s, 1687 iter, 8435000 ts, -5.13e+04 rew

agent-1: -4428.51349618202
agent-2: -5920.664456853922
agent-3: -8924.91438519021
agent-4: -11599.798211909178
agent-5: -5917.894989408363
Extrinsic Rewards:
-4336
-5796
-8750
-11398
-5786
Sum Reward: -36066
Avg Reward: -7213.2
Min Reward: -11398
Max Reward: -4336
Gini Coefficient: -0.18951921477291633
20:20 Ratio: 0.38041761712581157
Max-min Ratio: 0.38041761712581157
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-39-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -50685.14576032795
  episode_reward_min: -139647.68903904976
  episodes_this_iter: 1
  episodes_total: 1687
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.865
    dispatch_time_ms: 19.53
    learner:
      cur_lr: 0.0007982290117070079
      grad_gnorm: 40.0
      policy_entropy: 57.107601165771484
      policy_loss: 1125.1768798828125
      var_gnorm: 177.18618774414062
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 38728.08203125
    num_steps_sampled: 8440000
    num_steps_trained: 8440000
    wait_time_ms: 64.785
  iterations_since_restore: 1688
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14689.90719294548
  time_this_iter_s: 8.860460042953491
  time_total_s: 14689.90719294548
  timestamp: 1594870749
  timesteps_since_restore: 8440000
  timesteps_this_iter: 5000
  timesteps_total: 8440000
  training_iteration: 1688
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14689 s, 1688 iter, 8440000 ts, -5.07e+04 rew

agent-1: -7109.663609876521
agent-2: -8071.550061367568
agent-3: -4947.998103370792
agent-4: -4421.271642847073
agent-5: -8458.381035631477
Extrinsic Rewards:
-6952
-7901
-4830
-4314
-8276
Sum Reward: -32273
Avg Reward: -6454.6
Min Reward: -8276
Max Reward: -4314
Gini Coefficient: -0.13627490471911505
20:20 Ratio: 0.5212663122281296
Max-min Ratio: 0.5212663122281296
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-39-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -49929.72005994956
  episode_reward_min: -139647.68903904976
  episodes_this_iter: 1
  episodes_total: 1688
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.922
    dispatch_time_ms: 30.185
    learner:
      cur_lr: 0.0007978960056789219
      grad_gnorm: 40.0
      policy_entropy: 53.71938705444336
      policy_loss: 1201.134521484375
      var_gnorm: 176.9373779296875
      vf_explained_var: 0.0
      vf_loss: 34326.23828125
    num_steps_sampled: 8445000
    num_steps_trained: 8445000
    wait_time_ms: 59.85
  iterations_since_restore: 1689
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14698.611511945724
  time_this_iter_s: 8.70431900024414
  time_total_s: 14698.611511945724
  timestamp: 1594870758
  timesteps_since_restore: 8445000
  timesteps_this_iter: 5000
  timesteps_total: 8445000
  training_iteration: 1689
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14698 s, 1689 iter, 8445000 ts, -4.99e+04 rew

agent-1: -3433.5920159924817
agent-2: -5916.543456234212
agent-3: -5073.008038565476
agent-4: -4757.904302655162
agent-5: -5395.335907734128
Extrinsic Rewards:
-3325
-5759
-4915
-4604
-5234
Sum Reward: -23837
Avg Reward: -4767.4
Min Reward: -5759
Max Reward: -3325
Gini Coefficient: -0.09225993203842765
20:20 Ratio: 0.5773571800659837
Max-min Ratio: 0.5773571800659837
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-39-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -49508.84308337627
  episode_reward_min: -139647.68903904976
  episodes_this_iter: 1
  episodes_total: 1689
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.167
    dispatch_time_ms: 9.037
    learner:
      cur_lr: 0.000797562999650836
      grad_gnorm: 39.99999237060547
      policy_entropy: 48.42760467529297
      policy_loss: 12.203826904296875
      var_gnorm: 176.68089294433594
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 177641.53125
    num_steps_sampled: 8450000
    num_steps_trained: 8450000
    wait_time_ms: 68.504
  iterations_since_restore: 1690
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14706.756654262543
  time_this_iter_s: 8.145142316818237
  time_total_s: 14706.756654262543
  timestamp: 1594870766
  timesteps_since_restore: 8450000
  timesteps_this_iter: 5000
  timesteps_total: 8450000
  training_iteration: 1690
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14706 s, 1690 iter, 8450000 ts, -4.95e+04 rew

agent-1: -5437.108674387594
agent-2: -9189.268415374341
agent-3: -9046.884750405066
agent-4: -4776.7862122713095
agent-5: -6712.616801741705
Extrinsic Rewards:
-5320
-9005
-8858
-4671
-6563
Sum Reward: -34417
Avg Reward: -6883.4
Min Reward: -9005
Max Reward: -4671
Gini Coefficient: -0.14186012726268996
20:20 Ratio: 0.5187118267629095
Max-min Ratio: 0.5187118267629095
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-39-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -49202.13107432564
  episode_reward_min: -139647.68903904976
  episodes_this_iter: 1
  episodes_total: 1690
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.907
    dispatch_time_ms: 5.576
    learner:
      cur_lr: 0.00079722999362275
      grad_gnorm: 40.0
      policy_entropy: 49.78262710571289
      policy_loss: 903.5109252929688
      var_gnorm: 176.41896057128906
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 53350.2578125
    num_steps_sampled: 8455000
    num_steps_trained: 8455000
    wait_time_ms: 72.859
  iterations_since_restore: 1691
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14714.857877969742
  time_this_iter_s: 8.101223707199097
  time_total_s: 14714.857877969742
  timestamp: 1594870774
  timesteps_since_restore: 8455000
  timesteps_this_iter: 5000
  timesteps_total: 8455000
  training_iteration: 1691
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14714 s, 1691 iter, 8455000 ts, -4.92e+04 rew

agent-1: -1522.4509345463832
agent-2: -9258.712470101911
agent-3: -6808.717413008725
agent-4: -4903.0435175676
agent-5: -7201.983794513962
Extrinsic Rewards:
-1480
-9049
-6641
-4781
-7032
Sum Reward: -28983
Avg Reward: -5796.6
Min Reward: -9049
Max Reward: -1480
Gini Coefficient: -0.2399889590449574
20:20 Ratio: 0.1635539838656205
Max-min Ratio: 0.1635539838656205
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-39-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -48537.25363107777
  episode_reward_min: -139647.68903904976
  episodes_this_iter: 1
  episodes_total: 1691
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.156
    dispatch_time_ms: 8.139
    learner:
      cur_lr: 0.0007968969875946641
      grad_gnorm: 40.0
      policy_entropy: 43.780765533447266
      policy_loss: 1246.7493896484375
      var_gnorm: 176.12242126464844
      vf_explained_var: 0.0
      vf_loss: 28939.564453125
    num_steps_sampled: 8460000
    num_steps_trained: 8460000
    wait_time_ms: 69.047
  iterations_since_restore: 1692
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14722.90610408783
  time_this_iter_s: 8.048226118087769
  time_total_s: 14722.90610408783
  timestamp: 1594870782
  timesteps_since_restore: 8460000
  timesteps_this_iter: 5000
  timesteps_total: 8460000
  training_iteration: 1692
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14722 s, 1692 iter, 8460000 ts, -4.85e+04 rew

agent-1: -3379.588262897758
agent-2: -5620.136431457947
agent-3: -8288.792807590278
agent-4: -2960.3766378518258
agent-5: -5872.950705343367
Extrinsic Rewards:
-3267
-5470
-8074
-2870
-5720
Sum Reward: -25401
Avg Reward: -5080.2
Min Reward: -8074
Max Reward: -2870
Gini Coefficient: -0.20252745954883666
20:20 Ratio: 0.3554619767153827
Max-min Ratio: 0.3554619767153827
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-39-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -47919.80923154397
  episode_reward_min: -139647.68903904976
  episodes_this_iter: 1
  episodes_total: 1692
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.004
    dispatch_time_ms: 9.067
    learner:
      cur_lr: 0.0007965639815665781
      grad_gnorm: 40.000003814697266
      policy_entropy: 44.2064323425293
      policy_loss: 972.493408203125
      var_gnorm: 175.90509033203125
      vf_explained_var: 0.0
      vf_loss: 43852.78125
    num_steps_sampled: 8465000
    num_steps_trained: 8465000
    wait_time_ms: 68.537
  iterations_since_restore: 1693
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14730.870064496994
  time_this_iter_s: 7.963960409164429
  time_total_s: 14730.870064496994
  timestamp: 1594870790
  timesteps_since_restore: 8465000
  timesteps_this_iter: 5000
  timesteps_total: 8465000
  training_iteration: 1693
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14730 s, 1693 iter, 8465000 ts, -4.79e+04 rew

agent-1: -6573.381798050996
agent-2: -7009.2686331856885
agent-3: -2762.5199396267385
agent-4: -3586.4987524288836
agent-5: -8253.665173572746
Extrinsic Rewards:
-6406
-6833
-2674
-3482
-8059
Sum Reward: -27454
Avg Reward: -5490.8
Min Reward: -8059
Max Reward: -2674
Gini Coefficient: -0.20574051140088875
20:20 Ratio: 0.3318029532200025
Max-min Ratio: 0.3318029532200025
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-39-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -46979.28757014691
  episode_reward_min: -139647.68903904976
  episodes_this_iter: 1
  episodes_total: 1693
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.872
    dispatch_time_ms: 9.863
    learner:
      cur_lr: 0.0007962309755384922
      grad_gnorm: 39.999996185302734
      policy_entropy: 42.18170166015625
      policy_loss: 81.9787826538086
      var_gnorm: 175.55062866210938
      vf_explained_var: 0.0
      vf_loss: 48035.63671875
    num_steps_sampled: 8470000
    num_steps_trained: 8470000
    wait_time_ms: 65.763
  iterations_since_restore: 1694
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14738.904975414276
  time_this_iter_s: 8.034910917282104
  time_total_s: 14738.904975414276
  timestamp: 1594870798
  timesteps_since_restore: 8470000
  timesteps_this_iter: 5000
  timesteps_total: 8470000
  training_iteration: 1694
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14738 s, 1694 iter, 8470000 ts, -4.7e+04 rew

agent-1: -2871.977750516604
agent-2: -4907.414244626299
agent-3: -5938.754536787966
agent-4: -8878.07425305529
agent-5: -4455.531859792482
Extrinsic Rewards:
-2789
-4775
-5780
-8656
-4327
Sum Reward: -26327
Avg Reward: -5265.4
Min Reward: -8656
Max Reward: -2789
Gini Coefficient: -0.20035704789759562
20:20 Ratio: 0.32220425138632164
Max-min Ratio: 0.32220425138632164
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-40-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -45853.328206204205
  episode_reward_min: -136211.53564261633
  episodes_this_iter: 1
  episodes_total: 1694
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.001
    dispatch_time_ms: 9.135
    learner:
      cur_lr: 0.0007958980277180672
      grad_gnorm: 39.999996185302734
      policy_entropy: 47.067710876464844
      policy_loss: 362.7990417480469
      var_gnorm: 175.2144775390625
      vf_explained_var: 0.0
      vf_loss: 22534.923828125
    num_steps_sampled: 8475000
    num_steps_trained: 8475000
    wait_time_ms: 68.061
  iterations_since_restore: 1695
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14746.914410114288
  time_this_iter_s: 8.009434700012207
  time_total_s: 14746.914410114288
  timestamp: 1594870806
  timesteps_since_restore: 8475000
  timesteps_this_iter: 5000
  timesteps_total: 8475000
  training_iteration: 1695
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14746 s, 1695 iter, 8475000 ts, -4.59e+04 rew

agent-1: -6421.3131930825375
agent-2: -8536.653542888447
agent-3: -6434.0226102014385
agent-4: -7089.115157343095
agent-5: -4020.745485779491
Extrinsic Rewards:
-6274
-8355
-6283
-6935
-3917
Sum Reward: -31764
Avg Reward: -6352.8
Min Reward: -8355
Max Reward: -3917
Gini Coefficient: -0.12009822440498678
20:20 Ratio: 0.46882106523040096
Max-min Ratio: 0.46882106523040096
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-40-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -44878.508382435946
  episode_reward_min: -136211.53564261633
  episodes_this_iter: 1
  episodes_total: 1695
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.515
    dispatch_time_ms: 7.386
    learner:
      cur_lr: 0.0007955650216899812
      grad_gnorm: 40.0
      policy_entropy: 45.69999694824219
      policy_loss: 291.7860107421875
      var_gnorm: 175.22267150878906
      vf_explained_var: 0.0
      vf_loss: 55897.90625
    num_steps_sampled: 8480000
    num_steps_trained: 8480000
    wait_time_ms: 70.52
  iterations_since_restore: 1696
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14755.016396045685
  time_this_iter_s: 8.101985931396484
  time_total_s: 14755.016396045685
  timestamp: 1594870814
  timesteps_since_restore: 8480000
  timesteps_this_iter: 5000
  timesteps_total: 8480000
  training_iteration: 1696
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14755 s, 1696 iter, 8480000 ts, -4.49e+04 rew

agent-1: -11981.207551570462
agent-2: -7301.371339267779
agent-3: -7212.589498427206
agent-4: -3942.8088305863407
agent-5: -4907.590512786565
Extrinsic Rewards:
-11775
-7148
-7059
-3842
-4785
Sum Reward: -34609
Avg Reward: -6921.8
Min Reward: -11775
Max Reward: -3842
Gini Coefficient: -0.2106850819151088
20:20 Ratio: 0.32628450106157114
Max-min Ratio: 0.32628450106157114
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-40-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -44425.426658358105
  episode_reward_min: -136211.53564261633
  episodes_this_iter: 1
  episodes_total: 1696
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.463
    dispatch_time_ms: 9.145
    learner:
      cur_lr: 0.0007952320156618953
      grad_gnorm: 40.0
      policy_entropy: 49.55975341796875
      policy_loss: -95.84909057617188
      var_gnorm: 174.97251892089844
      vf_explained_var: 0.0
      vf_loss: 29430.021484375
    num_steps_sampled: 8485000
    num_steps_trained: 8485000
    wait_time_ms: 68.577
  iterations_since_restore: 1697
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14763.066843271255
  time_this_iter_s: 8.050447225570679
  time_total_s: 14763.066843271255
  timestamp: 1594870822
  timesteps_since_restore: 8485000
  timesteps_this_iter: 5000
  timesteps_total: 8485000
  training_iteration: 1697
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14763 s, 1697 iter, 8485000 ts, -4.44e+04 rew

agent-1: -5504.802929017315
agent-2: -4457.20504201677
agent-3: -5023.7218601549785
agent-4: -3375.6624844692637
agent-5: -5154.479903684035
Extrinsic Rewards:
-5337
-4321
-4861
-3269
-4987
Sum Reward: -22775
Avg Reward: -4555.0
Min Reward: -5337
Max Reward: -3269
Gini Coefficient: -0.08433809001097695
20:20 Ratio: 0.6125163949784523
Max-min Ratio: 0.6125163949784523
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-40-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -43623.232542368285
  episode_reward_min: -136211.53564261633
  episodes_this_iter: 1
  episodes_total: 1697
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 4.225
    dispatch_time_ms: 36.349
    learner:
      cur_lr: 0.0007948990096338093
      grad_gnorm: 40.0
      policy_entropy: 46.078678131103516
      policy_loss: 327.4747619628906
      var_gnorm: 174.6466827392578
      vf_explained_var: 0.0
      vf_loss: 19958.7109375
    num_steps_sampled: 8490000
    num_steps_trained: 8490000
    wait_time_ms: 52.513
  iterations_since_restore: 1698
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14771.615879774094
  time_this_iter_s: 8.549036502838135
  time_total_s: 14771.615879774094
  timestamp: 1594870831
  timesteps_since_restore: 8490000
  timesteps_this_iter: 5000
  timesteps_total: 8490000
  training_iteration: 1698
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14771 s, 1698 iter, 8490000 ts, -4.36e+04 rew

agent-1: -4975.497318467132
agent-2: -7125.271138295496
agent-3: -5613.257328017291
agent-4: -7278.899727452818
agent-5: -3679.660757619372
Extrinsic Rewards:
-4839
-6965
-5473
-7096
-3575
Sum Reward: -27948
Avg Reward: -5589.6
Min Reward: -7096
Max Reward: -3575
Gini Coefficient: -0.13121511378273937
20:20 Ratio: 0.50380496054115
Max-min Ratio: 0.50380496054115
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-40-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -42893.88402558903
  episode_reward_min: -136211.53564261633
  episodes_this_iter: 1
  episodes_total: 1698
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.196
    dispatch_time_ms: 47.397
    learner:
      cur_lr: 0.0007945660036057234
      grad_gnorm: 40.0
      policy_entropy: 47.10512161254883
      policy_loss: 285.63665771484375
      var_gnorm: 174.26356506347656
      vf_explained_var: 0.0
      vf_loss: 36082.9140625
    num_steps_sampled: 8495000
    num_steps_trained: 8495000
    wait_time_ms: 46.038
  iterations_since_restore: 1699
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14780.42828798294
  time_this_iter_s: 8.812408208847046
  time_total_s: 14780.42828798294
  timestamp: 1594870840
  timesteps_since_restore: 8495000
  timesteps_this_iter: 5000
  timesteps_total: 8495000
  training_iteration: 1699
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14780 s, 1699 iter, 8495000 ts, -4.29e+04 rew

agent-1: -2567.189394817778
agent-2: -6211.666601366467
agent-3: -1785.3254796404594
agent-4: -4356.456538203991
agent-5: -4337.868412997034
Extrinsic Rewards:
-2456
-6014
-1701
-4194
-4173
Sum Reward: -18538
Avg Reward: -3707.6
Min Reward: -6014
Max Reward: -1701
Gini Coefficient: -0.22362714424425503
20:20 Ratio: 0.28284003990688394
Max-min Ratio: 0.28284003990688394
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-40-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -41951.08898756276
  episode_reward_min: -136211.53564261633
  episodes_this_iter: 1
  episodes_total: 1699
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.851
    dispatch_time_ms: 6.716
    learner:
      cur_lr: 0.0007942329975776374
      grad_gnorm: 40.0
      policy_entropy: 50.65068817138672
      policy_loss: 1388.8951416015625
      var_gnorm: 173.94903564453125
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 47545.30078125
    num_steps_sampled: 8500000
    num_steps_trained: 8500000
    wait_time_ms: 70.564
  iterations_since_restore: 1700
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14788.43105006218
  time_this_iter_s: 8.002762079238892
  time_total_s: 14788.43105006218
  timestamp: 1594870848
  timesteps_since_restore: 8500000
  timesteps_this_iter: 5000
  timesteps_total: 8500000
  training_iteration: 1700
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14788 s, 1700 iter, 8500000 ts, -4.2e+04 rew

agent-1: -2821.7072026928813
agent-2: -8887.656877861851
agent-3: -5475.787520809369
agent-4: -3126.458836131667
agent-5: -6906.22003208378
Extrinsic Rewards:
-2736
-8681
-5316
-3028
-6726
Sum Reward: -26487
Avg Reward: -5297.4
Min Reward: -8681
Max Reward: -2736
Gini Coefficient: -0.23540604825008496
20:20 Ratio: 0.315171063241562
Max-min Ratio: 0.315171063241562
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-40-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -40973.807051410804
  episode_reward_min: -136211.53564261633
  episodes_this_iter: 1
  episodes_total: 1700
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.529
    dispatch_time_ms: 9.382
    learner:
      cur_lr: 0.0007938999915495515
      grad_gnorm: 39.999996185302734
      policy_entropy: 48.679500579833984
      policy_loss: 948.7258911132812
      var_gnorm: 173.56765747070312
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 41017.35546875
    num_steps_sampled: 8505000
    num_steps_trained: 8505000
    wait_time_ms: 67.816
  iterations_since_restore: 1701
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14796.447588443756
  time_this_iter_s: 8.016538381576538
  time_total_s: 14796.447588443756
  timestamp: 1594870856
  timesteps_since_restore: 8505000
  timesteps_this_iter: 5000
  timesteps_total: 8505000
  training_iteration: 1701
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14796 s, 1701 iter, 8505000 ts, -4.1e+04 rew

agent-1: -3068.3239260274386
agent-2: -6463.666367466166
agent-3: -4120.853001823411
agent-4: -6624.723936788624
agent-5: -3844.585453341347
Extrinsic Rewards:
-2956
-6285
-4024
-6426
-3709
Sum Reward: -23400
Avg Reward: -4680.0
Min Reward: -6426
Max Reward: -2956
Gini Coefficient: -0.16266666666666665
20:20 Ratio: 0.46000622471210706
Max-min Ratio: 0.46000622471210706
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-41-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -39971.068997354436
  episode_reward_min: -136211.53564261633
  episodes_this_iter: 1
  episodes_total: 1701
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.712
    dispatch_time_ms: 7.632
    learner:
      cur_lr: 0.0007935669855214655
      grad_gnorm: 40.0
      policy_entropy: 43.03622817993164
      policy_loss: 282.3111572265625
      var_gnorm: 173.27703857421875
      vf_explained_var: 0.0
      vf_loss: 36032.41015625
    num_steps_sampled: 8510000
    num_steps_trained: 8510000
    wait_time_ms: 69.177
  iterations_since_restore: 1702
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14804.529978752136
  time_this_iter_s: 8.082390308380127
  time_total_s: 14804.529978752136
  timestamp: 1594870864
  timesteps_since_restore: 8510000
  timesteps_this_iter: 5000
  timesteps_total: 8510000
  training_iteration: 1702
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14804 s, 1702 iter, 8510000 ts, -4e+04 rew

agent-1: -7370.265399345271
agent-2: -3739.2349527662254
agent-3: -5024.621498239237
agent-4: -6169.935151721121
agent-5: -4450.404028791995
Extrinsic Rewards:
-7171
-3637
-4881
-5995
-4348
Sum Reward: -26032
Avg Reward: -5206.4
Min Reward: -7171
Max Reward: -3637
Gini Coefficient: -0.1339121081745544
20:20 Ratio: 0.5071817040859016
Max-min Ratio: 0.5071817040859016
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-41-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -38876.49825123691
  episode_reward_min: -121067.09880172963
  episodes_this_iter: 1
  episodes_total: 1702
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.883
    dispatch_time_ms: 7.207
    learner:
      cur_lr: 0.0007932339794933796
      grad_gnorm: 40.0
      policy_entropy: 40.83017349243164
      policy_loss: -70.34394073486328
      var_gnorm: 172.91372680664062
      vf_explained_var: 0.0
      vf_loss: 33794.7890625
    num_steps_sampled: 8515000
    num_steps_trained: 8515000
    wait_time_ms: 70.232
  iterations_since_restore: 1703
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14812.541020154953
  time_this_iter_s: 8.011041402816772
  time_total_s: 14812.541020154953
  timestamp: 1594870872
  timesteps_since_restore: 8515000
  timesteps_this_iter: 5000
  timesteps_total: 8515000
  training_iteration: 1703
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14812 s, 1703 iter, 8515000 ts, -3.89e+04 rew

agent-1: -6349.414805155591
agent-2: -4269.896001458326
agent-3: -4698.352488506255
agent-4: -4151.078520693422
agent-5: -5875.395744791507
Extrinsic Rewards:
-6185
-4152
-4549
-4012
-5706
Sum Reward: -24604
Avg Reward: -4920.8
Min Reward: -6185
Max Reward: -4012
Gini Coefficient: -0.09591936270525118
20:20 Ratio: 0.6486661277283751
Max-min Ratio: 0.6486661277283751
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-41-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -38090.760080046144
  episode_reward_min: -121067.09880172963
  episodes_this_iter: 1
  episodes_total: 1703
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.602
    dispatch_time_ms: 6.162
    learner:
      cur_lr: 0.0007929009734652936
      grad_gnorm: 40.0
      policy_entropy: 50.22858810424805
      policy_loss: -845.02587890625
      var_gnorm: 172.5919189453125
      vf_explained_var: 0.0
      vf_loss: 77973.8671875
    num_steps_sampled: 8520000
    num_steps_trained: 8520000
    wait_time_ms: 71.477
  iterations_since_restore: 1704
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14820.525594234467
  time_this_iter_s: 7.98457407951355
  time_total_s: 14820.525594234467
  timestamp: 1594870880
  timesteps_since_restore: 8520000
  timesteps_this_iter: 5000
  timesteps_total: 8520000
  training_iteration: 1704
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14820 s, 1704 iter, 8520000 ts, -3.81e+04 rew

agent-1: -2442.0082345613896
agent-2: -3371.2281630105495
agent-3: -1984.6726090782
agent-4: -4979.724059433078
agent-5: -2536.4464988125233
Extrinsic Rewards:
-2309
-3195
-1896
-4783
-2414
Sum Reward: -14597
Avg Reward: -2919.4
Min Reward: -4783
Max Reward: -1896
Gini Coefficient: -0.18250325409330684
20:20 Ratio: 0.3964039305874974
Max-min Ratio: 0.3964039305874974
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-41-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -37033.22988767781
  episode_reward_min: -90221.34507061726
  episodes_this_iter: 1
  episodes_total: 1704
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.48
    dispatch_time_ms: 10.223
    learner:
      cur_lr: 0.0007925680256448686
      grad_gnorm: 40.0
      policy_entropy: 46.48136901855469
      policy_loss: 945.326904296875
      var_gnorm: 172.30857849121094
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 34195.1015625
    num_steps_sampled: 8525000
    num_steps_trained: 8525000
    wait_time_ms: 67.86
  iterations_since_restore: 1705
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14828.568731546402
  time_this_iter_s: 8.043137311935425
  time_total_s: 14828.568731546402
  timestamp: 1594870888
  timesteps_since_restore: 8525000
  timesteps_this_iter: 5000
  timesteps_total: 8525000
  training_iteration: 1705
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14828 s, 1705 iter, 8525000 ts, -3.7e+04 rew

agent-1: -1484.7573540912144
agent-2: -6337.154034963596
agent-3: -4651.991534685318
agent-4: -4391.156019790073
agent-5: -9119.899514731054
Extrinsic Rewards:
-1436
-6167
-4516
-4259
-8892
Sum Reward: -25270
Avg Reward: -5054.0
Min Reward: -8892
Max Reward: -1436
Gini Coefficient: -0.26624455876533437
20:20 Ratio: 0.16149347728295096
Max-min Ratio: 0.16149347728295096
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-41-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -36467.90819104374
  episode_reward_min: -90221.34507061726
  episodes_this_iter: 1
  episodes_total: 1705
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 4.04
    dispatch_time_ms: 7.116
    learner:
      cur_lr: 0.0007922350196167827
      grad_gnorm: 39.99999237060547
      policy_entropy: 48.622230529785156
      policy_loss: -47.98569869995117
      var_gnorm: 172.18115234375
      vf_explained_var: 0.0
      vf_loss: 68916.03125
    num_steps_sampled: 8530000
    num_steps_trained: 8530000
    wait_time_ms: 75.569
  iterations_since_restore: 1706
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14837.46192741394
  time_this_iter_s: 8.893195867538452
  time_total_s: 14837.46192741394
  timestamp: 1594870897
  timesteps_since_restore: 8530000
  timesteps_this_iter: 5000
  timesteps_total: 8530000
  training_iteration: 1706
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14837 s, 1706 iter, 8530000 ts, -3.65e+04 rew

agent-1: -5350.987101270666
agent-2: -5437.814568030857
agent-3: -11980.786829807668
agent-4: -5732.603465865514
agent-5: -7642.629187605982
Extrinsic Rewards:
-5237
-5330
-11755
-5609
-7489
Sum Reward: -35420
Avg Reward: -7084.0
Min Reward: -11755
Max Reward: -5237
Gini Coefficient: -0.17159796725014118
20:20 Ratio: 0.44551254785197786
Max-min Ratio: 0.44551254785197786
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-41-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -35927.142951863374
  episode_reward_min: -83575.84455822036
  episodes_this_iter: 1
  episodes_total: 1706
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.114
    dispatch_time_ms: 7.57
    learner:
      cur_lr: 0.0007919020135886967
      grad_gnorm: 40.0
      policy_entropy: 47.309906005859375
      policy_loss: -1098.228515625
      var_gnorm: 172.06414794921875
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 107380.2734375
    num_steps_sampled: 8535000
    num_steps_trained: 8535000
    wait_time_ms: 67.986
  iterations_since_restore: 1707
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14845.562458276749
  time_this_iter_s: 8.100530862808228
  time_total_s: 14845.562458276749
  timestamp: 1594870905
  timesteps_since_restore: 8535000
  timesteps_this_iter: 5000
  timesteps_total: 8535000
  training_iteration: 1707
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14845 s, 1707 iter, 8535000 ts, -3.59e+04 rew

agent-1: -6220.100619914433
agent-2: -7296.455884988224
agent-3: -14579.547460099764
agent-4: -2987.9835964313065
agent-5: -14950.674176975785
Extrinsic Rewards:
-6103
-7175
-14361
-2944
-14749
Sum Reward: -45332
Avg Reward: -9066.4
Min Reward: -14749
Max Reward: -2944
Gini Coefficient: -0.2811965057795818
20:20 Ratio: 0.1996067530002034
Max-min Ratio: 0.1996067530002034
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-41-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -35714.59731753068
  episode_reward_min: -83575.84455822036
  episodes_this_iter: 1
  episodes_total: 1707
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.383
    dispatch_time_ms: 10.025
    learner:
      cur_lr: 0.0007915690075606108
      grad_gnorm: 39.999996185302734
      policy_entropy: 50.90304183959961
      policy_loss: 37.519264221191406
      var_gnorm: 172.2213592529297
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 47434.98828125
    num_steps_sampled: 8540000
    num_steps_trained: 8540000
    wait_time_ms: 72.883
  iterations_since_restore: 1708
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14853.795020580292
  time_this_iter_s: 8.23256230354309
  time_total_s: 14853.795020580292
  timestamp: 1594870913
  timesteps_since_restore: 8540000
  timesteps_this_iter: 5000
  timesteps_total: 8540000
  training_iteration: 1708
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14853 s, 1708 iter, 8540000 ts, -3.57e+04 rew

agent-1: -13402.830280703693
agent-2: -9396.373763723006
agent-3: -8103.392146037251
agent-4: -6784.64741447111
agent-5: -8370.597964740555
Extrinsic Rewards:
-13203
-9246
-7966
-6668
-8227
Sum Reward: -45310
Avg Reward: -9062.0
Min Reward: -13203
Max Reward: -6668
Gini Coefficient: -0.12668285146766717
20:20 Ratio: 0.5050367340755889
Max-min Ratio: 0.5050367340755889
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-42-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -35602.91516299743
  episode_reward_min: -83575.84455822036
  episodes_this_iter: 1
  episodes_total: 1708
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.145
    dispatch_time_ms: 11.382
    learner:
      cur_lr: 0.0007912360015325248
      grad_gnorm: 39.999996185302734
      policy_entropy: 50.58052062988281
      policy_loss: -4513.5517578125
      var_gnorm: 172.54415893554688
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1162059.375
    num_steps_sampled: 8545000
    num_steps_trained: 8545000
    wait_time_ms: 71.935
  iterations_since_restore: 1709
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14862.208941459656
  time_this_iter_s: 8.413920879364014
  time_total_s: 14862.208941459656
  timestamp: 1594870922
  timesteps_since_restore: 8545000
  timesteps_this_iter: 5000
  timesteps_total: 8545000
  training_iteration: 1709
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14862 s, 1709 iter, 8545000 ts, -3.56e+04 rew

agent-1: -28092.154179705733
agent-2: -9104.158267824794
agent-3: -570.4503601017723
agent-4: -25300.654872758514
agent-5: -13576.357905496514
Extrinsic Rewards:
-27865
-9011
-563
-25081
-13441
Sum Reward: -75961
Avg Reward: -15192.2
Min Reward: -27865
Max Reward: -563
Gini Coefficient: -0.3721593975856031
20:20 Ratio: 0.02020455768885699
Max-min Ratio: 0.02020455768885699
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-42-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -35860.34625359534
  episode_reward_min: -83575.84455822036
  episodes_this_iter: 1
  episodes_total: 1709
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.027
    dispatch_time_ms: 8.193
    learner:
      cur_lr: 0.0007909029955044389
      grad_gnorm: 40.000003814697266
      policy_entropy: 48.317108154296875
      policy_loss: -960.101806640625
      var_gnorm: 172.9217529296875
      vf_explained_var: 0.0
      vf_loss: 166754.0625
    num_steps_sampled: 8550000
    num_steps_trained: 8550000
    wait_time_ms: 70.785
  iterations_since_restore: 1710
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14870.548907756805
  time_this_iter_s: 8.339966297149658
  time_total_s: 14870.548907756805
  timestamp: 1594870930
  timesteps_since_restore: 8550000
  timesteps_this_iter: 5000
  timesteps_total: 8550000
  training_iteration: 1710
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14870 s, 1710 iter, 8550000 ts, -3.59e+04 rew

agent-1: -5142.844504885272
agent-2: -29237.031510902063
agent-3: -12369.245765549618
agent-4: -29497.975286395395
agent-5: -29852.046080325497
Extrinsic Rewards:
-5107
-29040
-12276
-29303
-29656
Sum Reward: -105382
Avg Reward: -21076.4
Min Reward: -29656
Max Reward: -5107
Gini Coefficient: -0.25099163044922285
20:20 Ratio: 0.17220798489344483
Max-min Ratio: 0.17220798489344483
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-42-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -36106.69293627005
  episode_reward_min: -106099.14314805812
  episodes_this_iter: 1
  episodes_total: 1710
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.967
    dispatch_time_ms: 7.848
    learner:
      cur_lr: 0.0007905699894763529
      grad_gnorm: 40.000003814697266
      policy_entropy: 49.2738151550293
      policy_loss: -722.565185546875
      var_gnorm: 173.2421875
      vf_explained_var: 0.0
      vf_loss: 48140.359375
    num_steps_sampled: 8555000
    num_steps_trained: 8555000
    wait_time_ms: 72.66
  iterations_since_restore: 1711
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14878.812224388123
  time_this_iter_s: 8.263316631317139
  time_total_s: 14878.812224388123
  timestamp: 1594870939
  timesteps_since_restore: 8555000
  timesteps_this_iter: 5000
  timesteps_total: 8555000
  training_iteration: 1711
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14878 s, 1711 iter, 8555000 ts, -3.61e+04 rew

agent-1: -18672.861640749095
agent-2: -10153.057417658563
agent-3: -11764.283691140461
agent-4: -13419.114403864596
agent-5: -13728.496741508
Extrinsic Rewards:
-18487
-10034
-11625
-13272
-13580
Sum Reward: -66998
Avg Reward: -13399.6
Min Reward: -18487
Max Reward: -10034
Gini Coefficient: -0.11260634645810323
20:20 Ratio: 0.5427597771406935
Max-min Ratio: 0.5427597771406935
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-42-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -36254.0293783501
  episode_reward_min: -106099.14314805812
  episodes_this_iter: 1
  episodes_total: 1711
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.925
    dispatch_time_ms: 8.884
    learner:
      cur_lr: 0.000790236983448267
      grad_gnorm: 39.999996185302734
      policy_entropy: 54.2756462097168
      policy_loss: 1792.4132080078125
      var_gnorm: 173.54583740234375
      vf_explained_var: 0.0
      vf_loss: 38034.6328125
    num_steps_sampled: 8560000
    num_steps_trained: 8560000
    wait_time_ms: 69.974
  iterations_since_restore: 1712
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14887.108705043793
  time_this_iter_s: 8.296480655670166
  time_total_s: 14887.108705043793
  timestamp: 1594870947
  timesteps_since_restore: 8560000
  timesteps_this_iter: 5000
  timesteps_total: 8560000
  training_iteration: 1712
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14887 s, 1712 iter, 8560000 ts, -3.63e+04 rew

agent-1: -6892.243278589607
agent-2: -15712.97812557854
agent-3: -23369.935671387142
agent-4: -16570.408641757793
agent-5: -20814.810205361624
Extrinsic Rewards:
-6822
-15580
-23176
-16417
-20634
Sum Reward: -82629
Avg Reward: -16525.8
Min Reward: -23176
Max Reward: -6822
Gini Coefficient: -0.18280264798073315
20:20 Ratio: 0.2943562305833621
Max-min Ratio: 0.2943562305833621
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-42-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -36597.74913683278
  episode_reward_min: -106099.14314805812
  episodes_this_iter: 1
  episodes_total: 1712
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.939
    dispatch_time_ms: 8.293
    learner:
      cur_lr: 0.000789903977420181
      grad_gnorm: 40.000003814697266
      policy_entropy: 55.47843551635742
      policy_loss: -3966.00830078125
      var_gnorm: 173.7696990966797
      vf_explained_var: 0.0
      vf_loss: 510509.65625
    num_steps_sampled: 8565000
    num_steps_trained: 8565000
    wait_time_ms: 73.768
  iterations_since_restore: 1713
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14895.409870386124
  time_this_iter_s: 8.301165342330933
  time_total_s: 14895.409870386124
  timestamp: 1594870955
  timesteps_since_restore: 8565000
  timesteps_this_iter: 5000
  timesteps_total: 8565000
  training_iteration: 1713
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14895 s, 1713 iter, 8565000 ts, -3.66e+04 rew

agent-1: -9291.352697535982
agent-2: -24232.93400242443
agent-3: -17418.110397577155
agent-4: -9403.39099419261
agent-5: -18086.016522372665
Extrinsic Rewards:
-9188
-24030
-17258
-9306
-17929
Sum Reward: -77711
Avg Reward: -15542.2
Min Reward: -24030
Max Reward: -9188
Gini Coefficient: -0.19717671886862864
20:20 Ratio: 0.38235538909696215
Max-min Ratio: 0.38235538909696215
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-42-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -36901.21448201497
  episode_reward_min: -106099.14314805812
  episodes_this_iter: 1
  episodes_total: 1713
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.848
    dispatch_time_ms: 6.218
    learner:
      cur_lr: 0.0007895709713920951
      grad_gnorm: 40.0
      policy_entropy: 55.24217987060547
      policy_loss: -5750.203125
      var_gnorm: 174.0186309814453
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 478440.8125
    num_steps_sampled: 8570000
    num_steps_trained: 8570000
    wait_time_ms: 76.834
  iterations_since_restore: 1714
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14903.72451710701
  time_this_iter_s: 8.31464672088623
  time_total_s: 14903.72451710701
  timestamp: 1594870964
  timesteps_since_restore: 8570000
  timesteps_this_iter: 5000
  timesteps_total: 8570000
  training_iteration: 1714
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14903 s, 1714 iter, 8570000 ts, -3.69e+04 rew

agent-1: -13580.345057489798
agent-2: -4026.755708364273
agent-3: -12863.847946265521
agent-4: -16676.324946599005
agent-5: -7351.906148661524
Extrinsic Rewards:
-13400
-3974
-12690
-16468
-7248
Sum Reward: -53780
Avg Reward: -10756.0
Min Reward: -16468
Max Reward: -3974
Gini Coefficient: -0.2316102640386761
20:20 Ratio: 0.241316492591693
Max-min Ratio: 0.241316492591693
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-42-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -37051.86377697462
  episode_reward_min: -106099.14314805812
  episodes_this_iter: 1
  episodes_total: 1714
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.581
    dispatch_time_ms: 8.67
    learner:
      cur_lr: 0.0007892380235716701
      grad_gnorm: 40.0
      policy_entropy: 56.97541046142578
      policy_loss: -1334.6256103515625
      var_gnorm: 174.30865478515625
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 102103.4453125
    num_steps_sampled: 8575000
    num_steps_trained: 8575000
    wait_time_ms: 68.972
  iterations_since_restore: 1715
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14911.965305566788
  time_this_iter_s: 8.240788459777832
  time_total_s: 14911.965305566788
  timestamp: 1594870972
  timesteps_since_restore: 8575000
  timesteps_this_iter: 5000
  timesteps_total: 8575000
  training_iteration: 1715
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14911 s, 1715 iter, 8575000 ts, -3.71e+04 rew

agent-1: -23862.844637628277
agent-2: -8288.287999399781
agent-3: -20841.58774860805
agent-4: -23823.00134726466
agent-5: -26424.9849771853
Extrinsic Rewards:
-23693
-8222
-20684
-23657
-26242
Sum Reward: -102498
Avg Reward: -20499.6
Min Reward: -26242
Max Reward: -8222
Gini Coefficient: -0.15238931491346172
20:20 Ratio: 0.3133145339532048
Max-min Ratio: 0.3133145339532048
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-43-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -37817.47777446463
  episode_reward_min: -106099.14314805812
  episodes_this_iter: 1
  episodes_total: 1715
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.048
    dispatch_time_ms: 7.153
    learner:
      cur_lr: 0.0007889050175435841
      grad_gnorm: 40.0
      policy_entropy: 56.367183685302734
      policy_loss: -1153.2025146484375
      var_gnorm: 174.64291381835938
      vf_explained_var: 0.0
      vf_loss: 137510.21875
    num_steps_sampled: 8580000
    num_steps_trained: 8580000
    wait_time_ms: 77.329
  iterations_since_restore: 1716
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14920.275908470154
  time_this_iter_s: 8.310602903366089
  time_total_s: 14920.275908470154
  timestamp: 1594870980
  timesteps_since_restore: 8580000
  timesteps_this_iter: 5000
  timesteps_total: 8580000
  training_iteration: 1716
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14920 s, 1716 iter, 8580000 ts, -3.78e+04 rew

agent-1: -11260.965237594908
agent-2: -11933.508007100128
agent-3: -8311.28805895609
agent-4: -20179.850084916918
agent-5: -16668.803293332094
Extrinsic Rewards:
-11151
-11823
-8202
-19978
-16490
Sum Reward: -67644
Avg Reward: -13528.8
Min Reward: -19978
Max Reward: -8202
Gini Coefficient: -0.17084146413576962
20:20 Ratio: 0.4105516067674442
Max-min Ratio: 0.4105516067674442
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-43-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -38255.43978677019
  episode_reward_min: -106099.14314805812
  episodes_this_iter: 1
  episodes_total: 1716
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.482
    dispatch_time_ms: 7.911
    learner:
      cur_lr: 0.0007885720115154982
      grad_gnorm: 40.000003814697266
      policy_entropy: 54.614871978759766
      policy_loss: -6132.94873046875
      var_gnorm: 174.960693359375
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 542831.875
    num_steps_sampled: 8585000
    num_steps_trained: 8585000
    wait_time_ms: 73.037
  iterations_since_restore: 1717
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14928.600238323212
  time_this_iter_s: 8.324329853057861
  time_total_s: 14928.600238323212
  timestamp: 1594870988
  timesteps_since_restore: 8585000
  timesteps_this_iter: 5000
  timesteps_total: 8585000
  training_iteration: 1717
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14928 s, 1717 iter, 8585000 ts, -3.83e+04 rew

agent-1: -21194.788566567408
agent-2: -15217.772682935734
agent-3: -5817.143433138038
agent-4: -19744.933737285573
agent-5: -30157.714348310248
Extrinsic Rewards:
-21019
-15082
-5757
-19593
-29947
Sum Reward: -91398
Avg Reward: -18279.6
Min Reward: -29947
Max Reward: -5757
Gini Coefficient: -0.23771636140834593
20:20 Ratio: 0.1922396233345577
Max-min Ratio: 0.1922396233345577
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-43-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -38883.67957440867
  episode_reward_min: -106099.14314805812
  episodes_this_iter: 1
  episodes_total: 1717
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.631
    dispatch_time_ms: 5.803
    learner:
      cur_lr: 0.0007882390054874122
      grad_gnorm: 40.0
      policy_entropy: 55.166316986083984
      policy_loss: 918.7512817382812
      var_gnorm: 175.29441833496094
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 31000.06640625
    num_steps_sampled: 8590000
    num_steps_trained: 8590000
    wait_time_ms: 74.285
  iterations_since_restore: 1718
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14936.809908628464
  time_this_iter_s: 8.209670305252075
  time_total_s: 14936.809908628464
  timestamp: 1594870997
  timesteps_since_restore: 8590000
  timesteps_this_iter: 5000
  timesteps_total: 8590000
  training_iteration: 1718
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14936 s, 1718 iter, 8590000 ts, -3.89e+04 rew

agent-1: -15239.564731451024
agent-2: -11403.650549608059
agent-3: -15192.485808006842
agent-4: -16230.382213332448
agent-5: -4986.978349688462
Extrinsic Rewards:
-15067
-11262
-15017
-16049
-4921
Sum Reward: -62316
Avg Reward: -12463.2
Min Reward: -16049
Max Reward: -4921
Gini Coefficient: -0.16728288080107837
20:20 Ratio: 0.30662346563648823
Max-min Ratio: 0.30662346563648823
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-43-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -39244.28532274965
  episode_reward_min: -106099.14314805812
  episodes_this_iter: 1
  episodes_total: 1718
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.788
    dispatch_time_ms: 7.36
    learner:
      cur_lr: 0.0007879059994593263
      grad_gnorm: 40.0
      policy_entropy: 46.6132698059082
      policy_loss: -449.0267639160156
      var_gnorm: 175.33653259277344
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 90076.5546875
    num_steps_sampled: 8595000
    num_steps_trained: 8595000
    wait_time_ms: 69.463
  iterations_since_restore: 1719
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14945.004376888275
  time_this_iter_s: 8.194468259811401
  time_total_s: 14945.004376888275
  timestamp: 1594871005
  timesteps_since_restore: 8595000
  timesteps_this_iter: 5000
  timesteps_total: 8595000
  training_iteration: 1719
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14945 s, 1719 iter, 8595000 ts, -3.92e+04 rew

agent-1: -4949.146162337757
agent-2: -8140.232547562697
agent-3: -6978.603076041323
agent-4: -5516.5362626684255
agent-5: -11222.261789745497
Extrinsic Rewards:
-4839
-7976
-6837
-5405
-11019
Sum Reward: -36076
Avg Reward: -7215.2
Min Reward: -11019
Max Reward: -4839
Gini Coefficient: -0.16555050449052
20:20 Ratio: 0.43915055812687176
Max-min Ratio: 0.43915055812687176
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-43-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -39212.103370606834
  episode_reward_min: -106099.14314805812
  episodes_this_iter: 1
  episodes_total: 1719
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.913
    dispatch_time_ms: 7.404
    learner:
      cur_lr: 0.0007875729934312403
      grad_gnorm: 40.0
      policy_entropy: 38.09865951538086
      policy_loss: 1460.8399658203125
      var_gnorm: 175.29054260253906
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 46537.1953125
    num_steps_sampled: 8600000
    num_steps_trained: 8600000
    wait_time_ms: 75.579
  iterations_since_restore: 1720
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14953.211739778519
  time_this_iter_s: 8.20736289024353
  time_total_s: 14953.211739778519
  timestamp: 1594871013
  timesteps_since_restore: 8600000
  timesteps_this_iter: 5000
  timesteps_total: 8600000
  training_iteration: 1720
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14953 s, 1720 iter, 8600000 ts, -3.92e+04 rew

agent-1: -12433.12107431584
agent-2: -3550.66612054919
agent-3: -8390.926551861747
agent-4: -12383.38661933569
agent-5: -16600.387789084998
Extrinsic Rewards:
-12261
-3497
-8265
-12210
-16391
Sum Reward: -52624
Avg Reward: -10524.8
Min Reward: -16391
Max Reward: -3497
Gini Coefficient: -0.22639100030404377
20:20 Ratio: 0.21334878896955647
Max-min Ratio: 0.21334878896955647
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-43-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -39444.38286958232
  episode_reward_min: -106099.14314805812
  episodes_this_iter: 1
  episodes_total: 1720
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.794
    dispatch_time_ms: 11.307
    learner:
      cur_lr: 0.0007872399874031544
      grad_gnorm: 39.99999237060547
      policy_entropy: 32.14299392700195
      policy_loss: 954.9259643554688
      var_gnorm: 174.91641235351562
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 45085.9453125
    num_steps_sampled: 8605000
    num_steps_trained: 8605000
    wait_time_ms: 68.306
  iterations_since_restore: 1721
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14961.284528970718
  time_this_iter_s: 8.072789192199707
  time_total_s: 14961.284528970718
  timestamp: 1594871021
  timesteps_since_restore: 8605000
  timesteps_this_iter: 5000
  timesteps_total: 8605000
  training_iteration: 1721
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14961 s, 1721 iter, 8605000 ts, -3.94e+04 rew

agent-1: -3391.275278334353
agent-2: -2341.4809994514308
agent-3: -3666.374657587822
agent-4: -2962.671260146554
agent-5: -3905.318572930086
Extrinsic Rewards:
-3247
-2231
-3515
-2838
-3741
Sum Reward: -15572
Avg Reward: -3114.4
Min Reward: -3741
Max Reward: -2231
Gini Coefficient: -0.09496532237349088
20:20 Ratio: 0.5963646083934777
Max-min Ratio: 0.5963646083934777
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-43-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -39371.34641113282
  episode_reward_min: -106099.14314805812
  episodes_this_iter: 1
  episodes_total: 1721
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.02
    dispatch_time_ms: 8.04
    learner:
      cur_lr: 0.0007869069813750684
      grad_gnorm: 39.999996185302734
      policy_entropy: 29.71015167236328
      policy_loss: 459.3874816894531
      var_gnorm: 174.50808715820312
      vf_explained_var: 0.0
      vf_loss: 39269.40625
    num_steps_sampled: 8610000
    num_steps_trained: 8610000
    wait_time_ms: 70.652
  iterations_since_restore: 1722
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14969.438948631287
  time_this_iter_s: 8.154419660568237
  time_total_s: 14969.438948631287
  timestamp: 1594871030
  timesteps_since_restore: 8610000
  timesteps_this_iter: 5000
  timesteps_total: 8610000
  training_iteration: 1722
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14969 s, 1722 iter, 8610000 ts, -3.94e+04 rew

agent-1: -1554.5935580695452
agent-2: -2135.8215685119444
agent-3: -4385.654252394095
agent-4: -2491.5938575134924
agent-5: -3763.408999187077
Extrinsic Rewards:
-1476
-2027
-4191
-2365
-3582
Sum Reward: -13641
Avg Reward: -2728.2
Min Reward: -4191
Max Reward: -1476
Gini Coefficient: -0.20482369327761896
20:20 Ratio: 0.3521832498210451
Max-min Ratio: 0.3521832498210451
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-43-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -12191.873589945055
  episode_reward_mean: -39253.541886142135
  episode_reward_min: -106099.14314805812
  episodes_this_iter: 1
  episodes_total: 1722
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.912
    dispatch_time_ms: 6.305
    learner:
      cur_lr: 0.0007865739753469825
      grad_gnorm: 40.0
      policy_entropy: 26.149274826049805
      policy_loss: 815.0285034179688
      var_gnorm: 174.06039428710938
      vf_explained_var: 0.0
      vf_loss: 54110.16796875
    num_steps_sampled: 8615000
    num_steps_trained: 8615000
    wait_time_ms: 67.449
  iterations_since_restore: 1723
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14977.507868051529
  time_this_iter_s: 8.06891942024231
  time_total_s: 14977.507868051529
  timestamp: 1594871038
  timesteps_since_restore: 8615000
  timesteps_this_iter: 5000
  timesteps_total: 8615000
  training_iteration: 1723
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14977 s, 1723 iter, 8615000 ts, -3.93e+04 rew

agent-1: -1791.4951298958647
agent-2: -2992.7558177661085
agent-3: -3277.081384822256
agent-4: -1643.3426810041883
agent-5: -1965.7428445227802
Extrinsic Rewards:
-1680
-2847
-3094
-1540
-1846
Sum Reward: -11007
Avg Reward: -2201.4
Min Reward: -3094
Max Reward: -1540
Gini Coefficient: -0.1553556827473426
20:20 Ratio: 0.497737556561086
Max-min Ratio: 0.497737556561086
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-44-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -11670.417858011126
  episode_reward_mean: -39248.327328822794
  episode_reward_min: -106099.14314805812
  episodes_this_iter: 1
  episodes_total: 1723
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.006
    dispatch_time_ms: 10.12
    learner:
      cur_lr: 0.0007862410275265574
      grad_gnorm: 40.0
      policy_entropy: 27.38987159729004
      policy_loss: -56.09276580810547
      var_gnorm: 173.64418029785156
      vf_explained_var: 0.0
      vf_loss: 46708.53125
    num_steps_sampled: 8620000
    num_steps_trained: 8620000
    wait_time_ms: 65.582
  iterations_since_restore: 1724
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14985.563596010208
  time_this_iter_s: 8.0557279586792
  time_total_s: 14985.563596010208
  timestamp: 1594871046
  timesteps_since_restore: 8620000
  timesteps_this_iter: 5000
  timesteps_total: 8620000
  training_iteration: 1724
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14985 s, 1724 iter, 8620000 ts, -3.92e+04 rew

agent-1: -1922.2780790115885
agent-2: -4048.4956019761094
agent-3: -2735.1039589411084
agent-4: -2252.189757313032
agent-5: -4897.530556409262
Extrinsic Rewards:
-1832
-3887
-2608
-2152
-4685
Sum Reward: -15164
Avg Reward: -3032.8
Min Reward: -4685
Max Reward: -1832
Gini Coefficient: -0.1962806647322606
20:20 Ratio: 0.3910352187833511
Max-min Ratio: 0.3910352187833511
W0715 23:44:12.727694 22529 client_connection.cc:255] [worker]ProcessMessage with type 19 took 2324 ms.
W0715 23:44:15.955431 22529 node_manager.cc:250] Last heartbeat was sent 5607 ms ago 
W0715 23:44:19.333266 22529 client_connection.cc:255] [worker]ProcessMessage with type 19 took 1575 ms.
W0715 23:44:19.333441 22529 node_manager.cc:250] Last heartbeat was sent 1660 ms ago 
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-44-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -11670.417858011126
  episode_reward_mean: -39208.09754545088
  episode_reward_min: -106099.14314805812
  episodes_this_iter: 1
  episodes_total: 1724
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.939
    dispatch_time_ms: 6.887
    learner:
      cur_lr: 0.0007859080214984715
      grad_gnorm: 40.0
      policy_entropy: 36.03813934326172
      policy_loss: 1393.3228759765625
      var_gnorm: 173.29612731933594
      vf_explained_var: 0.0
      vf_loss: 38592.96875
    num_steps_sampled: 8625000
    num_steps_trained: 8625000
    wait_time_ms: 61.61
  iterations_since_restore: 1725
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 14999.9152135849
  time_this_iter_s: 14.351617574691772
  time_total_s: 14999.9152135849
  timestamp: 1594871060
  timesteps_since_restore: 8625000
  timesteps_this_iter: 5000
  timesteps_total: 8625000
  training_iteration: 1725
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 14999 s, 1725 iter, 8625000 ts, -3.92e+04 rew

agent-1: -4612.521104462246
agent-2: -3580.5827222992216
agent-3: -6315.070624424276
agent-4: -1198.500034029132
agent-5: -2733.5430383278053
Extrinsic Rewards:
-4447
-3451
-6120
-1135
-2638
Sum Reward: -17791
Avg Reward: -3558.2
Min Reward: -6120
Max Reward: -1135
Gini Coefficient: -0.26483053229160813
20:20 Ratio: 0.1854575163398693
Max-min Ratio: 0.1854575163398693
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-44-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -11670.417858011126
  episode_reward_mean: -39253.41036614424
  episode_reward_min: -106099.14314805812
  episodes_this_iter: 1
  episodes_total: 1725
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.824
    dispatch_time_ms: 8.707
    learner:
      cur_lr: 0.0007855750154703856
      grad_gnorm: 40.0
      policy_entropy: 28.53719711303711
      policy_loss: 1108.4227294921875
      var_gnorm: 173.01341247558594
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 52975.4296875
    num_steps_sampled: 8630000
    num_steps_trained: 8630000
    wait_time_ms: 71.392
  iterations_since_restore: 1726
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 15008.093828201294
  time_this_iter_s: 8.178614616394043
  time_total_s: 15008.093828201294
  timestamp: 1594871068
  timesteps_since_restore: 8630000
  timesteps_this_iter: 5000
  timesteps_total: 8630000
  training_iteration: 1726
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 15008 s, 1726 iter, 8630000 ts, -3.93e+04 rew

agent-1: -7292.582381465385
agent-2: -4695.137605328669
agent-3: -1234.0894484881835
agent-4: -5325.593812582563
agent-5: -6169.591620049424
Extrinsic Rewards:
-7118
-4541
-1188
-5182
-5985
Sum Reward: -24014
Avg Reward: -4802.8
Min Reward: -7118
Max Reward: -1188
Gini Coefficient: -0.22160406429582744
20:20 Ratio: 0.166900814835628
Max-min Ratio: 0.166900814835628
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-44-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -11670.417858011126
  episode_reward_mean: -39276.288196166875
  episode_reward_min: -106099.14314805812
  episodes_this_iter: 1
  episodes_total: 1726
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.473
    dispatch_time_ms: 7.475
    learner:
      cur_lr: 0.0007852420094422996
      grad_gnorm: 40.00000762939453
      policy_entropy: 30.14431381225586
      policy_loss: 541.82958984375
      var_gnorm: 172.7510986328125
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 64549.4921875
    num_steps_sampled: 8635000
    num_steps_trained: 8635000
    wait_time_ms: 71.397
  iterations_since_restore: 1727
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 15016.18808555603
  time_this_iter_s: 8.094257354736328
  time_total_s: 15016.18808555603
  timestamp: 1594871076
  timesteps_since_restore: 8635000
  timesteps_this_iter: 5000
  timesteps_total: 8635000
  training_iteration: 1727
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 15016 s, 1727 iter, 8635000 ts, -3.93e+04 rew

agent-1: -5298.974685878111
agent-2: -596.8630675872312
agent-3: -1574.4565106922776
agent-4: -5616.114043146637
agent-5: -7684.168567105795
Extrinsic Rewards:
-5125
-580
-1518
-5425
-7459
Sum Reward: -20107
Avg Reward: -4021.4
Min Reward: -7459
Max Reward: -580
Gini Coefficient: -0.3514199035161884
20:20 Ratio: 0.077758412655852
Max-min Ratio: 0.077758412655852
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-44-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -11670.417858011126
  episode_reward_mean: -39249.14837610744
  episode_reward_min: -106099.14314805812
  episodes_this_iter: 1
  episodes_total: 1727
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 3.58
    dispatch_time_ms: 8.117
    learner:
      cur_lr: 0.0007849090034142137
      grad_gnorm: 40.0
      policy_entropy: 31.45014762878418
      policy_loss: 748.3690795898438
      var_gnorm: 172.48281860351562
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 33842.91796875
    num_steps_sampled: 8640000
    num_steps_trained: 8640000
    wait_time_ms: 71.907
  iterations_since_restore: 1728
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 15024.295251846313
  time_this_iter_s: 8.107166290283203
  time_total_s: 15024.295251846313
  timestamp: 1594871085
  timesteps_since_restore: 8640000
  timesteps_this_iter: 5000
  timesteps_total: 8640000
  training_iteration: 1728
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 15024 s, 1728 iter, 8640000 ts, -3.92e+04 rew

agent-1: -4414.317426940524
agent-2: -7112.897430858288
agent-3: -7574.536916114485
agent-4: -8398.486401245324
agent-5: -149.91667081056485
Extrinsic Rewards:
-4289
-6933
-7383
-8199
-135
Sum Reward: -26939
Avg Reward: -5387.8
Min Reward: -8199
Max Reward: -135
Gini Coefficient: -0.2854151972975983
20:20 Ratio: 0.01646542261251372
Max-min Ratio: 0.01646542261251372
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_23-44-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -11670.417858011126
  episode_reward_mean: -39332.503049195744
  episode_reward_min: -106099.14314805812
  episodes_this_iter: 1
  episodes_total: 1728
  experiment_id: 8ccf0e512bfa462b96a343c4370f756c
  hostname: gpu047
  info:
    apply_time_ms: 2.583
    dispatch_time_ms: 6.202
    learner:
      cur_lr: 0.0007845759973861277
      grad_gnorm: 39.99999237060547
      policy_entropy: 29.08285140991211
      policy_loss: 597.1338500976562
      var_gnorm: 172.18099975585938
      vf_explained_var: 0.0
      vf_loss: 27021.4140625
    num_steps_sampled: 8645000
    num_steps_trained: 8645000
    wait_time_ms: 72.113
  iterations_since_restore: 1729
  node_ip: 172.17.8.47
  num_metric_batches_dropped: 0
  pid: 22533
  policy_reward_mean: {}
  time_since_restore: 15032.413771152496
  time_this_iter_s: 8.118519306182861
  time_total_s: 15032.413771152496
  timestamp: 1594871093
  timesteps_since_restore: 8645000
  timesteps_this_iter: 5000
  timesteps_total: 8645000
  training_iteration: 1729
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=22533], 15032 s, 1729 iter, 8645000 ts, -3.93e+04 rew

