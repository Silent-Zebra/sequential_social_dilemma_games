/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Process STDOUT and STDERR is being redirected to /tmp/ray/session_2020-07-03_20-23-33_7632/logs.
Waiting for redis server at 127.0.0.1:17421 to respond...
Waiting for redis server at 127.0.0.1:20323 to respond...
Warning: Capping object memory store to 20.0GB. To increase this further, specify `object_store_memory` when calling ray.init() or ray start.
Starting the Plasma object store with 20.0 GB memory using /dev/shm.

======================================================================
View the web UI at http://localhost:8888/notebooks/ray_ui.ipynb?token=eb0247f3365ddddbc4690293d4f187b76e8879a7a0238477
======================================================================

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.1/202.5 GB

Created LogSyncer for /h/zhaostep/ray_results/harvest_A3C/A3C_harvest_env_0_2020-07-03_20-23-3438zx01ua -> 
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING

/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-03 20:23:46,204	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 0 on CPU (please ignore any CUDA init errors)
2020-07-03 20:23:46.205711: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-03 20:23:58,055	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 1 on CPU (please ignore any CUDA init errors)
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-03 20:23:58,055	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 2 on CPU (please ignore any CUDA init errors)
2020-07-03 20:23:58.056076: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2020-07-03 20:23:58.056133: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-24-16
  done: false
  episode_len_mean: .nan
  episode_reward_max: .nan
  episode_reward_mean: .nan
  episode_reward_min: .nan
  episodes_this_iter: 0
  episodes_total: 0
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.942
    dispatch_time_ms: 9.248
    learner:
      cur_lr: 0.0013599999947473407
      grad_gnorm: 39.999996185302734
      policy_entropy: 121.91307067871094
      policy_loss: 23.26587677001953
      var_gnorm: 18.125526428222656
      vf_explained_var: -0.012263298034667969
      vf_loss: 11.315265655517578
    num_steps_sampled: 10000
    num_steps_trained: 10000
    wait_time_ms: 147.426
  iterations_since_restore: 1
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 28.867347955703735
  time_this_iter_s: 28.867347955703735
  time_total_s: 28.867347955703735
  timestamp: 1593822256
  timesteps_since_restore: 10000
  timesteps_this_iter: 10000
  timesteps_total: 10000
  training_iteration: 1
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 28 s, 1 iter, 10000 ts, nan rew

[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
agent-1: -437.0
agent-2: -15.0
agent-3: -258.0
agent-4: 4.0
agent-5: 44.0
agent-6: -375.0
agent-7: -97.0
agent-8: -75.0
agent-9: 18.0
agent-10: -358.0
Sum Reward: -1549.0
Avg Reward: -154.9
Min Reward: -437.0
Gini Coefficient -0.6224015493867011
[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
agent-1: 39.0
agent-2: -129.0
agent-3: -460.0
agent-4: -58.0
agent-5: -14.0
agent-6: -160.0
agent-7: -339.0
agent-8: -265.0
agent-9: -95.0
agent-10: 41.0
Sum Reward: -1440.0
Avg Reward: -144.0
Min Reward: -460.0
Gini Coefficient -0.6076388888888888
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-24-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -1440.0
  episode_reward_mean: -1494.5
  episode_reward_min: -1549.0
  episodes_this_iter: 2
  episodes_total: 2
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.722
    dispatch_time_ms: 6.623
    learner:
      cur_lr: 0.0013593339826911688
      grad_gnorm: 39.999996185302734
      policy_entropy: 88.01925659179688
      policy_loss: -262.69769287109375
      var_gnorm: 18.17898178100586
      vf_explained_var: -0.04601609706878662
      vf_loss: 468.7486877441406
    num_steps_sampled: 20000
    num_steps_trained: 20000
    wait_time_ms: 148.855
  iterations_since_restore: 2
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 44.83099865913391
  time_this_iter_s: 15.963650703430176
  time_total_s: 44.83099865913391
  timestamp: 1593822272
  timesteps_since_restore: 20000
  timesteps_this_iter: 10000
  timesteps_total: 20000
  training_iteration: 2
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 44 s, 2 iter, 20000 ts, -1.49e+03 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-24-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -1440.0
  episode_reward_mean: -1494.5
  episode_reward_min: -1549.0
  episodes_this_iter: 0
  episodes_total: 2
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.217
    dispatch_time_ms: 7.315
    learner:
      cur_lr: 0.0013586679706349969
      grad_gnorm: 40.00000762939453
      policy_entropy: 92.84172058105469
      policy_loss: 10.701679229736328
      var_gnorm: 18.218976974487305
      vf_explained_var: 0.1338512897491455
      vf_loss: 44.20997619628906
    num_steps_sampled: 30000
    num_steps_trained: 30000
    wait_time_ms: 147.194
  iterations_since_restore: 3
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 59.82723617553711
  time_this_iter_s: 14.996237516403198
  time_total_s: 59.82723617553711
  timestamp: 1593822287
  timesteps_since_restore: 30000
  timesteps_this_iter: 10000
  timesteps_total: 30000
  training_iteration: 3
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 59 s, 3 iter, 30000 ts, -1.49e+03 rew

agent-1: 72.0
agent-2: 48.0
agent-3: 66.0
agent-4: 25.0
agent-5: -22.0
agent-6: 92.0
agent-7: 60.0
agent-8: 47.0
agent-9: 36.0
agent-10: 49.0
Sum Reward: 473.0
Avg Reward: 47.3
Min Reward: -22.0
Gini Coefficient 0.3266384778012685
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-25-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 473.0
  episode_reward_mean: -838.6666666666666
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 3
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.826
    dispatch_time_ms: 8.224
    learner:
      cur_lr: 0.001358001958578825
      grad_gnorm: 40.00000762939453
      policy_entropy: 101.29853057861328
      policy_loss: -8.635709762573242
      var_gnorm: 18.80702018737793
      vf_explained_var: 0.12059265375137329
      vf_loss: 4.251640319824219
    num_steps_sampled: 40000
    num_steps_trained: 40000
    wait_time_ms: 161.816
  iterations_since_restore: 4
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 76.43558645248413
  time_this_iter_s: 16.60835027694702
  time_total_s: 76.43558645248413
  timestamp: 1593822304
  timesteps_since_restore: 40000
  timesteps_this_iter: 10000
  timesteps_total: 40000
  training_iteration: 4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 76 s, 4 iter, 40000 ts, -839 rew

agent-1: 56.0
agent-2: 64.0
agent-3: 51.0
agent-4: 42.0
agent-5: 63.0
agent-6: 79.0
agent-7: 86.0
agent-8: -5.0
agent-9: 60.0
agent-10: 57.0
Sum Reward: 553.0
Avg Reward: 55.3
Min Reward: -5.0
Gini Coefficient 0.21103074141048825
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-25-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: -490.75
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 4
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.913
    dispatch_time_ms: 6.644
    learner:
      cur_lr: 0.001357335946522653
      grad_gnorm: 40.000022888183594
      policy_entropy: 121.76419830322266
      policy_loss: -12.355264663696289
      var_gnorm: 19.318452835083008
      vf_explained_var: -0.16489887237548828
      vf_loss: 4.299942493438721
    num_steps_sampled: 50000
    num_steps_trained: 50000
    wait_time_ms: 163.307
  iterations_since_restore: 5
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 93.06678628921509
  time_this_iter_s: 16.631199836730957
  time_total_s: 93.06678628921509
  timestamp: 1593822320
  timesteps_since_restore: 50000
  timesteps_this_iter: 10000
  timesteps_total: 50000
  training_iteration: 5
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 93 s, 5 iter, 50000 ts, -491 rew

agent-1: 46.0
agent-2: 51.0
agent-3: 20.0
agent-4: 59.0
agent-5: 28.0
agent-6: 33.0
agent-7: 20.0
agent-8: 39.0
agent-9: -5.0
agent-10: -29.0
Sum Reward: 262.0
Avg Reward: 26.2
Min Reward: -29.0
Gini Coefficient 0.5251908396946565
agent-1: 17.0
agent-2: 30.0
agent-3: -9.0
agent-4: 26.0
agent-5: -11.0
agent-6: 28.0
agent-7: 35.0
agent-8: 29.0
agent-9: 31.0
agent-10: 32.0
Sum Reward: 208.0
Avg Reward: 20.8
Min Reward: -11.0
Gini Coefficient 0.3769230769230769
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-25-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: -248.83333333333334
  episode_reward_min: -1549.0
  episodes_this_iter: 2
  episodes_total: 6
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.573
    dispatch_time_ms: 8.589
    learner:
      cur_lr: 0.001356670050881803
      grad_gnorm: 31.199296951293945
      policy_entropy: 67.41023254394531
      policy_loss: -4.727323055267334
      var_gnorm: 19.75364875793457
      vf_explained_var: -1.0
      vf_loss: 0.5413032174110413
    num_steps_sampled: 60000
    num_steps_trained: 60000
    wait_time_ms: 163.952
  iterations_since_restore: 6
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 110.57250642776489
  time_this_iter_s: 17.505720138549805
  time_total_s: 110.57250642776489
  timestamp: 1593822338
  timesteps_since_restore: 60000
  timesteps_this_iter: 10000
  timesteps_total: 60000
  training_iteration: 6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 110 s, 6 iter, 60000 ts, -249 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-25-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: -248.83333333333334
  episode_reward_min: -1549.0
  episodes_this_iter: 0
  episodes_total: 6
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.226
    dispatch_time_ms: 7.652
    learner:
      cur_lr: 0.0013560040388256311
      grad_gnorm: 9.523991584777832
      policy_entropy: 138.48086547851562
      policy_loss: -1.1962589025497437
      var_gnorm: 21.62712287902832
      vf_explained_var: 0.2954217791557312
      vf_loss: 0.3986266255378723
    num_steps_sampled: 70000
    num_steps_trained: 70000
    wait_time_ms: 167.294
  iterations_since_restore: 7
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 127.28300547599792
  time_this_iter_s: 16.710499048233032
  time_total_s: 127.28300547599792
  timestamp: 1593822354
  timesteps_since_restore: 70000
  timesteps_this_iter: 10000
  timesteps_total: 70000
  training_iteration: 7
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 127 s, 7 iter, 70000 ts, -249 rew

agent-1: -35.0
agent-2: 45.0
agent-3: 16.0
agent-4: -27.0
agent-5: 21.0
agent-6: -28.0
agent-7: 38.0
agent-8: 26.0
agent-9: 42.0
agent-10: 27.0
Sum Reward: 125.0
Avg Reward: 12.5
Min Reward: -35.0
Gini Coefficient 1.2584
agent-1: 45.0
agent-2: -12.0
agent-3: 22.0
agent-4: 30.0
agent-5: 34.0
agent-6: 35.0
agent-7: 41.0
agent-8: 40.0
agent-9: 29.0
agent-10: 31.0
Sum Reward: 295.0
Avg Reward: 29.5
Min Reward: -12.0
Gini Coefficient 0.24372881355932202
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-26-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: -134.125
  episode_reward_min: -1549.0
  episodes_this_iter: 2
  episodes_total: 8
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.935
    dispatch_time_ms: 7.96
    learner:
      cur_lr: 0.0013553380267694592
      grad_gnorm: 33.69563293457031
      policy_entropy: 160.91879272460938
      policy_loss: 17.03787612915039
      var_gnorm: 22.2616024017334
      vf_explained_var: -1.0
      vf_loss: 0.5738883018493652
    num_steps_sampled: 80000
    num_steps_trained: 80000
    wait_time_ms: 168.434
  iterations_since_restore: 8
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 144.96244287490845
  time_this_iter_s: 17.679437398910522
  time_total_s: 144.96244287490845
  timestamp: 1593822372
  timesteps_since_restore: 80000
  timesteps_this_iter: 10000
  timesteps_total: 80000
  training_iteration: 8
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 144 s, 8 iter, 80000 ts, -134 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-26-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: -134.125
  episode_reward_min: -1549.0
  episodes_this_iter: 0
  episodes_total: 8
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.924
    dispatch_time_ms: 8.249
    learner:
      cur_lr: 0.0013546720147132874
      grad_gnorm: 7.008804798126221
      policy_entropy: 99.30799865722656
      policy_loss: -2.0108349323272705
      var_gnorm: 22.87701988220215
      vf_explained_var: -0.5157501697540283
      vf_loss: 0.25584036111831665
    num_steps_sampled: 90000
    num_steps_trained: 90000
    wait_time_ms: 155.715
  iterations_since_restore: 9
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 161.55678033828735
  time_this_iter_s: 16.594337463378906
  time_total_s: 161.55678033828735
  timestamp: 1593822389
  timesteps_since_restore: 90000
  timesteps_this_iter: 10000
  timesteps_total: 90000
  training_iteration: 9
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 161 s, 9 iter, 90000 ts, -134 rew

agent-1: 50.0
agent-2: 21.0
agent-3: 26.0
agent-4: 38.0
agent-5: 42.0
agent-6: 44.0
agent-7: 31.0
agent-8: 32.0
agent-9: 37.0
agent-10: 43.0
Sum Reward: 364.0
Avg Reward: 36.4
Min Reward: 21.0
Gini Coefficient 0.13131868131868132
agent-1: 26.0
agent-2: 31.0
agent-3: 29.0
agent-4: 42.0
agent-5: 44.0
agent-6: 34.0
agent-7: 23.0
agent-8: 27.0
agent-9: 47.0
agent-10: 48.0
Sum Reward: 351.0
Avg Reward: 35.1
Min Reward: 23.0
Gini Coefficient 0.14216524216524218
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-26-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: -35.8
  episode_reward_min: -1549.0
  episodes_this_iter: 2
  episodes_total: 10
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 4.196
    dispatch_time_ms: 7.167
    learner:
      cur_lr: 0.0013540060026571155
      grad_gnorm: 40.0
      policy_entropy: 67.3158187866211
      policy_loss: -58.518882751464844
      var_gnorm: 23.01015853881836
      vf_explained_var: -1.0
      vf_loss: 47.732452392578125
    num_steps_sampled: 100000
    num_steps_trained: 100000
    wait_time_ms: 157.184
  iterations_since_restore: 10
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 178.99173784255981
  time_this_iter_s: 17.43495750427246
  time_total_s: 178.99173784255981
  timestamp: 1593822406
  timesteps_since_restore: 100000
  timesteps_this_iter: 10000
  timesteps_total: 100000
  training_iteration: 10
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 178 s, 10 iter, 100000 ts, -35.8 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-27-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: -35.8
  episode_reward_min: -1549.0
  episodes_this_iter: 0
  episodes_total: 10
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 4.04
    dispatch_time_ms: 7.648
    learner:
      cur_lr: 0.0013533399906009436
      grad_gnorm: 7.317282199859619
      policy_entropy: 124.2490463256836
      policy_loss: -4.385499477386475
      var_gnorm: 23.483482360839844
      vf_explained_var: -1.0
      vf_loss: 0.24267981946468353
    num_steps_sampled: 110000
    num_steps_trained: 110000
    wait_time_ms: 163.599
  iterations_since_restore: 11
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 195.71931147575378
  time_this_iter_s: 16.72757363319397
  time_total_s: 195.71931147575378
  timestamp: 1593822423
  timesteps_since_restore: 110000
  timesteps_this_iter: 10000
  timesteps_total: 110000
  training_iteration: 11
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 195 s, 11 iter, 110000 ts, -35.8 rew

agent-1: 30.0
agent-2: 23.0
agent-3: 28.0
agent-4: 42.0
agent-5: -14.0
agent-6: 48.0
agent-7: 48.0
agent-8: 25.0
agent-9: 13.0
agent-10: 35.0
Sum Reward: 278.0
Avg Reward: 27.8
Min Reward: -14.0
Gini Coefficient 0.3345323741007194
agent-1: 38.0
agent-2: 23.0
agent-3: 36.0
agent-4: 21.0
agent-5: 23.0
agent-6: 27.0
agent-7: 12.0
agent-8: 29.0
agent-9: 31.0
agent-10: 37.0
Sum Reward: 277.0
Avg Reward: 27.7
Min Reward: 12.0
Gini Coefficient 0.15776173285198555
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-27-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 16.416666666666668
  episode_reward_min: -1549.0
  episodes_this_iter: 2
  episodes_total: 12
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.822
    dispatch_time_ms: 9.083
    learner:
      cur_lr: 0.0013526739785447717
      grad_gnorm: 1.1577723026275635
      policy_entropy: 114.75498962402344
      policy_loss: 0.40451109409332275
      var_gnorm: 23.528139114379883
      vf_explained_var: -1.0
      vf_loss: 0.021030977368354797
    num_steps_sampled: 120000
    num_steps_trained: 120000
    wait_time_ms: 163.403
  iterations_since_restore: 12
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 213.48614978790283
  time_this_iter_s: 17.766838312149048
  time_total_s: 213.48614978790283
  timestamp: 1593822441
  timesteps_since_restore: 120000
  timesteps_this_iter: 10000
  timesteps_total: 120000
  training_iteration: 12
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 213 s, 12 iter, 120000 ts, 16.4 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-27-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 16.416666666666668
  episode_reward_min: -1549.0
  episodes_this_iter: 0
  episodes_total: 12
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.039
    dispatch_time_ms: 6.79
    learner:
      cur_lr: 0.0013520079664885998
      grad_gnorm: 1.487694501876831
      policy_entropy: 121.38652801513672
      policy_loss: -1.1710658073425293
      var_gnorm: 23.956356048583984
      vf_explained_var: 0.8049931526184082
      vf_loss: 0.01692870631814003
    num_steps_sampled: 130000
    num_steps_trained: 130000
    wait_time_ms: 162.747
  iterations_since_restore: 13
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 230.50184726715088
  time_this_iter_s: 17.015697479248047
  time_total_s: 230.50184726715088
  timestamp: 1593822458
  timesteps_since_restore: 130000
  timesteps_this_iter: 10000
  timesteps_total: 130000
  training_iteration: 13
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 230 s, 13 iter, 130000 ts, 16.4 rew

agent-1: 15.0
agent-2: 29.0
agent-3: 21.0
agent-4: -32.0
agent-5: 31.0
agent-6: 35.0
agent-7: 31.0
agent-8: 25.0
agent-9: 36.0
agent-10: 26.0
Sum Reward: 217.0
Avg Reward: 21.7
Min Reward: -32.0
Gini Coefficient 0.3792626728110599
agent-1: 33.0
agent-2: 39.0
agent-3: 30.0
agent-4: 30.0
agent-5: 29.0
agent-6: 17.0
agent-7: 38.0
agent-8: 36.0
agent-9: 28.0
agent-10: 20.0
Sum Reward: 300.0
Avg Reward: 30.0
Min Reward: 17.0
Gini Coefficient 0.12533333333333332
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-27-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 51.0
  episode_reward_min: -1549.0
  episodes_this_iter: 2
  episodes_total: 14
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.661
    dispatch_time_ms: 6.241
    learner:
      cur_lr: 0.0013513419544324279
      grad_gnorm: 23.42806625366211
      policy_entropy: 131.92596435546875
      policy_loss: 9.802371978759766
      var_gnorm: 23.98468589782715
      vf_explained_var: -1.0
      vf_loss: 0.36839762330055237
    num_steps_sampled: 140000
    num_steps_trained: 140000
    wait_time_ms: 169.24
  iterations_since_restore: 14
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 248.27644419670105
  time_this_iter_s: 17.77459692955017
  time_total_s: 248.27644419670105
  timestamp: 1593822476
  timesteps_since_restore: 140000
  timesteps_this_iter: 10000
  timesteps_total: 140000
  training_iteration: 14
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 248 s, 14 iter, 140000 ts, 51 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-28-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 51.0
  episode_reward_min: -1549.0
  episodes_this_iter: 0
  episodes_total: 14
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.6
    dispatch_time_ms: 7.719
    learner:
      cur_lr: 0.001350675942376256
      grad_gnorm: 1.1840378046035767
      policy_entropy: 125.05326080322266
      policy_loss: 0.41141894459724426
      var_gnorm: 24.342567443847656
      vf_explained_var: -1.0
      vf_loss: 0.002164314268156886
    num_steps_sampled: 150000
    num_steps_trained: 150000
    wait_time_ms: 162.298
  iterations_since_restore: 15
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 265.4851360321045
  time_this_iter_s: 17.208691835403442
  time_total_s: 265.4851360321045
  timestamp: 1593822493
  timesteps_since_restore: 150000
  timesteps_this_iter: 10000
  timesteps_total: 150000
  training_iteration: 15
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 265 s, 15 iter, 150000 ts, 51 rew

agent-1: 19.0
agent-2: 28.0
agent-3: 25.0
agent-4: 38.0
agent-5: 30.0
agent-6: 19.0
agent-7: 24.0
agent-8: 20.0
agent-9: 24.0
agent-10: 27.0
Sum Reward: 254.0
Avg Reward: 25.4
Min Reward: 19.0
Gini Coefficient 0.1173228346456693
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-28-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 64.53333333333333
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 15
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.339
    dispatch_time_ms: 7.675
    learner:
      cur_lr: 0.001350010046735406
      grad_gnorm: 1.0117123126983643
      policy_entropy: 116.5220718383789
      policy_loss: 0.3129025995731354
      var_gnorm: 24.351478576660156
      vf_explained_var: 0.31338411569595337
      vf_loss: 0.001916954293847084
    num_steps_sampled: 160000
    num_steps_trained: 160000
    wait_time_ms: 159.83
  iterations_since_restore: 16
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 283.09511852264404
  time_this_iter_s: 17.60998249053955
  time_total_s: 283.09511852264404
  timestamp: 1593822511
  timesteps_since_restore: 160000
  timesteps_this_iter: 10000
  timesteps_total: 160000
  training_iteration: 16
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 283 s, 16 iter, 160000 ts, 64.5 rew

agent-1: 26.0
agent-2: 20.0
agent-3: 36.0
agent-4: 29.0
agent-5: 27.0
agent-6: 19.0
agent-7: 22.0
agent-8: 25.0
agent-9: 26.0
agent-10: 24.0
Sum Reward: 254.0
Avg Reward: 25.4
Min Reward: 19.0
Gini Coefficient 0.09763779527559055
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-28-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 76.375
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 16
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.47
    dispatch_time_ms: 6.137
    learner:
      cur_lr: 0.001349344034679234
      grad_gnorm: 9.616415977478027
      policy_entropy: 133.93312072753906
      policy_loss: -5.150200843811035
      var_gnorm: 24.76106071472168
      vf_explained_var: -1.0
      vf_loss: 0.23063701391220093
    num_steps_sampled: 170000
    num_steps_trained: 170000
    wait_time_ms: 162.652
  iterations_since_restore: 17
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 300.3578486442566
  time_this_iter_s: 17.26273012161255
  time_total_s: 300.3578486442566
  timestamp: 1593822528
  timesteps_since_restore: 170000
  timesteps_this_iter: 10000
  timesteps_total: 170000
  training_iteration: 17
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 300 s, 17 iter, 170000 ts, 76.4 rew

agent-1: 30.0
agent-2: 32.0
agent-3: 32.0
agent-4: 18.0
agent-5: 25.0
agent-6: 33.0
agent-7: 34.0
agent-8: 24.0
agent-9: 29.0
agent-10: 26.0
Sum Reward: 283.0
Avg Reward: 28.3
Min Reward: 18.0
Gini Coefficient 0.09222614840989399
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-29-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 88.52941176470588
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 17
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.142
    dispatch_time_ms: 7.2
    learner:
      cur_lr: 0.0013486780226230621
      grad_gnorm: 40.0
      policy_entropy: 81.7662124633789
      policy_loss: 74.07295227050781
      var_gnorm: 24.766794204711914
      vf_explained_var: -0.30046069622039795
      vf_loss: 179.85635375976562
    num_steps_sampled: 180000
    num_steps_trained: 180000
    wait_time_ms: 154.858
  iterations_since_restore: 18
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 318.05784344673157
  time_this_iter_s: 17.699994802474976
  time_total_s: 318.05784344673157
  timestamp: 1593822546
  timesteps_since_restore: 180000
  timesteps_this_iter: 10000
  timesteps_total: 180000
  training_iteration: 18
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 318 s, 18 iter, 180000 ts, 88.5 rew

agent-1: 39.0
agent-2: 21.0
agent-3: 21.0
agent-4: 21.0
agent-5: 25.0
agent-6: -29.0
agent-7: 28.0
agent-8: 16.0
agent-9: 22.0
agent-10: -27.0
Sum Reward: 137.0
Avg Reward: 13.7
Min Reward: -29.0
Gini Coefficient 0.7627737226277372
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-29-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 91.22222222222223
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 18
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 4.031
    dispatch_time_ms: 6.429
    learner:
      cur_lr: 0.0013480120105668902
      grad_gnorm: 6.0661492347717285
      policy_entropy: 121.34894561767578
      policy_loss: 0.7502090930938721
      var_gnorm: 25.27447509765625
      vf_explained_var: -0.08278965950012207
      vf_loss: 0.10893258452415466
    num_steps_sampled: 190000
    num_steps_trained: 190000
    wait_time_ms: 163.623
  iterations_since_restore: 19
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 335.3857915401459
  time_this_iter_s: 17.327948093414307
  time_total_s: 335.3857915401459
  timestamp: 1593822563
  timesteps_since_restore: 190000
  timesteps_this_iter: 10000
  timesteps_total: 190000
  training_iteration: 19
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 335 s, 19 iter, 190000 ts, 91.2 rew

agent-1: 25.0
agent-2: 28.0
agent-3: 23.0
agent-4: 23.0
agent-5: 25.0
agent-6: 24.0
agent-7: 24.0
agent-8: 24.0
agent-9: 31.0
agent-10: 16.0
Sum Reward: 243.0
Avg Reward: 24.3
Min Reward: 16.0
Gini Coefficient 0.07530864197530865
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-29-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 99.21052631578948
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 19
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.642
    dispatch_time_ms: 8.463
    learner:
      cur_lr: 0.0013473459985107183
      grad_gnorm: 1.0274789333343506
      policy_entropy: 141.04763793945312
      policy_loss: -0.029058787971735
      var_gnorm: 25.289411544799805
      vf_explained_var: -1.0
      vf_loss: 0.006489963736385107
    num_steps_sampled: 200000
    num_steps_trained: 200000
    wait_time_ms: 160.77
  iterations_since_restore: 20
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 352.9934742450714
  time_this_iter_s: 17.607682704925537
  time_total_s: 352.9934742450714
  timestamp: 1593822581
  timesteps_since_restore: 200000
  timesteps_this_iter: 10000
  timesteps_total: 200000
  training_iteration: 20
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 352 s, 20 iter, 200000 ts, 99.2 rew

agent-1: 17.0
agent-2: 20.0
agent-3: 29.0
agent-4: 26.0
agent-5: 25.0
agent-6: 17.0
agent-7: 23.0
agent-8: 21.0
agent-9: 19.0
agent-10: 21.0
Sum Reward: 218.0
Avg Reward: 21.8
Min Reward: 17.0
Gini Coefficient 0.0963302752293578
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-29-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 105.15
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 20
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.768
    dispatch_time_ms: 5.966
    learner:
      cur_lr: 0.0013466799864545465
      grad_gnorm: 6.8036370277404785
      policy_entropy: 123.15403747558594
      policy_loss: 1.1415725946426392
      var_gnorm: 25.54903793334961
      vf_explained_var: 0.5914366841316223
      vf_loss: 0.15763705968856812
    num_steps_sampled: 210000
    num_steps_trained: 210000
    wait_time_ms: 166.992
  iterations_since_restore: 21
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 370.28815817832947
  time_this_iter_s: 17.294683933258057
  time_total_s: 370.28815817832947
  timestamp: 1593822598
  timesteps_since_restore: 210000
  timesteps_this_iter: 10000
  timesteps_total: 210000
  training_iteration: 21
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 370 s, 21 iter, 210000 ts, 105 rew

agent-1: 18.0
agent-2: 30.0
agent-3: 25.0
agent-4: 20.0
agent-5: 17.0
agent-6: 17.0
agent-7: 14.0
agent-8: 18.0
agent-9: 28.0
agent-10: 23.0
Sum Reward: 210.0
Avg Reward: 21.0
Min Reward: 14.0
Gini Coefficient 0.13238095238095238
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-30-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 110.14285714285714
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 21
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.435
    dispatch_time_ms: 6.412
    learner:
      cur_lr: 0.0013460139743983746
      grad_gnorm: 1.1059620380401611
      policy_entropy: 126.10456085205078
      policy_loss: -0.1441255807876587
      var_gnorm: 25.567054748535156
      vf_explained_var: 0.9683516025543213
      vf_loss: 0.015556474216282368
    num_steps_sampled: 220000
    num_steps_trained: 220000
    wait_time_ms: 165.197
  iterations_since_restore: 22
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 387.96602630615234
  time_this_iter_s: 17.677868127822876
  time_total_s: 387.96602630615234
  timestamp: 1593822616
  timesteps_since_restore: 220000
  timesteps_this_iter: 10000
  timesteps_total: 220000
  training_iteration: 22
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 387 s, 22 iter, 220000 ts, 110 rew

agent-1: 26.0
agent-2: 23.0
agent-3: 26.0
agent-4: 28.0
agent-5: 31.0
agent-6: 20.0
agent-7: 19.0
agent-8: 29.0
agent-9: 23.0
agent-10: 33.0
Sum Reward: 258.0
Avg Reward: 25.8
Min Reward: 19.0
Gini Coefficient 0.09612403100775194
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-30-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 116.86363636363636
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 22
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.229
    dispatch_time_ms: 8.089
    learner:
      cur_lr: 0.0013453479623422027
      grad_gnorm: 0.9506545066833496
      policy_entropy: 95.25588989257812
      policy_loss: -0.23568502068519592
      var_gnorm: 25.917400360107422
      vf_explained_var: -1.0
      vf_loss: 0.006042226683348417
    num_steps_sampled: 230000
    num_steps_trained: 230000
    wait_time_ms: 166.801
  iterations_since_restore: 23
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 405.25045442581177
  time_this_iter_s: 17.284428119659424
  time_total_s: 405.25045442581177
  timestamp: 1593822633
  timesteps_since_restore: 230000
  timesteps_this_iter: 10000
  timesteps_total: 230000
  training_iteration: 23
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 405 s, 23 iter, 230000 ts, 117 rew

agent-1: 24.0
agent-2: 23.0
agent-3: 22.0
agent-4: 27.0
agent-5: 24.0
agent-6: 19.0
agent-7: 18.0
agent-8: 25.0
agent-9: 25.0
agent-10: 21.0
Sum Reward: 228.0
Avg Reward: 22.8
Min Reward: 18.0
Gini Coefficient 0.06578947368421052
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-30-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 121.69565217391305
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 23
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.917
    dispatch_time_ms: 6.009
    learner:
      cur_lr: 0.0013446819502860308
      grad_gnorm: 39.99999237060547
      policy_entropy: 37.07725524902344
      policy_loss: 36.07657241821289
      var_gnorm: 25.919513702392578
      vf_explained_var: 0.3783641457557678
      vf_loss: 122.81292724609375
    num_steps_sampled: 240000
    num_steps_trained: 240000
    wait_time_ms: 171.485
  iterations_since_restore: 24
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 423.0973105430603
  time_this_iter_s: 17.846856117248535
  time_total_s: 423.0973105430603
  timestamp: 1593822651
  timesteps_since_restore: 240000
  timesteps_this_iter: 10000
  timesteps_total: 240000
  training_iteration: 24
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 423 s, 24 iter, 240000 ts, 122 rew

agent-1: 25.0
agent-2: 33.0
agent-3: 23.0
agent-4: 24.0
agent-5: 45.0
agent-6: 20.0
agent-7: 33.0
agent-8: 13.0
agent-9: 18.0
agent-10: 27.0
Sum Reward: 261.0
Avg Reward: 26.1
Min Reward: 13.0
Gini Coefficient 0.18045977011494252
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-31-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 127.5
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 24
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.752
    dispatch_time_ms: 8.912
    learner:
      cur_lr: 0.0013440160546451807
      grad_gnorm: 1.3166732788085938
      policy_entropy: 128.987060546875
      policy_loss: -0.573796808719635
      var_gnorm: 26.12657356262207
      vf_explained_var: -0.1675560474395752
      vf_loss: 0.001191415125504136
    num_steps_sampled: 250000
    num_steps_trained: 250000
    wait_time_ms: 165.587
  iterations_since_restore: 25
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 440.20765447616577
  time_this_iter_s: 17.11034393310547
  time_total_s: 440.20765447616577
  timestamp: 1593822668
  timesteps_since_restore: 250000
  timesteps_this_iter: 10000
  timesteps_total: 250000
  training_iteration: 25
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 440 s, 25 iter, 250000 ts, 128 rew

agent-1: 22.0
agent-2: 33.0
agent-3: 20.0
agent-4: 23.0
agent-5: 28.0
agent-6: 31.0
agent-7: 27.0
agent-8: 16.0
agent-9: 32.0
agent-10: 19.0
Sum Reward: 251.0
Avg Reward: 25.1
Min Reward: 16.0
Gini Coefficient 0.12788844621513945
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-31-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 132.44
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 25
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.648
    dispatch_time_ms: 6.648
    learner:
      cur_lr: 0.0013433500425890088
      grad_gnorm: 0.05543780326843262
      policy_entropy: 131.15304565429688
      policy_loss: -1.4265664503909647e-05
      var_gnorm: 26.126535415649414
      vf_explained_var: -0.7499732971191406
      vf_loss: 5.912690781428864e-09
    num_steps_sampled: 260000
    num_steps_trained: 260000
    wait_time_ms: 167.884
  iterations_since_restore: 26
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 458.0210280418396
  time_this_iter_s: 17.813373565673828
  time_total_s: 458.0210280418396
  timestamp: 1593822686
  timesteps_since_restore: 260000
  timesteps_this_iter: 10000
  timesteps_total: 260000
  training_iteration: 26
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 458 s, 26 iter, 260000 ts, 132 rew

agent-1: 25.0
agent-2: 41.0
agent-3: 23.0
agent-4: 34.0
agent-5: 26.0
agent-6: 28.0
agent-7: 19.0
agent-8: 18.0
agent-9: 12.0
agent-10: 16.0
Sum Reward: 242.0
Avg Reward: 24.2
Min Reward: 12.0
Gini Coefficient 0.19008264462809918
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-31-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 136.65384615384616
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 26
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.612
    dispatch_time_ms: 7.861
    learner:
      cur_lr: 0.001342684030532837
      grad_gnorm: 12.215254783630371
      policy_entropy: 115.70216369628906
      policy_loss: -1.3629697561264038
      var_gnorm: 26.481542587280273
      vf_explained_var: -1.0
      vf_loss: 0.39890390634536743
    num_steps_sampled: 270000
    num_steps_trained: 270000
    wait_time_ms: 169.834
  iterations_since_restore: 27
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 475.1304678916931
  time_this_iter_s: 17.109439849853516
  time_total_s: 475.1304678916931
  timestamp: 1593822703
  timesteps_since_restore: 270000
  timesteps_this_iter: 10000
  timesteps_total: 270000
  training_iteration: 27
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 475 s, 27 iter, 270000 ts, 137 rew

agent-1: 22.0
agent-2: 27.0
agent-3: 19.0
agent-4: 23.0
agent-5: 22.0
agent-6: 28.0
agent-7: 31.0
agent-8: 33.0
agent-9: 25.0
agent-10: 30.0
Sum Reward: 260.0
Avg Reward: 26.0
Min Reward: 19.0
Gini Coefficient 0.09461538461538462
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-32-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 141.22222222222223
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 27
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.074
    dispatch_time_ms: 9.87
    learner:
      cur_lr: 0.001342018018476665
      grad_gnorm: 40.0
      policy_entropy: 43.67494583129883
      policy_loss: 109.12372589111328
      var_gnorm: 26.5065975189209
      vf_explained_var: 0.234477698802948
      vf_loss: 332.43682861328125
    num_steps_sampled: 280000
    num_steps_trained: 280000
    wait_time_ms: 155.306
  iterations_since_restore: 28
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 492.91116738319397
  time_this_iter_s: 17.780699491500854
  time_total_s: 492.91116738319397
  timestamp: 1593822721
  timesteps_since_restore: 280000
  timesteps_this_iter: 10000
  timesteps_total: 280000
  training_iteration: 28
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 492 s, 28 iter, 280000 ts, 141 rew

agent-1: 20.0
agent-2: 36.0
agent-3: 20.0
agent-4: 31.0
agent-5: 36.0
agent-6: 24.0
agent-7: 18.0
agent-8: 19.0
agent-9: 31.0
agent-10: 22.0
Sum Reward: 257.0
Avg Reward: 25.7
Min Reward: 18.0
Gini Coefficient 0.14435797665369648
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-32-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 145.35714285714286
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 28
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.865
    dispatch_time_ms: 5.956
    learner:
      cur_lr: 0.0013413520064204931
      grad_gnorm: 0.16809730231761932
      policy_entropy: 129.45452880859375
      policy_loss: -0.030888767912983894
      var_gnorm: 26.782426834106445
      vf_explained_var: -1.0
      vf_loss: 2.0885554476990364e-05
    num_steps_sampled: 290000
    num_steps_trained: 290000
    wait_time_ms: 163.377
  iterations_since_restore: 29
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 510.2313344478607
  time_this_iter_s: 17.320167064666748
  time_total_s: 510.2313344478607
  timestamp: 1593822738
  timesteps_since_restore: 290000
  timesteps_this_iter: 10000
  timesteps_total: 290000
  training_iteration: 29
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 510 s, 29 iter, 290000 ts, 145 rew

agent-1: 34.0
agent-2: 24.0
agent-3: 10.0
agent-4: 26.0
agent-5: 14.0
agent-6: 22.0
agent-7: 23.0
agent-8: 19.0
agent-9: 29.0
agent-10: 26.0
Sum Reward: 227.0
Avg Reward: 22.7
Min Reward: 10.0
Gini Coefficient 0.16255506607929515
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-32-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 148.17241379310346
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 29
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.933
    dispatch_time_ms: 8.603
    learner:
      cur_lr: 0.0013406859943643212
      grad_gnorm: 1.0028220415115356
      policy_entropy: 141.03781127929688
      policy_loss: 0.16614371538162231
      var_gnorm: 26.782169342041016
      vf_explained_var: -1.0
      vf_loss: 0.0019013008568435907
    num_steps_sampled: 300000
    num_steps_trained: 300000
    wait_time_ms: 161.957
  iterations_since_restore: 30
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 527.9806241989136
  time_this_iter_s: 17.749289751052856
  time_total_s: 527.9806241989136
  timestamp: 1593822756
  timesteps_since_restore: 300000
  timesteps_this_iter: 10000
  timesteps_total: 300000
  training_iteration: 30
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 527 s, 30 iter, 300000 ts, 148 rew

agent-1: 15.0
agent-2: 24.0
agent-3: 11.0
agent-4: 30.0
agent-5: 29.0
agent-6: 16.0
agent-7: 26.0
agent-8: 19.0
agent-9: 22.0
agent-10: 19.0
Sum Reward: 211.0
Avg Reward: 21.1
Min Reward: 11.0
Gini Coefficient 0.15971563981042655
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-32-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 150.26666666666668
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 30
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.788
    dispatch_time_ms: 7.236
    learner:
      cur_lr: 0.0013400199823081493
      grad_gnorm: 1.6222407817840576
      policy_entropy: 157.91786193847656
      policy_loss: -1.4545382261276245
      var_gnorm: 27.041244506835938
      vf_explained_var: -0.14665889739990234
      vf_loss: 0.0008933087810873985
    num_steps_sampled: 310000
    num_steps_trained: 310000
    wait_time_ms: 163.708
  iterations_since_restore: 31
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 545.3055934906006
  time_this_iter_s: 17.32496929168701
  time_total_s: 545.3055934906006
  timestamp: 1593822773
  timesteps_since_restore: 310000
  timesteps_this_iter: 10000
  timesteps_total: 310000
  training_iteration: 31
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 545 s, 31 iter, 310000 ts, 150 rew

agent-1: 26.0
agent-2: 19.0
agent-3: 19.0
agent-4: 39.0
agent-5: 40.0
agent-6: 26.0
agent-7: 16.0
agent-8: 19.0
agent-9: 19.0
agent-10: 20.0
Sum Reward: 243.0
Avg Reward: 24.3
Min Reward: 16.0
Gini Coefficient 0.1699588477366255
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-33-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 153.25806451612902
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 31
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.067
    dispatch_time_ms: 6.327
    learner:
      cur_lr: 0.0013393539702519774
      grad_gnorm: 0.3866146504878998
      policy_entropy: 161.33335876464844
      policy_loss: 0.15524612367153168
      var_gnorm: 27.06463623046875
      vf_explained_var: -0.6816248893737793
      vf_loss: 0.00025723077123984694
    num_steps_sampled: 320000
    num_steps_trained: 320000
    wait_time_ms: 160.573
  iterations_since_restore: 32
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 563.0045137405396
  time_this_iter_s: 17.698920249938965
  time_total_s: 563.0045137405396
  timestamp: 1593822791
  timesteps_since_restore: 320000
  timesteps_this_iter: 10000
  timesteps_total: 320000
  training_iteration: 32
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 563 s, 32 iter, 320000 ts, 153 rew

agent-1: 27.0
agent-2: 21.0
agent-3: 40.0
agent-4: 37.0
agent-5: 27.0
agent-6: 23.0
agent-7: 17.0
agent-8: 28.0
agent-9: 19.0
agent-10: 23.0
Sum Reward: 262.0
Avg Reward: 26.2
Min Reward: 17.0
Gini Coefficient 0.1465648854961832
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-33-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 156.65625
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 32
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.436
    dispatch_time_ms: 8.265
    learner:
      cur_lr: 0.0013386879581958055
      grad_gnorm: 7.284534454345703
      policy_entropy: 151.86245727539062
      policy_loss: -2.4698102474212646
      var_gnorm: 27.440675735473633
      vf_explained_var: -1.0
      vf_loss: 0.09701048582792282
    num_steps_sampled: 330000
    num_steps_trained: 330000
    wait_time_ms: 164.638
  iterations_since_restore: 33
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 580.1532807350159
  time_this_iter_s: 17.14876699447632
  time_total_s: 580.1532807350159
  timestamp: 1593822808
  timesteps_since_restore: 330000
  timesteps_this_iter: 10000
  timesteps_total: 330000
  training_iteration: 33
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 580 s, 33 iter, 330000 ts, 157 rew

agent-1: 22.0
agent-2: 21.0
agent-3: 32.0
agent-4: 25.0
agent-5: 16.0
agent-6: 24.0
agent-7: 19.0
agent-8: 21.0
agent-9: 13.0
agent-10: 21.0
Sum Reward: 214.0
Avg Reward: 21.4
Min Reward: 13.0
Gini Coefficient 0.12242990654205607
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-33-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 158.3939393939394
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 33
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.673
    dispatch_time_ms: 5.602
    learner:
      cur_lr: 0.0013380219461396337
      grad_gnorm: 0.7109665274620056
      policy_entropy: 155.61581420898438
      policy_loss: 0.24304388463497162
      var_gnorm: 27.487394332885742
      vf_explained_var: -1.0
      vf_loss: 0.0023976126685738564
    num_steps_sampled: 340000
    num_steps_trained: 340000
    wait_time_ms: 166.833
  iterations_since_restore: 34
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 597.9102275371552
  time_this_iter_s: 17.756946802139282
  time_total_s: 597.9102275371552
  timestamp: 1593822826
  timesteps_since_restore: 340000
  timesteps_this_iter: 10000
  timesteps_total: 340000
  training_iteration: 34
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 597 s, 34 iter, 340000 ts, 158 rew

agent-1: 30.0
agent-2: 38.0
agent-3: 32.0
agent-4: 34.0
agent-5: 14.0
agent-6: 16.0
agent-7: 18.0
agent-8: 18.0
agent-9: 33.0
agent-10: 34.0
Sum Reward: 267.0
Avg Reward: 26.7
Min Reward: 14.0
Gini Coefficient 0.1756554307116105
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-34-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 161.58823529411765
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 34
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.26
    dispatch_time_ms: 7.022
    learner:
      cur_lr: 0.0013373560504987836
      grad_gnorm: 7.416304111480713
      policy_entropy: 95.68255615234375
      policy_loss: -2.241691827774048
      var_gnorm: 27.851261138916016
      vf_explained_var: 0.8324534893035889
      vf_loss: 0.05899935960769653
    num_steps_sampled: 350000
    num_steps_trained: 350000
    wait_time_ms: 168.252
  iterations_since_restore: 35
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 615.284336566925
  time_this_iter_s: 17.374109029769897
  time_total_s: 615.284336566925
  timestamp: 1593822843
  timesteps_since_restore: 350000
  timesteps_this_iter: 10000
  timesteps_total: 350000
  training_iteration: 35
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 615 s, 35 iter, 350000 ts, 162 rew

agent-1: 23.0
agent-2: 27.0
agent-3: 25.0
agent-4: 28.0
agent-5: 26.0
agent-6: 21.0
agent-7: 27.0
agent-8: 34.0
agent-9: 23.0
agent-10: 21.0
Sum Reward: 255.0
Avg Reward: 25.5
Min Reward: 21.0
Gini Coefficient 0.0780392156862745
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-34-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 164.25714285714287
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 35
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.866
    dispatch_time_ms: 7.743
    learner:
      cur_lr: 0.0013366900384426117
      grad_gnorm: 0.4770788550376892
      policy_entropy: 118.73124694824219
      policy_loss: 0.14988744258880615
      var_gnorm: 27.86061668395996
      vf_explained_var: 0.9957975149154663
      vf_loss: 0.0006854688399471343
    num_steps_sampled: 360000
    num_steps_trained: 360000
    wait_time_ms: 169.844
  iterations_since_restore: 36
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 633.111453294754
  time_this_iter_s: 17.82711672782898
  time_total_s: 633.111453294754
  timestamp: 1593822861
  timesteps_since_restore: 360000
  timesteps_this_iter: 10000
  timesteps_total: 360000
  training_iteration: 36
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 633 s, 36 iter, 360000 ts, 164 rew

agent-1: 12.0
agent-2: 23.0
agent-3: 19.0
agent-4: 31.0
agent-5: 17.0
agent-6: 24.0
agent-7: 13.0
agent-8: 24.0
agent-9: 28.0
agent-10: 31.0
Sum Reward: 222.0
Avg Reward: 22.2
Min Reward: 12.0
Gini Coefficient 0.16576576576576577
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-34-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 165.86111111111111
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 36
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.969
    dispatch_time_ms: 7.169
    learner:
      cur_lr: 0.0013360240263864398
      grad_gnorm: 40.0
      policy_entropy: 86.14875793457031
      policy_loss: 30.196977615356445
      var_gnorm: 28.272079467773438
      vf_explained_var: 0.31645387411117554
      vf_loss: 31.23505973815918
    num_steps_sampled: 370000
    num_steps_trained: 370000
    wait_time_ms: 166.023
  iterations_since_restore: 37
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 650.1931209564209
  time_this_iter_s: 17.08166766166687
  time_total_s: 650.1931209564209
  timestamp: 1593822878
  timesteps_since_restore: 370000
  timesteps_this_iter: 10000
  timesteps_total: 370000
  training_iteration: 37
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 650 s, 37 iter, 370000 ts, 166 rew

agent-1: 42.0
agent-2: 29.0
agent-3: 26.0
agent-4: 21.0
agent-5: 36.0
agent-6: -31.0
agent-7: 35.0
agent-8: 39.0
agent-9: 17.0
agent-10: 41.0
Sum Reward: 255.0
Avg Reward: 25.5
Min Reward: -31.0
Gini Coefficient 0.3729411764705882
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-34-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 168.27027027027026
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 37
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.655
    dispatch_time_ms: 8.417
    learner:
      cur_lr: 0.001335358014330268
      grad_gnorm: 0.4489225745201111
      policy_entropy: 150.74777221679688
      policy_loss: -0.1822780817747116
      var_gnorm: 28.326017379760742
      vf_explained_var: 0.9959670901298523
      vf_loss: 0.0007130237645469606
    num_steps_sampled: 380000
    num_steps_trained: 380000
    wait_time_ms: 167.574
  iterations_since_restore: 38
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 667.887665271759
  time_this_iter_s: 17.694544315338135
  time_total_s: 667.887665271759
  timestamp: 1593822896
  timesteps_since_restore: 380000
  timesteps_this_iter: 10000
  timesteps_total: 380000
  training_iteration: 38
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 667 s, 38 iter, 380000 ts, 168 rew

agent-1: 23.0
agent-2: 33.0
agent-3: 16.0
agent-4: 32.0
agent-5: 25.0
agent-6: 35.0
agent-7: 19.0
agent-8: 32.0
agent-9: 39.0
agent-10: 25.0
Sum Reward: 279.0
Avg Reward: 27.9
Min Reward: 16.0
Gini Coefficient 0.14229390681003584
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-35-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 171.18421052631578
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 38
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.973
    dispatch_time_ms: 6.222
    learner:
      cur_lr: 0.001334692002274096
      grad_gnorm: 15.23738956451416
      policy_entropy: 108.72432708740234
      policy_loss: -1.7259517908096313
      var_gnorm: 28.59113311767578
      vf_explained_var: -1.0
      vf_loss: 0.10993227362632751
    num_steps_sampled: 390000
    num_steps_trained: 390000
    wait_time_ms: 166.575
  iterations_since_restore: 39
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 684.7392017841339
  time_this_iter_s: 16.851536512374878
  time_total_s: 684.7392017841339
  timestamp: 1593822913
  timesteps_since_restore: 390000
  timesteps_this_iter: 10000
  timesteps_total: 390000
  training_iteration: 39
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 684 s, 39 iter, 390000 ts, 171 rew

agent-1: 35.0
agent-2: 45.0
agent-3: 42.0
agent-4: 26.0
agent-5: 41.0
agent-6: 26.0
agent-7: 30.0
agent-8: 25.0
agent-9: 41.0
agent-10: 47.0
Sum Reward: 358.0
Avg Reward: 35.8
Min Reward: 25.0
Gini Coefficient 0.12569832402234637
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-35-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 175.97435897435898
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 39
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.806
    dispatch_time_ms: 6.474
    learner:
      cur_lr: 0.0013340259902179241
      grad_gnorm: 40.00001525878906
      policy_entropy: 53.5300407409668
      policy_loss: 94.99414825439453
      var_gnorm: 28.616291046142578
      vf_explained_var: 0.002866387367248535
      vf_loss: 232.9668426513672
    num_steps_sampled: 400000
    num_steps_trained: 400000
    wait_time_ms: 153.655
  iterations_since_restore: 40
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 702.3208498954773
  time_this_iter_s: 17.581648111343384
  time_total_s: 702.3208498954773
  timestamp: 1593822931
  timesteps_since_restore: 400000
  timesteps_this_iter: 10000
  timesteps_total: 400000
  training_iteration: 40
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 702 s, 40 iter, 400000 ts, 176 rew

agent-1: 22.0
agent-2: 28.0
agent-3: 29.0
agent-4: 29.0
agent-5: 28.0
agent-6: 35.0
agent-7: 24.0
agent-8: 28.0
agent-9: 32.0
agent-10: 48.0
Sum Reward: 303.0
Avg Reward: 30.3
Min Reward: 22.0
Gini Coefficient 0.11056105610561057
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-35-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 179.15
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 40
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.76
    dispatch_time_ms: 6.977
    learner:
      cur_lr: 0.0013333599781617522
      grad_gnorm: 0.3625531792640686
      policy_entropy: 117.68348693847656
      policy_loss: -0.18342988193035126
      var_gnorm: 28.77091407775879
      vf_explained_var: 0.1351027488708496
      vf_loss: 7.226695015560836e-05
    num_steps_sampled: 410000
    num_steps_trained: 410000
    wait_time_ms: 172.389
  iterations_since_restore: 41
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 719.5339908599854
  time_this_iter_s: 17.213140964508057
  time_total_s: 719.5339908599854
  timestamp: 1593822948
  timesteps_since_restore: 410000
  timesteps_this_iter: 10000
  timesteps_total: 410000
  training_iteration: 41
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 719 s, 41 iter, 410000 ts, 179 rew

agent-1: 30.0
agent-2: 18.0
agent-3: 27.0
agent-4: 22.0
agent-5: 21.0
agent-6: 33.0
agent-7: 19.0
agent-8: 28.0
agent-9: 28.0
agent-10: 16.0
Sum Reward: 242.0
Avg Reward: 24.2
Min Reward: 16.0
Gini Coefficient 0.12727272727272726
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-36-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 180.6829268292683
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 41
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 4.035
    dispatch_time_ms: 6.267
    learner:
      cur_lr: 0.0013326939661055803
      grad_gnorm: 14.24591064453125
      policy_entropy: 135.7989959716797
      policy_loss: -1.4658557176589966
      var_gnorm: 28.79338836669922
      vf_explained_var: -0.9216818809509277
      vf_loss: 0.14029532670974731
    num_steps_sampled: 420000
    num_steps_trained: 420000
    wait_time_ms: 166.335
  iterations_since_restore: 42
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 737.0968329906464
  time_this_iter_s: 17.56284213066101
  time_total_s: 737.0968329906464
  timestamp: 1593822965
  timesteps_since_restore: 420000
  timesteps_this_iter: 10000
  timesteps_total: 420000
  training_iteration: 42
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 737 s, 42 iter, 420000 ts, 181 rew

agent-1: 24.0
agent-2: 28.0
agent-3: 19.0
agent-4: 35.0
agent-5: 33.0
agent-6: 27.0
agent-7: 40.0
agent-8: 20.0
agent-9: 18.0
agent-10: 26.0
Sum Reward: 270.0
Avg Reward: 27.0
Min Reward: 18.0
Gini Coefficient 0.1437037037037037
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-36-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 182.8095238095238
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 42
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.549
    dispatch_time_ms: 11.542
    learner:
      cur_lr: 0.0013320279540494084
      grad_gnorm: 9.289040565490723
      policy_entropy: 130.3527069091797
      policy_loss: -0.31942325830459595
      var_gnorm: 28.978195190429688
      vf_explained_var: -0.9349273443222046
      vf_loss: 0.19034095108509064
    num_steps_sampled: 430000
    num_steps_trained: 430000
    wait_time_ms: 160.282
  iterations_since_restore: 43
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 754.4591248035431
  time_this_iter_s: 17.36229181289673
  time_total_s: 754.4591248035431
  timestamp: 1593822983
  timesteps_since_restore: 430000
  timesteps_this_iter: 10000
  timesteps_total: 430000
  training_iteration: 43
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 754 s, 43 iter, 430000 ts, 183 rew

agent-1: 25.0
agent-2: 19.0
agent-3: 21.0
agent-4: 24.0
agent-5: 22.0
agent-6: 25.0
agent-7: 19.0
agent-8: 24.0
agent-9: 22.0
agent-10: 30.0
Sum Reward: 231.0
Avg Reward: 23.1
Min Reward: 19.0
Gini Coefficient 0.07316017316017316
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-36-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 183.93023255813952
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 43
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.606
    dispatch_time_ms: 6.653
    learner:
      cur_lr: 0.0013313619419932365
      grad_gnorm: 0.9571486115455627
      policy_entropy: 150.23094177246094
      policy_loss: -0.1417301744222641
      var_gnorm: 28.988452911376953
      vf_explained_var: -0.7696306705474854
      vf_loss: 0.009485404007136822
    num_steps_sampled: 440000
    num_steps_trained: 440000
    wait_time_ms: 168.738
  iterations_since_restore: 44
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 772.0970184803009
  time_this_iter_s: 17.637893676757812
  time_total_s: 772.0970184803009
  timestamp: 1593823001
  timesteps_since_restore: 440000
  timesteps_this_iter: 10000
  timesteps_total: 440000
  training_iteration: 44
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 772 s, 44 iter, 440000 ts, 184 rew

agent-1: 23.0
agent-2: 20.0
agent-3: 34.0
agent-4: 37.0
agent-5: 27.0
agent-6: 22.0
agent-7: 14.0
agent-8: 24.0
agent-9: 18.0
agent-10: 23.0
Sum Reward: 242.0
Avg Reward: 24.2
Min Reward: 14.0
Gini Coefficient 0.1487603305785124
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-36-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 185.25
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 44
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.874
    dispatch_time_ms: 6.079
    learner:
      cur_lr: 0.0013306960463523865
      grad_gnorm: 7.499338626861572
      policy_entropy: 154.03746032714844
      policy_loss: -2.1009089946746826
      var_gnorm: 29.193077087402344
      vf_explained_var: -1.0
      vf_loss: 0.03259620442986488
    num_steps_sampled: 450000
    num_steps_trained: 450000
    wait_time_ms: 165.238
  iterations_since_restore: 45
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 789.2824165821075
  time_this_iter_s: 17.18539810180664
  time_total_s: 789.2824165821075
  timestamp: 1593823018
  timesteps_since_restore: 450000
  timesteps_this_iter: 10000
  timesteps_total: 450000
  training_iteration: 45
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 789 s, 45 iter, 450000 ts, 185 rew

agent-1: 24.0
agent-2: 23.0
agent-3: 25.0
agent-4: 17.0
agent-5: 24.0
agent-6: 27.0
agent-7: 32.0
agent-8: 24.0
agent-9: 36.0
agent-10: 28.0
Sum Reward: 260.0
Avg Reward: 26.0
Min Reward: 17.0
Gini Coefficient 0.10153846153846154
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-37-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 186.9111111111111
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 45
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.967
    dispatch_time_ms: 7.649
    learner:
      cur_lr: 0.0013300300342962146
      grad_gnorm: 39.99998092651367
      policy_entropy: 73.6257095336914
      policy_loss: 73.2916488647461
      var_gnorm: 29.252626419067383
      vf_explained_var: 0.21385681629180908
      vf_loss: 136.064453125
    num_steps_sampled: 460000
    num_steps_trained: 460000
    wait_time_ms: 150.534
  iterations_since_restore: 46
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 806.9270725250244
  time_this_iter_s: 17.64465594291687
  time_total_s: 806.9270725250244
  timestamp: 1593823035
  timesteps_since_restore: 460000
  timesteps_this_iter: 10000
  timesteps_total: 460000
  training_iteration: 46
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 806 s, 46 iter, 460000 ts, 187 rew

agent-1: 18.0
agent-2: 25.0
agent-3: 30.0
agent-4: 24.0
agent-5: 22.0
agent-6: 28.0
agent-7: 21.0
agent-8: 27.0
agent-9: 32.0
agent-10: 19.0
Sum Reward: 246.0
Avg Reward: 24.6
Min Reward: 18.0
Gini Coefficient 0.10325203252032521
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-37-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 188.19565217391303
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 46
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.559
    dispatch_time_ms: 8.876
    learner:
      cur_lr: 0.0013293640222400427
      grad_gnorm: 10.386398315429688
      policy_entropy: 108.87161254882812
      policy_loss: -3.524573564529419
      var_gnorm: 29.694814682006836
      vf_explained_var: 0.8694754838943481
      vf_loss: 0.06756377220153809
    num_steps_sampled: 470000
    num_steps_trained: 470000
    wait_time_ms: 163.055
  iterations_since_restore: 47
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 824.3657946586609
  time_this_iter_s: 17.438722133636475
  time_total_s: 824.3657946586609
  timestamp: 1593823053
  timesteps_since_restore: 470000
  timesteps_this_iter: 10000
  timesteps_total: 470000
  training_iteration: 47
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 824 s, 47 iter, 470000 ts, 188 rew

agent-1: 22.0
agent-2: 28.0
agent-3: 35.0
agent-4: 36.0
agent-5: 25.0
agent-6: 21.0
agent-7: 24.0
agent-8: 28.0
agent-9: 31.0
agent-10: 30.0
Sum Reward: 280.0
Avg Reward: 28.0
Min Reward: 21.0
Gini Coefficient 0.09857142857142857
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-37-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 190.14893617021278
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 47
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.016
    dispatch_time_ms: 9.984
    learner:
      cur_lr: 0.0013286980101838708
      grad_gnorm: 39.99999237060547
      policy_entropy: 35.017234802246094
      policy_loss: 51.1361198425293
      var_gnorm: 29.71413230895996
      vf_explained_var: 0.7833995819091797
      vf_loss: 161.86268615722656
    num_steps_sampled: 480000
    num_steps_trained: 480000
    wait_time_ms: 146.107
  iterations_since_restore: 48
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 841.8891336917877
  time_this_iter_s: 17.52333903312683
  time_total_s: 841.8891336917877
  timestamp: 1593823070
  timesteps_since_restore: 480000
  timesteps_this_iter: 10000
  timesteps_total: 480000
  training_iteration: 48
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 841 s, 48 iter, 480000 ts, 190 rew

agent-1: 23.0
agent-2: 27.0
agent-3: 20.0
agent-4: 31.0
agent-5: 24.0
agent-6: 32.0
agent-7: 18.0
agent-8: 22.0
agent-9: 23.0
agent-10: 20.0
Sum Reward: 240.0
Avg Reward: 24.0
Min Reward: 18.0
Gini Coefficient 0.10166666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-38-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 191.1875
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 48
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.853
    dispatch_time_ms: 6.165
    learner:
      cur_lr: 0.001328031998127699
      grad_gnorm: 4.714571475982666
      policy_entropy: 110.85836791992188
      policy_loss: 0.3034440875053406
      var_gnorm: 29.96685791015625
      vf_explained_var: -1.0
      vf_loss: 0.03107430785894394
    num_steps_sampled: 490000
    num_steps_trained: 490000
    wait_time_ms: 166.437
  iterations_since_restore: 49
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 859.1489543914795
  time_this_iter_s: 17.259820699691772
  time_total_s: 859.1489543914795
  timestamp: 1593823088
  timesteps_since_restore: 490000
  timesteps_this_iter: 10000
  timesteps_total: 490000
  training_iteration: 49
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 859 s, 49 iter, 490000 ts, 191 rew

agent-1: 33.0
agent-2: 16.0
agent-3: 31.0
agent-4: 22.0
agent-5: 50.0
agent-6: 45.0
agent-7: 14.0
agent-8: 27.0
agent-9: 23.0
agent-10: 24.0
Sum Reward: 285.0
Avg Reward: 28.5
Min Reward: 14.0
Gini Coefficient 0.21368421052631578
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-38-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 193.10204081632654
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 49
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.313
    dispatch_time_ms: 8.908
    learner:
      cur_lr: 0.001327365986071527
      grad_gnorm: 40.000003814697266
      policy_entropy: 40.89091110229492
      policy_loss: 8.932660102844238
      var_gnorm: 29.976078033447266
      vf_explained_var: 0.12019610404968262
      vf_loss: 145.9237060546875
    num_steps_sampled: 500000
    num_steps_trained: 500000
    wait_time_ms: 143.274
  iterations_since_restore: 50
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 876.767139673233
  time_this_iter_s: 17.61818528175354
  time_total_s: 876.767139673233
  timestamp: 1593823105
  timesteps_since_restore: 500000
  timesteps_this_iter: 10000
  timesteps_total: 500000
  training_iteration: 50
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 876 s, 50 iter, 500000 ts, 193 rew

agent-1: 22.0
agent-2: 20.0
agent-3: 38.0
agent-4: 26.0
agent-5: 36.0
agent-6: 16.0
agent-7: 21.0
agent-8: 13.0
agent-9: 17.0
agent-10: 25.0
Sum Reward: 234.0
Avg Reward: 23.4
Min Reward: 13.0
Gini Coefficient 0.18205128205128204
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-38-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 193.92
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 50
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.962
    dispatch_time_ms: 5.984
    learner:
      cur_lr: 0.0013266999740153551
      grad_gnorm: 0.942931592464447
      policy_entropy: 141.14259338378906
      policy_loss: 0.27072983980178833
      var_gnorm: 30.13543128967285
      vf_explained_var: 0.9460599422454834
      vf_loss: 0.0017967657186090946
    num_steps_sampled: 510000
    num_steps_trained: 510000
    wait_time_ms: 177.369
  iterations_since_restore: 51
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 894.2363998889923
  time_this_iter_s: 17.469260215759277
  time_total_s: 894.2363998889923
  timestamp: 1593823123
  timesteps_since_restore: 510000
  timesteps_this_iter: 10000
  timesteps_total: 510000
  training_iteration: 51
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 894 s, 51 iter, 510000 ts, 194 rew

agent-1: 24.0
agent-2: 17.0
agent-3: 23.0
agent-4: 31.0
agent-5: 29.0
agent-6: 16.0
agent-7: 22.0
agent-8: 25.0
agent-9: 14.0
agent-10: 22.0
Sum Reward: 223.0
Avg Reward: 22.3
Min Reward: 14.0
Gini Coefficient 0.1304932735426009
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-39-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 194.49019607843138
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 51
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.37
    dispatch_time_ms: 7.827
    learner:
      cur_lr: 0.0013260339619591832
      grad_gnorm: 0.5582893490791321
      policy_entropy: 157.2890167236328
      policy_loss: -0.01749134249985218
      var_gnorm: 30.135587692260742
      vf_explained_var: 0.9925606846809387
      vf_loss: 0.00022732227807864547
    num_steps_sampled: 520000
    num_steps_trained: 520000
    wait_time_ms: 165.297
  iterations_since_restore: 52
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 911.7544550895691
  time_this_iter_s: 17.518055200576782
  time_total_s: 911.7544550895691
  timestamp: 1593823140
  timesteps_since_restore: 520000
  timesteps_this_iter: 10000
  timesteps_total: 520000
  training_iteration: 52
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 911 s, 52 iter, 520000 ts, 194 rew

agent-1: 20.0
agent-2: 35.0
agent-3: 19.0
agent-4: 24.0
agent-5: 29.0
agent-6: 30.0
agent-7: 38.0
agent-8: 43.0
agent-9: 25.0
agent-10: 31.0
Sum Reward: 294.0
Avg Reward: 29.4
Min Reward: 19.0
Gini Coefficient 0.1414965986394558
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-39-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 196.40384615384616
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 52
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.696
    dispatch_time_ms: 6.574
    learner:
      cur_lr: 0.0013253679499030113
      grad_gnorm: 1.7405387163162231
      policy_entropy: 119.8148193359375
      policy_loss: 0.6951147317886353
      var_gnorm: 30.296186447143555
      vf_explained_var: -1.0
      vf_loss: 0.009650035761296749
    num_steps_sampled: 530000
    num_steps_trained: 530000
    wait_time_ms: 171.291
  iterations_since_restore: 53
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 929.2430698871613
  time_this_iter_s: 17.488614797592163
  time_total_s: 929.2430698871613
  timestamp: 1593823158
  timesteps_since_restore: 530000
  timesteps_this_iter: 10000
  timesteps_total: 530000
  training_iteration: 53
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 929 s, 53 iter, 530000 ts, 196 rew

agent-1: 19.0
agent-2: 29.0
agent-3: 38.0
agent-4: 18.0
agent-5: 17.0
agent-6: 18.0
agent-7: 28.0
agent-8: 27.0
agent-9: 31.0
agent-10: 32.0
Sum Reward: 257.0
Avg Reward: 25.7
Min Reward: 17.0
Gini Coefficient 0.1490272373540856
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-39-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 197.54716981132074
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 53
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.691
    dispatch_time_ms: 6.852
    learner:
      cur_lr: 0.0013247020542621613
      grad_gnorm: 4.919396877288818
      policy_entropy: 145.52235412597656
      policy_loss: -0.2537563443183899
      var_gnorm: 30.29497528076172
      vf_explained_var: -1.0
      vf_loss: 0.01495834905654192
    num_steps_sampled: 540000
    num_steps_trained: 540000
    wait_time_ms: 167.695
  iterations_since_restore: 54
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 946.8648176193237
  time_this_iter_s: 17.621747732162476
  time_total_s: 946.8648176193237
  timestamp: 1593823176
  timesteps_since_restore: 540000
  timesteps_this_iter: 10000
  timesteps_total: 540000
  training_iteration: 54
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 946 s, 54 iter, 540000 ts, 198 rew

agent-1: 26.0
agent-2: 27.0
agent-3: 27.0
agent-4: 23.0
agent-5: 27.0
agent-6: 10.0
agent-7: 26.0
agent-8: 22.0
agent-9: 32.0
agent-10: 11.0
Sum Reward: 231.0
Avg Reward: 23.1
Min Reward: 10.0
Gini Coefficient 0.15021645021645022
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-39-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 198.16666666666666
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 54
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.211
    dispatch_time_ms: 8.968
    learner:
      cur_lr: 0.0013240360422059894
      grad_gnorm: 1.553828239440918
      policy_entropy: 144.30101013183594
      policy_loss: -0.38237786293029785
      var_gnorm: 30.6462345123291
      vf_explained_var: 0.9406124353408813
      vf_loss: 0.008472556248307228
    num_steps_sampled: 550000
    num_steps_trained: 550000
    wait_time_ms: 162.672
  iterations_since_restore: 55
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 964.261697769165
  time_this_iter_s: 17.39688014984131
  time_total_s: 964.261697769165
  timestamp: 1593823193
  timesteps_since_restore: 550000
  timesteps_this_iter: 10000
  timesteps_total: 550000
  training_iteration: 55
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 964 s, 55 iter, 550000 ts, 198 rew

agent-1: 30.0
agent-2: 32.0
agent-3: 18.0
agent-4: 24.0
agent-5: 30.0
agent-6: 24.0
agent-7: 24.0
agent-8: 28.0
agent-9: 13.0
agent-10: 20.0
Sum Reward: 243.0
Avg Reward: 24.3
Min Reward: 13.0
Gini Coefficient 0.13045267489711934
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-40-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 198.98181818181817
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 55
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.87
    dispatch_time_ms: 7.745
    learner:
      cur_lr: 0.0013233700301498175
      grad_gnorm: 39.999996185302734
      policy_entropy: 67.88016510009766
      policy_loss: 19.15631103515625
      var_gnorm: 30.649667739868164
      vf_explained_var: -0.1388843059539795
      vf_loss: 55.34739685058594
    num_steps_sampled: 560000
    num_steps_trained: 560000
    wait_time_ms: 146.589
  iterations_since_restore: 56
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 981.7416989803314
  time_this_iter_s: 17.480001211166382
  time_total_s: 981.7416989803314
  timestamp: 1593823211
  timesteps_since_restore: 560000
  timesteps_this_iter: 10000
  timesteps_total: 560000
  training_iteration: 56
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 981 s, 56 iter, 560000 ts, 199 rew

agent-1: 27.0
agent-2: 22.0
agent-3: 17.0
agent-4: 16.0
agent-5: 25.0
agent-6: 29.0
agent-7: 25.0
agent-8: 21.0
agent-9: 20.0
agent-10: 24.0
Sum Reward: 226.0
Avg Reward: 22.6
Min Reward: 16.0
Gini Coefficient 0.1
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-40-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 199.46428571428572
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 56
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 4.496
    dispatch_time_ms: 7.716
    learner:
      cur_lr: 0.0013227040180936456
      grad_gnorm: 3.686875820159912
      policy_entropy: 141.2300262451172
      policy_loss: -0.6669403314590454
      var_gnorm: 30.96957015991211
      vf_explained_var: -1.0
      vf_loss: 0.004796852823346853
    num_steps_sampled: 570000
    num_steps_trained: 570000
    wait_time_ms: 165.896
  iterations_since_restore: 57
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 999.2500309944153
  time_this_iter_s: 17.508332014083862
  time_total_s: 999.2500309944153
  timestamp: 1593823228
  timesteps_since_restore: 570000
  timesteps_this_iter: 10000
  timesteps_total: 570000
  training_iteration: 57
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 999 s, 57 iter, 570000 ts, 199 rew

agent-1: 21.0
agent-2: 30.0
agent-3: 22.0
agent-4: 25.0
agent-5: 35.0
agent-6: 32.0
agent-7: 14.0
agent-8: 26.0
agent-9: 22.0
agent-10: 22.0
Sum Reward: 249.0
Avg Reward: 24.9
Min Reward: 14.0
Gini Coefficient 0.12891566265060242
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-40-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 200.33333333333334
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 57
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.555
    dispatch_time_ms: 5.906
    learner:
      cur_lr: 0.0013220380060374737
      grad_gnorm: 40.0
      policy_entropy: 27.587369918823242
      policy_loss: -32.9492301940918
      var_gnorm: 30.979463577270508
      vf_explained_var: 0.43317973613739014
      vf_loss: 217.57090759277344
    num_steps_sampled: 580000
    num_steps_trained: 580000
    wait_time_ms: 147.203
  iterations_since_restore: 58
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 1016.7848448753357
  time_this_iter_s: 17.53481388092041
  time_total_s: 1016.7848448753357
  timestamp: 1593823246
  timesteps_since_restore: 580000
  timesteps_this_iter: 10000
  timesteps_total: 580000
  training_iteration: 58
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 1016 s, 58 iter, 580000 ts, 200 rew

agent-1: 19.0
agent-2: 32.0
agent-3: 33.0
agent-4: 17.0
agent-5: 20.0
agent-6: 28.0
agent-7: 21.0
agent-8: 15.0
agent-9: 18.0
agent-10: 25.0
Sum Reward: 228.0
Avg Reward: 22.8
Min Reward: 15.0
Gini Coefficient 0.14736842105263157
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-41-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 200.81034482758622
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 58
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.515
    dispatch_time_ms: 7.351
    learner:
      cur_lr: 0.0013213719939813018
      grad_gnorm: 10.80414867401123
      policy_entropy: 114.6019515991211
      policy_loss: -3.764652967453003
      var_gnorm: 31.28872299194336
      vf_explained_var: 0.1433115005493164
      vf_loss: 0.8521581292152405
    num_steps_sampled: 590000
    num_steps_trained: 590000
    wait_time_ms: 163.928
  iterations_since_restore: 59
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 1033.9532101154327
  time_this_iter_s: 17.168365240097046
  time_total_s: 1033.9532101154327
  timestamp: 1593823263
  timesteps_since_restore: 590000
  timesteps_this_iter: 10000
  timesteps_total: 590000
  training_iteration: 59
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 1033 s, 59 iter, 590000 ts, 201 rew

agent-1: 29.0
agent-2: 21.0
agent-3: 24.0
agent-4: 19.0
agent-5: 23.0
agent-6: 27.0
agent-7: 17.0
agent-8: 29.0
agent-9: 19.0
agent-10: 30.0
Sum Reward: 238.0
Avg Reward: 23.8
Min Reward: 17.0
Gini Coefficient 0.10756302521008404
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-41-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 201.4406779661017
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 59
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.627
    dispatch_time_ms: 6.687
    learner:
      cur_lr: 0.0013207059819251299
      grad_gnorm: 9.78569221496582
      policy_entropy: 145.88400268554688
      policy_loss: -0.323326051235199
      var_gnorm: 31.31001853942871
      vf_explained_var: -1.0
      vf_loss: 0.0033232460264116526
    num_steps_sampled: 600000
    num_steps_trained: 600000
    wait_time_ms: 172.756
  iterations_since_restore: 60
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 1051.660442829132
  time_this_iter_s: 17.70723271369934
  time_total_s: 1051.660442829132
  timestamp: 1593823281
  timesteps_since_restore: 600000
  timesteps_this_iter: 10000
  timesteps_total: 600000
  training_iteration: 60
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 1051 s, 60 iter, 600000 ts, 201 rew

agent-1: 47.0
agent-2: 36.0
agent-3: 26.0
agent-4: 27.0
agent-5: 37.0
agent-6: 22.0
agent-7: 37.0
agent-8: 37.0
agent-9: 28.0
agent-10: 28.0
Sum Reward: 325.0
Avg Reward: 32.5
Min Reward: 22.0
Gini Coefficient 0.11907692307692308
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-41-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 203.5
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 60
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.5
    dispatch_time_ms: 6.812
    learner:
      cur_lr: 0.001320039969868958
      grad_gnorm: 1.655745506286621
      policy_entropy: 158.37745666503906
      policy_loss: -0.28443872928619385
      var_gnorm: 31.44025421142578
      vf_explained_var: -1.0
      vf_loss: 0.004528393968939781
    num_steps_sampled: 610000
    num_steps_trained: 610000
    wait_time_ms: 168.996
  iterations_since_restore: 61
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 1069.0067510604858
  time_this_iter_s: 17.34630823135376
  time_total_s: 1069.0067510604858
  timestamp: 1593823298
  timesteps_since_restore: 610000
  timesteps_this_iter: 10000
  timesteps_total: 610000
  training_iteration: 61
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 1069 s, 61 iter, 610000 ts, 204 rew

agent-1: 24.0
agent-2: 22.0
agent-3: 16.0
agent-4: 28.0
agent-5: 26.0
agent-6: 20.0
agent-7: 23.0
agent-8: 17.0
agent-9: 12.0
agent-10: 35.0
Sum Reward: 223.0
Avg Reward: 22.3
Min Reward: 12.0
Gini Coefficient 0.15650224215246636
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-41-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 203.81967213114754
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 61
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.116
    dispatch_time_ms: 7.981
    learner:
      cur_lr: 0.001319373957812786
      grad_gnorm: 40.0
      policy_entropy: 60.29498291015625
      policy_loss: -4.51407527923584
      var_gnorm: 31.450729370117188
      vf_explained_var: 0.18246722221374512
      vf_loss: 93.83611297607422
    num_steps_sampled: 620000
    num_steps_trained: 620000
    wait_time_ms: 152.801
  iterations_since_restore: 62
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 1086.6446979045868
  time_this_iter_s: 17.637946844100952
  time_total_s: 1086.6446979045868
  timestamp: 1593823316
  timesteps_since_restore: 620000
  timesteps_this_iter: 10000
  timesteps_total: 620000
  training_iteration: 62
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 1086 s, 62 iter, 620000 ts, 204 rew

agent-1: 39.0
agent-2: 20.0
agent-3: 23.0
agent-4: 41.0
agent-5: 19.0
agent-6: 21.0
agent-7: 15.0
agent-8: 21.0
agent-9: 25.0
agent-10: 21.0
Sum Reward: 245.0
Avg Reward: 24.5
Min Reward: 15.0
Gini Coefficient 0.1653061224489796
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-42-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 204.48387096774192
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 62
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.395
    dispatch_time_ms: 7.892
    learner:
      cur_lr: 0.0013187079457566142
      grad_gnorm: 1.4195871353149414
      policy_entropy: 156.31309509277344
      policy_loss: 0.4825022518634796
      var_gnorm: 31.701128005981445
      vf_explained_var: -1.0
      vf_loss: 0.0024682956282049417
    num_steps_sampled: 630000
    num_steps_trained: 630000
    wait_time_ms: 166.724
  iterations_since_restore: 63
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 1104.1222269535065
  time_this_iter_s: 17.477529048919678
  time_total_s: 1104.1222269535065
  timestamp: 1593823333
  timesteps_since_restore: 630000
  timesteps_this_iter: 10000
  timesteps_total: 630000
  training_iteration: 63
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 1104 s, 63 iter, 630000 ts, 204 rew

agent-1: 17.0
agent-2: 23.0
agent-3: 21.0
agent-4: 24.0
agent-5: 26.0
agent-6: 19.0
agent-7: 19.0
agent-8: 38.0
agent-9: 19.0
agent-10: 27.0
Sum Reward: 233.0
Avg Reward: 23.3
Min Reward: 17.0
Gini Coefficient 0.1274678111587983
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-42-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 204.93650793650792
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 63
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.037
    dispatch_time_ms: 6.379
    learner:
      cur_lr: 0.0013180420501157641
      grad_gnorm: 1.7521716356277466
      policy_entropy: 161.42657470703125
      policy_loss: -0.1005290299654007
      var_gnorm: 31.702884674072266
      vf_explained_var: -0.6854524612426758
      vf_loss: 0.0016098078340291977
    num_steps_sampled: 640000
    num_steps_trained: 640000
    wait_time_ms: 166.04
  iterations_since_restore: 64
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 1121.7652659416199
  time_this_iter_s: 17.643038988113403
  time_total_s: 1121.7652659416199
  timestamp: 1593823351
  timesteps_since_restore: 640000
  timesteps_this_iter: 10000
  timesteps_total: 640000
  training_iteration: 64
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 1121 s, 64 iter, 640000 ts, 205 rew

agent-1: 21.0
agent-2: 16.0
agent-3: 20.0
agent-4: 24.0
agent-5: 22.0
agent-6: 24.0
agent-7: 26.0
agent-8: 18.0
agent-9: 24.0
agent-10: 24.0
Sum Reward: 219.0
Avg Reward: 21.9
Min Reward: 16.0
Gini Coefficient 0.07442922374429224
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-42-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 205.15625
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 64
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.7
    dispatch_time_ms: 8.362
    learner:
      cur_lr: 0.0013173760380595922
      grad_gnorm: 2.698455810546875
      policy_entropy: 142.0143280029297
      policy_loss: -0.8843366503715515
      var_gnorm: 31.96894645690918
      vf_explained_var: -0.10770738124847412
      vf_loss: 0.0006661646766588092
    num_steps_sampled: 650000
    num_steps_trained: 650000
    wait_time_ms: 163.69
  iterations_since_restore: 65
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 1139.2405333518982
  time_this_iter_s: 17.47526741027832
  time_total_s: 1139.2405333518982
  timestamp: 1593823368
  timesteps_since_restore: 650000
  timesteps_this_iter: 10000
  timesteps_total: 650000
  training_iteration: 65
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 1139 s, 65 iter, 650000 ts, 205 rew

agent-1: 26.0
agent-2: 20.0
agent-3: 22.0
agent-4: 18.0
agent-5: 18.0
agent-6: 24.0
agent-7: 24.0
agent-8: 20.0
agent-9: 23.0
agent-10: 20.0
Sum Reward: 215.0
Avg Reward: 21.5
Min Reward: 18.0
Gini Coefficient 0.06744186046511629
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-43-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 205.30769230769232
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 65
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.739
    dispatch_time_ms: 7.317
    learner:
      cur_lr: 0.0013167100260034204
      grad_gnorm: 40.00000762939453
      policy_entropy: 29.466571807861328
      policy_loss: 53.520484924316406
      var_gnorm: 31.96278953552246
      vf_explained_var: -0.3846759796142578
      vf_loss: 103.30085754394531
    num_steps_sampled: 660000
    num_steps_trained: 660000
    wait_time_ms: 143.94
  iterations_since_restore: 66
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 1156.7438015937805
  time_this_iter_s: 17.503268241882324
  time_total_s: 1156.7438015937805
  timestamp: 1593823386
  timesteps_since_restore: 660000
  timesteps_this_iter: 10000
  timesteps_total: 660000
  training_iteration: 66
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 1156 s, 66 iter, 660000 ts, 205 rew

agent-1: 17.0
agent-2: 23.0
agent-3: 12.0
agent-4: 30.0
agent-5: 19.0
agent-6: 33.0
agent-7: 27.0
agent-8: 29.0
agent-9: 17.0
agent-10: 34.0
Sum Reward: 241.0
Avg Reward: 24.1
Min Reward: 12.0
Gini Coefficient 0.16970954356846474
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-43-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 205.84848484848484
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 66
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.986
    dispatch_time_ms: 7.617
    learner:
      cur_lr: 0.0013160440139472485
      grad_gnorm: 5.880248069763184
      policy_entropy: 148.31558227539062
      policy_loss: -1.9472037553787231
      var_gnorm: 32.145416259765625
      vf_explained_var: -0.9883553981781006
      vf_loss: 0.033657368272542953
    num_steps_sampled: 670000
    num_steps_trained: 670000
    wait_time_ms: 165.224
  iterations_since_restore: 67
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 1174.4139244556427
  time_this_iter_s: 17.670122861862183
  time_total_s: 1174.4139244556427
  timestamp: 1593823404
  timesteps_since_restore: 670000
  timesteps_this_iter: 10000
  timesteps_total: 670000
  training_iteration: 67
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 1174 s, 67 iter, 670000 ts, 206 rew

agent-1: 21.0
agent-2: 30.0
agent-3: 15.0
agent-4: 22.0
agent-5: 24.0
agent-6: 26.0
agent-7: 29.0
agent-8: 18.0
agent-9: 25.0
agent-10: 27.0
Sum Reward: 237.0
Avg Reward: 23.7
Min Reward: 15.0
Gini Coefficient 0.10759493670886076
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-43-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 206.3134328358209
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 67
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.001
    dispatch_time_ms: 32.605
    learner:
      cur_lr: 0.0013153780018910766
      grad_gnorm: 10.5126953125
      policy_entropy: 156.8744354248047
      policy_loss: -0.8439260721206665
      var_gnorm: 32.16168212890625
      vf_explained_var: -0.6927462816238403
      vf_loss: 0.058074191212654114
    num_steps_sampled: 680000
    num_steps_trained: 680000
    wait_time_ms: 264.722
  iterations_since_restore: 68
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 1193.4120297431946
  time_this_iter_s: 18.99810528755188
  time_total_s: 1193.4120297431946
  timestamp: 1593823423
  timesteps_since_restore: 680000
  timesteps_this_iter: 10000
  timesteps_total: 680000
  training_iteration: 68
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 1193 s, 68 iter, 680000 ts, 206 rew

agent-1: 24.0
agent-2: 24.0
agent-3: 15.0
agent-4: 30.0
agent-5: 31.0
agent-6: 31.0
agent-7: 17.0
agent-8: 25.0
agent-9: 27.0
agent-10: 34.0
Sum Reward: 258.0
Avg Reward: 25.8
Min Reward: 15.0
Gini Coefficient 0.12558139534883722
W0703 20:43:50.884183  7722 node_manager.cc:250] Last heartbeat was sent 6475 ms ago 
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-44-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 207.0735294117647
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 68
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.327
    dispatch_time_ms: 8.46
    learner:
      cur_lr: 0.0013147119898349047
      grad_gnorm: 1.9665826559066772
      policy_entropy: 121.66255187988281
      policy_loss: -0.17261919379234314
      var_gnorm: 32.47453689575195
      vf_explained_var: 0.9902552962303162
      vf_loss: 0.007385461125522852
    num_steps_sampled: 690000
    num_steps_trained: 690000
    wait_time_ms: 162.09
  iterations_since_restore: 69
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 1220.809354543686
  time_this_iter_s: 27.397324800491333
  time_total_s: 1220.809354543686
  timestamp: 1593823450
  timesteps_since_restore: 690000
  timesteps_this_iter: 10000
  timesteps_total: 690000
  training_iteration: 69
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 1220 s, 69 iter, 690000 ts, 207 rew

agent-1: 23.0
agent-2: 17.0
agent-3: 34.0
agent-4: 17.0
agent-5: 17.0
agent-6: 33.0
agent-7: 13.0
agent-8: 20.0
agent-9: 32.0
agent-10: 20.0
Sum Reward: 226.0
Avg Reward: 22.6
Min Reward: 13.0
Gini Coefficient 0.1743362831858407
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-44-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 207.34782608695653
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 69
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.06
    dispatch_time_ms: 6.492
    learner:
      cur_lr: 0.0013140459777787328
      grad_gnorm: 39.9999885559082
      policy_entropy: 14.403008460998535
      policy_loss: 5.894339084625244
      var_gnorm: 32.478546142578125
      vf_explained_var: -0.061540842056274414
      vf_loss: 176.6270294189453
    num_steps_sampled: 700000
    num_steps_trained: 700000
    wait_time_ms: 150.15
  iterations_since_restore: 70
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 1236.9885692596436
  time_this_iter_s: 16.17921471595764
  time_total_s: 1236.9885692596436
  timestamp: 1593823469
  timesteps_since_restore: 700000
  timesteps_this_iter: 10000
  timesteps_total: 700000
  training_iteration: 70
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 1236 s, 70 iter, 700000 ts, 207 rew

agent-1: 24.0
agent-2: 33.0
agent-3: 18.0
agent-4: 17.0
agent-5: 32.0
agent-6: 31.0
agent-7: 17.0
agent-8: 14.0
agent-9: 29.0
agent-10: 19.0
Sum Reward: 234.0
Avg Reward: 23.4
Min Reward: 14.0
Gini Coefficient 0.1641025641025641
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-44-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 207.72857142857143
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 70
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.193
    dispatch_time_ms: 8.513
    learner:
      cur_lr: 0.0013133799657225609
      grad_gnorm: 0.43824246525764465
      policy_entropy: 145.5499267578125
      policy_loss: 0.04516030475497246
      var_gnorm: 32.70984649658203
      vf_explained_var: -1.0
      vf_loss: 0.00014223787002265453
    num_steps_sampled: 710000
    num_steps_trained: 710000
    wait_time_ms: 170.819
  iterations_since_restore: 71
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 1254.530178308487
  time_this_iter_s: 17.541609048843384
  time_total_s: 1254.530178308487
  timestamp: 1593823486
  timesteps_since_restore: 710000
  timesteps_this_iter: 10000
  timesteps_total: 710000
  training_iteration: 71
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 1254 s, 71 iter, 710000 ts, 208 rew

agent-1: 19.0
agent-2: 27.0
agent-3: 16.0
agent-4: 25.0
agent-5: 23.0
agent-6: 22.0
agent-7: 23.0
agent-8: 31.0
agent-9: 23.0
agent-10: 25.0
Sum Reward: 234.0
Avg Reward: 23.4
Min Reward: 16.0
Gini Coefficient 0.0905982905982906
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-45-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 208.09859154929578
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 71
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.755
    dispatch_time_ms: 8.785
    learner:
      cur_lr: 0.001312713953666389
      grad_gnorm: 0.5608988404273987
      policy_entropy: 152.09315490722656
      policy_loss: -0.04171660169959068
      var_gnorm: 32.70366668701172
      vf_explained_var: -1.0
      vf_loss: 0.0003238159988541156
    num_steps_sampled: 720000
    num_steps_trained: 720000
    wait_time_ms: 168.521
  iterations_since_restore: 72
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 1272.5134558677673
  time_this_iter_s: 17.983277559280396
  time_total_s: 1272.5134558677673
  timestamp: 1593823504
  timesteps_since_restore: 720000
  timesteps_this_iter: 10000
  timesteps_total: 720000
  training_iteration: 72
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 1272 s, 72 iter, 720000 ts, 208 rew

agent-1: 17.0
agent-2: 22.0
agent-3: 22.0
agent-4: 19.0
agent-5: 21.0
agent-6: 18.0
agent-7: 21.0
agent-8: 25.0
agent-9: 29.0
agent-10: 18.0
Sum Reward: 212.0
Avg Reward: 21.2
Min Reward: 17.0
Gini Coefficient 0.08773584905660377
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-45-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 208.15277777777777
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 72
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.703
    dispatch_time_ms: 14.865
    learner:
      cur_lr: 0.001312048058025539
      grad_gnorm: 1.7431704998016357
      policy_entropy: 131.6607208251953
      policy_loss: -0.7444061040878296
      var_gnorm: 33.04179382324219
      vf_explained_var: -1.0
      vf_loss: 0.02527320571243763
    num_steps_sampled: 730000
    num_steps_trained: 730000
    wait_time_ms: 161.912
  iterations_since_restore: 73
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 1289.9580824375153
  time_this_iter_s: 17.444626569747925
  time_total_s: 1289.9580824375153
  timestamp: 1593823522
  timesteps_since_restore: 730000
  timesteps_this_iter: 10000
  timesteps_total: 730000
  training_iteration: 73
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 1289 s, 73 iter, 730000 ts, 208 rew

agent-1: 12.0
agent-2: 28.0
agent-3: 36.0
agent-4: 42.0
agent-5: 20.0
agent-6: 46.0
agent-7: 29.0
agent-8: 24.0
agent-9: 32.0
agent-10: 38.0
Sum Reward: 307.0
Avg Reward: 30.7
Min Reward: 12.0
Gini Coefficient 0.1814332247557003
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-45-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 209.5068493150685
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 73
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.913
    dispatch_time_ms: 15.559
    learner:
      cur_lr: 0.001311382045969367
      grad_gnorm: 39.999969482421875
      policy_entropy: 46.507022857666016
      policy_loss: -18.199337005615234
      var_gnorm: 33.051448822021484
      vf_explained_var: 0.05739104747772217
      vf_loss: 113.33443450927734
    num_steps_sampled: 740000
    num_steps_trained: 740000
    wait_time_ms: 99.648
  iterations_since_restore: 74
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 1316.8562173843384
  time_this_iter_s: 26.89813494682312
  time_total_s: 1316.8562173843384
  timestamp: 1593823549
  timesteps_since_restore: 740000
  timesteps_this_iter: 10000
  timesteps_total: 740000
  training_iteration: 74
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 1316 s, 74 iter, 740000 ts, 210 rew

agent-1: 26.0
agent-2: 23.0
agent-3: 17.0
agent-4: 26.0
agent-5: 23.0
agent-6: 16.0
agent-7: 22.0
agent-8: 25.0
agent-9: 28.0
agent-10: 18.0
Sum Reward: 224.0
Avg Reward: 22.4
Min Reward: 16.0
Gini Coefficient 0.09821428571428571
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-46-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 209.7027027027027
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 74
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.811
    dispatch_time_ms: 15.352
    learner:
      cur_lr: 0.0013107160339131951
      grad_gnorm: 8.923593521118164
      policy_entropy: 138.1063995361328
      policy_loss: -3.5176656246185303
      var_gnorm: 33.31657409667969
      vf_explained_var: 0.9727252721786499
      vf_loss: 0.04360102117061615
    num_steps_sampled: 750000
    num_steps_trained: 750000
    wait_time_ms: 166.44
  iterations_since_restore: 75
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 1334.4143681526184
  time_this_iter_s: 17.55815076828003
  time_total_s: 1334.4143681526184
  timestamp: 1593823566
  timesteps_since_restore: 750000
  timesteps_this_iter: 10000
  timesteps_total: 750000
  training_iteration: 75
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 1334 s, 75 iter, 750000 ts, 210 rew

agent-1: 38.0
agent-2: 30.0
agent-3: 28.0
agent-4: 15.0
agent-5: 42.0
agent-6: 36.0
agent-7: 25.0
agent-8: 28.0
agent-9: 20.0
agent-10: 27.0
Sum Reward: 289.0
Avg Reward: 28.9
Min Reward: 15.0
Gini Coefficient 0.14982698961937715
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-46-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 210.76
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 75
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.914
    dispatch_time_ms: 23.457
    learner:
      cur_lr: 0.0013100500218570232
      grad_gnorm: 39.99999237060547
      policy_entropy: 54.63861846923828
      policy_loss: -38.580875396728516
      var_gnorm: 33.34153366088867
      vf_explained_var: 0.562130331993103
      vf_loss: 135.63394165039062
    num_steps_sampled: 760000
    num_steps_trained: 760000
    wait_time_ms: 133.084
  iterations_since_restore: 76
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 1352.319296836853
  time_this_iter_s: 17.90492868423462
  time_total_s: 1352.319296836853
  timestamp: 1593823584
  timesteps_since_restore: 760000
  timesteps_this_iter: 10000
  timesteps_total: 760000
  training_iteration: 76
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 1352 s, 76 iter, 760000 ts, 211 rew

agent-1: 29.0
agent-2: 20.0
agent-3: 33.0
agent-4: 24.0
agent-5: 16.0
agent-6: 28.0
agent-7: 20.0
agent-8: 17.0
agent-9: 19.0
agent-10: 28.0
Sum Reward: 234.0
Avg Reward: 23.4
Min Reward: 16.0
Gini Coefficient 0.13247863247863248
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-46-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 211.06578947368422
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 76
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.252
    dispatch_time_ms: 34.646
    learner:
      cur_lr: 0.0013093840098008513
      grad_gnorm: 0.7867311239242554
      policy_entropy: 155.27386474609375
      policy_loss: -0.1217147707939148
      var_gnorm: 33.54581832885742
      vf_explained_var: -1.0
      vf_loss: 0.0016644725110381842
    num_steps_sampled: 770000
    num_steps_trained: 770000
    wait_time_ms: 149.874
  iterations_since_restore: 77
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 1370.3107562065125
  time_this_iter_s: 17.991459369659424
  time_total_s: 1370.3107562065125
  timestamp: 1593823602
  timesteps_since_restore: 770000
  timesteps_this_iter: 10000
  timesteps_total: 770000
  training_iteration: 77
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 1370 s, 77 iter, 770000 ts, 211 rew

agent-1: 22.0
agent-2: 22.0
agent-3: 21.0
agent-4: 13.0
agent-5: 23.0
agent-6: 13.0
agent-7: 19.0
agent-8: 29.0
agent-9: 29.0
agent-10: 36.0
Sum Reward: 227.0
Avg Reward: 22.7
Min Reward: 13.0
Gini Coefficient 0.16519823788546256
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-47-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 211.27272727272728
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 77
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.788
    dispatch_time_ms: 25.865
    learner:
      cur_lr: 0.0013087179977446795
      grad_gnorm: 3.565823793411255
      policy_entropy: 159.81089782714844
      policy_loss: 1.8966478109359741
      var_gnorm: 33.551727294921875
      vf_explained_var: -0.003273487091064453
      vf_loss: 0.0008342555374838412
    num_steps_sampled: 780000
    num_steps_trained: 780000
    wait_time_ms: 138.702
  iterations_since_restore: 78
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 1388.281314611435
  time_this_iter_s: 17.970558404922485
  time_total_s: 1388.281314611435
  timestamp: 1593823620
  timesteps_since_restore: 780000
  timesteps_this_iter: 10000
  timesteps_total: 780000
  training_iteration: 78
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 1388 s, 78 iter, 780000 ts, 211 rew

agent-1: 25.0
agent-2: 22.0
agent-3: 20.0
agent-4: 25.0
agent-5: 20.0
agent-6: 26.0
agent-7: 25.0
agent-8: 27.0
agent-9: 33.0
agent-10: 21.0
Sum Reward: 244.0
Avg Reward: 24.4
Min Reward: 20.0
Gini Coefficient 0.08196721311475409
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-47-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 211.69230769230768
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 78
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.997
    dispatch_time_ms: 23.206
    learner:
      cur_lr: 0.0013080519856885076
      grad_gnorm: 4.074618816375732
      policy_entropy: 134.0496368408203
      policy_loss: -3.2981536388397217
      var_gnorm: 33.759254455566406
      vf_explained_var: -1.0
      vf_loss: 0.001565819955430925
    num_steps_sampled: 790000
    num_steps_trained: 790000
    wait_time_ms: 156.825
  iterations_since_restore: 79
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 1406.3100757598877
  time_this_iter_s: 18.02876114845276
  time_total_s: 1406.3100757598877
  timestamp: 1593823639
  timesteps_since_restore: 790000
  timesteps_this_iter: 10000
  timesteps_total: 790000
  training_iteration: 79
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 1406 s, 79 iter, 790000 ts, 212 rew

agent-1: 23.0
agent-2: 25.0
agent-3: 29.0
agent-4: 27.0
agent-5: 25.0
agent-6: 20.0
agent-7: 29.0
agent-8: 18.0
agent-9: 26.0
agent-10: 23.0
Sum Reward: 245.0
Avg Reward: 24.5
Min Reward: 18.0
Gini Coefficient 0.07795918367346939
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-47-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 212.1139240506329
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 79
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.579
    dispatch_time_ms: 31.594
    learner:
      cur_lr: 0.0013073859736323357
      grad_gnorm: 1.664410948753357
      policy_entropy: 143.53421020507812
      policy_loss: 0.5143788456916809
      var_gnorm: 33.75516891479492
      vf_explained_var: -1.0
      vf_loss: 0.006388575304299593
    num_steps_sampled: 800000
    num_steps_trained: 800000
    wait_time_ms: 150.974
  iterations_since_restore: 80
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 1424.8925313949585
  time_this_iter_s: 18.5824556350708
  time_total_s: 1424.8925313949585
  timestamp: 1593823657
  timesteps_since_restore: 800000
  timesteps_this_iter: 10000
  timesteps_total: 800000
  training_iteration: 80
  
agent-1: 25.0
agent-2: 29.0
agent-3: 23.0
agent-4: 19.0
agent-5: 27.0
agent-6: 24.0
agent-7: 26.0
agent-8: 31.0
agent-9: 24.0
agent-10: 20.0
Sum Reward: 248.0
Avg Reward: 24.8
Min Reward: 19.0
Gini Coefficient 0.07983870967741935
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 1424 s, 80 iter, 800000 ts, 212 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-47-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 212.5625
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 80
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.33
    dispatch_time_ms: 35.51
    learner:
      cur_lr: 0.0013067199615761638
      grad_gnorm: 1.991292953491211
      policy_entropy: 127.67251586914062
      policy_loss: 1.7230591773986816
      var_gnorm: 33.9607048034668
      vf_explained_var: 0.9938318133354187
      vf_loss: 0.006122836377471685
    num_steps_sampled: 810000
    num_steps_trained: 810000
    wait_time_ms: 146.633
  iterations_since_restore: 81
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 1441.466949224472
  time_this_iter_s: 16.57441782951355
  time_total_s: 1441.466949224472
  timestamp: 1593823676
  timesteps_since_restore: 810000
  timesteps_this_iter: 10000
  timesteps_total: 810000
  training_iteration: 81
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 1441 s, 81 iter, 810000 ts, 213 rew

agent-1: 18.0
agent-2: 26.0
agent-3: 25.0
agent-4: 13.0
agent-5: 32.0
agent-6: 21.0
agent-7: 21.0
agent-8: 17.0
agent-9: 23.0
agent-10: 23.0
Sum Reward: 219.0
Avg Reward: 21.9
Min Reward: 13.0
Gini Coefficient 0.12648401826484018
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-48-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 212.64197530864197
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 81
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.861
    dispatch_time_ms: 18.238
    learner:
      cur_lr: 0.0013060539495199919
      grad_gnorm: 2.961111307144165
      policy_entropy: 147.8150634765625
      policy_loss: -0.5666478276252747
      var_gnorm: 33.97117233276367
      vf_explained_var: 0.9951423406600952
      vf_loss: 0.0054674698039889336
    num_steps_sampled: 820000
    num_steps_trained: 820000
    wait_time_ms: 171.847
  iterations_since_restore: 82
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 1458.0770282745361
  time_this_iter_s: 16.610079050064087
  time_total_s: 1458.0770282745361
  timestamp: 1593823709
  timesteps_since_restore: 820000
  timesteps_this_iter: 10000
  timesteps_total: 820000
  training_iteration: 82
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 1458 s, 82 iter, 820000 ts, 213 rew

agent-1: 22.0
agent-2: 22.0
agent-3: 23.0
agent-4: 35.0
agent-5: 30.0
agent-6: 31.0
agent-7: 17.0
agent-8: 29.0
agent-9: 14.0
agent-10: 17.0
Sum Reward: 240.0
Avg Reward: 24.0
Min Reward: 14.0
Gini Coefficient 0.15583333333333332
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-48-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 212.97560975609755
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 82
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.975
    dispatch_time_ms: 6.845
    learner:
      cur_lr: 0.0013053880538791418
      grad_gnorm: 2.913583517074585
      policy_entropy: 142.46136474609375
      policy_loss: -1.1262681484222412
      var_gnorm: 34.129234313964844
      vf_explained_var: 0.9867767691612244
      vf_loss: 0.016366034746170044
    num_steps_sampled: 830000
    num_steps_trained: 830000
    wait_time_ms: 165.739
  iterations_since_restore: 83
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 1475.3431499004364
  time_this_iter_s: 17.26612162590027
  time_total_s: 1475.3431499004364
  timestamp: 1593823726
  timesteps_since_restore: 830000
  timesteps_this_iter: 10000
  timesteps_total: 830000
  training_iteration: 83
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 1475 s, 83 iter, 830000 ts, 213 rew

agent-1: 44.0
agent-2: 18.0
agent-3: 26.0
agent-4: 32.0
agent-5: 22.0
agent-6: 33.0
agent-7: 8.0
agent-8: 20.0
agent-9: 37.0
agent-10: 10.0
Sum Reward: 250.0
Avg Reward: 25.0
Min Reward: 8.0
Gini Coefficient 0.2512
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-49-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 213.42168674698794
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 83
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.299
    dispatch_time_ms: 6.523
    learner:
      cur_lr: 0.00130472204182297
      grad_gnorm: 3.184607982635498
      policy_entropy: 148.6432647705078
      policy_loss: -1.047407865524292
      var_gnorm: 34.13246154785156
      vf_explained_var: 0.9919144511222839
      vf_loss: 0.009748700074851513
    num_steps_sampled: 840000
    num_steps_trained: 840000
    wait_time_ms: 163.137
  iterations_since_restore: 84
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 1492.9195303916931
  time_this_iter_s: 17.576380491256714
  time_total_s: 1492.9195303916931
  timestamp: 1593823744
  timesteps_since_restore: 840000
  timesteps_this_iter: 10000
  timesteps_total: 840000
  training_iteration: 84
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 1492 s, 84 iter, 840000 ts, 213 rew

agent-1: 24.0
agent-2: 26.0
agent-3: 24.0
agent-4: 26.0
agent-5: 22.0
agent-6: 24.0
agent-7: 32.0
agent-8: 21.0
agent-9: 33.0
agent-10: 24.0
Sum Reward: 256.0
Avg Reward: 25.6
Min Reward: 21.0
Gini Coefficient 0.07578125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-49-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 213.92857142857142
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 84
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.868
    dispatch_time_ms: 35.593
    learner:
      cur_lr: 0.001304056029766798
      grad_gnorm: 2.451674461364746
      policy_entropy: 136.08131408691406
      policy_loss: -3.451038122177124
      var_gnorm: 34.292877197265625
      vf_explained_var: 0.9944755434989929
      vf_loss: 0.002957755932584405
    num_steps_sampled: 850000
    num_steps_trained: 850000
    wait_time_ms: 157.119
  iterations_since_restore: 85
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 1510.4584701061249
  time_this_iter_s: 17.538939714431763
  time_total_s: 1510.4584701061249
  timestamp: 1593823762
  timesteps_since_restore: 850000
  timesteps_this_iter: 10000
  timesteps_total: 850000
  training_iteration: 85
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 1510 s, 85 iter, 850000 ts, 214 rew

agent-1: 17.0
agent-2: 18.0
agent-3: 22.0
agent-4: 22.0
agent-5: 20.0
agent-6: 25.0
agent-7: 22.0
agent-8: 17.0
agent-9: 28.0
agent-10: 17.0
Sum Reward: 208.0
Avg Reward: 20.8
Min Reward: 17.0
Gini Coefficient 0.09326923076923077
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-49-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 213.85882352941175
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 85
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 4.6
    dispatch_time_ms: 23.572
    learner:
      cur_lr: 0.0013033900177106261
      grad_gnorm: 0.3410753607749939
      policy_entropy: 149.6416473388672
      policy_loss: 0.38204410672187805
      var_gnorm: 34.28122329711914
      vf_explained_var: 0.9961662292480469
      vf_loss: 0.0009830719791352749
    num_steps_sampled: 860000
    num_steps_trained: 860000
    wait_time_ms: 156.614
  iterations_since_restore: 86
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 1528.68901181221
  time_this_iter_s: 18.230541706085205
  time_total_s: 1528.68901181221
  timestamp: 1593823780
  timesteps_since_restore: 860000
  timesteps_this_iter: 10000
  timesteps_total: 860000
  training_iteration: 86
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 1528 s, 86 iter, 860000 ts, 214 rew

agent-1: 17.0
agent-2: 28.0
agent-3: 28.0
agent-4: 38.0
agent-5: 19.0
agent-6: 23.0
agent-7: 18.0
agent-8: 24.0
agent-9: 31.0
agent-10: 19.0
Sum Reward: 245.0
Avg Reward: 24.5
Min Reward: 17.0
Gini Coefficient 0.14408163265306123
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-49-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 214.22093023255815
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 86
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.966
    dispatch_time_ms: 24.002
    learner:
      cur_lr: 0.0013027240056544542
      grad_gnorm: 2.363826036453247
      policy_entropy: 65.22480010986328
      policy_loss: -1.1150373220443726
      var_gnorm: 34.494869232177734
      vf_explained_var: 0.9943324327468872
      vf_loss: 0.0009875954128801823
    num_steps_sampled: 870000
    num_steps_trained: 870000
    wait_time_ms: 160.28
  iterations_since_restore: 87
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 1546.5329129695892
  time_this_iter_s: 17.84390115737915
  time_total_s: 1546.5329129695892
  timestamp: 1593823798
  timesteps_since_restore: 870000
  timesteps_this_iter: 10000
  timesteps_total: 870000
  training_iteration: 87
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 1546 s, 87 iter, 870000 ts, 214 rew

agent-1: 26.0
agent-2: 22.0
agent-3: 24.0
agent-4: 22.0
agent-5: 20.0
agent-6: 23.0
agent-7: 30.0
agent-8: 25.0
agent-9: 20.0
agent-10: 32.0
Sum Reward: 244.0
Avg Reward: 24.4
Min Reward: 20.0
Gini Coefficient 0.08524590163934426
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-50-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 214.5632183908046
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 87
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 4.072
    dispatch_time_ms: 27.238
    learner:
      cur_lr: 0.0013020579935982823
      grad_gnorm: 1.4604767560958862
      policy_entropy: 125.18126678466797
      policy_loss: -2.055330514907837
      var_gnorm: 34.5107421875
      vf_explained_var: -0.018016934394836426
      vf_loss: 0.00018250201537739486
    num_steps_sampled: 880000
    num_steps_trained: 880000
    wait_time_ms: 137.737
  iterations_since_restore: 88
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 1564.5296127796173
  time_this_iter_s: 17.996699810028076
  time_total_s: 1564.5296127796173
  timestamp: 1593823816
  timesteps_since_restore: 880000
  timesteps_this_iter: 10000
  timesteps_total: 880000
  training_iteration: 88
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 1564 s, 88 iter, 880000 ts, 215 rew

agent-1: 35.0
agent-2: 20.0
agent-3: 36.0
agent-4: 17.0
agent-5: 20.0
agent-6: 21.0
agent-7: 21.0
agent-8: 27.0
agent-9: 19.0
agent-10: 18.0
Sum Reward: 234.0
Avg Reward: 23.4
Min Reward: 17.0
Gini Coefficient 0.14273504273504273
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-50-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 214.7840909090909
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 88
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.977
    dispatch_time_ms: 34.174
    learner:
      cur_lr: 0.0013013919815421104
      grad_gnorm: 4.295454978942871
      policy_entropy: 125.63607788085938
      policy_loss: 11.467937469482422
      var_gnorm: 34.779136657714844
      vf_explained_var: 0.9958590269088745
      vf_loss: 0.0007447245880030096
    num_steps_sampled: 890000
    num_steps_trained: 890000
    wait_time_ms: 146.588
  iterations_since_restore: 89
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 1582.123476266861
  time_this_iter_s: 17.593863487243652
  time_total_s: 1582.123476266861
  timestamp: 1593823833
  timesteps_since_restore: 890000
  timesteps_this_iter: 10000
  timesteps_total: 890000
  training_iteration: 89
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 1582 s, 89 iter, 890000 ts, 215 rew

agent-1: 17.0
agent-2: 40.0
agent-3: 27.0
agent-4: 42.0
agent-5: 29.0
agent-6: 31.0
agent-7: 30.0
agent-8: 28.0
agent-9: 35.0
agent-10: 27.0
Sum Reward: 306.0
Avg Reward: 30.6
Min Reward: 17.0
Gini Coefficient 0.11960784313725491
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-50-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 215.80898876404495
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 89
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 4.076
    dispatch_time_ms: 24.852
    learner:
      cur_lr: 0.0013007259694859385
      grad_gnorm: 2.892025947570801
      policy_entropy: 136.19863891601562
      policy_loss: -0.6974276304244995
      var_gnorm: 34.78859329223633
      vf_explained_var: 0.9864592552185059
      vf_loss: 0.005176344886422157
    num_steps_sampled: 900000
    num_steps_trained: 900000
    wait_time_ms: 161.105
  iterations_since_restore: 90
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 1600.5195000171661
  time_this_iter_s: 18.396023750305176
  time_total_s: 1600.5195000171661
  timestamp: 1593823852
  timesteps_since_restore: 900000
  timesteps_this_iter: 10000
  timesteps_total: 900000
  training_iteration: 90
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 1600 s, 90 iter, 900000 ts, 216 rew

agent-1: 20.0
agent-2: 19.0
agent-3: 30.0
agent-4: 23.0
agent-5: 26.0
agent-6: 14.0
agent-7: 28.0
agent-8: 25.0
agent-9: 35.0
agent-10: 27.0
Sum Reward: 247.0
Avg Reward: 24.7
Min Reward: 14.0
Gini Coefficient 0.1291497975708502
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-51-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 216.15555555555557
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 90
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.882
    dispatch_time_ms: 33.014
    learner:
      cur_lr: 0.0013000599574297667
      grad_gnorm: 1.550523281097412
      policy_entropy: 166.3916015625
      policy_loss: -0.3054904639720917
      var_gnorm: 34.860565185546875
      vf_explained_var: 0.8167483806610107
      vf_loss: 0.001168739632703364
    num_steps_sampled: 910000
    num_steps_trained: 910000
    wait_time_ms: 533.079
  iterations_since_restore: 91
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 1622.4354448318481
  time_this_iter_s: 21.915944814682007
  time_total_s: 1622.4354448318481
  timestamp: 1593823874
  timesteps_since_restore: 910000
  timesteps_this_iter: 10000
  timesteps_total: 910000
  training_iteration: 91
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 1622 s, 91 iter, 910000 ts, 216 rew

agent-1: 25.0
agent-2: 18.0
agent-3: 30.0
agent-4: 29.0
agent-5: 18.0
agent-6: 16.0
agent-7: 26.0
agent-8: 15.0
agent-9: 25.0
agent-10: 15.0
Sum Reward: 217.0
Avg Reward: 21.7
Min Reward: 15.0
Gini Coefficient 0.14331797235023042
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-51-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 216.16483516483515
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 91
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.41
    dispatch_time_ms: 21.393
    learner:
      cur_lr: 0.0012993939453735948
      grad_gnorm: 1.6079775094985962
      policy_entropy: 169.99563598632812
      policy_loss: -0.31194961071014404
      var_gnorm: 34.85627365112305
      vf_explained_var: 0.37930935621261597
      vf_loss: 0.001531714922748506
    num_steps_sampled: 920000
    num_steps_trained: 920000
    wait_time_ms: 171.371
  iterations_since_restore: 92
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 1639.5957326889038
  time_this_iter_s: 17.160287857055664
  time_total_s: 1639.5957326889038
  timestamp: 1593823891
  timesteps_since_restore: 920000
  timesteps_this_iter: 10000
  timesteps_total: 920000
  training_iteration: 92
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 1639 s, 92 iter, 920000 ts, 216 rew

agent-1: 40.0
agent-2: 23.0
agent-3: 27.0
agent-4: 21.0
agent-5: 27.0
agent-6: 24.0
agent-7: 21.0
agent-8: 20.0
agent-9: 28.0
agent-10: 26.0
Sum Reward: 257.0
Avg Reward: 25.7
Min Reward: 20.0
Gini Coefficient 0.10622568093385214
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-51-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 216.6086956521739
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 92
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.903
    dispatch_time_ms: 26.167
    learner:
      cur_lr: 0.0012987280497327447
      grad_gnorm: 2.245072603225708
      policy_entropy: 135.04940795898438
      policy_loss: 1.5506093502044678
      var_gnorm: 35.033058166503906
      vf_explained_var: 0.055018484592437744
      vf_loss: 0.0026208735071122646
    num_steps_sampled: 930000
    num_steps_trained: 930000
    wait_time_ms: 148.216
  iterations_since_restore: 93
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 1657.3177962303162
  time_this_iter_s: 17.722063541412354
  time_total_s: 1657.3177962303162
  timestamp: 1593823909
  timesteps_since_restore: 930000
  timesteps_this_iter: 10000
  timesteps_total: 930000
  training_iteration: 93
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 1657 s, 93 iter, 930000 ts, 217 rew

agent-1: 28.0
agent-2: 23.0
agent-3: 35.0
agent-4: 31.0
agent-5: 26.0
agent-6: 19.0
agent-7: 33.0
agent-8: 21.0
agent-9: 26.0
agent-10: 24.0
Sum Reward: 266.0
Avg Reward: 26.6
Min Reward: 19.0
Gini Coefficient 0.10526315789473684
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-52-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 217.13978494623655
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 93
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.484
    dispatch_time_ms: 24.647
    learner:
      cur_lr: 0.0012980620376765728
      grad_gnorm: 40.0
      policy_entropy: 54.95841979980469
      policy_loss: 4.641027450561523
      var_gnorm: 35.0313720703125
      vf_explained_var: 0.2841331958770752
      vf_loss: 148.6282196044922
    num_steps_sampled: 940000
    num_steps_trained: 940000
    wait_time_ms: 154.024
  iterations_since_restore: 94
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 1675.6811878681183
  time_this_iter_s: 18.363391637802124
  time_total_s: 1675.6811878681183
  timestamp: 1593823927
  timesteps_since_restore: 940000
  timesteps_this_iter: 10000
  timesteps_total: 940000
  training_iteration: 94
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 1675 s, 94 iter, 940000 ts, 217 rew

agent-1: 13.0
agent-2: 24.0
agent-3: 37.0
agent-4: 22.0
agent-5: 29.0
agent-6: 31.0
agent-7: 27.0
agent-8: 31.0
agent-9: 25.0
agent-10: 15.0
Sum Reward: 254.0
Avg Reward: 25.4
Min Reward: 13.0
Gini Coefficient 0.15354330708661418
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-52-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 217.53191489361703
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 94
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.36
    dispatch_time_ms: 28.551
    learner:
      cur_lr: 0.001297396025620401
      grad_gnorm: 1.949644684791565
      policy_entropy: 134.15235900878906
      policy_loss: 0.8811095952987671
      var_gnorm: 35.21223831176758
      vf_explained_var: 0.9881502985954285
      vf_loss: 0.0016345182666555047
    num_steps_sampled: 950000
    num_steps_trained: 950000
    wait_time_ms: 144.893
  iterations_since_restore: 95
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 1693.7743451595306
  time_this_iter_s: 18.093157291412354
  time_total_s: 1693.7743451595306
  timestamp: 1593823945
  timesteps_since_restore: 950000
  timesteps_this_iter: 10000
  timesteps_total: 950000
  training_iteration: 95
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 1693 s, 95 iter, 950000 ts, 218 rew

agent-1: 20.0
agent-2: 26.0
agent-3: 34.0
agent-4: 33.0
agent-5: 20.0
agent-6: 27.0
agent-7: 9.0
agent-8: 26.0
agent-9: 18.0
agent-10: 25.0
Sum Reward: 238.0
Avg Reward: 23.8
Min Reward: 9.0
Gini Coefficient 0.16134453781512606
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-52-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 217.74736842105264
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 95
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.038
    dispatch_time_ms: 20.537
    learner:
      cur_lr: 0.001296730013564229
      grad_gnorm: 2.2901501655578613
      policy_entropy: 155.37062072753906
      policy_loss: -0.6180990934371948
      var_gnorm: 35.226566314697266
      vf_explained_var: 0.9803111553192139
      vf_loss: 0.003247425891458988
    num_steps_sampled: 960000
    num_steps_trained: 960000
    wait_time_ms: 167.602
  iterations_since_restore: 96
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 1712.0099048614502
  time_this_iter_s: 18.235559701919556
  time_total_s: 1712.0099048614502
  timestamp: 1593823964
  timesteps_since_restore: 960000
  timesteps_this_iter: 10000
  timesteps_total: 960000
  training_iteration: 96
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 1712 s, 96 iter, 960000 ts, 218 rew

agent-1: 28.0
agent-2: 27.0
agent-3: 30.0
agent-4: 10.0
agent-5: 14.0
agent-6: 25.0
agent-7: 22.0
agent-8: 30.0
agent-9: 20.0
agent-10: 21.0
Sum Reward: 227.0
Avg Reward: 22.7
Min Reward: 10.0
Gini Coefficient 0.15550660792951543
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-53-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 217.84375
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 96
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.268
    dispatch_time_ms: 28.846
    learner:
      cur_lr: 0.0012960640015080571
      grad_gnorm: 0.9229088425636292
      policy_entropy: 147.2178497314453
      policy_loss: -1.3201898336410522
      var_gnorm: 35.447242736816406
      vf_explained_var: 0.9423568248748779
      vf_loss: 0.002266436582431197
    num_steps_sampled: 970000
    num_steps_trained: 970000
    wait_time_ms: 152.216
  iterations_since_restore: 97
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 1729.9986219406128
  time_this_iter_s: 17.988717079162598
  time_total_s: 1729.9986219406128
  timestamp: 1593823982
  timesteps_since_restore: 970000
  timesteps_this_iter: 10000
  timesteps_total: 970000
  training_iteration: 97
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 1729 s, 97 iter, 970000 ts, 218 rew

agent-1: 32.0
agent-2: 23.0
agent-3: 10.0
agent-4: 21.0
agent-5: 32.0
agent-6: 14.0
agent-7: 22.0
agent-8: 27.0
agent-9: 28.0
agent-10: 32.0
Sum Reward: 241.0
Avg Reward: 24.1
Min Reward: 10.0
Gini Coefficient 0.16639004149377593
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-53-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 218.08247422680412
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 97
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.329
    dispatch_time_ms: 30.07
    learner:
      cur_lr: 0.0012953979894518852
      grad_gnorm: 40.0
      policy_entropy: 61.223636627197266
      policy_loss: 39.10813522338867
      var_gnorm: 35.444862365722656
      vf_explained_var: 0.6622316241264343
      vf_loss: 254.4642791748047
    num_steps_sampled: 980000
    num_steps_trained: 980000
    wait_time_ms: 136.117
  iterations_since_restore: 98
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 1748.3329634666443
  time_this_iter_s: 18.334341526031494
  time_total_s: 1748.3329634666443
  timestamp: 1593824000
  timesteps_since_restore: 980000
  timesteps_this_iter: 10000
  timesteps_total: 980000
  training_iteration: 98
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 1748 s, 98 iter, 980000 ts, 218 rew

agent-1: 31.0
agent-2: 17.0
agent-3: 30.0
agent-4: 21.0
agent-5: 17.0
agent-6: 15.0
agent-7: 19.0
agent-8: 24.0
agent-9: 19.0
agent-10: 27.0
Sum Reward: 220.0
Avg Reward: 22.0
Min Reward: 15.0
Gini Coefficient 0.13727272727272727
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-53-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 218.10204081632654
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 98
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.829
    dispatch_time_ms: 28.529
    learner:
      cur_lr: 0.0012947319773957133
      grad_gnorm: 4.130056381225586
      policy_entropy: 96.86820983886719
      policy_loss: 1.3846451044082642
      var_gnorm: 35.694984436035156
      vf_explained_var: 0.8833996057510376
      vf_loss: 0.007311239372938871
    num_steps_sampled: 990000
    num_steps_trained: 990000
    wait_time_ms: 153.898
  iterations_since_restore: 99
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 1766.3492050170898
  time_this_iter_s: 18.016241550445557
  time_total_s: 1766.3492050170898
  timestamp: 1593824018
  timesteps_since_restore: 990000
  timesteps_this_iter: 10000
  timesteps_total: 990000
  training_iteration: 99
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 1766 s, 99 iter, 990000 ts, 218 rew

agent-1: 26.0
agent-2: 30.0
agent-3: 24.0
agent-4: 31.0
agent-5: 34.0
agent-6: 21.0
agent-7: 37.0
agent-8: 10.0
agent-9: 24.0
agent-10: 31.0
Sum Reward: 268.0
Avg Reward: 26.8
Min Reward: 10.0
Gini Coefficient 0.14701492537313432
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-53-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 218.6060606060606
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 99
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.985
    dispatch_time_ms: 96.802
    learner:
      cur_lr: 0.0012940659653395414
      grad_gnorm: 6.201293468475342
      policy_entropy: 128.09463500976562
      policy_loss: 0.3514542579650879
      var_gnorm: 35.6927375793457
      vf_explained_var: 0.9481068849563599
      vf_loss: 0.01977783627808094
    num_steps_sampled: 1000000
    num_steps_trained: 1000000
    wait_time_ms: 118.761
  iterations_since_restore: 100
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 1784.9680523872375
  time_this_iter_s: 18.618847370147705
  time_total_s: 1784.9680523872375
  timestamp: 1593824037
  timesteps_since_restore: 1000000
  timesteps_this_iter: 10000
  timesteps_total: 1000000
  training_iteration: 100
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 1784 s, 100 iter, 1000000 ts, 219 rew

agent-1: 21.0
agent-2: 17.0
agent-3: 34.0
agent-4: 23.0
agent-5: 28.0
agent-6: 31.0
agent-7: 26.0
agent-8: 24.0
agent-9: 21.0
agent-10: 25.0
Sum Reward: 250.0
Avg Reward: 25.0
Min Reward: 17.0
Gini Coefficient 0.1072
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-54-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 218.92
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 100
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.365
    dispatch_time_ms: 25.633
    learner:
      cur_lr: 0.0012933999532833695
      grad_gnorm: 0.8177193999290466
      policy_entropy: 150.104736328125
      policy_loss: -0.21950623393058777
      var_gnorm: 35.84566879272461
      vf_explained_var: 0.9916787147521973
      vf_loss: 0.0006593613652512431
    num_steps_sampled: 1010000
    num_steps_trained: 1010000
    wait_time_ms: 153.553
  iterations_since_restore: 101
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 1802.6437273025513
  time_this_iter_s: 17.67567491531372
  time_total_s: 1802.6437273025513
  timestamp: 1593824055
  timesteps_since_restore: 1010000
  timesteps_this_iter: 10000
  timesteps_total: 1010000
  training_iteration: 101
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 1802 s, 101 iter, 1010000 ts, 219 rew

agent-1: 51.0
agent-2: 29.0
agent-3: 37.0
agent-4: 22.0
agent-5: 26.0
agent-6: 26.0
agent-7: 24.0
agent-8: 18.0
agent-9: 51.0
agent-10: 32.0
Sum Reward: 316.0
Avg Reward: 31.6
Min Reward: 18.0
Gini Coefficient 0.18544303797468353
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-54-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 236.48
  episode_reward_min: -1549.0
  episodes_this_iter: 1
  episodes_total: 101
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 4.085
    dispatch_time_ms: 27.427
    learner:
      cur_lr: 0.0012927340576425195
      grad_gnorm: 4.556532382965088
      policy_entropy: 151.5736083984375
      policy_loss: -1.9086153507232666
      var_gnorm: 35.837608337402344
      vf_explained_var: 0.7565232515335083
      vf_loss: 0.011693601496517658
    num_steps_sampled: 1020000
    num_steps_trained: 1020000
    wait_time_ms: 156.257
  iterations_since_restore: 102
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 1821.0517783164978
  time_this_iter_s: 18.408051013946533
  time_total_s: 1821.0517783164978
  timestamp: 1593824073
  timesteps_since_restore: 1020000
  timesteps_this_iter: 10000
  timesteps_total: 1020000
  training_iteration: 102
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 1821 s, 102 iter, 1020000 ts, 236 rew

agent-1: 18.0
agent-2: 14.0
agent-3: 22.0
agent-4: 28.0
agent-5: 38.0
agent-6: 30.0
agent-7: 21.0
agent-8: 29.0
agent-9: 24.0
agent-10: 19.0
Sum Reward: 243.0
Avg Reward: 24.3
Min Reward: 14.0
Gini Coefficient 0.1534979423868313
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-54-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 254.4
  episode_reward_min: 125.0
  episodes_this_iter: 1
  episodes_total: 102
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.026
    dispatch_time_ms: 28.099
    learner:
      cur_lr: 0.0012920680455863476
      grad_gnorm: 1.0074405670166016
      policy_entropy: 144.75924682617188
      policy_loss: 0.4098985493183136
      var_gnorm: 35.990989685058594
      vf_explained_var: -0.14201271533966064
      vf_loss: 0.020820077508687973
    num_steps_sampled: 1030000
    num_steps_trained: 1030000
    wait_time_ms: 146.725
  iterations_since_restore: 103
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 1839.077070236206
  time_this_iter_s: 18.025291919708252
  time_total_s: 1839.077070236206
  timestamp: 1593824091
  timesteps_since_restore: 1030000
  timesteps_this_iter: 10000
  timesteps_total: 1030000
  training_iteration: 103
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 1839 s, 103 iter, 1030000 ts, 254 rew

agent-1: 14.0
agent-2: 20.0
agent-3: 25.0
agent-4: 26.0
agent-5: 20.0
agent-6: 20.0
agent-7: 25.0
agent-8: 27.0
agent-9: 15.0
agent-10: 29.0
Sum Reward: 221.0
Avg Reward: 22.1
Min Reward: 14.0
Gini Coefficient 0.12171945701357466
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-55-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 553.0
  episode_reward_mean: 251.88
  episode_reward_min: 125.0
  episodes_this_iter: 1
  episodes_total: 103
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.801
    dispatch_time_ms: 33.264
    learner:
      cur_lr: 0.0012914020335301757
      grad_gnorm: 0.9670791625976562
      policy_entropy: 146.60621643066406
      policy_loss: 0.28779336810112
      var_gnorm: 36.024417877197266
      vf_explained_var: 0.9900375008583069
      vf_loss: 0.0006203820230439305
    num_steps_sampled: 1040000
    num_steps_trained: 1040000
    wait_time_ms: 145.472
  iterations_since_restore: 104
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 1857.2711417675018
  time_this_iter_s: 18.194071531295776
  time_total_s: 1857.2711417675018
  timestamp: 1593824109
  timesteps_since_restore: 1040000
  timesteps_this_iter: 10000
  timesteps_total: 1040000
  training_iteration: 104
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 1857 s, 104 iter, 1040000 ts, 252 rew

agent-1: 36.0
agent-2: 20.0
agent-3: 21.0
agent-4: 30.0
agent-5: 15.0
agent-6: 17.0
agent-7: 30.0
agent-8: 20.0
agent-9: 12.0
agent-10: 24.0
Sum Reward: 225.0
Avg Reward: 22.5
Min Reward: 12.0
Gini Coefficient 0.17733333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-55-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 364.0
  episode_reward_mean: 248.6
  episode_reward_min: 125.0
  episodes_this_iter: 1
  episodes_total: 104
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.935
    dispatch_time_ms: 31.943
    learner:
      cur_lr: 0.0012907360214740038
      grad_gnorm: 0.6439049243927002
      policy_entropy: 156.2234649658203
      policy_loss: -0.452627032995224
      var_gnorm: 36.178985595703125
      vf_explained_var: 0.6836771965026855
      vf_loss: 0.005186034832149744
    num_steps_sampled: 1050000
    num_steps_trained: 1050000
    wait_time_ms: 147.249
  iterations_since_restore: 105
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 1875.4097273349762
  time_this_iter_s: 18.138585567474365
  time_total_s: 1875.4097273349762
  timestamp: 1593824127
  timesteps_since_restore: 1050000
  timesteps_this_iter: 10000
  timesteps_total: 1050000
  training_iteration: 105
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 1875 s, 105 iter, 1050000 ts, 249 rew

agent-1: 19.0
agent-2: 19.0
agent-3: 24.0
agent-4: 19.0
agent-5: 17.0
agent-6: 26.0
agent-7: 20.0
agent-8: 27.0
agent-9: 18.0
agent-10: 27.0
Sum Reward: 216.0
Avg Reward: 21.6
Min Reward: 17.0
Gini Coefficient 0.09444444444444444
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-55-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 364.0
  episode_reward_mean: 248.14
  episode_reward_min: 125.0
  episodes_this_iter: 1
  episodes_total: 105
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.491
    dispatch_time_ms: 37.111
    learner:
      cur_lr: 0.001290070009417832
      grad_gnorm: 40.0
      policy_entropy: 39.347999572753906
      policy_loss: -34.39224624633789
      var_gnorm: 36.176509857177734
      vf_explained_var: 0.342698872089386
      vf_loss: 140.6583251953125
    num_steps_sampled: 1060000
    num_steps_trained: 1060000
    wait_time_ms: 133.729
  iterations_since_restore: 106
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 1893.7227280139923
  time_this_iter_s: 18.313000679016113
  time_total_s: 1893.7227280139923
  timestamp: 1593824146
  timesteps_since_restore: 1060000
  timesteps_this_iter: 10000
  timesteps_total: 1060000
  training_iteration: 106
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 1893 s, 106 iter, 1060000 ts, 248 rew

agent-1: 25.0
agent-2: 19.0
agent-3: 6.0
agent-4: 17.0
agent-5: 25.0
agent-6: 29.0
agent-7: 16.0
agent-8: 9.0
agent-9: 26.0
agent-10: 27.0
Sum Reward: 199.0
Avg Reward: 19.9
Min Reward: 6.0
Gini Coefficient 0.20753768844221104
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-56-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 364.0
  episode_reward_mean: 248.05
  episode_reward_min: 125.0
  episodes_this_iter: 1
  episodes_total: 106
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 4.117
    dispatch_time_ms: 37.77
    learner:
      cur_lr: 0.00128940399736166
      grad_gnorm: 1.4301267862319946
      policy_entropy: 130.72564697265625
      policy_loss: -0.7348375916481018
      var_gnorm: 36.32644271850586
      vf_explained_var: 0.648250937461853
      vf_loss: 0.0043182577937841415
    num_steps_sampled: 1070000
    num_steps_trained: 1070000
    wait_time_ms: 141.429
  iterations_since_restore: 107
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 1911.7707924842834
  time_this_iter_s: 18.048064470291138
  time_total_s: 1911.7707924842834
  timestamp: 1593824164
  timesteps_since_restore: 1070000
  timesteps_this_iter: 10000
  timesteps_total: 1070000
  training_iteration: 107
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 1911 s, 107 iter, 1070000 ts, 248 rew

agent-1: 24.0
agent-2: 29.0
agent-3: 16.0
agent-4: 18.0
agent-5: 24.0
agent-6: 18.0
agent-7: 25.0
agent-8: 15.0
agent-9: 27.0
agent-10: 28.0
Sum Reward: 224.0
Avg Reward: 22.4
Min Reward: 15.0
Gini Coefficient 0.12321428571428572
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-56-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 364.0
  episode_reward_mean: 249.04
  episode_reward_min: 137.0
  episodes_this_iter: 1
  episodes_total: 107
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.218
    dispatch_time_ms: 25.938
    learner:
      cur_lr: 0.0012887379853054881
      grad_gnorm: 40.00000762939453
      policy_entropy: 48.999961853027344
      policy_loss: 10.285638809204102
      var_gnorm: 36.37344741821289
      vf_explained_var: 0.7407757043838501
      vf_loss: 62.87150573730469
    num_steps_sampled: 1080000
    num_steps_trained: 1080000
    wait_time_ms: 145.003
  iterations_since_restore: 108
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 1930.022634267807
  time_this_iter_s: 18.25184178352356
  time_total_s: 1930.022634267807
  timestamp: 1593824182
  timesteps_since_restore: 1080000
  timesteps_this_iter: 10000
  timesteps_total: 1080000
  training_iteration: 108
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 1930 s, 108 iter, 1080000 ts, 249 rew

agent-1: 22.0
agent-2: 19.0
agent-3: 26.0
agent-4: 25.0
agent-5: 19.0
agent-6: 33.0
agent-7: 25.0
agent-8: 19.0
agent-9: 29.0
agent-10: 25.0
Sum Reward: 242.0
Avg Reward: 24.2
Min Reward: 19.0
Gini Coefficient 0.09917355371900827
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-56-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 364.0
  episode_reward_mean: 248.51
  episode_reward_min: 137.0
  episodes_this_iter: 1
  episodes_total: 108
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.699
    dispatch_time_ms: 22.507
    learner:
      cur_lr: 0.0012880719732493162
      grad_gnorm: 1.3863416910171509
      policy_entropy: 97.08738708496094
      policy_loss: 0.41263625025749207
      var_gnorm: 36.52579879760742
      vf_explained_var: -1.0
      vf_loss: 0.008699196390807629
    num_steps_sampled: 1090000
    num_steps_trained: 1090000
    wait_time_ms: 151.144
  iterations_since_restore: 109
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 1954.110891342163
  time_this_iter_s: 24.08825707435608
  time_total_s: 1954.110891342163
  timestamp: 1593824206
  timesteps_since_restore: 1090000
  timesteps_this_iter: 10000
  timesteps_total: 1090000
  training_iteration: 109
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 1954 s, 109 iter, 1090000 ts, 249 rew

agent-1: 25.0
agent-2: 24.0
agent-3: 25.0
agent-4: 23.0
agent-5: 35.0
agent-6: 18.0
agent-7: 31.0
agent-8: 22.0
agent-9: 23.0
agent-10: 24.0
Sum Reward: 250.0
Avg Reward: 25.0
Min Reward: 18.0
Gini Coefficient 0.0928
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-57-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 358.0
  episode_reward_mean: 247.37
  episode_reward_min: 137.0
  episodes_this_iter: 1
  episodes_total: 109
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.755
    dispatch_time_ms: 30.051
    learner:
      cur_lr: 0.0012874059611931443
      grad_gnorm: 3.0507471561431885
      policy_entropy: 124.6049575805664
      policy_loss: -0.6100796461105347
      var_gnorm: 36.49922561645508
      vf_explained_var: 0.9354071617126465
      vf_loss: 0.005884957034140825
    num_steps_sampled: 1100000
    num_steps_trained: 1100000
    wait_time_ms: 149.715
  iterations_since_restore: 110
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 1972.2070741653442
  time_this_iter_s: 18.096182823181152
  time_total_s: 1972.2070741653442
  timestamp: 1593824224
  timesteps_since_restore: 1100000
  timesteps_this_iter: 10000
  timesteps_total: 1100000
  training_iteration: 110
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 1972 s, 110 iter, 1100000 ts, 247 rew

agent-1: 16.0
agent-2: 25.0
agent-3: 17.0
agent-4: 26.0
agent-5: 27.0
agent-6: 30.0
agent-7: 23.0
agent-8: 21.0
agent-9: 22.0
agent-10: 21.0
Sum Reward: 228.0
Avg Reward: 22.8
Min Reward: 16.0
Gini Coefficient 0.10263157894736842
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-57-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 358.0
  episode_reward_mean: 246.14
  episode_reward_min: 137.0
  episodes_this_iter: 1
  episodes_total: 110
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.851
    dispatch_time_ms: 25.207
    learner:
      cur_lr: 0.0012867399491369724
      grad_gnorm: 25.693593978881836
      policy_entropy: 124.92172241210938
      policy_loss: -0.5374422669410706
      var_gnorm: 36.66708755493164
      vf_explained_var: -1.0
      vf_loss: 0.05511302873492241
    num_steps_sampled: 1110000
    num_steps_trained: 1110000
    wait_time_ms: 153.109
  iterations_since_restore: 111
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 1990.043711423874
  time_this_iter_s: 17.836637258529663
  time_total_s: 1990.043711423874
  timestamp: 1593824242
  timesteps_since_restore: 1110000
  timesteps_this_iter: 10000
  timesteps_total: 1110000
  training_iteration: 111
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 1990 s, 111 iter, 1110000 ts, 246 rew

agent-1: 20.0
agent-2: 25.0
agent-3: 23.0
agent-4: 15.0
agent-5: 23.0
agent-6: 15.0
agent-7: 26.0
agent-8: 22.0
agent-9: 23.0
agent-10: 33.0
Sum Reward: 225.0
Avg Reward: 22.5
Min Reward: 15.0
Gini Coefficient 0.11866666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-57-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 358.0
  episode_reward_mean: 245.61
  episode_reward_min: 137.0
  episodes_this_iter: 1
  episodes_total: 111
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 4.01
    dispatch_time_ms: 34.045
    learner:
      cur_lr: 0.0012860740534961224
      grad_gnorm: 40.0
      policy_entropy: 64.11849975585938
      policy_loss: -5.881051540374756
      var_gnorm: 36.660343170166016
      vf_explained_var: -0.15814828872680664
      vf_loss: 131.35157775878906
    num_steps_sampled: 1120000
    num_steps_trained: 1120000
    wait_time_ms: 144.474
  iterations_since_restore: 112
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2008.3543620109558
  time_this_iter_s: 18.31065058708191
  time_total_s: 2008.3543620109558
  timestamp: 1593824261
  timesteps_since_restore: 1120000
  timesteps_this_iter: 10000
  timesteps_total: 1120000
  training_iteration: 112
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2008 s, 112 iter, 1120000 ts, 246 rew

agent-1: 23.0
agent-2: 22.0
agent-3: 32.0
agent-4: 24.0
agent-5: 31.0
agent-6: 37.0
agent-7: 16.0
agent-8: 29.0
agent-9: 22.0
agent-10: 26.0
Sum Reward: 262.0
Avg Reward: 26.2
Min Reward: 16.0
Gini Coefficient 0.12366412213740458
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-57-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 358.0
  episode_reward_mean: 245.46
  episode_reward_min: 137.0
  episodes_this_iter: 1
  episodes_total: 112
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.867
    dispatch_time_ms: 61.495
    learner:
      cur_lr: 0.0012854080414399505
      grad_gnorm: 13.924139022827148
      policy_entropy: 97.6342544555664
      policy_loss: -0.4101683497428894
      var_gnorm: 36.90032958984375
      vf_explained_var: -0.0917513370513916
      vf_loss: 0.12302947044372559
    num_steps_sampled: 1130000
    num_steps_trained: 1130000
    wait_time_ms: 142.982
  iterations_since_restore: 113
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2026.4006249904633
  time_this_iter_s: 18.046262979507446
  time_total_s: 2026.4006249904633
  timestamp: 1593824279
  timesteps_since_restore: 1130000
  timesteps_this_iter: 10000
  timesteps_total: 1130000
  training_iteration: 113
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2026 s, 113 iter, 1130000 ts, 245 rew

agent-1: 21.0
agent-2: 30.0
agent-3: 23.0
agent-4: 22.0
agent-5: 26.0
agent-6: 28.0
agent-7: 18.0
agent-8: 25.0
agent-9: 32.0
agent-10: 31.0
Sum Reward: 256.0
Avg Reward: 25.6
Min Reward: 18.0
Gini Coefficient 0.0984375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-58-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 358.0
  episode_reward_mean: 245.85
  episode_reward_min: 137.0
  episodes_this_iter: 1
  episodes_total: 113
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.933
    dispatch_time_ms: 38.794
    learner:
      cur_lr: 0.0012847420293837786
      grad_gnorm: 40.0
      policy_entropy: 62.11915588378906
      policy_loss: -19.255474090576172
      var_gnorm: 36.92128372192383
      vf_explained_var: 0.2784680724143982
      vf_loss: 218.94981384277344
    num_steps_sampled: 1140000
    num_steps_trained: 1140000
    wait_time_ms: 122.376
  iterations_since_restore: 114
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2044.6342630386353
  time_this_iter_s: 18.233638048171997
  time_total_s: 2044.6342630386353
  timestamp: 1593824297
  timesteps_since_restore: 1140000
  timesteps_this_iter: 10000
  timesteps_total: 1140000
  training_iteration: 114
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2044 s, 114 iter, 1140000 ts, 246 rew

agent-1: 31.0
agent-2: 20.0
agent-3: 26.0
agent-4: 17.0
agent-5: 27.0
agent-6: 23.0
agent-7: 28.0
agent-8: 27.0
agent-9: 18.0
agent-10: 37.0
Sum Reward: 254.0
Avg Reward: 25.4
Min Reward: 17.0
Gini Coefficient 0.12755905511811025
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-58-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 358.0
  episode_reward_mean: 245.39
  episode_reward_min: 137.0
  episodes_this_iter: 1
  episodes_total: 114
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.927
    dispatch_time_ms: 28.458
    learner:
      cur_lr: 0.0012840760173276067
      grad_gnorm: 6.259310722351074
      policy_entropy: 138.63197326660156
      policy_loss: -0.5407098531723022
      var_gnorm: 37.157257080078125
      vf_explained_var: -1.0
      vf_loss: 0.027954602614045143
    num_steps_sampled: 1150000
    num_steps_trained: 1150000
    wait_time_ms: 149.968
  iterations_since_restore: 115
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2062.6150600910187
  time_this_iter_s: 17.980797052383423
  time_total_s: 2062.6150600910187
  timestamp: 1593824315
  timesteps_since_restore: 1150000
  timesteps_this_iter: 10000
  timesteps_total: 1150000
  training_iteration: 115
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2062 s, 115 iter, 1150000 ts, 245 rew

agent-1: 17.0
agent-2: 31.0
agent-3: 26.0
agent-4: 31.0
agent-5: 25.0
agent-6: 33.0
agent-7: 16.0
agent-8: 23.0
agent-9: 26.0
agent-10: 27.0
Sum Reward: 255.0
Avg Reward: 25.5
Min Reward: 16.0
Gini Coefficient 0.11647058823529412
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-58-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 358.0
  episode_reward_mean: 245.4
  episode_reward_min: 137.0
  episodes_this_iter: 1
  episodes_total: 115
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 4.105
    dispatch_time_ms: 31.281
    learner:
      cur_lr: 0.0012834100052714348
      grad_gnorm: 40.000003814697266
      policy_entropy: 53.48027420043945
      policy_loss: 11.06628131866455
      var_gnorm: 37.1686897277832
      vf_explained_var: 0.34791308641433716
      vf_loss: 105.41126251220703
    num_steps_sampled: 1160000
    num_steps_trained: 1160000
    wait_time_ms: 131.973
  iterations_since_restore: 116
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2080.8109085559845
  time_this_iter_s: 18.19584846496582
  time_total_s: 2080.8109085559845
  timestamp: 1593824333
  timesteps_since_restore: 1160000
  timesteps_this_iter: 10000
  timesteps_total: 1160000
  training_iteration: 116
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2080 s, 116 iter, 1160000 ts, 245 rew

agent-1: 24.0
agent-2: 16.0
agent-3: 26.0
agent-4: 27.0
agent-5: 21.0
agent-6: 25.0
agent-7: 15.0
agent-8: 21.0
agent-9: 19.0
agent-10: 16.0
Sum Reward: 210.0
Avg Reward: 21.0
Min Reward: 15.0
Gini Coefficient 0.11333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-59-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 358.0
  episode_reward_mean: 244.96
  episode_reward_min: 137.0
  episodes_this_iter: 1
  episodes_total: 116
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.904
    dispatch_time_ms: 33.26
    learner:
      cur_lr: 0.0012827439932152629
      grad_gnorm: 2.042755126953125
      policy_entropy: 114.01400756835938
      policy_loss: 0.32412028312683105
      var_gnorm: 37.38406753540039
      vf_explained_var: -0.4328519105911255
      vf_loss: 0.06003910303115845
    num_steps_sampled: 1170000
    num_steps_trained: 1170000
    wait_time_ms: 147.352
  iterations_since_restore: 117
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2098.9399502277374
  time_this_iter_s: 18.12904167175293
  time_total_s: 2098.9399502277374
  timestamp: 1593824351
  timesteps_since_restore: 1170000
  timesteps_this_iter: 10000
  timesteps_total: 1170000
  training_iteration: 117
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2098 s, 117 iter, 1170000 ts, 245 rew

agent-1: 24.0
agent-2: 29.0
agent-3: 37.0
agent-4: 26.0
agent-5: 17.0
agent-6: 19.0
agent-7: 29.0
agent-8: 15.0
agent-9: 12.0
agent-10: 27.0
Sum Reward: 235.0
Avg Reward: 23.5
Min Reward: 12.0
Gini Coefficient 0.17404255319148937
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-59-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 358.0
  episode_reward_mean: 244.48
  episode_reward_min: 137.0
  episodes_this_iter: 1
  episodes_total: 117
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.4
    dispatch_time_ms: 36.67
    learner:
      cur_lr: 0.001282077981159091
      grad_gnorm: 11.320865631103516
      policy_entropy: 122.68085479736328
      policy_loss: 1.5898234844207764
      var_gnorm: 37.394805908203125
      vf_explained_var: 0.31835049390792847
      vf_loss: 0.0048019299283623695
    num_steps_sampled: 1180000
    num_steps_trained: 1180000
    wait_time_ms: 144.582
  iterations_since_restore: 118
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2117.0262484550476
  time_this_iter_s: 18.08629822731018
  time_total_s: 2117.0262484550476
  timestamp: 1593824370
  timesteps_since_restore: 1180000
  timesteps_this_iter: 10000
  timesteps_total: 1180000
  training_iteration: 118
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2117 s, 118 iter, 1180000 ts, 244 rew

agent-1: 18.0
agent-2: 21.0
agent-3: 26.0
agent-4: 27.0
agent-5: 12.0
agent-6: 21.0
agent-7: 30.0
agent-8: 21.0
agent-9: 26.0
agent-10: 21.0
Sum Reward: 223.0
Avg Reward: 22.3
Min Reward: 12.0
Gini Coefficient 0.11883408071748879
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-59-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 358.0
  episode_reward_mean: 245.34
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 118
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.746
    dispatch_time_ms: 26.938
    learner:
      cur_lr: 0.001281411969102919
      grad_gnorm: 10.788614273071289
      policy_entropy: 96.30522155761719
      policy_loss: -3.171640396118164
      var_gnorm: 37.60392761230469
      vf_explained_var: -1.0
      vf_loss: 0.25203490257263184
    num_steps_sampled: 1190000
    num_steps_trained: 1190000
    wait_time_ms: 159.755
  iterations_since_restore: 119
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2135.225934743881
  time_this_iter_s: 18.199686288833618
  time_total_s: 2135.225934743881
  timestamp: 1593824388
  timesteps_since_restore: 1190000
  timesteps_this_iter: 10000
  timesteps_total: 1190000
  training_iteration: 119
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2135 s, 119 iter, 1190000 ts, 245 rew

agent-1: 22.0
agent-2: 23.0
agent-3: 26.0
agent-4: 14.0
agent-5: 23.0
agent-6: 14.0
agent-7: 22.0
agent-8: 35.0
agent-9: 22.0
agent-10: 23.0
Sum Reward: 224.0
Avg Reward: 22.4
Min Reward: 14.0
Gini Coefficient 0.12589285714285714
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-00-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 358.0
  episode_reward_mean: 245.15
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 119
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.224
    dispatch_time_ms: 32.714
    learner:
      cur_lr: 0.0012807459570467472
      grad_gnorm: 1.6088167428970337
      policy_entropy: 101.05581665039062
      policy_loss: 0.7992366552352905
      var_gnorm: 37.65168380737305
      vf_explained_var: 0.13164693117141724
      vf_loss: 0.006567756645381451
    num_steps_sampled: 1200000
    num_steps_trained: 1200000
    wait_time_ms: 153.72
  iterations_since_restore: 120
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2153.36563038826
  time_this_iter_s: 18.139695644378662
  time_total_s: 2153.36563038826
  timestamp: 1593824406
  timesteps_since_restore: 1200000
  timesteps_this_iter: 10000
  timesteps_total: 1200000
  training_iteration: 120
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2153 s, 120 iter, 1200000 ts, 245 rew

agent-1: 21.0
agent-2: 35.0
agent-3: 33.0
agent-4: 35.0
agent-5: 26.0
agent-6: 15.0
agent-7: 38.0
agent-8: 13.0
agent-9: 19.0
agent-10: 24.0
Sum Reward: 259.0
Avg Reward: 25.9
Min Reward: 13.0
Gini Coefficient 0.1864864864864865
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-00-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 358.0
  episode_reward_mean: 245.56
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 120
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.449
    dispatch_time_ms: 19.096
    learner:
      cur_lr: 0.0012800799449905753
      grad_gnorm: 1.8583436012268066
      policy_entropy: 141.64418029785156
      policy_loss: 2.389091968536377
      var_gnorm: 37.79585647583008
      vf_explained_var: -1.0
      vf_loss: 0.010078150779008865
    num_steps_sampled: 1210000
    num_steps_trained: 1210000
    wait_time_ms: 169.107
  iterations_since_restore: 121
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2170.607105731964
  time_this_iter_s: 17.241475343704224
  time_total_s: 2170.607105731964
  timestamp: 1593824427
  timesteps_since_restore: 1210000
  timesteps_this_iter: 10000
  timesteps_total: 1210000
  training_iteration: 121
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2170 s, 121 iter, 1210000 ts, 246 rew

agent-1: 24.0
agent-2: 34.0
agent-3: 18.0
agent-4: 28.0
agent-5: 31.0
agent-6: 18.0
agent-7: 33.0
agent-8: 19.0
agent-9: 28.0
agent-10: 25.0
Sum Reward: 258.0
Avg Reward: 25.8
Min Reward: 18.0
Gini Coefficient 0.12558139534883722
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-00-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 358.0
  episode_reward_mean: 246.04
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 121
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.181
    dispatch_time_ms: 36.002
    learner:
      cur_lr: 0.0012794140493497252
      grad_gnorm: 39.9999885559082
      policy_entropy: 59.23171615600586
      policy_loss: -33.3836784362793
      var_gnorm: 37.78641891479492
      vf_explained_var: 0.559491753578186
      vf_loss: 105.64801025390625
    num_steps_sampled: 1220000
    num_steps_trained: 1220000
    wait_time_ms: 132.534
  iterations_since_restore: 122
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2188.583467721939
  time_this_iter_s: 17.976361989974976
  time_total_s: 2188.583467721939
  timestamp: 1593824445
  timesteps_since_restore: 1220000
  timesteps_this_iter: 10000
  timesteps_total: 1220000
  training_iteration: 122
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2188 s, 122 iter, 1220000 ts, 246 rew

agent-1: 39.0
agent-2: 22.0
agent-3: 29.0
agent-4: 17.0
agent-5: 17.0
agent-6: 20.0
agent-7: 29.0
agent-8: 33.0
agent-9: 32.0
agent-10: 8.0
Sum Reward: 246.0
Avg Reward: 24.6
Min Reward: 8.0
Gini Coefficient 0.2032520325203252
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-01-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 358.0
  episode_reward_mean: 245.92
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 122
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.872
    dispatch_time_ms: 17.748
    learner:
      cur_lr: 0.0012787480372935534
      grad_gnorm: 1.896937608718872
      policy_entropy: 154.73965454101562
      policy_loss: -0.7864440679550171
      var_gnorm: 37.99232482910156
      vf_explained_var: -0.38676607608795166
      vf_loss: 0.0026931711472570896
    num_steps_sampled: 1230000
    num_steps_trained: 1230000
    wait_time_ms: 159.224
  iterations_since_restore: 123
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2206.7827455997467
  time_this_iter_s: 18.199277877807617
  time_total_s: 2206.7827455997467
  timestamp: 1593824463
  timesteps_since_restore: 1230000
  timesteps_this_iter: 10000
  timesteps_total: 1230000
  training_iteration: 123
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2206 s, 123 iter, 1230000 ts, 246 rew

agent-1: 20.0
agent-2: 20.0
agent-3: 19.0
agent-4: 19.0
agent-5: 23.0
agent-6: 28.0
agent-7: 21.0
agent-8: 21.0
agent-9: 25.0
agent-10: 31.0
Sum Reward: 227.0
Avg Reward: 22.7
Min Reward: 19.0
Gini Coefficient 0.09030837004405286
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-01-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 358.0
  episode_reward_mean: 245.91
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 123
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.859
    dispatch_time_ms: 28.303
    learner:
      cur_lr: 0.0012780820252373815
      grad_gnorm: 0.8627618551254272
      policy_entropy: 153.82421875
      policy_loss: -0.7873116731643677
      var_gnorm: 37.97869110107422
      vf_explained_var: 0.9731185436248779
      vf_loss: 0.0007277348777279258
    num_steps_sampled: 1240000
    num_steps_trained: 1240000
    wait_time_ms: 156.151
  iterations_since_restore: 124
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2225.0678567886353
  time_this_iter_s: 18.28511118888855
  time_total_s: 2225.0678567886353
  timestamp: 1593824481
  timesteps_since_restore: 1240000
  timesteps_this_iter: 10000
  timesteps_total: 1240000
  training_iteration: 124
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2225 s, 124 iter, 1240000 ts, 246 rew

agent-1: 21.0
agent-2: 31.0
agent-3: 27.0
agent-4: 21.0
agent-5: 24.0
agent-6: 20.0
agent-7: 20.0
agent-8: 23.0
agent-9: 24.0
agent-10: 25.0
Sum Reward: 236.0
Avg Reward: 23.6
Min Reward: 20.0
Gini Coefficient 0.07542372881355933
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-01-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 358.0
  episode_reward_mean: 245.66
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 124
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.509
    dispatch_time_ms: 28.105
    learner:
      cur_lr: 0.0012774160131812096
      grad_gnorm: 1.6655125617980957
      policy_entropy: 153.59005737304688
      policy_loss: -0.09272655844688416
      var_gnorm: 38.209808349609375
      vf_explained_var: -1.0
      vf_loss: 0.05121786519885063
    num_steps_sampled: 1250000
    num_steps_trained: 1250000
    wait_time_ms: 152.437
  iterations_since_restore: 125
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2243.333825826645
  time_this_iter_s: 18.265969038009644
  time_total_s: 2243.333825826645
  timestamp: 1593824500
  timesteps_since_restore: 1250000
  timesteps_this_iter: 10000
  timesteps_total: 1250000
  training_iteration: 125
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2243 s, 125 iter, 1250000 ts, 246 rew

agent-1: 20.0
agent-2: 25.0
agent-3: 35.0
agent-4: 18.0
agent-5: 22.0
agent-6: 31.0
agent-7: 23.0
agent-8: 22.0
agent-9: 24.0
agent-10: 19.0
Sum Reward: 239.0
Avg Reward: 23.9
Min Reward: 18.0
Gini Coefficient 0.11255230125523012
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-02-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 358.0
  episode_reward_mean: 245.54
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 125
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.696
    dispatch_time_ms: 15.781
    learner:
      cur_lr: 0.0012767500011250377
      grad_gnorm: 40.00000762939453
      policy_entropy: 52.99576950073242
      policy_loss: 21.881629943847656
      var_gnorm: 38.211143493652344
      vf_explained_var: 0.8180162310600281
      vf_loss: 143.95921325683594
    num_steps_sampled: 1260000
    num_steps_trained: 1260000
    wait_time_ms: 152.541
  iterations_since_restore: 126
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2280.6888196468353
  time_this_iter_s: 37.35499382019043
  time_total_s: 2280.6888196468353
  timestamp: 1593824537
  timesteps_since_restore: 1260000
  timesteps_this_iter: 10000
  timesteps_total: 1260000
  training_iteration: 126
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2280 s, 126 iter, 1260000 ts, 246 rew

agent-1: 31.0
agent-2: 20.0
agent-3: 22.0
agent-4: 32.0
agent-5: 20.0
agent-6: 38.0
agent-7: 10.0
agent-8: 18.0
agent-9: 26.0
agent-10: 28.0
Sum Reward: 245.0
Avg Reward: 24.5
Min Reward: 10.0
Gini Coefficient 0.17673469387755103
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-02-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 358.0
  episode_reward_mean: 245.57
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 126
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 4.008
    dispatch_time_ms: 13.899
    learner:
      cur_lr: 0.0012760839890688658
      grad_gnorm: 0.6506429314613342
      policy_entropy: 139.56732177734375
      policy_loss: 0.2567406892776489
      var_gnorm: 38.40074920654297
      vf_explained_var: 0.9448776245117188
      vf_loss: 0.0003945007629226893
    num_steps_sampled: 1270000
    num_steps_trained: 1270000
    wait_time_ms: 171.06
  iterations_since_restore: 127
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2297.6578760147095
  time_this_iter_s: 16.969056367874146
  time_total_s: 2297.6578760147095
  timestamp: 1593824555
  timesteps_since_restore: 1270000
  timesteps_this_iter: 10000
  timesteps_total: 1270000
  training_iteration: 127
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2297 s, 127 iter, 1270000 ts, 246 rew

agent-1: 13.0
agent-2: 30.0
agent-3: 25.0
agent-4: 19.0
agent-5: 23.0
agent-6: 17.0
agent-7: 36.0
agent-8: 40.0
agent-9: 27.0
agent-10: 36.0
Sum Reward: 266.0
Avg Reward: 26.6
Min Reward: 13.0
Gini Coefficient 0.18195488721804512
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-02-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 358.0
  episode_reward_mean: 245.63
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 127
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.276
    dispatch_time_ms: 6.212
    learner:
      cur_lr: 0.0012754179770126939
      grad_gnorm: 1.7901499271392822
      policy_entropy: 150.830078125
      policy_loss: -0.7802466154098511
      var_gnorm: 38.425785064697266
      vf_explained_var: 0.7331238985061646
      vf_loss: 0.002991011366248131
    num_steps_sampled: 1280000
    num_steps_trained: 1280000
    wait_time_ms: 155.089
  iterations_since_restore: 128
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2315.155364513397
  time_this_iter_s: 17.497488498687744
  time_total_s: 2315.155364513397
  timestamp: 1593824573
  timesteps_since_restore: 1280000
  timesteps_this_iter: 10000
  timesteps_total: 1280000
  training_iteration: 128
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2315 s, 128 iter, 1280000 ts, 246 rew

agent-1: 26.0
agent-2: 27.0
agent-3: 25.0
agent-4: 32.0
agent-5: 24.0
agent-6: 33.0
agent-7: 25.0
agent-8: 23.0
agent-9: 21.0
agent-10: 21.0
Sum Reward: 257.0
Avg Reward: 25.7
Min Reward: 21.0
Gini Coefficient 0.0821011673151751
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-03-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 358.0
  episode_reward_mean: 245.63
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 128
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.868
    dispatch_time_ms: 5.96
    learner:
      cur_lr: 0.001274751964956522
      grad_gnorm: 1.3373738527297974
      policy_entropy: 158.3206329345703
      policy_loss: 0.29320839047431946
      var_gnorm: 38.499839782714844
      vf_explained_var: 0.8927346467971802
      vf_loss: 0.00910868775099516
    num_steps_sampled: 1290000
    num_steps_trained: 1290000
    wait_time_ms: 169.175
  iterations_since_restore: 129
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2332.5990121364594
  time_this_iter_s: 17.443647623062134
  time_total_s: 2332.5990121364594
  timestamp: 1593824590
  timesteps_since_restore: 1290000
  timesteps_this_iter: 10000
  timesteps_total: 1290000
  training_iteration: 129
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2332 s, 129 iter, 1290000 ts, 246 rew

agent-1: 41.0
agent-2: 22.0
agent-3: 34.0
agent-4: 25.0
agent-5: 25.0
agent-6: 30.0
agent-7: 22.0
agent-8: 16.0
agent-9: 24.0
agent-10: 24.0
Sum Reward: 263.0
Avg Reward: 26.3
Min Reward: 16.0
Gini Coefficient 0.13422053231939163
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-03-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 358.0
  episode_reward_mean: 245.99
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 129
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.778
    dispatch_time_ms: 25.115
    learner:
      cur_lr: 0.00127408595290035
      grad_gnorm: 3.806321620941162
      policy_entropy: 164.19346618652344
      policy_loss: -1.5156617164611816
      var_gnorm: 38.51297378540039
      vf_explained_var: -0.34013450145721436
      vf_loss: 0.009079390205442905
    num_steps_sampled: 1300000
    num_steps_trained: 1300000
    wait_time_ms: 156.317
  iterations_since_restore: 130
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2350.7540230751038
  time_this_iter_s: 18.15501093864441
  time_total_s: 2350.7540230751038
  timestamp: 1593824608
  timesteps_since_restore: 1300000
  timesteps_this_iter: 10000
  timesteps_total: 1300000
  training_iteration: 130
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2350 s, 130 iter, 1300000 ts, 246 rew

agent-1: 19.0
agent-2: 28.0
agent-3: 29.0
agent-4: 28.0
agent-5: 25.0
agent-6: 28.0
agent-7: 27.0
agent-8: 28.0
agent-9: 21.0
agent-10: 17.0
Sum Reward: 250.0
Avg Reward: 25.0
Min Reward: 17.0
Gini Coefficient 0.0864
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-03-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 358.0
  episode_reward_mean: 246.38
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 130
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.667
    dispatch_time_ms: 25.44
    learner:
      cur_lr: 0.0012734200572595
      grad_gnorm: 9.347627639770508
      policy_entropy: 153.4190673828125
      policy_loss: -4.991734981536865
      var_gnorm: 38.792518615722656
      vf_explained_var: -1.0
      vf_loss: 0.14101001620292664
    num_steps_sampled: 1310000
    num_steps_trained: 1310000
    wait_time_ms: 161.915
  iterations_since_restore: 131
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2368.829931497574
  time_this_iter_s: 18.075908422470093
  time_total_s: 2368.829931497574
  timestamp: 1593824626
  timesteps_since_restore: 1310000
  timesteps_this_iter: 10000
  timesteps_total: 1310000
  training_iteration: 131
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2368 s, 131 iter, 1310000 ts, 246 rew

agent-1: 26.0
agent-2: 35.0
agent-3: 21.0
agent-4: 23.0
agent-5: 17.0
agent-6: 30.0
agent-7: 29.0
agent-8: 28.0
agent-9: 21.0
agent-10: 24.0
Sum Reward: 254.0
Avg Reward: 25.4
Min Reward: 17.0
Gini Coefficient 0.1110236220472441
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-04-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 358.0
  episode_reward_mean: 246.49
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 131
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.204
    dispatch_time_ms: 31.411
    learner:
      cur_lr: 0.0012727540452033281
      grad_gnorm: 39.99998092651367
      policy_entropy: 60.08135986328125
      policy_loss: -12.579437255859375
      var_gnorm: 38.826210021972656
      vf_explained_var: 0.4396473169326782
      vf_loss: 55.35877990722656
    num_steps_sampled: 1320000
    num_steps_trained: 1320000
    wait_time_ms: 128.669
  iterations_since_restore: 132
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2387.0438663959503
  time_this_iter_s: 18.213934898376465
  time_total_s: 2387.0438663959503
  timestamp: 1593824645
  timesteps_since_restore: 1320000
  timesteps_this_iter: 10000
  timesteps_total: 1320000
  training_iteration: 132
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2387 s, 132 iter, 1320000 ts, 246 rew

agent-1: 21.0
agent-2: 29.0
agent-3: 26.0
agent-4: 20.0
agent-5: 30.0
agent-6: 21.0
agent-7: 25.0
agent-8: 35.0
agent-9: 29.0
agent-10: 16.0
Sum Reward: 252.0
Avg Reward: 25.2
Min Reward: 16.0
Gini Coefficient 0.12142857142857143
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-04-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 358.0
  episode_reward_mean: 246.39
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 132
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.82
    dispatch_time_ms: 27.33
    learner:
      cur_lr: 0.0012720880331471562
      grad_gnorm: 1.6528810262680054
      policy_entropy: 150.4019012451172
      policy_loss: 1.235943078994751
      var_gnorm: 39.06610107421875
      vf_explained_var: -1.0
      vf_loss: 0.006140426266938448
    num_steps_sampled: 1330000
    num_steps_trained: 1330000
    wait_time_ms: 156.811
  iterations_since_restore: 133
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2405.214987039566
  time_this_iter_s: 18.171120643615723
  time_total_s: 2405.214987039566
  timestamp: 1593824663
  timesteps_since_restore: 1330000
  timesteps_this_iter: 10000
  timesteps_total: 1330000
  training_iteration: 133
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2405 s, 133 iter, 1330000 ts, 246 rew

agent-1: 17.0
agent-2: 22.0
agent-3: 16.0
agent-4: 21.0
agent-5: 17.0
agent-6: 24.0
agent-7: 26.0
agent-8: 30.0
agent-9: 18.0
agent-10: 28.0
Sum Reward: 219.0
Avg Reward: 21.9
Min Reward: 16.0
Gini Coefficient 0.12191780821917808
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-04-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 358.0
  episode_reward_mean: 246.44
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 133
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.845
    dispatch_time_ms: 20.155
    learner:
      cur_lr: 0.0012714220210909843
      grad_gnorm: 14.592456817626953
      policy_entropy: 166.05227661132812
      policy_loss: -1.6584477424621582
      var_gnorm: 39.05903625488281
      vf_explained_var: -1.0
      vf_loss: 0.029131565243005753
    num_steps_sampled: 1340000
    num_steps_trained: 1340000
    wait_time_ms: 154.452
  iterations_since_restore: 134
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2423.3869495391846
  time_this_iter_s: 18.17196249961853
  time_total_s: 2423.3869495391846
  timestamp: 1593824681
  timesteps_since_restore: 1340000
  timesteps_this_iter: 10000
  timesteps_total: 1340000
  training_iteration: 134
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2423 s, 134 iter, 1340000 ts, 246 rew

agent-1: 21.0
agent-2: 22.0
agent-3: 29.0
agent-4: 27.0
agent-5: 36.0
agent-6: 30.0
agent-7: 23.0
agent-8: 24.0
agent-9: 25.0
agent-10: 34.0
Sum Reward: 271.0
Avg Reward: 27.1
Min Reward: 21.0
Gini Coefficient 0.1
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-04-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 358.0
  episode_reward_mean: 246.48
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 134
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.161
    dispatch_time_ms: 19.884
    learner:
      cur_lr: 0.0012707560090348125
      grad_gnorm: 1.9974364042282104
      policy_entropy: 146.56387329101562
      policy_loss: 0.9788632392883301
      var_gnorm: 39.234039306640625
      vf_explained_var: -1.0
      vf_loss: 0.000971534289419651
    num_steps_sampled: 1350000
    num_steps_trained: 1350000
    wait_time_ms: 166.14
  iterations_since_restore: 135
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2441.588188648224
  time_this_iter_s: 18.201239109039307
  time_total_s: 2441.588188648224
  timestamp: 1593824699
  timesteps_since_restore: 1350000
  timesteps_this_iter: 10000
  timesteps_total: 1350000
  training_iteration: 135
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2441 s, 135 iter, 1350000 ts, 246 rew

agent-1: 29.0
agent-2: 20.0
agent-3: 28.0
agent-4: 12.0
agent-5: 18.0
agent-6: 16.0
agent-7: 20.0
agent-8: 21.0
agent-9: 25.0
agent-10: 18.0
Sum Reward: 207.0
Avg Reward: 20.7
Min Reward: 12.0
Gini Coefficient 0.1357487922705314
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-05-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 358.0
  episode_reward_mean: 246.0
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 135
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.817
    dispatch_time_ms: 22.162
    learner:
      cur_lr: 0.0012700899969786406
      grad_gnorm: 40.00001907348633
      policy_entropy: 79.97122192382812
      policy_loss: 41.01968765258789
      var_gnorm: 39.21805953979492
      vf_explained_var: 0.8834139108657837
      vf_loss: 67.66075134277344
    num_steps_sampled: 1360000
    num_steps_trained: 1360000
    wait_time_ms: 142.442
  iterations_since_restore: 136
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2459.796600341797
  time_this_iter_s: 18.208411693572998
  time_total_s: 2459.796600341797
  timestamp: 1593824718
  timesteps_since_restore: 1360000
  timesteps_this_iter: 10000
  timesteps_total: 1360000
  training_iteration: 136
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2459 s, 136 iter, 1360000 ts, 246 rew

agent-1: 14.0
agent-2: 22.0
agent-3: 21.0
agent-4: 39.0
agent-5: 40.0
agent-6: 13.0
agent-7: 20.0
agent-8: 14.0
agent-9: 42.0
agent-10: 34.0
Sum Reward: 259.0
Avg Reward: 25.9
Min Reward: 13.0
Gini Coefficient 0.2359073359073359
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-05-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 358.0
  episode_reward_mean: 246.37
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 136
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 4.488
    dispatch_time_ms: 30.007
    learner:
      cur_lr: 0.0012694239849224687
      grad_gnorm: 0.21643364429473877
      policy_entropy: 165.65386962890625
      policy_loss: 0.16212840378284454
      var_gnorm: 39.34298324584961
      vf_explained_var: -1.0
      vf_loss: 2.8613401809707284e-05
    num_steps_sampled: 1370000
    num_steps_trained: 1370000
    wait_time_ms: 150.084
  iterations_since_restore: 137
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2478.0954265594482
  time_this_iter_s: 18.298826217651367
  time_total_s: 2478.0954265594482
  timestamp: 1593824736
  timesteps_since_restore: 1370000
  timesteps_this_iter: 10000
  timesteps_total: 1370000
  training_iteration: 137
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2478 s, 137 iter, 1370000 ts, 246 rew

agent-1: 37.0
agent-2: 30.0
agent-3: 16.0
agent-4: 26.0
agent-5: 50.0
agent-6: 37.0
agent-7: 18.0
agent-8: 3.0
agent-9: 42.0
agent-10: 13.0
Sum Reward: 272.0
Avg Reward: 27.2
Min Reward: 3.0
Gini Coefficient 0.2911764705882353
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-05-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 358.0
  episode_reward_mean: 246.54
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 137
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.856
    dispatch_time_ms: 27.244
    learner:
      cur_lr: 0.0012687579728662968
      grad_gnorm: 1.3883683681488037
      policy_entropy: 173.020263671875
      policy_loss: -1.2678837776184082
      var_gnorm: 39.291053771972656
      vf_explained_var: -1.0
      vf_loss: 0.0019825550261884928
    num_steps_sampled: 1380000
    num_steps_trained: 1380000
    wait_time_ms: 156.991
  iterations_since_restore: 138
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2496.2659125328064
  time_this_iter_s: 18.170485973358154
  time_total_s: 2496.2659125328064
  timestamp: 1593824754
  timesteps_since_restore: 1380000
  timesteps_this_iter: 10000
  timesteps_total: 1380000
  training_iteration: 138
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2496 s, 138 iter, 1380000 ts, 247 rew

agent-1: 9.0
agent-2: 21.0
agent-3: 29.0
agent-4: 22.0
agent-5: 24.0
agent-6: 13.0
agent-7: 26.0
agent-8: 25.0
agent-9: 30.0
agent-10: 10.0
Sum Reward: 209.0
Avg Reward: 20.9
Min Reward: 9.0
Gini Coefficient 0.19186602870813396
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-06-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 358.0
  episode_reward_mean: 245.84
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 138
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.72
    dispatch_time_ms: 30.505
    learner:
      cur_lr: 0.0012680919608101249
      grad_gnorm: 2.0824732780456543
      policy_entropy: 141.36265563964844
      policy_loss: 0.5001733303070068
      var_gnorm: 39.44789505004883
      vf_explained_var: 0.6865715980529785
      vf_loss: 0.029255207628011703
    num_steps_sampled: 1390000
    num_steps_trained: 1390000
    wait_time_ms: 143.459
  iterations_since_restore: 139
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2514.348759651184
  time_this_iter_s: 18.082847118377686
  time_total_s: 2514.348759651184
  timestamp: 1593824772
  timesteps_since_restore: 1390000
  timesteps_this_iter: 10000
  timesteps_total: 1390000
  training_iteration: 139
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2514 s, 139 iter, 1390000 ts, 246 rew

agent-1: 21.0
agent-2: 20.0
agent-3: 29.0
agent-4: 25.0
agent-5: 29.0
agent-6: 20.0
agent-7: 24.0
agent-8: 32.0
agent-9: 22.0
agent-10: 25.0
Sum Reward: 247.0
Avg Reward: 24.7
Min Reward: 20.0
Gini Coefficient 0.08947368421052632
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-06-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 325.0
  episode_reward_mean: 244.73
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 139
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 4.116
    dispatch_time_ms: 27.671
    learner:
      cur_lr: 0.001267425948753953
      grad_gnorm: 1.9986966848373413
      policy_entropy: 153.6117401123047
      policy_loss: -1.2868320941925049
      var_gnorm: 39.45201873779297
      vf_explained_var: 0.9923101663589478
      vf_loss: 0.0036480093840509653
    num_steps_sampled: 1400000
    num_steps_trained: 1400000
    wait_time_ms: 156.054
  iterations_since_restore: 140
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2532.535258293152
  time_this_iter_s: 18.186498641967773
  time_total_s: 2532.535258293152
  timestamp: 1593824790
  timesteps_since_restore: 1400000
  timesteps_this_iter: 10000
  timesteps_total: 1400000
  training_iteration: 140
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2532 s, 140 iter, 1400000 ts, 245 rew

agent-1: 30.0
agent-2: 31.0
agent-3: 21.0
agent-4: 34.0
agent-5: 21.0
agent-6: 19.0
agent-7: 29.0
agent-8: 19.0
agent-9: 16.0
agent-10: 21.0
Sum Reward: 241.0
Avg Reward: 24.1
Min Reward: 16.0
Gini Coefficient 0.13485477178423236
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-06-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 325.0
  episode_reward_mean: 244.11
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 140
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 4.005
    dispatch_time_ms: 32.772
    learner:
      cur_lr: 0.001266760053113103
      grad_gnorm: 0.7462089657783508
      policy_entropy: 157.03201293945312
      policy_loss: -1.510675072669983
      var_gnorm: 39.64420700073242
      vf_explained_var: -0.28586268424987793
      vf_loss: 0.0001945263211382553
    num_steps_sampled: 1410000
    num_steps_trained: 1410000
    wait_time_ms: 156.128
  iterations_since_restore: 141
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2549.9806904792786
  time_this_iter_s: 17.44543218612671
  time_total_s: 2549.9806904792786
  timestamp: 1593824809
  timesteps_since_restore: 1410000
  timesteps_this_iter: 10000
  timesteps_total: 1410000
  training_iteration: 141
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2549 s, 141 iter, 1410000 ts, 244 rew

agent-1: 18.0
agent-2: 29.0
agent-3: 12.0
agent-4: 34.0
agent-5: 32.0
agent-6: 19.0
agent-7: 22.0
agent-8: 29.0
agent-9: 32.0
agent-10: 36.0
Sum Reward: 263.0
Avg Reward: 26.3
Min Reward: 12.0
Gini Coefficient 0.16083650190114068
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-07-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 325.0
  episode_reward_mean: 244.32
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 141
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.891
    dispatch_time_ms: 23.636
    learner:
      cur_lr: 0.001266094041056931
      grad_gnorm: 40.000003814697266
      policy_entropy: 37.69227600097656
      policy_loss: 16.205713272094727
      var_gnorm: 39.65076446533203
      vf_explained_var: 0.08996379375457764
      vf_loss: 92.46709442138672
    num_steps_sampled: 1420000
    num_steps_trained: 1420000
    wait_time_ms: 152.494
  iterations_since_restore: 142
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2568.2330899238586
  time_this_iter_s: 18.252399444580078
  time_total_s: 2568.2330899238586
  timestamp: 1593824827
  timesteps_since_restore: 1420000
  timesteps_this_iter: 10000
  timesteps_total: 1420000
  training_iteration: 142
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2568 s, 142 iter, 1420000 ts, 244 rew

agent-1: 32.0
agent-2: 23.0
agent-3: 20.0
agent-4: 23.0
agent-5: 29.0
agent-6: 14.0
agent-7: 25.0
agent-8: 21.0
agent-9: 16.0
agent-10: 13.0
Sum Reward: 216.0
Avg Reward: 21.6
Min Reward: 13.0
Gini Coefficient 0.1537037037037037
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-07-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 325.0
  episode_reward_mean: 243.78
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 142
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.177
    dispatch_time_ms: 8.394
    learner:
      cur_lr: 0.0012654280290007591
      grad_gnorm: 2.4661054611206055
      policy_entropy: 115.4825439453125
      policy_loss: -0.06969770789146423
      var_gnorm: 39.889190673828125
      vf_explained_var: 0.3762108087539673
      vf_loss: 0.010343872010707855
    num_steps_sampled: 1430000
    num_steps_trained: 1430000
    wait_time_ms: 159.862
  iterations_since_restore: 143
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2592.862606525421
  time_this_iter_s: 24.6295166015625
  time_total_s: 2592.862606525421
  timestamp: 1593824852
  timesteps_since_restore: 1430000
  timesteps_this_iter: 10000
  timesteps_total: 1430000
  training_iteration: 143
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2592 s, 143 iter, 1430000 ts, 244 rew

agent-1: 27.0
agent-2: 35.0
agent-3: 28.0
agent-4: 19.0
agent-5: 30.0
agent-6: 25.0
agent-7: 34.0
agent-8: 30.0
agent-9: 26.0
agent-10: 36.0
Sum Reward: 290.0
Avg Reward: 29.0
Min Reward: 19.0
Gini Coefficient 0.09448275862068965
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-07-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 325.0
  episode_reward_mean: 244.37
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 143
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.647
    dispatch_time_ms: 6.112
    learner:
      cur_lr: 0.0012647620169445872
      grad_gnorm: 2.010676383972168
      policy_entropy: 156.54129028320312
      policy_loss: -0.7130782604217529
      var_gnorm: 39.884700775146484
      vf_explained_var: 0.8200638890266418
      vf_loss: 0.0034261259716004133
    num_steps_sampled: 1440000
    num_steps_trained: 1440000
    wait_time_ms: 160.295
  iterations_since_restore: 144
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2610.0672748088837
  time_this_iter_s: 17.204668283462524
  time_total_s: 2610.0672748088837
  timestamp: 1593824869
  timesteps_since_restore: 1440000
  timesteps_this_iter: 10000
  timesteps_total: 1440000
  training_iteration: 144
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2610 s, 144 iter, 1440000 ts, 244 rew

agent-1: 16.0
agent-2: 20.0
agent-3: 36.0
agent-4: 38.0
agent-5: 28.0
agent-6: 20.0
agent-7: 24.0
agent-8: 32.0
agent-9: 24.0
agent-10: 28.0
Sum Reward: 266.0
Avg Reward: 26.6
Min Reward: 16.0
Gini Coefficient 0.14511278195488722
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-08-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 325.0
  episode_reward_mean: 244.61
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 144
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.955
    dispatch_time_ms: 6.349
    learner:
      cur_lr: 0.0012640960048884153
      grad_gnorm: 1.288836121559143
      policy_entropy: 158.23135375976562
      policy_loss: -0.5786099433898926
      var_gnorm: 39.994136810302734
      vf_explained_var: -1.0
      vf_loss: 0.00649873074144125
    num_steps_sampled: 1450000
    num_steps_trained: 1450000
    wait_time_ms: 169.322
  iterations_since_restore: 145
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2627.3638434410095
  time_this_iter_s: 17.296568632125854
  time_total_s: 2627.3638434410095
  timestamp: 1593824886
  timesteps_since_restore: 1450000
  timesteps_this_iter: 10000
  timesteps_total: 1450000
  training_iteration: 145
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2627 s, 145 iter, 1450000 ts, 245 rew

agent-1: 17.0
agent-2: 31.0
agent-3: 33.0
agent-4: 22.0
agent-5: 41.0
agent-6: 31.0
agent-7: 22.0
agent-8: 35.0
agent-9: 23.0
agent-10: 41.0
Sum Reward: 296.0
Avg Reward: 29.6
Min Reward: 17.0
Gini Coefficient 0.15
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-08-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 325.0
  episode_reward_mean: 244.97
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 145
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.536
    dispatch_time_ms: 7.204
    learner:
      cur_lr: 0.0012634299928322434
      grad_gnorm: 3.290591239929199
      policy_entropy: 171.0993194580078
      policy_loss: -1.4469243288040161
      var_gnorm: 39.992149353027344
      vf_explained_var: -1.0
      vf_loss: 0.008303641341626644
    num_steps_sampled: 1460000
    num_steps_trained: 1460000
    wait_time_ms: 154.879
  iterations_since_restore: 146
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2644.7283651828766
  time_this_iter_s: 17.364521741867065
  time_total_s: 2644.7283651828766
  timestamp: 1593824904
  timesteps_since_restore: 1460000
  timesteps_this_iter: 10000
  timesteps_total: 1460000
  training_iteration: 146
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2644 s, 146 iter, 1460000 ts, 245 rew

agent-1: 25.0
agent-2: 24.0
agent-3: 27.0
agent-4: 35.0
agent-5: 29.0
agent-6: 18.0
agent-7: 24.0
agent-8: 30.0
agent-9: 20.0
agent-10: 32.0
Sum Reward: 264.0
Avg Reward: 26.4
Min Reward: 18.0
Gini Coefficient 0.10757575757575757
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-08-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 325.0
  episode_reward_mean: 245.15
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 146
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 4.894
    dispatch_time_ms: 6.842
    learner:
      cur_lr: 0.0012627639807760715
      grad_gnorm: 1.4693045616149902
      policy_entropy: 162.16769409179688
      policy_loss: -0.7784528136253357
      var_gnorm: 40.12932586669922
      vf_explained_var: -1.0
      vf_loss: 0.008282758295536041
    num_steps_sampled: 1470000
    num_steps_trained: 1470000
    wait_time_ms: 163.564
  iterations_since_restore: 147
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2662.2054715156555
  time_this_iter_s: 17.47710633277893
  time_total_s: 2662.2054715156555
  timestamp: 1593824921
  timesteps_since_restore: 1470000
  timesteps_this_iter: 10000
  timesteps_total: 1470000
  training_iteration: 147
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2662 s, 147 iter, 1470000 ts, 245 rew

agent-1: 24.0
agent-2: 31.0
agent-3: 25.0
agent-4: 20.0
agent-5: 22.0
agent-6: 20.0
agent-7: 27.0
agent-8: 35.0
agent-9: 33.0
agent-10: 20.0
Sum Reward: 257.0
Avg Reward: 25.7
Min Reward: 20.0
Gini Coefficient 0.11556420233463036
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-08-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 325.0
  episode_reward_mean: 244.92
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 147
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.57
    dispatch_time_ms: 6.376
    learner:
      cur_lr: 0.0012620979687198997
      grad_gnorm: 2.265126943588257
      policy_entropy: 170.07191467285156
      policy_loss: -0.6971492767333984
      var_gnorm: 40.10929870605469
      vf_explained_var: 0.0
      vf_loss: 0.0029843526426702738
    num_steps_sampled: 1480000
    num_steps_trained: 1480000
    wait_time_ms: 158.696
  iterations_since_restore: 148
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2679.581002473831
  time_this_iter_s: 17.37553095817566
  time_total_s: 2679.581002473831
  timestamp: 1593824939
  timesteps_since_restore: 1480000
  timesteps_this_iter: 10000
  timesteps_total: 1480000
  training_iteration: 148
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2679 s, 148 iter, 1480000 ts, 245 rew

agent-1: 21.0
agent-2: 23.0
agent-3: 28.0
agent-4: 20.0
agent-5: 24.0
agent-6: 23.0
agent-7: 17.0
agent-8: 23.0
agent-9: 21.0
agent-10: 18.0
Sum Reward: 218.0
Avg Reward: 21.8
Min Reward: 17.0
Gini Coefficient 0.07522935779816514
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-09-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 325.0
  episode_reward_mean: 244.7
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 148
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.157
    dispatch_time_ms: 6.519
    learner:
      cur_lr: 0.0012614319566637278
      grad_gnorm: 5.148494720458984
      policy_entropy: 90.0076904296875
      policy_loss: -1.892932653427124
      var_gnorm: 40.23434829711914
      vf_explained_var: -0.27234554290771484
      vf_loss: 0.07550482451915741
    num_steps_sampled: 1490000
    num_steps_trained: 1490000
    wait_time_ms: 169.65
  iterations_since_restore: 149
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2697.0945694446564
  time_this_iter_s: 17.513566970825195
  time_total_s: 2697.0945694446564
  timestamp: 1593824956
  timesteps_since_restore: 1490000
  timesteps_this_iter: 10000
  timesteps_total: 1490000
  training_iteration: 149
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2697 s, 149 iter, 1490000 ts, 245 rew

agent-1: 24.0
agent-2: 37.0
agent-3: 14.0
agent-4: 40.0
agent-5: 31.0
agent-6: 18.0
agent-7: 22.0
agent-8: 20.0
agent-9: 23.0
agent-10: 26.0
Sum Reward: 255.0
Avg Reward: 25.5
Min Reward: 14.0
Gini Coefficient 0.17058823529411765
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-09-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 325.0
  episode_reward_mean: 244.4
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 149
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.685
    dispatch_time_ms: 7.534
    learner:
      cur_lr: 0.0012607659446075559
      grad_gnorm: 1.915067195892334
      policy_entropy: 134.6090850830078
      policy_loss: -0.007845445536077023
      var_gnorm: 40.25250244140625
      vf_explained_var: -0.10555016994476318
      vf_loss: 0.03923986852169037
    num_steps_sampled: 1500000
    num_steps_trained: 1500000
    wait_time_ms: 164.218
  iterations_since_restore: 150
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2714.625949859619
  time_this_iter_s: 17.53138041496277
  time_total_s: 2714.625949859619
  timestamp: 1593824974
  timesteps_since_restore: 1500000
  timesteps_this_iter: 10000
  timesteps_total: 1500000
  training_iteration: 150
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2714 s, 150 iter, 1500000 ts, 244 rew

agent-1: 22.0
agent-2: 30.0
agent-3: 31.0
agent-4: 18.0
agent-5: 26.0
agent-6: 21.0
agent-7: 30.0
agent-8: 29.0
agent-9: 16.0
agent-10: 24.0
Sum Reward: 247.0
Avg Reward: 24.7
Min Reward: 16.0
Gini Coefficient 0.11619433198380567
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-09-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 325.0
  episode_reward_mean: 244.53
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 150
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.68
    dispatch_time_ms: 6.046
    learner:
      cur_lr: 0.0012601000489667058
      grad_gnorm: 1.287368893623352
      policy_entropy: 131.14891052246094
      policy_loss: -0.6692916750907898
      var_gnorm: 40.383544921875
      vf_explained_var: 0.5437872409820557
      vf_loss: 0.0009754486382007599
    num_steps_sampled: 1510000
    num_steps_trained: 1510000
    wait_time_ms: 164.901
  iterations_since_restore: 151
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2731.809806585312
  time_this_iter_s: 17.18385672569275
  time_total_s: 2731.809806585312
  timestamp: 1593824991
  timesteps_since_restore: 1510000
  timesteps_this_iter: 10000
  timesteps_total: 1510000
  training_iteration: 151
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2731 s, 151 iter, 1510000 ts, 245 rew

agent-1: 17.0
agent-2: 14.0
agent-3: 27.0
agent-4: 37.0
agent-5: 37.0
agent-6: 28.0
agent-7: 29.0
agent-8: 32.0
agent-9: 29.0
agent-10: 36.0
Sum Reward: 286.0
Avg Reward: 28.6
Min Reward: 14.0
Gini Coefficient 0.14125874125874127
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-10-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 325.0
  episode_reward_mean: 245.16
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 151
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.707
    dispatch_time_ms: 8.463
    learner:
      cur_lr: 0.001259434036910534
      grad_gnorm: 1.1193361282348633
      policy_entropy: 143.35267639160156
      policy_loss: -0.564750075340271
      var_gnorm: 40.354957580566406
      vf_explained_var: 0.0
      vf_loss: 0.0006979921017773449
    num_steps_sampled: 1520000
    num_steps_trained: 1520000
    wait_time_ms: 165.775
  iterations_since_restore: 152
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2749.1760778427124
  time_this_iter_s: 17.366271257400513
  time_total_s: 2749.1760778427124
  timestamp: 1593825008
  timesteps_since_restore: 1520000
  timesteps_this_iter: 10000
  timesteps_total: 1520000
  training_iteration: 152
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2749 s, 152 iter, 1520000 ts, 245 rew

agent-1: 38.0
agent-2: 18.0
agent-3: 22.0
agent-4: 29.0
agent-5: 22.0
agent-6: 18.0
agent-7: 14.0
agent-8: 28.0
agent-9: 16.0
agent-10: 19.0
Sum Reward: 224.0
Avg Reward: 22.4
Min Reward: 14.0
Gini Coefficient 0.16607142857142856
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-10-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 325.0
  episode_reward_mean: 244.46
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 152
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.695
    dispatch_time_ms: 5.897
    learner:
      cur_lr: 0.001258768024854362
      grad_gnorm: 1.3749017715454102
      policy_entropy: 128.20774841308594
      policy_loss: -0.006301946938037872
      var_gnorm: 40.532379150390625
      vf_explained_var: -1.0
      vf_loss: 0.004507972858846188
    num_steps_sampled: 1530000
    num_steps_trained: 1530000
    wait_time_ms: 166.849
  iterations_since_restore: 153
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2766.499103784561
  time_this_iter_s: 17.323025941848755
  time_total_s: 2766.499103784561
  timestamp: 1593825026
  timesteps_since_restore: 1530000
  timesteps_this_iter: 10000
  timesteps_total: 1530000
  training_iteration: 153
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2766 s, 153 iter, 1530000 ts, 244 rew

agent-1: 20.0
agent-2: 17.0
agent-3: 25.0
agent-4: 35.0
agent-5: 23.0
agent-6: 31.0
agent-7: 21.0
agent-8: 25.0
agent-9: 26.0
agent-10: 26.0
Sum Reward: 249.0
Avg Reward: 24.9
Min Reward: 17.0
Gini Coefficient 0.10963855421686747
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-10-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 325.0
  episode_reward_mean: 244.38
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 153
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.942
    dispatch_time_ms: 5.26
    learner:
      cur_lr: 0.0012581020127981901
      grad_gnorm: 2.794646978378296
      policy_entropy: 154.01617431640625
      policy_loss: -1.4212534427642822
      var_gnorm: 40.54138946533203
      vf_explained_var: 0.8259613513946533
      vf_loss: 0.004288776777684689
    num_steps_sampled: 1540000
    num_steps_trained: 1540000
    wait_time_ms: 167.233
  iterations_since_restore: 154
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2783.969797372818
  time_this_iter_s: 17.470693588256836
  time_total_s: 2783.969797372818
  timestamp: 1593825043
  timesteps_since_restore: 1540000
  timesteps_this_iter: 10000
  timesteps_total: 1540000
  training_iteration: 154
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2783 s, 154 iter, 1540000 ts, 244 rew

agent-1: 27.0
agent-2: 19.0
agent-3: 27.0
agent-4: 28.0
agent-5: 20.0
agent-6: 31.0
agent-7: 28.0
agent-8: 28.0
agent-9: 16.0
agent-10: 21.0
Sum Reward: 245.0
Avg Reward: 24.5
Min Reward: 16.0
Gini Coefficient 0.10571428571428572
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-11-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 325.0
  episode_reward_mean: 244.52
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 154
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.975
    dispatch_time_ms: 14.705
    learner:
      cur_lr: 0.0012574360007420182
      grad_gnorm: 23.092222213745117
      policy_entropy: 115.95736694335938
      policy_loss: 0.38103187084198
      var_gnorm: 40.83583450317383
      vf_explained_var: -1.0
      vf_loss: 0.5120778679847717
    num_steps_sampled: 1550000
    num_steps_trained: 1550000
    wait_time_ms: 164.259
  iterations_since_restore: 155
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2801.03888130188
  time_this_iter_s: 17.06908392906189
  time_total_s: 2801.03888130188
  timestamp: 1593825060
  timesteps_since_restore: 1550000
  timesteps_this_iter: 10000
  timesteps_total: 1550000
  training_iteration: 155
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2801 s, 155 iter, 1550000 ts, 245 rew

agent-1: 37.0
agent-2: 40.0
agent-3: 41.0
agent-4: 34.0
agent-5: 47.0
agent-6: 56.0
agent-7: 47.0
agent-8: 23.0
agent-9: 46.0
agent-10: 40.0
Sum Reward: 411.0
Avg Reward: 41.1
Min Reward: 23.0
Gini Coefficient 0.11119221411192214
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-11-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 246.2
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 155
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 4.347
    dispatch_time_ms: 31.207
    learner:
      cur_lr: 0.0012567699886858463
      grad_gnorm: 4.585255146026611
      policy_entropy: 152.30467224121094
      policy_loss: -0.09530608355998993
      var_gnorm: 40.85985565185547
      vf_explained_var: -1.0
      vf_loss: 0.2400980293750763
    num_steps_sampled: 1560000
    num_steps_trained: 1560000
    wait_time_ms: 158.521
  iterations_since_restore: 156
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2818.934527873993
  time_this_iter_s: 17.895646572113037
  time_total_s: 2818.934527873993
  timestamp: 1593825078
  timesteps_since_restore: 1560000
  timesteps_this_iter: 10000
  timesteps_total: 1560000
  training_iteration: 156
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2818 s, 156 iter, 1560000 ts, 246 rew

agent-1: 25.0
agent-2: 26.0
agent-3: 25.0
agent-4: 34.0
agent-5: 24.0
agent-6: 26.0
agent-7: 22.0
agent-8: 30.0
agent-9: 20.0
agent-10: 19.0
Sum Reward: 251.0
Avg Reward: 25.1
Min Reward: 19.0
Gini Coefficient 0.09203187250996016
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-11-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 246.45
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 156
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 5.48
    dispatch_time_ms: 32.414
    learner:
      cur_lr: 0.0012561039766296744
      grad_gnorm: 13.438226699829102
      policy_entropy: 111.9422836303711
      policy_loss: 2.7343835830688477
      var_gnorm: 40.91923522949219
      vf_explained_var: -0.07689261436462402
      vf_loss: 1.1101634502410889
    num_steps_sampled: 1570000
    num_steps_trained: 1570000
    wait_time_ms: 148.243
  iterations_since_restore: 157
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2835.6141855716705
  time_this_iter_s: 16.679657697677612
  time_total_s: 2835.6141855716705
  timestamp: 1593825098
  timesteps_since_restore: 1570000
  timesteps_this_iter: 10000
  timesteps_total: 1570000
  training_iteration: 157
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2835 s, 157 iter, 1570000 ts, 246 rew

agent-1: 20.0
agent-2: 21.0
agent-3: 33.0
agent-4: 35.0
agent-5: 25.0
agent-6: 13.0
agent-7: 26.0
agent-8: 38.0
agent-9: 24.0
agent-10: 32.0
Sum Reward: 267.0
Avg Reward: 26.7
Min Reward: 13.0
Gini Coefficient 0.15543071161048688
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-11-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 246.63
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 157
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.304
    dispatch_time_ms: 32.533
    learner:
      cur_lr: 0.0012554379645735025
      grad_gnorm: 6.7906365394592285
      policy_entropy: 127.23589324951172
      policy_loss: -0.5367751121520996
      var_gnorm: 40.93496322631836
      vf_explained_var: -0.44856369495391846
      vf_loss: 0.051975421607494354
    num_steps_sampled: 1580000
    num_steps_trained: 1580000
    wait_time_ms: 135.101
  iterations_since_restore: 158
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2853.9885668754578
  time_this_iter_s: 18.37438130378723
  time_total_s: 2853.9885668754578
  timestamp: 1593825116
  timesteps_since_restore: 1580000
  timesteps_this_iter: 10000
  timesteps_total: 1580000
  training_iteration: 158
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2853 s, 158 iter, 1580000 ts, 247 rew

agent-1: 33.0
agent-2: 30.0
agent-3: 24.0
agent-4: 34.0
agent-5: 32.0
agent-6: 25.0
agent-7: 12.0
agent-8: 42.0
agent-9: 25.0
agent-10: 21.0
Sum Reward: 278.0
Avg Reward: 27.8
Min Reward: 12.0
Gini Coefficient 0.1553956834532374
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-12-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 247.13
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 158
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.635
    dispatch_time_ms: 26.559
    learner:
      cur_lr: 0.0012547719525173306
      grad_gnorm: 4.613087177276611
      policy_entropy: 153.20069885253906
      policy_loss: 2.4310545921325684
      var_gnorm: 41.1016845703125
      vf_explained_var: -1.0
      vf_loss: 0.00352111435495317
    num_steps_sampled: 1590000
    num_steps_trained: 1590000
    wait_time_ms: 161.244
  iterations_since_restore: 159
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2872.0495023727417
  time_this_iter_s: 18.060935497283936
  time_total_s: 2872.0495023727417
  timestamp: 1593825134
  timesteps_since_restore: 1590000
  timesteps_this_iter: 10000
  timesteps_total: 1590000
  training_iteration: 159
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2872 s, 159 iter, 1590000 ts, 247 rew

agent-1: 19.0
agent-2: 30.0
agent-3: 27.0
agent-4: 37.0
agent-5: 31.0
agent-6: 20.0
agent-7: 19.0
agent-8: 12.0
agent-9: 29.0
agent-10: 25.0
Sum Reward: 249.0
Avg Reward: 24.9
Min Reward: 12.0
Gini Coefficient 0.1578313253012048
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-12-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 247.24
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 159
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.835
    dispatch_time_ms: 6.131
    learner:
      cur_lr: 0.0012541060568764806
      grad_gnorm: 40.0000114440918
      policy_entropy: 35.56425857543945
      policy_loss: 14.906338691711426
      var_gnorm: 41.08314895629883
      vf_explained_var: 0.7858619689941406
      vf_loss: 84.43829345703125
    num_steps_sampled: 1600000
    num_steps_trained: 1600000
    wait_time_ms: 153.278
  iterations_since_restore: 160
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2891.697742700577
  time_this_iter_s: 19.648240327835083
  time_total_s: 2891.697742700577
  timestamp: 1593825154
  timesteps_since_restore: 1600000
  timesteps_this_iter: 10000
  timesteps_total: 1600000
  training_iteration: 160
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2891 s, 160 iter, 1600000 ts, 247 rew

agent-1: 17.0
agent-2: 31.0
agent-3: 24.0
agent-4: 15.0
agent-5: 26.0
agent-6: 28.0
agent-7: 25.0
agent-8: 20.0
agent-9: 23.0
agent-10: 18.0
Sum Reward: 227.0
Avg Reward: 22.7
Min Reward: 15.0
Gini Coefficient 0.12202643171806167
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-12-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 246.26
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 160
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.861
    dispatch_time_ms: 5.948
    learner:
      cur_lr: 0.0012534400448203087
      grad_gnorm: 1.7511438131332397
      policy_entropy: 151.53231811523438
      policy_loss: 0.9750398993492126
      var_gnorm: 41.204952239990234
      vf_explained_var: -1.0
      vf_loss: 0.008180073462426662
    num_steps_sampled: 1610000
    num_steps_trained: 1610000
    wait_time_ms: 171.768
  iterations_since_restore: 161
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2909.0141999721527
  time_this_iter_s: 17.316457271575928
  time_total_s: 2909.0141999721527
  timestamp: 1593825172
  timesteps_since_restore: 1610000
  timesteps_this_iter: 10000
  timesteps_total: 1610000
  training_iteration: 161
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2909 s, 161 iter, 1610000 ts, 246 rew

agent-1: 22.0
agent-2: 17.0
agent-3: 25.0
agent-4: 20.0
agent-5: 25.0
agent-6: 35.0
agent-7: 21.0
agent-8: 22.0
agent-9: 27.0
agent-10: 25.0
Sum Reward: 239.0
Avg Reward: 23.9
Min Reward: 17.0
Gini Coefficient 0.10167364016736402
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-13-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 246.42
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 161
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.848
    dispatch_time_ms: 6.372
    learner:
      cur_lr: 0.0012527740327641368
      grad_gnorm: 2.9557971954345703
      policy_entropy: 151.9251708984375
      policy_loss: -1.2486189603805542
      var_gnorm: 41.18553924560547
      vf_explained_var: -1.0
      vf_loss: 0.009153209626674652
    num_steps_sampled: 1620000
    num_steps_trained: 1620000
    wait_time_ms: 167.942
  iterations_since_restore: 162
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2926.3829181194305
  time_this_iter_s: 17.368718147277832
  time_total_s: 2926.3829181194305
  timestamp: 1593825189
  timesteps_since_restore: 1620000
  timesteps_this_iter: 10000
  timesteps_total: 1620000
  training_iteration: 162
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2926 s, 162 iter, 1620000 ts, 246 rew

agent-1: 24.0
agent-2: 31.0
agent-3: 26.0
agent-4: 23.0
agent-5: 18.0
agent-6: 18.0
agent-7: 27.0
agent-8: 17.0
agent-9: 22.0
agent-10: 36.0
Sum Reward: 242.0
Avg Reward: 24.2
Min Reward: 17.0
Gini Coefficient 0.1322314049586777
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-13-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 246.39
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 162
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 4.069
    dispatch_time_ms: 7.261
    learner:
      cur_lr: 0.001252108020707965
      grad_gnorm: 0.6415531039237976
      policy_entropy: 146.62583923339844
      policy_loss: -0.1575840562582016
      var_gnorm: 41.357330322265625
      vf_explained_var: -1.0
      vf_loss: 0.001244066283106804
    num_steps_sampled: 1630000
    num_steps_trained: 1630000
    wait_time_ms: 169.375
  iterations_since_restore: 163
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2943.763120651245
  time_this_iter_s: 17.380202531814575
  time_total_s: 2943.763120651245
  timestamp: 1593825206
  timesteps_since_restore: 1630000
  timesteps_this_iter: 10000
  timesteps_total: 1630000
  training_iteration: 163
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2943 s, 163 iter, 1630000 ts, 246 rew

agent-1: 22.0
agent-2: 29.0
agent-3: 21.0
agent-4: 32.0
agent-5: 25.0
agent-6: 18.0
agent-7: 41.0
agent-8: 24.0
agent-9: 28.0
agent-10: 27.0
Sum Reward: 267.0
Avg Reward: 26.7
Min Reward: 18.0
Gini Coefficient 0.12471910112359551
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-13-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 246.73
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 163
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.912
    dispatch_time_ms: 6.131
    learner:
      cur_lr: 0.001251442008651793
      grad_gnorm: 40.0000114440918
      policy_entropy: 65.8133316040039
      policy_loss: -2.2916674613952637
      var_gnorm: 41.371299743652344
      vf_explained_var: 0.5801351070404053
      vf_loss: 15.772268295288086
    num_steps_sampled: 1640000
    num_steps_trained: 1640000
    wait_time_ms: 159.045
  iterations_since_restore: 164
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2961.081390619278
  time_this_iter_s: 17.318269968032837
  time_total_s: 2961.081390619278
  timestamp: 1593825224
  timesteps_since_restore: 1640000
  timesteps_this_iter: 10000
  timesteps_total: 1640000
  training_iteration: 164
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2961 s, 164 iter, 1640000 ts, 247 rew

agent-1: 24.0
agent-2: 20.0
agent-3: 24.0
agent-4: 19.0
agent-5: 30.0
agent-6: 22.0
agent-7: 24.0
agent-8: 17.0
agent-9: 23.0
agent-10: 24.0
Sum Reward: 227.0
Avg Reward: 22.7
Min Reward: 17.0
Gini Coefficient 0.07885462555066079
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-14-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 246.81
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 164
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.822
    dispatch_time_ms: 6.586
    learner:
      cur_lr: 0.0012507759965956211
      grad_gnorm: 0.42057710886001587
      policy_entropy: 148.69613647460938
      policy_loss: -0.13319054245948792
      var_gnorm: 41.45331954956055
      vf_explained_var: -1.0
      vf_loss: 0.000419857184169814
    num_steps_sampled: 1650000
    num_steps_trained: 1650000
    wait_time_ms: 168.045
  iterations_since_restore: 165
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2978.5736725330353
  time_this_iter_s: 17.492281913757324
  time_total_s: 2978.5736725330353
  timestamp: 1593825241
  timesteps_since_restore: 1650000
  timesteps_this_iter: 10000
  timesteps_total: 1650000
  training_iteration: 165
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2978 s, 165 iter, 1650000 ts, 247 rew

agent-1: 34.0
agent-2: 21.0
agent-3: 32.0
agent-4: 24.0
agent-5: 15.0
agent-6: 28.0
agent-7: 26.0
agent-8: 20.0
agent-9: 16.0
agent-10: 31.0
Sum Reward: 247.0
Avg Reward: 24.7
Min Reward: 15.0
Gini Coefficient 0.14615384615384616
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-14-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 247.13
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 165
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.502
    dispatch_time_ms: 7.067
    learner:
      cur_lr: 0.0012501099845394492
      grad_gnorm: 40.0
      policy_entropy: 65.18009948730469
      policy_loss: 1.4130915403366089
      var_gnorm: 41.44798278808594
      vf_explained_var: 0.865412712097168
      vf_loss: 37.56794357299805
    num_steps_sampled: 1660000
    num_steps_trained: 1660000
    wait_time_ms: 161.46
  iterations_since_restore: 166
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 2995.9026639461517
  time_this_iter_s: 17.328991413116455
  time_total_s: 2995.9026639461517
  timestamp: 1593825259
  timesteps_since_restore: 1660000
  timesteps_this_iter: 10000
  timesteps_total: 1660000
  training_iteration: 166
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 2995 s, 166 iter, 1660000 ts, 247 rew

agent-1: 25.0
agent-2: 17.0
agent-3: 21.0
agent-4: 20.0
agent-5: 17.0
agent-6: 36.0
agent-7: 30.0
agent-8: 23.0
agent-9: 13.0
agent-10: 23.0
Sum Reward: 225.0
Avg Reward: 22.5
Min Reward: 13.0
Gini Coefficient 0.15511111111111112
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-14-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 246.97
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 166
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.545
    dispatch_time_ms: 7.141
    learner:
      cur_lr: 0.0012494439724832773
      grad_gnorm: 11.313653945922852
      policy_entropy: 54.696598052978516
      policy_loss: -0.30378589034080505
      var_gnorm: 41.447940826416016
      vf_explained_var: -1.0
      vf_loss: 0.11904573440551758
    num_steps_sampled: 1670000
    num_steps_trained: 1670000
    wait_time_ms: 166.289
  iterations_since_restore: 167
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3013.2768228054047
  time_this_iter_s: 17.37415885925293
  time_total_s: 3013.2768228054047
  timestamp: 1593825276
  timesteps_since_restore: 1670000
  timesteps_this_iter: 10000
  timesteps_total: 1670000
  training_iteration: 167
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3013 s, 167 iter, 1670000 ts, 247 rew

agent-1: 43.0
agent-2: 38.0
agent-3: 28.0
agent-4: 33.0
agent-5: 23.0
agent-6: 11.0
agent-7: 30.0
agent-8: 16.0
agent-9: 32.0
agent-10: 22.0
Sum Reward: 276.0
Avg Reward: 27.6
Min Reward: 11.0
Gini Coefficient 0.19057971014492753
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-14-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 247.36
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 167
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.867
    dispatch_time_ms: 5.895
    learner:
      cur_lr: 0.0012487779604271054
      grad_gnorm: 1.4664390087127686
      policy_entropy: 82.1529769897461
      policy_loss: -0.27984490990638733
      var_gnorm: 41.47163772583008
      vf_explained_var: -0.5332188606262207
      vf_loss: 0.0013098525814712048
    num_steps_sampled: 1680000
    num_steps_trained: 1680000
    wait_time_ms: 166.071
  iterations_since_restore: 168
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3030.743730068207
  time_this_iter_s: 17.466907262802124
  time_total_s: 3030.743730068207
  timestamp: 1593825294
  timesteps_since_restore: 1680000
  timesteps_this_iter: 10000
  timesteps_total: 1680000
  training_iteration: 168
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3030 s, 168 iter, 1680000 ts, 247 rew

agent-1: 14.0
agent-2: 18.0
agent-3: 22.0
agent-4: 33.0
agent-5: 27.0
agent-6: 25.0
agent-7: 33.0
agent-8: 27.0
agent-9: 25.0
agent-10: 21.0
Sum Reward: 245.0
Avg Reward: 24.5
Min Reward: 14.0
Gini Coefficient 0.1310204081632653
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-15-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 247.23
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 168
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.191
    dispatch_time_ms: 6.989
    learner:
      cur_lr: 0.0012481119483709335
      grad_gnorm: 1.0512768030166626
      policy_entropy: 65.59868621826172
      policy_loss: 0.17084497213363647
      var_gnorm: 41.654808044433594
      vf_explained_var: -1.0
      vf_loss: 0.006567940581589937
    num_steps_sampled: 1690000
    num_steps_trained: 1690000
    wait_time_ms: 167.729
  iterations_since_restore: 169
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3047.981069803238
  time_this_iter_s: 17.237339735031128
  time_total_s: 3047.981069803238
  timestamp: 1593825311
  timesteps_since_restore: 1690000
  timesteps_this_iter: 10000
  timesteps_total: 1690000
  training_iteration: 169
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3047 s, 169 iter, 1690000 ts, 247 rew

agent-1: 26.0
agent-2: 25.0
agent-3: 23.0
agent-4: 19.0
agent-5: 18.0
agent-6: 21.0
agent-7: 29.0
agent-8: 12.0
agent-9: 20.0
agent-10: 24.0
Sum Reward: 217.0
Avg Reward: 21.7
Min Reward: 12.0
Gini Coefficient 0.11658986175115207
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-15-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 247.14
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 169
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.042
    dispatch_time_ms: 5.766
    learner:
      cur_lr: 0.0012474460527300835
      grad_gnorm: 0.5376386046409607
      policy_entropy: 115.16852569580078
      policy_loss: -0.07841269671916962
      var_gnorm: 41.669395446777344
      vf_explained_var: -1.0
      vf_loss: 0.0028873314149677753
    num_steps_sampled: 1700000
    num_steps_trained: 1700000
    wait_time_ms: 155.024
  iterations_since_restore: 170
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3065.4423730373383
  time_this_iter_s: 17.461303234100342
  time_total_s: 3065.4423730373383
  timestamp: 1593825328
  timesteps_since_restore: 1700000
  timesteps_this_iter: 10000
  timesteps_total: 1700000
  training_iteration: 170
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3065 s, 170 iter, 1700000 ts, 247 rew

agent-1: 28.0
agent-2: 36.0
agent-3: 29.0
agent-4: 16.0
agent-5: 22.0
agent-6: 20.0
agent-7: 22.0
agent-8: 25.0
agent-9: 26.0
agent-10: 28.0
Sum Reward: 252.0
Avg Reward: 25.2
Min Reward: 16.0
Gini Coefficient 0.11587301587301588
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-15-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 247.32
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 170
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 4.013
    dispatch_time_ms: 7.207
    learner:
      cur_lr: 0.0012467800406739116
      grad_gnorm: 39.99999237060547
      policy_entropy: 120.68202209472656
      policy_loss: 13.176076889038086
      var_gnorm: 42.02067565917969
      vf_explained_var: -1.0
      vf_loss: 16.41587257385254
    num_steps_sampled: 1710000
    num_steps_trained: 1710000
    wait_time_ms: 166.828
  iterations_since_restore: 171
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3082.375495195389
  time_this_iter_s: 16.933122158050537
  time_total_s: 3082.375495195389
  timestamp: 1593825345
  timesteps_since_restore: 1710000
  timesteps_this_iter: 10000
  timesteps_total: 1710000
  training_iteration: 171
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3082 s, 171 iter, 1710000 ts, 247 rew

agent-1: 38.0
agent-2: 42.0
agent-3: 37.0
agent-4: 29.0
agent-5: 39.0
agent-6: 31.0
agent-7: 44.0
agent-8: 23.0
agent-9: 50.0
agent-10: 42.0
Sum Reward: 375.0
Avg Reward: 37.5
Min Reward: 23.0
Gini Coefficient 0.11173333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-16-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 248.73
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 171
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.479
    dispatch_time_ms: 7.555
    learner:
      cur_lr: 0.0012461140286177397
      grad_gnorm: 1.4077435731887817
      policy_entropy: 149.3630828857422
      policy_loss: -0.5295571684837341
      var_gnorm: 42.09686279296875
      vf_explained_var: 0.0024213194847106934
      vf_loss: 0.0011568620102480054
    num_steps_sampled: 1720000
    num_steps_trained: 1720000
    wait_time_ms: 169.418
  iterations_since_restore: 172
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3099.7541613578796
  time_this_iter_s: 17.378666162490845
  time_total_s: 3099.7541613578796
  timestamp: 1593825363
  timesteps_since_restore: 1720000
  timesteps_this_iter: 10000
  timesteps_total: 1720000
  training_iteration: 172
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3099 s, 172 iter, 1720000 ts, 249 rew

agent-1: 29.0
agent-2: 34.0
agent-3: 36.0
agent-4: 38.0
agent-5: 40.0
agent-6: 22.0
agent-7: 43.0
agent-8: 32.0
agent-9: 42.0
agent-10: 36.0
Sum Reward: 352.0
Avg Reward: 35.2
Min Reward: 22.0
Gini Coefficient 0.09431818181818181
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-16-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 250.13
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 172
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.324
    dispatch_time_ms: 7.026
    learner:
      cur_lr: 0.0012454480165615678
      grad_gnorm: 2.1308839321136475
      policy_entropy: 119.80487060546875
      policy_loss: -0.3017452657222748
      var_gnorm: 42.1667366027832
      vf_explained_var: 0.7236459255218506
      vf_loss: 0.03098900243639946
    num_steps_sampled: 1730000
    num_steps_trained: 1730000
    wait_time_ms: 168.769
  iterations_since_restore: 173
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3117.027510404587
  time_this_iter_s: 17.273349046707153
  time_total_s: 3117.027510404587
  timestamp: 1593825380
  timesteps_since_restore: 1730000
  timesteps_this_iter: 10000
  timesteps_total: 1730000
  training_iteration: 173
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3117 s, 173 iter, 1730000 ts, 250 rew

agent-1: 16.0
agent-2: 23.0
agent-3: 22.0
agent-4: 45.0
agent-5: 52.0
agent-6: 25.0
agent-7: -11.0
agent-8: 29.0
agent-9: 30.0
agent-10: 26.0
Sum Reward: 257.0
Avg Reward: 25.7
Min Reward: -11.0
Gini Coefficient 0.322568093385214
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-16-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 249.63
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 173
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 4.252
    dispatch_time_ms: 5.974
    learner:
      cur_lr: 0.0012447820045053959
      grad_gnorm: 1.8810006380081177
      policy_entropy: 119.80436706542969
      policy_loss: -0.7963485717773438
      var_gnorm: 42.15439987182617
      vf_explained_var: 0.005428671836853027
      vf_loss: 0.0030082943849265575
    num_steps_sampled: 1740000
    num_steps_trained: 1740000
    wait_time_ms: 167.609
  iterations_since_restore: 174
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3134.4745960235596
  time_this_iter_s: 17.44708561897278
  time_total_s: 3134.4745960235596
  timestamp: 1593825398
  timesteps_since_restore: 1740000
  timesteps_this_iter: 10000
  timesteps_total: 1740000
  training_iteration: 174
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3134 s, 174 iter, 1740000 ts, 250 rew

agent-1: 21.0
agent-2: 31.0
agent-3: 27.0
agent-4: 33.0
agent-5: 29.0
agent-6: 17.0
agent-7: 39.0
agent-8: 29.0
agent-9: 26.0
agent-10: 30.0
Sum Reward: 282.0
Avg Reward: 28.2
Min Reward: 17.0
Gini Coefficient 0.11205673758865248
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-16-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 250.21
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 174
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.01
    dispatch_time_ms: 6.894
    learner:
      cur_lr: 0.001244115992449224
      grad_gnorm: 0.390858918428421
      policy_entropy: 144.9237060546875
      policy_loss: -0.2148394137620926
      var_gnorm: 42.313716888427734
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.006266250740736723
    num_steps_sampled: 1750000
    num_steps_trained: 1750000
    wait_time_ms: 167.352
  iterations_since_restore: 175
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3151.8669514656067
  time_this_iter_s: 17.39235544204712
  time_total_s: 3151.8669514656067
  timestamp: 1593825415
  timesteps_since_restore: 1750000
  timesteps_this_iter: 10000
  timesteps_total: 1750000
  training_iteration: 175
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3151 s, 175 iter, 1750000 ts, 250 rew

agent-1: 25.0
agent-2: 29.0
agent-3: 32.0
agent-4: 26.0
agent-5: 34.0
agent-6: 23.0
agent-7: 18.0
agent-8: 27.0
agent-9: 26.0
agent-10: 29.0
Sum Reward: 269.0
Avg Reward: 26.9
Min Reward: 18.0
Gini Coefficient 0.08810408921933086
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-17-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 250.01
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 175
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.902
    dispatch_time_ms: 6.22
    learner:
      cur_lr: 0.001243449980393052
      grad_gnorm: 2.946899652481079
      policy_entropy: 161.4367218017578
      policy_loss: -1.4092532396316528
      var_gnorm: 42.329158782958984
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.005176081322133541
    num_steps_sampled: 1760000
    num_steps_trained: 1760000
    wait_time_ms: 173.502
  iterations_since_restore: 176
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3169.2506272792816
  time_this_iter_s: 17.383675813674927
  time_total_s: 3169.2506272792816
  timestamp: 1593825432
  timesteps_since_restore: 1760000
  timesteps_this_iter: 10000
  timesteps_total: 1760000
  training_iteration: 176
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3169 s, 176 iter, 1760000 ts, 250 rew

agent-1: 18.0
agent-2: 28.0
agent-3: 20.0
agent-4: 31.0
agent-5: 22.0
agent-6: 29.0
agent-7: 28.0
agent-8: 21.0
agent-9: 27.0
agent-10: 27.0
Sum Reward: 251.0
Avg Reward: 25.1
Min Reward: 18.0
Gini Coefficient 0.09282868525896415
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-17-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 250.18
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 176
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.685
    dispatch_time_ms: 5.427
    learner:
      cur_lr: 0.0012427839683368802
      grad_gnorm: 0.4894779920578003
      policy_entropy: 166.1793975830078
      policy_loss: -0.1194530725479126
      var_gnorm: 42.42185974121094
      vf_explained_var: -1.0
      vf_loss: 0.001766919856891036
    num_steps_sampled: 1770000
    num_steps_trained: 1770000
    wait_time_ms: 170.064
  iterations_since_restore: 177
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3186.820214509964
  time_this_iter_s: 17.569587230682373
  time_total_s: 3186.820214509964
  timestamp: 1593825450
  timesteps_since_restore: 1770000
  timesteps_this_iter: 10000
  timesteps_total: 1770000
  training_iteration: 177
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3186 s, 177 iter, 1770000 ts, 250 rew

agent-1: 29.0
agent-2: 25.0
agent-3: 31.0
agent-4: 25.0
agent-5: 18.0
agent-6: 23.0
agent-7: 34.0
agent-8: 20.0
agent-9: 30.0
agent-10: 24.0
Sum Reward: 259.0
Avg Reward: 25.9
Min Reward: 18.0
Gini Coefficient 0.10463320463320464
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-17-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 250.5
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 177
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.803
    dispatch_time_ms: 6.359
    learner:
      cur_lr: 0.0012421179562807083
      grad_gnorm: 40.0
      policy_entropy: 61.85489273071289
      policy_loss: 17.93096923828125
      var_gnorm: 42.40900802612305
      vf_explained_var: 0.8017019033432007
      vf_loss: 146.75111389160156
    num_steps_sampled: 1780000
    num_steps_trained: 1780000
    wait_time_ms: 159.738
  iterations_since_restore: 178
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3204.202138900757
  time_this_iter_s: 17.381924390792847
  time_total_s: 3204.202138900757
  timestamp: 1593825467
  timesteps_since_restore: 1780000
  timesteps_this_iter: 10000
  timesteps_total: 1780000
  training_iteration: 178
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3204 s, 178 iter, 1780000 ts, 250 rew

agent-1: 25.0
agent-2: 18.0
agent-3: 24.0
agent-4: 29.0
agent-5: 22.0
agent-6: 26.0
agent-7: 27.0
agent-8: 26.0
agent-9: 20.0
agent-10: 30.0
Sum Reward: 247.0
Avg Reward: 24.7
Min Reward: 18.0
Gini Coefficient 0.08218623481781377
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-18-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 250.53
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 178
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.785
    dispatch_time_ms: 8.652
    learner:
      cur_lr: 0.0012414519442245364
      grad_gnorm: 3.226794481277466
      policy_entropy: 158.7037353515625
      policy_loss: 1.2680119276046753
      var_gnorm: 42.6064453125
      vf_explained_var: 0.7470914125442505
      vf_loss: 0.012450565584003925
    num_steps_sampled: 1790000
    num_steps_trained: 1790000
    wait_time_ms: 171.227
  iterations_since_restore: 179
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3221.504857778549
  time_this_iter_s: 17.30271887779236
  time_total_s: 3221.504857778549
  timestamp: 1593825485
  timesteps_since_restore: 1790000
  timesteps_this_iter: 10000
  timesteps_total: 1790000
  training_iteration: 179
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3221 s, 179 iter, 1790000 ts, 251 rew

agent-1: 29.0
agent-2: 35.0
agent-3: 19.0
agent-4: 20.0
agent-5: 31.0
agent-6: 18.0
agent-7: 25.0
agent-8: 23.0
agent-9: 43.0
agent-10: 38.0
Sum Reward: 281.0
Avg Reward: 28.1
Min Reward: 18.0
Gini Coefficient 0.16405693950177935
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-18-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 250.89
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 179
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.88
    dispatch_time_ms: 7.927
    learner:
      cur_lr: 0.0012407860485836864
      grad_gnorm: 40.000003814697266
      policy_entropy: 51.058685302734375
      policy_loss: 17.54741859436035
      var_gnorm: 42.60182571411133
      vf_explained_var: 0.8060706853866577
      vf_loss: 76.74211120605469
    num_steps_sampled: 1800000
    num_steps_trained: 1800000
    wait_time_ms: 158.168
  iterations_since_restore: 180
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3238.8075280189514
  time_this_iter_s: 17.30267024040222
  time_total_s: 3238.8075280189514
  timestamp: 1593825502
  timesteps_since_restore: 1800000
  timesteps_this_iter: 10000
  timesteps_total: 1800000
  training_iteration: 180
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3238 s, 180 iter, 1800000 ts, 251 rew

agent-1: 25.0
agent-2: 12.0
agent-3: 36.0
agent-4: 36.0
agent-5: 26.0
agent-6: 26.0
agent-7: 25.0
agent-8: 46.0
agent-9: 33.0
agent-10: 32.0
Sum Reward: 297.0
Avg Reward: 29.7
Min Reward: 12.0
Gini Coefficient 0.15656565656565657
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-18-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 251.38
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 180
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.843
    dispatch_time_ms: 6.667
    learner:
      cur_lr: 0.0012401200365275145
      grad_gnorm: 13.091915130615234
      policy_entropy: 164.7608642578125
      policy_loss: 5.782932281494141
      var_gnorm: 42.826385498046875
      vf_explained_var: 0.004812359809875488
      vf_loss: 1.4929691553115845
    num_steps_sampled: 1810000
    num_steps_trained: 1810000
    wait_time_ms: 161.791
  iterations_since_restore: 181
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3256.089715719223
  time_this_iter_s: 17.282187700271606
  time_total_s: 3256.089715719223
  timestamp: 1593825519
  timesteps_since_restore: 1810000
  timesteps_this_iter: 10000
  timesteps_total: 1810000
  training_iteration: 181
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3256 s, 181 iter, 1810000 ts, 251 rew

agent-1: 29.0
agent-2: 23.0
agent-3: 29.0
agent-4: 29.0
agent-5: 23.0
agent-6: 23.0
agent-7: 35.0
agent-8: 27.0
agent-9: 31.0
agent-10: 26.0
Sum Reward: 275.0
Avg Reward: 27.5
Min Reward: 23.0
Gini Coefficient 0.07454545454545454
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-19-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 251.94
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 181
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.799
    dispatch_time_ms: 7.663
    learner:
      cur_lr: 0.0012394540244713426
      grad_gnorm: 40.0
      policy_entropy: 40.25007247924805
      policy_loss: -10.123682022094727
      var_gnorm: 42.8735237121582
      vf_explained_var: 0.8488086462020874
      vf_loss: 24.411258697509766
    num_steps_sampled: 1820000
    num_steps_trained: 1820000
    wait_time_ms: 155.255
  iterations_since_restore: 182
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3289.262157678604
  time_this_iter_s: 33.1724419593811
  time_total_s: 3289.262157678604
  timestamp: 1593825553
  timesteps_since_restore: 1820000
  timesteps_this_iter: 10000
  timesteps_total: 1820000
  training_iteration: 182
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3289 s, 182 iter, 1820000 ts, 252 rew

agent-1: 32.0
agent-2: 26.0
agent-3: 24.0
agent-4: 15.0
agent-5: 27.0
agent-6: 22.0
agent-7: 31.0
agent-8: 26.0
agent-9: 31.0
agent-10: 30.0
Sum Reward: 264.0
Avg Reward: 26.4
Min Reward: 15.0
Gini Coefficient 0.1
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-19-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 252.18
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 182
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.354
    dispatch_time_ms: 7.377
    learner:
      cur_lr: 0.0012387880124151707
      grad_gnorm: 40.0
      policy_entropy: 108.36811065673828
      policy_loss: 12.512755393981934
      var_gnorm: 43.05674362182617
      vf_explained_var: 0.24842751026153564
      vf_loss: 4.349074363708496
    num_steps_sampled: 1830000
    num_steps_trained: 1830000
    wait_time_ms: 170.076
  iterations_since_restore: 183
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3306.693448781967
  time_this_iter_s: 17.431291103363037
  time_total_s: 3306.693448781967
  timestamp: 1593825570
  timesteps_since_restore: 1830000
  timesteps_this_iter: 10000
  timesteps_total: 1830000
  training_iteration: 183
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3306 s, 183 iter, 1830000 ts, 252 rew

agent-1: 36.0
agent-2: 15.0
agent-3: 25.0
agent-4: 33.0
agent-5: 23.0
agent-6: 32.0
agent-7: 28.0
agent-8: 16.0
agent-9: 21.0
agent-10: 35.0
Sum Reward: 264.0
Avg Reward: 26.4
Min Reward: 15.0
Gini Coefficient 0.15606060606060607
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-19-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 252.32
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 183
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.27
    dispatch_time_ms: 7.749
    learner:
      cur_lr: 0.0012381220003589988
      grad_gnorm: 23.10281753540039
      policy_entropy: 57.06853485107422
      policy_loss: 3.9821996688842773
      var_gnorm: 43.10742950439453
      vf_explained_var: 0.4214673638343811
      vf_loss: 7.114741802215576
    num_steps_sampled: 1840000
    num_steps_trained: 1840000
    wait_time_ms: 163.408
  iterations_since_restore: 184
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3324.155807495117
  time_this_iter_s: 17.462358713150024
  time_total_s: 3324.155807495117
  timestamp: 1593825588
  timesteps_since_restore: 1840000
  timesteps_this_iter: 10000
  timesteps_total: 1840000
  training_iteration: 184
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3324 s, 184 iter, 1840000 ts, 252 rew

agent-1: 24.0
agent-2: 31.0
agent-3: 37.0
agent-4: 24.0
agent-5: 24.0
agent-6: 32.0
agent-7: 40.0
agent-8: 21.0
agent-9: 21.0
agent-10: 17.0
Sum Reward: 271.0
Avg Reward: 27.1
Min Reward: 17.0
Gini Coefficient 0.14575645756457564
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-20-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 252.47
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 184
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.535
    dispatch_time_ms: 5.722
    learner:
      cur_lr: 0.0012374559883028269
      grad_gnorm: 15.721752166748047
      policy_entropy: 137.04962158203125
      policy_loss: -7.259688854217529
      var_gnorm: 43.186805725097656
      vf_explained_var: 0.8907413482666016
      vf_loss: 0.5738531351089478
    num_steps_sampled: 1850000
    num_steps_trained: 1850000
    wait_time_ms: 166.688
  iterations_since_restore: 185
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3341.3800683021545
  time_this_iter_s: 17.224260807037354
  time_total_s: 3341.3800683021545
  timestamp: 1593825605
  timesteps_since_restore: 1850000
  timesteps_this_iter: 10000
  timesteps_total: 1850000
  training_iteration: 185
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3341 s, 185 iter, 1850000 ts, 252 rew

agent-1: 25.0
agent-2: 22.0
agent-3: 19.0
agent-4: 32.0
agent-5: 19.0
agent-6: 30.0
agent-7: 31.0
agent-8: 24.0
agent-9: 18.0
agent-10: 20.0
Sum Reward: 240.0
Avg Reward: 24.0
Min Reward: 18.0
Gini Coefficient 0.1175
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-20-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 252.79
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 185
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.908
    dispatch_time_ms: 6.842
    learner:
      cur_lr: 0.001236789976246655
      grad_gnorm: 40.000003814697266
      policy_entropy: 54.103355407714844
      policy_loss: -12.911104202270508
      var_gnorm: 43.21250534057617
      vf_explained_var: 0.7364101409912109
      vf_loss: 44.629085540771484
    num_steps_sampled: 1860000
    num_steps_trained: 1860000
    wait_time_ms: 160.369
  iterations_since_restore: 186
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3358.7678554058075
  time_this_iter_s: 17.387787103652954
  time_total_s: 3358.7678554058075
  timestamp: 1593825622
  timesteps_since_restore: 1860000
  timesteps_this_iter: 10000
  timesteps_total: 1860000
  training_iteration: 186
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3358 s, 186 iter, 1860000 ts, 253 rew

agent-1: 27.0
agent-2: 35.0
agent-3: 33.0
agent-4: 34.0
agent-5: 28.0
agent-6: 38.0
agent-7: 37.0
agent-8: 32.0
agent-9: 18.0
agent-10: 27.0
Sum Reward: 309.0
Avg Reward: 30.9
Min Reward: 18.0
Gini Coefficient 0.1
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-20-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 253.43
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 186
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.813
    dispatch_time_ms: 6.91
    learner:
      cur_lr: 0.001236123964190483
      grad_gnorm: 29.5791072845459
      policy_entropy: 148.00013732910156
      policy_loss: -14.474032402038574
      var_gnorm: 43.402252197265625
      vf_explained_var: -0.1749405860900879
      vf_loss: 2.595841884613037
    num_steps_sampled: 1870000
    num_steps_trained: 1870000
    wait_time_ms: 166.911
  iterations_since_restore: 187
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3375.6200029850006
  time_this_iter_s: 16.852147579193115
  time_total_s: 3375.6200029850006
  timestamp: 1593825639
  timesteps_since_restore: 1870000
  timesteps_this_iter: 10000
  timesteps_total: 1870000
  training_iteration: 187
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3375 s, 187 iter, 1870000 ts, 253 rew

agent-1: 35.0
agent-2: 42.0
agent-3: 35.0
agent-4: 22.0
agent-5: 37.0
agent-6: 34.0
agent-7: 48.0
agent-8: 51.0
agent-9: 41.0
agent-10: 30.0
Sum Reward: 375.0
Avg Reward: 37.5
Min Reward: 22.0
Gini Coefficient 0.1192
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-20-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 254.74
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 187
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.851
    dispatch_time_ms: 8.533
    learner:
      cur_lr: 0.0012354579521343112
      grad_gnorm: 40.0
      policy_entropy: 63.35508346557617
      policy_loss: 7.426045894622803
      var_gnorm: 43.449581146240234
      vf_explained_var: 0.6739394664764404
      vf_loss: 41.42103576660156
    num_steps_sampled: 1880000
    num_steps_trained: 1880000
    wait_time_ms: 151.684
  iterations_since_restore: 188
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3392.9883682727814
  time_this_iter_s: 17.36836528778076
  time_total_s: 3392.9883682727814
  timestamp: 1593825657
  timesteps_since_restore: 1880000
  timesteps_this_iter: 10000
  timesteps_total: 1880000
  training_iteration: 188
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3392 s, 188 iter, 1880000 ts, 255 rew

agent-1: 29.0
agent-2: 31.0
agent-3: 45.0
agent-4: 39.0
agent-5: 39.0
agent-6: 33.0
agent-7: 21.0
agent-8: 19.0
agent-9: 25.0
agent-10: 49.0
Sum Reward: 330.0
Avg Reward: 33.0
Min Reward: 19.0
Gini Coefficient 0.16363636363636364
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-21-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 255.7
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 188
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.374
    dispatch_time_ms: 6.882
    learner:
      cur_lr: 0.0012347920564934611
      grad_gnorm: 1.701206922531128
      policy_entropy: 129.75978088378906
      policy_loss: -0.8951671123504639
      var_gnorm: 43.551761627197266
      vf_explained_var: 0.987966001033783
      vf_loss: 0.011464802548289299
    num_steps_sampled: 1890000
    num_steps_trained: 1890000
    wait_time_ms: 166.417
  iterations_since_restore: 189
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3410.397643327713
  time_this_iter_s: 17.40927505493164
  time_total_s: 3410.397643327713
  timestamp: 1593825674
  timesteps_since_restore: 1890000
  timesteps_this_iter: 10000
  timesteps_total: 1890000
  training_iteration: 189
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3410 s, 189 iter, 1890000 ts, 256 rew

agent-1: 31.0
agent-2: 27.0
agent-3: 39.0
agent-4: 27.0
agent-5: 26.0
agent-6: 15.0
agent-7: 30.0
agent-8: 39.0
agent-9: 35.0
agent-10: 31.0
Sum Reward: 300.0
Avg Reward: 30.0
Min Reward: 15.0
Gini Coefficient 0.12
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-21-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 255.64
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 189
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 4.225
    dispatch_time_ms: 6.619
    learner:
      cur_lr: 0.0012341260444372892
      grad_gnorm: 2.4086642265319824
      policy_entropy: 139.60723876953125
      policy_loss: -1.2730035781860352
      var_gnorm: 43.562042236328125
      vf_explained_var: 0.9714314341545105
      vf_loss: 0.02470635250210762
    num_steps_sampled: 1900000
    num_steps_trained: 1900000
    wait_time_ms: 164.329
  iterations_since_restore: 190
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3427.7498726844788
  time_this_iter_s: 17.352229356765747
  time_total_s: 3427.7498726844788
  timestamp: 1593825691
  timesteps_since_restore: 1900000
  timesteps_this_iter: 10000
  timesteps_total: 1900000
  training_iteration: 190
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3427 s, 190 iter, 1900000 ts, 256 rew

agent-1: 25.0
agent-2: 20.0
agent-3: 30.0
agent-4: 33.0
agent-5: 28.0
agent-6: 27.0
agent-7: 31.0
agent-8: 19.0
agent-9: 21.0
agent-10: 14.0
Sum Reward: 248.0
Avg Reward: 24.8
Min Reward: 14.0
Gini Coefficient 0.13225806451612904
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-21-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 255.65
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 190
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.905
    dispatch_time_ms: 5.895
    learner:
      cur_lr: 0.0012334600323811173
      grad_gnorm: 1.354952096939087
      policy_entropy: 138.73379516601562
      policy_loss: 0.3642823100090027
      var_gnorm: 43.63344955444336
      vf_explained_var: -1.0
      vf_loss: 0.001656110631301999
    num_steps_sampled: 1910000
    num_steps_trained: 1910000
    wait_time_ms: 166.949
  iterations_since_restore: 191
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3445.183661222458
  time_this_iter_s: 17.433788537979126
  time_total_s: 3445.183661222458
  timestamp: 1593825709
  timesteps_since_restore: 1910000
  timesteps_this_iter: 10000
  timesteps_total: 1910000
  training_iteration: 191
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3445 s, 191 iter, 1910000 ts, 256 rew

agent-1: 27.0
agent-2: 34.0
agent-3: 29.0
agent-4: 36.0
agent-5: 21.0
agent-6: 28.0
agent-7: 32.0
agent-8: 29.0
agent-9: 21.0
agent-10: 31.0
Sum Reward: 288.0
Avg Reward: 28.8
Min Reward: 21.0
Gini Coefficient 0.09027777777777778
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-22-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 256.36
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 191
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.098
    dispatch_time_ms: 9.847
    learner:
      cur_lr: 0.0012327940203249454
      grad_gnorm: 40.0000114440918
      policy_entropy: 73.08734893798828
      policy_loss: 3.8978769779205322
      var_gnorm: 43.63203430175781
      vf_explained_var: 0.3424949049949646
      vf_loss: 20.92241668701172
    num_steps_sampled: 1920000
    num_steps_trained: 1920000
    wait_time_ms: 162.694
  iterations_since_restore: 192
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3462.5812163352966
  time_this_iter_s: 17.397555112838745
  time_total_s: 3462.5812163352966
  timestamp: 1593825726
  timesteps_since_restore: 1920000
  timesteps_this_iter: 10000
  timesteps_total: 1920000
  training_iteration: 192
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3462 s, 192 iter, 1920000 ts, 256 rew

agent-1: 28.0
agent-2: 25.0
agent-3: 32.0
agent-4: 23.0
agent-5: 17.0
agent-6: 24.0
agent-7: 21.0
agent-8: 36.0
agent-9: 14.0
agent-10: 21.0
Sum Reward: 241.0
Avg Reward: 24.1
Min Reward: 14.0
Gini Coefficient 0.14564315352697096
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-22-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 256.2
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 192
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.777
    dispatch_time_ms: 9.042
    learner:
      cur_lr: 0.0012321280082687736
      grad_gnorm: 19.04062271118164
      policy_entropy: 153.77108764648438
      policy_loss: 3.883042812347412
      var_gnorm: 43.731300354003906
      vf_explained_var: -1.0
      vf_loss: 0.1712176501750946
    num_steps_sampled: 1930000
    num_steps_trained: 1930000
    wait_time_ms: 163.134
  iterations_since_restore: 193
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3479.8789043426514
  time_this_iter_s: 17.297688007354736
  time_total_s: 3479.8789043426514
  timestamp: 1593825744
  timesteps_since_restore: 1930000
  timesteps_this_iter: 10000
  timesteps_total: 1930000
  training_iteration: 193
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3479 s, 193 iter, 1930000 ts, 256 rew

agent-1: 30.0
agent-2: 38.0
agent-3: 28.0
agent-4: 30.0
agent-5: 19.0
agent-6: 29.0
agent-7: 32.0
agent-8: 15.0
agent-9: 23.0
agent-10: 18.0
Sum Reward: 262.0
Avg Reward: 26.2
Min Reward: 15.0
Gini Coefficient 0.14580152671755725
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-22-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 256.16
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 193
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.468
    dispatch_time_ms: 7.153
    learner:
      cur_lr: 0.0012314619962126017
      grad_gnorm: 21.411869049072266
      policy_entropy: 124.61699676513672
      policy_loss: -5.464973449707031
      var_gnorm: 43.743099212646484
      vf_explained_var: 0.9068146347999573
      vf_loss: 0.9869865775108337
    num_steps_sampled: 1940000
    num_steps_trained: 1940000
    wait_time_ms: 161.27
  iterations_since_restore: 194
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3497.4177734851837
  time_this_iter_s: 17.53886914253235
  time_total_s: 3497.4177734851837
  timestamp: 1593825761
  timesteps_since_restore: 1940000
  timesteps_this_iter: 10000
  timesteps_total: 1940000
  training_iteration: 194
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3497 s, 194 iter, 1940000 ts, 256 rew

agent-1: 27.0
agent-2: 11.0
agent-3: 36.0
agent-4: 20.0
agent-5: 25.0
agent-6: 19.0
agent-7: 28.0
agent-8: 21.0
agent-9: 22.0
agent-10: 24.0
Sum Reward: 233.0
Avg Reward: 23.3
Min Reward: 11.0
Gini Coefficient 0.1446351931330472
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-22-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 255.95
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 194
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.539
    dispatch_time_ms: 6.855
    learner:
      cur_lr: 0.0012307959841564298
      grad_gnorm: 1.7684996128082275
      policy_entropy: 133.62388610839844
      policy_loss: 0.7796209454536438
      var_gnorm: 43.86985397338867
      vf_explained_var: 2.205371856689453e-05
      vf_loss: 0.0017624550964683294
    num_steps_sampled: 1950000
    num_steps_trained: 1950000
    wait_time_ms: 167.121
  iterations_since_restore: 195
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3515.1592609882355
  time_this_iter_s: 17.741487503051758
  time_total_s: 3515.1592609882355
  timestamp: 1593825779
  timesteps_since_restore: 1950000
  timesteps_this_iter: 10000
  timesteps_total: 1950000
  training_iteration: 195
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3515 s, 195 iter, 1950000 ts, 256 rew

agent-1: 25.0
agent-2: 19.0
agent-3: 21.0
agent-4: 25.0
agent-5: 18.0
agent-6: 16.0
agent-7: 18.0
agent-8: 35.0
agent-9: 26.0
agent-10: 17.0
Sum Reward: 220.0
Avg Reward: 22.0
Min Reward: 16.0
Gini Coefficient 0.13272727272727272
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-23-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 255.77
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 195
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.431
    dispatch_time_ms: 5.715
    learner:
      cur_lr: 0.0012301299721002579
      grad_gnorm: 2.5226237773895264
      policy_entropy: 152.2386016845703
      policy_loss: -0.8729197382926941
      var_gnorm: 43.909542083740234
      vf_explained_var: -1.0
      vf_loss: 0.005710578989237547
    num_steps_sampled: 1960000
    num_steps_trained: 1960000
    wait_time_ms: 167.724
  iterations_since_restore: 196
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3532.480612516403
  time_this_iter_s: 17.321351528167725
  time_total_s: 3532.480612516403
  timestamp: 1593825796
  timesteps_since_restore: 1960000
  timesteps_this_iter: 10000
  timesteps_total: 1960000
  training_iteration: 196
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3532 s, 196 iter, 1960000 ts, 256 rew

agent-1: 19.0
agent-2: 27.0
agent-3: 27.0
agent-4: 24.0
agent-5: 13.0
agent-6: 22.0
agent-7: 24.0
agent-8: 28.0
agent-9: 15.0
agent-10: 12.0
Sum Reward: 211.0
Avg Reward: 21.1
Min Reward: 12.0
Gini Coefficient 0.15118483412322276
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-23-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 255.61
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 196
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.159
    dispatch_time_ms: 5.78
    learner:
      cur_lr: 0.001229463960044086
      grad_gnorm: 1.4647979736328125
      policy_entropy: 117.27120971679688
      policy_loss: 0.8442327976226807
      var_gnorm: 43.984859466552734
      vf_explained_var: 0.0
      vf_loss: 0.0010042927460744977
    num_steps_sampled: 1970000
    num_steps_trained: 1970000
    wait_time_ms: 173.736
  iterations_since_restore: 197
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3550.0187408924103
  time_this_iter_s: 17.53812837600708
  time_total_s: 3550.0187408924103
  timestamp: 1593825814
  timesteps_since_restore: 1970000
  timesteps_this_iter: 10000
  timesteps_total: 1970000
  training_iteration: 197
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3550 s, 197 iter, 1970000 ts, 256 rew

agent-1: 24.0
agent-2: 17.0
agent-3: 16.0
agent-4: 25.0
agent-5: 25.0
agent-6: 16.0
agent-7: 18.0
agent-8: 22.0
agent-9: 16.0
agent-10: 29.0
Sum Reward: 208.0
Avg Reward: 20.8
Min Reward: 16.0
Gini Coefficient 0.1201923076923077
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-23-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 255.28
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 197
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.098
    dispatch_time_ms: 6.703
    learner:
      cur_lr: 0.001228797947987914
      grad_gnorm: 3.2803914546966553
      policy_entropy: 138.2012939453125
      policy_loss: 1.0829099416732788
      var_gnorm: 44.013362884521484
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 0.07755797356367111
    num_steps_sampled: 1980000
    num_steps_trained: 1980000
    wait_time_ms: 162.781
  iterations_since_restore: 198
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3567.473301887512
  time_this_iter_s: 17.45456099510193
  time_total_s: 3567.473301887512
  timestamp: 1593825832
  timesteps_since_restore: 1980000
  timesteps_this_iter: 10000
  timesteps_total: 1980000
  training_iteration: 198
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3567 s, 198 iter, 1980000 ts, 255 rew

agent-1: 26.0
agent-2: 14.0
agent-3: 24.0
agent-4: 25.0
agent-5: 23.0
agent-6: 22.0
agent-7: 29.0
agent-8: 18.0
agent-9: 21.0
agent-10: 24.0
Sum Reward: 226.0
Avg Reward: 22.6
Min Reward: 14.0
Gini Coefficient 0.09646017699115045
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-24-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 255.34
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 198
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.584
    dispatch_time_ms: 7.073
    learner:
      cur_lr: 0.001228132052347064
      grad_gnorm: 1.7564560174942017
      policy_entropy: 150.6870880126953
      policy_loss: -1.327675223350525
      var_gnorm: 44.13371276855469
      vf_explained_var: 6.830692291259766e-05
      vf_loss: 0.0016885586082935333
    num_steps_sampled: 1990000
    num_steps_trained: 1990000
    wait_time_ms: 166.992
  iterations_since_restore: 199
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3584.7669942379
  time_this_iter_s: 17.293692350387573
  time_total_s: 3584.7669942379
  timestamp: 1593825849
  timesteps_since_restore: 1990000
  timesteps_this_iter: 10000
  timesteps_total: 1990000
  training_iteration: 199
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3584 s, 199 iter, 1990000 ts, 255 rew

agent-1: 27.0
agent-2: 30.0
agent-3: 24.0
agent-4: 17.0
agent-5: 18.0
agent-6: 19.0
agent-7: 23.0
agent-8: 26.0
agent-9: 21.0
agent-10: 38.0
Sum Reward: 243.0
Avg Reward: 24.3
Min Reward: 17.0
Gini Coefficient 0.1353909465020576
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-24-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 255.09
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 199
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.258
    dispatch_time_ms: 6.313
    learner:
      cur_lr: 0.0012274660402908921
      grad_gnorm: 39.99999237060547
      policy_entropy: 48.33444595336914
      policy_loss: -25.076196670532227
      var_gnorm: 44.20268249511719
      vf_explained_var: 0.002282857894897461
      vf_loss: 110.52067565917969
    num_steps_sampled: 2000000
    num_steps_trained: 2000000
    wait_time_ms: 153.324
  iterations_since_restore: 200
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3602.132658958435
  time_this_iter_s: 17.36566472053528
  time_total_s: 3602.132658958435
  timestamp: 1593825866
  timesteps_since_restore: 2000000
  timesteps_this_iter: 10000
  timesteps_total: 2000000
  training_iteration: 200
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3602 s, 200 iter, 2000000 ts, 255 rew

agent-1: 16.0
agent-2: 26.0
agent-3: 24.0
agent-4: 26.0
agent-5: 25.0
agent-6: 23.0
agent-7: 27.0
agent-8: 33.0
agent-9: 23.0
agent-10: 33.0
Sum Reward: 256.0
Avg Reward: 25.6
Min Reward: 16.0
Gini Coefficient 0.09765625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-24-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 255.15
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 200
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.65
    dispatch_time_ms: 8.21
    learner:
      cur_lr: 0.0012268000282347202
      grad_gnorm: 12.556965827941895
      policy_entropy: 107.2595443725586
      policy_loss: -4.256619930267334
      var_gnorm: 44.432342529296875
      vf_explained_var: 0.9179126024246216
      vf_loss: 0.2067706286907196
    num_steps_sampled: 2010000
    num_steps_trained: 2010000
    wait_time_ms: 164.858
  iterations_since_restore: 201
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3619.294441461563
  time_this_iter_s: 17.16178250312805
  time_total_s: 3619.294441461563
  timestamp: 1593825883
  timesteps_since_restore: 2010000
  timesteps_this_iter: 10000
  timesteps_total: 2010000
  training_iteration: 201
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3619 s, 201 iter, 2010000 ts, 255 rew

agent-1: 40.0
agent-2: 30.0
agent-3: 26.0
agent-4: 21.0
agent-5: 34.0
agent-6: 27.0
agent-7: 30.0
agent-8: 19.0
agent-9: 27.0
agent-10: 18.0
Sum Reward: 272.0
Avg Reward: 27.2
Min Reward: 18.0
Gini Coefficient 0.1323529411764706
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-25-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 254.71
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 201
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.015
    dispatch_time_ms: 6.344
    learner:
      cur_lr: 0.0012261340161785483
      grad_gnorm: 40.0
      policy_entropy: 61.677467346191406
      policy_loss: -77.1065902709961
      var_gnorm: 44.41211700439453
      vf_explained_var: -0.00013554096221923828
      vf_loss: 218.7962188720703
    num_steps_sampled: 2020000
    num_steps_trained: 2020000
    wait_time_ms: 156.924
  iterations_since_restore: 202
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3636.622512817383
  time_this_iter_s: 17.328071355819702
  time_total_s: 3636.622512817383
  timestamp: 1593825901
  timesteps_since_restore: 2020000
  timesteps_this_iter: 10000
  timesteps_total: 2020000
  training_iteration: 202
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3636 s, 202 iter, 2020000 ts, 255 rew

agent-1: 22.0
agent-2: 28.0
agent-3: 24.0
agent-4: 31.0
agent-5: 17.0
agent-6: 34.0
agent-7: 19.0
agent-8: 37.0
agent-9: 43.0
agent-10: 26.0
Sum Reward: 281.0
Avg Reward: 28.1
Min Reward: 17.0
Gini Coefficient 0.15765124555160143
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-25-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 255.09
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 202
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.752
    dispatch_time_ms: 6.32
    learner:
      cur_lr: 0.0012254680041223764
      grad_gnorm: 5.453146457672119
      policy_entropy: 167.01370239257812
      policy_loss: 2.4099600315093994
      var_gnorm: 44.57855987548828
      vf_explained_var: -6.67572021484375e-05
      vf_loss: 0.015765905380249023
    num_steps_sampled: 2030000
    num_steps_trained: 2030000
    wait_time_ms: 166.577
  iterations_since_restore: 203
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3653.9356915950775
  time_this_iter_s: 17.313178777694702
  time_total_s: 3653.9356915950775
  timestamp: 1593825918
  timesteps_since_restore: 2030000
  timesteps_this_iter: 10000
  timesteps_total: 2030000
  training_iteration: 203
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3653 s, 203 iter, 2030000 ts, 255 rew

agent-1: 16.0
agent-2: 24.0
agent-3: 17.0
agent-4: 36.0
agent-5: 24.0
agent-6: 26.0
agent-7: 21.0
agent-8: 20.0
agent-9: 29.0
agent-10: 26.0
Sum Reward: 239.0
Avg Reward: 23.9
Min Reward: 16.0
Gini Coefficient 0.1292887029288703
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-25-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 255.27
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 203
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.729
    dispatch_time_ms: 8.05
    learner:
      cur_lr: 0.0012248019920662045
      grad_gnorm: 40.0
      policy_entropy: 94.06299591064453
      policy_loss: 9.700825691223145
      var_gnorm: 44.58479690551758
      vf_explained_var: 0.4540274739265442
      vf_loss: 19.14679527282715
    num_steps_sampled: 2040000
    num_steps_trained: 2040000
    wait_time_ms: 161.332
  iterations_since_restore: 204
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3671.3895909786224
  time_this_iter_s: 17.453899383544922
  time_total_s: 3671.3895909786224
  timestamp: 1593825936
  timesteps_since_restore: 2040000
  timesteps_this_iter: 10000
  timesteps_total: 2040000
  training_iteration: 204
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3671 s, 204 iter, 2040000 ts, 255 rew

agent-1: 22.0
agent-2: 31.0
agent-3: 18.0
agent-4: 27.0
agent-5: 33.0
agent-6: 33.0
agent-7: 18.0
agent-8: 32.0
agent-9: 21.0
agent-10: 20.0
Sum Reward: 255.0
Avg Reward: 25.5
Min Reward: 18.0
Gini Coefficient 0.13137254901960785
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-25-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 255.57
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 204
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.753
    dispatch_time_ms: 6.396
    learner:
      cur_lr: 0.0012241359800100327
      grad_gnorm: 2.216742753982544
      policy_entropy: 166.183349609375
      policy_loss: -2.7551355361938477
      var_gnorm: 44.80839157104492
      vf_explained_var: -0.14924418926239014
      vf_loss: 0.0019855760037899017
    num_steps_sampled: 2050000
    num_steps_trained: 2050000
    wait_time_ms: 163.548
  iterations_since_restore: 205
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3688.605223417282
  time_this_iter_s: 17.215632438659668
  time_total_s: 3688.605223417282
  timestamp: 1593825953
  timesteps_since_restore: 2050000
  timesteps_this_iter: 10000
  timesteps_total: 2050000
  training_iteration: 205
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3688 s, 205 iter, 2050000 ts, 256 rew

agent-1: 15.0
agent-2: 19.0
agent-3: 22.0
agent-4: 19.0
agent-5: 35.0
agent-6: 33.0
agent-7: 19.0
agent-8: 30.0
agent-9: 29.0
agent-10: 27.0
Sum Reward: 248.0
Avg Reward: 24.8
Min Reward: 15.0
Gini Coefficient 0.14838709677419354
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-26-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 255.89
  episode_reward_min: 199.0
  episodes_this_iter: 1
  episodes_total: 205
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.657
    dispatch_time_ms: 6.056
    learner:
      cur_lr: 0.0012234699679538608
      grad_gnorm: 40.000003814697266
      policy_entropy: 87.94306182861328
      policy_loss: 17.445993423461914
      var_gnorm: 44.875099182128906
      vf_explained_var: 0.2747798562049866
      vf_loss: 34.786476135253906
    num_steps_sampled: 2060000
    num_steps_trained: 2060000
    wait_time_ms: 170.425
  iterations_since_restore: 206
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3706.1748287677765
  time_this_iter_s: 17.569605350494385
  time_total_s: 3706.1748287677765
  timestamp: 1593825971
  timesteps_since_restore: 2060000
  timesteps_this_iter: 10000
  timesteps_total: 2060000
  training_iteration: 206
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3706 s, 206 iter, 2060000 ts, 256 rew

agent-1: 39.0
agent-2: 27.0
agent-3: 22.0
agent-4: 27.0
agent-5: 31.0
agent-6: 28.0
agent-7: 26.0
agent-8: 32.0
agent-9: 34.0
agent-10: 29.0
Sum Reward: 295.0
Avg Reward: 29.5
Min Reward: 22.0
Gini Coefficient 0.08372881355932203
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-26-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 256.85
  episode_reward_min: 207.0
  episodes_this_iter: 1
  episodes_total: 206
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.792
    dispatch_time_ms: 6.244
    learner:
      cur_lr: 0.0012228039558976889
      grad_gnorm: 5.456353187561035
      policy_entropy: 145.41957092285156
      policy_loss: -1.8657563924789429
      var_gnorm: 45.08324432373047
      vf_explained_var: 0.8542966842651367
      vf_loss: 0.14902736246585846
    num_steps_sampled: 2070000
    num_steps_trained: 2070000
    wait_time_ms: 173.851
  iterations_since_restore: 207
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3723.436401605606
  time_this_iter_s: 17.26157283782959
  time_total_s: 3723.436401605606
  timestamp: 1593825988
  timesteps_since_restore: 2070000
  timesteps_this_iter: 10000
  timesteps_total: 2070000
  training_iteration: 207
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3723 s, 207 iter, 2070000 ts, 257 rew

agent-1: 23.0
agent-2: 16.0
agent-3: 32.0
agent-4: 24.0
agent-5: 20.0
agent-6: 27.0
agent-7: 15.0
agent-8: 28.0
agent-9: 26.0
agent-10: 19.0
Sum Reward: 230.0
Avg Reward: 23.0
Min Reward: 15.0
Gini Coefficient 0.12869565217391304
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-26-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 256.91
  episode_reward_min: 207.0
  episodes_this_iter: 1
  episodes_total: 207
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.466
    dispatch_time_ms: 6.719
    learner:
      cur_lr: 0.001222137943841517
      grad_gnorm: 2.4322285652160645
      policy_entropy: 175.16603088378906
      policy_loss: -1.2725144624710083
      var_gnorm: 45.155364990234375
      vf_explained_var: 0.021416068077087402
      vf_loss: 0.003245562082156539
    num_steps_sampled: 2080000
    num_steps_trained: 2080000
    wait_time_ms: 165.547
  iterations_since_restore: 208
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3740.7491195201874
  time_this_iter_s: 17.3127179145813
  time_total_s: 3740.7491195201874
  timestamp: 1593826005
  timesteps_since_restore: 2080000
  timesteps_this_iter: 10000
  timesteps_total: 2080000
  training_iteration: 208
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3740 s, 208 iter, 2080000 ts, 257 rew

agent-1: 26.0
agent-2: 31.0
agent-3: 25.0
agent-4: 25.0
agent-5: 27.0
agent-6: 44.0
agent-7: 43.0
agent-8: 17.0
agent-9: 32.0
agent-10: 19.0
Sum Reward: 289.0
Avg Reward: 28.9
Min Reward: 17.0
Gini Coefficient 0.16089965397923875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-27-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 257.38
  episode_reward_min: 207.0
  episodes_this_iter: 1
  episodes_total: 208
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.791
    dispatch_time_ms: 9.543
    learner:
      cur_lr: 0.001221472048200667
      grad_gnorm: 4.180673599243164
      policy_entropy: 164.69207763671875
      policy_loss: 0.8464028239250183
      var_gnorm: 45.37782669067383
      vf_explained_var: 0.18845999240875244
      vf_loss: 0.036958158016204834
    num_steps_sampled: 2090000
    num_steps_trained: 2090000
    wait_time_ms: 166.406
  iterations_since_restore: 209
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3758.1746146678925
  time_this_iter_s: 17.425495147705078
  time_total_s: 3758.1746146678925
  timestamp: 1593826023
  timesteps_since_restore: 2090000
  timesteps_this_iter: 10000
  timesteps_total: 2090000
  training_iteration: 209
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3758 s, 209 iter, 2090000 ts, 257 rew

agent-1: 22.0
agent-2: 25.0
agent-3: 26.0
agent-4: 35.0
agent-5: 28.0
agent-6: 24.0
agent-7: 33.0
agent-8: 20.0
agent-9: 26.0
agent-10: 22.0
Sum Reward: 261.0
Avg Reward: 26.1
Min Reward: 20.0
Gini Coefficient 0.09540229885057472
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-27-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 257.49
  episode_reward_min: 207.0
  episodes_this_iter: 1
  episodes_total: 209
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.927
    dispatch_time_ms: 5.78
    learner:
      cur_lr: 0.001220806036144495
      grad_gnorm: 3.5787229537963867
      policy_entropy: 160.11705017089844
      policy_loss: -1.378954291343689
      var_gnorm: 45.40495300292969
      vf_explained_var: -0.3095581531524658
      vf_loss: 0.01187567412853241
    num_steps_sampled: 2100000
    num_steps_trained: 2100000
    wait_time_ms: 148.376
  iterations_since_restore: 210
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3775.22473859787
  time_this_iter_s: 17.050123929977417
  time_total_s: 3775.22473859787
  timestamp: 1593826040
  timesteps_since_restore: 2100000
  timesteps_this_iter: 10000
  timesteps_total: 2100000
  training_iteration: 210
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3775 s, 210 iter, 2100000 ts, 257 rew

agent-1: 24.0
agent-2: 10.0
agent-3: 30.0
agent-4: 27.0
agent-5: 9.0
agent-6: 39.0
agent-7: 29.0
agent-8: 23.0
agent-9: 36.0
agent-10: 19.0
Sum Reward: 246.0
Avg Reward: 24.6
Min Reward: 9.0
Gini Coefficient 0.2146341463414634
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-27-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 257.67
  episode_reward_min: 207.0
  episodes_this_iter: 1
  episodes_total: 210
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.783
    dispatch_time_ms: 6.987
    learner:
      cur_lr: 0.0012201400240883231
      grad_gnorm: 3.938347339630127
      policy_entropy: 169.88169860839844
      policy_loss: 2.479811906814575
      var_gnorm: 45.42543411254883
      vf_explained_var: 0.9901371002197266
      vf_loss: 0.008856398053467274
    num_steps_sampled: 2110000
    num_steps_trained: 2110000
    wait_time_ms: 159.132
  iterations_since_restore: 211
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3792.5191099643707
  time_this_iter_s: 17.294371366500854
  time_total_s: 3792.5191099643707
  timestamp: 1593826057
  timesteps_since_restore: 2110000
  timesteps_this_iter: 10000
  timesteps_total: 2110000
  training_iteration: 211
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3792 s, 211 iter, 2110000 ts, 258 rew

agent-1: 14.0
agent-2: -4.0
agent-3: 34.0
agent-4: 49.0
agent-5: 36.0
agent-6: 23.0
agent-7: 21.0
agent-8: 44.0
agent-9: 27.0
agent-10: 34.0
Sum Reward: 278.0
Avg Reward: 27.8
Min Reward: -4.0
Gini Coefficient 0.2884892086330935
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-27-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 258.2
  episode_reward_min: 207.0
  episodes_this_iter: 1
  episodes_total: 211
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.877
    dispatch_time_ms: 30.585
    learner:
      cur_lr: 0.0012194740120321512
      grad_gnorm: 40.000003814697266
      policy_entropy: 99.0103988647461
      policy_loss: -0.11269652843475342
      var_gnorm: 45.469303131103516
      vf_explained_var: -0.32024455070495605
      vf_loss: 36.105987548828125
    num_steps_sampled: 2120000
    num_steps_trained: 2120000
    wait_time_ms: 140.145
  iterations_since_restore: 212
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3811.8751542568207
  time_this_iter_s: 19.35604429244995
  time_total_s: 3811.8751542568207
  timestamp: 1593826076
  timesteps_since_restore: 2120000
  timesteps_this_iter: 10000
  timesteps_total: 2120000
  training_iteration: 212
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3811 s, 212 iter, 2120000 ts, 258 rew

agent-1: 22.0
agent-2: 13.0
agent-3: 35.0
agent-4: 23.0
agent-5: 34.0
agent-6: 22.0
agent-7: 18.0
agent-8: 26.0
agent-9: 31.0
agent-10: 13.0
Sum Reward: 237.0
Avg Reward: 23.7
Min Reward: 13.0
Gini Coefficient 0.17848101265822786
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-28-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 257.95
  episode_reward_min: 207.0
  episodes_this_iter: 1
  episodes_total: 212
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.855
    dispatch_time_ms: 29.204
    learner:
      cur_lr: 0.0012188079999759793
      grad_gnorm: 2.750028371810913
      policy_entropy: 168.54794311523438
      policy_loss: 2.9657840728759766
      var_gnorm: 45.59750747680664
      vf_explained_var: 0.07353383302688599
      vf_loss: 0.004980842582881451
    num_steps_sampled: 2130000
    num_steps_trained: 2130000
    wait_time_ms: 152.767
  iterations_since_restore: 213
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3830.1052849292755
  time_this_iter_s: 18.230130672454834
  time_total_s: 3830.1052849292755
  timestamp: 1593826095
  timesteps_since_restore: 2130000
  timesteps_this_iter: 10000
  timesteps_total: 2130000
  training_iteration: 213
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3830 s, 213 iter, 2130000 ts, 258 rew

agent-1: 28.0
agent-2: 18.0
agent-3: 30.0
agent-4: 24.0
agent-5: 26.0
agent-6: 23.0
agent-7: 24.0
agent-8: 25.0
agent-9: 18.0
agent-10: 22.0
Sum Reward: 238.0
Avg Reward: 23.8
Min Reward: 18.0
Gini Coefficient 0.08571428571428572
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-28-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 257.77
  episode_reward_min: 207.0
  episodes_this_iter: 1
  episodes_total: 213
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.764
    dispatch_time_ms: 32.126
    learner:
      cur_lr: 0.0012181419879198074
      grad_gnorm: 2.4035420417785645
      policy_entropy: 173.04563903808594
      policy_loss: -2.622152805328369
      var_gnorm: 45.63786697387695
      vf_explained_var: 0.9947336316108704
      vf_loss: 0.005138573702424765
    num_steps_sampled: 2140000
    num_steps_trained: 2140000
    wait_time_ms: 154.369
  iterations_since_restore: 214
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3848.141556739807
  time_this_iter_s: 18.036271810531616
  time_total_s: 3848.141556739807
  timestamp: 1593826113
  timesteps_since_restore: 2140000
  timesteps_this_iter: 10000
  timesteps_total: 2140000
  training_iteration: 214
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3848 s, 214 iter, 2140000 ts, 258 rew

agent-1: 29.0
agent-2: 19.0
agent-3: 17.0
agent-4: 25.0
agent-5: 16.0
agent-6: 46.0
agent-7: 31.0
agent-8: 17.0
agent-9: 29.0
agent-10: 26.0
Sum Reward: 255.0
Avg Reward: 25.5
Min Reward: 16.0
Gini Coefficient 0.18
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-28-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 257.78
  episode_reward_min: 207.0
  episodes_this_iter: 1
  episodes_total: 214
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.049
    dispatch_time_ms: 38.665
    learner:
      cur_lr: 0.0012174759758636355
      grad_gnorm: 8.23270320892334
      policy_entropy: 141.8335418701172
      policy_loss: -0.4005008339881897
      var_gnorm: 45.8595085144043
      vf_explained_var: -0.42113590240478516
      vf_loss: 1.2579971551895142
    num_steps_sampled: 2150000
    num_steps_trained: 2150000
    wait_time_ms: 143.77
  iterations_since_restore: 215
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3866.1644475460052
  time_this_iter_s: 18.02289080619812
  time_total_s: 3866.1644475460052
  timestamp: 1593826131
  timesteps_since_restore: 2150000
  timesteps_this_iter: 10000
  timesteps_total: 2150000
  training_iteration: 215
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3866 s, 215 iter, 2150000 ts, 258 rew

agent-1: 21.0
agent-2: 32.0
agent-3: 23.0
agent-4: 29.0
agent-5: 29.0
agent-6: 33.0
agent-7: 19.0
agent-8: 28.0
agent-9: 17.0
agent-10: 19.0
Sum Reward: 250.0
Avg Reward: 25.0
Min Reward: 17.0
Gini Coefficient 0.1256
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-29-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 257.73
  episode_reward_min: 207.0
  episodes_this_iter: 1
  episodes_total: 215
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.865
    dispatch_time_ms: 6.75
    learner:
      cur_lr: 0.0012168099638074636
      grad_gnorm: 39.999977111816406
      policy_entropy: 111.17842864990234
      policy_loss: 8.501119613647461
      var_gnorm: 45.85303497314453
      vf_explained_var: 0.0897720456123352
      vf_loss: 22.073604583740234
    num_steps_sampled: 2160000
    num_steps_trained: 2160000
    wait_time_ms: 161.287
  iterations_since_restore: 216
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3884.033794403076
  time_this_iter_s: 17.869346857070923
  time_total_s: 3884.033794403076
  timestamp: 1593826149
  timesteps_since_restore: 2160000
  timesteps_this_iter: 10000
  timesteps_total: 2160000
  training_iteration: 216
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3884 s, 216 iter, 2160000 ts, 258 rew

agent-1: 31.0
agent-2: 41.0
agent-3: 18.0
agent-4: 25.0
agent-5: 19.0
agent-6: 35.0
agent-7: 38.0
agent-8: 33.0
agent-9: 18.0
agent-10: 29.0
Sum Reward: 287.0
Avg Reward: 28.7
Min Reward: 18.0
Gini Coefficient 0.15783972125435541
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-29-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 258.5
  episode_reward_min: 207.0
  episodes_this_iter: 1
  episodes_total: 216
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.871
    dispatch_time_ms: 8.963
    learner:
      cur_lr: 0.0012161439517512918
      grad_gnorm: 10.909749031066895
      policy_entropy: 153.43621826171875
      policy_loss: -4.329444408416748
      var_gnorm: 45.94868087768555
      vf_explained_var: 0.6486219167709351
      vf_loss: 0.7109360694885254
    num_steps_sampled: 2170000
    num_steps_trained: 2170000
    wait_time_ms: 165.897
  iterations_since_restore: 217
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3901.3313558101654
  time_this_iter_s: 17.297561407089233
  time_total_s: 3901.3313558101654
  timestamp: 1593826166
  timesteps_since_restore: 2170000
  timesteps_this_iter: 10000
  timesteps_total: 2170000
  training_iteration: 217
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3901 s, 217 iter, 2170000 ts, 258 rew

agent-1: 24.0
agent-2: 26.0
agent-3: 34.0
agent-4: 33.0
agent-5: 22.0
agent-6: 24.0
agent-7: 37.0
agent-8: 29.0
agent-9: 14.0
agent-10: 20.0
Sum Reward: 263.0
Avg Reward: 26.3
Min Reward: 14.0
Gini Coefficient 0.14334600760456273
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-29-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 258.78
  episode_reward_min: 207.0
  episodes_this_iter: 1
  episodes_total: 217
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.087
    dispatch_time_ms: 7.327
    learner:
      cur_lr: 0.0012154780561104417
      grad_gnorm: 1.888765811920166
      policy_entropy: 170.69398498535156
      policy_loss: -0.8323264718055725
      var_gnorm: 45.950923919677734
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0020599456038326025
    num_steps_sampled: 2180000
    num_steps_trained: 2180000
    wait_time_ms: 164.038
  iterations_since_restore: 218
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3919.362594127655
  time_this_iter_s: 18.031238317489624
  time_total_s: 3919.362594127655
  timestamp: 1593826184
  timesteps_since_restore: 2180000
  timesteps_this_iter: 10000
  timesteps_total: 2180000
  training_iteration: 218
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3919 s, 218 iter, 2180000 ts, 259 rew

agent-1: 24.0
agent-2: 21.0
agent-3: 32.0
agent-4: 26.0
agent-5: 19.0
agent-6: 33.0
agent-7: 29.0
agent-8: 28.0
agent-9: 18.0
agent-10: 24.0
Sum Reward: 254.0
Avg Reward: 25.4
Min Reward: 18.0
Gini Coefficient 0.11023622047244094
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-30-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 259.09
  episode_reward_min: 207.0
  episodes_this_iter: 1
  episodes_total: 218
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.573
    dispatch_time_ms: 31.575
    learner:
      cur_lr: 0.0012148120440542698
      grad_gnorm: 0.7236983776092529
      policy_entropy: 151.0780487060547
      policy_loss: -0.23283055424690247
      var_gnorm: 46.06806945800781
      vf_explained_var: -1.0
      vf_loss: 0.010654189623892307
    num_steps_sampled: 2190000
    num_steps_trained: 2190000
    wait_time_ms: 152.992
  iterations_since_restore: 219
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3937.13685131073
  time_this_iter_s: 17.77425718307495
  time_total_s: 3937.13685131073
  timestamp: 1593826202
  timesteps_since_restore: 2190000
  timesteps_this_iter: 10000
  timesteps_total: 2190000
  training_iteration: 219
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3937 s, 219 iter, 2190000 ts, 259 rew

agent-1: 17.0
agent-2: 27.0
agent-3: 21.0
agent-4: 29.0
agent-5: 26.0
agent-6: 21.0
agent-7: 20.0
agent-8: 25.0
agent-9: 25.0
agent-10: 17.0
Sum Reward: 228.0
Avg Reward: 22.8
Min Reward: 17.0
Gini Coefficient 0.09824561403508772
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-30-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 259.13
  episode_reward_min: 207.0
  episodes_this_iter: 1
  episodes_total: 219
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.899
    dispatch_time_ms: 30.789
    learner:
      cur_lr: 0.001214146031998098
      grad_gnorm: 40.000003814697266
      policy_entropy: 115.1082534790039
      policy_loss: -3.8568904399871826
      var_gnorm: 46.06367492675781
      vf_explained_var: 0.9077911972999573
      vf_loss: 0.42347267270088196
    num_steps_sampled: 2200000
    num_steps_trained: 2200000
    wait_time_ms: 151.92
  iterations_since_restore: 220
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3955.246725797653
  time_this_iter_s: 18.109874486923218
  time_total_s: 3955.246725797653
  timestamp: 1593826220
  timesteps_since_restore: 2200000
  timesteps_this_iter: 10000
  timesteps_total: 2200000
  training_iteration: 220
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3955 s, 220 iter, 2200000 ts, 259 rew

agent-1: 22.0
agent-2: 24.0
agent-3: 24.0
agent-4: 17.0
agent-5: 32.0
agent-6: 36.0
agent-7: 24.0
agent-8: 20.0
agent-9: 34.0
agent-10: 23.0
Sum Reward: 256.0
Avg Reward: 25.6
Min Reward: 17.0
Gini Coefficient 0.12578125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-30-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 259.1
  episode_reward_min: 207.0
  episodes_this_iter: 1
  episodes_total: 220
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.928
    dispatch_time_ms: 27.462
    learner:
      cur_lr: 0.001213480019941926
      grad_gnorm: 3.82817006111145
      policy_entropy: 138.6558074951172
      policy_loss: -0.5124214887619019
      var_gnorm: 46.1356086730957
      vf_explained_var: -1.0
      vf_loss: 0.06828334182500839
    num_steps_sampled: 2210000
    num_steps_trained: 2210000
    wait_time_ms: 167.887
  iterations_since_restore: 221
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3973.46417760849
  time_this_iter_s: 18.217451810836792
  time_total_s: 3973.46417760849
  timestamp: 1593826239
  timesteps_since_restore: 2210000
  timesteps_this_iter: 10000
  timesteps_total: 2210000
  training_iteration: 221
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3973 s, 221 iter, 2210000 ts, 259 rew

agent-1: 20.0
agent-2: 21.0
agent-3: 17.0
agent-4: 13.0
agent-5: 24.0
agent-6: 19.0
agent-7: 27.0
agent-8: 19.0
agent-9: 22.0
agent-10: 34.0
Sum Reward: 216.0
Avg Reward: 21.6
Min Reward: 13.0
Gini Coefficient 0.1361111111111111
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-30-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 258.68
  episode_reward_min: 207.0
  episodes_this_iter: 1
  episodes_total: 221
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.878
    dispatch_time_ms: 25.567
    learner:
      cur_lr: 0.0012128140078857541
      grad_gnorm: 20.440032958984375
      policy_entropy: 106.61957550048828
      policy_loss: -1.9235202074050903
      var_gnorm: 46.19160842895508
      vf_explained_var: 0.22314900159835815
      vf_loss: 6.055226802825928
    num_steps_sampled: 2220000
    num_steps_trained: 2220000
    wait_time_ms: 155.645
  iterations_since_restore: 222
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 3990.390103340149
  time_this_iter_s: 16.925925731658936
  time_total_s: 3990.390103340149
  timestamp: 1593826259
  timesteps_since_restore: 2220000
  timesteps_this_iter: 10000
  timesteps_total: 2220000
  training_iteration: 222
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 3990 s, 222 iter, 2220000 ts, 259 rew

agent-1: 22.0
agent-2: 34.0
agent-3: 52.0
agent-4: 19.0
agent-5: 21.0
agent-6: 23.0
agent-7: 33.0
agent-8: 25.0
agent-9: 31.0
agent-10: 26.0
Sum Reward: 286.0
Avg Reward: 28.6
Min Reward: 19.0
Gini Coefficient 0.16363636363636364
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-31-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 259.08
  episode_reward_min: 207.0
  episodes_this_iter: 1
  episodes_total: 222
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 4.173
    dispatch_time_ms: 29.05
    learner:
      cur_lr: 0.0012121479958295822
      grad_gnorm: 4.530688762664795
      policy_entropy: 118.93690490722656
      policy_loss: -3.161120653152466
      var_gnorm: 46.28755187988281
      vf_explained_var: 0.988864541053772
      vf_loss: 0.012359041720628738
    num_steps_sampled: 2230000
    num_steps_trained: 2230000
    wait_time_ms: 146.152
  iterations_since_restore: 223
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4008.479856967926
  time_this_iter_s: 18.0897536277771
  time_total_s: 4008.479856967926
  timestamp: 1593826277
  timesteps_since_restore: 2230000
  timesteps_this_iter: 10000
  timesteps_total: 2230000
  training_iteration: 223
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4008 s, 223 iter, 2230000 ts, 259 rew

agent-1: 23.0
agent-2: 23.0
agent-3: 28.0
agent-4: 27.0
agent-5: 19.0
agent-6: 23.0
agent-7: 27.0
agent-8: 25.0
agent-9: 36.0
agent-10: 31.0
Sum Reward: 262.0
Avg Reward: 26.2
Min Reward: 19.0
Gini Coefficient 0.09465648854961832
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-31-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 259.43
  episode_reward_min: 207.0
  episodes_this_iter: 1
  episodes_total: 223
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.784
    dispatch_time_ms: 6.178
    learner:
      cur_lr: 0.0012114819837734103
      grad_gnorm: 1.2989833354949951
      policy_entropy: 116.59390258789062
      policy_loss: -0.41011911630630493
      var_gnorm: 46.32408142089844
      vf_explained_var: 0.9953381419181824
      vf_loss: 0.0022228669840842485
    num_steps_sampled: 2240000
    num_steps_trained: 2240000
    wait_time_ms: 167.903
  iterations_since_restore: 224
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4026.138781785965
  time_this_iter_s: 17.65892481803894
  time_total_s: 4026.138781785965
  timestamp: 1593826295
  timesteps_since_restore: 2240000
  timesteps_this_iter: 10000
  timesteps_total: 2240000
  training_iteration: 224
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4026 s, 224 iter, 2240000 ts, 259 rew

agent-1: 38.0
agent-2: 23.0
agent-3: 10.0
agent-4: 29.0
agent-5: 13.0
agent-6: 28.0
agent-7: 29.0
agent-8: 29.0
agent-9: 23.0
agent-10: 24.0
Sum Reward: 246.0
Avg Reward: 24.6
Min Reward: 10.0
Gini Coefficient 0.16910569105691056
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-31-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 259.53
  episode_reward_min: 207.0
  episodes_this_iter: 1
  episodes_total: 224
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.36
    dispatch_time_ms: 6.958
    learner:
      cur_lr: 0.0012108159717172384
      grad_gnorm: 2.6663689613342285
      policy_entropy: 134.1728973388672
      policy_loss: -1.1588863134384155
      var_gnorm: 46.373687744140625
      vf_explained_var: 0.9931881427764893
      vf_loss: 0.00528531800955534
    num_steps_sampled: 2250000
    num_steps_trained: 2250000
    wait_time_ms: 165.141
  iterations_since_restore: 225
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4043.688309431076
  time_this_iter_s: 17.549527645111084
  time_total_s: 4043.688309431076
  timestamp: 1593826312
  timesteps_since_restore: 2250000
  timesteps_this_iter: 10000
  timesteps_total: 2250000
  training_iteration: 225
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4043 s, 225 iter, 2250000 ts, 260 rew

agent-1: 25.0
agent-2: 18.0
agent-3: 27.0
agent-4: 52.0
agent-5: 22.0
agent-6: 24.0
agent-7: 12.0
agent-8: 26.0
agent-9: 14.0
agent-10: 30.0
Sum Reward: 250.0
Avg Reward: 25.0
Min Reward: 12.0
Gini Coefficient 0.212
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-32-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 259.64
  episode_reward_min: 207.0
  episodes_this_iter: 1
  episodes_total: 225
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.061
    dispatch_time_ms: 5.629
    learner:
      cur_lr: 0.0012101499596610665
      grad_gnorm: 40.0
      policy_entropy: 87.49674987792969
      policy_loss: 41.242881774902344
      var_gnorm: 46.40092086791992
      vf_explained_var: 0.2868182063102722
      vf_loss: 65.1219711303711
    num_steps_sampled: 2260000
    num_steps_trained: 2260000
    wait_time_ms: 161.996
  iterations_since_restore: 226
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4060.9666335582733
  time_this_iter_s: 17.278324127197266
  time_total_s: 4060.9666335582733
  timestamp: 1593826330
  timesteps_since_restore: 2260000
  timesteps_this_iter: 10000
  timesteps_total: 2260000
  training_iteration: 226
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4060 s, 226 iter, 2260000 ts, 260 rew

agent-1: 19.0
agent-2: 20.0
agent-3: 29.0
agent-4: 29.0
agent-5: 20.0
agent-6: 33.0
agent-7: 17.0
agent-8: 25.0
agent-9: 30.0
agent-10: 28.0
Sum Reward: 250.0
Avg Reward: 25.0
Min Reward: 17.0
Gini Coefficient 0.1184
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-32-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 259.69
  episode_reward_min: 207.0
  episodes_this_iter: 1
  episodes_total: 226
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.891
    dispatch_time_ms: 6.974
    learner:
      cur_lr: 0.0012094839476048946
      grad_gnorm: 24.695703506469727
      policy_entropy: 94.24003601074219
      policy_loss: -9.321043968200684
      var_gnorm: 46.50131607055664
      vf_explained_var: 0.9177807569503784
      vf_loss: 0.7601830363273621
    num_steps_sampled: 2270000
    num_steps_trained: 2270000
    wait_time_ms: 166.011
  iterations_since_restore: 227
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4078.2200429439545
  time_this_iter_s: 17.253409385681152
  time_total_s: 4078.2200429439545
  timestamp: 1593826347
  timesteps_since_restore: 2270000
  timesteps_this_iter: 10000
  timesteps_total: 2270000
  training_iteration: 227
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4078 s, 227 iter, 2270000 ts, 260 rew

agent-1: 29.0
agent-2: 29.0
agent-3: 43.0
agent-4: 31.0
agent-5: 36.0
agent-6: 14.0
agent-7: 43.0
agent-8: 25.0
agent-9: 27.0
agent-10: 18.0
Sum Reward: 295.0
Avg Reward: 29.5
Min Reward: 14.0
Gini Coefficient 0.1705084745762712
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-32-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 259.98
  episode_reward_min: 207.0
  episodes_this_iter: 1
  episodes_total: 227
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.375
    dispatch_time_ms: 7.41
    learner:
      cur_lr: 0.0012088180519640446
      grad_gnorm: 2.4751479625701904
      policy_entropy: 148.9871368408203
      policy_loss: -1.1985323429107666
      var_gnorm: 46.46939468383789
      vf_explained_var: 0.9950392246246338
      vf_loss: 0.006363858003169298
    num_steps_sampled: 2280000
    num_steps_trained: 2280000
    wait_time_ms: 157.05
  iterations_since_restore: 228
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4095.5954151153564
  time_this_iter_s: 17.375372171401978
  time_total_s: 4095.5954151153564
  timestamp: 1593826364
  timesteps_since_restore: 2280000
  timesteps_this_iter: 10000
  timesteps_total: 2280000
  training_iteration: 228
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4095 s, 228 iter, 2280000 ts, 260 rew

agent-1: 18.0
agent-2: 21.0
agent-3: 31.0
agent-4: 26.0
agent-5: 29.0
agent-6: 32.0
agent-7: 23.0
agent-8: 18.0
agent-9: 45.0
agent-10: 30.0
Sum Reward: 273.0
Avg Reward: 27.3
Min Reward: 18.0
Gini Coefficient 0.152014652014652
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-33-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 260.14
  episode_reward_min: 207.0
  episodes_this_iter: 1
  episodes_total: 228
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.682
    dispatch_time_ms: 9.923
    learner:
      cur_lr: 0.0012081520399078727
      grad_gnorm: 7.790273666381836
      policy_entropy: 117.54431915283203
      policy_loss: 3.282003879547119
      var_gnorm: 46.59847640991211
      vf_explained_var: 0.9646367430686951
      vf_loss: 0.03604090213775635
    num_steps_sampled: 2290000
    num_steps_trained: 2290000
    wait_time_ms: 159.092
  iterations_since_restore: 229
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4116.404342889786
  time_this_iter_s: 20.80892777442932
  time_total_s: 4116.404342889786
  timestamp: 1593826385
  timesteps_since_restore: 2290000
  timesteps_this_iter: 10000
  timesteps_total: 2290000
  training_iteration: 229
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4116 s, 229 iter, 2290000 ts, 260 rew

agent-1: 22.0
agent-2: 43.0
agent-3: 32.0
agent-4: 27.0
agent-5: 40.0
agent-6: 21.0
agent-7: 22.0
agent-8: 52.0
agent-9: 24.0
agent-10: 26.0
Sum Reward: 309.0
Avg Reward: 30.9
Min Reward: 21.0
Gini Coefficient 0.17508090614886732
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-33-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 260.6
  episode_reward_min: 207.0
  episodes_this_iter: 1
  episodes_total: 229
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.992
    dispatch_time_ms: 6.301
    learner:
      cur_lr: 0.0012074860278517008
      grad_gnorm: 1.0691332817077637
      policy_entropy: 135.6778564453125
      policy_loss: 0.6954402923583984
      var_gnorm: 46.67002487182617
      vf_explained_var: 0.9956697225570679
      vf_loss: 0.002377062104642391
    num_steps_sampled: 2300000
    num_steps_trained: 2300000
    wait_time_ms: 166.612
  iterations_since_restore: 230
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4133.9616730213165
  time_this_iter_s: 17.55733013153076
  time_total_s: 4133.9616730213165
  timestamp: 1593826403
  timesteps_since_restore: 2300000
  timesteps_this_iter: 10000
  timesteps_total: 2300000
  training_iteration: 230
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4133 s, 230 iter, 2300000 ts, 261 rew

agent-1: 29.0
agent-2: 21.0
agent-3: 27.0
agent-4: 24.0
agent-5: 21.0
agent-6: 27.0
agent-7: 25.0
agent-8: 18.0
agent-9: 23.0
agent-10: 30.0
Sum Reward: 245.0
Avg Reward: 24.5
Min Reward: 18.0
Gini Coefficient 0.08448979591836735
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-33-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 260.55
  episode_reward_min: 207.0
  episodes_this_iter: 1
  episodes_total: 230
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.019
    dispatch_time_ms: 8.887
    learner:
      cur_lr: 0.0012068200157955289
      grad_gnorm: 4.307488918304443
      policy_entropy: 139.79747009277344
      policy_loss: -1.4409980773925781
      var_gnorm: 46.75822830200195
      vf_explained_var: 0.9915196299552917
      vf_loss: 0.011782114394009113
    num_steps_sampled: 2310000
    num_steps_trained: 2310000
    wait_time_ms: 167.459
  iterations_since_restore: 231
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4151.489312887192
  time_this_iter_s: 17.527639865875244
  time_total_s: 4151.489312887192
  timestamp: 1593826420
  timesteps_since_restore: 2310000
  timesteps_this_iter: 10000
  timesteps_total: 2310000
  training_iteration: 231
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4151 s, 231 iter, 2310000 ts, 261 rew

agent-1: 19.0
agent-2: 16.0
agent-3: 28.0
agent-4: 24.0
agent-5: 43.0
agent-6: 22.0
agent-7: 26.0
agent-8: 21.0
agent-9: 33.0
agent-10: 30.0
Sum Reward: 262.0
Avg Reward: 26.2
Min Reward: 16.0
Gini Coefficient 0.1549618320610687
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-33-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 260.63
  episode_reward_min: 207.0
  episodes_this_iter: 1
  episodes_total: 231
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.137
    dispatch_time_ms: 8.395
    learner:
      cur_lr: 0.001206154003739357
      grad_gnorm: 1.1415964365005493
      policy_entropy: 142.33053588867188
      policy_loss: 0.1762407124042511
      var_gnorm: 46.7611198425293
      vf_explained_var: 0.17182481288909912
      vf_loss: 0.0006928998045623302
    num_steps_sampled: 2320000
    num_steps_trained: 2320000
    wait_time_ms: 170.863
  iterations_since_restore: 232
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4168.811472654343
  time_this_iter_s: 17.32215976715088
  time_total_s: 4168.811472654343
  timestamp: 1593826438
  timesteps_since_restore: 2320000
  timesteps_this_iter: 10000
  timesteps_total: 2320000
  training_iteration: 232
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4168 s, 232 iter, 2320000 ts, 261 rew

agent-1: 15.0
agent-2: 25.0
agent-3: 30.0
agent-4: 35.0
agent-5: 17.0
agent-6: 29.0
agent-7: 28.0
agent-8: 22.0
agent-9: 27.0
agent-10: 30.0
Sum Reward: 258.0
Avg Reward: 25.8
Min Reward: 15.0
Gini Coefficient 0.12558139534883722
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-34-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 260.69
  episode_reward_min: 207.0
  episodes_this_iter: 1
  episodes_total: 232
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.868
    dispatch_time_ms: 9.738
    learner:
      cur_lr: 0.001205487991683185
      grad_gnorm: 6.910568714141846
      policy_entropy: 142.10218811035156
      policy_loss: 3.1236181259155273
      var_gnorm: 46.83635330200195
      vf_explained_var: 0.9910834431648254
      vf_loss: 0.032381732016801834
    num_steps_sampled: 2330000
    num_steps_trained: 2330000
    wait_time_ms: 161.947
  iterations_since_restore: 233
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4186.211913347244
  time_this_iter_s: 17.40044069290161
  time_total_s: 4186.211913347244
  timestamp: 1593826455
  timesteps_since_restore: 2330000
  timesteps_this_iter: 10000
  timesteps_total: 2330000
  training_iteration: 233
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4186 s, 233 iter, 2330000 ts, 261 rew

agent-1: 25.0
agent-2: 36.0
agent-3: 21.0
agent-4: 25.0
agent-5: 30.0
agent-6: 15.0
agent-7: 23.0
agent-8: 29.0
agent-9: 26.0
agent-10: 31.0
Sum Reward: 261.0
Avg Reward: 26.1
Min Reward: 15.0
Gini Coefficient 0.11762452107279693
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-34-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 261.11
  episode_reward_min: 207.0
  episodes_this_iter: 1
  episodes_total: 233
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.958
    dispatch_time_ms: 5.886
    learner:
      cur_lr: 0.0012048219796270132
      grad_gnorm: 40.0
      policy_entropy: 58.835567474365234
      policy_loss: 4.6747541427612305
      var_gnorm: 46.84164810180664
      vf_explained_var: -0.055200815200805664
      vf_loss: 35.96317672729492
    num_steps_sampled: 2340000
    num_steps_trained: 2340000
    wait_time_ms: 163.734
  iterations_since_restore: 234
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4203.68235373497
  time_this_iter_s: 17.47044038772583
  time_total_s: 4203.68235373497
  timestamp: 1593826473
  timesteps_since_restore: 2340000
  timesteps_this_iter: 10000
  timesteps_total: 2340000
  training_iteration: 234
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4203 s, 234 iter, 2340000 ts, 261 rew

agent-1: 23.0
agent-2: 30.0
agent-3: 15.0
agent-4: 16.0
agent-5: 27.0
agent-6: 20.0
agent-7: 29.0
agent-8: 31.0
agent-9: 21.0
agent-10: 32.0
Sum Reward: 244.0
Avg Reward: 24.4
Min Reward: 15.0
Gini Coefficient 0.1377049180327869
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-34-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 260.84
  episode_reward_min: 207.0
  episodes_this_iter: 1
  episodes_total: 234
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.795
    dispatch_time_ms: 9.104
    learner:
      cur_lr: 0.0012041559675708413
      grad_gnorm: 9.387931823730469
      policy_entropy: 165.19200134277344
      policy_loss: 3.811419725418091
      var_gnorm: 47.08196258544922
      vf_explained_var: -1.0
      vf_loss: 0.30688831210136414
    num_steps_sampled: 2350000
    num_steps_trained: 2350000
    wait_time_ms: 163.01
  iterations_since_restore: 235
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4220.994635105133
  time_this_iter_s: 17.312281370162964
  time_total_s: 4220.994635105133
  timestamp: 1593826490
  timesteps_since_restore: 2350000
  timesteps_this_iter: 10000
  timesteps_total: 2350000
  training_iteration: 235
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4220 s, 235 iter, 2350000 ts, 261 rew

agent-1: 35.0
agent-2: 26.0
agent-3: 17.0
agent-4: 30.0
agent-5: 24.0
agent-6: 31.0
agent-7: 25.0
agent-8: 37.0
agent-9: 23.0
agent-10: 18.0
Sum Reward: 266.0
Avg Reward: 26.6
Min Reward: 17.0
Gini Coefficient 0.13458646616541353
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-35-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 261.43
  episode_reward_min: 208.0
  episodes_this_iter: 1
  episodes_total: 235
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.631
    dispatch_time_ms: 6.081
    learner:
      cur_lr: 0.0012034899555146694
      grad_gnorm: 40.0
      policy_entropy: 91.77542877197266
      policy_loss: -0.9702776074409485
      var_gnorm: 47.16638946533203
      vf_explained_var: 0.5140061378479004
      vf_loss: 10.28614330291748
    num_steps_sampled: 2360000
    num_steps_trained: 2360000
    wait_time_ms: 166.241
  iterations_since_restore: 236
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4238.441939353943
  time_this_iter_s: 17.447304248809814
  time_total_s: 4238.441939353943
  timestamp: 1593826507
  timesteps_since_restore: 2360000
  timesteps_this_iter: 10000
  timesteps_total: 2360000
  training_iteration: 236
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4238 s, 236 iter, 2360000 ts, 261 rew

agent-1: 29.0
agent-2: 38.0
agent-3: 31.0
agent-4: 26.0
agent-5: 18.0
agent-6: 32.0
agent-7: 33.0
agent-8: 16.0
agent-9: 19.0
agent-10: 29.0
Sum Reward: 271.0
Avg Reward: 27.1
Min Reward: 16.0
Gini Coefficient 0.14132841328413284
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-35-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 261.55
  episode_reward_min: 208.0
  episodes_this_iter: 1
  episodes_total: 236
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.757
    dispatch_time_ms: 5.607
    learner:
      cur_lr: 0.0012028239434584975
      grad_gnorm: 13.319602966308594
      policy_entropy: 115.61995697021484
      policy_loss: -5.473689079284668
      var_gnorm: 47.22158432006836
      vf_explained_var: -6.198883056640625e-06
      vf_loss: 0.099003367125988
    num_steps_sampled: 2370000
    num_steps_trained: 2370000
    wait_time_ms: 170.38
  iterations_since_restore: 237
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4255.94807100296
  time_this_iter_s: 17.506131649017334
  time_total_s: 4255.94807100296
  timestamp: 1593826525
  timesteps_since_restore: 2370000
  timesteps_this_iter: 10000
  timesteps_total: 2370000
  training_iteration: 237
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4255 s, 237 iter, 2370000 ts, 262 rew

agent-1: 21.0
agent-2: 27.0
agent-3: 19.0
agent-4: 22.0
agent-5: 25.0
agent-6: 34.0
agent-7: 15.0
agent-8: 30.0
agent-9: 33.0
agent-10: 27.0
Sum Reward: 253.0
Avg Reward: 25.3
Min Reward: 15.0
Gini Coefficient 0.1308300395256917
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-35-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 261.36
  episode_reward_min: 208.0
  episodes_this_iter: 1
  episodes_total: 237
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.573
    dispatch_time_ms: 6.568
    learner:
      cur_lr: 0.0012021580478176475
      grad_gnorm: 40.000003814697266
      policy_entropy: 120.24014282226562
      policy_loss: 20.439733505249023
      var_gnorm: 47.30439376831055
      vf_explained_var: 0.42594611644744873
      vf_loss: 13.776101112365723
    num_steps_sampled: 2380000
    num_steps_trained: 2380000
    wait_time_ms: 163.668
  iterations_since_restore: 238
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4273.402958869934
  time_this_iter_s: 17.454887866973877
  time_total_s: 4273.402958869934
  timestamp: 1593826542
  timesteps_since_restore: 2380000
  timesteps_this_iter: 10000
  timesteps_total: 2380000
  training_iteration: 238
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4273 s, 238 iter, 2380000 ts, 261 rew

agent-1: 29.0
agent-2: 23.0
agent-3: 18.0
agent-4: 33.0
agent-5: 25.0
agent-6: 15.0
agent-7: 35.0
agent-8: 33.0
agent-9: 20.0
agent-10: 19.0
Sum Reward: 250.0
Avg Reward: 25.0
Min Reward: 15.0
Gini Coefficient 0.1536
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-36-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 261.77
  episode_reward_min: 208.0
  episodes_this_iter: 1
  episodes_total: 238
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.803
    dispatch_time_ms: 7.094
    learner:
      cur_lr: 0.0012014920357614756
      grad_gnorm: 13.608895301818848
      policy_entropy: 136.1987762451172
      policy_loss: 3.274043560028076
      var_gnorm: 47.370479583740234
      vf_explained_var: -0.09579992294311523
      vf_loss: 1.9731018543243408
    num_steps_sampled: 2390000
    num_steps_trained: 2390000
    wait_time_ms: 166.902
  iterations_since_restore: 239
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4290.761247396469
  time_this_iter_s: 17.358288526535034
  time_total_s: 4290.761247396469
  timestamp: 1593826560
  timesteps_since_restore: 2390000
  timesteps_this_iter: 10000
  timesteps_total: 2390000
  training_iteration: 239
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4290 s, 239 iter, 2390000 ts, 262 rew

agent-1: 24.0
agent-2: 43.0
agent-3: 25.0
agent-4: 41.0
agent-5: 23.0
agent-6: 33.0
agent-7: 39.0
agent-8: 28.0
agent-9: 44.0
agent-10: 30.0
Sum Reward: 330.0
Avg Reward: 33.0
Min Reward: 23.0
Gini Coefficient 0.13272727272727272
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-36-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 262.6
  episode_reward_min: 208.0
  episodes_this_iter: 1
  episodes_total: 239
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.907
    dispatch_time_ms: 22.12
    learner:
      cur_lr: 0.0012008260237053037
      grad_gnorm: 9.474357604980469
      policy_entropy: 134.06707763671875
      policy_loss: 2.767341375350952
      var_gnorm: 47.4794921875
      vf_explained_var: 0.6383557319641113
      vf_loss: 1.6405577659606934
    num_steps_sampled: 2400000
    num_steps_trained: 2400000
    wait_time_ms: 144.472
  iterations_since_restore: 240
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4308.822378158569
  time_this_iter_s: 18.06113076210022
  time_total_s: 4308.822378158569
  timestamp: 1593826578
  timesteps_since_restore: 2400000
  timesteps_this_iter: 10000
  timesteps_total: 2400000
  training_iteration: 240
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4308 s, 240 iter, 2400000 ts, 263 rew

agent-1: 14.0
agent-2: 34.0
agent-3: 24.0
agent-4: 23.0
agent-5: 30.0
agent-6: 16.0
agent-7: 25.0
agent-8: 27.0
agent-9: 32.0
agent-10: 22.0
Sum Reward: 247.0
Avg Reward: 24.7
Min Reward: 14.0
Gini Coefficient 0.1396761133603239
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-36-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 262.66
  episode_reward_min: 208.0
  episodes_this_iter: 1
  episodes_total: 240
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.182
    dispatch_time_ms: 29.04
    learner:
      cur_lr: 0.0012001600116491318
      grad_gnorm: 39.999996185302734
      policy_entropy: 132.3607177734375
      policy_loss: 19.703432083129883
      var_gnorm: 47.54018020629883
      vf_explained_var: 0.27780479192733765
      vf_loss: 23.380258560180664
    num_steps_sampled: 2410000
    num_steps_trained: 2410000
    wait_time_ms: 156.802
  iterations_since_restore: 241
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4326.618454456329
  time_this_iter_s: 17.79607629776001
  time_total_s: 4326.618454456329
  timestamp: 1593826596
  timesteps_since_restore: 2410000
  timesteps_this_iter: 10000
  timesteps_total: 2410000
  training_iteration: 241
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4326 s, 241 iter, 2410000 ts, 263 rew

agent-1: 30.0
agent-2: 27.0
agent-3: 20.0
agent-4: 19.0
agent-5: 26.0
agent-6: 27.0
agent-7: 28.0
agent-8: 27.0
agent-9: 26.0
agent-10: 15.0
Sum Reward: 245.0
Avg Reward: 24.5
Min Reward: 15.0
Gini Coefficient 0.09673469387755101
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-36-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 262.48
  episode_reward_min: 208.0
  episodes_this_iter: 1
  episodes_total: 241
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.672
    dispatch_time_ms: 24.994
    learner:
      cur_lr: 0.0011994939995929599
      grad_gnorm: 5.331576824188232
      policy_entropy: 138.30491638183594
      policy_loss: -2.9596147537231445
      var_gnorm: 47.546958923339844
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.01650155335664749
    num_steps_sampled: 2420000
    num_steps_trained: 2420000
    wait_time_ms: 160.474
  iterations_since_restore: 242
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4344.808528423309
  time_this_iter_s: 18.19007396697998
  time_total_s: 4344.808528423309
  timestamp: 1593826615
  timesteps_since_restore: 2420000
  timesteps_this_iter: 10000
  timesteps_total: 2420000
  training_iteration: 242
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4344 s, 242 iter, 2420000 ts, 262 rew

agent-1: 34.0
agent-2: 28.0
agent-3: 32.0
agent-4: 41.0
agent-5: 21.0
agent-6: 21.0
agent-7: 32.0
agent-8: 13.0
agent-9: 29.0
agent-10: 22.0
Sum Reward: 273.0
Avg Reward: 27.3
Min Reward: 13.0
Gini Coefficient 0.15714285714285714
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-37-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 263.05
  episode_reward_min: 208.0
  episodes_this_iter: 1
  episodes_total: 242
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.223
    dispatch_time_ms: 25.625
    learner:
      cur_lr: 0.001198827987536788
      grad_gnorm: 3.2195322513580322
      policy_entropy: 128.86289978027344
      policy_loss: -0.6407539248466492
      var_gnorm: 47.689327239990234
      vf_explained_var: 0.9952174425125122
      vf_loss: 0.012341449968516827
    num_steps_sampled: 2430000
    num_steps_trained: 2430000
    wait_time_ms: 157.598
  iterations_since_restore: 243
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4361.69452047348
  time_this_iter_s: 16.8859920501709
  time_total_s: 4361.69452047348
  timestamp: 1593826633
  timesteps_since_restore: 2430000
  timesteps_this_iter: 10000
  timesteps_total: 2430000
  training_iteration: 243
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4361 s, 243 iter, 2430000 ts, 263 rew

agent-1: 26.0
agent-2: 18.0
agent-3: 27.0
agent-4: 28.0
agent-5: 21.0
agent-6: 26.0
agent-7: 18.0
agent-8: 29.0
agent-9: 18.0
agent-10: 30.0
Sum Reward: 241.0
Avg Reward: 24.1
Min Reward: 18.0
Gini Coefficient 0.1049792531120332
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-37-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 262.56
  episode_reward_min: 208.0
  episodes_this_iter: 1
  episodes_total: 243
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.75
    dispatch_time_ms: 28.676
    learner:
      cur_lr: 0.001198161975480616
      grad_gnorm: 17.280540466308594
      policy_entropy: 102.577880859375
      policy_loss: -4.240291595458984
      var_gnorm: 47.745540618896484
      vf_explained_var: 0.7912676334381104
      vf_loss: 2.9438066482543945
    num_steps_sampled: 2440000
    num_steps_trained: 2440000
    wait_time_ms: 149.722
  iterations_since_restore: 244
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4379.942613124847
  time_this_iter_s: 18.248092651367188
  time_total_s: 4379.942613124847
  timestamp: 1593826651
  timesteps_since_restore: 2440000
  timesteps_this_iter: 10000
  timesteps_total: 2440000
  training_iteration: 244
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4379 s, 244 iter, 2440000 ts, 263 rew

agent-1: 19.0
agent-2: 24.0
agent-3: 22.0
agent-4: 22.0
agent-5: 20.0
agent-6: 23.0
agent-7: 19.0
agent-8: 19.0
agent-9: 30.0
agent-10: 29.0
Sum Reward: 227.0
Avg Reward: 22.7
Min Reward: 19.0
Gini Coefficient 0.08942731277533039
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-37-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 262.17
  episode_reward_min: 208.0
  episodes_this_iter: 1
  episodes_total: 244
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.875
    dispatch_time_ms: 26.284
    learner:
      cur_lr: 0.0011974959634244442
      grad_gnorm: 3.037975311279297
      policy_entropy: 134.9048614501953
      policy_loss: 3.0146169662475586
      var_gnorm: 47.9017448425293
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.004329746589064598
    num_steps_sampled: 2450000
    num_steps_trained: 2450000
    wait_time_ms: 154.773
  iterations_since_restore: 245
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4398.079355716705
  time_this_iter_s: 18.13674259185791
  time_total_s: 4398.079355716705
  timestamp: 1593826669
  timesteps_since_restore: 2450000
  timesteps_this_iter: 10000
  timesteps_total: 2450000
  training_iteration: 245
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4398 s, 245 iter, 2450000 ts, 262 rew

agent-1: 25.0
agent-2: 23.0
agent-3: 22.0
agent-4: 37.0
agent-5: 21.0
agent-6: 23.0
agent-7: 23.0
agent-8: 24.0
agent-9: 29.0
agent-10: 41.0
Sum Reward: 268.0
Avg Reward: 26.8
Min Reward: 21.0
Gini Coefficient 0.12014925373134329
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-38-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 261.89
  episode_reward_min: 208.0
  episodes_this_iter: 1
  episodes_total: 245
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.504
    dispatch_time_ms: 7.157
    learner:
      cur_lr: 0.0011968299513682723
      grad_gnorm: 0.8329556584358215
      policy_entropy: 144.4218292236328
      policy_loss: 0.11265530437231064
      var_gnorm: 48.00104904174805
      vf_explained_var: 0.23855358362197876
      vf_loss: 0.0001487082481617108
    num_steps_sampled: 2460000
    num_steps_trained: 2460000
    wait_time_ms: 166.327
  iterations_since_restore: 246
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4416.32480597496
  time_this_iter_s: 18.245450258255005
  time_total_s: 4416.32480597496
  timestamp: 1593826688
  timesteps_since_restore: 2460000
  timesteps_this_iter: 10000
  timesteps_total: 2460000
  training_iteration: 246
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4416 s, 246 iter, 2460000 ts, 262 rew

agent-1: 14.0
agent-2: 21.0
agent-3: 30.0
agent-4: 33.0
agent-5: 7.0
agent-6: 24.0
agent-7: 27.0
agent-8: 26.0
agent-9: 20.0
agent-10: 37.0
Sum Reward: 239.0
Avg Reward: 23.9
Min Reward: 7.0
Gini Coefficient 0.19790794979079498
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-38-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 261.64
  episode_reward_min: 208.0
  episodes_this_iter: 1
  episodes_total: 246
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.609
    dispatch_time_ms: 5.774
    learner:
      cur_lr: 0.0011961640557274222
      grad_gnorm: 13.489267349243164
      policy_entropy: 121.02275085449219
      policy_loss: -3.331873893737793
      var_gnorm: 48.03496170043945
      vf_explained_var: 0.3035392165184021
      vf_loss: 0.764064371585846
    num_steps_sampled: 2470000
    num_steps_trained: 2470000
    wait_time_ms: 166.83
  iterations_since_restore: 247
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4433.622676610947
  time_this_iter_s: 17.297870635986328
  time_total_s: 4433.622676610947
  timestamp: 1593826705
  timesteps_since_restore: 2470000
  timesteps_this_iter: 10000
  timesteps_total: 2470000
  training_iteration: 247
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4433 s, 247 iter, 2470000 ts, 262 rew

agent-1: 26.0
agent-2: 24.0
agent-3: 29.0
agent-4: 18.0
agent-5: 19.0
agent-6: 20.0
agent-7: 20.0
agent-8: 32.0
agent-9: 16.0
agent-10: 22.0
Sum Reward: 226.0
Avg Reward: 22.6
Min Reward: 16.0
Gini Coefficient 0.11946902654867257
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-38-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 261.33
  episode_reward_min: 208.0
  episodes_this_iter: 1
  episodes_total: 247
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.967
    dispatch_time_ms: 7.411
    learner:
      cur_lr: 0.0011954980436712503
      grad_gnorm: 39.99995422363281
      policy_entropy: 132.20730590820312
      policy_loss: -3.124437093734741
      var_gnorm: 48.099754333496094
      vf_explained_var: 0.355934739112854
      vf_loss: 0.26595866680145264
    num_steps_sampled: 2480000
    num_steps_trained: 2480000
    wait_time_ms: 161.362
  iterations_since_restore: 248
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4450.869271039963
  time_this_iter_s: 17.246594429016113
  time_total_s: 4450.869271039963
  timestamp: 1593826722
  timesteps_since_restore: 2480000
  timesteps_this_iter: 10000
  timesteps_total: 2480000
  training_iteration: 248
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4450 s, 248 iter, 2480000 ts, 261 rew

agent-1: 29.0
agent-2: 16.0
agent-3: 5.0
agent-4: 33.0
agent-5: 30.0
agent-6: 30.0
agent-7: 33.0
agent-8: 16.0
agent-9: 27.0
agent-10: 26.0
Sum Reward: 245.0
Avg Reward: 24.5
Min Reward: 5.0
Gini Coefficient 0.18571428571428572
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-39-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 261.6
  episode_reward_min: 208.0
  episodes_this_iter: 1
  episodes_total: 248
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 4.314
    dispatch_time_ms: 5.897
    learner:
      cur_lr: 0.0011948320316150784
      grad_gnorm: 9.831742286682129
      policy_entropy: 103.77562713623047
      policy_loss: -3.329291582107544
      var_gnorm: 48.1024284362793
      vf_explained_var: 0.8224072456359863
      vf_loss: 0.36332759261131287
    num_steps_sampled: 2490000
    num_steps_trained: 2490000
    wait_time_ms: 166.656
  iterations_since_restore: 249
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4468.276402950287
  time_this_iter_s: 17.407131910324097
  time_total_s: 4468.276402950287
  timestamp: 1593826740
  timesteps_since_restore: 2490000
  timesteps_this_iter: 10000
  timesteps_total: 2490000
  training_iteration: 249
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4468 s, 249 iter, 2490000 ts, 262 rew

agent-1: 30.0
agent-2: 27.0
agent-3: 20.0
agent-4: 30.0
agent-5: 24.0
agent-6: 39.0
agent-7: 30.0
agent-8: 23.0
agent-9: 33.0
agent-10: 25.0
Sum Reward: 281.0
Avg Reward: 28.1
Min Reward: 20.0
Gini Coefficient 0.10284697508896797
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-39-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 261.86
  episode_reward_min: 208.0
  episodes_this_iter: 1
  episodes_total: 249
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.965
    dispatch_time_ms: 5.784
    learner:
      cur_lr: 0.0011941660195589066
      grad_gnorm: 0.383014053106308
      policy_entropy: 104.06449127197266
      policy_loss: -0.5337197184562683
      var_gnorm: 48.0997428894043
      vf_explained_var: 0.0
      vf_loss: 9.093245353142265e-06
    num_steps_sampled: 2500000
    num_steps_trained: 2500000
    wait_time_ms: 168.688
  iterations_since_restore: 250
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4485.766478776932
  time_this_iter_s: 17.490075826644897
  time_total_s: 4485.766478776932
  timestamp: 1593826757
  timesteps_since_restore: 2500000
  timesteps_this_iter: 10000
  timesteps_total: 2500000
  training_iteration: 250
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4485 s, 250 iter, 2500000 ts, 262 rew

agent-1: 20.0
agent-2: 13.0
agent-3: 10.0
agent-4: 27.0
agent-5: 15.0
agent-6: 34.0
agent-7: 41.0
agent-8: 21.0
agent-9: 23.0
agent-10: 37.0
Sum Reward: 241.0
Avg Reward: 24.1
Min Reward: 10.0
Gini Coefficient 0.23443983402489627
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-39-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 261.8
  episode_reward_min: 208.0
  episodes_this_iter: 1
  episodes_total: 250
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.79
    dispatch_time_ms: 6.734
    learner:
      cur_lr: 0.0011935000075027347
      grad_gnorm: 1.4412927627563477
      policy_entropy: 97.44829559326172
      policy_loss: 0.014528732746839523
      var_gnorm: 48.16289138793945
      vf_explained_var: 0.9959174990653992
      vf_loss: 0.01206477452069521
    num_steps_sampled: 2510000
    num_steps_trained: 2510000
    wait_time_ms: 167.593
  iterations_since_restore: 251
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4503.258467197418
  time_this_iter_s: 17.49198842048645
  time_total_s: 4503.258467197418
  timestamp: 1593826775
  timesteps_since_restore: 2510000
  timesteps_this_iter: 10000
  timesteps_total: 2510000
  training_iteration: 251
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4503 s, 251 iter, 2510000 ts, 262 rew

agent-1: 14.0
agent-2: 20.0
agent-3: 23.0
agent-4: 17.0
agent-5: 33.0
agent-6: 20.0
agent-7: 32.0
agent-8: 14.0
agent-9: 26.0
agent-10: 29.0
Sum Reward: 228.0
Avg Reward: 22.8
Min Reward: 14.0
Gini Coefficient 0.16578947368421051
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-39-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 261.22
  episode_reward_min: 208.0
  episodes_this_iter: 1
  episodes_total: 251
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.093
    dispatch_time_ms: 7.332
    learner:
      cur_lr: 0.0011928339954465628
      grad_gnorm: 35.54681396484375
      policy_entropy: 87.05057525634766
      policy_loss: -7.816420078277588
      var_gnorm: 48.278297424316406
      vf_explained_var: 0.905049204826355
      vf_loss: 1.6911427974700928
    num_steps_sampled: 2520000
    num_steps_trained: 2520000
    wait_time_ms: 165.366
  iterations_since_restore: 252
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4520.608549356461
  time_this_iter_s: 17.35008215904236
  time_total_s: 4520.608549356461
  timestamp: 1593826792
  timesteps_since_restore: 2520000
  timesteps_this_iter: 10000
  timesteps_total: 2520000
  training_iteration: 252
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4520 s, 252 iter, 2520000 ts, 261 rew

agent-1: 19.0
agent-2: 17.0
agent-3: 12.0
agent-4: 24.0
agent-5: 20.0
agent-6: 40.0
agent-7: 25.0
agent-8: 18.0
agent-9: 26.0
agent-10: 29.0
Sum Reward: 230.0
Avg Reward: 23.0
Min Reward: 12.0
Gini Coefficient 0.17304347826086958
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-40-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 261.28
  episode_reward_min: 208.0
  episodes_this_iter: 1
  episodes_total: 252
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.29
    dispatch_time_ms: 5.33
    learner:
      cur_lr: 0.0011921679833903909
      grad_gnorm: 19.21656036376953
      policy_entropy: 99.3951416015625
      policy_loss: 0.4612407088279724
      var_gnorm: 48.34025573730469
      vf_explained_var: -1.0
      vf_loss: 0.12077751010656357
    num_steps_sampled: 2530000
    num_steps_trained: 2530000
    wait_time_ms: 171.298
  iterations_since_restore: 253
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4537.916765928268
  time_this_iter_s: 17.30821657180786
  time_total_s: 4537.916765928268
  timestamp: 1593826810
  timesteps_since_restore: 2530000
  timesteps_this_iter: 10000
  timesteps_total: 2530000
  training_iteration: 253
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4537 s, 253 iter, 2530000 ts, 261 rew

agent-1: 30.0
agent-2: 31.0
agent-3: 20.0
agent-4: 23.0
agent-5: 11.0
agent-6: 14.0
agent-7: 43.0
agent-8: 32.0
agent-9: 37.0
agent-10: 15.0
Sum Reward: 256.0
Avg Reward: 25.6
Min Reward: 11.0
Gini Coefficient 0.22421875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-40-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 261.35
  episode_reward_min: 208.0
  episodes_this_iter: 1
  episodes_total: 253
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.79
    dispatch_time_ms: 6.579
    learner:
      cur_lr: 0.001191501971334219
      grad_gnorm: 7.728777885437012
      policy_entropy: 114.232421875
      policy_loss: 0.21218034625053406
      var_gnorm: 48.38115692138672
      vf_explained_var: 0.854880690574646
      vf_loss: 2.5379621982574463
    num_steps_sampled: 2540000
    num_steps_trained: 2540000
    wait_time_ms: 167.632
  iterations_since_restore: 254
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4555.2790150642395
  time_this_iter_s: 17.36224913597107
  time_total_s: 4555.2790150642395
  timestamp: 1593826827
  timesteps_since_restore: 2540000
  timesteps_this_iter: 10000
  timesteps_total: 2540000
  training_iteration: 254
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4555 s, 254 iter, 2540000 ts, 261 rew

agent-1: 28.0
agent-2: 27.0
agent-3: 18.0
agent-4: 28.0
agent-5: 26.0
agent-6: 21.0
agent-7: 21.0
agent-8: 24.0
agent-9: 29.0
agent-10: 16.0
Sum Reward: 238.0
Avg Reward: 23.8
Min Reward: 16.0
Gini Coefficient 0.10168067226890756
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-40-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 411.0
  episode_reward_mean: 261.28
  episode_reward_min: 208.0
  episodes_this_iter: 1
  episodes_total: 254
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.777
    dispatch_time_ms: 9.867
    learner:
      cur_lr: 0.001190835959278047
      grad_gnorm: 33.93722152709961
      policy_entropy: 121.2736587524414
      policy_loss: 2.009469747543335
      var_gnorm: 48.36677169799805
      vf_explained_var: 0.8029624819755554
      vf_loss: 5.749144554138184
    num_steps_sampled: 2550000
    num_steps_trained: 2550000
    wait_time_ms: 165.601
  iterations_since_restore: 255
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4572.6825735569
  time_this_iter_s: 17.403558492660522
  time_total_s: 4572.6825735569
  timestamp: 1593826844
  timesteps_since_restore: 2550000
  timesteps_this_iter: 10000
  timesteps_total: 2550000
  training_iteration: 255
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4572 s, 255 iter, 2550000 ts, 261 rew

agent-1: 24.0
agent-2: 12.0
agent-3: 17.0
agent-4: 29.0
agent-5: 24.0
agent-6: 28.0
agent-7: 33.0
agent-8: 24.0
agent-9: 21.0
agent-10: 16.0
Sum Reward: 228.0
Avg Reward: 22.8
Min Reward: 12.0
Gini Coefficient 0.15087719298245614
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-41-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 375.0
  episode_reward_mean: 259.45
  episode_reward_min: 208.0
  episodes_this_iter: 1
  episodes_total: 255
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.795
    dispatch_time_ms: 7.615
    learner:
      cur_lr: 0.0011901699472218752
      grad_gnorm: 28.04197120666504
      policy_entropy: 107.2679443359375
      policy_loss: 8.718971252441406
      var_gnorm: 48.389957427978516
      vf_explained_var: 0.9314999580383301
      vf_loss: 1.78801691532135
    num_steps_sampled: 2560000
    num_steps_trained: 2560000
    wait_time_ms: 164.914
  iterations_since_restore: 256
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4589.996535539627
  time_this_iter_s: 17.31396198272705
  time_total_s: 4589.996535539627
  timestamp: 1593826862
  timesteps_since_restore: 2560000
  timesteps_this_iter: 10000
  timesteps_total: 2560000
  training_iteration: 256
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4589 s, 256 iter, 2560000 ts, 259 rew

agent-1: 21.0
agent-2: 32.0
agent-3: 25.0
agent-4: 23.0
agent-5: 16.0
agent-6: 27.0
agent-7: 19.0
agent-8: 29.0
agent-9: 30.0
agent-10: 21.0
Sum Reward: 243.0
Avg Reward: 24.3
Min Reward: 16.0
Gini Coefficient 0.11563786008230453
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-41-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 375.0
  episode_reward_mean: 259.37
  episode_reward_min: 208.0
  episodes_this_iter: 1
  episodes_total: 256
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.683
    dispatch_time_ms: 5.94
    learner:
      cur_lr: 0.0011895040515810251
      grad_gnorm: 4.6879096031188965
      policy_entropy: 119.28697967529297
      policy_loss: 1.8144358396530151
      var_gnorm: 48.46775817871094
      vf_explained_var: 0.9404301643371582
      vf_loss: 0.016283970326185226
    num_steps_sampled: 2570000
    num_steps_trained: 2570000
    wait_time_ms: 171.864
  iterations_since_restore: 257
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4607.39066362381
  time_this_iter_s: 17.39412808418274
  time_total_s: 4607.39066362381
  timestamp: 1593826879
  timesteps_since_restore: 2570000
  timesteps_this_iter: 10000
  timesteps_total: 2570000
  training_iteration: 257
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4607 s, 257 iter, 2570000 ts, 259 rew

agent-1: 23.0
agent-2: 16.0
agent-3: 39.0
agent-4: 35.0
agent-5: 19.0
agent-6: 15.0
agent-7: 14.0
agent-8: 20.0
agent-9: 30.0
agent-10: 28.0
Sum Reward: 239.0
Avg Reward: 23.9
Min Reward: 14.0
Gini Coefficient 0.19456066945606695
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-41-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 375.0
  episode_reward_mean: 259.09
  episode_reward_min: 208.0
  episodes_this_iter: 1
  episodes_total: 257
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.861
    dispatch_time_ms: 5.326
    learner:
      cur_lr: 0.0011888380395248532
      grad_gnorm: 2.4047296047210693
      policy_entropy: 137.8215789794922
      policy_loss: -0.6311576962471008
      var_gnorm: 48.56619644165039
      vf_explained_var: -1.0
      vf_loss: 0.003156945575028658
    num_steps_sampled: 2580000
    num_steps_trained: 2580000
    wait_time_ms: 164.031
  iterations_since_restore: 258
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4624.767906427383
  time_this_iter_s: 17.37724280357361
  time_total_s: 4624.767906427383
  timestamp: 1593826897
  timesteps_since_restore: 2580000
  timesteps_this_iter: 10000
  timesteps_total: 2580000
  training_iteration: 258
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4624 s, 258 iter, 2580000 ts, 259 rew

agent-1: 24.0
agent-2: 16.0
agent-3: 10.0
agent-4: 23.0
agent-5: 19.0
agent-6: 20.0
agent-7: 18.0
agent-8: 30.0
agent-9: 27.0
agent-10: 18.0
Sum Reward: 205.0
Avg Reward: 20.5
Min Reward: 10.0
Gini Coefficient 0.14780487804878048
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-41-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 375.0
  episode_reward_mean: 258.36
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 258
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.78
    dispatch_time_ms: 6.276
    learner:
      cur_lr: 0.0011881720274686813
      grad_gnorm: 39.99998092651367
      policy_entropy: 128.69850158691406
      policy_loss: -10.911117553710938
      var_gnorm: 48.66919708251953
      vf_explained_var: -1.0
      vf_loss: 4.283706188201904
    num_steps_sampled: 2590000
    num_steps_trained: 2590000
    wait_time_ms: 165.076
  iterations_since_restore: 259
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4642.266369342804
  time_this_iter_s: 17.498462915420532
  time_total_s: 4642.266369342804
  timestamp: 1593826914
  timesteps_since_restore: 2590000
  timesteps_this_iter: 10000
  timesteps_total: 2590000
  training_iteration: 259
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4642 s, 259 iter, 2590000 ts, 258 rew

agent-1: 28.0
agent-2: 18.0
agent-3: 24.0
agent-4: 30.0
agent-5: 20.0
agent-6: 26.0
agent-7: 35.0
agent-8: 27.0
agent-9: 18.0
agent-10: 24.0
Sum Reward: 250.0
Avg Reward: 25.0
Min Reward: 18.0
Gini Coefficient 0.1152
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-42-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 375.0
  episode_reward_mean: 258.37
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 259
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.504
    dispatch_time_ms: 6.719
    learner:
      cur_lr: 0.0011875060154125094
      grad_gnorm: 39.9999885559082
      policy_entropy: 133.26004028320312
      policy_loss: -11.629213333129883
      var_gnorm: 48.65729904174805
      vf_explained_var: 0.01785975694656372
      vf_loss: 1.5116466283798218
    num_steps_sampled: 2600000
    num_steps_trained: 2600000
    wait_time_ms: 169.376
  iterations_since_restore: 260
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4659.675356864929
  time_this_iter_s: 17.408987522125244
  time_total_s: 4659.675356864929
  timestamp: 1593826931
  timesteps_since_restore: 2600000
  timesteps_this_iter: 10000
  timesteps_total: 2600000
  training_iteration: 260
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4659 s, 260 iter, 2600000 ts, 258 rew

agent-1: 33.0
agent-2: 23.0
agent-3: 26.0
agent-4: 30.0
agent-5: 26.0
agent-6: 19.0
agent-7: 20.0
agent-8: 20.0
agent-9: 32.0
agent-10: 21.0
Sum Reward: 250.0
Avg Reward: 25.0
Min Reward: 19.0
Gini Coefficient 0.1112
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-42-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 375.0
  episode_reward_mean: 258.6
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 260
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.815
    dispatch_time_ms: 7.043
    learner:
      cur_lr: 0.0011868400033563375
      grad_gnorm: 1.2909791469573975
      policy_entropy: 141.36691284179688
      policy_loss: 0.6023803353309631
      var_gnorm: 48.70598220825195
      vf_explained_var: 0.9958022236824036
      vf_loss: 0.012648647651076317
    num_steps_sampled: 2610000
    num_steps_trained: 2610000
    wait_time_ms: 166.705
  iterations_since_restore: 261
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4676.875589847565
  time_this_iter_s: 17.200232982635498
  time_total_s: 4676.875589847565
  timestamp: 1593826949
  timesteps_since_restore: 2610000
  timesteps_this_iter: 10000
  timesteps_total: 2610000
  training_iteration: 261
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4676 s, 261 iter, 2610000 ts, 259 rew

agent-1: 26.0
agent-2: 27.0
agent-3: 18.0
agent-4: 20.0
agent-5: 34.0
agent-6: 14.0
agent-7: 20.0
agent-8: 14.0
agent-9: 25.0
agent-10: 23.0
Sum Reward: 221.0
Avg Reward: 22.1
Min Reward: 14.0
Gini Coefficient 0.14886877828054298
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-42-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 375.0
  episode_reward_mean: 258.42
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 261
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.722
    dispatch_time_ms: 6.442
    learner:
      cur_lr: 0.0011861739913001657
      grad_gnorm: 5.375422477722168
      policy_entropy: 156.25634765625
      policy_loss: 2.0292084217071533
      var_gnorm: 48.81386947631836
      vf_explained_var: 0.9371019005775452
      vf_loss: 0.032433826476335526
    num_steps_sampled: 2620000
    num_steps_trained: 2620000
    wait_time_ms: 172.532
  iterations_since_restore: 262
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4694.315186023712
  time_this_iter_s: 17.43959617614746
  time_total_s: 4694.315186023712
  timestamp: 1593826966
  timesteps_since_restore: 2620000
  timesteps_this_iter: 10000
  timesteps_total: 2620000
  training_iteration: 262
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4694 s, 262 iter, 2620000 ts, 258 rew

agent-1: 15.0
agent-2: 21.0
agent-3: 20.0
agent-4: 19.0
agent-5: 12.0
agent-6: 43.0
agent-7: 19.0
agent-8: 29.0
agent-9: 24.0
agent-10: 28.0
Sum Reward: 230.0
Avg Reward: 23.0
Min Reward: 12.0
Gini Coefficient 0.19043478260869565
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-43-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 375.0
  episode_reward_mean: 258.3
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 262
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.382
    dispatch_time_ms: 6.203
    learner:
      cur_lr: 0.0011855079792439938
      grad_gnorm: 3.065242290496826
      policy_entropy: 154.12454223632812
      policy_loss: 0.7732402682304382
      var_gnorm: 48.81449890136719
      vf_explained_var: -0.28849101066589355
      vf_loss: 0.005981517489999533
    num_steps_sampled: 2630000
    num_steps_trained: 2630000
    wait_time_ms: 168.666
  iterations_since_restore: 263
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4711.884199619293
  time_this_iter_s: 17.569013595581055
  time_total_s: 4711.884199619293
  timestamp: 1593826984
  timesteps_since_restore: 2630000
  timesteps_this_iter: 10000
  timesteps_total: 2630000
  training_iteration: 263
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4711 s, 263 iter, 2630000 ts, 258 rew

agent-1: 25.0
agent-2: 28.0
agent-3: 27.0
agent-4: 26.0
agent-5: 17.0
agent-6: 26.0
agent-7: 8.0
agent-8: 17.0
agent-9: 32.0
agent-10: 13.0
Sum Reward: 219.0
Avg Reward: 21.9
Min Reward: 8.0
Gini Coefficient 0.1821917808219178
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-43-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 375.0
  episode_reward_mean: 257.82
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 263
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.738
    dispatch_time_ms: 7.48
    learner:
      cur_lr: 0.0011848419671878219
      grad_gnorm: 10.927490234375
      policy_entropy: 104.2537841796875
      policy_loss: -3.851369857788086
      var_gnorm: 48.87247085571289
      vf_explained_var: 0.9120774865150452
      vf_loss: 0.17193832993507385
    num_steps_sampled: 2640000
    num_steps_trained: 2640000
    wait_time_ms: 162.254
  iterations_since_restore: 264
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4729.202846050262
  time_this_iter_s: 17.31864643096924
  time_total_s: 4729.202846050262
  timestamp: 1593827001
  timesteps_since_restore: 2640000
  timesteps_this_iter: 10000
  timesteps_total: 2640000
  training_iteration: 264
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4729 s, 264 iter, 2640000 ts, 258 rew

agent-1: 34.0
agent-2: 26.0
agent-3: 23.0
agent-4: 17.0
agent-5: 21.0
agent-6: 20.0
agent-7: 24.0
agent-8: 33.0
agent-9: 27.0
agent-10: 38.0
Sum Reward: 263.0
Avg Reward: 26.3
Min Reward: 17.0
Gini Coefficient 0.13726235741444867
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-43-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 375.0
  episode_reward_mean: 258.18
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 264
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.897
    dispatch_time_ms: 6.072
    learner:
      cur_lr: 0.00118417595513165
      grad_gnorm: 0.9269372224807739
      policy_entropy: 142.30406188964844
      policy_loss: 0.19324253499507904
      var_gnorm: 48.94551086425781
      vf_explained_var: 0.508148729801178
      vf_loss: 0.005590650252997875
    num_steps_sampled: 2650000
    num_steps_trained: 2650000
    wait_time_ms: 172.596
  iterations_since_restore: 265
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4746.713941812515
  time_this_iter_s: 17.511095762252808
  time_total_s: 4746.713941812515
  timestamp: 1593827019
  timesteps_since_restore: 2650000
  timesteps_this_iter: 10000
  timesteps_total: 2650000
  training_iteration: 265
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4746 s, 265 iter, 2650000 ts, 258 rew

agent-1: 25.0
agent-2: 13.0
agent-3: 20.0
agent-4: 33.0
agent-5: 37.0
agent-6: 42.0
agent-7: 34.0
agent-8: 20.0
agent-9: 23.0
agent-10: 26.0
Sum Reward: 273.0
Avg Reward: 27.3
Min Reward: 13.0
Gini Coefficient 0.1761904761904762
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-43-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 375.0
  episode_reward_mean: 258.44
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 265
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.579
    dispatch_time_ms: 6.677
    learner:
      cur_lr: 0.001183509943075478
      grad_gnorm: 3.7768797874450684
      policy_entropy: 146.7166290283203
      policy_loss: -1.1726206541061401
      var_gnorm: 48.99097442626953
      vf_explained_var: -0.7594788074493408
      vf_loss: 0.00868214201182127
    num_steps_sampled: 2660000
    num_steps_trained: 2660000
    wait_time_ms: 168.406
  iterations_since_restore: 266
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4763.951442480087
  time_this_iter_s: 17.23750066757202
  time_total_s: 4763.951442480087
  timestamp: 1593827036
  timesteps_since_restore: 2660000
  timesteps_this_iter: 10000
  timesteps_total: 2660000
  training_iteration: 266
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4763 s, 266 iter, 2660000 ts, 258 rew

agent-1: 22.0
agent-2: 12.0
agent-3: 27.0
agent-4: 23.0
agent-5: 25.0
agent-6: 24.0
agent-7: 23.0
agent-8: 27.0
agent-9: 29.0
agent-10: 29.0
Sum Reward: 241.0
Avg Reward: 24.1
Min Reward: 12.0
Gini Coefficient 0.0975103734439834
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-44-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 375.0
  episode_reward_mean: 258.6
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 266
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.944
    dispatch_time_ms: 7.014
    learner:
      cur_lr: 0.001182844047434628
      grad_gnorm: 8.887751579284668
      policy_entropy: 139.22048950195312
      policy_loss: -1.9845423698425293
      var_gnorm: 49.0449333190918
      vf_explained_var: 0.4936901330947876
      vf_loss: 0.40167561173439026
    num_steps_sampled: 2670000
    num_steps_trained: 2670000
    wait_time_ms: 161.312
  iterations_since_restore: 267
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4781.334975242615
  time_this_iter_s: 17.383532762527466
  time_total_s: 4781.334975242615
  timestamp: 1593827053
  timesteps_since_restore: 2670000
  timesteps_this_iter: 10000
  timesteps_total: 2670000
  training_iteration: 267
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4781 s, 267 iter, 2670000 ts, 259 rew

agent-1: 3.0
agent-2: 32.0
agent-3: 17.0
agent-4: 26.0
agent-5: 19.0
agent-6: 38.0
agent-7: 23.0
agent-8: 24.0
agent-9: 33.0
agent-10: 13.0
Sum Reward: 228.0
Avg Reward: 22.8
Min Reward: 3.0
Gini Coefficient 0.24210526315789474
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-44-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 375.0
  episode_reward_mean: 258.12
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 267
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.875
    dispatch_time_ms: 7.614
    learner:
      cur_lr: 0.0011821780353784561
      grad_gnorm: 0.9605451226234436
      policy_entropy: 177.42005920410156
      policy_loss: 0.2766890227794647
      var_gnorm: 49.10675811767578
      vf_explained_var: -1.0
      vf_loss: 0.002161760115996003
    num_steps_sampled: 2680000
    num_steps_trained: 2680000
    wait_time_ms: 162.244
  iterations_since_restore: 268
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4798.647841930389
  time_this_iter_s: 17.312866687774658
  time_total_s: 4798.647841930389
  timestamp: 1593827071
  timesteps_since_restore: 2680000
  timesteps_this_iter: 10000
  timesteps_total: 2680000
  training_iteration: 268
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4798 s, 268 iter, 2680000 ts, 258 rew

agent-1: 12.0
agent-2: 32.0
agent-3: 21.0
agent-4: 18.0
agent-5: 28.0
agent-6: 24.0
agent-7: 32.0
agent-8: 16.0
agent-9: 18.0
agent-10: 21.0
Sum Reward: 222.0
Avg Reward: 22.2
Min Reward: 12.0
Gini Coefficient 0.16216216216216217
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-44-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 375.0
  episode_reward_mean: 257.89
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 268
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.892
    dispatch_time_ms: 5.893
    learner:
      cur_lr: 0.0011815120233222842
      grad_gnorm: 2.3099782466888428
      policy_entropy: 173.76751708984375
      policy_loss: 1.0726675987243652
      var_gnorm: 49.25248718261719
      vf_explained_var: 0.331851065158844
      vf_loss: 0.011298208497464657
    num_steps_sampled: 2690000
    num_steps_trained: 2690000
    wait_time_ms: 170.225
  iterations_since_restore: 269
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4816.137150764465
  time_this_iter_s: 17.489308834075928
  time_total_s: 4816.137150764465
  timestamp: 1593827088
  timesteps_since_restore: 2690000
  timesteps_this_iter: 10000
  timesteps_total: 2690000
  training_iteration: 269
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4816 s, 269 iter, 2690000 ts, 258 rew

agent-1: 24.0
agent-2: 18.0
agent-3: 25.0
agent-4: 20.0
agent-5: 24.0
agent-6: 23.0
agent-7: 19.0
agent-8: 35.0
agent-9: 24.0
agent-10: 16.0
Sum Reward: 228.0
Avg Reward: 22.8
Min Reward: 16.0
Gini Coefficient 0.11315789473684211
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-45-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 375.0
  episode_reward_mean: 258.0
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 269
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.827
    dispatch_time_ms: 8.929
    learner:
      cur_lr: 0.0011808460112661123
      grad_gnorm: 2.604205369949341
      policy_entropy: 180.71302795410156
      policy_loss: -2.2846271991729736
      var_gnorm: 49.22365188598633
      vf_explained_var: -1.0
      vf_loss: 0.004369079135358334
    num_steps_sampled: 2700000
    num_steps_trained: 2700000
    wait_time_ms: 156.417
  iterations_since_restore: 270
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4833.350751399994
  time_this_iter_s: 17.213600635528564
  time_total_s: 4833.350751399994
  timestamp: 1593827106
  timesteps_since_restore: 2700000
  timesteps_this_iter: 10000
  timesteps_total: 2700000
  training_iteration: 270
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4833 s, 270 iter, 2700000 ts, 258 rew

agent-1: 22.0
agent-2: 18.0
agent-3: 18.0
agent-4: 25.0
agent-5: 20.0
agent-6: 22.0
agent-7: 25.0
agent-8: 26.0
agent-9: 24.0
agent-10: 20.0
Sum Reward: 220.0
Avg Reward: 22.0
Min Reward: 18.0
Gini Coefficient 0.07181818181818182
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-45-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 375.0
  episode_reward_mean: 257.68
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 270
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.127
    dispatch_time_ms: 6.3
    learner:
      cur_lr: 0.0011801799992099404
      grad_gnorm: 2.328639030456543
      policy_entropy: 173.32626342773438
      policy_loss: 0.23045122623443604
      var_gnorm: 49.32049560546875
      vf_explained_var: -1.0
      vf_loss: 0.019922321662306786
    num_steps_sampled: 2710000
    num_steps_trained: 2710000
    wait_time_ms: 169.71
  iterations_since_restore: 271
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4850.849322080612
  time_this_iter_s: 17.498570680618286
  time_total_s: 4850.849322080612
  timestamp: 1593827123
  timesteps_since_restore: 2710000
  timesteps_this_iter: 10000
  timesteps_total: 2710000
  training_iteration: 271
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4850 s, 271 iter, 2710000 ts, 258 rew

agent-1: 27.0
agent-2: 17.0
agent-3: 12.0
agent-4: 31.0
agent-5: 28.0
agent-6: 17.0
agent-7: 26.0
agent-8: 9.0
agent-9: 22.0
agent-10: 29.0
Sum Reward: 218.0
Avg Reward: 21.8
Min Reward: 9.0
Gini Coefficient 0.18623853211009175
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-45-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 375.0
  episode_reward_mean: 256.11
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 271
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.336
    dispatch_time_ms: 6.895
    learner:
      cur_lr: 0.0011795139871537685
      grad_gnorm: 0.3107511103153229
      policy_entropy: 184.70465087890625
      policy_loss: -0.5096293687820435
      var_gnorm: 49.44237518310547
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1.1738600733224303e-05
    num_steps_sampled: 2720000
    num_steps_trained: 2720000
    wait_time_ms: 165.717
  iterations_since_restore: 272
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4868.17958855629
  time_this_iter_s: 17.33026647567749
  time_total_s: 4868.17958855629
  timestamp: 1593827140
  timesteps_since_restore: 2720000
  timesteps_this_iter: 10000
  timesteps_total: 2720000
  training_iteration: 272
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4868 s, 272 iter, 2720000 ts, 256 rew

agent-1: 15.0
agent-2: 26.0
agent-3: 24.0
agent-4: 31.0
agent-5: 21.0
agent-6: 20.0
agent-7: 18.0
agent-8: 19.0
agent-9: 25.0
agent-10: 23.0
Sum Reward: 222.0
Avg Reward: 22.2
Min Reward: 15.0
Gini Coefficient 0.10990990990990991
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-45-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 375.0
  episode_reward_mean: 254.81
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 272
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.859
    dispatch_time_ms: 6.17
    learner:
      cur_lr: 0.0011788479750975966
      grad_gnorm: 7.406171798706055
      policy_entropy: 117.39173889160156
      policy_loss: 1.7873958349227905
      var_gnorm: 49.47289276123047
      vf_explained_var: 0.7580137848854065
      vf_loss: 0.857633650302887
    num_steps_sampled: 2730000
    num_steps_trained: 2730000
    wait_time_ms: 167.95
  iterations_since_restore: 273
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4885.346485376358
  time_this_iter_s: 17.16689682006836
  time_total_s: 4885.346485376358
  timestamp: 1593827158
  timesteps_since_restore: 2730000
  timesteps_this_iter: 10000
  timesteps_total: 2730000
  training_iteration: 273
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4885 s, 273 iter, 2730000 ts, 255 rew

agent-1: 29.0
agent-2: 26.0
agent-3: 25.0
agent-4: 19.0
agent-5: 19.0
agent-6: 24.0
agent-7: 29.0
agent-8: 34.0
agent-9: 30.0
agent-10: 27.0
Sum Reward: 262.0
Avg Reward: 26.2
Min Reward: 19.0
Gini Coefficient 0.09541984732824428
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-46-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 375.0
  episode_reward_mean: 254.86
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 273
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.34
    dispatch_time_ms: 6.483
    learner:
      cur_lr: 0.0011781819630414248
      grad_gnorm: 39.99999237060547
      policy_entropy: 116.42962646484375
      policy_loss: -4.430022239685059
      var_gnorm: 49.59935760498047
      vf_explained_var: 0.45188063383102417
      vf_loss: 12.445554733276367
    num_steps_sampled: 2740000
    num_steps_trained: 2740000
    wait_time_ms: 162.85
  iterations_since_restore: 274
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4902.532672166824
  time_this_iter_s: 17.18618679046631
  time_total_s: 4902.532672166824
  timestamp: 1593827175
  timesteps_since_restore: 2740000
  timesteps_this_iter: 10000
  timesteps_total: 2740000
  training_iteration: 274
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4902 s, 274 iter, 2740000 ts, 255 rew

agent-1: 19.0
agent-2: 27.0
agent-3: 24.0
agent-4: 26.0
agent-5: 32.0
agent-6: 34.0
agent-7: 22.0
agent-8: 31.0
agent-9: 24.0
agent-10: 37.0
Sum Reward: 276.0
Avg Reward: 27.6
Min Reward: 19.0
Gini Coefficient 0.11159420289855072
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-46-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 375.0
  episode_reward_mean: 254.8
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 274
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.535
    dispatch_time_ms: 6.109
    learner:
      cur_lr: 0.0011775159509852529
      grad_gnorm: 27.494565963745117
      policy_entropy: 132.13462829589844
      policy_loss: 2.7557740211486816
      var_gnorm: 49.75930404663086
      vf_explained_var: 0.1862802505493164
      vf_loss: 0.13746899366378784
    num_steps_sampled: 2750000
    num_steps_trained: 2750000
    wait_time_ms: 171.978
  iterations_since_restore: 275
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4920.063272476196
  time_this_iter_s: 17.53060030937195
  time_total_s: 4920.063272476196
  timestamp: 1593827192
  timesteps_since_restore: 2750000
  timesteps_this_iter: 10000
  timesteps_total: 2750000
  training_iteration: 275
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4920 s, 275 iter, 2750000 ts, 255 rew

agent-1: 34.0
agent-2: 35.0
agent-3: 33.0
agent-4: 26.0
agent-5: 29.0
agent-6: 41.0
agent-7: 23.0
agent-8: 42.0
agent-9: 26.0
agent-10: 26.0
Sum Reward: 315.0
Avg Reward: 31.5
Min Reward: 23.0
Gini Coefficient 0.11079365079365079
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-46-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 375.0
  episode_reward_mean: 255.26
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 275
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.069
    dispatch_time_ms: 7.669
    learner:
      cur_lr: 0.0011768500553444028
      grad_gnorm: 14.874441146850586
      policy_entropy: 93.24040985107422
      policy_loss: -2.8351056575775146
      var_gnorm: 49.836769104003906
      vf_explained_var: -1.0
      vf_loss: 1.0307769775390625
    num_steps_sampled: 2760000
    num_steps_trained: 2760000
    wait_time_ms: 164.881
  iterations_since_restore: 276
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4937.376138925552
  time_this_iter_s: 17.31286644935608
  time_total_s: 4937.376138925552
  timestamp: 1593827210
  timesteps_since_restore: 2760000
  timesteps_this_iter: 10000
  timesteps_total: 2760000
  training_iteration: 276
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4937 s, 276 iter, 2760000 ts, 255 rew

agent-1: 23.0
agent-2: 14.0
agent-3: 32.0
agent-4: 24.0
agent-5: 27.0
agent-6: 28.0
agent-7: 21.0
agent-8: 19.0
agent-9: 18.0
agent-10: 25.0
Sum Reward: 231.0
Avg Reward: 23.1
Min Reward: 14.0
Gini Coefficient 0.12337662337662338
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-47-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 375.0
  episode_reward_mean: 255.06
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 276
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.219
    dispatch_time_ms: 7.185
    learner:
      cur_lr: 0.001176184043288231
      grad_gnorm: 11.799184799194336
      policy_entropy: 176.01846313476562
      policy_loss: -5.9998979568481445
      var_gnorm: 49.880435943603516
      vf_explained_var: 0.8931316137313843
      vf_loss: 0.09133799374103546
    num_steps_sampled: 2770000
    num_steps_trained: 2770000
    wait_time_ms: 161.996
  iterations_since_restore: 277
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4954.722334623337
  time_this_iter_s: 17.346195697784424
  time_total_s: 4954.722334623337
  timestamp: 1593827227
  timesteps_since_restore: 2770000
  timesteps_this_iter: 10000
  timesteps_total: 2770000
  training_iteration: 277
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4954 s, 277 iter, 2770000 ts, 255 rew

agent-1: 20.0
agent-2: 19.0
agent-3: 29.0
agent-4: 39.0
agent-5: 28.0
agent-6: 28.0
agent-7: 29.0
agent-8: 29.0
agent-9: 20.0
agent-10: 26.0
Sum Reward: 267.0
Avg Reward: 26.7
Min Reward: 19.0
Gini Coefficient 0.11123595505617978
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-47-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 375.0
  episode_reward_mean: 255.14
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 277
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.81
    dispatch_time_ms: 8.591
    learner:
      cur_lr: 0.001175518031232059
      grad_gnorm: 14.227710723876953
      policy_entropy: 138.4998779296875
      policy_loss: -5.27161979675293
      var_gnorm: 49.94797897338867
      vf_explained_var: 0.8386889100074768
      vf_loss: 0.12219700217247009
    num_steps_sampled: 2780000
    num_steps_trained: 2780000
    wait_time_ms: 171.099
  iterations_since_restore: 278
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4972.029923915863
  time_this_iter_s: 17.307589292526245
  time_total_s: 4972.029923915863
  timestamp: 1593827245
  timesteps_since_restore: 2780000
  timesteps_this_iter: 10000
  timesteps_total: 2780000
  training_iteration: 278
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4972 s, 278 iter, 2780000 ts, 255 rew

agent-1: 24.0
agent-2: 21.0
agent-3: 29.0
agent-4: 33.0
agent-5: 27.0
agent-6: 24.0
agent-7: 28.0
agent-8: 23.0
agent-9: 22.0
agent-10: 24.0
Sum Reward: 255.0
Avg Reward: 25.5
Min Reward: 21.0
Gini Coefficient 0.07490196078431373
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-47-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 375.0
  episode_reward_mean: 255.22
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 278
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.861
    dispatch_time_ms: 8.589
    learner:
      cur_lr: 0.001174852019175887
      grad_gnorm: 0.853079080581665
      policy_entropy: 159.2208709716797
      policy_loss: -0.555409848690033
      var_gnorm: 49.92009735107422
      vf_explained_var: 0.9955651760101318
      vf_loss: 0.000557722058147192
    num_steps_sampled: 2790000
    num_steps_trained: 2790000
    wait_time_ms: 163.454
  iterations_since_restore: 279
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 4989.264770269394
  time_this_iter_s: 17.234846353530884
  time_total_s: 4989.264770269394
  timestamp: 1593827262
  timesteps_since_restore: 2790000
  timesteps_this_iter: 10000
  timesteps_total: 2790000
  training_iteration: 279
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 4989 s, 279 iter, 2790000 ts, 255 rew

agent-1: 32.0
agent-2: 29.0
agent-3: 25.0
agent-4: 26.0
agent-5: 17.0
agent-6: 23.0
agent-7: 15.0
agent-8: 28.0
agent-9: 29.0
agent-10: 34.0
Sum Reward: 258.0
Avg Reward: 25.8
Min Reward: 15.0
Gini Coefficient 0.12403100775193798
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-47-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 375.0
  episode_reward_mean: 254.99
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 279
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.375
    dispatch_time_ms: 8.239
    learner:
      cur_lr: 0.0011741860071197152
      grad_gnorm: 2.0055935382843018
      policy_entropy: 150.25909423828125
      policy_loss: -2.160593271255493
      var_gnorm: 50.00017547607422
      vf_explained_var: 0.7509270310401917
      vf_loss: 0.0015678692143410444
    num_steps_sampled: 2800000
    num_steps_trained: 2800000
    wait_time_ms: 192.507
  iterations_since_restore: 280
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5006.919934988022
  time_this_iter_s: 17.65516471862793
  time_total_s: 5006.919934988022
  timestamp: 1593827279
  timesteps_since_restore: 2800000
  timesteps_this_iter: 10000
  timesteps_total: 2800000
  training_iteration: 280
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5006 s, 280 iter, 2800000 ts, 255 rew

agent-1: 15.0
agent-2: 21.0
agent-3: 27.0
agent-4: 26.0
agent-5: 33.0
agent-6: 20.0
agent-7: 38.0
agent-8: 26.0
agent-9: 18.0
agent-10: 41.0
Sum Reward: 265.0
Avg Reward: 26.5
Min Reward: 15.0
Gini Coefficient 0.17245283018867924
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-48-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 375.0
  episode_reward_mean: 254.67
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 280
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.549
    dispatch_time_ms: 6.477
    learner:
      cur_lr: 0.0011735199950635433
      grad_gnorm: 3.4105401039123535
      policy_entropy: 144.89346313476562
      policy_loss: -1.017861247062683
      var_gnorm: 50.05356216430664
      vf_explained_var: 2.6404857635498047e-05
      vf_loss: 0.006637925747781992
    num_steps_sampled: 2810000
    num_steps_trained: 2810000
    wait_time_ms: 157.531
  iterations_since_restore: 281
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5024.123499393463
  time_this_iter_s: 17.203564405441284
  time_total_s: 5024.123499393463
  timestamp: 1593827297
  timesteps_since_restore: 2810000
  timesteps_this_iter: 10000
  timesteps_total: 2810000
  training_iteration: 281
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5024 s, 281 iter, 2810000 ts, 255 rew

agent-1: 31.0
agent-2: 27.0
agent-3: 19.0
agent-4: 19.0
agent-5: 21.0
agent-6: 31.0
agent-7: 33.0
agent-8: 29.0
agent-9: 30.0
agent-10: 17.0
Sum Reward: 257.0
Avg Reward: 25.7
Min Reward: 17.0
Gini Coefficient 0.12334630350194553
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-48-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 375.0
  episode_reward_mean: 254.49
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 281
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.716
    dispatch_time_ms: 5.281
    learner:
      cur_lr: 0.0011728539830073714
      grad_gnorm: 2.9412145614624023
      policy_entropy: 141.4008331298828
      policy_loss: -1.106056809425354
      var_gnorm: 50.16464614868164
      vf_explained_var: 0.9790481328964233
      vf_loss: 0.005488032940775156
    num_steps_sampled: 2820000
    num_steps_trained: 2820000
    wait_time_ms: 157.299
  iterations_since_restore: 282
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5041.366858005524
  time_this_iter_s: 17.243358612060547
  time_total_s: 5041.366858005524
  timestamp: 1593827314
  timesteps_since_restore: 2820000
  timesteps_this_iter: 10000
  timesteps_total: 2820000
  training_iteration: 282
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5041 s, 282 iter, 2820000 ts, 254 rew

agent-1: 32.0
agent-2: 39.0
agent-3: 24.0
agent-4: 45.0
agent-5: 38.0
agent-6: 34.0
agent-7: 21.0
agent-8: 26.0
agent-9: 27.0
agent-10: 39.0
Sum Reward: 325.0
Avg Reward: 32.5
Min Reward: 21.0
Gini Coefficient 0.12953846153846155
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-48-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 375.0
  episode_reward_mean: 255.1
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 282
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.657
    dispatch_time_ms: 6.874
    learner:
      cur_lr: 0.0011721879709511995
      grad_gnorm: 10.2161865234375
      policy_entropy: 124.41901397705078
      policy_loss: -5.087655067443848
      var_gnorm: 50.29828643798828
      vf_explained_var: 0.9519966244697571
      vf_loss: 0.17420810461044312
    num_steps_sampled: 2830000
    num_steps_trained: 2830000
    wait_time_ms: 168.993
  iterations_since_restore: 283
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5058.476726293564
  time_this_iter_s: 17.10986828804016
  time_total_s: 5058.476726293564
  timestamp: 1593827331
  timesteps_since_restore: 2830000
  timesteps_this_iter: 10000
  timesteps_total: 2830000
  training_iteration: 283
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5058 s, 283 iter, 2830000 ts, 255 rew

agent-1: 56.0
agent-2: 38.0
agent-3: 31.0
agent-4: 44.0
agent-5: 49.0
agent-6: 43.0
agent-7: 52.0
agent-8: 42.0
agent-9: 43.0
agent-10: 39.0
Sum Reward: 437.0
Avg Reward: 43.7
Min Reward: 31.0
Gini Coefficient 0.08672768878718536
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-49-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 437.0
  episode_reward_mean: 256.83
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 283
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.758
    dispatch_time_ms: 6.969
    learner:
      cur_lr: 0.0011715219588950276
      grad_gnorm: 12.112248420715332
      policy_entropy: 102.05204010009766
      policy_loss: 0.16233566403388977
      var_gnorm: 50.42343521118164
      vf_explained_var: 0.9869445562362671
      vf_loss: 0.06654860824346542
    num_steps_sampled: 2840000
    num_steps_trained: 2840000
    wait_time_ms: 159.178
  iterations_since_restore: 284
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5075.312156915665
  time_this_iter_s: 16.83543062210083
  time_total_s: 5075.312156915665
  timestamp: 1593827348
  timesteps_since_restore: 2840000
  timesteps_this_iter: 10000
  timesteps_total: 2840000
  training_iteration: 284
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5075 s, 284 iter, 2840000 ts, 257 rew

agent-1: 47.0
agent-2: 53.0
agent-3: 55.0
agent-4: 39.0
agent-5: 55.0
agent-6: 48.0
agent-7: 49.0
agent-8: 46.0
agent-9: 39.0
agent-10: 39.0
Sum Reward: 470.0
Avg Reward: 47.0
Min Reward: 39.0
Gini Coefficient 0.07148936170212766
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-49-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 258.82
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 284
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.71
    dispatch_time_ms: 6.304
    learner:
      cur_lr: 0.0011708559468388557
      grad_gnorm: 40.000003814697266
      policy_entropy: 66.65231323242188
      policy_loss: -37.393699645996094
      var_gnorm: 50.430137634277344
      vf_explained_var: 0.24212056398391724
      vf_loss: 117.14376831054688
    num_steps_sampled: 2850000
    num_steps_trained: 2850000
    wait_time_ms: 160.95
  iterations_since_restore: 285
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5092.3878445625305
  time_this_iter_s: 17.075687646865845
  time_total_s: 5092.3878445625305
  timestamp: 1593827365
  timesteps_since_restore: 2850000
  timesteps_this_iter: 10000
  timesteps_total: 2850000
  training_iteration: 285
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5092 s, 285 iter, 2850000 ts, 259 rew

agent-1: 42.0
agent-2: 41.0
agent-3: 32.0
agent-4: 36.0
agent-5: 30.0
agent-6: 61.0
agent-7: 44.0
agent-8: 93.0
agent-9: 14.0
agent-10: 41.0
Sum Reward: 434.0
Avg Reward: 43.4
Min Reward: 14.0
Gini Coefficient 0.23179723502304148
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-49-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 260.76
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 285
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.894
    dispatch_time_ms: 7.957
    learner:
      cur_lr: 0.0011701900511980057
      grad_gnorm: 10.643807411193848
      policy_entropy: 98.04928588867188
      policy_loss: -3.4299609661102295
      var_gnorm: 50.59391403198242
      vf_explained_var: 0.9940569400787354
      vf_loss: 0.09333229064941406
    num_steps_sampled: 2860000
    num_steps_trained: 2860000
    wait_time_ms: 163.868
  iterations_since_restore: 286
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5109.468734741211
  time_this_iter_s: 17.08089017868042
  time_total_s: 5109.468734741211
  timestamp: 1593827382
  timesteps_since_restore: 2860000
  timesteps_this_iter: 10000
  timesteps_total: 2860000
  training_iteration: 286
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5109 s, 286 iter, 2860000 ts, 261 rew

agent-1: 42.0
agent-2: 46.0
agent-3: 41.0
agent-4: 32.0
agent-5: 30.0
agent-6: 35.0
agent-7: 32.0
agent-8: 54.0
agent-9: 44.0
agent-10: 29.0
Sum Reward: 385.0
Avg Reward: 38.5
Min Reward: 29.0
Gini Coefficient 0.11246753246753247
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-49-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 261.52
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 286
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.475
    dispatch_time_ms: 6.985
    learner:
      cur_lr: 0.0011695240391418338
      grad_gnorm: 40.0000114440918
      policy_entropy: 75.99951171875
      policy_loss: 9.422268867492676
      var_gnorm: 50.62570571899414
      vf_explained_var: 0.6279308795928955
      vf_loss: 119.84283447265625
    num_steps_sampled: 2870000
    num_steps_trained: 2870000
    wait_time_ms: 161.856
  iterations_since_restore: 287
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5126.650037050247
  time_this_iter_s: 17.181302309036255
  time_total_s: 5126.650037050247
  timestamp: 1593827399
  timesteps_since_restore: 2870000
  timesteps_this_iter: 10000
  timesteps_total: 2870000
  training_iteration: 287
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5126 s, 287 iter, 2870000 ts, 262 rew

agent-1: 36.0
agent-2: 61.0
agent-3: 47.0
agent-4: 25.0
agent-5: 28.0
agent-6: 28.0
agent-7: 44.0
agent-8: 56.0
agent-9: 52.0
agent-10: 33.0
Sum Reward: 410.0
Avg Reward: 41.0
Min Reward: 25.0
Gini Coefficient 0.16829268292682928
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-50-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 261.87
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 287
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.748
    dispatch_time_ms: 7.28
    learner:
      cur_lr: 0.0011688580270856619
      grad_gnorm: 40.0
      policy_entropy: 48.03105163574219
      policy_loss: 14.990225791931152
      var_gnorm: 50.687007904052734
      vf_explained_var: 0.16859287023544312
      vf_loss: 38.005859375
    num_steps_sampled: 2880000
    num_steps_trained: 2880000
    wait_time_ms: 158.165
  iterations_since_restore: 288
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5143.696378231049
  time_this_iter_s: 17.04634118080139
  time_total_s: 5143.696378231049
  timestamp: 1593827417
  timesteps_since_restore: 2880000
  timesteps_this_iter: 10000
  timesteps_total: 2880000
  training_iteration: 288
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5143 s, 288 iter, 2880000 ts, 262 rew

agent-1: 36.0
agent-2: 32.0
agent-3: 32.0
agent-4: 41.0
agent-5: 40.0
agent-6: 21.0
agent-7: 27.0
agent-8: 6.0
agent-9: 45.0
agent-10: 31.0
Sum Reward: 311.0
Avg Reward: 31.1
Min Reward: 6.0
Gini Coefficient 0.18360128617363344
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-50-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 261.68
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 288
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.928
    dispatch_time_ms: 6.79
    learner:
      cur_lr: 0.00116819201502949
      grad_gnorm: 2.7067275047302246
      policy_entropy: 133.27120971679688
      policy_loss: 0.4691866636276245
      var_gnorm: 50.69112014770508
      vf_explained_var: -1.0
      vf_loss: 0.03222865238785744
    num_steps_sampled: 2890000
    num_steps_trained: 2890000
    wait_time_ms: 162.141
  iterations_since_restore: 289
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5161.04757809639
  time_this_iter_s: 17.351199865341187
  time_total_s: 5161.04757809639
  timestamp: 1593827434
  timesteps_since_restore: 2890000
  timesteps_this_iter: 10000
  timesteps_total: 2890000
  training_iteration: 289
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5161 s, 289 iter, 2890000 ts, 262 rew

agent-1: 21.0
agent-2: 52.0
agent-3: 41.0
agent-4: 36.0
agent-5: 31.0
agent-6: 30.0
agent-7: 37.0
agent-8: 38.0
agent-9: 53.0
agent-10: 64.0
Sum Reward: 403.0
Avg Reward: 40.3
Min Reward: 21.0
Gini Coefficient 0.16600496277915633
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-50-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 262.71
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 289
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.891
    dispatch_time_ms: 6.488
    learner:
      cur_lr: 0.001167526002973318
      grad_gnorm: 40.0000114440918
      policy_entropy: 90.00102996826172
      policy_loss: 1.9247453212738037
      var_gnorm: 50.79490280151367
      vf_explained_var: 0.3988601565361023
      vf_loss: 22.861915588378906
    num_steps_sampled: 2900000
    num_steps_trained: 2900000
    wait_time_ms: 168.353
  iterations_since_restore: 290
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5178.400463104248
  time_this_iter_s: 17.352885007858276
  time_total_s: 5178.400463104248
  timestamp: 1593827451
  timesteps_since_restore: 2900000
  timesteps_this_iter: 10000
  timesteps_total: 2900000
  training_iteration: 290
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5178 s, 290 iter, 2900000 ts, 263 rew

agent-1: 24.0
agent-2: 24.0
agent-3: 34.0
agent-4: 42.0
agent-5: 26.0
agent-6: 29.0
agent-7: 32.0
agent-8: 20.0
agent-9: 27.0
agent-10: 21.0
Sum Reward: 279.0
Avg Reward: 27.9
Min Reward: 20.0
Gini Coefficient 0.12365591397849462
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-51-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 263.02
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 290
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.492
    dispatch_time_ms: 6.584
    learner:
      cur_lr: 0.0011668599909171462
      grad_gnorm: 3.866377592086792
      policy_entropy: 159.21363830566406
      policy_loss: -1.5630502700805664
      var_gnorm: 50.85276412963867
      vf_explained_var: -8.344650268554688e-07
      vf_loss: 0.008345155976712704
    num_steps_sampled: 2910000
    num_steps_trained: 2910000
    wait_time_ms: 164.373
  iterations_since_restore: 291
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5195.8499920368195
  time_this_iter_s: 17.44952893257141
  time_total_s: 5195.8499920368195
  timestamp: 1593827469
  timesteps_since_restore: 2910000
  timesteps_this_iter: 10000
  timesteps_total: 2910000
  training_iteration: 291
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5195 s, 291 iter, 2910000 ts, 263 rew

agent-1: 23.0
agent-2: 37.0
agent-3: 18.0
agent-4: 31.0
agent-5: 14.0
agent-6: 22.0
agent-7: 39.0
agent-8: 24.0
agent-9: 37.0
agent-10: 27.0
Sum Reward: 272.0
Avg Reward: 27.2
Min Reward: 14.0
Gini Coefficient 0.16911764705882354
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-51-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 262.86
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 291
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.562
    dispatch_time_ms: 6.584
    learner:
      cur_lr: 0.0011661939788609743
      grad_gnorm: 8.191143989562988
      policy_entropy: 154.7459259033203
      policy_loss: -2.5153427124023438
      var_gnorm: 50.9031867980957
      vf_explained_var: -0.32309699058532715
      vf_loss: 0.008009587414562702
    num_steps_sampled: 2920000
    num_steps_trained: 2920000
    wait_time_ms: 170.581
  iterations_since_restore: 292
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5213.252932310104
  time_this_iter_s: 17.402940273284912
  time_total_s: 5213.252932310104
  timestamp: 1593827486
  timesteps_since_restore: 2920000
  timesteps_this_iter: 10000
  timesteps_total: 2920000
  training_iteration: 292
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5213 s, 292 iter, 2920000 ts, 263 rew

agent-1: 29.0
agent-2: 20.0
agent-3: 15.0
agent-4: 33.0
agent-5: 21.0
agent-6: 38.0
agent-7: 20.0
agent-8: 30.0
agent-9: 31.0
agent-10: 20.0
Sum Reward: 257.0
Avg Reward: 25.7
Min Reward: 15.0
Gini Coefficient 0.15214007782101166
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-51-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 263.02
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 292
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.726
    dispatch_time_ms: 6.657
    learner:
      cur_lr: 0.0011655279668048024
      grad_gnorm: 0.8659225106239319
      policy_entropy: 161.92340087890625
      policy_loss: 0.039477623999118805
      var_gnorm: 50.904117584228516
      vf_explained_var: 0.7591127753257751
      vf_loss: 0.000849032832775265
    num_steps_sampled: 2930000
    num_steps_trained: 2930000
    wait_time_ms: 161.691
  iterations_since_restore: 293
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5230.601879119873
  time_this_iter_s: 17.348946809768677
  time_total_s: 5230.601879119873
  timestamp: 1593827504
  timesteps_since_restore: 2930000
  timesteps_this_iter: 10000
  timesteps_total: 2930000
  training_iteration: 293
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5230 s, 293 iter, 2930000 ts, 263 rew

agent-1: 20.0
agent-2: 26.0
agent-3: 26.0
agent-4: 24.0
agent-5: 27.0
agent-6: 26.0
agent-7: 42.0
agent-8: 21.0
agent-9: 30.0
agent-10: 28.0
Sum Reward: 270.0
Avg Reward: 27.0
Min Reward: 20.0
Gini Coefficient 0.10518518518518519
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-52-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 263.1
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 293
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.625
    dispatch_time_ms: 8.713
    learner:
      cur_lr: 0.0011648619547486305
      grad_gnorm: 1.984812617301941
      policy_entropy: 149.95355224609375
      policy_loss: -0.9095749855041504
      var_gnorm: 50.88080978393555
      vf_explained_var: 0.6769840717315674
      vf_loss: 0.0041427286341786385
    num_steps_sampled: 2940000
    num_steps_trained: 2940000
    wait_time_ms: 163.922
  iterations_since_restore: 294
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5248.104616165161
  time_this_iter_s: 17.502737045288086
  time_total_s: 5248.104616165161
  timestamp: 1593827521
  timesteps_since_restore: 2940000
  timesteps_this_iter: 10000
  timesteps_total: 2940000
  training_iteration: 294
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5248 s, 294 iter, 2940000 ts, 263 rew

agent-1: 21.0
agent-2: 34.0
agent-3: 30.0
agent-4: 28.0
agent-5: 26.0
agent-6: 27.0
agent-7: 26.0
agent-8: 28.0
agent-9: 27.0
agent-10: 31.0
Sum Reward: 278.0
Avg Reward: 27.8
Min Reward: 21.0
Gini Coefficient 0.06330935251798561
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-52-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 263.55
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 294
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.764
    dispatch_time_ms: 6.125
    learner:
      cur_lr: 0.0011641959426924586
      grad_gnorm: 0.21687518060207367
      policy_entropy: 160.73818969726562
      policy_loss: -0.03503216430544853
      var_gnorm: 50.92405700683594
      vf_explained_var: -1.0
      vf_loss: 0.00045627591316588223
    num_steps_sampled: 2950000
    num_steps_trained: 2950000
    wait_time_ms: 169.538
  iterations_since_restore: 295
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5265.485897541046
  time_this_iter_s: 17.38128137588501
  time_total_s: 5265.485897541046
  timestamp: 1593827539
  timesteps_since_restore: 2950000
  timesteps_this_iter: 10000
  timesteps_total: 2950000
  training_iteration: 295
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5265 s, 295 iter, 2950000 ts, 264 rew

agent-1: 27.0
agent-2: 23.0
agent-3: 25.0
agent-4: 20.0
agent-5: 21.0
agent-6: 25.0
agent-7: 26.0
agent-8: 24.0
agent-9: 30.0
agent-10: 27.0
Sum Reward: 248.0
Avg Reward: 24.8
Min Reward: 20.0
Gini Coefficient 0.06370967741935483
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-52-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 263.83
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 295
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.629
    dispatch_time_ms: 5.662
    learner:
      cur_lr: 0.0011635300470516086
      grad_gnorm: 3.634749412536621
      policy_entropy: 152.969482421875
      policy_loss: 1.7705119848251343
      var_gnorm: 50.99830627441406
      vf_explained_var: 0.8296031355857849
      vf_loss: 0.007690859958529472
    num_steps_sampled: 2960000
    num_steps_trained: 2960000
    wait_time_ms: 164.47
  iterations_since_restore: 296
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5282.858562469482
  time_this_iter_s: 17.37266492843628
  time_total_s: 5282.858562469482
  timestamp: 1593827556
  timesteps_since_restore: 2960000
  timesteps_this_iter: 10000
  timesteps_total: 2960000
  training_iteration: 296
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5282 s, 296 iter, 2960000 ts, 264 rew

agent-1: 28.0
agent-2: 23.0
agent-3: 29.0
agent-4: 25.0
agent-5: 14.0
agent-6: 32.0
agent-7: 27.0
agent-8: 27.0
agent-9: 28.0
agent-10: 29.0
Sum Reward: 262.0
Avg Reward: 26.2
Min Reward: 14.0
Gini Coefficient 0.08702290076335878
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-52-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 264.34
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 296
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.037
    dispatch_time_ms: 5.739
    learner:
      cur_lr: 0.0011628640349954367
      grad_gnorm: 40.0
      policy_entropy: 131.2008514404297
      policy_loss: 3.6279964447021484
      var_gnorm: 51.03171157836914
      vf_explained_var: 0.35972243547439575
      vf_loss: 17.15179443359375
    num_steps_sampled: 2970000
    num_steps_trained: 2970000
    wait_time_ms: 166.606
  iterations_since_restore: 297
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5300.282506227493
  time_this_iter_s: 17.423943758010864
  time_total_s: 5300.282506227493
  timestamp: 1593827574
  timesteps_since_restore: 2970000
  timesteps_this_iter: 10000
  timesteps_total: 2970000
  training_iteration: 297
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5300 s, 297 iter, 2970000 ts, 264 rew

agent-1: 28.0
agent-2: 29.0
agent-3: 19.0
agent-4: 20.0
agent-5: 19.0
agent-6: 15.0
agent-7: 18.0
agent-8: 25.0
agent-9: 32.0
agent-10: 23.0
Sum Reward: 228.0
Avg Reward: 22.8
Min Reward: 15.0
Gini Coefficient 0.12982456140350876
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-53-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 264.54
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 297
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.239
    dispatch_time_ms: 7.724
    learner:
      cur_lr: 0.0011621980229392648
      grad_gnorm: 5.438975811004639
      policy_entropy: 145.2890167236328
      policy_loss: -2.9092493057250977
      var_gnorm: 51.09269332885742
      vf_explained_var: -1.0
      vf_loss: 0.051321133971214294
    num_steps_sampled: 2980000
    num_steps_trained: 2980000
    wait_time_ms: 162.437
  iterations_since_restore: 298
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5320.848546743393
  time_this_iter_s: 20.566040515899658
  time_total_s: 5320.848546743393
  timestamp: 1593827594
  timesteps_since_restore: 2980000
  timesteps_this_iter: 10000
  timesteps_total: 2980000
  training_iteration: 298
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5320 s, 298 iter, 2980000 ts, 265 rew

agent-1: 28.0
agent-2: 18.0
agent-3: 19.0
agent-4: 25.0
agent-5: 40.0
agent-6: 25.0
agent-7: 21.0
agent-8: 16.0
agent-9: 21.0
agent-10: 25.0
Sum Reward: 238.0
Avg Reward: 23.8
Min Reward: 16.0
Gini Coefficient 0.13949579831932774
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-53-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 264.66
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 298
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 4.049
    dispatch_time_ms: 5.422
    learner:
      cur_lr: 0.0011615320108830929
      grad_gnorm: 39.999996185302734
      policy_entropy: 141.3164520263672
      policy_loss: -3.3197693824768066
      var_gnorm: 51.08006286621094
      vf_explained_var: 0.5714256763458252
      vf_loss: 7.049397945404053
    num_steps_sampled: 2990000
    num_steps_trained: 2990000
    wait_time_ms: 165.085
  iterations_since_restore: 299
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5338.313336849213
  time_this_iter_s: 17.464790105819702
  time_total_s: 5338.313336849213
  timestamp: 1593827612
  timesteps_since_restore: 2990000
  timesteps_this_iter: 10000
  timesteps_total: 2990000
  training_iteration: 299
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5338 s, 299 iter, 2990000 ts, 265 rew

agent-1: 20.0
agent-2: 37.0
agent-3: 23.0
agent-4: 25.0
agent-5: 20.0
agent-6: 28.0
agent-7: 9.0
agent-8: 25.0
agent-9: 17.0
agent-10: 22.0
Sum Reward: 226.0
Avg Reward: 22.6
Min Reward: 9.0
Gini Coefficient 0.16371681415929204
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-53-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 264.49
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 299
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.972
    dispatch_time_ms: 6.255
    learner:
      cur_lr: 0.001160865998826921
      grad_gnorm: 2.338233232498169
      policy_entropy: 161.09164428710938
      policy_loss: -1.0287777185440063
      var_gnorm: 51.14043045043945
      vf_explained_var: -1.0
      vf_loss: 0.02748243696987629
    num_steps_sampled: 3000000
    num_steps_trained: 3000000
    wait_time_ms: 161.288
  iterations_since_restore: 300
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5355.781124591827
  time_this_iter_s: 17.467787742614746
  time_total_s: 5355.781124591827
  timestamp: 1593827629
  timesteps_since_restore: 3000000
  timesteps_this_iter: 10000
  timesteps_total: 3000000
  training_iteration: 300
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5355 s, 300 iter, 3000000 ts, 264 rew

agent-1: 19.0
agent-2: 20.0
agent-3: 23.0
agent-4: 21.0
agent-5: 22.0
agent-6: 23.0
agent-7: 23.0
agent-8: 33.0
agent-9: 21.0
agent-10: 19.0
Sum Reward: 224.0
Avg Reward: 22.4
Min Reward: 19.0
Gini Coefficient 0.07857142857142857
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-54-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 264.17
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 300
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.978
    dispatch_time_ms: 8.458
    learner:
      cur_lr: 0.001160199986770749
      grad_gnorm: 1.4401146173477173
      policy_entropy: 164.3997802734375
      policy_loss: -0.556911826133728
      var_gnorm: 51.166080474853516
      vf_explained_var: -0.018451213836669922
      vf_loss: 0.001164499670267105
    num_steps_sampled: 3010000
    num_steps_trained: 3010000
    wait_time_ms: 170.756
  iterations_since_restore: 301
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5373.1433198452
  time_this_iter_s: 17.362195253372192
  time_total_s: 5373.1433198452
  timestamp: 1593827647
  timesteps_since_restore: 3010000
  timesteps_this_iter: 10000
  timesteps_total: 3010000
  training_iteration: 301
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5373 s, 301 iter, 3010000 ts, 264 rew

agent-1: 21.0
agent-2: 21.0
agent-3: 29.0
agent-4: 27.0
agent-5: 25.0
agent-6: 24.0
agent-7: 26.0
agent-8: 10.0
agent-9: 21.0
agent-10: 23.0
Sum Reward: 227.0
Avg Reward: 22.7
Min Reward: 10.0
Gini Coefficient 0.1105726872246696
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-54-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 263.72
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 301
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.64
    dispatch_time_ms: 6.433
    learner:
      cur_lr: 0.0011595339747145772
      grad_gnorm: 4.574273109436035
      policy_entropy: 159.47293090820312
      policy_loss: -1.7688517570495605
      var_gnorm: 51.18616485595703
      vf_explained_var: -0.7232195138931274
      vf_loss: 0.017929084599018097
    num_steps_sampled: 3020000
    num_steps_trained: 3020000
    wait_time_ms: 167.33
  iterations_since_restore: 302
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5390.461934566498
  time_this_iter_s: 17.318614721298218
  time_total_s: 5390.461934566498
  timestamp: 1593827664
  timesteps_since_restore: 3020000
  timesteps_this_iter: 10000
  timesteps_total: 3020000
  training_iteration: 302
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5390 s, 302 iter, 3020000 ts, 264 rew

agent-1: 24.0
agent-2: 24.0
agent-3: 23.0
agent-4: 24.0
agent-5: 39.0
agent-6: 28.0
agent-7: 17.0
agent-8: 25.0
agent-9: 19.0
agent-10: 21.0
Sum Reward: 244.0
Avg Reward: 24.4
Min Reward: 17.0
Gini Coefficient 0.11639344262295082
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-54-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 263.35
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 302
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.746
    dispatch_time_ms: 8.588
    learner:
      cur_lr: 0.0011588679626584053
      grad_gnorm: 2.8861582279205322
      policy_entropy: 151.8809356689453
      policy_loss: 1.5446220636367798
      var_gnorm: 51.199928283691406
      vf_explained_var: 0.0001342296600341797
      vf_loss: 0.004676345270127058
    num_steps_sampled: 3030000
    num_steps_trained: 3030000
    wait_time_ms: 158.569
  iterations_since_restore: 303
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5407.9342839717865
  time_this_iter_s: 17.472349405288696
  time_total_s: 5407.9342839717865
  timestamp: 1593827681
  timesteps_since_restore: 3030000
  timesteps_this_iter: 10000
  timesteps_total: 3030000
  training_iteration: 303
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5407 s, 303 iter, 3030000 ts, 263 rew

agent-1: 22.0
agent-2: 28.0
agent-3: 22.0
agent-4: 31.0
agent-5: 31.0
agent-6: 17.0
agent-7: 24.0
agent-8: 13.0
agent-9: 17.0
agent-10: 27.0
Sum Reward: 232.0
Avg Reward: 23.2
Min Reward: 13.0
Gini Coefficient 0.14310344827586208
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-54-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 263.28
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 303
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.949
    dispatch_time_ms: 5.919
    learner:
      cur_lr: 0.0011582019506022334
      grad_gnorm: 6.925223350524902
      policy_entropy: 145.3828125
      policy_loss: -2.7885866165161133
      var_gnorm: 51.266292572021484
      vf_explained_var: -1.0
      vf_loss: 0.09244613349437714
    num_steps_sampled: 3040000
    num_steps_trained: 3040000
    wait_time_ms: 165.997
  iterations_since_restore: 304
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5425.302600622177
  time_this_iter_s: 17.368316650390625
  time_total_s: 5425.302600622177
  timestamp: 1593827699
  timesteps_since_restore: 3040000
  timesteps_this_iter: 10000
  timesteps_total: 3040000
  training_iteration: 304
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5425 s, 304 iter, 3040000 ts, 263 rew

agent-1: 18.0
agent-2: 14.0
agent-3: 30.0
agent-4: 35.0
agent-5: 22.0
agent-6: 29.0
agent-7: 27.0
agent-8: 11.0
agent-9: 23.0
agent-10: 21.0
Sum Reward: 230.0
Avg Reward: 23.0
Min Reward: 11.0
Gini Coefficient 0.17478260869565218
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-55-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 263.03
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 304
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.472
    dispatch_time_ms: 7.121
    learner:
      cur_lr: 0.0011575360549613833
      grad_gnorm: 9.48854923248291
      policy_entropy: 146.1394500732422
      policy_loss: -3.8532698154449463
      var_gnorm: 51.276397705078125
      vf_explained_var: 0.3079695701599121
      vf_loss: 0.05038287863135338
    num_steps_sampled: 3050000
    num_steps_trained: 3050000
    wait_time_ms: 166.996
  iterations_since_restore: 305
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5442.516238927841
  time_this_iter_s: 17.213638305664062
  time_total_s: 5442.516238927841
  timestamp: 1593827716
  timesteps_since_restore: 3050000
  timesteps_this_iter: 10000
  timesteps_total: 3050000
  training_iteration: 305
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5442 s, 305 iter, 3050000 ts, 263 rew

agent-1: 30.0
agent-2: 33.0
agent-3: 27.0
agent-4: 31.0
agent-5: 24.0
agent-6: 27.0
agent-7: 19.0
agent-8: 27.0
agent-9: 20.0
agent-10: 23.0
Sum Reward: 261.0
Avg Reward: 26.1
Min Reward: 19.0
Gini Coefficient 0.0946360153256705
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-55-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 263.16
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 305
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.767
    dispatch_time_ms: 5.848
    learner:
      cur_lr: 0.0011568700429052114
      grad_gnorm: 39.99999237060547
      policy_entropy: 129.4868927001953
      policy_loss: 5.669637680053711
      var_gnorm: 51.35651397705078
      vf_explained_var: -0.36228668689727783
      vf_loss: 5.520564079284668
    num_steps_sampled: 3060000
    num_steps_trained: 3060000
    wait_time_ms: 168.851
  iterations_since_restore: 306
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5459.83758020401
  time_this_iter_s: 17.321341276168823
  time_total_s: 5459.83758020401
  timestamp: 1593827733
  timesteps_since_restore: 3060000
  timesteps_this_iter: 10000
  timesteps_total: 3060000
  training_iteration: 306
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5459 s, 306 iter, 3060000 ts, 263 rew

agent-1: 10.0
agent-2: 26.0
agent-3: 42.0
agent-4: 12.0
agent-5: 39.0
agent-6: 20.0
agent-7: 39.0
agent-8: 33.0
agent-9: 36.0
agent-10: 40.0
Sum Reward: 297.0
Avg Reward: 29.7
Min Reward: 10.0
Gini Coefficient 0.20909090909090908
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-55-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 263.18
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 306
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.981
    dispatch_time_ms: 6.707
    learner:
      cur_lr: 0.0011562040308490396
      grad_gnorm: 40.000003814697266
      policy_entropy: 143.95602416992188
      policy_loss: -2.262364149093628
      var_gnorm: 51.431190490722656
      vf_explained_var: 0.7234035730361938
      vf_loss: 8.242537498474121
    num_steps_sampled: 3070000
    num_steps_trained: 3070000
    wait_time_ms: 165.178
  iterations_since_restore: 307
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5477.128415346146
  time_this_iter_s: 17.29083514213562
  time_total_s: 5477.128415346146
  timestamp: 1593827751
  timesteps_since_restore: 3070000
  timesteps_this_iter: 10000
  timesteps_total: 3070000
  training_iteration: 307
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5477 s, 307 iter, 3070000 ts, 263 rew

agent-1: 26.0
agent-2: 32.0
agent-3: 17.0
agent-4: 29.0
agent-5: 24.0
agent-6: 21.0
agent-7: 30.0
agent-8: 29.0
agent-9: 37.0
agent-10: 29.0
Sum Reward: 274.0
Avg Reward: 27.4
Min Reward: 17.0
Gini Coefficient 0.10802919708029197
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-56-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 263.62
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 307
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.895
    dispatch_time_ms: 6.128
    learner:
      cur_lr: 0.0011555380187928677
      grad_gnorm: 1.6367353200912476
      policy_entropy: 135.54318237304688
      policy_loss: -0.9218294620513916
      var_gnorm: 51.4393196105957
      vf_explained_var: 0.8594189882278442
      vf_loss: 0.0030701749492436647
    num_steps_sampled: 3080000
    num_steps_trained: 3080000
    wait_time_ms: 167.47
  iterations_since_restore: 308
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5494.530098199844
  time_this_iter_s: 17.40168285369873
  time_total_s: 5494.530098199844
  timestamp: 1593827768
  timesteps_since_restore: 3080000
  timesteps_this_iter: 10000
  timesteps_total: 3080000
  training_iteration: 308
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5494 s, 308 iter, 3080000 ts, 264 rew

agent-1: 23.0
agent-2: 37.0
agent-3: 15.0
agent-4: 35.0
agent-5: 27.0
agent-6: 17.0
agent-7: 12.0
agent-8: 38.0
agent-9: 19.0
agent-10: 24.0
Sum Reward: 247.0
Avg Reward: 24.7
Min Reward: 12.0
Gini Coefficient 0.20364372469635628
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-56-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 263.2
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 308
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.007
    dispatch_time_ms: 29.863
    learner:
      cur_lr: 0.0011548720067366958
      grad_gnorm: 39.99999237060547
      policy_entropy: 111.799072265625
      policy_loss: 13.928720474243164
      var_gnorm: 51.444095611572266
      vf_explained_var: 0.6802363395690918
      vf_loss: 9.875143051147461
    num_steps_sampled: 3090000
    num_steps_trained: 3090000
    wait_time_ms: 150.876
  iterations_since_restore: 309
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5512.555262088776
  time_this_iter_s: 18.025163888931274
  time_total_s: 5512.555262088776
  timestamp: 1593827786
  timesteps_since_restore: 3090000
  timesteps_this_iter: 10000
  timesteps_total: 3090000
  training_iteration: 309
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5512 s, 309 iter, 3090000 ts, 263 rew

agent-1: 30.0
agent-2: 19.0
agent-3: 23.0
agent-4: 26.0
agent-5: 20.0
agent-6: 24.0
agent-7: 31.0
agent-8: 23.0
agent-9: 29.0
agent-10: 26.0
Sum Reward: 251.0
Avg Reward: 25.1
Min Reward: 19.0
Gini Coefficient 0.08725099601593625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-56-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 263.1
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 309
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 4.024
    dispatch_time_ms: 36.86
    learner:
      cur_lr: 0.0011542059946805239
      grad_gnorm: 4.216225624084473
      policy_entropy: 139.85714721679688
      policy_loss: -2.3977134227752686
      var_gnorm: 51.5352783203125
      vf_explained_var: 0.012157738208770752
      vf_loss: 0.009454253129661083
    num_steps_sampled: 3100000
    num_steps_trained: 3100000
    wait_time_ms: 144.888
  iterations_since_restore: 310
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5530.864633798599
  time_this_iter_s: 18.30937170982361
  time_total_s: 5530.864633798599
  timestamp: 1593827805
  timesteps_since_restore: 3100000
  timesteps_this_iter: 10000
  timesteps_total: 3100000
  training_iteration: 310
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5530 s, 310 iter, 3100000 ts, 263 rew

agent-1: 31.0
agent-2: 28.0
agent-3: 22.0
agent-4: 39.0
agent-5: 26.0
agent-6: 24.0
agent-7: 19.0
agent-8: 26.0
agent-9: 21.0
agent-10: 21.0
Sum Reward: 257.0
Avg Reward: 25.7
Min Reward: 19.0
Gini Coefficient 0.11634241245136187
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-57-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 263.21
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 310
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.414
    dispatch_time_ms: 30.56
    learner:
      cur_lr: 0.001153539982624352
      grad_gnorm: 4.044378280639648
      policy_entropy: 138.4713592529297
      policy_loss: -1.0724691152572632
      var_gnorm: 51.53304672241211
      vf_explained_var: 0.009602189064025879
      vf_loss: 0.009307372383773327
    num_steps_sampled: 3110000
    num_steps_trained: 3110000
    wait_time_ms: 156.274
  iterations_since_restore: 311
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5549.167358636856
  time_this_iter_s: 18.302724838256836
  time_total_s: 5549.167358636856
  timestamp: 1593827823
  timesteps_since_restore: 3110000
  timesteps_this_iter: 10000
  timesteps_total: 3110000
  training_iteration: 311
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5549 s, 311 iter, 3110000 ts, 263 rew

agent-1: 28.0
agent-2: 28.0
agent-3: 22.0
agent-4: 19.0
agent-5: 29.0
agent-6: 19.0
agent-7: 22.0
agent-8: 30.0
agent-9: 27.0
agent-10: 22.0
Sum Reward: 246.0
Avg Reward: 24.6
Min Reward: 19.0
Gini Coefficient 0.09024390243902439
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-57-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 262.89
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 311
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.586
    dispatch_time_ms: 24.68
    learner:
      cur_lr: 0.00115287397056818
      grad_gnorm: 1.9352167844772339
      policy_entropy: 131.06361389160156
      policy_loss: 1.2568656206130981
      var_gnorm: 51.56929397583008
      vf_explained_var: 0.9777829647064209
      vf_loss: 0.002251796191558242
    num_steps_sampled: 3120000
    num_steps_trained: 3120000
    wait_time_ms: 158.247
  iterations_since_restore: 312
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5567.368732690811
  time_this_iter_s: 18.201374053955078
  time_total_s: 5567.368732690811
  timestamp: 1593827841
  timesteps_since_restore: 3120000
  timesteps_this_iter: 10000
  timesteps_total: 3120000
  training_iteration: 312
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5567 s, 312 iter, 3120000 ts, 263 rew

agent-1: 23.0
agent-2: 27.0
agent-3: 26.0
agent-4: 20.0
agent-5: 29.0
agent-6: 23.0
agent-7: 24.0
agent-8: 17.0
agent-9: 16.0
agent-10: 18.0
Sum Reward: 223.0
Avg Reward: 22.3
Min Reward: 16.0
Gini Coefficient 0.10717488789237668
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-57-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 262.75
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 312
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.823
    dispatch_time_ms: 47.111
    learner:
      cur_lr: 0.0011522079585120082
      grad_gnorm: 0.24247944355010986
      policy_entropy: 142.58250427246094
      policy_loss: -0.7266450524330139
      var_gnorm: 51.58202362060547
      vf_explained_var: 0.9959897398948669
      vf_loss: 7.807616930222139e-05
    num_steps_sampled: 3130000
    num_steps_trained: 3130000
    wait_time_ms: 128.601
  iterations_since_restore: 313
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5585.5481815338135
  time_this_iter_s: 18.17944884300232
  time_total_s: 5585.5481815338135
  timestamp: 1593827859
  timesteps_since_restore: 3130000
  timesteps_this_iter: 10000
  timesteps_total: 3130000
  training_iteration: 313
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5585 s, 313 iter, 3130000 ts, 263 rew

agent-1: 34.0
agent-2: 19.0
agent-3: 24.0
agent-4: 26.0
agent-5: 18.0
agent-6: 20.0
agent-7: 18.0
agent-8: 31.0
agent-9: 23.0
agent-10: 8.0
Sum Reward: 221.0
Avg Reward: 22.1
Min Reward: 8.0
Gini Coefficient 0.17330316742081447
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-57-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 262.58
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 313
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.85
    dispatch_time_ms: 36.527
    learner:
      cur_lr: 0.0011515419464558363
      grad_gnorm: 5.844829082489014
      policy_entropy: 126.13916778564453
      policy_loss: 6.521580696105957
      var_gnorm: 51.65842056274414
      vf_explained_var: 0.4950442910194397
      vf_loss: 0.01843966171145439
    num_steps_sampled: 3140000
    num_steps_trained: 3140000
    wait_time_ms: 149.75
  iterations_since_restore: 314
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5603.85754609108
  time_this_iter_s: 18.309364557266235
  time_total_s: 5603.85754609108
  timestamp: 1593827878
  timesteps_since_restore: 3140000
  timesteps_this_iter: 10000
  timesteps_total: 3140000
  training_iteration: 314
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5603 s, 314 iter, 3140000 ts, 263 rew

W0703 21:58:07.280704  7722 node_manager.cc:250] Last heartbeat was sent 1072 ms ago 
agent-1: 15.0
agent-2: 29.0
agent-3: 33.0
agent-4: 24.0
agent-5: 23.0
agent-6: 30.0
agent-7: 7.0
agent-8: 26.0
agent-9: 27.0
agent-10: 18.0
Sum Reward: 232.0
Avg Reward: 23.2
Min Reward: 7.0
Gini Coefficient 0.17586206896551723
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-58-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 262.35
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 314
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.73
    dispatch_time_ms: 6.296
    learner:
      cur_lr: 0.0011508760508149862
      grad_gnorm: 19.781465530395508
      policy_entropy: 113.55982971191406
      policy_loss: -4.562131404876709
      var_gnorm: 51.6651611328125
      vf_explained_var: -0.14583492279052734
      vf_loss: 0.7335591316223145
    num_steps_sampled: 3150000
    num_steps_trained: 3150000
    wait_time_ms: 167.233
  iterations_since_restore: 315
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5634.32265496254
  time_this_iter_s: 30.46510887145996
  time_total_s: 5634.32265496254
  timestamp: 1593827908
  timesteps_since_restore: 3150000
  timesteps_this_iter: 10000
  timesteps_total: 3150000
  training_iteration: 315
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5634 s, 315 iter, 3150000 ts, 262 rew

agent-1: 18.0
agent-2: 20.0
agent-3: 25.0
agent-4: 20.0
agent-5: 20.0
agent-6: 25.0
agent-7: 23.0
agent-8: 21.0
agent-9: 21.0
agent-10: 28.0
Sum Reward: 221.0
Avg Reward: 22.1
Min Reward: 18.0
Gini Coefficient 0.07194570135746606
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-58-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 262.06
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 315
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.906
    dispatch_time_ms: 6.048
    learner:
      cur_lr: 0.0011502100387588143
      grad_gnorm: 3.56306529045105
      policy_entropy: 164.97662353515625
      policy_loss: 1.9608418941497803
      var_gnorm: 51.76531982421875
      vf_explained_var: 0.5210994482040405
      vf_loss: 0.007020159158855677
    num_steps_sampled: 3160000
    num_steps_trained: 3160000
    wait_time_ms: 161.651
  iterations_since_restore: 316
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5651.705133199692
  time_this_iter_s: 17.3824782371521
  time_total_s: 5651.705133199692
  timestamp: 1593827926
  timesteps_since_restore: 3160000
  timesteps_this_iter: 10000
  timesteps_total: 3160000
  training_iteration: 316
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5651 s, 316 iter, 3160000 ts, 262 rew

agent-1: 18.0
agent-2: 30.0
agent-3: 18.0
agent-4: 27.0
agent-5: 18.0
agent-6: 24.0
agent-7: 26.0
agent-8: 25.0
agent-9: 19.0
agent-10: 18.0
Sum Reward: 223.0
Avg Reward: 22.3
Min Reward: 18.0
Gini Coefficient 0.10627802690582959
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-59-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 261.42
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 316
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.852
    dispatch_time_ms: 8.424
    learner:
      cur_lr: 0.0011495440267026424
      grad_gnorm: 40.0
      policy_entropy: 133.42015075683594
      policy_loss: -4.88932466506958
      var_gnorm: 51.822021484375
      vf_explained_var: -1.0
      vf_loss: 3.678272247314453
    num_steps_sampled: 3170000
    num_steps_trained: 3170000
    wait_time_ms: 165.031
  iterations_since_restore: 317
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5669.242723464966
  time_this_iter_s: 17.537590265274048
  time_total_s: 5669.242723464966
  timestamp: 1593827943
  timesteps_since_restore: 3170000
  timesteps_this_iter: 10000
  timesteps_total: 3170000
  training_iteration: 317
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5669 s, 317 iter, 3170000 ts, 261 rew

agent-1: 23.0
agent-2: 15.0
agent-3: 21.0
agent-4: 18.0
agent-5: 11.0
agent-6: 21.0
agent-7: 26.0
agent-8: 29.0
agent-9: 28.0
agent-10: 30.0
Sum Reward: 222.0
Avg Reward: 22.2
Min Reward: 11.0
Gini Coefficient 0.15135135135135136
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-59-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 261.01
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 317
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.942
    dispatch_time_ms: 6.176
    learner:
      cur_lr: 0.0011488780146464705
      grad_gnorm: 3.551788806915283
      policy_entropy: 172.20997619628906
      policy_loss: -1.2188884019851685
      var_gnorm: 51.88918685913086
      vf_explained_var: -1.0
      vf_loss: 0.07481392472982407
    num_steps_sampled: 3180000
    num_steps_trained: 3180000
    wait_time_ms: 172.765
  iterations_since_restore: 318
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5686.527467489243
  time_this_iter_s: 17.284744024276733
  time_total_s: 5686.527467489243
  timestamp: 1593827961
  timesteps_since_restore: 3180000
  timesteps_this_iter: 10000
  timesteps_total: 3180000
  training_iteration: 318
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5686 s, 318 iter, 3180000 ts, 261 rew

agent-1: 18.0
agent-2: 21.0
agent-3: 21.0
agent-4: 21.0
agent-5: 28.0
agent-6: 18.0
agent-7: 25.0
agent-8: 19.0
agent-9: 18.0
agent-10: 34.0
Sum Reward: 223.0
Avg Reward: 22.3
Min Reward: 18.0
Gini Coefficient 0.11434977578475336
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-59-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 260.7
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 318
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.879
    dispatch_time_ms: 6.004
    learner:
      cur_lr: 0.0011482120025902987
      grad_gnorm: 21.56400489807129
      policy_entropy: 124.77410888671875
      policy_loss: -5.160508155822754
      var_gnorm: 51.896095275878906
      vf_explained_var: 0.42911815643310547
      vf_loss: 8.468923568725586
    num_steps_sampled: 3190000
    num_steps_trained: 3190000
    wait_time_ms: 169.619
  iterations_since_restore: 319
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5703.9515645504
  time_this_iter_s: 17.424097061157227
  time_total_s: 5703.9515645504
  timestamp: 1593827978
  timesteps_since_restore: 3190000
  timesteps_this_iter: 10000
  timesteps_total: 3190000
  training_iteration: 319
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5703 s, 319 iter, 3190000 ts, 261 rew

agent-1: 20.0
agent-2: 25.0
agent-3: 24.0
agent-4: 23.0
agent-5: 25.0
agent-6: 22.0
agent-7: 31.0
agent-8: 16.0
agent-9: 20.0
agent-10: 13.0
Sum Reward: 219.0
Avg Reward: 21.9
Min Reward: 13.0
Gini Coefficient 0.12009132420091324
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_21-59-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 260.61
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 319
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.799
    dispatch_time_ms: 8.08
    learner:
      cur_lr: 0.0011475459905341268
      grad_gnorm: 4.226749897003174
      policy_entropy: 149.54241943359375
      policy_loss: -1.6652544736862183
      var_gnorm: 51.91648864746094
      vf_explained_var: 0.5867096185684204
      vf_loss: 0.010410994291305542
    num_steps_sampled: 3200000
    num_steps_trained: 3200000
    wait_time_ms: 164.423
  iterations_since_restore: 320
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5721.399235010147
  time_this_iter_s: 17.447670459747314
  time_total_s: 5721.399235010147
  timestamp: 1593827996
  timesteps_since_restore: 3200000
  timesteps_this_iter: 10000
  timesteps_total: 3200000
  training_iteration: 320
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5721 s, 320 iter, 3200000 ts, 261 rew

agent-1: 15.0
agent-2: 23.0
agent-3: 31.0
agent-4: 20.0
agent-5: 34.0
agent-6: 33.0
agent-7: 16.0
agent-8: 13.0
agent-9: 39.0
agent-10: 11.0
Sum Reward: 235.0
Avg Reward: 23.5
Min Reward: 11.0
Gini Coefficient 0.22851063829787235
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-00-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 260.4
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 320
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.045
    dispatch_time_ms: 6.687
    learner:
      cur_lr: 0.0011468799784779549
      grad_gnorm: 0.5366111993789673
      policy_entropy: 163.2952423095703
      policy_loss: 0.260363906621933
      var_gnorm: 52.01881790161133
      vf_explained_var: 0.7763186097145081
      vf_loss: 0.00016613377374596894
    num_steps_sampled: 3210000
    num_steps_trained: 3210000
    wait_time_ms: 171.733
  iterations_since_restore: 321
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5738.72180724144
  time_this_iter_s: 17.322572231292725
  time_total_s: 5738.72180724144
  timestamp: 1593828013
  timesteps_since_restore: 3210000
  timesteps_this_iter: 10000
  timesteps_total: 3210000
  training_iteration: 321
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5738 s, 321 iter, 3210000 ts, 260 rew

agent-1: 19.0
agent-2: 20.0
agent-3: 29.0
agent-4: 35.0
agent-5: 13.0
agent-6: 31.0
agent-7: 23.0
agent-8: 30.0
agent-9: 28.0
agent-10: 15.0
Sum Reward: 243.0
Avg Reward: 24.3
Min Reward: 13.0
Gini Coefficient 0.1633744855967078
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-00-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 260.67
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 321
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.274
    dispatch_time_ms: 16.34
    learner:
      cur_lr: 0.001146213966421783
      grad_gnorm: 17.5532169342041
      policy_entropy: 133.22630310058594
      policy_loss: -6.264842510223389
      var_gnorm: 52.16041564941406
      vf_explained_var: -0.1472562551498413
      vf_loss: 2.217482089996338
    num_steps_sampled: 3220000
    num_steps_trained: 3220000
    wait_time_ms: 162.813
  iterations_since_restore: 322
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5756.170276403427
  time_this_iter_s: 17.448469161987305
  time_total_s: 5756.170276403427
  timestamp: 1593828030
  timesteps_since_restore: 3220000
  timesteps_this_iter: 10000
  timesteps_total: 3220000
  training_iteration: 322
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5756 s, 322 iter, 3220000 ts, 261 rew

agent-1: 27.0
agent-2: 20.0
agent-3: 12.0
agent-4: 33.0
agent-5: 23.0
agent-6: 27.0
agent-7: 25.0
agent-8: 21.0
agent-9: 36.0
agent-10: 14.0
Sum Reward: 238.0
Avg Reward: 23.8
Min Reward: 12.0
Gini Coefficient 0.16974789915966387
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-00-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 260.19
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 322
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.356
    dispatch_time_ms: 41.753
    learner:
      cur_lr: 0.001145547954365611
      grad_gnorm: 5.786659240722656
      policy_entropy: 136.70828247070312
      policy_loss: -0.8713318109512329
      var_gnorm: 52.18284606933594
      vf_explained_var: 0.25345081090927124
      vf_loss: 0.01997675746679306
    num_steps_sampled: 3230000
    num_steps_trained: 3230000
    wait_time_ms: 145.507
  iterations_since_restore: 323
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5774.397024393082
  time_this_iter_s: 18.22674798965454
  time_total_s: 5774.397024393082
  timestamp: 1593828049
  timesteps_since_restore: 3230000
  timesteps_this_iter: 10000
  timesteps_total: 3230000
  training_iteration: 323
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5774 s, 323 iter, 3230000 ts, 260 rew

agent-1: 49.0
agent-2: 16.0
agent-3: 31.0
agent-4: 30.0
agent-5: 26.0
agent-6: 33.0
agent-7: 35.0
agent-8: 24.0
agent-9: 20.0
agent-10: 17.0
Sum Reward: 281.0
Avg Reward: 28.1
Min Reward: 16.0
Gini Coefficient 0.18256227758007118
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-01-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 260.38
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 323
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.834
    dispatch_time_ms: 28.447
    learner:
      cur_lr: 0.0011448819423094392
      grad_gnorm: 0.8611171841621399
      policy_entropy: 111.85275268554688
      policy_loss: 0.8501688241958618
      var_gnorm: 52.203636169433594
      vf_explained_var: 0.9831741452217102
      vf_loss: 0.00014569018094334751
    num_steps_sampled: 3240000
    num_steps_trained: 3240000
    wait_time_ms: 158.409
  iterations_since_restore: 324
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5792.349187612534
  time_this_iter_s: 17.952163219451904
  time_total_s: 5792.349187612534
  timestamp: 1593828067
  timesteps_since_restore: 3240000
  timesteps_this_iter: 10000
  timesteps_total: 3240000
  training_iteration: 324
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5792 s, 324 iter, 3240000 ts, 260 rew

agent-1: 31.0
agent-2: 31.0
agent-3: 35.0
agent-4: 31.0
agent-5: 19.0
agent-6: 31.0
agent-7: 20.0
agent-8: 26.0
agent-9: 30.0
agent-10: 32.0
Sum Reward: 286.0
Avg Reward: 28.6
Min Reward: 19.0
Gini Coefficient 0.08951048951048951
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-01-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 260.78
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 324
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.943
    dispatch_time_ms: 28.341
    learner:
      cur_lr: 0.0011442160466685891
      grad_gnorm: 2.8420441150665283
      policy_entropy: 112.37382507324219
      policy_loss: -0.08381446450948715
      var_gnorm: 52.245079040527344
      vf_explained_var: 0.6087650060653687
      vf_loss: 0.004812913481146097
    num_steps_sampled: 3250000
    num_steps_trained: 3250000
    wait_time_ms: 155.075
  iterations_since_restore: 325
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5810.482080936432
  time_this_iter_s: 18.132893323898315
  time_total_s: 5810.482080936432
  timestamp: 1593828085
  timesteps_since_restore: 3250000
  timesteps_this_iter: 10000
  timesteps_total: 3250000
  training_iteration: 325
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5810 s, 325 iter, 3250000 ts, 261 rew

agent-1: 20.0
agent-2: 19.0
agent-3: 20.0
agent-4: 25.0
agent-5: 18.0
agent-6: 20.0
agent-7: 13.0
agent-8: 30.0
agent-9: 21.0
agent-10: 24.0
Sum Reward: 210.0
Avg Reward: 21.0
Min Reward: 13.0
Gini Coefficient 0.10952380952380952
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-01-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 260.38
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 325
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 4.272
    dispatch_time_ms: 32.431
    learner:
      cur_lr: 0.0011435500346124172
      grad_gnorm: 39.99999237060547
      policy_entropy: 114.86683654785156
      policy_loss: 6.564060688018799
      var_gnorm: 52.304073333740234
      vf_explained_var: 0.6706892251968384
      vf_loss: 5.494955062866211
    num_steps_sampled: 3260000
    num_steps_trained: 3260000
    wait_time_ms: 146.706
  iterations_since_restore: 326
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5828.462492465973
  time_this_iter_s: 17.980411529541016
  time_total_s: 5828.462492465973
  timestamp: 1593828103
  timesteps_since_restore: 3260000
  timesteps_this_iter: 10000
  timesteps_total: 3260000
  training_iteration: 326
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5828 s, 326 iter, 3260000 ts, 260 rew

agent-1: 22.0
agent-2: 26.0
agent-3: 17.0
agent-4: 27.0
agent-5: 11.0
agent-6: 26.0
agent-7: 24.0
agent-8: 23.0
agent-9: 26.0
agent-10: 25.0
Sum Reward: 227.0
Avg Reward: 22.7
Min Reward: 11.0
Gini Coefficient 0.10440528634361233
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-02-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 260.15
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 326
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.896
    dispatch_time_ms: 5.619
    learner:
      cur_lr: 0.0011428840225562453
      grad_gnorm: 40.0
      policy_entropy: 110.7093276977539
      policy_loss: 17.061250686645508
      var_gnorm: 52.35808181762695
      vf_explained_var: 0.5380953550338745
      vf_loss: 11.751420974731445
    num_steps_sampled: 3270000
    num_steps_trained: 3270000
    wait_time_ms: 168.818
  iterations_since_restore: 327
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5846.120621442795
  time_this_iter_s: 17.6581289768219
  time_total_s: 5846.120621442795
  timestamp: 1593828121
  timesteps_since_restore: 3270000
  timesteps_this_iter: 10000
  timesteps_total: 3270000
  training_iteration: 327
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5846 s, 327 iter, 3270000 ts, 260 rew

agent-1: 27.0
agent-2: 19.0
agent-3: 26.0
agent-4: 22.0
agent-5: 16.0
agent-6: 18.0
agent-7: 23.0
agent-8: 18.0
agent-9: 23.0
agent-10: 25.0
Sum Reward: 217.0
Avg Reward: 21.7
Min Reward: 16.0
Gini Coefficient 0.0935483870967742
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-02-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 259.37
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 327
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.026
    dispatch_time_ms: 5.742
    learner:
      cur_lr: 0.0011422180105000734
      grad_gnorm: 31.09145736694336
      policy_entropy: 123.69795227050781
      policy_loss: 5.5960917472839355
      var_gnorm: 52.39179229736328
      vf_explained_var: 0.3463759422302246
      vf_loss: 2.655061960220337
    num_steps_sampled: 3280000
    num_steps_trained: 3280000
    wait_time_ms: 164.901
  iterations_since_restore: 328
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5863.43105006218
  time_this_iter_s: 17.310428619384766
  time_total_s: 5863.43105006218
  timestamp: 1593828138
  timesteps_since_restore: 3280000
  timesteps_this_iter: 10000
  timesteps_total: 3280000
  training_iteration: 328
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5863 s, 328 iter, 3280000 ts, 259 rew

agent-1: 18.0
agent-2: 26.0
agent-3: 21.0
agent-4: 28.0
agent-5: 14.0
agent-6: 30.0
agent-7: 35.0
agent-8: 27.0
agent-9: 19.0
agent-10: 29.0
Sum Reward: 247.0
Avg Reward: 24.7
Min Reward: 14.0
Gini Coefficient 0.1396761133603239
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-02-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 259.11
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 328
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.465
    dispatch_time_ms: 5.627
    learner:
      cur_lr: 0.0011415519984439015
      grad_gnorm: 0.5424007773399353
      policy_entropy: 124.74258422851562
      policy_loss: 0.3542003929615021
      var_gnorm: 52.326168060302734
      vf_explained_var: 0.9935791492462158
      vf_loss: 2.3202663214760832e-05
    num_steps_sampled: 3290000
    num_steps_trained: 3290000
    wait_time_ms: 164.094
  iterations_since_restore: 329
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5880.875648975372
  time_this_iter_s: 17.44459891319275
  time_total_s: 5880.875648975372
  timestamp: 1593828156
  timesteps_since_restore: 3290000
  timesteps_this_iter: 10000
  timesteps_total: 3290000
  training_iteration: 329
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5880 s, 329 iter, 3290000 ts, 259 rew

agent-1: 21.0
agent-2: 24.0
agent-3: 19.0
agent-4: 21.0
agent-5: 27.0
agent-6: 30.0
agent-7: 22.0
agent-8: 22.0
agent-9: 20.0
agent-10: 28.0
Sum Reward: 234.0
Avg Reward: 23.4
Min Reward: 19.0
Gini Coefficient 0.0829059829059829
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-02-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 258.36
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 329
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.009
    dispatch_time_ms: 7.48
    learner:
      cur_lr: 0.0011408859863877296
      grad_gnorm: 1.5392563343048096
      policy_entropy: 100.52372741699219
      policy_loss: 0.6869391798973083
      var_gnorm: 52.397369384765625
      vf_explained_var: 0.0
      vf_loss: 0.0014054535422474146
    num_steps_sampled: 3300000
    num_steps_trained: 3300000
    wait_time_ms: 166.814
  iterations_since_restore: 330
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5898.456191778183
  time_this_iter_s: 17.58054280281067
  time_total_s: 5898.456191778183
  timestamp: 1593828173
  timesteps_since_restore: 3300000
  timesteps_this_iter: 10000
  timesteps_total: 3300000
  training_iteration: 330
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5898 s, 330 iter, 3300000 ts, 258 rew

agent-1: 30.0
agent-2: 23.0
agent-3: 14.0
agent-4: 13.0
agent-5: 13.0
agent-6: 24.0
agent-7: 21.0
agent-8: 31.0
agent-9: 19.0
agent-10: 19.0
Sum Reward: 207.0
Avg Reward: 20.7
Min Reward: 13.0
Gini Coefficient 0.16666666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-03-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 257.98
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 330
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.182
    dispatch_time_ms: 6.857
    learner:
      cur_lr: 0.0011402199743315578
      grad_gnorm: 1.476371169090271
      policy_entropy: 114.87483978271484
      policy_loss: -0.7959825396537781
      var_gnorm: 52.44718933105469
      vf_explained_var: 0.0
      vf_loss: 0.0012161640916019678
    num_steps_sampled: 3310000
    num_steps_trained: 3310000
    wait_time_ms: 169.582
  iterations_since_restore: 331
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5915.925399065018
  time_this_iter_s: 17.469207286834717
  time_total_s: 5915.925399065018
  timestamp: 1593828191
  timesteps_since_restore: 3310000
  timesteps_this_iter: 10000
  timesteps_total: 3310000
  training_iteration: 331
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5915 s, 331 iter, 3310000 ts, 258 rew

agent-1: 30.0
agent-2: 27.0
agent-3: 29.0
agent-4: 29.0
agent-5: 21.0
agent-6: 16.0
agent-7: 11.0
agent-8: 22.0
agent-9: 26.0
agent-10: 25.0
Sum Reward: 236.0
Avg Reward: 23.6
Min Reward: 11.0
Gini Coefficient 0.13474576271186442
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-03-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 257.72
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 331
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.188
    dispatch_time_ms: 28.096
    learner:
      cur_lr: 0.0011395539622753859
      grad_gnorm: 1.3229637145996094
      policy_entropy: 125.4574203491211
      policy_loss: -1.671441674232483
      var_gnorm: 52.47018814086914
      vf_explained_var: 0.9354075193405151
      vf_loss: 0.00021589219977613539
    num_steps_sampled: 3320000
    num_steps_trained: 3320000
    wait_time_ms: 156.286
  iterations_since_restore: 332
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5937.496684551239
  time_this_iter_s: 21.571285486221313
  time_total_s: 5937.496684551239
  timestamp: 1593828212
  timesteps_since_restore: 3320000
  timesteps_this_iter: 10000
  timesteps_total: 3320000
  training_iteration: 332
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5937 s, 332 iter, 3320000 ts, 258 rew

agent-1: 20.0
agent-2: 24.0
agent-3: 25.0
agent-4: 21.0
agent-5: 24.0
agent-6: 24.0
agent-7: 16.0
agent-8: 20.0
agent-9: 21.0
agent-10: 25.0
Sum Reward: 220.0
Avg Reward: 22.0
Min Reward: 16.0
Gini Coefficient 0.06727272727272728
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-03-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 257.34
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 332
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.833
    dispatch_time_ms: 24.109
    learner:
      cur_lr: 0.001138887950219214
      grad_gnorm: 39.999996185302734
      policy_entropy: 122.19171142578125
      policy_loss: 25.398090362548828
      var_gnorm: 52.475582122802734
      vf_explained_var: 0.5341124534606934
      vf_loss: 13.468062400817871
    num_steps_sampled: 3330000
    num_steps_trained: 3330000
    wait_time_ms: 153.765
  iterations_since_restore: 333
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5955.947058439255
  time_this_iter_s: 18.450373888015747
  time_total_s: 5955.947058439255
  timestamp: 1593828231
  timesteps_since_restore: 3330000
  timesteps_this_iter: 10000
  timesteps_total: 3330000
  training_iteration: 333
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5955 s, 333 iter, 3330000 ts, 257 rew

agent-1: 23.0
agent-2: 26.0
agent-3: 32.0
agent-4: 23.0
agent-5: 19.0
agent-6: 22.0
agent-7: 16.0
agent-8: 24.0
agent-9: 28.0
agent-10: 22.0
Sum Reward: 235.0
Avg Reward: 23.5
Min Reward: 16.0
Gini Coefficient 0.09914893617021277
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-04-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 257.08
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 333
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.082
    dispatch_time_ms: 29.117
    learner:
      cur_lr: 0.001138222054578364
      grad_gnorm: 0.4278542697429657
      policy_entropy: 133.39239501953125
      policy_loss: -0.9144339561462402
      var_gnorm: 52.52248764038086
      vf_explained_var: -0.1063157320022583
      vf_loss: 0.0027065295726060867
    num_steps_sampled: 3340000
    num_steps_trained: 3340000
    wait_time_ms: 165.926
  iterations_since_restore: 334
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5974.37898850441
  time_this_iter_s: 18.43193006515503
  time_total_s: 5974.37898850441
  timestamp: 1593828249
  timesteps_since_restore: 3340000
  timesteps_this_iter: 10000
  timesteps_total: 3340000
  training_iteration: 334
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5974 s, 334 iter, 3340000 ts, 257 rew

agent-1: 28.0
agent-2: 22.0
agent-3: 19.0
agent-4: 22.0
agent-5: 24.0
agent-6: 34.0
agent-7: 25.0
agent-8: 16.0
agent-9: 19.0
agent-10: 27.0
Sum Reward: 236.0
Avg Reward: 23.6
Min Reward: 16.0
Gini Coefficient 0.11694915254237288
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-04-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 257.0
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 334
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.835
    dispatch_time_ms: 30.735
    learner:
      cur_lr: 0.001137556042522192
      grad_gnorm: 2.6289854049682617
      policy_entropy: 139.32894897460938
      policy_loss: 0.29984724521636963
      var_gnorm: 52.557830810546875
      vf_explained_var: -0.5871061086654663
      vf_loss: 0.01185988262295723
    num_steps_sampled: 3350000
    num_steps_trained: 3350000
    wait_time_ms: 155.183
  iterations_since_restore: 335
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 5992.505154132843
  time_this_iter_s: 18.126165628433228
  time_total_s: 5992.505154132843
  timestamp: 1593828268
  timesteps_since_restore: 3350000
  timesteps_this_iter: 10000
  timesteps_total: 3350000
  training_iteration: 335
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 5992 s, 335 iter, 3350000 ts, 257 rew

agent-1: 25.0
agent-2: 21.0
agent-3: 29.0
agent-4: 33.0
agent-5: 27.0
agent-6: 22.0
agent-7: 20.0
agent-8: 18.0
agent-9: 22.0
agent-10: 20.0
Sum Reward: 237.0
Avg Reward: 23.7
Min Reward: 18.0
Gini Coefficient 0.10337552742616034
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-04-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 256.71
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 335
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.668
    dispatch_time_ms: 34.008
    learner:
      cur_lr: 0.00113689003046602
      grad_gnorm: 35.14946746826172
      policy_entropy: 114.75261688232422
      policy_loss: 18.66595458984375
      var_gnorm: 52.6458854675293
      vf_explained_var: 0.2206171751022339
      vf_loss: 8.727320671081543
    num_steps_sampled: 3360000
    num_steps_trained: 3360000
    wait_time_ms: 147.345
  iterations_since_restore: 336
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6010.728354930878
  time_this_iter_s: 18.223200798034668
  time_total_s: 6010.728354930878
  timestamp: 1593828286
  timesteps_since_restore: 3360000
  timesteps_this_iter: 10000
  timesteps_total: 3360000
  training_iteration: 336
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6010 s, 336 iter, 3360000 ts, 257 rew

agent-1: 28.0
agent-2: 25.0
agent-3: 13.0
agent-4: 18.0
agent-5: 30.0
agent-6: 23.0
agent-7: 30.0
agent-8: 19.0
agent-9: 22.0
agent-10: 20.0
Sum Reward: 228.0
Avg Reward: 22.8
Min Reward: 13.0
Gini Coefficient 0.1307017543859649
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-05-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 256.28
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 336
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 4.041
    dispatch_time_ms: 7.061
    learner:
      cur_lr: 0.0011362240184098482
      grad_gnorm: 3.8660666942596436
      policy_entropy: 127.04430389404297
      policy_loss: -0.9666126370429993
      var_gnorm: 52.761173248291016
      vf_explained_var: 0.8084107041358948
      vf_loss: 0.9228950142860413
    num_steps_sampled: 3370000
    num_steps_trained: 3370000
    wait_time_ms: 164.039
  iterations_since_restore: 337
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6028.514555215836
  time_this_iter_s: 17.786200284957886
  time_total_s: 6028.514555215836
  timestamp: 1593828304
  timesteps_since_restore: 3370000
  timesteps_this_iter: 10000
  timesteps_total: 3370000
  training_iteration: 337
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6028 s, 337 iter, 3370000 ts, 256 rew

agent-1: 23.0
agent-2: 34.0
agent-3: 17.0
agent-4: 16.0
agent-5: 17.0
agent-6: 26.0
agent-7: 23.0
agent-8: 25.0
agent-9: 27.0
agent-10: 22.0
Sum Reward: 230.0
Avg Reward: 23.0
Min Reward: 16.0
Gini Coefficient 0.12434782608695652
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-05-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 256.05
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 337
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.879
    dispatch_time_ms: 6.088
    learner:
      cur_lr: 0.0011355580063536763
      grad_gnorm: 5.25360631942749
      policy_entropy: 104.81986999511719
      policy_loss: -3.0977845191955566
      var_gnorm: 52.8196907043457
      vf_explained_var: 0.0003198981285095215
      vf_loss: 0.015184072777628899
    num_steps_sampled: 3380000
    num_steps_trained: 3380000
    wait_time_ms: 172.458
  iterations_since_restore: 338
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6045.97252202034
  time_this_iter_s: 17.457966804504395
  time_total_s: 6045.97252202034
  timestamp: 1593828321
  timesteps_since_restore: 3380000
  timesteps_this_iter: 10000
  timesteps_total: 3380000
  training_iteration: 338
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6045 s, 338 iter, 3380000 ts, 256 rew

agent-1: 18.0
agent-2: 20.0
agent-3: 17.0
agent-4: 44.0
agent-5: 29.0
agent-6: 25.0
agent-7: 20.0
agent-8: 23.0
agent-9: 24.0
agent-10: 21.0
Sum Reward: 241.0
Avg Reward: 24.1
Min Reward: 17.0
Gini Coefficient 0.14896265560165975
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-05-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 255.96
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 338
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.697
    dispatch_time_ms: 7.682
    learner:
      cur_lr: 0.0011348919942975044
      grad_gnorm: 7.541524410247803
      policy_entropy: 118.95655059814453
      policy_loss: -2.7822465896606445
      var_gnorm: 52.8515625
      vf_explained_var: 0.09352535009384155
      vf_loss: 0.03371043875813484
    num_steps_sampled: 3390000
    num_steps_trained: 3390000
    wait_time_ms: 159.238
  iterations_since_restore: 339
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6063.200235843658
  time_this_iter_s: 17.22771382331848
  time_total_s: 6063.200235843658
  timestamp: 1593828338
  timesteps_since_restore: 3390000
  timesteps_this_iter: 10000
  timesteps_total: 3390000
  training_iteration: 339
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6063 s, 339 iter, 3390000 ts, 256 rew

agent-1: 23.0
agent-2: 21.0
agent-3: 24.0
agent-4: 23.0
agent-5: 19.0
agent-6: 20.0
agent-7: 27.0
agent-8: 17.0
agent-9: 25.0
agent-10: 29.0
Sum Reward: 228.0
Avg Reward: 22.8
Min Reward: 17.0
Gini Coefficient 0.0868421052631579
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-05-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 254.94
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 339
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.07
    dispatch_time_ms: 5.797
    learner:
      cur_lr: 0.0011342259822413325
      grad_gnorm: 3.1417438983917236
      policy_entropy: 133.6822967529297
      policy_loss: -0.7481845617294312
      var_gnorm: 52.87823486328125
      vf_explained_var: 0.8633355498313904
      vf_loss: 0.005811886861920357
    num_steps_sampled: 3400000
    num_steps_trained: 3400000
    wait_time_ms: 169.057
  iterations_since_restore: 340
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6080.477387189865
  time_this_iter_s: 17.277151346206665
  time_total_s: 6080.477387189865
  timestamp: 1593828356
  timesteps_since_restore: 3400000
  timesteps_this_iter: 10000
  timesteps_total: 3400000
  training_iteration: 340
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6080 s, 340 iter, 3400000 ts, 255 rew

agent-1: 38.0
agent-2: 17.0
agent-3: 22.0
agent-4: 24.0
agent-5: 29.0
agent-6: 32.0
agent-7: 28.0
agent-8: 32.0
agent-9: 24.0
agent-10: 23.0
Sum Reward: 269.0
Avg Reward: 26.9
Min Reward: 17.0
Gini Coefficient 0.12007434944237919
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-06-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 255.16
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 340
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.562
    dispatch_time_ms: 5.925
    learner:
      cur_lr: 0.0011335599701851606
      grad_gnorm: 34.84791564941406
      policy_entropy: 131.29006958007812
      policy_loss: 13.473121643066406
      var_gnorm: 52.90671920776367
      vf_explained_var: 0.6360474228858948
      vf_loss: 8.47217845916748
    num_steps_sampled: 3410000
    num_steps_trained: 3410000
    wait_time_ms: 162.682
  iterations_since_restore: 341
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6096.398027181625
  time_this_iter_s: 15.920639991760254
  time_total_s: 6096.398027181625
  timestamp: 1593828377
  timesteps_since_restore: 3410000
  timesteps_this_iter: 10000
  timesteps_total: 3410000
  training_iteration: 341
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6096 s, 341 iter, 3410000 ts, 255 rew

agent-1: 43.0
agent-2: 29.0
agent-3: 28.0
agent-4: 44.0
agent-5: 13.0
agent-6: 22.0
agent-7: 21.0
agent-8: 21.0
agent-9: 9.0
agent-10: 24.0
Sum Reward: 254.0
Avg Reward: 25.4
Min Reward: 9.0
Gini Coefficient 0.231496062992126
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-06-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 255.25
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 341
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.468
    dispatch_time_ms: 8.725
    learner:
      cur_lr: 0.0011328939581289887
      grad_gnorm: 1.205246925354004
      policy_entropy: 149.3615264892578
      policy_loss: -1.1189720630645752
      var_gnorm: 53.017417907714844
      vf_explained_var: 0.9916384816169739
      vf_loss: 0.0007500292267650366
    num_steps_sampled: 3420000
    num_steps_trained: 3420000
    wait_time_ms: 168.645
  iterations_since_restore: 342
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6113.614418506622
  time_this_iter_s: 17.21639132499695
  time_total_s: 6113.614418506622
  timestamp: 1593828394
  timesteps_since_restore: 3420000
  timesteps_this_iter: 10000
  timesteps_total: 3420000
  training_iteration: 342
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6113 s, 342 iter, 3420000 ts, 255 rew

agent-1: 23.0
agent-2: 25.0
agent-3: 27.0
agent-4: 27.0
agent-5: 19.0
agent-6: 34.0
agent-7: 22.0
agent-8: 27.0
agent-9: 21.0
agent-10: 25.0
Sum Reward: 250.0
Avg Reward: 25.0
Min Reward: 19.0
Gini Coefficient 0.0856
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-06-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 255.02
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 342
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.663
    dispatch_time_ms: 6.02
    learner:
      cur_lr: 0.0011322279460728168
      grad_gnorm: 40.0
      policy_entropy: 130.13450622558594
      policy_loss: -5.86978006362915
      var_gnorm: 53.00291061401367
      vf_explained_var: 0.8572240471839905
      vf_loss: 5.700780391693115
    num_steps_sampled: 3430000
    num_steps_trained: 3430000
    wait_time_ms: 170.879
  iterations_since_restore: 343
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6131.053655385971
  time_this_iter_s: 17.439236879348755
  time_total_s: 6131.053655385971
  timestamp: 1593828412
  timesteps_since_restore: 3430000
  timesteps_this_iter: 10000
  timesteps_total: 3430000
  training_iteration: 343
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6131 s, 343 iter, 3430000 ts, 255 rew

agent-1: 27.0
agent-2: 25.0
agent-3: 47.0
agent-4: 30.0
agent-5: 35.0
agent-6: 25.0
agent-7: 22.0
agent-8: 33.0
agent-9: 21.0
agent-10: 29.0
Sum Reward: 294.0
Avg Reward: 29.4
Min Reward: 21.0
Gini Coefficient 0.12993197278911564
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-07-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 255.55
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 343
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.523
    dispatch_time_ms: 7.547
    learner:
      cur_lr: 0.0011315620504319668
      grad_gnorm: 35.20235824584961
      policy_entropy: 122.68911743164062
      policy_loss: 8.898848533630371
      var_gnorm: 53.01488494873047
      vf_explained_var: 0.47737574577331543
      vf_loss: 15.626951217651367
    num_steps_sampled: 3440000
    num_steps_trained: 3440000
    wait_time_ms: 168.715
  iterations_since_restore: 344
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6148.439379692078
  time_this_iter_s: 17.385724306106567
  time_total_s: 6148.439379692078
  timestamp: 1593828429
  timesteps_since_restore: 3440000
  timesteps_this_iter: 10000
  timesteps_total: 3440000
  training_iteration: 344
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6148 s, 344 iter, 3440000 ts, 256 rew

agent-1: 13.0
agent-2: 35.0
agent-3: 27.0
agent-4: 41.0
agent-5: 14.0
agent-6: 17.0
agent-7: 27.0
agent-8: 14.0
agent-9: 39.0
agent-10: 28.0
Sum Reward: 255.0
Avg Reward: 25.5
Min Reward: 13.0
Gini Coefficient 0.22156862745098038
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-07-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 255.83
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 344
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.719
    dispatch_time_ms: 6.343
    learner:
      cur_lr: 0.0011308960383757949
      grad_gnorm: 1.89083731174469
      policy_entropy: 136.2307586669922
      policy_loss: -1.2033963203430176
      var_gnorm: 53.00303649902344
      vf_explained_var: 0.9459859728813171
      vf_loss: 0.0019300873391330242
    num_steps_sampled: 3450000
    num_steps_trained: 3450000
    wait_time_ms: 166.086
  iterations_since_restore: 345
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6165.717851638794
  time_this_iter_s: 17.27847194671631
  time_total_s: 6165.717851638794
  timestamp: 1593828446
  timesteps_since_restore: 3450000
  timesteps_this_iter: 10000
  timesteps_total: 3450000
  training_iteration: 345
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6165 s, 345 iter, 3450000 ts, 256 rew

agent-1: 41.0
agent-2: 29.0
agent-3: 27.0
agent-4: 23.0
agent-5: 22.0
agent-6: 26.0
agent-7: 18.0
agent-8: 25.0
agent-9: 15.0
agent-10: 32.0
Sum Reward: 258.0
Avg Reward: 25.8
Min Reward: 15.0
Gini Coefficient 0.14728682170542637
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-07-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 255.73
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 345
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.255
    dispatch_time_ms: 5.827
    learner:
      cur_lr: 0.001130230026319623
      grad_gnorm: 20.894474029541016
      policy_entropy: 123.98651123046875
      policy_loss: 6.202988147735596
      var_gnorm: 53.0959587097168
      vf_explained_var: 0.009619712829589844
      vf_loss: 2.4816737174987793
    num_steps_sampled: 3460000
    num_steps_trained: 3460000
    wait_time_ms: 168.789
  iterations_since_restore: 346
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6183.2199075222015
  time_this_iter_s: 17.502055883407593
  time_total_s: 6183.2199075222015
  timestamp: 1593828464
  timesteps_since_restore: 3460000
  timesteps_this_iter: 10000
  timesteps_total: 3460000
  training_iteration: 346
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6183 s, 346 iter, 3460000 ts, 256 rew

agent-1: 18.0
agent-2: 36.0
agent-3: 24.0
agent-4: 28.0
agent-5: 23.0
agent-6: 15.0
agent-7: 29.0
agent-8: 21.0
agent-9: 15.0
agent-10: 11.0
Sum Reward: 220.0
Avg Reward: 22.0
Min Reward: 11.0
Gini Coefficient 0.18545454545454546
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-08-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 255.54
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 346
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.624
    dispatch_time_ms: 6.342
    learner:
      cur_lr: 0.001129564014263451
      grad_gnorm: 0.9848037958145142
      policy_entropy: 125.48660278320312
      policy_loss: -0.43403807282447815
      var_gnorm: 53.144996643066406
      vf_explained_var: 0.9289758205413818
      vf_loss: 0.0005803063977509737
    num_steps_sampled: 3470000
    num_steps_trained: 3470000
    wait_time_ms: 166.21
  iterations_since_restore: 347
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6200.48877120018
  time_this_iter_s: 17.268863677978516
  time_total_s: 6200.48877120018
  timestamp: 1593828481
  timesteps_since_restore: 3470000
  timesteps_this_iter: 10000
  timesteps_total: 3470000
  training_iteration: 347
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6200 s, 347 iter, 3470000 ts, 256 rew

agent-1: 19.0
agent-2: 27.0
agent-3: 22.0
agent-4: 22.0
agent-5: 28.0
agent-6: 25.0
agent-7: 24.0
agent-8: 21.0
agent-9: 29.0
agent-10: 26.0
Sum Reward: 243.0
Avg Reward: 24.3
Min Reward: 19.0
Gini Coefficient 0.0728395061728395
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-08-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 255.71
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 347
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.488
    dispatch_time_ms: 5.548
    learner:
      cur_lr: 0.0011288980022072792
      grad_gnorm: 6.262155055999756
      policy_entropy: 116.70652770996094
      policy_loss: 2.2755370140075684
      var_gnorm: 53.19980239868164
      vf_explained_var: 0.3398593068122864
      vf_loss: 0.023950325325131416
    num_steps_sampled: 3480000
    num_steps_trained: 3480000
    wait_time_ms: 169.798
  iterations_since_restore: 348
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6217.8694627285
  time_this_iter_s: 17.380691528320312
  time_total_s: 6217.8694627285
  timestamp: 1593828499
  timesteps_since_restore: 3480000
  timesteps_this_iter: 10000
  timesteps_total: 3480000
  training_iteration: 348
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6217 s, 348 iter, 3480000 ts, 256 rew

agent-1: 24.0
agent-2: 33.0
agent-3: 27.0
agent-4: 19.0
agent-5: 37.0
agent-6: 29.0
agent-7: 24.0
agent-8: 5.0
agent-9: 14.0
agent-10: 13.0
Sum Reward: 225.0
Avg Reward: 22.5
Min Reward: 5.0
Gini Coefficient 0.23422222222222222
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-08-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 255.51
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 348
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.175
    dispatch_time_ms: 5.96
    learner:
      cur_lr: 0.0011282319901511073
      grad_gnorm: 13.03235149383545
      policy_entropy: 105.29296875
      policy_loss: 2.9501919746398926
      var_gnorm: 53.13636779785156
      vf_explained_var: -0.5274326801300049
      vf_loss: 2.485199451446533
    num_steps_sampled: 3490000
    num_steps_trained: 3490000
    wait_time_ms: 165.374
  iterations_since_restore: 349
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6235.564179182053
  time_this_iter_s: 17.694716453552246
  time_total_s: 6235.564179182053
  timestamp: 1593828516
  timesteps_since_restore: 3490000
  timesteps_this_iter: 10000
  timesteps_total: 3490000
  training_iteration: 349
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6235 s, 349 iter, 3490000 ts, 256 rew

agent-1: 24.0
agent-2: 21.0
agent-3: 26.0
agent-4: 35.0
agent-5: 26.0
agent-6: 15.0
agent-7: 25.0
agent-8: 14.0
agent-9: 39.0
agent-10: 36.0
Sum Reward: 261.0
Avg Reward: 26.1
Min Reward: 14.0
Gini Coefficient 0.17203065134099618
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-08-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 255.31
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 349
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.131
    dispatch_time_ms: 7.533
    learner:
      cur_lr: 0.0011275659780949354
      grad_gnorm: 3.0831687450408936
      policy_entropy: 138.09954833984375
      policy_loss: 1.5694528818130493
      var_gnorm: 53.225460052490234
      vf_explained_var: 0.7717546820640564
      vf_loss: 0.005638600792735815
    num_steps_sampled: 3500000
    num_steps_trained: 3500000
    wait_time_ms: 165.319
  iterations_since_restore: 350
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6252.888387680054
  time_this_iter_s: 17.3242084980011
  time_total_s: 6252.888387680054
  timestamp: 1593828534
  timesteps_since_restore: 3500000
  timesteps_this_iter: 10000
  timesteps_total: 3500000
  training_iteration: 350
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6252 s, 350 iter, 3500000 ts, 255 rew

agent-1: 29.0
agent-2: 31.0
agent-3: 17.0
agent-4: 11.0
agent-5: 28.0
agent-6: 44.0
agent-7: 36.0
agent-8: 16.0
agent-9: 30.0
agent-10: 5.0
Sum Reward: 247.0
Avg Reward: 24.7
Min Reward: 5.0
Gini Coefficient 0.2595141700404858
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-09-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 255.37
  episode_reward_min: 205.0
  episodes_this_iter: 1
  episodes_total: 350
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.11
    dispatch_time_ms: 6.456
    learner:
      cur_lr: 0.0011268999660387635
      grad_gnorm: 1.7108933925628662
      policy_entropy: 140.6134796142578
      policy_loss: -1.592743992805481
      var_gnorm: 53.353416442871094
      vf_explained_var: 0.9823620915412903
      vf_loss: 3.700571687659249e-05
    num_steps_sampled: 3510000
    num_steps_trained: 3510000
    wait_time_ms: 165.158
  iterations_since_restore: 351
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6270.420430183411
  time_this_iter_s: 17.532042503356934
  time_total_s: 6270.420430183411
  timestamp: 1593828551
  timesteps_since_restore: 3510000
  timesteps_this_iter: 10000
  timesteps_total: 3510000
  training_iteration: 351
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6270 s, 351 iter, 3510000 ts, 255 rew

agent-1: 14.0
agent-2: 14.0
agent-3: 20.0
agent-4: 30.0
agent-5: 23.0
agent-6: 18.0
agent-7: 14.0
agent-8: 24.0
agent-9: 21.0
agent-10: 18.0
Sum Reward: 196.0
Avg Reward: 19.6
Min Reward: 14.0
Gini Coefficient 0.1377551020408163
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-09-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 255.05
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 351
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.051
    dispatch_time_ms: 8.939
    learner:
      cur_lr: 0.0011262339539825916
      grad_gnorm: 4.4007086753845215
      policy_entropy: 156.66151428222656
      policy_loss: -1.1665914058685303
      var_gnorm: 53.44815444946289
      vf_explained_var: -1.0
      vf_loss: 0.08796223253011703
    num_steps_sampled: 3520000
    num_steps_trained: 3520000
    wait_time_ms: 162.187
  iterations_since_restore: 352
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6287.833497285843
  time_this_iter_s: 17.41306710243225
  time_total_s: 6287.833497285843
  timestamp: 1593828569
  timesteps_since_restore: 3520000
  timesteps_this_iter: 10000
  timesteps_total: 3520000
  training_iteration: 352
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6287 s, 352 iter, 3520000 ts, 255 rew

agent-1: 33.0
agent-2: 29.0
agent-3: 20.0
agent-4: 17.0
agent-5: 25.0
agent-6: 19.0
agent-7: 13.0
agent-8: 20.0
agent-9: 23.0
agent-10: 33.0
Sum Reward: 232.0
Avg Reward: 23.2
Min Reward: 13.0
Gini Coefficient 0.15517241379310345
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-09-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 255.07
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 352
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.717
    dispatch_time_ms: 5.607
    learner:
      cur_lr: 0.0011255679419264197
      grad_gnorm: 40.0
      policy_entropy: 124.98789978027344
      policy_loss: 4.574375629425049
      var_gnorm: 53.46503448486328
      vf_explained_var: 0.46607524156570435
      vf_loss: 9.531326293945312
    num_steps_sampled: 3530000
    num_steps_trained: 3530000
    wait_time_ms: 159.976
  iterations_since_restore: 353
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6305.134732246399
  time_this_iter_s: 17.30123496055603
  time_total_s: 6305.134732246399
  timestamp: 1593828586
  timesteps_since_restore: 3530000
  timesteps_this_iter: 10000
  timesteps_total: 3530000
  training_iteration: 353
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6305 s, 353 iter, 3530000 ts, 255 rew

agent-1: 16.0
agent-2: 32.0
agent-3: 22.0
agent-4: 31.0
agent-5: 30.0
agent-6: 27.0
agent-7: 25.0
agent-8: 26.0
agent-9: 20.0
agent-10: 16.0
Sum Reward: 245.0
Avg Reward: 24.5
Min Reward: 16.0
Gini Coefficient 0.12857142857142856
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-10-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 254.96
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 353
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.311
    dispatch_time_ms: 9.289
    learner:
      cur_lr: 0.0011249020462855697
      grad_gnorm: 14.004109382629395
      policy_entropy: 114.48880004882812
      policy_loss: -5.608290195465088
      var_gnorm: 53.49742126464844
      vf_explained_var: 0.46420812606811523
      vf_loss: 0.11842261254787445
    num_steps_sampled: 3540000
    num_steps_trained: 3540000
    wait_time_ms: 162.038
  iterations_since_restore: 354
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6322.387485027313
  time_this_iter_s: 17.252752780914307
  time_total_s: 6322.387485027313
  timestamp: 1593828603
  timesteps_since_restore: 3540000
  timesteps_this_iter: 10000
  timesteps_total: 3540000
  training_iteration: 354
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6322 s, 354 iter, 3540000 ts, 255 rew

agent-1: 32.0
agent-2: 28.0
agent-3: 35.0
agent-4: 33.0
agent-5: 25.0
agent-6: 12.0
agent-7: 34.0
agent-8: 10.0
agent-9: 22.0
agent-10: 29.0
Sum Reward: 260.0
Avg Reward: 26.0
Min Reward: 10.0
Gini Coefficient 0.1753846153846154
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-10-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 255.18
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 354
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.41
    dispatch_time_ms: 6.772
    learner:
      cur_lr: 0.0011242360342293978
      grad_gnorm: 14.163296699523926
      policy_entropy: 107.35041046142578
      policy_loss: -4.636584281921387
      var_gnorm: 53.56263732910156
      vf_explained_var: 0.855273425579071
      vf_loss: 5.4838995933532715
    num_steps_sampled: 3550000
    num_steps_trained: 3550000
    wait_time_ms: 158.502
  iterations_since_restore: 355
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6339.802602052689
  time_this_iter_s: 17.415117025375366
  time_total_s: 6339.802602052689
  timestamp: 1593828621
  timesteps_since_restore: 3550000
  timesteps_this_iter: 10000
  timesteps_total: 3550000
  training_iteration: 355
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6339 s, 355 iter, 3550000 ts, 255 rew

agent-1: 25.0
agent-2: 37.0
agent-3: 33.0
agent-4: 25.0
agent-5: 22.0
agent-6: 18.0
agent-7: 26.0
agent-8: 19.0
agent-9: 23.0
agent-10: 29.0
Sum Reward: 257.0
Avg Reward: 25.7
Min Reward: 18.0
Gini Coefficient 0.12178988326848249
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-10-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 255.47
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 355
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.622
    dispatch_time_ms: 7.633
    learner:
      cur_lr: 0.0011235700221732259
      grad_gnorm: 4.4021759033203125
      policy_entropy: 139.3020477294922
      policy_loss: -2.322915554046631
      var_gnorm: 53.606689453125
      vf_explained_var: 0.9596062302589417
      vf_loss: 0.010166825726628304
    num_steps_sampled: 3560000
    num_steps_trained: 3560000
    wait_time_ms: 162.905
  iterations_since_restore: 356
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6357.19035243988
  time_this_iter_s: 17.387750387191772
  time_total_s: 6357.19035243988
  timestamp: 1593828638
  timesteps_since_restore: 3560000
  timesteps_this_iter: 10000
  timesteps_total: 3560000
  training_iteration: 356
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6357 s, 356 iter, 3560000 ts, 255 rew

agent-1: 20.0
agent-2: 28.0
agent-3: 33.0
agent-4: 32.0
agent-5: 20.0
agent-6: 46.0
agent-7: 10.0
agent-8: 17.0
agent-9: 39.0
agent-10: 30.0
Sum Reward: 275.0
Avg Reward: 27.5
Min Reward: 10.0
Gini Coefficient 0.21127272727272728
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-10-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 255.79
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 356
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 4.524
    dispatch_time_ms: 7.838
    learner:
      cur_lr: 0.001122904010117054
      grad_gnorm: 40.000003814697266
      policy_entropy: 61.880218505859375
      policy_loss: 2.401945114135742
      var_gnorm: 53.62223434448242
      vf_explained_var: 0.641517162322998
      vf_loss: 21.44289779663086
    num_steps_sampled: 3570000
    num_steps_trained: 3570000
    wait_time_ms: 159.302
  iterations_since_restore: 357
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6374.397618055344
  time_this_iter_s: 17.207265615463257
  time_total_s: 6374.397618055344
  timestamp: 1593828655
  timesteps_since_restore: 3570000
  timesteps_this_iter: 10000
  timesteps_total: 3570000
  training_iteration: 357
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6374 s, 357 iter, 3570000 ts, 256 rew

agent-1: 39.0
agent-2: 43.0
agent-3: 16.0
agent-4: 15.0
agent-5: 25.0
agent-6: 32.0
agent-7: 32.0
agent-8: 30.0
agent-9: 25.0
agent-10: 17.0
Sum Reward: 274.0
Avg Reward: 27.4
Min Reward: 15.0
Gini Coefficient 0.18759124087591242
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-11-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 256.14
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 357
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.788
    dispatch_time_ms: 7.416
    learner:
      cur_lr: 0.001122237998060882
      grad_gnorm: 1.4917287826538086
      policy_entropy: 112.28996276855469
      policy_loss: 0.6617229580879211
      var_gnorm: 53.72554016113281
      vf_explained_var: 0.9949906468391418
      vf_loss: 0.00031273215427063406
    num_steps_sampled: 3580000
    num_steps_trained: 3580000
    wait_time_ms: 167.083
  iterations_since_restore: 358
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6391.67258143425
  time_this_iter_s: 17.27496337890625
  time_total_s: 6391.67258143425
  timestamp: 1593828673
  timesteps_since_restore: 3580000
  timesteps_this_iter: 10000
  timesteps_total: 3580000
  training_iteration: 358
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6391 s, 358 iter, 3580000 ts, 256 rew

agent-1: 29.0
agent-2: 37.0
agent-3: 49.0
agent-4: 20.0
agent-5: 26.0
agent-6: 22.0
agent-7: 26.0
agent-8: 15.0
agent-9: 18.0
agent-10: 40.0
Sum Reward: 282.0
Avg Reward: 28.2
Min Reward: 15.0
Gini Coefficient 0.20070921985815604
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-11-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 256.91
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 358
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.013
    dispatch_time_ms: 6.732
    learner:
      cur_lr: 0.0011215719860047102
      grad_gnorm: 32.43269729614258
      policy_entropy: 78.5074691772461
      policy_loss: -6.907247543334961
      var_gnorm: 53.75323486328125
      vf_explained_var: 0.7121587991714478
      vf_loss: 10.674304962158203
    num_steps_sampled: 3590000
    num_steps_trained: 3590000
    wait_time_ms: 163.121
  iterations_since_restore: 359
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6409.132051229477
  time_this_iter_s: 17.45946979522705
  time_total_s: 6409.132051229477
  timestamp: 1593828690
  timesteps_since_restore: 3590000
  timesteps_this_iter: 10000
  timesteps_total: 3590000
  training_iteration: 359
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6409 s, 359 iter, 3590000 ts, 257 rew

agent-1: 29.0
agent-2: 26.0
agent-3: 29.0
agent-4: 17.0
agent-5: 13.0
agent-6: 15.0
agent-7: 17.0
agent-8: 37.0
agent-9: 32.0
agent-10: 37.0
Sum Reward: 252.0
Avg Reward: 25.2
Min Reward: 13.0
Gini Coefficient 0.19206349206349208
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-11-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 256.93
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 359
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.573
    dispatch_time_ms: 7.006
    learner:
      cur_lr: 0.0011209059739485383
      grad_gnorm: 39.999996185302734
      policy_entropy: 113.75680541992188
      policy_loss: 7.309711456298828
      var_gnorm: 53.812095642089844
      vf_explained_var: 0.6475279927253723
      vf_loss: 11.343173027038574
    num_steps_sampled: 3600000
    num_steps_trained: 3600000
    wait_time_ms: 158.451
  iterations_since_restore: 360
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6425.956114768982
  time_this_iter_s: 16.824063539505005
  time_total_s: 6425.956114768982
  timestamp: 1593828707
  timesteps_since_restore: 3600000
  timesteps_this_iter: 10000
  timesteps_total: 3600000
  training_iteration: 360
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6425 s, 360 iter, 3600000 ts, 257 rew

agent-1: 40.0
agent-2: 37.0
agent-3: 40.0
agent-4: 46.0
agent-5: 25.0
agent-6: 17.0
agent-7: 27.0
agent-8: 61.0
agent-9: 22.0
agent-10: 26.0
Sum Reward: 341.0
Avg Reward: 34.1
Min Reward: 17.0
Gini Coefficient 0.20263929618768328
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-12-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 257.84
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 360
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.969
    dispatch_time_ms: 5.939
    learner:
      cur_lr: 0.0011202399618923664
      grad_gnorm: 40.0
      policy_entropy: 80.52342224121094
      policy_loss: 41.6254997253418
      var_gnorm: 53.828956604003906
      vf_explained_var: 0.7611204385757446
      vf_loss: 76.18002319335938
    num_steps_sampled: 3610000
    num_steps_trained: 3610000
    wait_time_ms: 162.82
  iterations_since_restore: 361
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6443.2655482292175
  time_this_iter_s: 17.309433460235596
  time_total_s: 6443.2655482292175
  timestamp: 1593828724
  timesteps_since_restore: 3610000
  timesteps_this_iter: 10000
  timesteps_total: 3610000
  training_iteration: 361
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6443 s, 361 iter, 3610000 ts, 258 rew

agent-1: 37.0
agent-2: 43.0
agent-3: 37.0
agent-4: 55.0
agent-5: 39.0
agent-6: 24.0
agent-7: 7.0
agent-8: 16.0
agent-9: 23.0
agent-10: 50.0
Sum Reward: 331.0
Avg Reward: 33.1
Min Reward: 7.0
Gini Coefficient 0.24622356495468278
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-12-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 258.94
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 361
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.893
    dispatch_time_ms: 7.351
    learner:
      cur_lr: 0.0011195739498361945
      grad_gnorm: 24.3358154296875
      policy_entropy: 83.9256591796875
      policy_loss: 3.5700457096099854
      var_gnorm: 53.87449264526367
      vf_explained_var: -0.08618664741516113
      vf_loss: 3.980884552001953
    num_steps_sampled: 3620000
    num_steps_trained: 3620000
    wait_time_ms: 169.124
  iterations_since_restore: 362
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6460.571037769318
  time_this_iter_s: 17.305489540100098
  time_total_s: 6460.571037769318
  timestamp: 1593828742
  timesteps_since_restore: 3620000
  timesteps_this_iter: 10000
  timesteps_total: 3620000
  training_iteration: 362
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6460 s, 362 iter, 3620000 ts, 259 rew

agent-1: 25.0
agent-2: 24.0
agent-3: 28.0
agent-4: 38.0
agent-5: 21.0
agent-6: 36.0
agent-7: 14.0
agent-8: 34.0
agent-9: 27.0
agent-10: 26.0
Sum Reward: 273.0
Avg Reward: 27.3
Min Reward: 14.0
Gini Coefficient 0.13956043956043956
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-12-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 259.37
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 362
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.485
    dispatch_time_ms: 7.919
    learner:
      cur_lr: 0.0011189080541953444
      grad_gnorm: 39.999996185302734
      policy_entropy: 70.67790222167969
      policy_loss: -5.424407005310059
      var_gnorm: 53.88569641113281
      vf_explained_var: 0.33284032344818115
      vf_loss: 43.44419479370117
    num_steps_sampled: 3630000
    num_steps_trained: 3630000
    wait_time_ms: 160.854
  iterations_since_restore: 363
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6477.837710857391
  time_this_iter_s: 17.26667308807373
  time_total_s: 6477.837710857391
  timestamp: 1593828759
  timesteps_since_restore: 3630000
  timesteps_this_iter: 10000
  timesteps_total: 3630000
  training_iteration: 363
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6477 s, 363 iter, 3630000 ts, 259 rew

agent-1: 28.0
agent-2: 33.0
agent-3: 33.0
agent-4: 26.0
agent-5: 23.0
agent-6: 27.0
agent-7: 20.0
agent-8: 20.0
agent-9: 10.0
agent-10: 20.0
Sum Reward: 240.0
Avg Reward: 24.0
Min Reward: 10.0
Gini Coefficient 0.15083333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-12-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 259.58
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 363
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.102
    dispatch_time_ms: 8.157
    learner:
      cur_lr: 0.0011182420421391726
      grad_gnorm: 5.737288475036621
      policy_entropy: 119.89189910888672
      policy_loss: -1.7410773038864136
      var_gnorm: 53.885536193847656
      vf_explained_var: 0.0
      vf_loss: 0.020182598382234573
    num_steps_sampled: 3640000
    num_steps_trained: 3640000
    wait_time_ms: 169.127
  iterations_since_restore: 364
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6495.364698171616
  time_this_iter_s: 17.526987314224243
  time_total_s: 6495.364698171616
  timestamp: 1593828777
  timesteps_since_restore: 3640000
  timesteps_this_iter: 10000
  timesteps_total: 3640000
  training_iteration: 364
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6495 s, 364 iter, 3640000 ts, 260 rew

agent-1: 19.0
agent-2: 26.0
agent-3: 34.0
agent-4: 46.0
agent-5: 15.0
agent-6: 7.0
agent-7: 26.0
agent-8: 20.0
agent-9: 34.0
agent-10: 33.0
Sum Reward: 260.0
Avg Reward: 26.0
Min Reward: 7.0
Gini Coefficient 0.23
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-13-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 259.55
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 364
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.262
    dispatch_time_ms: 6.081
    learner:
      cur_lr: 0.0011175760300830007
      grad_gnorm: 1.6928343772888184
      policy_entropy: 131.30886840820312
      policy_loss: -0.7326639890670776
      var_gnorm: 53.86154556274414
      vf_explained_var: 0.0
      vf_loss: 0.0017306871013715863
    num_steps_sampled: 3650000
    num_steps_trained: 3650000
    wait_time_ms: 169.209
  iterations_since_restore: 365
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6512.593765258789
  time_this_iter_s: 17.229067087173462
  time_total_s: 6512.593765258789
  timestamp: 1593828794
  timesteps_since_restore: 3650000
  timesteps_this_iter: 10000
  timesteps_total: 3650000
  training_iteration: 365
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6512 s, 365 iter, 3650000 ts, 260 rew

agent-1: 13.0
agent-2: 20.0
agent-3: 32.0
agent-4: 35.0
agent-5: 25.0
agent-6: 18.0
agent-7: 25.0
agent-8: 30.0
agent-9: 20.0
agent-10: 31.0
Sum Reward: 249.0
Avg Reward: 24.9
Min Reward: 13.0
Gini Coefficient 0.1530120481927711
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-13-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 259.31
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 365
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.087
    dispatch_time_ms: 9.202
    learner:
      cur_lr: 0.0011169100180268288
      grad_gnorm: 1.637609839439392
      policy_entropy: 130.40065002441406
      policy_loss: 0.7140504121780396
      var_gnorm: 53.93159484863281
      vf_explained_var: 0.9622138142585754
      vf_loss: 0.0015492272796109319
    num_steps_sampled: 3660000
    num_steps_trained: 3660000
    wait_time_ms: 165.195
  iterations_since_restore: 366
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6530.152677297592
  time_this_iter_s: 17.5589120388031
  time_total_s: 6530.152677297592
  timestamp: 1593828812
  timesteps_since_restore: 3660000
  timesteps_this_iter: 10000
  timesteps_total: 3660000
  training_iteration: 366
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6530 s, 366 iter, 3660000 ts, 259 rew

agent-1: 14.0
agent-2: 24.0
agent-3: 30.0
agent-4: 24.0
agent-5: 30.0
agent-6: 16.0
agent-7: 23.0
agent-8: 29.0
agent-9: 14.0
agent-10: 38.0
Sum Reward: 242.0
Avg Reward: 24.2
Min Reward: 14.0
Gini Coefficient 0.171900826446281
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-13-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 259.32
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 366
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.912
    dispatch_time_ms: 6.919
    learner:
      cur_lr: 0.0011162440059706569
      grad_gnorm: 1.3963122367858887
      policy_entropy: 129.3748779296875
      policy_loss: -0.8756647109985352
      var_gnorm: 53.996646881103516
      vf_explained_var: 0.9896261096000671
      vf_loss: 0.0011842935346066952
    num_steps_sampled: 3670000
    num_steps_trained: 3670000
    wait_time_ms: 161.327
  iterations_since_restore: 367
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6547.58731842041
  time_this_iter_s: 17.434641122817993
  time_total_s: 6547.58731842041
  timestamp: 1593828829
  timesteps_since_restore: 3670000
  timesteps_this_iter: 10000
  timesteps_total: 3670000
  training_iteration: 367
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6547 s, 367 iter, 3670000 ts, 259 rew

agent-1: 16.0
agent-2: 44.0
agent-3: 32.0
agent-4: 33.0
agent-5: 14.0
agent-6: 28.0
agent-7: 24.0
agent-8: 26.0
agent-9: 22.0
agent-10: 20.0
Sum Reward: 259.0
Avg Reward: 25.9
Min Reward: 14.0
Gini Coefficient 0.1810810810810811
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-14-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 259.63
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 367
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.771
    dispatch_time_ms: 9.567
    learner:
      cur_lr: 0.001115577993914485
      grad_gnorm: 12.453758239746094
      policy_entropy: 129.37503051757812
      policy_loss: -4.632778167724609
      var_gnorm: 53.9760627746582
      vf_explained_var: 0.6618198156356812
      vf_loss: 0.08885783702135086
    num_steps_sampled: 3680000
    num_steps_trained: 3680000
    wait_time_ms: 166.089
  iterations_since_restore: 368
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6564.982167720795
  time_this_iter_s: 17.39484930038452
  time_total_s: 6564.982167720795
  timestamp: 1593828846
  timesteps_since_restore: 3680000
  timesteps_this_iter: 10000
  timesteps_total: 3680000
  training_iteration: 368
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6564 s, 368 iter, 3680000 ts, 260 rew

agent-1: 29.0
agent-2: 40.0
agent-3: 19.0
agent-4: 23.0
agent-5: 27.0
agent-6: 22.0
agent-7: 20.0
agent-8: 33.0
agent-9: 23.0
agent-10: 25.0
Sum Reward: 261.0
Avg Reward: 26.1
Min Reward: 19.0
Gini Coefficient 0.12605363984674328
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-14-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 260.02
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 368
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.56
    dispatch_time_ms: 7.958
    learner:
      cur_lr: 0.001114911981858313
      grad_gnorm: 0.9768272638320923
      policy_entropy: 122.88496398925781
      policy_loss: -0.36479413509368896
      var_gnorm: 54.050079345703125
      vf_explained_var: 0.9851558804512024
      vf_loss: 0.0006060187588445842
    num_steps_sampled: 3690000
    num_steps_trained: 3690000
    wait_time_ms: 161.358
  iterations_since_restore: 369
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6582.261078834534
  time_this_iter_s: 17.278911113739014
  time_total_s: 6582.261078834534
  timestamp: 1593828864
  timesteps_since_restore: 3690000
  timesteps_this_iter: 10000
  timesteps_total: 3690000
  training_iteration: 369
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6582 s, 369 iter, 3690000 ts, 260 rew

agent-1: 32.0
agent-2: 16.0
agent-3: 15.0
agent-4: 40.0
agent-5: 25.0
agent-6: 40.0
agent-7: 43.0
agent-8: 17.0
agent-9: 27.0
agent-10: 31.0
Sum Reward: 286.0
Avg Reward: 28.6
Min Reward: 15.0
Gini Coefficient 0.1958041958041958
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-14-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 260.6
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 369
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.841
    dispatch_time_ms: 6.659
    learner:
      cur_lr: 0.0011142459698021412
      grad_gnorm: 28.242578506469727
      policy_entropy: 117.28520965576172
      policy_loss: 14.376053810119629
      var_gnorm: 54.09370422363281
      vf_explained_var: 0.2274898886680603
      vf_loss: 4.587610721588135
    num_steps_sampled: 3700000
    num_steps_trained: 3700000
    wait_time_ms: 166.635
  iterations_since_restore: 370
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6599.4651753902435
  time_this_iter_s: 17.20409655570984
  time_total_s: 6599.4651753902435
  timestamp: 1593828881
  timesteps_since_restore: 3700000
  timesteps_this_iter: 10000
  timesteps_total: 3700000
  training_iteration: 370
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6599 s, 370 iter, 3700000 ts, 261 rew

agent-1: 24.0
agent-2: 16.0
agent-3: 27.0
agent-4: 34.0
agent-5: 17.0
agent-6: 37.0
agent-7: 27.0
agent-8: 30.0
agent-9: 20.0
agent-10: 33.0
Sum Reward: 265.0
Avg Reward: 26.5
Min Reward: 16.0
Gini Coefficient 0.14754716981132077
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-14-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 261.05
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 370
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.082
    dispatch_time_ms: 5.666
    learner:
      cur_lr: 0.0011135799577459693
      grad_gnorm: 40.0
      policy_entropy: 87.57998657226562
      policy_loss: -18.84298324584961
      var_gnorm: 54.09042739868164
      vf_explained_var: 0.5661874413490295
      vf_loss: 9.047187805175781
    num_steps_sampled: 3710000
    num_steps_trained: 3710000
    wait_time_ms: 164.613
  iterations_since_restore: 371
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6616.894948720932
  time_this_iter_s: 17.429773330688477
  time_total_s: 6616.894948720932
  timestamp: 1593828898
  timesteps_since_restore: 3710000
  timesteps_this_iter: 10000
  timesteps_total: 3710000
  training_iteration: 371
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6616 s, 371 iter, 3710000 ts, 261 rew

agent-1: 31.0
agent-2: 33.0
agent-3: 33.0
agent-4: 17.0
agent-5: 30.0
agent-6: 12.0
agent-7: 36.0
agent-8: 27.0
agent-9: 23.0
agent-10: 37.0
Sum Reward: 279.0
Avg Reward: 27.9
Min Reward: 12.0
Gini Coefficient 0.15304659498207884
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-15-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 261.66
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 371
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.853
    dispatch_time_ms: 8.193
    learner:
      cur_lr: 0.0011129139456897974
      grad_gnorm: 1.1843225955963135
      policy_entropy: 129.36170959472656
      policy_loss: 0.46117913722991943
      var_gnorm: 54.13460159301758
      vf_explained_var: 0.041787147521972656
      vf_loss: 0.0001686556206550449
    num_steps_sampled: 3720000
    num_steps_trained: 3720000
    wait_time_ms: 164.542
  iterations_since_restore: 372
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6634.249418258667
  time_this_iter_s: 17.354469537734985
  time_total_s: 6634.249418258667
  timestamp: 1593828916
  timesteps_since_restore: 3720000
  timesteps_this_iter: 10000
  timesteps_total: 3720000
  training_iteration: 372
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6634 s, 372 iter, 3720000 ts, 262 rew

agent-1: 22.0
agent-2: 20.0
agent-3: 13.0
agent-4: 23.0
agent-5: 24.0
agent-6: 19.0
agent-7: 31.0
agent-8: 24.0
agent-9: 28.0
agent-10: 16.0
Sum Reward: 220.0
Avg Reward: 22.0
Min Reward: 13.0
Gini Coefficient 0.1290909090909091
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-15-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 261.64
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 372
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.525
    dispatch_time_ms: 6.182
    learner:
      cur_lr: 0.0011122480500489473
      grad_gnorm: 0.5634217262268066
      policy_entropy: 128.64926147460938
      policy_loss: -0.2984289526939392
      var_gnorm: 54.182159423828125
      vf_explained_var: 0.02390187978744507
      vf_loss: 0.00016954545571934432
    num_steps_sampled: 3730000
    num_steps_trained: 3730000
    wait_time_ms: 165.238
  iterations_since_restore: 373
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6651.539078235626
  time_this_iter_s: 17.28965997695923
  time_total_s: 6651.539078235626
  timestamp: 1593828933
  timesteps_since_restore: 3730000
  timesteps_this_iter: 10000
  timesteps_total: 3730000
  training_iteration: 373
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6651 s, 373 iter, 3730000 ts, 262 rew

agent-1: 12.0
agent-2: 20.0
agent-3: 20.0
agent-4: 26.0
agent-5: 13.0
agent-6: 47.0
agent-7: 20.0
agent-8: 20.0
agent-9: 26.0
agent-10: 25.0
Sum Reward: 229.0
Avg Reward: 22.9
Min Reward: 12.0
Gini Coefficient 0.19694323144104803
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-15-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 261.31
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 373
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.301
    dispatch_time_ms: 8.837
    learner:
      cur_lr: 0.0011115820379927754
      grad_gnorm: 8.403253555297852
      policy_entropy: 98.79777526855469
      policy_loss: -0.4261764883995056
      var_gnorm: 54.157047271728516
      vf_explained_var: -1.0
      vf_loss: 0.05651051923632622
    num_steps_sampled: 3740000
    num_steps_trained: 3740000
    wait_time_ms: 167.76
  iterations_since_restore: 374
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6668.999624490738
  time_this_iter_s: 17.460546255111694
  time_total_s: 6668.999624490738
  timestamp: 1593828951
  timesteps_since_restore: 3740000
  timesteps_this_iter: 10000
  timesteps_total: 3740000
  training_iteration: 374
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6668 s, 374 iter, 3740000 ts, 261 rew

agent-1: 19.0
agent-2: 31.0
agent-3: 27.0
agent-4: 30.0
agent-5: 15.0
agent-6: 29.0
agent-7: 22.0
agent-8: 18.0
agent-9: 18.0
agent-10: 24.0
Sum Reward: 233.0
Avg Reward: 23.3
Min Reward: 15.0
Gini Coefficient 0.13261802575107295
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-16-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 260.88
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 374
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.397
    dispatch_time_ms: 7.72
    learner:
      cur_lr: 0.0011109160259366035
      grad_gnorm: 3.537177085876465
      policy_entropy: 103.91998291015625
      policy_loss: -1.0725069046020508
      var_gnorm: 54.17119216918945
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.0071249003522098064
    num_steps_sampled: 3750000
    num_steps_trained: 3750000
    wait_time_ms: 158.304
  iterations_since_restore: 375
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6686.247896671295
  time_this_iter_s: 17.24827218055725
  time_total_s: 6686.247896671295
  timestamp: 1593828968
  timesteps_since_restore: 3750000
  timesteps_this_iter: 10000
  timesteps_total: 3750000
  training_iteration: 375
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6686 s, 375 iter, 3750000 ts, 261 rew

agent-1: 51.0
agent-2: 24.0
agent-3: 25.0
agent-4: 18.0
agent-5: 26.0
agent-6: 28.0
agent-7: 18.0
agent-8: 24.0
agent-9: 28.0
agent-10: 32.0
Sum Reward: 274.0
Avg Reward: 27.4
Min Reward: 18.0
Gini Coefficient 0.1562043795620438
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-16-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 260.47
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 375
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.537
    dispatch_time_ms: 6.21
    learner:
      cur_lr: 0.0011102500138804317
      grad_gnorm: 7.917861461639404
      policy_entropy: 120.04332733154297
      policy_loss: -2.5346224308013916
      var_gnorm: 54.26863098144531
      vf_explained_var: -0.6965013742446899
      vf_loss: 0.03724846988916397
    num_steps_sampled: 3760000
    num_steps_trained: 3760000
    wait_time_ms: 160.872
  iterations_since_restore: 376
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6703.605326652527
  time_this_iter_s: 17.35742998123169
  time_total_s: 6703.605326652527
  timestamp: 1593828985
  timesteps_since_restore: 3760000
  timesteps_this_iter: 10000
  timesteps_total: 3760000
  training_iteration: 376
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6703 s, 376 iter, 3760000 ts, 260 rew

agent-1: 12.0
agent-2: 35.0
agent-3: 21.0
agent-4: 15.0
agent-5: 35.0
agent-6: 24.0
agent-7: 20.0
agent-8: 22.0
agent-9: 13.0
agent-10: 35.0
Sum Reward: 232.0
Avg Reward: 23.2
Min Reward: 12.0
Gini Coefficient 0.2043103448275862
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-16-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 260.48
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 376
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.168
    dispatch_time_ms: 6.599
    learner:
      cur_lr: 0.0011095840018242598
      grad_gnorm: 3.4679558277130127
      policy_entropy: 118.4996337890625
      policy_loss: -0.7280371189117432
      var_gnorm: 54.267635345458984
      vf_explained_var: 0.9952898621559143
      vf_loss: 0.07451268285512924
    num_steps_sampled: 3770000
    num_steps_trained: 3770000
    wait_time_ms: 160.93
  iterations_since_restore: 377
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6720.926247596741
  time_this_iter_s: 17.320920944213867
  time_total_s: 6720.926247596741
  timestamp: 1593829003
  timesteps_since_restore: 3770000
  timesteps_this_iter: 10000
  timesteps_total: 3770000
  training_iteration: 377
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6720 s, 377 iter, 3770000 ts, 260 rew

agent-1: 35.0
agent-2: 32.0
agent-3: 8.0
agent-4: 16.0
agent-5: 19.0
agent-6: 32.0
agent-7: 18.0
agent-8: 23.0
agent-9: 123.0
agent-10: 18.0
Sum Reward: 324.0
Avg Reward: 32.4
Min Reward: 8.0
Gini Coefficient 0.3962962962962963
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-17-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 261.05
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 377
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.842
    dispatch_time_ms: 7.297
    learner:
      cur_lr: 0.0011089179897680879
      grad_gnorm: 4.580292224884033
      policy_entropy: 125.71543884277344
      policy_loss: 1.8312196731567383
      var_gnorm: 54.31129455566406
      vf_explained_var: 0.0
      vf_loss: 0.01268700696527958
    num_steps_sampled: 3780000
    num_steps_trained: 3780000
    wait_time_ms: 171.932
  iterations_since_restore: 378
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6738.209353208542
  time_this_iter_s: 17.283105611801147
  time_total_s: 6738.209353208542
  timestamp: 1593829020
  timesteps_since_restore: 3780000
  timesteps_this_iter: 10000
  timesteps_total: 3780000
  training_iteration: 378
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6738 s, 378 iter, 3780000 ts, 261 rew

agent-1: 26.0
agent-2: 22.0
agent-3: 13.0
agent-4: 23.0
agent-5: 22.0
agent-6: 31.0
agent-7: 21.0
agent-8: 34.0
agent-9: 19.0
agent-10: 25.0
Sum Reward: 236.0
Avg Reward: 23.6
Min Reward: 13.0
Gini Coefficient 0.13050847457627118
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-17-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 260.86
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 378
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 4.03
    dispatch_time_ms: 5.784
    learner:
      cur_lr: 0.001108251977711916
      grad_gnorm: 40.0
      policy_entropy: 48.22636032104492
      policy_loss: 1.6961545944213867
      var_gnorm: 54.34157180786133
      vf_explained_var: 0.23766660690307617
      vf_loss: 49.71634292602539
    num_steps_sampled: 3790000
    num_steps_trained: 3790000
    wait_time_ms: 159.043
  iterations_since_restore: 379
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6755.4712517261505
  time_this_iter_s: 17.261898517608643
  time_total_s: 6755.4712517261505
  timestamp: 1593829037
  timesteps_since_restore: 3790000
  timesteps_this_iter: 10000
  timesteps_total: 3790000
  training_iteration: 379
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6755 s, 379 iter, 3790000 ts, 261 rew

agent-1: 15.0
agent-2: 38.0
agent-3: 27.0
agent-4: 27.0
agent-5: 35.0
agent-6: 22.0
agent-7: 21.0
agent-8: 25.0
agent-9: 34.0
agent-10: 19.0
Sum Reward: 263.0
Avg Reward: 26.3
Min Reward: 15.0
Gini Coefficient 0.15247148288973383
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-17-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 260.91
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 379
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.948
    dispatch_time_ms: 8.447
    learner:
      cur_lr: 0.001107585965655744
      grad_gnorm: 4.736959934234619
      policy_entropy: 122.1767349243164
      policy_loss: -1.6067135334014893
      var_gnorm: 54.39803695678711
      vf_explained_var: 0.021232962608337402
      vf_loss: 0.012278632260859013
    num_steps_sampled: 3800000
    num_steps_trained: 3800000
    wait_time_ms: 166.287
  iterations_since_restore: 380
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6772.699950933456
  time_this_iter_s: 17.228699207305908
  time_total_s: 6772.699950933456
  timestamp: 1593829055
  timesteps_since_restore: 3800000
  timesteps_this_iter: 10000
  timesteps_total: 3800000
  training_iteration: 380
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6772 s, 380 iter, 3800000 ts, 261 rew

agent-1: 38.0
agent-2: 17.0
agent-3: 26.0
agent-4: 29.0
agent-5: 16.0
agent-6: 27.0
agent-7: 22.0
agent-8: 25.0
agent-9: 23.0
agent-10: 27.0
Sum Reward: 250.0
Avg Reward: 25.0
Min Reward: 16.0
Gini Coefficient 0.128
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-17-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 260.76
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 380
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.956
    dispatch_time_ms: 6.602
    learner:
      cur_lr: 0.0011069199535995722
      grad_gnorm: 40.000003814697266
      policy_entropy: 83.24954986572266
      policy_loss: 12.67546558380127
      var_gnorm: 54.39445877075195
      vf_explained_var: 0.9164023995399475
      vf_loss: 30.926212310791016
    num_steps_sampled: 3810000
    num_steps_trained: 3810000
    wait_time_ms: 157.402
  iterations_since_restore: 381
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6790.224668741226
  time_this_iter_s: 17.524717807769775
  time_total_s: 6790.224668741226
  timestamp: 1593829072
  timesteps_since_restore: 3810000
  timesteps_this_iter: 10000
  timesteps_total: 3810000
  training_iteration: 381
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6790 s, 381 iter, 3810000 ts, 261 rew

agent-1: 18.0
agent-2: 29.0
agent-3: 23.0
agent-4: 29.0
agent-5: 24.0
agent-6: 17.0
agent-7: 18.0
agent-8: 30.0
agent-9: 20.0
agent-10: 23.0
Sum Reward: 231.0
Avg Reward: 23.1
Min Reward: 17.0
Gini Coefficient 0.11298701298701298
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-18-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 260.5
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 381
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.781
    dispatch_time_ms: 8.676
    learner:
      cur_lr: 0.0011062540579587221
      grad_gnorm: 0.3938465416431427
      policy_entropy: 120.08078002929688
      policy_loss: 0.0800573080778122
      var_gnorm: 54.45062255859375
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 5.7846780691761523e-05
    num_steps_sampled: 3820000
    num_steps_trained: 3820000
    wait_time_ms: 162.201
  iterations_since_restore: 382
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6807.652274847031
  time_this_iter_s: 17.427606105804443
  time_total_s: 6807.652274847031
  timestamp: 1593829090
  timesteps_since_restore: 3820000
  timesteps_this_iter: 10000
  timesteps_total: 3820000
  training_iteration: 382
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6807 s, 382 iter, 3820000 ts, 260 rew

agent-1: 38.0
agent-2: 19.0
agent-3: 42.0
agent-4: 35.0
agent-5: 11.0
agent-6: 12.0
agent-7: 39.0
agent-8: 20.0
agent-9: 15.0
agent-10: 25.0
Sum Reward: 256.0
Avg Reward: 25.6
Min Reward: 11.0
Gini Coefficient 0.2484375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-18-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 259.81
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 382
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.123
    dispatch_time_ms: 546.03
    learner:
      cur_lr: 0.0011055880459025502
      grad_gnorm: 4.714820861816406
      policy_entropy: 127.80427551269531
      policy_loss: -0.36235615611076355
      var_gnorm: 54.47943878173828
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.010741906240582466
    num_steps_sampled: 3830000
    num_steps_trained: 3830000
    wait_time_ms: 135.652
  iterations_since_restore: 383
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6830.193024635315
  time_this_iter_s: 22.5407497882843
  time_total_s: 6830.193024635315
  timestamp: 1593829112
  timesteps_since_restore: 3830000
  timesteps_this_iter: 10000
  timesteps_total: 3830000
  training_iteration: 383
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6830 s, 383 iter, 3830000 ts, 260 rew

agent-1: 19.0
agent-2: 17.0
agent-3: 20.0
agent-4: 15.0
agent-5: 22.0
agent-6: 24.0
agent-7: 19.0
agent-8: 23.0
agent-9: 23.0
agent-10: 18.0
Sum Reward: 200.0
Avg Reward: 20.0
Min Reward: 15.0
Gini Coefficient 0.079
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-18-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 470.0
  episode_reward_mean: 257.44
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 383
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.952
    dispatch_time_ms: 5.803
    learner:
      cur_lr: 0.0011049220338463783
      grad_gnorm: 4.902313232421875
      policy_entropy: 136.1072540283203
      policy_loss: 2.638685941696167
      var_gnorm: 54.621829986572266
      vf_explained_var: 0.005783379077911377
      vf_loss: 0.01373296044766903
    num_steps_sampled: 3840000
    num_steps_trained: 3840000
    wait_time_ms: 165.543
  iterations_since_restore: 384
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6846.18558382988
  time_this_iter_s: 15.99255919456482
  time_total_s: 6846.18558382988
  timestamp: 1593829128
  timesteps_since_restore: 3840000
  timesteps_this_iter: 10000
  timesteps_total: 3840000
  training_iteration: 384
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6846 s, 384 iter, 3840000 ts, 257 rew

agent-1: 21.0
agent-2: 18.0
agent-3: 12.0
agent-4: 24.0
agent-5: 26.0
agent-6: 16.0
agent-7: 33.0
agent-8: 20.0
agent-9: 29.0
agent-10: 33.0
Sum Reward: 232.0
Avg Reward: 23.2
Min Reward: 12.0
Gini Coefficient 0.16551724137931034
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-19-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 434.0
  episode_reward_mean: 255.06
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 384
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.263
    dispatch_time_ms: 6.849
    learner:
      cur_lr: 0.0011042560217902064
      grad_gnorm: 3.0979270935058594
      policy_entropy: 137.7167510986328
      policy_loss: -1.2589668035507202
      var_gnorm: 54.59254837036133
      vf_explained_var: 0.0
      vf_loss: 0.0057612196542322636
    num_steps_sampled: 3850000
    num_steps_trained: 3850000
    wait_time_ms: 161.507
  iterations_since_restore: 385
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6863.611203670502
  time_this_iter_s: 17.42561984062195
  time_total_s: 6863.611203670502
  timestamp: 1593829146
  timesteps_since_restore: 3850000
  timesteps_this_iter: 10000
  timesteps_total: 3850000
  training_iteration: 385
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6863 s, 385 iter, 3850000 ts, 255 rew

agent-1: 32.0
agent-2: 20.0
agent-3: 30.0
agent-4: 17.0
agent-5: 36.0
agent-6: 16.0
agent-7: 47.0
agent-8: 34.0
agent-9: 15.0
agent-10: 27.0
Sum Reward: 274.0
Avg Reward: 27.4
Min Reward: 15.0
Gini Coefficient 0.20145985401459854
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-19-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 410.0
  episode_reward_mean: 253.46
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 385
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.27
    dispatch_time_ms: 12.177
    learner:
      cur_lr: 0.0011035900097340345
      grad_gnorm: 3.9719607830047607
      policy_entropy: 130.59576416015625
      policy_loss: -1.1129168272018433
      var_gnorm: 54.652809143066406
      vf_explained_var: 0.9868898391723633
      vf_loss: 0.019720185548067093
    num_steps_sampled: 3860000
    num_steps_trained: 3860000
    wait_time_ms: 166.968
  iterations_since_restore: 386
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6881.234224557877
  time_this_iter_s: 17.623020887374878
  time_total_s: 6881.234224557877
  timestamp: 1593829163
  timesteps_since_restore: 3860000
  timesteps_this_iter: 10000
  timesteps_total: 3860000
  training_iteration: 386
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6881 s, 386 iter, 3860000 ts, 253 rew

agent-1: 13.0
agent-2: 35.0
agent-3: 27.0
agent-4: 26.0
agent-5: 34.0
agent-6: 30.0
agent-7: 21.0
agent-8: 21.0
agent-9: 27.0
agent-10: 10.0
Sum Reward: 244.0
Avg Reward: 24.4
Min Reward: 10.0
Gini Coefficient 0.17868852459016393
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-19-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 410.0
  episode_reward_mean: 252.05
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 386
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.469
    dispatch_time_ms: 32.212
    learner:
      cur_lr: 0.0011029239976778626
      grad_gnorm: 40.000003814697266
      policy_entropy: 39.61056137084961
      policy_loss: -31.76974868774414
      var_gnorm: 54.611244201660156
      vf_explained_var: 0.6944059133529663
      vf_loss: 146.30824279785156
    num_steps_sampled: 3870000
    num_steps_trained: 3870000
    wait_time_ms: 143.298
  iterations_since_restore: 387
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6899.364254951477
  time_this_iter_s: 18.130030393600464
  time_total_s: 6899.364254951477
  timestamp: 1593829182
  timesteps_since_restore: 3870000
  timesteps_this_iter: 10000
  timesteps_total: 3870000
  training_iteration: 387
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6899 s, 387 iter, 3870000 ts, 252 rew

agent-1: 25.0
agent-2: 17.0
agent-3: 38.0
agent-4: 48.0
agent-5: 18.0
agent-6: 29.0
agent-7: 30.0
agent-8: 22.0
agent-9: 17.0
agent-10: 28.0
Sum Reward: 272.0
Avg Reward: 27.2
Min Reward: 17.0
Gini Coefficient 0.1875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-20-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 403.0
  episode_reward_mean: 250.67
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 387
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 4.033
    dispatch_time_ms: 39.855
    learner:
      cur_lr: 0.0011022579856216908
      grad_gnorm: 5.4969024658203125
      policy_entropy: 143.54327392578125
      policy_loss: 5.380193710327148
      var_gnorm: 54.646934509277344
      vf_explained_var: 0.0
      vf_loss: 0.014096480794250965
    num_steps_sampled: 3880000
    num_steps_trained: 3880000
    wait_time_ms: 143.461
  iterations_since_restore: 388
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6917.462290525436
  time_this_iter_s: 18.09803557395935
  time_total_s: 6917.462290525436
  timestamp: 1593829200
  timesteps_since_restore: 3880000
  timesteps_this_iter: 10000
  timesteps_total: 3880000
  training_iteration: 388
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6917 s, 388 iter, 3880000 ts, 251 rew

agent-1: 20.0
agent-2: 37.0
agent-3: 29.0
agent-4: 34.0
agent-5: 12.0
agent-6: 17.0
agent-7: 18.0
agent-8: 27.0
agent-9: 11.0
agent-10: 35.0
Sum Reward: 240.0
Avg Reward: 24.0
Min Reward: 11.0
Gini Coefficient 0.21666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-20-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 403.0
  episode_reward_mean: 249.96
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 388
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.905
    dispatch_time_ms: 34.32
    learner:
      cur_lr: 0.0011015919735655189
      grad_gnorm: 1.3710613250732422
      policy_entropy: 147.49880981445312
      policy_loss: -1.8281582593917847
      var_gnorm: 54.686248779296875
      vf_explained_var: 0.0
      vf_loss: 9.726199641590938e-05
    num_steps_sampled: 3890000
    num_steps_trained: 3890000
    wait_time_ms: 157.253
  iterations_since_restore: 389
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6935.858281135559
  time_this_iter_s: 18.39599061012268
  time_total_s: 6935.858281135559
  timestamp: 1593829218
  timesteps_since_restore: 3890000
  timesteps_this_iter: 10000
  timesteps_total: 3890000
  training_iteration: 389
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6935 s, 389 iter, 3890000 ts, 250 rew

agent-1: 27.0
agent-2: 32.0
agent-3: 14.0
agent-4: 35.0
agent-5: 25.0
agent-6: 34.0
agent-7: 8.0
agent-8: 18.0
agent-9: 20.0
agent-10: 23.0
Sum Reward: 236.0
Avg Reward: 23.6
Min Reward: 8.0
Gini Coefficient 0.2016949152542373
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-20-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 248.29
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 389
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.4
    dispatch_time_ms: 22.386
    learner:
      cur_lr: 0.001100925961509347
      grad_gnorm: 0.5093703269958496
      policy_entropy: 148.07908630371094
      policy_loss: 0.4896666705608368
      var_gnorm: 54.689693450927734
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 0.00011426606215536594
    num_steps_sampled: 3900000
    num_steps_trained: 3900000
    wait_time_ms: 166.057
  iterations_since_restore: 390
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6954.2190198898315
  time_this_iter_s: 18.36073875427246
  time_total_s: 6954.2190198898315
  timestamp: 1593829237
  timesteps_since_restore: 3900000
  timesteps_this_iter: 10000
  timesteps_total: 3900000
  training_iteration: 390
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6954 s, 390 iter, 3900000 ts, 248 rew

agent-1: 27.0
agent-2: 19.0
agent-3: 18.0
agent-4: 22.0
agent-5: 30.0
agent-6: 15.0
agent-7: 32.0
agent-8: 24.0
agent-9: 21.0
agent-10: 23.0
Sum Reward: 231.0
Avg Reward: 23.1
Min Reward: 15.0
Gini Coefficient 0.12424242424242424
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-20-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 247.81
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 390
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.018
    dispatch_time_ms: 6.189
    learner:
      cur_lr: 0.001100259949453175
      grad_gnorm: 1.3458248376846313
      policy_entropy: 152.05905151367188
      policy_loss: -0.7070818543434143
      var_gnorm: 54.645286560058594
      vf_explained_var: -1.0
      vf_loss: 0.006251535378396511
    num_steps_sampled: 3910000
    num_steps_trained: 3910000
    wait_time_ms: 164.886
  iterations_since_restore: 391
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6971.586759090424
  time_this_iter_s: 17.36773920059204
  time_total_s: 6971.586759090424
  timestamp: 1593829254
  timesteps_since_restore: 3910000
  timesteps_this_iter: 10000
  timesteps_total: 3910000
  training_iteration: 391
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6971 s, 391 iter, 3910000 ts, 248 rew

agent-1: 32.0
agent-2: 13.0
agent-3: 30.0
agent-4: 17.0
agent-5: 25.0
agent-6: 26.0
agent-7: 19.0
agent-8: 20.0
agent-9: 29.0
agent-10: 22.0
Sum Reward: 233.0
Avg Reward: 23.3
Min Reward: 13.0
Gini Coefficient 0.14291845493562233
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-21-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 247.42
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 391
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.801
    dispatch_time_ms: 6.42
    learner:
      cur_lr: 0.001099594053812325
      grad_gnorm: 3.138706922531128
      policy_entropy: 144.281005859375
      policy_loss: -0.12431055307388306
      var_gnorm: 54.799564361572266
      vf_explained_var: -1.0
      vf_loss: 0.08984068781137466
    num_steps_sampled: 3920000
    num_steps_trained: 3920000
    wait_time_ms: 165.846
  iterations_since_restore: 392
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 6989.06755399704
  time_this_iter_s: 17.48079490661621
  time_total_s: 6989.06755399704
  timestamp: 1593829272
  timesteps_since_restore: 3920000
  timesteps_this_iter: 10000
  timesteps_total: 3920000
  training_iteration: 392
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 6989 s, 392 iter, 3920000 ts, 247 rew

agent-1: 40.0
agent-2: 21.0
agent-3: 26.0
agent-4: 29.0
agent-5: 22.0
agent-6: 21.0
agent-7: 25.0
agent-8: 30.0
agent-9: 23.0
agent-10: 19.0
Sum Reward: 256.0
Avg Reward: 25.6
Min Reward: 19.0
Gini Coefficient 0.11953125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-21-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 247.41
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 392
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.036
    dispatch_time_ms: 5.725
    learner:
      cur_lr: 0.001098928041756153
      grad_gnorm: 1.1906960010528564
      policy_entropy: 145.79588317871094
      policy_loss: -0.521812379360199
      var_gnorm: 54.80282211303711
      vf_explained_var: 0.17118537425994873
      vf_loss: 0.000805016839876771
    num_steps_sampled: 3930000
    num_steps_trained: 3930000
    wait_time_ms: 169.171
  iterations_since_restore: 393
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7006.488888502121
  time_this_iter_s: 17.421334505081177
  time_total_s: 7006.488888502121
  timestamp: 1593829289
  timesteps_since_restore: 3930000
  timesteps_this_iter: 10000
  timesteps_total: 3930000
  training_iteration: 393
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7006 s, 393 iter, 3930000 ts, 247 rew

agent-1: 29.0
agent-2: 24.0
agent-3: 26.0
agent-4: 21.0
agent-5: 25.0
agent-6: 32.0
agent-7: 17.0
agent-8: 14.0
agent-9: 26.0
agent-10: 20.0
Sum Reward: 234.0
Avg Reward: 23.4
Min Reward: 14.0
Gini Coefficient 0.12478632478632479
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-21-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 247.05
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 393
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.645
    dispatch_time_ms: 6.204
    learner:
      cur_lr: 0.0010982620296999812
      grad_gnorm: 13.571613311767578
      policy_entropy: 132.52061462402344
      policy_loss: 0.2374681532382965
      var_gnorm: 55.0182991027832
      vf_explained_var: -1.0
      vf_loss: 0.017762865871191025
    num_steps_sampled: 3940000
    num_steps_trained: 3940000
    wait_time_ms: 167.109
  iterations_since_restore: 394
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7023.791867494583
  time_this_iter_s: 17.302978992462158
  time_total_s: 7023.791867494583
  timestamp: 1593829307
  timesteps_since_restore: 3940000
  timesteps_this_iter: 10000
  timesteps_total: 3940000
  training_iteration: 394
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7023 s, 394 iter, 3940000 ts, 247 rew

agent-1: 44.0
agent-2: 21.0
agent-3: 55.0
agent-4: 26.0
agent-5: 33.0
agent-6: 18.0
agent-7: 21.0
agent-8: 24.0
agent-9: 14.0
agent-10: 16.0
Sum Reward: 272.0
Avg Reward: 27.2
Min Reward: 14.0
Gini Coefficient 0.24191176470588235
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-22-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 246.99
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 394
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.914
    dispatch_time_ms: 7.645
    learner:
      cur_lr: 0.0010975960176438093
      grad_gnorm: 1.512879729270935
      policy_entropy: 141.46072387695312
      policy_loss: -0.6348615288734436
      var_gnorm: 55.05986785888672
      vf_explained_var: -1.0
      vf_loss: 0.006437657400965691
    num_steps_sampled: 3950000
    num_steps_trained: 3950000
    wait_time_ms: 157.562
  iterations_since_restore: 395
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7041.247476577759
  time_this_iter_s: 17.45560908317566
  time_total_s: 7041.247476577759
  timestamp: 1593829324
  timesteps_since_restore: 3950000
  timesteps_this_iter: 10000
  timesteps_total: 3950000
  training_iteration: 395
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7041 s, 395 iter, 3950000 ts, 247 rew

agent-1: 22.0
agent-2: 22.0
agent-3: 22.0
agent-4: 40.0
agent-5: 25.0
agent-6: 25.0
agent-7: 29.0
agent-8: 24.0
agent-9: 32.0
agent-10: 25.0
Sum Reward: 266.0
Avg Reward: 26.6
Min Reward: 22.0
Gini Coefficient 0.10150375939849623
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-22-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 247.17
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 395
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 4.028
    dispatch_time_ms: 7.462
    learner:
      cur_lr: 0.0010969300055876374
      grad_gnorm: 1.0266824960708618
      policy_entropy: 121.49046325683594
      policy_loss: 0.21912193298339844
      var_gnorm: 55.165771484375
      vf_explained_var: -1.0
      vf_loss: 0.02424127236008644
    num_steps_sampled: 3960000
    num_steps_trained: 3960000
    wait_time_ms: 165.466
  iterations_since_restore: 396
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7058.65185046196
  time_this_iter_s: 17.40437388420105
  time_total_s: 7058.65185046196
  timestamp: 1593829341
  timesteps_since_restore: 3960000
  timesteps_this_iter: 10000
  timesteps_total: 3960000
  training_iteration: 396
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7058 s, 396 iter, 3960000 ts, 247 rew

agent-1: 19.0
agent-2: 33.0
agent-3: 30.0
agent-4: 31.0
agent-5: 19.0
agent-6: 23.0
agent-7: 20.0
agent-8: 23.0
agent-9: 32.0
agent-10: 29.0
Sum Reward: 259.0
Avg Reward: 25.9
Min Reward: 19.0
Gini Coefficient 0.11544401544401545
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-22-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 247.14
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 396
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.809
    dispatch_time_ms: 7.9
    learner:
      cur_lr: 0.0010962639935314655
      grad_gnorm: 1.7726866006851196
      policy_entropy: 140.5428009033203
      policy_loss: 0.3584011197090149
      var_gnorm: 55.158138275146484
      vf_explained_var: -0.17769348621368408
      vf_loss: 0.04957601800560951
    num_steps_sampled: 3970000
    num_steps_trained: 3970000
    wait_time_ms: 161.732
  iterations_since_restore: 397
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7076.2092435359955
  time_this_iter_s: 17.557393074035645
  time_total_s: 7076.2092435359955
  timestamp: 1593829359
  timesteps_since_restore: 3970000
  timesteps_this_iter: 10000
  timesteps_total: 3970000
  training_iteration: 397
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7076 s, 397 iter, 3970000 ts, 247 rew

agent-1: 23.0
agent-2: 25.0
agent-3: 22.0
agent-4: 21.0
agent-5: 22.0
agent-6: 21.0
agent-7: 24.0
agent-8: 30.0
agent-9: 13.0
agent-10: 33.0
Sum Reward: 234.0
Avg Reward: 23.4
Min Reward: 13.0
Gini Coefficient 0.11538461538461539
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-22-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 247.2
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 397
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.024
    dispatch_time_ms: 9.004
    learner:
      cur_lr: 0.0010955979814752936
      grad_gnorm: 2.2763190269470215
      policy_entropy: 142.51309204101562
      policy_loss: -1.072497010231018
      var_gnorm: 55.25437927246094
      vf_explained_var: 0.9731659293174744
      vf_loss: 0.008316432125866413
    num_steps_sampled: 3980000
    num_steps_trained: 3980000
    wait_time_ms: 163.282
  iterations_since_restore: 398
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7093.536830663681
  time_this_iter_s: 17.327587127685547
  time_total_s: 7093.536830663681
  timestamp: 1593829376
  timesteps_since_restore: 3980000
  timesteps_this_iter: 10000
  timesteps_total: 3980000
  training_iteration: 398
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7093 s, 398 iter, 3980000 ts, 247 rew

agent-1: 22.0
agent-2: 29.0
agent-3: 15.0
agent-4: 36.0
agent-5: 11.0
agent-6: 25.0
agent-7: 25.0
agent-8: 22.0
agent-9: 20.0
agent-10: 20.0
Sum Reward: 225.0
Avg Reward: 22.5
Min Reward: 11.0
Gini Coefficient 0.16133333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-23-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 247.07
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 398
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.163
    dispatch_time_ms: 5.992
    learner:
      cur_lr: 0.0010949319694191217
      grad_gnorm: 2.787801742553711
      policy_entropy: 149.13729858398438
      policy_loss: -1.111863613128662
      var_gnorm: 55.27015686035156
      vf_explained_var: 0.5879316926002502
      vf_loss: 0.009215367957949638
    num_steps_sampled: 3990000
    num_steps_trained: 3990000
    wait_time_ms: 173.017
  iterations_since_restore: 399
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7111.1316113471985
  time_this_iter_s: 17.594780683517456
  time_total_s: 7111.1316113471985
  timestamp: 1593829394
  timesteps_since_restore: 3990000
  timesteps_this_iter: 10000
  timesteps_total: 3990000
  training_iteration: 399
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7111 s, 399 iter, 3990000 ts, 247 rew

agent-1: 34.0
agent-2: 36.0
agent-3: 23.0
agent-4: 28.0
agent-5: 29.0
agent-6: 22.0
agent-7: 19.0
agent-8: 19.0
agent-9: 31.0
agent-10: 27.0
Sum Reward: 268.0
Avg Reward: 26.8
Min Reward: 19.0
Gini Coefficient 0.12014925373134329
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-23-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 247.49
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 399
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.761
    dispatch_time_ms: 6.609
    learner:
      cur_lr: 0.0010942659573629498
      grad_gnorm: 39.999961853027344
      policy_entropy: 100.94868469238281
      policy_loss: 3.047220230102539
      var_gnorm: 55.495094299316406
      vf_explained_var: 0.7877950072288513
      vf_loss: 18.361391067504883
    num_steps_sampled: 4000000
    num_steps_trained: 4000000
    wait_time_ms: 167.769
  iterations_since_restore: 400
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7128.140825986862
  time_this_iter_s: 17.009214639663696
  time_total_s: 7128.140825986862
  timestamp: 1593829411
  timesteps_since_restore: 4000000
  timesteps_this_iter: 10000
  timesteps_total: 4000000
  training_iteration: 400
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7128 s, 400 iter, 4000000 ts, 247 rew

agent-1: 20.0
agent-2: 32.0
agent-3: 30.0
agent-4: 29.0
agent-5: 25.0
agent-6: 25.0
agent-7: 36.0
agent-8: 23.0
agent-9: 21.0
agent-10: 31.0
Sum Reward: 272.0
Avg Reward: 27.2
Min Reward: 20.0
Gini Coefficient 0.10294117647058823
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-23-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 247.97
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 400
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.642
    dispatch_time_ms: 7.591
    learner:
      cur_lr: 0.001093599945306778
      grad_gnorm: 39.999996185302734
      policy_entropy: 79.95069122314453
      policy_loss: 10.14406967163086
      var_gnorm: 55.52751541137695
      vf_explained_var: 0.8147414326667786
      vf_loss: 45.326839447021484
    num_steps_sampled: 4010000
    num_steps_trained: 4010000
    wait_time_ms: 158.996
  iterations_since_restore: 401
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7149.738219976425
  time_this_iter_s: 21.59739398956299
  time_total_s: 7149.738219976425
  timestamp: 1593829433
  timesteps_since_restore: 4010000
  timesteps_this_iter: 10000
  timesteps_total: 4010000
  training_iteration: 401
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7149 s, 401 iter, 4010000 ts, 248 rew

agent-1: 28.0
agent-2: 42.0
agent-3: 16.0
agent-4: 41.0
agent-5: 55.0
agent-6: 32.0
agent-7: 45.0
agent-8: 27.0
agent-9: 24.0
agent-10: 20.0
Sum Reward: 330.0
Avg Reward: 33.0
Min Reward: 16.0
Gini Coefficient 0.2006060606060606
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-24-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 249.0
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 401
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 4.089
    dispatch_time_ms: 6.559
    learner:
      cur_lr: 0.0010929340496659279
      grad_gnorm: 8.348973274230957
      policy_entropy: 138.77857971191406
      policy_loss: -0.04956270009279251
      var_gnorm: 55.61613082885742
      vf_explained_var: 0.8913513422012329
      vf_loss: 2.963907480239868
    num_steps_sampled: 4020000
    num_steps_trained: 4020000
    wait_time_ms: 167.143
  iterations_since_restore: 402
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7166.8313908576965
  time_this_iter_s: 17.093170881271362
  time_total_s: 7166.8313908576965
  timestamp: 1593829450
  timesteps_since_restore: 4020000
  timesteps_this_iter: 10000
  timesteps_total: 4020000
  training_iteration: 402
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7166 s, 402 iter, 4020000 ts, 249 rew

agent-1: 30.0
agent-2: 25.0
agent-3: 25.0
agent-4: 40.0
agent-5: 41.0
agent-6: 35.0
agent-7: 38.0
agent-8: 36.0
agent-9: 34.0
agent-10: 30.0
Sum Reward: 334.0
Avg Reward: 33.4
Min Reward: 25.0
Gini Coefficient 0.09221556886227544
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-24-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 249.9
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 402
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.082
    dispatch_time_ms: 6.615
    learner:
      cur_lr: 0.001092268037609756
      grad_gnorm: 2.098149061203003
      policy_entropy: 135.30873107910156
      policy_loss: -0.4183342754840851
      var_gnorm: 55.605892181396484
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 0.0026228486094623804
    num_steps_sampled: 4030000
    num_steps_trained: 4030000
    wait_time_ms: 153.769
  iterations_since_restore: 403
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7184.226491689682
  time_this_iter_s: 17.395100831985474
  time_total_s: 7184.226491689682
  timestamp: 1593829467
  timesteps_since_restore: 4030000
  timesteps_this_iter: 10000
  timesteps_total: 4030000
  training_iteration: 403
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7184 s, 403 iter, 4030000 ts, 250 rew

agent-1: 24.0
agent-2: 23.0
agent-3: 30.0
agent-4: 26.0
agent-5: 47.0
agent-6: 19.0
agent-7: 23.0
agent-8: 26.0
agent-9: 30.0
agent-10: 25.0
Sum Reward: 273.0
Avg Reward: 27.3
Min Reward: 19.0
Gini Coefficient 0.12564102564102564
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-24-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 250.31
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 403
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.072
    dispatch_time_ms: 5.862
    learner:
      cur_lr: 0.001091602025553584
      grad_gnorm: 26.439393997192383
      policy_entropy: 93.68943786621094
      policy_loss: -7.480437755584717
      var_gnorm: 55.663002014160156
      vf_explained_var: 0.26418501138687134
      vf_loss: 1.644079566001892
    num_steps_sampled: 4040000
    num_steps_trained: 4040000
    wait_time_ms: 164.586
  iterations_since_restore: 404
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7201.458756446838
  time_this_iter_s: 17.232264757156372
  time_total_s: 7201.458756446838
  timestamp: 1593829485
  timesteps_since_restore: 4040000
  timesteps_this_iter: 10000
  timesteps_total: 4040000
  training_iteration: 404
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7201 s, 404 iter, 4040000 ts, 250 rew

agent-1: 16.0
agent-2: 51.0
agent-3: 41.0
agent-4: 39.0
agent-5: 35.0
agent-6: 26.0
agent-7: 19.0
agent-8: 14.0
agent-9: 40.0
agent-10: 36.0
Sum Reward: 317.0
Avg Reward: 31.7
Min Reward: 14.0
Gini Coefficient 0.20599369085173502
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-25-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 251.18
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 404
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.726
    dispatch_time_ms: 7.9
    learner:
      cur_lr: 0.0010909360134974122
      grad_gnorm: 40.0
      policy_entropy: 59.004981994628906
      policy_loss: 19.27884864807129
      var_gnorm: 55.64818572998047
      vf_explained_var: 0.3774712085723877
      vf_loss: 174.85121154785156
    num_steps_sampled: 4050000
    num_steps_trained: 4050000
    wait_time_ms: 157.293
  iterations_since_restore: 405
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7218.956844091415
  time_this_iter_s: 17.498087644577026
  time_total_s: 7218.956844091415
  timestamp: 1593829502
  timesteps_since_restore: 4050000
  timesteps_this_iter: 10000
  timesteps_total: 4050000
  training_iteration: 405
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7218 s, 405 iter, 4050000 ts, 251 rew

agent-1: 18.0
agent-2: 23.0
agent-3: 41.0
agent-4: 36.0
agent-5: 28.0
agent-6: 27.0
agent-7: 38.0
agent-8: 23.0
agent-9: 20.0
agent-10: 25.0
Sum Reward: 279.0
Avg Reward: 27.9
Min Reward: 18.0
Gini Coefficient 0.14874551971326164
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-25-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 251.36
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 405
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.057
    dispatch_time_ms: 5.78
    learner:
      cur_lr: 0.0010902700014412403
      grad_gnorm: 1.2321877479553223
      policy_entropy: 115.53185272216797
      policy_loss: -1.2964982986450195
      var_gnorm: 55.74345397949219
      vf_explained_var: 0.0
      vf_loss: 1.1806982911366504e-06
    num_steps_sampled: 4060000
    num_steps_trained: 4060000
    wait_time_ms: 164.411
  iterations_since_restore: 406
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7235.975202560425
  time_this_iter_s: 17.0183584690094
  time_total_s: 7235.975202560425
  timestamp: 1593829519
  timesteps_since_restore: 4060000
  timesteps_this_iter: 10000
  timesteps_total: 4060000
  training_iteration: 406
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7235 s, 406 iter, 4060000 ts, 251 rew

agent-1: 19.0
agent-2: 32.0
agent-3: 24.0
agent-4: 33.0
agent-5: 33.0
agent-6: 32.0
agent-7: 32.0
agent-8: 25.0
agent-9: 38.0
agent-10: 37.0
Sum Reward: 305.0
Avg Reward: 30.5
Min Reward: 19.0
Gini Coefficient 0.1
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-25-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 251.44
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 406
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.487
    dispatch_time_ms: 7.128
    learner:
      cur_lr: 0.0010896039893850684
      grad_gnorm: 40.0
      policy_entropy: 54.147769927978516
      policy_loss: -2.734949827194214
      var_gnorm: 55.764617919921875
      vf_explained_var: 0.46060699224472046
      vf_loss: 148.7161407470703
    num_steps_sampled: 4070000
    num_steps_trained: 4070000
    wait_time_ms: 164.29
  iterations_since_restore: 407
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7253.50487613678
  time_this_iter_s: 17.52967357635498
  time_total_s: 7253.50487613678
  timestamp: 1593829537
  timesteps_since_restore: 4070000
  timesteps_this_iter: 10000
  timesteps_total: 4070000
  training_iteration: 407
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7253 s, 407 iter, 4070000 ts, 251 rew

agent-1: 40.0
agent-2: 30.0
agent-3: 23.0
agent-4: 29.0
agent-5: 35.0
agent-6: 38.0
agent-7: 30.0
agent-8: 26.0
agent-9: 39.0
agent-10: 43.0
Sum Reward: 333.0
Avg Reward: 33.3
Min Reward: 23.0
Gini Coefficient 0.10720720720720721
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-25-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 252.03
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 407
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.878
    dispatch_time_ms: 7.219
    learner:
      cur_lr: 0.0010889379773288965
      grad_gnorm: 11.483514785766602
      policy_entropy: 128.1308135986328
      policy_loss: -4.693115234375
      var_gnorm: 55.82313919067383
      vf_explained_var: 0.9745776653289795
      vf_loss: 0.08328309655189514
    num_steps_sampled: 4080000
    num_steps_trained: 4080000
    wait_time_ms: 167.879
  iterations_since_restore: 408
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7270.585393190384
  time_this_iter_s: 17.080517053604126
  time_total_s: 7270.585393190384
  timestamp: 1593829554
  timesteps_since_restore: 4080000
  timesteps_this_iter: 10000
  timesteps_total: 4080000
  training_iteration: 408
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7270 s, 408 iter, 4080000 ts, 252 rew

agent-1: 41.0
agent-2: 46.0
agent-3: 26.0
agent-4: 35.0
agent-5: 24.0
agent-6: 30.0
agent-7: 43.0
agent-8: 19.0
agent-9: 18.0
agent-10: 43.0
Sum Reward: 325.0
Avg Reward: 32.5
Min Reward: 18.0
Gini Coefficient 0.17384615384615384
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-26-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 252.81
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 408
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.608
    dispatch_time_ms: 5.539
    learner:
      cur_lr: 0.0010882719652727246
      grad_gnorm: 1.4636062383651733
      policy_entropy: 135.69053649902344
      policy_loss: -0.5446376800537109
      var_gnorm: 55.84893798828125
      vf_explained_var: 0.0
      vf_loss: 0.0012729968875646591
    num_steps_sampled: 4090000
    num_steps_trained: 4090000
    wait_time_ms: 154.546
  iterations_since_restore: 409
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7287.906836271286
  time_this_iter_s: 17.3214430809021
  time_total_s: 7287.906836271286
  timestamp: 1593829571
  timesteps_since_restore: 4090000
  timesteps_this_iter: 10000
  timesteps_total: 4090000
  training_iteration: 409
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7287 s, 409 iter, 4090000 ts, 253 rew

agent-1: 35.0
agent-2: 27.0
agent-3: 39.0
agent-4: 31.0
agent-5: 13.0
agent-6: 28.0
agent-7: 30.0
agent-8: 39.0
agent-9: 40.0
agent-10: 45.0
Sum Reward: 327.0
Avg Reward: 32.7
Min Reward: 13.0
Gini Coefficient 0.14220183486238533
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-26-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 253.57
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 409
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.628
    dispatch_time_ms: 9.913
    learner:
      cur_lr: 0.0010876059532165527
      grad_gnorm: 10.887018203735352
      policy_entropy: 106.27069091796875
      policy_loss: -3.004483222961426
      var_gnorm: 55.954444885253906
      vf_explained_var: -0.5417743921279907
      vf_loss: 0.07409940659999847
    num_steps_sampled: 4100000
    num_steps_trained: 4100000
    wait_time_ms: 160.974
  iterations_since_restore: 410
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7305.200346708298
  time_this_iter_s: 17.29351043701172
  time_total_s: 7305.200346708298
  timestamp: 1593829589
  timesteps_since_restore: 4100000
  timesteps_this_iter: 10000
  timesteps_total: 4100000
  training_iteration: 410
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7305 s, 410 iter, 4100000 ts, 254 rew

agent-1: 37.0
agent-2: 26.0
agent-3: 17.0
agent-4: 34.0
agent-5: 18.0
agent-6: 32.0
agent-7: 14.0
agent-8: 40.0
agent-9: 35.0
agent-10: 12.0
Sum Reward: 265.0
Avg Reward: 26.5
Min Reward: 12.0
Gini Coefficient 0.210188679245283
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-26-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 253.65
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 410
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.313
    dispatch_time_ms: 6.29
    learner:
      cur_lr: 0.0010869400575757027
      grad_gnorm: 40.0000114440918
      policy_entropy: 69.59557342529297
      policy_loss: 27.496232986450195
      var_gnorm: 55.97322463989258
      vf_explained_var: 0.4125475287437439
      vf_loss: 85.50980377197266
    num_steps_sampled: 4110000
    num_steps_trained: 4110000
    wait_time_ms: 163.513
  iterations_since_restore: 411
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7322.768331289291
  time_this_iter_s: 17.567984580993652
  time_total_s: 7322.768331289291
  timestamp: 1593829606
  timesteps_since_restore: 4110000
  timesteps_this_iter: 10000
  timesteps_total: 4110000
  training_iteration: 411
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7322 s, 411 iter, 4110000 ts, 254 rew

agent-1: 20.0
agent-2: 20.0
agent-3: 26.0
agent-4: 36.0
agent-5: 21.0
agent-6: 29.0
agent-7: 34.0
agent-8: 30.0
agent-9: 17.0
agent-10: 18.0
Sum Reward: 251.0
Avg Reward: 25.1
Min Reward: 17.0
Gini Coefficient 0.1454183266932271
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-27-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 253.7
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 411
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.671
    dispatch_time_ms: 30.014
    learner:
      cur_lr: 0.0010862740455195308
      grad_gnorm: 40.00000762939453
      policy_entropy: 115.63023376464844
      policy_loss: 25.47439193725586
      var_gnorm: 55.996177673339844
      vf_explained_var: 0.415658175945282
      vf_loss: 24.761486053466797
    num_steps_sampled: 4120000
    num_steps_trained: 4120000
    wait_time_ms: 146.185
  iterations_since_restore: 412
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7340.04990196228
  time_this_iter_s: 17.28157067298889
  time_total_s: 7340.04990196228
  timestamp: 1593829624
  timesteps_since_restore: 4120000
  timesteps_this_iter: 10000
  timesteps_total: 4120000
  training_iteration: 412
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7340 s, 412 iter, 4120000 ts, 254 rew

agent-1: 44.0
agent-2: 34.0
agent-3: 30.0
agent-4: 26.0
agent-5: 43.0
agent-6: 16.0
agent-7: 13.0
agent-8: 19.0
agent-9: 35.0
agent-10: 31.0
Sum Reward: 291.0
Avg Reward: 29.1
Min Reward: 13.0
Gini Coefficient 0.19690721649484536
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-27-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 254.38
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 412
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.602
    dispatch_time_ms: 28.427
    learner:
      cur_lr: 0.0010856080334633589
      grad_gnorm: 1.8124170303344727
      policy_entropy: 123.12728118896484
      policy_loss: 0.16728530824184418
      var_gnorm: 55.99796676635742
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0019406767096370459
    num_steps_sampled: 4130000
    num_steps_trained: 4130000
    wait_time_ms: 138.004
  iterations_since_restore: 413
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7358.206434726715
  time_this_iter_s: 18.156532764434814
  time_total_s: 7358.206434726715
  timestamp: 1593829642
  timesteps_since_restore: 4130000
  timesteps_this_iter: 10000
  timesteps_total: 4130000
  training_iteration: 413
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7358 s, 413 iter, 4130000 ts, 254 rew

agent-1: 26.0
agent-2: 34.0
agent-3: 32.0
agent-4: 13.0
agent-5: 32.0
agent-6: 45.0
agent-7: 31.0
agent-8: 34.0
agent-9: 40.0
agent-10: 43.0
Sum Reward: 330.0
Avg Reward: 33.0
Min Reward: 13.0
Gini Coefficient 0.1393939393939394
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-27-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 255.47
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 413
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.678
    dispatch_time_ms: 6.075
    learner:
      cur_lr: 0.001084942021407187
      grad_gnorm: 40.0
      policy_entropy: 120.3018798828125
      policy_loss: 16.88793182373047
      var_gnorm: 56.003387451171875
      vf_explained_var: 0.9549232721328735
      vf_loss: 4.957978248596191
    num_steps_sampled: 4140000
    num_steps_trained: 4140000
    wait_time_ms: 167.152
  iterations_since_restore: 414
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7376.023207187653
  time_this_iter_s: 17.8167724609375
  time_total_s: 7376.023207187653
  timestamp: 1593829660
  timesteps_since_restore: 4140000
  timesteps_this_iter: 10000
  timesteps_total: 4140000
  training_iteration: 414
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7376 s, 414 iter, 4140000 ts, 255 rew

agent-1: 29.0
agent-2: 34.0
agent-3: 28.0
agent-4: 27.0
agent-5: 27.0
agent-6: 21.0
agent-7: 50.0
agent-8: 30.0
agent-9: 48.0
agent-10: 19.0
Sum Reward: 313.0
Avg Reward: 31.3
Min Reward: 19.0
Gini Coefficient 0.16389776357827476
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-27-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 256.28
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 414
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.898
    dispatch_time_ms: 6.582
    learner:
      cur_lr: 0.001084276009351015
      grad_gnorm: 0.419524610042572
      policy_entropy: 130.28146362304688
      policy_loss: -0.08835138380527496
      var_gnorm: 56.01954650878906
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.00010183395352214575
    num_steps_sampled: 4150000
    num_steps_trained: 4150000
    wait_time_ms: 158.785
  iterations_since_restore: 415
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7393.421810865402
  time_this_iter_s: 17.398603677749634
  time_total_s: 7393.421810865402
  timestamp: 1593829677
  timesteps_since_restore: 4150000
  timesteps_this_iter: 10000
  timesteps_total: 4150000
  training_iteration: 415
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7393 s, 415 iter, 4150000 ts, 256 rew

agent-1: 25.0
agent-2: 27.0
agent-3: 39.0
agent-4: 35.0
agent-5: 27.0
agent-6: 12.0
agent-7: 38.0
agent-8: 21.0
agent-9: 16.0
agent-10: 19.0
Sum Reward: 259.0
Avg Reward: 25.9
Min Reward: 12.0
Gini Coefficient 0.1918918918918919
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-28-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 256.66
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 415
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.775
    dispatch_time_ms: 26.916
    learner:
      cur_lr: 0.0010836099972948432
      grad_gnorm: 8.211835861206055
      policy_entropy: 130.84420776367188
      policy_loss: 2.945056200027466
      var_gnorm: 56.0771598815918
      vf_explained_var: 0.9897911548614502
      vf_loss: 0.04670857638120651
    num_steps_sampled: 4160000
    num_steps_trained: 4160000
    wait_time_ms: 155.783
  iterations_since_restore: 416
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7411.247576475143
  time_this_iter_s: 17.82576560974121
  time_total_s: 7411.247576475143
  timestamp: 1593829695
  timesteps_since_restore: 4160000
  timesteps_this_iter: 10000
  timesteps_total: 4160000
  training_iteration: 416
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7411 s, 416 iter, 4160000 ts, 257 rew

agent-1: 35.0
agent-2: 29.0
agent-3: 35.0
agent-4: 26.0
agent-5: 23.0
agent-6: 22.0
agent-7: 19.0
agent-8: 45.0
agent-9: 29.0
agent-10: 26.0
Sum Reward: 289.0
Avg Reward: 28.9
Min Reward: 19.0
Gini Coefficient 0.13737024221453287
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-28-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 257.32
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 416
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.91
    dispatch_time_ms: 39.049
    learner:
      cur_lr: 0.0010829439852386713
      grad_gnorm: 40.000003814697266
      policy_entropy: 67.11629486083984
      policy_loss: 19.605121612548828
      var_gnorm: 56.07992935180664
      vf_explained_var: 0.15785157680511475
      vf_loss: 67.92701721191406
    num_steps_sampled: 4170000
    num_steps_trained: 4170000
    wait_time_ms: 137.07
  iterations_since_restore: 417
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7429.388555288315
  time_this_iter_s: 18.140978813171387
  time_total_s: 7429.388555288315
  timestamp: 1593829713
  timesteps_since_restore: 4170000
  timesteps_this_iter: 10000
  timesteps_total: 4170000
  training_iteration: 417
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7429 s, 417 iter, 4170000 ts, 257 rew

agent-1: 24.0
agent-2: 25.0
agent-3: 34.0
agent-4: 26.0
agent-5: 32.0
agent-6: 32.0
agent-7: 35.0
agent-8: 23.0
agent-9: 26.0
agent-10: 16.0
Sum Reward: 273.0
Avg Reward: 27.3
Min Reward: 16.0
Gini Coefficient 0.11318681318681319
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-28-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 257.83
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 417
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.748
    dispatch_time_ms: 8.395
    learner:
      cur_lr: 0.0010822779731824994
      grad_gnorm: 4.510630130767822
      policy_entropy: 130.07705688476562
      policy_loss: 1.7275516986846924
      var_gnorm: 56.11187744140625
      vf_explained_var: 0.9949048757553101
      vf_loss: 0.020171403884887695
    num_steps_sampled: 4180000
    num_steps_trained: 4180000
    wait_time_ms: 163.887
  iterations_since_restore: 418
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7449.5868718624115
  time_this_iter_s: 20.19831657409668
  time_total_s: 7449.5868718624115
  timestamp: 1593829733
  timesteps_since_restore: 4180000
  timesteps_this_iter: 10000
  timesteps_total: 4180000
  training_iteration: 418
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7449 s, 418 iter, 4180000 ts, 258 rew

agent-1: 27.0
agent-2: 20.0
agent-3: 25.0
agent-4: 22.0
agent-5: 24.0
agent-6: 26.0
agent-7: 18.0
agent-8: 27.0
agent-9: 17.0
agent-10: 36.0
Sum Reward: 242.0
Avg Reward: 24.2
Min Reward: 17.0
Gini Coefficient 0.11652892561983472
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-29-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 258.02
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 418
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 4.201
    dispatch_time_ms: 8.602
    learner:
      cur_lr: 0.0010816119611263275
      grad_gnorm: 1.1750226020812988
      policy_entropy: 151.8105926513672
      policy_loss: -0.34831106662750244
      var_gnorm: 56.09806823730469
      vf_explained_var: 0.7087262868881226
      vf_loss: 0.0007762016030028462
    num_steps_sampled: 4190000
    num_steps_trained: 4190000
    wait_time_ms: 164.391
  iterations_since_restore: 419
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7467.111747741699
  time_this_iter_s: 17.52487587928772
  time_total_s: 7467.111747741699
  timestamp: 1593829751
  timesteps_since_restore: 4190000
  timesteps_this_iter: 10000
  timesteps_total: 4190000
  training_iteration: 419
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7467 s, 419 iter, 4190000 ts, 258 rew

agent-1: 23.0
agent-2: 36.0
agent-3: 26.0
agent-4: 29.0
agent-5: 25.0
agent-6: 18.0
agent-7: 37.0
agent-8: 30.0
agent-9: 42.0
agent-10: 21.0
Sum Reward: 287.0
Avg Reward: 28.7
Min Reward: 18.0
Gini Coefficient 0.143205574912892
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-29-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 258.7
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 419
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.154
    dispatch_time_ms: 6.632
    learner:
      cur_lr: 0.0010809459490701556
      grad_gnorm: 1.5818979740142822
      policy_entropy: 145.69789123535156
      policy_loss: 0.7302904725074768
      var_gnorm: 56.16474533081055
      vf_explained_var: 0.9944489002227783
      vf_loss: 0.001786460867151618
    num_steps_sampled: 4200000
    num_steps_trained: 4200000
    wait_time_ms: 157.915
  iterations_since_restore: 420
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7484.453981399536
  time_this_iter_s: 17.342233657836914
  time_total_s: 7484.453981399536
  timestamp: 1593829768
  timesteps_since_restore: 4200000
  timesteps_this_iter: 10000
  timesteps_total: 4200000
  training_iteration: 420
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7484 s, 420 iter, 4200000 ts, 259 rew

agent-1: 20.0
agent-2: 27.0
agent-3: 8.0
agent-4: 24.0
agent-5: 32.0
agent-6: 22.0
agent-7: 28.0
agent-8: 29.0
agent-9: 20.0
agent-10: 26.0
Sum Reward: 236.0
Avg Reward: 23.6
Min Reward: 8.0
Gini Coefficient 0.1423728813559322
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-29-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 258.71
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 420
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 4.028
    dispatch_time_ms: 6.564
    learner:
      cur_lr: 0.0010802800534293056
      grad_gnorm: 40.0000114440918
      policy_entropy: 84.99700164794922
      policy_loss: 19.11119270324707
      var_gnorm: 56.19401550292969
      vf_explained_var: 0.12755310535430908
      vf_loss: 40.91656494140625
    num_steps_sampled: 4210000
    num_steps_trained: 4210000
    wait_time_ms: 161.726
  iterations_since_restore: 421
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7502.040815591812
  time_this_iter_s: 17.586834192276
  time_total_s: 7502.040815591812
  timestamp: 1593829786
  timesteps_since_restore: 4210000
  timesteps_this_iter: 10000
  timesteps_total: 4210000
  training_iteration: 421
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7502 s, 421 iter, 4210000 ts, 259 rew

agent-1: 32.0
agent-2: 21.0
agent-3: 18.0
agent-4: 31.0
agent-5: 15.0
agent-6: 28.0
agent-7: 14.0
agent-8: 15.0
agent-9: 28.0
agent-10: 34.0
Sum Reward: 236.0
Avg Reward: 23.6
Min Reward: 14.0
Gini Coefficient 0.17627118644067796
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-30-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 258.64
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 421
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.669
    dispatch_time_ms: 6.259
    learner:
      cur_lr: 0.0010796140413731337
      grad_gnorm: 2.6973204612731934
      policy_entropy: 152.65643310546875
      policy_loss: 1.3101305961608887
      var_gnorm: 56.271053314208984
      vf_explained_var: 0.8069985508918762
      vf_loss: 0.004124211147427559
    num_steps_sampled: 4220000
    num_steps_trained: 4220000
    wait_time_ms: 165.729
  iterations_since_restore: 422
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7519.254506111145
  time_this_iter_s: 17.213690519332886
  time_total_s: 7519.254506111145
  timestamp: 1593829803
  timesteps_since_restore: 4220000
  timesteps_this_iter: 10000
  timesteps_total: 4220000
  training_iteration: 422
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7519 s, 422 iter, 4220000 ts, 259 rew

agent-1: 23.0
agent-2: 26.0
agent-3: 28.0
agent-4: 27.0
agent-5: 21.0
agent-6: 19.0
agent-7: 19.0
agent-8: 33.0
agent-9: 33.0
agent-10: 24.0
Sum Reward: 253.0
Avg Reward: 25.3
Min Reward: 19.0
Gini Coefficient 0.10790513833992095
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-30-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 258.79
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 422
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.162
    dispatch_time_ms: 6.496
    learner:
      cur_lr: 0.0010789480293169618
      grad_gnorm: 40.00000762939453
      policy_entropy: 73.84014892578125
      policy_loss: 13.577018737792969
      var_gnorm: 56.292354583740234
      vf_explained_var: 0.5452133417129517
      vf_loss: 68.57091522216797
    num_steps_sampled: 4230000
    num_steps_trained: 4230000
    wait_time_ms: 158.604
  iterations_since_restore: 423
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7536.7227029800415
  time_this_iter_s: 17.468196868896484
  time_total_s: 7536.7227029800415
  timestamp: 1593829821
  timesteps_since_restore: 4230000
  timesteps_this_iter: 10000
  timesteps_total: 4230000
  training_iteration: 423
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7536 s, 423 iter, 4230000 ts, 259 rew

agent-1: 19.0
agent-2: 33.0
agent-3: 37.0
agent-4: 28.0
agent-5: 29.0
agent-6: 27.0
agent-7: 23.0
agent-8: 19.0
agent-9: 20.0
agent-10: 33.0
Sum Reward: 268.0
Avg Reward: 26.8
Min Reward: 19.0
Gini Coefficient 0.12835820895522387
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-30-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 258.66
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 423
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.202
    dispatch_time_ms: 7.783
    learner:
      cur_lr: 0.0010782820172607899
      grad_gnorm: 2.0253171920776367
      policy_entropy: 149.6418914794922
      policy_loss: 1.049773931503296
      var_gnorm: 56.350425720214844
      vf_explained_var: 0.0
      vf_loss: 0.0021532271057367325
    num_steps_sampled: 4240000
    num_steps_trained: 4240000
    wait_time_ms: 166.707
  iterations_since_restore: 424
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7553.917265415192
  time_this_iter_s: 17.194562435150146
  time_total_s: 7553.917265415192
  timestamp: 1593829838
  timesteps_since_restore: 4240000
  timesteps_this_iter: 10000
  timesteps_total: 4240000
  training_iteration: 424
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7553 s, 424 iter, 4240000 ts, 259 rew

agent-1: 23.0
agent-2: 33.0
agent-3: 16.0
agent-4: 28.0
agent-5: 19.0
agent-6: 39.0
agent-7: 21.0
agent-8: 21.0
agent-9: 35.0
agent-10: 18.0
Sum Reward: 253.0
Avg Reward: 25.3
Min Reward: 16.0
Gini Coefficient 0.16561264822134386
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-30-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 258.33
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 424
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.571
    dispatch_time_ms: 6.387
    learner:
      cur_lr: 0.001077616005204618
      grad_gnorm: 40.000003814697266
      policy_entropy: 73.32537078857422
      policy_loss: -22.943471908569336
      var_gnorm: 56.32990264892578
      vf_explained_var: 0.6441130638122559
      vf_loss: 57.14844512939453
    num_steps_sampled: 4250000
    num_steps_trained: 4250000
    wait_time_ms: 156.551
  iterations_since_restore: 425
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7571.378157377243
  time_this_iter_s: 17.46089196205139
  time_total_s: 7571.378157377243
  timestamp: 1593829855
  timesteps_since_restore: 4250000
  timesteps_this_iter: 10000
  timesteps_total: 4250000
  training_iteration: 425
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7571 s, 425 iter, 4250000 ts, 258 rew

agent-1: 31.0
agent-2: 26.0
agent-3: 22.0
agent-4: 27.0
agent-5: 23.0
agent-6: 21.0
agent-7: 22.0
agent-8: 44.0
agent-9: 29.0
agent-10: 20.0
Sum Reward: 265.0
Avg Reward: 26.5
Min Reward: 20.0
Gini Coefficient 0.1279245283018868
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-31-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 258.88
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 425
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.756
    dispatch_time_ms: 6.161
    learner:
      cur_lr: 0.001076949993148446
      grad_gnorm: 1.3725301027297974
      policy_entropy: 141.4293212890625
      policy_loss: 0.7730074524879456
      var_gnorm: 56.347930908203125
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0007692063227295876
    num_steps_sampled: 4260000
    num_steps_trained: 4260000
    wait_time_ms: 165.26
  iterations_since_restore: 426
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7588.7690353393555
  time_this_iter_s: 17.390877962112427
  time_total_s: 7588.7690353393555
  timestamp: 1593829873
  timesteps_since_restore: 4260000
  timesteps_this_iter: 10000
  timesteps_total: 4260000
  training_iteration: 426
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7588 s, 426 iter, 4260000 ts, 259 rew

agent-1: 25.0
agent-2: 28.0
agent-3: 24.0
agent-4: 19.0
agent-5: 23.0
agent-6: 21.0
agent-7: 31.0
agent-8: 24.0
agent-9: 27.0
agent-10: 19.0
Sum Reward: 241.0
Avg Reward: 24.1
Min Reward: 19.0
Gini Coefficient 0.08589211618257261
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-31-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 259.02
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 426
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.791
    dispatch_time_ms: 8.798
    learner:
      cur_lr: 0.0010762839810922742
      grad_gnorm: 40.0
      policy_entropy: 59.762020111083984
      policy_loss: -26.6080265045166
      var_gnorm: 56.35985565185547
      vf_explained_var: 0.3424243927001953
      vf_loss: 130.74546813964844
    num_steps_sampled: 4270000
    num_steps_trained: 4270000
    wait_time_ms: 153.834
  iterations_since_restore: 427
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7606.222033500671
  time_this_iter_s: 17.452998161315918
  time_total_s: 7606.222033500671
  timestamp: 1593829890
  timesteps_since_restore: 4270000
  timesteps_this_iter: 10000
  timesteps_total: 4270000
  training_iteration: 427
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7606 s, 427 iter, 4270000 ts, 259 rew

agent-1: 29.0
agent-2: 29.0
agent-3: 30.0
agent-4: 23.0
agent-5: 20.0
agent-6: 13.0
agent-7: 24.0
agent-8: 24.0
agent-9: 12.0
agent-10: 34.0
Sum Reward: 238.0
Avg Reward: 23.8
Min Reward: 12.0
Gini Coefficient 0.15966386554621848
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-31-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 259.23
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 427
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.568
    dispatch_time_ms: 6.986
    learner:
      cur_lr: 0.0010756179690361023
      grad_gnorm: 3.531149387359619
      policy_entropy: 131.39837646484375
      policy_loss: -1.5659860372543335
      var_gnorm: 56.50222396850586
      vf_explained_var: -1.0
      vf_loss: 0.013632047921419144
    num_steps_sampled: 4280000
    num_steps_trained: 4280000
    wait_time_ms: 165.171
  iterations_since_restore: 428
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7623.491643190384
  time_this_iter_s: 17.269609689712524
  time_total_s: 7623.491643190384
  timestamp: 1593829908
  timesteps_since_restore: 4280000
  timesteps_this_iter: 10000
  timesteps_total: 4280000
  training_iteration: 428
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7623 s, 428 iter, 4280000 ts, 259 rew

agent-1: 23.0
agent-2: 39.0
agent-3: 25.0
agent-4: 22.0
agent-5: 30.0
agent-6: 23.0
agent-7: 30.0
agent-8: 18.0
agent-9: 21.0
agent-10: 27.0
Sum Reward: 258.0
Avg Reward: 25.8
Min Reward: 18.0
Gini Coefficient 0.1186046511627907
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-32-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 259.34
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 428
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.21
    dispatch_time_ms: 5.845
    learner:
      cur_lr: 0.0010749519569799304
      grad_gnorm: 0.40391474962234497
      policy_entropy: 133.74020385742188
      policy_loss: -0.18305030465126038
      var_gnorm: 56.493690490722656
      vf_explained_var: 0.0
      vf_loss: 6.620520434807986e-05
    num_steps_sampled: 4290000
    num_steps_trained: 4290000
    wait_time_ms: 158.069
  iterations_since_restore: 429
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7640.881095409393
  time_this_iter_s: 17.3894522190094
  time_total_s: 7640.881095409393
  timestamp: 1593829925
  timesteps_since_restore: 4290000
  timesteps_this_iter: 10000
  timesteps_total: 4290000
  training_iteration: 429
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7640 s, 429 iter, 4290000 ts, 259 rew

agent-1: 31.0
agent-2: 22.0
agent-3: 20.0
agent-4: 26.0
agent-5: 48.0
agent-6: 33.0
agent-7: 35.0
agent-8: 27.0
agent-9: 28.0
agent-10: 31.0
Sum Reward: 301.0
Avg Reward: 30.1
Min Reward: 20.0
Gini Coefficient 0.13056478405315614
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-32-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 260.01
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 429
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.849
    dispatch_time_ms: 33.316
    learner:
      cur_lr: 0.0010742859449237585
      grad_gnorm: 7.059849262237549
      policy_entropy: 144.34620666503906
      policy_loss: 3.4684395790100098
      var_gnorm: 56.530601501464844
      vf_explained_var: -1.0
      vf_loss: 0.03514419123530388
    num_steps_sampled: 4300000
    num_steps_trained: 4300000
    wait_time_ms: 153.957
  iterations_since_restore: 430
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7658.468366622925
  time_this_iter_s: 17.587271213531494
  time_total_s: 7658.468366622925
  timestamp: 1593829943
  timesteps_since_restore: 4300000
  timesteps_this_iter: 10000
  timesteps_total: 4300000
  training_iteration: 430
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7658 s, 430 iter, 4300000 ts, 260 rew

agent-1: 30.0
agent-2: 16.0
agent-3: 25.0
agent-4: 28.0
agent-5: 38.0
agent-6: 18.0
agent-7: 29.0
agent-8: 28.0
agent-9: 26.0
agent-10: 34.0
Sum Reward: 272.0
Avg Reward: 27.2
Min Reward: 16.0
Gini Coefficient 0.1264705882352941
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-32-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 260.66
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 430
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.337
    dispatch_time_ms: 32.871
    learner:
      cur_lr: 0.0010736200492829084
      grad_gnorm: 40.0
      policy_entropy: 66.97894287109375
      policy_loss: 10.759757995605469
      var_gnorm: 56.542179107666016
      vf_explained_var: -0.2373826503753662
      vf_loss: 110.1918716430664
    num_steps_sampled: 4310000
    num_steps_trained: 4310000
    wait_time_ms: 145.566
  iterations_since_restore: 431
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7676.994958400726
  time_this_iter_s: 18.526591777801514
  time_total_s: 7676.994958400726
  timestamp: 1593829961
  timesteps_since_restore: 4310000
  timesteps_this_iter: 10000
  timesteps_total: 4310000
  training_iteration: 431
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7676 s, 431 iter, 4310000 ts, 261 rew

agent-1: 30.0
agent-2: 36.0
agent-3: 32.0
agent-4: 34.0
agent-5: 38.0
agent-6: 19.0
agent-7: 16.0
agent-8: 21.0
agent-9: 29.0
agent-10: 20.0
Sum Reward: 275.0
Avg Reward: 27.5
Min Reward: 16.0
Gini Coefficient 0.15309090909090908
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-32-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 261.05
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 431
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.697
    dispatch_time_ms: 29.677
    learner:
      cur_lr: 0.0010729540372267365
      grad_gnorm: 5.849335670471191
      policy_entropy: 147.7901611328125
      policy_loss: 4.965541839599609
      var_gnorm: 56.595054626464844
      vf_explained_var: 0.0
      vf_loss: 0.015491489320993423
    num_steps_sampled: 4320000
    num_steps_trained: 4320000
    wait_time_ms: 154.47
  iterations_since_restore: 432
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7694.920649290085
  time_this_iter_s: 17.92569088935852
  time_total_s: 7694.920649290085
  timestamp: 1593829979
  timesteps_since_restore: 4320000
  timesteps_this_iter: 10000
  timesteps_total: 4320000
  training_iteration: 432
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7694 s, 432 iter, 4320000 ts, 261 rew

agent-1: 27.0
agent-2: 29.0
agent-3: 19.0
agent-4: 30.0
agent-5: 34.0
agent-6: 28.0
agent-7: 36.0
agent-8: 26.0
agent-9: 29.0
agent-10: 20.0
Sum Reward: 278.0
Avg Reward: 27.8
Min Reward: 19.0
Gini Coefficient 0.1
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-33-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 261.63
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 432
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.521
    dispatch_time_ms: 34.109
    learner:
      cur_lr: 0.0010722880251705647
      grad_gnorm: 40.000003814697266
      policy_entropy: 74.11767578125
      policy_loss: 20.24406623840332
      var_gnorm: 56.57525634765625
      vf_explained_var: 0.48213106393814087
      vf_loss: 41.431068420410156
    num_steps_sampled: 4330000
    num_steps_trained: 4330000
    wait_time_ms: 150.697
  iterations_since_restore: 433
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7713.276123046875
  time_this_iter_s: 18.35547375679016
  time_total_s: 7713.276123046875
  timestamp: 1593829998
  timesteps_since_restore: 4330000
  timesteps_this_iter: 10000
  timesteps_total: 4330000
  training_iteration: 433
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7713 s, 433 iter, 4330000 ts, 262 rew

agent-1: 39.0
agent-2: 36.0
agent-3: 25.0
agent-4: 17.0
agent-5: 40.0
agent-6: 28.0
agent-7: 30.0
agent-8: 37.0
agent-9: 24.0
agent-10: 21.0
Sum Reward: 297.0
Avg Reward: 29.7
Min Reward: 17.0
Gini Coefficient 0.1457912457912458
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-33-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 262.25
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 433
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.818
    dispatch_time_ms: 29.243
    learner:
      cur_lr: 0.0010716220131143928
      grad_gnorm: 5.735097885131836
      policy_entropy: 125.5885009765625
      policy_loss: -2.1375560760498047
      var_gnorm: 56.68240737915039
      vf_explained_var: 0.0
      vf_loss: 0.01693139411509037
    num_steps_sampled: 4340000
    num_steps_trained: 4340000
    wait_time_ms: 154.841
  iterations_since_restore: 434
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7731.392423629761
  time_this_iter_s: 18.116300582885742
  time_total_s: 7731.392423629761
  timestamp: 1593830016
  timesteps_since_restore: 4340000
  timesteps_this_iter: 10000
  timesteps_total: 4340000
  training_iteration: 434
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7731 s, 434 iter, 4340000 ts, 262 rew

agent-1: 34.0
agent-2: 14.0
agent-3: 23.0
agent-4: 27.0
agent-5: 24.0
agent-6: 16.0
agent-7: 20.0
agent-8: 16.0
agent-9: 17.0
agent-10: 34.0
Sum Reward: 225.0
Avg Reward: 22.5
Min Reward: 14.0
Gini Coefficient 0.1711111111111111
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-33-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 262.14
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 434
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.6
    dispatch_time_ms: 5.93
    learner:
      cur_lr: 0.0010709560010582209
      grad_gnorm: 1.4294096231460571
      policy_entropy: 135.06564331054688
      policy_loss: -0.5312393307685852
      var_gnorm: 56.643150329589844
      vf_explained_var: 0.0
      vf_loss: 0.0012051378143951297
    num_steps_sampled: 4350000
    num_steps_trained: 4350000
    wait_time_ms: 161.615
  iterations_since_restore: 435
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7753.594451665878
  time_this_iter_s: 22.202028036117554
  time_total_s: 7753.594451665878
  timestamp: 1593830038
  timesteps_since_restore: 4350000
  timesteps_this_iter: 10000
  timesteps_total: 4350000
  training_iteration: 435
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7753 s, 435 iter, 4350000 ts, 262 rew

agent-1: 29.0
agent-2: 23.0
agent-3: 25.0
agent-4: 38.0
agent-5: 26.0
agent-6: 35.0
agent-7: 29.0
agent-8: 25.0
agent-9: 18.0
agent-10: 17.0
Sum Reward: 265.0
Avg Reward: 26.5
Min Reward: 17.0
Gini Coefficient 0.13245283018867923
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-34-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 262.42
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 435
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.109
    dispatch_time_ms: 5.828
    learner:
      cur_lr: 0.001070289989002049
      grad_gnorm: 8.006501197814941
      policy_entropy: 134.24722290039062
      policy_loss: -3.367675542831421
      var_gnorm: 56.759342193603516
      vf_explained_var: 0.991271436214447
      vf_loss: 0.05012703686952591
    num_steps_sampled: 4360000
    num_steps_trained: 4360000
    wait_time_ms: 171.809
  iterations_since_restore: 436
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7770.846572875977
  time_this_iter_s: 17.252121210098267
  time_total_s: 7770.846572875977
  timestamp: 1593830055
  timesteps_since_restore: 4360000
  timesteps_this_iter: 10000
  timesteps_total: 4360000
  training_iteration: 436
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7770 s, 436 iter, 4360000 ts, 262 rew

agent-1: 35.0
agent-2: 19.0
agent-3: 32.0
agent-4: 24.0
agent-5: 45.0
agent-6: 6.0
agent-7: 15.0
agent-8: 32.0
agent-9: 32.0
agent-10: 33.0
Sum Reward: 273.0
Avg Reward: 27.3
Min Reward: 6.0
Gini Coefficient 0.21428571428571427
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-34-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 262.87
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 436
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 4.057
    dispatch_time_ms: 6.556
    learner:
      cur_lr: 0.001069623976945877
      grad_gnorm: 1.35382878780365
      policy_entropy: 151.5618438720703
      policy_loss: -0.24800589680671692
      var_gnorm: 56.741966247558594
      vf_explained_var: 0.0
      vf_loss: 0.0010058844927698374
    num_steps_sampled: 4370000
    num_steps_trained: 4370000
    wait_time_ms: 158.874
  iterations_since_restore: 437
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7788.3027856349945
  time_this_iter_s: 17.456212759017944
  time_total_s: 7788.3027856349945
  timestamp: 1593830073
  timesteps_since_restore: 4370000
  timesteps_this_iter: 10000
  timesteps_total: 4370000
  training_iteration: 437
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7788 s, 437 iter, 4370000 ts, 263 rew

agent-1: 29.0
agent-2: 29.0
agent-3: 26.0
agent-4: 30.0
agent-5: 32.0
agent-6: 26.0
agent-7: 26.0
agent-8: 30.0
agent-9: 26.0
agent-10: 36.0
Sum Reward: 290.0
Avg Reward: 29.0
Min Reward: 26.0
Gini Coefficient 0.05655172413793103
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-34-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 263.47
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 437
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 5.255
    dispatch_time_ms: 8.032
    learner:
      cur_lr: 0.0010689579648897052
      grad_gnorm: 10.383138656616211
      policy_entropy: 134.74606323242188
      policy_loss: -4.380885124206543
      var_gnorm: 56.85334777832031
      vf_explained_var: 0.885987401008606
      vf_loss: 0.2309204787015915
    num_steps_sampled: 4380000
    num_steps_trained: 4380000
    wait_time_ms: 160.329
  iterations_since_restore: 438
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7805.549906253815
  time_this_iter_s: 17.24712061882019
  time_total_s: 7805.549906253815
  timestamp: 1593830090
  timesteps_since_restore: 4380000
  timesteps_this_iter: 10000
  timesteps_total: 4380000
  training_iteration: 438
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7805 s, 438 iter, 4380000 ts, 263 rew

agent-1: 29.0
agent-2: 24.0
agent-3: 22.0
agent-4: 28.0
agent-5: 28.0
agent-6: 26.0
agent-7: 32.0
agent-8: 26.0
agent-9: 31.0
agent-10: 20.0
Sum Reward: 266.0
Avg Reward: 26.6
Min Reward: 20.0
Gini Coefficient 0.07669172932330827
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-35-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 263.72
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 438
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.531
    dispatch_time_ms: 6.757
    learner:
      cur_lr: 0.0010682919528335333
      grad_gnorm: 0.9768944382667542
      policy_entropy: 151.6514434814453
      policy_loss: -0.1849440485239029
      var_gnorm: 56.86052322387695
      vf_explained_var: 0.0
      vf_loss: 0.0005371345905587077
    num_steps_sampled: 4390000
    num_steps_trained: 4390000
    wait_time_ms: 160.811
  iterations_since_restore: 439
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7823.0472412109375
  time_this_iter_s: 17.497334957122803
  time_total_s: 7823.0472412109375
  timestamp: 1593830108
  timesteps_since_restore: 4390000
  timesteps_this_iter: 10000
  timesteps_total: 4390000
  training_iteration: 439
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7823 s, 439 iter, 4390000 ts, 264 rew

agent-1: 29.0
agent-2: 27.0
agent-3: 54.0
agent-4: 27.0
agent-5: 21.0
agent-6: 21.0
agent-7: 20.0
agent-8: 37.0
agent-9: 25.0
agent-10: 29.0
Sum Reward: 290.0
Avg Reward: 29.0
Min Reward: 20.0
Gini Coefficient 0.16206896551724137
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-35-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 264.34
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 439
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.805
    dispatch_time_ms: 8.019
    learner:
      cur_lr: 0.0010676260571926832
      grad_gnorm: 4.632964134216309
      policy_entropy: 141.8899688720703
      policy_loss: 2.0855705738067627
      var_gnorm: 56.949649810791016
      vf_explained_var: 0.0
      vf_loss: 0.012768160551786423
    num_steps_sampled: 4400000
    num_steps_trained: 4400000
    wait_time_ms: 164.787
  iterations_since_restore: 440
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7840.075959444046
  time_this_iter_s: 17.02871823310852
  time_total_s: 7840.075959444046
  timestamp: 1593830125
  timesteps_since_restore: 4400000
  timesteps_this_iter: 10000
  timesteps_total: 4400000
  training_iteration: 440
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7840 s, 440 iter, 4400000 ts, 264 rew

agent-1: 37.0
agent-2: 13.0
agent-3: 26.0
agent-4: 28.0
agent-5: 26.0
agent-6: 20.0
agent-7: 26.0
agent-8: 35.0
agent-9: 28.0
agent-10: 21.0
Sum Reward: 260.0
Avg Reward: 26.0
Min Reward: 13.0
Gini Coefficient 0.13923076923076924
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-35-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 264.25
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 440
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.974
    dispatch_time_ms: 6.629
    learner:
      cur_lr: 0.0010669600451365113
      grad_gnorm: 40.0
      policy_entropy: 55.93748474121094
      policy_loss: 31.718732833862305
      var_gnorm: 56.94390869140625
      vf_explained_var: -0.0527033805847168
      vf_loss: 101.70710754394531
    num_steps_sampled: 4410000
    num_steps_trained: 4410000
    wait_time_ms: 137.47
  iterations_since_restore: 441
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7857.575223684311
  time_this_iter_s: 17.499264240264893
  time_total_s: 7857.575223684311
  timestamp: 1593830142
  timesteps_since_restore: 4410000
  timesteps_this_iter: 10000
  timesteps_total: 4410000
  training_iteration: 441
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7857 s, 441 iter, 4410000 ts, 264 rew

agent-1: 29.0
agent-2: 21.0
agent-3: 41.0
agent-4: 35.0
agent-5: 31.0
agent-6: 29.0
agent-7: 21.0
agent-8: 30.0
agent-9: 16.0
agent-10: 20.0
Sum Reward: 273.0
Avg Reward: 27.3
Min Reward: 16.0
Gini Coefficient 0.14908424908424908
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-35-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 264.44
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 441
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.696
    dispatch_time_ms: 8.292
    learner:
      cur_lr: 0.0010662940330803394
      grad_gnorm: 0.9304003119468689
      policy_entropy: 137.383544921875
      policy_loss: 0.697559654712677
      var_gnorm: 56.99005889892578
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0003138715401291847
    num_steps_sampled: 4420000
    num_steps_trained: 4420000
    wait_time_ms: 164.046
  iterations_since_restore: 442
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7874.790425300598
  time_this_iter_s: 17.21520161628723
  time_total_s: 7874.790425300598
  timestamp: 1593830159
  timesteps_since_restore: 4420000
  timesteps_this_iter: 10000
  timesteps_total: 4420000
  training_iteration: 442
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7874 s, 442 iter, 4420000 ts, 264 rew

agent-1: 17.0
agent-2: 17.0
agent-3: 25.0
agent-4: 22.0
agent-5: 27.0
agent-6: 29.0
agent-7: 34.0
agent-8: 21.0
agent-9: 25.0
agent-10: 34.0
Sum Reward: 251.0
Avg Reward: 25.1
Min Reward: 17.0
Gini Coefficient 0.13027888446215138
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-36-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 264.45
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 442
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.656
    dispatch_time_ms: 6.406
    learner:
      cur_lr: 0.0010656280210241675
      grad_gnorm: 39.99999237060547
      policy_entropy: 35.637779235839844
      policy_loss: -0.6223370432853699
      var_gnorm: 56.976680755615234
      vf_explained_var: 0.16594719886779785
      vf_loss: 169.8427276611328
    num_steps_sampled: 4430000
    num_steps_trained: 4430000
    wait_time_ms: 155.028
  iterations_since_restore: 443
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7892.42440533638
  time_this_iter_s: 17.63398003578186
  time_total_s: 7892.42440533638
  timestamp: 1593830177
  timesteps_since_restore: 4430000
  timesteps_this_iter: 10000
  timesteps_total: 4430000
  training_iteration: 443
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7892 s, 443 iter, 4430000 ts, 264 rew

agent-1: 26.0
agent-2: 23.0
agent-3: 19.0
agent-4: 25.0
agent-5: 25.0
agent-6: 29.0
agent-7: 16.0
agent-8: 21.0
agent-9: 25.0
agent-10: 22.0
Sum Reward: 231.0
Avg Reward: 23.1
Min Reward: 16.0
Gini Coefficient 0.08528138528138528
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-36-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 263.82
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 443
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.622
    dispatch_time_ms: 6.041
    learner:
      cur_lr: 0.0010649620089679956
      grad_gnorm: 2.946681261062622
      policy_entropy: 144.51304626464844
      policy_loss: -1.0473393201828003
      var_gnorm: 57.12535095214844
      vf_explained_var: 0.0
      vf_loss: 0.005033360794186592
    num_steps_sampled: 4440000
    num_steps_trained: 4440000
    wait_time_ms: 167.676
  iterations_since_restore: 444
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7909.6428480148315
  time_this_iter_s: 17.218442678451538
  time_total_s: 7909.6428480148315
  timestamp: 1593830194
  timesteps_since_restore: 4440000
  timesteps_this_iter: 10000
  timesteps_total: 4440000
  training_iteration: 444
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7909 s, 444 iter, 4440000 ts, 264 rew

agent-1: 25.0
agent-2: 19.0
agent-3: 12.0
agent-4: 21.0
agent-5: 28.0
agent-6: 15.0
agent-7: 27.0
agent-8: 26.0
agent-9: 21.0
agent-10: 13.0
Sum Reward: 207.0
Avg Reward: 20.7
Min Reward: 12.0
Gini Coefficient 0.15217391304347827
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-36-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 263.34
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 444
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.736
    dispatch_time_ms: 5.728
    learner:
      cur_lr: 0.0010642959969118237
      grad_gnorm: 0.2220383584499359
      policy_entropy: 147.74185180664062
      policy_loss: -0.07543056458234787
      var_gnorm: 57.115352630615234
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.8445443604141474e-05
    num_steps_sampled: 4450000
    num_steps_trained: 4450000
    wait_time_ms: 171.236
  iterations_since_restore: 445
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7927.304190635681
  time_this_iter_s: 17.66134262084961
  time_total_s: 7927.304190635681
  timestamp: 1593830212
  timesteps_since_restore: 4450000
  timesteps_this_iter: 10000
  timesteps_total: 4450000
  training_iteration: 445
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7927 s, 445 iter, 4450000 ts, 263 rew

agent-1: 31.0
agent-2: 18.0
agent-3: 18.0
agent-4: 32.0
agent-5: 37.0
agent-6: 31.0
agent-7: 24.0
agent-8: 26.0
agent-9: 22.0
agent-10: 30.0
Sum Reward: 269.0
Avg Reward: 26.9
Min Reward: 18.0
Gini Coefficient 0.12602230483271376
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-37-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 263.45
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 445
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.72
    dispatch_time_ms: 6.043
    learner:
      cur_lr: 0.0010636299848556519
      grad_gnorm: 31.71281623840332
      policy_entropy: 102.71121978759766
      policy_loss: 5.275490760803223
      var_gnorm: 57.19280242919922
      vf_explained_var: 0.7895021438598633
      vf_loss: 3.5453555583953857
    num_steps_sampled: 4460000
    num_steps_trained: 4460000
    wait_time_ms: 164.856
  iterations_since_restore: 446
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7944.17440032959
  time_this_iter_s: 16.87020969390869
  time_total_s: 7944.17440032959
  timestamp: 1593830229
  timesteps_since_restore: 4460000
  timesteps_this_iter: 10000
  timesteps_total: 4460000
  training_iteration: 446
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7944 s, 446 iter, 4460000 ts, 263 rew

agent-1: 21.0
agent-2: 50.0
agent-3: 19.0
agent-4: 37.0
agent-5: 23.0
agent-6: 23.0
agent-7: 44.0
agent-8: 23.0
agent-9: 46.0
agent-10: 38.0
Sum Reward: 324.0
Avg Reward: 32.4
Min Reward: 19.0
Gini Coefficient 0.19074074074074074
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-37-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 264.49
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 446
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.778
    dispatch_time_ms: 51.071
    learner:
      cur_lr: 0.00106296397279948
      grad_gnorm: 8.488137245178223
      policy_entropy: 108.90206909179688
      policy_loss: -0.6029248833656311
      var_gnorm: 57.208770751953125
      vf_explained_var: -1.0
      vf_loss: 0.05383710935711861
    num_steps_sampled: 4470000
    num_steps_trained: 4470000
    wait_time_ms: 161.509
  iterations_since_restore: 447
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7962.514046192169
  time_this_iter_s: 18.339645862579346
  time_total_s: 7962.514046192169
  timestamp: 1593830247
  timesteps_since_restore: 4470000
  timesteps_this_iter: 10000
  timesteps_total: 4470000
  training_iteration: 447
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7962 s, 447 iter, 4470000 ts, 264 rew

agent-1: 30.0
agent-2: 24.0
agent-3: 35.0
agent-4: 27.0
agent-5: 20.0
agent-6: 29.0
agent-7: 27.0
agent-8: 29.0
agent-9: 26.0
agent-10: 28.0
Sum Reward: 275.0
Avg Reward: 27.5
Min Reward: 20.0
Gini Coefficient 0.07236363636363637
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-37-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 264.81
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 447
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.997
    dispatch_time_ms: 45.732
    learner:
      cur_lr: 0.001062297960743308
      grad_gnorm: 25.309694290161133
      policy_entropy: 104.3765869140625
      policy_loss: -9.503735542297363
      var_gnorm: 57.28116226196289
      vf_explained_var: 0.5524270534515381
      vf_loss: 1.3915166854858398
    num_steps_sampled: 4480000
    num_steps_trained: 4480000
    wait_time_ms: 150.099
  iterations_since_restore: 448
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7980.202388048172
  time_this_iter_s: 17.688341856002808
  time_total_s: 7980.202388048172
  timestamp: 1593830265
  timesteps_since_restore: 4480000
  timesteps_this_iter: 10000
  timesteps_total: 4480000
  training_iteration: 448
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7980 s, 448 iter, 4480000 ts, 265 rew

agent-1: 20.0
agent-2: 46.0
agent-3: 41.0
agent-4: 30.0
agent-5: 24.0
agent-6: 16.0
agent-7: 41.0
agent-8: 29.0
agent-9: 42.0
agent-10: 25.0
Sum Reward: 314.0
Avg Reward: 31.4
Min Reward: 16.0
Gini Coefficient 0.17770700636942674
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-38-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 341.0
  episode_reward_mean: 265.7
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 448
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.954
    dispatch_time_ms: 47.495
    learner:
      cur_lr: 0.0010616319486871362
      grad_gnorm: 40.0
      policy_entropy: 69.10382843017578
      policy_loss: -6.296346187591553
      var_gnorm: 57.26549530029297
      vf_explained_var: 0.8409815430641174
      vf_loss: 73.64990997314453
    num_steps_sampled: 4490000
    num_steps_trained: 4490000
    wait_time_ms: 112.896
  iterations_since_restore: 449
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 7998.47695684433
  time_this_iter_s: 18.274568796157837
  time_total_s: 7998.47695684433
  timestamp: 1593830283
  timesteps_since_restore: 4490000
  timesteps_this_iter: 10000
  timesteps_total: 4490000
  training_iteration: 449
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 7998 s, 449 iter, 4490000 ts, 266 rew

agent-1: 47.0
agent-2: 34.0
agent-3: 40.0
agent-4: 24.0
agent-5: 25.0
agent-6: 33.0
agent-7: 45.0
agent-8: 24.0
agent-9: 40.0
agent-10: 32.0
Sum Reward: 344.0
Avg Reward: 34.4
Min Reward: 24.0
Gini Coefficient 0.13197674418604652
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-38-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 344.0
  episode_reward_mean: 266.53
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 449
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.683
    dispatch_time_ms: 26.882
    learner:
      cur_lr: 0.001060966053046286
      grad_gnorm: 29.310020446777344
      policy_entropy: 89.74541473388672
      policy_loss: -6.326539039611816
      var_gnorm: 57.367130279541016
      vf_explained_var: 0.5881832838058472
      vf_loss: 9.134683609008789
    num_steps_sampled: 4500000
    num_steps_trained: 4500000
    wait_time_ms: 142.585
  iterations_since_restore: 450
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 8016.037932395935
  time_this_iter_s: 17.560975551605225
  time_total_s: 8016.037932395935
  timestamp: 1593830301
  timesteps_since_restore: 4500000
  timesteps_this_iter: 10000
  timesteps_total: 4500000
  training_iteration: 450
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 8016 s, 450 iter, 4500000 ts, 267 rew

agent-1: 39.0
agent-2: 22.0
agent-3: 35.0
agent-4: 26.0
agent-5: 46.0
agent-6: 46.0
agent-7: 51.0
agent-8: 21.0
agent-9: 33.0
agent-10: 16.0
Sum Reward: 335.0
Avg Reward: 33.5
Min Reward: 16.0
Gini Coefficient 0.19432835820895522
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-38-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 344.0
  episode_reward_mean: 267.41
  episode_reward_min: 196.0
  episodes_this_iter: 1
  episodes_total: 450
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.588
    dispatch_time_ms: 36.01
    learner:
      cur_lr: 0.0010603000409901142
      grad_gnorm: 39.999996185302734
      policy_entropy: 58.02250289916992
      policy_loss: 3.561330795288086
      var_gnorm: 57.37924575805664
      vf_explained_var: 0.40425366163253784
      vf_loss: 137.25567626953125
    num_steps_sampled: 4510000
    num_steps_trained: 4510000
    wait_time_ms: 113.931
  iterations_since_restore: 451
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 8034.41237616539
  time_this_iter_s: 18.374443769454956
  time_total_s: 8034.41237616539
  timestamp: 1593830319
  timesteps_since_restore: 4510000
  timesteps_this_iter: 10000
  timesteps_total: 4510000
  training_iteration: 451
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 8034 s, 451 iter, 4510000 ts, 267 rew

agent-1: 33.0
agent-2: 29.0
agent-3: 39.0
agent-4: 26.0
agent-5: 42.0
agent-6: 44.0
agent-7: 34.0
agent-8: 43.0
agent-9: 60.0
agent-10: 36.0
Sum Reward: 386.0
Avg Reward: 38.6
Min Reward: 26.0
Gini Coefficient 0.12642487046632125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-39-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 386.0
  episode_reward_mean: 269.31
  episode_reward_min: 200.0
  episodes_this_iter: 1
  episodes_total: 451
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.814
    dispatch_time_ms: 6.686
    learner:
      cur_lr: 0.0010596340289339423
      grad_gnorm: 39.214637756347656
      policy_entropy: 114.5425033569336
      policy_loss: 10.596711158752441
      var_gnorm: 57.34881591796875
      vf_explained_var: 0.028178751468658447
      vf_loss: 14.960213661193848
    num_steps_sampled: 4520000
    num_steps_trained: 4520000
    wait_time_ms: 165.522
  iterations_since_restore: 452
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 8055.4467577934265
  time_this_iter_s: 21.0343816280365
  time_total_s: 8055.4467577934265
  timestamp: 1593830340
  timesteps_since_restore: 4520000
  timesteps_this_iter: 10000
  timesteps_total: 4520000
  training_iteration: 452
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 8055 s, 452 iter, 4520000 ts, 269 rew

agent-1: 23.0
agent-2: 30.0
agent-3: 27.0
agent-4: 33.0
agent-5: 23.0
agent-6: 35.0
agent-7: 31.0
agent-8: 19.0
agent-9: 27.0
agent-10: 31.0
Sum Reward: 279.0
Avg Reward: 27.9
Min Reward: 19.0
Gini Coefficient 0.096415770609319
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-39-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 386.0
  episode_reward_mean: 269.78
  episode_reward_min: 200.0
  episodes_this_iter: 1
  episodes_total: 452
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.278
    dispatch_time_ms: 6.167
    learner:
      cur_lr: 0.0010589680168777704
      grad_gnorm: 40.0
      policy_entropy: 48.543983459472656
      policy_loss: 17.951961517333984
      var_gnorm: 57.35799026489258
      vf_explained_var: 0.7425135970115662
      vf_loss: 197.079833984375
    num_steps_sampled: 4530000
    num_steps_trained: 4530000
    wait_time_ms: 143.722
  iterations_since_restore: 453
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 8072.775456190109
  time_this_iter_s: 17.32869839668274
  time_total_s: 8072.775456190109
  timestamp: 1593830358
  timesteps_since_restore: 4530000
  timesteps_this_iter: 10000
  timesteps_total: 4530000
  training_iteration: 453
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 8072 s, 453 iter, 4530000 ts, 270 rew

agent-1: 36.0
agent-2: 33.0
agent-3: 49.0
agent-4: 46.0
agent-5: 48.0
agent-6: 23.0
agent-7: 52.0
agent-8: 35.0
agent-9: 48.0
agent-10: 24.0
Sum Reward: 394.0
Avg Reward: 39.4
Min Reward: 23.0
Gini Coefficient 0.14213197969543148
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-39-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 394.0
  episode_reward_mean: 271.27
  episode_reward_min: 200.0
  episodes_this_iter: 1
  episodes_total: 453
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.723
    dispatch_time_ms: 6.342
    learner:
      cur_lr: 0.0010583020048215985
      grad_gnorm: 40.0
      policy_entropy: 132.32174682617188
      policy_loss: 25.144865036010742
      var_gnorm: 57.417022705078125
      vf_explained_var: 0.7447714805603027
      vf_loss: 15.983475685119629
    num_steps_sampled: 4540000
    num_steps_trained: 4540000
    wait_time_ms: 162.396
  iterations_since_restore: 454
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 8089.852742671967
  time_this_iter_s: 17.0772864818573
  time_total_s: 8089.852742671967
  timestamp: 1593830375
  timesteps_since_restore: 4540000
  timesteps_this_iter: 10000
  timesteps_total: 4540000
  training_iteration: 454
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 8089 s, 454 iter, 4540000 ts, 271 rew

agent-1: 27.0
agent-2: 45.0
agent-3: 34.0
agent-4: 34.0
agent-5: 37.0
agent-6: 26.0
agent-7: 30.0
agent-8: 34.0
agent-9: 21.0
agent-10: 24.0
Sum Reward: 312.0
Avg Reward: 31.2
Min Reward: 21.0
Gini Coefficient 0.11923076923076924
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-39-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 394.0
  episode_reward_mean: 271.79
  episode_reward_min: 200.0
  episodes_this_iter: 1
  episodes_total: 454
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.998
    dispatch_time_ms: 6.298
    learner:
      cur_lr: 0.0010576359927654266
      grad_gnorm: 39.999996185302734
      policy_entropy: 31.245344161987305
      policy_loss: -26.482328414916992
      var_gnorm: 57.420631408691406
      vf_explained_var: 0.04413837194442749
      vf_loss: 372.7470397949219
    num_steps_sampled: 4550000
    num_steps_trained: 4550000
    wait_time_ms: 155.604
  iterations_since_restore: 455
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 8107.430629968643
  time_this_iter_s: 17.577887296676636
  time_total_s: 8107.430629968643
  timestamp: 1593830393
  timesteps_since_restore: 4550000
  timesteps_this_iter: 10000
  timesteps_total: 4550000
  training_iteration: 455
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 8107 s, 455 iter, 4550000 ts, 272 rew

agent-1: 28.0
agent-2: 26.0
agent-3: 42.0
agent-4: 54.0
agent-5: 22.0
agent-6: 51.0
agent-7: 18.0
agent-8: 28.0
agent-9: 18.0
agent-10: 29.0
Sum Reward: 316.0
Avg Reward: 31.6
Min Reward: 18.0
Gini Coefficient 0.21012658227848102
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-40-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 394.0
  episode_reward_mean: 272.38
  episode_reward_min: 200.0
  episodes_this_iter: 1
  episodes_total: 455
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.781
    dispatch_time_ms: 6.361
    learner:
      cur_lr: 0.0010569699807092547
      grad_gnorm: 40.0
      policy_entropy: 130.08905029296875
      policy_loss: 21.68246078491211
      var_gnorm: 57.523868560791016
      vf_explained_var: -0.06231188774108887
      vf_loss: 19.96644401550293
    num_steps_sampled: 4560000
    num_steps_trained: 4560000
    wait_time_ms: 164.158
  iterations_since_restore: 456
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 8124.657733201981
  time_this_iter_s: 17.227103233337402
  time_total_s: 8124.657733201981
  timestamp: 1593830410
  timesteps_since_restore: 4560000
  timesteps_this_iter: 10000
  timesteps_total: 4560000
  training_iteration: 456
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 8124 s, 456 iter, 4560000 ts, 272 rew

agent-1: 29.0
agent-2: 38.0
agent-3: 31.0
agent-4: 31.0
agent-5: 25.0
agent-6: 18.0
agent-7: 28.0
agent-8: 28.0
agent-9: 40.0
agent-10: 25.0
Sum Reward: 293.0
Avg Reward: 29.3
Min Reward: 18.0
Gini Coefficient 0.11228668941979522
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-40-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 394.0
  episode_reward_mean: 272.56
  episode_reward_min: 200.0
  episodes_this_iter: 1
  episodes_total: 456
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.306
    dispatch_time_ms: 8.46
    learner:
      cur_lr: 0.0010563039686530828
      grad_gnorm: 40.0
      policy_entropy: 36.87479782104492
      policy_loss: 27.752660751342773
      var_gnorm: 57.53286361694336
      vf_explained_var: -1.0
      vf_loss: 173.33197021484375
    num_steps_sampled: 4570000
    num_steps_trained: 4570000
    wait_time_ms: 143.176
  iterations_since_restore: 457
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 8142.055235862732
  time_this_iter_s: 17.397502660751343
  time_total_s: 8142.055235862732
  timestamp: 1593830427
  timesteps_since_restore: 4570000
  timesteps_this_iter: 10000
  timesteps_total: 4570000
  training_iteration: 457
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 8142 s, 457 iter, 4570000 ts, 273 rew

agent-1: 34.0
agent-2: 24.0
agent-3: 36.0
agent-4: 29.0
agent-5: 32.0
agent-6: 36.0
agent-7: 30.0
agent-8: 35.0
agent-9: 50.0
agent-10: 27.0
Sum Reward: 333.0
Avg Reward: 33.3
Min Reward: 24.0
Gini Coefficient 0.10480480480480481
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-40-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 394.0
  episode_reward_mean: 273.15
  episode_reward_min: 200.0
  episodes_this_iter: 1
  episodes_total: 457
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.836
    dispatch_time_ms: 7.629
    learner:
      cur_lr: 0.001055637956596911
      grad_gnorm: 0.12424052506685257
      policy_entropy: 117.12120819091797
      policy_loss: 0.13852854073047638
      var_gnorm: 57.49625015258789
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 7.374163942586165e-06
    num_steps_sampled: 4580000
    num_steps_trained: 4580000
    wait_time_ms: 160.634
  iterations_since_restore: 458
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 8159.113222360611
  time_this_iter_s: 17.05798649787903
  time_total_s: 8159.113222360611
  timestamp: 1593830444
  timesteps_since_restore: 4580000
  timesteps_this_iter: 10000
  timesteps_total: 4580000
  training_iteration: 458
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 8159 s, 458 iter, 4580000 ts, 273 rew

agent-1: 25.0
agent-2: 23.0
agent-3: 39.0
agent-4: 27.0
agent-5: 29.0
agent-6: 23.0
agent-7: 36.0
agent-8: 28.0
agent-9: 34.0
agent-10: 29.0
Sum Reward: 293.0
Avg Reward: 29.3
Min Reward: 23.0
Gini Coefficient 0.09795221843003413
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-41-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 394.0
  episode_reward_mean: 273.26
  episode_reward_min: 200.0
  episodes_this_iter: 1
  episodes_total: 458
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.574
    dispatch_time_ms: 5.612
    learner:
      cur_lr: 0.001054971944540739
      grad_gnorm: 0.3616596460342407
      policy_entropy: 120.97394561767578
      policy_loss: -0.10793376713991165
      var_gnorm: 57.499080657958984
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 6.245666736504063e-05
    num_steps_sampled: 4590000
    num_steps_trained: 4590000
    wait_time_ms: 164.001
  iterations_since_restore: 459
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 8176.743544578552
  time_this_iter_s: 17.630322217941284
  time_total_s: 8176.743544578552
  timestamp: 1593830462
  timesteps_since_restore: 4590000
  timesteps_this_iter: 10000
  timesteps_total: 4590000
  training_iteration: 459
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 8176 s, 459 iter, 4590000 ts, 273 rew

agent-1: 18.0
agent-2: 21.0
agent-3: 31.0
agent-4: 22.0
agent-5: 34.0
agent-6: 30.0
agent-7: 23.0
agent-8: 32.0
agent-9: 25.0
agent-10: 22.0
Sum Reward: 258.0
Avg Reward: 25.8
Min Reward: 18.0
Gini Coefficient 0.11317829457364341
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-41-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 394.0
  episode_reward_mean: 273.32
  episode_reward_min: 200.0
  episodes_this_iter: 1
  episodes_total: 459
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.729
    dispatch_time_ms: 5.884
    learner:
      cur_lr: 0.001054306048899889
      grad_gnorm: 2.169205665588379
      policy_entropy: 120.04498291015625
      policy_loss: -0.16515736281871796
      var_gnorm: 57.708595275878906
      vf_explained_var: -1.0
      vf_loss: 0.19757503271102905
    num_steps_sampled: 4600000
    num_steps_trained: 4600000
    wait_time_ms: 163.063
  iterations_since_restore: 460
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 8193.706361055374
  time_this_iter_s: 16.9628164768219
  time_total_s: 8193.706361055374
  timestamp: 1593830479
  timesteps_since_restore: 4600000
  timesteps_this_iter: 10000
  timesteps_total: 4600000
  training_iteration: 460
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 8193 s, 460 iter, 4600000 ts, 273 rew

agent-1: 44.0
agent-2: 28.0
agent-3: 25.0
agent-4: 39.0
agent-5: 31.0
agent-6: 30.0
agent-7: 34.0
agent-8: 43.0
agent-9: 24.0
agent-10: 36.0
Sum Reward: 334.0
Avg Reward: 33.4
Min Reward: 24.0
Gini Coefficient 0.11437125748502994
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-41-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 394.0
  episode_reward_mean: 273.25
  episode_reward_min: 200.0
  episodes_this_iter: 1
  episodes_total: 460
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.356
    dispatch_time_ms: 6.616
    learner:
      cur_lr: 0.001053640036843717
      grad_gnorm: 0.8551296591758728
      policy_entropy: 124.14481353759766
      policy_loss: 0.3769572377204895
      var_gnorm: 57.711578369140625
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.00018872552027460188
    num_steps_sampled: 4610000
    num_steps_trained: 4610000
    wait_time_ms: 162.139
  iterations_since_restore: 461
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 8211.290841579437
  time_this_iter_s: 17.58448052406311
  time_total_s: 8211.290841579437
  timestamp: 1593830497
  timesteps_since_restore: 4610000
  timesteps_this_iter: 10000
  timesteps_total: 4610000
  training_iteration: 461
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 8211 s, 461 iter, 4610000 ts, 273 rew

agent-1: 26.0
agent-2: 36.0
agent-3: 20.0
agent-4: 29.0
agent-5: 30.0
agent-6: 25.0
agent-7: 23.0
agent-8: 24.0
agent-9: 38.0
agent-10: 30.0
Sum Reward: 281.0
Avg Reward: 28.1
Min Reward: 20.0
Gini Coefficient 0.10711743772241993
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-41-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 394.0
  episode_reward_mean: 272.75
  episode_reward_min: 200.0
  episodes_this_iter: 1
  episodes_total: 461
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.129
    dispatch_time_ms: 6.147
    learner:
      cur_lr: 0.0010529740247875452
      grad_gnorm: 39.999996185302734
      policy_entropy: 95.16687774658203
      policy_loss: 15.432024002075195
      var_gnorm: 57.749141693115234
      vf_explained_var: 0.07965654134750366
      vf_loss: 8.264753341674805
    num_steps_sampled: 4620000
    num_steps_trained: 4620000
    wait_time_ms: 168.894
  iterations_since_restore: 462
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 8228.646818876266
  time_this_iter_s: 17.355977296829224
  time_total_s: 8228.646818876266
  timestamp: 1593830514
  timesteps_since_restore: 4620000
  timesteps_this_iter: 10000
  timesteps_total: 4620000
  training_iteration: 462
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 8228 s, 462 iter, 4620000 ts, 273 rew

agent-1: 17.0
agent-2: 32.0
agent-3: 27.0
agent-4: 29.0
agent-5: 23.0
agent-6: 19.0
agent-7: 26.0
agent-8: 18.0
agent-9: 24.0
agent-10: 23.0
Sum Reward: 238.0
Avg Reward: 23.8
Min Reward: 17.0
Gini Coefficient 0.11008403361344538
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-42-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 394.0
  episode_reward_mean: 272.4
  episode_reward_min: 200.0
  episodes_this_iter: 1
  episodes_total: 462
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.723
    dispatch_time_ms: 8.93
    learner:
      cur_lr: 0.0010523080127313733
      grad_gnorm: 40.0
      policy_entropy: 48.90444564819336
      policy_loss: 4.6035380363464355
      var_gnorm: 57.7515754699707
      vf_explained_var: 0.08777832984924316
      vf_loss: 132.6822509765625
    num_steps_sampled: 4630000
    num_steps_trained: 4630000
    wait_time_ms: 150.288
  iterations_since_restore: 463
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 8246.1558675766
  time_this_iter_s: 17.50904870033264
  time_total_s: 8246.1558675766
  timestamp: 1593830532
  timesteps_since_restore: 4630000
  timesteps_this_iter: 10000
  timesteps_total: 4630000
  training_iteration: 463
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 8246 s, 463 iter, 4630000 ts, 272 rew

agent-1: 16.0
agent-2: 35.0
agent-3: 23.0
agent-4: 16.0
agent-5: 19.0
agent-6: 30.0
agent-7: 34.0
agent-8: 28.0
agent-9: 30.0
agent-10: 34.0
Sum Reward: 265.0
Avg Reward: 26.5
Min Reward: 16.0
Gini Coefficient 0.1490566037735849
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-42-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 394.0
  episode_reward_mean: 272.65
  episode_reward_min: 200.0
  episodes_this_iter: 1
  episodes_total: 463
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.859
    dispatch_time_ms: 8.252
    learner:
      cur_lr: 0.0010516420006752014
      grad_gnorm: 5.9745612144470215
      policy_entropy: 111.28901672363281
      policy_loss: -2.3048362731933594
      var_gnorm: 57.7395133972168
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 0.02133881114423275
    num_steps_sampled: 4640000
    num_steps_trained: 4640000
    wait_time_ms: 165.81
  iterations_since_restore: 464
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 8263.454410552979
  time_this_iter_s: 17.298542976379395
  time_total_s: 8263.454410552979
  timestamp: 1593830549
  timesteps_since_restore: 4640000
  timesteps_this_iter: 10000
  timesteps_total: 4640000
  training_iteration: 464
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 8263 s, 464 iter, 4640000 ts, 273 rew

agent-1: 18.0
agent-2: 29.0
agent-3: 28.0
agent-4: 20.0
agent-5: 24.0
agent-6: 20.0
agent-7: 37.0
agent-8: 24.0
agent-9: 33.0
agent-10: 30.0
Sum Reward: 263.0
Avg Reward: 26.3
Min Reward: 18.0
Gini Coefficient 0.12585551330798478
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-42-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 394.0
  episode_reward_mean: 272.68
  episode_reward_min: 200.0
  episodes_this_iter: 1
  episodes_total: 464
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.679
    dispatch_time_ms: 5.59
    learner:
      cur_lr: 0.0010509759886190295
      grad_gnorm: 40.0
      policy_entropy: 30.362857818603516
      policy_loss: 30.915077209472656
      var_gnorm: 57.74245834350586
      vf_explained_var: 0.33007699251174927
      vf_loss: 149.43238830566406
    num_steps_sampled: 4650000
    num_steps_trained: 4650000
    wait_time_ms: 153.218
  iterations_since_restore: 465
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 8281.080616950989
  time_this_iter_s: 17.626206398010254
  time_total_s: 8281.080616950989
  timestamp: 1593830567
  timesteps_since_restore: 4650000
  timesteps_this_iter: 10000
  timesteps_total: 4650000
  training_iteration: 465
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 8281 s, 465 iter, 4650000 ts, 273 rew

agent-1: 21.0
agent-2: 22.0
agent-3: 20.0
agent-4: 24.0
agent-5: 28.0
agent-6: 26.0
agent-7: 39.0
agent-8: 23.0
agent-9: 16.0
agent-10: 21.0
Sum Reward: 240.0
Avg Reward: 24.0
Min Reward: 16.0
Gini Coefficient 0.12416666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-43-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 394.0
  episode_reward_mean: 272.59
  episode_reward_min: 200.0
  episodes_this_iter: 1
  episodes_total: 465
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.0
    dispatch_time_ms: 7.33
    learner:
      cur_lr: 0.0010503099765628576
      grad_gnorm: 1.8933852910995483
      policy_entropy: 124.63063049316406
      policy_loss: -0.7327212691307068
      var_gnorm: 57.727081298828125
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.002131260698661208
    num_steps_sampled: 4660000
    num_steps_trained: 4660000
    wait_time_ms: 166.383
  iterations_since_restore: 466
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 8298.473702669144
  time_this_iter_s: 17.393085718154907
  time_total_s: 8298.473702669144
  timestamp: 1593830584
  timesteps_since_restore: 4660000
  timesteps_this_iter: 10000
  timesteps_total: 4660000
  training_iteration: 466
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 8298 s, 466 iter, 4660000 ts, 273 rew

agent-1: 17.0
agent-2: 25.0
agent-3: 21.0
agent-4: 16.0
agent-5: 22.0
agent-6: 25.0
agent-7: 28.0
agent-8: 24.0
agent-9: 21.0
agent-10: 22.0
Sum Reward: 221.0
Avg Reward: 22.1
Min Reward: 16.0
Gini Coefficient 0.08733031674208144
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-43-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 394.0
  episode_reward_mean: 272.38
  episode_reward_min: 200.0
  episodes_this_iter: 1
  episodes_total: 466
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.238
    dispatch_time_ms: 6.991
    learner:
      cur_lr: 0.0010496439645066857
      grad_gnorm: 40.0
      policy_entropy: 45.12412643432617
      policy_loss: 13.923397064208984
      var_gnorm: 57.72761917114258
      vf_explained_var: 0.049237966537475586
      vf_loss: 132.55430603027344
    num_steps_sampled: 4670000
    num_steps_trained: 4670000
    wait_time_ms: 148.075
  iterations_since_restore: 467
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 8315.870880842209
  time_this_iter_s: 17.397178173065186
  time_total_s: 8315.870880842209
  timestamp: 1593830602
  timesteps_since_restore: 4670000
  timesteps_this_iter: 10000
  timesteps_total: 4670000
  training_iteration: 467
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 8315 s, 467 iter, 4670000 ts, 272 rew

agent-1: 23.0
agent-2: 19.0
agent-3: 26.0
agent-4: 29.0
agent-5: 29.0
agent-6: 18.0
agent-7: 16.0
agent-8: 20.0
agent-9: 20.0
agent-10: 14.0
Sum Reward: 214.0
Avg Reward: 21.4
Min Reward: 14.0
Gini Coefficient 0.12990654205607477
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-43-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 394.0
  episode_reward_mean: 271.93
  episode_reward_min: 200.0
  episodes_this_iter: 1
  episodes_total: 467
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.754
    dispatch_time_ms: 7.157
    learner:
      cur_lr: 0.0010489779524505138
      grad_gnorm: 2.353977918624878
      policy_entropy: 121.3204345703125
      policy_loss: -0.43128201365470886
      var_gnorm: 57.8200569152832
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 0.0033348016440868378
    num_steps_sampled: 4680000
    num_steps_trained: 4680000
    wait_time_ms: 162.341
  iterations_since_restore: 468
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 8333.022464036942
  time_this_iter_s: 17.151583194732666
  time_total_s: 8333.022464036942
  timestamp: 1593830619
  timesteps_since_restore: 4680000
  timesteps_this_iter: 10000
  timesteps_total: 4680000
  training_iteration: 468
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 8333 s, 468 iter, 4680000 ts, 272 rew

agent-1: 15.0
agent-2: 20.0
agent-3: 20.0
agent-4: 25.0
agent-5: 31.0
agent-6: 28.0
agent-7: 39.0
agent-8: 17.0
agent-9: 15.0
agent-10: 23.0
Sum Reward: 233.0
Avg Reward: 23.3
Min Reward: 15.0
Gini Coefficient 0.1721030042918455
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-43-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 394.0
  episode_reward_mean: 271.65
  episode_reward_min: 200.0
  episodes_this_iter: 1
  episodes_total: 468
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.099
    dispatch_time_ms: 9.559
    learner:
      cur_lr: 0.0010483120568096638
      grad_gnorm: 40.0
      policy_entropy: 47.88859939575195
      policy_loss: 106.98453521728516
      var_gnorm: 57.82809066772461
      vf_explained_var: -1.0
      vf_loss: 436.1134338378906
    num_steps_sampled: 4690000
    num_steps_trained: 4690000
    wait_time_ms: 143.494
  iterations_since_restore: 469
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 8350.760491132736
  time_this_iter_s: 17.738027095794678
  time_total_s: 8350.760491132736
  timestamp: 1593830637
  timesteps_since_restore: 4690000
  timesteps_this_iter: 10000
  timesteps_total: 4690000
  training_iteration: 469
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 8350 s, 469 iter, 4690000 ts, 272 rew

agent-1: 26.0
agent-2: 24.0
agent-3: 31.0
agent-4: 25.0
agent-5: 21.0
agent-6: 23.0
agent-7: 30.0
agent-8: 30.0
agent-9: 21.0
agent-10: 38.0
Sum Reward: 269.0
Avg Reward: 26.9
Min Reward: 21.0
Gini Coefficient 0.10297397769516729
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-44-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 394.0
  episode_reward_mean: 271.48
  episode_reward_min: 200.0
  episodes_this_iter: 1
  episodes_total: 469
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.281
    dispatch_time_ms: 5.91
    learner:
      cur_lr: 0.0010476460447534919
      grad_gnorm: 1.6984097957611084
      policy_entropy: 95.40760040283203
      policy_loss: 0.8608314990997314
      var_gnorm: 57.832096099853516
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 0.0015311642782762647
    num_steps_sampled: 4700000
    num_steps_trained: 4700000
    wait_time_ms: 166.446
  iterations_since_restore: 470
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 8367.912372350693
  time_this_iter_s: 17.151881217956543
  time_total_s: 8367.912372350693
  timestamp: 1593830654
  timesteps_since_restore: 4700000
  timesteps_this_iter: 10000
  timesteps_total: 4700000
  training_iteration: 470
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 8367 s, 470 iter, 4700000 ts, 271 rew

agent-1: 37.0
agent-2: 18.0
agent-3: 17.0
agent-4: 21.0
agent-5: 21.0
agent-6: 31.0
agent-7: 26.0
agent-8: 12.0
agent-9: 25.0
agent-10: 15.0
Sum Reward: 223.0
Avg Reward: 22.3
Min Reward: 12.0
Gini Coefficient 0.18071748878923766
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-44-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 394.0
  episode_reward_mean: 271.06
  episode_reward_min: 200.0
  episodes_this_iter: 1
  episodes_total: 470
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.885
    dispatch_time_ms: 6.25
    learner:
      cur_lr: 0.00104698003269732
      grad_gnorm: 40.0
      policy_entropy: 64.51820373535156
      policy_loss: 41.93527603149414
      var_gnorm: 57.83612823486328
      vf_explained_var: 0.4013625383377075
      vf_loss: 186.6376495361328
    num_steps_sampled: 4710000
    num_steps_trained: 4710000
    wait_time_ms: 156.47
  iterations_since_restore: 471
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 8385.576570987701
  time_this_iter_s: 17.664198637008667
  time_total_s: 8385.576570987701
  timestamp: 1593830671
  timesteps_since_restore: 4710000
  timesteps_this_iter: 10000
  timesteps_total: 4710000
  training_iteration: 471
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 8385 s, 471 iter, 4710000 ts, 271 rew

agent-1: 23.0
agent-2: 42.0
agent-3: 29.0
agent-4: 29.0
agent-5: 35.0
agent-6: 30.0
agent-7: 18.0
agent-8: 26.0
agent-9: 23.0
agent-10: 12.0
Sum Reward: 267.0
Avg Reward: 26.7
Min Reward: 12.0
Gini Coefficient 0.16666666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-44-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 394.0
  episode_reward_mean: 270.94
  episode_reward_min: 200.0
  episodes_this_iter: 1
  episodes_total: 471
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.801
    dispatch_time_ms: 6.005
    learner:
      cur_lr: 0.001046314020641148
      grad_gnorm: 2.4068713188171387
      policy_entropy: 128.23123168945312
      policy_loss: -0.8647216558456421
      var_gnorm: 57.8499641418457
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.003270842367783189
    num_steps_sampled: 4720000
    num_steps_trained: 4720000
    wait_time_ms: 167.677
  iterations_since_restore: 472
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 8402.894410133362
  time_this_iter_s: 17.3178391456604
  time_total_s: 8402.894410133362
  timestamp: 1593830689
  timesteps_since_restore: 4720000
  timesteps_this_iter: 10000
  timesteps_total: 4720000
  training_iteration: 472
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 8402 s, 472 iter, 4720000 ts, 271 rew

agent-1: 35.0
agent-2: 22.0
agent-3: 24.0
agent-4: 34.0
agent-5: 23.0
agent-6: 33.0
agent-7: 19.0
agent-8: 17.0
agent-9: 14.0
agent-10: 17.0
Sum Reward: 238.0
Avg Reward: 23.8
Min Reward: 14.0
Gini Coefficient 0.16974789915966387
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-45-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 394.0
  episode_reward_mean: 271.12
  episode_reward_min: 200.0
  episodes_this_iter: 1
  episodes_total: 472
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.787
    dispatch_time_ms: 8.896
    learner:
      cur_lr: 0.0010456480085849762
      grad_gnorm: 4.577235698699951
      policy_entropy: 139.10377502441406
      policy_loss: 2.21014404296875
      var_gnorm: 57.850013732910156
      vf_explained_var: 0.0
      vf_loss: 0.07158159464597702
    num_steps_sampled: 4730000
    num_steps_trained: 4730000
    wait_time_ms: 166.633
  iterations_since_restore: 473
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 8420.424629688263
  time_this_iter_s: 17.530219554901123
  time_total_s: 8420.424629688263
  timestamp: 1593830706
  timesteps_since_restore: 4730000
  timesteps_this_iter: 10000
  timesteps_total: 4730000
  training_iteration: 473
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 8420 s, 473 iter, 4730000 ts, 271 rew

agent-1: 18.0
agent-2: 21.0
agent-3: 32.0
agent-4: 18.0
agent-5: 29.0
agent-6: 17.0
agent-7: 25.0
agent-8: 22.0
agent-9: 28.0
agent-10: 28.0
Sum Reward: 238.0
Avg Reward: 23.8
Min Reward: 17.0
Gini Coefficient 0.12016806722689076
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-45-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 394.0
  episode_reward_mean: 271.21
  episode_reward_min: 200.0
  episodes_this_iter: 1
  episodes_total: 473
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.916
    dispatch_time_ms: 6.441
    learner:
      cur_lr: 0.0010449819965288043
      grad_gnorm: 1.1766176223754883
      policy_entropy: 130.8954315185547
      policy_loss: -0.32503801584243774
      var_gnorm: 58.038780212402344
      vf_explained_var: -1.0
      vf_loss: 0.008628014475107193
    num_steps_sampled: 4740000
    num_steps_trained: 4740000
    wait_time_ms: 165.542
  iterations_since_restore: 474
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 8437.607421159744
  time_this_iter_s: 17.182791471481323
  time_total_s: 8437.607421159744
  timestamp: 1593830724
  timesteps_since_restore: 4740000
  timesteps_this_iter: 10000
  timesteps_total: 4740000
  training_iteration: 474
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 8437 s, 474 iter, 4740000 ts, 271 rew

agent-1: 27.0
agent-2: 28.0
agent-3: 29.0
agent-4: 17.0
agent-5: 34.0
agent-6: 21.0
agent-7: 25.0
agent-8: 27.0
agent-9: 26.0
agent-10: 16.0
Sum Reward: 250.0
Avg Reward: 25.0
Min Reward: 16.0
Gini Coefficient 0.1152
agent-1: 26.0
agent-2: 22.0
agent-3: 27.0
agent-4: 43.0
agent-5: 19.0
agent-6: 27.0
agent-7: 12.0
agent-8: 28.0
agent-9: 19.0
agent-10: 19.0
Sum Reward: 242.0
Avg Reward: 24.2
Min Reward: 12.0
Gini Coefficient 0.16942148760330578
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-45-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 394.0
  episode_reward_mean: 271.06
  episode_reward_min: 200.0
  episodes_this_iter: 2
  episodes_total: 475
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.027
    dispatch_time_ms: 6.359
    learner:
      cur_lr: 0.0010443159844726324
      grad_gnorm: 1.2025704383850098
      policy_entropy: 134.1484375
      policy_loss: 0.3839263319969177
      var_gnorm: 58.03955078125
      vf_explained_var: -1.0
      vf_loss: 0.008440732024610043
    num_steps_sampled: 4750000
    num_steps_trained: 4750000
    wait_time_ms: 170.797
  iterations_since_restore: 475
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 8455.297464609146
  time_this_iter_s: 17.690043449401855
  time_total_s: 8455.297464609146
  timestamp: 1593830741
  timesteps_since_restore: 4750000
  timesteps_this_iter: 10000
  timesteps_total: 4750000
  training_iteration: 475
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 8455 s, 475 iter, 4750000 ts, 271 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-45-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 394.0
  episode_reward_mean: 271.06
  episode_reward_min: 200.0
  episodes_this_iter: 0
  episodes_total: 475
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.758
    dispatch_time_ms: 6.506
    learner:
      cur_lr: 0.0010436499724164605
      grad_gnorm: 6.44885778427124
      policy_entropy: 101.55525970458984
      policy_loss: -2.157346725463867
      var_gnorm: 58.25935363769531
      vf_explained_var: 0.9532037377357483
      vf_loss: 0.05908473581075668
    num_steps_sampled: 4760000
    num_steps_trained: 4760000
    wait_time_ms: 168.739
  iterations_since_restore: 476
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 8472.136712551117
  time_this_iter_s: 16.839247941970825
  time_total_s: 8472.136712551117
  timestamp: 1593830758
  timesteps_since_restore: 4760000
  timesteps_this_iter: 10000
  timesteps_total: 4760000
  training_iteration: 476
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 8472 s, 476 iter, 4760000 ts, 271 rew

agent-1: 23.0
agent-2: 26.0
agent-3: 18.0
agent-4: 29.0
agent-5: 33.0
agent-6: 35.0
agent-7: 26.0
agent-8: 29.0
agent-9: 31.0
agent-10: 27.0
Sum Reward: 277.0
Avg Reward: 27.7
Min Reward: 18.0
Gini Coefficient 0.09350180505415162
agent-1: 27.0
agent-2: 41.0
agent-3: 40.0
agent-4: 25.0
agent-5: 33.0
agent-6: 14.0
agent-7: 35.0
agent-8: 41.0
agent-9: 32.0
agent-10: 54.0
Sum Reward: 342.0
Avg Reward: 34.2
Min Reward: 14.0
Gini Coefficient 0.16608187134502925
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-46-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 394.0
  episode_reward_mean: 271.69
  episode_reward_min: 200.0
  episodes_this_iter: 2
  episodes_total: 477
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.525
    dispatch_time_ms: 5.752
    learner:
      cur_lr: 0.0010429839603602886
      grad_gnorm: 0.5096599459648132
      policy_entropy: 132.20518493652344
      policy_loss: 0.19733384251594543
      var_gnorm: 58.28236770629883
      vf_explained_var: -1.0
      vf_loss: 0.00011733117571566254
    num_steps_sampled: 4770000
    num_steps_trained: 4770000
    wait_time_ms: 163.542
  iterations_since_restore: 477
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 8489.80618929863
  time_this_iter_s: 17.669476747512817
  time_total_s: 8489.80618929863
  timestamp: 1593830776
  timesteps_since_restore: 4770000
  timesteps_this_iter: 10000
  timesteps_total: 4770000
  training_iteration: 477
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 8489 s, 477 iter, 4770000 ts, 272 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-46-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 394.0
  episode_reward_mean: 271.69
  episode_reward_min: 200.0
  episodes_this_iter: 0
  episodes_total: 477
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.678
    dispatch_time_ms: 6.196
    learner:
      cur_lr: 0.0010423179483041167
      grad_gnorm: 7.272218227386475
      policy_entropy: 133.6789093017578
      policy_loss: -2.219151020050049
      var_gnorm: 58.33343505859375
      vf_explained_var: -1.0
      vf_loss: 0.411406934261322
    num_steps_sampled: 4780000
    num_steps_trained: 4780000
    wait_time_ms: 161.049
  iterations_since_restore: 478
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 8506.792536973953
  time_this_iter_s: 16.986347675323486
  time_total_s: 8506.792536973953
  timestamp: 1593830793
  timesteps_since_restore: 4780000
  timesteps_this_iter: 10000
  timesteps_total: 4780000
  training_iteration: 478
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 8506 s, 478 iter, 4780000 ts, 272 rew

agent-1: 31.0
agent-2: 17.0
agent-3: 30.0
agent-4: 30.0
agent-5: 25.0
agent-6: 17.0
agent-7: 33.0
agent-8: 28.0
agent-9: 38.0
agent-10: 24.0
Sum Reward: 273.0
Avg Reward: 27.3
Min Reward: 17.0
Gini Coefficient 0.12930402930402932
agent-1: 29.0
agent-2: 34.0
agent-3: 18.0
agent-4: 28.0
agent-5: 25.0
agent-6: 28.0
agent-7: 26.0
agent-8: 24.0
agent-9: 44.0
agent-10: 21.0
Sum Reward: 277.0
Avg Reward: 27.7
Min Reward: 18.0
Gini Coefficient 0.1303249097472924
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-46-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 394.0
  episode_reward_mean: 272.2
  episode_reward_min: 200.0
  episodes_this_iter: 2
  episodes_total: 479
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.688
    dispatch_time_ms: 7.055
    learner:
      cur_lr: 0.0010416520526632667
      grad_gnorm: 13.009805679321289
      policy_entropy: 149.93057250976562
      policy_loss: 6.171797752380371
      var_gnorm: 58.34703826904297
      vf_explained_var: -1.0
      vf_loss: 0.0789957046508789
    num_steps_sampled: 4790000
    num_steps_trained: 4790000
    wait_time_ms: 170.79
  iterations_since_restore: 479
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 8524.605858802795
  time_this_iter_s: 17.813321828842163
  time_total_s: 8524.605858802795
  timestamp: 1593830811
  timesteps_since_restore: 4790000
  timesteps_this_iter: 10000
  timesteps_total: 4790000
  training_iteration: 479
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 8524 s, 479 iter, 4790000 ts, 272 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-47-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 394.0
  episode_reward_mean: 272.2
  episode_reward_min: 200.0
  episodes_this_iter: 0
  episodes_total: 479
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.619
    dispatch_time_ms: 7.421
    learner:
      cur_lr: 0.0010409860406070948
      grad_gnorm: 4.170124053955078
      policy_entropy: 124.45468139648438
      policy_loss: -1.9264943599700928
      var_gnorm: 58.34091567993164
      vf_explained_var: 0.13221770524978638
      vf_loss: 0.09273705631494522
    num_steps_sampled: 4800000
    num_steps_trained: 4800000
    wait_time_ms: 166.145
  iterations_since_restore: 480
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 8541.664046287537
  time_this_iter_s: 17.05818748474121
  time_total_s: 8541.664046287537
  timestamp: 1593830828
  timesteps_since_restore: 4800000
  timesteps_this_iter: 10000
  timesteps_total: 4800000
  training_iteration: 480
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 8541 s, 480 iter, 4800000 ts, 272 rew

agent-1: 22.0
agent-2: 29.0
agent-3: 22.0
agent-4: 25.0
agent-5: 29.0
agent-6: 34.0
agent-7: 35.0
agent-8: 26.0
agent-9: 27.0
agent-10: 24.0
Sum Reward: 273.0
Avg Reward: 27.3
Min Reward: 22.0
Gini Coefficient 0.08754578754578754
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-47-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 394.0
  episode_reward_mean: 272.43
  episode_reward_min: 200.0
  episodes_this_iter: 1
  episodes_total: 480
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.87
    dispatch_time_ms: 6.165
    learner:
      cur_lr: 0.0010403200285509229
      grad_gnorm: 40.0
      policy_entropy: 34.24946212768555
      policy_loss: 52.526023864746094
      var_gnorm: 58.343257904052734
      vf_explained_var: -0.04673314094543457
      vf_loss: 345.530029296875
    num_steps_sampled: 4810000
    num_steps_trained: 4810000
    wait_time_ms: 157.357
  iterations_since_restore: 481
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 8559.198204517365
  time_this_iter_s: 17.53415822982788
  time_total_s: 8559.198204517365
  timestamp: 1593830845
  timesteps_since_restore: 4810000
  timesteps_this_iter: 10000
  timesteps_total: 4810000
  training_iteration: 481
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 8559 s, 481 iter, 4810000 ts, 272 rew

agent-1: 25.0
agent-2: 26.0
agent-3: 24.0
agent-4: 30.0
agent-5: 32.0
agent-6: 35.0
agent-7: 32.0
agent-8: 17.0
agent-9: 28.0
agent-10: 17.0
Sum Reward: 266.0
Avg Reward: 26.6
Min Reward: 17.0
Gini Coefficient 0.12180451127819548
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-47-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 394.0
  episode_reward_mean: 272.78
  episode_reward_min: 200.0
  episodes_this_iter: 1
  episodes_total: 481
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.686
    dispatch_time_ms: 10.071
    learner:
      cur_lr: 0.001039654016494751
      grad_gnorm: 0.6055423617362976
      policy_entropy: 156.1641845703125
      policy_loss: -0.11989288032054901
      var_gnorm: 58.47492980957031
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.00018949572404380888
    num_steps_sampled: 4820000
    num_steps_trained: 4820000
    wait_time_ms: 163.871
  iterations_since_restore: 482
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 8576.143311738968
  time_this_iter_s: 16.945107221603394
  time_total_s: 8576.143311738968
  timestamp: 1593830862
  timesteps_since_restore: 4820000
  timesteps_this_iter: 10000
  timesteps_total: 4820000
  training_iteration: 482
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 8576 s, 482 iter, 4820000 ts, 273 rew

agent-1: 29.0
agent-2: 39.0
agent-3: 36.0
agent-4: 29.0
agent-5: 45.0
agent-6: 51.0
agent-7: 38.0
agent-8: 24.0
agent-9: 37.0
agent-10: 22.0
Sum Reward: 350.0
Avg Reward: 35.0
Min Reward: 22.0
Gini Coefficient 0.13885714285714285
agent-1: 30.0
agent-2: 21.0
agent-3: 34.0
agent-4: 13.0
agent-5: 28.0
agent-6: 28.0
agent-7: 22.0
agent-8: 5.0
agent-9: 19.0
agent-10: 38.0
Sum Reward: 238.0
Avg Reward: 23.8
Min Reward: 5.0
Gini Coefficient 0.22100840336134453
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-48-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 394.0
  episode_reward_mean: 273.72
  episode_reward_min: 200.0
  episodes_this_iter: 1
  episodes_total: 482
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.464
    dispatch_time_ms: 6.262
    learner:
      cur_lr: 0.001038988004438579
      grad_gnorm: 40.0
      policy_entropy: 22.749954223632812
      policy_loss: 75.70664978027344
      var_gnorm: 58.47603988647461
      vf_explained_var: -0.1839601993560791
      vf_loss: 328.5325012207031
    num_steps_sampled: 4830000
    num_steps_trained: 4830000
    wait_time_ms: 159.262
  iterations_since_restore: 483
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 8593.846472740173
  time_this_iter_s: 17.703161001205444
  time_total_s: 8593.846472740173
  timestamp: 1593830880
  timesteps_since_restore: 4830000
  timesteps_this_iter: 10000
  timesteps_total: 4830000
  training_iteration: 483
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 8593 s, 483 iter, 4830000 ts, 274 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-48-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 394.0
  episode_reward_mean: 274.1
  episode_reward_min: 207.0
  episodes_this_iter: 1
  episodes_total: 483
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.157
    dispatch_time_ms: 8.259
    learner:
      cur_lr: 0.0010383219923824072
      grad_gnorm: 1.5921988487243652
      policy_entropy: 151.67291259765625
      policy_loss: -0.7357243895530701
      var_gnorm: 58.496917724609375
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.0014741967897862196
    num_steps_sampled: 4840000
    num_steps_trained: 4840000
    wait_time_ms: 166.043
  iterations_since_restore: 484
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 8610.979990720749
  time_this_iter_s: 17.13351798057556
  time_total_s: 8610.979990720749
  timestamp: 1593830897
  timesteps_since_restore: 4840000
  timesteps_this_iter: 10000
  timesteps_total: 4840000
  training_iteration: 484
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 8610 s, 484 iter, 4840000 ts, 274 rew

agent-1: 22.0
agent-2: 34.0
agent-3: 27.0
agent-4: 37.0
agent-5: 27.0
agent-6: 18.0
agent-7: 32.0
agent-8: 25.0
agent-9: 25.0
agent-10: 28.0
Sum Reward: 275.0
Avg Reward: 27.5
Min Reward: 18.0
Gini Coefficient 0.10872727272727273
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-48-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 394.0
  episode_reward_mean: 274.53
  episode_reward_min: 207.0
  episodes_this_iter: 1
  episodes_total: 484
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.79
    dispatch_time_ms: 6.973
    learner:
      cur_lr: 0.0010376559803262353
      grad_gnorm: 40.0
      policy_entropy: 35.64888381958008
      policy_loss: 144.607421875
      var_gnorm: 58.49748992919922
      vf_explained_var: -0.08084738254547119
      vf_loss: 437.09197998046875
    num_steps_sampled: 4850000
    num_steps_trained: 4850000
    wait_time_ms: 158.472
  iterations_since_restore: 485
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 8628.408920764923
  time_this_iter_s: 17.428930044174194
  time_total_s: 8628.408920764923
  timestamp: 1593830915
  timesteps_since_restore: 4850000
  timesteps_this_iter: 10000
  timesteps_total: 4850000
  training_iteration: 485
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 8628 s, 485 iter, 4850000 ts, 275 rew

agent-1: 28.0
agent-2: 23.0
agent-3: 39.0
agent-4: 25.0
agent-5: 28.0
agent-6: 38.0
agent-7: 15.0
agent-8: 26.0
agent-9: 19.0
agent-10: 15.0
Sum Reward: 256.0
Avg Reward: 25.6
Min Reward: 15.0
Gini Coefficient 0.17109375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-48-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 394.0
  episode_reward_mean: 274.35
  episode_reward_min: 207.0
  episodes_this_iter: 1
  episodes_total: 485
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.947
    dispatch_time_ms: 6.601
    learner:
      cur_lr: 0.0010369899682700634
      grad_gnorm: 1.0615040063858032
      policy_entropy: 103.20597839355469
      policy_loss: 0.20548716187477112
      var_gnorm: 58.61848068237305
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.0006556998705491424
    num_steps_sampled: 4860000
    num_steps_trained: 4860000
    wait_time_ms: 167.8
  iterations_since_restore: 486
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 8645.79647564888
  time_this_iter_s: 17.38755488395691
  time_total_s: 8645.79647564888
  timestamp: 1593830932
  timesteps_since_restore: 4860000
  timesteps_this_iter: 10000
  timesteps_total: 4860000
  training_iteration: 486
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 8645 s, 486 iter, 4860000 ts, 274 rew

agent-1: 19.0
agent-2: 32.0
agent-3: 16.0
agent-4: 8.0
agent-5: 11.0
agent-6: 26.0
agent-7: 21.0
agent-8: 31.0
agent-9: 21.0
agent-10: 24.0
Sum Reward: 209.0
Avg Reward: 20.9
Min Reward: 8.0
Gini Coefficient 0.2014354066985646
agent-1: 25.0
agent-2: 26.0
agent-3: 29.0
agent-4: 20.0
agent-5: 11.0
agent-6: 20.0
agent-7: 25.0
agent-8: 26.0
agent-9: 36.0
agent-10: 28.0
Sum Reward: 246.0
Avg Reward: 24.6
Min Reward: 11.0
Gini Coefficient 0.13495934959349593
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-49-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 394.0
  episode_reward_mean: 274.0
  episode_reward_min: 207.0
  episodes_this_iter: 1
  episodes_total: 486
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.842
    dispatch_time_ms: 6.565
    learner:
      cur_lr: 0.0010363239562138915
      grad_gnorm: 40.0
      policy_entropy: 22.83534812927246
      policy_loss: 68.3241958618164
      var_gnorm: 58.61930847167969
      vf_explained_var: 0.5454838871955872
      vf_loss: 391.2741394042969
    num_steps_sampled: 4870000
    num_steps_trained: 4870000
    wait_time_ms: 159.063
  iterations_since_restore: 487
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 8663.664391040802
  time_this_iter_s: 17.867915391921997
  time_total_s: 8663.664391040802
  timestamp: 1593830950
  timesteps_since_restore: 4870000
  timesteps_this_iter: 10000
  timesteps_total: 4870000
  training_iteration: 487
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 8663 s, 487 iter, 4870000 ts, 274 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-49-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 394.0
  episode_reward_mean: 273.74
  episode_reward_min: 207.0
  episodes_this_iter: 1
  episodes_total: 487
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.132
    dispatch_time_ms: 5.911
    learner:
      cur_lr: 0.0010356579441577196
      grad_gnorm: 7.908945083618164
      policy_entropy: 105.30155944824219
      policy_loss: -2.808953046798706
      var_gnorm: 58.63509750366211
      vf_explained_var: 0.0
      vf_loss: 0.035877395421266556
    num_steps_sampled: 4880000
    num_steps_trained: 4880000
    wait_time_ms: 163.314
  iterations_since_restore: 488
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 8680.650380373001
  time_this_iter_s: 16.985989332199097
  time_total_s: 8680.650380373001
  timestamp: 1593830967
  timesteps_since_restore: 4880000
  timesteps_this_iter: 10000
  timesteps_total: 4880000
  training_iteration: 488
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 8680 s, 488 iter, 4880000 ts, 274 rew

agent-1: 32.0
agent-2: 31.0
agent-3: 28.0
agent-4: 31.0
agent-5: 29.0
agent-6: 21.0
agent-7: 23.0
agent-8: 34.0
agent-9: 14.0
agent-10: 21.0
Sum Reward: 264.0
Avg Reward: 26.4
Min Reward: 14.0
Gini Coefficient 0.12575757575757576
agent-1: 33.0
agent-2: 34.0
agent-3: 39.0
agent-4: 28.0
agent-5: 12.0
agent-6: 9.0
agent-7: 29.0
agent-8: 40.0
agent-9: 24.0
agent-10: 30.0
Sum Reward: 278.0
Avg Reward: 27.8
Min Reward: 9.0
Gini Coefficient 0.1920863309352518
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-49-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 394.0
  episode_reward_mean: 274.4
  episode_reward_min: 207.0
  episodes_this_iter: 2
  episodes_total: 489
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.555
    dispatch_time_ms: 7.123
    learner:
      cur_lr: 0.0010349920485168695
      grad_gnorm: 15.788717269897461
      policy_entropy: 141.03097534179688
      policy_loss: -6.362486362457275
      var_gnorm: 58.6316032409668
      vf_explained_var: -1.0
      vf_loss: 0.11506073921918869
    num_steps_sampled: 4890000
    num_steps_trained: 4890000
    wait_time_ms: 162.248
  iterations_since_restore: 489
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 8698.076575517654
  time_this_iter_s: 17.42619514465332
  time_total_s: 8698.076575517654
  timestamp: 1593830985
  timesteps_since_restore: 4890000
  timesteps_this_iter: 10000
  timesteps_total: 4890000
  training_iteration: 489
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 8698 s, 489 iter, 4890000 ts, 274 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-50-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 394.0
  episode_reward_mean: 274.4
  episode_reward_min: 207.0
  episodes_this_iter: 0
  episodes_total: 489
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.705
    dispatch_time_ms: 7.327
    learner:
      cur_lr: 0.0010343260364606977
      grad_gnorm: 2.8533692359924316
      policy_entropy: 140.3909912109375
      policy_loss: -1.2766495943069458
      var_gnorm: 58.61262512207031
      vf_explained_var: 0.0
      vf_loss: 0.0038390872068703175
    num_steps_sampled: 4900000
    num_steps_trained: 4900000
    wait_time_ms: 171.566
  iterations_since_restore: 490
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 8715.290840625763
  time_this_iter_s: 17.21426510810852
  time_total_s: 8715.290840625763
  timestamp: 1593831002
  timesteps_since_restore: 4900000
  timesteps_this_iter: 10000
  timesteps_total: 4900000
  training_iteration: 490
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 8715 s, 490 iter, 4900000 ts, 274 rew

agent-1: 13.0
agent-2: 34.0
agent-3: 33.0
agent-4: 20.0
agent-5: 45.0
agent-6: 20.0
agent-7: 17.0
agent-8: 12.0
agent-9: 18.0
agent-10: 28.0
Sum Reward: 240.0
Avg Reward: 24.0
Min Reward: 12.0
Gini Coefficient 0.23083333333333333
agent-1: 23.0
agent-2: 16.0
agent-3: 19.0
agent-4: 38.0
agent-5: 34.0
agent-6: 14.0
agent-7: 27.0
agent-8: 26.0
agent-9: 20.0
agent-10: 14.0
Sum Reward: 231.0
Avg Reward: 23.1
Min Reward: 14.0
Gini Coefficient 0.18831168831168832
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-50-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 394.0
  episode_reward_mean: 274.47
  episode_reward_min: 207.0
  episodes_this_iter: 2
  episodes_total: 491
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.95
    dispatch_time_ms: 6.946
    learner:
      cur_lr: 0.0010336600244045258
      grad_gnorm: 0.14337480068206787
      policy_entropy: 151.09661865234375
      policy_loss: -0.018917065113782883
      var_gnorm: 58.61555862426758
      vf_explained_var: -1.0
      vf_loss: 3.004352606694738e-07
    num_steps_sampled: 4910000
    num_steps_trained: 4910000
    wait_time_ms: 169.038
  iterations_since_restore: 491
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 8732.918954133987
  time_this_iter_s: 17.628113508224487
  time_total_s: 8732.918954133987
  timestamp: 1593831019
  timesteps_since_restore: 4910000
  timesteps_this_iter: 10000
  timesteps_total: 4910000
  training_iteration: 491
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 8732 s, 491 iter, 4910000 ts, 274 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-50-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 394.0
  episode_reward_mean: 274.47
  episode_reward_min: 207.0
  episodes_this_iter: 0
  episodes_total: 491
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.199
    dispatch_time_ms: 8.014
    learner:
      cur_lr: 0.0010329940123483539
      grad_gnorm: 1.4102427959442139
      policy_entropy: 156.62213134765625
      policy_loss: -0.7445458173751831
      var_gnorm: 58.68361282348633
      vf_explained_var: 0.0
      vf_loss: 0.001093556871637702
    num_steps_sampled: 4920000
    num_steps_trained: 4920000
    wait_time_ms: 164.664
  iterations_since_restore: 492
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 8749.819853782654
  time_this_iter_s: 16.900899648666382
  time_total_s: 8749.819853782654
  timestamp: 1593831036
  timesteps_since_restore: 4920000
  timesteps_this_iter: 10000
  timesteps_total: 4920000
  training_iteration: 492
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 8749 s, 492 iter, 4920000 ts, 274 rew

agent-1: 32.0
agent-2: 16.0
agent-3: 43.0
agent-4: 41.0
agent-5: 43.0
agent-6: 7.0
agent-7: 10.0
agent-8: 15.0
agent-9: 25.0
agent-10: 46.0
Sum Reward: 278.0
Avg Reward: 27.8
Min Reward: 7.0
Gini Coefficient 0.2892086330935252
agent-1: 28.0
agent-2: 13.0
agent-3: 39.0
agent-4: 16.0
agent-5: 13.0
agent-6: 28.0
agent-7: 23.0
agent-8: 18.0
agent-9: 24.0
agent-10: 21.0
Sum Reward: 223.0
Avg Reward: 22.3
Min Reward: 13.0
Gini Coefficient 0.18789237668161435
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-50-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 394.0
  episode_reward_mean: 274.58
  episode_reward_min: 207.0
  episodes_this_iter: 2
  episodes_total: 493
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.801
    dispatch_time_ms: 6.509
    learner:
      cur_lr: 0.001032328000292182
      grad_gnorm: 0.644074022769928
      policy_entropy: 162.92355346679688
      policy_loss: 0.2965579628944397
      var_gnorm: 58.6845703125
      vf_explained_var: -1.0
      vf_loss: 0.00019060100021306425
    num_steps_sampled: 4930000
    num_steps_trained: 4930000
    wait_time_ms: 166.796
  iterations_since_restore: 493
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 8767.44640660286
  time_this_iter_s: 17.62655282020569
  time_total_s: 8767.44640660286
  timestamp: 1593831054
  timesteps_since_restore: 4930000
  timesteps_this_iter: 10000
  timesteps_total: 4930000
  training_iteration: 493
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 8767 s, 493 iter, 4930000 ts, 275 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-51-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 394.0
  episode_reward_mean: 274.58
  episode_reward_min: 207.0
  episodes_this_iter: 0
  episodes_total: 493
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.56
    dispatch_time_ms: 6.185
    learner:
      cur_lr: 0.00103166198823601
      grad_gnorm: 0.5100027322769165
      policy_entropy: 155.89990234375
      policy_loss: -0.2161986380815506
      var_gnorm: 58.72601318359375
      vf_explained_var: 0.0
      vf_loss: 0.00014027160068508238
    num_steps_sampled: 4940000
    num_steps_trained: 4940000
    wait_time_ms: 171.586
  iterations_since_restore: 494
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 8784.689572811127
  time_this_iter_s: 17.243166208267212
  time_total_s: 8784.689572811127
  timestamp: 1593831071
  timesteps_since_restore: 4940000
  timesteps_this_iter: 10000
  timesteps_total: 4940000
  training_iteration: 494
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 8784 s, 494 iter, 4940000 ts, 275 rew

agent-1: 27.0
agent-2: 26.0
agent-3: 20.0
agent-4: 22.0
agent-5: 29.0
agent-6: 26.0
agent-7: 19.0
agent-8: 15.0
agent-9: 25.0
agent-10: 25.0
Sum Reward: 234.0
Avg Reward: 23.4
Min Reward: 15.0
Gini Coefficient 0.09572649572649573
agent-1: 22.0
agent-2: 28.0
agent-3: 30.0
agent-4: 36.0
agent-5: 26.0
agent-6: 28.0
agent-7: 19.0
agent-8: 18.0
agent-9: 14.0
agent-10: 17.0
Sum Reward: 238.0
Avg Reward: 23.8
Min Reward: 14.0
Gini Coefficient 0.15546218487394958
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-51-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 394.0
  episode_reward_mean: 273.92
  episode_reward_min: 207.0
  episodes_this_iter: 2
  episodes_total: 495
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.624
    dispatch_time_ms: 7.788
    learner:
      cur_lr: 0.0010309959761798382
      grad_gnorm: 5.26942253112793
      policy_entropy: 158.63885498046875
      policy_loss: -2.444279909133911
      var_gnorm: 58.72636413574219
      vf_explained_var: -1.0
      vf_loss: 0.012796188704669476
    num_steps_sampled: 4950000
    num_steps_trained: 4950000
    wait_time_ms: 163.971
  iterations_since_restore: 495
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 8802.151350021362
  time_this_iter_s: 17.461777210235596
  time_total_s: 8802.151350021362
  timestamp: 1593831089
  timesteps_since_restore: 4950000
  timesteps_this_iter: 10000
  timesteps_total: 4950000
  training_iteration: 495
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 8802 s, 495 iter, 4950000 ts, 274 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-51-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 394.0
  episode_reward_mean: 273.92
  episode_reward_min: 207.0
  episodes_this_iter: 0
  episodes_total: 495
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.52
    dispatch_time_ms: 7.928
    learner:
      cur_lr: 0.0010303299641236663
      grad_gnorm: 0.42302030324935913
      policy_entropy: 119.35485076904297
      policy_loss: -0.25605517625808716
      var_gnorm: 58.813438415527344
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 5.0049720812239684e-08
    num_steps_sampled: 4960000
    num_steps_trained: 4960000
    wait_time_ms: 161.465
  iterations_since_restore: 496
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 8819.284409284592
  time_this_iter_s: 17.13305926322937
  time_total_s: 8819.284409284592
  timestamp: 1593831106
  timesteps_since_restore: 4960000
  timesteps_this_iter: 10000
  timesteps_total: 4960000
  training_iteration: 496
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 8819 s, 496 iter, 4960000 ts, 274 rew

agent-1: 16.0
agent-2: 20.0
agent-3: 39.0
agent-4: 28.0
agent-5: 44.0
agent-6: 29.0
agent-7: 24.0
agent-8: 19.0
agent-9: 25.0
agent-10: 21.0
Sum Reward: 265.0
Avg Reward: 26.5
Min Reward: 16.0
Gini Coefficient 0.17320754716981132
agent-1: 29.0
agent-2: 22.0
agent-3: 41.0
agent-4: 31.0
agent-5: 4.0
agent-6: 23.0
agent-7: 21.0
agent-8: 24.0
agent-9: 14.0
agent-10: 27.0
Sum Reward: 236.0
Avg Reward: 23.6
Min Reward: 4.0
Gini Coefficient 0.21525423728813559
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-52-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 394.0
  episode_reward_mean: 274.0
  episode_reward_min: 207.0
  episodes_this_iter: 2
  episodes_total: 497
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.226
    dispatch_time_ms: 8.882
    learner:
      cur_lr: 0.0010296639520674944
      grad_gnorm: 0.48755064606666565
      policy_entropy: 127.90965270996094
      policy_loss: 0.18783757090568542
      var_gnorm: 58.81414031982422
      vf_explained_var: -1.0
      vf_loss: 0.0001009881088975817
    num_steps_sampled: 4970000
    num_steps_trained: 4970000
    wait_time_ms: 160.337
  iterations_since_restore: 497
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 8836.79975771904
  time_this_iter_s: 17.515348434448242
  time_total_s: 8836.79975771904
  timestamp: 1593831124
  timesteps_since_restore: 4970000
  timesteps_this_iter: 10000
  timesteps_total: 4970000
  training_iteration: 497
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 8836 s, 497 iter, 4970000 ts, 274 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-52-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 394.0
  episode_reward_mean: 274.0
  episode_reward_min: 207.0
  episodes_this_iter: 0
  episodes_total: 497
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.061
    dispatch_time_ms: 6.439
    learner:
      cur_lr: 0.0010289980564266443
      grad_gnorm: 1.2701083421707153
      policy_entropy: 136.5612030029297
      policy_loss: -0.4966558516025543
      var_gnorm: 58.9066047668457
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.0009298691293224692
    num_steps_sampled: 4980000
    num_steps_trained: 4980000
    wait_time_ms: 167.194
  iterations_since_restore: 498
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 8853.789830684662
  time_this_iter_s: 16.99007296562195
  time_total_s: 8853.789830684662
  timestamp: 1593831141
  timesteps_since_restore: 4980000
  timesteps_this_iter: 10000
  timesteps_total: 4980000
  training_iteration: 498
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 8853 s, 498 iter, 4980000 ts, 274 rew

agent-1: 29.0
agent-2: 33.0
agent-3: 31.0
agent-4: 32.0
agent-5: 21.0
agent-6: 24.0
agent-7: 18.0
agent-8: 32.0
agent-9: 30.0
agent-10: 26.0
Sum Reward: 276.0
Avg Reward: 27.6
Min Reward: 18.0
Gini Coefficient 0.09710144927536232
agent-1: 29.0
agent-2: 23.0
agent-3: 21.0
agent-4: 27.0
agent-5: 25.0
agent-6: 29.0
agent-7: 15.0
agent-8: 30.0
agent-9: 32.0
agent-10: 21.0
Sum Reward: 252.0
Avg Reward: 25.2
Min Reward: 15.0
Gini Coefficient 0.10952380952380952
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-52-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 394.0
  episode_reward_mean: 274.35
  episode_reward_min: 207.0
  episodes_this_iter: 2
  episodes_total: 499
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 3.76
    dispatch_time_ms: 7.026
    learner:
      cur_lr: 0.0010283320443704724
      grad_gnorm: 0.3099043667316437
      policy_entropy: 143.95668029785156
      policy_loss: -0.11921072006225586
      var_gnorm: 58.905479431152344
      vf_explained_var: -1.0
      vf_loss: 3.639079659478739e-05
    num_steps_sampled: 4990000
    num_steps_trained: 4990000
    wait_time_ms: 171.955
  iterations_since_restore: 499
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 8871.497579336166
  time_this_iter_s: 17.707748651504517
  time_total_s: 8871.497579336166
  timestamp: 1593831158
  timesteps_since_restore: 4990000
  timesteps_this_iter: 10000
  timesteps_total: 4990000
  training_iteration: 499
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=7727], 8871 s, 499 iter, 4990000 ts, 274 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_22-52-55
  done: true
  episode_len_mean: 1000.0
  episode_reward_max: 394.0
  episode_reward_mean: 274.35
  episode_reward_min: 207.0
  episodes_this_iter: 0
  episodes_total: 499
  experiment_id: 1e89802fba7a43529a9c84443ddcb888
  hostname: gpu001
  info:
    apply_time_ms: 2.753
    dispatch_time_ms: 8.173
    learner:
      cur_lr: 0.0010276660323143005
      grad_gnorm: 3.7495577335357666
      policy_entropy: 136.24525451660156
      policy_loss: -1.4832360744476318
      var_gnorm: 58.94041061401367
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.00812533125281334
    num_steps_sampled: 5000000
    num_steps_trained: 5000000
    wait_time_ms: 167.685
  iterations_since_restore: 500
  node_ip: 172.17.8.1
  num_metric_batches_dropped: 0
  pid: 7727
  policy_reward_mean: {}
  time_since_restore: 8888.549455404282
  time_this_iter_s: 17.051876068115234
  time_total_s: 8888.549455404282
  timestamp: 1593831175
  timesteps_since_restore: 5000000
  timesteps_this_iter: 10000
  timesteps_total: 5000000
  training_iteration: 500
  
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
TERMINATED trials:
 - A3C_harvest_env_0:	TERMINATED [pid=7727], 8888 s, 500 iter, 5000000 ts, 274 rew

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
TERMINATED trials:
 - A3C_harvest_env_0:	TERMINATED [pid=7727], 8888 s, 500 iter, 5000000 ts, 274 rew

WARNING: Logging before InitGoogleLogging() is written to STDERR
E0703 22:52:56.456223  7766 raylet_client.cc:345] IOError: [RayletClient] Connection closed unexpectedly. [RayletClient] Failed to push profile events.
WARNING: Logging before InitGoogleLogging() is written to STDERR
E0703 22:52:56.700927  7747 raylet_client.cc:345] IOError: [RayletClient] Connection closed unexpectedly. [RayletClient] Failed to push profile events.
Commencing experiment harvest_A3C
E0703 22:52:57.493304  7766 raylet_client.cc:345] IOError: [RayletClient] Connection closed unexpectedly. [RayletClient] Failed to push profile events.
E0703 22:52:57.758986  7747 raylet_client.cc:345] IOError: [RayletClient] Connection closed unexpectedly. [RayletClient] Failed to push profile events.
