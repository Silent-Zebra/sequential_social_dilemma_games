/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Process STDOUT and STDERR is being redirected to /tmp/ray/session_2020-07-05_20-06-09_2301/logs.
Waiting for redis server at 127.0.0.1:24331 to respond...
Waiting for redis server at 127.0.0.1:33985 to respond...
Warning: Capping object memory store to 20.0GB. To increase this further, specify `object_store_memory` when calling ray.init() or ray start.
Starting the Plasma object store with 20.0 GB memory using /dev/shm.

======================================================================
View the web UI at http://localhost:8888/notebooks/ray_ui.ipynb?token=9cfc22126781ba437c9d32a9428104648a5739ca2550b8c1
======================================================================

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.6/202.5 GB

Created LogSyncer for /h/zhaostep/ray_results/harvest_A3C/A3C_harvest_env_0_2020-07-05_20-06-10ajb67al2 -> 
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING

/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-05 20:06:23,129	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 0 on CPU (please ignore any CUDA init errors)
2020-07-05 20:06:23.129947: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-05 20:06:36,167	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 2 on CPU (please ignore any CUDA init errors)
2020-07-05 20:06:36.169697: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-05 20:06:36,364	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 1 on CPU (please ignore any CUDA init errors)
2020-07-05 20:06:36.366771: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-06-49
  done: false
  episode_len_mean: .nan
  episode_reward_max: .nan
  episode_reward_mean: .nan
  episode_reward_min: .nan
  episodes_this_iter: 0
  episodes_total: 0
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.709
    dispatch_time_ms: 7.26
    learner:
      cur_lr: 0.0013599999947473407
      grad_gnorm: 40.0
      policy_entropy: 72.75272369384766
      policy_loss: 54.08488845825195
      var_gnorm: 18.06621742248535
      vf_explained_var: -0.025965094566345215
      vf_loss: 73.30303955078125
    num_steps_sampled: 5000
    num_steps_trained: 5000
    wait_time_ms: 88.565
  iterations_since_restore: 1
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 24.77843141555786
  time_this_iter_s: 24.77843141555786
  time_total_s: 24.77843141555786
  timestamp: 1593994009
  timesteps_since_restore: 5000
  timesteps_this_iter: 5000
  timesteps_total: 5000
  training_iteration: 1
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 11.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 24 s, 1 iter, 5000 ts, nan rew

[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
agent-1: -10.0
agent-2: 61.0
agent-3: -121.0
agent-4: -27.0
agent-5: 72.0
Sum Reward: -25.0
Avg Reward: -5.0
Min Reward: -121.0
Gini Coefficient: -7.584
20:20 Ratio: -0.5950413223140496
Max-min Ratio: -0.5950413223140496
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-06-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -25.0
  episode_reward_mean: -25.0
  episode_reward_min: -25.0
  episodes_this_iter: 1
  episodes_total: 1
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.145
    dispatch_time_ms: 10.651
    learner:
      cur_lr: 0.0013596670469269156
      grad_gnorm: 40.0
      policy_entropy: 37.25352096557617
      policy_loss: -11.64310073852539
      var_gnorm: 18.097211837768555
      vf_explained_var: 0.2976415157318115
      vf_loss: 2.9292070865631104
    num_steps_sampled: 10000
    num_steps_trained: 10000
    wait_time_ms: 82.586
  iterations_since_restore: 2
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 34.651647090911865
  time_this_iter_s: 9.873215675354004
  time_total_s: 34.651647090911865
  timestamp: 1593994019
  timesteps_since_restore: 10000
  timesteps_this_iter: 5000
  timesteps_total: 10000
  training_iteration: 2
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 34 s, 2 iter, 10000 ts, -25 rew

[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
agent-1: -88.0
agent-2: -103.0
agent-3: -312.0
agent-4: 14.0
agent-5: 62.0
Sum Reward: -427.0
Avg Reward: -85.4
Min Reward: -312.0
Gini Coefficient: -0.810304449648712
20:20 Ratio: -0.1987179487179487
Max-min Ratio: -0.1987179487179487
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-07-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -25.0
  episode_reward_mean: -226.0
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 2
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.092
    dispatch_time_ms: 10.168
    learner:
      cur_lr: 0.0013593339826911688
      grad_gnorm: 40.000038146972656
      policy_entropy: 44.83904266357422
      policy_loss: -10.60175895690918
      var_gnorm: 18.298873901367188
      vf_explained_var: -0.13506031036376953
      vf_loss: 14.643844604492188
    num_steps_sampled: 15000
    num_steps_trained: 15000
    wait_time_ms: 90.154
  iterations_since_restore: 3
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 44.48845148086548
  time_this_iter_s: 9.836804389953613
  time_total_s: 44.48845148086548
  timestamp: 1593994028
  timesteps_since_restore: 15000
  timesteps_this_iter: 5000
  timesteps_total: 15000
  training_iteration: 3
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 11.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 44 s, 3 iter, 15000 ts, -226 rew

agent-1: 121.0
agent-2: 154.0
agent-3: 116.0
agent-4: 44.0
agent-5: 159.0
Sum Reward: 594.0
Avg Reward: 118.8
Min Reward: 44.0
Gini Coefficient: 0.18047138047138048
20:20 Ratio: 3.6136363636363638
Max-min Ratio: 3.6136363636363638
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-07-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 594.0
  episode_reward_mean: 47.333333333333336
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 3
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.967
    dispatch_time_ms: 10.388
    learner:
      cur_lr: 0.0013590010348707438
      grad_gnorm: 34.371665954589844
      policy_entropy: 53.44147491455078
      policy_loss: -8.999856948852539
      var_gnorm: 18.601545333862305
      vf_explained_var: 0.07481640577316284
      vf_loss: 16.327327728271484
    num_steps_sampled: 20000
    num_steps_trained: 20000
    wait_time_ms: 86.706
  iterations_since_restore: 4
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 55.15646433830261
  time_this_iter_s: 10.668012857437134
  time_total_s: 55.15646433830261
  timestamp: 1593994039
  timesteps_since_restore: 20000
  timesteps_this_iter: 5000
  timesteps_total: 20000
  training_iteration: 4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 55 s, 4 iter, 20000 ts, 47.3 rew

agent-1: 149.0
agent-2: 116.0
agent-3: 110.0
agent-4: 119.0
agent-5: 118.0
Sum Reward: 612.0
Avg Reward: 122.4
Min Reward: 110.0
Gini Coefficient: 0.052941176470588235
20:20 Ratio: 1.3545454545454545
Max-min Ratio: 1.3545454545454545
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-07-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 612.0
  episode_reward_mean: 188.5
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 4
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.178
    dispatch_time_ms: 13.931
    learner:
      cur_lr: 0.0013586679706349969
      grad_gnorm: 40.000003814697266
      policy_entropy: 53.66529083251953
      policy_loss: 31.803659439086914
      var_gnorm: 18.829849243164062
      vf_explained_var: -0.23651742935180664
      vf_loss: 21.664342880249023
    num_steps_sampled: 25000
    num_steps_trained: 25000
    wait_time_ms: 92.338
  iterations_since_restore: 5
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 65.82749652862549
  time_this_iter_s: 10.671032190322876
  time_total_s: 65.82749652862549
  timestamp: 1593994050
  timesteps_since_restore: 25000
  timesteps_this_iter: 5000
  timesteps_total: 25000
  training_iteration: 5
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 65 s, 5 iter, 25000 ts, 188 rew

agent-1: 161.0
agent-2: 155.0
agent-3: 167.0
agent-4: 135.0
agent-5: 98.0
Sum Reward: 716.0
Avg Reward: 143.2
Min Reward: 98.0
Gini Coefficient: 0.09162011173184358
20:20 Ratio: 1.7040816326530612
Max-min Ratio: 1.7040816326530612
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-07-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 716.0
  episode_reward_mean: 294.0
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 5
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.125
    dispatch_time_ms: 7.327
    learner:
      cur_lr: 0.0013583350228145719
      grad_gnorm: 40.000003814697266
      policy_entropy: 59.46525192260742
      policy_loss: -18.963150024414062
      var_gnorm: 19.196025848388672
      vf_explained_var: -0.27828383445739746
      vf_loss: 6.091054439544678
    num_steps_sampled: 30000
    num_steps_trained: 30000
    wait_time_ms: 109.137
  iterations_since_restore: 6
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 77.21932649612427
  time_this_iter_s: 11.39182996749878
  time_total_s: 77.21932649612427
  timestamp: 1593994061
  timesteps_since_restore: 30000
  timesteps_this_iter: 5000
  timesteps_total: 30000
  training_iteration: 6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 77 s, 6 iter, 30000 ts, 294 rew

agent-1: 101.0
agent-2: 99.0
agent-3: 101.0
agent-4: 119.0
agent-5: 142.0
Sum Reward: 562.0
Avg Reward: 112.4
Min Reward: 99.0
Gini Coefficient: 0.07402135231316725
20:20 Ratio: 1.4343434343434343
Max-min Ratio: 1.4343434343434343
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-07-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 716.0
  episode_reward_mean: 338.6666666666667
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 6
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.651
    dispatch_time_ms: 7.328
    learner:
      cur_lr: 0.001358001958578825
      grad_gnorm: 39.9999885559082
      policy_entropy: 49.48094177246094
      policy_loss: -14.052387237548828
      var_gnorm: 19.586801528930664
      vf_explained_var: 0.6411217451095581
      vf_loss: 17.23509407043457
    num_steps_sampled: 35000
    num_steps_trained: 35000
    wait_time_ms: 107.122
  iterations_since_restore: 7
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 88.0243227481842
  time_this_iter_s: 10.804996252059937
  time_total_s: 88.0243227481842
  timestamp: 1593994072
  timesteps_since_restore: 35000
  timesteps_this_iter: 5000
  timesteps_total: 35000
  training_iteration: 7
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 11.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 88 s, 7 iter, 35000 ts, 339 rew

agent-1: 81.0
agent-2: 109.0
agent-3: 102.0
agent-4: 62.0
agent-5: 66.0
Sum Reward: 420.0
Avg Reward: 84.0
Min Reward: 62.0
Gini Coefficient: 0.12380952380952381
20:20 Ratio: 1.7580645161290323
Max-min Ratio: 1.7580645161290323
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-08-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 716.0
  episode_reward_mean: 350.2857142857143
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 7
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.913
    dispatch_time_ms: 9.189
    learner:
      cur_lr: 0.0013576690107584
      grad_gnorm: 40.000003814697266
      policy_entropy: 75.03134155273438
      policy_loss: 28.707340240478516
      var_gnorm: 20.138078689575195
      vf_explained_var: 0.6291269063949585
      vf_loss: 45.34983825683594
    num_steps_sampled: 40000
    num_steps_trained: 40000
    wait_time_ms: 96.42
  iterations_since_restore: 8
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 99.8795735836029
  time_this_iter_s: 11.855250835418701
  time_total_s: 99.8795735836029
  timestamp: 1593994084
  timesteps_since_restore: 40000
  timesteps_this_iter: 5000
  timesteps_total: 40000
  training_iteration: 8
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 11.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 99 s, 8 iter, 40000 ts, 350 rew

agent-1: 71.0
agent-2: 100.0
agent-3: 119.0
agent-4: 102.0
agent-5: 80.0
Sum Reward: 472.0
Avg Reward: 94.4
Min Reward: 71.0
Gini Coefficient: 0.1
20:20 Ratio: 1.676056338028169
Max-min Ratio: 1.676056338028169
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-08-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 716.0
  episode_reward_mean: 365.5
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 8
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.655
    dispatch_time_ms: 7.248
    learner:
      cur_lr: 0.001357335946522653
      grad_gnorm: 39.9999885559082
      policy_entropy: 53.0302734375
      policy_loss: 13.292367935180664
      var_gnorm: 20.333356857299805
      vf_explained_var: 0.9028303027153015
      vf_loss: 20.431110382080078
    num_steps_sampled: 45000
    num_steps_trained: 45000
    wait_time_ms: 110.555
  iterations_since_restore: 9
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 110.41705775260925
  time_this_iter_s: 10.537484169006348
  time_total_s: 110.41705775260925
  timestamp: 1593994095
  timesteps_since_restore: 45000
  timesteps_this_iter: 5000
  timesteps_total: 45000
  training_iteration: 9
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 11.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 110 s, 9 iter, 45000 ts, 366 rew

agent-1: 109.0
agent-2: 66.0
agent-3: 75.0
agent-4: 93.0
agent-5: 92.0
Sum Reward: 435.0
Avg Reward: 87.0
Min Reward: 66.0
Gini Coefficient: 0.09563218390804598
20:20 Ratio: 1.6515151515151516
Max-min Ratio: 1.6515151515151516
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-08-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 716.0
  episode_reward_mean: 373.22222222222223
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 9
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.573
    dispatch_time_ms: 7.337
    learner:
      cur_lr: 0.001357002998702228
      grad_gnorm: 19.796035766601562
      policy_entropy: 69.44432067871094
      policy_loss: -6.911036014556885
      var_gnorm: 21.232736587524414
      vf_explained_var: 0.718742847442627
      vf_loss: 0.2633218765258789
    num_steps_sampled: 50000
    num_steps_trained: 50000
    wait_time_ms: 107.579
  iterations_since_restore: 10
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 122.23939085006714
  time_this_iter_s: 11.822333097457886
  time_total_s: 122.23939085006714
  timestamp: 1593994107
  timesteps_since_restore: 50000
  timesteps_this_iter: 5000
  timesteps_total: 50000
  training_iteration: 10
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 11.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 122 s, 10 iter, 50000 ts, 373 rew

agent-1: 113.0
agent-2: 76.0
agent-3: 89.0
agent-4: 63.0
agent-5: 71.0
Sum Reward: 412.0
Avg Reward: 82.4
Min Reward: 63.0
Gini Coefficient: 0.1145631067961165
20:20 Ratio: 1.7936507936507937
Max-min Ratio: 1.7936507936507937
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-08-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 716.0
  episode_reward_mean: 377.1
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 10
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.61
    dispatch_time_ms: 6.701
    learner:
      cur_lr: 0.001356670050881803
      grad_gnorm: 40.00000762939453
      policy_entropy: 64.12521362304688
      policy_loss: 9.230653762817383
      var_gnorm: 21.52408218383789
      vf_explained_var: 0.9481542706489563
      vf_loss: 19.74444007873535
    num_steps_sampled: 55000
    num_steps_trained: 55000
    wait_time_ms: 111.323
  iterations_since_restore: 11
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 133.16122603416443
  time_this_iter_s: 10.92183518409729
  time_total_s: 133.16122603416443
  timestamp: 1593994117
  timesteps_since_restore: 55000
  timesteps_this_iter: 5000
  timesteps_total: 55000
  training_iteration: 11
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 11.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 133 s, 11 iter, 55000 ts, 377 rew

agent-1: 106.0
agent-2: 116.0
agent-3: 93.0
agent-4: 111.0
agent-5: 123.0
Sum Reward: 549.0
Avg Reward: 109.8
Min Reward: 93.0
Gini Coefficient: 0.051001821493624776
20:20 Ratio: 1.3225806451612903
Max-min Ratio: 1.3225806451612903
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-08-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 716.0
  episode_reward_mean: 392.72727272727275
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 11
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.049
    dispatch_time_ms: 6.494
    learner:
      cur_lr: 0.0013563369866460562
      grad_gnorm: 40.0
      policy_entropy: 53.284446716308594
      policy_loss: 14.294748306274414
      var_gnorm: 21.870296478271484
      vf_explained_var: 0.7653378248214722
      vf_loss: 7.620222568511963
    num_steps_sampled: 60000
    num_steps_trained: 60000
    wait_time_ms: 114.633
  iterations_since_restore: 12
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 145.33786416053772
  time_this_iter_s: 12.176638126373291
  time_total_s: 145.33786416053772
  timestamp: 1593994130
  timesteps_since_restore: 60000
  timesteps_this_iter: 5000
  timesteps_total: 60000
  training_iteration: 12
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 12.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 145 s, 12 iter, 60000 ts, 393 rew

agent-1: 70.0
agent-2: 68.0
agent-3: 71.0
agent-4: 68.0
agent-5: 87.0
Sum Reward: 364.0
Avg Reward: 72.8
Min Reward: 68.0
Gini Coefficient: 0.045054945054945054
20:20 Ratio: 1.2794117647058822
Max-min Ratio: 1.2794117647058822
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-09-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 716.0
  episode_reward_mean: 390.3333333333333
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 12
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.728
    dispatch_time_ms: 11.074
    learner:
      cur_lr: 0.0013560040388256311
      grad_gnorm: 39.9999885559082
      policy_entropy: 51.214805603027344
      policy_loss: 38.163516998291016
      var_gnorm: 22.122365951538086
      vf_explained_var: 0.4012858271598816
      vf_loss: 34.38028335571289
    num_steps_sampled: 65000
    num_steps_trained: 65000
    wait_time_ms: 102.582
  iterations_since_restore: 13
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 156.12774300575256
  time_this_iter_s: 10.789878845214844
  time_total_s: 156.12774300575256
  timestamp: 1593994141
  timesteps_since_restore: 65000
  timesteps_this_iter: 5000
  timesteps_total: 65000
  training_iteration: 13
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 12.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 156 s, 13 iter, 65000 ts, 390 rew

agent-1: 99.0
agent-2: 97.0
agent-3: 89.0
agent-4: 119.0
agent-5: 99.0
Sum Reward: 503.0
Avg Reward: 100.6
Min Reward: 89.0
Gini Coefficient: 0.04930417495029821
20:20 Ratio: 1.3370786516853932
Max-min Ratio: 1.3370786516853932
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-09-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 716.0
  episode_reward_mean: 399.0
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 13
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.77
    dispatch_time_ms: 8.97
    learner:
      cur_lr: 0.0013556709745898843
      grad_gnorm: 39.99999237060547
      policy_entropy: 62.051849365234375
      policy_loss: 14.49306583404541
      var_gnorm: 22.429475784301758
      vf_explained_var: 0.7094169855117798
      vf_loss: 64.38819122314453
    num_steps_sampled: 70000
    num_steps_trained: 70000
    wait_time_ms: 106.0
  iterations_since_restore: 14
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 167.9913318157196
  time_this_iter_s: 11.863588809967041
  time_total_s: 167.9913318157196
  timestamp: 1593994152
  timesteps_since_restore: 70000
  timesteps_this_iter: 5000
  timesteps_total: 70000
  training_iteration: 14
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 12.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 167 s, 14 iter, 70000 ts, 399 rew

agent-1: 103.0
agent-2: 114.0
agent-3: 93.0
agent-4: 99.0
agent-5: 148.0
Sum Reward: 557.0
Avg Reward: 111.4
Min Reward: 93.0
Gini Coefficient: 0.08976660682226212
20:20 Ratio: 1.5913978494623655
Max-min Ratio: 1.5913978494623655
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-09-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 716.0
  episode_reward_mean: 410.2857142857143
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 14
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.553
    dispatch_time_ms: 7.241
    learner:
      cur_lr: 0.0013553380267694592
      grad_gnorm: 40.000022888183594
      policy_entropy: 44.259647369384766
      policy_loss: -14.256389617919922
      var_gnorm: 22.572818756103516
      vf_explained_var: 0.7427524328231812
      vf_loss: 104.43804168701172
    num_steps_sampled: 75000
    num_steps_trained: 75000
    wait_time_ms: 102.401
  iterations_since_restore: 15
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 178.59081649780273
  time_this_iter_s: 10.59948468208313
  time_total_s: 178.59081649780273
  timestamp: 1593994163
  timesteps_since_restore: 75000
  timesteps_this_iter: 5000
  timesteps_total: 75000
  training_iteration: 15
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 12.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 178 s, 15 iter, 75000 ts, 410 rew

agent-1: 120.0
agent-2: 128.0
agent-3: 114.0
agent-4: 137.0
agent-5: 113.0
Sum Reward: 612.0
Avg Reward: 122.4
Min Reward: 113.0
Gini Coefficient: 0.040522875816993466
20:20 Ratio: 1.2123893805309736
Max-min Ratio: 1.2123893805309736
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-09-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 716.0
  episode_reward_mean: 423.73333333333335
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 15
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.499
    dispatch_time_ms: 7.797
    learner:
      cur_lr: 0.0013550049625337124
      grad_gnorm: 15.567442893981934
      policy_entropy: 62.06172561645508
      policy_loss: -5.638659477233887
      var_gnorm: 22.931015014648438
      vf_explained_var: 0.8155950307846069
      vf_loss: 0.3594147264957428
    num_steps_sampled: 80000
    num_steps_trained: 80000
    wait_time_ms: 89.948
  iterations_since_restore: 16
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 190.4121539592743
  time_this_iter_s: 11.821337461471558
  time_total_s: 190.4121539592743
  timestamp: 1593994175
  timesteps_since_restore: 80000
  timesteps_this_iter: 5000
  timesteps_total: 80000
  training_iteration: 16
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 12.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 190 s, 16 iter, 80000 ts, 424 rew

agent-1: 99.0
agent-2: 79.0
agent-3: 82.0
agent-4: 111.0
agent-5: 101.0
Sum Reward: 472.0
Avg Reward: 94.4
Min Reward: 79.0
Gini Coefficient: 0.07033898305084746
20:20 Ratio: 1.4050632911392404
Max-min Ratio: 1.4050632911392404
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-09-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 716.0
  episode_reward_mean: 426.75
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 16
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.166
    dispatch_time_ms: 9.528
    learner:
      cur_lr: 0.0013546720147132874
      grad_gnorm: 39.99999237060547
      policy_entropy: 57.40716552734375
      policy_loss: 14.639458656311035
      var_gnorm: 23.27595329284668
      vf_explained_var: 0.7394437789916992
      vf_loss: 53.80168151855469
    num_steps_sampled: 85000
    num_steps_trained: 85000
    wait_time_ms: 110.987
  iterations_since_restore: 17
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 201.5508770942688
  time_this_iter_s: 11.138723134994507
  time_total_s: 201.5508770942688
  timestamp: 1593994186
  timesteps_since_restore: 85000
  timesteps_this_iter: 5000
  timesteps_total: 85000
  training_iteration: 17
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 12.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 201 s, 17 iter, 85000 ts, 427 rew

agent-1: 71.0
agent-2: 106.0
agent-3: 90.0
agent-4: 80.0
agent-5: 86.0
Sum Reward: 433.0
Avg Reward: 86.6
Min Reward: 71.0
Gini Coefficient: 0.07390300230946882
20:20 Ratio: 1.4929577464788732
Max-min Ratio: 1.4929577464788732
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-09-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 716.0
  episode_reward_mean: 427.11764705882354
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 17
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.058
    dispatch_time_ms: 7.12
    learner:
      cur_lr: 0.0013543389504775405
      grad_gnorm: 39.999996185302734
      policy_entropy: 44.71648406982422
      policy_loss: 0.7749245166778564
      var_gnorm: 23.56056785583496
      vf_explained_var: 0.37675589323043823
      vf_loss: 17.345922470092773
    num_steps_sampled: 90000
    num_steps_trained: 90000
    wait_time_ms: 95.751
  iterations_since_restore: 18
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 213.66516995429993
  time_this_iter_s: 12.114292860031128
  time_total_s: 213.66516995429993
  timestamp: 1593994198
  timesteps_since_restore: 90000
  timesteps_this_iter: 5000
  timesteps_total: 90000
  training_iteration: 18
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 213 s, 18 iter, 90000 ts, 427 rew

agent-1: 107.0
agent-2: 88.0
agent-3: 76.0
agent-4: 64.0
agent-5: 97.0
Sum Reward: 432.0
Avg Reward: 86.4
Min Reward: 64.0
Gini Coefficient: 0.09907407407407408
20:20 Ratio: 1.671875
Max-min Ratio: 1.671875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-10-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 716.0
  episode_reward_mean: 427.3888888888889
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 18
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.705
    dispatch_time_ms: 8.642
    learner:
      cur_lr: 0.0013540060026571155
      grad_gnorm: 39.99998092651367
      policy_entropy: 45.50103759765625
      policy_loss: -0.6627740859985352
      var_gnorm: 23.692852020263672
      vf_explained_var: 0.7322647571563721
      vf_loss: 63.40822219848633
    num_steps_sampled: 95000
    num_steps_trained: 95000
    wait_time_ms: 104.172
  iterations_since_restore: 19
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 224.73222398757935
  time_this_iter_s: 11.067054033279419
  time_total_s: 224.73222398757935
  timestamp: 1593994209
  timesteps_since_restore: 95000
  timesteps_this_iter: 5000
  timesteps_total: 95000
  training_iteration: 19
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 224 s, 19 iter, 95000 ts, 427 rew

agent-1: 71.0
agent-2: 73.0
agent-3: 70.0
agent-4: 83.0
agent-5: 97.0
Sum Reward: 394.0
Avg Reward: 78.8
Min Reward: 70.0
Gini Coefficient: 0.06700507614213198
20:20 Ratio: 1.3857142857142857
Max-min Ratio: 1.3857142857142857
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-10-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 716.0
  episode_reward_mean: 425.63157894736844
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 19
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.36
    dispatch_time_ms: 8.489
    learner:
      cur_lr: 0.0013536730548366904
      grad_gnorm: 5.181419372558594
      policy_entropy: 37.07215118408203
      policy_loss: -1.510676383972168
      var_gnorm: 23.919464111328125
      vf_explained_var: -1.0
      vf_loss: 0.14422661066055298
    num_steps_sampled: 100000
    num_steps_trained: 100000
    wait_time_ms: 92.265
  iterations_since_restore: 20
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 236.68600177764893
  time_this_iter_s: 11.95377779006958
  time_total_s: 236.68600177764893
  timestamp: 1593994221
  timesteps_since_restore: 100000
  timesteps_this_iter: 5000
  timesteps_total: 100000
  training_iteration: 20
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 236 s, 20 iter, 100000 ts, 426 rew

agent-1: 94.0
agent-2: 148.0
agent-3: 99.0
agent-4: 114.0
agent-5: 111.0
Sum Reward: 566.0
Avg Reward: 113.2
Min Reward: 94.0
Gini Coefficient: 0.08692579505300353
20:20 Ratio: 1.574468085106383
Max-min Ratio: 1.574468085106383
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-10-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 716.0
  episode_reward_mean: 432.65
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 20
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.131
    dispatch_time_ms: 10.565
    learner:
      cur_lr: 0.0013533399906009436
      grad_gnorm: 40.00000762939453
      policy_entropy: 39.53555679321289
      policy_loss: 17.152339935302734
      var_gnorm: 24.02071189880371
      vf_explained_var: 0.8810914158821106
      vf_loss: 60.54178237915039
    num_steps_sampled: 105000
    num_steps_trained: 105000
    wait_time_ms: 106.502
  iterations_since_restore: 21
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 247.7432577610016
  time_this_iter_s: 11.057255983352661
  time_total_s: 247.7432577610016
  timestamp: 1593994232
  timesteps_since_restore: 105000
  timesteps_this_iter: 5000
  timesteps_total: 105000
  training_iteration: 21
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 247 s, 21 iter, 105000 ts, 433 rew

agent-1: 94.0
agent-2: 99.0
agent-3: 90.0
agent-4: 93.0
agent-5: 90.0
Sum Reward: 466.0
Avg Reward: 93.2
Min Reward: 90.0
Gini Coefficient: 0.01888412017167382
20:20 Ratio: 1.1
Max-min Ratio: 1.1
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-10-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 716.0
  episode_reward_mean: 434.23809523809524
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 21
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.251
    dispatch_time_ms: 7.748
    learner:
      cur_lr: 0.0013530070427805185
      grad_gnorm: 40.00000762939453
      policy_entropy: 37.56415557861328
      policy_loss: 34.24728775024414
      var_gnorm: 24.367294311523438
      vf_explained_var: 0.061318278312683105
      vf_loss: 22.59344482421875
    num_steps_sampled: 110000
    num_steps_trained: 110000
    wait_time_ms: 99.106
  iterations_since_restore: 22
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 260.02863907814026
  time_this_iter_s: 12.285381317138672
  time_total_s: 260.02863907814026
  timestamp: 1593994245
  timesteps_since_restore: 110000
  timesteps_this_iter: 5000
  timesteps_total: 110000
  training_iteration: 22
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 260 s, 22 iter, 110000 ts, 434 rew

agent-1: 93.0
agent-2: 84.0
agent-3: 93.0
agent-4: 83.0
agent-5: 78.0
Sum Reward: 431.0
Avg Reward: 86.2
Min Reward: 78.0
Gini Coefficient: 0.037122969837587005
20:20 Ratio: 1.1923076923076923
Max-min Ratio: 1.1923076923076923
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-10-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 716.0
  episode_reward_mean: 434.09090909090907
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 22
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.974
    dispatch_time_ms: 7.906
    learner:
      cur_lr: 0.0013526739785447717
      grad_gnorm: 39.99998474121094
      policy_entropy: 37.97915267944336
      policy_loss: -2.6113877296447754
      var_gnorm: 24.521190643310547
      vf_explained_var: 0.6074897050857544
      vf_loss: 21.9107723236084
    num_steps_sampled: 115000
    num_steps_trained: 115000
    wait_time_ms: 109.629
  iterations_since_restore: 23
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 271.13161635398865
  time_this_iter_s: 11.102977275848389
  time_total_s: 271.13161635398865
  timestamp: 1593994256
  timesteps_since_restore: 115000
  timesteps_this_iter: 5000
  timesteps_total: 115000
  training_iteration: 23
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 271 s, 23 iter, 115000 ts, 434 rew

agent-1: 106.0
agent-2: 104.0
agent-3: 98.0
agent-4: 105.0
agent-5: 101.0
Sum Reward: 514.0
Avg Reward: 102.8
Min Reward: 98.0
Gini Coefficient: 0.01556420233463035
20:20 Ratio: 1.0816326530612246
Max-min Ratio: 1.0816326530612246
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-11-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 716.0
  episode_reward_mean: 437.5652173913044
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 23
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.417
    dispatch_time_ms: 8.092
    learner:
      cur_lr: 0.0013523410307243466
      grad_gnorm: 25.360700607299805
      policy_entropy: 57.09442901611328
      policy_loss: -7.36752462387085
      var_gnorm: 24.731260299682617
      vf_explained_var: 0.352852463722229
      vf_loss: 2.4984755516052246
    num_steps_sampled: 120000
    num_steps_trained: 120000
    wait_time_ms: 104.286
  iterations_since_restore: 24
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 283.4802939891815
  time_this_iter_s: 12.348677635192871
  time_total_s: 283.4802939891815
  timestamp: 1593994268
  timesteps_since_restore: 120000
  timesteps_this_iter: 5000
  timesteps_total: 120000
  training_iteration: 24
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 283 s, 24 iter, 120000 ts, 438 rew

agent-1: 42.0
agent-2: 148.0
agent-3: 89.0
agent-4: 115.0
agent-5: 99.0
Sum Reward: 493.0
Avg Reward: 98.6
Min Reward: 42.0
Gini Coefficient: 0.19310344827586207
20:20 Ratio: 3.5238095238095237
Max-min Ratio: 3.5238095238095237
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-11-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 716.0
  episode_reward_mean: 439.875
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 24
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.64
    dispatch_time_ms: 6.911
    learner:
      cur_lr: 0.0013520079664885998
      grad_gnorm: 40.0
      policy_entropy: 29.189044952392578
      policy_loss: 11.047395706176758
      var_gnorm: 24.774049758911133
      vf_explained_var: 0.6333297491073608
      vf_loss: 21.065256118774414
    num_steps_sampled: 125000
    num_steps_trained: 125000
    wait_time_ms: 109.522
  iterations_since_restore: 25
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 294.52466201782227
  time_this_iter_s: 11.044368028640747
  time_total_s: 294.52466201782227
  timestamp: 1593994279
  timesteps_since_restore: 125000
  timesteps_this_iter: 5000
  timesteps_total: 125000
  training_iteration: 25
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 294 s, 25 iter, 125000 ts, 440 rew

agent-1: 107.0
agent-2: 151.0
agent-3: 107.0
agent-4: 132.0
agent-5: 150.0
Sum Reward: 647.0
Avg Reward: 129.4
Min Reward: 107.0
Gini Coefficient: 0.08098918083462132
20:20 Ratio: 1.411214953271028
Max-min Ratio: 1.411214953271028
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-11-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 716.0
  episode_reward_mean: 448.16
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 25
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.107
    dispatch_time_ms: 6.436
    learner:
      cur_lr: 0.0013516750186681747
      grad_gnorm: 40.000003814697266
      policy_entropy: 30.8664608001709
      policy_loss: 1.5636993646621704
      var_gnorm: 24.913103103637695
      vf_explained_var: 0.808677077293396
      vf_loss: 45.625770568847656
    num_steps_sampled: 130000
    num_steps_trained: 130000
    wait_time_ms: 96.841
  iterations_since_restore: 26
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 305.88571786880493
  time_this_iter_s: 11.361055850982666
  time_total_s: 305.88571786880493
  timestamp: 1593994291
  timesteps_since_restore: 130000
  timesteps_this_iter: 5000
  timesteps_total: 130000
  training_iteration: 26
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 305 s, 26 iter, 130000 ts, 448 rew

agent-1: 120.0
agent-2: 118.0
agent-3: 99.0
agent-4: 172.0
agent-5: 101.0
Sum Reward: 610.0
Avg Reward: 122.0
Min Reward: 99.0
Gini Coefficient: 0.10819672131147541
20:20 Ratio: 1.7373737373737375
Max-min Ratio: 1.7373737373737375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-11-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 716.0
  episode_reward_mean: 454.38461538461536
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 26
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.252
    dispatch_time_ms: 13.076
    learner:
      cur_lr: 0.0013513419544324279
      grad_gnorm: 40.0
      policy_entropy: 48.83119201660156
      policy_loss: -23.220888137817383
      var_gnorm: 25.10811424255371
      vf_explained_var: 0.1409996747970581
      vf_loss: 24.680130004882812
    num_steps_sampled: 135000
    num_steps_trained: 135000
    wait_time_ms: 108.933
  iterations_since_restore: 27
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 317.29146432876587
  time_this_iter_s: 11.405746459960938
  time_total_s: 317.29146432876587
  timestamp: 1593994302
  timesteps_since_restore: 135000
  timesteps_this_iter: 5000
  timesteps_total: 135000
  training_iteration: 27
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 317 s, 27 iter, 135000 ts, 454 rew

agent-1: 99.0
agent-2: 76.0
agent-3: 124.0
agent-4: 65.0
agent-5: 136.0
Sum Reward: 500.0
Avg Reward: 100.0
Min Reward: 65.0
Gini Coefficient: 0.152
20:20 Ratio: 2.0923076923076924
Max-min Ratio: 2.0923076923076924
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-11-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 716.0
  episode_reward_mean: 456.0740740740741
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 27
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.829
    dispatch_time_ms: 7.381
    learner:
      cur_lr: 0.0013510090066120028
      grad_gnorm: 39.999996185302734
      policy_entropy: 36.36876678466797
      policy_loss: -8.172001838684082
      var_gnorm: 25.217527389526367
      vf_explained_var: 0.4677703380584717
      vf_loss: 105.99803161621094
    num_steps_sampled: 140000
    num_steps_trained: 140000
    wait_time_ms: 100.414
  iterations_since_restore: 28
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 329.4076828956604
  time_this_iter_s: 12.116218566894531
  time_total_s: 329.4076828956604
  timestamp: 1593994314
  timesteps_since_restore: 140000
  timesteps_this_iter: 5000
  timesteps_total: 140000
  training_iteration: 28
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 329 s, 28 iter, 140000 ts, 456 rew

agent-1: 69.0
agent-2: 86.0
agent-3: 100.0
agent-4: 96.0
agent-5: 82.0
Sum Reward: 433.0
Avg Reward: 86.6
Min Reward: 69.0
Gini Coefficient: 0.07020785219399538
20:20 Ratio: 1.4492753623188406
Max-min Ratio: 1.4492753623188406
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-12-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 716.0
  episode_reward_mean: 455.25
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 28
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.769
    dispatch_time_ms: 7.238
    learner:
      cur_lr: 0.001350675942376256
      grad_gnorm: 39.99999237060547
      policy_entropy: 39.38019561767578
      policy_loss: -31.26348114013672
      var_gnorm: 25.342430114746094
      vf_explained_var: 0.45962095260620117
      vf_loss: 74.17340850830078
    num_steps_sampled: 145000
    num_steps_trained: 145000
    wait_time_ms: 113.049
  iterations_since_restore: 29
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 340.56340861320496
  time_this_iter_s: 11.155725717544556
  time_total_s: 340.56340861320496
  timestamp: 1593994326
  timesteps_since_restore: 145000
  timesteps_this_iter: 5000
  timesteps_total: 145000
  training_iteration: 29
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 340 s, 29 iter, 145000 ts, 455 rew

agent-1: 88.0
agent-2: 97.0
agent-3: 91.0
agent-4: 90.0
agent-5: 110.0
Sum Reward: 476.0
Avg Reward: 95.2
Min Reward: 88.0
Gini Coefficient: 0.04285714285714286
20:20 Ratio: 1.25
Max-min Ratio: 1.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-12-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 716.0
  episode_reward_mean: 455.9655172413793
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 29
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.64
    dispatch_time_ms: 7.903
    learner:
      cur_lr: 0.001350342994555831
      grad_gnorm: 40.000003814697266
      policy_entropy: 32.14813995361328
      policy_loss: 28.072933197021484
      var_gnorm: 25.45809555053711
      vf_explained_var: 0.9160089492797852
      vf_loss: 86.99537658691406
    num_steps_sampled: 150000
    num_steps_trained: 150000
    wait_time_ms: 89.793
  iterations_since_restore: 30
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 352.2894697189331
  time_this_iter_s: 11.72606110572815
  time_total_s: 352.2894697189331
  timestamp: 1593994337
  timesteps_since_restore: 150000
  timesteps_this_iter: 5000
  timesteps_total: 150000
  training_iteration: 30
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 352 s, 30 iter, 150000 ts, 456 rew

agent-1: 161.0
agent-2: 84.0
agent-3: 98.0
agent-4: 88.0
agent-5: 109.0
Sum Reward: 540.0
Avg Reward: 108.0
Min Reward: 84.0
Gini Coefficient: 0.12962962962962962
20:20 Ratio: 1.9166666666666667
Max-min Ratio: 1.9166666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-12-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 716.0
  episode_reward_mean: 458.76666666666665
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 30
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.475
    dispatch_time_ms: 11.082
    learner:
      cur_lr: 0.001350010046735406
      grad_gnorm: 40.000003814697266
      policy_entropy: 22.09235382080078
      policy_loss: 6.72322940826416
      var_gnorm: 25.584407806396484
      vf_explained_var: 0.988875150680542
      vf_loss: 20.895618438720703
    num_steps_sampled: 155000
    num_steps_trained: 155000
    wait_time_ms: 100.465
  iterations_since_restore: 31
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 363.6136338710785
  time_this_iter_s: 11.324164152145386
  time_total_s: 363.6136338710785
  timestamp: 1593994349
  timesteps_since_restore: 155000
  timesteps_this_iter: 5000
  timesteps_total: 155000
  training_iteration: 31
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 363 s, 31 iter, 155000 ts, 459 rew

agent-1: 120.0
agent-2: 181.0
agent-3: 49.0
agent-4: 68.0
agent-5: 59.0
Sum Reward: 477.0
Avg Reward: 95.4
Min Reward: 49.0
Gini Coefficient: 0.27253668763102723
20:20 Ratio: 3.693877551020408
Max-min Ratio: 3.693877551020408
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-12-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 716.0
  episode_reward_mean: 459.35483870967744
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 31
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.31
    dispatch_time_ms: 10.688
    learner:
      cur_lr: 0.001349676982499659
      grad_gnorm: 20.650775909423828
      policy_entropy: 40.96968460083008
      policy_loss: -5.072874546051025
      var_gnorm: 25.728899002075195
      vf_explained_var: 0.9769502282142639
      vf_loss: 0.553871214389801
    num_steps_sampled: 160000
    num_steps_trained: 160000
    wait_time_ms: 96.092
  iterations_since_restore: 32
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 375.56484270095825
  time_this_iter_s: 11.95120882987976
  time_total_s: 375.56484270095825
  timestamp: 1593994361
  timesteps_since_restore: 160000
  timesteps_this_iter: 5000
  timesteps_total: 160000
  training_iteration: 32
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 375 s, 32 iter, 160000 ts, 459 rew

agent-1: 88.0
agent-2: 112.0
agent-3: 80.0
agent-4: 97.0
agent-5: 81.0
Sum Reward: 458.0
Avg Reward: 91.6
Min Reward: 80.0
Gini Coefficient: 0.06986899563318777
20:20 Ratio: 1.4
Max-min Ratio: 1.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-12-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 716.0
  episode_reward_mean: 459.3125
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 32
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.614
    dispatch_time_ms: 11.137
    learner:
      cur_lr: 0.001349344034679234
      grad_gnorm: 40.0
      policy_entropy: 31.66054916381836
      policy_loss: -8.016129493713379
      var_gnorm: 25.805482864379883
      vf_explained_var: 0.9780188202857971
      vf_loss: 22.509681701660156
    num_steps_sampled: 165000
    num_steps_trained: 165000
    wait_time_ms: 104.687
  iterations_since_restore: 33
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 386.7182958126068
  time_this_iter_s: 11.15345311164856
  time_total_s: 386.7182958126068
  timestamp: 1593994372
  timesteps_since_restore: 165000
  timesteps_this_iter: 5000
  timesteps_total: 165000
  training_iteration: 33
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 386 s, 33 iter, 165000 ts, 459 rew

agent-1: 119.0
agent-2: 116.0
agent-3: 94.0
agent-4: 99.0
agent-5: 113.0
Sum Reward: 541.0
Avg Reward: 108.2
Min Reward: 94.0
Gini Coefficient: 0.04953789279112754
20:20 Ratio: 1.2659574468085106
Max-min Ratio: 1.2659574468085106
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-13-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 716.0
  episode_reward_mean: 461.7878787878788
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 33
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.163
    dispatch_time_ms: 7.449
    learner:
      cur_lr: 0.0013490109704434872
      grad_gnorm: 39.999996185302734
      policy_entropy: 24.70543670654297
      policy_loss: 22.65234375
      var_gnorm: 25.986385345458984
      vf_explained_var: -1.0
      vf_loss: 42.85548400878906
    num_steps_sampled: 170000
    num_steps_trained: 170000
    wait_time_ms: 102.555
  iterations_since_restore: 34
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 398.4852147102356
  time_this_iter_s: 11.766918897628784
  time_total_s: 398.4852147102356
  timestamp: 1593994384
  timesteps_since_restore: 170000
  timesteps_this_iter: 5000
  timesteps_total: 170000
  training_iteration: 34
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 398 s, 34 iter, 170000 ts, 462 rew

agent-1: 98.0
agent-2: 107.0
agent-3: 124.0
agent-4: 128.0
agent-5: 102.0
Sum Reward: 559.0
Avg Reward: 111.8
Min Reward: 98.0
Gini Coefficient: 0.05867620751341682
20:20 Ratio: 1.3061224489795917
Max-min Ratio: 1.3061224489795917
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-13-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 716.0
  episode_reward_mean: 464.6470588235294
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 34
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.609
    dispatch_time_ms: 6.62
    learner:
      cur_lr: 0.0013486780226230621
      grad_gnorm: 40.00001525878906
      policy_entropy: 24.003541946411133
      policy_loss: -8.836620330810547
      var_gnorm: 26.081186294555664
      vf_explained_var: 0.7847187519073486
      vf_loss: 33.711212158203125
    num_steps_sampled: 175000
    num_steps_trained: 175000
    wait_time_ms: 105.901
  iterations_since_restore: 35
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 409.49707436561584
  time_this_iter_s: 11.011859655380249
  time_total_s: 409.49707436561584
  timestamp: 1593994395
  timesteps_since_restore: 175000
  timesteps_this_iter: 5000
  timesteps_total: 175000
  training_iteration: 35
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 409 s, 35 iter, 175000 ts, 465 rew

agent-1: 103.0
agent-2: 103.0
agent-3: 115.0
agent-4: 104.0
agent-5: 123.0
Sum Reward: 548.0
Avg Reward: 109.6
Min Reward: 103.0
Gini Coefficient: 0.03795620437956204
20:20 Ratio: 1.1941747572815533
Max-min Ratio: 1.1941747572815533
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-13-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 716.0
  episode_reward_mean: 467.0285714285714
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 35
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.263
    dispatch_time_ms: 7.897
    learner:
      cur_lr: 0.0013483449583873153
      grad_gnorm: 40.00000762939453
      policy_entropy: 25.277395248413086
      policy_loss: -9.265360832214355
      var_gnorm: 26.2442569732666
      vf_explained_var: 0.34878116846084595
      vf_loss: 19.292827606201172
    num_steps_sampled: 180000
    num_steps_trained: 180000
    wait_time_ms: 96.746
  iterations_since_restore: 36
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 421.4563705921173
  time_this_iter_s: 11.959296226501465
  time_total_s: 421.4563705921173
  timestamp: 1593994407
  timesteps_since_restore: 180000
  timesteps_this_iter: 5000
  timesteps_total: 180000
  training_iteration: 36
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 421 s, 36 iter, 180000 ts, 467 rew

agent-1: 83.0
agent-2: 110.0
agent-3: 97.0
agent-4: 98.0
agent-5: 108.0
Sum Reward: 496.0
Avg Reward: 99.2
Min Reward: 83.0
Gini Coefficient: 0.05241935483870968
20:20 Ratio: 1.3253012048192772
Max-min Ratio: 1.3253012048192772
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-13-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 716.0
  episode_reward_mean: 467.8333333333333
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 36
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.463
    dispatch_time_ms: 10.425
    learner:
      cur_lr: 0.0013480120105668902
      grad_gnorm: 40.000003814697266
      policy_entropy: 27.491146087646484
      policy_loss: -14.923799514770508
      var_gnorm: 26.30832862854004
      vf_explained_var: 0.48533833026885986
      vf_loss: 37.30473709106445
    num_steps_sampled: 185000
    num_steps_trained: 185000
    wait_time_ms: 96.708
  iterations_since_restore: 37
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 432.16775727272034
  time_this_iter_s: 10.711386680603027
  time_total_s: 432.16775727272034
  timestamp: 1593994417
  timesteps_since_restore: 185000
  timesteps_this_iter: 5000
  timesteps_total: 185000
  training_iteration: 37
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 432 s, 37 iter, 185000 ts, 468 rew

agent-1: 120.0
agent-2: 150.0
agent-3: 118.0
agent-4: 102.0
agent-5: 134.0
Sum Reward: 624.0
Avg Reward: 124.8
Min Reward: 102.0
Gini Coefficient: 0.07179487179487179
20:20 Ratio: 1.4705882352941178
Max-min Ratio: 1.4705882352941178
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-13-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 716.0
  episode_reward_mean: 472.05405405405406
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 37
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.596
    dispatch_time_ms: 8.49
    learner:
      cur_lr: 0.0013476789463311434
      grad_gnorm: 39.999996185302734
      policy_entropy: 26.161949157714844
      policy_loss: -16.132389068603516
      var_gnorm: 26.419986724853516
      vf_explained_var: 0.6290268898010254
      vf_loss: 108.85243225097656
    num_steps_sampled: 190000
    num_steps_trained: 190000
    wait_time_ms: 93.712
  iterations_since_restore: 38
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 443.3605463504791
  time_this_iter_s: 11.192789077758789
  time_total_s: 443.3605463504791
  timestamp: 1593994429
  timesteps_since_restore: 190000
  timesteps_this_iter: 5000
  timesteps_total: 190000
  training_iteration: 38
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 443 s, 38 iter, 190000 ts, 472 rew

agent-1: 138.0
agent-2: 144.0
agent-3: 144.0
agent-4: 169.0
agent-5: 169.0
Sum Reward: 764.0
Avg Reward: 152.8
Min Reward: 138.0
Gini Coefficient: 0.04554973821989529
20:20 Ratio: 1.2246376811594204
Max-min Ratio: 1.2246376811594204
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-14-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 764.0
  episode_reward_mean: 479.7368421052632
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 38
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.737
    dispatch_time_ms: 6.985
    learner:
      cur_lr: 0.0013473459985107183
      grad_gnorm: 40.00001525878906
      policy_entropy: 24.430429458618164
      policy_loss: 5.335649490356445
      var_gnorm: 26.512420654296875
      vf_explained_var: 0.6943984627723694
      vf_loss: 34.72615051269531
    num_steps_sampled: 195000
    num_steps_trained: 195000
    wait_time_ms: 98.874
  iterations_since_restore: 39
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 454.4698054790497
  time_this_iter_s: 11.109259128570557
  time_total_s: 454.4698054790497
  timestamp: 1593994440
  timesteps_since_restore: 195000
  timesteps_this_iter: 5000
  timesteps_total: 195000
  training_iteration: 39
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 454 s, 39 iter, 195000 ts, 480 rew

agent-1: 97.0
agent-2: 98.0
agent-3: 85.0
agent-4: 90.0
agent-5: 96.0
Sum Reward: 466.0
Avg Reward: 93.2
Min Reward: 85.0
Gini Coefficient: 0.02832618025751073
20:20 Ratio: 1.1529411764705881
Max-min Ratio: 1.1529411764705881
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-14-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 764.0
  episode_reward_mean: 479.38461538461536
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 39
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.542
    dispatch_time_ms: 7.743
    learner:
      cur_lr: 0.0013470130506902933
      grad_gnorm: 39.99999237060547
      policy_entropy: 29.884897232055664
      policy_loss: 10.566474914550781
      var_gnorm: 26.64472198486328
      vf_explained_var: -0.006257414817810059
      vf_loss: 55.402366638183594
    num_steps_sampled: 200000
    num_steps_trained: 200000
    wait_time_ms: 99.709
  iterations_since_restore: 40
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 466.32983803749084
  time_this_iter_s: 11.860032558441162
  time_total_s: 466.32983803749084
  timestamp: 1593994452
  timesteps_since_restore: 200000
  timesteps_this_iter: 5000
  timesteps_total: 200000
  training_iteration: 40
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 466 s, 40 iter, 200000 ts, 479 rew

agent-1: 88.0
agent-2: 123.0
agent-3: 104.0
agent-4: 145.0
agent-5: 113.0
Sum Reward: 573.0
Avg Reward: 114.6
Min Reward: 88.0
Gini Coefficient: 0.09284467713787085
20:20 Ratio: 1.6477272727272727
Max-min Ratio: 1.6477272727272727
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-14-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 764.0
  episode_reward_mean: 481.725
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 40
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.49
    dispatch_time_ms: 7.651
    learner:
      cur_lr: 0.0013466799864545465
      grad_gnorm: 39.9999885559082
      policy_entropy: 23.43611717224121
      policy_loss: 10.531652450561523
      var_gnorm: 26.684385299682617
      vf_explained_var: 0.45192885398864746
      vf_loss: 52.421974182128906
    num_steps_sampled: 205000
    num_steps_trained: 205000
    wait_time_ms: 97.03
  iterations_since_restore: 41
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 476.6924788951874
  time_this_iter_s: 10.362640857696533
  time_total_s: 476.6924788951874
  timestamp: 1593994462
  timesteps_since_restore: 205000
  timesteps_this_iter: 5000
  timesteps_total: 205000
  training_iteration: 41
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 476 s, 41 iter, 205000 ts, 482 rew

agent-1: 145.0
agent-2: 174.0
agent-3: 154.0
agent-4: 150.0
agent-5: 165.0
Sum Reward: 788.0
Avg Reward: 157.6
Min Reward: 145.0
Gini Coefficient: 0.03705583756345178
20:20 Ratio: 1.2
Max-min Ratio: 1.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-14-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 788.0
  episode_reward_mean: 489.1951219512195
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 41
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.129
    dispatch_time_ms: 6.526
    learner:
      cur_lr: 0.0013463470386341214
      grad_gnorm: 40.000003814697266
      policy_entropy: 35.45458984375
      policy_loss: -45.397220611572266
      var_gnorm: 26.773319244384766
      vf_explained_var: -1.0
      vf_loss: 122.79973602294922
    num_steps_sampled: 210000
    num_steps_trained: 210000
    wait_time_ms: 93.32
  iterations_since_restore: 42
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 487.9403393268585
  time_this_iter_s: 11.247860431671143
  time_total_s: 487.9403393268585
  timestamp: 1593994473
  timesteps_since_restore: 210000
  timesteps_this_iter: 5000
  timesteps_total: 210000
  training_iteration: 42
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 487 s, 42 iter, 210000 ts, 489 rew

agent-1: 123.0
agent-2: 149.0
agent-3: 106.0
agent-4: 137.0
agent-5: 126.0
Sum Reward: 641.0
Avg Reward: 128.2
Min Reward: 106.0
Gini Coefficient: 0.062402496099843996
20:20 Ratio: 1.4056603773584906
Max-min Ratio: 1.4056603773584906
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-14-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 788.0
  episode_reward_mean: 492.8095238095238
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 42
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.078
    dispatch_time_ms: 7.928
    learner:
      cur_lr: 0.0013460139743983746
      grad_gnorm: 40.0000114440918
      policy_entropy: 32.993896484375
      policy_loss: 5.065032482147217
      var_gnorm: 26.895906448364258
      vf_explained_var: 0.9481502771377563
      vf_loss: 22.342885971069336
    num_steps_sampled: 215000
    num_steps_trained: 215000
    wait_time_ms: 104.336
  iterations_since_restore: 43
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 499.06021094322205
  time_this_iter_s: 11.119871616363525
  time_total_s: 499.06021094322205
  timestamp: 1593994484
  timesteps_since_restore: 215000
  timesteps_this_iter: 5000
  timesteps_total: 215000
  training_iteration: 43
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 499 s, 43 iter, 215000 ts, 493 rew

agent-1: 112.0
agent-2: 114.0
agent-3: 121.0
agent-4: 136.0
agent-5: 134.0
Sum Reward: 617.0
Avg Reward: 123.4
Min Reward: 112.0
Gini Coefficient: 0.044084278768233384
20:20 Ratio: 1.2142857142857142
Max-min Ratio: 1.2142857142857142
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-14-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 788.0
  episode_reward_mean: 495.69767441860466
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 43
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.676
    dispatch_time_ms: 9.152
    learner:
      cur_lr: 0.0013456810265779495
      grad_gnorm: 40.000030517578125
      policy_entropy: 24.621999740600586
      policy_loss: 3.2662642002105713
      var_gnorm: 27.007490158081055
      vf_explained_var: 0.3022514581680298
      vf_loss: 30.373294830322266
    num_steps_sampled: 220000
    num_steps_trained: 220000
    wait_time_ms: 104.594
  iterations_since_restore: 44
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 510.59302616119385
  time_this_iter_s: 11.532815217971802
  time_total_s: 510.59302616119385
  timestamp: 1593994496
  timesteps_since_restore: 220000
  timesteps_this_iter: 5000
  timesteps_total: 220000
  training_iteration: 44
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 510 s, 44 iter, 220000 ts, 496 rew

agent-1: 121.0
agent-2: 128.0
agent-3: 106.0
agent-4: 130.0
agent-5: 108.0
Sum Reward: 593.0
Avg Reward: 118.6
Min Reward: 106.0
Gini Coefficient: 0.045868465430016866
20:20 Ratio: 1.2264150943396226
Max-min Ratio: 1.2264150943396226
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-15-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 788.0
  episode_reward_mean: 497.90909090909093
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 44
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.266
    dispatch_time_ms: 7.207
    learner:
      cur_lr: 0.0013453479623422027
      grad_gnorm: 40.00000762939453
      policy_entropy: 28.666664123535156
      policy_loss: -0.5957643985748291
      var_gnorm: 27.088281631469727
      vf_explained_var: 0.986049473285675
      vf_loss: 10.122870445251465
    num_steps_sampled: 225000
    num_steps_trained: 225000
    wait_time_ms: 99.007
  iterations_since_restore: 45
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 521.7929995059967
  time_this_iter_s: 11.199973344802856
  time_total_s: 521.7929995059967
  timestamp: 1593994507
  timesteps_since_restore: 225000
  timesteps_this_iter: 5000
  timesteps_total: 225000
  training_iteration: 45
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 521 s, 45 iter, 225000 ts, 498 rew

agent-1: 85.0
agent-2: 72.0
agent-3: 88.0
agent-4: 77.0
agent-5: 121.0
Sum Reward: 443.0
Avg Reward: 88.6
Min Reward: 72.0
Gini Coefficient: 0.09841986455981941
20:20 Ratio: 1.6805555555555556
Max-min Ratio: 1.6805555555555556
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-15-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 788.0
  episode_reward_mean: 496.68888888888887
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 45
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.769
    dispatch_time_ms: 8.241
    learner:
      cur_lr: 0.0013450150145217776
      grad_gnorm: 40.0
      policy_entropy: 52.11851119995117
      policy_loss: -1.315800428390503
      var_gnorm: 27.162704467773438
      vf_explained_var: 0.8952467441558838
      vf_loss: 4.548400402069092
    num_steps_sampled: 230000
    num_steps_trained: 230000
    wait_time_ms: 110.694
  iterations_since_restore: 46
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 533.7887225151062
  time_this_iter_s: 11.995723009109497
  time_total_s: 533.7887225151062
  timestamp: 1593994519
  timesteps_since_restore: 230000
  timesteps_this_iter: 5000
  timesteps_total: 230000
  training_iteration: 46
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 533 s, 46 iter, 230000 ts, 497 rew

agent-1: 85.0
agent-2: 107.0
agent-3: 102.0
agent-4: 96.0
agent-5: 100.0
Sum Reward: 490.0
Avg Reward: 98.0
Min Reward: 85.0
Gini Coefficient: 0.04081632653061224
20:20 Ratio: 1.2588235294117647
Max-min Ratio: 1.2588235294117647
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-15-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 788.0
  episode_reward_mean: 496.54347826086956
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 46
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.213
    dispatch_time_ms: 12.031
    learner:
      cur_lr: 0.0013446819502860308
      grad_gnorm: 39.99998474121094
      policy_entropy: 44.74187088012695
      policy_loss: -37.884098052978516
      var_gnorm: 27.250316619873047
      vf_explained_var: 0.7147903442382812
      vf_loss: 70.85735321044922
    num_steps_sampled: 235000
    num_steps_trained: 235000
    wait_time_ms: 98.767
  iterations_since_restore: 47
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 545.0164468288422
  time_this_iter_s: 11.227724313735962
  time_total_s: 545.0164468288422
  timestamp: 1593994531
  timesteps_since_restore: 235000
  timesteps_this_iter: 5000
  timesteps_total: 235000
  training_iteration: 47
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 545 s, 47 iter, 235000 ts, 497 rew

agent-1: 76.0
agent-2: 105.0
agent-3: 96.0
agent-4: 85.0
agent-5: 97.0
Sum Reward: 459.0
Avg Reward: 91.8
Min Reward: 76.0
Gini Coefficient: 0.06100217864923747
20:20 Ratio: 1.381578947368421
Max-min Ratio: 1.381578947368421
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-15-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 788.0
  episode_reward_mean: 495.74468085106383
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 47
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.17
    dispatch_time_ms: 6.848
    learner:
      cur_lr: 0.0013443490024656057
      grad_gnorm: 40.000003814697266
      policy_entropy: 27.274349212646484
      policy_loss: -5.26762580871582
      var_gnorm: 27.339752197265625
      vf_explained_var: 0.07106989622116089
      vf_loss: 121.9686508178711
    num_steps_sampled: 240000
    num_steps_trained: 240000
    wait_time_ms: 107.17
  iterations_since_restore: 48
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 556.6924824714661
  time_this_iter_s: 11.676035642623901
  time_total_s: 556.6924824714661
  timestamp: 1593994542
  timesteps_since_restore: 240000
  timesteps_this_iter: 5000
  timesteps_total: 240000
  training_iteration: 48
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 556 s, 48 iter, 240000 ts, 496 rew

agent-1: 136.0
agent-2: 152.0
agent-3: 92.0
agent-4: 170.0
agent-5: 134.0
Sum Reward: 684.0
Avg Reward: 136.8
Min Reward: 92.0
Gini Coefficient: 0.10175438596491228
20:20 Ratio: 1.8478260869565217
Max-min Ratio: 1.8478260869565217
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-15-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 788.0
  episode_reward_mean: 499.6666666666667
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 48
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.307
    dispatch_time_ms: 9.442
    learner:
      cur_lr: 0.0013440160546451807
      grad_gnorm: 40.00001525878906
      policy_entropy: 39.93892288208008
      policy_loss: -1.1255662441253662
      var_gnorm: 27.463815689086914
      vf_explained_var: -0.6172748804092407
      vf_loss: 32.312744140625
    num_steps_sampled: 245000
    num_steps_trained: 245000
    wait_time_ms: 106.377
  iterations_since_restore: 49
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 568.0864412784576
  time_this_iter_s: 11.393958806991577
  time_total_s: 568.0864412784576
  timestamp: 1593994554
  timesteps_since_restore: 245000
  timesteps_this_iter: 5000
  timesteps_total: 245000
  training_iteration: 49
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 568 s, 49 iter, 245000 ts, 500 rew

agent-1: 66.0
agent-2: 63.0
agent-3: 94.0
agent-4: 88.0
agent-5: 101.0
Sum Reward: 412.0
Avg Reward: 82.4
Min Reward: 63.0
Gini Coefficient: 0.10097087378640776
20:20 Ratio: 1.6031746031746033
Max-min Ratio: 1.6031746031746033
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-16-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 788.0
  episode_reward_mean: 497.8775510204082
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 49
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.941
    dispatch_time_ms: 6.941
    learner:
      cur_lr: 0.0013436829904094338
      grad_gnorm: 39.99999237060547
      policy_entropy: 27.39295768737793
      policy_loss: -18.43506622314453
      var_gnorm: 27.524738311767578
      vf_explained_var: -1.0
      vf_loss: 49.91386413574219
    num_steps_sampled: 250000
    num_steps_trained: 250000
    wait_time_ms: 98.968
  iterations_since_restore: 50
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 579.8743569850922
  time_this_iter_s: 11.787915706634521
  time_total_s: 579.8743569850922
  timestamp: 1593994566
  timesteps_since_restore: 250000
  timesteps_this_iter: 5000
  timesteps_total: 250000
  training_iteration: 50
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 579 s, 50 iter, 250000 ts, 498 rew

agent-1: 123.0
agent-2: 114.0
agent-3: 104.0
agent-4: 116.0
agent-5: 107.0
Sum Reward: 564.0
Avg Reward: 112.8
Min Reward: 104.0
Gini Coefficient: 0.03333333333333333
20:20 Ratio: 1.1826923076923077
Max-min Ratio: 1.1826923076923077
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-16-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 788.0
  episode_reward_mean: 499.2
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 50
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.433
    dispatch_time_ms: 6.752
    learner:
      cur_lr: 0.0013433500425890088
      grad_gnorm: 39.999977111816406
      policy_entropy: 21.939453125
      policy_loss: 22.652740478515625
      var_gnorm: 27.60439682006836
      vf_explained_var: 0.735916256904602
      vf_loss: 97.79391479492188
    num_steps_sampled: 255000
    num_steps_trained: 255000
    wait_time_ms: 108.712
  iterations_since_restore: 51
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 591.1577470302582
  time_this_iter_s: 11.283390045166016
  time_total_s: 591.1577470302582
  timestamp: 1593994577
  timesteps_since_restore: 255000
  timesteps_this_iter: 5000
  timesteps_total: 255000
  training_iteration: 51
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 591 s, 51 iter, 255000 ts, 499 rew

agent-1: 79.0
agent-2: 85.0
agent-3: 79.0
agent-4: 111.0
agent-5: 103.0
Sum Reward: 457.0
Avg Reward: 91.4
Min Reward: 79.0
Gini Coefficient: 0.07702407002188184
20:20 Ratio: 1.4050632911392404
Max-min Ratio: 1.4050632911392404
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-16-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 788.0
  episode_reward_mean: 498.37254901960785
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 51
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.044
    dispatch_time_ms: 8.532
    learner:
      cur_lr: 0.001343016978353262
      grad_gnorm: 39.99999237060547
      policy_entropy: 27.30023956298828
      policy_loss: 10.021978378295898
      var_gnorm: 27.692195892333984
      vf_explained_var: 0.7575583457946777
      vf_loss: 48.31747817993164
    num_steps_sampled: 260000
    num_steps_trained: 260000
    wait_time_ms: 94.649
  iterations_since_restore: 52
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 603.218531370163
  time_this_iter_s: 12.060784339904785
  time_total_s: 603.218531370163
  timestamp: 1593994589
  timesteps_since_restore: 260000
  timesteps_this_iter: 5000
  timesteps_total: 260000
  training_iteration: 52
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 603 s, 52 iter, 260000 ts, 498 rew

agent-1: 103.0
agent-2: 130.0
agent-3: 99.0
agent-4: 119.0
agent-5: 87.0
Sum Reward: 538.0
Avg Reward: 107.6
Min Reward: 87.0
Gini Coefficient: 0.07881040892193308
20:20 Ratio: 1.4942528735632183
Max-min Ratio: 1.4942528735632183
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-16-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 788.0
  episode_reward_mean: 499.13461538461536
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 52
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.072
    dispatch_time_ms: 6.55
    learner:
      cur_lr: 0.001342684030532837
      grad_gnorm: 39.999996185302734
      policy_entropy: 39.62861633300781
      policy_loss: 18.788530349731445
      var_gnorm: 27.82404899597168
      vf_explained_var: 0.21125471591949463
      vf_loss: 31.069538116455078
    num_steps_sampled: 265000
    num_steps_trained: 265000
    wait_time_ms: 114.238
  iterations_since_restore: 53
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 614.4670343399048
  time_this_iter_s: 11.248502969741821
  time_total_s: 614.4670343399048
  timestamp: 1593994600
  timesteps_since_restore: 265000
  timesteps_this_iter: 5000
  timesteps_total: 265000
  training_iteration: 53
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 614 s, 53 iter, 265000 ts, 499 rew

agent-1: 114.0
agent-2: 105.0
agent-3: 106.0
agent-4: 116.0
agent-5: 121.0
Sum Reward: 562.0
Avg Reward: 112.4
Min Reward: 105.0
Gini Coefficient: 0.0298932384341637
20:20 Ratio: 1.1523809523809523
Max-min Ratio: 1.1523809523809523
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-16-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 788.0
  episode_reward_mean: 500.3207547169811
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 53
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.009
    dispatch_time_ms: 7.422
    learner:
      cur_lr: 0.00134235096629709
      grad_gnorm: 40.000022888183594
      policy_entropy: 30.753889083862305
      policy_loss: -12.389509201049805
      var_gnorm: 27.913698196411133
      vf_explained_var: 0.5741313099861145
      vf_loss: 133.3165283203125
    num_steps_sampled: 270000
    num_steps_trained: 270000
    wait_time_ms: 99.089
  iterations_since_restore: 54
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 626.4401552677155
  time_this_iter_s: 11.973120927810669
  time_total_s: 626.4401552677155
  timestamp: 1593994612
  timesteps_since_restore: 270000
  timesteps_this_iter: 5000
  timesteps_total: 270000
  training_iteration: 54
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 626 s, 54 iter, 270000 ts, 500 rew

agent-1: 66.0
agent-2: 81.0
agent-3: 70.0
agent-4: 107.0
agent-5: 81.0
Sum Reward: 405.0
Avg Reward: 81.0
Min Reward: 66.0
Gini Coefficient: 0.09185185185185185
20:20 Ratio: 1.621212121212121
Max-min Ratio: 1.621212121212121
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-17-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 788.0
  episode_reward_mean: 498.55555555555554
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 54
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.619
    dispatch_time_ms: 7.633
    learner:
      cur_lr: 0.001342018018476665
      grad_gnorm: 39.99998474121094
      policy_entropy: 17.239683151245117
      policy_loss: -25.108022689819336
      var_gnorm: 28.016450881958008
      vf_explained_var: 0.18589597940444946
      vf_loss: 47.25149917602539
    num_steps_sampled: 275000
    num_steps_trained: 275000
    wait_time_ms: 101.818
  iterations_since_restore: 55
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 637.5897507667542
  time_this_iter_s: 11.149595499038696
  time_total_s: 637.5897507667542
  timestamp: 1593994623
  timesteps_since_restore: 275000
  timesteps_this_iter: 5000
  timesteps_total: 275000
  training_iteration: 55
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 637 s, 55 iter, 275000 ts, 499 rew

agent-1: 86.0
agent-2: 72.0
agent-3: 109.0
agent-4: 107.0
agent-5: 90.0
Sum Reward: 464.0
Avg Reward: 92.8
Min Reward: 72.0
Gini Coefficient: 0.08189655172413793
20:20 Ratio: 1.5138888888888888
Max-min Ratio: 1.5138888888888888
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-17-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 788.0
  episode_reward_mean: 497.92727272727274
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 55
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.898
    dispatch_time_ms: 7.275
    learner:
      cur_lr: 0.0013416849542409182
      grad_gnorm: 39.999996185302734
      policy_entropy: 13.249277114868164
      policy_loss: 1.9326236248016357
      var_gnorm: 28.127832412719727
      vf_explained_var: -0.3350977897644043
      vf_loss: 46.40912628173828
    num_steps_sampled: 280000
    num_steps_trained: 280000
    wait_time_ms: 98.521
  iterations_since_restore: 56
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 649.4737772941589
  time_this_iter_s: 11.884026527404785
  time_total_s: 649.4737772941589
  timestamp: 1593994635
  timesteps_since_restore: 280000
  timesteps_this_iter: 5000
  timesteps_total: 280000
  training_iteration: 56
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 649 s, 56 iter, 280000 ts, 498 rew

agent-1: 112.0
agent-2: 161.0
agent-3: 132.0
agent-4: 109.0
agent-5: 111.0
Sum Reward: 625.0
Avg Reward: 125.0
Min Reward: 109.0
Gini Coefficient: 0.08
20:20 Ratio: 1.4770642201834863
Max-min Ratio: 1.4770642201834863
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-17-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 788.0
  episode_reward_mean: 500.19642857142856
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 56
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.62
    dispatch_time_ms: 10.191
    learner:
      cur_lr: 0.0013413520064204931
      grad_gnorm: 34.919010162353516
      policy_entropy: 18.389516830444336
      policy_loss: -5.962253570556641
      var_gnorm: 28.168720245361328
      vf_explained_var: -0.32242000102996826
      vf_loss: 13.549888610839844
    num_steps_sampled: 285000
    num_steps_trained: 285000
    wait_time_ms: 88.022
  iterations_since_restore: 57
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 659.99258685112
  time_this_iter_s: 10.51880955696106
  time_total_s: 659.99258685112
  timestamp: 1593994646
  timesteps_since_restore: 285000
  timesteps_this_iter: 5000
  timesteps_total: 285000
  training_iteration: 57
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 659 s, 57 iter, 285000 ts, 500 rew

agent-1: 178.0
agent-2: 144.0
agent-3: 133.0
agent-4: 191.0
agent-5: 179.0
Sum Reward: 825.0
Avg Reward: 165.0
Min Reward: 133.0
Gini Coefficient: 0.07321212121212121
20:20 Ratio: 1.4360902255639099
Max-min Ratio: 1.4360902255639099
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-17-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 825.0
  episode_reward_mean: 505.89473684210526
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 57
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.513
    dispatch_time_ms: 8.187
    learner:
      cur_lr: 0.0013410189421847463
      grad_gnorm: 40.0000114440918
      policy_entropy: 29.24387550354004
      policy_loss: -11.123896598815918
      var_gnorm: 28.239517211914062
      vf_explained_var: 0.9548242092132568
      vf_loss: 46.14711380004883
    num_steps_sampled: 290000
    num_steps_trained: 290000
    wait_time_ms: 98.251
  iterations_since_restore: 58
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 670.8767561912537
  time_this_iter_s: 10.884169340133667
  time_total_s: 670.8767561912537
  timestamp: 1593994657
  timesteps_since_restore: 290000
  timesteps_this_iter: 5000
  timesteps_total: 290000
  training_iteration: 58
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 670 s, 58 iter, 290000 ts, 506 rew

agent-1: 182.0
agent-2: 145.0
agent-3: 160.0
agent-4: 115.0
agent-5: 150.0
Sum Reward: 752.0
Avg Reward: 150.4
Min Reward: 115.0
Gini Coefficient: 0.07925531914893617
20:20 Ratio: 1.5826086956521739
Max-min Ratio: 1.5826086956521739
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-17-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 825.0
  episode_reward_mean: 510.13793103448273
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 58
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.898
    dispatch_time_ms: 10.512
    learner:
      cur_lr: 0.0013406859943643212
      grad_gnorm: 40.0
      policy_entropy: 21.198286056518555
      policy_loss: -4.2588887214660645
      var_gnorm: 28.561988830566406
      vf_explained_var: -0.29477858543395996
      vf_loss: 31.736221313476562
    num_steps_sampled: 295000
    num_steps_trained: 295000
    wait_time_ms: 111.537
  iterations_since_restore: 59
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 682.592355966568
  time_this_iter_s: 11.715599775314331
  time_total_s: 682.592355966568
  timestamp: 1593994669
  timesteps_since_restore: 295000
  timesteps_this_iter: 5000
  timesteps_total: 295000
  training_iteration: 59
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 682 s, 59 iter, 295000 ts, 510 rew

agent-1: 71.0
agent-2: 68.0
agent-3: 57.0
agent-4: 62.0
agent-5: 107.0
Sum Reward: 365.0
Avg Reward: 73.0
Min Reward: 57.0
Gini Coefficient: 0.11945205479452055
20:20 Ratio: 1.8771929824561404
Max-min Ratio: 1.8771929824561404
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-18-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 825.0
  episode_reward_mean: 507.6779661016949
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 59
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.745
    dispatch_time_ms: 7.846
    learner:
      cur_lr: 0.0013403530465438962
      grad_gnorm: 6.969845294952393
      policy_entropy: 36.96812057495117
      policy_loss: -0.9040592312812805
      var_gnorm: 28.715364456176758
      vf_explained_var: 0.9952430725097656
      vf_loss: 0.10482209175825119
    num_steps_sampled: 300000
    num_steps_trained: 300000
    wait_time_ms: 107.915
  iterations_since_restore: 60
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 694.8829464912415
  time_this_iter_s: 12.290590524673462
  time_total_s: 694.8829464912415
  timestamp: 1593994681
  timesteps_since_restore: 300000
  timesteps_this_iter: 5000
  timesteps_total: 300000
  training_iteration: 60
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 694 s, 60 iter, 300000 ts, 508 rew

agent-1: 88.0
agent-2: 119.0
agent-3: 71.0
agent-4: 81.0
agent-5: 99.0
Sum Reward: 458.0
Avg Reward: 91.6
Min Reward: 71.0
Gini Coefficient: 0.09956331877729258
20:20 Ratio: 1.676056338028169
Max-min Ratio: 1.676056338028169
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-18-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 825.0
  episode_reward_mean: 506.85
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 60
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.223
    dispatch_time_ms: 8.059
    learner:
      cur_lr: 0.0013400199823081493
      grad_gnorm: 39.999996185302734
      policy_entropy: 9.874837875366211
      policy_loss: -8.389681816101074
      var_gnorm: 28.824142456054688
      vf_explained_var: 0.6916927099227905
      vf_loss: 78.41984558105469
    num_steps_sampled: 305000
    num_steps_trained: 305000
    wait_time_ms: 105.197
  iterations_since_restore: 61
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 706.0539169311523
  time_this_iter_s: 11.170970439910889
  time_total_s: 706.0539169311523
  timestamp: 1593994692
  timesteps_since_restore: 305000
  timesteps_this_iter: 5000
  timesteps_total: 305000
  training_iteration: 61
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 706 s, 61 iter, 305000 ts, 507 rew

agent-1: 84.0
agent-2: 82.0
agent-3: 84.0
agent-4: 81.0
agent-5: 95.0
Sum Reward: 426.0
Avg Reward: 85.2
Min Reward: 81.0
Gini Coefficient: 0.028169014084507043
20:20 Ratio: 1.1728395061728396
Max-min Ratio: 1.1728395061728396
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-18-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 825.0
  episode_reward_mean: 505.5245901639344
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 61
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.332
    dispatch_time_ms: 7.955
    learner:
      cur_lr: 0.0013396870344877243
      grad_gnorm: 40.00000762939453
      policy_entropy: 19.107393264770508
      policy_loss: 9.797599792480469
      var_gnorm: 28.979162216186523
      vf_explained_var: -0.7156320810317993
      vf_loss: 29.39999771118164
    num_steps_sampled: 310000
    num_steps_trained: 310000
    wait_time_ms: 101.821
  iterations_since_restore: 62
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 718.1504907608032
  time_this_iter_s: 12.096573829650879
  time_total_s: 718.1504907608032
  timestamp: 1593994704
  timesteps_since_restore: 310000
  timesteps_this_iter: 5000
  timesteps_total: 310000
  training_iteration: 62
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 718 s, 62 iter, 310000 ts, 506 rew

agent-1: 89.0
agent-2: 142.0
agent-3: 94.0
agent-4: 124.0
agent-5: 106.0
Sum Reward: 555.0
Avg Reward: 111.0
Min Reward: 89.0
Gini Coefficient: 0.09801801801801802
20:20 Ratio: 1.595505617977528
Max-min Ratio: 1.595505617977528
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-18-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 825.0
  episode_reward_mean: 506.3225806451613
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 62
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.862
    dispatch_time_ms: 6.823
    learner:
      cur_lr: 0.0013393539702519774
      grad_gnorm: 33.19523239135742
      policy_entropy: 24.35139274597168
      policy_loss: -2.57656192779541
      var_gnorm: 29.07920265197754
      vf_explained_var: 0.7534081935882568
      vf_loss: 15.138089179992676
    num_steps_sampled: 315000
    num_steps_trained: 315000
    wait_time_ms: 110.693
  iterations_since_restore: 63
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 729.5497806072235
  time_this_iter_s: 11.399289846420288
  time_total_s: 729.5497806072235
  timestamp: 1593994716
  timesteps_since_restore: 315000
  timesteps_this_iter: 5000
  timesteps_total: 315000
  training_iteration: 63
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 729 s, 63 iter, 315000 ts, 506 rew

agent-1: 100.0
agent-2: 135.0
agent-3: 123.0
agent-4: 121.0
agent-5: 121.0
Sum Reward: 600.0
Avg Reward: 120.0
Min Reward: 100.0
Gini Coefficient: 0.048
20:20 Ratio: 1.35
Max-min Ratio: 1.35
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-18-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 825.0
  episode_reward_mean: 507.8095238095238
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 63
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.469
    dispatch_time_ms: 7.861
    learner:
      cur_lr: 0.0013390210224315524
      grad_gnorm: 15.122300148010254
      policy_entropy: 37.67565155029297
      policy_loss: -3.4063291549682617
      var_gnorm: 29.208009719848633
      vf_explained_var: 0.7017523050308228
      vf_loss: 1.5180402994155884
    num_steps_sampled: 320000
    num_steps_trained: 320000
    wait_time_ms: 108.498
  iterations_since_restore: 64
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 741.7576422691345
  time_this_iter_s: 12.20786166191101
  time_total_s: 741.7576422691345
  timestamp: 1593994728
  timesteps_since_restore: 320000
  timesteps_this_iter: 5000
  timesteps_total: 320000
  training_iteration: 64
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 741 s, 64 iter, 320000 ts, 508 rew

agent-1: 65.0
agent-2: 85.0
agent-3: 70.0
agent-4: 64.0
agent-5: 77.0
Sum Reward: 361.0
Avg Reward: 72.2
Min Reward: 64.0
Gini Coefficient: 0.059833795013850416
20:20 Ratio: 1.328125
Max-min Ratio: 1.328125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-19-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 825.0
  episode_reward_mean: 505.515625
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 64
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.798
    dispatch_time_ms: 10.366
    learner:
      cur_lr: 0.0013386879581958055
      grad_gnorm: 39.99999237060547
      policy_entropy: 26.876235961914062
      policy_loss: -15.052285194396973
      var_gnorm: 29.2679386138916
      vf_explained_var: -0.28464818000793457
      vf_loss: 53.888092041015625
    num_steps_sampled: 325000
    num_steps_trained: 325000
    wait_time_ms: 112.374
  iterations_since_restore: 65
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 753.412926197052
  time_this_iter_s: 11.65528392791748
  time_total_s: 753.412926197052
  timestamp: 1593994740
  timesteps_since_restore: 325000
  timesteps_this_iter: 5000
  timesteps_total: 325000
  training_iteration: 65
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 753 s, 65 iter, 325000 ts, 506 rew

agent-1: 69.0
agent-2: 87.0
agent-3: 89.0
agent-4: 81.0
agent-5: 80.0
Sum Reward: 406.0
Avg Reward: 81.2
Min Reward: 69.0
Gini Coefficient: 0.04630541871921182
20:20 Ratio: 1.289855072463768
Max-min Ratio: 1.289855072463768
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-19-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 825.0
  episode_reward_mean: 503.9846153846154
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 65
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.638
    dispatch_time_ms: 8.015
    learner:
      cur_lr: 0.0013383550103753805
      grad_gnorm: 39.999996185302734
      policy_entropy: 13.182319641113281
      policy_loss: 38.56351089477539
      var_gnorm: 29.311073303222656
      vf_explained_var: -0.21460652351379395
      vf_loss: 248.9385986328125
    num_steps_sampled: 330000
    num_steps_trained: 330000
    wait_time_ms: 101.295
  iterations_since_restore: 66
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 765.5455679893494
  time_this_iter_s: 12.132641792297363
  time_total_s: 765.5455679893494
  timestamp: 1593994752
  timesteps_since_restore: 330000
  timesteps_this_iter: 5000
  timesteps_total: 330000
  training_iteration: 66
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 765 s, 66 iter, 330000 ts, 504 rew

agent-1: 76.0
agent-2: 92.0
agent-3: 69.0
agent-4: 71.0
agent-5: 75.0
Sum Reward: 383.0
Avg Reward: 76.6
Min Reward: 69.0
Gini Coefficient: 0.053263707571801565
20:20 Ratio: 1.3333333333333333
Max-min Ratio: 1.3333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-19-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 825.0
  episode_reward_mean: 502.1515151515151
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 66
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.737
    dispatch_time_ms: 6.204
    learner:
      cur_lr: 0.0013380219461396337
      grad_gnorm: 40.000003814697266
      policy_entropy: 29.075313568115234
      policy_loss: 1.4233324527740479
      var_gnorm: 29.3610897064209
      vf_explained_var: 0.49746954441070557
      vf_loss: 58.96306610107422
    num_steps_sampled: 335000
    num_steps_trained: 335000
    wait_time_ms: 110.719
  iterations_since_restore: 67
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 776.8597922325134
  time_this_iter_s: 11.314224243164062
  time_total_s: 776.8597922325134
  timestamp: 1593994763
  timesteps_since_restore: 335000
  timesteps_this_iter: 5000
  timesteps_total: 335000
  training_iteration: 67
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 776 s, 67 iter, 335000 ts, 502 rew

agent-1: 85.0
agent-2: 124.0
agent-3: 80.0
agent-4: 89.0
agent-5: 94.0
Sum Reward: 472.0
Avg Reward: 94.4
Min Reward: 80.0
Gini Coefficient: 0.08220338983050847
20:20 Ratio: 1.55
Max-min Ratio: 1.55
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-19-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 825.0
  episode_reward_mean: 501.7014925373134
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 67
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.515
    dispatch_time_ms: 7.819
    learner:
      cur_lr: 0.0013376889983192086
      grad_gnorm: 40.0
      policy_entropy: 23.844457626342773
      policy_loss: 4.3119964599609375
      var_gnorm: 29.562009811401367
      vf_explained_var: 0.47965753078460693
      vf_loss: 55.847389221191406
    num_steps_sampled: 340000
    num_steps_trained: 340000
    wait_time_ms: 99.177
  iterations_since_restore: 68
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 788.3716747760773
  time_this_iter_s: 11.511882543563843
  time_total_s: 788.3716747760773
  timestamp: 1593994775
  timesteps_since_restore: 340000
  timesteps_this_iter: 5000
  timesteps_total: 340000
  training_iteration: 68
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 788 s, 68 iter, 340000 ts, 502 rew

agent-1: 97.0
agent-2: 136.0
agent-3: 120.0
agent-4: 102.0
agent-5: 143.0
Sum Reward: 598.0
Avg Reward: 119.6
Min Reward: 97.0
Gini Coefficient: 0.08428093645484949
20:20 Ratio: 1.4742268041237114
Max-min Ratio: 1.4742268041237114
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-19-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 825.0
  episode_reward_mean: 503.11764705882354
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 68
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.938
    dispatch_time_ms: 8.016
    learner:
      cur_lr: 0.0013373560504987836
      grad_gnorm: 40.00000762939453
      policy_entropy: 19.149267196655273
      policy_loss: 6.343830108642578
      var_gnorm: 29.54022789001465
      vf_explained_var: 0.9365724921226501
      vf_loss: 47.33234786987305
    num_steps_sampled: 345000
    num_steps_trained: 345000
    wait_time_ms: 105.847
  iterations_since_restore: 69
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 799.1921265125275
  time_this_iter_s: 10.820451736450195
  time_total_s: 799.1921265125275
  timestamp: 1593994785
  timesteps_since_restore: 345000
  timesteps_this_iter: 5000
  timesteps_total: 345000
  training_iteration: 69
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 799 s, 69 iter, 345000 ts, 503 rew

agent-1: 93.0
agent-2: 153.0
agent-3: 103.0
agent-4: 124.0
agent-5: 103.0
Sum Reward: 576.0
Avg Reward: 115.2
Min Reward: 93.0
Gini Coefficient: 0.09791666666666667
20:20 Ratio: 1.6451612903225807
Max-min Ratio: 1.6451612903225807
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-19-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 825.0
  episode_reward_mean: 504.17391304347825
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 69
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.378
    dispatch_time_ms: 8.686
    learner:
      cur_lr: 0.0013370229862630367
      grad_gnorm: 40.00001525878906
      policy_entropy: 25.567663192749023
      policy_loss: 18.69228172302246
      var_gnorm: 29.73478889465332
      vf_explained_var: 0.18053990602493286
      vf_loss: 34.040008544921875
    num_steps_sampled: 350000
    num_steps_trained: 350000
    wait_time_ms: 104.57
  iterations_since_restore: 70
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 811.3479635715485
  time_this_iter_s: 12.155837059020996
  time_total_s: 811.3479635715485
  timestamp: 1593994798
  timesteps_since_restore: 350000
  timesteps_this_iter: 5000
  timesteps_total: 350000
  training_iteration: 70
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 811 s, 70 iter, 350000 ts, 504 rew

agent-1: 89.0
agent-2: 78.0
agent-3: 76.0
agent-4: 124.0
agent-5: 122.0
Sum Reward: 489.0
Avg Reward: 97.8
Min Reward: 76.0
Gini Coefficient: 0.11451942740286299
20:20 Ratio: 1.631578947368421
Max-min Ratio: 1.631578947368421
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-20-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 825.0
  episode_reward_mean: 503.95714285714286
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 70
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.79
    dispatch_time_ms: 6.17
    learner:
      cur_lr: 0.0013366900384426117
      grad_gnorm: 40.000003814697266
      policy_entropy: 25.452312469482422
      policy_loss: -24.668642044067383
      var_gnorm: 29.81985092163086
      vf_explained_var: 0.22573107481002808
      vf_loss: 35.220603942871094
    num_steps_sampled: 355000
    num_steps_trained: 355000
    wait_time_ms: 108.639
  iterations_since_restore: 71
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 822.5883922576904
  time_this_iter_s: 11.240428686141968
  time_total_s: 822.5883922576904
  timestamp: 1593994809
  timesteps_since_restore: 355000
  timesteps_this_iter: 5000
  timesteps_total: 355000
  training_iteration: 71
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 822 s, 71 iter, 355000 ts, 504 rew

agent-1: 120.0
agent-2: 131.0
agent-3: 96.0
agent-4: 139.0
agent-5: 134.0
Sum Reward: 620.0
Avg Reward: 124.0
Min Reward: 96.0
Gini Coefficient: 0.06451612903225806
20:20 Ratio: 1.4479166666666667
Max-min Ratio: 1.4479166666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-20-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 825.0
  episode_reward_mean: 505.59154929577466
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 71
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.478
    dispatch_time_ms: 10.743
    learner:
      cur_lr: 0.0013363569742068648
      grad_gnorm: 40.0
      policy_entropy: 15.145050048828125
      policy_loss: 3.7270994186401367
      var_gnorm: 30.024789810180664
      vf_explained_var: 0.36228471994400024
      vf_loss: 48.1718864440918
    num_steps_sampled: 360000
    num_steps_trained: 360000
    wait_time_ms: 106.133
  iterations_since_restore: 72
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 834.4005205631256
  time_this_iter_s: 11.81212830543518
  time_total_s: 834.4005205631256
  timestamp: 1593994821
  timesteps_since_restore: 360000
  timesteps_this_iter: 5000
  timesteps_total: 360000
  training_iteration: 72
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 834 s, 72 iter, 360000 ts, 506 rew

agent-1: 95.0
agent-2: 102.0
agent-3: 107.0
agent-4: 116.0
agent-5: 97.0
Sum Reward: 517.0
Avg Reward: 103.4
Min Reward: 95.0
Gini Coefficient: 0.0402321083172147
20:20 Ratio: 1.2210526315789474
Max-min Ratio: 1.2210526315789474
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-20-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 825.0
  episode_reward_mean: 505.75
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 72
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.367
    dispatch_time_ms: 6.315
    learner:
      cur_lr: 0.0013360240263864398
      grad_gnorm: 40.00001525878906
      policy_entropy: 20.99823760986328
      policy_loss: -13.805265426635742
      var_gnorm: 30.08932113647461
      vf_explained_var: -0.8817404508590698
      vf_loss: 134.72332763671875
    num_steps_sampled: 365000
    num_steps_trained: 365000
    wait_time_ms: 112.399
  iterations_since_restore: 73
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 845.7687497138977
  time_this_iter_s: 11.368229150772095
  time_total_s: 845.7687497138977
  timestamp: 1593994832
  timesteps_since_restore: 365000
  timesteps_this_iter: 5000
  timesteps_total: 365000
  training_iteration: 73
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 845 s, 73 iter, 365000 ts, 506 rew

agent-1: 104.0
agent-2: 115.0
agent-3: 97.0
agent-4: 121.0
agent-5: 99.0
Sum Reward: 536.0
Avg Reward: 107.2
Min Reward: 97.0
Gini Coefficient: 0.04776119402985075
20:20 Ratio: 1.2474226804123711
Max-min Ratio: 1.2474226804123711
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-20-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 825.0
  episode_reward_mean: 506.16438356164383
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 73
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.058
    dispatch_time_ms: 7.061
    learner:
      cur_lr: 0.001335690962150693
      grad_gnorm: 40.00000762939453
      policy_entropy: 18.809907913208008
      policy_loss: -9.116466522216797
      var_gnorm: 30.257835388183594
      vf_explained_var: -0.3649430274963379
      vf_loss: 187.98716735839844
    num_steps_sampled: 370000
    num_steps_trained: 370000
    wait_time_ms: 102.346
  iterations_since_restore: 74
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 857.9547009468079
  time_this_iter_s: 12.185951232910156
  time_total_s: 857.9547009468079
  timestamp: 1593994844
  timesteps_since_restore: 370000
  timesteps_this_iter: 5000
  timesteps_total: 370000
  training_iteration: 74
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 857 s, 74 iter, 370000 ts, 506 rew

agent-1: 73.0
agent-2: 111.0
agent-3: 83.0
agent-4: 108.0
agent-5: 87.0
Sum Reward: 462.0
Avg Reward: 92.4
Min Reward: 73.0
Gini Coefficient: 0.08744588744588745
20:20 Ratio: 1.5205479452054795
Max-min Ratio: 1.5205479452054795
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-20-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 825.0
  episode_reward_mean: 505.56756756756755
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 74
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.622
    dispatch_time_ms: 7.1
    learner:
      cur_lr: 0.001335358014330268
      grad_gnorm: 39.999996185302734
      policy_entropy: 19.3257999420166
      policy_loss: 21.054460525512695
      var_gnorm: 30.384769439697266
      vf_explained_var: -0.6296306848526001
      vf_loss: 119.32583618164062
    num_steps_sampled: 375000
    num_steps_trained: 375000
    wait_time_ms: 101.302
  iterations_since_restore: 75
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 869.1829342842102
  time_this_iter_s: 11.228233337402344
  time_total_s: 869.1829342842102
  timestamp: 1593994856
  timesteps_since_restore: 375000
  timesteps_this_iter: 5000
  timesteps_total: 375000
  training_iteration: 75
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 869 s, 75 iter, 375000 ts, 506 rew

agent-1: 91.0
agent-2: 130.0
agent-3: 87.0
agent-4: 108.0
agent-5: 136.0
Sum Reward: 552.0
Avg Reward: 110.4
Min Reward: 87.0
Gini Coefficient: 0.09927536231884058
20:20 Ratio: 1.5632183908045978
Max-min Ratio: 1.5632183908045978
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-21-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 825.0
  episode_reward_mean: 506.18666666666667
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 75
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.375
    dispatch_time_ms: 9.557
    learner:
      cur_lr: 0.001335024950094521
      grad_gnorm: 40.0
      policy_entropy: 24.561548233032227
      policy_loss: 11.72454833984375
      var_gnorm: 30.520116806030273
      vf_explained_var: -0.898639440536499
      vf_loss: 36.109981536865234
    num_steps_sampled: 380000
    num_steps_trained: 380000
    wait_time_ms: 103.965
  iterations_since_restore: 76
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 880.9959614276886
  time_this_iter_s: 11.813027143478394
  time_total_s: 880.9959614276886
  timestamp: 1593994868
  timesteps_since_restore: 380000
  timesteps_this_iter: 5000
  timesteps_total: 380000
  training_iteration: 76
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 880 s, 76 iter, 380000 ts, 506 rew

agent-1: 125.0
agent-2: 98.0
agent-3: 94.0
agent-4: 145.0
agent-5: 120.0
Sum Reward: 582.0
Avg Reward: 116.4
Min Reward: 94.0
Gini Coefficient: 0.088659793814433
20:20 Ratio: 1.5425531914893618
Max-min Ratio: 1.5425531914893618
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-21-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 825.0
  episode_reward_mean: 507.1842105263158
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 76
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.048
    dispatch_time_ms: 6.53
    learner:
      cur_lr: 0.001334692002274096
      grad_gnorm: 40.000003814697266
      policy_entropy: 25.89191436767578
      policy_loss: -9.12203311920166
      var_gnorm: 30.58701515197754
      vf_explained_var: -1.0
      vf_loss: 60.657318115234375
    num_steps_sampled: 385000
    num_steps_trained: 385000
    wait_time_ms: 105.954
  iterations_since_restore: 77
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 892.1059184074402
  time_this_iter_s: 11.109956979751587
  time_total_s: 892.1059184074402
  timestamp: 1593994879
  timesteps_since_restore: 385000
  timesteps_this_iter: 5000
  timesteps_total: 385000
  training_iteration: 77
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 892 s, 77 iter, 385000 ts, 507 rew

agent-1: 99.0
agent-2: 131.0
agent-3: 99.0
agent-4: 104.0
agent-5: 96.0
Sum Reward: 529.0
Avg Reward: 105.8
Min Reward: 96.0
Gini Coefficient: 0.05671077504725898
20:20 Ratio: 1.3645833333333333
Max-min Ratio: 1.3645833333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-21-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 825.0
  episode_reward_mean: 507.46753246753246
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 77
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.642
    dispatch_time_ms: 7.631
    learner:
      cur_lr: 0.001334359054453671
      grad_gnorm: 40.00001525878906
      policy_entropy: 20.666255950927734
      policy_loss: 5.900854110717773
      var_gnorm: 30.690195083618164
      vf_explained_var: 0.3183409571647644
      vf_loss: 40.099082946777344
    num_steps_sampled: 390000
    num_steps_trained: 390000
    wait_time_ms: 92.944
  iterations_since_restore: 78
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 903.3962509632111
  time_this_iter_s: 11.290332555770874
  time_total_s: 903.3962509632111
  timestamp: 1593994890
  timesteps_since_restore: 390000
  timesteps_this_iter: 5000
  timesteps_total: 390000
  training_iteration: 78
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 903 s, 78 iter, 390000 ts, 507 rew

agent-1: 96.0
agent-2: 140.0
agent-3: 118.0
agent-4: 121.0
agent-5: 141.0
Sum Reward: 616.0
Avg Reward: 123.2
Min Reward: 96.0
Gini Coefficient: 0.07272727272727272
20:20 Ratio: 1.46875
Max-min Ratio: 1.46875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-21-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 825.0
  episode_reward_mean: 508.85897435897436
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 78
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.2
    dispatch_time_ms: 9.585
    learner:
      cur_lr: 0.0013340259902179241
      grad_gnorm: 40.0000114440918
      policy_entropy: 19.65312385559082
      policy_loss: -12.319905281066895
      var_gnorm: 30.745254516601562
      vf_explained_var: 0.29521000385284424
      vf_loss: 23.237579345703125
    num_steps_sampled: 395000
    num_steps_trained: 395000
    wait_time_ms: 107.5
  iterations_since_restore: 79
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 914.5450661182404
  time_this_iter_s: 11.148815155029297
  time_total_s: 914.5450661182404
  timestamp: 1593994901
  timesteps_since_restore: 395000
  timesteps_this_iter: 5000
  timesteps_total: 395000
  training_iteration: 79
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 914 s, 79 iter, 395000 ts, 509 rew

agent-1: 100.0
agent-2: 121.0
agent-3: 116.0
agent-4: 139.0
agent-5: 106.0
Sum Reward: 582.0
Avg Reward: 116.4
Min Reward: 100.0
Gini Coefficient: 0.06391752577319587
20:20 Ratio: 1.39
Max-min Ratio: 1.39
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-21-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 825.0
  episode_reward_mean: 509.7848101265823
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 79
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.227
    dispatch_time_ms: 8.002
    learner:
      cur_lr: 0.001333693042397499
      grad_gnorm: 40.000003814697266
      policy_entropy: 16.67732810974121
      policy_loss: -1.7138962745666504
      var_gnorm: 30.806819915771484
      vf_explained_var: 0.6433039903640747
      vf_loss: 28.166399002075195
    num_steps_sampled: 400000
    num_steps_trained: 400000
    wait_time_ms: 108.05
  iterations_since_restore: 80
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 926.2585110664368
  time_this_iter_s: 11.713444948196411
  time_total_s: 926.2585110664368
  timestamp: 1593994913
  timesteps_since_restore: 400000
  timesteps_this_iter: 5000
  timesteps_total: 400000
  training_iteration: 80
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 926 s, 80 iter, 400000 ts, 510 rew

agent-1: 84.0
agent-2: 103.0
agent-3: 91.0
agent-4: 124.0
agent-5: 123.0
Sum Reward: 525.0
Avg Reward: 105.0
Min Reward: 84.0
Gini Coefficient: 0.08533333333333333
20:20 Ratio: 1.4761904761904763
Max-min Ratio: 1.4761904761904763
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-22-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 825.0
  episode_reward_mean: 509.975
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 80
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.086
    dispatch_time_ms: 6.777
    learner:
      cur_lr: 0.0013333599781617522
      grad_gnorm: 40.0
      policy_entropy: 14.817329406738281
      policy_loss: 21.822664260864258
      var_gnorm: 30.86524200439453
      vf_explained_var: 0.7342264652252197
      vf_loss: 98.1064224243164
    num_steps_sampled: 405000
    num_steps_trained: 405000
    wait_time_ms: 106.439
  iterations_since_restore: 81
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 937.6745758056641
  time_this_iter_s: 11.416064739227295
  time_total_s: 937.6745758056641
  timestamp: 1593994924
  timesteps_since_restore: 405000
  timesteps_this_iter: 5000
  timesteps_total: 405000
  training_iteration: 81
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 937 s, 81 iter, 405000 ts, 510 rew

agent-1: 112.0
agent-2: 143.0
agent-3: 112.0
agent-4: 108.0
agent-5: 134.0
Sum Reward: 609.0
Avg Reward: 121.8
Min Reward: 108.0
Gini Coefficient: 0.060426929392446635
20:20 Ratio: 1.3240740740740742
Max-min Ratio: 1.3240740740740742
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-22-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 825.0
  episode_reward_mean: 511.1975308641975
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 81
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.972
    dispatch_time_ms: 7.012
    learner:
      cur_lr: 0.0013330270303413272
      grad_gnorm: 39.99994659423828
      policy_entropy: 31.145484924316406
      policy_loss: 0.01802074909210205
      var_gnorm: 30.990625381469727
      vf_explained_var: 0.8490791320800781
      vf_loss: 10.592520713806152
    num_steps_sampled: 410000
    num_steps_trained: 410000
    wait_time_ms: 105.258
  iterations_since_restore: 82
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 949.3420598506927
  time_this_iter_s: 11.667484045028687
  time_total_s: 949.3420598506927
  timestamp: 1593994936
  timesteps_since_restore: 410000
  timesteps_this_iter: 5000
  timesteps_total: 410000
  training_iteration: 82
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 949 s, 82 iter, 410000 ts, 511 rew

agent-1: 69.0
agent-2: 78.0
agent-3: 100.0
agent-4: 102.0
agent-5: 85.0
Sum Reward: 434.0
Avg Reward: 86.8
Min Reward: 69.0
Gini Coefficient: 0.08110599078341015
20:20 Ratio: 1.4782608695652173
Max-min Ratio: 1.4782608695652173
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-22-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 825.0
  episode_reward_mean: 510.2560975609756
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 82
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.423
    dispatch_time_ms: 12.438
    learner:
      cur_lr: 0.0013326939661055803
      grad_gnorm: 39.99999237060547
      policy_entropy: 23.78327178955078
      policy_loss: 3.0370140075683594
      var_gnorm: 31.066118240356445
      vf_explained_var: -1.0
      vf_loss: 47.91825866699219
    num_steps_sampled: 415000
    num_steps_trained: 415000
    wait_time_ms: 99.69
  iterations_since_restore: 83
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 960.6070337295532
  time_this_iter_s: 11.264973878860474
  time_total_s: 960.6070337295532
  timestamp: 1593994947
  timesteps_since_restore: 415000
  timesteps_this_iter: 5000
  timesteps_total: 415000
  training_iteration: 83
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 960 s, 83 iter, 415000 ts, 510 rew

agent-1: 81.0
agent-2: 118.0
agent-3: 108.0
agent-4: 97.0
agent-5: 141.0
Sum Reward: 545.0
Avg Reward: 109.0
Min Reward: 81.0
Gini Coefficient: 0.10348623853211009
20:20 Ratio: 1.7407407407407407
Max-min Ratio: 1.7407407407407407
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-22-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 825.0
  episode_reward_mean: 510.67469879518075
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 83
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.012
    dispatch_time_ms: 7.624
    learner:
      cur_lr: 0.0013323610182851553
      grad_gnorm: 40.00000762939453
      policy_entropy: 15.804064750671387
      policy_loss: -13.005645751953125
      var_gnorm: 31.171186447143555
      vf_explained_var: 0.35929083824157715
      vf_loss: 52.51438903808594
    num_steps_sampled: 420000
    num_steps_trained: 420000
    wait_time_ms: 100.952
  iterations_since_restore: 84
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 971.9058973789215
  time_this_iter_s: 11.298863649368286
  time_total_s: 971.9058973789215
  timestamp: 1593994959
  timesteps_since_restore: 420000
  timesteps_this_iter: 5000
  timesteps_total: 420000
  training_iteration: 84
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 971 s, 84 iter, 420000 ts, 511 rew

agent-1: 131.0
agent-2: 134.0
agent-3: 152.0
agent-4: 157.0
agent-5: 151.0
Sum Reward: 725.0
Avg Reward: 145.0
Min Reward: 131.0
Gini Coefficient: 0.038620689655172416
20:20 Ratio: 1.1984732824427482
Max-min Ratio: 1.1984732824427482
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-22-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 825.0
  episode_reward_mean: 513.2261904761905
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 84
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.808
    dispatch_time_ms: 10.424
    learner:
      cur_lr: 0.0013320279540494084
      grad_gnorm: 40.0
      policy_entropy: 28.040803909301758
      policy_loss: 0.4333137273788452
      var_gnorm: 31.29587173461914
      vf_explained_var: 0.43118542432785034
      vf_loss: 41.88966751098633
    num_steps_sampled: 425000
    num_steps_trained: 425000
    wait_time_ms: 103.994
  iterations_since_restore: 85
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 983.2403481006622
  time_this_iter_s: 11.334450721740723
  time_total_s: 983.2403481006622
  timestamp: 1593994970
  timesteps_since_restore: 425000
  timesteps_this_iter: 5000
  timesteps_total: 425000
  training_iteration: 85
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 983 s, 85 iter, 425000 ts, 513 rew

agent-1: 75.0
agent-2: 85.0
agent-3: 87.0
agent-4: 88.0
agent-5: 84.0
Sum Reward: 419.0
Avg Reward: 83.8
Min Reward: 75.0
Gini Coefficient: 0.02768496420047733
20:20 Ratio: 1.1733333333333333
Max-min Ratio: 1.1733333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-23-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 825.0
  episode_reward_mean: 512.1176470588235
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 85
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.296
    dispatch_time_ms: 10.364
    learner:
      cur_lr: 0.0013316950062289834
      grad_gnorm: 39.999996185302734
      policy_entropy: 19.309326171875
      policy_loss: 16.91813850402832
      var_gnorm: 31.304119110107422
      vf_explained_var: 0.30750972032546997
      vf_loss: 35.03214645385742
    num_steps_sampled: 430000
    num_steps_trained: 430000
    wait_time_ms: 101.556
  iterations_since_restore: 86
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 994.4712543487549
  time_this_iter_s: 11.230906248092651
  time_total_s: 994.4712543487549
  timestamp: 1593994981
  timesteps_since_restore: 430000
  timesteps_this_iter: 5000
  timesteps_total: 430000
  training_iteration: 86
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 994 s, 86 iter, 430000 ts, 512 rew

agent-1: 169.0
agent-2: 155.0
agent-3: 149.0
agent-4: 194.0
agent-5: 161.0
Sum Reward: 828.0
Avg Reward: 165.6
Min Reward: 149.0
Gini Coefficient: 0.050241545893719805
20:20 Ratio: 1.3020134228187918
Max-min Ratio: 1.3020134228187918
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-23-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 515.7906976744187
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 86
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.172
    dispatch_time_ms: 9.061
    learner:
      cur_lr: 0.0013313619419932365
      grad_gnorm: 39.999996185302734
      policy_entropy: 16.20024871826172
      policy_loss: 1.2824641466140747
      var_gnorm: 31.41250228881836
      vf_explained_var: -1.0
      vf_loss: 148.54237365722656
    num_steps_sampled: 435000
    num_steps_trained: 435000
    wait_time_ms: 107.385
  iterations_since_restore: 87
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1005.6152756214142
  time_this_iter_s: 11.144021272659302
  time_total_s: 1005.6152756214142
  timestamp: 1593994993
  timesteps_since_restore: 435000
  timesteps_this_iter: 5000
  timesteps_total: 435000
  training_iteration: 87
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1005 s, 87 iter, 435000 ts, 516 rew

agent-1: 129.0
agent-2: 117.0
agent-3: 112.0
agent-4: 127.0
agent-5: 120.0
Sum Reward: 605.0
Avg Reward: 121.0
Min Reward: 112.0
Gini Coefficient: 0.02909090909090909
20:20 Ratio: 1.1517857142857142
Max-min Ratio: 1.1517857142857142
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-23-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 516.816091954023
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 87
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.907
    dispatch_time_ms: 8.46
    learner:
      cur_lr: 0.0013310289941728115
      grad_gnorm: 6.093454360961914
      policy_entropy: 37.88349533081055
      policy_loss: -1.4684457778930664
      var_gnorm: 31.59962272644043
      vf_explained_var: -1.0
      vf_loss: 0.14414426684379578
    num_steps_sampled: 440000
    num_steps_trained: 440000
    wait_time_ms: 108.233
  iterations_since_restore: 88
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1017.4810423851013
  time_this_iter_s: 11.865766763687134
  time_total_s: 1017.4810423851013
  timestamp: 1593995004
  timesteps_since_restore: 440000
  timesteps_this_iter: 5000
  timesteps_total: 440000
  training_iteration: 88
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1017 s, 88 iter, 440000 ts, 517 rew

agent-1: 83.0
agent-2: 74.0
agent-3: 71.0
agent-4: 76.0
agent-5: 96.0
Sum Reward: 400.0
Avg Reward: 80.0
Min Reward: 71.0
Gini Coefficient: 0.059
20:20 Ratio: 1.352112676056338
Max-min Ratio: 1.352112676056338
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-23-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 515.4886363636364
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 88
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.593
    dispatch_time_ms: 6.448
    learner:
      cur_lr: 0.0013306960463523865
      grad_gnorm: 10.131717681884766
      policy_entropy: 30.947839736938477
      policy_loss: -2.0840160846710205
      var_gnorm: 31.682300567626953
      vf_explained_var: 0.0
      vf_loss: 0.12213292717933655
    num_steps_sampled: 445000
    num_steps_trained: 445000
    wait_time_ms: 114.629
  iterations_since_restore: 89
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1029.1068360805511
  time_this_iter_s: 11.625793695449829
  time_total_s: 1029.1068360805511
  timestamp: 1593995016
  timesteps_since_restore: 445000
  timesteps_this_iter: 5000
  timesteps_total: 445000
  training_iteration: 89
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1029 s, 89 iter, 445000 ts, 515 rew

agent-1: 97.0
agent-2: 86.0
agent-3: 78.0
agent-4: 82.0
agent-5: 70.0
Sum Reward: 413.0
Avg Reward: 82.6
Min Reward: 70.0
Gini Coefficient: 0.06004842615012106
20:20 Ratio: 1.3857142857142857
Max-min Ratio: 1.3857142857142857
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-23-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 514.3370786516854
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 89
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.22
    dispatch_time_ms: 9.416
    learner:
      cur_lr: 0.0013303629821166396
      grad_gnorm: 40.0
      policy_entropy: 29.074636459350586
      policy_loss: -13.226053237915039
      var_gnorm: 31.73282814025879
      vf_explained_var: 0.9838246703147888
      vf_loss: 17.80600929260254
    num_steps_sampled: 450000
    num_steps_trained: 450000
    wait_time_ms: 103.494
  iterations_since_restore: 90
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1040.8022770881653
  time_this_iter_s: 11.695441007614136
  time_total_s: 1040.8022770881653
  timestamp: 1593995028
  timesteps_since_restore: 450000
  timesteps_this_iter: 5000
  timesteps_total: 450000
  training_iteration: 90
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1040 s, 90 iter, 450000 ts, 514 rew

agent-1: 123.0
agent-2: 118.0
agent-3: 147.0
agent-4: 118.0
agent-5: 125.0
Sum Reward: 631.0
Avg Reward: 126.2
Min Reward: 118.0
Gini Coefficient: 0.04120443740095087
20:20 Ratio: 1.2457627118644068
Max-min Ratio: 1.2457627118644068
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-23-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 515.6333333333333
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 90
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.755
    dispatch_time_ms: 9.858
    learner:
      cur_lr: 0.0013300300342962146
      grad_gnorm: 40.000003814697266
      policy_entropy: 17.936410903930664
      policy_loss: 0.46638888120651245
      var_gnorm: 31.8886661529541
      vf_explained_var: 0.5138349533081055
      vf_loss: 48.16061019897461
    num_steps_sampled: 455000
    num_steps_trained: 455000
    wait_time_ms: 94.817
  iterations_since_restore: 91
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1052.022770166397
  time_this_iter_s: 11.220493078231812
  time_total_s: 1052.022770166397
  timestamp: 1593995039
  timesteps_since_restore: 455000
  timesteps_this_iter: 5000
  timesteps_total: 455000
  training_iteration: 91
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1052 s, 91 iter, 455000 ts, 516 rew

agent-1: 112.0
agent-2: 106.0
agent-3: 112.0
agent-4: 97.0
agent-5: 92.0
Sum Reward: 519.0
Avg Reward: 103.8
Min Reward: 92.0
Gini Coefficient: 0.04238921001926782
20:20 Ratio: 1.2173913043478262
Max-min Ratio: 1.2173913043478262
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-24-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 515.6703296703297
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 91
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.48
    dispatch_time_ms: 9.676
    learner:
      cur_lr: 0.0013296969700604677
      grad_gnorm: 40.00000762939453
      policy_entropy: 26.06083106994629
      policy_loss: -4.574402809143066
      var_gnorm: 31.98556900024414
      vf_explained_var: 0.9543951749801636
      vf_loss: 0.6883125901222229
    num_steps_sampled: 460000
    num_steps_trained: 460000
    wait_time_ms: 90.723
  iterations_since_restore: 92
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1063.8414249420166
  time_this_iter_s: 11.818654775619507
  time_total_s: 1063.8414249420166
  timestamp: 1593995051
  timesteps_since_restore: 460000
  timesteps_this_iter: 5000
  timesteps_total: 460000
  training_iteration: 92
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1063 s, 92 iter, 460000 ts, 516 rew

agent-1: 99.0
agent-2: 113.0
agent-3: 114.0
agent-4: 112.0
agent-5: 75.0
Sum Reward: 513.0
Avg Reward: 102.6
Min Reward: 75.0
Gini Coefficient: 0.07173489278752436
20:20 Ratio: 1.52
Max-min Ratio: 1.52
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-24-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 515.6413043478261
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 92
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.075
    dispatch_time_ms: 10.41
    learner:
      cur_lr: 0.0013293640222400427
      grad_gnorm: 40.000003814697266
      policy_entropy: 28.990455627441406
      policy_loss: -16.16978645324707
      var_gnorm: 32.04008483886719
      vf_explained_var: -1.0
      vf_loss: 45.62552261352539
    num_steps_sampled: 465000
    num_steps_trained: 465000
    wait_time_ms: 105.621
  iterations_since_restore: 93
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1075.131459236145
  time_this_iter_s: 11.290034294128418
  time_total_s: 1075.131459236145
  timestamp: 1593995062
  timesteps_since_restore: 465000
  timesteps_this_iter: 5000
  timesteps_total: 465000
  training_iteration: 93
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1075 s, 93 iter, 465000 ts, 516 rew

agent-1: 106.0
agent-2: 128.0
agent-3: 118.0
agent-4: 115.0
agent-5: 108.0
Sum Reward: 575.0
Avg Reward: 115.0
Min Reward: 106.0
Gini Coefficient: 0.03756521739130435
20:20 Ratio: 1.2075471698113207
Max-min Ratio: 1.2075471698113207
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-24-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 516.2795698924731
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 93
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.276
    dispatch_time_ms: 8.522
    learner:
      cur_lr: 0.0013290309580042958
      grad_gnorm: 36.84068298339844
      policy_entropy: 28.12371826171875
      policy_loss: 4.790383338928223
      var_gnorm: 32.114383697509766
      vf_explained_var: 0.0833706259727478
      vf_loss: 9.792170524597168
    num_steps_sampled: 470000
    num_steps_trained: 470000
    wait_time_ms: 104.519
  iterations_since_restore: 94
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1087.1716809272766
  time_this_iter_s: 12.040221691131592
  time_total_s: 1087.1716809272766
  timestamp: 1593995074
  timesteps_since_restore: 470000
  timesteps_this_iter: 5000
  timesteps_total: 470000
  training_iteration: 94
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1087 s, 94 iter, 470000 ts, 516 rew

W0705 20:24:38.529732  2378 node_manager.cc:250] Last heartbeat was sent 1215 ms ago 
W0705 20:25:01.290823  2378 task_dependency_manager.cc:259] Task lease to renew has already expired by -1410ms
W0705 20:25:01.290982  2378 task_dependency_manager.cc:259] Task lease to renew has already expired by -400ms
W0705 20:25:01.291044  2378 task_dependency_manager.cc:259] Task lease to renew has already expired by -95ms
W0705 20:25:02.108837  2378 client_connection.cc:255] [worker]ProcessMessage with type 16 took 783 ms.
W0705 20:25:02.143761  2378 node_manager.cc:250] Last heartbeat was sent 14729 ms ago 
W0705 20:25:04.354310  2378 client_connection.cc:255] [worker]ProcessMessage with type 16 took 128 ms.
W0705 20:25:04.430621  2378 node_manager.cc:250] Last heartbeat was sent 2282 ms ago 
W0705 20:25:05.567131  2378 node_manager.cc:250] Last heartbeat was sent 1142 ms ago 
W0705 20:25:10.237378  2378 client_connection.cc:255] [worker]ProcessMessage with type 16 took 447 ms.
W0705 20:25:10.272635  2378 node_manager.cc:250] Last heartbeat was sent 535 ms ago 
W0705 20:25:11.753005  2378 client_connection.cc:255] [worker]ProcessMessage with type 16 took 539 ms.
W0705 20:25:12.212950  2378 client_connection.cc:255] [worker]ProcessMessage with type 19 took 459 ms.
W0705 20:25:13.058668  2378 node_manager.cc:250] Last heartbeat was sent 2786 ms ago 
W0705 20:25:23.245893  2378 client_connection.cc:255] [worker]ProcessMessage with type 19 took 416 ms.
W0705 20:25:23.312577  2378 task_dependency_manager.cc:259] Task lease to renew has already expired by -3523ms
W0705 20:25:23.312666  2378 task_dependency_manager.cc:259] Task lease to renew has already expired by -3075ms
W0705 20:25:23.363931  2378 node_manager.cc:250] Last heartbeat was sent 10305 ms ago 
W0705 20:25:25.891010  2378 client_connection.cc:255] [worker]ProcessMessage with type 8 took 336 ms.
W0705 20:25:25.891176  2378 node_manager.cc:250] Last heartbeat was sent 2528 ms ago 
agent-1: 98.0
agent-2: 107.0
agent-3: 113.0
agent-4: 106.0
agent-5: 122.0
Sum Reward: 546.0
Avg Reward: 109.2
Min Reward: 98.0
Gini Coefficient: 0.040293040293040296
20:20 Ratio: 1.2448979591836735
Max-min Ratio: 1.2448979591836735
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-25-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 516.5957446808511
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 94
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.828
    dispatch_time_ms: 11.145
    learner:
      cur_lr: 0.0013286980101838708
      grad_gnorm: 40.000003814697266
      policy_entropy: 26.090198516845703
      policy_loss: 0.198326975107193
      var_gnorm: 32.15321731567383
      vf_explained_var: -0.6136611700057983
      vf_loss: 83.76295471191406
    num_steps_sampled: 475000
    num_steps_trained: 475000
    wait_time_ms: 100.577
  iterations_since_restore: 95
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1151.966225385666
  time_this_iter_s: 64.79454445838928
  time_total_s: 1151.966225385666
  timestamp: 1593995139
  timesteps_since_restore: 475000
  timesteps_this_iter: 5000
  timesteps_total: 475000
  training_iteration: 95
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1151 s, 95 iter, 475000 ts, 517 rew

agent-1: 102.0
agent-2: 94.0
agent-3: 101.0
agent-4: 91.0
agent-5: 82.0
Sum Reward: 470.0
Avg Reward: 94.0
Min Reward: 82.0
Gini Coefficient: 0.0425531914893617
20:20 Ratio: 1.2439024390243902
Max-min Ratio: 1.2439024390243902
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-25-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 516.1052631578947
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 95
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.827
    dispatch_time_ms: 9.034
    learner:
      cur_lr: 0.001328364945948124
      grad_gnorm: 40.00000762939453
      policy_entropy: 18.223979949951172
      policy_loss: 9.074763298034668
      var_gnorm: 32.23713302612305
      vf_explained_var: -0.10074937343597412
      vf_loss: 54.91486358642578
    num_steps_sampled: 480000
    num_steps_trained: 480000
    wait_time_ms: 103.352
  iterations_since_restore: 96
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1163.416734457016
  time_this_iter_s: 11.450509071350098
  time_total_s: 1163.416734457016
  timestamp: 1593995158
  timesteps_since_restore: 480000
  timesteps_this_iter: 5000
  timesteps_total: 480000
  training_iteration: 96
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1163 s, 96 iter, 480000 ts, 516 rew

agent-1: 132.0
agent-2: 94.0
agent-3: 91.0
agent-4: 112.0
agent-5: 93.0
Sum Reward: 522.0
Avg Reward: 104.4
Min Reward: 91.0
Gini Coefficient: 0.07739463601532567
20:20 Ratio: 1.4505494505494505
Max-min Ratio: 1.4505494505494505
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-26-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 516.1666666666666
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 96
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.333
    dispatch_time_ms: 7.471
    learner:
      cur_lr: 0.001328031998127699
      grad_gnorm: 40.000003814697266
      policy_entropy: 16.25778579711914
      policy_loss: -33.12685775756836
      var_gnorm: 32.31135940551758
      vf_explained_var: -1.0
      vf_loss: 200.6268310546875
    num_steps_sampled: 485000
    num_steps_trained: 485000
    wait_time_ms: 105.081
  iterations_since_restore: 97
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1174.1401543617249
  time_this_iter_s: 10.723419904708862
  time_total_s: 1174.1401543617249
  timestamp: 1593995169
  timesteps_since_restore: 485000
  timesteps_this_iter: 5000
  timesteps_total: 485000
  training_iteration: 97
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1174 s, 97 iter, 485000 ts, 516 rew

agent-1: 130.0
agent-2: 116.0
agent-3: 125.0
agent-4: 124.0
agent-5: 101.0
Sum Reward: 596.0
Avg Reward: 119.2
Min Reward: 101.0
Gini Coefficient: 0.04496644295302014
20:20 Ratio: 1.2871287128712872
Max-min Ratio: 1.2871287128712872
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-26-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 516.9896907216495
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 97
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.804
    dispatch_time_ms: 11.087
    learner:
      cur_lr: 0.0013276990503072739
      grad_gnorm: 40.0
      policy_entropy: 13.398980140686035
      policy_loss: 4.997044086456299
      var_gnorm: 32.42042541503906
      vf_explained_var: 0.10704565048217773
      vf_loss: 36.73305892944336
    num_steps_sampled: 490000
    num_steps_trained: 490000
    wait_time_ms: 98.984
  iterations_since_restore: 98
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1186.2592618465424
  time_this_iter_s: 12.119107484817505
  time_total_s: 1186.2592618465424
  timestamp: 1593995181
  timesteps_since_restore: 490000
  timesteps_this_iter: 5000
  timesteps_total: 490000
  training_iteration: 98
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1186 s, 98 iter, 490000 ts, 517 rew

agent-1: 98.0
agent-2: 94.0
agent-3: 99.0
agent-4: 105.0
agent-5: 105.0
Sum Reward: 501.0
Avg Reward: 100.2
Min Reward: 94.0
Gini Coefficient: 0.02315369261477046
20:20 Ratio: 1.1170212765957446
Max-min Ratio: 1.1170212765957446
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-26-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 516.8265306122449
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 98
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.785
    dispatch_time_ms: 12.186
    learner:
      cur_lr: 0.001327365986071527
      grad_gnorm: 40.00000762939453
      policy_entropy: 15.036107063293457
      policy_loss: 3.9579834938049316
      var_gnorm: 32.52607727050781
      vf_explained_var: 0.6733788251876831
      vf_loss: 122.13607025146484
    num_steps_sampled: 495000
    num_steps_trained: 495000
    wait_time_ms: 101.007
  iterations_since_restore: 99
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1197.3609774112701
  time_this_iter_s: 11.101715564727783
  time_total_s: 1197.3609774112701
  timestamp: 1593995192
  timesteps_since_restore: 495000
  timesteps_this_iter: 5000
  timesteps_total: 495000
  training_iteration: 99
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1197 s, 99 iter, 495000 ts, 517 rew

agent-1: 97.0
agent-2: 95.0
agent-3: 114.0
agent-4: 116.0
agent-5: 91.0
Sum Reward: 513.0
Avg Reward: 102.6
Min Reward: 91.0
Gini Coefficient: 0.05380116959064327
20:20 Ratio: 1.2747252747252746
Max-min Ratio: 1.2747252747252746
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-26-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 516.7878787878788
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 99
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.076
    dispatch_time_ms: 7.863
    learner:
      cur_lr: 0.001327033038251102
      grad_gnorm: 39.999996185302734
      policy_entropy: 10.151490211486816
      policy_loss: 15.48582935333252
      var_gnorm: 32.643516540527344
      vf_explained_var: 0.3323974609375
      vf_loss: 159.3455047607422
    num_steps_sampled: 500000
    num_steps_trained: 500000
    wait_time_ms: 104.674
  iterations_since_restore: 100
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1209.2026762962341
  time_this_iter_s: 11.84169888496399
  time_total_s: 1209.2026762962341
  timestamp: 1593995204
  timesteps_since_restore: 500000
  timesteps_this_iter: 5000
  timesteps_total: 500000
  training_iteration: 100
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1209 s, 100 iter, 500000 ts, 517 rew

agent-1: 159.0
agent-2: 122.0
agent-3: 133.0
agent-4: 133.0
agent-5: 131.0
Sum Reward: 678.0
Avg Reward: 135.6
Min Reward: 122.0
Gini Coefficient: 0.044837758112094395
20:20 Ratio: 1.3032786885245902
Max-min Ratio: 1.3032786885245902
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-26-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 518.4
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 100
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.574
    dispatch_time_ms: 9.777
    learner:
      cur_lr: 0.0013266999740153551
      grad_gnorm: 39.999996185302734
      policy_entropy: 15.793919563293457
      policy_loss: 18.807518005371094
      var_gnorm: 32.73088073730469
      vf_explained_var: 0.5936635732650757
      vf_loss: 84.91962432861328
    num_steps_sampled: 505000
    num_steps_trained: 505000
    wait_time_ms: 110.317
  iterations_since_restore: 101
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1220.1824140548706
  time_this_iter_s: 10.979737758636475
  time_total_s: 1220.1824140548706
  timestamp: 1593995216
  timesteps_since_restore: 505000
  timesteps_this_iter: 5000
  timesteps_total: 505000
  training_iteration: 101
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1220 s, 101 iter, 505000 ts, 518 rew

agent-1: 81.0
agent-2: 108.0
agent-3: 92.0
agent-4: 97.0
agent-5: 109.0
Sum Reward: 487.0
Avg Reward: 97.4
Min Reward: 81.0
Gini Coefficient: 0.05913757700205339
20:20 Ratio: 1.345679012345679
Max-min Ratio: 1.345679012345679
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-27-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 523.52
  episode_reward_min: -427.0
  episodes_this_iter: 1
  episodes_total: 101
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.055
    dispatch_time_ms: 7.604
    learner:
      cur_lr: 0.00132636702619493
      grad_gnorm: 16.543556213378906
      policy_entropy: 14.274383544921875
      policy_loss: 2.0107815265655518
      var_gnorm: 32.823158264160156
      vf_explained_var: 0.0
      vf_loss: 0.3510281443595886
    num_steps_sampled: 510000
    num_steps_trained: 510000
    wait_time_ms: 95.588
  iterations_since_restore: 102
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1232.186829328537
  time_this_iter_s: 12.004415273666382
  time_total_s: 1232.186829328537
  timestamp: 1593995228
  timesteps_since_restore: 510000
  timesteps_this_iter: 5000
  timesteps_total: 510000
  training_iteration: 102
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1232 s, 102 iter, 510000 ts, 524 rew

agent-1: 64.0
agent-2: 64.0
agent-3: 55.0
agent-4: 51.0
agent-5: 86.0
Sum Reward: 320.0
Avg Reward: 64.0
Min Reward: 51.0
Gini Coefficient: 0.09875
20:20 Ratio: 1.6862745098039216
Max-min Ratio: 1.6862745098039216
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-27-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 530.99
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 102
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.153
    dispatch_time_ms: 15.835
    learner:
      cur_lr: 0.0013260339619591832
      grad_gnorm: 40.00000762939453
      policy_entropy: 19.32036590576172
      policy_loss: -4.533219337463379
      var_gnorm: 32.87337112426758
      vf_explained_var: 0.32046908140182495
      vf_loss: 33.52313232421875
    num_steps_sampled: 515000
    num_steps_trained: 515000
    wait_time_ms: 89.799
  iterations_since_restore: 103
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1255.551457643509
  time_this_iter_s: 23.364628314971924
  time_total_s: 1255.551457643509
  timestamp: 1593995251
  timesteps_since_restore: 515000
  timesteps_this_iter: 5000
  timesteps_total: 515000
  training_iteration: 103
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1255 s, 103 iter, 515000 ts, 531 rew

agent-1: 108.0
agent-2: 106.0
agent-3: 110.0
agent-4: 95.0
agent-5: 117.0
Sum Reward: 536.0
Avg Reward: 107.2
Min Reward: 95.0
Gini Coefficient: 0.03582089552238806
20:20 Ratio: 1.231578947368421
Max-min Ratio: 1.231578947368421
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-27-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 530.41
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 103
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.942
    dispatch_time_ms: 19.559
    learner:
      cur_lr: 0.0013257010141387582
      grad_gnorm: 39.99997329711914
      policy_entropy: 13.65466594696045
      policy_loss: -14.438457489013672
      var_gnorm: 32.91715621948242
      vf_explained_var: 0.352542519569397
      vf_loss: 179.00775146484375
    num_steps_sampled: 520000
    num_steps_trained: 520000
    wait_time_ms: 81.913
  iterations_since_restore: 104
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1267.0562760829926
  time_this_iter_s: 11.504818439483643
  time_total_s: 1267.0562760829926
  timestamp: 1593995263
  timesteps_since_restore: 520000
  timesteps_this_iter: 5000
  timesteps_total: 520000
  training_iteration: 104
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1267 s, 104 iter, 520000 ts, 530 rew

agent-1: 158.0
agent-2: 134.0
agent-3: 167.0
agent-4: 164.0
agent-5: 151.0
Sum Reward: 774.0
Avg Reward: 154.8
Min Reward: 134.0
Gini Coefficient: 0.04082687338501292
20:20 Ratio: 1.2462686567164178
Max-min Ratio: 1.2462686567164178
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-27-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 532.03
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 104
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.799
    dispatch_time_ms: 15.314
    learner:
      cur_lr: 0.0013253679499030113
      grad_gnorm: 39.999996185302734
      policy_entropy: 14.91060733795166
      policy_loss: 25.252155303955078
      var_gnorm: 33.008872985839844
      vf_explained_var: -1.0
      vf_loss: 325.3476257324219
    num_steps_sampled: 525000
    num_steps_trained: 525000
    wait_time_ms: 102.911
  iterations_since_restore: 105
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1278.4130473136902
  time_this_iter_s: 11.356771230697632
  time_total_s: 1278.4130473136902
  timestamp: 1593995274
  timesteps_since_restore: 525000
  timesteps_this_iter: 5000
  timesteps_total: 525000
  training_iteration: 105
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1278 s, 105 iter, 525000 ts, 532 rew

agent-1: 110.0
agent-2: 91.0
agent-3: 101.0
agent-4: 111.0
agent-5: 117.0
Sum Reward: 530.0
Avg Reward: 106.0
Min Reward: 91.0
Gini Coefficient: 0.04679245283018868
20:20 Ratio: 1.2857142857142858
Max-min Ratio: 1.2857142857142858
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-28-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 530.17
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 105
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.4
    dispatch_time_ms: 12.994
    learner:
      cur_lr: 0.0013250350020825863
      grad_gnorm: 40.000003814697266
      policy_entropy: 22.788021087646484
      policy_loss: 7.30582857131958
      var_gnorm: 33.0846061706543
      vf_explained_var: -0.1634126901626587
      vf_loss: 45.02997589111328
    num_steps_sampled: 530000
    num_steps_trained: 530000
    wait_time_ms: 97.475
  iterations_since_restore: 106
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1289.8384628295898
  time_this_iter_s: 11.425415515899658
  time_total_s: 1289.8384628295898
  timestamp: 1593995285
  timesteps_since_restore: 530000
  timesteps_this_iter: 5000
  timesteps_total: 530000
  training_iteration: 106
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1289 s, 106 iter, 530000 ts, 530 rew

agent-1: 157.0
agent-2: 165.0
agent-3: 159.0
agent-4: 181.0
agent-5: 163.0
Sum Reward: 825.0
Avg Reward: 165.0
Min Reward: 157.0
Gini Coefficient: 0.02618181818181818
20:20 Ratio: 1.1528662420382165
Max-min Ratio: 1.1528662420382165
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-28-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 532.8
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 106
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.315
    dispatch_time_ms: 15.98
    learner:
      cur_lr: 0.0013247020542621613
      grad_gnorm: 39.999996185302734
      policy_entropy: 22.157636642456055
      policy_loss: -14.018691062927246
      var_gnorm: 33.151885986328125
      vf_explained_var: 0.09166979789733887
      vf_loss: 43.689876556396484
    num_steps_sampled: 535000
    num_steps_trained: 535000
    wait_time_ms: 96.764
  iterations_since_restore: 107
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1300.6281085014343
  time_this_iter_s: 10.789645671844482
  time_total_s: 1300.6281085014343
  timestamp: 1593995296
  timesteps_since_restore: 535000
  timesteps_this_iter: 5000
  timesteps_total: 535000
  training_iteration: 107
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1300 s, 107 iter, 535000 ts, 533 rew

agent-1: 132.0
agent-2: 158.0
agent-3: 131.0
agent-4: 136.0
agent-5: 138.0
Sum Reward: 695.0
Avg Reward: 139.0
Min Reward: 131.0
Gini Coefficient: 0.034532374100719423
20:20 Ratio: 1.2061068702290076
Max-min Ratio: 1.2061068702290076
W0705 20:28:27.384613  2378 client_connection.cc:255] [worker]ProcessMessage with type 8 took 147 ms.
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-28-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 535.55
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 107
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.336
    dispatch_time_ms: 16.919
    learner:
      cur_lr: 0.0013243689900264144
      grad_gnorm: 40.0
      policy_entropy: 19.028705596923828
      policy_loss: 13.842490196228027
      var_gnorm: 33.24050521850586
      vf_explained_var: 0.8628196120262146
      vf_loss: 35.123687744140625
    num_steps_sampled: 540000
    num_steps_trained: 540000
    wait_time_ms: 117.614
  iterations_since_restore: 108
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1311.1982114315033
  time_this_iter_s: 10.57010293006897
  time_total_s: 1311.1982114315033
  timestamp: 1593995307
  timesteps_since_restore: 540000
  timesteps_this_iter: 5000
  timesteps_total: 540000
  training_iteration: 108
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1311 s, 108 iter, 540000 ts, 536 rew

agent-1: 126.0
agent-2: 154.0
agent-3: 108.0
agent-4: 154.0
agent-5: 155.0
Sum Reward: 697.0
Avg Reward: 139.4
Min Reward: 108.0
Gini Coefficient: 0.07001434720229555
20:20 Ratio: 1.4351851851851851
Max-min Ratio: 1.4351851851851851
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-28-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 537.8
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 108
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.853
    dispatch_time_ms: 17.218
    learner:
      cur_lr: 0.0013240360422059894
      grad_gnorm: 40.0
      policy_entropy: 29.591588973999023
      policy_loss: -21.3597412109375
      var_gnorm: 33.257423400878906
      vf_explained_var: -0.09922182559967041
      vf_loss: 21.602375030517578
    num_steps_sampled: 545000
    num_steps_trained: 545000
    wait_time_ms: 97.486
  iterations_since_restore: 109
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1322.2325887680054
  time_this_iter_s: 11.034377336502075
  time_total_s: 1322.2325887680054
  timestamp: 1593995318
  timesteps_since_restore: 545000
  timesteps_this_iter: 5000
  timesteps_total: 545000
  training_iteration: 109
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1322 s, 109 iter, 545000 ts, 538 rew

W0705 20:28:46.107980  2378 node_manager.cc:250] Last heartbeat was sent 1559 ms ago 
agent-1: 95.0
agent-2: 139.0
agent-3: 86.0
agent-4: 106.0
agent-5: 130.0
Sum Reward: 556.0
Avg Reward: 111.2
Min Reward: 86.0
Gini Coefficient: 0.10143884892086331
20:20 Ratio: 1.6162790697674418
Max-min Ratio: 1.6162790697674418
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-29-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 539.01
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 109
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.933
    dispatch_time_ms: 17.492
    learner:
      cur_lr: 0.0013237029779702425
      grad_gnorm: 40.000003814697266
      policy_entropy: 19.12898826599121
      policy_loss: -1.5219298601150513
      var_gnorm: 33.32503890991211
      vf_explained_var: -1.0
      vf_loss: 8.849272727966309
    num_steps_sampled: 550000
    num_steps_trained: 550000
    wait_time_ms: 88.679
  iterations_since_restore: 110
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1349.9873464107513
  time_this_iter_s: 27.75475764274597
  time_total_s: 1349.9873464107513
  timestamp: 1593995346
  timesteps_since_restore: 550000
  timesteps_this_iter: 5000
  timesteps_total: 550000
  training_iteration: 110
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1349 s, 110 iter, 550000 ts, 539 rew

agent-1: 137.0
agent-2: 119.0
agent-3: 104.0
agent-4: 104.0
agent-5: 141.0
Sum Reward: 605.0
Avg Reward: 121.0
Min Reward: 104.0
Gini Coefficient: 0.07074380165289257
20:20 Ratio: 1.3557692307692308
Max-min Ratio: 1.3557692307692308
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-29-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 540.94
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 110
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.28
    dispatch_time_ms: 19.482
    learner:
      cur_lr: 0.0013233700301498175
      grad_gnorm: 40.0
      policy_entropy: 27.864599227905273
      policy_loss: -4.996595859527588
      var_gnorm: 33.38056945800781
      vf_explained_var: 0.36245977878570557
      vf_loss: 20.091651916503906
    num_steps_sampled: 555000
    num_steps_trained: 555000
    wait_time_ms: 97.204
  iterations_since_restore: 111
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1361.6403846740723
  time_this_iter_s: 11.653038263320923
  time_total_s: 1361.6403846740723
  timestamp: 1593995358
  timesteps_since_restore: 555000
  timesteps_this_iter: 5000
  timesteps_total: 555000
  training_iteration: 111
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1361 s, 111 iter, 555000 ts, 541 rew

agent-1: 150.0
agent-2: 134.0
agent-3: 139.0
agent-4: 134.0
agent-5: 142.0
Sum Reward: 699.0
Avg Reward: 139.8
Min Reward: 134.0
Gini Coefficient: 0.022889842632331903
20:20 Ratio: 1.1194029850746268
Max-min Ratio: 1.1194029850746268
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-29-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 542.44
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 111
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.791
    dispatch_time_ms: 24.392
    learner:
      cur_lr: 0.0013230369659140706
      grad_gnorm: 39.99998474121094
      policy_entropy: 22.570253372192383
      policy_loss: -39.3931770324707
      var_gnorm: 33.4631462097168
      vf_explained_var: 0.5159076452255249
      vf_loss: 184.3112335205078
    num_steps_sampled: 560000
    num_steps_trained: 560000
    wait_time_ms: 98.092
  iterations_since_restore: 112
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1373.3896145820618
  time_this_iter_s: 11.749229907989502
  time_total_s: 1373.3896145820618
  timestamp: 1593995369
  timesteps_since_restore: 560000
  timesteps_this_iter: 5000
  timesteps_total: 560000
  training_iteration: 112
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1373 s, 112 iter, 560000 ts, 542 rew

agent-1: 125.0
agent-2: 128.0
agent-3: 148.0
agent-4: 107.0
agent-5: 124.0
Sum Reward: 632.0
Avg Reward: 126.4
Min Reward: 107.0
Gini Coefficient: 0.05443037974683544
20:20 Ratio: 1.3831775700934579
Max-min Ratio: 1.3831775700934579
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-29-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 545.12
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 112
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.182
    dispatch_time_ms: 22.123
    learner:
      cur_lr: 0.0013227040180936456
      grad_gnorm: 40.0
      policy_entropy: 12.703910827636719
      policy_loss: 8.471392631530762
      var_gnorm: 33.52739715576172
      vf_explained_var: 0.04787653684616089
      vf_loss: 30.816457748413086
    num_steps_sampled: 565000
    num_steps_trained: 565000
    wait_time_ms: 96.854
  iterations_since_restore: 113
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1385.1519920825958
  time_this_iter_s: 11.762377500534058
  time_total_s: 1385.1519920825958
  timestamp: 1593995381
  timesteps_since_restore: 565000
  timesteps_this_iter: 5000
  timesteps_total: 565000
  training_iteration: 113
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1385 s, 113 iter, 565000 ts, 545 rew

agent-1: 131.0
agent-2: 132.0
agent-3: 137.0
agent-4: 123.0
agent-5: 134.0
Sum Reward: 657.0
Avg Reward: 131.4
Min Reward: 123.0
Gini Coefficient: 0.018873668188736682
20:20 Ratio: 1.113821138211382
Max-min Ratio: 1.113821138211382
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-29-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 546.66
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 113
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.382
    dispatch_time_ms: 7.357
    learner:
      cur_lr: 0.0013223709538578987
      grad_gnorm: 40.0
      policy_entropy: 30.44256019592285
      policy_loss: -12.10546588897705
      var_gnorm: 33.65407943725586
      vf_explained_var: 0.9925776124000549
      vf_loss: 7.182393550872803
    num_steps_sampled: 570000
    num_steps_trained: 570000
    wait_time_ms: 109.676
  iterations_since_restore: 114
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1396.9249365329742
  time_this_iter_s: 11.772944450378418
  time_total_s: 1396.9249365329742
  timestamp: 1593995393
  timesteps_since_restore: 570000
  timesteps_this_iter: 5000
  timesteps_total: 570000
  training_iteration: 114
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1396 s, 114 iter, 570000 ts, 547 rew

agent-1: 91.0
agent-2: 104.0
agent-3: 136.0
agent-4: 125.0
agent-5: 105.0
Sum Reward: 561.0
Avg Reward: 112.2
Min Reward: 91.0
Gini Coefficient: 0.07914438502673797
20:20 Ratio: 1.4945054945054945
Max-min Ratio: 1.4945054945054945
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-30-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 546.7
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 114
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.14
    dispatch_time_ms: 8.717
    learner:
      cur_lr: 0.0013220380060374737
      grad_gnorm: 11.122970581054688
      policy_entropy: 30.8382568359375
      policy_loss: -3.0381667613983154
      var_gnorm: 33.78416061401367
      vf_explained_var: 0.21346372365951538
      vf_loss: 5.6574296951293945
    num_steps_sampled: 575000
    num_steps_trained: 575000
    wait_time_ms: 102.365
  iterations_since_restore: 115
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1408.7795753479004
  time_this_iter_s: 11.854638814926147
  time_total_s: 1408.7795753479004
  timestamp: 1593995405
  timesteps_since_restore: 575000
  timesteps_this_iter: 5000
  timesteps_total: 575000
  training_iteration: 115
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1408 s, 115 iter, 575000 ts, 547 rew

agent-1: 114.0
agent-2: 91.0
agent-3: 110.0
agent-4: 133.0
agent-5: 112.0
Sum Reward: 560.0
Avg Reward: 112.0
Min Reward: 91.0
Gini Coefficient: 0.06285714285714286
20:20 Ratio: 1.4615384615384615
Max-min Ratio: 1.4615384615384615
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-30-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 546.18
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 115
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.669
    dispatch_time_ms: 12.93
    learner:
      cur_lr: 0.0013217049418017268
      grad_gnorm: 40.00000762939453
      policy_entropy: 20.286453247070312
      policy_loss: 44.83881378173828
      var_gnorm: 33.85026931762695
      vf_explained_var: -1.0
      vf_loss: 473.9382019042969
    num_steps_sampled: 580000
    num_steps_trained: 580000
    wait_time_ms: 95.009
  iterations_since_restore: 116
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1420.6940982341766
  time_this_iter_s: 11.914522886276245
  time_total_s: 1420.6940982341766
  timestamp: 1593995417
  timesteps_since_restore: 580000
  timesteps_this_iter: 5000
  timesteps_total: 580000
  training_iteration: 116
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1420 s, 116 iter, 580000 ts, 546 rew

agent-1: 113.0
agent-2: 117.0
agent-3: 104.0
agent-4: 117.0
agent-5: 119.0
Sum Reward: 570.0
Avg Reward: 114.0
Min Reward: 104.0
Gini Coefficient: 0.023859649122807018
20:20 Ratio: 1.1442307692307692
Max-min Ratio: 1.1442307692307692
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-30-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 547.16
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 116
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.864
    dispatch_time_ms: 24.68
    learner:
      cur_lr: 0.0013213719939813018
      grad_gnorm: 39.99998092651367
      policy_entropy: 28.182443618774414
      policy_loss: 35.18011474609375
      var_gnorm: 33.97056198120117
      vf_explained_var: 0.8004599809646606
      vf_loss: 83.43745422363281
    num_steps_sampled: 585000
    num_steps_trained: 585000
    wait_time_ms: 85.616
  iterations_since_restore: 117
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1432.3705847263336
  time_this_iter_s: 11.676486492156982
  time_total_s: 1432.3705847263336
  timestamp: 1593995429
  timesteps_since_restore: 585000
  timesteps_this_iter: 5000
  timesteps_total: 585000
  training_iteration: 117
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1432 s, 117 iter, 585000 ts, 547 rew

agent-1: 100.0
agent-2: 190.0
agent-3: 127.0
agent-4: 179.0
agent-5: 129.0
Sum Reward: 725.0
Avg Reward: 145.0
Min Reward: 100.0
Gini Coefficient: 0.128
20:20 Ratio: 1.9
Max-min Ratio: 1.9
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-30-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 550.08
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 117
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.904
    dispatch_time_ms: 34.386
    learner:
      cur_lr: 0.0013210390461608768
      grad_gnorm: 40.00000762939453
      policy_entropy: 18.71973991394043
      policy_loss: -2.181938648223877
      var_gnorm: 34.052146911621094
      vf_explained_var: 0.29829323291778564
      vf_loss: 72.38482666015625
    num_steps_sampled: 590000
    num_steps_trained: 590000
    wait_time_ms: 88.591
  iterations_since_restore: 118
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1443.7375748157501
  time_this_iter_s: 11.366990089416504
  time_total_s: 1443.7375748157501
  timestamp: 1593995440
  timesteps_since_restore: 590000
  timesteps_this_iter: 5000
  timesteps_total: 590000
  training_iteration: 118
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1443 s, 118 iter, 590000 ts, 550 rew

agent-1: 123.0
agent-2: 151.0
agent-3: 112.0
agent-4: 143.0
agent-5: 171.0
Sum Reward: 700.0
Avg Reward: 140.0
Min Reward: 112.0
Gini Coefficient: 0.08342857142857144
20:20 Ratio: 1.5267857142857142
Max-min Ratio: 1.5267857142857142
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-30-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 552.76
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 118
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.163
    dispatch_time_ms: 23.263
    learner:
      cur_lr: 0.0013207059819251299
      grad_gnorm: 40.0
      policy_entropy: 30.047500610351562
      policy_loss: -0.2536187171936035
      var_gnorm: 34.13406753540039
      vf_explained_var: 0.8878000378608704
      vf_loss: 21.8485107421875
    num_steps_sampled: 595000
    num_steps_trained: 595000
    wait_time_ms: 36.448
  iterations_since_restore: 119
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1455.7609791755676
  time_this_iter_s: 12.023404359817505
  time_total_s: 1455.7609791755676
  timestamp: 1593995452
  timesteps_since_restore: 595000
  timesteps_this_iter: 5000
  timesteps_total: 595000
  training_iteration: 119
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1455 s, 119 iter, 595000 ts, 553 rew

agent-1: 102.0
agent-2: 88.0
agent-3: 132.0
agent-4: 162.0
agent-5: 169.0
Sum Reward: 653.0
Avg Reward: 130.6
Min Reward: 88.0
Gini Coefficient: 0.13598774885145481
20:20 Ratio: 1.9204545454545454
Max-min Ratio: 1.9204545454545454
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-31-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 555.35
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 119
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.857
    dispatch_time_ms: 28.441
    learner:
      cur_lr: 0.0013203730341047049
      grad_gnorm: 40.000003814697266
      policy_entropy: 20.138660430908203
      policy_loss: 18.551082611083984
      var_gnorm: 34.193870544433594
      vf_explained_var: -0.4256443977355957
      vf_loss: 56.36341094970703
    num_steps_sampled: 600000
    num_steps_trained: 600000
    wait_time_ms: 81.252
  iterations_since_restore: 120
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1466.775800704956
  time_this_iter_s: 11.014821529388428
  time_total_s: 1466.775800704956
  timestamp: 1593995463
  timesteps_since_restore: 600000
  timesteps_this_iter: 5000
  timesteps_total: 600000
  training_iteration: 120
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1466 s, 120 iter, 600000 ts, 555 rew

agent-1: 130.0
agent-2: 145.0
agent-3: 98.0
agent-4: 131.0
agent-5: 162.0
Sum Reward: 666.0
Avg Reward: 133.2
Min Reward: 98.0
Gini Coefficient: 0.08588588588588589
20:20 Ratio: 1.653061224489796
Max-min Ratio: 1.653061224489796
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-31-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 556.35
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 120
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.938
    dispatch_time_ms: 26.195
    learner:
      cur_lr: 0.001320039969868958
      grad_gnorm: 39.99999237060547
      policy_entropy: 20.572832107543945
      policy_loss: 1.5844022035598755
      var_gnorm: 34.21335220336914
      vf_explained_var: 0.763693630695343
      vf_loss: 41.184383392333984
    num_steps_sampled: 605000
    num_steps_trained: 605000
    wait_time_ms: 88.97
  iterations_since_restore: 121
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1478.0973534584045
  time_this_iter_s: 11.321552753448486
  time_total_s: 1478.0973534584045
  timestamp: 1593995474
  timesteps_since_restore: 605000
  timesteps_this_iter: 5000
  timesteps_total: 605000
  training_iteration: 121
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1478 s, 121 iter, 605000 ts, 556 rew

agent-1: 144.0
agent-2: 160.0
agent-3: 140.0
agent-4: 124.0
agent-5: 158.0
Sum Reward: 726.0
Avg Reward: 145.2
Min Reward: 124.0
Gini Coefficient: 0.049586776859504134
20:20 Ratio: 1.2903225806451613
Max-min Ratio: 1.2903225806451613
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-31-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 558.95
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 121
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.516
    dispatch_time_ms: 30.729
    learner:
      cur_lr: 0.001319707022048533
      grad_gnorm: 40.0
      policy_entropy: 27.335485458374023
      policy_loss: -10.329374313354492
      var_gnorm: 34.248287200927734
      vf_explained_var: 0.3183525800704956
      vf_loss: 29.721988677978516
    num_steps_sampled: 610000
    num_steps_trained: 610000
    wait_time_ms: 84.376
  iterations_since_restore: 122
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1489.8210799694061
  time_this_iter_s: 11.723726511001587
  time_total_s: 1489.8210799694061
  timestamp: 1593995486
  timesteps_since_restore: 610000
  timesteps_this_iter: 5000
  timesteps_total: 610000
  training_iteration: 122
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1489 s, 122 iter, 610000 ts, 559 rew

agent-1: 83.0
agent-2: 115.0
agent-3: 83.0
agent-4: 103.0
agent-5: 109.0
Sum Reward: 493.0
Avg Reward: 98.6
Min Reward: 83.0
Gini Coefficient: 0.07302231237322515
20:20 Ratio: 1.3855421686746987
Max-min Ratio: 1.3855421686746987
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-31-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 559.57
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 122
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.659
    dispatch_time_ms: 26.591
    learner:
      cur_lr: 0.001319373957812786
      grad_gnorm: 39.99999237060547
      policy_entropy: 27.482418060302734
      policy_loss: 21.090219497680664
      var_gnorm: 34.357421875
      vf_explained_var: 0.6433460712432861
      vf_loss: 20.267276763916016
    num_steps_sampled: 615000
    num_steps_trained: 615000
    wait_time_ms: 86.872
  iterations_since_restore: 123
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1501.8005146980286
  time_this_iter_s: 11.979434728622437
  time_total_s: 1501.8005146980286
  timestamp: 1593995498
  timesteps_since_restore: 615000
  timesteps_this_iter: 5000
  timesteps_total: 615000
  training_iteration: 123
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1501 s, 123 iter, 615000 ts, 560 rew

agent-1: 128.0
agent-2: 153.0
agent-3: 143.0
agent-4: 131.0
agent-5: 141.0
Sum Reward: 696.0
Avg Reward: 139.2
Min Reward: 128.0
Gini Coefficient: 0.035632183908045977
20:20 Ratio: 1.1953125
Max-min Ratio: 1.1953125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-31-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 561.39
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 123
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.184
    dispatch_time_ms: 36.466
    learner:
      cur_lr: 0.001319041009992361
      grad_gnorm: 40.00000762939453
      policy_entropy: 21.0185604095459
      policy_loss: 2.056274652481079
      var_gnorm: 34.42295455932617
      vf_explained_var: 0.518731951713562
      vf_loss: 49.42703628540039
    num_steps_sampled: 620000
    num_steps_trained: 620000
    wait_time_ms: 66.77
  iterations_since_restore: 124
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1513.194911956787
  time_this_iter_s: 11.394397258758545
  time_total_s: 1513.194911956787
  timestamp: 1593995510
  timesteps_since_restore: 620000
  timesteps_this_iter: 5000
  timesteps_total: 620000
  training_iteration: 124
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1513 s, 124 iter, 620000 ts, 561 rew

agent-1: 152.0
agent-2: 178.0
agent-3: 130.0
agent-4: 138.0
agent-5: 138.0
Sum Reward: 736.0
Avg Reward: 147.2
Min Reward: 130.0
Gini Coefficient: 0.059782608695652176
20:20 Ratio: 1.3692307692307693
Max-min Ratio: 1.3692307692307693
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-32-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 563.82
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 124
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.512
    dispatch_time_ms: 27.107
    learner:
      cur_lr: 0.0013187079457566142
      grad_gnorm: 40.00000762939453
      policy_entropy: 12.582633972167969
      policy_loss: 31.766923904418945
      var_gnorm: 34.4588623046875
      vf_explained_var: -1.0
      vf_loss: 165.28794860839844
    num_steps_sampled: 625000
    num_steps_trained: 625000
    wait_time_ms: 88.462
  iterations_since_restore: 125
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1525.1312744617462
  time_this_iter_s: 11.936362504959106
  time_total_s: 1525.1312744617462
  timestamp: 1593995522
  timesteps_since_restore: 625000
  timesteps_this_iter: 5000
  timesteps_total: 625000
  training_iteration: 125
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1525 s, 125 iter, 625000 ts, 564 rew

agent-1: 154.0
agent-2: 135.0
agent-3: 132.0
agent-4: 176.0
agent-5: 150.0
Sum Reward: 747.0
Avg Reward: 149.4
Min Reward: 132.0
Gini Coefficient: 0.057295850066934405
20:20 Ratio: 1.3333333333333333
Max-min Ratio: 1.3333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-32-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 564.82
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 125
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.209
    dispatch_time_ms: 32.879
    learner:
      cur_lr: 0.0013183749979361892
      grad_gnorm: 40.0
      policy_entropy: 29.77264404296875
      policy_loss: -6.761585235595703
      var_gnorm: 34.50092697143555
      vf_explained_var: 0.8210080862045288
      vf_loss: 6.143789291381836
    num_steps_sampled: 630000
    num_steps_trained: 630000
    wait_time_ms: 54.255
  iterations_since_restore: 126
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1540.7010881900787
  time_this_iter_s: 15.56981372833252
  time_total_s: 1540.7010881900787
  timestamp: 1593995537
  timesteps_since_restore: 630000
  timesteps_this_iter: 5000
  timesteps_total: 630000
  training_iteration: 126
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1540 s, 126 iter, 630000 ts, 565 rew

agent-1: 92.0
agent-2: 82.0
agent-3: 55.0
agent-4: 87.0
agent-5: 89.0
Sum Reward: 405.0
Avg Reward: 81.0
Min Reward: 55.0
Gini Coefficient: 0.08
20:20 Ratio: 1.6727272727272726
Max-min Ratio: 1.6727272727272726
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-32-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 562.77
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 126
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.188
    dispatch_time_ms: 53.962
    learner:
      cur_lr: 0.0013180420501157641
      grad_gnorm: 40.0
      policy_entropy: 7.39504861831665
      policy_loss: 3.5261716842651367
      var_gnorm: 34.52500915527344
      vf_explained_var: 0.1885155439376831
      vf_loss: 54.116477966308594
    num_steps_sampled: 635000
    num_steps_trained: 635000
    wait_time_ms: 60.977
  iterations_since_restore: 127
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1552.3796656131744
  time_this_iter_s: 11.678577423095703
  time_total_s: 1552.3796656131744
  timestamp: 1593995550
  timesteps_since_restore: 635000
  timesteps_this_iter: 5000
  timesteps_total: 635000
  training_iteration: 127
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1552 s, 127 iter, 635000 ts, 563 rew

agent-1: 89.0
agent-2: 93.0
agent-3: 133.0
agent-4: 141.0
agent-5: 87.0
Sum Reward: 543.0
Avg Reward: 108.6
Min Reward: 87.0
Gini Coefficient: 0.11197053406998159
20:20 Ratio: 1.6206896551724137
Max-min Ratio: 1.6206896551724137
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-32-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 563.2
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 127
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.769
    dispatch_time_ms: 31.259
    learner:
      cur_lr: 0.0013177089858800173
      grad_gnorm: 16.65559196472168
      policy_entropy: 27.797515869140625
      policy_loss: -6.208145618438721
      var_gnorm: 34.61311721801758
      vf_explained_var: 0.9888574481010437
      vf_loss: 5.102536678314209
    num_steps_sampled: 640000
    num_steps_trained: 640000
    wait_time_ms: 90.24
  iterations_since_restore: 128
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1564.1400272846222
  time_this_iter_s: 11.760361671447754
  time_total_s: 1564.1400272846222
  timestamp: 1593995562
  timesteps_since_restore: 640000
  timesteps_this_iter: 5000
  timesteps_total: 640000
  training_iteration: 128
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1564 s, 128 iter, 640000 ts, 563 rew

agent-1: 84.0
agent-2: 131.0
agent-3: 121.0
agent-4: 93.0
agent-5: 132.0
Sum Reward: 561.0
Avg Reward: 112.2
Min Reward: 84.0
Gini Coefficient: 0.09554367201426026
20:20 Ratio: 1.5714285714285714
Max-min Ratio: 1.5714285714285714
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-32-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 564.48
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 128
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.671
    dispatch_time_ms: 22.621
    learner:
      cur_lr: 0.0013173760380595922
      grad_gnorm: 40.0
      policy_entropy: 23.18890380859375
      policy_loss: 19.14421844482422
      var_gnorm: 34.677303314208984
      vf_explained_var: 0.7589318752288818
      vf_loss: 46.577205657958984
    num_steps_sampled: 645000
    num_steps_trained: 645000
    wait_time_ms: 100.669
  iterations_since_restore: 129
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1576.4095780849457
  time_this_iter_s: 12.269550800323486
  time_total_s: 1576.4095780849457
  timestamp: 1593995574
  timesteps_since_restore: 645000
  timesteps_this_iter: 5000
  timesteps_total: 645000
  training_iteration: 129
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1576 s, 129 iter, 645000 ts, 564 rew

agent-1: 110.0
agent-2: 100.0
agent-3: 106.0
agent-4: 72.0
agent-5: 107.0
Sum Reward: 495.0
Avg Reward: 99.0
Min Reward: 72.0
Gini Coefficient: 0.06707070707070707
20:20 Ratio: 1.5277777777777777
Max-min Ratio: 1.5277777777777777
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-33-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 564.67
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 129
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.415
    dispatch_time_ms: 32.373
    learner:
      cur_lr: 0.0013170429738238454
      grad_gnorm: 40.0000114440918
      policy_entropy: 16.64539337158203
      policy_loss: 3.3502750396728516
      var_gnorm: 34.731773376464844
      vf_explained_var: 0.45954710245132446
      vf_loss: 48.23087692260742
    num_steps_sampled: 650000
    num_steps_trained: 650000
    wait_time_ms: 83.589
  iterations_since_restore: 130
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1588.056834936142
  time_this_iter_s: 11.647256851196289
  time_total_s: 1588.056834936142
  timestamp: 1593995586
  timesteps_since_restore: 650000
  timesteps_this_iter: 5000
  timesteps_total: 650000
  training_iteration: 130
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1588 s, 130 iter, 650000 ts, 565 rew

agent-1: 113.0
agent-2: 104.0
agent-3: 84.0
agent-4: 104.0
agent-5: 107.0
Sum Reward: 512.0
Avg Reward: 102.4
Min Reward: 84.0
Gini Coefficient: 0.04765625
20:20 Ratio: 1.3452380952380953
Max-min Ratio: 1.3452380952380953
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-33-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 564.39
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 130
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.816
    dispatch_time_ms: 29.05
    learner:
      cur_lr: 0.0013167100260034204
      grad_gnorm: 31.44145393371582
      policy_entropy: 25.04330062866211
      policy_loss: 7.373149394989014
      var_gnorm: 34.81129455566406
      vf_explained_var: -1.0
      vf_loss: 4.044620037078857
    num_steps_sampled: 655000
    num_steps_trained: 655000
    wait_time_ms: 82.284
  iterations_since_restore: 131
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1600.4691035747528
  time_this_iter_s: 12.41226863861084
  time_total_s: 1600.4691035747528
  timestamp: 1593995598
  timesteps_since_restore: 655000
  timesteps_this_iter: 5000
  timesteps_total: 655000
  training_iteration: 131
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1600 s, 131 iter, 655000 ts, 564 rew

agent-1: 105.0
agent-2: 79.0
agent-3: 95.0
agent-4: 134.0
agent-5: 125.0
Sum Reward: 538.0
Avg Reward: 107.6
Min Reward: 79.0
Gini Coefficient: 0.10408921933085502
20:20 Ratio: 1.6962025316455696
Max-min Ratio: 1.6962025316455696
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-33-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 565.0
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 131
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.81
    dispatch_time_ms: 29.529
    learner:
      cur_lr: 0.0013163769617676735
      grad_gnorm: 39.99999237060547
      policy_entropy: 27.967487335205078
      policy_loss: -5.6363959312438965
      var_gnorm: 34.832847595214844
      vf_explained_var: 0.4187356233596802
      vf_loss: 5.441295623779297
    num_steps_sampled: 660000
    num_steps_trained: 660000
    wait_time_ms: 79.205
  iterations_since_restore: 132
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1612.239520072937
  time_this_iter_s: 11.770416498184204
  time_total_s: 1612.239520072937
  timestamp: 1593995610
  timesteps_since_restore: 660000
  timesteps_this_iter: 5000
  timesteps_total: 660000
  training_iteration: 132
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1612 s, 132 iter, 660000 ts, 565 rew

agent-1: 105.0
agent-2: 93.0
agent-3: 75.0
agent-4: 71.0
agent-5: 74.0
Sum Reward: 418.0
Avg Reward: 83.6
Min Reward: 71.0
Gini Coefficient: 0.08325358851674641
20:20 Ratio: 1.4788732394366197
Max-min Ratio: 1.4788732394366197
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-33-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 564.6
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 132
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.67
    dispatch_time_ms: 32.659
    learner:
      cur_lr: 0.0013160440139472485
      grad_gnorm: 18.79008674621582
      policy_entropy: 19.842670440673828
      policy_loss: -1.7700728178024292
      var_gnorm: 34.87710189819336
      vf_explained_var: 0.0
      vf_loss: 0.4553736746311188
    num_steps_sampled: 665000
    num_steps_trained: 665000
    wait_time_ms: 92.844
  iterations_since_restore: 133
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1624.5818991661072
  time_this_iter_s: 12.342379093170166
  time_total_s: 1624.5818991661072
  timestamp: 1593995622
  timesteps_since_restore: 665000
  timesteps_this_iter: 5000
  timesteps_total: 665000
  training_iteration: 133
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1624 s, 133 iter, 665000 ts, 565 rew

agent-1: 154.0
agent-2: 123.0
agent-3: 125.0
agent-4: 132.0
agent-5: 136.0
Sum Reward: 670.0
Avg Reward: 134.0
Min Reward: 123.0
Gini Coefficient: 0.04358208955223881
20:20 Ratio: 1.2520325203252032
Max-min Ratio: 1.2520325203252032
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-33-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 565.89
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 133
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.102
    dispatch_time_ms: 24.597
    learner:
      cur_lr: 0.0013157109497115016
      grad_gnorm: 40.00001907348633
      policy_entropy: 13.581576347351074
      policy_loss: -8.071639060974121
      var_gnorm: 34.97599792480469
      vf_explained_var: 0.6167904138565063
      vf_loss: 74.156982421875
    num_steps_sampled: 670000
    num_steps_trained: 670000
    wait_time_ms: 97.938
  iterations_since_restore: 134
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1636.252051115036
  time_this_iter_s: 11.670151948928833
  time_total_s: 1636.252051115036
  timestamp: 1593995634
  timesteps_since_restore: 670000
  timesteps_this_iter: 5000
  timesteps_total: 670000
  training_iteration: 134
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1636 s, 134 iter, 670000 ts, 566 rew

agent-1: 94.0
agent-2: 96.0
agent-3: 94.0
agent-4: 94.0
agent-5: 95.0
Sum Reward: 473.0
Avg Reward: 94.6
Min Reward: 94.0
Gini Coefficient: 0.004228329809725159
20:20 Ratio: 1.0212765957446808
Max-min Ratio: 1.0212765957446808
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-34-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 565.03
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 134
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.85
    dispatch_time_ms: 39.541
    learner:
      cur_lr: 0.0013153780018910766
      grad_gnorm: 40.0
      policy_entropy: 22.809022903442383
      policy_loss: 24.830249786376953
      var_gnorm: 35.00897979736328
      vf_explained_var: 0.21246880292892456
      vf_loss: 39.03614044189453
    num_steps_sampled: 675000
    num_steps_trained: 675000
    wait_time_ms: 71.796
  iterations_since_restore: 135
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1649.1818294525146
  time_this_iter_s: 12.929778337478638
  time_total_s: 1649.1818294525146
  timestamp: 1593995647
  timesteps_since_restore: 675000
  timesteps_this_iter: 5000
  timesteps_total: 675000
  training_iteration: 135
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1649 s, 135 iter, 675000 ts, 565 rew

agent-1: 96.0
agent-2: 85.0
agent-3: 74.0
agent-4: 80.0
agent-5: 88.0
Sum Reward: 423.0
Avg Reward: 84.6
Min Reward: 74.0
Gini Coefficient: 0.0491725768321513
20:20 Ratio: 1.2972972972972974
Max-min Ratio: 1.2972972972972974
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-34-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 563.78
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 135
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.94
    dispatch_time_ms: 19.561
    learner:
      cur_lr: 0.0013150450540706515
      grad_gnorm: 40.0
      policy_entropy: 41.21768569946289
      policy_loss: -40.151756286621094
      var_gnorm: 35.094234466552734
      vf_explained_var: 0.3853685259819031
      vf_loss: 239.12939453125
    num_steps_sampled: 680000
    num_steps_trained: 680000
    wait_time_ms: 93.253
  iterations_since_restore: 136
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1660.779590845108
  time_this_iter_s: 11.597761392593384
  time_total_s: 1660.779590845108
  timestamp: 1593995659
  timesteps_since_restore: 680000
  timesteps_this_iter: 5000
  timesteps_total: 680000
  training_iteration: 136
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1660 s, 136 iter, 680000 ts, 564 rew

agent-1: 111.0
agent-2: 75.0
agent-3: 106.0
agent-4: 133.0
agent-5: 109.0
Sum Reward: 534.0
Avg Reward: 106.8
Min Reward: 75.0
Gini Coefficient: 0.09063670411985018
20:20 Ratio: 1.7733333333333334
Max-min Ratio: 1.7733333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-34-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 564.16
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 136
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.053
    dispatch_time_ms: 40.657
    learner:
      cur_lr: 0.0013147119898349047
      grad_gnorm: 39.999996185302734
      policy_entropy: 30.799802780151367
      policy_loss: 7.173569679260254
      var_gnorm: 35.14623260498047
      vf_explained_var: -0.9695483446121216
      vf_loss: 59.347434997558594
    num_steps_sampled: 685000
    num_steps_trained: 685000
    wait_time_ms: 67.553
  iterations_since_restore: 137
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1672.8470396995544
  time_this_iter_s: 12.067448854446411
  time_total_s: 1672.8470396995544
  timestamp: 1593995671
  timesteps_since_restore: 685000
  timesteps_this_iter: 5000
  timesteps_total: 685000
  training_iteration: 137
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1672 s, 137 iter, 685000 ts, 564 rew

agent-1: 121.0
agent-2: 144.0
agent-3: 126.0
agent-4: 100.0
agent-5: 123.0
Sum Reward: 614.0
Avg Reward: 122.8
Min Reward: 100.0
Gini Coefficient: 0.06058631921824104
20:20 Ratio: 1.44
Max-min Ratio: 1.44
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-34-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 564.06
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 137
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.099
    dispatch_time_ms: 30.302
    learner:
      cur_lr: 0.0013143790420144796
      grad_gnorm: 39.99998474121094
      policy_entropy: 37.62458038330078
      policy_loss: -16.585615158081055
      var_gnorm: 35.289920806884766
      vf_explained_var: -0.20612239837646484
      vf_loss: 42.419498443603516
    num_steps_sampled: 690000
    num_steps_trained: 690000
    wait_time_ms: 97.502
  iterations_since_restore: 138
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1684.5136528015137
  time_this_iter_s: 11.666613101959229
  time_total_s: 1684.5136528015137
  timestamp: 1593995682
  timesteps_since_restore: 690000
  timesteps_this_iter: 5000
  timesteps_total: 690000
  training_iteration: 138
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1684 s, 138 iter, 690000 ts, 564 rew

agent-1: 88.0
agent-2: 91.0
agent-3: 102.0
agent-4: 89.0
agent-5: 112.0
Sum Reward: 482.0
Avg Reward: 96.4
Min Reward: 88.0
Gini Coefficient: 0.05062240663900415
20:20 Ratio: 1.2727272727272727
Max-min Ratio: 1.2727272727272727
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-34-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 561.24
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 138
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.0
    dispatch_time_ms: 28.196
    learner:
      cur_lr: 0.0013140459777787328
      grad_gnorm: 39.999996185302734
      policy_entropy: 50.27908706665039
      policy_loss: -14.89888858795166
      var_gnorm: 35.471370697021484
      vf_explained_var: 0.22126704454421997
      vf_loss: 13.653692245483398
    num_steps_sampled: 695000
    num_steps_trained: 695000
    wait_time_ms: 75.0
  iterations_since_restore: 139
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1697.0684478282928
  time_this_iter_s: 12.554795026779175
  time_total_s: 1697.0684478282928
  timestamp: 1593995695
  timesteps_since_restore: 695000
  timesteps_this_iter: 5000
  timesteps_total: 695000
  training_iteration: 139
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1697 s, 139 iter, 695000 ts, 561 rew

agent-1: 105.0
agent-2: 113.0
agent-3: 112.0
agent-4: 115.0
agent-5: 101.0
Sum Reward: 546.0
Avg Reward: 109.2
Min Reward: 101.0
Gini Coefficient: 0.026373626373626374
20:20 Ratio: 1.1386138613861385
Max-min Ratio: 1.1386138613861385
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-35-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 562.04
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 139
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.706
    dispatch_time_ms: 32.692
    learner:
      cur_lr: 0.0013137130299583077
      grad_gnorm: 39.99999237060547
      policy_entropy: 39.7664909362793
      policy_loss: -127.04374694824219
      var_gnorm: 35.48811721801758
      vf_explained_var: -1.0
      vf_loss: 402.6490478515625
    num_steps_sampled: 700000
    num_steps_trained: 700000
    wait_time_ms: 90.505
  iterations_since_restore: 140
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1708.550496339798
  time_this_iter_s: 11.482048511505127
  time_total_s: 1708.550496339798
  timestamp: 1593995707
  timesteps_since_restore: 700000
  timesteps_this_iter: 5000
  timesteps_total: 700000
  training_iteration: 140
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1708 s, 140 iter, 700000 ts, 562 rew

agent-1: 95.0
agent-2: 91.0
agent-3: 93.0
agent-4: 112.0
agent-5: 89.0
Sum Reward: 480.0
Avg Reward: 96.0
Min Reward: 89.0
Gini Coefficient: 0.041666666666666664
20:20 Ratio: 1.2584269662921348
Max-min Ratio: 1.2584269662921348
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-35-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 561.11
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 140
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.918
    dispatch_time_ms: 43.219
    learner:
      cur_lr: 0.0013133799657225609
      grad_gnorm: 9.812191009521484
      policy_entropy: 50.38130187988281
      policy_loss: -2.8692266941070557
      var_gnorm: 35.56965255737305
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.12061402201652527
    num_steps_sampled: 705000
    num_steps_trained: 705000
    wait_time_ms: 68.409
  iterations_since_restore: 141
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1721.2715556621552
  time_this_iter_s: 12.721059322357178
  time_total_s: 1721.2715556621552
  timestamp: 1593995719
  timesteps_since_restore: 705000
  timesteps_this_iter: 5000
  timesteps_total: 705000
  training_iteration: 141
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1721 s, 141 iter, 705000 ts, 561 rew

agent-1: 105.0
agent-2: 109.0
agent-3: 97.0
agent-4: 91.0
agent-5: 127.0
Sum Reward: 529.0
Avg Reward: 105.8
Min Reward: 91.0
Gini Coefficient: 0.06351606805293006
20:20 Ratio: 1.3956043956043955
Max-min Ratio: 1.3956043956043955
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-35-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 558.52
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 141
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.607
    dispatch_time_ms: 20.443
    learner:
      cur_lr: 0.0013130470179021358
      grad_gnorm: 40.0
      policy_entropy: 35.07606887817383
      policy_loss: 76.28887176513672
      var_gnorm: 35.6099853515625
      vf_explained_var: -1.0
      vf_loss: 315.5910949707031
    num_steps_sampled: 710000
    num_steps_trained: 710000
    wait_time_ms: 91.96
  iterations_since_restore: 142
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1732.9980187416077
  time_this_iter_s: 11.726463079452515
  time_total_s: 1732.9980187416077
  timestamp: 1593995731
  timesteps_since_restore: 710000
  timesteps_this_iter: 5000
  timesteps_total: 710000
  training_iteration: 142
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1732 s, 142 iter, 710000 ts, 559 rew

agent-1: 84.0
agent-2: 77.0
agent-3: 101.0
agent-4: 109.0
agent-5: 81.0
Sum Reward: 452.0
Avg Reward: 90.4
Min Reward: 77.0
Gini Coefficient: 0.0743362831858407
20:20 Ratio: 1.4155844155844155
Max-min Ratio: 1.4155844155844155
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-35-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 556.63
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 142
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.633
    dispatch_time_ms: 43.123
    learner:
      cur_lr: 0.001312713953666389
      grad_gnorm: 8.964178085327148
      policy_entropy: 42.99896240234375
      policy_loss: -2.866312265396118
      var_gnorm: 35.720699310302734
      vf_explained_var: 0.9949737787246704
      vf_loss: 0.17224492132663727
    num_steps_sampled: 715000
    num_steps_trained: 715000
    wait_time_ms: 75.397
  iterations_since_restore: 143
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1745.689579486847
  time_this_iter_s: 12.691560745239258
  time_total_s: 1745.689579486847
  timestamp: 1593995744
  timesteps_since_restore: 715000
  timesteps_this_iter: 5000
  timesteps_total: 715000
  training_iteration: 143
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1745 s, 143 iter, 715000 ts, 557 rew

agent-1: 103.0
agent-2: 103.0
agent-3: 92.0
agent-4: 101.0
agent-5: 107.0
Sum Reward: 506.0
Avg Reward: 101.2
Min Reward: 92.0
Gini Coefficient: 0.025296442687747035
20:20 Ratio: 1.1630434782608696
Max-min Ratio: 1.1630434782608696
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-35-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 555.52
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 143
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.756
    dispatch_time_ms: 23.779
    learner:
      cur_lr: 0.001312381005845964
      grad_gnorm: 39.9999885559082
      policy_entropy: 47.426124572753906
      policy_loss: 7.565311908721924
      var_gnorm: 35.7365837097168
      vf_explained_var: 0.3056803345680237
      vf_loss: 12.324690818786621
    num_steps_sampled: 720000
    num_steps_trained: 720000
    wait_time_ms: 100.704
  iterations_since_restore: 144
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1757.1428475379944
  time_this_iter_s: 11.453268051147461
  time_total_s: 1757.1428475379944
  timestamp: 1593995755
  timesteps_since_restore: 720000
  timesteps_this_iter: 5000
  timesteps_total: 720000
  training_iteration: 144
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1757 s, 144 iter, 720000 ts, 556 rew

agent-1: 80.0
agent-2: 63.0
agent-3: 67.0
agent-4: 81.0
agent-5: 86.0
Sum Reward: 377.0
Avg Reward: 75.4
Min Reward: 63.0
Gini Coefficient: 0.0636604774535809
20:20 Ratio: 1.3650793650793651
Max-min Ratio: 1.3650793650793651
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-36-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 553.36
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 144
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.455
    dispatch_time_ms: 28.839
    learner:
      cur_lr: 0.001312048058025539
      grad_gnorm: 40.0
      policy_entropy: 42.170658111572266
      policy_loss: 46.13639831542969
      var_gnorm: 35.82219696044922
      vf_explained_var: 0.36103785037994385
      vf_loss: 106.3897476196289
    num_steps_sampled: 725000
    num_steps_trained: 725000
    wait_time_ms: 79.891
  iterations_since_restore: 145
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1769.8420844078064
  time_this_iter_s: 12.699236869812012
  time_total_s: 1769.8420844078064
  timestamp: 1593995768
  timesteps_since_restore: 725000
  timesteps_this_iter: 5000
  timesteps_total: 725000
  training_iteration: 145
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1769 s, 145 iter, 725000 ts, 553 rew

agent-1: 105.0
agent-2: 79.0
agent-3: 96.0
agent-4: 98.0
agent-5: 89.0
Sum Reward: 467.0
Avg Reward: 93.4
Min Reward: 79.0
Gini Coefficient: 0.052248394004282654
20:20 Ratio: 1.3291139240506329
Max-min Ratio: 1.3291139240506329
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-36-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 553.6
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 145
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.338
    dispatch_time_ms: 27.062
    learner:
      cur_lr: 0.001311714993789792
      grad_gnorm: 40.0
      policy_entropy: 37.9911003112793
      policy_loss: -129.76284790039062
      var_gnorm: 35.88496398925781
      vf_explained_var: 0.45210057497024536
      vf_loss: 333.5151672363281
    num_steps_sampled: 730000
    num_steps_trained: 730000
    wait_time_ms: 88.464
  iterations_since_restore: 146
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1781.387130022049
  time_this_iter_s: 11.545045614242554
  time_total_s: 1781.387130022049
  timestamp: 1593995780
  timesteps_since_restore: 730000
  timesteps_this_iter: 5000
  timesteps_total: 730000
  training_iteration: 146
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1781 s, 146 iter, 730000 ts, 554 rew

agent-1: 87.0
agent-2: 118.0
agent-3: 107.0
agent-4: 90.0
agent-5: 88.0
Sum Reward: 490.0
Avg Reward: 98.0
Min Reward: 87.0
Gini Coefficient: 0.06612244897959184
20:20 Ratio: 1.3563218390804597
Max-min Ratio: 1.3563218390804597
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-36-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 553.6
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 146
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.556
    dispatch_time_ms: 33.254
    learner:
      cur_lr: 0.001311382045969367
      grad_gnorm: 40.0
      policy_entropy: 32.66946029663086
      policy_loss: 29.35882568359375
      var_gnorm: 35.990577697753906
      vf_explained_var: 0.1569114327430725
      vf_loss: 75.76029968261719
    num_steps_sampled: 735000
    num_steps_trained: 735000
    wait_time_ms: 82.169
  iterations_since_restore: 147
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1793.7220180034637
  time_this_iter_s: 12.334887981414795
  time_total_s: 1793.7220180034637
  timestamp: 1593995792
  timesteps_since_restore: 735000
  timesteps_this_iter: 5000
  timesteps_total: 735000
  training_iteration: 147
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1793 s, 147 iter, 735000 ts, 554 rew

agent-1: 103.0
agent-2: 129.0
agent-3: 111.0
agent-4: 124.0
agent-5: 118.0
Sum Reward: 585.0
Avg Reward: 117.0
Min Reward: 103.0
Gini Coefficient: 0.044444444444444446
20:20 Ratio: 1.2524271844660195
Max-min Ratio: 1.2524271844660195
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-36-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 554.86
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 147
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.738
    dispatch_time_ms: 32.716
    learner:
      cur_lr: 0.0013110489817336202
      grad_gnorm: 40.0
      policy_entropy: 36.96275329589844
      policy_loss: -8.07490348815918
      var_gnorm: 36.039588928222656
      vf_explained_var: -0.3215550184249878
      vf_loss: 61.536354064941406
    num_steps_sampled: 740000
    num_steps_trained: 740000
    wait_time_ms: 85.243
  iterations_since_restore: 148
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1804.815304517746
  time_this_iter_s: 11.093286514282227
  time_total_s: 1804.815304517746
  timestamp: 1593995803
  timesteps_since_restore: 740000
  timesteps_this_iter: 5000
  timesteps_total: 740000
  training_iteration: 148
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1804 s, 148 iter, 740000 ts, 555 rew

agent-1: 122.0
agent-2: 116.0
agent-3: 102.0
agent-4: 167.0
agent-5: 109.0
Sum Reward: 616.0
Avg Reward: 123.2
Min Reward: 102.0
Gini Coefficient: 0.09285714285714286
20:20 Ratio: 1.6372549019607843
Max-min Ratio: 1.6372549019607843
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-36-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 554.18
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 148
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.196
    dispatch_time_ms: 25.055
    learner:
      cur_lr: 0.0013107160339131951
      grad_gnorm: 39.99998474121094
      policy_entropy: 36.052490234375
      policy_loss: -20.061893463134766
      var_gnorm: 36.10155487060547
      vf_explained_var: -1.0
      vf_loss: 32.58417892456055
    num_steps_sampled: 745000
    num_steps_trained: 745000
    wait_time_ms: 101.87
  iterations_since_restore: 149
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1817.1328632831573
  time_this_iter_s: 12.317558765411377
  time_total_s: 1817.1328632831573
  timestamp: 1593995816
  timesteps_since_restore: 745000
  timesteps_this_iter: 5000
  timesteps_total: 745000
  training_iteration: 149
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1817 s, 149 iter, 745000 ts, 554 rew

agent-1: 139.0
agent-2: 159.0
agent-3: 114.0
agent-4: 102.0
agent-5: 132.0
Sum Reward: 646.0
Avg Reward: 129.2
Min Reward: 102.0
Gini Coefficient: 0.08606811145510836
20:20 Ratio: 1.5588235294117647
Max-min Ratio: 1.5588235294117647
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-37-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 556.52
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 149
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.872
    dispatch_time_ms: 40.784
    learner:
      cur_lr: 0.0013103829696774483
      grad_gnorm: 40.0000114440918
      policy_entropy: 31.005096435546875
      policy_loss: 47.8958854675293
      var_gnorm: 36.08750915527344
      vf_explained_var: -0.1968752145767212
      vf_loss: 77.07327270507812
    num_steps_sampled: 750000
    num_steps_trained: 750000
    wait_time_ms: 52.167
  iterations_since_restore: 150
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1831.971032857895
  time_this_iter_s: 14.838169574737549
  time_total_s: 1831.971032857895
  timestamp: 1593995830
  timesteps_since_restore: 750000
  timesteps_this_iter: 5000
  timesteps_total: 750000
  training_iteration: 150
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1831 s, 150 iter, 750000 ts, 557 rew

agent-1: 152.0
agent-2: 121.0
agent-3: 125.0
agent-4: 162.0
agent-5: 132.0
Sum Reward: 692.0
Avg Reward: 138.4
Min Reward: 121.0
Gini Coefficient: 0.0630057803468208
20:20 Ratio: 1.3388429752066116
Max-min Ratio: 1.3388429752066116
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-37-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 557.8
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 150
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.062
    dispatch_time_ms: 29.78
    learner:
      cur_lr: 0.0013100500218570232
      grad_gnorm: 36.150238037109375
      policy_entropy: 21.638315200805664
      policy_loss: 2.522087335586548
      var_gnorm: 36.22808074951172
      vf_explained_var: -0.32396435737609863
      vf_loss: 22.06397819519043
    num_steps_sampled: 755000
    num_steps_trained: 755000
    wait_time_ms: 73.804
  iterations_since_restore: 151
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1844.6688492298126
  time_this_iter_s: 12.697816371917725
  time_total_s: 1844.6688492298126
  timestamp: 1593995843
  timesteps_since_restore: 755000
  timesteps_this_iter: 5000
  timesteps_total: 755000
  training_iteration: 151
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1844 s, 151 iter, 755000 ts, 558 rew

agent-1: 108.0
agent-2: 100.0
agent-3: 126.0
agent-4: 91.0
agent-5: 121.0
Sum Reward: 546.0
Avg Reward: 109.2
Min Reward: 91.0
Gini Coefficient: 0.06666666666666667
20:20 Ratio: 1.3846153846153846
Max-min Ratio: 1.3846153846153846
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-37-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 558.69
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 151
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.798
    dispatch_time_ms: 34.526
    learner:
      cur_lr: 0.0013097169576212764
      grad_gnorm: 39.99999237060547
      policy_entropy: 24.567243576049805
      policy_loss: -2.436203956604004
      var_gnorm: 36.32769775390625
      vf_explained_var: 0.20876765251159668
      vf_loss: 59.03015899658203
    num_steps_sampled: 760000
    num_steps_trained: 760000
    wait_time_ms: 89.832
  iterations_since_restore: 152
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1856.5272591114044
  time_this_iter_s: 11.858409881591797
  time_total_s: 1856.5272591114044
  timestamp: 1593995855
  timesteps_since_restore: 760000
  timesteps_this_iter: 5000
  timesteps_total: 760000
  training_iteration: 152
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1856 s, 152 iter, 760000 ts, 559 rew

agent-1: 93.0
agent-2: 79.0
agent-3: 76.0
agent-4: 105.0
agent-5: 83.0
Sum Reward: 436.0
Avg Reward: 87.2
Min Reward: 76.0
Gini Coefficient: 0.06605504587155964
20:20 Ratio: 1.381578947368421
Max-min Ratio: 1.381578947368421
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-37-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 557.67
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 152
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.963
    dispatch_time_ms: 28.069
    learner:
      cur_lr: 0.0013093840098008513
      grad_gnorm: 40.0
      policy_entropy: 22.27958869934082
      policy_loss: 4.854166030883789
      var_gnorm: 36.37092208862305
      vf_explained_var: 0.23945236206054688
      vf_loss: 40.808895111083984
    num_steps_sampled: 765000
    num_steps_trained: 765000
    wait_time_ms: 86.618
  iterations_since_restore: 153
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1869.4303743839264
  time_this_iter_s: 12.903115272521973
  time_total_s: 1869.4303743839264
  timestamp: 1593995868
  timesteps_since_restore: 765000
  timesteps_this_iter: 5000
  timesteps_total: 765000
  training_iteration: 153
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1869 s, 153 iter, 765000 ts, 558 rew

agent-1: 71.0
agent-2: 76.0
agent-3: 84.0
agent-4: 65.0
agent-5: 79.0
Sum Reward: 375.0
Avg Reward: 75.0
Min Reward: 65.0
Gini Coefficient: 0.04906666666666667
20:20 Ratio: 1.2923076923076924
Max-min Ratio: 1.2923076923076924
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-38-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 555.8
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 153
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.576
    dispatch_time_ms: 32.231
    learner:
      cur_lr: 0.0013090509455651045
      grad_gnorm: 40.0000114440918
      policy_entropy: 20.670827865600586
      policy_loss: -2.5810718536376953
      var_gnorm: 36.484947204589844
      vf_explained_var: 0.03595471382141113
      vf_loss: 86.92724609375
    num_steps_sampled: 770000
    num_steps_trained: 770000
    wait_time_ms: 93.404
  iterations_since_restore: 154
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1881.434993982315
  time_this_iter_s: 12.004619598388672
  time_total_s: 1881.434993982315
  timestamp: 1593995880
  timesteps_since_restore: 770000
  timesteps_this_iter: 5000
  timesteps_total: 770000
  training_iteration: 154
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1881 s, 154 iter, 770000 ts, 556 rew

agent-1: 62.0
agent-2: 128.0
agent-3: 67.0
agent-4: 61.0
agent-5: 74.0
Sum Reward: 392.0
Avg Reward: 78.4
Min Reward: 61.0
Gini Coefficient: 0.1489795918367347
20:20 Ratio: 2.098360655737705
Max-min Ratio: 2.098360655737705
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-38-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 555.67
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 154
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.631
    dispatch_time_ms: 25.486
    learner:
      cur_lr: 0.0013087179977446795
      grad_gnorm: 39.999996185302734
      policy_entropy: 32.50260925292969
      policy_loss: 8.099135398864746
      var_gnorm: 36.52281951904297
      vf_explained_var: -0.1534038782119751
      vf_loss: 21.256521224975586
    num_steps_sampled: 775000
    num_steps_trained: 775000
    wait_time_ms: 57.081
  iterations_since_restore: 155
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1893.3859071731567
  time_this_iter_s: 11.950913190841675
  time_total_s: 1893.3859071731567
  timestamp: 1593995892
  timesteps_since_restore: 775000
  timesteps_this_iter: 5000
  timesteps_total: 775000
  training_iteration: 155
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1893 s, 155 iter, 775000 ts, 556 rew

agent-1: 126.0
agent-2: 114.0
agent-3: 116.0
agent-4: 129.0
agent-5: 119.0
Sum Reward: 604.0
Avg Reward: 120.8
Min Reward: 114.0
Gini Coefficient: 0.026490066225165563
20:20 Ratio: 1.131578947368421
Max-min Ratio: 1.131578947368421
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-38-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 557.07
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 155
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.79
    dispatch_time_ms: 41.174
    learner:
      cur_lr: 0.0013083850499242544
      grad_gnorm: 39.999996185302734
      policy_entropy: 30.68726921081543
      policy_loss: 6.4109721183776855
      var_gnorm: 36.63446807861328
      vf_explained_var: 0.7381263971328735
      vf_loss: 100.70840454101562
    num_steps_sampled: 780000
    num_steps_trained: 780000
    wait_time_ms: 86.806
  iterations_since_restore: 156
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1905.0907514095306
  time_this_iter_s: 11.704844236373901
  time_total_s: 1905.0907514095306
  timestamp: 1593995904
  timesteps_since_restore: 780000
  timesteps_this_iter: 5000
  timesteps_total: 780000
  training_iteration: 156
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1905 s, 156 iter, 780000 ts, 557 rew

agent-1: 144.0
agent-2: 163.0
agent-3: 158.0
agent-4: 141.0
agent-5: 137.0
Sum Reward: 743.0
Avg Reward: 148.6
Min Reward: 137.0
Gini Coefficient: 0.03714670255720054
20:20 Ratio: 1.1897810218978102
Max-min Ratio: 1.1897810218978102
agent-1: 85.0
agent-2: 92.0
agent-3: 65.0
agent-4: 97.0
agent-5: 85.0
Sum Reward: 424.0
Avg Reward: 84.8
Min Reward: 65.0
Gini Coefficient: 0.0669811320754717
20:20 Ratio: 1.4923076923076923
Max-min Ratio: 1.4923076923076923
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-38-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 554.24
  episode_reward_min: 320.0
  episodes_this_iter: 2
  episodes_total: 157
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.855
    dispatch_time_ms: 40.143
    learner:
      cur_lr: 0.0013080519856885076
      grad_gnorm: 39.999996185302734
      policy_entropy: 47.21630096435547
      policy_loss: 46.65229034423828
      var_gnorm: 36.73215103149414
      vf_explained_var: -1.0
      vf_loss: 23.03228187561035
    num_steps_sampled: 785000
    num_steps_trained: 785000
    wait_time_ms: 90.191
  iterations_since_restore: 157
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1917.643938779831
  time_this_iter_s: 12.553187370300293
  time_total_s: 1917.643938779831
  timestamp: 1593995916
  timesteps_since_restore: 785000
  timesteps_this_iter: 5000
  timesteps_total: 785000
  training_iteration: 157
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1917 s, 157 iter, 785000 ts, 554 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-38-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 554.24
  episode_reward_min: 320.0
  episodes_this_iter: 0
  episodes_total: 157
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.91
    dispatch_time_ms: 38.214
    learner:
      cur_lr: 0.0013077190378680825
      grad_gnorm: 40.0
      policy_entropy: 43.89884948730469
      policy_loss: 40.2827262878418
      var_gnorm: 36.86125946044922
      vf_explained_var: -0.10145103931427002
      vf_loss: 46.916038513183594
    num_steps_sampled: 790000
    num_steps_trained: 790000
    wait_time_ms: 68.786
  iterations_since_restore: 158
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1928.3109760284424
  time_this_iter_s: 10.66703724861145
  time_total_s: 1928.3109760284424
  timestamp: 1593995927
  timesteps_since_restore: 790000
  timesteps_this_iter: 5000
  timesteps_total: 790000
  training_iteration: 158
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1928 s, 158 iter, 790000 ts, 554 rew

agent-1: 127.0
agent-2: 168.0
agent-3: 137.0
agent-4: 145.0
agent-5: 138.0
Sum Reward: 715.0
Avg Reward: 143.0
Min Reward: 127.0
Gini Coefficient: 0.05034965034965035
20:20 Ratio: 1.3228346456692914
Max-min Ratio: 1.3228346456692914
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-38-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 553.87
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 158
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.522
    dispatch_time_ms: 32.634
    learner:
      cur_lr: 0.0013073859736323357
      grad_gnorm: 40.000003814697266
      policy_entropy: 46.020511627197266
      policy_loss: 20.990787506103516
      var_gnorm: 36.89342498779297
      vf_explained_var: 0.9255368113517761
      vf_loss: 22.286972045898438
    num_steps_sampled: 795000
    num_steps_trained: 795000
    wait_time_ms: 82.867
  iterations_since_restore: 159
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1939.3732392787933
  time_this_iter_s: 11.062263250350952
  time_total_s: 1939.3732392787933
  timestamp: 1593995938
  timesteps_since_restore: 795000
  timesteps_this_iter: 5000
  timesteps_total: 795000
  training_iteration: 159
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1939 s, 159 iter, 795000 ts, 554 rew

agent-1: 93.0
agent-2: 136.0
agent-3: 142.0
agent-4: 105.0
agent-5: 124.0
Sum Reward: 600.0
Avg Reward: 120.0
Min Reward: 93.0
Gini Coefficient: 0.086
20:20 Ratio: 1.5268817204301075
Max-min Ratio: 1.5268817204301075
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-39-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 556.22
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 159
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.154
    dispatch_time_ms: 34.142
    learner:
      cur_lr: 0.0013070530258119106
      grad_gnorm: 40.0
      policy_entropy: 36.31666946411133
      policy_loss: -30.351579666137695
      var_gnorm: 36.94114685058594
      vf_explained_var: 0.6557210683822632
      vf_loss: 96.93576049804688
    num_steps_sampled: 800000
    num_steps_trained: 800000
    wait_time_ms: 82.702
  iterations_since_restore: 160
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1950.5015914440155
  time_this_iter_s: 11.128352165222168
  time_total_s: 1950.5015914440155
  timestamp: 1593995949
  timesteps_since_restore: 800000
  timesteps_this_iter: 5000
  timesteps_total: 800000
  training_iteration: 160
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1950 s, 160 iter, 800000 ts, 556 rew

agent-1: 122.0
agent-2: 105.0
agent-3: 114.0
agent-4: 111.0
agent-5: 124.0
Sum Reward: 576.0
Avg Reward: 115.2
Min Reward: 105.0
Gini Coefficient: 0.034027777777777775
20:20 Ratio: 1.180952380952381
Max-min Ratio: 1.180952380952381
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-39-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 557.4
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 160
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.865
    dispatch_time_ms: 29.714
    learner:
      cur_lr: 0.0013067199615761638
      grad_gnorm: 30.515377044677734
      policy_entropy: 49.345062255859375
      policy_loss: -10.28321647644043
      var_gnorm: 36.97175979614258
      vf_explained_var: 0.8154293298721313
      vf_loss: 3.2165961265563965
    num_steps_sampled: 805000
    num_steps_trained: 805000
    wait_time_ms: 76.228
  iterations_since_restore: 161
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1962.0220577716827
  time_this_iter_s: 11.520466327667236
  time_total_s: 1962.0220577716827
  timestamp: 1593995962
  timesteps_since_restore: 805000
  timesteps_this_iter: 5000
  timesteps_total: 805000
  training_iteration: 161
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1962 s, 161 iter, 805000 ts, 557 rew

agent-1: 106.0
agent-2: 94.0
agent-3: 87.0
agent-4: 54.0
agent-5: 58.0
Sum Reward: 399.0
Avg Reward: 79.8
Min Reward: 54.0
Gini Coefficient: 0.14035087719298245
20:20 Ratio: 1.962962962962963
Max-min Ratio: 1.962962962962963
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-39-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 557.13
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 161
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.452
    dispatch_time_ms: 38.293
    learner:
      cur_lr: 0.0013063870137557387
      grad_gnorm: 37.455902099609375
      policy_entropy: 29.42593002319336
      policy_loss: 12.100564956665039
      var_gnorm: 36.988243103027344
      vf_explained_var: -0.14114773273468018
      vf_loss: 32.97758483886719
    num_steps_sampled: 810000
    num_steps_trained: 810000
    wait_time_ms: 77.678
  iterations_since_restore: 162
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1972.987706899643
  time_this_iter_s: 10.965649127960205
  time_total_s: 1972.987706899643
  timestamp: 1593995973
  timesteps_since_restore: 810000
  timesteps_this_iter: 5000
  timesteps_total: 810000
  training_iteration: 162
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1972 s, 162 iter, 810000 ts, 557 rew

agent-1: 99.0
agent-2: 151.0
agent-3: 144.0
agent-4: 134.0
agent-5: 120.0
Sum Reward: 648.0
Avg Reward: 129.6
Min Reward: 99.0
Gini Coefficient: 0.07901234567901234
20:20 Ratio: 1.5252525252525253
Max-min Ratio: 1.5252525252525253
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-39-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 558.06
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 162
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.402
    dispatch_time_ms: 33.295
    learner:
      cur_lr: 0.0013060539495199919
      grad_gnorm: 39.999996185302734
      policy_entropy: 50.12638854980469
      policy_loss: -22.15763282775879
      var_gnorm: 37.031639099121094
      vf_explained_var: 0.6094739437103271
      vf_loss: 34.0638313293457
    num_steps_sampled: 815000
    num_steps_trained: 815000
    wait_time_ms: 72.087
  iterations_since_restore: 163
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1984.9254336357117
  time_this_iter_s: 11.937726736068726
  time_total_s: 1984.9254336357117
  timestamp: 1593995985
  timesteps_since_restore: 815000
  timesteps_this_iter: 5000
  timesteps_total: 815000
  training_iteration: 163
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1984 s, 163 iter, 815000 ts, 558 rew

agent-1: 128.0
agent-2: 120.0
agent-3: 116.0
agent-4: 132.0
agent-5: 118.0
Sum Reward: 614.0
Avg Reward: 122.8
Min Reward: 116.0
Gini Coefficient: 0.02736156351791531
20:20 Ratio: 1.1379310344827587
Max-min Ratio: 1.1379310344827587
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-39-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 558.2
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 163
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 5.142
    dispatch_time_ms: 27.805
    learner:
      cur_lr: 0.0013057210016995668
      grad_gnorm: 39.999969482421875
      policy_entropy: 44.994781494140625
      policy_loss: -0.05883288383483887
      var_gnorm: 37.097503662109375
      vf_explained_var: 0.8824155926704407
      vf_loss: 39.73989486694336
    num_steps_sampled: 820000
    num_steps_trained: 820000
    wait_time_ms: 88.477
  iterations_since_restore: 164
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 1995.9763779640198
  time_this_iter_s: 11.050944328308105
  time_total_s: 1995.9763779640198
  timestamp: 1593995996
  timesteps_since_restore: 820000
  timesteps_this_iter: 5000
  timesteps_total: 820000
  training_iteration: 164
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 1995 s, 164 iter, 820000 ts, 558 rew

agent-1: 118.0
agent-2: 118.0
agent-3: 126.0
agent-4: 105.0
agent-5: 118.0
Sum Reward: 585.0
Avg Reward: 117.0
Min Reward: 105.0
Gini Coefficient: 0.028717948717948718
20:20 Ratio: 1.2
Max-min Ratio: 1.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-40-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 560.44
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 164
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.345
    dispatch_time_ms: 33.812
    learner:
      cur_lr: 0.0013053880538791418
      grad_gnorm: 40.00001907348633
      policy_entropy: 52.61857223510742
      policy_loss: -84.3689956665039
      var_gnorm: 37.17067337036133
      vf_explained_var: 0.06746208667755127
      vf_loss: 183.0295867919922
    num_steps_sampled: 825000
    num_steps_trained: 825000
    wait_time_ms: 93.319
  iterations_since_restore: 165
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2008.5606565475464
  time_this_iter_s: 12.584278583526611
  time_total_s: 2008.5606565475464
  timestamp: 1593996009
  timesteps_since_restore: 825000
  timesteps_this_iter: 5000
  timesteps_total: 825000
  training_iteration: 165
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2008 s, 165 iter, 825000 ts, 560 rew

agent-1: 100.0
agent-2: 120.0
agent-3: 125.0
agent-4: 110.0
agent-5: 139.0
Sum Reward: 594.0
Avg Reward: 118.8
Min Reward: 100.0
Gini Coefficient: 0.06262626262626263
20:20 Ratio: 1.39
Max-min Ratio: 1.39
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-40-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 562.32
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 165
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.878
    dispatch_time_ms: 28.042
    learner:
      cur_lr: 0.001305054989643395
      grad_gnorm: 40.0
      policy_entropy: 49.029937744140625
      policy_loss: -15.186498641967773
      var_gnorm: 37.227081298828125
      vf_explained_var: 0.05308210849761963
      vf_loss: 14.116873741149902
    num_steps_sampled: 830000
    num_steps_trained: 830000
    wait_time_ms: 80.888
  iterations_since_restore: 166
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2019.5848705768585
  time_this_iter_s: 11.024214029312134
  time_total_s: 2019.5848705768585
  timestamp: 1593996020
  timesteps_since_restore: 830000
  timesteps_this_iter: 5000
  timesteps_total: 830000
  training_iteration: 166
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2019 s, 166 iter, 830000 ts, 562 rew

agent-1: 110.0
agent-2: 129.0
agent-3: 128.0
agent-4: 116.0
agent-5: 103.0
Sum Reward: 586.0
Avg Reward: 117.2
Min Reward: 103.0
Gini Coefficient: 0.04778156996587031
20:20 Ratio: 1.2524271844660195
Max-min Ratio: 1.2524271844660195
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-40-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 564.35
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 166
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.05
    dispatch_time_ms: 26.701
    learner:
      cur_lr: 0.00130472204182297
      grad_gnorm: 39.999996185302734
      policy_entropy: 47.79823684692383
      policy_loss: -40.90570068359375
      var_gnorm: 37.243404388427734
      vf_explained_var: 0.4483094811439514
      vf_loss: 115.92704772949219
    num_steps_sampled: 835000
    num_steps_trained: 835000
    wait_time_ms: 84.222
  iterations_since_restore: 167
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2031.3206460475922
  time_this_iter_s: 11.735775470733643
  time_total_s: 2031.3206460475922
  timestamp: 1593996031
  timesteps_since_restore: 835000
  timesteps_this_iter: 5000
  timesteps_total: 835000
  training_iteration: 167
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2031 s, 167 iter, 835000 ts, 564 rew

agent-1: 103.0
agent-2: 125.0
agent-3: 112.0
agent-4: 113.0
agent-5: 146.0
Sum Reward: 599.0
Avg Reward: 119.8
Min Reward: 103.0
Gini Coefficient: 0.066110183639399
20:20 Ratio: 1.4174757281553398
Max-min Ratio: 1.4174757281553398
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-40-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 565.62
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 167
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.392
    dispatch_time_ms: 44.933
    learner:
      cur_lr: 0.001304388977587223
      grad_gnorm: 33.29541778564453
      policy_entropy: 37.61460494995117
      policy_loss: 9.058606147766113
      var_gnorm: 37.270050048828125
      vf_explained_var: 0.012497246265411377
      vf_loss: 30.284366607666016
    num_steps_sampled: 840000
    num_steps_trained: 840000
    wait_time_ms: 66.954
  iterations_since_restore: 168
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2042.110225200653
  time_this_iter_s: 10.789579153060913
  time_total_s: 2042.110225200653
  timestamp: 1593996042
  timesteps_since_restore: 840000
  timesteps_this_iter: 5000
  timesteps_total: 840000
  training_iteration: 168
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2042 s, 168 iter, 840000 ts, 566 rew

agent-1: 110.0
agent-2: 148.0
agent-3: 138.0
agent-4: 114.0
agent-5: 112.0
Sum Reward: 622.0
Avg Reward: 124.4
Min Reward: 110.0
Gini Coefficient: 0.06559485530546624
20:20 Ratio: 1.3454545454545455
Max-min Ratio: 1.3454545454545455
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-40-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 565.86
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 168
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.452
    dispatch_time_ms: 31.738
    learner:
      cur_lr: 0.001304056029766798
      grad_gnorm: 39.999996185302734
      policy_entropy: 34.58306121826172
      policy_loss: 16.622623443603516
      var_gnorm: 37.31616973876953
      vf_explained_var: 0.2572292685508728
      vf_loss: 27.601024627685547
    num_steps_sampled: 845000
    num_steps_trained: 845000
    wait_time_ms: 83.026
  iterations_since_restore: 169
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2054.383316040039
  time_this_iter_s: 12.273090839385986
  time_total_s: 2054.383316040039
  timestamp: 1593996055
  timesteps_since_restore: 845000
  timesteps_this_iter: 5000
  timesteps_total: 845000
  training_iteration: 169
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2054 s, 169 iter, 845000 ts, 566 rew

agent-1: 125.0
agent-2: 112.0
agent-3: 115.0
agent-4: 146.0
agent-5: 112.0
Sum Reward: 610.0
Avg Reward: 122.0
Min Reward: 112.0
Gini Coefficient: 0.05311475409836065
20:20 Ratio: 1.3035714285714286
Max-min Ratio: 1.3035714285714286
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-41-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 566.2
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 169
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.822
    dispatch_time_ms: 33.099
    learner:
      cur_lr: 0.0013037229655310512
      grad_gnorm: 40.0
      policy_entropy: 43.631534576416016
      policy_loss: 37.37620162963867
      var_gnorm: 37.381160736083984
      vf_explained_var: 0.8415266871452332
      vf_loss: 60.369808197021484
    num_steps_sampled: 850000
    num_steps_trained: 850000
    wait_time_ms: 89.636
  iterations_since_restore: 170
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2065.617010116577
  time_this_iter_s: 11.233694076538086
  time_total_s: 2065.617010116577
  timestamp: 1593996066
  timesteps_since_restore: 850000
  timesteps_this_iter: 5000
  timesteps_total: 850000
  training_iteration: 170
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2065 s, 170 iter, 850000 ts, 566 rew

agent-1: 85.0
agent-2: 100.0
agent-3: 111.0
agent-4: 98.0
agent-5: 117.0
Sum Reward: 511.0
Avg Reward: 102.2
Min Reward: 85.0
Gini Coefficient: 0.06027397260273973
20:20 Ratio: 1.3764705882352941
Max-min Ratio: 1.3764705882352941
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-41-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 566.42
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 170
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.113
    dispatch_time_ms: 38.607
    learner:
      cur_lr: 0.0013033900177106261
      grad_gnorm: 40.0000114440918
      policy_entropy: 46.24449157714844
      policy_loss: -0.30881738662719727
      var_gnorm: 37.41457748413086
      vf_explained_var: 0.9001733064651489
      vf_loss: 7.420402526855469
    num_steps_sampled: 855000
    num_steps_trained: 855000
    wait_time_ms: 86.303
  iterations_since_restore: 171
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2078.318070411682
  time_this_iter_s: 12.70106029510498
  time_total_s: 2078.318070411682
  timestamp: 1593996079
  timesteps_since_restore: 855000
  timesteps_this_iter: 5000
  timesteps_total: 855000
  training_iteration: 171
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2078 s, 171 iter, 855000 ts, 566 rew

agent-1: 108.0
agent-2: 87.0
agent-3: 107.0
agent-4: 99.0
agent-5: 116.0
Sum Reward: 517.0
Avg Reward: 103.4
Min Reward: 87.0
Gini Coefficient: 0.051837524177949706
20:20 Ratio: 1.3333333333333333
Max-min Ratio: 1.3333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-41-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 565.39
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 171
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.57
    dispatch_time_ms: 36.533
    learner:
      cur_lr: 0.0013030569534748793
      grad_gnorm: 39.999996185302734
      policy_entropy: 35.349266052246094
      policy_loss: -19.113130569458008
      var_gnorm: 37.45345687866211
      vf_explained_var: 0.6929399371147156
      vf_loss: 48.08147430419922
    num_steps_sampled: 860000
    num_steps_trained: 860000
    wait_time_ms: 81.285
  iterations_since_restore: 172
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2089.8042662143707
  time_this_iter_s: 11.486195802688599
  time_total_s: 2089.8042662143707
  timestamp: 1593996090
  timesteps_since_restore: 860000
  timesteps_this_iter: 5000
  timesteps_total: 860000
  training_iteration: 172
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2089 s, 172 iter, 860000 ts, 565 rew

agent-1: 119.0
agent-2: 141.0
agent-3: 113.0
agent-4: 119.0
agent-5: 111.0
Sum Reward: 603.0
Avg Reward: 120.6
Min Reward: 111.0
Gini Coefficient: 0.04378109452736319
20:20 Ratio: 1.2702702702702702
Max-min Ratio: 1.2702702702702702
agent-1: 81.0
agent-2: 117.0
agent-3: 75.0
agent-4: 89.0
agent-5: 75.0
Sum Reward: 437.0
Avg Reward: 87.4
Min Reward: 75.0
Gini Coefficient: 0.08970251716247139
20:20 Ratio: 1.56
Max-min Ratio: 1.56
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-41-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 565.26
  episode_reward_min: 320.0
  episodes_this_iter: 2
  episodes_total: 173
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.419
    dispatch_time_ms: 33.389
    learner:
      cur_lr: 0.0013027240056544542
      grad_gnorm: 40.0
      policy_entropy: 46.00057601928711
      policy_loss: -66.97203063964844
      var_gnorm: 37.56432342529297
      vf_explained_var: -1.0
      vf_loss: 88.63331604003906
    num_steps_sampled: 865000
    num_steps_trained: 865000
    wait_time_ms: 89.509
  iterations_since_restore: 173
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2102.929256439209
  time_this_iter_s: 13.124990224838257
  time_total_s: 2102.929256439209
  timestamp: 1593996103
  timesteps_since_restore: 865000
  timesteps_this_iter: 5000
  timesteps_total: 865000
  training_iteration: 173
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2102 s, 173 iter, 865000 ts, 565 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-41-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 565.26
  episode_reward_min: 320.0
  episodes_this_iter: 0
  episodes_total: 173
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.445
    dispatch_time_ms: 41.638
    learner:
      cur_lr: 0.0013023910578340292
      grad_gnorm: 39.99999237060547
      policy_entropy: 46.21045684814453
      policy_loss: 9.236847877502441
      var_gnorm: 37.63578796386719
      vf_explained_var: 0.9066835045814514
      vf_loss: 19.14162826538086
    num_steps_sampled: 870000
    num_steps_trained: 870000
    wait_time_ms: 78.637
  iterations_since_restore: 174
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2118.3061928749084
  time_this_iter_s: 15.376936435699463
  time_total_s: 2118.3061928749084
  timestamp: 1593996119
  timesteps_since_restore: 870000
  timesteps_this_iter: 5000
  timesteps_total: 870000
  training_iteration: 174
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2118 s, 174 iter, 870000 ts, 565 rew

agent-1: 141.0
agent-2: 191.0
agent-3: 145.0
agent-4: 139.0
agent-5: 115.0
Sum Reward: 731.0
Avg Reward: 146.2
Min Reward: 115.0
Gini Coefficient: 0.08645690834473324
20:20 Ratio: 1.6608695652173913
Max-min Ratio: 1.6608695652173913
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-42-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 567.95
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 174
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.051
    dispatch_time_ms: 32.272
    learner:
      cur_lr: 0.0013020579935982823
      grad_gnorm: 40.0
      policy_entropy: 40.067108154296875
      policy_loss: 43.23979568481445
      var_gnorm: 37.664337158203125
      vf_explained_var: 0.06409430503845215
      vf_loss: 60.89002227783203
    num_steps_sampled: 875000
    num_steps_trained: 875000
    wait_time_ms: 74.461
  iterations_since_restore: 175
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2130.1693770885468
  time_this_iter_s: 11.863184213638306
  time_total_s: 2130.1693770885468
  timestamp: 1593996131
  timesteps_since_restore: 875000
  timesteps_this_iter: 5000
  timesteps_total: 875000
  training_iteration: 175
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2130 s, 175 iter, 875000 ts, 568 rew

agent-1: 94.0
agent-2: 152.0
agent-3: 156.0
agent-4: 105.0
agent-5: 118.0
Sum Reward: 625.0
Avg Reward: 125.0
Min Reward: 94.0
Gini Coefficient: 0.10944
20:20 Ratio: 1.6595744680851063
Max-min Ratio: 1.6595744680851063
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-42-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 568.68
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 175
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.949
    dispatch_time_ms: 31.906
    learner:
      cur_lr: 0.0013017250457778573
      grad_gnorm: 40.0
      policy_entropy: 54.53250503540039
      policy_loss: -17.9033145904541
      var_gnorm: 37.636112213134766
      vf_explained_var: 0.02516859769821167
      vf_loss: 4.331257343292236
    num_steps_sampled: 880000
    num_steps_trained: 880000
    wait_time_ms: 95.404
  iterations_since_restore: 176
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2141.8007419109344
  time_this_iter_s: 11.631364822387695
  time_total_s: 2141.8007419109344
  timestamp: 1593996142
  timesteps_since_restore: 880000
  timesteps_this_iter: 5000
  timesteps_total: 880000
  training_iteration: 176
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2141 s, 176 iter, 880000 ts, 569 rew

agent-1: 78.0
agent-2: 87.0
agent-3: 91.0
agent-4: 99.0
agent-5: 104.0
Sum Reward: 459.0
Avg Reward: 91.8
Min Reward: 78.0
Gini Coefficient: 0.05577342047930283
20:20 Ratio: 1.3333333333333333
Max-min Ratio: 1.3333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-42-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 567.45
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 176
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.047
    dispatch_time_ms: 36.371
    learner:
      cur_lr: 0.0013013919815421104
      grad_gnorm: 40.0
      policy_entropy: 31.218448638916016
      policy_loss: 61.514835357666016
      var_gnorm: 37.66508102416992
      vf_explained_var: 0.24367409944534302
      vf_loss: 126.38905334472656
    num_steps_sampled: 885000
    num_steps_trained: 885000
    wait_time_ms: 85.004
  iterations_since_restore: 177
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2154.263239145279
  time_this_iter_s: 12.462497234344482
  time_total_s: 2154.263239145279
  timestamp: 1593996155
  timesteps_since_restore: 885000
  timesteps_this_iter: 5000
  timesteps_total: 885000
  training_iteration: 177
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2154 s, 177 iter, 885000 ts, 567 rew

agent-1: 90.0
agent-2: 99.0
agent-3: 143.0
agent-4: 89.0
agent-5: 78.0
Sum Reward: 499.0
Avg Reward: 99.8
Min Reward: 78.0
Gini Coefficient: 0.11222444889779559
20:20 Ratio: 1.8333333333333333
Max-min Ratio: 1.8333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-42-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 567.15
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 177
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.789
    dispatch_time_ms: 26.301
    learner:
      cur_lr: 0.0013010590337216854
      grad_gnorm: 40.00000762939453
      policy_entropy: 30.121187210083008
      policy_loss: -2.1290981769561768
      var_gnorm: 37.708290100097656
      vf_explained_var: 0.6924587488174438
      vf_loss: 72.78262329101562
    num_steps_sampled: 890000
    num_steps_trained: 890000
    wait_time_ms: 98.882
  iterations_since_restore: 178
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2165.6786324977875
  time_this_iter_s: 11.415393352508545
  time_total_s: 2165.6786324977875
  timestamp: 1593996166
  timesteps_since_restore: 890000
  timesteps_this_iter: 5000
  timesteps_total: 890000
  training_iteration: 178
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2165 s, 178 iter, 890000 ts, 567 rew

agent-1: 80.0
agent-2: 99.0
agent-3: 102.0
agent-4: 124.0
agent-5: 127.0
Sum Reward: 532.0
Avg Reward: 106.4
Min Reward: 80.0
Gini Coefficient: 0.08947368421052632
20:20 Ratio: 1.5875
Max-min Ratio: 1.5875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-42-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 566.31
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 178
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.941
    dispatch_time_ms: 33.927
    learner:
      cur_lr: 0.0013007259694859385
      grad_gnorm: 39.9999885559082
      policy_entropy: 41.505615234375
      policy_loss: 4.3772149085998535
      var_gnorm: 37.81027603149414
      vf_explained_var: 0.9827977418899536
      vf_loss: 9.369583129882812
    num_steps_sampled: 895000
    num_steps_trained: 895000
    wait_time_ms: 70.597
  iterations_since_restore: 179
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2178.203508615494
  time_this_iter_s: 12.524876117706299
  time_total_s: 2178.203508615494
  timestamp: 1593996179
  timesteps_since_restore: 895000
  timesteps_this_iter: 5000
  timesteps_total: 895000
  training_iteration: 179
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2178 s, 179 iter, 895000 ts, 566 rew

agent-1: 90.0
agent-2: 141.0
agent-3: 110.0
agent-4: 146.0
agent-5: 111.0
Sum Reward: 598.0
Avg Reward: 119.6
Min Reward: 90.0
Gini Coefficient: 0.09565217391304348
20:20 Ratio: 1.6222222222222222
Max-min Ratio: 1.6222222222222222
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-43-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 566.47
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 179
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.477
    dispatch_time_ms: 38.005
    learner:
      cur_lr: 0.0013003930216655135
      grad_gnorm: 40.000003814697266
      policy_entropy: 39.849098205566406
      policy_loss: -42.690391540527344
      var_gnorm: 37.82147216796875
      vf_explained_var: 0.43366438150405884
      vf_loss: 99.49927520751953
    num_steps_sampled: 900000
    num_steps_trained: 900000
    wait_time_ms: 69.344
  iterations_since_restore: 180
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2210.617935180664
  time_this_iter_s: 32.41442656517029
  time_total_s: 2210.617935180664
  timestamp: 1593996211
  timesteps_since_restore: 900000
  timesteps_this_iter: 5000
  timesteps_total: 900000
  training_iteration: 180
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2210 s, 180 iter, 900000 ts, 566 rew

agent-1: 75.0
agent-2: 104.0
agent-3: 106.0
agent-4: 91.0
agent-5: 83.0
Sum Reward: 459.0
Avg Reward: 91.8
Min Reward: 75.0
Gini Coefficient: 0.07233115468409586
20:20 Ratio: 1.4133333333333333
Max-min Ratio: 1.4133333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-43-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 565.81
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 180
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.781
    dispatch_time_ms: 35.441
    learner:
      cur_lr: 0.0013000599574297667
      grad_gnorm: 31.43881607055664
      policy_entropy: 50.852657318115234
      policy_loss: -7.862165451049805
      var_gnorm: 37.92306900024414
      vf_explained_var: 0.873757004737854
      vf_loss: 5.054327487945557
    num_steps_sampled: 905000
    num_steps_trained: 905000
    wait_time_ms: 68.309
  iterations_since_restore: 181
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2222.6564724445343
  time_this_iter_s: 12.03853726387024
  time_total_s: 2222.6564724445343
  timestamp: 1593996224
  timesteps_since_restore: 905000
  timesteps_this_iter: 5000
  timesteps_total: 905000
  training_iteration: 181
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2222 s, 181 iter, 905000 ts, 566 rew

agent-1: 116.0
agent-2: 127.0
agent-3: 103.0
agent-4: 133.0
agent-5: 111.0
Sum Reward: 590.0
Avg Reward: 118.0
Min Reward: 103.0
Gini Coefficient: 0.05152542372881356
20:20 Ratio: 1.2912621359223302
Max-min Ratio: 1.2912621359223302
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-43-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 565.62
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 181
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.968
    dispatch_time_ms: 28.303
    learner:
      cur_lr: 0.0012997270096093416
      grad_gnorm: 39.999996185302734
      policy_entropy: 37.31169509887695
      policy_loss: -30.43720245361328
      var_gnorm: 37.978755950927734
      vf_explained_var: 0.7363622188568115
      vf_loss: 50.727867126464844
    num_steps_sampled: 910000
    num_steps_trained: 910000
    wait_time_ms: 89.559
  iterations_since_restore: 182
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2234.081100463867
  time_this_iter_s: 11.424628019332886
  time_total_s: 2234.081100463867
  timestamp: 1593996235
  timesteps_since_restore: 910000
  timesteps_this_iter: 5000
  timesteps_total: 910000
  training_iteration: 182
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2234 s, 182 iter, 910000 ts, 566 rew

agent-1: 111.0
agent-2: 158.0
agent-3: 107.0
agent-4: 131.0
agent-5: 125.0
Sum Reward: 632.0
Avg Reward: 126.4
Min Reward: 107.0
Gini Coefficient: 0.07721518987341772
20:20 Ratio: 1.4766355140186915
Max-min Ratio: 1.4766355140186915
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-44-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 567.6
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 182
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.111
    dispatch_time_ms: 23.678
    learner:
      cur_lr: 0.0012993939453735948
      grad_gnorm: 34.25921630859375
      policy_entropy: 44.53107452392578
      policy_loss: 8.069549560546875
      var_gnorm: 38.053218841552734
      vf_explained_var: 0.8807782530784607
      vf_loss: 14.667848587036133
    num_steps_sampled: 915000
    num_steps_trained: 915000
    wait_time_ms: 82.869
  iterations_since_restore: 183
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2246.360239982605
  time_this_iter_s: 12.279139518737793
  time_total_s: 2246.360239982605
  timestamp: 1593996247
  timesteps_since_restore: 915000
  timesteps_this_iter: 5000
  timesteps_total: 915000
  training_iteration: 183
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2246 s, 183 iter, 915000 ts, 568 rew

agent-1: 106.0
agent-2: 111.0
agent-3: 95.0
agent-4: 117.0
agent-5: 115.0
Sum Reward: 544.0
Avg Reward: 108.8
Min Reward: 95.0
Gini Coefficient: 0.03897058823529412
20:20 Ratio: 1.231578947368421
Max-min Ratio: 1.231578947368421
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-44-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 567.59
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 183
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.157
    dispatch_time_ms: 44.482
    learner:
      cur_lr: 0.0012990609975531697
      grad_gnorm: 40.0
      policy_entropy: 33.250648498535156
      policy_loss: 22.48828887939453
      var_gnorm: 38.00799560546875
      vf_explained_var: 0.4136549234390259
      vf_loss: 90.0983657836914
    num_steps_sampled: 920000
    num_steps_trained: 920000
    wait_time_ms: 77.862
  iterations_since_restore: 184
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2258.01558470726
  time_this_iter_s: 11.655344724655151
  time_total_s: 2258.01558470726
  timestamp: 1593996259
  timesteps_since_restore: 920000
  timesteps_this_iter: 5000
  timesteps_total: 920000
  training_iteration: 184
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2258 s, 184 iter, 920000 ts, 568 rew

agent-1: 117.0
agent-2: 101.0
agent-3: 67.0
agent-4: 188.0
agent-5: 74.0
Sum Reward: 547.0
Avg Reward: 109.4
Min Reward: 67.0
Gini Coefficient: 0.20840950639853748
20:20 Ratio: 2.8059701492537314
Max-min Ratio: 2.8059701492537314
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-44-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 565.81
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 184
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.007
    dispatch_time_ms: 29.927
    learner:
      cur_lr: 0.0012987280497327447
      grad_gnorm: 40.0
      policy_entropy: 16.04737091064453
      policy_loss: 7.883172035217285
      var_gnorm: 38.21546173095703
      vf_explained_var: 0.4127603769302368
      vf_loss: 75.33523559570312
    num_steps_sampled: 925000
    num_steps_trained: 925000
    wait_time_ms: 92.953
  iterations_since_restore: 185
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2270.464495420456
  time_this_iter_s: 12.4489107131958
  time_total_s: 2270.464495420456
  timestamp: 1593996272
  timesteps_since_restore: 925000
  timesteps_this_iter: 5000
  timesteps_total: 925000
  training_iteration: 185
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2270 s, 185 iter, 925000 ts, 566 rew

agent-1: 80.0
agent-2: 102.0
agent-3: 78.0
agent-4: 113.0
agent-5: 132.0
Sum Reward: 505.0
Avg Reward: 101.0
Min Reward: 78.0
Gini Coefficient: 0.11168316831683169
20:20 Ratio: 1.6923076923076923
Max-min Ratio: 1.6923076923076923
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-44-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 566.67
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 185
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.898
    dispatch_time_ms: 34.835
    learner:
      cur_lr: 0.0012983949854969978
      grad_gnorm: 40.0
      policy_entropy: 24.72914695739746
      policy_loss: -27.65652084350586
      var_gnorm: 38.161190032958984
      vf_explained_var: 0.8312176465988159
      vf_loss: 129.37429809570312
    num_steps_sampled: 930000
    num_steps_trained: 930000
    wait_time_ms: 80.413
  iterations_since_restore: 186
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2281.449732542038
  time_this_iter_s: 10.985237121582031
  time_total_s: 2281.449732542038
  timestamp: 1593996283
  timesteps_since_restore: 930000
  timesteps_this_iter: 5000
  timesteps_total: 930000
  training_iteration: 186
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2281 s, 186 iter, 930000 ts, 567 rew

agent-1: 166.0
agent-2: 198.0
agent-3: 151.0
agent-4: 171.0
agent-5: 148.0
Sum Reward: 834.0
Avg Reward: 166.8
Min Reward: 148.0
Gini Coefficient: 0.05755395683453238
20:20 Ratio: 1.337837837837838
Max-min Ratio: 1.337837837837838
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-44-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 566.73
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 186
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.807
    dispatch_time_ms: 22.122
    learner:
      cur_lr: 0.0012980620376765728
      grad_gnorm: 40.0
      policy_entropy: 22.073768615722656
      policy_loss: 16.455385208129883
      var_gnorm: 38.28459548950195
      vf_explained_var: -0.523082971572876
      vf_loss: 45.40260314941406
    num_steps_sampled: 935000
    num_steps_trained: 935000
    wait_time_ms: 88.368
  iterations_since_restore: 187
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2292.949624300003
  time_this_iter_s: 11.499891757965088
  time_total_s: 2292.949624300003
  timestamp: 1593996294
  timesteps_since_restore: 935000
  timesteps_this_iter: 5000
  timesteps_total: 935000
  training_iteration: 187
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2292 s, 187 iter, 935000 ts, 567 rew

agent-1: 107.0
agent-2: 120.0
agent-3: 106.0
agent-4: 152.0
agent-5: 112.0
Sum Reward: 597.0
Avg Reward: 119.4
Min Reward: 106.0
Gini Coefficient: 0.07035175879396985
20:20 Ratio: 1.4339622641509433
Max-min Ratio: 1.4339622641509433
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-45-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 566.65
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 187
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.817
    dispatch_time_ms: 32.068
    learner:
      cur_lr: 0.001297728973440826
      grad_gnorm: 40.0
      policy_entropy: 32.81478500366211
      policy_loss: -56.71345520019531
      var_gnorm: 38.320926666259766
      vf_explained_var: 0.3927510380744934
      vf_loss: 122.90351104736328
    num_steps_sampled: 940000
    num_steps_trained: 940000
    wait_time_ms: 83.946
  iterations_since_restore: 188
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2304.615183353424
  time_this_iter_s: 11.66555905342102
  time_total_s: 2304.615183353424
  timestamp: 1593996306
  timesteps_since_restore: 940000
  timesteps_this_iter: 5000
  timesteps_total: 940000
  training_iteration: 188
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2304 s, 188 iter, 940000 ts, 567 rew

agent-1: 103.0
agent-2: 145.0
agent-3: 117.0
agent-4: 127.0
agent-5: 108.0
Sum Reward: 600.0
Avg Reward: 120.0
Min Reward: 103.0
Gini Coefficient: 0.06866666666666667
20:20 Ratio: 1.4077669902912622
Max-min Ratio: 1.4077669902912622
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-45-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 568.65
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 188
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.692
    dispatch_time_ms: 35.686
    learner:
      cur_lr: 0.001297396025620401
      grad_gnorm: 39.999996185302734
      policy_entropy: 39.6042366027832
      policy_loss: -12.092414855957031
      var_gnorm: 38.351593017578125
      vf_explained_var: 0.6855558753013611
      vf_loss: 32.59507751464844
    num_steps_sampled: 945000
    num_steps_trained: 945000
    wait_time_ms: 72.374
  iterations_since_restore: 189
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2316.0833926200867
  time_this_iter_s: 11.468209266662598
  time_total_s: 2316.0833926200867
  timestamp: 1593996317
  timesteps_since_restore: 945000
  timesteps_this_iter: 5000
  timesteps_total: 945000
  training_iteration: 189
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2316 s, 189 iter, 945000 ts, 569 rew

agent-1: 138.0
agent-2: 187.0
agent-3: 145.0
agent-4: 154.0
agent-5: 152.0
Sum Reward: 776.0
Avg Reward: 155.2
Min Reward: 138.0
Gini Coefficient: 0.05515463917525773
20:20 Ratio: 1.355072463768116
Max-min Ratio: 1.355072463768116
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-45-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 572.28
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 189
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.1
    dispatch_time_ms: 32.822
    learner:
      cur_lr: 0.001297062961384654
      grad_gnorm: 40.000003814697266
      policy_entropy: 31.819162368774414
      policy_loss: 2.192126512527466
      var_gnorm: 38.4654426574707
      vf_explained_var: 0.7901076078414917
      vf_loss: 22.399581909179688
    num_steps_sampled: 950000
    num_steps_trained: 950000
    wait_time_ms: 74.282
  iterations_since_restore: 190
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2326.8225803375244
  time_this_iter_s: 10.739187717437744
  time_total_s: 2326.8225803375244
  timestamp: 1593996328
  timesteps_since_restore: 950000
  timesteps_this_iter: 5000
  timesteps_total: 950000
  training_iteration: 190
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2326 s, 190 iter, 950000 ts, 572 rew

agent-1: 102.0
agent-2: 178.0
agent-3: 111.0
agent-4: 143.0
agent-5: 166.0
Sum Reward: 700.0
Avg Reward: 140.0
Min Reward: 102.0
Gini Coefficient: 0.11828571428571429
20:20 Ratio: 1.7450980392156863
Max-min Ratio: 1.7450980392156863
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-45-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 572.97
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 190
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.309
    dispatch_time_ms: 26.348
    learner:
      cur_lr: 0.001296730013564229
      grad_gnorm: 40.00000762939453
      policy_entropy: 31.819110870361328
      policy_loss: -11.280864715576172
      var_gnorm: 38.50371551513672
      vf_explained_var: 0.701974093914032
      vf_loss: 127.59276580810547
    num_steps_sampled: 955000
    num_steps_trained: 955000
    wait_time_ms: 84.164
  iterations_since_restore: 191
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2338.3407764434814
  time_this_iter_s: 11.518196105957031
  time_total_s: 2338.3407764434814
  timestamp: 1593996340
  timesteps_since_restore: 955000
  timesteps_this_iter: 5000
  timesteps_total: 955000
  training_iteration: 191
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2338 s, 191 iter, 955000 ts, 573 rew

agent-1: 128.0
agent-2: 151.0
agent-3: 137.0
agent-4: 160.0
agent-5: 153.0
Sum Reward: 729.0
Avg Reward: 145.8
Min Reward: 128.0
Gini Coefficient: 0.0438957475994513
20:20 Ratio: 1.25
Max-min Ratio: 1.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-45-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 575.07
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 191
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.954
    dispatch_time_ms: 34.233
    learner:
      cur_lr: 0.0012963969493284822
      grad_gnorm: 40.000003814697266
      policy_entropy: 35.81904602050781
      policy_loss: -61.89580154418945
      var_gnorm: 38.59425354003906
      vf_explained_var: 0.9204890727996826
      vf_loss: 69.52691650390625
    num_steps_sampled: 960000
    num_steps_trained: 960000
    wait_time_ms: 76.968
  iterations_since_restore: 192
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2349.787491083145
  time_this_iter_s: 11.446714639663696
  time_total_s: 2349.787491083145
  timestamp: 1593996351
  timesteps_since_restore: 960000
  timesteps_this_iter: 5000
  timesteps_total: 960000
  training_iteration: 192
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2349 s, 192 iter, 960000 ts, 575 rew

agent-1: 148.0
agent-2: 188.0
agent-3: 95.0
agent-4: 158.0
agent-5: 135.0
Sum Reward: 724.0
Avg Reward: 144.8
Min Reward: 95.0
Gini Coefficient: 0.11546961325966851
20:20 Ratio: 1.9789473684210526
Max-min Ratio: 1.9789473684210526
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-46-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 577.18
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 192
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.089
    dispatch_time_ms: 33.738
    learner:
      cur_lr: 0.0012960640015080571
      grad_gnorm: 40.0
      policy_entropy: 43.430721282958984
      policy_loss: 8.586905479431152
      var_gnorm: 38.77194595336914
      vf_explained_var: 0.651512622833252
      vf_loss: 45.24423599243164
    num_steps_sampled: 965000
    num_steps_trained: 965000
    wait_time_ms: 73.713
  iterations_since_restore: 193
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2361.530700445175
  time_this_iter_s: 11.74320936203003
  time_total_s: 2361.530700445175
  timestamp: 1593996363
  timesteps_since_restore: 965000
  timesteps_this_iter: 5000
  timesteps_total: 965000
  training_iteration: 193
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2361 s, 193 iter, 965000 ts, 577 rew

agent-1: 92.0
agent-2: 69.0
agent-3: 94.0
agent-4: 142.0
agent-5: 71.0
Sum Reward: 468.0
Avg Reward: 93.6
Min Reward: 69.0
Gini Coefficient: 0.14444444444444443
20:20 Ratio: 2.0579710144927534
Max-min Ratio: 2.0579710144927534
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-46-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 576.11
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 193
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.451
    dispatch_time_ms: 42.38
    learner:
      cur_lr: 0.001295731053687632
      grad_gnorm: 40.0
      policy_entropy: 40.34223937988281
      policy_loss: -1.6483772993087769
      var_gnorm: 38.82146453857422
      vf_explained_var: -0.3447387218475342
      vf_loss: 30.37682342529297
    num_steps_sampled: 970000
    num_steps_trained: 970000
    wait_time_ms: 72.867
  iterations_since_restore: 194
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2373.193605661392
  time_this_iter_s: 11.662905216217041
  time_total_s: 2373.193605661392
  timestamp: 1593996375
  timesteps_since_restore: 970000
  timesteps_this_iter: 5000
  timesteps_total: 970000
  training_iteration: 194
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2373 s, 194 iter, 970000 ts, 576 rew

agent-1: 121.0
agent-2: 127.0
agent-3: 69.0
agent-4: 140.0
agent-5: 140.0
Sum Reward: 597.0
Avg Reward: 119.4
Min Reward: 69.0
Gini Coefficient: 0.10787269681742044
20:20 Ratio: 2.028985507246377
Max-min Ratio: 2.028985507246377
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-46-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 576.62
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 194
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.949
    dispatch_time_ms: 38.147
    learner:
      cur_lr: 0.0012953979894518852
      grad_gnorm: 40.0
      policy_entropy: 50.83421325683594
      policy_loss: -19.04854965209961
      var_gnorm: 38.78215789794922
      vf_explained_var: -1.0
      vf_loss: 27.072771072387695
    num_steps_sampled: 975000
    num_steps_trained: 975000
    wait_time_ms: 72.408
  iterations_since_restore: 195
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2385.0173642635345
  time_this_iter_s: 11.823758602142334
  time_total_s: 2385.0173642635345
  timestamp: 1593996387
  timesteps_since_restore: 975000
  timesteps_this_iter: 5000
  timesteps_total: 975000
  training_iteration: 195
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2385 s, 195 iter, 975000 ts, 577 rew

agent-1: 130.0
agent-2: 147.0
agent-3: 112.0
agent-4: 121.0
agent-5: 139.0
Sum Reward: 649.0
Avg Reward: 129.8
Min Reward: 112.0
Gini Coefficient: 0.05423728813559322
20:20 Ratio: 1.3125
Max-min Ratio: 1.3125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-46-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 578.41
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 195
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.815
    dispatch_time_ms: 47.114
    learner:
      cur_lr: 0.0012950650416314602
      grad_gnorm: 40.0
      policy_entropy: 35.36541748046875
      policy_loss: 13.22219181060791
      var_gnorm: 38.80670166015625
      vf_explained_var: 0.12401258945465088
      vf_loss: 103.86710357666016
    num_steps_sampled: 980000
    num_steps_trained: 980000
    wait_time_ms: 74.999
  iterations_since_restore: 196
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2396.7418928146362
  time_this_iter_s: 11.724528551101685
  time_total_s: 2396.7418928146362
  timestamp: 1593996398
  timesteps_since_restore: 980000
  timesteps_this_iter: 5000
  timesteps_total: 980000
  training_iteration: 196
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2396 s, 196 iter, 980000 ts, 578 rew

agent-1: 62.0
agent-2: 124.0
agent-3: 90.0
agent-4: 94.0
agent-5: 88.0
Sum Reward: 458.0
Avg Reward: 91.6
Min Reward: 62.0
Gini Coefficient: 0.11353711790393013
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-46-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 577.77
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 196
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.148
    dispatch_time_ms: 29.764
    learner:
      cur_lr: 0.0012947319773957133
      grad_gnorm: 39.999996185302734
      policy_entropy: 41.688350677490234
      policy_loss: -9.64571762084961
      var_gnorm: 38.88530731201172
      vf_explained_var: 0.6278563141822815
      vf_loss: 35.07699203491211
    num_steps_sampled: 985000
    num_steps_trained: 985000
    wait_time_ms: 99.113
  iterations_since_restore: 197
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2409.206088066101
  time_this_iter_s: 12.464195251464844
  time_total_s: 2409.206088066101
  timestamp: 1593996411
  timesteps_since_restore: 985000
  timesteps_this_iter: 5000
  timesteps_total: 985000
  training_iteration: 197
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2409 s, 197 iter, 985000 ts, 578 rew

agent-1: 99.0
agent-2: 130.0
agent-3: 104.0
agent-4: 123.0
agent-5: 105.0
Sum Reward: 561.0
Avg Reward: 112.2
Min Reward: 99.0
Gini Coefficient: 0.057754010695187166
20:20 Ratio: 1.3131313131313131
Max-min Ratio: 1.3131313131313131
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-47-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 577.42
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 197
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.713
    dispatch_time_ms: 11.866
    learner:
      cur_lr: 0.0012943990295752883
      grad_gnorm: 40.000003814697266
      policy_entropy: 36.384178161621094
      policy_loss: -10.823744773864746
      var_gnorm: 38.93347930908203
      vf_explained_var: 0.9529719352722168
      vf_loss: 25.8060245513916
    num_steps_sampled: 990000
    num_steps_trained: 990000
    wait_time_ms: 102.989
  iterations_since_restore: 198
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2425.0305280685425
  time_this_iter_s: 15.824440002441406
  time_total_s: 2425.0305280685425
  timestamp: 1593996427
  timesteps_since_restore: 990000
  timesteps_this_iter: 5000
  timesteps_total: 990000
  training_iteration: 198
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2425 s, 198 iter, 990000 ts, 577 rew

agent-1: 75.0
agent-2: 181.0
agent-3: 89.0
agent-4: 126.0
agent-5: 86.0
Sum Reward: 557.0
Avg Reward: 111.4
Min Reward: 75.0
Gini Coefficient: 0.18096947935368043
20:20 Ratio: 2.4133333333333336
Max-min Ratio: 2.4133333333333336
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-47-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 577.98
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 198
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.172
    dispatch_time_ms: 6.999
    learner:
      cur_lr: 0.0012940659653395414
      grad_gnorm: 40.00000762939453
      policy_entropy: 39.22372055053711
      policy_loss: -12.316229820251465
      var_gnorm: 39.057701110839844
      vf_explained_var: -0.3935636281967163
      vf_loss: 80.30938720703125
    num_steps_sampled: 995000
    num_steps_trained: 995000
    wait_time_ms: 93.473
  iterations_since_restore: 199
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2436.2309653759003
  time_this_iter_s: 11.200437307357788
  time_total_s: 2436.2309653759003
  timestamp: 1593996438
  timesteps_since_restore: 995000
  timesteps_this_iter: 5000
  timesteps_total: 995000
  training_iteration: 199
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2436 s, 199 iter, 995000 ts, 578 rew

agent-1: 106.0
agent-2: 136.0
agent-3: 118.0
agent-4: 149.0
agent-5: 130.0
Sum Reward: 639.0
Avg Reward: 127.8
Min Reward: 106.0
Gini Coefficient: 0.06510172143974961
20:20 Ratio: 1.4056603773584906
Max-min Ratio: 1.4056603773584906
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-47-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 579.24
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 199
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.326
    dispatch_time_ms: 9.186
    learner:
      cur_lr: 0.0012937330175191164
      grad_gnorm: 40.00000762939453
      policy_entropy: 34.137237548828125
      policy_loss: -37.048744201660156
      var_gnorm: 39.00703430175781
      vf_explained_var: -0.33993279933929443
      vf_loss: 140.36141967773438
    num_steps_sampled: 1000000
    num_steps_trained: 1000000
    wait_time_ms: 98.237
  iterations_since_restore: 200
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2446.997458457947
  time_this_iter_s: 10.766493082046509
  time_total_s: 2446.997458457947
  timestamp: 1593996449
  timesteps_since_restore: 1000000
  timesteps_this_iter: 5000
  timesteps_total: 1000000
  training_iteration: 200
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2446 s, 200 iter, 1000000 ts, 579 rew

agent-1: 154.0
agent-2: 162.0
agent-3: 132.0
agent-4: 140.0
agent-5: 134.0
Sum Reward: 722.0
Avg Reward: 144.4
Min Reward: 132.0
Gini Coefficient: 0.0443213296398892
20:20 Ratio: 1.2272727272727273
Max-min Ratio: 1.2272727272727273
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-47-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 579.68
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 200
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.75
    dispatch_time_ms: 7.858
    learner:
      cur_lr: 0.0012933999532833695
      grad_gnorm: 40.0
      policy_entropy: 31.005197525024414
      policy_loss: 11.888116836547852
      var_gnorm: 39.08858108520508
      vf_explained_var: 0.16425836086273193
      vf_loss: 50.60096740722656
    num_steps_sampled: 1005000
    num_steps_trained: 1005000
    wait_time_ms: 92.312
  iterations_since_restore: 201
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2458.1213672161102
  time_this_iter_s: 11.123908758163452
  time_total_s: 2458.1213672161102
  timestamp: 1593996460
  timesteps_since_restore: 1005000
  timesteps_this_iter: 5000
  timesteps_total: 1005000
  training_iteration: 201
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2458 s, 201 iter, 1005000 ts, 580 rew

agent-1: 98.0
agent-2: 108.0
agent-3: 115.0
agent-4: 126.0
agent-5: 128.0
Sum Reward: 575.0
Avg Reward: 115.0
Min Reward: 98.0
Gini Coefficient: 0.05426086956521739
20:20 Ratio: 1.3061224489795917
Max-min Ratio: 1.3061224489795917
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-47-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 580.56
  episode_reward_min: 320.0
  episodes_this_iter: 1
  episodes_total: 201
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.237
    dispatch_time_ms: 5.791
    learner:
      cur_lr: 0.0012930670054629445
      grad_gnorm: 39.999996185302734
      policy_entropy: 41.34786605834961
      policy_loss: -14.396340370178223
      var_gnorm: 39.14501953125
      vf_explained_var: 0.20141083002090454
      vf_loss: 18.47191047668457
    num_steps_sampled: 1010000
    num_steps_trained: 1010000
    wait_time_ms: 96.857
  iterations_since_restore: 202
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2469.077080965042
  time_this_iter_s: 10.955713748931885
  time_total_s: 2469.077080965042
  timestamp: 1593996471
  timesteps_since_restore: 1010000
  timesteps_this_iter: 5000
  timesteps_total: 1010000
  training_iteration: 202
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2469 s, 202 iter, 1010000 ts, 581 rew

agent-1: 124.0
agent-2: 136.0
agent-3: 111.0
agent-4: 146.0
agent-5: 143.0
Sum Reward: 660.0
Avg Reward: 132.0
Min Reward: 111.0
Gini Coefficient: 0.05393939393939394
20:20 Ratio: 1.3153153153153154
Max-min Ratio: 1.3153153153153154
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-48-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 583.96
  episode_reward_min: 375.0
  episodes_this_iter: 1
  episodes_total: 202
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.635
    dispatch_time_ms: 5.524
    learner:
      cur_lr: 0.0012927340576425195
      grad_gnorm: 39.99998092651367
      policy_entropy: 26.69501304626465
      policy_loss: 24.173076629638672
      var_gnorm: 39.307899475097656
      vf_explained_var: 0.42850345373153687
      vf_loss: 36.42524719238281
    num_steps_sampled: 1015000
    num_steps_trained: 1015000
    wait_time_ms: 102.425
  iterations_since_restore: 203
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2479.7259061336517
  time_this_iter_s: 10.64882516860962
  time_total_s: 2479.7259061336517
  timestamp: 1593996482
  timesteps_since_restore: 1015000
  timesteps_this_iter: 5000
  timesteps_total: 1015000
  training_iteration: 203
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2479 s, 203 iter, 1015000 ts, 584 rew

agent-1: 160.0
agent-2: 176.0
agent-3: 136.0
agent-4: 143.0
agent-5: 121.0
Sum Reward: 736.0
Avg Reward: 147.2
Min Reward: 121.0
Gini Coefficient: 0.07282608695652174
20:20 Ratio: 1.4545454545454546
Max-min Ratio: 1.4545454545454546
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-48-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 585.96
  episode_reward_min: 375.0
  episodes_this_iter: 1
  episodes_total: 203
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.883
    dispatch_time_ms: 6.758
    learner:
      cur_lr: 0.0012924009934067726
      grad_gnorm: 39.9999885559082
      policy_entropy: 37.09910583496094
      policy_loss: -15.509176254272461
      var_gnorm: 39.25984573364258
      vf_explained_var: 0.9455919861793518
      vf_loss: 10.859411239624023
    num_steps_sampled: 1020000
    num_steps_trained: 1020000
    wait_time_ms: 107.765
  iterations_since_restore: 204
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2490.5281312465668
  time_this_iter_s: 10.802225112915039
  time_total_s: 2490.5281312465668
  timestamp: 1593996493
  timesteps_since_restore: 1020000
  timesteps_this_iter: 5000
  timesteps_total: 1020000
  training_iteration: 204
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2490 s, 204 iter, 1020000 ts, 586 rew

agent-1: 102.0
agent-2: 96.0
agent-3: 96.0
agent-4: 100.0
agent-5: 108.0
Sum Reward: 502.0
Avg Reward: 100.4
Min Reward: 96.0
Gini Coefficient: 0.02390438247011952
20:20 Ratio: 1.125
Max-min Ratio: 1.125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-48-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 583.24
  episode_reward_min: 375.0
  episodes_this_iter: 1
  episodes_total: 204
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.067
    dispatch_time_ms: 7.099
    learner:
      cur_lr: 0.0012920680455863476
      grad_gnorm: 40.00000762939453
      policy_entropy: 40.95170974731445
      policy_loss: -3.354888439178467
      var_gnorm: 39.36138916015625
      vf_explained_var: -0.028942108154296875
      vf_loss: 5.195239067077637
    num_steps_sampled: 1025000
    num_steps_trained: 1025000
    wait_time_ms: 102.224
  iterations_since_restore: 205
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2502.088167667389
  time_this_iter_s: 11.560036420822144
  time_total_s: 2502.088167667389
  timestamp: 1593996504
  timesteps_since_restore: 1025000
  timesteps_this_iter: 5000
  timesteps_total: 1025000
  training_iteration: 205
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2502 s, 205 iter, 1025000 ts, 583 rew

agent-1: 113.0
agent-2: 93.0
agent-3: 121.0
agent-4: 101.0
agent-5: 111.0
Sum Reward: 539.0
Avg Reward: 107.8
Min Reward: 93.0
Gini Coefficient: 0.05046382189239332
20:20 Ratio: 1.3010752688172043
Max-min Ratio: 1.3010752688172043
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-48-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 583.33
  episode_reward_min: 375.0
  episodes_this_iter: 1
  episodes_total: 205
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.458
    dispatch_time_ms: 9.848
    learner:
      cur_lr: 0.0012917349813506007
      grad_gnorm: 40.0
      policy_entropy: 31.469581604003906
      policy_loss: 21.908164978027344
      var_gnorm: 39.394447326660156
      vf_explained_var: 0.521915853023529
      vf_loss: 39.046016693115234
    num_steps_sampled: 1030000
    num_steps_trained: 1030000
    wait_time_ms: 97.626
  iterations_since_restore: 206
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2513.1328523159027
  time_this_iter_s: 11.044684648513794
  time_total_s: 2513.1328523159027
  timestamp: 1593996515
  timesteps_since_restore: 1030000
  timesteps_this_iter: 5000
  timesteps_total: 1030000
  training_iteration: 206
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2513 s, 206 iter, 1030000 ts, 583 rew

agent-1: 124.0
agent-2: 132.0
agent-3: 118.0
agent-4: 140.0
agent-5: 123.0
Sum Reward: 637.0
Avg Reward: 127.4
Min Reward: 118.0
Gini Coefficient: 0.03328100470957614
20:20 Ratio: 1.1864406779661016
Max-min Ratio: 1.1864406779661016
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-48-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 581.45
  episode_reward_min: 375.0
  episodes_this_iter: 1
  episodes_total: 206
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.749
    dispatch_time_ms: 9.002
    learner:
      cur_lr: 0.0012914020335301757
      grad_gnorm: 40.000003814697266
      policy_entropy: 36.49229049682617
      policy_loss: -8.844279289245605
      var_gnorm: 39.49856948852539
      vf_explained_var: -0.33750414848327637
      vf_loss: 11.364612579345703
    num_steps_sampled: 1035000
    num_steps_trained: 1035000
    wait_time_ms: 93.494
  iterations_since_restore: 207
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2524.1821472644806
  time_this_iter_s: 11.04929494857788
  time_total_s: 2524.1821472644806
  timestamp: 1593996526
  timesteps_since_restore: 1035000
  timesteps_this_iter: 5000
  timesteps_total: 1035000
  training_iteration: 207
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2524 s, 207 iter, 1035000 ts, 581 rew

agent-1: 110.0
agent-2: 104.0
agent-3: 119.0
agent-4: 144.0
agent-5: 130.0
Sum Reward: 607.0
Avg Reward: 121.4
Min Reward: 104.0
Gini Coefficient: 0.06589785831960461
20:20 Ratio: 1.3846153846153846
Max-min Ratio: 1.3846153846153846
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-48-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 580.57
  episode_reward_min: 375.0
  episodes_this_iter: 1
  episodes_total: 207
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.059
    dispatch_time_ms: 9.576
    learner:
      cur_lr: 0.0012910689692944288
      grad_gnorm: 40.0
      policy_entropy: 45.49482345581055
      policy_loss: 5.037449359893799
      var_gnorm: 39.604774475097656
      vf_explained_var: -0.1918189525604248
      vf_loss: 40.87014389038086
    num_steps_sampled: 1040000
    num_steps_trained: 1040000
    wait_time_ms: 93.363
  iterations_since_restore: 208
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2535.1406235694885
  time_this_iter_s: 10.958476305007935
  time_total_s: 2535.1406235694885
  timestamp: 1593996537
  timesteps_since_restore: 1040000
  timesteps_this_iter: 5000
  timesteps_total: 1040000
  training_iteration: 208
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2535 s, 208 iter, 1040000 ts, 581 rew

agent-1: 105.0
agent-2: 136.0
agent-3: 148.0
agent-4: 128.0
agent-5: 139.0
Sum Reward: 656.0
Avg Reward: 131.2
Min Reward: 105.0
Gini Coefficient: 0.05914634146341463
20:20 Ratio: 1.4095238095238096
Max-min Ratio: 1.4095238095238096
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-49-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 580.16
  episode_reward_min: 375.0
  episodes_this_iter: 1
  episodes_total: 208
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.077
    dispatch_time_ms: 8.522
    learner:
      cur_lr: 0.0012907360214740038
      grad_gnorm: 39.999996185302734
      policy_entropy: 42.496116638183594
      policy_loss: -21.191692352294922
      var_gnorm: 39.67719268798828
      vf_explained_var: -0.19791698455810547
      vf_loss: 39.65677261352539
    num_steps_sampled: 1045000
    num_steps_trained: 1045000
    wait_time_ms: 92.555
  iterations_since_restore: 209
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2545.7253885269165
  time_this_iter_s: 10.584764957427979
  time_total_s: 2545.7253885269165
  timestamp: 1593996548
  timesteps_since_restore: 1045000
  timesteps_this_iter: 5000
  timesteps_total: 1045000
  training_iteration: 209
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2545 s, 209 iter, 1045000 ts, 580 rew

agent-1: 118.0
agent-2: 190.0
agent-3: 137.0
agent-4: 159.0
agent-5: 197.0
Sum Reward: 801.0
Avg Reward: 160.2
Min Reward: 118.0
Gini Coefficient: 0.10536828963795256
20:20 Ratio: 1.6694915254237288
Max-min Ratio: 1.6694915254237288
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-49-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 582.61
  episode_reward_min: 375.0
  episodes_this_iter: 1
  episodes_total: 209
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.153
    dispatch_time_ms: 9.297
    learner:
      cur_lr: 0.001290402957238257
      grad_gnorm: 40.0
      policy_entropy: 33.964393615722656
      policy_loss: -14.744427680969238
      var_gnorm: 39.78238296508789
      vf_explained_var: -1.0
      vf_loss: 29.02025032043457
    num_steps_sampled: 1050000
    num_steps_trained: 1050000
    wait_time_ms: 96.567
  iterations_since_restore: 210
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2556.5398123264313
  time_this_iter_s: 10.81442379951477
  time_total_s: 2556.5398123264313
  timestamp: 1593996559
  timesteps_since_restore: 1050000
  timesteps_this_iter: 5000
  timesteps_total: 1050000
  training_iteration: 210
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2556 s, 210 iter, 1050000 ts, 583 rew

agent-1: 106.0
agent-2: 128.0
agent-3: 108.0
agent-4: 120.0
agent-5: 122.0
Sum Reward: 584.0
Avg Reward: 116.8
Min Reward: 106.0
Gini Coefficient: 0.03972602739726028
20:20 Ratio: 1.2075471698113207
Max-min Ratio: 1.2075471698113207
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-49-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 582.4
  episode_reward_min: 375.0
  episodes_this_iter: 1
  episodes_total: 210
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.833
    dispatch_time_ms: 6.936
    learner:
      cur_lr: 0.001290070009417832
      grad_gnorm: 39.999996185302734
      policy_entropy: 42.39114761352539
      policy_loss: -0.14736148715019226
      var_gnorm: 39.75259017944336
      vf_explained_var: 0.2631802558898926
      vf_loss: 44.392669677734375
    num_steps_sampled: 1055000
    num_steps_trained: 1055000
    wait_time_ms: 100.875
  iterations_since_restore: 211
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2567.78919172287
  time_this_iter_s: 11.249379396438599
  time_total_s: 2567.78919172287
  timestamp: 1593996570
  timesteps_since_restore: 1055000
  timesteps_this_iter: 5000
  timesteps_total: 1055000
  training_iteration: 211
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2567 s, 211 iter, 1055000 ts, 582 rew

agent-1: 114.0
agent-2: 153.0
agent-3: 153.0
agent-4: 144.0
agent-5: 139.0
Sum Reward: 703.0
Avg Reward: 140.6
Min Reward: 114.0
Gini Coefficient: 0.052347083926031296
20:20 Ratio: 1.3421052631578947
Max-min Ratio: 1.3421052631578947
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-49-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 582.44
  episode_reward_min: 375.0
  episodes_this_iter: 1
  episodes_total: 211
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.718
    dispatch_time_ms: 9.492
    learner:
      cur_lr: 0.001289736945182085
      grad_gnorm: 40.0
      policy_entropy: 45.58230209350586
      policy_loss: 26.37700080871582
      var_gnorm: 39.79014205932617
      vf_explained_var: 0.7648211717605591
      vf_loss: 54.30529022216797
    num_steps_sampled: 1060000
    num_steps_trained: 1060000
    wait_time_ms: 97.967
  iterations_since_restore: 212
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2578.7133967876434
  time_this_iter_s: 10.92420506477356
  time_total_s: 2578.7133967876434
  timestamp: 1593996581
  timesteps_since_restore: 1060000
  timesteps_this_iter: 5000
  timesteps_total: 1060000
  training_iteration: 212
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2578 s, 212 iter, 1060000 ts, 582 rew

agent-1: 145.0
agent-2: 97.0
agent-3: 146.0
agent-4: 107.0
agent-5: 119.0
Sum Reward: 614.0
Avg Reward: 122.8
Min Reward: 97.0
Gini Coefficient: 0.08859934853420195
20:20 Ratio: 1.5051546391752577
Max-min Ratio: 1.5051546391752577
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-49-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 582.26
  episode_reward_min: 375.0
  episodes_this_iter: 1
  episodes_total: 212
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.355
    dispatch_time_ms: 6.885
    learner:
      cur_lr: 0.00128940399736166
      grad_gnorm: 40.0
      policy_entropy: 36.47124481201172
      policy_loss: 15.415550231933594
      var_gnorm: 39.84069061279297
      vf_explained_var: 0.12400990724563599
      vf_loss: 62.40104293823242
    num_steps_sampled: 1065000
    num_steps_trained: 1065000
    wait_time_ms: 106.299
  iterations_since_restore: 213
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2590.0363149642944
  time_this_iter_s: 11.322918176651001
  time_total_s: 2590.0363149642944
  timestamp: 1593996592
  timesteps_since_restore: 1065000
  timesteps_this_iter: 5000
  timesteps_total: 1065000
  training_iteration: 213
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2590 s, 213 iter, 1065000 ts, 582 rew

agent-1: 109.0
agent-2: 142.0
agent-3: 70.0
agent-4: 98.0
agent-5: 144.0
Sum Reward: 563.0
Avg Reward: 112.6
Min Reward: 70.0
Gini Coefficient: 0.1364120781527531
20:20 Ratio: 2.057142857142857
Max-min Ratio: 2.057142857142857
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-50-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 581.32
  episode_reward_min: 375.0
  episodes_this_iter: 1
  episodes_total: 213
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.717
    dispatch_time_ms: 13.012
    learner:
      cur_lr: 0.001289071049541235
      grad_gnorm: 40.00000762939453
      policy_entropy: 38.59867477416992
      policy_loss: 76.15685272216797
      var_gnorm: 39.914764404296875
      vf_explained_var: 0.22094953060150146
      vf_loss: 212.21939086914062
    num_steps_sampled: 1070000
    num_steps_trained: 1070000
    wait_time_ms: 109.065
  iterations_since_restore: 214
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2601.4201645851135
  time_this_iter_s: 11.383849620819092
  time_total_s: 2601.4201645851135
  timestamp: 1593996604
  timesteps_since_restore: 1070000
  timesteps_this_iter: 5000
  timesteps_total: 1070000
  training_iteration: 214
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2601 s, 214 iter, 1070000 ts, 581 rew

agent-1: 99.0
agent-2: 125.0
agent-3: 80.0
agent-4: 122.0
agent-5: 103.0
Sum Reward: 529.0
Avg Reward: 105.8
Min Reward: 80.0
Gini Coefficient: 0.08544423440453686
20:20 Ratio: 1.5625
Max-min Ratio: 1.5625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-50-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 581.0
  episode_reward_min: 375.0
  episodes_this_iter: 1
  episodes_total: 214
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.809
    dispatch_time_ms: 28.289
    learner:
      cur_lr: 0.0012887379853054881
      grad_gnorm: 40.00001525878906
      policy_entropy: 35.6322135925293
      policy_loss: -5.748135566711426
      var_gnorm: 39.94818878173828
      vf_explained_var: 0.9255276918411255
      vf_loss: 19.66228485107422
    num_steps_sampled: 1075000
    num_steps_trained: 1075000
    wait_time_ms: 79.619
  iterations_since_restore: 215
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2613.43936252594
  time_this_iter_s: 12.019197940826416
  time_total_s: 2613.43936252594
  timestamp: 1593996616
  timesteps_since_restore: 1075000
  timesteps_this_iter: 5000
  timesteps_total: 1075000
  training_iteration: 215
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2613 s, 215 iter, 1075000 ts, 581 rew

agent-1: 96.0
agent-2: 108.0
agent-3: 136.0
agent-4: 98.0
agent-5: 112.0
Sum Reward: 550.0
Avg Reward: 110.0
Min Reward: 96.0
Gini Coefficient: 0.06836363636363636
20:20 Ratio: 1.4166666666666667
Max-min Ratio: 1.4166666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-50-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 580.9
  episode_reward_min: 375.0
  episodes_this_iter: 1
  episodes_total: 215
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.189
    dispatch_time_ms: 40.993
    learner:
      cur_lr: 0.001288405037485063
      grad_gnorm: 40.0
      policy_entropy: 38.12325668334961
      policy_loss: -18.488502502441406
      var_gnorm: 40.007423400878906
      vf_explained_var: -0.3966940641403198
      vf_loss: 17.17633819580078
    num_steps_sampled: 1080000
    num_steps_trained: 1080000
    wait_time_ms: 75.498
  iterations_since_restore: 216
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2625.0398077964783
  time_this_iter_s: 11.60044527053833
  time_total_s: 2625.0398077964783
  timestamp: 1593996628
  timesteps_since_restore: 1080000
  timesteps_this_iter: 5000
  timesteps_total: 1080000
  training_iteration: 216
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2625 s, 216 iter, 1080000 ts, 581 rew

agent-1: 148.0
agent-2: 131.0
agent-3: 130.0
agent-4: 155.0
agent-5: 177.0
Sum Reward: 741.0
Avg Reward: 148.2
Min Reward: 130.0
Gini Coefficient: 0.06369770580296896
20:20 Ratio: 1.3615384615384616
Max-min Ratio: 1.3615384615384616
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-50-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 582.61
  episode_reward_min: 375.0
  episodes_this_iter: 1
  episodes_total: 216
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.637
    dispatch_time_ms: 24.889
    learner:
      cur_lr: 0.0012880719732493162
      grad_gnorm: 28.4700870513916
      policy_entropy: 32.37627029418945
      policy_loss: -6.439225673675537
      var_gnorm: 40.09145736694336
      vf_explained_var: 0.5419567823410034
      vf_loss: 16.046180725097656
    num_steps_sampled: 1085000
    num_steps_trained: 1085000
    wait_time_ms: 85.351
  iterations_since_restore: 217
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2636.868104457855
  time_this_iter_s: 11.828296661376953
  time_total_s: 2636.868104457855
  timestamp: 1593996639
  timesteps_since_restore: 1085000
  timesteps_this_iter: 5000
  timesteps_total: 1085000
  training_iteration: 217
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2636 s, 217 iter, 1085000 ts, 583 rew

agent-1: 85.0
agent-2: 115.0
agent-3: 100.0
agent-4: 132.0
agent-5: 137.0
Sum Reward: 569.0
Avg Reward: 113.8
Min Reward: 85.0
Gini Coefficient: 0.09560632688927943
20:20 Ratio: 1.611764705882353
Max-min Ratio: 1.611764705882353
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-50-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 581.05
  episode_reward_min: 375.0
  episodes_this_iter: 1
  episodes_total: 217
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.597
    dispatch_time_ms: 33.919
    learner:
      cur_lr: 0.0012877390254288912
      grad_gnorm: 40.0000114440918
      policy_entropy: 24.23783302307129
      policy_loss: 14.175732612609863
      var_gnorm: 40.10449981689453
      vf_explained_var: -0.11632430553436279
      vf_loss: 59.7946662902832
    num_steps_sampled: 1090000
    num_steps_trained: 1090000
    wait_time_ms: 83.156
  iterations_since_restore: 218
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2648.677757024765
  time_this_iter_s: 11.80965256690979
  time_total_s: 2648.677757024765
  timestamp: 1593996651
  timesteps_since_restore: 1090000
  timesteps_this_iter: 5000
  timesteps_total: 1090000
  training_iteration: 218
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2648 s, 218 iter, 1090000 ts, 581 rew

agent-1: 156.0
agent-2: 139.0
agent-3: 109.0
agent-4: 154.0
agent-5: 171.0
Sum Reward: 729.0
Avg Reward: 145.8
Min Reward: 109.0
Gini Coefficient: 0.07736625514403292
20:20 Ratio: 1.5688073394495412
Max-min Ratio: 1.5688073394495412
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-51-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 581.34
  episode_reward_min: 375.0
  episodes_this_iter: 1
  episodes_total: 218
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.015
    dispatch_time_ms: 44.007
    learner:
      cur_lr: 0.0012874059611931443
      grad_gnorm: 40.0
      policy_entropy: 43.72130584716797
      policy_loss: -17.32407569885254
      var_gnorm: 40.1506233215332
      vf_explained_var: 0.9258788824081421
      vf_loss: 3.6673851013183594
    num_steps_sampled: 1095000
    num_steps_trained: 1095000
    wait_time_ms: 77.085
  iterations_since_restore: 219
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2660.7536890506744
  time_this_iter_s: 12.075932025909424
  time_total_s: 2660.7536890506744
  timestamp: 1593996663
  timesteps_since_restore: 1095000
  timesteps_this_iter: 5000
  timesteps_total: 1095000
  training_iteration: 219
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2660 s, 219 iter, 1095000 ts, 581 rew

agent-1: 98.0
agent-2: 98.0
agent-3: 79.0
agent-4: 109.0
agent-5: 91.0
Sum Reward: 475.0
Avg Reward: 95.0
Min Reward: 79.0
Gini Coefficient: 0.05642105263157895
20:20 Ratio: 1.379746835443038
Max-min Ratio: 1.379746835443038
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-51-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 579.56
  episode_reward_min: 375.0
  episodes_this_iter: 1
  episodes_total: 219
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.492
    dispatch_time_ms: 22.084
    learner:
      cur_lr: 0.0012870730133727193
      grad_gnorm: 39.999996185302734
      policy_entropy: 51.35108947753906
      policy_loss: -24.223840713500977
      var_gnorm: 40.17960739135742
      vf_explained_var: 0.17807334661483765
      vf_loss: 17.705106735229492
    num_steps_sampled: 1100000
    num_steps_trained: 1100000
    wait_time_ms: 103.582
  iterations_since_restore: 220
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2672.8488459587097
  time_this_iter_s: 12.095156908035278
  time_total_s: 2672.8488459587097
  timestamp: 1593996676
  timesteps_since_restore: 1100000
  timesteps_this_iter: 5000
  timesteps_total: 1100000
  training_iteration: 220
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2672 s, 220 iter, 1100000 ts, 580 rew

agent-1: 83.0
agent-2: 107.0
agent-3: 112.0
agent-4: 89.0
agent-5: 119.0
Sum Reward: 510.0
Avg Reward: 102.0
Min Reward: 83.0
Gini Coefficient: 0.07450980392156863
20:20 Ratio: 1.4337349397590362
Max-min Ratio: 1.4337349397590362
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-51-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 578.0
  episode_reward_min: 375.0
  episodes_this_iter: 1
  episodes_total: 220
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.063
    dispatch_time_ms: 39.021
    learner:
      cur_lr: 0.0012867399491369724
      grad_gnorm: 40.0
      policy_entropy: 48.05253219604492
      policy_loss: 32.55941390991211
      var_gnorm: 40.282493591308594
      vf_explained_var: 0.634412944316864
      vf_loss: 78.11778259277344
    num_steps_sampled: 1105000
    num_steps_trained: 1105000
    wait_time_ms: 129.992
  iterations_since_restore: 221
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2685.526827096939
  time_this_iter_s: 12.67798113822937
  time_total_s: 2685.526827096939
  timestamp: 1593996688
  timesteps_since_restore: 1105000
  timesteps_this_iter: 5000
  timesteps_total: 1105000
  training_iteration: 221
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2685 s, 221 iter, 1105000 ts, 578 rew

agent-1: 89.0
agent-2: 119.0
agent-3: 101.0
agent-4: 98.0
agent-5: 105.0
Sum Reward: 512.0
Avg Reward: 102.4
Min Reward: 89.0
Gini Coefficient: 0.05234375
20:20 Ratio: 1.3370786516853932
Max-min Ratio: 1.3370786516853932
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-51-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 575.86
  episode_reward_min: 375.0
  episodes_this_iter: 1
  episodes_total: 221
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.056
    dispatch_time_ms: 6.664
    learner:
      cur_lr: 0.0012864070013165474
      grad_gnorm: 40.000003814697266
      policy_entropy: 50.63800048828125
      policy_loss: -5.403360366821289
      var_gnorm: 40.33452224731445
      vf_explained_var: 0.681136965751648
      vf_loss: 7.8119306564331055
    num_steps_sampled: 1110000
    num_steps_trained: 1110000
    wait_time_ms: 98.705
  iterations_since_restore: 222
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2696.779461145401
  time_this_iter_s: 11.252634048461914
  time_total_s: 2696.779461145401
  timestamp: 1593996700
  timesteps_since_restore: 1110000
  timesteps_this_iter: 5000
  timesteps_total: 1110000
  training_iteration: 222
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2696 s, 222 iter, 1110000 ts, 576 rew

agent-1: 90.0
agent-2: 105.0
agent-3: 89.0
agent-4: 104.0
agent-5: 106.0
Sum Reward: 494.0
Avg Reward: 98.8
Min Reward: 89.0
Gini Coefficient: 0.03967611336032389
20:20 Ratio: 1.1910112359550562
Max-min Ratio: 1.1910112359550562
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-51-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 575.87
  episode_reward_min: 375.0
  episodes_this_iter: 1
  episodes_total: 222
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.972
    dispatch_time_ms: 5.975
    learner:
      cur_lr: 0.0012860740534961224
      grad_gnorm: 40.000003814697266
      policy_entropy: 43.23906707763672
      policy_loss: 6.612098217010498
      var_gnorm: 40.38751220703125
      vf_explained_var: 0.2521846890449524
      vf_loss: 34.35585403442383
    num_steps_sampled: 1115000
    num_steps_trained: 1115000
    wait_time_ms: 96.026
  iterations_since_restore: 223
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2708.3124146461487
  time_this_iter_s: 11.53295350074768
  time_total_s: 2708.3124146461487
  timestamp: 1593996711
  timesteps_since_restore: 1115000
  timesteps_this_iter: 5000
  timesteps_total: 1115000
  training_iteration: 223
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2708 s, 223 iter, 1115000 ts, 576 rew

agent-1: 83.0
agent-2: 104.0
agent-3: 99.0
agent-4: 104.0
agent-5: 98.0
Sum Reward: 488.0
Avg Reward: 97.6
Min Reward: 83.0
Gini Coefficient: 0.03934426229508197
20:20 Ratio: 1.2530120481927711
Max-min Ratio: 1.2530120481927711
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-52-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 573.79
  episode_reward_min: 375.0
  episodes_this_iter: 1
  episodes_total: 223
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.709
    dispatch_time_ms: 6.155
    learner:
      cur_lr: 0.0012857409892603755
      grad_gnorm: 39.9999885559082
      policy_entropy: 31.085159301757812
      policy_loss: 17.308135986328125
      var_gnorm: 40.4406623840332
      vf_explained_var: 0.15629571676254272
      vf_loss: 44.258235931396484
    num_steps_sampled: 1120000
    num_steps_trained: 1120000
    wait_time_ms: 104.915
  iterations_since_restore: 224
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2719.6749954223633
  time_this_iter_s: 11.3625807762146
  time_total_s: 2719.6749954223633
  timestamp: 1593996723
  timesteps_since_restore: 1120000
  timesteps_this_iter: 5000
  timesteps_total: 1120000
  training_iteration: 224
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2719 s, 224 iter, 1120000 ts, 574 rew

agent-1: 129.0
agent-2: 120.0
agent-3: 133.0
agent-4: 135.0
agent-5: 127.0
Sum Reward: 644.0
Avg Reward: 128.8
Min Reward: 120.0
Gini Coefficient: 0.02236024844720497
20:20 Ratio: 1.125
Max-min Ratio: 1.125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-52-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 572.87
  episode_reward_min: 375.0
  episodes_this_iter: 1
  episodes_total: 224
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.192
    dispatch_time_ms: 8.262
    learner:
      cur_lr: 0.0012854080414399505
      grad_gnorm: 38.80156707763672
      policy_entropy: 46.838104248046875
      policy_loss: 6.780488014221191
      var_gnorm: 40.49751663208008
      vf_explained_var: 0.6436164379119873
      vf_loss: 10.129481315612793
    num_steps_sampled: 1125000
    num_steps_trained: 1125000
    wait_time_ms: 100.745
  iterations_since_restore: 225
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2731.4615590572357
  time_this_iter_s: 11.786563634872437
  time_total_s: 2731.4615590572357
  timestamp: 1593996734
  timesteps_since_restore: 1125000
  timesteps_this_iter: 5000
  timesteps_total: 1125000
  training_iteration: 225
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2731 s, 225 iter, 1125000 ts, 573 rew

agent-1: 71.0
agent-2: 62.0
agent-3: 94.0
agent-4: 62.0
agent-5: 71.0
Sum Reward: 360.0
Avg Reward: 72.0
Min Reward: 62.0
Gini Coefficient: 0.0811111111111111
20:20 Ratio: 1.5161290322580645
Max-min Ratio: 1.5161290322580645
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-52-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 569.0
  episode_reward_min: 360.0
  episodes_this_iter: 1
  episodes_total: 225
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.974
    dispatch_time_ms: 6.271
    learner:
      cur_lr: 0.0012850749772042036
      grad_gnorm: 39.999996185302734
      policy_entropy: 42.20185089111328
      policy_loss: -9.358007431030273
      var_gnorm: 40.543617248535156
      vf_explained_var: 0.9667816162109375
      vf_loss: 5.008997440338135
    num_steps_sampled: 1130000
    num_steps_trained: 1130000
    wait_time_ms: 111.84
  iterations_since_restore: 226
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2743.2250423431396
  time_this_iter_s: 11.76348328590393
  time_total_s: 2743.2250423431396
  timestamp: 1593996746
  timesteps_since_restore: 1130000
  timesteps_this_iter: 5000
  timesteps_total: 1130000
  training_iteration: 226
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2743 s, 226 iter, 1130000 ts, 569 rew

agent-1: 85.0
agent-2: 78.0
agent-3: 75.0
agent-4: 103.0
agent-5: 102.0
Sum Reward: 443.0
Avg Reward: 88.6
Min Reward: 75.0
Gini Coefficient: 0.07223476297968397
20:20 Ratio: 1.3733333333333333
Max-min Ratio: 1.3733333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-52-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 569.38
  episode_reward_min: 360.0
  episodes_this_iter: 1
  episodes_total: 226
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.667
    dispatch_time_ms: 7.761
    learner:
      cur_lr: 0.0012847420293837786
      grad_gnorm: 24.780420303344727
      policy_entropy: 29.89544677734375
      policy_loss: -3.930337429046631
      var_gnorm: 40.52264404296875
      vf_explained_var: 0.7585883736610413
      vf_loss: 17.08534049987793
    num_steps_sampled: 1135000
    num_steps_trained: 1135000
    wait_time_ms: 110.816
  iterations_since_restore: 227
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2754.89532327652
  time_this_iter_s: 11.670280933380127
  time_total_s: 2754.89532327652
  timestamp: 1593996758
  timesteps_since_restore: 1135000
  timesteps_this_iter: 5000
  timesteps_total: 1135000
  training_iteration: 227
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2754 s, 227 iter, 1135000 ts, 569 rew

agent-1: 114.0
agent-2: 92.0
agent-3: 153.0
agent-4: 79.0
agent-5: 135.0
Sum Reward: 573.0
Avg Reward: 114.6
Min Reward: 79.0
Gini Coefficient: 0.13333333333333333
20:20 Ratio: 1.9367088607594938
Max-min Ratio: 1.9367088607594938
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-52-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 569.68
  episode_reward_min: 360.0
  episodes_this_iter: 1
  episodes_total: 227
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.079
    dispatch_time_ms: 6.605
    learner:
      cur_lr: 0.0012844089651480317
      grad_gnorm: 40.0
      policy_entropy: 43.682376861572266
      policy_loss: -7.653302192687988
      var_gnorm: 40.603515625
      vf_explained_var: 0.9357653260231018
      vf_loss: 10.097297668457031
    num_steps_sampled: 1140000
    num_steps_trained: 1140000
    wait_time_ms: 104.509
  iterations_since_restore: 228
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2766.757764816284
  time_this_iter_s: 11.862441539764404
  time_total_s: 2766.757764816284
  timestamp: 1593996770
  timesteps_since_restore: 1140000
  timesteps_this_iter: 5000
  timesteps_total: 1140000
  training_iteration: 228
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2766 s, 228 iter, 1140000 ts, 570 rew

agent-1: 85.0
agent-2: 80.0
agent-3: 71.0
agent-4: 107.0
agent-5: 109.0
Sum Reward: 452.0
Avg Reward: 90.4
Min Reward: 71.0
Gini Coefficient: 0.09115044247787611
20:20 Ratio: 1.5352112676056338
Max-min Ratio: 1.5352112676056338
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-53-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 568.59
  episode_reward_min: 360.0
  episodes_this_iter: 1
  episodes_total: 228
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.171
    dispatch_time_ms: 6.529
    learner:
      cur_lr: 0.0012840760173276067
      grad_gnorm: 28.94849395751953
      policy_entropy: 47.16492462158203
      policy_loss: -7.607710838317871
      var_gnorm: 40.596221923828125
      vf_explained_var: 0.9778962731361389
      vf_loss: 2.481759786605835
    num_steps_sampled: 1145000
    num_steps_trained: 1145000
    wait_time_ms: 116.06
  iterations_since_restore: 229
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2778.8261938095093
  time_this_iter_s: 12.068428993225098
  time_total_s: 2778.8261938095093
  timestamp: 1593996782
  timesteps_since_restore: 1145000
  timesteps_this_iter: 5000
  timesteps_total: 1145000
  training_iteration: 229
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2778 s, 229 iter, 1145000 ts, 569 rew

agent-1: 88.0
agent-2: 75.0
agent-3: 80.0
agent-4: 73.0
agent-5: 101.0
Sum Reward: 417.0
Avg Reward: 83.4
Min Reward: 73.0
Gini Coefficient: 0.06618705035971223
20:20 Ratio: 1.3835616438356164
Max-min Ratio: 1.3835616438356164
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-53-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 567.81
  episode_reward_min: 360.0
  episodes_this_iter: 1
  episodes_total: 229
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.99
    dispatch_time_ms: 10.316
    learner:
      cur_lr: 0.0012837429530918598
      grad_gnorm: 40.0
      policy_entropy: 18.71919822692871
      policy_loss: 17.555606842041016
      var_gnorm: 40.588134765625
      vf_explained_var: 0.917942464351654
      vf_loss: 37.99446487426758
    num_steps_sampled: 1150000
    num_steps_trained: 1150000
    wait_time_ms: 106.617
  iterations_since_restore: 230
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2791.0640890598297
  time_this_iter_s: 12.237895250320435
  time_total_s: 2791.0640890598297
  timestamp: 1593996794
  timesteps_since_restore: 1150000
  timesteps_this_iter: 5000
  timesteps_total: 1150000
  training_iteration: 230
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2791 s, 230 iter, 1150000 ts, 568 rew

agent-1: 76.0
agent-2: 57.0
agent-3: 88.0
agent-4: 77.0
agent-5: 67.0
Sum Reward: 365.0
Avg Reward: 73.0
Min Reward: 57.0
Gini Coefficient: 0.0789041095890411
20:20 Ratio: 1.543859649122807
Max-min Ratio: 1.543859649122807
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-53-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 566.34
  episode_reward_min: 360.0
  episodes_this_iter: 1
  episodes_total: 230
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.865
    dispatch_time_ms: 8.479
    learner:
      cur_lr: 0.0012834100052714348
      grad_gnorm: 40.00000762939453
      policy_entropy: 14.475467681884766
      policy_loss: -20.472822189331055
      var_gnorm: 40.631080627441406
      vf_explained_var: 0.019844412803649902
      vf_loss: 49.430389404296875
    num_steps_sampled: 1155000
    num_steps_trained: 1155000
    wait_time_ms: 107.706
  iterations_since_restore: 231
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2803.0216867923737
  time_this_iter_s: 11.957597732543945
  time_total_s: 2803.0216867923737
  timestamp: 1593996806
  timesteps_since_restore: 1155000
  timesteps_this_iter: 5000
  timesteps_total: 1155000
  training_iteration: 231
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2803 s, 231 iter, 1155000 ts, 566 rew

agent-1: 52.0
agent-2: 70.0
agent-3: 79.0
agent-4: 81.0
agent-5: 81.0
Sum Reward: 363.0
Avg Reward: 72.6
Min Reward: 52.0
Gini Coefficient: 0.07603305785123966
20:20 Ratio: 1.5576923076923077
Max-min Ratio: 1.5576923076923077
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-53-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 564.59
  episode_reward_min: 360.0
  episodes_this_iter: 1
  episodes_total: 231
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.29
    dispatch_time_ms: 6.263
    learner:
      cur_lr: 0.0012830770574510098
      grad_gnorm: 40.0
      policy_entropy: 19.600475311279297
      policy_loss: 23.34575653076172
      var_gnorm: 40.71135711669922
      vf_explained_var: -0.1026616096496582
      vf_loss: 123.78815460205078
    num_steps_sampled: 1160000
    num_steps_trained: 1160000
    wait_time_ms: 108.577
  iterations_since_restore: 232
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2815.046486377716
  time_this_iter_s: 12.024799585342407
  time_total_s: 2815.046486377716
  timestamp: 1593996818
  timesteps_since_restore: 1160000
  timesteps_this_iter: 5000
  timesteps_total: 1160000
  training_iteration: 232
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2815 s, 232 iter, 1160000 ts, 565 rew

agent-1: 77.0
agent-2: 74.0
agent-3: 104.0
agent-4: 59.0
agent-5: 76.0
Sum Reward: 390.0
Avg Reward: 78.0
Min Reward: 59.0
Gini Coefficient: 0.09538461538461539
20:20 Ratio: 1.7627118644067796
Max-min Ratio: 1.7627118644067796
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-53-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 564.31
  episode_reward_min: 360.0
  episodes_this_iter: 1
  episodes_total: 232
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.884
    dispatch_time_ms: 6.235
    learner:
      cur_lr: 0.0012827439932152629
      grad_gnorm: 40.0
      policy_entropy: 15.439043045043945
      policy_loss: 26.15311622619629
      var_gnorm: 40.67889404296875
      vf_explained_var: -0.6228551864624023
      vf_loss: 85.55579376220703
    num_steps_sampled: 1165000
    num_steps_trained: 1165000
    wait_time_ms: 102.161
  iterations_since_restore: 233
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2826.8957076072693
  time_this_iter_s: 11.849221229553223
  time_total_s: 2826.8957076072693
  timestamp: 1593996830
  timesteps_since_restore: 1165000
  timesteps_this_iter: 5000
  timesteps_total: 1165000
  training_iteration: 233
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2826 s, 233 iter, 1165000 ts, 564 rew

agent-1: 76.0
agent-2: 64.0
agent-3: 95.0
agent-4: 77.0
agent-5: 84.0
Sum Reward: 396.0
Avg Reward: 79.2
Min Reward: 64.0
Gini Coefficient: 0.0707070707070707
20:20 Ratio: 1.484375
Max-min Ratio: 1.484375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-54-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 561.57
  episode_reward_min: 360.0
  episodes_this_iter: 1
  episodes_total: 233
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.773
    dispatch_time_ms: 6.863
    learner:
      cur_lr: 0.0012824110453948379
      grad_gnorm: 22.698728561401367
      policy_entropy: 32.48040008544922
      policy_loss: -3.866328477859497
      var_gnorm: 40.70759201049805
      vf_explained_var: 0.9840624928474426
      vf_loss: 2.1713950634002686
    num_steps_sampled: 1170000
    num_steps_trained: 1170000
    wait_time_ms: 96.629
  iterations_since_restore: 234
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2838.6037759780884
  time_this_iter_s: 11.708068370819092
  time_total_s: 2838.6037759780884
  timestamp: 1593996842
  timesteps_since_restore: 1170000
  timesteps_this_iter: 5000
  timesteps_total: 1170000
  training_iteration: 234
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2838 s, 234 iter, 1170000 ts, 562 rew

agent-1: 124.0
agent-2: 85.0
agent-3: 137.0
agent-4: 89.0
agent-5: 85.0
Sum Reward: 520.0
Avg Reward: 104.0
Min Reward: 85.0
Gini Coefficient: 0.11
20:20 Ratio: 1.611764705882353
Max-min Ratio: 1.611764705882353
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-54-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 562.04
  episode_reward_min: 360.0
  episodes_this_iter: 1
  episodes_total: 234
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.605
    dispatch_time_ms: 6.336
    learner:
      cur_lr: 0.001282077981159091
      grad_gnorm: 20.61020851135254
      policy_entropy: 35.55961608886719
      policy_loss: -3.805882692337036
      var_gnorm: 40.85468673706055
      vf_explained_var: 0.9029314517974854
      vf_loss: 4.685753345489502
    num_steps_sampled: 1175000
    num_steps_trained: 1175000
    wait_time_ms: 118.97
  iterations_since_restore: 235
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2850.450567483902
  time_this_iter_s: 11.846791505813599
  time_total_s: 2850.450567483902
  timestamp: 1593996854
  timesteps_since_restore: 1175000
  timesteps_this_iter: 5000
  timesteps_total: 1175000
  training_iteration: 235
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2850 s, 235 iter, 1175000 ts, 562 rew

agent-1: 124.0
agent-2: 120.0
agent-3: 82.0
agent-4: 71.0
agent-5: 80.0
Sum Reward: 477.0
Avg Reward: 95.4
Min Reward: 71.0
Gini Coefficient: 0.12243186582809225
20:20 Ratio: 1.7464788732394365
Max-min Ratio: 1.7464788732394365
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-54-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 562.58
  episode_reward_min: 360.0
  episodes_this_iter: 1
  episodes_total: 235
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.244
    dispatch_time_ms: 7.235
    learner:
      cur_lr: 0.001281745033338666
      grad_gnorm: 7.902299404144287
      policy_entropy: 45.89323425292969
      policy_loss: 1.799371361732483
      var_gnorm: 40.8338737487793
      vf_explained_var: 0.9878507852554321
      vf_loss: 0.07457690685987473
    num_steps_sampled: 1180000
    num_steps_trained: 1180000
    wait_time_ms: 105.433
  iterations_since_restore: 236
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2862.3524312973022
  time_this_iter_s: 11.901863813400269
  time_total_s: 2862.3524312973022
  timestamp: 1593996866
  timesteps_since_restore: 1180000
  timesteps_this_iter: 5000
  timesteps_total: 1180000
  training_iteration: 236
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2862 s, 236 iter, 1180000 ts, 563 rew

agent-1: 100.0
agent-2: 82.0
agent-3: 67.0
agent-4: 52.0
agent-5: 73.0
Sum Reward: 374.0
Avg Reward: 74.8
Min Reward: 52.0
Gini Coefficient: 0.11871657754010695
20:20 Ratio: 1.9230769230769231
Max-min Ratio: 1.9230769230769231
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-54-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 560.98
  episode_reward_min: 360.0
  episodes_this_iter: 1
  episodes_total: 236
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.742
    dispatch_time_ms: 5.71
    learner:
      cur_lr: 0.001281411969102919
      grad_gnorm: 39.99998092651367
      policy_entropy: 31.720046997070312
      policy_loss: 45.13679885864258
      var_gnorm: 40.90778732299805
      vf_explained_var: 0.5897586345672607
      vf_loss: 211.03262329101562
    num_steps_sampled: 1185000
    num_steps_trained: 1185000
    wait_time_ms: 108.048
  iterations_since_restore: 237
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2874.2491211891174
  time_this_iter_s: 11.896689891815186
  time_total_s: 2874.2491211891174
  timestamp: 1593996878
  timesteps_since_restore: 1185000
  timesteps_this_iter: 5000
  timesteps_total: 1185000
  training_iteration: 237
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2874 s, 237 iter, 1185000 ts, 561 rew

agent-1: 90.0
agent-2: 82.0
agent-3: 74.0
agent-4: 68.0
agent-5: 67.0
Sum Reward: 381.0
Avg Reward: 76.2
Min Reward: 67.0
Gini Coefficient: 0.06299212598425197
20:20 Ratio: 1.3432835820895523
Max-min Ratio: 1.3432835820895523
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-54-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 558.65
  episode_reward_min: 360.0
  episodes_this_iter: 1
  episodes_total: 237
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.22
    dispatch_time_ms: 8.631
    learner:
      cur_lr: 0.001281079021282494
      grad_gnorm: 40.0
      policy_entropy: 38.436580657958984
      policy_loss: -1.568336009979248
      var_gnorm: 40.91012954711914
      vf_explained_var: 0.19875824451446533
      vf_loss: 24.287628173828125
    num_steps_sampled: 1190000
    num_steps_trained: 1190000
    wait_time_ms: 106.384
  iterations_since_restore: 238
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2886.0763154029846
  time_this_iter_s: 11.827194213867188
  time_total_s: 2886.0763154029846
  timestamp: 1593996889
  timesteps_since_restore: 1190000
  timesteps_this_iter: 5000
  timesteps_total: 1190000
  training_iteration: 238
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2886 s, 238 iter, 1190000 ts, 559 rew

agent-1: 57.0
agent-2: 72.0
agent-3: 97.0
agent-4: 73.0
agent-5: 54.0
Sum Reward: 353.0
Avg Reward: 70.6
Min Reward: 54.0
Gini Coefficient: 0.11558073654390935
20:20 Ratio: 1.7962962962962963
Max-min Ratio: 1.7962962962962963
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-55-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 557.36
  episode_reward_min: 353.0
  episodes_this_iter: 1
  episodes_total: 238
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.517
    dispatch_time_ms: 7.324
    learner:
      cur_lr: 0.0012807459570467472
      grad_gnorm: 40.00000762939453
      policy_entropy: 34.026214599609375
      policy_loss: -21.37047576904297
      var_gnorm: 41.00453186035156
      vf_explained_var: 0.9054180979728699
      vf_loss: 62.48418045043945
    num_steps_sampled: 1195000
    num_steps_trained: 1195000
    wait_time_ms: 105.098
  iterations_since_restore: 239
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2897.7232871055603
  time_this_iter_s: 11.646971702575684
  time_total_s: 2897.7232871055603
  timestamp: 1593996901
  timesteps_since_restore: 1195000
  timesteps_this_iter: 5000
  timesteps_total: 1195000
  training_iteration: 239
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2897 s, 239 iter, 1195000 ts, 557 rew

agent-1: 111.0
agent-2: 116.0
agent-3: 81.0
agent-4: 83.0
agent-5: 76.0
Sum Reward: 467.0
Avg Reward: 93.4
Min Reward: 76.0
Gini Coefficient: 0.09421841541755889
20:20 Ratio: 1.5263157894736843
Max-min Ratio: 1.5263157894736843
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-55-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 556.57
  episode_reward_min: 353.0
  episodes_this_iter: 1
  episodes_total: 239
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.813
    dispatch_time_ms: 7.281
    learner:
      cur_lr: 0.0012804130092263222
      grad_gnorm: 27.60403060913086
      policy_entropy: 31.971872329711914
      policy_loss: -5.036792278289795
      var_gnorm: 41.189613342285156
      vf_explained_var: 0.841636061668396
      vf_loss: 7.126400947570801
    num_steps_sampled: 1200000
    num_steps_trained: 1200000
    wait_time_ms: 111.783
  iterations_since_restore: 240
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2909.5759716033936
  time_this_iter_s: 11.852684497833252
  time_total_s: 2909.5759716033936
  timestamp: 1593996913
  timesteps_since_restore: 1200000
  timesteps_this_iter: 5000
  timesteps_total: 1200000
  training_iteration: 240
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2909 s, 240 iter, 1200000 ts, 557 rew

agent-1: 65.0
agent-2: 89.0
agent-3: 69.0
agent-4: 58.0
agent-5: 72.0
Sum Reward: 353.0
Avg Reward: 70.6
Min Reward: 58.0
Gini Coefficient: 0.07818696883852691
20:20 Ratio: 1.5344827586206897
Max-min Ratio: 1.5344827586206897
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-55-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 555.3
  episode_reward_min: 353.0
  episodes_this_iter: 1
  episodes_total: 240
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.709
    dispatch_time_ms: 8.095
    learner:
      cur_lr: 0.0012800799449905753
      grad_gnorm: 14.846948623657227
      policy_entropy: 47.880210876464844
      policy_loss: -4.645061492919922
      var_gnorm: 41.254676818847656
      vf_explained_var: 0.23630815744400024
      vf_loss: 1.4389616250991821
    num_steps_sampled: 1205000
    num_steps_trained: 1205000
    wait_time_ms: 103.227
  iterations_since_restore: 241
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2921.25795173645
  time_this_iter_s: 11.68198013305664
  time_total_s: 2921.25795173645
  timestamp: 1593996925
  timesteps_since_restore: 1205000
  timesteps_this_iter: 5000
  timesteps_total: 1205000
  training_iteration: 241
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2921 s, 241 iter, 1205000 ts, 555 rew

agent-1: 131.0
agent-2: 84.0
agent-3: 116.0
agent-4: 112.0
agent-5: 94.0
Sum Reward: 537.0
Avg Reward: 107.4
Min Reward: 84.0
Gini Coefficient: 0.08640595903165736
20:20 Ratio: 1.5595238095238095
Max-min Ratio: 1.5595238095238095
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-55-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 555.38
  episode_reward_min: 353.0
  episodes_this_iter: 1
  episodes_total: 241
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.106
    dispatch_time_ms: 7.505
    learner:
      cur_lr: 0.0012797469971701503
      grad_gnorm: 39.999996185302734
      policy_entropy: 30.114660263061523
      policy_loss: -8.669208526611328
      var_gnorm: 41.31267547607422
      vf_explained_var: -1.0
      vf_loss: 154.28147888183594
    num_steps_sampled: 1210000
    num_steps_trained: 1210000
    wait_time_ms: 98.45
  iterations_since_restore: 242
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2933.1299295425415
  time_this_iter_s: 11.871977806091309
  time_total_s: 2933.1299295425415
  timestamp: 1593996937
  timesteps_since_restore: 1210000
  timesteps_this_iter: 5000
  timesteps_total: 1210000
  training_iteration: 242
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2933 s, 242 iter, 1210000 ts, 555 rew

agent-1: 95.0
agent-2: 76.0
agent-3: 74.0
agent-4: 61.0
agent-5: 126.0
Sum Reward: 432.0
Avg Reward: 86.4
Min Reward: 61.0
Gini Coefficient: 0.1398148148148148
20:20 Ratio: 2.0655737704918034
Max-min Ratio: 2.0655737704918034
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-55-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 555.18
  episode_reward_min: 353.0
  episodes_this_iter: 1
  episodes_total: 242
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.483
    dispatch_time_ms: 8.975
    learner:
      cur_lr: 0.0012794140493497252
      grad_gnorm: 33.25217819213867
      policy_entropy: 51.20435333251953
      policy_loss: 8.832893371582031
      var_gnorm: 41.481807708740234
      vf_explained_var: 0.41675370931625366
      vf_loss: 14.243611335754395
    num_steps_sampled: 1215000
    num_steps_trained: 1215000
    wait_time_ms: 104.774
  iterations_since_restore: 243
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2944.789228439331
  time_this_iter_s: 11.65929889678955
  time_total_s: 2944.789228439331
  timestamp: 1593996948
  timesteps_since_restore: 1215000
  timesteps_this_iter: 5000
  timesteps_total: 1215000
  training_iteration: 243
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2944 s, 243 iter, 1215000 ts, 555 rew

agent-1: 111.0
agent-2: 106.0
agent-3: 91.0
agent-4: 99.0
agent-5: 76.0
Sum Reward: 483.0
Avg Reward: 96.6
Min Reward: 76.0
Gini Coefficient: 0.07039337474120083
20:20 Ratio: 1.4605263157894737
Max-min Ratio: 1.4605263157894737
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-56-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 554.95
  episode_reward_min: 353.0
  episodes_this_iter: 1
  episodes_total: 243
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.167
    dispatch_time_ms: 9.281
    learner:
      cur_lr: 0.0012790809851139784
      grad_gnorm: 40.0
      policy_entropy: 16.229814529418945
      policy_loss: -30.05839729309082
      var_gnorm: 41.499107360839844
      vf_explained_var: 0.35529786348342896
      vf_loss: 134.83831787109375
    num_steps_sampled: 1220000
    num_steps_trained: 1220000
    wait_time_ms: 98.442
  iterations_since_restore: 244
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2956.3179194927216
  time_this_iter_s: 11.528691053390503
  time_total_s: 2956.3179194927216
  timestamp: 1593996960
  timesteps_since_restore: 1220000
  timesteps_this_iter: 5000
  timesteps_total: 1220000
  training_iteration: 244
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2956 s, 244 iter, 1220000 ts, 555 rew

agent-1: 110.0
agent-2: 104.0
agent-3: 119.0
agent-4: 122.0
agent-5: 139.0
Sum Reward: 594.0
Avg Reward: 118.8
Min Reward: 104.0
Gini Coefficient: 0.055218855218855216
20:20 Ratio: 1.3365384615384615
Max-min Ratio: 1.3365384615384615
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-56-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 557.12
  episode_reward_min: 353.0
  episodes_this_iter: 1
  episodes_total: 244
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.676
    dispatch_time_ms: 8.406
    learner:
      cur_lr: 0.0012787480372935534
      grad_gnorm: 40.0000114440918
      policy_entropy: 25.790748596191406
      policy_loss: -38.436553955078125
      var_gnorm: 41.47406768798828
      vf_explained_var: 0.43384748697280884
      vf_loss: 138.99803161621094
    num_steps_sampled: 1225000
    num_steps_trained: 1225000
    wait_time_ms: 108.086
  iterations_since_restore: 245
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2968.371263027191
  time_this_iter_s: 12.053343534469604
  time_total_s: 2968.371263027191
  timestamp: 1593996972
  timesteps_since_restore: 1225000
  timesteps_this_iter: 5000
  timesteps_total: 1225000
  training_iteration: 245
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2968 s, 245 iter, 1225000 ts, 557 rew

agent-1: 118.0
agent-2: 77.0
agent-3: 105.0
agent-4: 101.0
agent-5: 86.0
Sum Reward: 487.0
Avg Reward: 97.4
Min Reward: 77.0
Gini Coefficient: 0.08295687885010267
20:20 Ratio: 1.5324675324675325
Max-min Ratio: 1.5324675324675325
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-56-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 557.32
  episode_reward_min: 353.0
  episodes_this_iter: 1
  episodes_total: 245
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.086
    dispatch_time_ms: 8.809
    learner:
      cur_lr: 0.0012784149730578065
      grad_gnorm: 22.736404418945312
      policy_entropy: 43.49092483520508
      policy_loss: -3.663153886795044
      var_gnorm: 41.47162628173828
      vf_explained_var: 0.9885839819908142
      vf_loss: 0.6161246299743652
    num_steps_sampled: 1230000
    num_steps_trained: 1230000
    wait_time_ms: 115.493
  iterations_since_restore: 246
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2980.3993134498596
  time_this_iter_s: 12.028050422668457
  time_total_s: 2980.3993134498596
  timestamp: 1593996984
  timesteps_since_restore: 1230000
  timesteps_this_iter: 5000
  timesteps_total: 1230000
  training_iteration: 246
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2980 s, 246 iter, 1230000 ts, 557 rew

agent-1: 106.0
agent-2: 108.0
agent-3: 93.0
agent-4: 86.0
agent-5: 66.0
Sum Reward: 459.0
Avg Reward: 91.8
Min Reward: 66.0
Gini Coefficient: 0.0906318082788671
20:20 Ratio: 1.6363636363636365
Max-min Ratio: 1.6363636363636365
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-56-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 557.01
  episode_reward_min: 353.0
  episodes_this_iter: 1
  episodes_total: 246
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.066
    dispatch_time_ms: 6.631
    learner:
      cur_lr: 0.0012780820252373815
      grad_gnorm: 11.823149681091309
      policy_entropy: 48.342872619628906
      policy_loss: -4.250903129577637
      var_gnorm: 41.5308723449707
      vf_explained_var: 0.9782156944274902
      vf_loss: 0.3923104703426361
    num_steps_sampled: 1235000
    num_steps_trained: 1235000
    wait_time_ms: 116.379
  iterations_since_restore: 247
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 2992.2277686595917
  time_this_iter_s: 11.828455209732056
  time_total_s: 2992.2277686595917
  timestamp: 1593996996
  timesteps_since_restore: 1235000
  timesteps_this_iter: 5000
  timesteps_total: 1235000
  training_iteration: 247
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 2992 s, 247 iter, 1235000 ts, 557 rew

agent-1: 58.0
agent-2: 91.0
agent-3: 68.0
agent-4: 88.0
agent-5: 71.0
Sum Reward: 376.0
Avg Reward: 75.2
Min Reward: 58.0
Gini Coefficient: 0.09148936170212765
20:20 Ratio: 1.5689655172413792
Max-min Ratio: 1.5689655172413792
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-56-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 554.92
  episode_reward_min: 353.0
  episodes_this_iter: 1
  episodes_total: 247
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.086
    dispatch_time_ms: 7.345
    learner:
      cur_lr: 0.0012777489610016346
      grad_gnorm: 40.000003814697266
      policy_entropy: 25.864330291748047
      policy_loss: -7.350741386413574
      var_gnorm: 41.57364273071289
      vf_explained_var: 0.3903962969779968
      vf_loss: 54.763423919677734
    num_steps_sampled: 1240000
    num_steps_trained: 1240000
    wait_time_ms: 110.265
  iterations_since_restore: 248
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3004.2299478054047
  time_this_iter_s: 12.002179145812988
  time_total_s: 3004.2299478054047
  timestamp: 1593997008
  timesteps_since_restore: 1240000
  timesteps_this_iter: 5000
  timesteps_total: 1240000
  training_iteration: 248
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3004 s, 248 iter, 1240000 ts, 555 rew

agent-1: 82.0
agent-2: 75.0
agent-3: 82.0
agent-4: 60.0
agent-5: 69.0
Sum Reward: 368.0
Avg Reward: 73.6
Min Reward: 60.0
Gini Coefficient: 0.06195652173913044
20:20 Ratio: 1.3666666666666667
Max-min Ratio: 1.3666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-57-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 552.44
  episode_reward_min: 353.0
  episodes_this_iter: 1
  episodes_total: 248
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.793
    dispatch_time_ms: 6.119
    learner:
      cur_lr: 0.0012774160131812096
      grad_gnorm: 40.000003814697266
      policy_entropy: 32.91141891479492
      policy_loss: 8.302657127380371
      var_gnorm: 41.672119140625
      vf_explained_var: 0.5850780606269836
      vf_loss: 64.29654693603516
    num_steps_sampled: 1245000
    num_steps_trained: 1245000
    wait_time_ms: 116.084
  iterations_since_restore: 249
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3015.911724805832
  time_this_iter_s: 11.681777000427246
  time_total_s: 3015.911724805832
  timestamp: 1593997020
  timesteps_since_restore: 1245000
  timesteps_this_iter: 5000
  timesteps_total: 1245000
  training_iteration: 249
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3015 s, 249 iter, 1245000 ts, 552 rew

agent-1: 89.0
agent-2: 114.0
agent-3: 84.0
agent-4: 69.0
agent-5: 85.0
Sum Reward: 441.0
Avg Reward: 88.2
Min Reward: 69.0
Gini Coefficient: 0.08616780045351474
20:20 Ratio: 1.6521739130434783
Max-min Ratio: 1.6521739130434783
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-57-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 550.39
  episode_reward_min: 353.0
  episodes_this_iter: 1
  episodes_total: 249
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.766
    dispatch_time_ms: 7.521
    learner:
      cur_lr: 0.0012770829489454627
      grad_gnorm: 40.0
      policy_entropy: 19.92393684387207
      policy_loss: 9.039224624633789
      var_gnorm: 41.72917938232422
      vf_explained_var: 0.4794670343399048
      vf_loss: 63.70768737792969
    num_steps_sampled: 1250000
    num_steps_trained: 1250000
    wait_time_ms: 97.463
  iterations_since_restore: 250
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3027.7598645687103
  time_this_iter_s: 11.848139762878418
  time_total_s: 3027.7598645687103
  timestamp: 1593997032
  timesteps_since_restore: 1250000
  timesteps_this_iter: 5000
  timesteps_total: 1250000
  training_iteration: 250
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3027 s, 250 iter, 1250000 ts, 550 rew

agent-1: 103.0
agent-2: 88.0
agent-3: 78.0
agent-4: 90.0
agent-5: 99.0
Sum Reward: 458.0
Avg Reward: 91.6
Min Reward: 78.0
Gini Coefficient: 0.05327510917030567
20:20 Ratio: 1.3205128205128205
Max-min Ratio: 1.3205128205128205
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-57-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 548.05
  episode_reward_min: 353.0
  episodes_this_iter: 1
  episodes_total: 250
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.523
    dispatch_time_ms: 7.939
    learner:
      cur_lr: 0.0012767500011250377
      grad_gnorm: 14.208672523498535
      policy_entropy: 51.6778564453125
      policy_loss: -3.4957263469696045
      var_gnorm: 41.77440643310547
      vf_explained_var: 0.9916433691978455
      vf_loss: 0.3989950716495514
    num_steps_sampled: 1255000
    num_steps_trained: 1255000
    wait_time_ms: 110.827
  iterations_since_restore: 251
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3039.4253404140472
  time_this_iter_s: 11.665475845336914
  time_total_s: 3039.4253404140472
  timestamp: 1593997043
  timesteps_since_restore: 1255000
  timesteps_this_iter: 5000
  timesteps_total: 1255000
  training_iteration: 251
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3039 s, 251 iter, 1255000 ts, 548 rew

agent-1: 81.0
agent-2: 98.0
agent-3: 104.0
agent-4: 76.0
agent-5: 109.0
Sum Reward: 468.0
Avg Reward: 93.6
Min Reward: 76.0
Gini Coefficient: 0.07606837606837606
20:20 Ratio: 1.4342105263157894
Max-min Ratio: 1.4342105263157894
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-57-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 547.27
  episode_reward_min: 353.0
  episodes_this_iter: 1
  episodes_total: 251
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.738
    dispatch_time_ms: 7.081
    learner:
      cur_lr: 0.0012764170533046126
      grad_gnorm: 5.010720252990723
      policy_entropy: 44.35103225708008
      policy_loss: -1.3294928073883057
      var_gnorm: 41.85857009887695
      vf_explained_var: -1.0
      vf_loss: 0.06225155293941498
    num_steps_sampled: 1260000
    num_steps_trained: 1260000
    wait_time_ms: 116.177
  iterations_since_restore: 252
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3051.36341714859
  time_this_iter_s: 11.938076734542847
  time_total_s: 3051.36341714859
  timestamp: 1593997055
  timesteps_since_restore: 1260000
  timesteps_this_iter: 5000
  timesteps_total: 1260000
  training_iteration: 252
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3051 s, 252 iter, 1260000 ts, 547 rew

agent-1: 93.0
agent-2: 92.0
agent-3: 64.0
agent-4: 108.0
agent-5: 84.0
Sum Reward: 441.0
Avg Reward: 88.2
Min Reward: 64.0
Gini Coefficient: 0.08798185941043084
20:20 Ratio: 1.6875
Max-min Ratio: 1.6875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-57-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 547.32
  episode_reward_min: 353.0
  episodes_this_iter: 1
  episodes_total: 252
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.768
    dispatch_time_ms: 5.715
    learner:
      cur_lr: 0.0012760839890688658
      grad_gnorm: 34.75836181640625
      policy_entropy: 51.19293212890625
      policy_loss: -11.656210899353027
      var_gnorm: 41.98946762084961
      vf_explained_var: 0.9754610061645508
      vf_loss: 1.703452229499817
    num_steps_sampled: 1265000
    num_steps_trained: 1265000
    wait_time_ms: 117.156
  iterations_since_restore: 253
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3062.958608150482
  time_this_iter_s: 11.59519100189209
  time_total_s: 3062.958608150482
  timestamp: 1593997067
  timesteps_since_restore: 1265000
  timesteps_this_iter: 5000
  timesteps_total: 1265000
  training_iteration: 253
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3062 s, 253 iter, 1265000 ts, 547 rew

agent-1: 119.0
agent-2: 107.0
agent-3: 100.0
agent-4: 99.0
agent-5: 126.0
Sum Reward: 551.0
Avg Reward: 110.2
Min Reward: 99.0
Gini Coefficient: 0.052994555353902
20:20 Ratio: 1.2727272727272727
Max-min Ratio: 1.2727272727272727
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-57-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 549.08
  episode_reward_min: 353.0
  episodes_this_iter: 1
  episodes_total: 253
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.554
    dispatch_time_ms: 6.985
    learner:
      cur_lr: 0.0012757510412484407
      grad_gnorm: 40.000003814697266
      policy_entropy: 20.6241397857666
      policy_loss: 14.179723739624023
      var_gnorm: 42.04331970214844
      vf_explained_var: 0.5990278720855713
      vf_loss: 56.69380187988281
    num_steps_sampled: 1270000
    num_steps_trained: 1270000
    wait_time_ms: 95.653
  iterations_since_restore: 254
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3074.8112003803253
  time_this_iter_s: 11.85259222984314
  time_total_s: 3074.8112003803253
  timestamp: 1593997079
  timesteps_since_restore: 1270000
  timesteps_this_iter: 5000
  timesteps_total: 1270000
  training_iteration: 254
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3074 s, 254 iter, 1270000 ts, 549 rew

agent-1: 78.0
agent-2: 76.0
agent-3: 61.0
agent-4: 75.0
agent-5: 49.0
Sum Reward: 339.0
Avg Reward: 67.8
Min Reward: 49.0
Gini Coefficient: 0.08613569321533923
20:20 Ratio: 1.5918367346938775
Max-min Ratio: 1.5918367346938775
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-58-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 548.55
  episode_reward_min: 339.0
  episodes_this_iter: 1
  episodes_total: 254
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.2
    dispatch_time_ms: 7.248
    learner:
      cur_lr: 0.0012754179770126939
      grad_gnorm: 40.00000762939453
      policy_entropy: 36.067832946777344
      policy_loss: -20.149030685424805
      var_gnorm: 42.11393737792969
      vf_explained_var: -1.0
      vf_loss: 66.255615234375
    num_steps_sampled: 1275000
    num_steps_trained: 1275000
    wait_time_ms: 102.462
  iterations_since_restore: 255
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3086.704309940338
  time_this_iter_s: 11.893109560012817
  time_total_s: 3086.704309940338
  timestamp: 1593997091
  timesteps_since_restore: 1275000
  timesteps_this_iter: 5000
  timesteps_total: 1275000
  training_iteration: 255
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3086 s, 255 iter, 1275000 ts, 549 rew

agent-1: 62.0
agent-2: 89.0
agent-3: 79.0
agent-4: 78.0
agent-5: 94.0
Sum Reward: 402.0
Avg Reward: 80.4
Min Reward: 62.0
Gini Coefficient: 0.07462686567164178
20:20 Ratio: 1.5161290322580645
Max-min Ratio: 1.5161290322580645
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-58-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 546.53
  episode_reward_min: 339.0
  episodes_this_iter: 1
  episodes_total: 255
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.276
    dispatch_time_ms: 5.851
    learner:
      cur_lr: 0.0012750850291922688
      grad_gnorm: 40.00000762939453
      policy_entropy: 27.29424476623535
      policy_loss: -42.6749267578125
      var_gnorm: 42.15524673461914
      vf_explained_var: -1.0
      vf_loss: 214.8919677734375
    num_steps_sampled: 1280000
    num_steps_trained: 1280000
    wait_time_ms: 104.484
  iterations_since_restore: 256
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3098.5596191883087
  time_this_iter_s: 11.855309247970581
  time_total_s: 3098.5596191883087
  timestamp: 1593997103
  timesteps_since_restore: 1280000
  timesteps_this_iter: 5000
  timesteps_total: 1280000
  training_iteration: 256
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3098 s, 256 iter, 1280000 ts, 547 rew

agent-1: 89.0
agent-2: 80.0
agent-3: 103.0
agent-4: 99.0
agent-5: 112.0
Sum Reward: 483.0
Avg Reward: 96.6
Min Reward: 80.0
Gini Coefficient: 0.06459627329192547
20:20 Ratio: 1.4
Max-min Ratio: 1.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-58-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 543.93
  episode_reward_min: 339.0
  episodes_this_iter: 1
  episodes_total: 256
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.272
    dispatch_time_ms: 6.649
    learner:
      cur_lr: 0.001274751964956522
      grad_gnorm: 11.021662712097168
      policy_entropy: 44.95012283325195
      policy_loss: -1.8459056615829468
      var_gnorm: 42.316104888916016
      vf_explained_var: 0.9950293898582458
      vf_loss: 0.29001814126968384
    num_steps_sampled: 1285000
    num_steps_trained: 1285000
    wait_time_ms: 115.909
  iterations_since_restore: 257
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3110.170561313629
  time_this_iter_s: 11.610942125320435
  time_total_s: 3110.170561313629
  timestamp: 1593997114
  timesteps_since_restore: 1285000
  timesteps_this_iter: 5000
  timesteps_total: 1285000
  training_iteration: 257
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3110 s, 257 iter, 1285000 ts, 544 rew

agent-1: 85.0
agent-2: 102.0
agent-3: 57.0
agent-4: 60.0
agent-5: 89.0
Sum Reward: 393.0
Avg Reward: 78.6
Min Reward: 57.0
Gini Coefficient: 0.12111959287531807
20:20 Ratio: 1.7894736842105263
Max-min Ratio: 1.7894736842105263
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-58-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 543.62
  episode_reward_min: 339.0
  episodes_this_iter: 1
  episodes_total: 257
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.662
    dispatch_time_ms: 6.549
    learner:
      cur_lr: 0.001274419017136097
      grad_gnorm: 15.833966255187988
      policy_entropy: 44.54485321044922
      policy_loss: 2.9630918502807617
      var_gnorm: 42.480064392089844
      vf_explained_var: 0.9127713441848755
      vf_loss: 3.759054660797119
    num_steps_sampled: 1290000
    num_steps_trained: 1290000
    wait_time_ms: 110.475
  iterations_since_restore: 258
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3121.9307079315186
  time_this_iter_s: 11.760146617889404
  time_total_s: 3121.9307079315186
  timestamp: 1593997126
  timesteps_since_restore: 1290000
  timesteps_this_iter: 5000
  timesteps_total: 1290000
  training_iteration: 258
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3121 s, 258 iter, 1290000 ts, 544 rew

agent-1: 138.0
agent-2: 105.0
agent-3: 76.0
agent-4: 82.0
agent-5: 88.0
Sum Reward: 489.0
Avg Reward: 97.8
Min Reward: 76.0
Gini Coefficient: 0.12024539877300613
20:20 Ratio: 1.8157894736842106
Max-min Ratio: 1.8157894736842106
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-58-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 541.36
  episode_reward_min: 339.0
  episodes_this_iter: 1
  episodes_total: 258
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.999
    dispatch_time_ms: 10.899
    learner:
      cur_lr: 0.00127408595290035
      grad_gnorm: 40.0
      policy_entropy: 27.52574920654297
      policy_loss: 6.094712257385254
      var_gnorm: 42.54927444458008
      vf_explained_var: 0.013781130313873291
      vf_loss: 176.11865234375
    num_steps_sampled: 1295000
    num_steps_trained: 1295000
    wait_time_ms: 108.686
  iterations_since_restore: 259
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3133.6785078048706
  time_this_iter_s: 11.74779987335205
  time_total_s: 3133.6785078048706
  timestamp: 1593997138
  timesteps_since_restore: 1295000
  timesteps_this_iter: 5000
  timesteps_total: 1295000
  training_iteration: 259
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3133 s, 259 iter, 1295000 ts, 541 rew

agent-1: 65.0
agent-2: 65.0
agent-3: 55.0
agent-4: 51.0
agent-5: 87.0
Sum Reward: 323.0
Avg Reward: 64.6
Min Reward: 51.0
Gini Coefficient: 0.10154798761609907
20:20 Ratio: 1.7058823529411764
Max-min Ratio: 1.7058823529411764
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-59-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 538.59
  episode_reward_min: 323.0
  episodes_this_iter: 1
  episodes_total: 259
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.808
    dispatch_time_ms: 10.032
    learner:
      cur_lr: 0.001273753005079925
      grad_gnorm: 9.136913299560547
      policy_entropy: 50.044071197509766
      policy_loss: -2.212935209274292
      var_gnorm: 42.58473205566406
      vf_explained_var: -1.0
      vf_loss: 0.09926801174879074
    num_steps_sampled: 1300000
    num_steps_trained: 1300000
    wait_time_ms: 111.614
  iterations_since_restore: 260
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3145.7175073623657
  time_this_iter_s: 12.038999557495117
  time_total_s: 3145.7175073623657
  timestamp: 1593997150
  timesteps_since_restore: 1300000
  timesteps_this_iter: 5000
  timesteps_total: 1300000
  training_iteration: 260
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3145 s, 260 iter, 1300000 ts, 539 rew

agent-1: 88.0
agent-2: 78.0
agent-3: 99.0
agent-4: 87.0
agent-5: 86.0
Sum Reward: 438.0
Avg Reward: 87.6
Min Reward: 78.0
Gini Coefficient: 0.04018264840182648
20:20 Ratio: 1.2692307692307692
Max-min Ratio: 1.2692307692307692
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-59-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 537.21
  episode_reward_min: 323.0
  episodes_this_iter: 1
  episodes_total: 260
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.683
    dispatch_time_ms: 7.255
    learner:
      cur_lr: 0.0012734200572595
      grad_gnorm: 40.0
      policy_entropy: 23.475753784179688
      policy_loss: 67.45113372802734
      var_gnorm: 42.626338958740234
      vf_explained_var: 0.7281652688980103
      vf_loss: 139.94808959960938
    num_steps_sampled: 1305000
    num_steps_trained: 1305000
    wait_time_ms: 104.896
  iterations_since_restore: 261
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3157.414935350418
  time_this_iter_s: 11.697427988052368
  time_total_s: 3157.414935350418
  timestamp: 1593997162
  timesteps_since_restore: 1305000
  timesteps_this_iter: 5000
  timesteps_total: 1305000
  training_iteration: 261
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3157 s, 261 iter, 1305000 ts, 537 rew

agent-1: 64.0
agent-2: 94.0
agent-3: 65.0
agent-4: 80.0
agent-5: 63.0
Sum Reward: 366.0
Avg Reward: 73.2
Min Reward: 63.0
Gini Coefficient: 0.08524590163934426
20:20 Ratio: 1.492063492063492
Max-min Ratio: 1.492063492063492
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-59-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 536.88
  episode_reward_min: 323.0
  episodes_this_iter: 1
  episodes_total: 261
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.158
    dispatch_time_ms: 6.059
    learner:
      cur_lr: 0.0012730869930237532
      grad_gnorm: 34.93303298950195
      policy_entropy: 29.527328491210938
      policy_loss: 0.9352247714996338
      var_gnorm: 42.663455963134766
      vf_explained_var: 0.8496749997138977
      vf_loss: 46.31674575805664
    num_steps_sampled: 1310000
    num_steps_trained: 1310000
    wait_time_ms: 107.25
  iterations_since_restore: 262
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3169.464365005493
  time_this_iter_s: 12.049429655075073
  time_total_s: 3169.464365005493
  timestamp: 1593997174
  timesteps_since_restore: 1310000
  timesteps_this_iter: 5000
  timesteps_total: 1310000
  training_iteration: 262
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3169 s, 262 iter, 1310000 ts, 537 rew

agent-1: 95.0
agent-2: 104.0
agent-3: 108.0
agent-4: 108.0
agent-5: 77.0
Sum Reward: 492.0
Avg Reward: 98.4
Min Reward: 77.0
Gini Coefficient: 0.06097560975609756
20:20 Ratio: 1.4025974025974026
Max-min Ratio: 1.4025974025974026
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-59-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 535.32
  episode_reward_min: 323.0
  episodes_this_iter: 1
  episodes_total: 262
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.957
    dispatch_time_ms: 6.156
    learner:
      cur_lr: 0.0012727540452033281
      grad_gnorm: 39.999996185302734
      policy_entropy: 48.86928939819336
      policy_loss: 10.745285987854004
      var_gnorm: 42.79286575317383
      vf_explained_var: 0.3587093949317932
      vf_loss: 9.054542541503906
    num_steps_sampled: 1315000
    num_steps_trained: 1315000
    wait_time_ms: 116.729
  iterations_since_restore: 263
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3181.2017335891724
  time_this_iter_s: 11.7373685836792
  time_total_s: 3181.2017335891724
  timestamp: 1593997186
  timesteps_since_restore: 1315000
  timesteps_this_iter: 5000
  timesteps_total: 1315000
  training_iteration: 263
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3181 s, 263 iter, 1315000 ts, 535 rew

agent-1: 67.0
agent-2: 91.0
agent-3: 68.0
agent-4: 80.0
agent-5: 91.0
Sum Reward: 397.0
Avg Reward: 79.4
Min Reward: 67.0
Gini Coefficient: 0.07153652392947103
20:20 Ratio: 1.3582089552238805
Max-min Ratio: 1.3582089552238805
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-59-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 533.15
  episode_reward_min: 323.0
  episodes_this_iter: 1
  episodes_total: 263
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.068
    dispatch_time_ms: 7.787
    learner:
      cur_lr: 0.0012724209809675813
      grad_gnorm: 14.702553749084473
      policy_entropy: 48.9913444519043
      policy_loss: 2.2477447986602783
      var_gnorm: 42.81605529785156
      vf_explained_var: 0.38536882400512695
      vf_loss: 2.4052157402038574
    num_steps_sampled: 1320000
    num_steps_trained: 1320000
    wait_time_ms: 103.205
  iterations_since_restore: 264
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3193.131546020508
  time_this_iter_s: 11.92981243133545
  time_total_s: 3193.131546020508
  timestamp: 1593997197
  timesteps_since_restore: 1320000
  timesteps_this_iter: 5000
  timesteps_total: 1320000
  training_iteration: 264
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3193 s, 264 iter, 1320000 ts, 533 rew

agent-1: 78.0
agent-2: 108.0
agent-3: 109.0
agent-4: 62.0
agent-5: 97.0
Sum Reward: 454.0
Avg Reward: 90.8
Min Reward: 62.0
Gini Coefficient: 0.1092511013215859
20:20 Ratio: 1.7580645161290323
Max-min Ratio: 1.7580645161290323
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-00-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 531.84
  episode_reward_min: 323.0
  episodes_this_iter: 1
  episodes_total: 264
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.263
    dispatch_time_ms: 6.63
    learner:
      cur_lr: 0.0012720880331471562
      grad_gnorm: 15.681513786315918
      policy_entropy: 51.85132598876953
      policy_loss: -5.742433547973633
      var_gnorm: 42.88105392456055
      vf_explained_var: 0.991712212562561
      vf_loss: 0.367279052734375
    num_steps_sampled: 1325000
    num_steps_trained: 1325000
    wait_time_ms: 113.438
  iterations_since_restore: 265
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3204.7965145111084
  time_this_iter_s: 11.664968490600586
  time_total_s: 3204.7965145111084
  timestamp: 1593997209
  timesteps_since_restore: 1325000
  timesteps_this_iter: 5000
  timesteps_total: 1325000
  training_iteration: 265
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3204 s, 265 iter, 1325000 ts, 532 rew

agent-1: 87.0
agent-2: 82.0
agent-3: 73.0
agent-4: 85.0
agent-5: 102.0
Sum Reward: 429.0
Avg Reward: 85.8
Min Reward: 73.0
Gini Coefficient: 0.05874125874125874
20:20 Ratio: 1.3972602739726028
Max-min Ratio: 1.3972602739726028
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-00-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 530.19
  episode_reward_min: 323.0
  episodes_this_iter: 1
  episodes_total: 265
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.267
    dispatch_time_ms: 5.922
    learner:
      cur_lr: 0.0012717549689114094
      grad_gnorm: 10.53968334197998
      policy_entropy: 54.397064208984375
      policy_loss: 2.066399335861206
      var_gnorm: 42.91291427612305
      vf_explained_var: -0.0153578519821167
      vf_loss: 4.075064182281494
    num_steps_sampled: 1330000
    num_steps_trained: 1330000
    wait_time_ms: 102.31
  iterations_since_restore: 266
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3216.7322216033936
  time_this_iter_s: 11.935707092285156
  time_total_s: 3216.7322216033936
  timestamp: 1593997221
  timesteps_since_restore: 1330000
  timesteps_this_iter: 5000
  timesteps_total: 1330000
  training_iteration: 266
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3216 s, 266 iter, 1330000 ts, 530 rew

agent-1: 79.0
agent-2: 94.0
agent-3: 78.0
agent-4: 73.0
agent-5: 106.0
Sum Reward: 430.0
Avg Reward: 86.0
Min Reward: 73.0
Gini Coefficient: 0.07627906976744186
20:20 Ratio: 1.452054794520548
Max-min Ratio: 1.452054794520548
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-00-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 528.63
  episode_reward_min: 323.0
  episodes_this_iter: 1
  episodes_total: 266
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.791
    dispatch_time_ms: 9.103
    learner:
      cur_lr: 0.0012714220210909843
      grad_gnorm: 40.0
      policy_entropy: 45.836143493652344
      policy_loss: -19.98716926574707
      var_gnorm: 42.946441650390625
      vf_explained_var: -1.0
      vf_loss: 18.81794548034668
    num_steps_sampled: 1335000
    num_steps_trained: 1335000
    wait_time_ms: 107.551
  iterations_since_restore: 267
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3228.426655292511
  time_this_iter_s: 11.694433689117432
  time_total_s: 3228.426655292511
  timestamp: 1593997233
  timesteps_since_restore: 1335000
  timesteps_this_iter: 5000
  timesteps_total: 1335000
  training_iteration: 267
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3228 s, 267 iter, 1335000 ts, 529 rew

agent-1: 64.0
agent-2: 82.0
agent-3: 62.0
agent-4: 93.0
agent-5: 76.0
Sum Reward: 377.0
Avg Reward: 75.4
Min Reward: 62.0
Gini Coefficient: 0.08488063660477453
20:20 Ratio: 1.5
Max-min Ratio: 1.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-00-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 526.41
  episode_reward_min: 323.0
  episodes_this_iter: 1
  episodes_total: 267
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.665
    dispatch_time_ms: 6.868
    learner:
      cur_lr: 0.0012710889568552375
      grad_gnorm: 40.0
      policy_entropy: 6.511873245239258
      policy_loss: 17.40924835205078
      var_gnorm: 42.972904205322266
      vf_explained_var: -0.6852434873580933
      vf_loss: 90.33702087402344
    num_steps_sampled: 1340000
    num_steps_trained: 1340000
    wait_time_ms: 103.704
  iterations_since_restore: 268
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3240.491153717041
  time_this_iter_s: 12.06449842453003
  time_total_s: 3240.491153717041
  timestamp: 1593997245
  timesteps_since_restore: 1340000
  timesteps_this_iter: 5000
  timesteps_total: 1340000
  training_iteration: 268
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3240 s, 268 iter, 1340000 ts, 526 rew

agent-1: 78.0
agent-2: 70.0
agent-3: 79.0
agent-4: 82.0
agent-5: 72.0
Sum Reward: 381.0
Avg Reward: 76.2
Min Reward: 70.0
Gini Coefficient: 0.03254593175853018
20:20 Ratio: 1.1714285714285715
Max-min Ratio: 1.1714285714285715
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-00-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 524.0
  episode_reward_min: 323.0
  episodes_this_iter: 1
  episodes_total: 268
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.921
    dispatch_time_ms: 5.601
    learner:
      cur_lr: 0.0012707560090348125
      grad_gnorm: 7.610535621643066
      policy_entropy: 51.01668930053711
      policy_loss: -2.839667320251465
      var_gnorm: 43.02175521850586
      vf_explained_var: 0.9926490187644958
      vf_loss: 0.18826748430728912
    num_steps_sampled: 1345000
    num_steps_trained: 1345000
    wait_time_ms: 114.557
  iterations_since_restore: 269
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3252.33523106575
  time_this_iter_s: 11.844077348709106
  time_total_s: 3252.33523106575
  timestamp: 1593997257
  timesteps_since_restore: 1345000
  timesteps_this_iter: 5000
  timesteps_total: 1345000
  training_iteration: 269
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3252 s, 269 iter, 1345000 ts, 524 rew

agent-1: 86.0
agent-2: 79.0
agent-3: 94.0
agent-4: 79.0
agent-5: 102.0
Sum Reward: 440.0
Avg Reward: 88.0
Min Reward: 79.0
Gini Coefficient: 0.05545454545454546
20:20 Ratio: 1.2911392405063291
Max-min Ratio: 1.2911392405063291
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-01-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 522.3
  episode_reward_min: 323.0
  episodes_this_iter: 1
  episodes_total: 269
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.621
    dispatch_time_ms: 7.237
    learner:
      cur_lr: 0.0012704229447990656
      grad_gnorm: 8.035867691040039
      policy_entropy: 41.094818115234375
      policy_loss: -1.56948721408844
      var_gnorm: 43.0644645690918
      vf_explained_var: 0.0
      vf_loss: 0.07375065237283707
    num_steps_sampled: 1350000
    num_steps_trained: 1350000
    wait_time_ms: 102.943
  iterations_since_restore: 270
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3264.314356803894
  time_this_iter_s: 11.979125738143921
  time_total_s: 3264.314356803894
  timestamp: 1593997269
  timesteps_since_restore: 1350000
  timesteps_this_iter: 5000
  timesteps_total: 1350000
  training_iteration: 270
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3264 s, 270 iter, 1350000 ts, 522 rew

agent-1: 90.0
agent-2: 80.0
agent-3: 81.0
agent-4: 124.0
agent-5: 98.0
Sum Reward: 473.0
Avg Reward: 94.6
Min Reward: 80.0
Gini Coefficient: 0.08879492600422834
20:20 Ratio: 1.55
Max-min Ratio: 1.55
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-01-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 521.92
  episode_reward_min: 323.0
  episodes_this_iter: 1
  episodes_total: 270
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.305
    dispatch_time_ms: 9.637
    learner:
      cur_lr: 0.0012700899969786406
      grad_gnorm: 5.41344690322876
      policy_entropy: 53.71852111816406
      policy_loss: -1.4764541387557983
      var_gnorm: 43.17973327636719
      vf_explained_var: -1.0
      vf_loss: 0.0427561029791832
    num_steps_sampled: 1355000
    num_steps_trained: 1355000
    wait_time_ms: 107.231
  iterations_since_restore: 271
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3275.8735790252686
  time_this_iter_s: 11.559222221374512
  time_total_s: 3275.8735790252686
  timestamp: 1593997281
  timesteps_since_restore: 1355000
  timesteps_this_iter: 5000
  timesteps_total: 1355000
  training_iteration: 271
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3275 s, 271 iter, 1355000 ts, 522 rew

agent-1: 100.0
agent-2: 102.0
agent-3: 85.0
agent-4: 108.0
agent-5: 86.0
Sum Reward: 481.0
Avg Reward: 96.2
Min Reward: 85.0
Gini Coefficient: 0.05155925155925156
20:20 Ratio: 1.2705882352941176
Max-min Ratio: 1.2705882352941176
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-01-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 521.56
  episode_reward_min: 323.0
  episodes_this_iter: 1
  episodes_total: 271
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.103
    dispatch_time_ms: 8.594
    learner:
      cur_lr: 0.0012697570491582155
      grad_gnorm: 40.0
      policy_entropy: 16.230758666992188
      policy_loss: 4.382939338684082
      var_gnorm: 43.167171478271484
      vf_explained_var: -0.18409764766693115
      vf_loss: 276.45391845703125
    num_steps_sampled: 1360000
    num_steps_trained: 1360000
    wait_time_ms: 103.43
  iterations_since_restore: 272
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3287.831211566925
  time_this_iter_s: 11.957632541656494
  time_total_s: 3287.831211566925
  timestamp: 1593997293
  timesteps_since_restore: 1360000
  timesteps_this_iter: 5000
  timesteps_total: 1360000
  training_iteration: 272
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3287 s, 272 iter, 1360000 ts, 522 rew

agent-1: 73.0
agent-2: 72.0
agent-3: 58.0
agent-4: 59.0
agent-5: 80.0
Sum Reward: 342.0
Avg Reward: 68.4
Min Reward: 58.0
Gini Coefficient: 0.06783625730994151
20:20 Ratio: 1.3793103448275863
Max-min Ratio: 1.3793103448275863
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-01-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 518.95
  episode_reward_min: 323.0
  episodes_this_iter: 1
  episodes_total: 272
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.801
    dispatch_time_ms: 7.052
    learner:
      cur_lr: 0.0012694239849224687
      grad_gnorm: 40.00000762939453
      policy_entropy: 32.087181091308594
      policy_loss: -17.776697158813477
      var_gnorm: 43.213008880615234
      vf_explained_var: 0.9446020722389221
      vf_loss: 32.18962860107422
    num_steps_sampled: 1365000
    num_steps_trained: 1365000
    wait_time_ms: 108.527
  iterations_since_restore: 273
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3299.3255088329315
  time_this_iter_s: 11.49429726600647
  time_total_s: 3299.3255088329315
  timestamp: 1593997304
  timesteps_since_restore: 1365000
  timesteps_this_iter: 5000
  timesteps_total: 1365000
  training_iteration: 273
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3299 s, 273 iter, 1365000 ts, 519 rew

agent-1: 70.0
agent-2: 99.0
agent-3: 85.0
agent-4: 110.0
agent-5: 91.0
Sum Reward: 455.0
Avg Reward: 91.0
Min Reward: 70.0
Gini Coefficient: 0.08263736263736264
20:20 Ratio: 1.5714285714285714
Max-min Ratio: 1.5714285714285714
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-01-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 519.13
  episode_reward_min: 323.0
  episodes_this_iter: 1
  episodes_total: 273
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.97
    dispatch_time_ms: 7.314
    learner:
      cur_lr: 0.0012690910371020436
      grad_gnorm: 40.0
      policy_entropy: 50.24101638793945
      policy_loss: 16.960670471191406
      var_gnorm: 43.23602294921875
      vf_explained_var: 0.505259096622467
      vf_loss: 20.745769500732422
    num_steps_sampled: 1370000
    num_steps_trained: 1370000
    wait_time_ms: 95.285
  iterations_since_restore: 274
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3311.202336549759
  time_this_iter_s: 11.876827716827393
  time_total_s: 3311.202336549759
  timestamp: 1593997316
  timesteps_since_restore: 1370000
  timesteps_this_iter: 5000
  timesteps_total: 1370000
  training_iteration: 274
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3311 s, 274 iter, 1370000 ts, 519 rew

agent-1: 78.0
agent-2: 105.0
agent-3: 101.0
agent-4: 102.0
agent-5: 82.0
Sum Reward: 468.0
Avg Reward: 93.6
Min Reward: 78.0
Gini Coefficient: 0.06324786324786325
20:20 Ratio: 1.3461538461538463
Max-min Ratio: 1.3461538461538463
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-02-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 516.5
  episode_reward_min: 323.0
  episodes_this_iter: 1
  episodes_total: 274
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.655
    dispatch_time_ms: 6.24
    learner:
      cur_lr: 0.0012687579728662968
      grad_gnorm: 10.35149097442627
      policy_entropy: 47.42421340942383
      policy_loss: -2.5857698917388916
      var_gnorm: 43.28238296508789
      vf_explained_var: 0.9942194223403931
      vf_loss: 0.16591952741146088
    num_steps_sampled: 1375000
    num_steps_trained: 1375000
    wait_time_ms: 119.294
  iterations_since_restore: 275
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3322.8755373954773
  time_this_iter_s: 11.673200845718384
  time_total_s: 3322.8755373954773
  timestamp: 1593997328
  timesteps_since_restore: 1375000
  timesteps_this_iter: 5000
  timesteps_total: 1375000
  training_iteration: 275
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3322 s, 275 iter, 1375000 ts, 516 rew

agent-1: 77.0
agent-2: 74.0
agent-3: 52.0
agent-4: 71.0
agent-5: 84.0
Sum Reward: 358.0
Avg Reward: 71.6
Min Reward: 52.0
Gini Coefficient: 0.0782122905027933
20:20 Ratio: 1.6153846153846154
Max-min Ratio: 1.6153846153846154
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-02-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 513.83
  episode_reward_min: 323.0
  episodes_this_iter: 1
  episodes_total: 275
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.932
    dispatch_time_ms: 6.549
    learner:
      cur_lr: 0.0012684250250458717
      grad_gnorm: 3.6220085620880127
      policy_entropy: 40.29298782348633
      policy_loss: -0.8646513223648071
      var_gnorm: 43.35158157348633
      vf_explained_var: 0.0
      vf_loss: 0.01546970009803772
    num_steps_sampled: 1380000
    num_steps_trained: 1380000
    wait_time_ms: 100.8
  iterations_since_restore: 276
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3334.8611075878143
  time_this_iter_s: 11.985570192337036
  time_total_s: 3334.8611075878143
  timestamp: 1593997340
  timesteps_since_restore: 1380000
  timesteps_this_iter: 5000
  timesteps_total: 1380000
  training_iteration: 276
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3334 s, 276 iter, 1380000 ts, 514 rew

agent-1: 72.0
agent-2: 91.0
agent-3: 96.0
agent-4: 121.0
agent-5: 75.0
Sum Reward: 455.0
Avg Reward: 91.0
Min Reward: 72.0
Gini Coefficient: 0.10461538461538461
20:20 Ratio: 1.6805555555555556
Max-min Ratio: 1.6805555555555556
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-02-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 513.79
  episode_reward_min: 323.0
  episodes_this_iter: 1
  episodes_total: 276
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.734
    dispatch_time_ms: 6.943
    learner:
      cur_lr: 0.0012680919608101249
      grad_gnorm: 39.867244720458984
      policy_entropy: 35.630191802978516
      policy_loss: -3.9035842418670654
      var_gnorm: 43.380306243896484
      vf_explained_var: 0.8349096775054932
      vf_loss: 31.704721450805664
    num_steps_sampled: 1385000
    num_steps_trained: 1385000
    wait_time_ms: 110.422
  iterations_since_restore: 277
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3346.403523683548
  time_this_iter_s: 11.542416095733643
  time_total_s: 3346.403523683548
  timestamp: 1593997351
  timesteps_since_restore: 1385000
  timesteps_this_iter: 5000
  timesteps_total: 1385000
  training_iteration: 277
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3346 s, 277 iter, 1385000 ts, 514 rew

agent-1: 90.0
agent-2: 84.0
agent-3: 73.0
agent-4: 97.0
agent-5: 119.0
Sum Reward: 463.0
Avg Reward: 92.6
Min Reward: 73.0
Gini Coefficient: 0.09071274298056156
20:20 Ratio: 1.63013698630137
Max-min Ratio: 1.63013698630137
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-02-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 513.43
  episode_reward_min: 323.0
  episodes_this_iter: 1
  episodes_total: 277
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.849
    dispatch_time_ms: 8.227
    learner:
      cur_lr: 0.0012677590129896998
      grad_gnorm: 40.000003814697266
      policy_entropy: 7.732565879821777
      policy_loss: 11.233105659484863
      var_gnorm: 43.41692352294922
      vf_explained_var: -0.0032297372817993164
      vf_loss: 82.35538482666016
    num_steps_sampled: 1390000
    num_steps_trained: 1390000
    wait_time_ms: 108.145
  iterations_since_restore: 278
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3358.368439435959
  time_this_iter_s: 11.964915752410889
  time_total_s: 3358.368439435959
  timestamp: 1593997363
  timesteps_since_restore: 1390000
  timesteps_this_iter: 5000
  timesteps_total: 1390000
  training_iteration: 278
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3358 s, 278 iter, 1390000 ts, 513 rew

agent-1: 72.0
agent-2: 95.0
agent-3: 55.0
agent-4: 103.0
agent-5: 93.0
Sum Reward: 418.0
Avg Reward: 83.6
Min Reward: 55.0
Gini Coefficient: 0.11387559808612441
20:20 Ratio: 1.8727272727272728
Max-min Ratio: 1.8727272727272728
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-02-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 512.29
  episode_reward_min: 323.0
  episodes_this_iter: 1
  episodes_total: 278
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.196
    dispatch_time_ms: 9.503
    learner:
      cur_lr: 0.001267425948753953
      grad_gnorm: 40.0
      policy_entropy: 21.955202102661133
      policy_loss: 5.193375110626221
      var_gnorm: 43.47057342529297
      vf_explained_var: 0.681159257888794
      vf_loss: 16.39126968383789
    num_steps_sampled: 1395000
    num_steps_trained: 1395000
    wait_time_ms: 109.443
  iterations_since_restore: 279
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3369.807534456253
  time_this_iter_s: 11.43909502029419
  time_total_s: 3369.807534456253
  timestamp: 1593997375
  timesteps_since_restore: 1395000
  timesteps_this_iter: 5000
  timesteps_total: 1395000
  training_iteration: 279
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3369 s, 279 iter, 1395000 ts, 512 rew

agent-1: 94.0
agent-2: 126.0
agent-3: 82.0
agent-4: 88.0
agent-5: 97.0
Sum Reward: 487.0
Avg Reward: 97.4
Min Reward: 82.0
Gini Coefficient: 0.07967145790554415
20:20 Ratio: 1.5365853658536586
Max-min Ratio: 1.5365853658536586
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-03-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 511.18
  episode_reward_min: 323.0
  episodes_this_iter: 1
  episodes_total: 279
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.833
    dispatch_time_ms: 6.328
    learner:
      cur_lr: 0.001267093000933528
      grad_gnorm: 40.0
      policy_entropy: 7.637376308441162
      policy_loss: -11.728007316589355
      var_gnorm: 43.625614166259766
      vf_explained_var: -0.9825623035430908
      vf_loss: 160.64312744140625
    num_steps_sampled: 1400000
    num_steps_trained: 1400000
    wait_time_ms: 104.43
  iterations_since_restore: 280
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3381.6790289878845
  time_this_iter_s: 11.87149453163147
  time_total_s: 3381.6790289878845
  timestamp: 1593997387
  timesteps_since_restore: 1400000
  timesteps_this_iter: 5000
  timesteps_total: 1400000
  training_iteration: 280
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3381 s, 280 iter, 1400000 ts, 511 rew

agent-1: 100.0
agent-2: 105.0
agent-3: 75.0
agent-4: 95.0
agent-5: 103.0
Sum Reward: 478.0
Avg Reward: 95.6
Min Reward: 75.0
Gini Coefficient: 0.05690376569037657
20:20 Ratio: 1.4
Max-min Ratio: 1.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-03-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 511.37
  episode_reward_min: 323.0
  episodes_this_iter: 1
  episodes_total: 280
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.985
    dispatch_time_ms: 8.547
    learner:
      cur_lr: 0.001266760053113103
      grad_gnorm: 40.0
      policy_entropy: 34.895668029785156
      policy_loss: 2.631808280944824
      var_gnorm: 43.612953186035156
      vf_explained_var: 0.9107675552368164
      vf_loss: 24.838153839111328
    num_steps_sampled: 1405000
    num_steps_trained: 1405000
    wait_time_ms: 107.485
  iterations_since_restore: 281
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3393.411792039871
  time_this_iter_s: 11.732763051986694
  time_total_s: 3393.411792039871
  timestamp: 1593997398
  timesteps_since_restore: 1405000
  timesteps_this_iter: 5000
  timesteps_total: 1405000
  training_iteration: 281
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3393 s, 281 iter, 1405000 ts, 511 rew

agent-1: 70.0
agent-2: 91.0
agent-3: 47.0
agent-4: 71.0
agent-5: 100.0
Sum Reward: 379.0
Avg Reward: 75.8
Min Reward: 47.0
Gini Coefficient: 0.13403693931398417
20:20 Ratio: 2.127659574468085
Max-min Ratio: 2.127659574468085
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-03-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 509.26
  episode_reward_min: 323.0
  episodes_this_iter: 1
  episodes_total: 281
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.88
    dispatch_time_ms: 7.191
    learner:
      cur_lr: 0.001266426988877356
      grad_gnorm: 40.0
      policy_entropy: 6.631330490112305
      policy_loss: 11.298595428466797
      var_gnorm: 43.62050247192383
      vf_explained_var: 0.22986191511154175
      vf_loss: 97.00126647949219
    num_steps_sampled: 1410000
    num_steps_trained: 1410000
    wait_time_ms: 104.819
  iterations_since_restore: 282
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3405.2137031555176
  time_this_iter_s: 11.801911115646362
  time_total_s: 3405.2137031555176
  timestamp: 1593997411
  timesteps_since_restore: 1410000
  timesteps_this_iter: 5000
  timesteps_total: 1410000
  training_iteration: 282
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3405 s, 282 iter, 1410000 ts, 509 rew

agent-1: 55.0
agent-2: 91.0
agent-3: 66.0
agent-4: 75.0
agent-5: 77.0
Sum Reward: 364.0
Avg Reward: 72.8
Min Reward: 55.0
Gini Coefficient: 0.0912087912087912
20:20 Ratio: 1.6545454545454545
Max-min Ratio: 1.6545454545454545
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-03-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 506.58
  episode_reward_min: 323.0
  episodes_this_iter: 1
  episodes_total: 282
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.587
    dispatch_time_ms: 8.519
    learner:
      cur_lr: 0.001266094041056931
      grad_gnorm: 40.000003814697266
      policy_entropy: 38.52244186401367
      policy_loss: -9.263935089111328
      var_gnorm: 43.69296646118164
      vf_explained_var: 0.6651427745819092
      vf_loss: 9.411556243896484
    num_steps_sampled: 1415000
    num_steps_trained: 1415000
    wait_time_ms: 114.669
  iterations_since_restore: 283
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3417.0521850585938
  time_this_iter_s: 11.838481903076172
  time_total_s: 3417.0521850585938
  timestamp: 1593997422
  timesteps_since_restore: 1415000
  timesteps_this_iter: 5000
  timesteps_total: 1415000
  training_iteration: 283
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3417 s, 283 iter, 1415000 ts, 507 rew

agent-1: 98.0
agent-2: 79.0
agent-3: 69.0
agent-4: 69.0
agent-5: 86.0
Sum Reward: 401.0
Avg Reward: 80.2
Min Reward: 69.0
Gini Coefficient: 0.07481296758104738
20:20 Ratio: 1.4202898550724639
Max-min Ratio: 1.4202898550724639
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-03-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 505.15
  episode_reward_min: 323.0
  episodes_this_iter: 1
  episodes_total: 283
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.898
    dispatch_time_ms: 7.838
    learner:
      cur_lr: 0.0012657609768211842
      grad_gnorm: 40.00000762939453
      policy_entropy: 31.179290771484375
      policy_loss: 36.42275619506836
      var_gnorm: 43.70814514160156
      vf_explained_var: 0.707915186882019
      vf_loss: 115.1872329711914
    num_steps_sampled: 1420000
    num_steps_trained: 1420000
    wait_time_ms: 96.756
  iterations_since_restore: 284
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3429.0639641284943
  time_this_iter_s: 12.011779069900513
  time_total_s: 3429.0639641284943
  timestamp: 1593997434
  timesteps_since_restore: 1420000
  timesteps_this_iter: 5000
  timesteps_total: 1420000
  training_iteration: 284
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3429 s, 284 iter, 1420000 ts, 505 rew

agent-1: 69.0
agent-2: 71.0
agent-3: 56.0
agent-4: 59.0
agent-5: 71.0
Sum Reward: 326.0
Avg Reward: 65.2
Min Reward: 56.0
Gini Coefficient: 0.051533742331288344
20:20 Ratio: 1.2678571428571428
Max-min Ratio: 1.2678571428571428
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-04-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 502.94
  episode_reward_min: 323.0
  episodes_this_iter: 1
  episodes_total: 284
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.073
    dispatch_time_ms: 8.076
    learner:
      cur_lr: 0.0012654280290007591
      grad_gnorm: 39.99999237060547
      policy_entropy: 31.976776123046875
      policy_loss: -14.732641220092773
      var_gnorm: 43.74652862548828
      vf_explained_var: 0.27319908142089844
      vf_loss: 59.37395477294922
    num_steps_sampled: 1425000
    num_steps_trained: 1425000
    wait_time_ms: 112.775
  iterations_since_restore: 285
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3440.8030416965485
  time_this_iter_s: 11.7390775680542
  time_total_s: 3440.8030416965485
  timestamp: 1593997446
  timesteps_since_restore: 1425000
  timesteps_this_iter: 5000
  timesteps_total: 1425000
  training_iteration: 285
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3440 s, 285 iter, 1425000 ts, 503 rew

agent-1: 87.0
agent-2: 80.0
agent-3: 87.0
agent-4: 103.0
agent-5: 101.0
Sum Reward: 458.0
Avg Reward: 91.6
Min Reward: 80.0
Gini Coefficient: 0.05240174672489083
20:20 Ratio: 1.2875
Max-min Ratio: 1.2875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-04-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 834.0
  episode_reward_mean: 502.47
  episode_reward_min: 323.0
  episodes_this_iter: 1
  episodes_total: 285
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.158
    dispatch_time_ms: 6.655
    learner:
      cur_lr: 0.0012650949647650123
      grad_gnorm: 5.356934547424316
      policy_entropy: 44.356422424316406
      policy_loss: 2.1285035610198975
      var_gnorm: 43.74639892578125
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.030427493155002594
    num_steps_sampled: 1430000
    num_steps_trained: 1430000
    wait_time_ms: 113.754
  iterations_since_restore: 286
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3453.0907995700836
  time_this_iter_s: 12.287757873535156
  time_total_s: 3453.0907995700836
  timestamp: 1593997459
  timesteps_since_restore: 1430000
  timesteps_this_iter: 5000
  timesteps_total: 1430000
  training_iteration: 286
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3453 s, 286 iter, 1430000 ts, 502 rew

agent-1: 79.0
agent-2: 65.0
agent-3: 94.0
agent-4: 106.0
agent-5: 94.0
Sum Reward: 438.0
Avg Reward: 87.6
Min Reward: 65.0
Gini Coefficient: 0.08858447488584476
20:20 Ratio: 1.6307692307692307
Max-min Ratio: 1.6307692307692307
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-04-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 801.0
  episode_reward_mean: 498.51
  episode_reward_min: 323.0
  episodes_this_iter: 1
  episodes_total: 286
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.275
    dispatch_time_ms: 11.853
    learner:
      cur_lr: 0.0012647620169445872
      grad_gnorm: 40.000003814697266
      policy_entropy: 13.558939933776855
      policy_loss: -5.0309977531433105
      var_gnorm: 43.83588409423828
      vf_explained_var: -0.04283738136291504
      vf_loss: 37.91075897216797
    num_steps_sampled: 1435000
    num_steps_trained: 1435000
    wait_time_ms: 109.061
  iterations_since_restore: 287
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3465.227962732315
  time_this_iter_s: 12.137163162231445
  time_total_s: 3465.227962732315
  timestamp: 1593997471
  timesteps_since_restore: 1435000
  timesteps_this_iter: 5000
  timesteps_total: 1435000
  training_iteration: 287
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3465 s, 287 iter, 1435000 ts, 499 rew

agent-1: 59.0
agent-2: 68.0
agent-3: 71.0
agent-4: 70.0
agent-5: 67.0
Sum Reward: 335.0
Avg Reward: 67.0
Min Reward: 59.0
Gini Coefficient: 0.032238805970149255
20:20 Ratio: 1.2033898305084745
Max-min Ratio: 1.2033898305084745
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-04-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 801.0
  episode_reward_mean: 495.89
  episode_reward_min: 323.0
  episodes_this_iter: 1
  episodes_total: 287
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.198
    dispatch_time_ms: 6.996
    learner:
      cur_lr: 0.0012644289527088404
      grad_gnorm: 40.0
      policy_entropy: 40.086299896240234
      policy_loss: -2.5868980884552
      var_gnorm: 43.933006286621094
      vf_explained_var: 0.11170381307601929
      vf_loss: 9.87112045288086
    num_steps_sampled: 1440000
    num_steps_trained: 1440000
    wait_time_ms: 115.972
  iterations_since_restore: 288
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3477.62806224823
  time_this_iter_s: 12.400099515914917
  time_total_s: 3477.62806224823
  timestamp: 1593997483
  timesteps_since_restore: 1440000
  timesteps_this_iter: 5000
  timesteps_total: 1440000
  training_iteration: 288
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3477 s, 288 iter, 1440000 ts, 496 rew

agent-1: 108.0
agent-2: 93.0
agent-3: 89.0
agent-4: 149.0
agent-5: 106.0
Sum Reward: 545.0
Avg Reward: 109.0
Min Reward: 89.0
Gini Coefficient: 0.09908256880733946
20:20 Ratio: 1.6741573033707866
Max-min Ratio: 1.6741573033707866
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-04-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 801.0
  episode_reward_mean: 495.34
  episode_reward_min: 323.0
  episodes_this_iter: 1
  episodes_total: 288
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.67
    dispatch_time_ms: 6.374
    learner:
      cur_lr: 0.0012640960048884153
      grad_gnorm: 40.0
      policy_entropy: 25.141231536865234
      policy_loss: -4.49812650680542
      var_gnorm: 43.99363708496094
      vf_explained_var: 0.9063450694084167
      vf_loss: 67.75452423095703
    num_steps_sampled: 1445000
    num_steps_trained: 1445000
    wait_time_ms: 108.931
  iterations_since_restore: 289
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3489.333438873291
  time_this_iter_s: 11.705376625061035
  time_total_s: 3489.333438873291
  timestamp: 1593997495
  timesteps_since_restore: 1445000
  timesteps_this_iter: 5000
  timesteps_total: 1445000
  training_iteration: 289
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3489 s, 289 iter, 1445000 ts, 495 rew

agent-1: 81.0
agent-2: 91.0
agent-3: 88.0
agent-4: 94.0
agent-5: 97.0
Sum Reward: 451.0
Avg Reward: 90.2
Min Reward: 81.0
Gini Coefficient: 0.03370288248337029
20:20 Ratio: 1.1975308641975309
Max-min Ratio: 1.1975308641975309
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-05-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 801.0
  episode_reward_mean: 492.09
  episode_reward_min: 323.0
  episodes_this_iter: 1
  episodes_total: 289
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.695
    dispatch_time_ms: 8.012
    learner:
      cur_lr: 0.0012637630570679903
      grad_gnorm: 1.3858247995376587
      policy_entropy: 43.74969482421875
      policy_loss: 0.3994905352592468
      var_gnorm: 44.001983642578125
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0022763798478990793
    num_steps_sampled: 1450000
    num_steps_trained: 1450000
    wait_time_ms: 110.348
  iterations_since_restore: 290
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3501.724954366684
  time_this_iter_s: 12.391515493392944
  time_total_s: 3501.724954366684
  timestamp: 1593997507
  timesteps_since_restore: 1450000
  timesteps_this_iter: 5000
  timesteps_total: 1450000
  training_iteration: 290
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3501 s, 290 iter, 1450000 ts, 492 rew

agent-1: 80.0
agent-2: 67.0
agent-3: 75.0
agent-4: 98.0
agent-5: 51.0
Sum Reward: 371.0
Avg Reward: 74.2
Min Reward: 51.0
Gini Coefficient: 0.11536388140161725
20:20 Ratio: 1.9215686274509804
Max-min Ratio: 1.9215686274509804
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-05-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 801.0
  episode_reward_mean: 488.8
  episode_reward_min: 323.0
  episodes_this_iter: 1
  episodes_total: 290
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.194
    dispatch_time_ms: 9.621
    learner:
      cur_lr: 0.0012634299928322434
      grad_gnorm: 37.28266525268555
      policy_entropy: 34.25568389892578
      policy_loss: 4.423508644104004
      var_gnorm: 44.027278900146484
      vf_explained_var: 0.7815114259719849
      vf_loss: 14.791592597961426
    num_steps_sampled: 1455000
    num_steps_trained: 1455000
    wait_time_ms: 107.507
  iterations_since_restore: 291
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3513.637567281723
  time_this_iter_s: 11.912612915039062
  time_total_s: 3513.637567281723
  timestamp: 1593997519
  timesteps_since_restore: 1455000
  timesteps_this_iter: 5000
  timesteps_total: 1455000
  training_iteration: 291
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3513 s, 291 iter, 1455000 ts, 489 rew

agent-1: 84.0
agent-2: 68.0
agent-3: 88.0
agent-4: 73.0
agent-5: 73.0
Sum Reward: 386.0
Avg Reward: 77.2
Min Reward: 68.0
Gini Coefficient: 0.05284974093264249
20:20 Ratio: 1.2941176470588236
Max-min Ratio: 1.2941176470588236
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-05-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 801.0
  episode_reward_mean: 485.37
  episode_reward_min: 323.0
  episodes_this_iter: 1
  episodes_total: 291
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.085
    dispatch_time_ms: 6.985
    learner:
      cur_lr: 0.0012630970450118184
      grad_gnorm: 40.0
      policy_entropy: 13.548836708068848
      policy_loss: 3.5331077575683594
      var_gnorm: 44.061744689941406
      vf_explained_var: 0.056558847427368164
      vf_loss: 135.84068298339844
    num_steps_sampled: 1460000
    num_steps_trained: 1460000
    wait_time_ms: 104.563
  iterations_since_restore: 292
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3525.8934214115143
  time_this_iter_s: 12.25585412979126
  time_total_s: 3525.8934214115143
  timestamp: 1593997532
  timesteps_since_restore: 1460000
  timesteps_this_iter: 5000
  timesteps_total: 1460000
  training_iteration: 292
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3525 s, 292 iter, 1460000 ts, 485 rew

agent-1: 96.0
agent-2: 94.0
agent-3: 114.0
agent-4: 105.0
agent-5: 100.0
Sum Reward: 509.0
Avg Reward: 101.8
Min Reward: 94.0
Gini Coefficient: 0.03850687622789784
20:20 Ratio: 1.2127659574468086
Max-min Ratio: 1.2127659574468086
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-05-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 801.0
  episode_reward_mean: 483.22
  episode_reward_min: 323.0
  episodes_this_iter: 1
  episodes_total: 292
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.176
    dispatch_time_ms: 6.464
    learner:
      cur_lr: 0.0012627639807760715
      grad_gnorm: 39.999977111816406
      policy_entropy: 26.370813369750977
      policy_loss: -16.354646682739258
      var_gnorm: 44.10672378540039
      vf_explained_var: 0.3807365298271179
      vf_loss: 137.6119384765625
    num_steps_sampled: 1465000
    num_steps_trained: 1465000
    wait_time_ms: 112.528
  iterations_since_restore: 293
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3541.2826478481293
  time_this_iter_s: 15.38922643661499
  time_total_s: 3541.2826478481293
  timestamp: 1593997547
  timesteps_since_restore: 1465000
  timesteps_this_iter: 5000
  timesteps_total: 1465000
  training_iteration: 293
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3541 s, 293 iter, 1465000 ts, 483 rew

agent-1: 85.0
agent-2: 38.0
agent-3: 73.0
agent-4: 56.0
agent-5: 64.0
Sum Reward: 316.0
Avg Reward: 63.2
Min Reward: 38.0
Gini Coefficient: 0.14050632911392405
20:20 Ratio: 2.236842105263158
Max-min Ratio: 2.236842105263158
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-05-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 801.0
  episode_reward_mean: 481.7
  episode_reward_min: 316.0
  episodes_this_iter: 1
  episodes_total: 293
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.831
    dispatch_time_ms: 21.515
    learner:
      cur_lr: 0.0012624310329556465
      grad_gnorm: 7.657538890838623
      policy_entropy: 42.479984283447266
      policy_loss: -0.4488106966018677
      var_gnorm: 44.12419128417969
      vf_explained_var: 0.35304468870162964
      vf_loss: 0.2791649401187897
    num_steps_sampled: 1470000
    num_steps_trained: 1470000
    wait_time_ms: 106.52
  iterations_since_restore: 294
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3553.7099764347076
  time_this_iter_s: 12.42732858657837
  time_total_s: 3553.7099764347076
  timestamp: 1593997559
  timesteps_since_restore: 1470000
  timesteps_this_iter: 5000
  timesteps_total: 1470000
  training_iteration: 294
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3553 s, 294 iter, 1470000 ts, 482 rew

agent-1: 66.0
agent-2: 91.0
agent-3: 75.0
agent-4: 105.0
agent-5: 76.0
Sum Reward: 413.0
Avg Reward: 82.6
Min Reward: 66.0
Gini Coefficient: 0.0910411622276029
20:20 Ratio: 1.5909090909090908
Max-min Ratio: 1.5909090909090908
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-06-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 801.0
  episode_reward_mean: 479.86
  episode_reward_min: 316.0
  episodes_this_iter: 1
  episodes_total: 294
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.617
    dispatch_time_ms: 32.767
    learner:
      cur_lr: 0.0012620979687198997
      grad_gnorm: 26.432857513427734
      policy_entropy: 29.89832305908203
      policy_loss: -6.573167324066162
      var_gnorm: 44.321067810058594
      vf_explained_var: 0.8109692931175232
      vf_loss: 16.681278228759766
    num_steps_sampled: 1475000
    num_steps_trained: 1475000
    wait_time_ms: 107.094
  iterations_since_restore: 295
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3565.881914138794
  time_this_iter_s: 12.171937704086304
  time_total_s: 3565.881914138794
  timestamp: 1593997572
  timesteps_since_restore: 1475000
  timesteps_this_iter: 5000
  timesteps_total: 1475000
  training_iteration: 295
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3565 s, 295 iter, 1475000 ts, 480 rew

agent-1: 102.0
agent-2: 92.0
agent-3: 79.0
agent-4: 69.0
agent-5: 93.0
Sum Reward: 435.0
Avg Reward: 87.0
Min Reward: 69.0
Gini Coefficient: 0.0735632183908046
20:20 Ratio: 1.4782608695652173
Max-min Ratio: 1.4782608695652173
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-06-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 801.0
  episode_reward_mean: 477.72
  episode_reward_min: 316.0
  episodes_this_iter: 1
  episodes_total: 295
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.972
    dispatch_time_ms: 29.081
    learner:
      cur_lr: 0.0012617650208994746
      grad_gnorm: 40.000003814697266
      policy_entropy: 7.667087554931641
      policy_loss: 3.504643678665161
      var_gnorm: 44.391990661621094
      vf_explained_var: -0.010915040969848633
      vf_loss: 53.40973663330078
    num_steps_sampled: 1480000
    num_steps_trained: 1480000
    wait_time_ms: 95.447
  iterations_since_restore: 296
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3578.4647545814514
  time_this_iter_s: 12.58284044265747
  time_total_s: 3578.4647545814514
  timestamp: 1593997584
  timesteps_since_restore: 1480000
  timesteps_this_iter: 5000
  timesteps_total: 1480000
  training_iteration: 296
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3578 s, 296 iter, 1480000 ts, 478 rew

agent-1: 67.0
agent-2: 80.0
agent-3: 79.0
agent-4: 72.0
agent-5: 81.0
Sum Reward: 379.0
Avg Reward: 75.8
Min Reward: 67.0
Gini Coefficient: 0.03799472295514512
20:20 Ratio: 1.208955223880597
Max-min Ratio: 1.208955223880597
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-06-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 801.0
  episode_reward_mean: 476.93
  episode_reward_min: 316.0
  episodes_this_iter: 1
  episodes_total: 296
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.743
    dispatch_time_ms: 28.673
    learner:
      cur_lr: 0.0012614319566637278
      grad_gnorm: 10.145139694213867
      policy_entropy: 52.93489074707031
      policy_loss: -5.064138412475586
      var_gnorm: 44.43465805053711
      vf_explained_var: 0.9830053448677063
      vf_loss: 0.6990100741386414
    num_steps_sampled: 1485000
    num_steps_trained: 1485000
    wait_time_ms: 97.53
  iterations_since_restore: 297
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3590.9982039928436
  time_this_iter_s: 12.533449411392212
  time_total_s: 3590.9982039928436
  timestamp: 1593997597
  timesteps_since_restore: 1485000
  timesteps_this_iter: 5000
  timesteps_total: 1485000
  training_iteration: 297
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3590 s, 297 iter, 1485000 ts, 477 rew

agent-1: 74.0
agent-2: 84.0
agent-3: 88.0
agent-4: 74.0
agent-5: 74.0
Sum Reward: 394.0
Avg Reward: 78.8
Min Reward: 74.0
Gini Coefficient: 0.03857868020304569
20:20 Ratio: 1.1891891891891893
Max-min Ratio: 1.1891891891891893
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-06-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 801.0
  episode_reward_mean: 475.26
  episode_reward_min: 316.0
  episodes_this_iter: 1
  episodes_total: 297
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.205
    dispatch_time_ms: 37.207
    learner:
      cur_lr: 0.0012610990088433027
      grad_gnorm: 39.999996185302734
      policy_entropy: 11.100118637084961
      policy_loss: -1.7871026992797852
      var_gnorm: 44.45314025878906
      vf_explained_var: 0.010202646255493164
      vf_loss: 39.03125762939453
    num_steps_sampled: 1490000
    num_steps_trained: 1490000
    wait_time_ms: 82.474
  iterations_since_restore: 298
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3603.8579862117767
  time_this_iter_s: 12.859782218933105
  time_total_s: 3603.8579862117767
  timestamp: 1593997610
  timesteps_since_restore: 1490000
  timesteps_this_iter: 5000
  timesteps_total: 1490000
  training_iteration: 298
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3603 s, 298 iter, 1490000 ts, 475 rew

agent-1: 61.0
agent-2: 43.0
agent-3: 52.0
agent-4: 54.0
agent-5: 37.0
Sum Reward: 247.0
Avg Reward: 49.4
Min Reward: 37.0
Gini Coefficient: 0.09554655870445344
20:20 Ratio: 1.6486486486486487
Max-min Ratio: 1.6486486486486487
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-07-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 801.0
  episode_reward_mean: 472.16
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 298
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.464
    dispatch_time_ms: 43.766
    learner:
      cur_lr: 0.0012607659446075559
      grad_gnorm: 40.000003814697266
      policy_entropy: 16.496288299560547
      policy_loss: -7.155068874359131
      var_gnorm: 44.54787063598633
      vf_explained_var: 0.6502978205680847
      vf_loss: 86.7120132446289
    num_steps_sampled: 1495000
    num_steps_trained: 1495000
    wait_time_ms: 79.523
  iterations_since_restore: 299
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3615.5932331085205
  time_this_iter_s: 11.735246896743774
  time_total_s: 3615.5932331085205
  timestamp: 1593997622
  timesteps_since_restore: 1495000
  timesteps_this_iter: 5000
  timesteps_total: 1495000
  training_iteration: 299
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3615 s, 299 iter, 1495000 ts, 472 rew

agent-1: 132.0
agent-2: 150.0
agent-3: 104.0
agent-4: 144.0
agent-5: 116.0
Sum Reward: 646.0
Avg Reward: 129.2
Min Reward: 104.0
Gini Coefficient: 0.07430340557275542
20:20 Ratio: 1.4423076923076923
Max-min Ratio: 1.4423076923076923
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-07-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 801.0
  episode_reward_mean: 472.23
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 299
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.426
    dispatch_time_ms: 6.948
    learner:
      cur_lr: 0.0012604329967871308
      grad_gnorm: 0.45219600200653076
      policy_entropy: 44.94270706176758
      policy_loss: 0.13158242404460907
      var_gnorm: 44.627132415771484
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.000145216123200953
    num_steps_sampled: 1500000
    num_steps_trained: 1500000
    wait_time_ms: 102.375
  iterations_since_restore: 300
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3627.963382959366
  time_this_iter_s: 12.370149850845337
  time_total_s: 3627.963382959366
  timestamp: 1593997634
  timesteps_since_restore: 1500000
  timesteps_this_iter: 5000
  timesteps_total: 1500000
  training_iteration: 300
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3627 s, 300 iter, 1500000 ts, 472 rew

agent-1: 90.0
agent-2: 64.0
agent-3: 82.0
agent-4: 100.0
agent-5: 74.0
Sum Reward: 410.0
Avg Reward: 82.0
Min Reward: 64.0
Gini Coefficient: 0.08585365853658537
20:20 Ratio: 1.5625
Max-min Ratio: 1.5625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-07-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 801.0
  episode_reward_mean: 469.11
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 300
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.634
    dispatch_time_ms: 7.636
    learner:
      cur_lr: 0.0012601000489667058
      grad_gnorm: 29.01765251159668
      policy_entropy: 54.755313873291016
      policy_loss: -10.800890922546387
      var_gnorm: 44.656898498535156
      vf_explained_var: 0.9113603830337524
      vf_loss: 3.406820058822632
    num_steps_sampled: 1505000
    num_steps_trained: 1505000
    wait_time_ms: 113.278
  iterations_since_restore: 301
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3639.2802612781525
  time_this_iter_s: 11.316878318786621
  time_total_s: 3639.2802612781525
  timestamp: 1593997645
  timesteps_since_restore: 1505000
  timesteps_this_iter: 5000
  timesteps_total: 1505000
  training_iteration: 301
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3639 s, 301 iter, 1505000 ts, 469 rew

agent-1: 69.0
agent-2: 64.0
agent-3: 92.0
agent-4: 83.0
agent-5: 72.0
Sum Reward: 380.0
Avg Reward: 76.0
Min Reward: 64.0
Gini Coefficient: 0.07368421052631578
20:20 Ratio: 1.4375
Max-min Ratio: 1.4375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-07-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 801.0
  episode_reward_mean: 467.16
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 301
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.913
    dispatch_time_ms: 6.336
    learner:
      cur_lr: 0.001259766984730959
      grad_gnorm: 40.0
      policy_entropy: 20.302610397338867
      policy_loss: 1.6438267230987549
      var_gnorm: 44.62434768676758
      vf_explained_var: 0.11691629886627197
      vf_loss: 34.64238739013672
    num_steps_sampled: 1510000
    num_steps_trained: 1510000
    wait_time_ms: 94.959
  iterations_since_restore: 302
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3651.052329301834
  time_this_iter_s: 11.77206802368164
  time_total_s: 3651.052329301834
  timestamp: 1593997657
  timesteps_since_restore: 1510000
  timesteps_this_iter: 5000
  timesteps_total: 1510000
  training_iteration: 302
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3651 s, 302 iter, 1510000 ts, 467 rew

agent-1: 112.0
agent-2: 148.0
agent-3: 142.0
agent-4: 121.0
agent-5: 129.0
Sum Reward: 652.0
Avg Reward: 130.4
Min Reward: 112.0
Gini Coefficient: 0.05705521472392638
20:20 Ratio: 1.3214285714285714
Max-min Ratio: 1.3214285714285714
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-07-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 801.0
  episode_reward_mean: 467.08
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 302
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.45
    dispatch_time_ms: 33.342
    learner:
      cur_lr: 0.001259434036910534
      grad_gnorm: 36.1884651184082
      policy_entropy: 52.941505432128906
      policy_loss: -10.463066101074219
      var_gnorm: 44.74370193481445
      vf_explained_var: 0.7537978887557983
      vf_loss: 8.405720710754395
    num_steps_sampled: 1515000
    num_steps_trained: 1515000
    wait_time_ms: 95.804
  iterations_since_restore: 303
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3662.951406955719
  time_this_iter_s: 11.899077653884888
  time_total_s: 3662.951406955719
  timestamp: 1593997669
  timesteps_since_restore: 1515000
  timesteps_this_iter: 5000
  timesteps_total: 1515000
  training_iteration: 303
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3662 s, 303 iter, 1515000 ts, 467 rew

agent-1: 85.0
agent-2: 61.0
agent-3: 65.0
agent-4: 66.0
agent-5: 66.0
Sum Reward: 343.0
Avg Reward: 68.6
Min Reward: 61.0
Gini Coefficient: 0.05714285714285714
20:20 Ratio: 1.3934426229508197
Max-min Ratio: 1.3934426229508197
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-08-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 801.0
  episode_reward_mean: 463.15
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 303
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.995
    dispatch_time_ms: 30.482
    learner:
      cur_lr: 0.001259100972674787
      grad_gnorm: 40.000003814697266
      policy_entropy: 18.232952117919922
      policy_loss: -1.6681327819824219
      var_gnorm: 44.794193267822266
      vf_explained_var: -0.3888758420944214
      vf_loss: 63.56932830810547
    num_steps_sampled: 1520000
    num_steps_trained: 1520000
    wait_time_ms: 85.616
  iterations_since_restore: 304
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3675.6995730400085
  time_this_iter_s: 12.74816608428955
  time_total_s: 3675.6995730400085
  timestamp: 1593997682
  timesteps_since_restore: 1520000
  timesteps_this_iter: 5000
  timesteps_total: 1520000
  training_iteration: 304
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3675 s, 304 iter, 1520000 ts, 463 rew

agent-1: 79.0
agent-2: 64.0
agent-3: 90.0
agent-4: 81.0
agent-5: 84.0
Sum Reward: 398.0
Avg Reward: 79.6
Min Reward: 64.0
Gini Coefficient: 0.05728643216080402
20:20 Ratio: 1.40625
Max-min Ratio: 1.40625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-08-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 801.0
  episode_reward_mean: 462.11
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 304
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.361
    dispatch_time_ms: 38.734
    learner:
      cur_lr: 0.001258768024854362
      grad_gnorm: 40.0
      policy_entropy: 32.64838790893555
      policy_loss: 20.36695098876953
      var_gnorm: 44.90737533569336
      vf_explained_var: 0.7285425662994385
      vf_loss: 162.7920684814453
    num_steps_sampled: 1525000
    num_steps_trained: 1525000
    wait_time_ms: 76.549
  iterations_since_restore: 305
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3688.0086636543274
  time_this_iter_s: 12.309090614318848
  time_total_s: 3688.0086636543274
  timestamp: 1593997694
  timesteps_since_restore: 1525000
  timesteps_this_iter: 5000
  timesteps_total: 1525000
  training_iteration: 305
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3688 s, 305 iter, 1525000 ts, 462 rew

agent-1: 77.0
agent-2: 77.0
agent-3: 89.0
agent-4: 64.0
agent-5: 83.0
Sum Reward: 390.0
Avg Reward: 78.0
Min Reward: 64.0
Gini Coefficient: 0.057435897435897436
20:20 Ratio: 1.390625
Max-min Ratio: 1.390625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-08-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 801.0
  episode_reward_mean: 460.62
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 305
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.058
    dispatch_time_ms: 11.293
    learner:
      cur_lr: 0.0012584349606186152
      grad_gnorm: 9.708342552185059
      policy_entropy: 48.7637939453125
      policy_loss: -2.9475276470184326
      var_gnorm: 44.934326171875
      vf_explained_var: 0.995559573173523
      vf_loss: 0.3044353723526001
    num_steps_sampled: 1530000
    num_steps_trained: 1530000
    wait_time_ms: 103.087
  iterations_since_restore: 306
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3699.622980117798
  time_this_iter_s: 11.614316463470459
  time_total_s: 3699.622980117798
  timestamp: 1593997719
  timesteps_since_restore: 1530000
  timesteps_this_iter: 5000
  timesteps_total: 1530000
  training_iteration: 306
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3699 s, 306 iter, 1530000 ts, 461 rew

agent-1: 77.0
agent-2: 79.0
agent-3: 72.0
agent-4: 120.0
agent-5: 92.0
Sum Reward: 440.0
Avg Reward: 88.0
Min Reward: 72.0
Gini Coefficient: 0.1009090909090909
20:20 Ratio: 1.6666666666666667
Max-min Ratio: 1.6666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-08-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 801.0
  episode_reward_mean: 458.65
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 306
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.682
    dispatch_time_ms: 13.629
    learner:
      cur_lr: 0.0012581020127981901
      grad_gnorm: 39.9999885559082
      policy_entropy: 40.21958923339844
      policy_loss: -11.864005088806152
      var_gnorm: 44.91535186767578
      vf_explained_var: -1.0
      vf_loss: 7.622945785522461
    num_steps_sampled: 1535000
    num_steps_trained: 1535000
    wait_time_ms: 112.324
  iterations_since_restore: 307
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3711.075385093689
  time_this_iter_s: 11.452404975891113
  time_total_s: 3711.075385093689
  timestamp: 1593997731
  timesteps_since_restore: 1535000
  timesteps_this_iter: 5000
  timesteps_total: 1535000
  training_iteration: 307
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3711 s, 307 iter, 1535000 ts, 459 rew

agent-1: 91.0
agent-2: 91.0
agent-3: 81.0
agent-4: 85.0
agent-5: 77.0
Sum Reward: 425.0
Avg Reward: 85.0
Min Reward: 77.0
Gini Coefficient: 0.03576470588235294
20:20 Ratio: 1.1818181818181819
Max-min Ratio: 1.1818181818181819
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-09-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 801.0
  episode_reward_mean: 456.83
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 307
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.27
    dispatch_time_ms: 28.519
    learner:
      cur_lr: 0.0012577689485624433
      grad_gnorm: 39.999996185302734
      policy_entropy: 37.021541595458984
      policy_loss: 26.576730728149414
      var_gnorm: 44.9113655090332
      vf_explained_var: -0.11937928199768066
      vf_loss: 81.5466537475586
    num_steps_sampled: 1540000
    num_steps_trained: 1540000
    wait_time_ms: 90.107
  iterations_since_restore: 308
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3723.5362610816956
  time_this_iter_s: 12.460875988006592
  time_total_s: 3723.5362610816956
  timestamp: 1593997743
  timesteps_since_restore: 1540000
  timesteps_this_iter: 5000
  timesteps_total: 1540000
  training_iteration: 308
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3723 s, 308 iter, 1540000 ts, 457 rew

agent-1: 82.0
agent-2: 100.0
agent-3: 71.0
agent-4: 75.0
agent-5: 78.0
Sum Reward: 406.0
Avg Reward: 81.2
Min Reward: 71.0
Gini Coefficient: 0.06403940886699508
20:20 Ratio: 1.408450704225352
Max-min Ratio: 1.408450704225352
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-09-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 801.0
  episode_reward_mean: 454.33
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 308
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.029
    dispatch_time_ms: 26.802
    learner:
      cur_lr: 0.0012574360007420182
      grad_gnorm: 8.030170440673828
      policy_entropy: 32.779964447021484
      policy_loss: -2.155850410461426
      var_gnorm: 45.0052490234375
      vf_explained_var: -1.0
      vf_loss: 1.142082691192627
    num_steps_sampled: 1545000
    num_steps_trained: 1545000
    wait_time_ms: 96.252
  iterations_since_restore: 309
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3735.2717461586
  time_this_iter_s: 11.735485076904297
  time_total_s: 3735.2717461586
  timestamp: 1593997755
  timesteps_since_restore: 1545000
  timesteps_this_iter: 5000
  timesteps_total: 1545000
  training_iteration: 309
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3735 s, 309 iter, 1545000 ts, 454 rew

agent-1: 66.0
agent-2: 66.0
agent-3: 71.0
agent-4: 43.0
agent-5: 58.0
Sum Reward: 304.0
Avg Reward: 60.8
Min Reward: 43.0
Gini Coefficient: 0.08421052631578947
20:20 Ratio: 1.6511627906976745
Max-min Ratio: 1.6511627906976745
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-09-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 741.0
  episode_reward_mean: 449.36
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 309
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.947
    dispatch_time_ms: 6.735
    learner:
      cur_lr: 0.0012571030529215932
      grad_gnorm: 40.0
      policy_entropy: 10.225127220153809
      policy_loss: 6.606142044067383
      var_gnorm: 45.060420989990234
      vf_explained_var: 0.05540519952774048
      vf_loss: 27.339340209960938
    num_steps_sampled: 1550000
    num_steps_trained: 1550000
    wait_time_ms: 105.274
  iterations_since_restore: 310
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3747.091874361038
  time_this_iter_s: 11.820128202438354
  time_total_s: 3747.091874361038
  timestamp: 1593997767
  timesteps_since_restore: 1550000
  timesteps_this_iter: 5000
  timesteps_total: 1550000
  training_iteration: 310
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3747 s, 310 iter, 1550000 ts, 449 rew

agent-1: 144.0
agent-2: 153.0
agent-3: 135.0
agent-4: 111.0
agent-5: 123.0
Sum Reward: 666.0
Avg Reward: 133.2
Min Reward: 111.0
Gini Coefficient: 0.06306306306306306
20:20 Ratio: 1.3783783783783783
Max-min Ratio: 1.3783783783783783
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-09-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 741.0
  episode_reward_mean: 450.18
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 310
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.985
    dispatch_time_ms: 5.975
    learner:
      cur_lr: 0.0012567699886858463
      grad_gnorm: 39.999996185302734
      policy_entropy: 23.077072143554688
      policy_loss: -7.682253360748291
      var_gnorm: 45.12946319580078
      vf_explained_var: -1.0
      vf_loss: 163.313720703125
    num_steps_sampled: 1555000
    num_steps_trained: 1555000
    wait_time_ms: 114.093
  iterations_since_restore: 311
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3758.4633457660675
  time_this_iter_s: 11.371471405029297
  time_total_s: 3758.4633457660675
  timestamp: 1593997778
  timesteps_since_restore: 1555000
  timesteps_this_iter: 5000
  timesteps_total: 1555000
  training_iteration: 311
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3758 s, 311 iter, 1555000 ts, 450 rew

agent-1: 77.0
agent-2: 102.0
agent-3: 63.0
agent-4: 99.0
agent-5: 90.0
Sum Reward: 431.0
Avg Reward: 86.2
Min Reward: 63.0
Gini Coefficient: 0.09280742459396751
20:20 Ratio: 1.619047619047619
Max-min Ratio: 1.619047619047619
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-09-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 741.0
  episode_reward_mean: 447.46
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 311
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.605
    dispatch_time_ms: 9.146
    learner:
      cur_lr: 0.0012564370408654213
      grad_gnorm: 7.143342971801758
      policy_entropy: 30.97701644897461
      policy_loss: -1.0032135248184204
      var_gnorm: 45.1877555847168
      vf_explained_var: 0.9963265061378479
      vf_loss: 0.1280687153339386
    num_steps_sampled: 1560000
    num_steps_trained: 1560000
    wait_time_ms: 93.089
  iterations_since_restore: 312
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3770.6377351284027
  time_this_iter_s: 12.174389362335205
  time_total_s: 3770.6377351284027
  timestamp: 1593997790
  timesteps_since_restore: 1560000
  timesteps_this_iter: 5000
  timesteps_total: 1560000
  training_iteration: 312
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3770 s, 312 iter, 1560000 ts, 447 rew

agent-1: 90.0
agent-2: 97.0
agent-3: 98.0
agent-4: 111.0
agent-5: 121.0
Sum Reward: 517.0
Avg Reward: 103.4
Min Reward: 90.0
Gini Coefficient: 0.05880077369439071
20:20 Ratio: 1.3444444444444446
Max-min Ratio: 1.3444444444444446
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-10-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 741.0
  episode_reward_mean: 446.49
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 312
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.662
    dispatch_time_ms: 8.081
    learner:
      cur_lr: 0.0012561039766296744
      grad_gnorm: 39.9999885559082
      policy_entropy: 16.422441482543945
      policy_loss: -17.658571243286133
      var_gnorm: 45.17830276489258
      vf_explained_var: 0.8801656365394592
      vf_loss: 98.12890625
    num_steps_sampled: 1565000
    num_steps_trained: 1565000
    wait_time_ms: 106.589
  iterations_since_restore: 313
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3781.661535024643
  time_this_iter_s: 11.023799896240234
  time_total_s: 3781.661535024643
  timestamp: 1593997802
  timesteps_since_restore: 1565000
  timesteps_this_iter: 5000
  timesteps_total: 1565000
  training_iteration: 313
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3781 s, 313 iter, 1565000 ts, 446 rew

agent-1: 83.0
agent-2: 114.0
agent-3: 98.0
agent-4: 121.0
agent-5: 111.0
Sum Reward: 527.0
Avg Reward: 105.4
Min Reward: 83.0
Gini Coefficient: 0.0698292220113852
20:20 Ratio: 1.4578313253012047
Max-min Ratio: 1.4578313253012047
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-10-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 741.0
  episode_reward_mean: 446.13
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 313
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.132
    dispatch_time_ms: 6.463
    learner:
      cur_lr: 0.0012557710288092494
      grad_gnorm: 28.88614845275879
      policy_entropy: 23.198680877685547
      policy_loss: 2.099186658859253
      var_gnorm: 45.297245025634766
      vf_explained_var: -1.0
      vf_loss: 19.49351692199707
    num_steps_sampled: 1570000
    num_steps_trained: 1570000
    wait_time_ms: 95.759
  iterations_since_restore: 314
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3793.6045162677765
  time_this_iter_s: 11.942981243133545
  time_total_s: 3793.6045162677765
  timestamp: 1593997814
  timesteps_since_restore: 1570000
  timesteps_this_iter: 5000
  timesteps_total: 1570000
  training_iteration: 314
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3793 s, 314 iter, 1570000 ts, 446 rew

agent-1: 141.0
agent-2: 101.0
agent-3: 133.0
agent-4: 121.0
agent-5: 99.0
Sum Reward: 595.0
Avg Reward: 119.0
Min Reward: 99.0
Gini Coefficient: 0.07798319327731093
20:20 Ratio: 1.4242424242424243
Max-min Ratio: 1.4242424242424243
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-10-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 741.0
  episode_reward_mean: 446.79
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 314
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.214
    dispatch_time_ms: 7.466
    learner:
      cur_lr: 0.0012554379645735025
      grad_gnorm: 40.000003814697266
      policy_entropy: 14.652234077453613
      policy_loss: 57.01654052734375
      var_gnorm: 45.443756103515625
      vf_explained_var: 0.18403273820877075
      vf_loss: 326.56842041015625
    num_steps_sampled: 1575000
    num_steps_trained: 1575000
    wait_time_ms: 111.065
  iterations_since_restore: 315
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3804.7538113594055
  time_this_iter_s: 11.149295091629028
  time_total_s: 3804.7538113594055
  timestamp: 1593997825
  timesteps_since_restore: 1575000
  timesteps_this_iter: 5000
  timesteps_total: 1575000
  training_iteration: 315
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3804 s, 315 iter, 1575000 ts, 447 rew

agent-1: 69.0
agent-2: 93.0
agent-3: 69.0
agent-4: 85.0
agent-5: 86.0
Sum Reward: 402.0
Avg Reward: 80.4
Min Reward: 69.0
Gini Coefficient: 0.06467661691542288
20:20 Ratio: 1.3478260869565217
Max-min Ratio: 1.3478260869565217
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-10-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 741.0
  episode_reward_mean: 445.31
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 315
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.501
    dispatch_time_ms: 8.92
    learner:
      cur_lr: 0.0012551050167530775
      grad_gnorm: 40.000003814697266
      policy_entropy: 23.388137817382812
      policy_loss: -5.009132385253906
      var_gnorm: 45.50785446166992
      vf_explained_var: -0.0554661750793457
      vf_loss: 23.230545043945312
    num_steps_sampled: 1580000
    num_steps_trained: 1580000
    wait_time_ms: 106.564
  iterations_since_restore: 316
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3817.0435490608215
  time_this_iter_s: 12.289737701416016
  time_total_s: 3817.0435490608215
  timestamp: 1593997837
  timesteps_since_restore: 1580000
  timesteps_this_iter: 5000
  timesteps_total: 1580000
  training_iteration: 316
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3817 s, 316 iter, 1580000 ts, 445 rew

agent-1: 80.0
agent-2: 97.0
agent-3: 100.0
agent-4: 100.0
agent-5: 110.0
Sum Reward: 487.0
Avg Reward: 97.4
Min Reward: 80.0
Gini Coefficient: 0.05174537987679671
20:20 Ratio: 1.375
Max-min Ratio: 1.375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-10-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 729.0
  episode_reward_mean: 442.77
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 316
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.559
    dispatch_time_ms: 7.006
    learner:
      cur_lr: 0.0012547719525173306
      grad_gnorm: 40.0
      policy_entropy: 6.713106632232666
      policy_loss: 0.5814980268478394
      var_gnorm: 45.51145935058594
      vf_explained_var: 0.23489195108413696
      vf_loss: 73.1257553100586
    num_steps_sampled: 1585000
    num_steps_trained: 1585000
    wait_time_ms: 102.128
  iterations_since_restore: 317
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3833.296725511551
  time_this_iter_s: 16.25317645072937
  time_total_s: 3833.296725511551
  timestamp: 1593997853
  timesteps_since_restore: 1585000
  timesteps_this_iter: 5000
  timesteps_total: 1585000
  training_iteration: 317
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3833 s, 317 iter, 1585000 ts, 443 rew

agent-1: 145.0
agent-2: 117.0
agent-3: 139.0
agent-4: 120.0
agent-5: 119.0
Sum Reward: 640.0
Avg Reward: 128.0
Min Reward: 117.0
Gini Coefficient: 0.0475
20:20 Ratio: 1.2393162393162394
Max-min Ratio: 1.2393162393162394
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-11-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 729.0
  episode_reward_mean: 443.48
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 317
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.341
    dispatch_time_ms: 8.661
    learner:
      cur_lr: 0.0012544390046969056
      grad_gnorm: 6.633515357971191
      policy_entropy: 32.24445724487305
      policy_loss: -0.9203804731369019
      var_gnorm: 45.60647201538086
      vf_explained_var: 0.9958813786506653
      vf_loss: 0.1789364069700241
    num_steps_sampled: 1590000
    num_steps_trained: 1590000
    wait_time_ms: 87.89
  iterations_since_restore: 318
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3845.309090614319
  time_this_iter_s: 12.012365102767944
  time_total_s: 3845.309090614319
  timestamp: 1593997865
  timesteps_since_restore: 1590000
  timesteps_this_iter: 5000
  timesteps_total: 1590000
  training_iteration: 318
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3845 s, 318 iter, 1590000 ts, 443 rew

agent-1: 94.0
agent-2: 89.0
agent-3: 153.0
agent-4: 90.0
agent-5: 130.0
Sum Reward: 556.0
Avg Reward: 111.2
Min Reward: 89.0
Gini Coefficient: 0.12086330935251799
20:20 Ratio: 1.7191011235955056
Max-min Ratio: 1.7191011235955056
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-11-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 666.0
  episode_reward_mean: 441.75
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 318
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.823
    dispatch_time_ms: 8.081
    learner:
      cur_lr: 0.0012541060568764806
      grad_gnorm: 40.0
      policy_entropy: 26.042560577392578
      policy_loss: 19.166404724121094
      var_gnorm: 45.7155876159668
      vf_explained_var: 0.44349777698516846
      vf_loss: 92.05235290527344
    num_steps_sampled: 1595000
    num_steps_trained: 1595000
    wait_time_ms: 108.172
  iterations_since_restore: 319
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3856.560270547867
  time_this_iter_s: 11.251179933547974
  time_total_s: 3856.560270547867
  timestamp: 1593997877
  timesteps_since_restore: 1595000
  timesteps_this_iter: 5000
  timesteps_total: 1595000
  training_iteration: 319
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3856 s, 319 iter, 1595000 ts, 442 rew

agent-1: 70.0
agent-2: 88.0
agent-3: 92.0
agent-4: 104.0
agent-5: 81.0
Sum Reward: 435.0
Avg Reward: 87.0
Min Reward: 70.0
Gini Coefficient: 0.07264367816091954
20:20 Ratio: 1.4857142857142858
Max-min Ratio: 1.4857142857142858
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-11-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 666.0
  episode_reward_mean: 441.35
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 319
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.781
    dispatch_time_ms: 6.238
    learner:
      cur_lr: 0.0012537729926407337
      grad_gnorm: 6.057660102844238
      policy_entropy: 36.16914749145508
      policy_loss: 1.3850338459014893
      var_gnorm: 45.71963882446289
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.043644264340400696
    num_steps_sampled: 1600000
    num_steps_trained: 1600000
    wait_time_ms: 112.417
  iterations_since_restore: 320
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3868.768713235855
  time_this_iter_s: 12.208442687988281
  time_total_s: 3868.768713235855
  timestamp: 1593997889
  timesteps_since_restore: 1600000
  timesteps_this_iter: 5000
  timesteps_total: 1600000
  training_iteration: 320
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3868 s, 320 iter, 1600000 ts, 441 rew

agent-1: 100.0
agent-2: 98.0
agent-3: 89.0
agent-4: 116.0
agent-5: 86.0
Sum Reward: 489.0
Avg Reward: 97.8
Min Reward: 86.0
Gini Coefficient: 0.05807770961145194
20:20 Ratio: 1.3488372093023255
Max-min Ratio: 1.3488372093023255
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-11-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 666.0
  episode_reward_mean: 441.14
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 320
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.653
    dispatch_time_ms: 6.539
    learner:
      cur_lr: 0.0012534400448203087
      grad_gnorm: 40.0
      policy_entropy: 34.71671676635742
      policy_loss: -8.550793647766113
      var_gnorm: 45.706573486328125
      vf_explained_var: 0.012610137462615967
      vf_loss: 23.44194793701172
    num_steps_sampled: 1605000
    num_steps_trained: 1605000
    wait_time_ms: 114.781
  iterations_since_restore: 321
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3879.665199279785
  time_this_iter_s: 10.896486043930054
  time_total_s: 3879.665199279785
  timestamp: 1593997900
  timesteps_since_restore: 1605000
  timesteps_this_iter: 5000
  timesteps_total: 1605000
  training_iteration: 321
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3879 s, 321 iter, 1605000 ts, 441 rew

agent-1: 115.0
agent-2: 106.0
agent-3: 105.0
agent-4: 92.0
agent-5: 104.0
Sum Reward: 522.0
Avg Reward: 104.4
Min Reward: 92.0
Gini Coefficient: 0.0367816091954023
20:20 Ratio: 1.25
Max-min Ratio: 1.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-11-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 666.0
  episode_reward_mean: 441.24
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 321
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.694
    dispatch_time_ms: 8.072
    learner:
      cur_lr: 0.0012531069805845618
      grad_gnorm: 40.0
      policy_entropy: 19.619619369506836
      policy_loss: 11.461376190185547
      var_gnorm: 45.709842681884766
      vf_explained_var: -0.08704543113708496
      vf_loss: 46.51931381225586
    num_steps_sampled: 1610000
    num_steps_trained: 1610000
    wait_time_ms: 99.205
  iterations_since_restore: 322
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3891.9186000823975
  time_this_iter_s: 12.253400802612305
  time_total_s: 3891.9186000823975
  timestamp: 1593997912
  timesteps_since_restore: 1610000
  timesteps_this_iter: 5000
  timesteps_total: 1610000
  training_iteration: 322
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3891 s, 322 iter, 1610000 ts, 441 rew

agent-1: 76.0
agent-2: 82.0
agent-3: 63.0
agent-4: 79.0
agent-5: 77.0
Sum Reward: 377.0
Avg Reward: 75.4
Min Reward: 63.0
Gini Coefficient: 0.04350132625994695
20:20 Ratio: 1.3015873015873016
Max-min Ratio: 1.3015873015873016
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-12-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 666.0
  episode_reward_mean: 440.07
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 322
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.374
    dispatch_time_ms: 5.959
    learner:
      cur_lr: 0.0012527740327641368
      grad_gnorm: 40.0
      policy_entropy: 12.171327590942383
      policy_loss: 4.859579563140869
      var_gnorm: 45.741580963134766
      vf_explained_var: 0.8992009162902832
      vf_loss: 45.12705612182617
    num_steps_sampled: 1615000
    num_steps_trained: 1615000
    wait_time_ms: 110.788
  iterations_since_restore: 323
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3903.0562357902527
  time_this_iter_s: 11.137635707855225
  time_total_s: 3903.0562357902527
  timestamp: 1593997923
  timesteps_since_restore: 1615000
  timesteps_this_iter: 5000
  timesteps_total: 1615000
  training_iteration: 323
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3903 s, 323 iter, 1615000 ts, 440 rew

agent-1: 93.0
agent-2: 89.0
agent-3: 88.0
agent-4: 71.0
agent-5: 85.0
Sum Reward: 426.0
Avg Reward: 85.2
Min Reward: 71.0
Gini Coefficient: 0.04507042253521127
20:20 Ratio: 1.3098591549295775
Max-min Ratio: 1.3098591549295775
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-12-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 666.0
  episode_reward_mean: 439.45
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 323
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.145
    dispatch_time_ms: 7.277
    learner:
      cur_lr: 0.00125244096852839
      grad_gnorm: 40.0
      policy_entropy: 8.76721477508545
      policy_loss: 6.5342254638671875
      var_gnorm: 45.76331329345703
      vf_explained_var: -0.21141290664672852
      vf_loss: 91.73309326171875
    num_steps_sampled: 1620000
    num_steps_trained: 1620000
    wait_time_ms: 107.521
  iterations_since_restore: 324
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3915.399265527725
  time_this_iter_s: 12.343029737472534
  time_total_s: 3915.399265527725
  timestamp: 1593997936
  timesteps_since_restore: 1620000
  timesteps_this_iter: 5000
  timesteps_total: 1620000
  training_iteration: 324
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3915 s, 324 iter, 1620000 ts, 439 rew

agent-1: 112.0
agent-2: 107.0
agent-3: 82.0
agent-4: 92.0
agent-5: 99.0
Sum Reward: 492.0
Avg Reward: 98.4
Min Reward: 82.0
Gini Coefficient: 0.06097560975609756
20:20 Ratio: 1.3658536585365855
Max-min Ratio: 1.3658536585365855
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-12-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 666.0
  episode_reward_mean: 437.93
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 324
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.171
    dispatch_time_ms: 33.263
    learner:
      cur_lr: 0.001252108020707965
      grad_gnorm: 39.999996185302734
      policy_entropy: 31.785648345947266
      policy_loss: -1.4331448078155518
      var_gnorm: 45.87809753417969
      vf_explained_var: 0.3228735327720642
      vf_loss: 12.887346267700195
    num_steps_sampled: 1625000
    num_steps_trained: 1625000
    wait_time_ms: 93.531
  iterations_since_restore: 325
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3927.163460254669
  time_this_iter_s: 11.76419472694397
  time_total_s: 3927.163460254669
  timestamp: 1593997948
  timesteps_since_restore: 1625000
  timesteps_this_iter: 5000
  timesteps_total: 1625000
  training_iteration: 325
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3927 s, 325 iter, 1625000 ts, 438 rew

agent-1: 68.0
agent-2: 82.0
agent-3: 85.0
agent-4: 85.0
agent-5: 83.0
Sum Reward: 403.0
Avg Reward: 80.6
Min Reward: 68.0
Gini Coefficient: 0.03672456575682382
20:20 Ratio: 1.25
Max-min Ratio: 1.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-12-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 666.0
  episode_reward_mean: 438.36
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 325
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.552
    dispatch_time_ms: 23.641
    learner:
      cur_lr: 0.001251774956472218
      grad_gnorm: 3.2311720848083496
      policy_entropy: 34.520179748535156
      policy_loss: 1.262930154800415
      var_gnorm: 45.8372802734375
      vf_explained_var: 9.5367431640625e-06
      vf_loss: 0.010193918831646442
    num_steps_sampled: 1630000
    num_steps_trained: 1630000
    wait_time_ms: 101.101
  iterations_since_restore: 326
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3940.1133248806
  time_this_iter_s: 12.949864625930786
  time_total_s: 3940.1133248806
  timestamp: 1593997960
  timesteps_since_restore: 1630000
  timesteps_this_iter: 5000
  timesteps_total: 1630000
  training_iteration: 326
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3940 s, 326 iter, 1630000 ts, 438 rew

agent-1: 79.0
agent-2: 91.0
agent-3: 87.0
agent-4: 88.0
agent-5: 84.0
Sum Reward: 429.0
Avg Reward: 85.8
Min Reward: 79.0
Gini Coefficient: 0.026107226107226107
20:20 Ratio: 1.1518987341772151
Max-min Ratio: 1.1518987341772151
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-12-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 666.0
  episode_reward_mean: 438.22
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 326
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.117
    dispatch_time_ms: 20.977
    learner:
      cur_lr: 0.001251442008651793
      grad_gnorm: 40.00000762939453
      policy_entropy: 8.332218170166016
      policy_loss: 22.47138786315918
      var_gnorm: 45.89177322387695
      vf_explained_var: 0.3355308771133423
      vf_loss: 186.22564697265625
    num_steps_sampled: 1635000
    num_steps_trained: 1635000
    wait_time_ms: 96.824
  iterations_since_restore: 327
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3951.389567375183
  time_this_iter_s: 11.27624249458313
  time_total_s: 3951.389567375183
  timestamp: 1593997972
  timesteps_since_restore: 1635000
  timesteps_this_iter: 5000
  timesteps_total: 1635000
  training_iteration: 327
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3951 s, 327 iter, 1635000 ts, 438 rew

agent-1: 79.0
agent-2: 135.0
agent-3: 72.0
agent-4: 102.0
agent-5: 97.0
Sum Reward: 485.0
Avg Reward: 97.0
Min Reward: 72.0
Gini Coefficient: 0.12288659793814433
20:20 Ratio: 1.875
Max-min Ratio: 1.875
agent-1: 89.0
agent-2: 111.0
agent-3: 94.0
agent-4: 98.0
agent-5: 131.0
Sum Reward: 523.0
Avg Reward: 104.6
Min Reward: 89.0
Gini Coefficient: 0.07724665391969407
20:20 Ratio: 1.4719101123595506
Max-min Ratio: 1.4719101123595506
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-13-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 666.0
  episode_reward_mean: 438.05
  episode_reward_min: 247.0
  episodes_this_iter: 2
  episodes_total: 328
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.641
    dispatch_time_ms: 36.825
    learner:
      cur_lr: 0.0012511089444160461
      grad_gnorm: 8.549089431762695
      policy_entropy: 35.80995559692383
      policy_loss: -1.8972992897033691
      var_gnorm: 45.996585845947266
      vf_explained_var: 0.9971286654472351
      vf_loss: 0.07784196734428406
    num_steps_sampled: 1640000
    num_steps_trained: 1640000
    wait_time_ms: 67.759
  iterations_since_restore: 328
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3965.569347858429
  time_this_iter_s: 14.17978048324585
  time_total_s: 3965.569347858429
  timestamp: 1593997986
  timesteps_since_restore: 1640000
  timesteps_this_iter: 5000
  timesteps_total: 1640000
  training_iteration: 328
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3965 s, 328 iter, 1640000 ts, 438 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-13-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 666.0
  episode_reward_mean: 438.05
  episode_reward_min: 247.0
  episodes_this_iter: 0
  episodes_total: 328
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.954
    dispatch_time_ms: 30.051
    learner:
      cur_lr: 0.0012507759965956211
      grad_gnorm: 36.20957946777344
      policy_entropy: 32.2618293762207
      policy_loss: -1.9621021747589111
      var_gnorm: 46.113521575927734
      vf_explained_var: 0.9668824672698975
      vf_loss: 1.0273245573043823
    num_steps_sampled: 1645000
    num_steps_trained: 1645000
    wait_time_ms: 97.271
  iterations_since_restore: 329
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 3976.8647623062134
  time_this_iter_s: 11.295414447784424
  time_total_s: 3976.8647623062134
  timestamp: 1593997997
  timesteps_since_restore: 1645000
  timesteps_this_iter: 5000
  timesteps_total: 1645000
  training_iteration: 329
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 3976 s, 329 iter, 1645000 ts, 438 rew

W0705 21:13:38.945156  2378 node_manager.cc:250] Last heartbeat was sent 7215 ms ago 
W0705 21:13:39.068665  2378 node_manager.cc:250] Last heartbeat was sent 508 ms ago 
agent-1: 61.0
agent-2: 84.0
agent-3: 69.0
agent-4: 65.0
agent-5: 77.0
Sum Reward: 356.0
Avg Reward: 71.2
Min Reward: 61.0
Gini Coefficient: 0.0651685393258427
20:20 Ratio: 1.3770491803278688
Max-min Ratio: 1.3770491803278688
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-13-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 666.0
  episode_reward_mean: 437.44
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 329
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.112
    dispatch_time_ms: 11.579
    learner:
      cur_lr: 0.001250443048775196
      grad_gnorm: 0.2335447520017624
      policy_entropy: 32.095516204833984
      policy_loss: 0.07119876146316528
      var_gnorm: 46.11785125732422
      vf_explained_var: 0.0
      vf_loss: 6.551638944074512e-05
    num_steps_sampled: 1650000
    num_steps_trained: 1650000
    wait_time_ms: 112.625
  iterations_since_restore: 330
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4001.669865131378
  time_this_iter_s: 24.805102825164795
  time_total_s: 4001.669865131378
  timestamp: 1593998029
  timesteps_since_restore: 1650000
  timesteps_this_iter: 5000
  timesteps_total: 1650000
  training_iteration: 330
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4001 s, 330 iter, 1650000 ts, 437 rew

agent-1: 59.0
agent-2: 81.0
agent-3: 62.0
agent-4: 55.0
agent-5: 78.0
Sum Reward: 335.0
Avg Reward: 67.0
Min Reward: 55.0
Gini Coefficient: 0.08477611940298507
20:20 Ratio: 1.4727272727272727
Max-min Ratio: 1.4727272727272727
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-14-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 666.0
  episode_reward_mean: 437.14
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 330
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.529
    dispatch_time_ms: 23.129
    learner:
      cur_lr: 0.0012501099845394492
      grad_gnorm: 40.0
      policy_entropy: 14.420166015625
      policy_loss: -10.79297924041748
      var_gnorm: 46.18666076660156
      vf_explained_var: 0.7324984073638916
      vf_loss: 109.623046875
    num_steps_sampled: 1655000
    num_steps_trained: 1655000
    wait_time_ms: 98.056
  iterations_since_restore: 331
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4013.4511063098907
  time_this_iter_s: 11.781241178512573
  time_total_s: 4013.4511063098907
  timestamp: 1593998040
  timesteps_since_restore: 1655000
  timesteps_this_iter: 5000
  timesteps_total: 1655000
  training_iteration: 331
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4013 s, 331 iter, 1655000 ts, 437 rew

agent-1: 59.0
agent-2: 52.0
agent-3: 69.0
agent-4: 61.0
agent-5: 57.0
Sum Reward: 298.0
Avg Reward: 59.6
Min Reward: 52.0
Gini Coefficient: 0.05100671140939597
20:20 Ratio: 1.3269230769230769
Max-min Ratio: 1.3269230769230769
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-14-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 666.0
  episode_reward_mean: 436.49
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 331
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.302
    dispatch_time_ms: 15.731
    learner:
      cur_lr: 0.0012497770367190242
      grad_gnorm: 40.0
      policy_entropy: 8.919378280639648
      policy_loss: 8.058554649353027
      var_gnorm: 46.173919677734375
      vf_explained_var: -0.13987195491790771
      vf_loss: 126.73847198486328
    num_steps_sampled: 1660000
    num_steps_trained: 1660000
    wait_time_ms: 96.887
  iterations_since_restore: 332
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4026.030581712723
  time_this_iter_s: 12.579475402832031
  time_total_s: 4026.030581712723
  timestamp: 1593998053
  timesteps_since_restore: 1660000
  timesteps_this_iter: 5000
  timesteps_total: 1660000
  training_iteration: 332
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4026 s, 332 iter, 1660000 ts, 436 rew

agent-1: 63.0
agent-2: 83.0
agent-3: 80.0
agent-4: 84.0
agent-5: 112.0
Sum Reward: 422.0
Avg Reward: 84.4
Min Reward: 63.0
Gini Coefficient: 0.0966824644549763
20:20 Ratio: 1.7777777777777777
Max-min Ratio: 1.7777777777777777
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-14-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 666.0
  episode_reward_mean: 436.81
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 332
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.42
    dispatch_time_ms: 7.986
    learner:
      cur_lr: 0.0012494439724832773
      grad_gnorm: 33.95000457763672
      policy_entropy: 5.936926364898682
      policy_loss: 4.023414134979248
      var_gnorm: 46.15497589111328
      vf_explained_var: 0.10781252384185791
      vf_loss: 31.187536239624023
    num_steps_sampled: 1665000
    num_steps_trained: 1665000
    wait_time_ms: 107.467
  iterations_since_restore: 333
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4037.4071180820465
  time_this_iter_s: 11.37653636932373
  time_total_s: 4037.4071180820465
  timestamp: 1593998065
  timesteps_since_restore: 1665000
  timesteps_this_iter: 5000
  timesteps_total: 1665000
  training_iteration: 333
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4037 s, 333 iter, 1665000 ts, 437 rew

agent-1: 164.0
agent-2: 153.0
agent-3: 119.0
agent-4: 120.0
agent-5: 138.0
Sum Reward: 694.0
Avg Reward: 138.8
Min Reward: 119.0
Gini Coefficient: 0.07089337175792507
20:20 Ratio: 1.3781512605042017
Max-min Ratio: 1.3781512605042017
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-14-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 694.0
  episode_reward_mean: 439.79
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 333
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.84
    dispatch_time_ms: 5.616
    learner:
      cur_lr: 0.0012491110246628523
      grad_gnorm: 8.095026016235352
      policy_entropy: 32.03020477294922
      policy_loss: 1.3896511793136597
      var_gnorm: 46.244720458984375
      vf_explained_var: 0.0
      vf_loss: 0.07837127894163132
    num_steps_sampled: 1670000
    num_steps_trained: 1670000
    wait_time_ms: 118.862
  iterations_since_restore: 334
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4049.72634267807
  time_this_iter_s: 12.31922459602356
  time_total_s: 4049.72634267807
  timestamp: 1593998077
  timesteps_since_restore: 1670000
  timesteps_this_iter: 5000
  timesteps_total: 1670000
  training_iteration: 334
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4049 s, 334 iter, 1670000 ts, 440 rew

agent-1: 69.0
agent-2: 95.0
agent-3: 66.0
agent-4: 77.0
agent-5: 80.0
Sum Reward: 387.0
Avg Reward: 77.4
Min Reward: 66.0
Gini Coefficient: 0.07131782945736434
20:20 Ratio: 1.4393939393939394
Max-min Ratio: 1.4393939393939394
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-14-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 694.0
  episode_reward_mean: 438.46
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 334
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.796
    dispatch_time_ms: 8.698
    learner:
      cur_lr: 0.0012487779604271054
      grad_gnorm: 39.999996185302734
      policy_entropy: 17.024263381958008
      policy_loss: 3.203429937362671
      var_gnorm: 46.371952056884766
      vf_explained_var: -0.34241783618927
      vf_loss: 7.331349849700928
    num_steps_sampled: 1675000
    num_steps_trained: 1675000
    wait_time_ms: 110.655
  iterations_since_restore: 335
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4060.709949731827
  time_this_iter_s: 10.983607053756714
  time_total_s: 4060.709949731827
  timestamp: 1593998088
  timesteps_since_restore: 1675000
  timesteps_this_iter: 5000
  timesteps_total: 1675000
  training_iteration: 335
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4060 s, 335 iter, 1675000 ts, 438 rew

agent-1: 93.0
agent-2: 106.0
agent-3: 104.0
agent-4: 75.0
agent-5: 87.0
Sum Reward: 465.0
Avg Reward: 93.0
Min Reward: 75.0
Gini Coefficient: 0.06795698924731183
20:20 Ratio: 1.4133333333333333
Max-min Ratio: 1.4133333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-15-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 694.0
  episode_reward_mean: 438.34
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 335
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.047
    dispatch_time_ms: 8.631
    learner:
      cur_lr: 0.0012484450126066804
      grad_gnorm: 4.81064510345459
      policy_entropy: 36.469261169433594
      policy_loss: 1.1653048992156982
      var_gnorm: 46.41233825683594
      vf_explained_var: 0.0
      vf_loss: 0.026218565180897713
    num_steps_sampled: 1680000
    num_steps_trained: 1680000
    wait_time_ms: 112.847
  iterations_since_restore: 336
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4073.1632153987885
  time_this_iter_s: 12.45326566696167
  time_total_s: 4073.1632153987885
  timestamp: 1593998100
  timesteps_since_restore: 1680000
  timesteps_this_iter: 5000
  timesteps_total: 1680000
  training_iteration: 336
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4073 s, 336 iter, 1680000 ts, 438 rew

agent-1: 82.0
agent-2: 62.0
agent-3: 86.0
agent-4: 54.0
agent-5: 74.0
Sum Reward: 358.0
Avg Reward: 71.6
Min Reward: 54.0
Gini Coefficient: 0.09385474860335195
20:20 Ratio: 1.5925925925925926
Max-min Ratio: 1.5925925925925926
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-15-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 694.0
  episode_reward_mean: 438.18
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 336
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.587
    dispatch_time_ms: 9.134
    learner:
      cur_lr: 0.0012481119483709335
      grad_gnorm: 19.839519500732422
      policy_entropy: 23.316879272460938
      policy_loss: -1.6318250894546509
      var_gnorm: 46.538536071777344
      vf_explained_var: 0.9886152148246765
      vf_loss: 0.5096887350082397
    num_steps_sampled: 1685000
    num_steps_trained: 1685000
    wait_time_ms: 106.942
  iterations_since_restore: 337
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4084.2066135406494
  time_this_iter_s: 11.043398141860962
  time_total_s: 4084.2066135406494
  timestamp: 1593998111
  timesteps_since_restore: 1685000
  timesteps_this_iter: 5000
  timesteps_total: 1685000
  training_iteration: 337
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4084 s, 337 iter, 1685000 ts, 438 rew

agent-1: 74.0
agent-2: 86.0
agent-3: 112.0
agent-4: 108.0
agent-5: 93.0
Sum Reward: 473.0
Avg Reward: 94.6
Min Reward: 74.0
Gini Coefficient: 0.0828752642706131
20:20 Ratio: 1.5135135135135136
Max-min Ratio: 1.5135135135135136
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-15-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 694.0
  episode_reward_mean: 439.1
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 337
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.95
    dispatch_time_ms: 9.966
    learner:
      cur_lr: 0.0012477790005505085
      grad_gnorm: 36.71358871459961
      policy_entropy: 29.99240493774414
      policy_loss: 1.9985233545303345
      var_gnorm: 46.71367645263672
      vf_explained_var: 0.70491623878479
      vf_loss: 11.505610466003418
    num_steps_sampled: 1690000
    num_steps_trained: 1690000
    wait_time_ms: 107.215
  iterations_since_restore: 338
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4096.20276260376
  time_this_iter_s: 11.996149063110352
  time_total_s: 4096.20276260376
  timestamp: 1593998123
  timesteps_since_restore: 1690000
  timesteps_this_iter: 5000
  timesteps_total: 1690000
  training_iteration: 338
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4096 s, 338 iter, 1690000 ts, 439 rew

agent-1: 150.0
agent-2: 137.0
agent-3: 105.0
agent-4: 94.0
agent-5: 122.0
Sum Reward: 608.0
Avg Reward: 121.6
Min Reward: 94.0
Gini Coefficient: 0.09473684210526316
20:20 Ratio: 1.5957446808510638
Max-min Ratio: 1.5957446808510638
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-15-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 694.0
  episode_reward_mean: 441.65
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 338
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.879
    dispatch_time_ms: 9.157
    learner:
      cur_lr: 0.0012474460527300835
      grad_gnorm: 40.0
      policy_entropy: 20.258886337280273
      policy_loss: 2.9352283477783203
      var_gnorm: 46.81650161743164
      vf_explained_var: 0.759330153465271
      vf_loss: 32.23765182495117
    num_steps_sampled: 1695000
    num_steps_trained: 1695000
    wait_time_ms: 109.771
  iterations_since_restore: 339
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4107.163179159164
  time_this_iter_s: 10.960416555404663
  time_total_s: 4107.163179159164
  timestamp: 1593998135
  timesteps_since_restore: 1695000
  timesteps_this_iter: 5000
  timesteps_total: 1695000
  training_iteration: 339
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4107 s, 339 iter, 1695000 ts, 442 rew

agent-1: 110.0
agent-2: 145.0
agent-3: 71.0
agent-4: 139.0
agent-5: 106.0
Sum Reward: 571.0
Avg Reward: 114.2
Min Reward: 71.0
Gini Coefficient: 0.12679509632224167
20:20 Ratio: 2.0422535211267605
Max-min Ratio: 2.0422535211267605
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-15-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 694.0
  episode_reward_mean: 442.69
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 339
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.231
    dispatch_time_ms: 8.291
    learner:
      cur_lr: 0.0012471129884943366
      grad_gnorm: 39.999996185302734
      policy_entropy: 18.482006072998047
      policy_loss: 8.08658504486084
      var_gnorm: 46.857940673828125
      vf_explained_var: -0.731086015701294
      vf_loss: 158.94869995117188
    num_steps_sampled: 1700000
    num_steps_trained: 1700000
    wait_time_ms: 96.026
  iterations_since_restore: 340
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4119.4484395980835
  time_this_iter_s: 12.285260438919067
  time_total_s: 4119.4484395980835
  timestamp: 1593998147
  timesteps_since_restore: 1700000
  timesteps_this_iter: 5000
  timesteps_total: 1700000
  training_iteration: 340
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4119 s, 340 iter, 1700000 ts, 443 rew

agent-1: 108.0
agent-2: 103.0
agent-3: 112.0
agent-4: 129.0
agent-5: 108.0
Sum Reward: 560.0
Avg Reward: 112.0
Min Reward: 103.0
Gini Coefficient: 0.04
20:20 Ratio: 1.2524271844660195
Max-min Ratio: 1.2524271844660195
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-15-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 694.0
  episode_reward_mean: 444.76
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 340
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.276
    dispatch_time_ms: 8.477
    learner:
      cur_lr: 0.0012467800406739116
      grad_gnorm: 13.063312530517578
      policy_entropy: 19.882307052612305
      policy_loss: 5.265091896057129
      var_gnorm: 46.8980712890625
      vf_explained_var: 0.5861446857452393
      vf_loss: 19.14048194885254
    num_steps_sampled: 1705000
    num_steps_trained: 1705000
    wait_time_ms: 105.323
  iterations_since_restore: 341
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4130.30612206459
  time_this_iter_s: 10.857682466506958
  time_total_s: 4130.30612206459
  timestamp: 1593998158
  timesteps_since_restore: 1705000
  timesteps_this_iter: 5000
  timesteps_total: 1705000
  training_iteration: 341
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4130 s, 341 iter, 1705000 ts, 445 rew

agent-1: 101.0
agent-2: 106.0
agent-3: 113.0
agent-4: 84.0
agent-5: 124.0
Sum Reward: 528.0
Avg Reward: 105.6
Min Reward: 84.0
Gini Coefficient: 0.0696969696969697
20:20 Ratio: 1.4761904761904763
Max-min Ratio: 1.4761904761904763
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-16-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 694.0
  episode_reward_mean: 444.67
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 341
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.029
    dispatch_time_ms: 9.566
    learner:
      cur_lr: 0.0012464469764381647
      grad_gnorm: 40.0
      policy_entropy: 8.760491371154785
      policy_loss: 0.040305063128471375
      var_gnorm: 46.93204879760742
      vf_explained_var: 0.4113868474960327
      vf_loss: 47.019264221191406
    num_steps_sampled: 1710000
    num_steps_trained: 1710000
    wait_time_ms: 104.739
  iterations_since_restore: 342
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4142.485728263855
  time_this_iter_s: 12.179606199264526
  time_total_s: 4142.485728263855
  timestamp: 1593998170
  timesteps_since_restore: 1710000
  timesteps_this_iter: 5000
  timesteps_total: 1710000
  training_iteration: 342
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4142 s, 342 iter, 1710000 ts, 445 rew

agent-1: 119.0
agent-2: 145.0
agent-3: 126.0
agent-4: 109.0
agent-5: 137.0
Sum Reward: 636.0
Avg Reward: 127.2
Min Reward: 109.0
Gini Coefficient: 0.05660377358490566
20:20 Ratio: 1.3302752293577982
Max-min Ratio: 1.3302752293577982
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-16-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 694.0
  episode_reward_mean: 446.71
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 342
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.428
    dispatch_time_ms: 7.856
    learner:
      cur_lr: 0.0012461140286177397
      grad_gnorm: 40.0
      policy_entropy: 4.073673248291016
      policy_loss: 1.074486494064331
      var_gnorm: 46.88749694824219
      vf_explained_var: 0.23740321397781372
      vf_loss: 65.36380767822266
    num_steps_sampled: 1715000
    num_steps_trained: 1715000
    wait_time_ms: 111.807
  iterations_since_restore: 343
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4153.9012978076935
  time_this_iter_s: 11.415569543838501
  time_total_s: 4153.9012978076935
  timestamp: 1593998181
  timesteps_since_restore: 1715000
  timesteps_this_iter: 5000
  timesteps_total: 1715000
  training_iteration: 343
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4153 s, 343 iter, 1715000 ts, 447 rew

agent-1: 118.0
agent-2: 97.0
agent-3: 86.0
agent-4: 119.0
agent-5: 102.0
Sum Reward: 522.0
Avg Reward: 104.4
Min Reward: 86.0
Gini Coefficient: 0.06666666666666667
20:20 Ratio: 1.3837209302325582
Max-min Ratio: 1.3837209302325582
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-16-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 694.0
  episode_reward_mean: 447.1
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 343
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.329
    dispatch_time_ms: 6.869
    learner:
      cur_lr: 0.0012457809643819928
      grad_gnorm: 13.18377685546875
      policy_entropy: 23.55656623840332
      policy_loss: 1.5103654861450195
      var_gnorm: 46.933265686035156
      vf_explained_var: 0.9217379093170166
      vf_loss: 2.2294111251831055
    num_steps_sampled: 1720000
    num_steps_trained: 1720000
    wait_time_ms: 109.003
  iterations_since_restore: 344
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4166.199036836624
  time_this_iter_s: 12.297739028930664
  time_total_s: 4166.199036836624
  timestamp: 1593998194
  timesteps_since_restore: 1720000
  timesteps_this_iter: 5000
  timesteps_total: 1720000
  training_iteration: 344
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4166 s, 344 iter, 1720000 ts, 447 rew

agent-1: 122.0
agent-2: 103.0
agent-3: 88.0
agent-4: 112.0
agent-5: 105.0
Sum Reward: 530.0
Avg Reward: 106.0
Min Reward: 88.0
Gini Coefficient: 0.05811320754716981
20:20 Ratio: 1.3863636363636365
Max-min Ratio: 1.3863636363636365
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-16-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 694.0
  episode_reward_mean: 446.46
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 344
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.188
    dispatch_time_ms: 8.579
    learner:
      cur_lr: 0.0012454480165615678
      grad_gnorm: 32.38968276977539
      policy_entropy: 7.130096912384033
      policy_loss: 5.711084365844727
      var_gnorm: 46.97369384765625
      vf_explained_var: 0.7002310752868652
      vf_loss: 70.2974624633789
    num_steps_sampled: 1725000
    num_steps_trained: 1725000
    wait_time_ms: 103.474
  iterations_since_restore: 345
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4177.071337461472
  time_this_iter_s: 10.872300624847412
  time_total_s: 4177.071337461472
  timestamp: 1593998205
  timesteps_since_restore: 1725000
  timesteps_this_iter: 5000
  timesteps_total: 1725000
  training_iteration: 345
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4177 s, 345 iter, 1725000 ts, 446 rew

agent-1: 105.0
agent-2: 138.0
agent-3: 113.0
agent-4: 139.0
agent-5: 125.0
Sum Reward: 620.0
Avg Reward: 124.0
Min Reward: 105.0
Gini Coefficient: 0.06
20:20 Ratio: 1.3238095238095238
Max-min Ratio: 1.3238095238095238
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-16-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 694.0
  episode_reward_mean: 447.79
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 345
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.184
    dispatch_time_ms: 7.402
    learner:
      cur_lr: 0.001245114952325821
      grad_gnorm: 17.069589614868164
      policy_entropy: 25.605304718017578
      policy_loss: -3.240793466567993
      var_gnorm: 47.03633117675781
      vf_explained_var: 0.9915520548820496
      vf_loss: 0.4163115918636322
    num_steps_sampled: 1730000
    num_steps_trained: 1730000
    wait_time_ms: 109.351
  iterations_since_restore: 346
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4189.340453624725
  time_this_iter_s: 12.269116163253784
  time_total_s: 4189.340453624725
  timestamp: 1593998217
  timesteps_since_restore: 1730000
  timesteps_this_iter: 5000
  timesteps_total: 1730000
  training_iteration: 346
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4189 s, 346 iter, 1730000 ts, 448 rew

agent-1: 120.0
agent-2: 114.0
agent-3: 126.0
agent-4: 112.0
agent-5: 105.0
Sum Reward: 577.0
Avg Reward: 115.4
Min Reward: 105.0
Gini Coefficient: 0.03466204506065858
20:20 Ratio: 1.2
Max-min Ratio: 1.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-17-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 694.0
  episode_reward_mean: 448.97
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 346
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.937
    dispatch_time_ms: 10.04
    learner:
      cur_lr: 0.0012447820045053959
      grad_gnorm: 40.0
      policy_entropy: 16.50875473022461
      policy_loss: 35.74104309082031
      var_gnorm: 46.964088439941406
      vf_explained_var: 0.07992798089981079
      vf_loss: 52.04685592651367
    num_steps_sampled: 1735000
    num_steps_trained: 1735000
    wait_time_ms: 108.88
  iterations_since_restore: 347
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4200.295725107193
  time_this_iter_s: 10.955271482467651
  time_total_s: 4200.295725107193
  timestamp: 1593998228
  timesteps_since_restore: 1735000
  timesteps_this_iter: 5000
  timesteps_total: 1735000
  training_iteration: 347
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4200 s, 347 iter, 1735000 ts, 449 rew

agent-1: 111.0
agent-2: 99.0
agent-3: 97.0
agent-4: 99.0
agent-5: 78.0
Sum Reward: 484.0
Avg Reward: 96.8
Min Reward: 78.0
Gini Coefficient: 0.05619834710743802
20:20 Ratio: 1.4230769230769231
Max-min Ratio: 1.4230769230769231
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-17-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 694.0
  episode_reward_mean: 450.05
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 347
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.56
    dispatch_time_ms: 6.778
    learner:
      cur_lr: 0.0012444490566849709
      grad_gnorm: 5.718707084655762
      policy_entropy: 16.117332458496094
      policy_loss: -0.7963441014289856
      var_gnorm: 47.05185317993164
      vf_explained_var: 0.9938319325447083
      vf_loss: 0.09117735177278519
    num_steps_sampled: 1740000
    num_steps_trained: 1740000
    wait_time_ms: 105.282
  iterations_since_restore: 348
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4212.378139734268
  time_this_iter_s: 12.082414627075195
  time_total_s: 4212.378139734268
  timestamp: 1593998240
  timesteps_since_restore: 1740000
  timesteps_this_iter: 5000
  timesteps_total: 1740000
  training_iteration: 348
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4212 s, 348 iter, 1740000 ts, 450 rew

agent-1: 90.0
agent-2: 85.0
agent-3: 75.0
agent-4: 89.0
agent-5: 105.0
Sum Reward: 444.0
Avg Reward: 88.8
Min Reward: 75.0
Gini Coefficient: 0.05855855855855856
20:20 Ratio: 1.4
Max-min Ratio: 1.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-17-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 694.0
  episode_reward_mean: 450.81
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 348
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.707
    dispatch_time_ms: 8.824
    learner:
      cur_lr: 0.001244115992449224
      grad_gnorm: 30.8344783782959
      policy_entropy: 9.704553604125977
      policy_loss: 0.0345427468419075
      var_gnorm: 47.17608642578125
      vf_explained_var: 0.7830102443695068
      vf_loss: 78.32408142089844
    num_steps_sampled: 1745000
    num_steps_trained: 1745000
    wait_time_ms: 102.665
  iterations_since_restore: 349
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4223.368021726608
  time_this_iter_s: 10.989881992340088
  time_total_s: 4223.368021726608
  timestamp: 1593998251
  timesteps_since_restore: 1745000
  timesteps_this_iter: 5000
  timesteps_total: 1745000
  training_iteration: 349
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4223 s, 349 iter, 1745000 ts, 451 rew

agent-1: 63.0
agent-2: 85.0
agent-3: 58.0
agent-4: 93.0
agent-5: 149.0
Sum Reward: 448.0
Avg Reward: 89.6
Min Reward: 58.0
Gini Coefficient: 0.18928571428571428
20:20 Ratio: 2.5689655172413794
Max-min Ratio: 2.5689655172413794
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-17-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 694.0
  episode_reward_mean: 450.88
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 349
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.916
    dispatch_time_ms: 6.982
    learner:
      cur_lr: 0.001243783044628799
      grad_gnorm: 40.0
      policy_entropy: 12.804347038269043
      policy_loss: -3.916412830352783
      var_gnorm: 47.2923469543457
      vf_explained_var: -0.05152308940887451
      vf_loss: 14.59429931640625
    num_steps_sampled: 1750000
    num_steps_trained: 1750000
    wait_time_ms: 94.019
  iterations_since_restore: 350
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4234.995768070221
  time_this_iter_s: 11.627746343612671
  time_total_s: 4234.995768070221
  timestamp: 1593998263
  timesteps_since_restore: 1750000
  timesteps_this_iter: 5000
  timesteps_total: 1750000
  training_iteration: 350
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4234 s, 350 iter, 1750000 ts, 451 rew

agent-1: 132.0
agent-2: 137.0
agent-3: 123.0
agent-4: 118.0
agent-5: 94.0
Sum Reward: 604.0
Avg Reward: 120.8
Min Reward: 94.0
Gini Coefficient: 0.06622516556291391
20:20 Ratio: 1.4574468085106382
Max-min Ratio: 1.4574468085106382
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-17-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 694.0
  episode_reward_mean: 452.34
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 350
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.753
    dispatch_time_ms: 6.352
    learner:
      cur_lr: 0.001243449980393052
      grad_gnorm: 40.0
      policy_entropy: 17.93924903869629
      policy_loss: 6.58853816986084
      var_gnorm: 47.43914794921875
      vf_explained_var: 0.6793355941772461
      vf_loss: 31.965856552124023
    num_steps_sampled: 1755000
    num_steps_trained: 1755000
    wait_time_ms: 114.349
  iterations_since_restore: 351
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4246.034029722214
  time_this_iter_s: 11.038261651992798
  time_total_s: 4246.034029722214
  timestamp: 1593998274
  timesteps_since_restore: 1755000
  timesteps_this_iter: 5000
  timesteps_total: 1755000
  training_iteration: 351
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4246 s, 351 iter, 1755000 ts, 452 rew

agent-1: 109.0
agent-2: 101.0
agent-3: 106.0
agent-4: 80.0
agent-5: 96.0
Sum Reward: 492.0
Avg Reward: 98.4
Min Reward: 80.0
Gini Coefficient: 0.055284552845528454
20:20 Ratio: 1.3625
Max-min Ratio: 1.3625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-18-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 694.0
  episode_reward_mean: 452.58
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 351
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.97
    dispatch_time_ms: 6.925
    learner:
      cur_lr: 0.001243117032572627
      grad_gnorm: 16.61253547668457
      policy_entropy: 38.911659240722656
      policy_loss: -1.2251240015029907
      var_gnorm: 47.48229217529297
      vf_explained_var: 0.01692807674407959
      vf_loss: 3.177685260772705
    num_steps_sampled: 1760000
    num_steps_trained: 1760000
    wait_time_ms: 97.599
  iterations_since_restore: 352
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4257.872792005539
  time_this_iter_s: 11.838762283325195
  time_total_s: 4257.872792005539
  timestamp: 1593998286
  timesteps_since_restore: 1760000
  timesteps_this_iter: 5000
  timesteps_total: 1760000
  training_iteration: 352
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4257 s, 352 iter, 1760000 ts, 453 rew

agent-1: 80.0
agent-2: 118.0
agent-3: 87.0
agent-4: 98.0
agent-5: 102.0
Sum Reward: 485.0
Avg Reward: 97.0
Min Reward: 80.0
Gini Coefficient: 0.07505154639175257
20:20 Ratio: 1.475
Max-min Ratio: 1.475
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-18-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 694.0
  episode_reward_mean: 453.02
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 352
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.668
    dispatch_time_ms: 9.246
    learner:
      cur_lr: 0.0012427839683368802
      grad_gnorm: 40.0
      policy_entropy: 23.923362731933594
      policy_loss: 11.441756248474121
      var_gnorm: 47.571041107177734
      vf_explained_var: 0.5420106649398804
      vf_loss: 24.26808738708496
    num_steps_sampled: 1765000
    num_steps_trained: 1765000
    wait_time_ms: 101.889
  iterations_since_restore: 353
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4268.674172878265
  time_this_iter_s: 10.80138087272644
  time_total_s: 4268.674172878265
  timestamp: 1593998297
  timesteps_since_restore: 1765000
  timesteps_this_iter: 5000
  timesteps_total: 1765000
  training_iteration: 353
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4268 s, 353 iter, 1765000 ts, 453 rew

agent-1: 110.0
agent-2: 156.0
agent-3: 128.0
agent-4: 133.0
agent-5: 129.0
Sum Reward: 656.0
Avg Reward: 131.2
Min Reward: 110.0
Gini Coefficient: 0.05914634146341463
20:20 Ratio: 1.4181818181818182
Max-min Ratio: 1.4181818181818182
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-18-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 694.0
  episode_reward_mean: 454.07
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 353
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.264
    dispatch_time_ms: 8.982
    learner:
      cur_lr: 0.0012424510205164552
      grad_gnorm: 40.000003814697266
      policy_entropy: 5.656686782836914
      policy_loss: -1.3806557655334473
      var_gnorm: 47.54495620727539
      vf_explained_var: -0.6633272171020508
      vf_loss: 47.98967742919922
    num_steps_sampled: 1770000
    num_steps_trained: 1770000
    wait_time_ms: 94.155
  iterations_since_restore: 354
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4280.391505718231
  time_this_iter_s: 11.71733283996582
  time_total_s: 4280.391505718231
  timestamp: 1593998308
  timesteps_since_restore: 1770000
  timesteps_this_iter: 5000
  timesteps_total: 1770000
  training_iteration: 354
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4280 s, 354 iter, 1770000 ts, 454 rew

agent-1: 110.0
agent-2: 158.0
agent-3: 146.0
agent-4: 114.0
agent-5: 100.0
Sum Reward: 628.0
Avg Reward: 125.6
Min Reward: 100.0
Gini Coefficient: 0.09681528662420383
20:20 Ratio: 1.58
Max-min Ratio: 1.58
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-18-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 694.0
  episode_reward_mean: 456.96
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 354
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.312
    dispatch_time_ms: 7.639
    learner:
      cur_lr: 0.0012421179562807083
      grad_gnorm: 39.999996185302734
      policy_entropy: 23.531482696533203
      policy_loss: -4.377896785736084
      var_gnorm: 47.59367752075195
      vf_explained_var: -1.0
      vf_loss: 12.243182182312012
    num_steps_sampled: 1775000
    num_steps_trained: 1775000
    wait_time_ms: 104.69
  iterations_since_restore: 355
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4291.87396812439
  time_this_iter_s: 11.482462406158447
  time_total_s: 4291.87396812439
  timestamp: 1593998320
  timesteps_since_restore: 1775000
  timesteps_this_iter: 5000
  timesteps_total: 1775000
  training_iteration: 355
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4291 s, 355 iter, 1775000 ts, 457 rew

agent-1: 118.0
agent-2: 90.0
agent-3: 61.0
agent-4: 122.0
agent-5: 119.0
Sum Reward: 510.0
Avg Reward: 102.0
Min Reward: 61.0
Gini Coefficient: 0.11843137254901961
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-18-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 694.0
  episode_reward_mean: 458.04
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 355
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.753
    dispatch_time_ms: 6.301
    learner:
      cur_lr: 0.0012417850084602833
      grad_gnorm: 39.999996185302734
      policy_entropy: 31.70703887939453
      policy_loss: -6.450655937194824
      var_gnorm: 47.64670944213867
      vf_explained_var: -0.4655802249908447
      vf_loss: 5.458268642425537
    num_steps_sampled: 1780000
    num_steps_trained: 1780000
    wait_time_ms: 106.897
  iterations_since_restore: 356
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4303.6435832977295
  time_this_iter_s: 11.769615173339844
  time_total_s: 4303.6435832977295
  timestamp: 1593998332
  timesteps_since_restore: 1780000
  timesteps_this_iter: 5000
  timesteps_total: 1780000
  training_iteration: 356
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4303 s, 356 iter, 1780000 ts, 458 rew

agent-1: 100.0
agent-2: 114.0
agent-3: 74.0
agent-4: 75.0
agent-5: 101.0
Sum Reward: 464.0
Avg Reward: 92.8
Min Reward: 74.0
Gini Coefficient: 0.09137931034482759
20:20 Ratio: 1.5405405405405406
Max-min Ratio: 1.5405405405405406
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-19-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 694.0
  episode_reward_mean: 457.85
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 356
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.955
    dispatch_time_ms: 6.044
    learner:
      cur_lr: 0.0012414519442245364
      grad_gnorm: 40.0
      policy_entropy: 16.92264175415039
      policy_loss: 14.11358642578125
      var_gnorm: 47.6862907409668
      vf_explained_var: 0.7009854912757874
      vf_loss: 60.260684967041016
    num_steps_sampled: 1785000
    num_steps_trained: 1785000
    wait_time_ms: 95.691
  iterations_since_restore: 357
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4314.471244812012
  time_this_iter_s: 10.827661514282227
  time_total_s: 4314.471244812012
  timestamp: 1593998343
  timesteps_since_restore: 1785000
  timesteps_this_iter: 5000
  timesteps_total: 1785000
  training_iteration: 357
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4314 s, 357 iter, 1785000 ts, 458 rew

agent-1: 113.0
agent-2: 130.0
agent-3: 96.0
agent-4: 170.0
agent-5: 166.0
Sum Reward: 675.0
Avg Reward: 135.0
Min Reward: 96.0
Gini Coefficient: 0.11911111111111111
20:20 Ratio: 1.7708333333333333
Max-min Ratio: 1.7708333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-19-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 694.0
  episode_reward_mean: 460.67
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 357
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.982
    dispatch_time_ms: 6.845
    learner:
      cur_lr: 0.0012411189964041114
      grad_gnorm: 40.00000762939453
      policy_entropy: 9.167649269104004
      policy_loss: 21.163137435913086
      var_gnorm: 47.67059326171875
      vf_explained_var: 0.4143539071083069
      vf_loss: 107.90473175048828
    num_steps_sampled: 1790000
    num_steps_trained: 1790000
    wait_time_ms: 92.784
  iterations_since_restore: 358
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4325.788572311401
  time_this_iter_s: 11.317327499389648
  time_total_s: 4325.788572311401
  timestamp: 1593998354
  timesteps_since_restore: 1790000
  timesteps_this_iter: 5000
  timesteps_total: 1790000
  training_iteration: 358
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4325 s, 358 iter, 1790000 ts, 461 rew

agent-1: 118.0
agent-2: 166.0
agent-3: 114.0
agent-4: 175.0
agent-5: 124.0
Sum Reward: 697.0
Avg Reward: 139.4
Min Reward: 114.0
Gini Coefficient: 0.0975609756097561
20:20 Ratio: 1.5350877192982457
Max-min Ratio: 1.5350877192982457
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-19-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 697.0
  episode_reward_mean: 462.75
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 358
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.531
    dispatch_time_ms: 6.759
    learner:
      cur_lr: 0.0012407860485836864
      grad_gnorm: 40.0
      policy_entropy: 14.25448989868164
      policy_loss: 18.51100730895996
      var_gnorm: 47.64875030517578
      vf_explained_var: 0.33968043327331543
      vf_loss: 142.57635498046875
    num_steps_sampled: 1795000
    num_steps_trained: 1795000
    wait_time_ms: 107.775
  iterations_since_restore: 359
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4336.978472471237
  time_this_iter_s: 11.189900159835815
  time_total_s: 4336.978472471237
  timestamp: 1593998365
  timesteps_since_restore: 1795000
  timesteps_this_iter: 5000
  timesteps_total: 1795000
  training_iteration: 359
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4336 s, 359 iter, 1795000 ts, 463 rew

agent-1: 69.0
agent-2: 102.0
agent-3: 129.0
agent-4: 74.0
agent-5: 103.0
Sum Reward: 477.0
Avg Reward: 95.4
Min Reward: 69.0
Gini Coefficient: 0.1249475890985325
20:20 Ratio: 1.8695652173913044
Max-min Ratio: 1.8695652173913044
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-19-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 697.0
  episode_reward_mean: 464.29
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 359
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.478
    dispatch_time_ms: 7.944
    learner:
      cur_lr: 0.0012404529843479395
      grad_gnorm: 40.0
      policy_entropy: 29.315418243408203
      policy_loss: -3.630227565765381
      var_gnorm: 47.687538146972656
      vf_explained_var: 0.9716097116470337
      vf_loss: 1.5522462129592896
    num_steps_sampled: 1800000
    num_steps_trained: 1800000
    wait_time_ms: 87.635
  iterations_since_restore: 360
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4348.868467330933
  time_this_iter_s: 11.889994859695435
  time_total_s: 4348.868467330933
  timestamp: 1593998377
  timesteps_since_restore: 1800000
  timesteps_this_iter: 5000
  timesteps_total: 1800000
  training_iteration: 360
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4348 s, 360 iter, 1800000 ts, 464 rew

agent-1: 99.0
agent-2: 111.0
agent-3: 129.0
agent-4: 95.0
agent-5: 161.0
Sum Reward: 595.0
Avg Reward: 119.0
Min Reward: 95.0
Gini Coefficient: 0.10890756302521008
20:20 Ratio: 1.694736842105263
Max-min Ratio: 1.694736842105263
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-19-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 697.0
  episode_reward_mean: 465.86
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 360
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.609
    dispatch_time_ms: 8.399
    learner:
      cur_lr: 0.0012401200365275145
      grad_gnorm: 29.020837783813477
      policy_entropy: 28.619918823242188
      policy_loss: -2.4545319080352783
      var_gnorm: 47.73127365112305
      vf_explained_var: 0.8994837403297424
      vf_loss: 6.920486927032471
    num_steps_sampled: 1805000
    num_steps_trained: 1805000
    wait_time_ms: 106.453
  iterations_since_restore: 361
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4359.761518716812
  time_this_iter_s: 10.893051385879517
  time_total_s: 4359.761518716812
  timestamp: 1593998388
  timesteps_since_restore: 1805000
  timesteps_this_iter: 5000
  timesteps_total: 1805000
  training_iteration: 361
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4359 s, 361 iter, 1805000 ts, 466 rew

agent-1: 96.0
agent-2: 135.0
agent-3: 104.0
agent-4: 74.0
agent-5: 139.0
Sum Reward: 548.0
Avg Reward: 109.6
Min Reward: 74.0
Gini Coefficient: 0.12335766423357664
20:20 Ratio: 1.8783783783783783
Max-min Ratio: 1.8783783783783783
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-20-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 697.0
  episode_reward_mean: 467.68
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 361
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.74
    dispatch_time_ms: 6.354
    learner:
      cur_lr: 0.0012397869722917676
      grad_gnorm: 29.82456398010254
      policy_entropy: 30.547975540161133
      policy_loss: 2.1865007877349854
      var_gnorm: 47.76495361328125
      vf_explained_var: 0.535030722618103
      vf_loss: 17.194488525390625
    num_steps_sampled: 1810000
    num_steps_trained: 1810000
    wait_time_ms: 104.318
  iterations_since_restore: 362
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4371.82077050209
  time_this_iter_s: 12.05925178527832
  time_total_s: 4371.82077050209
  timestamp: 1593998400
  timesteps_since_restore: 1810000
  timesteps_this_iter: 5000
  timesteps_total: 1810000
  training_iteration: 362
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4371 s, 362 iter, 1810000 ts, 468 rew

agent-1: 88.0
agent-2: 138.0
agent-3: 107.0
agent-4: 113.0
agent-5: 117.0
Sum Reward: 563.0
Avg Reward: 112.6
Min Reward: 88.0
Gini Coefficient: 0.07815275310834814
20:20 Ratio: 1.5681818181818181
Max-min Ratio: 1.5681818181818181
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-20-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 697.0
  episode_reward_mean: 468.39
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 362
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.969
    dispatch_time_ms: 8.439
    learner:
      cur_lr: 0.0012394540244713426
      grad_gnorm: 36.76553726196289
      policy_entropy: 23.193681716918945
      policy_loss: 9.871167182922363
      var_gnorm: 47.76717758178711
      vf_explained_var: 0.17864298820495605
      vf_loss: 33.69386672973633
    num_steps_sampled: 1815000
    num_steps_trained: 1815000
    wait_time_ms: 103.85
  iterations_since_restore: 363
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4382.807592391968
  time_this_iter_s: 10.98682188987732
  time_total_s: 4382.807592391968
  timestamp: 1593998411
  timesteps_since_restore: 1815000
  timesteps_this_iter: 5000
  timesteps_total: 1815000
  training_iteration: 363
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4382 s, 363 iter, 1815000 ts, 468 rew

agent-1: 120.0
agent-2: 123.0
agent-3: 124.0
agent-4: 100.0
agent-5: 113.0
Sum Reward: 580.0
Avg Reward: 116.0
Min Reward: 100.0
Gini Coefficient: 0.04
20:20 Ratio: 1.24
Max-min Ratio: 1.24
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-20-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 697.0
  episode_reward_mean: 470.22
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 363
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.369
    dispatch_time_ms: 5.753
    learner:
      cur_lr: 0.0012391209602355957
      grad_gnorm: 11.905059814453125
      policy_entropy: 34.54518127441406
      policy_loss: -2.5369298458099365
      var_gnorm: 47.84125900268555
      vf_explained_var: 0.9935429096221924
      vf_loss: 0.231479212641716
    num_steps_sampled: 1820000
    num_steps_trained: 1820000
    wait_time_ms: 109.699
  iterations_since_restore: 364
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4395.217321634293
  time_this_iter_s: 12.409729242324829
  time_total_s: 4395.217321634293
  timestamp: 1593998424
  timesteps_since_restore: 1820000
  timesteps_this_iter: 5000
  timesteps_total: 1820000
  training_iteration: 364
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4395 s, 364 iter, 1820000 ts, 470 rew

agent-1: 34.0
agent-2: 82.0
agent-3: 76.0
agent-4: 99.0
agent-5: 75.0
Sum Reward: 366.0
Avg Reward: 73.2
Min Reward: 34.0
Gini Coefficient: 0.14972677595628414
20:20 Ratio: 2.911764705882353
Max-min Ratio: 2.911764705882353
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-20-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 697.0
  episode_reward_mean: 469.34
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 364
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.456
    dispatch_time_ms: 6.094
    learner:
      cur_lr: 0.0012387880124151707
      grad_gnorm: 40.000003814697266
      policy_entropy: 19.87755012512207
      policy_loss: 0.6534886956214905
      var_gnorm: 47.905921936035156
      vf_explained_var: 0.6231199502944946
      vf_loss: 51.67975997924805
    num_steps_sampled: 1825000
    num_steps_trained: 1825000
    wait_time_ms: 113.732
  iterations_since_restore: 365
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4406.6110010147095
  time_this_iter_s: 11.39367938041687
  time_total_s: 4406.6110010147095
  timestamp: 1593998435
  timesteps_since_restore: 1825000
  timesteps_this_iter: 5000
  timesteps_total: 1825000
  training_iteration: 365
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4406 s, 365 iter, 1825000 ts, 469 rew

agent-1: 72.0
agent-2: 90.0
agent-3: 94.0
agent-4: 81.0
agent-5: 84.0
Sum Reward: 421.0
Avg Reward: 84.2
Min Reward: 72.0
Gini Coefficient: 0.0503562945368171
20:20 Ratio: 1.3055555555555556
Max-min Ratio: 1.3055555555555556
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-20-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 697.0
  episode_reward_mean: 469.26
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 365
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.804
    dispatch_time_ms: 8.81
    learner:
      cur_lr: 0.0012384549481794238
      grad_gnorm: 6.662259578704834
      policy_entropy: 28.9296817779541
      policy_loss: -0.8272863626480103
      var_gnorm: 47.927734375
      vf_explained_var: 0.0
      vf_loss: 0.04940011352300644
    num_steps_sampled: 1830000
    num_steps_trained: 1830000
    wait_time_ms: 106.924
  iterations_since_restore: 366
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4418.702029943466
  time_this_iter_s: 12.091028928756714
  time_total_s: 4418.702029943466
  timestamp: 1593998447
  timesteps_since_restore: 1830000
  timesteps_this_iter: 5000
  timesteps_total: 1830000
  training_iteration: 366
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4418 s, 366 iter, 1830000 ts, 469 rew

agent-1: 59.0
agent-2: 79.0
agent-3: 87.0
agent-4: 83.0
agent-5: 90.0
Sum Reward: 398.0
Avg Reward: 79.6
Min Reward: 59.0
Gini Coefficient: 0.07035175879396985
20:20 Ratio: 1.5254237288135593
Max-min Ratio: 1.5254237288135593
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-20-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 697.0
  episode_reward_mean: 468.94
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 366
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.119
    dispatch_time_ms: 6.865
    learner:
      cur_lr: 0.0012381220003589988
      grad_gnorm: 40.00000762939453
      policy_entropy: 11.742237091064453
      policy_loss: 5.945923805236816
      var_gnorm: 47.920963287353516
      vf_explained_var: 0.6895424127578735
      vf_loss: 104.77313995361328
    num_steps_sampled: 1835000
    num_steps_trained: 1835000
    wait_time_ms: 107.949
  iterations_since_restore: 367
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4429.8934535980225
  time_this_iter_s: 11.191423654556274
  time_total_s: 4429.8934535980225
  timestamp: 1593998458
  timesteps_since_restore: 1835000
  timesteps_this_iter: 5000
  timesteps_total: 1835000
  training_iteration: 367
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4429 s, 367 iter, 1835000 ts, 469 rew

agent-1: 66.0
agent-2: 102.0
agent-3: 99.0
agent-4: 96.0
agent-5: 93.0
Sum Reward: 456.0
Avg Reward: 91.2
Min Reward: 66.0
Gini Coefficient: 0.06842105263157895
20:20 Ratio: 1.5454545454545454
Max-min Ratio: 1.5454545454545454
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-21-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 697.0
  episode_reward_mean: 469.73
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 367
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.82
    dispatch_time_ms: 6.321
    learner:
      cur_lr: 0.0012377890525385737
      grad_gnorm: 39.999996185302734
      policy_entropy: 7.56037712097168
      policy_loss: -0.4412909746170044
      var_gnorm: 47.98305892944336
      vf_explained_var: 0.4521911144256592
      vf_loss: 162.85186767578125
    num_steps_sampled: 1840000
    num_steps_trained: 1840000
    wait_time_ms: 102.793
  iterations_since_restore: 368
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4441.858239412308
  time_this_iter_s: 11.964785814285278
  time_total_s: 4441.858239412308
  timestamp: 1593998470
  timesteps_since_restore: 1840000
  timesteps_this_iter: 5000
  timesteps_total: 1840000
  training_iteration: 368
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4441 s, 368 iter, 1840000 ts, 470 rew

agent-1: 104.0
agent-2: 79.0
agent-3: 69.0
agent-4: 77.0
agent-5: 120.0
Sum Reward: 449.0
Avg Reward: 89.8
Min Reward: 69.0
Gini Coefficient: 0.11492204899777284
20:20 Ratio: 1.7391304347826086
Max-min Ratio: 1.7391304347826086
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-21-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 697.0
  episode_reward_mean: 470.41
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 368
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.609
    dispatch_time_ms: 7.128
    learner:
      cur_lr: 0.0012374559883028269
      grad_gnorm: 40.0
      policy_entropy: 32.48774337768555
      policy_loss: -6.561094760894775
      var_gnorm: 47.95713806152344
      vf_explained_var: 0.5734742879867554
      vf_loss: 11.194153785705566
    num_steps_sampled: 1845000
    num_steps_trained: 1845000
    wait_time_ms: 111.52
  iterations_since_restore: 369
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4453.399430274963
  time_this_iter_s: 11.54119086265564
  time_total_s: 4453.399430274963
  timestamp: 1593998482
  timesteps_since_restore: 1845000
  timesteps_this_iter: 5000
  timesteps_total: 1845000
  training_iteration: 369
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4453 s, 369 iter, 1845000 ts, 470 rew

agent-1: 79.0
agent-2: 76.0
agent-3: 67.0
agent-4: 61.0
agent-5: 61.0
Sum Reward: 344.0
Avg Reward: 68.8
Min Reward: 61.0
Gini Coefficient: 0.05930232558139535
20:20 Ratio: 1.2950819672131149
Max-min Ratio: 1.2950819672131149
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-21-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 697.0
  episode_reward_mean: 469.45
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 369
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.282
    dispatch_time_ms: 7.029
    learner:
      cur_lr: 0.0012371230404824018
      grad_gnorm: 40.0
      policy_entropy: 33.27939224243164
      policy_loss: -10.311616897583008
      var_gnorm: 47.915077209472656
      vf_explained_var: 0.7455922365188599
      vf_loss: 11.091602325439453
    num_steps_sampled: 1850000
    num_steps_trained: 1850000
    wait_time_ms: 112.355
  iterations_since_restore: 370
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4465.468188285828
  time_this_iter_s: 12.068758010864258
  time_total_s: 4465.468188285828
  timestamp: 1593998494
  timesteps_since_restore: 1850000
  timesteps_this_iter: 5000
  timesteps_total: 1850000
  training_iteration: 370
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4465 s, 370 iter, 1850000 ts, 469 rew

agent-1: 99.0
agent-2: 94.0
agent-3: 79.0
agent-4: 110.0
agent-5: 118.0
Sum Reward: 500.0
Avg Reward: 100.0
Min Reward: 79.0
Gini Coefficient: 0.0752
20:20 Ratio: 1.4936708860759493
Max-min Ratio: 1.4936708860759493
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-21-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 697.0
  episode_reward_mean: 469.72
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 370
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.847
    dispatch_time_ms: 9.363
    learner:
      cur_lr: 0.001236789976246655
      grad_gnorm: 40.00000762939453
      policy_entropy: 25.54248809814453
      policy_loss: -1.6177523136138916
      var_gnorm: 47.93067932128906
      vf_explained_var: 0.7349441051483154
      vf_loss: 4.06490421295166
    num_steps_sampled: 1855000
    num_steps_trained: 1855000
    wait_time_ms: 110.944
  iterations_since_restore: 371
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4476.588106632233
  time_this_iter_s: 11.11991834640503
  time_total_s: 4476.588106632233
  timestamp: 1593998505
  timesteps_since_restore: 1855000
  timesteps_this_iter: 5000
  timesteps_total: 1855000
  training_iteration: 371
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4476 s, 371 iter, 1855000 ts, 470 rew

agent-1: 93.0
agent-2: 104.0
agent-3: 104.0
agent-4: 93.0
agent-5: 105.0
Sum Reward: 499.0
Avg Reward: 99.8
Min Reward: 93.0
Gini Coefficient: 0.028056112224448898
20:20 Ratio: 1.1290322580645162
Max-min Ratio: 1.1290322580645162
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-21-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 697.0
  episode_reward_mean: 469.9
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 371
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.735
    dispatch_time_ms: 6.922
    learner:
      cur_lr: 0.00123645702842623
      grad_gnorm: 24.684141159057617
      policy_entropy: 34.614593505859375
      policy_loss: -4.5332932472229
      var_gnorm: 47.943084716796875
      vf_explained_var: -1.0
      vf_loss: 9.289304733276367
    num_steps_sampled: 1860000
    num_steps_trained: 1860000
    wait_time_ms: 97.933
  iterations_since_restore: 372
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4488.658581733704
  time_this_iter_s: 12.070475101470947
  time_total_s: 4488.658581733704
  timestamp: 1593998517
  timesteps_since_restore: 1860000
  timesteps_this_iter: 5000
  timesteps_total: 1860000
  training_iteration: 372
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4488 s, 372 iter, 1860000 ts, 470 rew

agent-1: 66.0
agent-2: 66.0
agent-3: 74.0
agent-4: 113.0
agent-5: 87.0
Sum Reward: 406.0
Avg Reward: 81.2
Min Reward: 66.0
Gini Coefficient: 0.11330049261083744
20:20 Ratio: 1.7121212121212122
Max-min Ratio: 1.7121212121212122
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-22-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 697.0
  episode_reward_mean: 470.54
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 372
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.776
    dispatch_time_ms: 6.218
    learner:
      cur_lr: 0.001236123964190483
      grad_gnorm: 31.607831954956055
      policy_entropy: 22.27398681640625
      policy_loss: 4.250883102416992
      var_gnorm: 47.91346740722656
      vf_explained_var: 0.7137923836708069
      vf_loss: 58.910736083984375
    num_steps_sampled: 1865000
    num_steps_trained: 1865000
    wait_time_ms: 110.2
  iterations_since_restore: 373
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4499.944514036179
  time_this_iter_s: 11.285932302474976
  time_total_s: 4499.944514036179
  timestamp: 1593998529
  timesteps_since_restore: 1865000
  timesteps_this_iter: 5000
  timesteps_total: 1865000
  training_iteration: 373
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4499 s, 373 iter, 1865000 ts, 471 rew

agent-1: 68.0
agent-2: 75.0
agent-3: 68.0
agent-4: 83.0
agent-5: 66.0
Sum Reward: 360.0
Avg Reward: 72.0
Min Reward: 66.0
Gini Coefficient: 0.04555555555555556
20:20 Ratio: 1.2575757575757576
Max-min Ratio: 1.2575757575757576
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-22-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 697.0
  episode_reward_mean: 469.59
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 373
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.987
    dispatch_time_ms: 7.06
    learner:
      cur_lr: 0.001235791016370058
      grad_gnorm: 26.95040512084961
      policy_entropy: 34.92937469482422
      policy_loss: -5.697511196136475
      var_gnorm: 48.02043914794922
      vf_explained_var: 0.0
      vf_loss: 0.8725210428237915
    num_steps_sampled: 1870000
    num_steps_trained: 1870000
    wait_time_ms: 110.652
  iterations_since_restore: 374
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4511.80388379097
  time_this_iter_s: 11.85936975479126
  time_total_s: 4511.80388379097
  timestamp: 1593998541
  timesteps_since_restore: 1870000
  timesteps_this_iter: 5000
  timesteps_total: 1870000
  training_iteration: 374
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4511 s, 374 iter, 1870000 ts, 470 rew

agent-1: 141.0
agent-2: 134.0
agent-3: 134.0
agent-4: 146.0
agent-5: 129.0
Sum Reward: 684.0
Avg Reward: 136.8
Min Reward: 129.0
Gini Coefficient: 0.023976608187134502
20:20 Ratio: 1.1317829457364341
Max-min Ratio: 1.1317829457364341
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-22-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 697.0
  episode_reward_mean: 471.75
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 374
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.09
    dispatch_time_ms: 6.132
    learner:
      cur_lr: 0.0012354579521343112
      grad_gnorm: 40.0
      policy_entropy: 7.015614032745361
      policy_loss: 12.045526504516602
      var_gnorm: 47.997005462646484
      vf_explained_var: -1.0
      vf_loss: 282.20001220703125
    num_steps_sampled: 1875000
    num_steps_trained: 1875000
    wait_time_ms: 103.372
  iterations_since_restore: 375
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4523.144075632095
  time_this_iter_s: 11.340191841125488
  time_total_s: 4523.144075632095
  timestamp: 1593998552
  timesteps_since_restore: 1875000
  timesteps_this_iter: 5000
  timesteps_total: 1875000
  training_iteration: 375
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4523 s, 375 iter, 1875000 ts, 472 rew

agent-1: 79.0
agent-2: 60.0
agent-3: 91.0
agent-4: 88.0
agent-5: 90.0
Sum Reward: 408.0
Avg Reward: 81.6
Min Reward: 60.0
Gini Coefficient: 0.07156862745098039
20:20 Ratio: 1.5166666666666666
Max-min Ratio: 1.5166666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-22-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 697.0
  episode_reward_mean: 472.25
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 375
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.543
    dispatch_time_ms: 7.263
    learner:
      cur_lr: 0.0012351250043138862
      grad_gnorm: 40.0
      policy_entropy: 28.46955680847168
      policy_loss: -8.24383544921875
      var_gnorm: 48.02263641357422
      vf_explained_var: 0.762566328048706
      vf_loss: 8.929818153381348
    num_steps_sampled: 1880000
    num_steps_trained: 1880000
    wait_time_ms: 94.422
  iterations_since_restore: 376
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4535.1111879348755
  time_this_iter_s: 11.967112302780151
  time_total_s: 4535.1111879348755
  timestamp: 1593998564
  timesteps_since_restore: 1880000
  timesteps_this_iter: 5000
  timesteps_total: 1880000
  training_iteration: 376
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4535 s, 376 iter, 1880000 ts, 472 rew

agent-1: 71.0
agent-2: 94.0
agent-3: 82.0
agent-4: 84.0
agent-5: 89.0
Sum Reward: 420.0
Avg Reward: 84.0
Min Reward: 71.0
Gini Coefficient: 0.05047619047619047
20:20 Ratio: 1.323943661971831
Max-min Ratio: 1.323943661971831
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-22-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 697.0
  episode_reward_mean: 471.9
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 376
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.268
    dispatch_time_ms: 9.912
    learner:
      cur_lr: 0.0012347920564934611
      grad_gnorm: 32.526790618896484
      policy_entropy: 4.830680847167969
      policy_loss: -1.8704792261123657
      var_gnorm: 48.200531005859375
      vf_explained_var: -0.5086770057678223
      vf_loss: 103.36217498779297
    num_steps_sampled: 1885000
    num_steps_trained: 1885000
    wait_time_ms: 105.471
  iterations_since_restore: 377
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4546.491675615311
  time_this_iter_s: 11.38048768043518
  time_total_s: 4546.491675615311
  timestamp: 1593998576
  timesteps_since_restore: 1885000
  timesteps_this_iter: 5000
  timesteps_total: 1885000
  training_iteration: 377
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4546 s, 377 iter, 1885000 ts, 472 rew

agent-1: 124.0
agent-2: 70.0
agent-3: 79.0
agent-4: 79.0
agent-5: 94.0
Sum Reward: 446.0
Avg Reward: 89.2
Min Reward: 70.0
Gini Coefficient: 0.11031390134529148
20:20 Ratio: 1.7714285714285714
Max-min Ratio: 1.7714285714285714
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-23-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 697.0
  episode_reward_mean: 471.73
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 377
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.592
    dispatch_time_ms: 7.528
    learner:
      cur_lr: 0.0012344589922577143
      grad_gnorm: 39.999996185302734
      policy_entropy: 27.328269958496094
      policy_loss: 2.3975374698638916
      var_gnorm: 48.28725814819336
      vf_explained_var: 0.7769550681114197
      vf_loss: 59.48443603515625
    num_steps_sampled: 1890000
    num_steps_trained: 1890000
    wait_time_ms: 114.437
  iterations_since_restore: 378
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4558.632696866989
  time_this_iter_s: 12.141021251678467
  time_total_s: 4558.632696866989
  timestamp: 1593998588
  timesteps_since_restore: 1890000
  timesteps_this_iter: 5000
  timesteps_total: 1890000
  training_iteration: 378
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4558 s, 378 iter, 1890000 ts, 472 rew

agent-1: 101.0
agent-2: 132.0
agent-3: 99.0
agent-4: 89.0
agent-5: 140.0
Sum Reward: 561.0
Avg Reward: 112.2
Min Reward: 89.0
Gini Coefficient: 0.0962566844919786
20:20 Ratio: 1.5730337078651686
Max-min Ratio: 1.5730337078651686
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-23-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 697.0
  episode_reward_mean: 473.16
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 378
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.787
    dispatch_time_ms: 6.812
    learner:
      cur_lr: 0.0012341260444372892
      grad_gnorm: 36.847198486328125
      policy_entropy: 32.0226936340332
      policy_loss: -5.475564479827881
      var_gnorm: 48.3316650390625
      vf_explained_var: 0.3336912989616394
      vf_loss: 3.1992664337158203
    num_steps_sampled: 1895000
    num_steps_trained: 1895000
    wait_time_ms: 114.953
  iterations_since_restore: 379
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4570.093415021896
  time_this_iter_s: 11.460718154907227
  time_total_s: 4570.093415021896
  timestamp: 1593998599
  timesteps_since_restore: 1895000
  timesteps_this_iter: 5000
  timesteps_total: 1895000
  training_iteration: 379
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4570 s, 379 iter, 1895000 ts, 473 rew

agent-1: 107.0
agent-2: 91.0
agent-3: 112.0
agent-4: 90.0
agent-5: 92.0
Sum Reward: 492.0
Avg Reward: 98.4
Min Reward: 90.0
Gini Coefficient: 0.04878048780487805
20:20 Ratio: 1.2444444444444445
Max-min Ratio: 1.2444444444444445
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-23-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 697.0
  episode_reward_mean: 473.21
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 379
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.867
    dispatch_time_ms: 6.781
    learner:
      cur_lr: 0.0012337929802015424
      grad_gnorm: 7.998754024505615
      policy_entropy: 31.963844299316406
      policy_loss: 0.26400378346443176
      var_gnorm: 48.43012619018555
      vf_explained_var: -1.0
      vf_loss: 1.9537053108215332
    num_steps_sampled: 1900000
    num_steps_trained: 1900000
    wait_time_ms: 110.375
  iterations_since_restore: 380
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4582.249824762344
  time_this_iter_s: 12.156409740447998
  time_total_s: 4582.249824762344
  timestamp: 1593998611
  timesteps_since_restore: 1900000
  timesteps_this_iter: 5000
  timesteps_total: 1900000
  training_iteration: 380
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4582 s, 380 iter, 1900000 ts, 473 rew

agent-1: 68.0
agent-2: 61.0
agent-3: 73.0
agent-4: 71.0
agent-5: 71.0
Sum Reward: 344.0
Avg Reward: 68.8
Min Reward: 61.0
Gini Coefficient: 0.031395348837209305
20:20 Ratio: 1.1967213114754098
Max-min Ratio: 1.1967213114754098
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-23-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 697.0
  episode_reward_mean: 471.87
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 380
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.869
    dispatch_time_ms: 6.709
    learner:
      cur_lr: 0.0012334600323811173
      grad_gnorm: 39.99999237060547
      policy_entropy: 7.790104866027832
      policy_loss: -3.788846731185913
      var_gnorm: 48.343326568603516
      vf_explained_var: 0.03797507286071777
      vf_loss: 123.88138580322266
    num_steps_sampled: 1905000
    num_steps_trained: 1905000
    wait_time_ms: 107.999
  iterations_since_restore: 381
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4593.855590343475
  time_this_iter_s: 11.605765581130981
  time_total_s: 4593.855590343475
  timestamp: 1593998623
  timesteps_since_restore: 1905000
  timesteps_this_iter: 5000
  timesteps_total: 1905000
  training_iteration: 381
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4593 s, 381 iter, 1905000 ts, 472 rew

agent-1: 89.0
agent-2: 90.0
agent-3: 109.0
agent-4: 90.0
agent-5: 72.0
Sum Reward: 450.0
Avg Reward: 90.0
Min Reward: 72.0
Gini Coefficient: 0.06666666666666667
20:20 Ratio: 1.5138888888888888
Max-min Ratio: 1.5138888888888888
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-23-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 697.0
  episode_reward_mean: 472.58
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 381
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.265
    dispatch_time_ms: 7.61
    learner:
      cur_lr: 0.0012331269681453705
      grad_gnorm: 28.934213638305664
      policy_entropy: 2.6381912231445312
      policy_loss: 0.9567667841911316
      var_gnorm: 48.365966796875
      vf_explained_var: -0.3613942861557007
      vf_loss: 16.30821418762207
    num_steps_sampled: 1910000
    num_steps_trained: 1910000
    wait_time_ms: 101.713
  iterations_since_restore: 382
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4605.85834479332
  time_this_iter_s: 12.00275444984436
  time_total_s: 4605.85834479332
  timestamp: 1593998635
  timesteps_since_restore: 1910000
  timesteps_this_iter: 5000
  timesteps_total: 1910000
  training_iteration: 382
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4605 s, 382 iter, 1910000 ts, 473 rew

agent-1: 91.0
agent-2: 104.0
agent-3: 93.0
agent-4: 83.0
agent-5: 95.0
Sum Reward: 466.0
Avg Reward: 93.2
Min Reward: 83.0
Gini Coefficient: 0.039484978540772535
20:20 Ratio: 1.2530120481927711
Max-min Ratio: 1.2530120481927711
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-24-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 697.0
  episode_reward_mean: 473.6
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 382
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.758
    dispatch_time_ms: 8.353
    learner:
      cur_lr: 0.0012327940203249454
      grad_gnorm: 40.000003814697266
      policy_entropy: 4.574166774749756
      policy_loss: -1.1145371198654175
      var_gnorm: 48.37738800048828
      vf_explained_var: -1.0
      vf_loss: 42.64986038208008
    num_steps_sampled: 1915000
    num_steps_trained: 1915000
    wait_time_ms: 105.363
  iterations_since_restore: 383
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4617.22346162796
  time_this_iter_s: 11.365116834640503
  time_total_s: 4617.22346162796
  timestamp: 1593998647
  timesteps_since_restore: 1915000
  timesteps_this_iter: 5000
  timesteps_total: 1915000
  training_iteration: 383
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4617 s, 383 iter, 1915000 ts, 474 rew

agent-1: 113.0
agent-2: 97.0
agent-3: 85.0
agent-4: 84.0
agent-5: 89.0
Sum Reward: 468.0
Avg Reward: 93.6
Min Reward: 84.0
Gini Coefficient: 0.05982905982905983
20:20 Ratio: 1.3452380952380953
Max-min Ratio: 1.3452380952380953
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-24-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 697.0
  episode_reward_mean: 474.27
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 383
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.486
    dispatch_time_ms: 7.612
    learner:
      cur_lr: 0.0012324609560891986
      grad_gnorm: 10.054886817932129
      policy_entropy: 33.21099853515625
      policy_loss: -2.1296496391296387
      var_gnorm: 48.45857238769531
      vf_explained_var: 0.0
      vf_loss: 0.12073466926813126
    num_steps_sampled: 1920000
    num_steps_trained: 1920000
    wait_time_ms: 98.322
  iterations_since_restore: 384
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4629.108199596405
  time_this_iter_s: 11.884737968444824
  time_total_s: 4629.108199596405
  timestamp: 1593998658
  timesteps_since_restore: 1920000
  timesteps_this_iter: 5000
  timesteps_total: 1920000
  training_iteration: 384
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4629 s, 384 iter, 1920000 ts, 474 rew

agent-1: 99.0
agent-2: 102.0
agent-3: 78.0
agent-4: 96.0
agent-5: 109.0
Sum Reward: 484.0
Avg Reward: 96.8
Min Reward: 78.0
Gini Coefficient: 0.05619834710743802
20:20 Ratio: 1.3974358974358974
Max-min Ratio: 1.3974358974358974
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-24-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 697.0
  episode_reward_mean: 475.85
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 384
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.513
    dispatch_time_ms: 8.921
    learner:
      cur_lr: 0.0012321280082687736
      grad_gnorm: 32.120994567871094
      policy_entropy: 29.16080093383789
      policy_loss: -1.8354275226593018
      var_gnorm: 48.557308197021484
      vf_explained_var: 0.9477197527885437
      vf_loss: 24.398164749145508
    num_steps_sampled: 1925000
    num_steps_trained: 1925000
    wait_time_ms: 106.418
  iterations_since_restore: 385
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4640.30158662796
  time_this_iter_s: 11.193387031555176
  time_total_s: 4640.30158662796
  timestamp: 1593998670
  timesteps_since_restore: 1925000
  timesteps_this_iter: 5000
  timesteps_total: 1925000
  training_iteration: 385
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4640 s, 385 iter, 1925000 ts, 476 rew

agent-1: 122.0
agent-2: 112.0
agent-3: 140.0
agent-4: 110.0
agent-5: 147.0
Sum Reward: 631.0
Avg Reward: 126.2
Min Reward: 110.0
Gini Coefficient: 0.06465927099841522
20:20 Ratio: 1.3363636363636364
Max-min Ratio: 1.3363636363636364
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-24-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 697.0
  episode_reward_mean: 477.58
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 385
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.155
    dispatch_time_ms: 7.887
    learner:
      cur_lr: 0.0012317949440330267
      grad_gnorm: 39.999996185302734
      policy_entropy: 5.837122440338135
      policy_loss: 2.25594162940979
      var_gnorm: 48.63488006591797
      vf_explained_var: 0.7302882671356201
      vf_loss: 56.690242767333984
    num_steps_sampled: 1930000
    num_steps_trained: 1930000
    wait_time_ms: 103.791
  iterations_since_restore: 386
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4652.227203607559
  time_this_iter_s: 11.925616979598999
  time_total_s: 4652.227203607559
  timestamp: 1593998682
  timesteps_since_restore: 1930000
  timesteps_this_iter: 5000
  timesteps_total: 1930000
  training_iteration: 386
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4652 s, 386 iter, 1930000 ts, 478 rew

agent-1: 74.0
agent-2: 86.0
agent-3: 82.0
agent-4: 86.0
agent-5: 73.0
Sum Reward: 401.0
Avg Reward: 80.2
Min Reward: 73.0
Gini Coefficient: 0.03790523690773067
20:20 Ratio: 1.178082191780822
Max-min Ratio: 1.178082191780822
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-24-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 697.0
  episode_reward_mean: 477.21
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 386
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.225
    dispatch_time_ms: 9.252
    learner:
      cur_lr: 0.0012314619962126017
      grad_gnorm: 40.0
      policy_entropy: 13.958246231079102
      policy_loss: 59.054931640625
      var_gnorm: 48.70748519897461
      vf_explained_var: -0.4118841886520386
      vf_loss: 336.3076171875
    num_steps_sampled: 1935000
    num_steps_trained: 1935000
    wait_time_ms: 109.433
  iterations_since_restore: 387
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4663.716728925705
  time_this_iter_s: 11.489525318145752
  time_total_s: 4663.716728925705
  timestamp: 1593998693
  timesteps_since_restore: 1935000
  timesteps_this_iter: 5000
  timesteps_total: 1935000
  training_iteration: 387
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4663 s, 387 iter, 1935000 ts, 477 rew

agent-1: 107.0
agent-2: 105.0
agent-3: 111.0
agent-4: 83.0
agent-5: 125.0
Sum Reward: 531.0
Avg Reward: 106.2
Min Reward: 83.0
Gini Coefficient: 0.06779661016949153
20:20 Ratio: 1.5060240963855422
Max-min Ratio: 1.5060240963855422
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-25-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 697.0
  episode_reward_mean: 479.17
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 387
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.873
    dispatch_time_ms: 5.662
    learner:
      cur_lr: 0.0012311290483921766
      grad_gnorm: 9.439661026000977
      policy_entropy: 30.29684829711914
      policy_loss: 1.584001064300537
      var_gnorm: 48.911659240722656
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.10729949921369553
    num_steps_sampled: 1940000
    num_steps_trained: 1940000
    wait_time_ms: 119.968
  iterations_since_restore: 388
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4675.944698572159
  time_this_iter_s: 12.227969646453857
  time_total_s: 4675.944698572159
  timestamp: 1593998705
  timesteps_since_restore: 1940000
  timesteps_this_iter: 5000
  timesteps_total: 1940000
  training_iteration: 388
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4675 s, 388 iter, 1940000 ts, 479 rew

agent-1: 76.0
agent-2: 55.0
agent-3: 74.0
agent-4: 70.0
agent-5: 64.0
Sum Reward: 339.0
Avg Reward: 67.8
Min Reward: 55.0
Gini Coefficient: 0.06135693215339233
20:20 Ratio: 1.3818181818181818
Max-min Ratio: 1.3818181818181818
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-25-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 697.0
  episode_reward_mean: 477.11
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 388
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.301
    dispatch_time_ms: 7.283
    learner:
      cur_lr: 0.0012307959841564298
      grad_gnorm: 8.844316482543945
      policy_entropy: 17.71142578125
      policy_loss: -1.1625453233718872
      var_gnorm: 48.93931579589844
      vf_explained_var: 0.9953268766403198
      vf_loss: 0.20852093398571014
    num_steps_sampled: 1945000
    num_steps_trained: 1945000
    wait_time_ms: 113.777
  iterations_since_restore: 389
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4687.675580739975
  time_this_iter_s: 11.730882167816162
  time_total_s: 4687.675580739975
  timestamp: 1593998717
  timesteps_since_restore: 1945000
  timesteps_this_iter: 5000
  timesteps_total: 1945000
  training_iteration: 389
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4687 s, 389 iter, 1945000 ts, 477 rew

agent-1: 77.0
agent-2: 61.0
agent-3: 71.0
agent-4: 57.0
agent-5: 73.0
Sum Reward: 339.0
Avg Reward: 67.8
Min Reward: 57.0
Gini Coefficient: 0.06135693215339233
20:20 Ratio: 1.3508771929824561
Max-min Ratio: 1.3508771929824561
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-25-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 697.0
  episode_reward_mean: 475.99
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 389
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.507
    dispatch_time_ms: 8.449
    learner:
      cur_lr: 0.0012304630363360047
      grad_gnorm: 39.999996185302734
      policy_entropy: 9.524612426757812
      policy_loss: -11.475425720214844
      var_gnorm: 48.990848541259766
      vf_explained_var: 0.23239833116531372
      vf_loss: 324.4836120605469
    num_steps_sampled: 1950000
    num_steps_trained: 1950000
    wait_time_ms: 109.951
  iterations_since_restore: 390
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4699.4385759830475
  time_this_iter_s: 11.76299524307251
  time_total_s: 4699.4385759830475
  timestamp: 1593998729
  timesteps_since_restore: 1950000
  timesteps_this_iter: 5000
  timesteps_total: 1950000
  training_iteration: 390
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4699 s, 390 iter, 1950000 ts, 476 rew

agent-1: 137.0
agent-2: 125.0
agent-3: 113.0
agent-4: 100.0
agent-5: 118.0
Sum Reward: 593.0
Avg Reward: 118.6
Min Reward: 100.0
Gini Coefficient: 0.05801011804384486
20:20 Ratio: 1.37
Max-min Ratio: 1.37
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-25-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 697.0
  episode_reward_mean: 478.21
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 390
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.025
    dispatch_time_ms: 7.822
    learner:
      cur_lr: 0.0012301299721002579
      grad_gnorm: 18.17775535583496
      policy_entropy: 18.26319694519043
      policy_loss: 9.853486061096191
      var_gnorm: 49.098838806152344
      vf_explained_var: 0.2955174446105957
      vf_loss: 81.01737976074219
    num_steps_sampled: 1955000
    num_steps_trained: 1955000
    wait_time_ms: 109.185
  iterations_since_restore: 391
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4710.961233615875
  time_this_iter_s: 11.522657632827759
  time_total_s: 4710.961233615875
  timestamp: 1593998741
  timesteps_since_restore: 1955000
  timesteps_this_iter: 5000
  timesteps_total: 1955000
  training_iteration: 391
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4710 s, 391 iter, 1955000 ts, 478 rew

agent-1: 79.0
agent-2: 91.0
agent-3: 79.0
agent-4: 92.0
agent-5: 115.0
Sum Reward: 456.0
Avg Reward: 91.2
Min Reward: 79.0
Gini Coefficient: 0.07456140350877193
20:20 Ratio: 1.4556962025316456
Max-min Ratio: 1.4556962025316456
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-25-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 697.0
  episode_reward_mean: 478.91
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 391
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.862
    dispatch_time_ms: 7.867
    learner:
      cur_lr: 0.0012297970242798328
      grad_gnorm: 26.530893325805664
      policy_entropy: 13.765453338623047
      policy_loss: 2.2435379028320312
      var_gnorm: 49.25120162963867
      vf_explained_var: -1.0
      vf_loss: 57.49599838256836
    num_steps_sampled: 1960000
    num_steps_trained: 1960000
    wait_time_ms: 86.766
  iterations_since_restore: 392
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4722.041181087494
  time_this_iter_s: 11.079947471618652
  time_total_s: 4722.041181087494
  timestamp: 1593998752
  timesteps_since_restore: 1960000
  timesteps_this_iter: 5000
  timesteps_total: 1960000
  training_iteration: 392
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4722 s, 392 iter, 1960000 ts, 479 rew

agent-1: 100.0
agent-2: 157.0
agent-3: 109.0
agent-4: 153.0
agent-5: 140.0
Sum Reward: 659.0
Avg Reward: 131.8
Min Reward: 100.0
Gini Coefficient: 0.09590288315629741
20:20 Ratio: 1.57
Max-min Ratio: 1.57
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-26-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 697.0
  episode_reward_mean: 480.41
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 392
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.763
    dispatch_time_ms: 10.194
    learner:
      cur_lr: 0.001229463960044086
      grad_gnorm: 40.0
      policy_entropy: 16.663976669311523
      policy_loss: 24.82474708557129
      var_gnorm: 49.31892013549805
      vf_explained_var: -0.8353925943374634
      vf_loss: 101.73724365234375
    num_steps_sampled: 1965000
    num_steps_trained: 1965000
    wait_time_ms: 87.676
  iterations_since_restore: 393
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4732.527436733246
  time_this_iter_s: 10.486255645751953
  time_total_s: 4732.527436733246
  timestamp: 1593998762
  timesteps_since_restore: 1965000
  timesteps_this_iter: 5000
  timesteps_total: 1965000
  training_iteration: 393
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4732 s, 393 iter, 1965000 ts, 480 rew

agent-1: 98.0
agent-2: 148.0
agent-3: 135.0
agent-4: 138.0
agent-5: 117.0
Sum Reward: 636.0
Avg Reward: 127.2
Min Reward: 98.0
Gini Coefficient: 0.07610062893081761
20:20 Ratio: 1.510204081632653
Max-min Ratio: 1.510204081632653
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-26-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 697.0
  episode_reward_mean: 483.61
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 393
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.314
    dispatch_time_ms: 6.172
    learner:
      cur_lr: 0.001229131012223661
      grad_gnorm: 40.0
      policy_entropy: 16.589202880859375
      policy_loss: 19.421138763427734
      var_gnorm: 49.31935501098633
      vf_explained_var: 0.062315165996551514
      vf_loss: 67.92811584472656
    num_steps_sampled: 1970000
    num_steps_trained: 1970000
    wait_time_ms: 92.096
  iterations_since_restore: 394
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4743.437747478485
  time_this_iter_s: 10.910310745239258
  time_total_s: 4743.437747478485
  timestamp: 1593998773
  timesteps_since_restore: 1970000
  timesteps_this_iter: 5000
  timesteps_total: 1970000
  training_iteration: 394
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4743 s, 394 iter, 1970000 ts, 484 rew

agent-1: 149.0
agent-2: 127.0
agent-3: 123.0
agent-4: 131.0
agent-5: 132.0
Sum Reward: 662.0
Avg Reward: 132.4
Min Reward: 123.0
Gini Coefficient: 0.03444108761329305
20:20 Ratio: 1.2113821138211383
Max-min Ratio: 1.2113821138211383
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-26-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 697.0
  episode_reward_mean: 486.1
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 394
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.866
    dispatch_time_ms: 7.821
    learner:
      cur_lr: 0.001228797947987914
      grad_gnorm: 40.0
      policy_entropy: 24.466875076293945
      policy_loss: 8.150341987609863
      var_gnorm: 49.418006896972656
      vf_explained_var: -0.022497892379760742
      vf_loss: 36.16962432861328
    num_steps_sampled: 1975000
    num_steps_trained: 1975000
    wait_time_ms: 99.207
  iterations_since_restore: 395
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4754.331047534943
  time_this_iter_s: 10.89330005645752
  time_total_s: 4754.331047534943
  timestamp: 1593998784
  timesteps_since_restore: 1975000
  timesteps_this_iter: 5000
  timesteps_total: 1975000
  training_iteration: 395
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4754 s, 395 iter, 1975000 ts, 486 rew

agent-1: 139.0
agent-2: 126.0
agent-3: 92.0
agent-4: 133.0
agent-5: 104.0
Sum Reward: 594.0
Avg Reward: 118.8
Min Reward: 92.0
Gini Coefficient: 0.08282828282828283
20:20 Ratio: 1.5108695652173914
Max-min Ratio: 1.5108695652173914
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-26-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 697.0
  episode_reward_mean: 487.69
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 395
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.118
    dispatch_time_ms: 7.397
    learner:
      cur_lr: 0.001228465000167489
      grad_gnorm: 40.0
      policy_entropy: 17.88339614868164
      policy_loss: 19.51556968688965
      var_gnorm: 49.42308044433594
      vf_explained_var: -0.11917424201965332
      vf_loss: 75.44112396240234
    num_steps_sampled: 1980000
    num_steps_trained: 1980000
    wait_time_ms: 100.275
  iterations_since_restore: 396
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4765.668375015259
  time_this_iter_s: 11.337327480316162
  time_total_s: 4765.668375015259
  timestamp: 1593998796
  timesteps_since_restore: 1980000
  timesteps_this_iter: 5000
  timesteps_total: 1980000
  training_iteration: 396
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4765 s, 396 iter, 1980000 ts, 488 rew

agent-1: 121.0
agent-2: 178.0
agent-3: 153.0
agent-4: 135.0
agent-5: 113.0
Sum Reward: 700.0
Avg Reward: 140.0
Min Reward: 113.0
Gini Coefficient: 0.09257142857142857
20:20 Ratio: 1.575221238938053
Max-min Ratio: 1.575221238938053
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-26-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 700.0
  episode_reward_mean: 490.9
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 396
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.636
    dispatch_time_ms: 7.728
    learner:
      cur_lr: 0.001228132052347064
      grad_gnorm: 40.000003814697266
      policy_entropy: 26.493907928466797
      policy_loss: 1.040342092514038
      var_gnorm: 49.42106628417969
      vf_explained_var: -0.02138662338256836
      vf_loss: 57.74931335449219
    num_steps_sampled: 1985000
    num_steps_trained: 1985000
    wait_time_ms: 95.267
  iterations_since_restore: 397
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4776.195932865143
  time_this_iter_s: 10.527557849884033
  time_total_s: 4776.195932865143
  timestamp: 1593998806
  timesteps_since_restore: 1985000
  timesteps_this_iter: 5000
  timesteps_total: 1985000
  training_iteration: 397
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4776 s, 397 iter, 1985000 ts, 491 rew

agent-1: 145.0
agent-2: 157.0
agent-3: 149.0
agent-4: 160.0
agent-5: 145.0
Sum Reward: 756.0
Avg Reward: 151.2
Min Reward: 145.0
Gini Coefficient: 0.022222222222222223
20:20 Ratio: 1.103448275862069
Max-min Ratio: 1.103448275862069
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-26-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 756.0
  episode_reward_mean: 494.52
  episode_reward_min: 247.0
  episodes_this_iter: 1
  episodes_total: 397
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.259
    dispatch_time_ms: 7.11
    learner:
      cur_lr: 0.0012277989881113172
      grad_gnorm: 39.999996185302734
      policy_entropy: 22.75727081298828
      policy_loss: 5.556934833526611
      var_gnorm: 49.45304489135742
      vf_explained_var: 0.4424101710319519
      vf_loss: 23.01224136352539
    num_steps_sampled: 1990000
    num_steps_trained: 1990000
    wait_time_ms: 90.793
  iterations_since_restore: 398
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4786.975023508072
  time_this_iter_s: 10.779090642929077
  time_total_s: 4786.975023508072
  timestamp: 1593998817
  timesteps_since_restore: 1990000
  timesteps_this_iter: 5000
  timesteps_total: 1990000
  training_iteration: 398
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4786 s, 398 iter, 1990000 ts, 495 rew

agent-1: 167.0
agent-2: 168.0
agent-3: 156.0
agent-4: 174.0
agent-5: 130.0
Sum Reward: 795.0
Avg Reward: 159.0
Min Reward: 130.0
Gini Coefficient: 0.050314465408805034
20:20 Ratio: 1.3384615384615384
Max-min Ratio: 1.3384615384615384
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-27-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 795.0
  episode_reward_mean: 500.0
  episode_reward_min: 298.0
  episodes_this_iter: 1
  episodes_total: 398
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.455
    dispatch_time_ms: 13.31
    learner:
      cur_lr: 0.0012274660402908921
      grad_gnorm: 17.795345306396484
      policy_entropy: 22.931339263916016
      policy_loss: 4.020761966705322
      var_gnorm: 49.48905944824219
      vf_explained_var: 0.26308196783065796
      vf_loss: 23.385059356689453
    num_steps_sampled: 1995000
    num_steps_trained: 1995000
    wait_time_ms: 93.067
  iterations_since_restore: 399
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4797.660865783691
  time_this_iter_s: 10.685842275619507
  time_total_s: 4797.660865783691
  timestamp: 1593998828
  timesteps_since_restore: 1995000
  timesteps_this_iter: 5000
  timesteps_total: 1995000
  training_iteration: 399
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4797 s, 399 iter, 1995000 ts, 500 rew

agent-1: 139.0
agent-2: 151.0
agent-3: 124.0
agent-4: 135.0
agent-5: 137.0
Sum Reward: 686.0
Avg Reward: 137.2
Min Reward: 124.0
Gini Coefficient: 0.03381924198250729
20:20 Ratio: 1.217741935483871
Max-min Ratio: 1.217741935483871
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-27-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 795.0
  episode_reward_mean: 500.4
  episode_reward_min: 298.0
  episodes_this_iter: 1
  episodes_total: 399
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 5.101
    dispatch_time_ms: 7.905
    learner:
      cur_lr: 0.0012271329760551453
      grad_gnorm: 15.513264656066895
      policy_entropy: 27.78295135498047
      policy_loss: -4.457287788391113
      var_gnorm: 49.55664825439453
      vf_explained_var: -1.0
      vf_loss: 11.810713768005371
    num_steps_sampled: 2000000
    num_steps_trained: 2000000
    wait_time_ms: 103.932
  iterations_since_restore: 400
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4808.879729509354
  time_this_iter_s: 11.218863725662231
  time_total_s: 4808.879729509354
  timestamp: 1593998839
  timesteps_since_restore: 2000000
  timesteps_this_iter: 5000
  timesteps_total: 2000000
  training_iteration: 400
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4808 s, 400 iter, 2000000 ts, 500 rew

agent-1: 128.0
agent-2: 136.0
agent-3: 146.0
agent-4: 125.0
agent-5: 140.0
Sum Reward: 675.0
Avg Reward: 135.0
Min Reward: 125.0
Gini Coefficient: 0.032
20:20 Ratio: 1.168
Max-min Ratio: 1.168
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-27-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 795.0
  episode_reward_mean: 503.05
  episode_reward_min: 298.0
  episodes_this_iter: 1
  episodes_total: 400
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.054
    dispatch_time_ms: 8.389
    learner:
      cur_lr: 0.0012268000282347202
      grad_gnorm: 33.18590545654297
      policy_entropy: 23.626291275024414
      policy_loss: 6.66531229019165
      var_gnorm: 49.5681037902832
      vf_explained_var: -0.3389892578125
      vf_loss: 37.34140396118164
    num_steps_sampled: 2005000
    num_steps_trained: 2005000
    wait_time_ms: 96.32
  iterations_since_restore: 401
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4819.53354883194
  time_this_iter_s: 10.65381932258606
  time_total_s: 4819.53354883194
  timestamp: 1593998850
  timesteps_since_restore: 2005000
  timesteps_this_iter: 5000
  timesteps_total: 2005000
  training_iteration: 401
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4819 s, 401 iter, 2005000 ts, 503 rew

agent-1: 135.0
agent-2: 149.0
agent-3: 123.0
agent-4: 141.0
agent-5: 177.0
Sum Reward: 725.0
Avg Reward: 145.0
Min Reward: 123.0
Gini Coefficient: 0.0673103448275862
20:20 Ratio: 1.4390243902439024
Max-min Ratio: 1.4390243902439024
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-27-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 795.0
  episode_reward_mean: 506.5
  episode_reward_min: 298.0
  episodes_this_iter: 1
  episodes_total: 401
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.831
    dispatch_time_ms: 6.243
    learner:
      cur_lr: 0.0012264669639989734
      grad_gnorm: 9.407405853271484
      policy_entropy: 23.96253204345703
      policy_loss: -2.9566543102264404
      var_gnorm: 49.58584976196289
      vf_explained_var: 0.08062660694122314
      vf_loss: 35.68585205078125
    num_steps_sampled: 2010000
    num_steps_trained: 2010000
    wait_time_ms: 97.274
  iterations_since_restore: 402
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4830.429036617279
  time_this_iter_s: 10.895487785339355
  time_total_s: 4830.429036617279
  timestamp: 1593998861
  timesteps_since_restore: 2010000
  timesteps_this_iter: 5000
  timesteps_total: 2010000
  training_iteration: 402
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4830 s, 402 iter, 2010000 ts, 506 rew

agent-1: 127.0
agent-2: 166.0
agent-3: 119.0
agent-4: 166.0
agent-5: 154.0
Sum Reward: 732.0
Avg Reward: 146.4
Min Reward: 119.0
Gini Coefficient: 0.0726775956284153
20:20 Ratio: 1.3949579831932772
Max-min Ratio: 1.3949579831932772
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-27-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 795.0
  episode_reward_mean: 507.3
  episode_reward_min: 298.0
  episodes_this_iter: 1
  episodes_total: 402
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.258
    dispatch_time_ms: 7.695
    learner:
      cur_lr: 0.0012261340161785483
      grad_gnorm: 17.801050186157227
      policy_entropy: 28.076147079467773
      policy_loss: 4.0622992515563965
      var_gnorm: 49.626216888427734
      vf_explained_var: -0.11322021484375
      vf_loss: 21.849008560180664
    num_steps_sampled: 2015000
    num_steps_trained: 2015000
    wait_time_ms: 104.414
  iterations_since_restore: 403
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4841.228333473206
  time_this_iter_s: 10.799296855926514
  time_total_s: 4841.228333473206
  timestamp: 1593998871
  timesteps_since_restore: 2015000
  timesteps_this_iter: 5000
  timesteps_total: 2015000
  training_iteration: 403
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4841 s, 403 iter, 2015000 ts, 507 rew

agent-1: 179.0
agent-2: 175.0
agent-3: 159.0
agent-4: 148.0
agent-5: 148.0
Sum Reward: 809.0
Avg Reward: 161.8
Min Reward: 148.0
Gini Coefficient: 0.044004944375772556
20:20 Ratio: 1.2094594594594594
Max-min Ratio: 1.2094594594594594
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-28-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 511.96
  episode_reward_min: 298.0
  episodes_this_iter: 1
  episodes_total: 403
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.126
    dispatch_time_ms: 7.184
    learner:
      cur_lr: 0.0012258009519428015
      grad_gnorm: 40.000003814697266
      policy_entropy: 27.54988670349121
      policy_loss: -12.254627227783203
      var_gnorm: 49.63512420654297
      vf_explained_var: 0.5386307239532471
      vf_loss: 50.971710205078125
    num_steps_sampled: 2020000
    num_steps_trained: 2020000
    wait_time_ms: 108.368
  iterations_since_restore: 404
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4852.34748840332
  time_this_iter_s: 11.119154930114746
  time_total_s: 4852.34748840332
  timestamp: 1593998883
  timesteps_since_restore: 2020000
  timesteps_this_iter: 5000
  timesteps_total: 2020000
  training_iteration: 404
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4852 s, 404 iter, 2020000 ts, 512 rew

agent-1: 107.0
agent-2: 129.0
agent-3: 129.0
agent-4: 161.0
agent-5: 124.0
Sum Reward: 650.0
Avg Reward: 130.0
Min Reward: 107.0
Gini Coefficient: 0.06953846153846154
20:20 Ratio: 1.5046728971962617
Max-min Ratio: 1.5046728971962617
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-28-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 514.48
  episode_reward_min: 298.0
  episodes_this_iter: 1
  episodes_total: 404
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.049
    dispatch_time_ms: 7.332
    learner:
      cur_lr: 0.0012254680041223764
      grad_gnorm: 40.0
      policy_entropy: 25.510604858398438
      policy_loss: 18.47127914428711
      var_gnorm: 49.62929916381836
      vf_explained_var: -0.7257070541381836
      vf_loss: 56.52056884765625
    num_steps_sampled: 2025000
    num_steps_trained: 2025000
    wait_time_ms: 99.891
  iterations_since_restore: 405
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4863.028759241104
  time_this_iter_s: 10.681270837783813
  time_total_s: 4863.028759241104
  timestamp: 1593998893
  timesteps_since_restore: 2025000
  timesteps_this_iter: 5000
  timesteps_total: 2025000
  training_iteration: 405
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4863 s, 405 iter, 2025000 ts, 514 rew

agent-1: 139.0
agent-2: 136.0
agent-3: 114.0
agent-4: 118.0
agent-5: 148.0
Sum Reward: 655.0
Avg Reward: 131.0
Min Reward: 114.0
Gini Coefficient: 0.05435114503816794
20:20 Ratio: 1.2982456140350878
Max-min Ratio: 1.2982456140350878
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-28-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 517.13
  episode_reward_min: 298.0
  episodes_this_iter: 1
  episodes_total: 405
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.638
    dispatch_time_ms: 7.888
    learner:
      cur_lr: 0.0012251350563019514
      grad_gnorm: 40.0
      policy_entropy: 18.938688278198242
      policy_loss: 6.171757698059082
      var_gnorm: 49.60993957519531
      vf_explained_var: 0.3458501696586609
      vf_loss: 31.07200813293457
    num_steps_sampled: 2030000
    num_steps_trained: 2030000
    wait_time_ms: 100.406
  iterations_since_restore: 406
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4874.2810089588165
  time_this_iter_s: 11.252249717712402
  time_total_s: 4874.2810089588165
  timestamp: 1593998905
  timesteps_since_restore: 2030000
  timesteps_this_iter: 5000
  timesteps_total: 2030000
  training_iteration: 406
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4874 s, 406 iter, 2030000 ts, 517 rew

agent-1: 125.0
agent-2: 146.0
agent-3: 126.0
agent-4: 134.0
agent-5: 115.0
Sum Reward: 646.0
Avg Reward: 129.2
Min Reward: 115.0
Gini Coefficient: 0.04396284829721362
20:20 Ratio: 1.2695652173913043
Max-min Ratio: 1.2695652173913043
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-28-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 519.19
  episode_reward_min: 298.0
  episodes_this_iter: 1
  episodes_total: 406
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.065
    dispatch_time_ms: 5.383
    learner:
      cur_lr: 0.0012248019920662045
      grad_gnorm: 40.0
      policy_entropy: 29.337913513183594
      policy_loss: -23.153995513916016
      var_gnorm: 49.67554473876953
      vf_explained_var: 0.9630914926528931
      vf_loss: 21.856853485107422
    num_steps_sampled: 2035000
    num_steps_trained: 2035000
    wait_time_ms: 106.356
  iterations_since_restore: 407
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4885.494972229004
  time_this_iter_s: 11.213963270187378
  time_total_s: 4885.494972229004
  timestamp: 1593998916
  timesteps_since_restore: 2035000
  timesteps_this_iter: 5000
  timesteps_total: 2035000
  training_iteration: 407
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4885 s, 407 iter, 2035000 ts, 519 rew

agent-1: 155.0
agent-2: 99.0
agent-3: 190.0
agent-4: 172.0
agent-5: 118.0
Sum Reward: 734.0
Avg Reward: 146.8
Min Reward: 99.0
Gini Coefficient: 0.12861035422343325
20:20 Ratio: 1.9191919191919191
Max-min Ratio: 1.9191919191919191
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-28-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 522.28
  episode_reward_min: 298.0
  episodes_this_iter: 1
  episodes_total: 407
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.577
    dispatch_time_ms: 9.496
    learner:
      cur_lr: 0.0012244690442457795
      grad_gnorm: 40.000003814697266
      policy_entropy: 24.85149383544922
      policy_loss: -23.909854888916016
      var_gnorm: 49.775753021240234
      vf_explained_var: 0.4097771644592285
      vf_loss: 68.6014175415039
    num_steps_sampled: 2040000
    num_steps_trained: 2040000
    wait_time_ms: 97.876
  iterations_since_restore: 408
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4896.501519918442
  time_this_iter_s: 11.006547689437866
  time_total_s: 4896.501519918442
  timestamp: 1593998927
  timesteps_since_restore: 2040000
  timesteps_this_iter: 5000
  timesteps_total: 2040000
  training_iteration: 408
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4896 s, 408 iter, 2040000 ts, 522 rew

agent-1: 153.0
agent-2: 130.0
agent-3: 128.0
agent-4: 167.0
agent-5: 135.0
Sum Reward: 713.0
Avg Reward: 142.6
Min Reward: 128.0
Gini Coefficient: 0.05666199158485274
20:20 Ratio: 1.3046875
Max-min Ratio: 1.3046875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-28-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 525.35
  episode_reward_min: 298.0
  episodes_this_iter: 1
  episodes_total: 408
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.173
    dispatch_time_ms: 9.891
    learner:
      cur_lr: 0.0012241359800100327
      grad_gnorm: 40.000003814697266
      policy_entropy: 18.372543334960938
      policy_loss: -3.980245351791382
      var_gnorm: 49.84794235229492
      vf_explained_var: -0.5023959875106812
      vf_loss: 146.17608642578125
    num_steps_sampled: 2045000
    num_steps_trained: 2045000
    wait_time_ms: 98.456
  iterations_since_restore: 409
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4907.437889814377
  time_this_iter_s: 10.936369895935059
  time_total_s: 4907.437889814377
  timestamp: 1593998938
  timesteps_since_restore: 2045000
  timesteps_this_iter: 5000
  timesteps_total: 2045000
  training_iteration: 409
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4907 s, 409 iter, 2045000 ts, 525 rew

agent-1: 110.0
agent-2: 120.0
agent-3: 105.0
agent-4: 114.0
agent-5: 115.0
Sum Reward: 564.0
Avg Reward: 112.8
Min Reward: 105.0
Gini Coefficient: 0.024822695035460994
20:20 Ratio: 1.1428571428571428
Max-min Ratio: 1.1428571428571428
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-29-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 527.95
  episode_reward_min: 298.0
  episodes_this_iter: 1
  episodes_total: 409
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.569
    dispatch_time_ms: 8.512
    learner:
      cur_lr: 0.0012238030321896076
      grad_gnorm: 40.000003814697266
      policy_entropy: 16.67101287841797
      policy_loss: 6.366430759429932
      var_gnorm: 49.91278839111328
      vf_explained_var: 0.026104271411895752
      vf_loss: 40.1536865234375
    num_steps_sampled: 2050000
    num_steps_trained: 2050000
    wait_time_ms: 96.689
  iterations_since_restore: 410
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4918.350100278854
  time_this_iter_s: 10.912210464477539
  time_total_s: 4918.350100278854
  timestamp: 1593998949
  timesteps_since_restore: 2050000
  timesteps_this_iter: 5000
  timesteps_total: 2050000
  training_iteration: 410
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4918 s, 410 iter, 2050000 ts, 528 rew

agent-1: 160.0
agent-2: 118.0
agent-3: 141.0
agent-4: 113.0
agent-5: 167.0
Sum Reward: 699.0
Avg Reward: 139.8
Min Reward: 113.0
Gini Coefficient: 0.08583690987124463
20:20 Ratio: 1.4778761061946903
Max-min Ratio: 1.4778761061946903
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-29-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 528.28
  episode_reward_min: 298.0
  episodes_this_iter: 1
  episodes_total: 410
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.707
    dispatch_time_ms: 6.985
    learner:
      cur_lr: 0.0012234699679538608
      grad_gnorm: 40.0
      policy_entropy: 25.395938873291016
      policy_loss: -9.430889129638672
      var_gnorm: 49.89459991455078
      vf_explained_var: 0.39461565017700195
      vf_loss: 27.418466567993164
    num_steps_sampled: 2055000
    num_steps_trained: 2055000
    wait_time_ms: 95.339
  iterations_since_restore: 411
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4928.948559045792
  time_this_iter_s: 10.598458766937256
  time_total_s: 4928.948559045792
  timestamp: 1593998959
  timesteps_since_restore: 2055000
  timesteps_this_iter: 5000
  timesteps_total: 2055000
  training_iteration: 411
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4928 s, 411 iter, 2055000 ts, 528 rew

agent-1: 137.0
agent-2: 138.0
agent-3: 110.0
agent-4: 164.0
agent-5: 136.0
Sum Reward: 685.0
Avg Reward: 137.0
Min Reward: 110.0
Gini Coefficient: 0.06423357664233577
20:20 Ratio: 1.490909090909091
Max-min Ratio: 1.490909090909091
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-29-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 530.82
  episode_reward_min: 298.0
  episodes_this_iter: 1
  episodes_total: 411
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.189
    dispatch_time_ms: 6.74
    learner:
      cur_lr: 0.0012231370201334357
      grad_gnorm: 16.189926147460938
      policy_entropy: 28.336196899414062
      policy_loss: -4.754377365112305
      var_gnorm: 49.91387939453125
      vf_explained_var: 0.31203514337539673
      vf_loss: 39.038753509521484
    num_steps_sampled: 2060000
    num_steps_trained: 2060000
    wait_time_ms: 93.99
  iterations_since_restore: 412
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4945.435736179352
  time_this_iter_s: 16.48717713356018
  time_total_s: 4945.435736179352
  timestamp: 1593998976
  timesteps_since_restore: 2060000
  timesteps_this_iter: 5000
  timesteps_total: 2060000
  training_iteration: 412
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4945 s, 412 iter, 2060000 ts, 531 rew

agent-1: 160.0
agent-2: 162.0
agent-3: 107.0
agent-4: 198.0
agent-5: 116.0
Sum Reward: 743.0
Avg Reward: 148.6
Min Reward: 107.0
Gini Coefficient: 0.12274562584118438
20:20 Ratio: 1.8504672897196262
Max-min Ratio: 1.8504672897196262
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-29-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 533.08
  episode_reward_min: 298.0
  episodes_this_iter: 1
  episodes_total: 412
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.994
    dispatch_time_ms: 7.008
    learner:
      cur_lr: 0.0012228039558976889
      grad_gnorm: 27.974973678588867
      policy_entropy: 23.484159469604492
      policy_loss: 12.632698059082031
      var_gnorm: 49.936763763427734
      vf_explained_var: 0.5516105890274048
      vf_loss: 32.38677215576172
    num_steps_sampled: 2065000
    num_steps_trained: 2065000
    wait_time_ms: 97.827
  iterations_since_restore: 413
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4956.173339128494
  time_this_iter_s: 10.737602949142456
  time_total_s: 4956.173339128494
  timestamp: 1593998987
  timesteps_since_restore: 2065000
  timesteps_this_iter: 5000
  timesteps_total: 2065000
  training_iteration: 413
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4956 s, 413 iter, 2065000 ts, 533 rew

agent-1: 123.0
agent-2: 140.0
agent-3: 128.0
agent-4: 123.0
agent-5: 146.0
Sum Reward: 660.0
Avg Reward: 132.0
Min Reward: 123.0
Gini Coefficient: 0.038181818181818185
20:20 Ratio: 1.1869918699186992
Max-min Ratio: 1.1869918699186992
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-29-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 534.41
  episode_reward_min: 298.0
  episodes_this_iter: 1
  episodes_total: 413
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.17
    dispatch_time_ms: 6.569
    learner:
      cur_lr: 0.0012224710080772638
      grad_gnorm: 40.000003814697266
      policy_entropy: 15.218402862548828
      policy_loss: 9.694437980651855
      var_gnorm: 50.02046203613281
      vf_explained_var: 0.690245509147644
      vf_loss: 23.334373474121094
    num_steps_sampled: 2070000
    num_steps_trained: 2070000
    wait_time_ms: 90.335
  iterations_since_restore: 414
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4967.024183988571
  time_this_iter_s: 10.850844860076904
  time_total_s: 4967.024183988571
  timestamp: 1593998998
  timesteps_since_restore: 2070000
  timesteps_this_iter: 5000
  timesteps_total: 2070000
  training_iteration: 414
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4967 s, 414 iter, 2070000 ts, 534 rew

agent-1: 118.0
agent-2: 157.0
agent-3: 131.0
agent-4: 151.0
agent-5: 129.0
Sum Reward: 686.0
Avg Reward: 137.2
Min Reward: 118.0
Gini Coefficient: 0.05830903790087463
20:20 Ratio: 1.3305084745762712
Max-min Ratio: 1.3305084745762712
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-30-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 535.32
  episode_reward_min: 298.0
  episodes_this_iter: 1
  episodes_total: 414
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.95
    dispatch_time_ms: 6.321
    learner:
      cur_lr: 0.001222137943841517
      grad_gnorm: 39.999996185302734
      policy_entropy: 35.275630950927734
      policy_loss: -10.365662574768066
      var_gnorm: 50.09410858154297
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 11.705737113952637
    num_steps_sampled: 2075000
    num_steps_trained: 2075000
    wait_time_ms: 108.466
  iterations_since_restore: 415
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4977.936693191528
  time_this_iter_s: 10.912509202957153
  time_total_s: 4977.936693191528
  timestamp: 1593999009
  timesteps_since_restore: 2075000
  timesteps_this_iter: 5000
  timesteps_total: 2075000
  training_iteration: 415
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4977 s, 415 iter, 2075000 ts, 535 rew

agent-1: 92.0
agent-2: 128.0
agent-3: 94.0
agent-4: 177.0
agent-5: 166.0
Sum Reward: 657.0
Avg Reward: 131.4
Min Reward: 92.0
Gini Coefficient: 0.14733637747336378
20:20 Ratio: 1.923913043478261
Max-min Ratio: 1.923913043478261
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-30-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 537.87
  episode_reward_min: 298.0
  episodes_this_iter: 1
  episodes_total: 415
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.04
    dispatch_time_ms: 6.589
    learner:
      cur_lr: 0.001221804996021092
      grad_gnorm: 39.999996185302734
      policy_entropy: 25.506715774536133
      policy_loss: -3.504861354827881
      var_gnorm: 50.034339904785156
      vf_explained_var: 0.23185908794403076
      vf_loss: 5.045486927032471
    num_steps_sampled: 2080000
    num_steps_trained: 2080000
    wait_time_ms: 98.797
  iterations_since_restore: 416
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 4989.058624982834
  time_this_iter_s: 11.121931791305542
  time_total_s: 4989.058624982834
  timestamp: 1593999020
  timesteps_since_restore: 2080000
  timesteps_this_iter: 5000
  timesteps_total: 2080000
  training_iteration: 416
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 4989 s, 416 iter, 2080000 ts, 538 rew

agent-1: 133.0
agent-2: 114.0
agent-3: 115.0
agent-4: 158.0
agent-5: 115.0
Sum Reward: 635.0
Avg Reward: 127.0
Min Reward: 114.0
Gini Coefficient: 0.06677165354330708
20:20 Ratio: 1.3859649122807018
Max-min Ratio: 1.3859649122807018
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-30-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 539.35
  episode_reward_min: 298.0
  episodes_this_iter: 1
  episodes_total: 416
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.088
    dispatch_time_ms: 6.991
    learner:
      cur_lr: 0.001221472048200667
      grad_gnorm: 40.000003814697266
      policy_entropy: 14.776078224182129
      policy_loss: -2.6638097763061523
      var_gnorm: 50.0700798034668
      vf_explained_var: 0.27944397926330566
      vf_loss: 37.79167175292969
    num_steps_sampled: 2085000
    num_steps_trained: 2085000
    wait_time_ms: 103.17
  iterations_since_restore: 417
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5000.435979604721
  time_this_iter_s: 11.377354621887207
  time_total_s: 5000.435979604721
  timestamp: 1593999031
  timesteps_since_restore: 2085000
  timesteps_this_iter: 5000
  timesteps_total: 2085000
  training_iteration: 417
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5000 s, 417 iter, 2085000 ts, 539 rew

agent-1: 96.0
agent-2: 121.0
agent-3: 111.0
agent-4: 143.0
agent-5: 152.0
Sum Reward: 623.0
Avg Reward: 124.6
Min Reward: 96.0
Gini Coefficient: 0.09245585874799359
20:20 Ratio: 1.5833333333333333
Max-min Ratio: 1.5833333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-30-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 539.18
  episode_reward_min: 298.0
  episodes_this_iter: 1
  episodes_total: 417
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.053
    dispatch_time_ms: 6.872
    learner:
      cur_lr: 0.00122113898396492
      grad_gnorm: 39.999996185302734
      policy_entropy: 11.411517143249512
      policy_loss: 10.137641906738281
      var_gnorm: 50.10466766357422
      vf_explained_var: -0.1982508897781372
      vf_loss: 46.363033294677734
    num_steps_sampled: 2090000
    num_steps_trained: 2090000
    wait_time_ms: 106.959
  iterations_since_restore: 418
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5012.04047036171
  time_this_iter_s: 11.604490756988525
  time_total_s: 5012.04047036171
  timestamp: 1593999043
  timesteps_since_restore: 2090000
  timesteps_this_iter: 5000
  timesteps_total: 2090000
  training_iteration: 418
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5012 s, 418 iter, 2090000 ts, 539 rew

agent-1: 84.0
agent-2: 88.0
agent-3: 77.0
agent-4: 80.0
agent-5: 102.0
Sum Reward: 431.0
Avg Reward: 86.2
Min Reward: 77.0
Gini Coefficient: 0.05382830626450116
20:20 Ratio: 1.3246753246753247
Max-min Ratio: 1.3246753246753247
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-30-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 537.93
  episode_reward_min: 298.0
  episodes_this_iter: 1
  episodes_total: 418
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.131
    dispatch_time_ms: 19.367
    learner:
      cur_lr: 0.001220806036144495
      grad_gnorm: 40.0
      policy_entropy: 28.50692367553711
      policy_loss: -6.566294193267822
      var_gnorm: 50.16944885253906
      vf_explained_var: 0.6417375802993774
      vf_loss: 11.668413162231445
    num_steps_sampled: 2095000
    num_steps_trained: 2095000
    wait_time_ms: 91.975
  iterations_since_restore: 419
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5023.824292182922
  time_this_iter_s: 11.783821821212769
  time_total_s: 5023.824292182922
  timestamp: 1593999055
  timesteps_since_restore: 2095000
  timesteps_this_iter: 5000
  timesteps_total: 2095000
  training_iteration: 419
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5023 s, 419 iter, 2095000 ts, 538 rew

agent-1: 95.0
agent-2: 110.0
agent-3: 86.0
agent-4: 89.0
agent-5: 109.0
Sum Reward: 489.0
Avg Reward: 97.8
Min Reward: 86.0
Gini Coefficient: 0.05562372188139059
20:20 Ratio: 1.2790697674418605
Max-min Ratio: 1.2790697674418605
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-31-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 538.47
  episode_reward_min: 298.0
  episodes_this_iter: 1
  episodes_total: 419
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.483
    dispatch_time_ms: 17.438
    learner:
      cur_lr: 0.0012204729719087481
      grad_gnorm: 40.0
      policy_entropy: 27.86330795288086
      policy_loss: -8.66051959991455
      var_gnorm: 50.201812744140625
      vf_explained_var: 0.6900321245193481
      vf_loss: 3.3803107738494873
    num_steps_sampled: 2100000
    num_steps_trained: 2100000
    wait_time_ms: 94.691
  iterations_since_restore: 420
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5035.527631759644
  time_this_iter_s: 11.703339576721191
  time_total_s: 5035.527631759644
  timestamp: 1593999066
  timesteps_since_restore: 2100000
  timesteps_this_iter: 5000
  timesteps_total: 2100000
  training_iteration: 420
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5035 s, 420 iter, 2100000 ts, 538 rew

agent-1: 144.0
agent-2: 144.0
agent-3: 96.0
agent-4: 100.0
agent-5: 101.0
Sum Reward: 585.0
Avg Reward: 117.0
Min Reward: 96.0
Gini Coefficient: 0.09572649572649573
20:20 Ratio: 1.5
Max-min Ratio: 1.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-31-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 539.43
  episode_reward_min: 298.0
  episodes_this_iter: 1
  episodes_total: 420
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.744
    dispatch_time_ms: 24.435
    learner:
      cur_lr: 0.0012201400240883231
      grad_gnorm: 35.147857666015625
      policy_entropy: 28.941179275512695
      policy_loss: -6.332980155944824
      var_gnorm: 50.29885482788086
      vf_explained_var: 0.9821944832801819
      vf_loss: 1.884774088859558
    num_steps_sampled: 2105000
    num_steps_trained: 2105000
    wait_time_ms: 97.592
  iterations_since_restore: 421
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5047.364246368408
  time_this_iter_s: 11.836614608764648
  time_total_s: 5047.364246368408
  timestamp: 1593999078
  timesteps_since_restore: 2105000
  timesteps_this_iter: 5000
  timesteps_total: 2105000
  training_iteration: 421
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5047 s, 421 iter, 2105000 ts, 539 rew

W0705 21:31:22.094184  2378 client_connection.cc:255] [worker]ProcessMessage with type 19 took 330 ms.
W0705 21:31:22.444952  2378 node_manager.cc:250] Last heartbeat was sent 780 ms ago 
agent-1: 126.0
agent-2: 141.0
agent-3: 76.0
agent-4: 89.0
agent-5: 75.0
Sum Reward: 507.0
Avg Reward: 101.4
Min Reward: 75.0
Gini Coefficient: 0.14358974358974358
20:20 Ratio: 1.88
Max-min Ratio: 1.88
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-31-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 539.28
  episode_reward_min: 298.0
  episodes_this_iter: 1
  episodes_total: 421
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.085
    dispatch_time_ms: 15.561
    learner:
      cur_lr: 0.0012198069598525763
      grad_gnorm: 40.0
      policy_entropy: 29.635997772216797
      policy_loss: 5.491515159606934
      var_gnorm: 50.34987258911133
      vf_explained_var: 0.13764721155166626
      vf_loss: 24.402421951293945
    num_steps_sampled: 2110000
    num_steps_trained: 2110000
    wait_time_ms: 102.416
  iterations_since_restore: 422
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5061.548706769943
  time_this_iter_s: 14.184460401535034
  time_total_s: 5061.548706769943
  timestamp: 1593999092
  timesteps_since_restore: 2110000
  timesteps_this_iter: 5000
  timesteps_total: 2110000
  training_iteration: 422
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5061 s, 422 iter, 2110000 ts, 539 rew

agent-1: 68.0
agent-2: 113.0
agent-3: 82.0
agent-4: 112.0
agent-5: 49.0
Sum Reward: 424.0
Avg Reward: 84.8
Min Reward: 49.0
Gini Coefficient: 0.16226415094339622
20:20 Ratio: 2.306122448979592
Max-min Ratio: 2.306122448979592
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-31-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 539.75
  episode_reward_min: 298.0
  episodes_this_iter: 1
  episodes_total: 422
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.894
    dispatch_time_ms: 29.31
    learner:
      cur_lr: 0.0012194740120321512
      grad_gnorm: 27.28859519958496
      policy_entropy: 26.23625373840332
      policy_loss: -9.217425346374512
      var_gnorm: 50.3422737121582
      vf_explained_var: 0.8146544098854065
      vf_loss: 3.8647820949554443
    num_steps_sampled: 2115000
    num_steps_trained: 2115000
    wait_time_ms: 91.947
  iterations_since_restore: 423
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5073.723305463791
  time_this_iter_s: 12.174598693847656
  time_total_s: 5073.723305463791
  timestamp: 1593999105
  timesteps_since_restore: 2115000
  timesteps_this_iter: 5000
  timesteps_total: 2115000
  training_iteration: 423
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5073 s, 423 iter, 2115000 ts, 540 rew

agent-1: 100.0
agent-2: 124.0
agent-3: 75.0
agent-4: 102.0
agent-5: 98.0
Sum Reward: 499.0
Avg Reward: 99.8
Min Reward: 75.0
Gini Coefficient: 0.08176352705410822
20:20 Ratio: 1.6533333333333333
Max-min Ratio: 1.6533333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-32-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 540.48
  episode_reward_min: 298.0
  episodes_this_iter: 1
  episodes_total: 423
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.196
    dispatch_time_ms: 16.207
    learner:
      cur_lr: 0.0012191409477964044
      grad_gnorm: 12.986808776855469
      policy_entropy: 30.523502349853516
      policy_loss: -3.6274518966674805
      var_gnorm: 50.293663024902344
      vf_explained_var: 0.849737823009491
      vf_loss: 2.3605518341064453
    num_steps_sampled: 2120000
    num_steps_trained: 2120000
    wait_time_ms: 96.772
  iterations_since_restore: 424
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5084.722663164139
  time_this_iter_s: 10.9993577003479
  time_total_s: 5084.722663164139
  timestamp: 1593999134
  timesteps_since_restore: 2120000
  timesteps_this_iter: 5000
  timesteps_total: 2120000
  training_iteration: 424
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5084 s, 424 iter, 2120000 ts, 540 rew

agent-1: 58.0
agent-2: 78.0
agent-3: 97.0
agent-4: 108.0
agent-5: 78.0
Sum Reward: 419.0
Avg Reward: 83.8
Min Reward: 58.0
Gini Coefficient: 0.11360381861575179
20:20 Ratio: 1.8620689655172413
Max-min Ratio: 1.8620689655172413
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-32-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 539.75
  episode_reward_min: 298.0
  episodes_this_iter: 1
  episodes_total: 424
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.434
    dispatch_time_ms: 13.135
    learner:
      cur_lr: 0.0012188079999759793
      grad_gnorm: 39.999996185302734
      policy_entropy: 8.302225112915039
      policy_loss: 10.901711463928223
      var_gnorm: 50.26893615722656
      vf_explained_var: 0.3536345362663269
      vf_loss: 61.77611541748047
    num_steps_sampled: 2125000
    num_steps_trained: 2125000
    wait_time_ms: 100.548
  iterations_since_restore: 425
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5096.833646297455
  time_this_iter_s: 12.11098313331604
  time_total_s: 5096.833646297455
  timestamp: 1593999146
  timesteps_since_restore: 2125000
  timesteps_this_iter: 5000
  timesteps_total: 2125000
  training_iteration: 425
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5096 s, 425 iter, 2125000 ts, 540 rew

agent-1: 91.0
agent-2: 81.0
agent-3: 77.0
agent-4: 95.0
agent-5: 83.0
Sum Reward: 427.0
Avg Reward: 85.4
Min Reward: 77.0
Gini Coefficient: 0.04309133489461359
20:20 Ratio: 1.2337662337662338
Max-min Ratio: 1.2337662337662338
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-32-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 539.99
  episode_reward_min: 298.0
  episodes_this_iter: 1
  episodes_total: 425
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.716
    dispatch_time_ms: 18.532
    learner:
      cur_lr: 0.0012184750521555543
      grad_gnorm: 40.0
      policy_entropy: 31.963525772094727
      policy_loss: -11.667491912841797
      var_gnorm: 50.24049758911133
      vf_explained_var: 0.24623429775238037
      vf_loss: 9.401952743530273
    num_steps_sampled: 2130000
    num_steps_trained: 2130000
    wait_time_ms: 105.002
  iterations_since_restore: 426
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5108.863990783691
  time_this_iter_s: 12.030344486236572
  time_total_s: 5108.863990783691
  timestamp: 1593999158
  timesteps_since_restore: 2130000
  timesteps_this_iter: 5000
  timesteps_total: 2130000
  training_iteration: 426
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5108 s, 426 iter, 2130000 ts, 540 rew

agent-1: 91.0
agent-2: 74.0
agent-3: 65.0
agent-4: 74.0
agent-5: 73.0
Sum Reward: 377.0
Avg Reward: 75.4
Min Reward: 65.0
Gini Coefficient: 0.05623342175066313
20:20 Ratio: 1.4
Max-min Ratio: 1.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-32-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 539.47
  episode_reward_min: 298.0
  episodes_this_iter: 1
  episodes_total: 426
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.161
    dispatch_time_ms: 7.642
    learner:
      cur_lr: 0.0012181419879198074
      grad_gnorm: 40.0
      policy_entropy: 2.2744970321655273
      policy_loss: 1.520031452178955
      var_gnorm: 50.178749084472656
      vf_explained_var: 0.5793343782424927
      vf_loss: 28.12631607055664
    num_steps_sampled: 2135000
    num_steps_trained: 2135000
    wait_time_ms: 98.028
  iterations_since_restore: 427
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5120.7261073589325
  time_this_iter_s: 11.862116575241089
  time_total_s: 5120.7261073589325
  timestamp: 1593999170
  timesteps_since_restore: 2135000
  timesteps_this_iter: 5000
  timesteps_total: 2135000
  training_iteration: 427
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5120 s, 427 iter, 2135000 ts, 539 rew

agent-1: 91.0
agent-2: 117.0
agent-3: 119.0
agent-4: 88.0
agent-5: 81.0
Sum Reward: 496.0
Avg Reward: 99.2
Min Reward: 81.0
Gini Coefficient: 0.0846774193548387
20:20 Ratio: 1.4691358024691359
Max-min Ratio: 1.4691358024691359
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-33-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 539.2
  episode_reward_min: 298.0
  episodes_this_iter: 1
  episodes_total: 427
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.847
    dispatch_time_ms: 7.507
    learner:
      cur_lr: 0.0012178090400993824
      grad_gnorm: 39.99999237060547
      policy_entropy: 5.6045637130737305
      policy_loss: 2.518571138381958
      var_gnorm: 50.22883987426758
      vf_explained_var: 0.2860342264175415
      vf_loss: 83.47930908203125
    num_steps_sampled: 2140000
    num_steps_trained: 2140000
    wait_time_ms: 103.253
  iterations_since_restore: 428
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5132.350121498108
  time_this_iter_s: 11.624014139175415
  time_total_s: 5132.350121498108
  timestamp: 1593999182
  timesteps_since_restore: 2140000
  timesteps_this_iter: 5000
  timesteps_total: 2140000
  training_iteration: 428
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5132 s, 428 iter, 2140000 ts, 539 rew

agent-1: 100.0
agent-2: 111.0
agent-3: 95.0
agent-4: 105.0
agent-5: 92.0
Sum Reward: 503.0
Avg Reward: 100.6
Min Reward: 92.0
Gini Coefficient: 0.038170974155069586
20:20 Ratio: 1.2065217391304348
Max-min Ratio: 1.2065217391304348
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-33-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 539.38
  episode_reward_min: 298.0
  episodes_this_iter: 1
  episodes_total: 428
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.952
    dispatch_time_ms: 6.81
    learner:
      cur_lr: 0.0012174759758636355
      grad_gnorm: 16.754796981811523
      policy_entropy: 15.945357322692871
      policy_loss: -1.365318775177002
      var_gnorm: 50.3049430847168
      vf_explained_var: 0.0
      vf_loss: 0.33952048420906067
    num_steps_sampled: 2145000
    num_steps_trained: 2145000
    wait_time_ms: 104.22
  iterations_since_restore: 429
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5144.169140338898
  time_this_iter_s: 11.819018840789795
  time_total_s: 5144.169140338898
  timestamp: 1593999194
  timesteps_since_restore: 2145000
  timesteps_this_iter: 5000
  timesteps_total: 2145000
  training_iteration: 429
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5144 s, 429 iter, 2145000 ts, 539 rew

agent-1: 90.0
agent-2: 121.0
agent-3: 108.0
agent-4: 87.0
agent-5: 91.0
Sum Reward: 497.0
Avg Reward: 99.4
Min Reward: 87.0
Gini Coefficient: 0.06921529175050302
20:20 Ratio: 1.3908045977011494
Max-min Ratio: 1.3908045977011494
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-33-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 540.79
  episode_reward_min: 298.0
  episodes_this_iter: 1
  episodes_total: 429
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.654
    dispatch_time_ms: 10.54
    learner:
      cur_lr: 0.0012171430280432105
      grad_gnorm: 36.627586364746094
      policy_entropy: 10.614618301391602
      policy_loss: -3.115645408630371
      var_gnorm: 50.30843734741211
      vf_explained_var: 0.7235552668571472
      vf_loss: 13.66054630279541
    num_steps_sampled: 2150000
    num_steps_trained: 2150000
    wait_time_ms: 105.467
  iterations_since_restore: 430
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5155.8497614860535
  time_this_iter_s: 11.680621147155762
  time_total_s: 5155.8497614860535
  timestamp: 1593999205
  timesteps_since_restore: 2150000
  timesteps_this_iter: 5000
  timesteps_total: 2150000
  training_iteration: 430
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5155 s, 430 iter, 2150000 ts, 541 rew

agent-1: 85.0
agent-2: 103.0
agent-3: 89.0
agent-4: 93.0
agent-5: 131.0
Sum Reward: 501.0
Avg Reward: 100.2
Min Reward: 85.0
Gini Coefficient: 0.0846307385229541
20:20 Ratio: 1.5411764705882354
Max-min Ratio: 1.5411764705882354
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-33-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 542.45
  episode_reward_min: 298.0
  episodes_this_iter: 1
  episodes_total: 430
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.903
    dispatch_time_ms: 8.767
    learner:
      cur_lr: 0.0012168099638074636
      grad_gnorm: 24.983125686645508
      policy_entropy: 10.047806739807129
      policy_loss: 2.8334662914276123
      var_gnorm: 50.35283660888672
      vf_explained_var: -0.999362587928772
      vf_loss: 65.55277252197266
    num_steps_sampled: 2155000
    num_steps_trained: 2155000
    wait_time_ms: 102.799
  iterations_since_restore: 431
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5167.517809152603
  time_this_iter_s: 11.668047666549683
  time_total_s: 5167.517809152603
  timestamp: 1593999217
  timesteps_since_restore: 2155000
  timesteps_this_iter: 5000
  timesteps_total: 2155000
  training_iteration: 431
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5167 s, 431 iter, 2155000 ts, 542 rew

agent-1: 91.0
agent-2: 74.0
agent-3: 111.0
agent-4: 61.0
agent-5: 82.0
Sum Reward: 419.0
Avg Reward: 83.8
Min Reward: 61.0
Gini Coefficient: 0.1116945107398568
20:20 Ratio: 1.819672131147541
Max-min Ratio: 1.819672131147541
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-33-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 543.66
  episode_reward_min: 339.0
  episodes_this_iter: 1
  episodes_total: 431
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.26
    dispatch_time_ms: 6.57
    learner:
      cur_lr: 0.0012164770159870386
      grad_gnorm: 40.0
      policy_entropy: 5.805726528167725
      policy_loss: -2.6192519664764404
      var_gnorm: 50.331756591796875
      vf_explained_var: 0.610605776309967
      vf_loss: 61.05051040649414
    num_steps_sampled: 2160000
    num_steps_trained: 2160000
    wait_time_ms: 102.833
  iterations_since_restore: 432
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5179.065029621124
  time_this_iter_s: 11.547220468521118
  time_total_s: 5179.065029621124
  timestamp: 1593999229
  timesteps_since_restore: 2160000
  timesteps_this_iter: 5000
  timesteps_total: 2160000
  training_iteration: 432
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5179 s, 432 iter, 2160000 ts, 544 rew

agent-1: 50.0
agent-2: 60.0
agent-3: 64.0
agent-4: 71.0
agent-5: 58.0
Sum Reward: 303.0
Avg Reward: 60.6
Min Reward: 50.0
Gini Coefficient: 0.06336633663366337
20:20 Ratio: 1.42
Max-min Ratio: 1.42
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-34-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 542.47
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 432
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.745
    dispatch_time_ms: 7.832
    learner:
      cur_lr: 0.0012161439517512918
      grad_gnorm: 40.0
      policy_entropy: 5.683570384979248
      policy_loss: 2.939709424972534
      var_gnorm: 50.391937255859375
      vf_explained_var: 0.8024865984916687
      vf_loss: 25.705913543701172
    num_steps_sampled: 2165000
    num_steps_trained: 2165000
    wait_time_ms: 109.169
  iterations_since_restore: 433
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5190.678630590439
  time_this_iter_s: 11.613600969314575
  time_total_s: 5190.678630590439
  timestamp: 1593999240
  timesteps_since_restore: 2165000
  timesteps_this_iter: 5000
  timesteps_total: 2165000
  training_iteration: 433
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5190 s, 433 iter, 2165000 ts, 542 rew

agent-1: 65.0
agent-2: 102.0
agent-3: 137.0
agent-4: 107.0
agent-5: 90.0
Sum Reward: 501.0
Avg Reward: 100.2
Min Reward: 65.0
Gini Coefficient: 0.1285429141716567
20:20 Ratio: 2.1076923076923078
Max-min Ratio: 2.1076923076923078
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-34-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 540.54
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 433
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.715
    dispatch_time_ms: 6.688
    learner:
      cur_lr: 0.0012158110039308667
      grad_gnorm: 40.0
      policy_entropy: 13.673381805419922
      policy_loss: -2.1453161239624023
      var_gnorm: 50.2890510559082
      vf_explained_var: -1.0
      vf_loss: 30.701679229736328
    num_steps_sampled: 2170000
    num_steps_trained: 2170000
    wait_time_ms: 115.549
  iterations_since_restore: 434
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5202.002261161804
  time_this_iter_s: 11.323630571365356
  time_total_s: 5202.002261161804
  timestamp: 1593999252
  timesteps_since_restore: 2170000
  timesteps_this_iter: 5000
  timesteps_total: 2170000
  training_iteration: 434
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5202 s, 434 iter, 2170000 ts, 541 rew

agent-1: 99.0
agent-2: 102.0
agent-3: 105.0
agent-4: 96.0
agent-5: 108.0
Sum Reward: 510.0
Avg Reward: 102.0
Min Reward: 96.0
Gini Coefficient: 0.023529411764705882
20:20 Ratio: 1.125
Max-min Ratio: 1.125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-34-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 541.77
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 434
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.741
    dispatch_time_ms: 9.745
    learner:
      cur_lr: 0.0012154780561104417
      grad_gnorm: 25.600727081298828
      policy_entropy: 21.53973388671875
      policy_loss: -1.9672915935516357
      var_gnorm: 50.32179260253906
      vf_explained_var: 0.0
      vf_loss: 0.6793040633201599
    num_steps_sampled: 2175000
    num_steps_trained: 2175000
    wait_time_ms: 934.947
  iterations_since_restore: 435
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5221.929457426071
  time_this_iter_s: 19.927196264266968
  time_total_s: 5221.929457426071
  timestamp: 1593999272
  timesteps_since_restore: 2175000
  timesteps_this_iter: 5000
  timesteps_total: 2175000
  training_iteration: 435
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5221 s, 435 iter, 2175000 ts, 542 rew

agent-1: 111.0
agent-2: 118.0
agent-3: 102.0
agent-4: 93.0
agent-5: 103.0
Sum Reward: 527.0
Avg Reward: 105.4
Min Reward: 93.0
Gini Coefficient: 0.044781783681214424
20:20 Ratio: 1.2688172043010753
Max-min Ratio: 1.2688172043010753
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-34-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 542.39
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 435
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.016
    dispatch_time_ms: 9.885
    learner:
      cur_lr: 0.0012151449918746948
      grad_gnorm: 39.999996185302734
      policy_entropy: 15.59841537475586
      policy_loss: -0.8719692230224609
      var_gnorm: 50.39947509765625
      vf_explained_var: 0.13853436708450317
      vf_loss: 14.009644508361816
    num_steps_sampled: 2180000
    num_steps_trained: 2180000
    wait_time_ms: 106.158
  iterations_since_restore: 436
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5232.72767496109
  time_this_iter_s: 10.798217535018921
  time_total_s: 5232.72767496109
  timestamp: 1593999282
  timesteps_since_restore: 2180000
  timesteps_this_iter: 5000
  timesteps_total: 2180000
  training_iteration: 436
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5232 s, 436 iter, 2180000 ts, 542 rew

agent-1: 125.0
agent-2: 159.0
agent-3: 106.0
agent-4: 115.0
agent-5: 86.0
Sum Reward: 591.0
Avg Reward: 118.2
Min Reward: 86.0
Gini Coefficient: 0.1116751269035533
20:20 Ratio: 1.8488372093023255
Max-min Ratio: 1.8488372093023255
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-34-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 544.72
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 436
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.891
    dispatch_time_ms: 6.6
    learner:
      cur_lr: 0.0012148120440542698
      grad_gnorm: 2.5334527492523193
      policy_entropy: 32.15223693847656
      policy_loss: -0.23891134560108185
      var_gnorm: 50.40239715576172
      vf_explained_var: 0.9957439303398132
      vf_loss: 0.03198236599564552
    num_steps_sampled: 2185000
    num_steps_trained: 2185000
    wait_time_ms: 114.285
  iterations_since_restore: 437
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5244.621153354645
  time_this_iter_s: 11.893478393554688
  time_total_s: 5244.621153354645
  timestamp: 1593999294
  timesteps_since_restore: 2185000
  timesteps_this_iter: 5000
  timesteps_total: 2185000
  training_iteration: 437
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5244 s, 437 iter, 2185000 ts, 545 rew

agent-1: 73.0
agent-2: 61.0
agent-3: 47.0
agent-4: 99.0
agent-5: 70.0
Sum Reward: 350.0
Avg Reward: 70.0
Min Reward: 47.0
Gini Coefficient: 0.13257142857142856
20:20 Ratio: 2.106382978723404
Max-min Ratio: 2.106382978723404
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-35-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 543.49
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 437
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.681
    dispatch_time_ms: 6.371
    learner:
      cur_lr: 0.001214478979818523
      grad_gnorm: 31.950218200683594
      policy_entropy: 19.701213836669922
      policy_loss: -0.7504841089248657
      var_gnorm: 50.540382385253906
      vf_explained_var: -1.0
      vf_loss: 7.877010345458984
    num_steps_sampled: 2190000
    num_steps_trained: 2190000
    wait_time_ms: 114.43
  iterations_since_restore: 438
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5255.882595300674
  time_this_iter_s: 11.261441946029663
  time_total_s: 5255.882595300674
  timestamp: 1593999306
  timesteps_since_restore: 2190000
  timesteps_this_iter: 5000
  timesteps_total: 2190000
  training_iteration: 438
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5255 s, 438 iter, 2190000 ts, 543 rew

agent-1: 163.0
agent-2: 109.0
agent-3: 112.0
agent-4: 84.0
agent-5: 125.0
Sum Reward: 593.0
Avg Reward: 118.6
Min Reward: 84.0
Gini Coefficient: 0.11736930860033727
20:20 Ratio: 1.9404761904761905
Max-min Ratio: 1.9404761904761905
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-35-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 543.34
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 438
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.54
    dispatch_time_ms: 7.028
    learner:
      cur_lr: 0.001214146031998098
      grad_gnorm: 40.0
      policy_entropy: 20.244945526123047
      policy_loss: 1.7981797456741333
      var_gnorm: 50.73740768432617
      vf_explained_var: 0.8856440782546997
      vf_loss: 30.236291885375977
    num_steps_sampled: 2195000
    num_steps_trained: 2195000
    wait_time_ms: 111.21
  iterations_since_restore: 439
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5267.3759570121765
  time_this_iter_s: 11.493361711502075
  time_total_s: 5267.3759570121765
  timestamp: 1593999317
  timesteps_since_restore: 2195000
  timesteps_this_iter: 5000
  timesteps_total: 2195000
  training_iteration: 439
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5267 s, 439 iter, 2195000 ts, 543 rew

agent-1: 125.0
agent-2: 121.0
agent-3: 109.0
agent-4: 148.0
agent-5: 88.0
Sum Reward: 591.0
Avg Reward: 118.2
Min Reward: 88.0
Gini Coefficient: 0.09204737732656515
20:20 Ratio: 1.6818181818181819
Max-min Ratio: 1.6818181818181819
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-35-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 543.54
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 439
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.628
    dispatch_time_ms: 5.294
    learner:
      cur_lr: 0.001213812967762351
      grad_gnorm: 2.239057779312134
      policy_entropy: 33.000247955322266
      policy_loss: -0.5263794660568237
      var_gnorm: 50.77832794189453
      vf_explained_var: 0.9957906603813171
      vf_loss: 0.030691860243678093
    num_steps_sampled: 2200000
    num_steps_trained: 2200000
    wait_time_ms: 106.952
  iterations_since_restore: 440
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5279.012269020081
  time_this_iter_s: 11.636312007904053
  time_total_s: 5279.012269020081
  timestamp: 1593999329
  timesteps_since_restore: 2200000
  timesteps_this_iter: 5000
  timesteps_total: 2200000
  training_iteration: 440
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5279 s, 440 iter, 2200000 ts, 544 rew

agent-1: 80.0
agent-2: 56.0
agent-3: 77.0
agent-4: 80.0
agent-5: 73.0
Sum Reward: 366.0
Avg Reward: 73.2
Min Reward: 56.0
Gini Coefficient: 0.060109289617486336
20:20 Ratio: 1.4285714285714286
Max-min Ratio: 1.4285714285714286
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-35-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 541.6
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 440
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.994
    dispatch_time_ms: 6.792
    learner:
      cur_lr: 0.001213480019941926
      grad_gnorm: 40.0
      policy_entropy: 6.0625481605529785
      policy_loss: 5.214122772216797
      var_gnorm: 50.81500244140625
      vf_explained_var: -1.0
      vf_loss: 72.22604370117188
    num_steps_sampled: 2205000
    num_steps_trained: 2205000
    wait_time_ms: 101.016
  iterations_since_restore: 441
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5290.927383184433
  time_this_iter_s: 11.915114164352417
  time_total_s: 5290.927383184433
  timestamp: 1593999341
  timesteps_since_restore: 2205000
  timesteps_this_iter: 5000
  timesteps_total: 2205000
  training_iteration: 441
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5290 s, 441 iter, 2205000 ts, 542 rew

agent-1: 102.0
agent-2: 107.0
agent-3: 59.0
agent-4: 116.0
agent-5: 91.0
Sum Reward: 475.0
Avg Reward: 95.0
Min Reward: 59.0
Gini Coefficient: 0.10947368421052632
20:20 Ratio: 1.9661016949152543
Max-min Ratio: 1.9661016949152543
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-35-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 541.07
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 441
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.113
    dispatch_time_ms: 6.028
    learner:
      cur_lr: 0.0012131469557061791
      grad_gnorm: 40.000003814697266
      policy_entropy: 17.35797882080078
      policy_loss: 11.047168731689453
      var_gnorm: 50.839385986328125
      vf_explained_var: -1.0
      vf_loss: 46.92601776123047
    num_steps_sampled: 2210000
    num_steps_trained: 2210000
    wait_time_ms: 111.259
  iterations_since_restore: 442
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5302.519417524338
  time_this_iter_s: 11.592034339904785
  time_total_s: 5302.519417524338
  timestamp: 1593999353
  timesteps_since_restore: 2210000
  timesteps_this_iter: 5000
  timesteps_total: 2210000
  training_iteration: 442
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5302 s, 442 iter, 2210000 ts, 541 rew

agent-1: 87.0
agent-2: 103.0
agent-3: 124.0
agent-4: 110.0
agent-5: 123.0
Sum Reward: 547.0
Avg Reward: 109.4
Min Reward: 87.0
Gini Coefficient: 0.06873857404021938
20:20 Ratio: 1.4252873563218391
Max-min Ratio: 1.4252873563218391
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-36-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 540.18
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 442
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.594
    dispatch_time_ms: 8.509
    learner:
      cur_lr: 0.0012128140078857541
      grad_gnorm: 40.0
      policy_entropy: 12.836811065673828
      policy_loss: 3.134242534637451
      var_gnorm: 50.86075973510742
      vf_explained_var: 0.3869849443435669
      vf_loss: 92.74774932861328
    num_steps_sampled: 2215000
    num_steps_trained: 2215000
    wait_time_ms: 107.022
  iterations_since_restore: 443
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5314.35231423378
  time_this_iter_s: 11.832896709442139
  time_total_s: 5314.35231423378
  timestamp: 1593999364
  timesteps_since_restore: 2215000
  timesteps_this_iter: 5000
  timesteps_total: 2215000
  training_iteration: 443
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5314 s, 443 iter, 2215000 ts, 540 rew

agent-1: 61.0
agent-2: 69.0
agent-3: 64.0
agent-4: 67.0
agent-5: 87.0
Sum Reward: 348.0
Avg Reward: 69.6
Min Reward: 61.0
Gini Coefficient: 0.06551724137931035
20:20 Ratio: 1.4262295081967213
Max-min Ratio: 1.4262295081967213
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-36-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 538.44
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 443
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.093
    dispatch_time_ms: 8.079
    learner:
      cur_lr: 0.0012124809436500072
      grad_gnorm: 4.216898441314697
      policy_entropy: 24.58441162109375
      policy_loss: -0.5515367984771729
      var_gnorm: 50.89133071899414
      vf_explained_var: 0.9953630566596985
      vf_loss: 0.04236041381955147
    num_steps_sampled: 2220000
    num_steps_trained: 2220000
    wait_time_ms: 111.877
  iterations_since_restore: 444
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5326.109606266022
  time_this_iter_s: 11.757292032241821
  time_total_s: 5326.109606266022
  timestamp: 1593999376
  timesteps_since_restore: 2220000
  timesteps_this_iter: 5000
  timesteps_total: 2220000
  training_iteration: 444
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5326 s, 444 iter, 2220000 ts, 538 rew

agent-1: 79.0
agent-2: 80.0
agent-3: 73.0
agent-4: 54.0
agent-5: 78.0
Sum Reward: 364.0
Avg Reward: 72.8
Min Reward: 54.0
Gini Coefficient: 0.06373626373626373
20:20 Ratio: 1.4814814814814814
Max-min Ratio: 1.4814814814814814
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-36-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 536.78
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 444
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.153
    dispatch_time_ms: 7.111
    learner:
      cur_lr: 0.0012121479958295822
      grad_gnorm: 4.975063800811768
      policy_entropy: 21.51256561279297
      policy_loss: -0.21255752444267273
      var_gnorm: 50.92821502685547
      vf_explained_var: 0.19304555654525757
      vf_loss: 1.3867077827453613
    num_steps_sampled: 2225000
    num_steps_trained: 2225000
    wait_time_ms: 96.952
  iterations_since_restore: 445
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5338.10528421402
  time_this_iter_s: 11.995677947998047
  time_total_s: 5338.10528421402
  timestamp: 1593999388
  timesteps_since_restore: 2225000
  timesteps_this_iter: 5000
  timesteps_total: 2225000
  training_iteration: 445
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5338 s, 445 iter, 2225000 ts, 537 rew

agent-1: 75.0
agent-2: 60.0
agent-3: 109.0
agent-4: 95.0
agent-5: 78.0
Sum Reward: 417.0
Avg Reward: 83.4
Min Reward: 60.0
Gini Coefficient: 0.11318944844124701
20:20 Ratio: 1.8166666666666667
Max-min Ratio: 1.8166666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-36-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 534.75
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 445
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.529
    dispatch_time_ms: 7.189
    learner:
      cur_lr: 0.0012118150480091572
      grad_gnorm: 40.0
      policy_entropy: 29.946062088012695
      policy_loss: 2.22741436958313
      var_gnorm: 51.04630661010742
      vf_explained_var: 0.030582785606384277
      vf_loss: 27.21146011352539
    num_steps_sampled: 2230000
    num_steps_trained: 2230000
    wait_time_ms: 112.09
  iterations_since_restore: 446
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5349.56484746933
  time_this_iter_s: 11.459563255310059
  time_total_s: 5349.56484746933
  timestamp: 1593999400
  timesteps_since_restore: 2230000
  timesteps_this_iter: 5000
  timesteps_total: 2230000
  training_iteration: 446
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5349 s, 446 iter, 2230000 ts, 535 rew

agent-1: 94.0
agent-2: 96.0
agent-3: 87.0
agent-4: 131.0
agent-5: 102.0
Sum Reward: 510.0
Avg Reward: 102.0
Min Reward: 87.0
Gini Coefficient: 0.07529411764705882
20:20 Ratio: 1.5057471264367817
Max-min Ratio: 1.5057471264367817
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-36-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 534.08
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 446
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.987
    dispatch_time_ms: 37.797
    learner:
      cur_lr: 0.0012114819837734103
      grad_gnorm: 40.000003814697266
      policy_entropy: 9.349552154541016
      policy_loss: -10.588337898254395
      var_gnorm: 51.2117919921875
      vf_explained_var: -1.0
      vf_loss: 51.087764739990234
    num_steps_sampled: 2235000
    num_steps_trained: 2235000
    wait_time_ms: 65.997
  iterations_since_restore: 447
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5361.352929830551
  time_this_iter_s: 11.788082361221313
  time_total_s: 5361.352929830551
  timestamp: 1593999412
  timesteps_since_restore: 2235000
  timesteps_this_iter: 5000
  timesteps_total: 2235000
  training_iteration: 447
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5361 s, 447 iter, 2235000 ts, 534 rew

agent-1: 109.0
agent-2: 130.0
agent-3: 151.0
agent-4: 128.0
agent-5: 134.0
Sum Reward: 652.0
Avg Reward: 130.4
Min Reward: 109.0
Gini Coefficient: 0.05521472392638037
20:20 Ratio: 1.385321100917431
Max-min Ratio: 1.385321100917431
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-37-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 535.76
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 447
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.07
    dispatch_time_ms: 33.86
    learner:
      cur_lr: 0.0012111490359529853
      grad_gnorm: 40.0
      policy_entropy: 16.260257720947266
      policy_loss: 1.6332321166992188
      var_gnorm: 51.25495529174805
      vf_explained_var: -0.0872727632522583
      vf_loss: 67.59623718261719
    num_steps_sampled: 2240000
    num_steps_trained: 2240000
    wait_time_ms: 76.047
  iterations_since_restore: 448
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5372.537132978439
  time_this_iter_s: 11.184203147888184
  time_total_s: 5372.537132978439
  timestamp: 1593999423
  timesteps_since_restore: 2240000
  timesteps_this_iter: 5000
  timesteps_total: 2240000
  training_iteration: 448
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5372 s, 448 iter, 2240000 ts, 536 rew

agent-1: 131.0
agent-2: 167.0
agent-3: 123.0
agent-4: 127.0
agent-5: 159.0
Sum Reward: 707.0
Avg Reward: 141.4
Min Reward: 123.0
Gini Coefficient: 0.06789250353606789
20:20 Ratio: 1.3577235772357723
Max-min Ratio: 1.3577235772357723
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-37-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 538.39
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 448
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.918
    dispatch_time_ms: 35.983
    learner:
      cur_lr: 0.0012108159717172384
      grad_gnorm: 33.755462646484375
      policy_entropy: 27.384328842163086
      policy_loss: -3.3690385818481445
      var_gnorm: 51.52046585083008
      vf_explained_var: -0.4919847249984741
      vf_loss: 33.208839416503906
    num_steps_sampled: 2245000
    num_steps_trained: 2245000
    wait_time_ms: 62.542
  iterations_since_restore: 449
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5383.419213294983
  time_this_iter_s: 10.882080316543579
  time_total_s: 5383.419213294983
  timestamp: 1593999434
  timesteps_since_restore: 2245000
  timesteps_this_iter: 5000
  timesteps_total: 2245000
  training_iteration: 449
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5383 s, 449 iter, 2245000 ts, 538 rew

agent-1: 91.0
agent-2: 178.0
agent-3: 99.0
agent-4: 119.0
agent-5: 152.0
Sum Reward: 639.0
Avg Reward: 127.8
Min Reward: 91.0
Gini Coefficient: 0.14209702660406887
20:20 Ratio: 1.956043956043956
Max-min Ratio: 1.956043956043956
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-37-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 540.3
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 449
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.462
    dispatch_time_ms: 24.309
    learner:
      cur_lr: 0.0012104830238968134
      grad_gnorm: 40.0
      policy_entropy: 19.23036766052246
      policy_loss: 3.0277998447418213
      var_gnorm: 51.54676055908203
      vf_explained_var: -0.5350539684295654
      vf_loss: 46.50032043457031
    num_steps_sampled: 2250000
    num_steps_trained: 2250000
    wait_time_ms: 84.945
  iterations_since_restore: 450
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5394.199330806732
  time_this_iter_s: 10.780117511749268
  time_total_s: 5394.199330806732
  timestamp: 1593999444
  timesteps_since_restore: 2250000
  timesteps_this_iter: 5000
  timesteps_total: 2250000
  training_iteration: 450
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5394 s, 450 iter, 2250000 ts, 540 rew

agent-1: 131.0
agent-2: 138.0
agent-3: 162.0
agent-4: 117.0
agent-5: 136.0
Sum Reward: 684.0
Avg Reward: 136.8
Min Reward: 117.0
Gini Coefficient: 0.05672514619883041
20:20 Ratio: 1.3846153846153846
Max-min Ratio: 1.3846153846153846
W0705 21:37:36.411041  2378 client_connection.cc:255] [worker]ProcessMessage with type 19 took 112 ms.
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-37-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 541.1
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 450
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 41.902
    dispatch_time_ms: 216.509
    learner:
      cur_lr: 0.0012101499596610665
      grad_gnorm: 40.00000762939453
      policy_entropy: 27.694440841674805
      policy_loss: -10.734236717224121
      var_gnorm: 51.57366943359375
      vf_explained_var: 0.4235832095146179
      vf_loss: 37.021888732910156
    num_steps_sampled: 2255000
    num_steps_trained: 2255000
    wait_time_ms: 228.292
  iterations_since_restore: 451
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5409.102262973785
  time_this_iter_s: 14.902932167053223
  time_total_s: 5409.102262973785
  timestamp: 1593999459
  timesteps_since_restore: 2255000
  timesteps_this_iter: 5000
  timesteps_total: 2255000
  training_iteration: 451
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5409 s, 451 iter, 2255000 ts, 541 rew

agent-1: 124.0
agent-2: 170.0
agent-3: 155.0
agent-4: 149.0
agent-5: 131.0
Sum Reward: 729.0
Avg Reward: 145.8
Min Reward: 124.0
Gini Coefficient: 0.06364883401920439
20:20 Ratio: 1.3709677419354838
Max-min Ratio: 1.3709677419354838
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-37-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 543.47
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 451
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.854
    dispatch_time_ms: 6.927
    learner:
      cur_lr: 0.0012098170118406415
      grad_gnorm: 34.790122985839844
      policy_entropy: 16.266630172729492
      policy_loss: 10.291871070861816
      var_gnorm: 51.574310302734375
      vf_explained_var: -0.34322524070739746
      vf_loss: 48.380306243896484
    num_steps_sampled: 2260000
    num_steps_trained: 2260000
    wait_time_ms: 93.113
  iterations_since_restore: 452
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5418.912906885147
  time_this_iter_s: 9.810643911361694
  time_total_s: 5418.912906885147
  timestamp: 1593999469
  timesteps_since_restore: 2260000
  timesteps_this_iter: 5000
  timesteps_total: 2260000
  training_iteration: 452
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5418 s, 452 iter, 2260000 ts, 543 rew

agent-1: 135.0
agent-2: 151.0
agent-3: 140.0
agent-4: 128.0
agent-5: 137.0
Sum Reward: 691.0
Avg Reward: 138.2
Min Reward: 128.0
Gini Coefficient: 0.029522431259044864
20:20 Ratio: 1.1796875
Max-min Ratio: 1.1796875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-38-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 545.53
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 452
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.181
    dispatch_time_ms: 6.562
    learner:
      cur_lr: 0.0012094839476048946
      grad_gnorm: 39.999996185302734
      policy_entropy: 22.771411895751953
      policy_loss: -8.071654319763184
      var_gnorm: 51.681827545166016
      vf_explained_var: 0.720684289932251
      vf_loss: 26.197566986083984
    num_steps_sampled: 2265000
    num_steps_trained: 2265000
    wait_time_ms: 101.923
  iterations_since_restore: 453
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5429.901780605316
  time_this_iter_s: 10.988873720169067
  time_total_s: 5429.901780605316
  timestamp: 1593999480
  timesteps_since_restore: 2265000
  timesteps_this_iter: 5000
  timesteps_total: 2265000
  training_iteration: 453
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5429 s, 453 iter, 2265000 ts, 546 rew

agent-1: 115.0
agent-2: 142.0
agent-3: 136.0
agent-4: 128.0
agent-5: 174.0
Sum Reward: 695.0
Avg Reward: 139.0
Min Reward: 115.0
Gini Coefficient: 0.07597122302158274
20:20 Ratio: 1.5130434782608695
Max-min Ratio: 1.5130434782608695
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-38-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 545.92
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 453
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.896
    dispatch_time_ms: 9.028
    learner:
      cur_lr: 0.0012091509997844696
      grad_gnorm: 37.86044692993164
      policy_entropy: 23.87470245361328
      policy_loss: -5.475711822509766
      var_gnorm: 51.63284683227539
      vf_explained_var: 0.8887378573417664
      vf_loss: 13.170378684997559
    num_steps_sampled: 2270000
    num_steps_trained: 2270000
    wait_time_ms: 96.697
  iterations_since_restore: 454
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5440.473918914795
  time_this_iter_s: 10.57213830947876
  time_total_s: 5440.473918914795
  timestamp: 1593999491
  timesteps_since_restore: 2270000
  timesteps_this_iter: 5000
  timesteps_total: 2270000
  training_iteration: 454
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5440 s, 454 iter, 2270000 ts, 546 rew

agent-1: 127.0
agent-2: 168.0
agent-3: 121.0
agent-4: 136.0
agent-5: 120.0
Sum Reward: 672.0
Avg Reward: 134.4
Min Reward: 120.0
Gini Coefficient: 0.06607142857142857
20:20 Ratio: 1.4
Max-min Ratio: 1.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-38-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 546.36
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 454
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.778
    dispatch_time_ms: 7.742
    learner:
      cur_lr: 0.0012088180519640446
      grad_gnorm: 40.0
      policy_entropy: 26.99497413635254
      policy_loss: 7.698473930358887
      var_gnorm: 51.711570739746094
      vf_explained_var: 0.8595243692398071
      vf_loss: 22.83690071105957
    num_steps_sampled: 2275000
    num_steps_trained: 2275000
    wait_time_ms: 101.072
  iterations_since_restore: 455
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5451.31569814682
  time_this_iter_s: 10.841779232025146
  time_total_s: 5451.31569814682
  timestamp: 1593999502
  timesteps_since_restore: 2275000
  timesteps_this_iter: 5000
  timesteps_total: 2275000
  training_iteration: 455
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5451 s, 455 iter, 2275000 ts, 546 rew

agent-1: 136.0
agent-2: 125.0
agent-3: 109.0
agent-4: 147.0
agent-5: 128.0
Sum Reward: 645.0
Avg Reward: 129.0
Min Reward: 109.0
Gini Coefficient: 0.053953488372093024
20:20 Ratio: 1.348623853211009
Max-min Ratio: 1.348623853211009
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-38-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 547.71
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 455
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.358
    dispatch_time_ms: 5.983
    learner:
      cur_lr: 0.0012084849877282977
      grad_gnorm: 40.0
      policy_entropy: 20.62450408935547
      policy_loss: 8.14341926574707
      var_gnorm: 51.69808578491211
      vf_explained_var: 0.2024572491645813
      vf_loss: 44.828575134277344
    num_steps_sampled: 2280000
    num_steps_trained: 2280000
    wait_time_ms: 94.481
  iterations_since_restore: 456
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5461.795563220978
  time_this_iter_s: 10.479865074157715
  time_total_s: 5461.795563220978
  timestamp: 1593999512
  timesteps_since_restore: 2280000
  timesteps_this_iter: 5000
  timesteps_total: 2280000
  training_iteration: 456
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5461 s, 456 iter, 2280000 ts, 548 rew

agent-1: 113.0
agent-2: 138.0
agent-3: 133.0
agent-4: 152.0
agent-5: 160.0
Sum Reward: 696.0
Avg Reward: 139.2
Min Reward: 113.0
Gini Coefficient: 0.06494252873563218
20:20 Ratio: 1.415929203539823
Max-min Ratio: 1.415929203539823
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-38-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 550.03
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 456
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.291
    dispatch_time_ms: 12.844
    learner:
      cur_lr: 0.0012081520399078727
      grad_gnorm: 40.0
      policy_entropy: 30.040782928466797
      policy_loss: -7.099896430969238
      var_gnorm: 51.776912689208984
      vf_explained_var: 0.36110323667526245
      vf_loss: 33.46900177001953
    num_steps_sampled: 2285000
    num_steps_trained: 2285000
    wait_time_ms: 85.292
  iterations_since_restore: 457
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5472.884402513504
  time_this_iter_s: 11.088839292526245
  time_total_s: 5472.884402513504
  timestamp: 1593999523
  timesteps_since_restore: 2285000
  timesteps_this_iter: 5000
  timesteps_total: 2285000
  training_iteration: 457
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5472 s, 457 iter, 2285000 ts, 550 rew

agent-1: 115.0
agent-2: 130.0
agent-3: 120.0
agent-4: 140.0
agent-5: 150.0
Sum Reward: 655.0
Avg Reward: 131.0
Min Reward: 115.0
Gini Coefficient: 0.0549618320610687
20:20 Ratio: 1.3043478260869565
Max-min Ratio: 1.3043478260869565
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-38-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 549.83
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 457
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.873
    dispatch_time_ms: 9.841
    learner:
      cur_lr: 0.0012078189756721258
      grad_gnorm: 40.0
      policy_entropy: 23.177034378051758
      policy_loss: 25.031688690185547
      var_gnorm: 51.69701385498047
      vf_explained_var: 0.5165027379989624
      vf_loss: 47.996028900146484
    num_steps_sampled: 2290000
    num_steps_trained: 2290000
    wait_time_ms: 94.44
  iterations_since_restore: 458
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5483.345420360565
  time_this_iter_s: 10.461017847061157
  time_total_s: 5483.345420360565
  timestamp: 1593999534
  timesteps_since_restore: 2290000
  timesteps_this_iter: 5000
  timesteps_total: 2290000
  training_iteration: 458
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5483 s, 458 iter, 2290000 ts, 550 rew

agent-1: 137.0
agent-2: 147.0
agent-3: 94.0
agent-4: 149.0
agent-5: 161.0
Sum Reward: 688.0
Avg Reward: 137.6
Min Reward: 94.0
Gini Coefficient: 0.08488372093023255
20:20 Ratio: 1.7127659574468086
Max-min Ratio: 1.7127659574468086
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-39-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 549.74
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 458
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.77
    dispatch_time_ms: 6.233
    learner:
      cur_lr: 0.0012074860278517008
      grad_gnorm: 40.0
      policy_entropy: 24.06496810913086
      policy_loss: 14.574393272399902
      var_gnorm: 51.777706146240234
      vf_explained_var: 0.674909770488739
      vf_loss: 35.79423904418945
    num_steps_sampled: 2295000
    num_steps_trained: 2295000
    wait_time_ms: 98.49
  iterations_since_restore: 459
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5499.9327120780945
  time_this_iter_s: 16.587291717529297
  time_total_s: 5499.9327120780945
  timestamp: 1593999551
  timesteps_since_restore: 2295000
  timesteps_this_iter: 5000
  timesteps_total: 2295000
  training_iteration: 459
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5499 s, 459 iter, 2295000 ts, 550 rew

agent-1: 132.0
agent-2: 175.0
agent-3: 173.0
agent-4: 132.0
agent-5: 147.0
Sum Reward: 759.0
Avg Reward: 151.8
Min Reward: 132.0
Gini Coefficient: 0.06693017127799737
20:20 Ratio: 1.3257575757575757
Max-min Ratio: 1.3257575757575757
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-39-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 552.56
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 459
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.524
    dispatch_time_ms: 8.466
    learner:
      cur_lr: 0.001207152963615954
      grad_gnorm: 14.175352096557617
      policy_entropy: 21.290128707885742
      policy_loss: 0.3068292737007141
      var_gnorm: 51.938961029052734
      vf_explained_var: 0.858544111251831
      vf_loss: 16.516456604003906
    num_steps_sampled: 2300000
    num_steps_trained: 2300000
    wait_time_ms: 92.508
  iterations_since_restore: 460
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5510.616399526596
  time_this_iter_s: 10.683687448501587
  time_total_s: 5510.616399526596
  timestamp: 1593999561
  timesteps_since_restore: 2300000
  timesteps_this_iter: 5000
  timesteps_total: 2300000
  training_iteration: 460
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5510 s, 460 iter, 2300000 ts, 553 rew

agent-1: 94.0
agent-2: 88.0
agent-3: 82.0
agent-4: 139.0
agent-5: 183.0
Sum Reward: 586.0
Avg Reward: 117.2
Min Reward: 82.0
Gini Coefficient: 0.1726962457337884
20:20 Ratio: 2.231707317073171
Max-min Ratio: 2.231707317073171
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-39-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 809.0
  episode_reward_mean: 552.47
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 460
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.425
    dispatch_time_ms: 8.885
    learner:
      cur_lr: 0.0012068200157955289
      grad_gnorm: 27.451709747314453
      policy_entropy: 23.791501998901367
      policy_loss: -4.391928195953369
      var_gnorm: 51.874732971191406
      vf_explained_var: 0.8287022113800049
      vf_loss: 24.090478897094727
    num_steps_sampled: 2305000
    num_steps_trained: 2305000
    wait_time_ms: 91.226
  iterations_since_restore: 461
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5521.194546222687
  time_this_iter_s: 10.578146696090698
  time_total_s: 5521.194546222687
  timestamp: 1593999572
  timesteps_since_restore: 2305000
  timesteps_this_iter: 5000
  timesteps_total: 2305000
  training_iteration: 461
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5521 s, 461 iter, 2305000 ts, 552 rew

agent-1: 114.0
agent-2: 207.0
agent-3: 163.0
agent-4: 180.0
agent-5: 164.0
Sum Reward: 828.0
Avg Reward: 165.6
Min Reward: 114.0
Gini Coefficient: 0.09806763285024155
20:20 Ratio: 1.8157894736842106
Max-min Ratio: 1.8157894736842106
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-39-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 555.27
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 461
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.322
    dispatch_time_ms: 31.429
    learner:
      cur_lr: 0.001206486951559782
      grad_gnorm: 40.0
      policy_entropy: 31.809280395507812
      policy_loss: -31.87746238708496
      var_gnorm: 51.84490203857422
      vf_explained_var: 0.3821357488632202
      vf_loss: 57.99018478393555
    num_steps_sampled: 2310000
    num_steps_trained: 2310000
    wait_time_ms: 82.833
  iterations_since_restore: 462
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5532.139587640762
  time_this_iter_s: 10.945041418075562
  time_total_s: 5532.139587640762
  timestamp: 1593999583
  timesteps_since_restore: 2310000
  timesteps_this_iter: 5000
  timesteps_total: 2310000
  training_iteration: 462
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5532 s, 462 iter, 2310000 ts, 555 rew

agent-1: 167.0
agent-2: 158.0
agent-3: 96.0
agent-4: 159.0
agent-5: 116.0
Sum Reward: 696.0
Avg Reward: 139.2
Min Reward: 96.0
Gini Coefficient: 0.10632183908045977
20:20 Ratio: 1.7395833333333333
Max-min Ratio: 1.7395833333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-39-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 556.6
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 462
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.138
    dispatch_time_ms: 33.705
    learner:
      cur_lr: 0.001206154003739357
      grad_gnorm: 40.000003814697266
      policy_entropy: 15.113883972167969
      policy_loss: -2.6736605167388916
      var_gnorm: 51.87321472167969
      vf_explained_var: -0.002449512481689453
      vf_loss: 92.71037292480469
    num_steps_sampled: 2315000
    num_steps_trained: 2315000
    wait_time_ms: 73.828
  iterations_since_restore: 463
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5544.121779203415
  time_this_iter_s: 11.982191562652588
  time_total_s: 5544.121779203415
  timestamp: 1593999595
  timesteps_since_restore: 2315000
  timesteps_this_iter: 5000
  timesteps_total: 2315000
  training_iteration: 463
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5544 s, 463 iter, 2315000 ts, 557 rew

agent-1: 104.0
agent-2: 121.0
agent-3: 128.0
agent-4: 82.0
agent-5: 129.0
Sum Reward: 564.0
Avg Reward: 112.8
Min Reward: 82.0
Gini Coefficient: 0.08368794326241134
20:20 Ratio: 1.5731707317073171
Max-min Ratio: 1.5731707317073171
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-40-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 556.44
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 463
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.962
    dispatch_time_ms: 25.929
    learner:
      cur_lr: 0.001205821055918932
      grad_gnorm: 40.0
      policy_entropy: 37.46603012084961
      policy_loss: -12.13938045501709
      var_gnorm: 52.03795623779297
      vf_explained_var: -0.3262549638748169
      vf_loss: 14.013379096984863
    num_steps_sampled: 2320000
    num_steps_trained: 2320000
    wait_time_ms: 84.46
  iterations_since_restore: 464
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5555.501479625702
  time_this_iter_s: 11.379700422286987
  time_total_s: 5555.501479625702
  timestamp: 1593999606
  timesteps_since_restore: 2320000
  timesteps_this_iter: 5000
  timesteps_total: 2320000
  training_iteration: 464
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5555 s, 464 iter, 2320000 ts, 556 rew

agent-1: 120.0
agent-2: 146.0
agent-3: 138.0
agent-4: 156.0
agent-5: 134.0
Sum Reward: 694.0
Avg Reward: 138.8
Min Reward: 120.0
Gini Coefficient: 0.0484149855907781
20:20 Ratio: 1.3
Max-min Ratio: 1.3
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-40-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 559.72
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 464
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.926
    dispatch_time_ms: 26.175
    learner:
      cur_lr: 0.001205487991683185
      grad_gnorm: 40.0
      policy_entropy: 44.167537689208984
      policy_loss: -12.026905059814453
      var_gnorm: 52.1570930480957
      vf_explained_var: -0.24814319610595703
      vf_loss: 44.493560791015625
    num_steps_sampled: 2325000
    num_steps_trained: 2325000
    wait_time_ms: 80.882
  iterations_since_restore: 465
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5566.874313116074
  time_this_iter_s: 11.372833490371704
  time_total_s: 5566.874313116074
  timestamp: 1593999618
  timesteps_since_restore: 2325000
  timesteps_this_iter: 5000
  timesteps_total: 2325000
  training_iteration: 465
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5566 s, 465 iter, 2325000 ts, 560 rew

agent-1: 116.0
agent-2: 104.0
agent-3: 148.0
agent-4: 166.0
agent-5: 119.0
Sum Reward: 653.0
Avg Reward: 130.6
Min Reward: 104.0
Gini Coefficient: 0.09555895865237365
20:20 Ratio: 1.5961538461538463
Max-min Ratio: 1.5961538461538463
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-40-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 562.04
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 465
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.331
    dispatch_time_ms: 36.185
    learner:
      cur_lr: 0.00120515504386276
      grad_gnorm: 39.999996185302734
      policy_entropy: 48.086055755615234
      policy_loss: 43.1945915222168
      var_gnorm: 52.21587371826172
      vf_explained_var: -1.0
      vf_loss: 46.98326873779297
    num_steps_sampled: 2330000
    num_steps_trained: 2330000
    wait_time_ms: 74.447
  iterations_since_restore: 466
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5577.936039924622
  time_this_iter_s: 11.061726808547974
  time_total_s: 5577.936039924622
  timestamp: 1593999629
  timesteps_since_restore: 2330000
  timesteps_this_iter: 5000
  timesteps_total: 2330000
  training_iteration: 466
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5577 s, 466 iter, 2330000 ts, 562 rew

agent-1: 125.0
agent-2: 132.0
agent-3: 164.0
agent-4: 106.0
agent-5: 95.0
Sum Reward: 622.0
Avg Reward: 124.4
Min Reward: 95.0
Gini Coefficient: 0.10546623794212219
20:20 Ratio: 1.7263157894736842
Max-min Ratio: 1.7263157894736842
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-40-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 564.28
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 466
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.235
    dispatch_time_ms: 31.786
    learner:
      cur_lr: 0.0012048219796270132
      grad_gnorm: 39.012306213378906
      policy_entropy: 49.507171630859375
      policy_loss: 10.807967185974121
      var_gnorm: 52.20758056640625
      vf_explained_var: 0.7863204479217529
      vf_loss: 12.23646354675293
    num_steps_sampled: 2335000
    num_steps_trained: 2335000
    wait_time_ms: 70.883
  iterations_since_restore: 467
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5588.902977228165
  time_this_iter_s: 10.96693730354309
  time_total_s: 5588.902977228165
  timestamp: 1593999640
  timesteps_since_restore: 2335000
  timesteps_this_iter: 5000
  timesteps_total: 2335000
  training_iteration: 467
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5588 s, 467 iter, 2335000 ts, 564 rew

agent-1: 122.0
agent-2: 128.0
agent-3: 105.0
agent-4: 99.0
agent-5: 151.0
Sum Reward: 605.0
Avg Reward: 121.0
Min Reward: 99.0
Gini Coefficient: 0.08396694214876033
20:20 Ratio: 1.5252525252525253
Max-min Ratio: 1.5252525252525253
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-40-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 565.77
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 467
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.364
    dispatch_time_ms: 31.416
    learner:
      cur_lr: 0.0012044890318065882
      grad_gnorm: 40.0
      policy_entropy: 46.54790496826172
      policy_loss: 35.539554595947266
      var_gnorm: 52.19152069091797
      vf_explained_var: 0.7126270532608032
      vf_loss: 57.869136810302734
    num_steps_sampled: 2340000
    num_steps_trained: 2340000
    wait_time_ms: 85.173
  iterations_since_restore: 468
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5599.86753320694
  time_this_iter_s: 10.964555978775024
  time_total_s: 5599.86753320694
  timestamp: 1593999651
  timesteps_since_restore: 2340000
  timesteps_this_iter: 5000
  timesteps_total: 2340000
  training_iteration: 468
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5599 s, 468 iter, 2340000 ts, 566 rew

agent-1: 139.0
agent-2: 167.0
agent-3: 86.0
agent-4: 105.0
agent-5: 161.0
Sum Reward: 658.0
Avg Reward: 131.6
Min Reward: 86.0
Gini Coefficient: 0.1325227963525836
20:20 Ratio: 1.941860465116279
Max-min Ratio: 1.941860465116279
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-41-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 567.86
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 468
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.89
    dispatch_time_ms: 6.883
    learner:
      cur_lr: 0.0012041559675708413
      grad_gnorm: 40.000003814697266
      policy_entropy: 45.85737609863281
      policy_loss: -32.70994567871094
      var_gnorm: 52.25137710571289
      vf_explained_var: -0.4392225742340088
      vf_loss: 48.06515121459961
    num_steps_sampled: 2345000
    num_steps_trained: 2345000
    wait_time_ms: 102.878
  iterations_since_restore: 469
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5610.341602802277
  time_this_iter_s: 10.474069595336914
  time_total_s: 5610.341602802277
  timestamp: 1593999661
  timesteps_since_restore: 2345000
  timesteps_this_iter: 5000
  timesteps_total: 2345000
  training_iteration: 469
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5610 s, 469 iter, 2345000 ts, 568 rew

agent-1: 103.0
agent-2: 153.0
agent-3: 96.0
agent-4: 120.0
agent-5: 131.0
Sum Reward: 603.0
Avg Reward: 120.6
Min Reward: 96.0
Gini Coefficient: 0.09419568822553898
20:20 Ratio: 1.59375
Max-min Ratio: 1.59375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-41-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 570.45
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 469
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.38
    dispatch_time_ms: 6.224
    learner:
      cur_lr: 0.0012038230197504163
      grad_gnorm: 40.0
      policy_entropy: 43.80743408203125
      policy_loss: 13.725041389465332
      var_gnorm: 52.292884826660156
      vf_explained_var: 0.5616493225097656
      vf_loss: 32.646766662597656
    num_steps_sampled: 2350000
    num_steps_trained: 2350000
    wait_time_ms: 102.989
  iterations_since_restore: 470
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5620.687792301178
  time_this_iter_s: 10.346189498901367
  time_total_s: 5620.687792301178
  timestamp: 1593999672
  timesteps_since_restore: 2350000
  timesteps_this_iter: 5000
  timesteps_total: 2350000
  training_iteration: 470
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5620 s, 470 iter, 2350000 ts, 570 rew

agent-1: 154.0
agent-2: 107.0
agent-3: 90.0
agent-4: 134.0
agent-5: 127.0
Sum Reward: 612.0
Avg Reward: 122.4
Min Reward: 90.0
Gini Coefficient: 0.10130718954248366
20:20 Ratio: 1.711111111111111
Max-min Ratio: 1.711111111111111
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-41-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 571.57
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 470
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.212
    dispatch_time_ms: 9.181
    learner:
      cur_lr: 0.0012034899555146694
      grad_gnorm: 39.999996185302734
      policy_entropy: 41.96491241455078
      policy_loss: 15.837182998657227
      var_gnorm: 52.28028106689453
      vf_explained_var: 0.717375636100769
      vf_loss: 23.408527374267578
    num_steps_sampled: 2355000
    num_steps_trained: 2355000
    wait_time_ms: 89.258
  iterations_since_restore: 471
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5630.973149061203
  time_this_iter_s: 10.285356760025024
  time_total_s: 5630.973149061203
  timestamp: 1593999682
  timesteps_since_restore: 2355000
  timesteps_this_iter: 5000
  timesteps_total: 2355000
  training_iteration: 471
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5630 s, 471 iter, 2355000 ts, 572 rew

agent-1: 151.0
agent-2: 156.0
agent-3: 104.0
agent-4: 172.0
agent-5: 149.0
Sum Reward: 732.0
Avg Reward: 146.4
Min Reward: 104.0
Gini Coefficient: 0.07814207650273224
20:20 Ratio: 1.6538461538461537
Max-min Ratio: 1.6538461538461537
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-41-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 573.9
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 471
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.001
    dispatch_time_ms: 12.754
    learner:
      cur_lr: 0.0012031570076942444
      grad_gnorm: 40.000003814697266
      policy_entropy: 49.945396423339844
      policy_loss: 26.006938934326172
      var_gnorm: 52.28022384643555
      vf_explained_var: 0.893566370010376
      vf_loss: 34.28946304321289
    num_steps_sampled: 2360000
    num_steps_trained: 2360000
    wait_time_ms: 83.989
  iterations_since_restore: 472
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5641.086941719055
  time_this_iter_s: 10.113792657852173
  time_total_s: 5641.086941719055
  timestamp: 1593999692
  timesteps_since_restore: 2360000
  timesteps_this_iter: 5000
  timesteps_total: 2360000
  training_iteration: 472
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5641 s, 472 iter, 2360000 ts, 574 rew

agent-1: 196.0
agent-2: 123.0
agent-3: 94.0
agent-4: 150.0
agent-5: 126.0
Sum Reward: 689.0
Avg Reward: 137.8
Min Reward: 94.0
Gini Coefficient: 0.13410740203193033
20:20 Ratio: 2.0851063829787235
Max-min Ratio: 2.0851063829787235
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-41-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 576.73
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 472
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.142
    dispatch_time_ms: 10.243
    learner:
      cur_lr: 0.0012028239434584975
      grad_gnorm: 39.999996185302734
      policy_entropy: 46.524654388427734
      policy_loss: -15.032017707824707
      var_gnorm: 52.280235290527344
      vf_explained_var: 0.132632315158844
      vf_loss: 37.8629264831543
    num_steps_sampled: 2365000
    num_steps_trained: 2365000
    wait_time_ms: 93.122
  iterations_since_restore: 473
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5651.465813159943
  time_this_iter_s: 10.378871440887451
  time_total_s: 5651.465813159943
  timestamp: 1593999703
  timesteps_since_restore: 2365000
  timesteps_this_iter: 5000
  timesteps_total: 2365000
  training_iteration: 473
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5651 s, 473 iter, 2365000 ts, 577 rew

agent-1: 144.0
agent-2: 157.0
agent-3: 140.0
agent-4: 132.0
agent-5: 135.0
Sum Reward: 708.0
Avg Reward: 141.6
Min Reward: 132.0
Gini Coefficient: 0.03333333333333333
20:20 Ratio: 1.1893939393939394
Max-min Ratio: 1.1893939393939394
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-41-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 580.21
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 473
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.518
    dispatch_time_ms: 12.093
    learner:
      cur_lr: 0.0012024909956380725
      grad_gnorm: 40.0
      policy_entropy: 34.93763732910156
      policy_loss: -16.897554397583008
      var_gnorm: 52.35529327392578
      vf_explained_var: 0.8843239545822144
      vf_loss: 17.48109245300293
    num_steps_sampled: 2370000
    num_steps_trained: 2370000
    wait_time_ms: 96.896
  iterations_since_restore: 474
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5662.250747203827
  time_this_iter_s: 10.784934043884277
  time_total_s: 5662.250747203827
  timestamp: 1593999714
  timesteps_since_restore: 2370000
  timesteps_this_iter: 5000
  timesteps_total: 2370000
  training_iteration: 474
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5662 s, 474 iter, 2370000 ts, 580 rew

agent-1: 101.0
agent-2: 89.0
agent-3: 157.0
agent-4: 123.0
agent-5: 167.0
Sum Reward: 637.0
Avg Reward: 127.4
Min Reward: 89.0
Gini Coefficient: 0.13312401883830455
20:20 Ratio: 1.8764044943820224
Max-min Ratio: 1.8764044943820224
W0705 21:42:11.978658  2378 node_manager.cc:250] Last heartbeat was sent 798 ms ago 
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-42-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 579.74
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 474
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 7.844
    dispatch_time_ms: 7.866
    learner:
      cur_lr: 0.0012021580478176475
      grad_gnorm: 22.73369789123535
      policy_entropy: 43.9482536315918
      policy_loss: -2.844146728515625
      var_gnorm: 52.38923263549805
      vf_explained_var: 0.23989087343215942
      vf_loss: 43.268375396728516
    num_steps_sampled: 2375000
    num_steps_trained: 2375000
    wait_time_ms: 831.552
  iterations_since_restore: 475
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5680.3917689323425
  time_this_iter_s: 18.141021728515625
  time_total_s: 5680.3917689323425
  timestamp: 1593999732
  timesteps_since_restore: 2375000
  timesteps_this_iter: 5000
  timesteps_total: 2375000
  training_iteration: 475
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5680 s, 475 iter, 2375000 ts, 580 rew

agent-1: 138.0
agent-2: 129.0
agent-3: 103.0
agent-4: 145.0
agent-5: 148.0
Sum Reward: 663.0
Avg Reward: 132.6
Min Reward: 103.0
Gini Coefficient: 0.06395173453996983
20:20 Ratio: 1.4368932038834952
Max-min Ratio: 1.4368932038834952
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-42-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 582.29
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 475
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.213
    dispatch_time_ms: 5.687
    learner:
      cur_lr: 0.0012018249835819006
      grad_gnorm: 40.0
      policy_entropy: 38.16105270385742
      policy_loss: -10.43855094909668
      var_gnorm: 52.398624420166016
      vf_explained_var: 0.20935416221618652
      vf_loss: 25.629865646362305
    num_steps_sampled: 2380000
    num_steps_trained: 2380000
    wait_time_ms: 99.761
  iterations_since_restore: 476
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5689.92115354538
  time_this_iter_s: 9.52938461303711
  time_total_s: 5689.92115354538
  timestamp: 1593999741
  timesteps_since_restore: 2380000
  timesteps_this_iter: 5000
  timesteps_total: 2380000
  training_iteration: 476
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5689 s, 476 iter, 2380000 ts, 582 rew

agent-1: 132.0
agent-2: 141.0
agent-3: 109.0
agent-4: 135.0
agent-5: 86.0
Sum Reward: 603.0
Avg Reward: 120.6
Min Reward: 86.0
Gini Coefficient: 0.09021558872305141
20:20 Ratio: 1.6395348837209303
Max-min Ratio: 1.6395348837209303
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-42-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 584.12
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 476
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.323
    dispatch_time_ms: 7.032
    learner:
      cur_lr: 0.0012014920357614756
      grad_gnorm: 39.999996185302734
      policy_entropy: 45.37492370605469
      policy_loss: -24.45664405822754
      var_gnorm: 52.52796936035156
      vf_explained_var: -0.45773136615753174
      vf_loss: 30.830371856689453
    num_steps_sampled: 2385000
    num_steps_trained: 2385000
    wait_time_ms: 87.377
  iterations_since_restore: 477
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5700.497150182724
  time_this_iter_s: 10.57599663734436
  time_total_s: 5700.497150182724
  timestamp: 1593999752
  timesteps_since_restore: 2385000
  timesteps_this_iter: 5000
  timesteps_total: 2385000
  training_iteration: 477
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5700 s, 477 iter, 2385000 ts, 584 rew

agent-1: 116.0
agent-2: 156.0
agent-3: 105.0
agent-4: 125.0
agent-5: 120.0
Sum Reward: 622.0
Avg Reward: 124.4
Min Reward: 105.0
Gini Coefficient: 0.07138263665594856
20:20 Ratio: 1.4857142857142858
Max-min Ratio: 1.4857142857142858
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-42-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 585.88
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 477
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.513
    dispatch_time_ms: 6.211
    learner:
      cur_lr: 0.0012011589715257287
      grad_gnorm: 23.615917205810547
      policy_entropy: 52.950653076171875
      policy_loss: -3.2061243057250977
      var_gnorm: 52.591949462890625
      vf_explained_var: 0.12969011068344116
      vf_loss: 8.19442081451416
    num_steps_sampled: 2390000
    num_steps_trained: 2390000
    wait_time_ms: 101.114
  iterations_since_restore: 478
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5710.750766992569
  time_this_iter_s: 10.25361680984497
  time_total_s: 5710.750766992569
  timestamp: 1593999762
  timesteps_since_restore: 2390000
  timesteps_this_iter: 5000
  timesteps_total: 2390000
  training_iteration: 478
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5710 s, 478 iter, 2390000 ts, 586 rew

agent-1: 121.0
agent-2: 102.0
agent-3: 118.0
agent-4: 131.0
agent-5: 136.0
Sum Reward: 608.0
Avg Reward: 121.6
Min Reward: 102.0
Gini Coefficient: 0.053289473684210525
20:20 Ratio: 1.3333333333333333
Max-min Ratio: 1.3333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-42-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 586.35
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 478
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.888
    dispatch_time_ms: 8.957
    learner:
      cur_lr: 0.0012008260237053037
      grad_gnorm: 40.0
      policy_entropy: 46.727195739746094
      policy_loss: 42.28803634643555
      var_gnorm: 52.62865447998047
      vf_explained_var: 0.4673946499824524
      vf_loss: 53.85687255859375
    num_steps_sampled: 2395000
    num_steps_trained: 2395000
    wait_time_ms: 78.71
  iterations_since_restore: 479
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5721.2815272808075
  time_this_iter_s: 10.530760288238525
  time_total_s: 5721.2815272808075
  timestamp: 1593999773
  timesteps_since_restore: 2395000
  timesteps_this_iter: 5000
  timesteps_total: 2395000
  training_iteration: 479
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5721 s, 479 iter, 2395000 ts, 586 rew

agent-1: 141.0
agent-2: 125.0
agent-3: 128.0
agent-4: 160.0
agent-5: 156.0
Sum Reward: 710.0
Avg Reward: 142.0
Min Reward: 125.0
Gini Coefficient: 0.0552112676056338
20:20 Ratio: 1.28
Max-min Ratio: 1.28
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-43-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 588.53
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 479
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.098
    dispatch_time_ms: 11.0
    learner:
      cur_lr: 0.0012004929594695568
      grad_gnorm: 39.999996185302734
      policy_entropy: 47.67448806762695
      policy_loss: -16.27155113220215
      var_gnorm: 52.63129425048828
      vf_explained_var: 0.21838146448135376
      vf_loss: 10.499277114868164
    num_steps_sampled: 2400000
    num_steps_trained: 2400000
    wait_time_ms: 90.977
  iterations_since_restore: 480
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5731.409669160843
  time_this_iter_s: 10.1281418800354
  time_total_s: 5731.409669160843
  timestamp: 1593999783
  timesteps_since_restore: 2400000
  timesteps_this_iter: 5000
  timesteps_total: 2400000
  training_iteration: 480
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5731 s, 480 iter, 2400000 ts, 589 rew

agent-1: 96.0
agent-2: 107.0
agent-3: 97.0
agent-4: 142.0
agent-5: 105.0
Sum Reward: 547.0
Avg Reward: 109.4
Min Reward: 96.0
Gini Coefficient: 0.07458866544789762
20:20 Ratio: 1.4791666666666667
Max-min Ratio: 1.4791666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-43-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 590.56
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 480
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.493
    dispatch_time_ms: 6.872
    learner:
      cur_lr: 0.0012001600116491318
      grad_gnorm: 39.999996185302734
      policy_entropy: 48.99971389770508
      policy_loss: 6.481514930725098
      var_gnorm: 52.65714645385742
      vf_explained_var: 0.37649083137512207
      vf_loss: 51.840171813964844
    num_steps_sampled: 2405000
    num_steps_trained: 2405000
    wait_time_ms: 91.414
  iterations_since_restore: 481
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5742.080163240433
  time_this_iter_s: 10.670494079589844
  time_total_s: 5742.080163240433
  timestamp: 1593999794
  timesteps_since_restore: 2405000
  timesteps_this_iter: 5000
  timesteps_total: 2405000
  training_iteration: 481
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5742 s, 481 iter, 2405000 ts, 591 rew

agent-1: 98.0
agent-2: 123.0
agent-3: 92.0
agent-4: 133.0
agent-5: 129.0
Sum Reward: 575.0
Avg Reward: 115.0
Min Reward: 92.0
Gini Coefficient: 0.07860869565217392
20:20 Ratio: 1.4456521739130435
Max-min Ratio: 1.4456521739130435
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-43-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 591.81
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 481
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.465
    dispatch_time_ms: 6.58
    learner:
      cur_lr: 0.001199826947413385
      grad_gnorm: 40.00001525878906
      policy_entropy: 46.67998504638672
      policy_loss: 3.442906379699707
      var_gnorm: 52.60666275024414
      vf_explained_var: 0.3599628806114197
      vf_loss: 37.292781829833984
    num_steps_sampled: 2410000
    num_steps_trained: 2410000
    wait_time_ms: 88.614
  iterations_since_restore: 482
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5752.275319576263
  time_this_iter_s: 10.195156335830688
  time_total_s: 5752.275319576263
  timestamp: 1593999804
  timesteps_since_restore: 2410000
  timesteps_this_iter: 5000
  timesteps_total: 2410000
  training_iteration: 482
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5752 s, 482 iter, 2410000 ts, 592 rew

agent-1: 139.0
agent-2: 115.0
agent-3: 80.0
agent-4: 117.0
agent-5: 140.0
Sum Reward: 591.0
Avg Reward: 118.2
Min Reward: 80.0
Gini Coefficient: 0.09746192893401015
20:20 Ratio: 1.75
Max-min Ratio: 1.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-43-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 593.06
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 482
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.471
    dispatch_time_ms: 6.329
    learner:
      cur_lr: 0.0011994939995929599
      grad_gnorm: 15.025209426879883
      policy_entropy: 52.06104278564453
      policy_loss: -2.424119472503662
      var_gnorm: 52.61888122558594
      vf_explained_var: 0.58598792552948
      vf_loss: 30.74265480041504
    num_steps_sampled: 2415000
    num_steps_trained: 2415000
    wait_time_ms: 91.494
  iterations_since_restore: 483
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5763.140128612518
  time_this_iter_s: 10.864809036254883
  time_total_s: 5763.140128612518
  timestamp: 1593999815
  timesteps_since_restore: 2415000
  timesteps_this_iter: 5000
  timesteps_total: 2415000
  training_iteration: 483
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5763 s, 483 iter, 2415000 ts, 593 rew

agent-1: 128.0
agent-2: 121.0
agent-3: 145.0
agent-4: 136.0
agent-5: 159.0
Sum Reward: 689.0
Avg Reward: 137.8
Min Reward: 121.0
Gini Coefficient: 0.05399129172714078
20:20 Ratio: 1.3140495867768596
Max-min Ratio: 1.3140495867768596
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-43-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 595.27
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 483
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.739
    dispatch_time_ms: 6.706
    learner:
      cur_lr: 0.0011991610517725348
      grad_gnorm: 40.000003814697266
      policy_entropy: 37.53884506225586
      policy_loss: -13.317340850830078
      var_gnorm: 52.6905632019043
      vf_explained_var: 0.4744182229042053
      vf_loss: 47.59244918823242
    num_steps_sampled: 2420000
    num_steps_trained: 2420000
    wait_time_ms: 91.73
  iterations_since_restore: 484
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5773.259278535843
  time_this_iter_s: 10.119149923324585
  time_total_s: 5773.259278535843
  timestamp: 1593999825
  timesteps_since_restore: 2420000
  timesteps_this_iter: 5000
  timesteps_total: 2420000
  training_iteration: 484
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5773 s, 484 iter, 2420000 ts, 595 rew

agent-1: 164.0
agent-2: 121.0
agent-3: 178.0
agent-4: 159.0
agent-5: 80.0
Sum Reward: 702.0
Avg Reward: 140.4
Min Reward: 80.0
Gini Coefficient: 0.1361823361823362
20:20 Ratio: 2.225
Max-min Ratio: 2.225
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-43-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 597.45
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 484
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.222
    dispatch_time_ms: 6.683
    learner:
      cur_lr: 0.001198827987536788
      grad_gnorm: 40.0
      policy_entropy: 35.518795013427734
      policy_loss: 74.84114837646484
      var_gnorm: 52.6512336730957
      vf_explained_var: -0.1042490005493164
      vf_loss: 125.378662109375
    num_steps_sampled: 2425000
    num_steps_trained: 2425000
    wait_time_ms: 92.221
  iterations_since_restore: 485
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5783.801166534424
  time_this_iter_s: 10.541887998580933
  time_total_s: 5783.801166534424
  timestamp: 1593999835
  timesteps_since_restore: 2425000
  timesteps_this_iter: 5000
  timesteps_total: 2425000
  training_iteration: 485
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5783 s, 485 iter, 2425000 ts, 597 rew

agent-1: 142.0
agent-2: 102.0
agent-3: 150.0
agent-4: 107.0
agent-5: 217.0
Sum Reward: 718.0
Avg Reward: 143.6
Min Reward: 102.0
Gini Coefficient: 0.1520891364902507
20:20 Ratio: 2.127450980392157
Max-min Ratio: 2.127450980392157
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-44-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 598.32
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 485
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.2
    dispatch_time_ms: 7.536
    learner:
      cur_lr: 0.001198495039716363
      grad_gnorm: 40.0
      policy_entropy: 47.1982307434082
      policy_loss: -44.01295471191406
      var_gnorm: 52.66389846801758
      vf_explained_var: -0.3684384822845459
      vf_loss: 30.95073127746582
    num_steps_sampled: 2430000
    num_steps_trained: 2430000
    wait_time_ms: 92.109
  iterations_since_restore: 486
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5794.058630943298
  time_this_iter_s: 10.257464408874512
  time_total_s: 5794.058630943298
  timestamp: 1593999846
  timesteps_since_restore: 2430000
  timesteps_this_iter: 5000
  timesteps_total: 2430000
  training_iteration: 486
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5794 s, 486 iter, 2430000 ts, 598 rew

agent-1: 145.0
agent-2: 148.0
agent-3: 76.0
agent-4: 147.0
agent-5: 146.0
Sum Reward: 662.0
Avg Reward: 132.4
Min Reward: 76.0
Gini Coefficient: 0.08821752265861027
20:20 Ratio: 1.9473684210526316
Max-min Ratio: 1.9473684210526316
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-44-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 600.93
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 486
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.975
    dispatch_time_ms: 6.934
    learner:
      cur_lr: 0.001198161975480616
      grad_gnorm: 40.0
      policy_entropy: 47.76368713378906
      policy_loss: 20.19145965576172
      var_gnorm: 52.7411003112793
      vf_explained_var: -1.0
      vf_loss: 55.34247589111328
    num_steps_sampled: 2435000
    num_steps_trained: 2435000
    wait_time_ms: 91.631
  iterations_since_restore: 487
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5804.43655705452
  time_this_iter_s: 10.377926111221313
  time_total_s: 5804.43655705452
  timestamp: 1593999856
  timesteps_since_restore: 2435000
  timesteps_this_iter: 5000
  timesteps_total: 2435000
  training_iteration: 487
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5804 s, 487 iter, 2435000 ts, 601 rew

agent-1: 119.0
agent-2: 126.0
agent-3: 121.0
agent-4: 162.0
agent-5: 153.0
Sum Reward: 681.0
Avg Reward: 136.2
Min Reward: 119.0
Gini Coefficient: 0.06930983847283406
20:20 Ratio: 1.361344537815126
Max-min Ratio: 1.361344537815126
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-44-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 602.43
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 487
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.26
    dispatch_time_ms: 9.022
    learner:
      cur_lr: 0.001197829027660191
      grad_gnorm: 30.001569747924805
      policy_entropy: 48.15406036376953
      policy_loss: 1.5026017427444458
      var_gnorm: 52.913360595703125
      vf_explained_var: 0.14553529024124146
      vf_loss: 31.3511962890625
    num_steps_sampled: 2440000
    num_steps_trained: 2440000
    wait_time_ms: 90.839
  iterations_since_restore: 488
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5814.508674621582
  time_this_iter_s: 10.072117567062378
  time_total_s: 5814.508674621582
  timestamp: 1593999866
  timesteps_since_restore: 2440000
  timesteps_this_iter: 5000
  timesteps_total: 2440000
  training_iteration: 488
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5814 s, 488 iter, 2440000 ts, 602 rew

agent-1: 172.0
agent-2: 81.0
agent-3: 75.0
agent-4: 96.0
agent-5: 167.0
Sum Reward: 591.0
Avg Reward: 118.2
Min Reward: 75.0
Gini Coefficient: 0.1895093062605753
20:20 Ratio: 2.2933333333333334
Max-min Ratio: 2.2933333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-44-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 604.95
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 488
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.567
    dispatch_time_ms: 5.77
    learner:
      cur_lr: 0.0011974959634244442
      grad_gnorm: 40.000003814697266
      policy_entropy: 52.29539489746094
      policy_loss: -15.614209175109863
      var_gnorm: 52.91582107543945
      vf_explained_var: 0.05487746000289917
      vf_loss: 9.26146411895752
    num_steps_sampled: 2445000
    num_steps_trained: 2445000
    wait_time_ms: 98.813
  iterations_since_restore: 489
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5824.921066522598
  time_this_iter_s: 10.412391901016235
  time_total_s: 5824.921066522598
  timestamp: 1593999877
  timesteps_since_restore: 2445000
  timesteps_this_iter: 5000
  timesteps_total: 2445000
  training_iteration: 489
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5824 s, 489 iter, 2445000 ts, 605 rew

agent-1: 114.0
agent-2: 150.0
agent-3: 112.0
agent-4: 135.0
agent-5: 157.0
Sum Reward: 668.0
Avg Reward: 133.6
Min Reward: 112.0
Gini Coefficient: 0.07544910179640718
20:20 Ratio: 1.4017857142857142
Max-min Ratio: 1.4017857142857142
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-44-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 608.24
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 489
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.626
    dispatch_time_ms: 6.934
    learner:
      cur_lr: 0.0011971630156040192
      grad_gnorm: 38.69783401489258
      policy_entropy: 45.59391784667969
      policy_loss: -13.372222900390625
      var_gnorm: 52.88178634643555
      vf_explained_var: 0.4716513156890869
      vf_loss: 16.860368728637695
    num_steps_sampled: 2450000
    num_steps_trained: 2450000
    wait_time_ms: 93.94
  iterations_since_restore: 490
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5835.049027919769
  time_this_iter_s: 10.12796139717102
  time_total_s: 5835.049027919769
  timestamp: 1593999887
  timesteps_since_restore: 2450000
  timesteps_this_iter: 5000
  timesteps_total: 2450000
  training_iteration: 490
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5835 s, 490 iter, 2450000 ts, 608 rew

agent-1: 135.0
agent-2: 143.0
agent-3: 136.0
agent-4: 110.0
agent-5: 132.0
Sum Reward: 656.0
Avg Reward: 131.2
Min Reward: 110.0
Gini Coefficient: 0.042682926829268296
20:20 Ratio: 1.3
Max-min Ratio: 1.3
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-44-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 608.87
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 490
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.833
    dispatch_time_ms: 7.62
    learner:
      cur_lr: 0.0011968299513682723
      grad_gnorm: 40.00000762939453
      policy_entropy: 48.86703872680664
      policy_loss: 42.402828216552734
      var_gnorm: 52.95346450805664
      vf_explained_var: 0.4035186767578125
      vf_loss: 72.33875274658203
    num_steps_sampled: 2455000
    num_steps_trained: 2455000
    wait_time_ms: 90.852
  iterations_since_restore: 491
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5845.453497409821
  time_this_iter_s: 10.40446949005127
  time_total_s: 5845.453497409821
  timestamp: 1593999897
  timesteps_since_restore: 2455000
  timesteps_this_iter: 5000
  timesteps_total: 2455000
  training_iteration: 491
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5845 s, 491 iter, 2455000 ts, 609 rew

agent-1: 152.0
agent-2: 107.0
agent-3: 67.0
agent-4: 146.0
agent-5: 184.0
Sum Reward: 656.0
Avg Reward: 131.2
Min Reward: 67.0
Gini Coefficient: 0.1701219512195122
20:20 Ratio: 2.746268656716418
Max-min Ratio: 2.746268656716418
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-45-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 610.87
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 491
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.897
    dispatch_time_ms: 6.805
    learner:
      cur_lr: 0.0011964970035478473
      grad_gnorm: 40.0
      policy_entropy: 26.595792770385742
      policy_loss: 13.166622161865234
      var_gnorm: 52.99238967895508
      vf_explained_var: 0.5877687931060791
      vf_loss: 32.012977600097656
    num_steps_sampled: 2460000
    num_steps_trained: 2460000
    wait_time_ms: 91.888
  iterations_since_restore: 492
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5855.59516954422
  time_this_iter_s: 10.141672134399414
  time_total_s: 5855.59516954422
  timestamp: 1593999908
  timesteps_since_restore: 2460000
  timesteps_this_iter: 5000
  timesteps_total: 2460000
  training_iteration: 492
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5855 s, 492 iter, 2460000 ts, 611 rew

agent-1: 97.0
agent-2: 94.0
agent-3: 132.0
agent-4: 89.0
agent-5: 156.0
Sum Reward: 568.0
Avg Reward: 113.6
Min Reward: 89.0
Gini Coefficient: 0.12112676056338029
20:20 Ratio: 1.752808988764045
Max-min Ratio: 1.752808988764045
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-45-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 609.96
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 492
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.343
    dispatch_time_ms: 7.352
    learner:
      cur_lr: 0.0011961640557274222
      grad_gnorm: 40.0
      policy_entropy: 44.55158615112305
      policy_loss: 46.30325698852539
      var_gnorm: 52.94297409057617
      vf_explained_var: 0.47146791219711304
      vf_loss: 129.28887939453125
    num_steps_sampled: 2465000
    num_steps_trained: 2465000
    wait_time_ms: 90.517
  iterations_since_restore: 493
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5865.641147375107
  time_this_iter_s: 10.04597783088684
  time_total_s: 5865.641147375107
  timestamp: 1593999918
  timesteps_since_restore: 2465000
  timesteps_this_iter: 5000
  timesteps_total: 2465000
  training_iteration: 493
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5865 s, 493 iter, 2465000 ts, 610 rew

agent-1: 93.0
agent-2: 179.0
agent-3: 85.0
agent-4: 88.0
agent-5: 135.0
Sum Reward: 580.0
Avg Reward: 116.0
Min Reward: 85.0
Gini Coefficient: 0.16206896551724137
20:20 Ratio: 2.1058823529411765
Max-min Ratio: 2.1058823529411765
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-45-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 609.4
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 493
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.43
    dispatch_time_ms: 9.312
    learner:
      cur_lr: 0.0011958309914916754
      grad_gnorm: 40.00000762939453
      policy_entropy: 44.761924743652344
      policy_loss: -18.417865753173828
      var_gnorm: 52.96470642089844
      vf_explained_var: 0.6573987603187561
      vf_loss: 7.215014934539795
    num_steps_sampled: 2470000
    num_steps_trained: 2470000
    wait_time_ms: 93.82
  iterations_since_restore: 494
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5875.712481737137
  time_this_iter_s: 10.07133436203003
  time_total_s: 5875.712481737137
  timestamp: 1593999928
  timesteps_since_restore: 2470000
  timesteps_this_iter: 5000
  timesteps_total: 2470000
  training_iteration: 494
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5875 s, 494 iter, 2470000 ts, 609 rew

agent-1: 125.0
agent-2: 126.0
agent-3: 122.0
agent-4: 107.0
agent-5: 130.0
Sum Reward: 610.0
Avg Reward: 122.0
Min Reward: 107.0
Gini Coefficient: 0.03278688524590164
20:20 Ratio: 1.2149532710280373
Max-min Ratio: 1.2149532710280373
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-45-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 608.88
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 494
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 4.076
    dispatch_time_ms: 10.595
    learner:
      cur_lr: 0.0011954980436712503
      grad_gnorm: 40.0
      policy_entropy: 35.92570114135742
      policy_loss: 2.453630208969116
      var_gnorm: 52.998199462890625
      vf_explained_var: 0.22998851537704468
      vf_loss: 47.38954544067383
    num_steps_sampled: 2475000
    num_steps_trained: 2475000
    wait_time_ms: 90.466
  iterations_since_restore: 495
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5886.346384525299
  time_this_iter_s: 10.633902788162231
  time_total_s: 5886.346384525299
  timestamp: 1593999938
  timesteps_since_restore: 2475000
  timesteps_this_iter: 5000
  timesteps_total: 2475000
  training_iteration: 495
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5886 s, 495 iter, 2475000 ts, 609 rew

agent-1: 138.0
agent-2: 187.0
agent-3: 173.0
agent-4: 112.0
agent-5: 146.0
Sum Reward: 756.0
Avg Reward: 151.2
Min Reward: 112.0
Gini Coefficient: 0.09788359788359788
20:20 Ratio: 1.6696428571428572
Max-min Ratio: 1.6696428571428572
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-45-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 610.5
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 495
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.816
    dispatch_time_ms: 5.919
    learner:
      cur_lr: 0.0011951649794355035
      grad_gnorm: 24.55561637878418
      policy_entropy: 35.636104583740234
      policy_loss: -4.06118631362915
      var_gnorm: 53.071311950683594
      vf_explained_var: 0.566107451915741
      vf_loss: 16.36571502685547
    num_steps_sampled: 2480000
    num_steps_trained: 2480000
    wait_time_ms: 96.533
  iterations_since_restore: 496
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5896.258659601212
  time_this_iter_s: 9.912275075912476
  time_total_s: 5896.258659601212
  timestamp: 1593999948
  timesteps_since_restore: 2480000
  timesteps_this_iter: 5000
  timesteps_total: 2480000
  training_iteration: 496
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5896 s, 496 iter, 2480000 ts, 610 rew

agent-1: 131.0
agent-2: 151.0
agent-3: 138.0
agent-4: 130.0
agent-5: 150.0
Sum Reward: 700.0
Avg Reward: 140.0
Min Reward: 130.0
Gini Coefficient: 0.03485714285714286
20:20 Ratio: 1.1615384615384616
Max-min Ratio: 1.1615384615384616
agent-1: 122.0
agent-2: 147.0
agent-3: 77.0
agent-4: 122.0
agent-5: 213.0
Sum Reward: 681.0
Avg Reward: 136.2
Min Reward: 77.0
Gini Coefficient: 0.17444933920704847
20:20 Ratio: 2.7662337662337664
Max-min Ratio: 2.7662337662337664
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-45-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 609.75
  episode_reward_min: 303.0
  episodes_this_iter: 2
  episodes_total: 497
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.456
    dispatch_time_ms: 8.415
    learner:
      cur_lr: 0.0011948320316150784
      grad_gnorm: 40.000003814697266
      policy_entropy: 36.61056137084961
      policy_loss: -368.3839111328125
      var_gnorm: 53.13288497924805
      vf_explained_var: 6.115436553955078e-05
      vf_loss: 3059.65478515625
    num_steps_sampled: 2485000
    num_steps_trained: 2485000
    wait_time_ms: 88.999
  iterations_since_restore: 497
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5906.562831163406
  time_this_iter_s: 10.304171562194824
  time_total_s: 5906.562831163406
  timestamp: 1593999959
  timesteps_since_restore: 2485000
  timesteps_this_iter: 5000
  timesteps_total: 2485000
  training_iteration: 497
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5906 s, 497 iter, 2485000 ts, 610 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-46-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 609.75
  episode_reward_min: 303.0
  episodes_this_iter: 0
  episodes_total: 497
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.899
    dispatch_time_ms: 7.122
    learner:
      cur_lr: 0.0011944989673793316
      grad_gnorm: 40.0
      policy_entropy: 47.69646453857422
      policy_loss: -11.7733736038208
      var_gnorm: 53.14959716796875
      vf_explained_var: -0.00030803680419921875
      vf_loss: 21.954877853393555
    num_steps_sampled: 2490000
    num_steps_trained: 2490000
    wait_time_ms: 86.899
  iterations_since_restore: 498
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5916.331898927689
  time_this_iter_s: 9.769067764282227
  time_total_s: 5916.331898927689
  timestamp: 1593999969
  timesteps_since_restore: 2490000
  timesteps_this_iter: 5000
  timesteps_total: 2490000
  training_iteration: 498
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5916 s, 498 iter, 2490000 ts, 610 rew

agent-1: 110.0
agent-2: 168.0
agent-3: 120.0
agent-4: 127.0
agent-5: 143.0
Sum Reward: 668.0
Avg Reward: 133.6
Min Reward: 110.0
Gini Coefficient: 0.08323353293413174
20:20 Ratio: 1.5272727272727273
Max-min Ratio: 1.5272727272727273
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-46-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 608.48
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 498
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 3.082
    dispatch_time_ms: 10.229
    learner:
      cur_lr: 0.0011941660195589066
      grad_gnorm: 40.000003814697266
      policy_entropy: 39.44552993774414
      policy_loss: 9.215747833251953
      var_gnorm: 53.13197326660156
      vf_explained_var: 0.0025848746299743652
      vf_loss: 31.025671005249023
    num_steps_sampled: 2495000
    num_steps_trained: 2495000
    wait_time_ms: 82.9
  iterations_since_restore: 499
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5926.4526908397675
  time_this_iter_s: 10.120791912078857
  time_total_s: 5926.4526908397675
  timestamp: 1593999979
  timesteps_since_restore: 2495000
  timesteps_this_iter: 5000
  timesteps_total: 2495000
  training_iteration: 499
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=2384], 5926 s, 499 iter, 2495000 ts, 608 rew

agent-1: 91.0
agent-2: 112.0
agent-3: 97.0
agent-4: 155.0
agent-5: 161.0
Sum Reward: 616.0
Avg Reward: 123.2
Min Reward: 91.0
Gini Coefficient: 0.12857142857142856
20:20 Ratio: 1.7692307692307692
Max-min Ratio: 1.7692307692307692
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-46-28
  done: true
  episode_len_mean: 1000.0
  episode_reward_max: 828.0
  episode_reward_mean: 607.78
  episode_reward_min: 303.0
  episodes_this_iter: 1
  episodes_total: 499
  experiment_id: 9992864275724c65a8e2b752fca674ae
  hostname: gpu049
  info:
    apply_time_ms: 2.964
    dispatch_time_ms: 8.597
    learner:
      cur_lr: 0.0011938329553231597
      grad_gnorm: 40.0
      policy_entropy: 46.38984298706055
      policy_loss: 7.19565486907959
      var_gnorm: 53.12440872192383
      vf_explained_var: 0.08721500635147095
      vf_loss: 25.111852645874023
    num_steps_sampled: 2500000
    num_steps_trained: 2500000
    wait_time_ms: 90.618
  iterations_since_restore: 500
  node_ip: 172.17.8.49
  num_metric_batches_dropped: 0
  pid: 2384
  policy_reward_mean: {}
  time_since_restore: 5936.0676882267
  time_this_iter_s: 9.614997386932373
  time_total_s: 5936.0676882267
  timestamp: 1593999988
  timesteps_since_restore: 2500000
  timesteps_this_iter: 5000
  timesteps_total: 2500000
  training_iteration: 500
  
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
TERMINATED trials:
 - A3C_harvest_env_0:	TERMINATED [pid=2384], 5936 s, 500 iter, 2500000 ts, 608 rew

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
TERMINATED trials:
 - A3C_harvest_env_0:	TERMINATED [pid=2384], 5936 s, 500 iter, 2500000 ts, 608 rew

Commencing experiment harvest_A3C
WARNING: Logging before InitGoogleLogging() is written to STDERR
E0705 21:46:29.635890  2414 raylet_client.cc:345] IOError: [RayletClient] Connection closed unexpectedly. [RayletClient] Failed to push profile events.
WARNING: Logging before InitGoogleLogging() is written to STDERR
E0705 21:46:29.790980  2402 raylet_client.cc:345] IOError: [RayletClient] Connection closed unexpectedly. [RayletClient] Failed to push profile events.
E0705 21:46:30.709455  2414 raylet_client.cc:345] IOError: [RayletClient] Connection closed unexpectedly. [RayletClient] Failed to push profile events.
E0705 21:46:30.907439  2402 raylet_client.cc:345] IOError: [RayletClient] Connection closed unexpectedly. [RayletClient] Failed to push profile events.
