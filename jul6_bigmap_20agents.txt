/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Process STDOUT and STDERR is being redirected to /tmp/ray/session_2020-07-07_12-00-27_17743/logs.
Waiting for redis server at 127.0.0.1:45566 to respond...
Waiting for redis server at 127.0.0.1:47113 to respond...
Warning: Capping object memory store to 20.0GB. To increase this further, specify `object_store_memory` when calling ray.init() or ray start.
Starting the Plasma object store with 20.0 GB memory using /dev/shm.

======================================================================
View the web UI at http://localhost:8888/notebooks/ray_ui.ipynb?token=0e409c1c4dc8bf97b921aae4a59143435746b2eac17c8d94
======================================================================

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0/2 CPUs, 0/1 GPUs
Memory usage on this node: 12.9/202.5 GB

Created LogSyncer for /h/zhaostep/ray_results/harvest_A3C/A3C_harvest_env_0_2020-07-07_12-00-2895u3okdp -> 
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 12.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING

/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-07 12:00:40,416	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 0 on CPU (please ignore any CUDA init errors)
2020-07-07 12:00:40.417182: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-07 12:00:52,045	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 2 on CPU (please ignore any CUDA init errors)
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-07 12:00:52,045	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 1 on CPU (please ignore any CUDA init errors)
2020-07-07 12:00:52.046645: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2020-07-07 12:00:52.046692: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-01-24
  done: false
  episode_len_mean: .nan
  episode_reward_max: .nan
  episode_reward_mean: .nan
  episode_reward_min: .nan
  episodes_this_iter: 0
  episodes_total: 0
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 4.878
    dispatch_time_ms: 12.712
    learner:
      cur_lr: 0.0013599999947473407
      grad_gnorm: 39.99999237060547
      policy_entropy: 249.60662841796875
      policy_loss: 125.81808471679688
      var_gnorm: 18.097187042236328
      vf_explained_var: 0.00809246301651001
      vf_loss: 85.532958984375
    num_steps_sampled: 20000
    num_steps_trained: 20000
    wait_time_ms: 293.025
  iterations_since_restore: 1
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 42.9563524723053
  time_this_iter_s: 42.9563524723053
  time_total_s: 42.9563524723053
  timestamp: 1594137684
  timesteps_since_restore: 20000
  timesteps_this_iter: 20000
  timesteps_total: 20000
  training_iteration: 1
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 42 s, 1 iter, 20000 ts, nan rew

[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
agent-1: -410.0
agent-2: -332.0
agent-3: -507.0
agent-4: -189.0
agent-5: -349.0
agent-6: -423.0
agent-7: 20.0
agent-8: 2.0
agent-9: 46.0
agent-10: -69.0
agent-11: -19.0
agent-12: -312.0
agent-13: -161.0
agent-14: -312.0
agent-15: -164.0
agent-16: -166.0
agent-17: -175.0
agent-18: -157.0
agent-19: -689.0
agent-20: -631.0
Sum Reward: -4997.0
Avg Reward: -249.85
Min Reward: -689.0
Max Reward: 46.0
Gini Coefficient: -0.4581448869321593
20:20 Ratio: -0.021777777777777778
Max-min Ratio: -0.06676342525399129
[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
agent-1: -430.0
agent-2: -52.0
agent-3: 80.0
agent-4: 66.0
agent-5: -425.0
agent-6: 36.0
agent-7: -664.0
agent-8: -78.0
agent-9: -83.0
agent-10: -548.0
agent-11: -438.0
agent-12: -297.0
agent-13: 8.0
agent-14: -80.0
agent-15: -459.0
agent-16: -152.0
agent-17: -199.0
agent-18: -49.0
agent-19: 88.0
agent-20: -243.0
Sum Reward: -3919.0
Avg Reward: -195.95
Min Reward: -664.0
Max Reward: 88.0
Gini Coefficient: -0.6400739984689972
20:20 Ratio: -0.12802275960170698
Max-min Ratio: -0.13253012048192772
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-01-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -3919.0
  episode_reward_mean: -4458.0
  episode_reward_min: -4997.0
  episodes_this_iter: 2
  episodes_total: 2
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.694
    dispatch_time_ms: 10.864
    learner:
      cur_lr: 0.0013586679706349969
      grad_gnorm: 40.000003814697266
      policy_entropy: 214.7859649658203
      policy_loss: -679.3986206054688
      var_gnorm: 18.110403060913086
      vf_explained_var: -0.5367848873138428
      vf_loss: 1065.277587890625
    num_steps_sampled: 40000
    num_steps_trained: 40000
    wait_time_ms: 306.954
  iterations_since_restore: 2
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 74.69191646575928
  time_this_iter_s: 31.73556399345398
  time_total_s: 74.69191646575928
  timestamp: 1594137716
  timesteps_since_restore: 40000
  timesteps_this_iter: 20000
  timesteps_total: 40000
  training_iteration: 2
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 74 s, 2 iter, 40000 ts, -4.46e+03 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-02-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -3919.0
  episode_reward_mean: -4458.0
  episode_reward_min: -4997.0
  episodes_this_iter: 0
  episodes_total: 2
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.616
    dispatch_time_ms: 8.091
    learner:
      cur_lr: 0.001357335946522653
      grad_gnorm: 40.000003814697266
      policy_entropy: 118.22381591796875
      policy_loss: -39.476959228515625
      var_gnorm: 18.152469635009766
      vf_explained_var: -4.744529724121094e-05
      vf_loss: 15.333640098571777
    num_steps_sampled: 60000
    num_steps_trained: 60000
    wait_time_ms: 306.463
  iterations_since_restore: 3
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 105.01092648506165
  time_this_iter_s: 30.319010019302368
  time_total_s: 105.01092648506165
  timestamp: 1594137746
  timesteps_since_restore: 60000
  timesteps_this_iter: 20000
  timesteps_total: 60000
  training_iteration: 3
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 105 s, 3 iter, 60000 ts, -4.46e+03 rew

agent-1: 49.0
agent-2: 96.0
agent-3: 126.0
agent-4: 70.0
agent-5: 95.0
agent-6: 79.0
agent-7: 62.0
agent-8: 67.0
agent-9: 14.0
agent-10: 70.0
agent-11: 69.0
agent-12: 59.0
agent-13: 78.0
agent-14: 37.0
agent-15: 58.0
agent-16: 94.0
agent-17: 80.0
agent-18: 34.0
agent-19: 54.0
agent-20: 37.0
Sum Reward: 1328.0
Avg Reward: 66.4
Min Reward: 14.0
Max Reward: 126.0
Gini Coefficient: 0.21009036144578314
20:20 Ratio: 3.3688524590163933
Max-min Ratio: 9.0
agent-1: 89.0
agent-2: 66.0
agent-3: 97.0
agent-4: 106.0
agent-5: 61.0
agent-6: 38.0
agent-7: 79.0
agent-8: 57.0
agent-9: 42.0
agent-10: 81.0
agent-11: 79.0
agent-12: 54.0
agent-13: 25.0
agent-14: 93.0
agent-15: 51.0
agent-16: 83.0
agent-17: 104.0
agent-18: 83.0
agent-19: 33.0
agent-20: 79.0
Sum Reward: 1400.0
Avg Reward: 70.0
Min Reward: 25.0
Max Reward: 106.0
Gini Coefficient: 0.18907142857142858
20:20 Ratio: 2.898550724637681
Max-min Ratio: 4.24
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-02-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: -1547.0
  episode_reward_min: -4997.0
  episodes_this_iter: 2
  episodes_total: 4
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.506
    dispatch_time_ms: 7.067
    learner:
      cur_lr: 0.0013560040388256311
      grad_gnorm: 40.000003814697266
      policy_entropy: 220.93026733398438
      policy_loss: -1021.2532958984375
      var_gnorm: 18.46854591369629
      vf_explained_var: 0.10575199127197266
      vf_loss: 2128.77001953125
    num_steps_sampled: 80000
    num_steps_trained: 80000
    wait_time_ms: 327.714
  iterations_since_restore: 4
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 137.2608449459076
  time_this_iter_s: 32.24991846084595
  time_total_s: 137.2608449459076
  timestamp: 1594137779
  timesteps_since_restore: 80000
  timesteps_this_iter: 20000
  timesteps_total: 80000
  training_iteration: 4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 137 s, 4 iter, 80000 ts, -1.55e+03 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-03-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: -1547.0
  episode_reward_min: -4997.0
  episodes_this_iter: 0
  episodes_total: 4
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.822
    dispatch_time_ms: 6.178
    learner:
      cur_lr: 0.0013546720147132874
      grad_gnorm: 40.0
      policy_entropy: 208.64688110351562
      policy_loss: 60.0015869140625
      var_gnorm: 19.0727481842041
      vf_explained_var: 0.4985926151275635
      vf_loss: 101.98829650878906
    num_steps_sampled: 100000
    num_steps_trained: 100000
    wait_time_ms: 337.003
  iterations_since_restore: 5
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 169.21585869789124
  time_this_iter_s: 31.955013751983643
  time_total_s: 169.21585869789124
  timestamp: 1594137811
  timesteps_since_restore: 100000
  timesteps_this_iter: 20000
  timesteps_total: 100000
  training_iteration: 5
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 169 s, 5 iter, 100000 ts, -1.55e+03 rew

agent-1: 47.0
agent-2: -24.0
agent-3: 41.0
agent-4: 40.0
agent-5: 62.0
agent-6: 62.0
agent-7: 14.0
agent-8: 58.0
agent-9: 69.0
agent-10: 14.0
agent-11: 52.0
agent-12: 65.0
agent-13: 28.0
agent-14: 42.0
agent-15: 38.0
agent-16: 79.0
agent-17: 45.0
agent-18: 56.0
agent-19: 3.0
agent-20: 58.0
Sum Reward: 849.0
Avg Reward: 42.45
Min Reward: -24.0
Max Reward: 79.0
Gini Coefficient: 0.30948174322732624
20:20 Ratio: 39.285714285714285
Max-min Ratio: -3.2916666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-04-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: -1067.8
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 5
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.188
    dispatch_time_ms: 5.883
    learner:
      cur_lr: 0.0013533399906009436
      grad_gnorm: 39.999996185302734
      policy_entropy: 231.23379516601562
      policy_loss: 164.75621032714844
      var_gnorm: 19.511587142944336
      vf_explained_var: 0.22185605764389038
      vf_loss: 184.00845336914062
    num_steps_sampled: 120000
    num_steps_trained: 120000
    wait_time_ms: 327.93
  iterations_since_restore: 6
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 203.95114660263062
  time_this_iter_s: 34.73528790473938
  time_total_s: 203.95114660263062
  timestamp: 1594137845
  timesteps_since_restore: 120000
  timesteps_this_iter: 20000
  timesteps_total: 120000
  training_iteration: 6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 203 s, 6 iter, 120000 ts, -1.07e+03 rew

agent-1: 63.0
agent-2: 46.0
agent-3: 68.0
agent-4: 26.0
agent-5: 47.0
agent-6: 44.0
agent-7: 36.0
agent-8: 30.0
agent-9: 41.0
agent-10: 35.0
agent-11: 33.0
agent-12: 52.0
agent-13: -16.0
agent-14: 31.0
agent-15: 52.0
agent-16: 50.0
agent-17: 40.0
agent-18: 37.0
agent-19: 50.0
agent-20: 39.0
Sum Reward: 804.0
Avg Reward: 40.2
Min Reward: -16.0
Max Reward: 68.0
Gini Coefficient: 0.2044776119402985
20:20 Ratio: 3.3098591549295775
Max-min Ratio: -4.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-04-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: -755.8333333333334
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 6
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.726
    dispatch_time_ms: 5.882
    learner:
      cur_lr: 0.0013520079664885998
      grad_gnorm: 40.000003814697266
      policy_entropy: 221.8995819091797
      policy_loss: -17.33755111694336
      var_gnorm: 19.883787155151367
      vf_explained_var: 0.6161961555480957
      vf_loss: 48.8504753112793
    num_steps_sampled: 140000
    num_steps_trained: 140000
    wait_time_ms: 326.72
  iterations_since_restore: 7
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 235.81370759010315
  time_this_iter_s: 31.862560987472534
  time_total_s: 235.81370759010315
  timestamp: 1594137877
  timesteps_since_restore: 140000
  timesteps_this_iter: 20000
  timesteps_total: 140000
  training_iteration: 7
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 235 s, 7 iter, 140000 ts, -756 rew

agent-1: 37.0
agent-2: 46.0
agent-3: 32.0
agent-4: 53.0
agent-5: 56.0
agent-6: 41.0
agent-7: 92.0
agent-8: 45.0
agent-9: 80.0
agent-10: 69.0
agent-11: 15.0
agent-12: 50.0
agent-13: 50.0
agent-14: 70.0
agent-15: 65.0
agent-16: 60.0
agent-17: 89.0
agent-18: 50.0
agent-19: 58.0
agent-20: 81.0
Sum Reward: 1139.0
Avg Reward: 56.95
Min Reward: 15.0
Max Reward: 92.0
Gini Coefficient: 0.18713784021071114
20:20 Ratio: 2.736
Max-min Ratio: 6.133333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-05-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: -485.14285714285717
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 7
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.646
    dispatch_time_ms: 6.953
    learner:
      cur_lr: 0.001350675942376256
      grad_gnorm: 40.0
      policy_entropy: 147.41973876953125
      policy_loss: 191.66549682617188
      var_gnorm: 20.381731033325195
      vf_explained_var: 0.19174617528915405
      vf_loss: 393.8653869628906
    num_steps_sampled: 160000
    num_steps_trained: 160000
    wait_time_ms: 326.11
  iterations_since_restore: 8
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 269.8846695423126
  time_this_iter_s: 34.07096195220947
  time_total_s: 269.8846695423126
  timestamp: 1594137911
  timesteps_since_restore: 160000
  timesteps_this_iter: 20000
  timesteps_total: 160000
  training_iteration: 8
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 269 s, 8 iter, 160000 ts, -485 rew

agent-1: 86.0
agent-2: 52.0
agent-3: 63.0
agent-4: 31.0
agent-5: 47.0
agent-6: 68.0
agent-7: 74.0
agent-8: 61.0
agent-9: 30.0
agent-10: 30.0
agent-11: -6.0
agent-12: 49.0
agent-13: 81.0
agent-14: 61.0
agent-15: 53.0
agent-16: -1.0
agent-17: 73.0
agent-18: 65.0
agent-19: 47.0
agent-20: 42.0
Sum Reward: 1006.0
Avg Reward: 50.3
Min Reward: -6.0
Max Reward: 86.0
Gini Coefficient: 0.2581510934393638
20:20 Ratio: 5.9245283018867925
Max-min Ratio: -14.333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-05-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: -298.75
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 8
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.657
    dispatch_time_ms: 6.378
    learner:
      cur_lr: 0.001349344034679234
      grad_gnorm: 39.999996185302734
      policy_entropy: 202.5366668701172
      policy_loss: -31.44533920288086
      var_gnorm: 20.727510452270508
      vf_explained_var: 0.6132056713104248
      vf_loss: 62.07453918457031
    num_steps_sampled: 180000
    num_steps_trained: 180000
    wait_time_ms: 331.656
  iterations_since_restore: 9
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 302.09407210350037
  time_this_iter_s: 32.209402561187744
  time_total_s: 302.09407210350037
  timestamp: 1594137944
  timesteps_since_restore: 180000
  timesteps_this_iter: 20000
  timesteps_total: 180000
  training_iteration: 9
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 302 s, 9 iter, 180000 ts, -299 rew

agent-1: 40.0
agent-2: 36.0
agent-3: 30.0
agent-4: 56.0
agent-5: 79.0
agent-6: 31.0
agent-7: 42.0
agent-8: 41.0
agent-9: 40.0
agent-10: 47.0
agent-11: 71.0
agent-12: 59.0
agent-13: 45.0
agent-14: 46.0
agent-15: 53.0
agent-16: 36.0
agent-17: 0.0
agent-18: 9.0
agent-19: 38.0
agent-20: 60.0
Sum Reward: 859.0
Avg Reward: 42.95
Min Reward: 0.0
Max Reward: 79.0
Gini Coefficient: 0.2241559953434226
20:20 Ratio: 3.842857142857143
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-06-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: -170.11111111111111
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 9
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.684
    dispatch_time_ms: 5.504
    learner:
      cur_lr: 0.0013480120105668902
      grad_gnorm: 39.99999237060547
      policy_entropy: 147.82415771484375
      policy_loss: 177.45298767089844
      var_gnorm: 21.056257247924805
      vf_explained_var: 0.20327037572860718
      vf_loss: 303.5298767089844
    num_steps_sampled: 200000
    num_steps_trained: 200000
    wait_time_ms: 299.003
  iterations_since_restore: 10
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 336.67503929138184
  time_this_iter_s: 34.58096718788147
  time_total_s: 336.67503929138184
  timestamp: 1594137978
  timesteps_since_restore: 200000
  timesteps_this_iter: 20000
  timesteps_total: 200000
  training_iteration: 10
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 336 s, 10 iter, 200000 ts, -170 rew

agent-1: 49.0
agent-2: 33.0
agent-3: 40.0
agent-4: 63.0
agent-5: 1.0
agent-6: 64.0
agent-7: 61.0
agent-8: 40.0
agent-9: 52.0
agent-10: 52.0
agent-11: 54.0
agent-12: 56.0
agent-13: 38.0
agent-14: 39.0
agent-15: 53.0
agent-16: 47.0
agent-17: 59.0
agent-18: 50.0
agent-19: 42.0
agent-20: 60.0
Sum Reward: 953.0
Avg Reward: 47.65
Min Reward: 1.0
Max Reward: 64.0
Gini Coefficient: 0.14706190975865688
20:20 Ratio: 2.234234234234234
Max-min Ratio: 64.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-06-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: -57.8
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 10
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.428
    dispatch_time_ms: 7.163
    learner:
      cur_lr: 0.0013466799864545465
      grad_gnorm: 40.000003814697266
      policy_entropy: 224.4820556640625
      policy_loss: -18.920631408691406
      var_gnorm: 21.45989990234375
      vf_explained_var: 0.5264371633529663
      vf_loss: 8.71944522857666
    num_steps_sampled: 220000
    num_steps_trained: 220000
    wait_time_ms: 339.051
  iterations_since_restore: 11
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 370.0700714588165
  time_this_iter_s: 33.39503216743469
  time_total_s: 370.0700714588165
  timestamp: 1594138012
  timesteps_since_restore: 220000
  timesteps_this_iter: 20000
  timesteps_total: 220000
  training_iteration: 11
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 370 s, 11 iter, 220000 ts, -57.8 rew

agent-1: 40.0
agent-2: 31.0
agent-3: 42.0
agent-4: 30.0
agent-5: 41.0
agent-6: 49.0
agent-7: 27.0
agent-8: 48.0
agent-9: 32.0
agent-10: 29.0
agent-11: 31.0
agent-12: 53.0
agent-13: 44.0
agent-14: 26.0
agent-15: 26.0
agent-16: 45.0
agent-17: 48.0
agent-18: 43.0
agent-19: 41.0
agent-20: 45.0
Sum Reward: 771.0
Avg Reward: 38.55
Min Reward: 26.0
Max Reward: 53.0
Gini Coefficient: 0.12380025940337225
20:20 Ratio: 1.8333333333333333
Max-min Ratio: 2.0384615384615383
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-07-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 17.545454545454547
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 11
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.753
    dispatch_time_ms: 7.094
    learner:
      cur_lr: 0.0013453479623422027
      grad_gnorm: 40.0
      policy_entropy: 193.47698974609375
      policy_loss: 69.09407806396484
      var_gnorm: 21.59232521057129
      vf_explained_var: 0.24085670709609985
      vf_loss: 176.1362762451172
    num_steps_sampled: 240000
    num_steps_trained: 240000
    wait_time_ms: 321.972
  iterations_since_restore: 12
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 404.8843472003937
  time_this_iter_s: 34.81427574157715
  time_total_s: 404.8843472003937
  timestamp: 1594138046
  timesteps_since_restore: 240000
  timesteps_this_iter: 20000
  timesteps_total: 240000
  training_iteration: 12
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 404 s, 12 iter, 240000 ts, 17.5 rew

agent-1: 69.0
agent-2: 33.0
agent-3: 43.0
agent-4: 41.0
agent-5: 42.0
agent-6: 35.0
agent-7: 53.0
agent-8: 45.0
agent-9: 36.0
agent-10: -8.0
agent-11: 44.0
agent-12: 42.0
agent-13: 45.0
agent-14: 37.0
agent-15: 41.0
agent-16: 32.0
agent-17: 24.0
agent-18: 28.0
agent-19: 45.0
agent-20: 33.0
Sum Reward: 760.0
Avg Reward: 38.0
Min Reward: -8.0
Max Reward: 69.0
Gini Coefficient: 0.17842105263157895
20:20 Ratio: 2.789473684210526
Max-min Ratio: -8.625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-08-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 79.41666666666667
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 12
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.502
    dispatch_time_ms: 6.112
    learner:
      cur_lr: 0.0013440160546451807
      grad_gnorm: 8.012412071228027
      policy_entropy: 281.71826171875
      policy_loss: -6.045806884765625
      var_gnorm: 22.0390682220459
      vf_explained_var: 0.9940260052680969
      vf_loss: 0.023002183064818382
    num_steps_sampled: 260000
    num_steps_trained: 260000
    wait_time_ms: 346.893
  iterations_since_restore: 13
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 438.21189546585083
  time_this_iter_s: 33.32754826545715
  time_total_s: 438.21189546585083
  timestamp: 1594138080
  timesteps_since_restore: 260000
  timesteps_this_iter: 20000
  timesteps_total: 260000
  training_iteration: 13
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 438 s, 13 iter, 260000 ts, 79.4 rew

agent-1: 37.0
agent-2: -12.0
agent-3: 33.0
agent-4: 28.0
agent-5: 53.0
agent-6: 24.0
agent-7: 50.0
agent-8: 42.0
agent-9: 45.0
agent-10: 50.0
agent-11: 28.0
agent-12: 38.0
agent-13: 31.0
agent-14: 36.0
agent-15: 40.0
agent-16: 35.0
agent-17: 40.0
agent-18: 28.0
agent-19: 55.0
agent-20: 33.0
Sum Reward: 714.0
Avg Reward: 35.7
Min Reward: -12.0
Max Reward: 55.0
Gini Coefficient: 0.19341736694677872
20:20 Ratio: 3.0588235294117645
Max-min Ratio: -4.583333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-08-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 128.23076923076923
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 13
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.007
    dispatch_time_ms: 5.727
    learner:
      cur_lr: 0.001342684030532837
      grad_gnorm: 3.9836535453796387
      policy_entropy: 300.990478515625
      policy_loss: -0.3331301212310791
      var_gnorm: 22.054344177246094
      vf_explained_var: 0.007499039173126221
      vf_loss: 0.003999074921011925
    num_steps_sampled: 280000
    num_steps_trained: 280000
    wait_time_ms: 299.927
  iterations_since_restore: 14
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 472.8137938976288
  time_this_iter_s: 34.601898431777954
  time_total_s: 472.8137938976288
  timestamp: 1594138114
  timesteps_since_restore: 280000
  timesteps_this_iter: 20000
  timesteps_total: 280000
  training_iteration: 14
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 472 s, 14 iter, 280000 ts, 128 rew

agent-1: 50.0
agent-2: 26.0
agent-3: 36.0
agent-4: 20.0
agent-5: 26.0
agent-6: 55.0
agent-7: 35.0
agent-8: 31.0
agent-9: 51.0
agent-10: 28.0
agent-11: 40.0
agent-12: 59.0
agent-13: 41.0
agent-14: 29.0
agent-15: 23.0
agent-16: 36.0
agent-17: 31.0
agent-18: 32.0
agent-19: 47.0
agent-20: 25.0
Sum Reward: 721.0
Avg Reward: 36.05
Min Reward: 20.0
Max Reward: 59.0
Gini Coefficient: 0.170249653259362
20:20 Ratio: 2.2872340425531914
Max-min Ratio: 2.95
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-09-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 170.57142857142858
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 14
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.872
    dispatch_time_ms: 6.128
    learner:
      cur_lr: 0.0013413520064204931
      grad_gnorm: 32.481449127197266
      policy_entropy: 277.21905517578125
      policy_loss: -17.891061782836914
      var_gnorm: 22.35051727294922
      vf_explained_var: 4.231929779052734e-06
      vf_loss: 0.2834523916244507
    num_steps_sampled: 300000
    num_steps_trained: 300000
    wait_time_ms: 339.82
  iterations_since_restore: 15
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 506.19155502319336
  time_this_iter_s: 33.377761125564575
  time_total_s: 506.19155502319336
  timestamp: 1594138148
  timesteps_since_restore: 300000
  timesteps_this_iter: 20000
  timesteps_total: 300000
  training_iteration: 15
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 506 s, 15 iter, 300000 ts, 171 rew

agent-1: 38.0
agent-2: 59.0
agent-3: 50.0
agent-4: 44.0
agent-5: 45.0
agent-6: 44.0
agent-7: 32.0
agent-8: 27.0
agent-9: 43.0
agent-10: 50.0
agent-11: 25.0
agent-12: 31.0
agent-13: 20.0
agent-14: 33.0
agent-15: 48.0
agent-16: 31.0
agent-17: 29.0
agent-18: 62.0
agent-19: 36.0
agent-20: 36.0
Sum Reward: 783.0
Avg Reward: 39.15
Min Reward: 20.0
Max Reward: 62.0
Gini Coefficient: 0.15766283524904215
20:20 Ratio: 2.1881188118811883
Max-min Ratio: 3.1
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-09-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 211.4
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 15
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.507
    dispatch_time_ms: 5.918
    learner:
      cur_lr: 0.0013400199823081493
      grad_gnorm: 40.000003814697266
      policy_entropy: 105.49030303955078
      policy_loss: 58.04090118408203
      var_gnorm: 22.45591926574707
      vf_explained_var: 0.42555201053619385
      vf_loss: 141.54000854492188
    num_steps_sampled: 320000
    num_steps_trained: 320000
    wait_time_ms: 284.047
  iterations_since_restore: 16
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 540.8555788993835
  time_this_iter_s: 34.664023876190186
  time_total_s: 540.8555788993835
  timestamp: 1594138183
  timesteps_since_restore: 320000
  timesteps_this_iter: 20000
  timesteps_total: 320000
  training_iteration: 16
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 540 s, 16 iter, 320000 ts, 211 rew

agent-1: 55.0
agent-2: 32.0
agent-3: 42.0
agent-4: 60.0
agent-5: 42.0
agent-6: 40.0
agent-7: 40.0
agent-8: 22.0
agent-9: 19.0
agent-10: 33.0
agent-11: 31.0
agent-12: 42.0
agent-13: 31.0
agent-14: 31.0
agent-15: 27.0
agent-16: 33.0
agent-17: 24.0
agent-18: 44.0
agent-19: 30.0
agent-20: 37.0
Sum Reward: 715.0
Avg Reward: 35.75
Min Reward: 19.0
Max Reward: 60.0
Gini Coefficient: 0.15307692307692308
20:20 Ratio: 2.1847826086956523
Max-min Ratio: 3.1578947368421053
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-10-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 242.875
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 16
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.406
    dispatch_time_ms: 5.359
    learner:
      cur_lr: 0.0013386879581958055
      grad_gnorm: 40.000003814697266
      policy_entropy: 250.78102111816406
      policy_loss: 11.318510055541992
      var_gnorm: 22.739242553710938
      vf_explained_var: 0.27888023853302
      vf_loss: 26.210264205932617
    num_steps_sampled: 340000
    num_steps_trained: 340000
    wait_time_ms: 339.071
  iterations_since_restore: 17
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 574.5358021259308
  time_this_iter_s: 33.68022322654724
  time_total_s: 574.5358021259308
  timestamp: 1594138216
  timesteps_since_restore: 340000
  timesteps_this_iter: 20000
  timesteps_total: 340000
  training_iteration: 17
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 574 s, 17 iter, 340000 ts, 243 rew

agent-1: 42.0
agent-2: 14.0
agent-3: 35.0
agent-4: 30.0
agent-5: 49.0
agent-6: 50.0
agent-7: 51.0
agent-8: 47.0
agent-9: 25.0
agent-10: 32.0
agent-11: 36.0
agent-12: 41.0
agent-13: 35.0
agent-14: 51.0
agent-15: 39.0
agent-16: 59.0
agent-17: 26.0
agent-18: 32.0
agent-19: 44.0
agent-20: 36.0
Sum Reward: 774.0
Avg Reward: 38.7
Min Reward: 14.0
Max Reward: 59.0
Gini Coefficient: 0.15310077519379844
20:20 Ratio: 2.221052631578947
Max-min Ratio: 4.214285714285714
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-10-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 274.11764705882354
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 17
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.958
    dispatch_time_ms: 6.683
    learner:
      cur_lr: 0.0013373560504987836
      grad_gnorm: 40.000003814697266
      policy_entropy: 186.7138214111328
      policy_loss: 120.92933654785156
      var_gnorm: 22.781198501586914
      vf_explained_var: 0.6799312829971313
      vf_loss: 218.8040771484375
    num_steps_sampled: 360000
    num_steps_trained: 360000
    wait_time_ms: 331.952
  iterations_since_restore: 18
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 609.4474472999573
  time_this_iter_s: 34.91164517402649
  time_total_s: 609.4474472999573
  timestamp: 1594138251
  timesteps_since_restore: 360000
  timesteps_this_iter: 20000
  timesteps_total: 360000
  training_iteration: 18
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 609 s, 18 iter, 360000 ts, 274 rew

agent-1: 40.0
agent-2: 24.0
agent-3: 23.0
agent-4: 52.0
agent-5: 33.0
agent-6: 42.0
agent-7: 30.0
agent-8: 59.0
agent-9: 35.0
agent-10: 38.0
agent-11: 28.0
agent-12: 38.0
agent-13: 44.0
agent-14: 46.0
agent-15: 60.0
agent-16: 40.0
agent-17: 47.0
agent-18: 36.0
agent-19: 18.0
agent-20: 33.0
Sum Reward: 766.0
Avg Reward: 38.3
Min Reward: 18.0
Max Reward: 60.0
Gini Coefficient: 0.16005221932114883
20:20 Ratio: 2.3440860215053765
Max-min Ratio: 3.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-11-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 301.44444444444446
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 18
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.931
    dispatch_time_ms: 6.078
    learner:
      cur_lr: 0.0013360240263864398
      grad_gnorm: 2.352921724319458
      policy_entropy: 199.03485107421875
      policy_loss: -0.6796889305114746
      var_gnorm: 23.09189224243164
      vf_explained_var: 0.9915305972099304
      vf_loss: 0.007246125023812056
    num_steps_sampled: 380000
    num_steps_trained: 380000
    wait_time_ms: 340.129
  iterations_since_restore: 19
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 643.2760224342346
  time_this_iter_s: 33.828575134277344
  time_total_s: 643.2760224342346
  timestamp: 1594138285
  timesteps_since_restore: 380000
  timesteps_this_iter: 20000
  timesteps_total: 380000
  training_iteration: 19
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 643 s, 19 iter, 380000 ts, 301 rew

agent-1: 36.0
agent-2: 35.0
agent-3: 21.0
agent-4: 37.0
agent-5: 9.0
agent-6: 37.0
agent-7: 39.0
agent-8: 31.0
agent-9: 33.0
agent-10: 36.0
agent-11: 25.0
agent-12: 23.0
agent-13: 39.0
agent-14: 47.0
agent-15: 28.0
agent-16: 22.0
agent-17: 28.0
agent-18: 30.0
agent-19: 40.0
agent-20: 45.0
Sum Reward: 641.0
Avg Reward: 32.05
Min Reward: 9.0
Max Reward: 47.0
Gini Coefficient: 0.15234009360374415
20:20 Ratio: 2.28
Max-min Ratio: 5.222222222222222
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-12-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 319.3157894736842
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 19
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.686
    dispatch_time_ms: 6.223
    learner:
      cur_lr: 0.001334692002274096
      grad_gnorm: 40.0
      policy_entropy: 117.34449768066406
      policy_loss: 45.997413635253906
      var_gnorm: 23.132734298706055
      vf_explained_var: 0.3719487190246582
      vf_loss: 287.43597412109375
    num_steps_sampled: 400000
    num_steps_trained: 400000
    wait_time_ms: 311.968
  iterations_since_restore: 20
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 677.7715244293213
  time_this_iter_s: 34.49550199508667
  time_total_s: 677.7715244293213
  timestamp: 1594138320
  timesteps_since_restore: 400000
  timesteps_this_iter: 20000
  timesteps_total: 400000
  training_iteration: 20
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 677 s, 20 iter, 400000 ts, 319 rew

agent-1: 33.0
agent-2: 42.0
agent-3: 40.0
agent-4: 33.0
agent-5: 48.0
agent-6: 37.0
agent-7: 24.0
agent-8: 32.0
agent-9: 22.0
agent-10: 33.0
agent-11: 44.0
agent-12: 27.0
agent-13: 41.0
agent-14: 35.0
agent-15: 26.0
agent-16: 32.0
agent-17: 31.0
agent-18: 40.0
agent-19: 32.0
agent-20: 25.0
Sum Reward: 677.0
Avg Reward: 33.85
Min Reward: 22.0
Max Reward: 48.0
Gini Coefficient: 0.11528803545051698
20:20 Ratio: 1.8041237113402062
Max-min Ratio: 2.1818181818181817
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-12-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 337.2
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 20
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.707
    dispatch_time_ms: 6.751
    learner:
      cur_lr: 0.0013333599781617522
      grad_gnorm: 3.7460079193115234
      policy_entropy: 132.1170196533203
      policy_loss: 1.1535727977752686
      var_gnorm: 23.37934112548828
      vf_explained_var: 0.9935525059700012
      vf_loss: 0.004299231804907322
    num_steps_sampled: 420000
    num_steps_trained: 420000
    wait_time_ms: 346.376
  iterations_since_restore: 21
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 711.6656332015991
  time_this_iter_s: 33.89410877227783
  time_total_s: 711.6656332015991
  timestamp: 1594138354
  timesteps_since_restore: 420000
  timesteps_this_iter: 20000
  timesteps_total: 420000
  training_iteration: 21
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 711 s, 21 iter, 420000 ts, 337 rew

agent-1: 43.0
agent-2: 38.0
agent-3: 28.0
agent-4: 12.0
agent-5: 32.0
agent-6: 25.0
agent-7: 38.0
agent-8: 40.0
agent-9: 24.0
agent-10: 35.0
agent-11: 42.0
agent-12: 39.0
agent-13: 37.0
agent-14: 35.0
agent-15: 18.0
agent-16: 32.0
agent-17: 25.0
agent-18: 41.0
agent-19: 20.0
agent-20: 28.0
Sum Reward: 632.0
Avg Reward: 31.6
Min Reward: 12.0
Max Reward: 43.0
Gini Coefficient: 0.15174050632911393
20:20 Ratio: 2.2432432432432434
Max-min Ratio: 3.5833333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-13-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 351.23809523809524
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 21
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.218
    dispatch_time_ms: 8.562
    learner:
      cur_lr: 0.0013320279540494084
      grad_gnorm: 3.689866065979004
      policy_entropy: 167.44332885742188
      policy_loss: -0.17072954773902893
      var_gnorm: 23.379972457885742
      vf_explained_var: 0.011972427368164062
      vf_loss: 0.0033254886511713266
    num_steps_sampled: 440000
    num_steps_trained: 440000
    wait_time_ms: 313.236
  iterations_since_restore: 22
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 746.5416049957275
  time_this_iter_s: 34.87597179412842
  time_total_s: 746.5416049957275
  timestamp: 1594138388
  timesteps_since_restore: 440000
  timesteps_this_iter: 20000
  timesteps_total: 440000
  training_iteration: 22
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 746 s, 22 iter, 440000 ts, 351 rew

agent-1: 19.0
agent-2: 26.0
agent-3: 20.0
agent-4: 26.0
agent-5: 25.0
agent-6: 31.0
agent-7: 24.0
agent-8: 31.0
agent-9: 29.0
agent-10: 28.0
agent-11: 34.0
agent-12: 29.0
agent-13: 46.0
agent-14: 44.0
agent-15: 36.0
agent-16: 24.0
agent-17: 24.0
agent-18: 37.0
agent-19: 28.0
agent-20: 21.0
Sum Reward: 582.0
Avg Reward: 29.1
Min Reward: 19.0
Max Reward: 46.0
Gini Coefficient: 0.13367697594501718
20:20 Ratio: 1.9404761904761905
Max-min Ratio: 2.4210526315789473
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-13-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 361.72727272727275
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 22
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.637
    dispatch_time_ms: 7.445
    learner:
      cur_lr: 0.0013306960463523865
      grad_gnorm: 40.000030517578125
      policy_entropy: 142.71385192871094
      policy_loss: -1.4848413467407227
      var_gnorm: 23.6267032623291
      vf_explained_var: 0.5001858472824097
      vf_loss: 2.2705483436584473
    num_steps_sampled: 460000
    num_steps_trained: 460000
    wait_time_ms: 339.98
  iterations_since_restore: 23
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 780.330372095108
  time_this_iter_s: 33.78876709938049
  time_total_s: 780.330372095108
  timestamp: 1594138422
  timesteps_since_restore: 460000
  timesteps_this_iter: 20000
  timesteps_total: 460000
  training_iteration: 23
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 780 s, 23 iter, 460000 ts, 362 rew

agent-1: 35.0
agent-2: 30.0
agent-3: 20.0
agent-4: 61.0
agent-5: 28.0
agent-6: 21.0
agent-7: 29.0
agent-8: 32.0
agent-9: 38.0
agent-10: 40.0
agent-11: 22.0
agent-12: 31.0
agent-13: 26.0
agent-14: 29.0
agent-15: 54.0
agent-16: 33.0
agent-17: 26.0
agent-18: 27.0
agent-19: 22.0
agent-20: 28.0
Sum Reward: 632.0
Avg Reward: 31.6
Min Reward: 20.0
Max Reward: 61.0
Gini Coefficient: 0.1610759493670886
20:20 Ratio: 2.2705882352941176
Max-min Ratio: 3.05
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-14-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 373.4782608695652
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 23
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.196
    dispatch_time_ms: 6.967
    learner:
      cur_lr: 0.0013293640222400427
      grad_gnorm: 40.000003814697266
      policy_entropy: 63.945003509521484
      policy_loss: -15.913726806640625
      var_gnorm: 23.646923065185547
      vf_explained_var: 0.12419384717941284
      vf_loss: 450.7874755859375
    num_steps_sampled: 480000
    num_steps_trained: 480000
    wait_time_ms: 291.772
  iterations_since_restore: 24
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 814.9749104976654
  time_this_iter_s: 34.64453840255737
  time_total_s: 814.9749104976654
  timestamp: 1594138457
  timesteps_since_restore: 480000
  timesteps_this_iter: 20000
  timesteps_total: 480000
  training_iteration: 24
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 814 s, 24 iter, 480000 ts, 373 rew

agent-1: 25.0
agent-2: 35.0
agent-3: 40.0
agent-4: 45.0
agent-5: 8.0
agent-6: 32.0
agent-7: 28.0
agent-8: 23.0
agent-9: 33.0
agent-10: 43.0
agent-11: 42.0
agent-12: 32.0
agent-13: 25.0
agent-14: 30.0
agent-15: 29.0
agent-16: 29.0
agent-17: 35.0
agent-18: 23.0
agent-19: 45.0
agent-20: 32.0
Sum Reward: 634.0
Avg Reward: 31.7
Min Reward: 8.0
Max Reward: 45.0
Gini Coefficient: 0.1493690851735016
20:20 Ratio: 2.2151898734177213
Max-min Ratio: 5.625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-14-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 384.3333333333333
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 24
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.436
    dispatch_time_ms: 7.277
    learner:
      cur_lr: 0.001328031998127699
      grad_gnorm: 5.323389530181885
      policy_entropy: 206.28468322753906
      policy_loss: 0.15612827241420746
      var_gnorm: 23.8967227935791
      vf_explained_var: -1.0
      vf_loss: 0.02043914422392845
    num_steps_sampled: 500000
    num_steps_trained: 500000
    wait_time_ms: 349.846
  iterations_since_restore: 25
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 849.4306988716125
  time_this_iter_s: 34.455788373947144
  time_total_s: 849.4306988716125
  timestamp: 1594138491
  timesteps_since_restore: 500000
  timesteps_this_iter: 20000
  timesteps_total: 500000
  training_iteration: 25
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 849 s, 25 iter, 500000 ts, 384 rew

agent-1: 30.0
agent-2: 40.0
agent-3: 27.0
agent-4: 39.0
agent-5: 33.0
agent-6: 40.0
agent-7: 31.0
agent-8: 32.0
agent-9: 35.0
agent-10: 40.0
agent-11: 26.0
agent-12: 35.0
agent-13: 44.0
agent-14: 31.0
agent-15: 17.0
agent-16: 32.0
agent-17: 49.0
agent-18: 22.0
agent-19: 36.0
agent-20: 25.0
Sum Reward: 664.0
Avg Reward: 33.2
Min Reward: 17.0
Max Reward: 49.0
Gini Coefficient: 0.126355421686747
20:20 Ratio: 1.9222222222222223
Max-min Ratio: 2.8823529411764706
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-15-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 395.52
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 25
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.8
    dispatch_time_ms: 6.611
    learner:
      cur_lr: 0.0013266999740153551
      grad_gnorm: 39.999996185302734
      policy_entropy: 120.93509674072266
      policy_loss: -42.72148895263672
      var_gnorm: 23.904430389404297
      vf_explained_var: -0.025087833404541016
      vf_loss: 221.8046112060547
    num_steps_sampled: 520000
    num_steps_trained: 520000
    wait_time_ms: 315.195
  iterations_since_restore: 26
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 883.7835783958435
  time_this_iter_s: 34.35287952423096
  time_total_s: 883.7835783958435
  timestamp: 1594138526
  timesteps_since_restore: 520000
  timesteps_this_iter: 20000
  timesteps_total: 520000
  training_iteration: 26
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 883 s, 26 iter, 520000 ts, 396 rew

agent-1: 32.0
agent-2: 32.0
agent-3: 32.0
agent-4: 26.0
agent-5: 31.0
agent-6: 39.0
agent-7: 22.0
agent-8: 37.0
agent-9: 46.0
agent-10: 24.0
agent-11: 25.0
agent-12: 26.0
agent-13: 36.0
agent-14: 31.0
agent-15: 27.0
agent-16: 28.0
agent-17: 36.0
agent-18: 40.0
agent-19: 43.0
agent-20: 27.0
Sum Reward: 640.0
Avg Reward: 32.0
Min Reward: 22.0
Max Reward: 46.0
Gini Coefficient: 0.11421875
20:20 Ratio: 1.731958762886598
Max-min Ratio: 2.090909090909091
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-16-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 404.9230769230769
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 26
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.532
    dispatch_time_ms: 7.878
    learner:
      cur_lr: 0.0013253679499030113
      grad_gnorm: 33.21957778930664
      policy_entropy: 197.39260864257812
      policy_loss: 3.9332773685455322
      var_gnorm: 24.175273895263672
      vf_explained_var: 0.8580496907234192
      vf_loss: 1.1803932189941406
    num_steps_sampled: 540000
    num_steps_trained: 540000
    wait_time_ms: 330.848
  iterations_since_restore: 27
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 917.5694875717163
  time_this_iter_s: 33.7859091758728
  time_total_s: 917.5694875717163
  timestamp: 1594138560
  timesteps_since_restore: 540000
  timesteps_this_iter: 20000
  timesteps_total: 540000
  training_iteration: 27
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 917 s, 27 iter, 540000 ts, 405 rew

agent-1: 44.0
agent-2: 36.0
agent-3: 29.0
agent-4: 37.0
agent-5: 34.0
agent-6: 66.0
agent-7: 34.0
agent-8: 30.0
agent-9: 20.0
agent-10: 46.0
agent-11: 28.0
agent-12: 29.0
agent-13: 29.0
agent-14: 33.0
agent-15: 36.0
agent-16: 28.0
agent-17: 28.0
agent-18: 43.0
agent-19: 37.0
agent-20: 24.0
Sum Reward: 691.0
Avg Reward: 34.55
Min Reward: 20.0
Max Reward: 66.0
Gini Coefficient: 0.14117221418234444
20:20 Ratio: 1.99
Max-min Ratio: 3.3
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-16-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 415.51851851851853
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 27
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.514
    dispatch_time_ms: 7.333
    learner:
      cur_lr: 0.0013240360422059894
      grad_gnorm: 40.0
      policy_entropy: 128.6258544921875
      policy_loss: 13.464433670043945
      var_gnorm: 24.186965942382812
      vf_explained_var: 0.3734159469604492
      vf_loss: 266.33197021484375
    num_steps_sampled: 560000
    num_steps_trained: 560000
    wait_time_ms: 336.021
  iterations_since_restore: 28
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 952.1790318489075
  time_this_iter_s: 34.60954427719116
  time_total_s: 952.1790318489075
  timestamp: 1594138594
  timesteps_since_restore: 560000
  timesteps_this_iter: 20000
  timesteps_total: 560000
  training_iteration: 28
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 952 s, 28 iter, 560000 ts, 416 rew

agent-1: 31.0
agent-2: 38.0
agent-3: 33.0
agent-4: 27.0
agent-5: 30.0
agent-6: 42.0
agent-7: 53.0
agent-8: 32.0
agent-9: 23.0
agent-10: 24.0
agent-11: 27.0
agent-12: 42.0
agent-13: 37.0
agent-14: 40.0
agent-15: 37.0
agent-16: 29.0
agent-17: 40.0
agent-18: 17.0
agent-19: 23.0
agent-20: 27.0
Sum Reward: 652.0
Avg Reward: 32.6
Min Reward: 17.0
Max Reward: 53.0
Gini Coefficient: 0.1427914110429448
20:20 Ratio: 2.0344827586206895
Max-min Ratio: 3.1176470588235294
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-17-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 423.9642857142857
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 28
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.258
    dispatch_time_ms: 7.712
    learner:
      cur_lr: 0.0013227040180936456
      grad_gnorm: 1.3231970071792603
      policy_entropy: 223.72393798828125
      policy_loss: 1.1845245361328125
      var_gnorm: 24.4144344329834
      vf_explained_var: 2.372264862060547e-05
      vf_loss: 0.00045524092274717987
    num_steps_sampled: 580000
    num_steps_trained: 580000
    wait_time_ms: 337.837
  iterations_since_restore: 29
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 986.1692271232605
  time_this_iter_s: 33.99019527435303
  time_total_s: 986.1692271232605
  timestamp: 1594138628
  timesteps_since_restore: 580000
  timesteps_this_iter: 20000
  timesteps_total: 580000
  training_iteration: 29
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 986 s, 29 iter, 580000 ts, 424 rew

agent-1: 38.0
agent-2: 32.0
agent-3: 19.0
agent-4: 43.0
agent-5: 34.0
agent-6: 21.0
agent-7: 38.0
agent-8: 33.0
agent-9: 38.0
agent-10: 22.0
agent-11: 31.0
agent-12: 19.0
agent-13: 32.0
agent-14: 31.0
agent-15: 35.0
agent-16: 25.0
agent-17: 31.0
agent-18: 21.0
agent-19: 28.0
agent-20: 17.0
Sum Reward: 588.0
Avg Reward: 29.4
Min Reward: 17.0
Max Reward: 43.0
Gini Coefficient: 0.1414965986394558
20:20 Ratio: 2.0657894736842106
Max-min Ratio: 2.5294117647058822
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-17-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 429.62068965517244
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 29
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.013
    dispatch_time_ms: 5.846
    learner:
      cur_lr: 0.0013213719939813018
      grad_gnorm: 10.82332992553711
      policy_entropy: 220.3827667236328
      policy_loss: -3.119917869567871
      var_gnorm: 24.404773712158203
      vf_explained_var: 0.002541065216064453
      vf_loss: 0.03161273151636124
    num_steps_sampled: 600000
    num_steps_trained: 600000
    wait_time_ms: 312.126
  iterations_since_restore: 30
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 1020.6342644691467
  time_this_iter_s: 34.46503734588623
  time_total_s: 1020.6342644691467
  timestamp: 1594138663
  timesteps_since_restore: 600000
  timesteps_this_iter: 20000
  timesteps_total: 600000
  training_iteration: 30
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 1020 s, 30 iter, 600000 ts, 430 rew

agent-1: 30.0
agent-2: 29.0
agent-3: 27.0
agent-4: 24.0
agent-5: 36.0
agent-6: 32.0
agent-7: 39.0
agent-8: 36.0
agent-9: 32.0
agent-10: 33.0
agent-11: 29.0
agent-12: 35.0
agent-13: 45.0
agent-14: 32.0
agent-15: 32.0
agent-16: 28.0
agent-17: 31.0
agent-18: 25.0
agent-19: 36.0
agent-20: 22.0
Sum Reward: 633.0
Avg Reward: 31.65
Min Reward: 22.0
Max Reward: 45.0
Gini Coefficient: 0.09139020537124802
20:20 Ratio: 1.5918367346938775
Max-min Ratio: 2.0454545454545454
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-18-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 436.4
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 30
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.264
    dispatch_time_ms: 6.259
    learner:
      cur_lr: 0.001320039969868958
      grad_gnorm: 7.75521183013916
      policy_entropy: 240.33108520507812
      policy_loss: 2.637681484222412
      var_gnorm: 24.646289825439453
      vf_explained_var: -0.2768063545227051
      vf_loss: 0.018473487347364426
    num_steps_sampled: 620000
    num_steps_trained: 620000
    wait_time_ms: 333.969
  iterations_since_restore: 31
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 1054.9645969867706
  time_this_iter_s: 34.3303325176239
  time_total_s: 1054.9645969867706
  timestamp: 1594138697
  timesteps_since_restore: 620000
  timesteps_this_iter: 20000
  timesteps_total: 620000
  training_iteration: 31
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 1054 s, 31 iter, 620000 ts, 436 rew

agent-1: 34.0
agent-2: 35.0
agent-3: 30.0
agent-4: 34.0
agent-5: 35.0
agent-6: 36.0
agent-7: 29.0
agent-8: 27.0
agent-9: 28.0
agent-10: 32.0
agent-11: 29.0
agent-12: 37.0
agent-13: 41.0
agent-14: 40.0
agent-15: 17.0
agent-16: 25.0
agent-17: 30.0
agent-18: 36.0
agent-19: 37.0
agent-20: 29.0
Sum Reward: 641.0
Avg Reward: 32.05
Min Reward: 17.0
Max Reward: 41.0
Gini Coefficient: 0.09352574102964119
20:20 Ratio: 1.597938144329897
Max-min Ratio: 2.411764705882353
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-18-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 443.0
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 31
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.509
    dispatch_time_ms: 5.926
    learner:
      cur_lr: 0.0013187079457566142
      grad_gnorm: 5.73061466217041
      policy_entropy: 251.7943115234375
      policy_loss: -1.6371568441390991
      var_gnorm: 24.634714126586914
      vf_explained_var: -0.011068224906921387
      vf_loss: 0.008836065419018269
    num_steps_sampled: 640000
    num_steps_trained: 640000
    wait_time_ms: 343.035
  iterations_since_restore: 32
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 1089.6602499485016
  time_this_iter_s: 34.69565296173096
  time_total_s: 1089.6602499485016
  timestamp: 1594138732
  timesteps_since_restore: 640000
  timesteps_this_iter: 20000
  timesteps_total: 640000
  training_iteration: 32
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 1089 s, 32 iter, 640000 ts, 443 rew

agent-1: 34.0
agent-2: 28.0
agent-3: 33.0
agent-4: 35.0
agent-5: 32.0
agent-6: 45.0
agent-7: 30.0
agent-8: 33.0
agent-9: 30.0
agent-10: 25.0
agent-11: 26.0
agent-12: 38.0
agent-13: 32.0
agent-14: 28.0
agent-15: 31.0
agent-16: 31.0
agent-17: 26.0
agent-18: 19.0
agent-19: 31.0
agent-20: 24.0
Sum Reward: 611.0
Avg Reward: 30.55
Min Reward: 19.0
Max Reward: 45.0
Gini Coefficient: 0.09402618657937807
20:20 Ratio: 1.6170212765957446
Max-min Ratio: 2.3684210526315788
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-19-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 448.25
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 32
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.6
    dispatch_time_ms: 5.97
    learner:
      cur_lr: 0.0013173760380595922
      grad_gnorm: 3.0239064693450928
      policy_entropy: 243.7354278564453
      policy_loss: 1.3985803127288818
      var_gnorm: 24.827774047851562
      vf_explained_var: 0.0005336999893188477
      vf_loss: 0.0022827875800430775
    num_steps_sampled: 660000
    num_steps_trained: 660000
    wait_time_ms: 346.865
  iterations_since_restore: 33
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 1123.8807396888733
  time_this_iter_s: 34.220489740371704
  time_total_s: 1123.8807396888733
  timestamp: 1594138766
  timesteps_since_restore: 660000
  timesteps_this_iter: 20000
  timesteps_total: 660000
  training_iteration: 33
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 1123 s, 33 iter, 660000 ts, 448 rew

agent-1: 36.0
agent-2: 31.0
agent-3: 36.0
agent-4: 40.0
agent-5: 25.0
agent-6: 24.0
agent-7: 42.0
agent-8: 41.0
agent-9: 28.0
agent-10: 22.0
agent-11: 30.0
agent-12: 26.0
agent-13: 25.0
agent-14: 30.0
agent-15: 45.0
agent-16: 19.0
agent-17: 28.0
agent-18: 35.0
agent-19: 28.0
agent-20: 25.0
Sum Reward: 616.0
Avg Reward: 30.8
Min Reward: 19.0
Max Reward: 45.0
Gini Coefficient: 0.12905844155844157
20:20 Ratio: 1.8666666666666667
Max-min Ratio: 2.3684210526315788
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-20-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 453.3333333333333
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 33
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.651
    dispatch_time_ms: 5.744
    learner:
      cur_lr: 0.0013160440139472485
      grad_gnorm: 40.0000114440918
      policy_entropy: 132.35061645507812
      policy_loss: -42.8494873046875
      var_gnorm: 24.791645050048828
      vf_explained_var: -0.17606759071350098
      vf_loss: 233.14430236816406
    num_steps_sampled: 680000
    num_steps_trained: 680000
    wait_time_ms: 324.297
  iterations_since_restore: 34
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 1158.5410630702972
  time_this_iter_s: 34.66032338142395
  time_total_s: 1158.5410630702972
  timestamp: 1594138801
  timesteps_since_restore: 680000
  timesteps_this_iter: 20000
  timesteps_total: 680000
  training_iteration: 34
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 1158 s, 34 iter, 680000 ts, 453 rew

agent-1: 32.0
agent-2: 48.0
agent-3: 31.0
agent-4: 36.0
agent-5: 26.0
agent-6: 27.0
agent-7: 39.0
agent-8: 24.0
agent-9: 46.0
agent-10: 30.0
agent-11: 41.0
agent-12: 15.0
agent-13: 25.0
agent-14: 33.0
agent-15: 22.0
agent-16: 24.0
agent-17: 30.0
agent-18: 25.0
agent-19: 27.0
agent-20: 22.0
Sum Reward: 603.0
Avg Reward: 30.15
Min Reward: 15.0
Max Reward: 48.0
Gini Coefficient: 0.14966832504145938
20:20 Ratio: 2.0963855421686746
Max-min Ratio: 3.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-20-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 457.7352941176471
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 34
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.465
    dispatch_time_ms: 6.158
    learner:
      cur_lr: 0.0013147119898349047
      grad_gnorm: 39.99997329711914
      policy_entropy: 253.1011962890625
      policy_loss: -2.903041362762451
      var_gnorm: 25.067363739013672
      vf_explained_var: -1.0
      vf_loss: 4.056515693664551
    num_steps_sampled: 700000
    num_steps_trained: 700000
    wait_time_ms: 349.243
  iterations_since_restore: 35
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 1192.7961010932922
  time_this_iter_s: 34.255038022994995
  time_total_s: 1192.7961010932922
  timestamp: 1594138835
  timesteps_since_restore: 700000
  timesteps_this_iter: 20000
  timesteps_total: 700000
  training_iteration: 35
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 1192 s, 35 iter, 700000 ts, 458 rew

agent-1: 31.0
agent-2: 20.0
agent-3: 24.0
agent-4: 40.0
agent-5: 35.0
agent-6: 43.0
agent-7: 29.0
agent-8: 29.0
agent-9: 29.0
agent-10: 25.0
agent-11: 36.0
agent-12: 33.0
agent-13: 43.0
agent-14: 23.0
agent-15: 34.0
agent-16: 35.0
agent-17: 38.0
agent-18: 40.0
agent-19: 31.0
agent-20: 34.0
Sum Reward: 652.0
Avg Reward: 32.6
Min Reward: 20.0
Max Reward: 43.0
Gini Coefficient: 0.11088957055214724
20:20 Ratio: 1.8043478260869565
Max-min Ratio: 2.15
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-21-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 463.2857142857143
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 35
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.049
    dispatch_time_ms: 6.431
    learner:
      cur_lr: 0.0013133799657225609
      grad_gnorm: 10.610503196716309
      policy_entropy: 288.4089050292969
      policy_loss: -5.148158550262451
      var_gnorm: 25.118507385253906
      vf_explained_var: -1.0
      vf_loss: 0.05186544731259346
    num_steps_sampled: 720000
    num_steps_trained: 720000
    wait_time_ms: 333.556
  iterations_since_restore: 36
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 1227.3901808261871
  time_this_iter_s: 34.5940797328949
  time_total_s: 1227.3901808261871
  timestamp: 1594138870
  timesteps_since_restore: 720000
  timesteps_this_iter: 20000
  timesteps_total: 720000
  training_iteration: 36
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 1227 s, 36 iter, 720000 ts, 463 rew

agent-1: 26.0
agent-2: 30.0
agent-3: 25.0
agent-4: 22.0
agent-5: 35.0
agent-6: 34.0
agent-7: 27.0
agent-8: 21.0
agent-9: 38.0
agent-10: 32.0
agent-11: 34.0
agent-12: 23.0
agent-13: 37.0
agent-14: 29.0
agent-15: 33.0
agent-16: 40.0
agent-17: 44.0
agent-18: 27.0
agent-19: 31.0
agent-20: 27.0
Sum Reward: 615.0
Avg Reward: 30.75
Min Reward: 21.0
Max Reward: 44.0
Gini Coefficient: 0.11178861788617886
20:20 Ratio: 1.7472527472527473
Max-min Ratio: 2.0952380952380953
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-21-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 467.5
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 36
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.54
    dispatch_time_ms: 7.035
    learner:
      cur_lr: 0.001312048058025539
      grad_gnorm: 3.639334201812744
      policy_entropy: 232.8211669921875
      policy_loss: 0.8285696506500244
      var_gnorm: 25.387775421142578
      vf_explained_var: -0.8268616199493408
      vf_loss: 0.0044443863444030285
    num_steps_sampled: 740000
    num_steps_trained: 740000
    wait_time_ms: 338.924
  iterations_since_restore: 37
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 1261.9442517757416
  time_this_iter_s: 34.55407094955444
  time_total_s: 1261.9442517757416
  timestamp: 1594138904
  timesteps_since_restore: 740000
  timesteps_this_iter: 20000
  timesteps_total: 740000
  training_iteration: 37
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 1261 s, 37 iter, 740000 ts, 468 rew

agent-1: 41.0
agent-2: 35.0
agent-3: 40.0
agent-4: 30.0
agent-5: 32.0
agent-6: 29.0
agent-7: 41.0
agent-8: 28.0
agent-9: 23.0
agent-10: 29.0
agent-11: 30.0
agent-12: 35.0
agent-13: 40.0
agent-14: 34.0
agent-15: 37.0
agent-16: 37.0
agent-17: 22.0
agent-18: 33.0
agent-19: 33.0
agent-20: 41.0
Sum Reward: 670.0
Avg Reward: 33.5
Min Reward: 22.0
Max Reward: 41.0
Gini Coefficient: 0.09402985074626866
20:20 Ratio: 1.5980392156862746
Max-min Ratio: 1.8636363636363635
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-22-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 472.97297297297297
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 37
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.867
    dispatch_time_ms: 7.93
    learner:
      cur_lr: 0.0013107160339131951
      grad_gnorm: 3.2471556663513184
      policy_entropy: 258.401123046875
      policy_loss: -1.530206322669983
      var_gnorm: 25.40431022644043
      vf_explained_var: -0.3235933780670166
      vf_loss: 0.002328234724700451
    num_steps_sampled: 760000
    num_steps_trained: 760000
    wait_time_ms: 343.735
  iterations_since_restore: 38
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 1296.7191953659058
  time_this_iter_s: 34.774943590164185
  time_total_s: 1296.7191953659058
  timestamp: 1594138939
  timesteps_since_restore: 760000
  timesteps_this_iter: 20000
  timesteps_total: 760000
  training_iteration: 38
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 1296 s, 38 iter, 760000 ts, 473 rew

agent-1: 38.0
agent-2: 35.0
agent-3: 22.0
agent-4: 37.0
agent-5: 36.0
agent-6: 31.0
agent-7: 32.0
agent-8: 40.0
agent-9: 16.0
agent-10: 38.0
agent-11: 23.0
agent-12: 36.0
agent-13: 34.0
agent-14: 41.0
agent-15: 34.0
agent-16: 32.0
agent-17: 32.0
agent-18: 24.0
agent-19: 27.0
agent-20: 25.0
Sum Reward: 633.0
Avg Reward: 31.65
Min Reward: 16.0
Max Reward: 41.0
Gini Coefficient: 0.11524486571879937
20:20 Ratio: 1.8470588235294119
Max-min Ratio: 2.5625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-22-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 477.1842105263158
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 38
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.312
    dispatch_time_ms: 6.166
    learner:
      cur_lr: 0.0013093840098008513
      grad_gnorm: 0.9997660517692566
      policy_entropy: 205.80252075195312
      policy_loss: -2.1384739875793457
      var_gnorm: 25.647199630737305
      vf_explained_var: 0.7598881721496582
      vf_loss: 6.409884372260422e-05
    num_steps_sampled: 780000
    num_steps_trained: 780000
    wait_time_ms: 355.882
  iterations_since_restore: 39
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 1331.1022372245789
  time_this_iter_s: 34.383041858673096
  time_total_s: 1331.1022372245789
  timestamp: 1594138974
  timesteps_since_restore: 780000
  timesteps_this_iter: 20000
  timesteps_total: 780000
  training_iteration: 39
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 1331 s, 39 iter, 780000 ts, 477 rew

agent-1: 14.0
agent-2: 38.0
agent-3: 12.0
agent-4: 48.0
agent-5: 19.0
agent-6: 28.0
agent-7: 26.0
agent-8: 32.0
agent-9: 33.0
agent-10: 34.0
agent-11: 37.0
agent-12: 39.0
agent-13: 31.0
agent-14: 39.0
agent-15: 30.0
agent-16: 26.0
agent-17: 24.0
agent-18: 32.0
agent-19: 36.0
agent-20: 27.0
Sum Reward: 605.0
Avg Reward: 30.25
Min Reward: 12.0
Max Reward: 48.0
Gini Coefficient: 0.1556198347107438
20:20 Ratio: 2.3768115942028984
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-23-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 480.46153846153845
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 39
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.668
    dispatch_time_ms: 5.811
    learner:
      cur_lr: 0.0013080519856885076
      grad_gnorm: 4.3675103187561035
      policy_entropy: 274.88177490234375
      policy_loss: -2.2411584854125977
      var_gnorm: 25.666431427001953
      vf_explained_var: -0.44959890842437744
      vf_loss: 0.005096578039228916
    num_steps_sampled: 800000
    num_steps_trained: 800000
    wait_time_ms: 331.658
  iterations_since_restore: 40
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 1365.501690864563
  time_this_iter_s: 34.39945363998413
  time_total_s: 1365.501690864563
  timestamp: 1594139008
  timesteps_since_restore: 800000
  timesteps_this_iter: 20000
  timesteps_total: 800000
  training_iteration: 40
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 1365 s, 40 iter, 800000 ts, 480 rew

agent-1: 28.0
agent-2: 29.0
agent-3: 34.0
agent-4: 30.0
agent-5: 33.0
agent-6: 22.0
agent-7: 31.0
agent-8: 44.0
agent-9: 38.0
agent-10: 40.0
agent-11: 40.0
agent-12: 40.0
agent-13: 32.0
agent-14: 36.0
agent-15: 45.0
agent-16: 32.0
agent-17: 17.0
agent-18: 38.0
agent-19: 25.0
agent-20: 30.0
Sum Reward: 664.0
Avg Reward: 33.2
Min Reward: 17.0
Max Reward: 45.0
Gini Coefficient: 0.1180722891566265
20:20 Ratio: 1.8369565217391304
Max-min Ratio: 2.6470588235294117
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-24-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 485.05
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 40
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.578
    dispatch_time_ms: 6.123
    learner:
      cur_lr: 0.0013067199615761638
      grad_gnorm: 0.804170548915863
      policy_entropy: 260.7953796386719
      policy_loss: 0.7074835300445557
      var_gnorm: 25.887836456298828
      vf_explained_var: -1.0
      vf_loss: 0.006559216417372227
    num_steps_sampled: 820000
    num_steps_trained: 820000
    wait_time_ms: 339.523
  iterations_since_restore: 41
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 1400.2210068702698
  time_this_iter_s: 34.71931600570679
  time_total_s: 1400.2210068702698
  timestamp: 1594139043
  timesteps_since_restore: 820000
  timesteps_this_iter: 20000
  timesteps_total: 820000
  training_iteration: 41
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 1400 s, 41 iter, 820000 ts, 485 rew

agent-1: 30.0
agent-2: 32.0
agent-3: 34.0
agent-4: 33.0
agent-5: 32.0
agent-6: 34.0
agent-7: 31.0
agent-8: 26.0
agent-9: 36.0
agent-10: 29.0
agent-11: 17.0
agent-12: 31.0
agent-13: 38.0
agent-14: 29.0
agent-15: 30.0
agent-16: 29.0
agent-17: 39.0
agent-18: 30.0
agent-19: 22.0
agent-20: 32.0
Sum Reward: 614.0
Avg Reward: 30.7
Min Reward: 17.0
Max Reward: 39.0
Gini Coefficient: 0.08355048859934854
20:20 Ratio: 1.5638297872340425
Max-min Ratio: 2.2941176470588234
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-24-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 488.1951219512195
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 41
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.549
    dispatch_time_ms: 6.114
    learner:
      cur_lr: 0.0013053880538791418
      grad_gnorm: 40.00000762939453
      policy_entropy: 166.2396240234375
      policy_loss: 47.78275680541992
      var_gnorm: 25.92298698425293
      vf_explained_var: 0.28970080614089966
      vf_loss: 119.27716064453125
    num_steps_sampled: 840000
    num_steps_trained: 840000
    wait_time_ms: 315.18
  iterations_since_restore: 42
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 1434.5667469501495
  time_this_iter_s: 34.34574007987976
  time_total_s: 1434.5667469501495
  timestamp: 1594139077
  timesteps_since_restore: 840000
  timesteps_this_iter: 20000
  timesteps_total: 840000
  training_iteration: 42
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 1434 s, 42 iter, 840000 ts, 488 rew

agent-1: 39.0
agent-2: 41.0
agent-3: 31.0
agent-4: 40.0
agent-5: 39.0
agent-6: 24.0
agent-7: 45.0
agent-8: 27.0
agent-9: 37.0
agent-10: 26.0
agent-11: 32.0
agent-12: 18.0
agent-13: 33.0
agent-14: 24.0
agent-15: 26.0
agent-16: 19.0
agent-17: 18.0
agent-18: 36.0
agent-19: 29.0
agent-20: 20.0
Sum Reward: 604.0
Avg Reward: 30.2
Min Reward: 18.0
Max Reward: 45.0
Gini Coefficient: 0.15480132450331127
20:20 Ratio: 2.2
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-25-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 490.95238095238096
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 42
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.486
    dispatch_time_ms: 6.096
    learner:
      cur_lr: 0.001304056029766798
      grad_gnorm: 39.99995422363281
      policy_entropy: 196.7877197265625
      policy_loss: -2.324910879135132
      var_gnorm: 26.068458557128906
      vf_explained_var: -0.4405149221420288
      vf_loss: 2.8941123485565186
    num_steps_sampled: 860000
    num_steps_trained: 860000
    wait_time_ms: 340.256
  iterations_since_restore: 43
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 1469.2957675457
  time_this_iter_s: 34.72902059555054
  time_total_s: 1469.2957675457
  timestamp: 1594139112
  timesteps_since_restore: 860000
  timesteps_this_iter: 20000
  timesteps_total: 860000
  training_iteration: 43
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 1469 s, 43 iter, 860000 ts, 491 rew

agent-1: 48.0
agent-2: 52.0
agent-3: 32.0
agent-4: 37.0
agent-5: 32.0
agent-6: 36.0
agent-7: 32.0
agent-8: 26.0
agent-9: 39.0
agent-10: 31.0
agent-11: 45.0
agent-12: 30.0
agent-13: 20.0
agent-14: 42.0
agent-15: 29.0
agent-16: 31.0
agent-17: 30.0
agent-18: 30.0
agent-19: 32.0
agent-20: 41.0
Sum Reward: 695.0
Avg Reward: 34.75
Min Reward: 20.0
Max Reward: 52.0
Gini Coefficient: 0.11848920863309352
20:20 Ratio: 1.7809523809523808
Max-min Ratio: 2.6
W0707 12:25:40.390749 17834 client_connection.cc:255] [worker]ProcessMessage with type 19 took 1491 ms.
W0707 12:25:40.391115 17834 node_manager.cc:250] Last heartbeat was sent 1528 ms ago 
W0707 12:25:41.416543 17834 node_manager.cc:250] Last heartbeat was sent 510 ms ago 
W0707 12:25:42.886495 17834 node_manager.cc:250] Last heartbeat was sent 597 ms ago 
W0707 12:25:46.935869 17834 node_manager.cc:250] Last heartbeat was sent 844 ms ago 
W0707 12:25:49.736675 17834 node_manager.cc:250] Last heartbeat was sent 1023 ms ago 
W0707 12:25:56.346774 17834 client_connection.cc:255] [worker]ProcessMessage with type 8 took 1257 ms.
W0707 12:25:56.348783 17834 node_manager.cc:250] Last heartbeat was sent 1313 ms ago 
W0707 12:25:59.043265 17834 node_manager.cc:250] Last heartbeat was sent 777 ms ago 
W0707 12:25:59.964120 17834 client_connection.cc:255] [worker]ProcessMessage with type 16 took 124 ms.
W0707 12:26:00.178236 17834 client_connection.cc:255] [worker]ProcessMessage with type 16 took 208 ms.
W0707 12:26:00.777051 17834 client_connection.cc:255] [worker]ProcessMessage with type 16 took 146 ms.
W0707 12:26:01.397123 17834 client_connection.cc:255] [worker]ProcessMessage with type 8 took 195 ms.
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-26-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 495.69767441860466
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 43
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.723
    dispatch_time_ms: 6.338
    learner:
      cur_lr: 0.0013027240056544542
      grad_gnorm: 39.9999885559082
      policy_entropy: 197.7120361328125
      policy_loss: 9.947399139404297
      var_gnorm: 26.159013748168945
      vf_explained_var: 0.7601723670959473
      vf_loss: 12.303667068481445
    num_steps_sampled: 880000
    num_steps_trained: 880000
    wait_time_ms: 339.125
  iterations_since_restore: 44
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 1526.2204508781433
  time_this_iter_s: 56.92468333244324
  time_total_s: 1526.2204508781433
  timestamp: 1594139169
  timesteps_since_restore: 880000
  timesteps_this_iter: 20000
  timesteps_total: 880000
  training_iteration: 44
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 1526 s, 44 iter, 880000 ts, 496 rew

agent-1: 46.0
agent-2: 44.0
agent-3: 33.0
agent-4: 43.0
agent-5: 39.0
agent-6: 16.0
agent-7: 31.0
agent-8: 33.0
agent-9: 9.0
agent-10: 33.0
agent-11: 15.0
agent-12: 14.0
agent-13: 28.0
agent-14: 31.0
agent-15: 27.0
agent-16: 31.0
agent-17: 40.0
agent-18: 23.0
agent-19: 25.0
agent-20: 22.0
Sum Reward: 583.0
Avg Reward: 29.15
Min Reward: 9.0
Max Reward: 46.0
Gini Coefficient: 0.19871355060034304
20:20 Ratio: 3.2037037037037037
Max-min Ratio: 5.111111111111111
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-26-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 497.6818181818182
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 44
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.7
    dispatch_time_ms: 7.167
    learner:
      cur_lr: 0.0013013919815421104
      grad_gnorm: 17.496644973754883
      policy_entropy: 186.437255859375
      policy_loss: -2.482285499572754
      var_gnorm: 26.29174041748047
      vf_explained_var: -1.0
      vf_loss: 0.07059346139431
    num_steps_sampled: 900000
    num_steps_trained: 900000
    wait_time_ms: 347.415
  iterations_since_restore: 45
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 1558.2598938941956
  time_this_iter_s: 32.039443016052246
  time_total_s: 1558.2598938941956
  timestamp: 1594139203
  timesteps_since_restore: 900000
  timesteps_this_iter: 20000
  timesteps_total: 900000
  training_iteration: 45
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 1558 s, 45 iter, 900000 ts, 498 rew

agent-1: 23.0
agent-2: 40.0
agent-3: 31.0
agent-4: 36.0
agent-5: 34.0
agent-6: 38.0
agent-7: 38.0
agent-8: 34.0
agent-9: 25.0
agent-10: 23.0
agent-11: 45.0
agent-12: 37.0
agent-13: 27.0
agent-14: 35.0
agent-15: 26.0
agent-16: 36.0
agent-17: 19.0
agent-18: 47.0
agent-19: 27.0
agent-20: 27.0
Sum Reward: 648.0
Avg Reward: 32.4
Min Reward: 19.0
Max Reward: 47.0
Gini Coefficient: 0.12901234567901235
20:20 Ratio: 1.8888888888888888
Max-min Ratio: 2.473684210526316
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-27-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 501.02222222222224
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 45
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.461
    dispatch_time_ms: 5.745
    learner:
      cur_lr: 0.0013000599574297667
      grad_gnorm: 3.5375094413757324
      policy_entropy: 227.58316040039062
      policy_loss: -1.0192574262619019
      var_gnorm: 26.359350204467773
      vf_explained_var: -0.1969972848892212
      vf_loss: 0.003911382053047419
    num_steps_sampled: 920000
    num_steps_trained: 920000
    wait_time_ms: 340.764
  iterations_since_restore: 46
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 1592.771906375885
  time_this_iter_s: 34.51201248168945
  time_total_s: 1592.771906375885
  timestamp: 1594139238
  timesteps_since_restore: 920000
  timesteps_this_iter: 20000
  timesteps_total: 920000
  training_iteration: 46
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 1592 s, 46 iter, 920000 ts, 501 rew

agent-1: 30.0
agent-2: 36.0
agent-3: 25.0
agent-4: 26.0
agent-5: 24.0
agent-6: 22.0
agent-7: 31.0
agent-8: 37.0
agent-9: 41.0
agent-10: 40.0
agent-11: 27.0
agent-12: 34.0
agent-13: 37.0
agent-14: 30.0
agent-15: 32.0
agent-16: 37.0
agent-17: 27.0
agent-18: 20.0
agent-19: 29.0
agent-20: 33.0
Sum Reward: 618.0
Avg Reward: 30.9
Min Reward: 20.0
Max Reward: 41.0
Gini Coefficient: 0.10792880258899676
20:20 Ratio: 1.7032967032967032
Max-min Ratio: 2.05
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-27-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 503.5652173913044
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 46
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.651
    dispatch_time_ms: 6.995
    learner:
      cur_lr: 0.0012987280497327447
      grad_gnorm: 14.024425506591797
      policy_entropy: 235.8422088623047
      policy_loss: 4.183343410491943
      var_gnorm: 26.431957244873047
      vf_explained_var: 0.05327802896499634
      vf_loss: 0.27323365211486816
    num_steps_sampled: 940000
    num_steps_trained: 940000
    wait_time_ms: 357.066
  iterations_since_restore: 47
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 1627.5627913475037
  time_this_iter_s: 34.79088497161865
  time_total_s: 1627.5627913475037
  timestamp: 1594139273
  timesteps_since_restore: 940000
  timesteps_this_iter: 20000
  timesteps_total: 940000
  training_iteration: 47
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 1627 s, 47 iter, 940000 ts, 504 rew

agent-1: 26.0
agent-2: 22.0
agent-3: 36.0
agent-4: 28.0
agent-5: 43.0
agent-6: 20.0
agent-7: 31.0
agent-8: 34.0
agent-9: 40.0
agent-10: 31.0
agent-11: 16.0
agent-12: 25.0
agent-13: 25.0
agent-14: 38.0
agent-15: 25.0
agent-16: 37.0
agent-17: 24.0
agent-18: 33.0
agent-19: 38.0
agent-20: 37.0
Sum Reward: 609.0
Avg Reward: 30.45
Min Reward: 16.0
Max Reward: 43.0
Gini Coefficient: 0.1352216748768473
20:20 Ratio: 1.9390243902439024
Max-min Ratio: 2.6875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-28-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 505.8085106382979
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 47
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.088
    dispatch_time_ms: 5.772
    learner:
      cur_lr: 0.001297396025620401
      grad_gnorm: 39.99998474121094
      policy_entropy: 290.9061279296875
      policy_loss: 0.01801753044128418
      var_gnorm: 26.60083770751953
      vf_explained_var: 0.4003596901893616
      vf_loss: 16.348825454711914
    num_steps_sampled: 960000
    num_steps_trained: 960000
    wait_time_ms: 329.977
  iterations_since_restore: 48
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 1662.202910900116
  time_this_iter_s: 34.640119552612305
  time_total_s: 1662.202910900116
  timestamp: 1594139307
  timesteps_since_restore: 960000
  timesteps_this_iter: 20000
  timesteps_total: 960000
  training_iteration: 48
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 1662 s, 48 iter, 960000 ts, 506 rew

agent-1: 32.0
agent-2: 38.0
agent-3: 27.0
agent-4: 29.0
agent-5: 43.0
agent-6: 35.0
agent-7: 18.0
agent-8: 37.0
agent-9: 26.0
agent-10: 33.0
agent-11: 29.0
agent-12: 30.0
agent-13: 27.0
agent-14: 34.0
agent-15: 37.0
agent-16: 27.0
agent-17: 44.0
agent-18: 31.0
agent-19: 35.0
agent-20: 29.0
Sum Reward: 641.0
Avg Reward: 32.05
Min Reward: 18.0
Max Reward: 44.0
Gini Coefficient: 0.10288611544461779
20:20 Ratio: 1.653061224489796
Max-min Ratio: 2.4444444444444446
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-29-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 508.625
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 48
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.98
    dispatch_time_ms: 6.199
    learner:
      cur_lr: 0.0012960640015080571
      grad_gnorm: 39.9999885559082
      policy_entropy: 290.11431884765625
      policy_loss: 8.54318904876709
      var_gnorm: 26.69961929321289
      vf_explained_var: 0.8295553922653198
      vf_loss: 1.9873231649398804
    num_steps_sampled: 980000
    num_steps_trained: 980000
    wait_time_ms: 338.9
  iterations_since_restore: 49
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 1696.3782486915588
  time_this_iter_s: 34.17533779144287
  time_total_s: 1696.3782486915588
  timestamp: 1594139341
  timesteps_since_restore: 980000
  timesteps_this_iter: 20000
  timesteps_total: 980000
  training_iteration: 49
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 1696 s, 49 iter, 980000 ts, 509 rew

agent-1: 31.0
agent-2: 41.0
agent-3: 35.0
agent-4: 19.0
agent-5: 34.0
agent-6: 34.0
agent-7: 26.0
agent-8: 34.0
agent-9: 34.0
agent-10: 37.0
agent-11: 38.0
agent-12: 32.0
agent-13: 28.0
agent-14: 24.0
agent-15: 20.0
agent-16: 45.0
agent-17: 26.0
agent-18: 26.0
agent-19: 32.0
agent-20: 37.0
Sum Reward: 633.0
Avg Reward: 31.65
Min Reward: 19.0
Max Reward: 45.0
Gini Coefficient: 0.11619273301737756
20:20 Ratio: 1.8089887640449438
Max-min Ratio: 2.3684210526315788
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-29-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 511.16326530612247
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 49
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.921
    dispatch_time_ms: 6.197
    learner:
      cur_lr: 0.0012947319773957133
      grad_gnorm: 38.95578384399414
      policy_entropy: 281.98260498046875
      policy_loss: 5.53264045715332
      var_gnorm: 26.859909057617188
      vf_explained_var: 0.6733302474021912
      vf_loss: 6.702962875366211
    num_steps_sampled: 1000000
    num_steps_trained: 1000000
    wait_time_ms: 327.881
  iterations_since_restore: 50
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 1730.6219127178192
  time_this_iter_s: 34.243664026260376
  time_total_s: 1730.6219127178192
  timestamp: 1594139376
  timesteps_since_restore: 1000000
  timesteps_this_iter: 20000
  timesteps_total: 1000000
  training_iteration: 50
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 1730 s, 50 iter, 1000000 ts, 511 rew

agent-1: 31.0
agent-2: 13.0
agent-3: 31.0
agent-4: 40.0
agent-5: 32.0
agent-6: 17.0
agent-7: 23.0
agent-8: 30.0
agent-9: 25.0
agent-10: 40.0
agent-11: 29.0
agent-12: 27.0
agent-13: 35.0
agent-14: 40.0
agent-15: 36.0
agent-16: 33.0
agent-17: 31.0
agent-18: 23.0
agent-19: 24.0
agent-20: 35.0
Sum Reward: 595.0
Avg Reward: 29.75
Min Reward: 13.0
Max Reward: 40.0
Gini Coefficient: 0.13436974789915967
20:20 Ratio: 2.0526315789473686
Max-min Ratio: 3.076923076923077
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-30-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 512.84
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 50
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.979
    dispatch_time_ms: 5.76
    learner:
      cur_lr: 0.0012933999532833695
      grad_gnorm: 29.32636070251465
      policy_entropy: 242.91839599609375
      policy_loss: 2.876610279083252
      var_gnorm: 27.049114227294922
      vf_explained_var: -0.9070476293563843
      vf_loss: 2.046872138977051
    num_steps_sampled: 1020000
    num_steps_trained: 1020000
    wait_time_ms: 344.836
  iterations_since_restore: 51
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 1765.1431229114532
  time_this_iter_s: 34.52121019363403
  time_total_s: 1765.1431229114532
  timestamp: 1594139410
  timesteps_since_restore: 1020000
  timesteps_this_iter: 20000
  timesteps_total: 1020000
  training_iteration: 51
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 1765 s, 51 iter, 1020000 ts, 513 rew

agent-1: 45.0
agent-2: 39.0
agent-3: 43.0
agent-4: 38.0
agent-5: 38.0
agent-6: 40.0
agent-7: 31.0
agent-8: 44.0
agent-9: 31.0
agent-10: 29.0
agent-11: 37.0
agent-12: 31.0
agent-13: 24.0
agent-14: 17.0
agent-15: 41.0
agent-16: 25.0
agent-17: 24.0
agent-18: 25.0
agent-19: 30.0
agent-20: 33.0
Sum Reward: 665.0
Avg Reward: 33.25
Min Reward: 17.0
Max Reward: 45.0
Gini Coefficient: 0.13015037593984963
20:20 Ratio: 1.9222222222222223
Max-min Ratio: 2.6470588235294117
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-30-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 515.8235294117648
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 51
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 4.058
    dispatch_time_ms: 7.388
    learner:
      cur_lr: 0.0012920680455863476
      grad_gnorm: 34.522743225097656
      policy_entropy: 208.91461181640625
      policy_loss: -4.606906890869141
      var_gnorm: 27.16282081604004
      vf_explained_var: 0.0028600096702575684
      vf_loss: 7.222458839416504
    num_steps_sampled: 1040000
    num_steps_trained: 1040000
    wait_time_ms: 331.208
  iterations_since_restore: 52
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 1799.453855752945
  time_this_iter_s: 34.3107328414917
  time_total_s: 1799.453855752945
  timestamp: 1594139445
  timesteps_since_restore: 1040000
  timesteps_this_iter: 20000
  timesteps_total: 1040000
  training_iteration: 52
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 1799 s, 52 iter, 1040000 ts, 516 rew

agent-1: 27.0
agent-2: 39.0
agent-3: 33.0
agent-4: 34.0
agent-5: 25.0
agent-6: 31.0
agent-7: 25.0
agent-8: 33.0
agent-9: 41.0
agent-10: 41.0
agent-11: 35.0
agent-12: 25.0
agent-13: 29.0
agent-14: 30.0
agent-15: 37.0
agent-16: 28.0
agent-17: 20.0
agent-18: 28.0
agent-19: 39.0
agent-20: 35.0
Sum Reward: 635.0
Avg Reward: 31.75
Min Reward: 20.0
Max Reward: 41.0
Gini Coefficient: 0.10401574803149606
20:20 Ratio: 1.6842105263157894
Max-min Ratio: 2.05
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-31-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 518.1153846153846
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 52
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.903
    dispatch_time_ms: 6.184
    learner:
      cur_lr: 0.0012907360214740038
      grad_gnorm: 17.37769889831543
      policy_entropy: 273.02764892578125
      policy_loss: 6.127941608428955
      var_gnorm: 27.225439071655273
      vf_explained_var: -1.0
      vf_loss: 0.11008758842945099
    num_steps_sampled: 1060000
    num_steps_trained: 1060000
    wait_time_ms: 340.952
  iterations_since_restore: 53
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 1834.2095623016357
  time_this_iter_s: 34.755706548690796
  time_total_s: 1834.2095623016357
  timestamp: 1594139479
  timesteps_since_restore: 1060000
  timesteps_this_iter: 20000
  timesteps_total: 1060000
  training_iteration: 53
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 1834 s, 53 iter, 1060000 ts, 518 rew

agent-1: 29.0
agent-2: 24.0
agent-3: 28.0
agent-4: 35.0
agent-5: 30.0
agent-6: 28.0
agent-7: 21.0
agent-8: 27.0
agent-9: 21.0
agent-10: 29.0
agent-11: 26.0
agent-12: 25.0
agent-13: 25.0
agent-14: 26.0
agent-15: 23.0
agent-16: 29.0
agent-17: 28.0
agent-18: 23.0
agent-19: 39.0
agent-20: 29.0
Sum Reward: 545.0
Avg Reward: 27.25
Min Reward: 21.0
Max Reward: 39.0
Gini Coefficient: 0.08247706422018349
20:20 Ratio: 1.5113636363636365
Max-min Ratio: 1.8571428571428572
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-31-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 518.622641509434
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 53
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.316
    dispatch_time_ms: 5.911
    learner:
      cur_lr: 0.00128940399736166
      grad_gnorm: 24.36884117126465
      policy_entropy: 215.48397827148438
      policy_loss: -2.0126471519470215
      var_gnorm: 27.333459854125977
      vf_explained_var: 0.9168131351470947
      vf_loss: 0.4032253921031952
    num_steps_sampled: 1080000
    num_steps_trained: 1080000
    wait_time_ms: 347.25
  iterations_since_restore: 54
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 1868.5420563220978
  time_this_iter_s: 34.332494020462036
  time_total_s: 1868.5420563220978
  timestamp: 1594139514
  timesteps_since_restore: 1080000
  timesteps_this_iter: 20000
  timesteps_total: 1080000
  training_iteration: 54
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 1868 s, 54 iter, 1080000 ts, 519 rew

agent-1: 26.0
agent-2: 25.0
agent-3: 23.0
agent-4: 38.0
agent-5: 16.0
agent-6: 33.0
agent-7: 31.0
agent-8: 43.0
agent-9: 21.0
agent-10: 27.0
agent-11: 31.0
agent-12: 33.0
agent-13: 32.0
agent-14: 39.0
agent-15: 27.0
agent-16: 32.0
agent-17: 29.0
agent-18: 31.0
agent-19: 32.0
agent-20: 20.0
Sum Reward: 589.0
Avg Reward: 29.45
Min Reward: 16.0
Max Reward: 43.0
Gini Coefficient: 0.12130730050933786
20:20 Ratio: 1.9125
Max-min Ratio: 2.6875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-32-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 519.925925925926
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 54
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.776
    dispatch_time_ms: 8.272
    learner:
      cur_lr: 0.0012880719732493162
      grad_gnorm: 6.9591288566589355
      policy_entropy: 257.7076416015625
      policy_loss: -1.2329375743865967
      var_gnorm: 27.451114654541016
      vf_explained_var: -1.0
      vf_loss: 0.5760228037834167
    num_steps_sampled: 1100000
    num_steps_trained: 1100000
    wait_time_ms: 339.469
  iterations_since_restore: 55
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 1903.1087081432343
  time_this_iter_s: 34.566651821136475
  time_total_s: 1903.1087081432343
  timestamp: 1594139548
  timesteps_since_restore: 1100000
  timesteps_this_iter: 20000
  timesteps_total: 1100000
  training_iteration: 55
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 1903 s, 55 iter, 1100000 ts, 520 rew

agent-1: 22.0
agent-2: 22.0
agent-3: 31.0
agent-4: 23.0
agent-5: 47.0
agent-6: 28.0
agent-7: 40.0
agent-8: 28.0
agent-9: 34.0
agent-10: 36.0
agent-11: 30.0
agent-12: 27.0
agent-13: 22.0
agent-14: 20.0
agent-15: 42.0
agent-16: 29.0
agent-17: 26.0
agent-18: 37.0
agent-19: 28.0
agent-20: 32.0
Sum Reward: 604.0
Avg Reward: 30.2
Min Reward: 20.0
Max Reward: 47.0
Gini Coefficient: 0.1316225165562914
20:20 Ratio: 1.930232558139535
Max-min Ratio: 2.35
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-33-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 521.4545454545455
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 55
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.983
    dispatch_time_ms: 6.191
    learner:
      cur_lr: 0.0012867399491369724
      grad_gnorm: 9.34821891784668
      policy_entropy: 247.3900146484375
      policy_loss: 2.8672847747802734
      var_gnorm: 27.529170989990234
      vf_explained_var: -0.5064331293106079
      vf_loss: 0.02993030846118927
    num_steps_sampled: 1120000
    num_steps_trained: 1120000
    wait_time_ms: 344.733
  iterations_since_restore: 56
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 1937.3712491989136
  time_this_iter_s: 34.26254105567932
  time_total_s: 1937.3712491989136
  timestamp: 1594139583
  timesteps_since_restore: 1120000
  timesteps_this_iter: 20000
  timesteps_total: 1120000
  training_iteration: 56
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 1937 s, 56 iter, 1120000 ts, 521 rew

agent-1: 35.0
agent-2: 22.0
agent-3: 31.0
agent-4: 24.0
agent-5: 34.0
agent-6: 25.0
agent-7: 24.0
agent-8: 26.0
agent-9: 29.0
agent-10: 21.0
agent-11: 30.0
agent-12: 43.0
agent-13: 34.0
agent-14: 31.0
agent-15: 42.0
agent-16: 19.0
agent-17: 42.0
agent-18: 39.0
agent-19: 34.0
agent-20: 31.0
Sum Reward: 616.0
Avg Reward: 30.8
Min Reward: 19.0
Max Reward: 43.0
Gini Coefficient: 0.12938311688311688
20:20 Ratio: 1.930232558139535
Max-min Ratio: 2.263157894736842
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-33-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 523.1428571428571
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 56
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.782
    dispatch_time_ms: 7.562
    learner:
      cur_lr: 0.0012854080414399505
      grad_gnorm: 5.604550838470459
      policy_entropy: 252.87657165527344
      policy_loss: 2.3442864418029785
      var_gnorm: 27.664003372192383
      vf_explained_var: 4.351139068603516e-06
      vf_loss: 0.008647323586046696
    num_steps_sampled: 1140000
    num_steps_trained: 1140000
    wait_time_ms: 337.558
  iterations_since_restore: 57
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 1971.579345703125
  time_this_iter_s: 34.208096504211426
  time_total_s: 1971.579345703125
  timestamp: 1594139617
  timesteps_since_restore: 1140000
  timesteps_this_iter: 20000
  timesteps_total: 1140000
  training_iteration: 57
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 1971 s, 57 iter, 1140000 ts, 523 rew

agent-1: 16.0
agent-2: 31.0
agent-3: 30.0
agent-4: 30.0
agent-5: 29.0
agent-6: 24.0
agent-7: 27.0
agent-8: 34.0
agent-9: 30.0
agent-10: 32.0
agent-11: 29.0
agent-12: 38.0
agent-13: 35.0
agent-14: 23.0
agent-15: 29.0
agent-16: 26.0
agent-17: 31.0
agent-18: 34.0
agent-19: 28.0
agent-20: 18.0
Sum Reward: 574.0
Avg Reward: 28.7
Min Reward: 16.0
Max Reward: 38.0
Gini Coefficient: 0.09878048780487805
20:20 Ratio: 1.7407407407407407
Max-min Ratio: 2.375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-34-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 524.0350877192982
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 57
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.681
    dispatch_time_ms: 6.358
    learner:
      cur_lr: 0.0012840760173276067
      grad_gnorm: 13.817448616027832
      policy_entropy: 310.65130615234375
      policy_loss: 5.252239227294922
      var_gnorm: 27.74290657043457
      vf_explained_var: 2.7954578399658203e-05
      vf_loss: 0.05164199322462082
    num_steps_sampled: 1160000
    num_steps_trained: 1160000
    wait_time_ms: 343.55
  iterations_since_restore: 58
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 2006.002393245697
  time_this_iter_s: 34.42304754257202
  time_total_s: 2006.002393245697
  timestamp: 1594139651
  timesteps_since_restore: 1160000
  timesteps_this_iter: 20000
  timesteps_total: 1160000
  training_iteration: 58
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 2006 s, 58 iter, 1160000 ts, 524 rew

agent-1: 33.0
agent-2: 28.0
agent-3: 11.0
agent-4: 34.0
agent-5: 29.0
agent-6: 31.0
agent-7: 31.0
agent-8: 21.0
agent-9: 31.0
agent-10: 34.0
agent-11: 31.0
agent-12: 28.0
agent-13: 25.0
agent-14: 22.0
agent-15: 33.0
agent-16: 27.0
agent-17: 25.0
agent-18: 28.0
agent-19: 21.0
agent-20: 24.0
Sum Reward: 547.0
Avg Reward: 27.35
Min Reward: 11.0
Max Reward: 34.0
Gini Coefficient: 0.10758683729433273
20:20 Ratio: 1.7866666666666666
Max-min Ratio: 3.090909090909091
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-34-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 524.4310344827586
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 58
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.383
    dispatch_time_ms: 5.981
    learner:
      cur_lr: 0.0012827439932152629
      grad_gnorm: 10.294907569885254
      policy_entropy: 338.3070068359375
      policy_loss: 4.505768775939941
      var_gnorm: 27.800331115722656
      vf_explained_var: -0.26623594760894775
      vf_loss: 0.030225330963730812
    num_steps_sampled: 1180000
    num_steps_trained: 1180000
    wait_time_ms: 333.913
  iterations_since_restore: 59
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 2040.6041193008423
  time_this_iter_s: 34.601726055145264
  time_total_s: 2040.6041193008423
  timestamp: 1594139686
  timesteps_since_restore: 1180000
  timesteps_this_iter: 20000
  timesteps_total: 1180000
  training_iteration: 59
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 2040 s, 59 iter, 1180000 ts, 524 rew

agent-1: 25.0
agent-2: 25.0
agent-3: 39.0
agent-4: 31.0
agent-5: 36.0
agent-6: 24.0
agent-7: 37.0
agent-8: 25.0
agent-9: 31.0
agent-10: 31.0
agent-11: 19.0
agent-12: 32.0
agent-13: 25.0
agent-14: 38.0
agent-15: 18.0
agent-16: 34.0
agent-17: 28.0
agent-18: 29.0
agent-19: 23.0
agent-20: 36.0
Sum Reward: 586.0
Avg Reward: 29.3
Min Reward: 18.0
Max Reward: 39.0
Gini Coefficient: 0.11774744027303755
20:20 Ratio: 1.7857142857142858
Max-min Ratio: 2.1666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-35-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 525.4745762711865
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 59
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.514
    dispatch_time_ms: 7.147
    learner:
      cur_lr: 0.001281411969102919
      grad_gnorm: 39.999969482421875
      policy_entropy: 289.99920654296875
      policy_loss: 26.288423538208008
      var_gnorm: 27.9898624420166
      vf_explained_var: 0.7382587194442749
      vf_loss: 27.40347671508789
    num_steps_sampled: 1200000
    num_steps_trained: 1200000
    wait_time_ms: 338.143
  iterations_since_restore: 60
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 2075.188153743744
  time_this_iter_s: 34.58403444290161
  time_total_s: 2075.188153743744
  timestamp: 1594139721
  timesteps_since_restore: 1200000
  timesteps_this_iter: 20000
  timesteps_total: 1200000
  training_iteration: 60
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 2075 s, 60 iter, 1200000 ts, 525 rew

agent-1: 32.0
agent-2: 32.0
agent-3: 34.0
agent-4: 28.0
agent-5: 28.0
agent-6: 19.0
agent-7: 25.0
agent-8: 20.0
agent-9: 29.0
agent-10: 27.0
agent-11: 19.0
agent-12: 29.0
agent-13: 19.0
agent-14: 31.0
agent-15: 32.0
agent-16: 34.0
agent-17: 32.0
agent-18: 31.0
agent-19: 24.0
agent-20: 29.0
Sum Reward: 554.0
Avg Reward: 27.7
Min Reward: 19.0
Max Reward: 34.0
Gini Coefficient: 0.09819494584837545
20:20 Ratio: 1.7142857142857142
Max-min Ratio: 1.7894736842105263
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-35-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 525.95
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 60
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.508
    dispatch_time_ms: 6.218
    learner:
      cur_lr: 0.0012800799449905753
      grad_gnorm: 40.0
      policy_entropy: 231.6387481689453
      policy_loss: -15.6708984375
      var_gnorm: 28.131103515625
      vf_explained_var: 0.552829384803772
      vf_loss: 8.678916931152344
    num_steps_sampled: 1220000
    num_steps_trained: 1220000
    wait_time_ms: 343.971
  iterations_since_restore: 61
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 2109.224816083908
  time_this_iter_s: 34.036662340164185
  time_total_s: 2109.224816083908
  timestamp: 1594139755
  timesteps_since_restore: 1220000
  timesteps_this_iter: 20000
  timesteps_total: 1220000
  training_iteration: 61
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 2109 s, 61 iter, 1220000 ts, 526 rew

agent-1: 33.0
agent-2: 38.0
agent-3: 27.0
agent-4: 25.0
agent-5: 31.0
agent-6: 21.0
agent-7: 26.0
agent-8: 34.0
agent-9: 36.0
agent-10: 32.0
agent-11: 34.0
agent-12: 31.0
agent-13: 39.0
agent-14: 28.0
agent-15: 44.0
agent-16: 40.0
agent-17: 28.0
agent-18: 32.0
agent-19: 27.0
agent-20: 29.0
Sum Reward: 635.0
Avg Reward: 31.75
Min Reward: 21.0
Max Reward: 44.0
Gini Coefficient: 0.09834645669291339
20:20 Ratio: 1.6262626262626263
Max-min Ratio: 2.0952380952380953
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-36-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 527.7377049180328
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 61
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.708
    dispatch_time_ms: 8.229
    learner:
      cur_lr: 0.0012787480372935534
      grad_gnorm: 39.99999237060547
      policy_entropy: 289.9227294921875
      policy_loss: -15.754766464233398
      var_gnorm: 28.358890533447266
      vf_explained_var: -1.0
      vf_loss: 4.904181957244873
    num_steps_sampled: 1240000
    num_steps_trained: 1240000
    wait_time_ms: 335.876
  iterations_since_restore: 62
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 2143.865818977356
  time_this_iter_s: 34.641002893447876
  time_total_s: 2143.865818977356
  timestamp: 1594139790
  timesteps_since_restore: 1240000
  timesteps_this_iter: 20000
  timesteps_total: 1240000
  training_iteration: 62
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 2143 s, 62 iter, 1240000 ts, 528 rew

agent-1: 28.0
agent-2: 21.0
agent-3: 32.0
agent-4: 29.0
agent-5: 38.0
agent-6: 34.0
agent-7: 30.0
agent-8: 48.0
agent-9: 37.0
agent-10: 27.0
agent-11: 21.0
agent-12: 25.0
agent-13: 23.0
agent-14: 34.0
agent-15: 34.0
agent-16: 32.0
agent-17: 23.0
agent-18: 24.0
agent-19: 19.0
agent-20: 22.0
Sum Reward: 581.0
Avg Reward: 29.05
Min Reward: 19.0
Max Reward: 48.0
Gini Coefficient: 0.1339931153184165
20:20 Ratio: 1.891566265060241
Max-min Ratio: 2.526315789473684
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-37-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 528.5967741935484
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 62
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.725
    dispatch_time_ms: 6.511
    learner:
      cur_lr: 0.0012774160131812096
      grad_gnorm: 3.20933198928833
      policy_entropy: 311.9984436035156
      policy_loss: -0.9513208866119385
      var_gnorm: 28.439611434936523
      vf_explained_var: 0.0
      vf_loss: 0.0027671675197780132
    num_steps_sampled: 1260000
    num_steps_trained: 1260000
    wait_time_ms: 339.907
  iterations_since_restore: 63
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 2178.1966569423676
  time_this_iter_s: 34.3308379650116
  time_total_s: 2178.1966569423676
  timestamp: 1594139824
  timesteps_since_restore: 1260000
  timesteps_this_iter: 20000
  timesteps_total: 1260000
  training_iteration: 63
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 2178 s, 63 iter, 1260000 ts, 529 rew

agent-1: 21.0
agent-2: 18.0
agent-3: 18.0
agent-4: 32.0
agent-5: 35.0
agent-6: 32.0
agent-7: 29.0
agent-8: 32.0
agent-9: 33.0
agent-10: 25.0
agent-11: 29.0
agent-12: 24.0
agent-13: 17.0
agent-14: 12.0
agent-15: 32.0
agent-16: 28.0
agent-17: 21.0
agent-18: 33.0
agent-19: 48.0
agent-20: 32.0
Sum Reward: 551.0
Avg Reward: 27.55
Min Reward: 12.0
Max Reward: 48.0
Gini Coefficient: 0.1572595281306715
20:20 Ratio: 2.292307692307692
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-37-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 528.952380952381
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 63
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.546
    dispatch_time_ms: 6.468
    learner:
      cur_lr: 0.0012760839890688658
      grad_gnorm: 37.211761474609375
      policy_entropy: 261.913330078125
      policy_loss: 0.3625446557998657
      var_gnorm: 28.541685104370117
      vf_explained_var: -0.5410137176513672
      vf_loss: 0.2647516429424286
    num_steps_sampled: 1280000
    num_steps_trained: 1280000
    wait_time_ms: 341.759
  iterations_since_restore: 64
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 2212.5757524967194
  time_this_iter_s: 34.37909555435181
  time_total_s: 2212.5757524967194
  timestamp: 1594139858
  timesteps_since_restore: 1280000
  timesteps_this_iter: 20000
  timesteps_total: 1280000
  training_iteration: 64
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 2212 s, 64 iter, 1280000 ts, 529 rew

agent-1: 28.0
agent-2: 30.0
agent-3: 22.0
agent-4: 31.0
agent-5: 32.0
agent-6: 21.0
agent-7: 38.0
agent-8: 20.0
agent-9: 29.0
agent-10: 38.0
agent-11: 24.0
agent-12: 38.0
agent-13: 30.0
agent-14: 45.0
agent-15: 38.0
agent-16: 35.0
agent-17: 38.0
agent-18: 29.0
agent-19: 41.0
agent-20: 22.0
Sum Reward: 629.0
Avg Reward: 31.45
Min Reward: 20.0
Max Reward: 45.0
Gini Coefficient: 0.12774244833068363
20:20 Ratio: 1.9058823529411764
Max-min Ratio: 2.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-38-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 530.515625
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 64
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.537
    dispatch_time_ms: 6.056
    learner:
      cur_lr: 0.001274751964956522
      grad_gnorm: 2.0399415493011475
      policy_entropy: 285.4990234375
      policy_loss: -0.559281051158905
      var_gnorm: 28.609201431274414
      vf_explained_var: -1.0
      vf_loss: 0.010329971089959145
    num_steps_sampled: 1300000
    num_steps_trained: 1300000
    wait_time_ms: 343.667
  iterations_since_restore: 65
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 2247.055906057358
  time_this_iter_s: 34.48015356063843
  time_total_s: 2247.055906057358
  timestamp: 1594139893
  timesteps_since_restore: 1300000
  timesteps_this_iter: 20000
  timesteps_total: 1300000
  training_iteration: 65
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 2247 s, 65 iter, 1300000 ts, 531 rew

agent-1: 40.0
agent-2: 31.0
agent-3: 31.0
agent-4: 29.0
agent-5: 20.0
agent-6: 30.0
agent-7: 33.0
agent-8: 41.0
agent-9: 29.0
agent-10: 28.0
agent-11: 31.0
agent-12: 39.0
agent-13: 32.0
agent-14: 24.0
agent-15: 25.0
agent-16: 26.0
agent-17: 18.0
agent-18: 21.0
agent-19: 22.0
agent-20: 28.0
Sum Reward: 578.0
Avg Reward: 28.9
Min Reward: 18.0
Max Reward: 41.0
Gini Coefficient: 0.12006920415224913
20:20 Ratio: 1.8888888888888888
Max-min Ratio: 2.2777777777777777
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-38-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 531.2461538461539
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 65
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 4.163
    dispatch_time_ms: 7.939
    learner:
      cur_lr: 0.0012734200572595
      grad_gnorm: 33.19879150390625
      policy_entropy: 292.6874084472656
      policy_loss: 4.610157012939453
      var_gnorm: 28.71142578125
      vf_explained_var: -0.1809300184249878
      vf_loss: 0.019955266267061234
    num_steps_sampled: 1320000
    num_steps_trained: 1320000
    wait_time_ms: 335.243
  iterations_since_restore: 66
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 2281.325545310974
  time_this_iter_s: 34.26963925361633
  time_total_s: 2281.325545310974
  timestamp: 1594139927
  timesteps_since_restore: 1320000
  timesteps_this_iter: 20000
  timesteps_total: 1320000
  training_iteration: 66
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 2281 s, 66 iter, 1320000 ts, 531 rew

agent-1: 30.0
agent-2: 29.0
agent-3: 33.0
agent-4: 33.0
agent-5: 20.0
agent-6: 43.0
agent-7: 27.0
agent-8: 21.0
agent-9: 43.0
agent-10: 25.0
agent-11: 29.0
agent-12: 24.0
agent-13: 13.0
agent-14: 31.0
agent-15: 20.0
agent-16: 30.0
agent-17: 22.0
agent-18: 24.0
agent-19: 28.0
agent-20: 29.0
Sum Reward: 554.0
Avg Reward: 27.7
Min Reward: 13.0
Max Reward: 43.0
Gini Coefficient: 0.13844765342960288
20:20 Ratio: 2.054054054054054
Max-min Ratio: 3.3076923076923075
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-39-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 531.5909090909091
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 66
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.701
    dispatch_time_ms: 6.447
    learner:
      cur_lr: 0.0012720880331471562
      grad_gnorm: 40.0
      policy_entropy: 271.5289001464844
      policy_loss: -10.180728912353516
      var_gnorm: 28.82120132446289
      vf_explained_var: 0.5834868550300598
      vf_loss: 6.009116172790527
    num_steps_sampled: 1340000
    num_steps_trained: 1340000
    wait_time_ms: 344.166
  iterations_since_restore: 67
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 2315.7476511001587
  time_this_iter_s: 34.42210578918457
  time_total_s: 2315.7476511001587
  timestamp: 1594139962
  timesteps_since_restore: 1340000
  timesteps_this_iter: 20000
  timesteps_total: 1340000
  training_iteration: 67
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 2315 s, 67 iter, 1340000 ts, 532 rew

agent-1: 31.0
agent-2: 27.0
agent-3: 28.0
agent-4: 29.0
agent-5: 25.0
agent-6: 36.0
agent-7: 34.0
agent-8: 26.0
agent-9: 28.0
agent-10: 24.0
agent-11: 31.0
agent-12: 24.0
agent-13: 32.0
agent-14: 32.0
agent-15: 41.0
agent-16: 21.0
agent-17: 27.0
agent-18: 25.0
agent-19: 25.0
agent-20: 23.0
Sum Reward: 569.0
Avg Reward: 28.45
Min Reward: 21.0
Max Reward: 41.0
Gini Coefficient: 0.09200351493848857
20:20 Ratio: 1.5543478260869565
Max-min Ratio: 1.9523809523809523
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-39-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 532.1492537313433
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 67
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.516
    dispatch_time_ms: 6.82
    learner:
      cur_lr: 0.0012707560090348125
      grad_gnorm: 30.7966365814209
      policy_entropy: 278.4677734375
      policy_loss: 1.3351805210113525
      var_gnorm: 28.979440689086914
      vf_explained_var: -1.0
      vf_loss: 1.509398102760315
    num_steps_sampled: 1360000
    num_steps_trained: 1360000
    wait_time_ms: 346.102
  iterations_since_restore: 68
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 2350.3287811279297
  time_this_iter_s: 34.581130027770996
  time_total_s: 2350.3287811279297
  timestamp: 1594139996
  timesteps_since_restore: 1360000
  timesteps_this_iter: 20000
  timesteps_total: 1360000
  training_iteration: 68
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 2350 s, 68 iter, 1360000 ts, 532 rew

agent-1: 25.0
agent-2: 29.0
agent-3: 26.0
agent-4: 31.0
agent-5: 21.0
agent-6: 38.0
agent-7: 35.0
agent-8: 32.0
agent-9: 28.0
agent-10: 37.0
agent-11: 40.0
agent-12: 28.0
agent-13: 36.0
agent-14: 25.0
agent-15: 34.0
agent-16: 30.0
agent-17: 26.0
agent-18: 28.0
agent-19: 19.0
agent-20: 27.0
Sum Reward: 595.0
Avg Reward: 29.75
Min Reward: 19.0
Max Reward: 40.0
Gini Coefficient: 0.10411764705882352
20:20 Ratio: 1.6777777777777778
Max-min Ratio: 2.1052631578947367
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-40-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 533.0735294117648
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 68
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.584
    dispatch_time_ms: 5.609
    learner:
      cur_lr: 0.0012694239849224687
      grad_gnorm: 2.848581552505493
      policy_entropy: 332.2608337402344
      policy_loss: 1.988836646080017
      var_gnorm: 29.04583740234375
      vf_explained_var: -0.00011992454528808594
      vf_loss: 0.002120385877788067
    num_steps_sampled: 1380000
    num_steps_trained: 1380000
    wait_time_ms: 339.063
  iterations_since_restore: 69
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 2384.7476239204407
  time_this_iter_s: 34.418842792510986
  time_total_s: 2384.7476239204407
  timestamp: 1594140031
  timesteps_since_restore: 1380000
  timesteps_this_iter: 20000
  timesteps_total: 1380000
  training_iteration: 69
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 2384 s, 69 iter, 1380000 ts, 533 rew

agent-1: 20.0
agent-2: 43.0
agent-3: 28.0
agent-4: 37.0
agent-5: 25.0
agent-6: 29.0
agent-7: 29.0
agent-8: 28.0
agent-9: 25.0
agent-10: 26.0
agent-11: 29.0
agent-12: 29.0
agent-13: 21.0
agent-14: 36.0
agent-15: 22.0
agent-16: 36.0
agent-17: 25.0
agent-18: 31.0
agent-19: 23.0
agent-20: 24.0
Sum Reward: 566.0
Avg Reward: 28.3
Min Reward: 20.0
Max Reward: 43.0
Gini Coefficient: 0.11113074204946996
20:20 Ratio: 1.7674418604651163
Max-min Ratio: 2.15
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-41-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 533.5507246376811
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 69
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.593
    dispatch_time_ms: 5.636
    learner:
      cur_lr: 0.0012680919608101249
      grad_gnorm: 1.0684409141540527
      policy_entropy: 328.3251037597656
      policy_loss: -1.3270788192749023
      var_gnorm: 29.2545166015625
      vf_explained_var: 0.9959645867347717
      vf_loss: 0.002135399729013443
    num_steps_sampled: 1400000
    num_steps_trained: 1400000
    wait_time_ms: 340.351
  iterations_since_restore: 70
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 2419.4761221408844
  time_this_iter_s: 34.728498220443726
  time_total_s: 2419.4761221408844
  timestamp: 1594140066
  timesteps_since_restore: 1400000
  timesteps_this_iter: 20000
  timesteps_total: 1400000
  training_iteration: 70
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 2419 s, 70 iter, 1400000 ts, 534 rew

agent-1: 20.0
agent-2: 27.0
agent-3: 24.0
agent-4: 48.0
agent-5: 29.0
agent-6: 30.0
agent-7: 39.0
agent-8: 22.0
agent-9: 38.0
agent-10: 33.0
agent-11: 30.0
agent-12: 20.0
agent-13: 30.0
agent-14: 31.0
agent-15: 41.0
agent-16: 26.0
agent-17: 26.0
agent-18: 45.0
agent-19: 25.0
agent-20: 17.0
Sum Reward: 601.0
Avg Reward: 30.05
Min Reward: 17.0
Max Reward: 48.0
Gini Coefficient: 0.1531613976705491
20:20 Ratio: 2.189873417721519
Max-min Ratio: 2.823529411764706
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-41-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 534.5142857142857
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 70
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.503
    dispatch_time_ms: 5.633
    learner:
      cur_lr: 0.001266760053113103
      grad_gnorm: 4.030151844024658
      policy_entropy: 302.1680908203125
      policy_loss: -0.4591034948825836
      var_gnorm: 29.359546661376953
      vf_explained_var: -1.0
      vf_loss: 0.0007824721978977323
    num_steps_sampled: 1420000
    num_steps_trained: 1420000
    wait_time_ms: 343.619
  iterations_since_restore: 71
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 2453.770119905472
  time_this_iter_s: 34.2939977645874
  time_total_s: 2453.770119905472
  timestamp: 1594140100
  timesteps_since_restore: 1420000
  timesteps_this_iter: 20000
  timesteps_total: 1420000
  training_iteration: 71
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 2453 s, 71 iter, 1420000 ts, 535 rew

agent-1: 22.0
agent-2: 27.0
agent-3: 39.0
agent-4: 27.0
agent-5: 46.0
agent-6: 33.0
agent-7: 26.0
agent-8: 21.0
agent-9: 23.0
agent-10: 17.0
agent-11: 30.0
agent-12: 30.0
agent-13: 43.0
agent-14: 43.0
agent-15: 37.0
agent-16: 69.0
agent-17: 14.0
agent-18: 36.0
agent-19: 43.0
agent-20: 26.0
Sum Reward: 652.0
Avg Reward: 32.6
Min Reward: 14.0
Max Reward: 69.0
Gini Coefficient: 0.20076687116564418
20:20 Ratio: 2.7162162162162162
Max-min Ratio: 4.928571428571429
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-42-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 536.169014084507
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 71
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.622
    dispatch_time_ms: 5.596
    learner:
      cur_lr: 0.0012654280290007591
      grad_gnorm: 1.2739368677139282
      policy_entropy: 289.0816345214844
      policy_loss: 0.42347192764282227
      var_gnorm: 29.53885269165039
      vf_explained_var: 0.00016486644744873047
      vf_loss: 0.00041487073758617043
    num_steps_sampled: 1440000
    num_steps_trained: 1440000
    wait_time_ms: 340.337
  iterations_since_restore: 72
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 2488.2798085212708
  time_this_iter_s: 34.50968861579895
  time_total_s: 2488.2798085212708
  timestamp: 1594140134
  timesteps_since_restore: 1440000
  timesteps_this_iter: 20000
  timesteps_total: 1440000
  training_iteration: 72
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 2488 s, 72 iter, 1440000 ts, 536 rew

agent-1: 28.0
agent-2: 33.0
agent-3: 26.0
agent-4: 20.0
agent-5: 22.0
agent-6: 17.0
agent-7: 23.0
agent-8: 22.0
agent-9: 35.0
agent-10: 31.0
agent-11: 22.0
agent-12: 31.0
agent-13: 34.0
agent-14: 36.0
agent-15: 21.0
agent-16: 39.0
agent-17: 35.0
agent-18: 22.0
agent-19: 35.0
agent-20: 22.0
Sum Reward: 554.0
Avg Reward: 27.7
Min Reward: 17.0
Max Reward: 39.0
Gini Coefficient: 0.13249097472924187
20:20 Ratio: 1.8125
Max-min Ratio: 2.2941176470588234
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-42-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 536.4166666666666
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 72
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.53
    dispatch_time_ms: 5.686
    learner:
      cur_lr: 0.0012640960048884153
      grad_gnorm: 2.9850258827209473
      policy_entropy: 334.95147705078125
      policy_loss: -1.7419285774230957
      var_gnorm: 29.52284812927246
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.0022767488844692707
    num_steps_sampled: 1460000
    num_steps_trained: 1460000
    wait_time_ms: 332.488
  iterations_since_restore: 73
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 2522.782999753952
  time_this_iter_s: 34.503191232681274
  time_total_s: 2522.782999753952
  timestamp: 1594140169
  timesteps_since_restore: 1460000
  timesteps_this_iter: 20000
  timesteps_total: 1460000
  training_iteration: 73
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 2522 s, 73 iter, 1460000 ts, 536 rew

agent-1: 19.0
agent-2: 30.0
agent-3: 27.0
agent-4: 33.0
agent-5: 31.0
agent-6: 36.0
agent-7: 30.0
agent-8: 23.0
agent-9: 36.0
agent-10: 34.0
agent-11: 34.0
agent-12: 38.0
agent-13: 31.0
agent-14: 22.0
agent-15: 33.0
agent-16: 21.0
agent-17: 23.0
agent-18: 20.0
agent-19: 25.0
agent-20: 35.0
Sum Reward: 581.0
Avg Reward: 29.05
Min Reward: 19.0
Max Reward: 38.0
Gini Coefficient: 0.11506024096385542
20:20 Ratio: 1.7682926829268293
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-43-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 537.027397260274
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 73
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.912
    dispatch_time_ms: 4.857
    learner:
      cur_lr: 0.0012627639807760715
      grad_gnorm: 4.743045806884766
      policy_entropy: 221.52919006347656
      policy_loss: 2.859828472137451
      var_gnorm: 29.628263473510742
      vf_explained_var: 0.00011348724365234375
      vf_loss: 0.00582514051347971
    num_steps_sampled: 1480000
    num_steps_trained: 1480000
    wait_time_ms: 343.337
  iterations_since_restore: 74
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 2556.9736676216125
  time_this_iter_s: 34.19066786766052
  time_total_s: 2556.9736676216125
  timestamp: 1594140203
  timesteps_since_restore: 1480000
  timesteps_this_iter: 20000
  timesteps_total: 1480000
  training_iteration: 74
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 2556 s, 74 iter, 1480000 ts, 537 rew

agent-1: 25.0
agent-2: 25.0
agent-3: 34.0
agent-4: 37.0
agent-5: 36.0
agent-6: 44.0
agent-7: 36.0
agent-8: 29.0
agent-9: 29.0
agent-10: 43.0
agent-11: 30.0
agent-12: 30.0
agent-13: 8.0
agent-14: 10.0
agent-15: 31.0
agent-16: 40.0
agent-17: 30.0
agent-18: 38.0
agent-19: 28.0
agent-20: 23.0
Sum Reward: 606.0
Avg Reward: 30.3
Min Reward: 8.0
Max Reward: 44.0
Gini Coefficient: 0.1608910891089109
20:20 Ratio: 2.5
Max-min Ratio: 5.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-43-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 537.9594594594595
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 74
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.596
    dispatch_time_ms: 5.876
    learner:
      cur_lr: 0.0012614319566637278
      grad_gnorm: 0.7120116949081421
      policy_entropy: 325.55084228515625
      policy_loss: -0.6006128787994385
      var_gnorm: 29.679841995239258
      vf_explained_var: -0.9364532232284546
      vf_loss: 7.995374471647665e-05
    num_steps_sampled: 1500000
    num_steps_trained: 1500000
    wait_time_ms: 338.276
  iterations_since_restore: 75
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 2591.323870897293
  time_this_iter_s: 34.35020327568054
  time_total_s: 2591.323870897293
  timestamp: 1594140238
  timesteps_since_restore: 1500000
  timesteps_this_iter: 20000
  timesteps_total: 1500000
  training_iteration: 75
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 2591 s, 75 iter, 1500000 ts, 538 rew

agent-1: 22.0
agent-2: 31.0
agent-3: 31.0
agent-4: 28.0
agent-5: 39.0
agent-6: 42.0
agent-7: 29.0
agent-8: 26.0
agent-9: 39.0
agent-10: 37.0
agent-11: 26.0
agent-12: 32.0
agent-13: 34.0
agent-14: 35.0
agent-15: 38.0
agent-16: 29.0
agent-17: 24.0
agent-18: 32.0
agent-19: 28.0
agent-20: 30.0
Sum Reward: 632.0
Avg Reward: 31.6
Min Reward: 22.0
Max Reward: 42.0
Gini Coefficient: 0.09525316455696202
20:20 Ratio: 1.6122448979591837
Max-min Ratio: 1.9090909090909092
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-44-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 539.2133333333334
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 75
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.278
    dispatch_time_ms: 5.932
    learner:
      cur_lr: 0.0012601000489667058
      grad_gnorm: 4.5602569580078125
      policy_entropy: 319.1326904296875
      policy_loss: 2.4067630767822266
      var_gnorm: 29.86479377746582
      vf_explained_var: 0.0019416213035583496
      vf_loss: 0.005330313928425312
    num_steps_sampled: 1520000
    num_steps_trained: 1520000
    wait_time_ms: 345.052
  iterations_since_restore: 76
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 2625.768079996109
  time_this_iter_s: 34.44420909881592
  time_total_s: 2625.768079996109
  timestamp: 1594140272
  timesteps_since_restore: 1520000
  timesteps_this_iter: 20000
  timesteps_total: 1520000
  training_iteration: 76
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 2625 s, 76 iter, 1520000 ts, 539 rew

agent-1: 31.0
agent-2: 28.0
agent-3: 25.0
agent-4: 29.0
agent-5: 30.0
agent-6: 33.0
agent-7: 32.0
agent-8: 23.0
agent-9: 28.0
agent-10: 34.0
agent-11: 25.0
agent-12: 37.0
agent-13: 23.0
agent-14: 20.0
agent-15: 37.0
agent-16: 27.0
agent-17: 29.0
agent-18: 16.0
agent-19: 29.0
agent-20: 22.0
Sum Reward: 558.0
Avg Reward: 27.9
Min Reward: 16.0
Max Reward: 37.0
Gini Coefficient: 0.10752688172043011
20:20 Ratio: 1.7407407407407407
Max-min Ratio: 2.3125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-45-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 539.4605263157895
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 76
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.582
    dispatch_time_ms: 5.696
    learner:
      cur_lr: 0.001258768024854362
      grad_gnorm: 40.00000762939453
      policy_entropy: 294.94366455078125
      policy_loss: -2.682892084121704
      var_gnorm: 29.962696075439453
      vf_explained_var: 0.313088595867157
      vf_loss: 10.474685668945312
    num_steps_sampled: 1540000
    num_steps_trained: 1540000
    wait_time_ms: 333.896
  iterations_since_restore: 77
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 2660.2238421440125
  time_this_iter_s: 34.45576214790344
  time_total_s: 2660.2238421440125
  timestamp: 1594140307
  timesteps_since_restore: 1540000
  timesteps_this_iter: 20000
  timesteps_total: 1540000
  training_iteration: 77
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 2660 s, 77 iter, 1540000 ts, 539 rew

agent-1: 25.0
agent-2: 24.0
agent-3: 30.0
agent-4: 30.0
agent-5: 22.0
agent-6: 22.0
agent-7: 29.0
agent-8: 31.0
agent-9: 36.0
agent-10: 37.0
agent-11: 31.0
agent-12: 31.0
agent-13: 26.0
agent-14: 30.0
agent-15: 24.0
agent-16: 24.0
agent-17: 23.0
agent-18: 28.0
agent-19: 31.0
agent-20: 16.0
Sum Reward: 550.0
Avg Reward: 27.5
Min Reward: 16.0
Max Reward: 37.0
Gini Coefficient: 0.09963636363636363
20:20 Ratio: 1.6265060240963856
Max-min Ratio: 2.3125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-45-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 539.5974025974026
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 77
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.765
    dispatch_time_ms: 7.198
    learner:
      cur_lr: 0.0012574360007420182
      grad_gnorm: 1.0076223611831665
      policy_entropy: 347.6264953613281
      policy_loss: -0.802505373954773
      var_gnorm: 30.089595794677734
      vf_explained_var: -0.002560257911682129
      vf_loss: 0.0001944112009368837
    num_steps_sampled: 1560000
    num_steps_trained: 1560000
    wait_time_ms: 349.157
  iterations_since_restore: 78
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 2694.911252975464
  time_this_iter_s: 34.687410831451416
  time_total_s: 2694.911252975464
  timestamp: 1594140341
  timesteps_since_restore: 1560000
  timesteps_this_iter: 20000
  timesteps_total: 1560000
  training_iteration: 78
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 2694 s, 78 iter, 1560000 ts, 540 rew

agent-1: 23.0
agent-2: 32.0
agent-3: 24.0
agent-4: 15.0
agent-5: 39.0
agent-6: 35.0
agent-7: 27.0
agent-8: 25.0
agent-9: 18.0
agent-10: 31.0
agent-11: 17.0
agent-12: 32.0
agent-13: 37.0
agent-14: 23.0
agent-15: 38.0
agent-16: 38.0
agent-17: 15.0
agent-18: 18.0
agent-19: 18.0
agent-20: 30.0
Sum Reward: 535.0
Avg Reward: 26.75
Min Reward: 15.0
Max Reward: 39.0
Gini Coefficient: 0.1724299065420561
20:20 Ratio: 2.3384615384615386
Max-min Ratio: 2.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-46-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 539.5384615384615
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 78
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.172
    dispatch_time_ms: 6.664
    learner:
      cur_lr: 0.0012561039766296744
      grad_gnorm: 1.3965829610824585
      policy_entropy: 360.325927734375
      policy_loss: -1.1122498512268066
      var_gnorm: 30.13941764831543
      vf_explained_var: -1.0
      vf_loss: 0.004690796602517366
    num_steps_sampled: 1580000
    num_steps_trained: 1580000
    wait_time_ms: 337.359
  iterations_since_restore: 79
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 2729.425007581711
  time_this_iter_s: 34.51375460624695
  time_total_s: 2729.425007581711
  timestamp: 1594140376
  timesteps_since_restore: 1580000
  timesteps_this_iter: 20000
  timesteps_total: 1580000
  training_iteration: 79
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 2729 s, 79 iter, 1580000 ts, 540 rew

agent-1: 27.0
agent-2: 26.0
agent-3: 27.0
agent-4: 30.0
agent-5: 29.0
agent-6: 32.0
agent-7: 31.0
agent-8: 30.0
agent-9: 29.0
agent-10: 25.0
agent-11: 22.0
agent-12: 32.0
agent-13: 28.0
agent-14: 34.0
agent-15: 16.0
agent-16: 30.0
agent-17: 25.0
agent-18: 24.0
agent-19: 21.0
agent-20: 34.0
Sum Reward: 552.0
Avg Reward: 27.6
Min Reward: 16.0
Max Reward: 34.0
Gini Coefficient: 0.08858695652173913
20:20 Ratio: 1.5903614457831325
Max-min Ratio: 2.125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-46-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 539.6962025316456
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 79
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.571
    dispatch_time_ms: 7.006
    learner:
      cur_lr: 0.0012547719525173306
      grad_gnorm: 9.935275077819824
      policy_entropy: 362.55999755859375
      policy_loss: 2.1896069049835205
      var_gnorm: 30.276323318481445
      vf_explained_var: -1.0
      vf_loss: 0.023057322949171066
    num_steps_sampled: 1600000
    num_steps_trained: 1600000
    wait_time_ms: 341.122
  iterations_since_restore: 80
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 2764.054292201996
  time_this_iter_s: 34.629284620285034
  time_total_s: 2764.054292201996
  timestamp: 1594140411
  timesteps_since_restore: 1600000
  timesteps_this_iter: 20000
  timesteps_total: 1600000
  training_iteration: 80
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 2764 s, 80 iter, 1600000 ts, 540 rew

agent-1: 21.0
agent-2: 29.0
agent-3: 34.0
agent-4: 27.0
agent-5: 30.0
agent-6: 24.0
agent-7: 20.0
agent-8: 26.0
agent-9: 26.0
agent-10: 35.0
agent-11: 29.0
agent-12: 31.0
agent-13: 25.0
agent-14: 31.0
agent-15: 21.0
agent-16: 30.0
agent-17: 39.0
agent-18: 29.0
agent-19: 18.0
agent-20: 27.0
Sum Reward: 552.0
Avg Reward: 27.6
Min Reward: 18.0
Max Reward: 39.0
Gini Coefficient: 0.10434782608695652
20:20 Ratio: 1.7375
Max-min Ratio: 2.1666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-47-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 539.85
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 80
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.597
    dispatch_time_ms: 22.977
    learner:
      cur_lr: 0.0012534400448203087
      grad_gnorm: 1.0934178829193115
      policy_entropy: 362.84716796875
      policy_loss: -0.8643349409103394
      var_gnorm: 30.340206146240234
      vf_explained_var: -0.46855437755584717
      vf_loss: 0.009048999287188053
    num_steps_sampled: 1620000
    num_steps_trained: 1620000
    wait_time_ms: 349.439
  iterations_since_restore: 81
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 2800.442161798477
  time_this_iter_s: 36.38786959648132
  time_total_s: 2800.442161798477
  timestamp: 1594140447
  timesteps_since_restore: 1620000
  timesteps_this_iter: 20000
  timesteps_total: 1620000
  training_iteration: 81
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 2800 s, 81 iter, 1620000 ts, 540 rew

agent-1: 20.0
agent-2: 27.0
agent-3: 29.0
agent-4: 24.0
agent-5: 35.0
agent-6: 37.0
agent-7: 19.0
agent-8: 18.0
agent-9: 30.0
agent-10: 25.0
agent-11: 35.0
agent-12: 11.0
agent-13: 30.0
agent-14: 24.0
agent-15: 25.0
agent-16: 31.0
agent-17: 30.0
agent-18: 23.0
agent-19: 21.0
agent-20: 36.0
Sum Reward: 530.0
Avg Reward: 26.5
Min Reward: 11.0
Max Reward: 37.0
Gini Coefficient: 0.1409433962264151
20:20 Ratio: 2.1029411764705883
Max-min Ratio: 3.3636363636363638
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-48-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 539.7283950617284
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 81
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.576
    dispatch_time_ms: 21.971
    learner:
      cur_lr: 0.001252108020707965
      grad_gnorm: 13.762578010559082
      policy_entropy: 331.72235107421875
      policy_loss: 8.675922393798828
      var_gnorm: 30.56549835205078
      vf_explained_var: -0.5210111141204834
      vf_loss: 0.05749431252479553
    num_steps_sampled: 1640000
    num_steps_trained: 1640000
    wait_time_ms: 359.068
  iterations_since_restore: 82
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 2835.7351014614105
  time_this_iter_s: 35.29293966293335
  time_total_s: 2835.7351014614105
  timestamp: 1594140482
  timesteps_since_restore: 1640000
  timesteps_this_iter: 20000
  timesteps_total: 1640000
  training_iteration: 82
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 2835 s, 82 iter, 1640000 ts, 540 rew

agent-1: 23.0
agent-2: 34.0
agent-3: 31.0
agent-4: 33.0
agent-5: 30.0
agent-6: 34.0
agent-7: 29.0
agent-8: 34.0
agent-9: 21.0
agent-10: 28.0
agent-11: 31.0
agent-12: 27.0
agent-13: 28.0
agent-14: 31.0
agent-15: 38.0
agent-16: 16.0
agent-17: 25.0
agent-18: 26.0
agent-19: 19.0
agent-20: 31.0
Sum Reward: 569.0
Avg Reward: 28.45
Min Reward: 16.0
Max Reward: 38.0
Gini Coefficient: 0.10518453427065026
20:20 Ratio: 1.7721518987341771
Max-min Ratio: 2.375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-48-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 540.0853658536586
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 82
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.796
    dispatch_time_ms: 18.359
    learner:
      cur_lr: 0.0012507759965956211
      grad_gnorm: 40.000003814697266
      policy_entropy: 125.92737579345703
      policy_loss: -53.45265579223633
      var_gnorm: 30.58344268798828
      vf_explained_var: 0.26859724521636963
      vf_loss: 146.2445068359375
    num_steps_sampled: 1660000
    num_steps_trained: 1660000
    wait_time_ms: 316.435
  iterations_since_restore: 83
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 2871.0773606300354
  time_this_iter_s: 35.34225916862488
  time_total_s: 2871.0773606300354
  timestamp: 1594140518
  timesteps_since_restore: 1660000
  timesteps_this_iter: 20000
  timesteps_total: 1660000
  training_iteration: 83
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 2871 s, 83 iter, 1660000 ts, 540 rew

agent-1: 31.0
agent-2: 34.0
agent-3: 56.0
agent-4: 33.0
agent-5: 30.0
agent-6: 35.0
agent-7: 27.0
agent-8: 36.0
agent-9: 28.0
agent-10: 41.0
agent-11: 31.0
agent-12: 33.0
agent-13: 43.0
agent-14: 25.0
agent-15: 21.0
agent-16: 23.0
agent-17: 32.0
agent-18: 33.0
agent-19: 23.0
agent-20: 28.0
Sum Reward: 643.0
Avg Reward: 32.15
Min Reward: 21.0
Max Reward: 56.0
Gini Coefficient: 0.12573872472783826
20:20 Ratio: 1.9130434782608696
Max-min Ratio: 2.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-49-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 541.3253012048193
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 83
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 4.157
    dispatch_time_ms: 32.358
    learner:
      cur_lr: 0.0012494439724832773
      grad_gnorm: 13.22696590423584
      policy_entropy: 328.85821533203125
      policy_loss: 10.063719749450684
      var_gnorm: 30.739118576049805
      vf_explained_var: -1.0
      vf_loss: 0.013771390542387962
    num_steps_sampled: 1680000
    num_steps_trained: 1680000
    wait_time_ms: 342.405
  iterations_since_restore: 84
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 2908.647297859192
  time_this_iter_s: 37.569937229156494
  time_total_s: 2908.647297859192
  timestamp: 1594140555
  timesteps_since_restore: 1680000
  timesteps_this_iter: 20000
  timesteps_total: 1680000
  training_iteration: 84
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 2908 s, 84 iter, 1680000 ts, 541 rew

agent-1: 32.0
agent-2: 21.0
agent-3: 26.0
agent-4: 27.0
agent-5: 21.0
agent-6: 24.0
agent-7: 27.0
agent-8: 30.0
agent-9: 31.0
agent-10: 30.0
agent-11: 38.0
agent-12: 28.0
agent-13: 22.0
agent-14: 39.0
agent-15: 25.0
agent-16: 34.0
agent-17: 33.0
agent-18: 30.0
agent-19: 28.0
agent-20: 27.0
Sum Reward: 573.0
Avg Reward: 28.65
Min Reward: 21.0
Max Reward: 39.0
Gini Coefficient: 0.09554973821989529
20:20 Ratio: 1.6363636363636365
Max-min Ratio: 1.8571428571428572
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-49-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 541.702380952381
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 84
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.765
    dispatch_time_ms: 5.65
    learner:
      cur_lr: 0.0012481119483709335
      grad_gnorm: 39.99998474121094
      policy_entropy: 161.6048126220703
      policy_loss: -1.0928065776824951
      var_gnorm: 30.756792068481445
      vf_explained_var: 0.37753647565841675
      vf_loss: 17.927024841308594
    num_steps_sampled: 1700000
    num_steps_trained: 1700000
    wait_time_ms: 334.444
  iterations_since_restore: 85
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 2941.215217113495
  time_this_iter_s: 32.56791925430298
  time_total_s: 2941.215217113495
  timestamp: 1594140591
  timesteps_since_restore: 1700000
  timesteps_this_iter: 20000
  timesteps_total: 1700000
  training_iteration: 85
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 2941 s, 85 iter, 1700000 ts, 542 rew

agent-1: 44.0
agent-2: 30.0
agent-3: 28.0
agent-4: 38.0
agent-5: 28.0
agent-6: 23.0
agent-7: 27.0
agent-8: 52.0
agent-9: 27.0
agent-10: 27.0
agent-11: 46.0
agent-12: 28.0
agent-13: 30.0
agent-14: 28.0
agent-15: 31.0
agent-16: 22.0
agent-17: 34.0
agent-18: 35.0
agent-19: 23.0
agent-20: 33.0
Sum Reward: 634.0
Avg Reward: 31.7
Min Reward: 22.0
Max Reward: 52.0
Gini Coefficient: 0.12839116719242902
20:20 Ratio: 1.894736842105263
Max-min Ratio: 2.3636363636363638
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-50-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 542.7882352941176
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 85
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.509
    dispatch_time_ms: 4.974
    learner:
      cur_lr: 0.0012467800406739116
      grad_gnorm: 5.591401100158691
      policy_entropy: 319.5609436035156
      policy_loss: 3.205749988555908
      var_gnorm: 30.941869735717773
      vf_explained_var: -1.0
      vf_loss: 0.016200430691242218
    num_steps_sampled: 1720000
    num_steps_trained: 1720000
    wait_time_ms: 341.357
  iterations_since_restore: 86
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 2974.7352542877197
  time_this_iter_s: 33.52003717422485
  time_total_s: 2974.7352542877197
  timestamp: 1594140624
  timesteps_since_restore: 1720000
  timesteps_this_iter: 20000
  timesteps_total: 1720000
  training_iteration: 86
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 2974 s, 86 iter, 1720000 ts, 543 rew

agent-1: 19.0
agent-2: 27.0
agent-3: 18.0
agent-4: 29.0
agent-5: 26.0
agent-6: 32.0
agent-7: 28.0
agent-8: 30.0
agent-9: 30.0
agent-10: 30.0
agent-11: 21.0
agent-12: 28.0
agent-13: 33.0
agent-14: 26.0
agent-15: 24.0
agent-16: 22.0
agent-17: 30.0
agent-18: 29.0
agent-19: 29.0
agent-20: 33.0
Sum Reward: 544.0
Avg Reward: 27.2
Min Reward: 18.0
Max Reward: 33.0
Gini Coefficient: 0.08602941176470588
20:20 Ratio: 1.6
Max-min Ratio: 1.8333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-50-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 542.8023255813954
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 86
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.544
    dispatch_time_ms: 6.259
    learner:
      cur_lr: 0.0012454480165615678
      grad_gnorm: 12.011411666870117
      policy_entropy: 348.8046875
      policy_loss: -3.4980580806732178
      var_gnorm: 30.9414119720459
      vf_explained_var: -0.2549302577972412
      vf_loss: 0.05480564385652542
    num_steps_sampled: 1740000
    num_steps_trained: 1740000
    wait_time_ms: 327.983
  iterations_since_restore: 87
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 3008.9722168445587
  time_this_iter_s: 34.23696255683899
  time_total_s: 3008.9722168445587
  timestamp: 1594140658
  timesteps_since_restore: 1740000
  timesteps_this_iter: 20000
  timesteps_total: 1740000
  training_iteration: 87
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 3008 s, 87 iter, 1740000 ts, 543 rew

agent-1: 46.0
agent-2: 44.0
agent-3: 36.0
agent-4: 43.0
agent-5: 55.0
agent-6: 48.0
agent-7: 40.0
agent-8: 57.0
agent-9: 51.0
agent-10: 47.0
agent-11: 38.0
agent-12: 31.0
agent-13: 34.0
agent-14: 37.0
agent-15: 45.0
agent-16: 44.0
agent-17: 62.0
agent-18: 36.0
agent-19: 45.0
agent-20: 47.0
Sum Reward: 886.0
Avg Reward: 44.3
Min Reward: 31.0
Max Reward: 62.0
Gini Coefficient: 0.09762979683972912
20:20 Ratio: 1.6423357664233578
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-51-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 546.7471264367816
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 87
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.127
    dispatch_time_ms: 6.111
    learner:
      cur_lr: 0.001244115992449224
      grad_gnorm: 4.19912576675415
      policy_entropy: 339.21142578125
      policy_loss: -2.148801565170288
      var_gnorm: 31.063617706298828
      vf_explained_var: -1.0
      vf_loss: 0.008452341891825199
    num_steps_sampled: 1760000
    num_steps_trained: 1760000
    wait_time_ms: 358.324
  iterations_since_restore: 88
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 3043.510553598404
  time_this_iter_s: 34.538336753845215
  time_total_s: 3043.510553598404
  timestamp: 1594140693
  timesteps_since_restore: 1760000
  timesteps_this_iter: 20000
  timesteps_total: 1760000
  training_iteration: 88
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 3043 s, 88 iter, 1760000 ts, 547 rew

agent-1: 32.0
agent-2: 21.0
agent-3: 36.0
agent-4: 26.0
agent-5: 31.0
agent-6: 32.0
agent-7: 32.0
agent-8: 30.0
agent-9: 26.0
agent-10: 32.0
agent-11: 43.0
agent-12: 47.0
agent-13: 27.0
agent-14: 44.0
agent-15: 20.0
agent-16: 36.0
agent-17: 18.0
agent-18: 36.0
agent-19: 29.0
agent-20: 37.0
Sum Reward: 635.0
Avg Reward: 31.75
Min Reward: 18.0
Max Reward: 47.0
Gini Coefficient: 0.13267716535433072
20:20 Ratio: 2.011764705882353
Max-min Ratio: 2.611111111111111
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-52-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 547.75
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 88
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.184
    dispatch_time_ms: 6.269
    learner:
      cur_lr: 0.0012427839683368802
      grad_gnorm: 40.000030517578125
      policy_entropy: 153.1416778564453
      policy_loss: -35.913719177246094
      var_gnorm: 31.07061767578125
      vf_explained_var: 0.5675829648971558
      vf_loss: 258.02813720703125
    num_steps_sampled: 1780000
    num_steps_trained: 1780000
    wait_time_ms: 303.845
  iterations_since_restore: 89
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 3077.895354986191
  time_this_iter_s: 34.384801387786865
  time_total_s: 3077.895354986191
  timestamp: 1594140727
  timesteps_since_restore: 1780000
  timesteps_this_iter: 20000
  timesteps_total: 1780000
  training_iteration: 89
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 3077 s, 89 iter, 1780000 ts, 548 rew

agent-1: 43.0
agent-2: 27.0
agent-3: 34.0
agent-4: 26.0
agent-5: 29.0
agent-6: 42.0
agent-7: 35.0
agent-8: 40.0
agent-9: 45.0
agent-10: 31.0
agent-11: 28.0
agent-12: 32.0
agent-13: 25.0
agent-14: 29.0
agent-15: 23.0
agent-16: 32.0
agent-17: 30.0
agent-18: 24.0
agent-19: 39.0
agent-20: 27.0
Sum Reward: 641.0
Avg Reward: 32.05
Min Reward: 23.0
Max Reward: 45.0
Gini Coefficient: 0.11302652106084243
20:20 Ratio: 1.7346938775510203
Max-min Ratio: 1.9565217391304348
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-52-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 548.7977528089888
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 89
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.469
    dispatch_time_ms: 6.565
    learner:
      cur_lr: 0.0012414519442245364
      grad_gnorm: 1.721981167793274
      policy_entropy: 324.5412292480469
      policy_loss: -1.4370943307876587
      var_gnorm: 31.53032112121582
      vf_explained_var: 6.258487701416016e-06
      vf_loss: 0.0006060046143829823
    num_steps_sampled: 1800000
    num_steps_trained: 1800000
    wait_time_ms: 338.222
  iterations_since_restore: 90
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 3112.222857236862
  time_this_iter_s: 34.32750225067139
  time_total_s: 3112.222857236862
  timestamp: 1594140762
  timesteps_since_restore: 1800000
  timesteps_this_iter: 20000
  timesteps_total: 1800000
  training_iteration: 90
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 3112 s, 90 iter, 1800000 ts, 549 rew

agent-1: 19.0
agent-2: 30.0
agent-3: 42.0
agent-4: 29.0
agent-5: 17.0
agent-6: 15.0
agent-7: 31.0
agent-8: 22.0
agent-9: 33.0
agent-10: 33.0
agent-11: 29.0
agent-12: 40.0
agent-13: 35.0
agent-14: 30.0
agent-15: 51.0
agent-16: 27.0
agent-17: 48.0
agent-18: 33.0
agent-19: 27.0
agent-20: 38.0
Sum Reward: 629.0
Avg Reward: 31.45
Min Reward: 15.0
Max Reward: 51.0
Gini Coefficient: 0.162241653418124
20:20 Ratio: 2.4794520547945207
Max-min Ratio: 3.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-53-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 549.6888888888889
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 90
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.446
    dispatch_time_ms: 7.702
    learner:
      cur_lr: 0.0012401200365275145
      grad_gnorm: 39.9999885559082
      policy_entropy: 208.92324829101562
      policy_loss: 42.0026741027832
      var_gnorm: 31.54954719543457
      vf_explained_var: 0.16726601123809814
      vf_loss: 191.63255310058594
    num_steps_sampled: 1820000
    num_steps_trained: 1820000
    wait_time_ms: 284.995
  iterations_since_restore: 91
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 3146.711993455887
  time_this_iter_s: 34.48913621902466
  time_total_s: 3146.711993455887
  timestamp: 1594140796
  timesteps_since_restore: 1820000
  timesteps_this_iter: 20000
  timesteps_total: 1820000
  training_iteration: 91
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 3146 s, 91 iter, 1820000 ts, 550 rew

agent-1: 39.0
agent-2: 50.0
agent-3: 23.0
agent-4: 17.0
agent-5: 34.0
agent-6: 40.0
agent-7: 39.0
agent-8: 30.0
agent-9: 28.0
agent-10: 31.0
agent-11: 46.0
agent-12: 23.0
agent-13: 46.0
agent-14: 46.0
agent-15: 45.0
agent-16: 20.0
agent-17: 39.0
agent-18: 19.0
agent-19: 40.0
agent-20: 39.0
Sum Reward: 694.0
Avg Reward: 34.7
Min Reward: 17.0
Max Reward: 50.0
Gini Coefficient: 0.16210374639769454
20:20 Ratio: 2.3797468354430378
Max-min Ratio: 2.9411764705882355
W0707 12:54:10.773330 17834 client_connection.cc:255] [worker]ProcessMessage with type 19 took 104 ms.
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-54-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 551.2747252747253
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 91
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.669
    dispatch_time_ms: 5.417
    learner:
      cur_lr: 0.0012387880124151707
      grad_gnorm: 9.12651252746582
      policy_entropy: 289.6243896484375
      policy_loss: -4.339229583740234
      var_gnorm: 31.625717163085938
      vf_explained_var: 0.9956232905387878
      vf_loss: 0.06672967970371246
    num_steps_sampled: 1840000
    num_steps_trained: 1840000
    wait_time_ms: 341.148
  iterations_since_restore: 92
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 3207.6225066184998
  time_this_iter_s: 60.910513162612915
  time_total_s: 3207.6225066184998
  timestamp: 1594140857
  timesteps_since_restore: 1840000
  timesteps_this_iter: 20000
  timesteps_total: 1840000
  training_iteration: 92
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 3207 s, 92 iter, 1840000 ts, 551 rew

agent-1: 33.0
agent-2: 34.0
agent-3: 46.0
agent-4: 43.0
agent-5: 46.0
agent-6: 42.0
agent-7: 38.0
agent-8: 34.0
agent-9: 58.0
agent-10: 50.0
agent-11: 40.0
agent-12: 50.0
agent-13: 37.0
agent-14: 36.0
agent-15: 47.0
agent-16: 35.0
agent-17: 31.0
agent-18: 32.0
agent-19: 41.0
agent-20: 33.0
Sum Reward: 806.0
Avg Reward: 40.3
Min Reward: 31.0
Max Reward: 58.0
Gini Coefficient: 0.09900744416873448
20:20 Ratio: 1.5891472868217054
Max-min Ratio: 1.8709677419354838
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-54-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 554.0434782608696
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 92
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.53
    dispatch_time_ms: 14.167
    learner:
      cur_lr: 0.0012374559883028269
      grad_gnorm: 40.0
      policy_entropy: 167.25567626953125
      policy_loss: 64.79686737060547
      var_gnorm: 31.61420249938965
      vf_explained_var: 0.4575587511062622
      vf_loss: 297.5447082519531
    num_steps_sampled: 1860000
    num_steps_trained: 1860000
    wait_time_ms: 295.595
  iterations_since_restore: 93
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 3243.27205991745
  time_this_iter_s: 35.649553298950195
  time_total_s: 3243.27205991745
  timestamp: 1594140893
  timesteps_since_restore: 1860000
  timesteps_this_iter: 20000
  timesteps_total: 1860000
  training_iteration: 93
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 3243 s, 93 iter, 1860000 ts, 554 rew

agent-1: 39.0
agent-2: 34.0
agent-3: 32.0
agent-4: 29.0
agent-5: 25.0
agent-6: 25.0
agent-7: 25.0
agent-8: 22.0
agent-9: 26.0
agent-10: 28.0
agent-11: 19.0
agent-12: 27.0
agent-13: 31.0
agent-14: 25.0
agent-15: 32.0
agent-16: 30.0
agent-17: 21.0
agent-18: 28.0
agent-19: 24.0
agent-20: 25.0
Sum Reward: 547.0
Avg Reward: 27.35
Min Reward: 19.0
Max Reward: 39.0
Gini Coefficient: 0.09314442413162706
20:20 Ratio: 1.5930232558139534
Max-min Ratio: 2.0526315789473686
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-55-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 553.9677419354839
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 93
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.4
    dispatch_time_ms: 15.567
    learner:
      cur_lr: 0.001236123964190483
      grad_gnorm: 2.073591709136963
      policy_entropy: 379.8545837402344
      policy_loss: -2.4619297981262207
      var_gnorm: 31.74751091003418
      vf_explained_var: 0.00010782480239868164
      vf_loss: 0.0010301421862095594
    num_steps_sampled: 1880000
    num_steps_trained: 1880000
    wait_time_ms: 359.819
  iterations_since_restore: 94
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 3278.7599337100983
  time_this_iter_s: 35.487873792648315
  time_total_s: 3278.7599337100983
  timestamp: 1594140929
  timesteps_since_restore: 1880000
  timesteps_this_iter: 20000
  timesteps_total: 1880000
  training_iteration: 94
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 3278 s, 94 iter, 1880000 ts, 554 rew

agent-1: 38.0
agent-2: 30.0
agent-3: 32.0
agent-4: 33.0
agent-5: 31.0
agent-6: 29.0
agent-7: 30.0
agent-8: 28.0
agent-9: 26.0
agent-10: 37.0
agent-11: 25.0
agent-12: 31.0
agent-13: 35.0
agent-14: 25.0
agent-15: 26.0
agent-16: 34.0
agent-17: 41.0
agent-18: 27.0
agent-19: 31.0
agent-20: 45.0
Sum Reward: 634.0
Avg Reward: 31.7
Min Reward: 25.0
Max Reward: 45.0
Gini Coefficient: 0.09132492113564669
20:20 Ratio: 1.5784313725490196
Max-min Ratio: 1.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-56-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 554.8191489361702
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 94
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.715
    dispatch_time_ms: 6.022
    learner:
      cur_lr: 0.0012347920564934611
      grad_gnorm: 1.4601496458053589
      policy_entropy: 385.63055419921875
      policy_loss: 0.16187211871147156
      var_gnorm: 31.742172241210938
      vf_explained_var: 6.377696990966797e-06
      vf_loss: 0.0004554805054794997
    num_steps_sampled: 1900000
    num_steps_trained: 1900000
    wait_time_ms: 336.892
  iterations_since_restore: 95
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 3314.4314041137695
  time_this_iter_s: 35.671470403671265
  time_total_s: 3314.4314041137695
  timestamp: 1594140964
  timesteps_since_restore: 1900000
  timesteps_this_iter: 20000
  timesteps_total: 1900000
  training_iteration: 95
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 3314 s, 95 iter, 1900000 ts, 555 rew

agent-1: 25.0
agent-2: 23.0
agent-3: 35.0
agent-4: 23.0
agent-5: 37.0
agent-6: 25.0
agent-7: 42.0
agent-8: 36.0
agent-9: 36.0
agent-10: 25.0
agent-11: 36.0
agent-12: 31.0
agent-13: 27.0
agent-14: 29.0
agent-15: 22.0
agent-16: 28.0
agent-17: 19.0
agent-18: 28.0
agent-19: 33.0
agent-20: 25.0
Sum Reward: 585.0
Avg Reward: 29.25
Min Reward: 19.0
Max Reward: 42.0
Gini Coefficient: 0.11615384615384615
20:20 Ratio: 1.735632183908046
Max-min Ratio: 2.210526315789474
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-56-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 555.1368421052632
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 95
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.348
    dispatch_time_ms: 5.768
    learner:
      cur_lr: 0.0012334600323811173
      grad_gnorm: 6.166259765625
      policy_entropy: 267.821533203125
      policy_loss: -2.190619707107544
      var_gnorm: 31.977741241455078
      vf_explained_var: 4.667043685913086e-05
      vf_loss: 0.009652236476540565
    num_steps_sampled: 1920000
    num_steps_trained: 1920000
    wait_time_ms: 351.003
  iterations_since_restore: 96
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 3348.6616542339325
  time_this_iter_s: 34.230250120162964
  time_total_s: 3348.6616542339325
  timestamp: 1594140999
  timesteps_since_restore: 1920000
  timesteps_this_iter: 20000
  timesteps_total: 1920000
  training_iteration: 96
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 3348 s, 96 iter, 1920000 ts, 555 rew

agent-1: 21.0
agent-2: 28.0
agent-3: 28.0
agent-4: 47.0
agent-5: 18.0
agent-6: 17.0
agent-7: 42.0
agent-8: 21.0
agent-9: 23.0
agent-10: 33.0
agent-11: 31.0
agent-12: 32.0
agent-13: 21.0
agent-14: 37.0
agent-15: 20.0
agent-16: 42.0
agent-17: 31.0
agent-18: 33.0
agent-19: 34.0
agent-20: 25.0
Sum Reward: 584.0
Avg Reward: 29.2
Min Reward: 17.0
Max Reward: 47.0
Gini Coefficient: 0.1613013698630137
20:20 Ratio: 2.210526315789474
Max-min Ratio: 2.764705882352941
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-57-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 555.4375
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 96
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.504
    dispatch_time_ms: 18.982
    learner:
      cur_lr: 0.0012321280082687736
      grad_gnorm: 0.3480885922908783
      policy_entropy: 333.98541259765625
      policy_loss: 0.9473814964294434
      var_gnorm: 31.987579345703125
      vf_explained_var: 0.0
      vf_loss: 7.257092875079252e-06
    num_steps_sampled: 1940000
    num_steps_trained: 1940000
    wait_time_ms: 330.523
  iterations_since_restore: 97
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 3384.670816421509
  time_this_iter_s: 36.009162187576294
  time_total_s: 3384.670816421509
  timestamp: 1594141035
  timesteps_since_restore: 1940000
  timesteps_this_iter: 20000
  timesteps_total: 1940000
  training_iteration: 97
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 3384 s, 97 iter, 1940000 ts, 555 rew

agent-1: 19.0
agent-2: 21.0
agent-3: 32.0
agent-4: 36.0
agent-5: 28.0
agent-6: 26.0
agent-7: 37.0
agent-8: 27.0
agent-9: 43.0
agent-10: 30.0
agent-11: 28.0
agent-12: 27.0
agent-13: 34.0
agent-14: 32.0
agent-15: 36.0
agent-16: 24.0
agent-17: 36.0
agent-18: 27.0
agent-19: 40.0
agent-20: 32.0
Sum Reward: 615.0
Avg Reward: 30.75
Min Reward: 19.0
Max Reward: 43.0
Gini Coefficient: 0.11113821138211383
20:20 Ratio: 1.7333333333333334
Max-min Ratio: 2.263157894736842
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-57-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 556.0515463917526
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 97
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.669
    dispatch_time_ms: 25.924
    learner:
      cur_lr: 0.0012307959841564298
      grad_gnorm: 2.4035680294036865
      policy_entropy: 345.81488037109375
      policy_loss: -6.571130752563477
      var_gnorm: 32.15583419799805
      vf_explained_var: -0.1652381420135498
      vf_loss: 0.0006205788813531399
    num_steps_sampled: 1960000
    num_steps_trained: 1960000
    wait_time_ms: 321.597
  iterations_since_restore: 98
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 3420.111604452133
  time_this_iter_s: 35.44078803062439
  time_total_s: 3420.111604452133
  timestamp: 1594141070
  timesteps_since_restore: 1960000
  timesteps_this_iter: 20000
  timesteps_total: 1960000
  training_iteration: 98
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 3420 s, 98 iter, 1960000 ts, 556 rew

agent-1: 41.0
agent-2: 33.0
agent-3: 29.0
agent-4: 23.0
agent-5: 27.0
agent-6: 30.0
agent-7: 37.0
agent-8: 25.0
agent-9: 21.0
agent-10: 38.0
agent-11: 27.0
agent-12: 46.0
agent-13: 32.0
agent-14: 31.0
agent-15: 39.0
agent-16: 54.0
agent-17: 31.0
agent-18: 28.0
agent-19: 49.0
agent-20: 26.0
Sum Reward: 667.0
Avg Reward: 33.35
Min Reward: 21.0
Max Reward: 54.0
Gini Coefficient: 0.14235382308845576
20:20 Ratio: 2.0
Max-min Ratio: 2.5714285714285716
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-58-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 557.1836734693877
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 98
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.637
    dispatch_time_ms: 19.452
    learner:
      cur_lr: 0.001229463960044086
      grad_gnorm: 10.628157615661621
      policy_entropy: 367.5005187988281
      policy_loss: 1.2650606632232666
      var_gnorm: 32.154197692871094
      vf_explained_var: 0.12783056497573853
      vf_loss: 0.008190163411200047
    num_steps_sampled: 1980000
    num_steps_trained: 1980000
    wait_time_ms: 332.41
  iterations_since_restore: 99
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 3456.4143891334534
  time_this_iter_s: 36.30278468132019
  time_total_s: 3456.4143891334534
  timestamp: 1594141106
  timesteps_since_restore: 1980000
  timesteps_this_iter: 20000
  timesteps_total: 1980000
  training_iteration: 99
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 3456 s, 99 iter, 1980000 ts, 557 rew

agent-1: 17.0
agent-2: 38.0
agent-3: 40.0
agent-4: 20.0
agent-5: 21.0
agent-6: 30.0
agent-7: 26.0
agent-8: 27.0
agent-9: 48.0
agent-10: 26.0
agent-11: 27.0
agent-12: 29.0
agent-13: 20.0
agent-14: 35.0
agent-15: 40.0
agent-16: 28.0
agent-17: 24.0
agent-18: 33.0
agent-19: 20.0
agent-20: 22.0
Sum Reward: 571.0
Avg Reward: 28.55
Min Reward: 17.0
Max Reward: 48.0
Gini Coefficient: 0.15577933450087567
20:20 Ratio: 2.155844155844156
Max-min Ratio: 2.823529411764706
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-59-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 557.3232323232323
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 99
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.598
    dispatch_time_ms: 6.949
    learner:
      cur_lr: 0.001228132052347064
      grad_gnorm: 2.5049798488616943
      policy_entropy: 295.6466369628906
      policy_loss: 0.48909759521484375
      var_gnorm: 32.283321380615234
      vf_explained_var: -0.5895416736602783
      vf_loss: 0.0029117008671164513
    num_steps_sampled: 2000000
    num_steps_trained: 2000000
    wait_time_ms: 350.833
  iterations_since_restore: 100
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 3490.957046985626
  time_this_iter_s: 34.54265785217285
  time_total_s: 3490.957046985626
  timestamp: 1594141141
  timesteps_since_restore: 2000000
  timesteps_this_iter: 20000
  timesteps_total: 2000000
  training_iteration: 100
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 3490 s, 100 iter, 2000000 ts, 557 rew

agent-1: 26.0
agent-2: 18.0
agent-3: 29.0
agent-4: 18.0
agent-5: 28.0
agent-6: 16.0
agent-7: 24.0
agent-8: 30.0
agent-9: 23.0
agent-10: 34.0
agent-11: 32.0
agent-12: 35.0
agent-13: 46.0
agent-14: 28.0
agent-15: 36.0
agent-16: 34.0
agent-17: 34.0
agent-18: 21.0
agent-19: 28.0
agent-20: 39.0
Sum Reward: 579.0
Avg Reward: 28.95
Min Reward: 16.0
Max Reward: 46.0
Gini Coefficient: 0.14447322970639032
20:20 Ratio: 2.136986301369863
Max-min Ratio: 2.875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-59-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 557.54
  episode_reward_min: -4997.0
  episodes_this_iter: 1
  episodes_total: 100
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.485
    dispatch_time_ms: 5.831
    learner:
      cur_lr: 0.0012268000282347202
      grad_gnorm: 40.0
      policy_entropy: 72.49493408203125
      policy_loss: 56.24985885620117
      var_gnorm: 32.282779693603516
      vf_explained_var: -0.3966493606567383
      vf_loss: 500.3267517089844
    num_steps_sampled: 2020000
    num_steps_trained: 2020000
    wait_time_ms: 328.286
  iterations_since_restore: 101
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 3522.705124616623
  time_this_iter_s: 31.748077630996704
  time_total_s: 3522.705124616623
  timestamp: 1594141182
  timesteps_since_restore: 2020000
  timesteps_this_iter: 20000
  timesteps_total: 2020000
  training_iteration: 101
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 3522 s, 101 iter, 2020000 ts, 558 rew

agent-1: 34.0
agent-2: 28.0
agent-3: 31.0
agent-4: 24.0
agent-5: 38.0
agent-6: 32.0
agent-7: 50.0
agent-8: 31.0
agent-9: 27.0
agent-10: 26.0
agent-11: 25.0
agent-12: 22.0
agent-13: 38.0
agent-14: 46.0
agent-15: 22.0
agent-16: 20.0
agent-17: 21.0
agent-18: 43.0
agent-19: 36.0
agent-20: 24.0
Sum Reward: 618.0
Avg Reward: 30.9
Min Reward: 20.0
Max Reward: 50.0
Gini Coefficient: 0.15275080906148866
20:20 Ratio: 2.0823529411764707
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-00-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 613.69
  episode_reward_min: -3919.0
  episodes_this_iter: 1
  episodes_total: 101
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.904
    dispatch_time_ms: 5.724
    learner:
      cur_lr: 0.0012254680041223764
      grad_gnorm: 2.496074676513672
      policy_entropy: 341.57769775390625
      policy_loss: 1.060760259628296
      var_gnorm: 32.47439956665039
      vf_explained_var: 0.9660983085632324
      vf_loss: 0.0009392228676006198
    num_steps_sampled: 2040000
    num_steps_trained: 2040000
    wait_time_ms: 344.003
  iterations_since_restore: 102
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 3556.702749490738
  time_this_iter_s: 33.99762487411499
  time_total_s: 3556.702749490738
  timestamp: 1594141216
  timesteps_since_restore: 2040000
  timesteps_this_iter: 20000
  timesteps_total: 2040000
  training_iteration: 102
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 3556 s, 102 iter, 2040000 ts, 614 rew

agent-1: 44.0
agent-2: 28.0
agent-3: 26.0
agent-4: 22.0
agent-5: 28.0
agent-6: 36.0
agent-7: 22.0
agent-8: 37.0
agent-9: 28.0
agent-10: 25.0
agent-11: 40.0
agent-12: 30.0
agent-13: 42.0
agent-14: 22.0
agent-15: 30.0
agent-16: 23.0
agent-17: 28.0
agent-18: 31.0
agent-19: 24.0
agent-20: 27.0
Sum Reward: 593.0
Avg Reward: 29.65
Min Reward: 22.0
Max Reward: 44.0
Gini Coefficient: 0.12133220910623946
20:20 Ratio: 1.8314606741573034
Max-min Ratio: 2.0
agent-1: 25.0
agent-2: 22.0
agent-3: 31.0
agent-4: 34.0
agent-5: 23.0
agent-6: 32.0
agent-7: 31.0
agent-8: 32.0
agent-9: 16.0
agent-10: 32.0
agent-11: 31.0
agent-12: 24.0
agent-13: 30.0
agent-14: 32.0
agent-15: 29.0
agent-16: 38.0
agent-17: 31.0
agent-18: 26.0
agent-19: 34.0
agent-20: 31.0
Sum Reward: 584.0
Avg Reward: 29.2
Min Reward: 16.0
Max Reward: 38.0
Gini Coefficient: 0.08972602739726028
20:20 Ratio: 1.6235294117647059
Max-min Ratio: 2.375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-00-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 651.37
  episode_reward_min: 530.0
  episodes_this_iter: 2
  episodes_total: 103
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.069
    dispatch_time_ms: 7.139
    learner:
      cur_lr: 0.0012241359800100327
      grad_gnorm: 1.6854723691940308
      policy_entropy: 377.1521301269531
      policy_loss: 0.7949769496917725
      var_gnorm: 32.474693298339844
      vf_explained_var: -1.0
      vf_loss: 0.001949545694515109
    num_steps_sampled: 2060000
    num_steps_trained: 2060000
    wait_time_ms: 341.838
  iterations_since_restore: 103
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 3592.1763610839844
  time_this_iter_s: 35.47361159324646
  time_total_s: 3592.1763610839844
  timestamp: 1594141252
  timesteps_since_restore: 2060000
  timesteps_this_iter: 20000
  timesteps_total: 2060000
  training_iteration: 103
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 3592 s, 103 iter, 2060000 ts, 651 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-01-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1400.0
  episode_reward_mean: 651.37
  episode_reward_min: 530.0
  episodes_this_iter: 0
  episodes_total: 103
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.555
    dispatch_time_ms: 5.704
    learner:
      cur_lr: 0.0012228039558976889
      grad_gnorm: 2.1546077728271484
      policy_entropy: 240.84732055664062
      policy_loss: -0.6306508183479309
      var_gnorm: 32.744873046875
      vf_explained_var: -0.40352582931518555
      vf_loss: 0.03835591301321983
    num_steps_sampled: 2080000
    num_steps_trained: 2080000
    wait_time_ms: 348.77
  iterations_since_restore: 104
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 3626.065773487091
  time_this_iter_s: 33.88941240310669
  time_total_s: 3626.065773487091
  timestamp: 1594141286
  timesteps_since_restore: 2080000
  timesteps_this_iter: 20000
  timesteps_total: 2080000
  training_iteration: 104
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 3626 s, 104 iter, 2080000 ts, 651 rew

agent-1: 31.0
agent-2: 39.0
agent-3: 26.0
agent-4: 26.0
agent-5: 40.0
agent-6: 34.0
agent-7: 49.0
agent-8: 30.0
agent-9: 47.0
agent-10: 28.0
agent-11: 19.0
agent-12: 25.0
agent-13: 39.0
agent-14: 26.0
agent-15: 30.0
agent-16: 25.0
agent-17: 36.0
agent-18: 33.0
agent-19: 31.0
agent-20: 27.0
Sum Reward: 641.0
Avg Reward: 32.05
Min Reward: 19.0
Max Reward: 49.0
Gini Coefficient: 0.12862714508580345
20:20 Ratio: 1.8421052631578947
Max-min Ratio: 2.5789473684210527
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-02-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1139.0
  episode_reward_mean: 643.78
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 104
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.587
    dispatch_time_ms: 5.662
    learner:
      cur_lr: 0.001221472048200667
      grad_gnorm: 0.5290191173553467
      policy_entropy: 337.7866516113281
      policy_loss: 0.919487714767456
      var_gnorm: 32.75128936767578
      vf_explained_var: 0.0
      vf_loss: 1.979083208425436e-05
    num_steps_sampled: 2100000
    num_steps_trained: 2100000
    wait_time_ms: 347.337
  iterations_since_restore: 105
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 3661.325339317322
  time_this_iter_s: 35.25956583023071
  time_total_s: 3661.325339317322
  timestamp: 1594141321
  timesteps_since_restore: 2100000
  timesteps_this_iter: 20000
  timesteps_total: 2100000
  training_iteration: 105
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 3661 s, 105 iter, 2100000 ts, 644 rew

agent-1: 33.0
agent-2: 25.0
agent-3: 25.0
agent-4: 22.0
agent-5: 26.0
agent-6: 21.0
agent-7: 27.0
agent-8: 24.0
agent-9: 30.0
agent-10: 35.0
agent-11: 27.0
agent-12: 23.0
agent-13: 29.0
agent-14: 31.0
agent-15: 29.0
agent-16: 23.0
agent-17: 23.0
agent-18: 39.0
agent-19: 36.0
agent-20: 19.0
Sum Reward: 547.0
Avg Reward: 27.35
Min Reward: 19.0
Max Reward: 39.0
Gini Coefficient: 0.10722120658135284
20:20 Ratio: 1.6823529411764706
Max-min Ratio: 2.0526315789473686
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-02-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1139.0
  episode_reward_mean: 640.76
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 105
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.247
    dispatch_time_ms: 6.311
    learner:
      cur_lr: 0.0012201400240883231
      grad_gnorm: 6.288370609283447
      policy_entropy: 334.0435791015625
      policy_loss: 0.6460261940956116
      var_gnorm: 32.82778549194336
      vf_explained_var: -0.3641594648361206
      vf_loss: 0.013936460949480534
    num_steps_sampled: 2120000
    num_steps_trained: 2120000
    wait_time_ms: 339.706
  iterations_since_restore: 106
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 3695.7364370822906
  time_this_iter_s: 34.41109776496887
  time_total_s: 3695.7364370822906
  timestamp: 1594141355
  timesteps_since_restore: 2120000
  timesteps_this_iter: 20000
  timesteps_total: 2120000
  training_iteration: 106
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 3695 s, 106 iter, 2120000 ts, 641 rew

agent-1: 21.0
agent-2: 26.0
agent-3: 20.0
agent-4: 29.0
agent-5: 27.0
agent-6: 17.0
agent-7: 33.0
agent-8: 26.0
agent-9: 31.0
agent-10: 27.0
agent-11: 35.0
agent-12: 27.0
agent-13: 35.0
agent-14: 25.0
agent-15: 34.0
agent-16: 34.0
agent-17: 27.0
agent-18: 28.0
agent-19: 33.0
agent-20: 37.0
Sum Reward: 572.0
Avg Reward: 28.6
Min Reward: 17.0
Max Reward: 37.0
Gini Coefficient: 0.10332167832167832
20:20 Ratio: 1.6987951807228916
Max-min Ratio: 2.176470588235294
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-03-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1139.0
  episode_reward_mean: 638.44
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 106
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.576
    dispatch_time_ms: 6.332
    learner:
      cur_lr: 0.0012188079999759793
      grad_gnorm: 1.041076898574829
      policy_entropy: 359.47540283203125
      policy_loss: -0.37424930930137634
      var_gnorm: 32.82999801635742
      vf_explained_var: -1.0
      vf_loss: 0.00035712006501853466
    num_steps_sampled: 2140000
    num_steps_trained: 2140000
    wait_time_ms: 321.743
  iterations_since_restore: 107
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 3730.6368424892426
  time_this_iter_s: 34.900405406951904
  time_total_s: 3730.6368424892426
  timestamp: 1594141390
  timesteps_since_restore: 2140000
  timesteps_this_iter: 20000
  timesteps_total: 2140000
  training_iteration: 107
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 3730 s, 107 iter, 2140000 ts, 638 rew

agent-1: 34.0
agent-2: 30.0
agent-3: 38.0
agent-4: 27.0
agent-5: 31.0
agent-6: 40.0
agent-7: 44.0
agent-8: 27.0
agent-9: 28.0
agent-10: 32.0
agent-11: 28.0
agent-12: 28.0
agent-13: 35.0
agent-14: 22.0
agent-15: 24.0
agent-16: 21.0
agent-17: 15.0
agent-18: 25.0
agent-19: 23.0
agent-20: 32.0
Sum Reward: 584.0
Avg Reward: 29.2
Min Reward: 15.0
Max Reward: 44.0
Gini Coefficient: 0.12876712328767123
20:20 Ratio: 1.9382716049382716
Max-min Ratio: 2.933333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-03-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1006.0
  episode_reward_mean: 632.89
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 107
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.429
    dispatch_time_ms: 5.395
    learner:
      cur_lr: 0.0012174759758636355
      grad_gnorm: 2.9338996410369873
      policy_entropy: 334.8171081542969
      policy_loss: 1.6364970207214355
      var_gnorm: 32.875
      vf_explained_var: -0.8113188743591309
      vf_loss: 0.01264525018632412
    num_steps_sampled: 2160000
    num_steps_trained: 2160000
    wait_time_ms: 347.365
  iterations_since_restore: 108
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 3764.8660912513733
  time_this_iter_s: 34.22924876213074
  time_total_s: 3764.8660912513733
  timestamp: 1594141425
  timesteps_since_restore: 2160000
  timesteps_this_iter: 20000
  timesteps_total: 2160000
  training_iteration: 108
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 3764 s, 108 iter, 2160000 ts, 633 rew

agent-1: 34.0
agent-2: 32.0
agent-3: 38.0
agent-4: 20.0
agent-5: 28.0
agent-6: 26.0
agent-7: 24.0
agent-8: 18.0
agent-9: 32.0
agent-10: 20.0
agent-11: 28.0
agent-12: 27.0
agent-13: 34.0
agent-14: 37.0
agent-15: 28.0
agent-16: 29.0
agent-17: 25.0
agent-18: 34.0
agent-19: 35.0
agent-20: 20.0
Sum Reward: 569.0
Avg Reward: 28.45
Min Reward: 18.0
Max Reward: 38.0
Gini Coefficient: 0.11748681898066783
20:20 Ratio: 1.8461538461538463
Max-min Ratio: 2.111111111111111
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-04-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 953.0
  episode_reward_mean: 628.52
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 108
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.697
    dispatch_time_ms: 6.104
    learner:
      cur_lr: 0.0012161439517512918
      grad_gnorm: 40.0
      policy_entropy: 26.66827392578125
      policy_loss: 11.136098861694336
      var_gnorm: 32.8782958984375
      vf_explained_var: 0.1986488699913025
      vf_loss: 203.87246704101562
    num_steps_sampled: 2180000
    num_steps_trained: 2180000
    wait_time_ms: 340.555
  iterations_since_restore: 109
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 3799.933469057083
  time_this_iter_s: 35.06737780570984
  time_total_s: 3799.933469057083
  timestamp: 1594141460
  timesteps_since_restore: 2180000
  timesteps_this_iter: 20000
  timesteps_total: 2180000
  training_iteration: 109
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 3799 s, 109 iter, 2180000 ts, 629 rew

agent-1: 25.0
agent-2: 26.0
agent-3: 33.0
agent-4: 37.0
agent-5: 28.0
agent-6: 30.0
agent-7: 33.0
agent-8: 29.0
agent-9: 25.0
agent-10: 24.0
agent-11: 26.0
agent-12: 30.0
agent-13: 35.0
agent-14: 21.0
agent-15: 22.0
agent-16: 33.0
agent-17: 31.0
agent-18: 25.0
agent-19: 18.0
agent-20: 18.0
Sum Reward: 549.0
Avg Reward: 27.45
Min Reward: 18.0
Max Reward: 37.0
Gini Coefficient: 0.10901639344262296
20:20 Ratio: 1.7468354430379747
Max-min Ratio: 2.0555555555555554
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-04-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 953.0
  episode_reward_mean: 625.42
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 109
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.435
    dispatch_time_ms: 4.99
    learner:
      cur_lr: 0.0012148120440542698
      grad_gnorm: 2.5562102794647217
      policy_entropy: 353.4890441894531
      policy_loss: 0.5175089240074158
      var_gnorm: 33.216033935546875
      vf_explained_var: -0.0456622838973999
      vf_loss: 0.0017119930125772953
    num_steps_sampled: 2200000
    num_steps_trained: 2200000
    wait_time_ms: 344.244
  iterations_since_restore: 110
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 3834.1718702316284
  time_this_iter_s: 34.23840117454529
  time_total_s: 3834.1718702316284
  timestamp: 1594141494
  timesteps_since_restore: 2200000
  timesteps_this_iter: 20000
  timesteps_total: 2200000
  training_iteration: 110
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 3834 s, 110 iter, 2200000 ts, 625 rew

agent-1: 26.0
agent-2: 25.0
agent-3: 23.0
agent-4: 35.0
agent-5: 39.0
agent-6: 25.0
agent-7: 23.0
agent-8: 35.0
agent-9: 26.0
agent-10: 18.0
agent-11: 37.0
agent-12: 39.0
agent-13: 28.0
agent-14: 42.0
agent-15: 21.0
agent-16: 27.0
agent-17: 27.0
agent-18: 30.0
agent-19: 30.0
agent-20: 35.0
Sum Reward: 591.0
Avg Reward: 29.55
Min Reward: 18.0
Max Reward: 42.0
Gini Coefficient: 0.12495769881556684
20:20 Ratio: 1.8470588235294119
Max-min Ratio: 2.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-05-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 621.8
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 110
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.546
    dispatch_time_ms: 5.63
    learner:
      cur_lr: 0.001213480019941926
      grad_gnorm: 1.2208751440048218
      policy_entropy: 378.2404479980469
      policy_loss: 0.24308744072914124
      var_gnorm: 33.20908737182617
      vf_explained_var: -2.2649765014648438e-06
      vf_loss: 0.0003772405325435102
    num_steps_sampled: 2220000
    num_steps_trained: 2220000
    wait_time_ms: 300.145
  iterations_since_restore: 111
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 3869.050669193268
  time_this_iter_s: 34.878798961639404
  time_total_s: 3869.050669193268
  timestamp: 1594141529
  timesteps_since_restore: 2220000
  timesteps_this_iter: 20000
  timesteps_total: 2220000
  training_iteration: 111
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 3869 s, 111 iter, 2220000 ts, 622 rew

agent-1: 32.0
agent-2: 28.0
agent-3: 32.0
agent-4: 34.0
agent-5: 28.0
agent-6: 25.0
agent-7: 27.0
agent-8: 20.0
agent-9: 34.0
agent-10: 29.0
agent-11: 40.0
agent-12: 33.0
agent-13: 35.0
agent-14: 30.0
agent-15: 19.0
agent-16: 25.0
agent-17: 28.0
agent-18: 23.0
agent-19: 23.0
agent-20: 28.0
Sum Reward: 573.0
Avg Reward: 28.65
Min Reward: 19.0
Max Reward: 40.0
Gini Coefficient: 0.10130890052356022
20:20 Ratio: 1.6823529411764706
Max-min Ratio: 2.1052631578947367
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-06-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 619.82
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 111
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.517
    dispatch_time_ms: 6.089
    learner:
      cur_lr: 0.0012121479958295822
      grad_gnorm: 0.6021693348884583
      policy_entropy: 337.2080993652344
      policy_loss: 0.09984122216701508
      var_gnorm: 33.287105560302734
      vf_explained_var: 3.784894943237305e-05
      vf_loss: 0.0005810877773910761
    num_steps_sampled: 2240000
    num_steps_trained: 2240000
    wait_time_ms: 343.848
  iterations_since_restore: 112
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 3903.438057899475
  time_this_iter_s: 34.387388706207275
  time_total_s: 3903.438057899475
  timestamp: 1594141563
  timesteps_since_restore: 2240000
  timesteps_this_iter: 20000
  timesteps_total: 2240000
  training_iteration: 112
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 3903 s, 112 iter, 2240000 ts, 620 rew

agent-1: 22.0
agent-2: 23.0
agent-3: 31.0
agent-4: 29.0
agent-5: 28.0
agent-6: 24.0
agent-7: 33.0
agent-8: 25.0
agent-9: 19.0
agent-10: 30.0
agent-11: 19.0
agent-12: 24.0
agent-13: 31.0
agent-14: 26.0
agent-15: 27.0
agent-16: 28.0
agent-17: 36.0
agent-18: 29.0
agent-19: 30.0
agent-20: 16.0
Sum Reward: 530.0
Avg Reward: 26.5
Min Reward: 16.0
Max Reward: 36.0
Gini Coefficient: 0.10452830188679245
20:20 Ratio: 1.7236842105263157
Max-min Ratio: 2.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-06-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 617.52
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 112
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.751
    dispatch_time_ms: 5.885
    learner:
      cur_lr: 0.0012108159717172384
      grad_gnorm: 40.0
      policy_entropy: 52.647369384765625
      policy_loss: 34.00840759277344
      var_gnorm: 33.271148681640625
      vf_explained_var: 0.40777772665023804
      vf_loss: 545.7059936523438
    num_steps_sampled: 2260000
    num_steps_trained: 2260000
    wait_time_ms: 325.308
  iterations_since_restore: 113
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 3938.5630781650543
  time_this_iter_s: 35.125020265579224
  time_total_s: 3938.5630781650543
  timestamp: 1594141598
  timesteps_since_restore: 2260000
  timesteps_this_iter: 20000
  timesteps_total: 2260000
  training_iteration: 113
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 3938 s, 113 iter, 2260000 ts, 618 rew

agent-1: 29.0
agent-2: 29.0
agent-3: 35.0
agent-4: 31.0
agent-5: 31.0
agent-6: 16.0
agent-7: 21.0
agent-8: 37.0
agent-9: 30.0
agent-10: 33.0
agent-11: 30.0
agent-12: 33.0
agent-13: 18.0
agent-14: 32.0
agent-15: 26.0
agent-16: 25.0
agent-17: 25.0
agent-18: 29.0
agent-19: 29.0
agent-20: 33.0
Sum Reward: 572.0
Avg Reward: 28.6
Min Reward: 16.0
Max Reward: 37.0
Gini Coefficient: 0.09982517482517482
20:20 Ratio: 1.725
Max-min Ratio: 2.3125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-07-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 616.1
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 113
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.62
    dispatch_time_ms: 5.986
    learner:
      cur_lr: 0.0012094839476048946
      grad_gnorm: 0.31900539994239807
      policy_entropy: 347.0498046875
      policy_loss: -0.3111920952796936
      var_gnorm: 33.43218231201172
      vf_explained_var: -1.0
      vf_loss: 3.93794834963046e-05
    num_steps_sampled: 2280000
    num_steps_trained: 2280000
    wait_time_ms: 349.695
  iterations_since_restore: 114
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 3972.822870016098
  time_this_iter_s: 34.2597918510437
  time_total_s: 3972.822870016098
  timestamp: 1594141633
  timesteps_since_restore: 2280000
  timesteps_this_iter: 20000
  timesteps_total: 2280000
  training_iteration: 114
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 3972 s, 114 iter, 2280000 ts, 616 rew

agent-1: 30.0
agent-2: 28.0
agent-3: 36.0
agent-4: 31.0
agent-5: 34.0
agent-6: 28.0
agent-7: 35.0
agent-8: 16.0
agent-9: 35.0
agent-10: 28.0
agent-11: 31.0
agent-12: 23.0
agent-13: 49.0
agent-14: 25.0
agent-15: 31.0
agent-16: 34.0
agent-17: 26.0
agent-18: 30.0
agent-19: 34.0
agent-20: 31.0
Sum Reward: 615.0
Avg Reward: 30.75
Min Reward: 16.0
Max Reward: 49.0
Gini Coefficient: 0.10447154471544716
20:20 Ratio: 1.7222222222222223
Max-min Ratio: 3.0625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-07-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 615.04
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 114
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.447
    dispatch_time_ms: 6.238
    learner:
      cur_lr: 0.0012081520399078727
      grad_gnorm: 39.99999237060547
      policy_entropy: 71.53163146972656
      policy_loss: 36.556846618652344
      var_gnorm: 33.42777633666992
      vf_explained_var: 0.5415701866149902
      vf_loss: 489.6231689453125
    num_steps_sampled: 2300000
    num_steps_trained: 2300000
    wait_time_ms: 313.195
  iterations_since_restore: 115
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 4007.7178444862366
  time_this_iter_s: 34.89497447013855
  time_total_s: 4007.7178444862366
  timestamp: 1594141668
  timesteps_since_restore: 2300000
  timesteps_this_iter: 20000
  timesteps_total: 2300000
  training_iteration: 115
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 4007 s, 115 iter, 2300000 ts, 615 rew

agent-1: 13.0
agent-2: 32.0
agent-3: 34.0
agent-4: 24.0
agent-5: 32.0
agent-6: 29.0
agent-7: 29.0
agent-8: 48.0
agent-9: 14.0
agent-10: 24.0
agent-11: 25.0
agent-12: 30.0
agent-13: 27.0
agent-14: 30.0
agent-15: 38.0
agent-16: 25.0
agent-17: 20.0
agent-18: 36.0
agent-19: 20.0
agent-20: 33.0
Sum Reward: 563.0
Avg Reward: 28.15
Min Reward: 13.0
Max Reward: 48.0
Gini Coefficient: 0.15532859680284192
20:20 Ratio: 2.328358208955224
Max-min Ratio: 3.6923076923076925
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-08-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 612.84
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 115
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.643
    dispatch_time_ms: 6.42
    learner:
      cur_lr: 0.0012068200157955289
      grad_gnorm: 1.1691370010375977
      policy_entropy: 311.56256103515625
      policy_loss: 0.04032382369041443
      var_gnorm: 33.56673049926758
      vf_explained_var: -1.0
      vf_loss: 0.004710353910923004
    num_steps_sampled: 2320000
    num_steps_trained: 2320000
    wait_time_ms: 354.419
  iterations_since_restore: 116
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 4042.438931465149
  time_this_iter_s: 34.72108697891235
  time_total_s: 4042.438931465149
  timestamp: 1594141702
  timesteps_since_restore: 2320000
  timesteps_this_iter: 20000
  timesteps_total: 2320000
  training_iteration: 116
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 4042 s, 116 iter, 2320000 ts, 613 rew

agent-1: 22.0
agent-2: 42.0
agent-3: 26.0
agent-4: 33.0
agent-5: 37.0
agent-6: 27.0
agent-7: 33.0
agent-8: 34.0
agent-9: 20.0
agent-10: 30.0
agent-11: 30.0
agent-12: 27.0
agent-13: 28.0
agent-14: 23.0
agent-15: 32.0
agent-16: 17.0
agent-17: 29.0
agent-18: 13.0
agent-19: 30.0
agent-20: 24.0
Sum Reward: 557.0
Avg Reward: 27.85
Min Reward: 13.0
Max Reward: 42.0
Gini Coefficient: 0.13276481149012567
20:20 Ratio: 2.0277777777777777
Max-min Ratio: 3.230769230769231
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-08-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 611.26
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 116
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.671
    dispatch_time_ms: 6.491
    learner:
      cur_lr: 0.001205487991683185
      grad_gnorm: 3.220754861831665
      policy_entropy: 355.7106018066406
      policy_loss: -0.5579633116722107
      var_gnorm: 33.56436538696289
      vf_explained_var: -0.62326979637146
      vf_loss: 0.0025959224440157413
    num_steps_sampled: 2340000
    num_steps_trained: 2340000
    wait_time_ms: 306.012
  iterations_since_restore: 117
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 4077.119780063629
  time_this_iter_s: 34.680848598480225
  time_total_s: 4077.119780063629
  timestamp: 1594141737
  timesteps_since_restore: 2340000
  timesteps_this_iter: 20000
  timesteps_total: 2340000
  training_iteration: 117
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 4077 s, 117 iter, 2340000 ts, 611 rew

agent-1: 31.0
agent-2: 27.0
agent-3: 22.0
agent-4: 21.0
agent-5: 26.0
agent-6: 27.0
agent-7: 21.0
agent-8: 17.0
agent-9: 37.0
agent-10: 27.0
agent-11: 29.0
agent-12: 39.0
agent-13: 35.0
agent-14: 30.0
agent-15: 31.0
agent-16: 22.0
agent-17: 15.0
agent-18: 28.0
agent-19: 27.0
agent-20: 28.0
Sum Reward: 540.0
Avg Reward: 27.0
Min Reward: 15.0
Max Reward: 39.0
Gini Coefficient: 0.1237037037037037
20:20 Ratio: 1.9189189189189189
Max-min Ratio: 2.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-09-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 608.92
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 117
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.533
    dispatch_time_ms: 5.543
    learner:
      cur_lr: 0.0012041559675708413
      grad_gnorm: 1.6071079969406128
      policy_entropy: 339.7620544433594
      policy_loss: 0.8145167231559753
      var_gnorm: 33.64585876464844
      vf_explained_var: 0.0
      vf_loss: 0.0006574269500561059
    num_steps_sampled: 2360000
    num_steps_trained: 2360000
    wait_time_ms: 343.545
  iterations_since_restore: 118
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 4111.481677532196
  time_this_iter_s: 34.361897468566895
  time_total_s: 4111.481677532196
  timestamp: 1594141772
  timesteps_since_restore: 2360000
  timesteps_this_iter: 20000
  timesteps_total: 2360000
  training_iteration: 118
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 4111 s, 118 iter, 2360000 ts, 609 rew

agent-1: 39.0
agent-2: 27.0
agent-3: 33.0
agent-4: 31.0
agent-5: 23.0
agent-6: 19.0
agent-7: 34.0
agent-8: 27.0
agent-9: 29.0
agent-10: 16.0
agent-11: 26.0
agent-12: 16.0
agent-13: 25.0
agent-14: 32.0
agent-15: 27.0
agent-16: 27.0
agent-17: 18.0
agent-18: 33.0
agent-19: 22.0
agent-20: 27.0
Sum Reward: 531.0
Avg Reward: 26.55
Min Reward: 16.0
Max Reward: 39.0
Gini Coefficient: 0.1285310734463277
20:20 Ratio: 2.0144927536231885
Max-min Ratio: 2.4375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-10-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 606.57
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 118
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.736
    dispatch_time_ms: 5.339
    learner:
      cur_lr: 0.0012028239434584975
      grad_gnorm: 40.00002670288086
      policy_entropy: 29.096107482910156
      policy_loss: -52.098915100097656
      var_gnorm: 33.60368347167969
      vf_explained_var: 0.2230122685432434
      vf_loss: 740.6300048828125
    num_steps_sampled: 2380000
    num_steps_trained: 2380000
    wait_time_ms: 300.218
  iterations_since_restore: 119
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 4146.275114536285
  time_this_iter_s: 34.793437004089355
  time_total_s: 4146.275114536285
  timestamp: 1594141806
  timesteps_since_restore: 2380000
  timesteps_this_iter: 20000
  timesteps_total: 2380000
  training_iteration: 119
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 4146 s, 119 iter, 2380000 ts, 607 rew

agent-1: 28.0
agent-2: 20.0
agent-3: 27.0
agent-4: 37.0
agent-5: 30.0
agent-6: 33.0
agent-7: 32.0
agent-8: 20.0
agent-9: 35.0
agent-10: 28.0
agent-11: 21.0
agent-12: 28.0
agent-13: 23.0
agent-14: 23.0
agent-15: 28.0
agent-16: 34.0
agent-17: 27.0
agent-18: 32.0
agent-19: 16.0
agent-20: 33.0
Sum Reward: 555.0
Avg Reward: 27.75
Min Reward: 16.0
Max Reward: 37.0
Gini Coefficient: 0.11360360360360361
20:20 Ratio: 1.8051948051948052
Max-min Ratio: 2.3125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-10-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 605.71
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 119
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.481
    dispatch_time_ms: 5.995
    learner:
      cur_lr: 0.0012014920357614756
      grad_gnorm: 2.7581288814544678
      policy_entropy: 357.6678161621094
      policy_loss: -2.20973539352417
      var_gnorm: 33.704891204833984
      vf_explained_var: 0.9655357599258423
      vf_loss: 0.0017776156309992075
    num_steps_sampled: 2400000
    num_steps_trained: 2400000
    wait_time_ms: 346.525
  iterations_since_restore: 120
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 4180.915511846542
  time_this_iter_s: 34.64039731025696
  time_total_s: 4180.915511846542
  timestamp: 1594141841
  timesteps_since_restore: 2400000
  timesteps_this_iter: 20000
  timesteps_total: 2400000
  training_iteration: 120
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 4180 s, 120 iter, 2400000 ts, 606 rew

agent-1: 28.0
agent-2: 36.0
agent-3: 29.0
agent-4: 11.0
agent-5: 29.0
agent-6: 30.0
agent-7: 28.0
agent-8: 34.0
agent-9: 38.0
agent-10: 38.0
agent-11: 32.0
agent-12: 21.0
agent-13: 27.0
agent-14: 25.0
agent-15: 24.0
agent-16: 16.0
agent-17: 25.0
agent-18: 28.0
agent-19: 16.0
agent-20: 23.0
Sum Reward: 538.0
Avg Reward: 26.9
Min Reward: 11.0
Max Reward: 38.0
Gini Coefficient: 0.1449814126394052
20:20 Ratio: 2.28125
Max-min Ratio: 3.4545454545454546
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-11-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 604.32
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 120
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.789
    dispatch_time_ms: 6.366
    learner:
      cur_lr: 0.0012001600116491318
      grad_gnorm: 3.4209351539611816
      policy_entropy: 385.5129089355469
      policy_loss: -1.402748703956604
      var_gnorm: 33.65508270263672
      vf_explained_var: 0.8405673503875732
      vf_loss: 0.003102209884673357
    num_steps_sampled: 2420000
    num_steps_trained: 2420000
    wait_time_ms: 347.529
  iterations_since_restore: 121
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 4215.891747951508
  time_this_iter_s: 34.97623610496521
  time_total_s: 4215.891747951508
  timestamp: 1594141876
  timesteps_since_restore: 2420000
  timesteps_this_iter: 20000
  timesteps_total: 2420000
  training_iteration: 121
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 4215 s, 121 iter, 2420000 ts, 604 rew

agent-1: 43.0
agent-2: 43.0
agent-3: 33.0
agent-4: 32.0
agent-5: 30.0
agent-6: 11.0
agent-7: 40.0
agent-8: 31.0
agent-9: 39.0
agent-10: 23.0
agent-11: 26.0
agent-12: 28.0
agent-13: 30.0
agent-14: 21.0
agent-15: 29.0
agent-16: 26.0
agent-17: 32.0
agent-18: 32.0
agent-19: 38.0
agent-20: 14.0
Sum Reward: 601.0
Avg Reward: 30.05
Min Reward: 11.0
Max Reward: 43.0
Gini Coefficient: 0.15299500831946755
20:20 Ratio: 2.391304347826087
Max-min Ratio: 3.909090909090909
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-11-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 604.01
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 121
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.459
    dispatch_time_ms: 7.239
    learner:
      cur_lr: 0.001198827987536788
      grad_gnorm: 0.44154787063598633
      policy_entropy: 348.82305908203125
      policy_loss: 0.6993337273597717
      var_gnorm: 33.86325454711914
      vf_explained_var: -0.0010391473770141602
      vf_loss: 1.7658123852015706e-06
    num_steps_sampled: 2440000
    num_steps_trained: 2440000
    wait_time_ms: 346.486
  iterations_since_restore: 122
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 4250.089600324631
  time_this_iter_s: 34.19785237312317
  time_total_s: 4250.089600324631
  timestamp: 1594141910
  timesteps_since_restore: 2440000
  timesteps_this_iter: 20000
  timesteps_total: 2440000
  training_iteration: 122
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 4250 s, 122 iter, 2440000 ts, 604 rew

agent-1: 29.0
agent-2: 24.0
agent-3: 21.0
agent-4: 41.0
agent-5: 22.0
agent-6: 27.0
agent-7: 28.0
agent-8: 36.0
agent-9: 30.0
agent-10: 26.0
agent-11: 23.0
agent-12: 34.0
agent-13: 32.0
agent-14: 25.0
agent-15: 30.0
agent-16: 42.0
agent-17: 16.0
agent-18: 29.0
agent-19: 26.0
agent-20: 34.0
Sum Reward: 575.0
Avg Reward: 28.75
Min Reward: 16.0
Max Reward: 42.0
Gini Coefficient: 0.12304347826086956
20:20 Ratio: 1.8658536585365855
Max-min Ratio: 2.625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-12-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 603.94
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 122
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.614
    dispatch_time_ms: 6.154
    learner:
      cur_lr: 0.0011974959634244442
      grad_gnorm: 39.9999885559082
      policy_entropy: 74.76932525634766
      policy_loss: -86.94296264648438
      var_gnorm: 33.88665771484375
      vf_explained_var: 0.3232375979423523
      vf_loss: 511.48321533203125
    num_steps_sampled: 2460000
    num_steps_trained: 2460000
    wait_time_ms: 297.484
  iterations_since_restore: 123
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 4284.706456661224
  time_this_iter_s: 34.61685633659363
  time_total_s: 4284.706456661224
  timestamp: 1594141945
  timesteps_since_restore: 2460000
  timesteps_this_iter: 20000
  timesteps_total: 2460000
  training_iteration: 123
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 4284 s, 123 iter, 2460000 ts, 604 rew

agent-1: 32.0
agent-2: 30.0
agent-3: 35.0
agent-4: 36.0
agent-5: 33.0
agent-6: 26.0
agent-7: 27.0
agent-8: 39.0
agent-9: 22.0
agent-10: 29.0
agent-11: 22.0
agent-12: 25.0
agent-13: 10.0
agent-14: 21.0
agent-15: 38.0
agent-16: 30.0
agent-17: 43.0
agent-18: 16.0
agent-19: 34.0
agent-20: 23.0
Sum Reward: 571.0
Avg Reward: 28.55
Min Reward: 10.0
Max Reward: 43.0
Gini Coefficient: 0.15700525394045534
20:20 Ratio: 2.260869565217391
Max-min Ratio: 4.3
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-13-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 603.33
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 123
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.455
    dispatch_time_ms: 6.449
    learner:
      cur_lr: 0.0011961640557274222
      grad_gnorm: 1.9036833047866821
      policy_entropy: 334.7786560058594
      policy_loss: 0.32850897312164307
      var_gnorm: 34.212215423583984
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.0009308792650699615
    num_steps_sampled: 2480000
    num_steps_trained: 2480000
    wait_time_ms: 331.964
  iterations_since_restore: 124
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 4319.3083691596985
  time_this_iter_s: 34.60191249847412
  time_total_s: 4319.3083691596985
  timestamp: 1594141980
  timesteps_since_restore: 2480000
  timesteps_this_iter: 20000
  timesteps_total: 2480000
  training_iteration: 124
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 4319 s, 124 iter, 2480000 ts, 603 rew

agent-1: 40.0
agent-2: 25.0
agent-3: 32.0
agent-4: 25.0
agent-5: 34.0
agent-6: 29.0
agent-7: 35.0
agent-8: 34.0
agent-9: 34.0
agent-10: 19.0
agent-11: 33.0
agent-12: 20.0
agent-13: 32.0
agent-14: 24.0
agent-15: 33.0
agent-16: 21.0
agent-17: 38.0
agent-18: 32.0
agent-19: 39.0
agent-20: 25.0
Sum Reward: 604.0
Avg Reward: 30.2
Min Reward: 19.0
Max Reward: 40.0
Gini Coefficient: 0.11473509933774835
20:20 Ratio: 1.8095238095238095
Max-min Ratio: 2.1052631578947367
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-13-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 603.03
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 124
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.457
    dispatch_time_ms: 6.298
    learner:
      cur_lr: 0.0011948320316150784
      grad_gnorm: 40.00000762939453
      policy_entropy: 57.4770393371582
      policy_loss: 36.432559967041016
      var_gnorm: 34.19805145263672
      vf_explained_var: 0.05172306299209595
      vf_loss: 314.34381103515625
    num_steps_sampled: 2500000
    num_steps_trained: 2500000
    wait_time_ms: 254.682
  iterations_since_restore: 125
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 4354.405330181122
  time_this_iter_s: 35.09696102142334
  time_total_s: 4354.405330181122
  timestamp: 1594142015
  timesteps_since_restore: 2500000
  timesteps_this_iter: 20000
  timesteps_total: 2500000
  training_iteration: 125
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 4354 s, 125 iter, 2500000 ts, 603 rew

agent-1: 24.0
agent-2: 30.0
agent-3: 26.0
agent-4: 24.0
agent-5: 26.0
agent-6: 18.0
agent-7: 26.0
agent-8: 18.0
agent-9: 33.0
agent-10: 24.0
agent-11: 25.0
agent-12: 21.0
agent-13: 27.0
agent-14: 28.0
agent-15: 32.0
agent-16: 24.0
agent-17: 17.0
agent-18: 37.0
agent-19: 31.0
agent-20: 28.0
Sum Reward: 519.0
Avg Reward: 25.95
Min Reward: 17.0
Max Reward: 37.0
Gini Coefficient: 0.1081888246628131
20:20 Ratio: 1.7972972972972974
Max-min Ratio: 2.176470588235294
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-14-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 601.58
  episode_reward_min: 519.0
  episodes_this_iter: 1
  episodes_total: 125
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.688
    dispatch_time_ms: 5.902
    learner:
      cur_lr: 0.0011935000075027347
      grad_gnorm: 0.5811412930488586
      policy_entropy: 296.1338806152344
      policy_loss: -0.8422321081161499
      var_gnorm: 34.34159851074219
      vf_explained_var: -1.7881393432617188e-06
      vf_loss: 6.695813499391079e-05
    num_steps_sampled: 2520000
    num_steps_trained: 2520000
    wait_time_ms: 342.457
  iterations_since_restore: 126
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 4389.012999534607
  time_this_iter_s: 34.60766935348511
  time_total_s: 4389.012999534607
  timestamp: 1594142049
  timesteps_since_restore: 2520000
  timesteps_this_iter: 20000
  timesteps_total: 2520000
  training_iteration: 126
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 4389 s, 126 iter, 2520000 ts, 602 rew

agent-1: 27.0
agent-2: 19.0
agent-3: 36.0
agent-4: 26.0
agent-5: 24.0
agent-6: 26.0
agent-7: 25.0
agent-8: 42.0
agent-9: 30.0
agent-10: 44.0
agent-11: 33.0
agent-12: 19.0
agent-13: 28.0
agent-14: 33.0
agent-15: 24.0
agent-16: 30.0
agent-17: 25.0
agent-18: 31.0
agent-19: 21.0
agent-20: 26.0
Sum Reward: 569.0
Avg Reward: 28.45
Min Reward: 19.0
Max Reward: 44.0
Gini Coefficient: 0.1250439367311072
20:20 Ratio: 1.8674698795180722
Max-min Ratio: 2.3157894736842106
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-14-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 600.87
  episode_reward_min: 519.0
  episodes_this_iter: 1
  episodes_total: 126
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.683
    dispatch_time_ms: 5.788
    learner:
      cur_lr: 0.0011921679833903909
      grad_gnorm: 1.7916849851608276
      policy_entropy: 349.4036560058594
      policy_loss: -2.261110305786133
      var_gnorm: 34.32831954956055
      vf_explained_var: 0.0
      vf_loss: 0.0008116704411804676
    num_steps_sampled: 2540000
    num_steps_trained: 2540000
    wait_time_ms: 313.888
  iterations_since_restore: 127
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 4422.763597726822
  time_this_iter_s: 33.750598192214966
  time_total_s: 4422.763597726822
  timestamp: 1594142084
  timesteps_since_restore: 2540000
  timesteps_this_iter: 20000
  timesteps_total: 2540000
  training_iteration: 127
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 4422 s, 127 iter, 2540000 ts, 601 rew

agent-1: 40.0
agent-2: 28.0
agent-3: 33.0
agent-4: 31.0
agent-5: 22.0
agent-6: 24.0
agent-7: 12.0
agent-8: 36.0
agent-9: 30.0
agent-10: 33.0
agent-11: 18.0
agent-12: 29.0
agent-13: 22.0
agent-14: 30.0
agent-15: 33.0
agent-16: 25.0
agent-17: 46.0
agent-18: 30.0
agent-19: 32.0
agent-20: 30.0
Sum Reward: 584.0
Avg Reward: 29.2
Min Reward: 12.0
Max Reward: 46.0
Gini Coefficient: 0.13544520547945205
20:20 Ratio: 2.0945945945945947
Max-min Ratio: 3.8333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-15-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 599.8
  episode_reward_min: 519.0
  episodes_this_iter: 1
  episodes_total: 127
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.585
    dispatch_time_ms: 7.692
    learner:
      cur_lr: 0.001190835959278047
      grad_gnorm: 1.1143972873687744
      policy_entropy: 322.3165283203125
      policy_loss: 0.020015940070152283
      var_gnorm: 34.47712707519531
      vf_explained_var: 0.9819837212562561
      vf_loss: 0.001712888479232788
    num_steps_sampled: 2560000
    num_steps_trained: 2560000
    wait_time_ms: 344.108
  iterations_since_restore: 128
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 4457.4570508003235
  time_this_iter_s: 34.69345307350159
  time_total_s: 4457.4570508003235
  timestamp: 1594142119
  timesteps_since_restore: 2560000
  timesteps_this_iter: 20000
  timesteps_total: 2560000
  training_iteration: 128
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 4457 s, 128 iter, 2560000 ts, 600 rew

agent-1: 19.0
agent-2: 28.0
agent-3: 26.0
agent-4: 30.0
agent-5: 25.0
agent-6: 33.0
agent-7: 32.0
agent-8: 22.0
agent-9: 15.0
agent-10: 19.0
agent-11: 29.0
agent-12: 26.0
agent-13: 27.0
agent-14: 32.0
agent-15: 33.0
agent-16: 38.0
agent-17: 36.0
agent-18: 27.0
agent-19: 33.0
agent-20: 22.0
Sum Reward: 552.0
Avg Reward: 27.6
Min Reward: 15.0
Max Reward: 38.0
Gini Coefficient: 0.12065217391304348
20:20 Ratio: 1.8666666666666667
Max-min Ratio: 2.533333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-15-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 598.8
  episode_reward_min: 519.0
  episodes_this_iter: 1
  episodes_total: 128
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.24
    dispatch_time_ms: 6.97
    learner:
      cur_lr: 0.0011895040515810251
      grad_gnorm: 7.722665786743164
      policy_entropy: 362.9322204589844
      policy_loss: -3.93381404876709
      var_gnorm: 34.498451232910156
      vf_explained_var: 0.8707510828971863
      vf_loss: 0.023340925574302673
    num_steps_sampled: 2580000
    num_steps_trained: 2580000
    wait_time_ms: 314.127
  iterations_since_restore: 129
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 4492.209321260452
  time_this_iter_s: 34.752270460128784
  time_total_s: 4492.209321260452
  timestamp: 1594142154
  timesteps_since_restore: 2580000
  timesteps_this_iter: 20000
  timesteps_total: 2580000
  training_iteration: 129
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 4492 s, 129 iter, 2580000 ts, 599 rew

agent-1: 24.0
agent-2: 21.0
agent-3: 20.0
agent-4: 28.0
agent-5: 25.0
agent-6: 12.0
agent-7: 29.0
agent-8: 21.0
agent-9: 16.0
agent-10: 34.0
agent-11: 31.0
agent-12: 28.0
agent-13: 23.0
agent-14: 21.0
agent-15: 30.0
agent-16: 33.0
agent-17: 30.0
agent-18: 14.0
agent-19: 31.0
agent-20: 44.0
Sum Reward: 515.0
Avg Reward: 25.75
Min Reward: 12.0
Max Reward: 44.0
Gini Coefficient: 0.15970873786407766
20:20 Ratio: 2.2903225806451615
Max-min Ratio: 3.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-16-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 598.07
  episode_reward_min: 515.0
  episodes_this_iter: 1
  episodes_total: 129
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.383
    dispatch_time_ms: 5.579
    learner:
      cur_lr: 0.0011881720274686813
      grad_gnorm: 1.3867812156677246
      policy_entropy: 370.4857177734375
      policy_loss: 0.16920503973960876
      var_gnorm: 34.67969512939453
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.0004452132561709732
    num_steps_sampled: 2600000
    num_steps_trained: 2600000
    wait_time_ms: 341.158
  iterations_since_restore: 130
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 4527.053616523743
  time_this_iter_s: 34.844295263290405
  time_total_s: 4527.053616523743
  timestamp: 1594142189
  timesteps_since_restore: 2600000
  timesteps_this_iter: 20000
  timesteps_total: 2600000
  training_iteration: 130
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 4527 s, 130 iter, 2600000 ts, 598 rew

agent-1: 36.0
agent-2: 14.0
agent-3: 12.0
agent-4: 29.0
agent-5: 21.0
agent-6: 35.0
agent-7: 34.0
agent-8: 29.0
agent-9: 34.0
agent-10: 32.0
agent-11: 21.0
agent-12: 30.0
agent-13: 34.0
agent-14: 29.0
agent-15: 35.0
agent-16: 18.0
agent-17: 37.0
agent-18: 25.0
agent-19: 26.0
agent-20: 32.0
Sum Reward: 563.0
Avg Reward: 28.15
Min Reward: 12.0
Max Reward: 37.0
Gini Coefficient: 0.14129662522202488
20:20 Ratio: 2.2
Max-min Ratio: 3.0833333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-17-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 597.37
  episode_reward_min: 515.0
  episodes_this_iter: 1
  episodes_total: 130
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.058
    dispatch_time_ms: 6.998
    learner:
      cur_lr: 0.0011868400033563375
      grad_gnorm: 40.000022888183594
      policy_entropy: 109.57483673095703
      policy_loss: 5.397895812988281
      var_gnorm: 34.735774993896484
      vf_explained_var: 0.3282809257507324
      vf_loss: 213.74942016601562
    num_steps_sampled: 2620000
    num_steps_trained: 2620000
    wait_time_ms: 332.294
  iterations_since_restore: 131
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 4561.983150720596
  time_this_iter_s: 34.92953419685364
  time_total_s: 4561.983150720596
  timestamp: 1594142224
  timesteps_since_restore: 2620000
  timesteps_this_iter: 20000
  timesteps_total: 2620000
  training_iteration: 131
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 4561 s, 131 iter, 2620000 ts, 597 rew

agent-1: 17.0
agent-2: 26.0
agent-3: 30.0
agent-4: 31.0
agent-5: 20.0
agent-6: 18.0
agent-7: 24.0
agent-8: 26.0
agent-9: 27.0
agent-10: 22.0
agent-11: 16.0
agent-12: 36.0
agent-13: 12.0
agent-14: 30.0
agent-15: 23.0
agent-16: 23.0
agent-17: 34.0
agent-18: 25.0
agent-19: 28.0
agent-20: 48.0
Sum Reward: 516.0
Avg Reward: 25.8
Min Reward: 12.0
Max Reward: 48.0
Gini Coefficient: 0.16395348837209303
20:20 Ratio: 2.365079365079365
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-17-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 596.12
  episode_reward_min: 515.0
  episodes_this_iter: 1
  episodes_total: 131
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.566
    dispatch_time_ms: 10.893
    learner:
      cur_lr: 0.0011855079792439938
      grad_gnorm: 0.9252880215644836
      policy_entropy: 364.81011962890625
      policy_loss: 0.30794352293014526
      var_gnorm: 35.00709915161133
      vf_explained_var: -9.894371032714844e-06
      vf_loss: 0.00021546395146287978
    num_steps_sampled: 2640000
    num_steps_trained: 2640000
    wait_time_ms: 349.496
  iterations_since_restore: 132
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 4596.526606798172
  time_this_iter_s: 34.543456077575684
  time_total_s: 4596.526606798172
  timestamp: 1594142258
  timesteps_since_restore: 2640000
  timesteps_this_iter: 20000
  timesteps_total: 2640000
  training_iteration: 132
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 4596 s, 132 iter, 2640000 ts, 596 rew

agent-1: 19.0
agent-2: 30.0
agent-3: 21.0
agent-4: 18.0
agent-5: 22.0
agent-6: 25.0
agent-7: 32.0
agent-8: 36.0
agent-9: 29.0
agent-10: 32.0
agent-11: 25.0
agent-12: 30.0
agent-13: 22.0
agent-14: 36.0
agent-15: 33.0
agent-16: 34.0
agent-17: 35.0
agent-18: 15.0
agent-19: 23.0
agent-20: 39.0
Sum Reward: 556.0
Avg Reward: 27.8
Min Reward: 15.0
Max Reward: 39.0
Gini Coefficient: 0.13884892086330936
20:20 Ratio: 2.0
Max-min Ratio: 2.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-18-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 595.57
  episode_reward_min: 515.0
  episodes_this_iter: 1
  episodes_total: 132
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.618
    dispatch_time_ms: 31.742
    learner:
      cur_lr: 0.00118417595513165
      grad_gnorm: 5.116935729980469
      policy_entropy: 376.48779296875
      policy_loss: 2.32696795463562
      var_gnorm: 35.02017593383789
      vf_explained_var: 0.0006697773933410645
      vf_loss: 0.007439043372869492
    num_steps_sampled: 2660000
    num_steps_trained: 2660000
    wait_time_ms: 326.715
  iterations_since_restore: 133
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 4632.122117757797
  time_this_iter_s: 35.595510959625244
  time_total_s: 4632.122117757797
  timestamp: 1594142294
  timesteps_since_restore: 2660000
  timesteps_this_iter: 20000
  timesteps_total: 2660000
  training_iteration: 133
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 4632 s, 133 iter, 2660000 ts, 596 rew

agent-1: 35.0
agent-2: 26.0
agent-3: 33.0
agent-4: 9.0
agent-5: 28.0
agent-6: 24.0
agent-7: 33.0
agent-8: 27.0
agent-9: 30.0
agent-10: 22.0
agent-11: 27.0
agent-12: 28.0
agent-13: 31.0
agent-14: 26.0
agent-15: 34.0
agent-16: 26.0
agent-17: 36.0
agent-18: 29.0
agent-19: 27.0
agent-20: 29.0
Sum Reward: 560.0
Avg Reward: 28.0
Min Reward: 9.0
Max Reward: 36.0
Gini Coefficient: 0.10125
20:20 Ratio: 1.7037037037037037
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-18-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 595.01
  episode_reward_min: 515.0
  episodes_this_iter: 1
  episodes_total: 133
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.216
    dispatch_time_ms: 44.044
    learner:
      cur_lr: 0.001182844047434628
      grad_gnorm: 28.478240966796875
      policy_entropy: 295.8691711425781
      policy_loss: 2.543365001678467
      var_gnorm: 35.187843322753906
      vf_explained_var: -1.0
      vf_loss: 0.10845033079385757
    num_steps_sampled: 2680000
    num_steps_trained: 2680000
    wait_time_ms: 310.315
  iterations_since_restore: 134
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 4667.764071941376
  time_this_iter_s: 35.64195418357849
  time_total_s: 4667.764071941376
  timestamp: 1594142329
  timesteps_since_restore: 2680000
  timesteps_this_iter: 20000
  timesteps_total: 2680000
  training_iteration: 134
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 4667 s, 134 iter, 2680000 ts, 595 rew

agent-1: 25.0
agent-2: 16.0
agent-3: 35.0
agent-4: 31.0
agent-5: 29.0
agent-6: 28.0
agent-7: 26.0
agent-8: 24.0
agent-9: 28.0
agent-10: 31.0
agent-11: 25.0
agent-12: 28.0
agent-13: 15.0
agent-14: 43.0
agent-15: 30.0
agent-16: 34.0
agent-17: 24.0
agent-18: 23.0
agent-19: 31.0
agent-20: 35.0
Sum Reward: 561.0
Avg Reward: 28.05
Min Reward: 15.0
Max Reward: 43.0
Gini Coefficient: 0.12130124777183601
20:20 Ratio: 1.8846153846153846
Max-min Ratio: 2.8666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-19-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 594.59
  episode_reward_min: 515.0
  episodes_this_iter: 1
  episodes_total: 134
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.582
    dispatch_time_ms: 26.373
    learner:
      cur_lr: 0.0011815120233222842
      grad_gnorm: 39.999961853027344
      policy_entropy: 106.4877700805664
      policy_loss: 14.383330345153809
      var_gnorm: 35.173763275146484
      vf_explained_var: 0.36210864782333374
      vf_loss: 110.38418579101562
    num_steps_sampled: 2700000
    num_steps_trained: 2700000
    wait_time_ms: 337.22
  iterations_since_restore: 135
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 4703.943865537643
  time_this_iter_s: 36.1797935962677
  time_total_s: 4703.943865537643
  timestamp: 1594142366
  timesteps_since_restore: 2700000
  timesteps_this_iter: 20000
  timesteps_total: 2700000
  training_iteration: 135
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 4703 s, 135 iter, 2700000 ts, 595 rew

agent-1: 35.0
agent-2: 22.0
agent-3: 31.0
agent-4: 22.0
agent-5: 30.0
agent-6: 29.0
agent-7: 16.0
agent-8: 25.0
agent-9: 23.0
agent-10: 28.0
agent-11: 28.0
agent-12: 26.0
agent-13: 29.0
agent-14: 20.0
agent-15: 30.0
agent-16: 30.0
agent-17: 27.0
agent-18: 22.0
agent-19: 27.0
agent-20: 33.0
Sum Reward: 533.0
Avg Reward: 26.65
Min Reward: 16.0
Max Reward: 35.0
Gini Coefficient: 0.09559099437148218
20:20 Ratio: 1.6125
Max-min Ratio: 2.1875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-20-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 593.4
  episode_reward_min: 515.0
  episodes_this_iter: 1
  episodes_total: 135
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.359
    dispatch_time_ms: 15.501
    learner:
      cur_lr: 0.0011801799992099404
      grad_gnorm: 5.823078155517578
      policy_entropy: 372.352783203125
      policy_loss: -3.6310482025146484
      var_gnorm: 35.295467376708984
      vf_explained_var: -0.0588223934173584
      vf_loss: 0.009764306247234344
    num_steps_sampled: 2720000
    num_steps_trained: 2720000
    wait_time_ms: 168.805
  iterations_since_restore: 136
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 4739.401899576187
  time_this_iter_s: 35.4580340385437
  time_total_s: 4739.401899576187
  timestamp: 1594142401
  timesteps_since_restore: 2720000
  timesteps_this_iter: 20000
  timesteps_total: 2720000
  training_iteration: 136
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 4739 s, 136 iter, 2720000 ts, 593 rew

agent-1: 21.0
agent-2: 30.0
agent-3: 12.0
agent-4: 26.0
agent-5: 37.0
agent-6: 20.0
agent-7: 31.0
agent-8: 37.0
agent-9: 35.0
agent-10: 41.0
agent-11: 39.0
agent-12: 41.0
agent-13: 23.0
agent-14: 34.0
agent-15: 38.0
agent-16: 37.0
agent-17: 29.0
agent-18: 27.0
agent-19: 16.0
agent-20: 44.0
Sum Reward: 618.0
Avg Reward: 30.9
Min Reward: 12.0
Max Reward: 44.0
Gini Coefficient: 0.15970873786407766
20:20 Ratio: 2.391304347826087
Max-min Ratio: 3.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-20-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 593.43
  episode_reward_min: 515.0
  episodes_this_iter: 1
  episodes_total: 136
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.903
    dispatch_time_ms: 5.34
    learner:
      cur_lr: 0.0011788479750975966
      grad_gnorm: 34.98691177368164
      policy_entropy: 379.7943115234375
      policy_loss: 12.479244232177734
      var_gnorm: 35.323646545410156
      vf_explained_var: 0.09947144985198975
      vf_loss: 2.5883307456970215
    num_steps_sampled: 2740000
    num_steps_trained: 2740000
    wait_time_ms: 346.118
  iterations_since_restore: 137
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 4774.10448884964
  time_this_iter_s: 34.70258927345276
  time_total_s: 4774.10448884964
  timestamp: 1594142436
  timesteps_since_restore: 2740000
  timesteps_this_iter: 20000
  timesteps_total: 2740000
  training_iteration: 137
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 4774 s, 137 iter, 2740000 ts, 593 rew

agent-1: 33.0
agent-2: 23.0
agent-3: 28.0
agent-4: 17.0
agent-5: 27.0
agent-6: 31.0
agent-7: 31.0
agent-8: 22.0
agent-9: 33.0
agent-10: 19.0
agent-11: 29.0
agent-12: 31.0
agent-13: 13.0
agent-14: 34.0
agent-15: 25.0
agent-16: 22.0
agent-17: 19.0
agent-18: 27.0
agent-19: 28.0
agent-20: 27.0
Sum Reward: 519.0
Avg Reward: 25.95
Min Reward: 13.0
Max Reward: 34.0
Gini Coefficient: 0.12302504816955684
20:20 Ratio: 1.9264705882352942
Max-min Ratio: 2.6153846153846154
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-21-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 591.92
  episode_reward_min: 515.0
  episodes_this_iter: 1
  episodes_total: 137
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 4.087
    dispatch_time_ms: 7.766
    learner:
      cur_lr: 0.0011775159509852529
      grad_gnorm: 1.2612930536270142
      policy_entropy: 319.2012939453125
      policy_loss: 1.045393705368042
      var_gnorm: 35.413211822509766
      vf_explained_var: 0.22708100080490112
      vf_loss: 0.012203752994537354
    num_steps_sampled: 2760000
    num_steps_trained: 2760000
    wait_time_ms: 337.118
  iterations_since_restore: 138
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 4809.056298971176
  time_this_iter_s: 34.951810121536255
  time_total_s: 4809.056298971176
  timestamp: 1594142471
  timesteps_since_restore: 2760000
  timesteps_this_iter: 20000
  timesteps_total: 2760000
  training_iteration: 138
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 4809 s, 138 iter, 2760000 ts, 592 rew

agent-1: 29.0
agent-2: 22.0
agent-3: 12.0
agent-4: 19.0
agent-5: 25.0
agent-6: 21.0
agent-7: 48.0
agent-8: 34.0
agent-9: 25.0
agent-10: 19.0
agent-11: 29.0
agent-12: 33.0
agent-13: 26.0
agent-14: 35.0
agent-15: 27.0
agent-16: 24.0
agent-17: 26.0
agent-18: 22.0
agent-19: 24.0
agent-20: 26.0
Sum Reward: 526.0
Avg Reward: 26.3
Min Reward: 12.0
Max Reward: 48.0
Gini Coefficient: 0.14372623574144486
20:20 Ratio: 2.112676056338028
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-21-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 590.85
  episode_reward_min: 515.0
  episodes_this_iter: 1
  episodes_total: 138
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.673
    dispatch_time_ms: 28.025
    learner:
      cur_lr: 0.001176184043288231
      grad_gnorm: 39.999961853027344
      policy_entropy: 224.13616943359375
      policy_loss: 7.220316410064697
      var_gnorm: 35.43460464477539
      vf_explained_var: 0.17291831970214844
      vf_loss: 36.33977127075195
    num_steps_sampled: 2780000
    num_steps_trained: 2780000
    wait_time_ms: 323.525
  iterations_since_restore: 139
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 4844.146370887756
  time_this_iter_s: 35.0900719165802
  time_total_s: 4844.146370887756
  timestamp: 1594142506
  timesteps_since_restore: 2780000
  timesteps_this_iter: 20000
  timesteps_total: 2780000
  training_iteration: 139
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 4844 s, 139 iter, 2780000 ts, 591 rew

agent-1: 28.0
agent-2: 24.0
agent-3: 41.0
agent-4: 22.0
agent-5: 9.0
agent-6: 17.0
agent-7: 40.0
agent-8: 28.0
agent-9: 35.0
agent-10: 27.0
agent-11: 30.0
agent-12: 31.0
agent-13: 27.0
agent-14: 12.0
agent-15: 30.0
agent-16: 30.0
agent-17: 24.0
agent-18: 17.0
agent-19: 24.0
agent-20: 26.0
Sum Reward: 522.0
Avg Reward: 26.1
Min Reward: 9.0
Max Reward: 41.0
Gini Coefficient: 0.16724137931034483
20:20 Ratio: 2.672727272727273
Max-min Ratio: 4.555555555555555
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-22-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 590.02
  episode_reward_min: 515.0
  episodes_this_iter: 1
  episodes_total: 139
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.681
    dispatch_time_ms: 43.733
    learner:
      cur_lr: 0.001174852019175887
      grad_gnorm: 9.534211158752441
      policy_entropy: 373.0413818359375
      policy_loss: -1.503493070602417
      var_gnorm: 35.54404830932617
      vf_explained_var: -0.12448155879974365
      vf_loss: 0.018558770418167114
    num_steps_sampled: 2800000
    num_steps_trained: 2800000
    wait_time_ms: 322.063
  iterations_since_restore: 140
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 4880.382171630859
  time_this_iter_s: 36.23580074310303
  time_total_s: 4880.382171630859
  timestamp: 1594142542
  timesteps_since_restore: 2800000
  timesteps_this_iter: 20000
  timesteps_total: 2800000
  training_iteration: 140
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 4880 s, 140 iter, 2800000 ts, 590 rew

agent-1: 25.0
agent-2: 25.0
agent-3: 29.0
agent-4: 25.0
agent-5: 30.0
agent-6: 27.0
agent-7: 18.0
agent-8: 24.0
agent-9: 18.0
agent-10: 16.0
agent-11: 27.0
agent-12: 25.0
agent-13: 34.0
agent-14: 48.0
agent-15: 19.0
agent-16: 14.0
agent-17: 30.0
agent-18: 20.0
agent-19: 29.0
agent-20: 28.0
Sum Reward: 511.0
Avg Reward: 25.55
Min Reward: 14.0
Max Reward: 48.0
Gini Coefficient: 0.1490215264187867
20:20 Ratio: 2.1515151515151514
Max-min Ratio: 3.4285714285714284
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-22-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 588.49
  episode_reward_min: 511.0
  episodes_this_iter: 1
  episodes_total: 140
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.707
    dispatch_time_ms: 5.956
    learner:
      cur_lr: 0.0011735199950635433
      grad_gnorm: 40.0
      policy_entropy: 293.79852294921875
      policy_loss: -7.141119003295898
      var_gnorm: 35.5916862487793
      vf_explained_var: 0.7395708560943604
      vf_loss: 4.644671440124512
    num_steps_sampled: 2820000
    num_steps_trained: 2820000
    wait_time_ms: 337.978
  iterations_since_restore: 141
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 4915.999347686768
  time_this_iter_s: 35.6171760559082
  time_total_s: 4915.999347686768
  timestamp: 1594142578
  timesteps_since_restore: 2820000
  timesteps_this_iter: 20000
  timesteps_total: 2820000
  training_iteration: 141
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 4915 s, 141 iter, 2820000 ts, 588 rew

agent-1: 24.0
agent-2: 33.0
agent-3: 22.0
agent-4: 25.0
agent-5: 35.0
agent-6: 22.0
agent-7: 22.0
agent-8: 42.0
agent-9: 27.0
agent-10: 26.0
agent-11: 22.0
agent-12: 20.0
agent-13: 23.0
agent-14: 25.0
agent-15: 27.0
agent-16: 31.0
agent-17: 30.0
agent-18: 29.0
agent-19: 18.0
agent-20: 28.0
Sum Reward: 531.0
Avg Reward: 26.55
Min Reward: 18.0
Max Reward: 42.0
Gini Coefficient: 0.11308851224105461
20:20 Ratio: 1.7195121951219512
Max-min Ratio: 2.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-23-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 587.66
  episode_reward_min: 511.0
  episodes_this_iter: 1
  episodes_total: 141
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.429
    dispatch_time_ms: 6.044
    learner:
      cur_lr: 0.0011721879709511995
      grad_gnorm: 0.8223977088928223
      policy_entropy: 319.86614990234375
      policy_loss: 0.26723238825798035
      var_gnorm: 35.71202850341797
      vf_explained_var: 1.704692840576172e-05
      vf_loss: 0.0003097307635471225
    num_steps_sampled: 2840000
    num_steps_trained: 2840000
    wait_time_ms: 347.625
  iterations_since_restore: 142
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 4950.804942369461
  time_this_iter_s: 34.80559468269348
  time_total_s: 4950.804942369461
  timestamp: 1594142613
  timesteps_since_restore: 2840000
  timesteps_this_iter: 20000
  timesteps_total: 2840000
  training_iteration: 142
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 4950 s, 142 iter, 2840000 ts, 588 rew

agent-1: 26.0
agent-2: 24.0
agent-3: 29.0
agent-4: 26.0
agent-5: 34.0
agent-6: 29.0
agent-7: 15.0
agent-8: 25.0
agent-9: 25.0
agent-10: 23.0
agent-11: 21.0
agent-12: 46.0
agent-13: 22.0
agent-14: 28.0
agent-15: 38.0
agent-16: 6.0
agent-17: 28.0
agent-18: 19.0
agent-19: 28.0
agent-20: 27.0
Sum Reward: 519.0
Avg Reward: 25.95
Min Reward: 6.0
Max Reward: 46.0
Gini Coefficient: 0.1590558766859345
20:20 Ratio: 2.4098360655737703
Max-min Ratio: 7.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-24-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 586.81
  episode_reward_min: 511.0
  episodes_this_iter: 1
  episodes_total: 142
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 4.201
    dispatch_time_ms: 7.426
    learner:
      cur_lr: 0.0011708559468388557
      grad_gnorm: 39.999996185302734
      policy_entropy: 308.57720947265625
      policy_loss: 16.06531524658203
      var_gnorm: 35.730926513671875
      vf_explained_var: 0.24274802207946777
      vf_loss: 9.302860260009766
    num_steps_sampled: 2860000
    num_steps_trained: 2860000
    wait_time_ms: 343.12
  iterations_since_restore: 143
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 4985.751907348633
  time_this_iter_s: 34.94696497917175
  time_total_s: 4985.751907348633
  timestamp: 1594142648
  timesteps_since_restore: 2860000
  timesteps_this_iter: 20000
  timesteps_total: 2860000
  training_iteration: 143
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 4985 s, 143 iter, 2860000 ts, 587 rew

agent-1: 16.0
agent-2: 34.0
agent-3: 25.0
agent-4: 36.0
agent-5: 35.0
agent-6: 21.0
agent-7: 10.0
agent-8: 27.0
agent-9: 30.0
agent-10: 32.0
agent-11: 26.0
agent-12: 28.0
agent-13: 37.0
agent-14: 39.0
agent-15: 30.0
agent-16: 19.0
agent-17: 23.0
agent-18: 31.0
agent-19: 21.0
agent-20: 34.0
Sum Reward: 554.0
Avg Reward: 27.7
Min Reward: 10.0
Max Reward: 39.0
Gini Coefficient: 0.15090252707581228
20:20 Ratio: 2.227272727272727
Max-min Ratio: 3.9
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-24-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 585.4
  episode_reward_min: 511.0
  episodes_this_iter: 1
  episodes_total: 143
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.526
    dispatch_time_ms: 5.697
    learner:
      cur_lr: 0.0011695240391418338
      grad_gnorm: 1.367660403251648
      policy_entropy: 302.3427734375
      policy_loss: 0.25850915908813477
      var_gnorm: 35.92432403564453
      vf_explained_var: 0.8295371532440186
      vf_loss: 0.014149462804198265
    num_steps_sampled: 2880000
    num_steps_trained: 2880000
    wait_time_ms: 347.326
  iterations_since_restore: 144
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 5020.254086732864
  time_this_iter_s: 34.50217938423157
  time_total_s: 5020.254086732864
  timestamp: 1594142682
  timesteps_since_restore: 2880000
  timesteps_this_iter: 20000
  timesteps_total: 2880000
  training_iteration: 144
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 5020 s, 144 iter, 2880000 ts, 585 rew

agent-1: 28.0
agent-2: 14.0
agent-3: 33.0
agent-4: 33.0
agent-5: 14.0
agent-6: 31.0
agent-7: 30.0
agent-8: 27.0
agent-9: 22.0
agent-10: 22.0
agent-11: 37.0
agent-12: 24.0
agent-13: 33.0
agent-14: 11.0
agent-15: 27.0
agent-16: 26.0
agent-17: 35.0
agent-18: 25.0
agent-19: 22.0
agent-20: 32.0
Sum Reward: 526.0
Avg Reward: 26.3
Min Reward: 11.0
Max Reward: 37.0
Gini Coefficient: 0.14923954372623574
20:20 Ratio: 2.262295081967213
Max-min Ratio: 3.3636363636363638
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-25-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 584.83
  episode_reward_min: 511.0
  episodes_this_iter: 1
  episodes_total: 144
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.74
    dispatch_time_ms: 6.153
    learner:
      cur_lr: 0.00116819201502949
      grad_gnorm: 3.338637590408325
      policy_entropy: 347.69598388671875
      policy_loss: -1.1279726028442383
      var_gnorm: 35.92152404785156
      vf_explained_var: -1.0
      vf_loss: 0.01361317839473486
    num_steps_sampled: 2900000
    num_steps_trained: 2900000
    wait_time_ms: 343.221
  iterations_since_restore: 145
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 5055.121587514877
  time_this_iter_s: 34.86750078201294
  time_total_s: 5055.121587514877
  timestamp: 1594142717
  timesteps_since_restore: 2900000
  timesteps_this_iter: 20000
  timesteps_total: 2900000
  training_iteration: 145
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 5055 s, 145 iter, 2900000 ts, 585 rew

agent-1: 21.0
agent-2: 20.0
agent-3: 35.0
agent-4: 41.0
agent-5: 41.0
agent-6: 27.0
agent-7: 27.0
agent-8: 42.0
agent-9: 26.0
agent-10: 33.0
agent-11: 18.0
agent-12: 27.0
agent-13: 31.0
agent-14: 39.0
agent-15: 21.0
agent-16: 25.0
agent-17: 21.0
agent-18: 24.0
agent-19: 37.0
agent-20: 26.0
Sum Reward: 582.0
Avg Reward: 29.1
Min Reward: 18.0
Max Reward: 42.0
Gini Coefficient: 0.14656357388316152
20:20 Ratio: 2.0375
Max-min Ratio: 2.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-25-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 584.17
  episode_reward_min: 511.0
  episodes_this_iter: 1
  episodes_total: 145
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 4.005
    dispatch_time_ms: 7.16
    learner:
      cur_lr: 0.0011668599909171462
      grad_gnorm: 5.252449989318848
      policy_entropy: 366.032958984375
      policy_loss: 0.6911349296569824
      var_gnorm: 36.031219482421875
      vf_explained_var: -1.0
      vf_loss: 0.0008474882342852652
    num_steps_sampled: 2920000
    num_steps_trained: 2920000
    wait_time_ms: 343.866
  iterations_since_restore: 146
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 5090.147804021835
  time_this_iter_s: 35.02621650695801
  time_total_s: 5090.147804021835
  timestamp: 1594142752
  timesteps_since_restore: 2920000
  timesteps_this_iter: 20000
  timesteps_total: 2920000
  training_iteration: 146
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 5090 s, 146 iter, 2920000 ts, 584 rew

agent-1: 30.0
agent-2: 21.0
agent-3: 22.0
agent-4: 28.0
agent-5: 25.0
agent-6: 27.0
agent-7: 30.0
agent-8: 25.0
agent-9: 24.0
agent-10: 21.0
agent-11: 28.0
agent-12: 24.0
agent-13: 29.0
agent-14: 23.0
agent-15: 26.0
agent-16: 37.0
agent-17: 22.0
agent-18: 23.0
agent-19: 36.0
agent-20: 32.0
Sum Reward: 533.0
Avg Reward: 26.65
Min Reward: 21.0
Max Reward: 37.0
Gini Coefficient: 0.09371482176360225
20:20 Ratio: 1.569767441860465
Max-min Ratio: 1.7619047619047619
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-26-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 583.32
  episode_reward_min: 511.0
  episodes_this_iter: 1
  episodes_total: 146
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.828
    dispatch_time_ms: 9.919
    learner:
      cur_lr: 0.0011655279668048024
      grad_gnorm: 39.999996185302734
      policy_entropy: 84.50477600097656
      policy_loss: -18.630762100219727
      var_gnorm: 36.06517028808594
      vf_explained_var: 0.28484582901000977
      vf_loss: 109.83806610107422
    num_steps_sampled: 2940000
    num_steps_trained: 2940000
    wait_time_ms: 60.357
  iterations_since_restore: 147
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 5125.976079940796
  time_this_iter_s: 35.82827591896057
  time_total_s: 5125.976079940796
  timestamp: 1594142788
  timesteps_since_restore: 2940000
  timesteps_this_iter: 20000
  timesteps_total: 2940000
  training_iteration: 147
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 5125 s, 147 iter, 2940000 ts, 583 rew

agent-1: 18.0
agent-2: 26.0
agent-3: 25.0
agent-4: 31.0
agent-5: 33.0
agent-6: 39.0
agent-7: 32.0
agent-8: 22.0
agent-9: 27.0
agent-10: 32.0
agent-11: 34.0
agent-12: 28.0
agent-13: 29.0
agent-14: 23.0
agent-15: 26.0
agent-16: 26.0
agent-17: 26.0
agent-18: 26.0
agent-19: 26.0
agent-20: 22.0
Sum Reward: 551.0
Avg Reward: 27.55
Min Reward: 18.0
Max Reward: 39.0
Gini Coefficient: 0.09446460980036298
20:20 Ratio: 1.6235294117647059
Max-min Ratio: 2.1666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-27-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 582.74
  episode_reward_min: 511.0
  episodes_this_iter: 1
  episodes_total: 147
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.897
    dispatch_time_ms: 26.276
    learner:
      cur_lr: 0.0011641959426924586
      grad_gnorm: 2.482875108718872
      policy_entropy: 375.8305969238281
      policy_loss: 4.403750896453857
      var_gnorm: 36.219932556152344
      vf_explained_var: -1.0
      vf_loss: 0.008722336031496525
    num_steps_sampled: 2960000
    num_steps_trained: 2960000
    wait_time_ms: 328.406
  iterations_since_restore: 148
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 5159.978508710861
  time_this_iter_s: 34.00242877006531
  time_total_s: 5159.978508710861
  timestamp: 1594142822
  timesteps_since_restore: 2960000
  timesteps_this_iter: 20000
  timesteps_total: 2960000
  training_iteration: 148
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 5159 s, 148 iter, 2960000 ts, 583 rew

agent-1: 22.0
agent-2: 25.0
agent-3: 40.0
agent-4: 28.0
agent-5: 29.0
agent-6: 45.0
agent-7: 26.0
agent-8: 23.0
agent-9: 21.0
agent-10: 28.0
agent-11: 33.0
agent-12: 36.0
agent-13: 46.0
agent-14: 31.0
agent-15: 31.0
agent-16: 23.0
agent-17: 23.0
agent-18: 30.0
agent-19: 29.0
agent-20: 36.0
Sum Reward: 605.0
Avg Reward: 30.25
Min Reward: 21.0
Max Reward: 46.0
Gini Coefficient: 0.1290082644628099
20:20 Ratio: 1.8764044943820224
Max-min Ratio: 2.1904761904761907
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-27-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 582.38
  episode_reward_min: 511.0
  episodes_this_iter: 1
  episodes_total: 148
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.067
    dispatch_time_ms: 27.037
    learner:
      cur_lr: 0.0011628640349954367
      grad_gnorm: 6.338523864746094
      policy_entropy: 381.47357177734375
      policy_loss: -2.4268274307250977
      var_gnorm: 36.23160171508789
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.012178251519799232
    num_steps_sampled: 2980000
    num_steps_trained: 2980000
    wait_time_ms: 330.083
  iterations_since_restore: 149
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 5195.912208080292
  time_this_iter_s: 35.93369936943054
  time_total_s: 5195.912208080292
  timestamp: 1594142858
  timesteps_since_restore: 2980000
  timesteps_this_iter: 20000
  timesteps_total: 2980000
  training_iteration: 149
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 5195 s, 149 iter, 2980000 ts, 582 rew

agent-1: 39.0
agent-2: 38.0
agent-3: 29.0
agent-4: 37.0
agent-5: 43.0
agent-6: 37.0
agent-7: 48.0
agent-8: 42.0
agent-9: 34.0
agent-10: 23.0
agent-11: 22.0
agent-12: 30.0
agent-13: 40.0
agent-14: 35.0
agent-15: 26.0
agent-16: 28.0
agent-17: 22.0
agent-18: 25.0
agent-19: 31.0
agent-20: 36.0
Sum Reward: 665.0
Avg Reward: 33.25
Min Reward: 22.0
Max Reward: 48.0
Gini Coefficient: 0.1256390977443609
20:20 Ratio: 1.8804347826086956
Max-min Ratio: 2.1818181818181817
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-28-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 582.7
  episode_reward_min: 511.0
  episodes_this_iter: 1
  episodes_total: 149
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.951
    dispatch_time_ms: 36.972
    learner:
      cur_lr: 0.0011615320108830929
      grad_gnorm: 1.5467804670333862
      policy_entropy: 371.71820068359375
      policy_loss: 0.8970328569412231
      var_gnorm: 36.34565734863281
      vf_explained_var: 0.0
      vf_loss: 0.0006866998155601323
    num_steps_sampled: 3000000
    num_steps_trained: 3000000
    wait_time_ms: 317.848
  iterations_since_restore: 150
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 5232.07210111618
  time_this_iter_s: 36.15989303588867
  time_total_s: 5232.07210111618
  timestamp: 1594142894
  timesteps_since_restore: 3000000
  timesteps_this_iter: 20000
  timesteps_total: 3000000
  training_iteration: 150
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 5232 s, 150 iter, 3000000 ts, 583 rew

agent-1: 38.0
agent-2: 31.0
agent-3: 35.0
agent-4: 30.0
agent-5: 48.0
agent-6: 20.0
agent-7: 17.0
agent-8: 25.0
agent-9: 34.0
agent-10: 34.0
agent-11: 20.0
agent-12: 38.0
agent-13: 20.0
agent-14: 22.0
agent-15: 37.0
agent-16: 21.0
agent-17: 25.0
agent-18: 24.0
agent-19: 27.0
agent-20: 28.0
Sum Reward: 574.0
Avg Reward: 28.7
Min Reward: 17.0
Max Reward: 48.0
Gini Coefficient: 0.15365853658536585
20:20 Ratio: 2.090909090909091
Max-min Ratio: 2.823529411764706
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-28-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 582.49
  episode_reward_min: 511.0
  episodes_this_iter: 1
  episodes_total: 150
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.366
    dispatch_time_ms: 5.588
    learner:
      cur_lr: 0.001160199986770749
      grad_gnorm: 13.047390937805176
      policy_entropy: 367.7318115234375
      policy_loss: -3.3125691413879395
      var_gnorm: 36.34161376953125
      vf_explained_var: -1.0
      vf_loss: 0.046707138419151306
    num_steps_sampled: 3020000
    num_steps_trained: 3020000
    wait_time_ms: 341.664
  iterations_since_restore: 151
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 5267.257177352905
  time_this_iter_s: 35.18507623672485
  time_total_s: 5267.257177352905
  timestamp: 1594142930
  timesteps_since_restore: 3020000
  timesteps_this_iter: 20000
  timesteps_total: 3020000
  training_iteration: 151
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 5267 s, 151 iter, 3020000 ts, 582 rew

agent-1: 41.0
agent-2: 11.0
agent-3: 26.0
agent-4: 23.0
agent-5: 27.0
agent-6: 42.0
agent-7: 24.0
agent-8: 38.0
agent-9: 25.0
agent-10: 13.0
agent-11: 41.0
agent-12: 30.0
agent-13: 24.0
agent-14: 20.0
agent-15: 33.0
agent-16: 35.0
agent-17: 30.0
agent-18: 43.0
agent-19: 24.0
agent-20: 32.0
Sum Reward: 582.0
Avg Reward: 29.1
Min Reward: 11.0
Max Reward: 43.0
Gini Coefficient: 0.1731958762886598
20:20 Ratio: 2.4925373134328357
Max-min Ratio: 3.909090909090909
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-29-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 581.66
  episode_reward_min: 511.0
  episodes_this_iter: 1
  episodes_total: 151
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.445
    dispatch_time_ms: 4.632
    learner:
      cur_lr: 0.0011588679626584053
      grad_gnorm: 5.580718040466309
      policy_entropy: 343.42547607421875
      policy_loss: -3.8331170082092285
      var_gnorm: 36.41640090942383
      vf_explained_var: -0.002562284469604492
      vf_loss: 0.009007470682263374
    num_steps_sampled: 3040000
    num_steps_trained: 3040000
    wait_time_ms: 337.123
  iterations_since_restore: 152
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 5302.172496080399
  time_this_iter_s: 34.915318727493286
  time_total_s: 5302.172496080399
  timestamp: 1594142965
  timesteps_since_restore: 3040000
  timesteps_this_iter: 20000
  timesteps_total: 3040000
  training_iteration: 152
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 5302 s, 152 iter, 3040000 ts, 582 rew

agent-1: 28.0
agent-2: 20.0
agent-3: 24.0
agent-4: 26.0
agent-5: 21.0
agent-6: 38.0
agent-7: 35.0
agent-8: 27.0
agent-9: 20.0
agent-10: 30.0
agent-11: 21.0
agent-12: 33.0
agent-13: 27.0
agent-14: 19.0
agent-15: 23.0
agent-16: 26.0
agent-17: 27.0
agent-18: 21.0
agent-19: 33.0
agent-20: 20.0
Sum Reward: 519.0
Avg Reward: 25.95
Min Reward: 19.0
Max Reward: 38.0
Gini Coefficient: 0.11685934489402698
20:20 Ratio: 1.759493670886076
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-29-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 580.5
  episode_reward_min: 511.0
  episodes_this_iter: 1
  episodes_total: 152
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.984
    dispatch_time_ms: 5.982
    learner:
      cur_lr: 0.0011575360549613833
      grad_gnorm: 0.8262580037117004
      policy_entropy: 370.5373229980469
      policy_loss: 0.2392895519733429
      var_gnorm: 36.40164566040039
      vf_explained_var: -5.0067901611328125e-06
      vf_loss: 0.00019246550800744444
    num_steps_sampled: 3060000
    num_steps_trained: 3060000
    wait_time_ms: 337.955
  iterations_since_restore: 153
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 5336.922038555145
  time_this_iter_s: 34.749542474746704
  time_total_s: 5336.922038555145
  timestamp: 1594142999
  timesteps_since_restore: 3060000
  timesteps_this_iter: 20000
  timesteps_total: 3060000
  training_iteration: 153
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 5336 s, 153 iter, 3060000 ts, 580 rew

agent-1: 32.0
agent-2: 26.0
agent-3: 25.0
agent-4: 32.0
agent-5: 29.0
agent-6: 35.0
agent-7: 23.0
agent-8: 30.0
agent-9: 17.0
agent-10: 30.0
agent-11: 24.0
agent-12: 38.0
agent-13: 38.0
agent-14: 17.0
agent-15: 36.0
agent-16: 27.0
agent-17: 31.0
agent-18: 30.0
agent-19: 26.0
agent-20: 18.0
Sum Reward: 564.0
Avg Reward: 28.2
Min Reward: 17.0
Max Reward: 38.0
Gini Coefficient: 0.12393617021276596
20:20 Ratio: 1.96
Max-min Ratio: 2.235294117647059
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-30-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 580.69
  episode_reward_min: 511.0
  episodes_this_iter: 1
  episodes_total: 153
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.58
    dispatch_time_ms: 6.292
    learner:
      cur_lr: 0.0011562040308490396
      grad_gnorm: 4.221676826477051
      policy_entropy: 350.4028015136719
      policy_loss: -2.355741262435913
      var_gnorm: 36.529361724853516
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.005425325129181147
    num_steps_sampled: 3080000
    num_steps_trained: 3080000
    wait_time_ms: 332.583
  iterations_since_restore: 154
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 5371.34549164772
  time_this_iter_s: 34.42345309257507
  time_total_s: 5371.34549164772
  timestamp: 1594143034
  timesteps_since_restore: 3080000
  timesteps_this_iter: 20000
  timesteps_total: 3080000
  training_iteration: 154
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 5371 s, 154 iter, 3080000 ts, 581 rew

agent-1: 17.0
agent-2: 21.0
agent-3: 9.0
agent-4: 32.0
agent-5: 29.0
agent-6: 19.0
agent-7: 42.0
agent-8: 29.0
agent-9: 29.0
agent-10: 14.0
agent-11: 34.0
agent-12: 30.0
agent-13: 29.0
agent-14: 25.0
agent-15: 31.0
agent-16: 28.0
agent-17: 22.0
agent-18: 21.0
agent-19: 23.0
agent-20: 23.0
Sum Reward: 507.0
Avg Reward: 25.35
Min Reward: 9.0
Max Reward: 42.0
Gini Coefficient: 0.1596646942800789
20:20 Ratio: 2.3559322033898304
Max-min Ratio: 4.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-31-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 579.87
  episode_reward_min: 507.0
  episodes_this_iter: 1
  episodes_total: 154
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.499
    dispatch_time_ms: 15.803
    learner:
      cur_lr: 0.0011548720067366958
      grad_gnorm: 1.4179481267929077
      policy_entropy: 358.7545166015625
      policy_loss: -0.6069305539131165
      var_gnorm: 36.594268798828125
      vf_explained_var: -5.960464477539062e-07
      vf_loss: 0.0006125018699094653
    num_steps_sampled: 3100000
    num_steps_trained: 3100000
    wait_time_ms: 342.126
  iterations_since_restore: 155
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 5406.2946145534515
  time_this_iter_s: 34.9491229057312
  time_total_s: 5406.2946145534515
  timestamp: 1594143069
  timesteps_since_restore: 3100000
  timesteps_this_iter: 20000
  timesteps_total: 3100000
  training_iteration: 155
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 5406 s, 155 iter, 3100000 ts, 580 rew

agent-1: 35.0
agent-2: 21.0
agent-3: 24.0
agent-4: 19.0
agent-5: 29.0
agent-6: 24.0
agent-7: 27.0
agent-8: 30.0
agent-9: 25.0
agent-10: 39.0
agent-11: 30.0
agent-12: 37.0
agent-13: 26.0
agent-14: 29.0
agent-15: 30.0
agent-16: 31.0
agent-17: 23.0
agent-18: 16.0
agent-19: 24.0
agent-20: 29.0
Sum Reward: 548.0
Avg Reward: 27.4
Min Reward: 16.0
Max Reward: 39.0
Gini Coefficient: 0.11405109489051095
20:20 Ratio: 1.7974683544303798
Max-min Ratio: 2.4375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-31-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 579.31
  episode_reward_min: 507.0
  episodes_this_iter: 1
  episodes_total: 155
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.665
    dispatch_time_ms: 21.021
    learner:
      cur_lr: 0.001153539982624352
      grad_gnorm: 5.026360511779785
      policy_entropy: 333.82440185546875
      policy_loss: 0.856011688709259
      var_gnorm: 36.784427642822266
      vf_explained_var: 1.3709068298339844e-06
      vf_loss: 0.006775518413633108
    num_steps_sampled: 3120000
    num_steps_trained: 3120000
    wait_time_ms: 325.624
  iterations_since_restore: 156
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 5444.306604862213
  time_this_iter_s: 38.0119903087616
  time_total_s: 5444.306604862213
  timestamp: 1594143107
  timesteps_since_restore: 3120000
  timesteps_this_iter: 20000
  timesteps_total: 3120000
  training_iteration: 156
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 5444 s, 156 iter, 3120000 ts, 579 rew

agent-1: 26.0
agent-2: 17.0
agent-3: 18.0
agent-4: 29.0
agent-5: 28.0
agent-6: 25.0
agent-7: 21.0
agent-8: 26.0
agent-9: 29.0
agent-10: 29.0
agent-11: 29.0
agent-12: 35.0
agent-13: 24.0
agent-14: 34.0
agent-15: 21.0
agent-16: 37.0
agent-17: 27.0
agent-18: 33.0
agent-19: 20.0
agent-20: 40.0
Sum Reward: 548.0
Avg Reward: 27.4
Min Reward: 17.0
Max Reward: 40.0
Gini Coefficient: 0.12627737226277372
20:20 Ratio: 1.9210526315789473
Max-min Ratio: 2.3529411764705883
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-32-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 578.63
  episode_reward_min: 507.0
  episodes_this_iter: 1
  episodes_total: 156
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.579
    dispatch_time_ms: 14.597
    learner:
      cur_lr: 0.0011522079585120082
      grad_gnorm: 16.343093872070312
      policy_entropy: 316.3027648925781
      policy_loss: 6.675107955932617
      var_gnorm: 36.88080596923828
      vf_explained_var: 0.40874117612838745
      vf_loss: 6.3688063621521
    num_steps_sampled: 3140000
    num_steps_trained: 3140000
    wait_time_ms: 332.635
  iterations_since_restore: 157
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 5477.514402627945
  time_this_iter_s: 33.20779776573181
  time_total_s: 5477.514402627945
  timestamp: 1594143141
  timesteps_since_restore: 3140000
  timesteps_this_iter: 20000
  timesteps_total: 3140000
  training_iteration: 157
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 5477 s, 157 iter, 3140000 ts, 579 rew

agent-1: 18.0
agent-2: 33.0
agent-3: 17.0
agent-4: 31.0
agent-5: 34.0
agent-6: 38.0
agent-7: 22.0
agent-8: 23.0
agent-9: 41.0
agent-10: 22.0
agent-11: 25.0
agent-12: 29.0
agent-13: 25.0
agent-14: 33.0
agent-15: 32.0
agent-16: 41.0
agent-17: 48.0
agent-18: 16.0
agent-19: 29.0
agent-20: 30.0
Sum Reward: 587.0
Avg Reward: 29.35
Min Reward: 16.0
Max Reward: 48.0
Gini Coefficient: 0.16090289608177172
20:20 Ratio: 2.3013698630136985
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-32-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 578.76
  episode_reward_min: 507.0
  episodes_this_iter: 1
  episodes_total: 157
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.437
    dispatch_time_ms: 11.485
    learner:
      cur_lr: 0.0011508760508149862
      grad_gnorm: 9.10671615600586
      policy_entropy: 365.28350830078125
      policy_loss: 0.024037539958953857
      var_gnorm: 37.005088806152344
      vf_explained_var: -1.0
      vf_loss: 0.20159311592578888
    num_steps_sampled: 3160000
    num_steps_trained: 3160000
    wait_time_ms: 360.315
  iterations_since_restore: 158
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 5513.125817060471
  time_this_iter_s: 35.611414432525635
  time_total_s: 5513.125817060471
  timestamp: 1594143177
  timesteps_since_restore: 3160000
  timesteps_this_iter: 20000
  timesteps_total: 3160000
  training_iteration: 158
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 5513 s, 158 iter, 3160000 ts, 579 rew

agent-1: 33.0
agent-2: 22.0
agent-3: 22.0
agent-4: 29.0
agent-5: 26.0
agent-6: 32.0
agent-7: 26.0
agent-8: 26.0
agent-9: 23.0
agent-10: 24.0
agent-11: 26.0
agent-12: 17.0
agent-13: 16.0
agent-14: 24.0
agent-15: 27.0
agent-16: 25.0
agent-17: 30.0
agent-18: 25.0
agent-19: 30.0
agent-20: 30.0
Sum Reward: 513.0
Avg Reward: 25.65
Min Reward: 16.0
Max Reward: 33.0
Gini Coefficient: 0.0928849902534113
20:20 Ratio: 1.6233766233766234
Max-min Ratio: 2.0625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-33-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 578.42
  episode_reward_min: 507.0
  episodes_this_iter: 1
  episodes_total: 158
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.848
    dispatch_time_ms: 6.038
    learner:
      cur_lr: 0.0011495440267026424
      grad_gnorm: 5.542904376983643
      policy_entropy: 340.94744873046875
      policy_loss: -5.161807060241699
      var_gnorm: 37.05173873901367
      vf_explained_var: -1.0
      vf_loss: 0.10815580189228058
    num_steps_sampled: 3180000
    num_steps_trained: 3180000
    wait_time_ms: 339.556
  iterations_since_restore: 159
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 5547.654007434845
  time_this_iter_s: 34.52819037437439
  time_total_s: 5547.654007434845
  timestamp: 1594143211
  timesteps_since_restore: 3180000
  timesteps_this_iter: 20000
  timesteps_total: 3180000
  training_iteration: 159
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 5547 s, 159 iter, 3180000 ts, 578 rew

agent-1: 29.0
agent-2: 39.0
agent-3: 26.0
agent-4: 15.0
agent-5: 24.0
agent-6: 30.0
agent-7: 37.0
agent-8: 27.0
agent-9: 41.0
agent-10: 26.0
agent-11: 28.0
agent-12: 22.0
agent-13: 30.0
agent-14: 20.0
agent-15: 28.0
agent-16: 24.0
agent-17: 25.0
agent-18: 27.0
agent-19: 30.0
agent-20: 32.0
Sum Reward: 560.0
Avg Reward: 28.0
Min Reward: 15.0
Max Reward: 41.0
Gini Coefficient: 0.11642857142857142
20:20 Ratio: 1.8395061728395061
Max-min Ratio: 2.7333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-34-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 578.16
  episode_reward_min: 507.0
  episodes_this_iter: 1
  episodes_total: 159
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.684
    dispatch_time_ms: 6.391
    learner:
      cur_lr: 0.0011482120025902987
      grad_gnorm: 1.8352644443511963
      policy_entropy: 334.62945556640625
      policy_loss: 0.004071265459060669
      var_gnorm: 37.08742904663086
      vf_explained_var: -1.0
      vf_loss: 0.07818445563316345
    num_steps_sampled: 3200000
    num_steps_trained: 3200000
    wait_time_ms: 354.366
  iterations_since_restore: 160
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 5582.464172840118
  time_this_iter_s: 34.81016540527344
  time_total_s: 5582.464172840118
  timestamp: 1594143246
  timesteps_since_restore: 3200000
  timesteps_this_iter: 20000
  timesteps_total: 3200000
  training_iteration: 160
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 5582 s, 160 iter, 3200000 ts, 578 rew

agent-1: 36.0
agent-2: 22.0
agent-3: 22.0
agent-4: 31.0
agent-5: 33.0
agent-6: 27.0
agent-7: 27.0
agent-8: 26.0
agent-9: 14.0
agent-10: 26.0
agent-11: 34.0
agent-12: 24.0
agent-13: 25.0
agent-14: 25.0
agent-15: 24.0
agent-16: 28.0
agent-17: 20.0
agent-18: 20.0
agent-19: 38.0
agent-20: 23.0
Sum Reward: 525.0
Avg Reward: 26.25
Min Reward: 14.0
Max Reward: 38.0
Gini Coefficient: 0.12047619047619047
20:20 Ratio: 1.855263157894737
Max-min Ratio: 2.7142857142857144
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-34-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 577.87
  episode_reward_min: 507.0
  episodes_this_iter: 1
  episodes_total: 160
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.389
    dispatch_time_ms: 5.287
    learner:
      cur_lr: 0.0011468799784779549
      grad_gnorm: 39.99997329711914
      policy_entropy: 304.17572021484375
      policy_loss: 11.762630462646484
      var_gnorm: 37.10700988769531
      vf_explained_var: 0.48972105979919434
      vf_loss: 8.699604988098145
    num_steps_sampled: 3220000
    num_steps_trained: 3220000
    wait_time_ms: 336.474
  iterations_since_restore: 161
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 5617.258869409561
  time_this_iter_s: 34.79469656944275
  time_total_s: 5617.258869409561
  timestamp: 1594143281
  timesteps_since_restore: 3220000
  timesteps_this_iter: 20000
  timesteps_total: 3220000
  training_iteration: 161
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 5617 s, 161 iter, 3220000 ts, 578 rew

agent-1: 29.0
agent-2: 44.0
agent-3: 26.0
agent-4: 18.0
agent-5: 27.0
agent-6: 29.0
agent-7: 26.0
agent-8: 27.0
agent-9: 20.0
agent-10: 30.0
agent-11: 30.0
agent-12: 22.0
agent-13: 24.0
agent-14: 32.0
agent-15: 32.0
agent-16: 35.0
agent-17: 23.0
agent-18: 34.0
agent-19: 38.0
agent-20: 24.0
Sum Reward: 570.0
Avg Reward: 28.5
Min Reward: 18.0
Max Reward: 44.0
Gini Coefficient: 0.1187719298245614
20:20 Ratio: 1.819277108433735
Max-min Ratio: 2.4444444444444446
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-35-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 577.22
  episode_reward_min: 507.0
  episodes_this_iter: 1
  episodes_total: 161
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.836
    dispatch_time_ms: 5.663
    learner:
      cur_lr: 0.001145547954365611
      grad_gnorm: 1.154833197593689
      policy_entropy: 383.60888671875
      policy_loss: 1.5397741794586182
      var_gnorm: 37.28076171875
      vf_explained_var: -1.0
      vf_loss: 0.005262802820652723
    num_steps_sampled: 3240000
    num_steps_trained: 3240000
    wait_time_ms: 335.241
  iterations_since_restore: 162
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 5652.073353767395
  time_this_iter_s: 34.81448435783386
  time_total_s: 5652.073353767395
  timestamp: 1594143316
  timesteps_since_restore: 3240000
  timesteps_this_iter: 20000
  timesteps_total: 3240000
  training_iteration: 162
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 5652 s, 162 iter, 3240000 ts, 577 rew

agent-1: 36.0
agent-2: 23.0
agent-3: 34.0
agent-4: 26.0
agent-5: 32.0
agent-6: 29.0
agent-7: 27.0
agent-8: 31.0
agent-9: 17.0
agent-10: 25.0
agent-11: 20.0
agent-12: 29.0
agent-13: 28.0
agent-14: 20.0
agent-15: 24.0
agent-16: 46.0
agent-17: 38.0
agent-18: 22.0
agent-19: 8.0
agent-20: 23.0
Sum Reward: 538.0
Avg Reward: 26.9
Min Reward: 8.0
Max Reward: 46.0
Gini Coefficient: 0.16356877323420074
20:20 Ratio: 2.3692307692307693
Max-min Ratio: 5.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-35-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 576.79
  episode_reward_min: 507.0
  episodes_this_iter: 1
  episodes_total: 162
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.998
    dispatch_time_ms: 7.035
    learner:
      cur_lr: 0.0011442160466685891
      grad_gnorm: 18.270851135253906
      policy_entropy: 342.9443664550781
      policy_loss: -9.205765724182129
      var_gnorm: 37.32532501220703
      vf_explained_var: -0.11063218116760254
      vf_loss: 0.6243808269500732
    num_steps_sampled: 3260000
    num_steps_trained: 3260000
    wait_time_ms: 337.533
  iterations_since_restore: 163
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 5686.674942970276
  time_this_iter_s: 34.60158920288086
  time_total_s: 5686.674942970276
  timestamp: 1594143350
  timesteps_since_restore: 3260000
  timesteps_this_iter: 20000
  timesteps_total: 3260000
  training_iteration: 163
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 5686 s, 163 iter, 3260000 ts, 577 rew

agent-1: 20.0
agent-2: 35.0
agent-3: 31.0
agent-4: 26.0
agent-5: 23.0
agent-6: 35.0
agent-7: 25.0
agent-8: 30.0
agent-9: 35.0
agent-10: 10.0
agent-11: 23.0
agent-12: 26.0
agent-13: 32.0
agent-14: 29.0
agent-15: 16.0
agent-16: 35.0
agent-17: 31.0
agent-18: 28.0
agent-19: 21.0
agent-20: 26.0
Sum Reward: 537.0
Avg Reward: 26.85
Min Reward: 10.0
Max Reward: 35.0
Gini Coefficient: 0.13491620111731845
20:20 Ratio: 2.08955223880597
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-36-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 576.65
  episode_reward_min: 507.0
  episodes_this_iter: 1
  episodes_total: 163
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.161
    dispatch_time_ms: 5.547
    learner:
      cur_lr: 0.0011428840225562453
      grad_gnorm: 3.3579018115997314
      policy_entropy: 378.64544677734375
      policy_loss: 2.611020088195801
      var_gnorm: 37.393306732177734
      vf_explained_var: -1.0
      vf_loss: 0.008653979748487473
    num_steps_sampled: 3280000
    num_steps_trained: 3280000
    wait_time_ms: 345.874
  iterations_since_restore: 164
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 5721.252913951874
  time_this_iter_s: 34.5779709815979
  time_total_s: 5721.252913951874
  timestamp: 1594143385
  timesteps_since_restore: 3280000
  timesteps_this_iter: 20000
  timesteps_total: 3280000
  training_iteration: 164
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 5721 s, 164 iter, 3280000 ts, 577 rew

agent-1: 21.0
agent-2: 30.0
agent-3: 31.0
agent-4: 45.0
agent-5: 22.0
agent-6: 21.0
agent-7: 10.0
agent-8: 29.0
agent-9: 32.0
agent-10: 29.0
agent-11: 33.0
agent-12: 23.0
agent-13: 35.0
agent-14: 27.0
agent-15: 25.0
agent-16: 32.0
agent-17: 17.0
agent-18: 22.0
agent-19: 21.0
agent-20: 30.0
Sum Reward: 535.0
Avg Reward: 26.75
Min Reward: 10.0
Max Reward: 45.0
Gini Coefficient: 0.14962616822429906
20:20 Ratio: 2.101449275362319
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-37-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 575.71
  episode_reward_min: 507.0
  episodes_this_iter: 1
  episodes_total: 164
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.686
    dispatch_time_ms: 8.461
    learner:
      cur_lr: 0.0011415519984439015
      grad_gnorm: 4.204281806945801
      policy_entropy: 384.0443420410156
      policy_loss: -2.8875718116760254
      var_gnorm: 37.495182037353516
      vf_explained_var: -0.14581787586212158
      vf_loss: 0.0012357872910797596
    num_steps_sampled: 3300000
    num_steps_trained: 3300000
    wait_time_ms: 341.568
  iterations_since_restore: 165
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 5755.811834812164
  time_this_iter_s: 34.55892086029053
  time_total_s: 5755.811834812164
  timestamp: 1594143420
  timesteps_since_restore: 3300000
  timesteps_this_iter: 20000
  timesteps_total: 3300000
  training_iteration: 165
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 5755 s, 165 iter, 3300000 ts, 576 rew

agent-1: 26.0
agent-2: 26.0
agent-3: 18.0
agent-4: 31.0
agent-5: 29.0
agent-6: 20.0
agent-7: 29.0
agent-8: 22.0
agent-9: 27.0
agent-10: 22.0
agent-11: 31.0
agent-12: 34.0
agent-13: 44.0
agent-14: 30.0
agent-15: 28.0
agent-16: 32.0
agent-17: 17.0
agent-18: 23.0
agent-19: 25.0
agent-20: 27.0
Sum Reward: 541.0
Avg Reward: 27.05
Min Reward: 17.0
Max Reward: 44.0
Gini Coefficient: 0.11950092421441774
20:20 Ratio: 1.8311688311688312
Max-min Ratio: 2.588235294117647
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-37-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 575.34
  episode_reward_min: 507.0
  episodes_this_iter: 1
  episodes_total: 165
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.603
    dispatch_time_ms: 6.101
    learner:
      cur_lr: 0.0011402199743315578
      grad_gnorm: 7.654997825622559
      policy_entropy: 332.4163513183594
      policy_loss: 5.654217720031738
      var_gnorm: 37.544898986816406
      vf_explained_var: 0.00021225214004516602
      vf_loss: 0.06526215374469757
    num_steps_sampled: 3320000
    num_steps_trained: 3320000
    wait_time_ms: 344.766
  iterations_since_restore: 166
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 5790.466682910919
  time_this_iter_s: 34.65484809875488
  time_total_s: 5790.466682910919
  timestamp: 1594143454
  timesteps_since_restore: 3320000
  timesteps_this_iter: 20000
  timesteps_total: 3320000
  training_iteration: 166
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 5790 s, 166 iter, 3320000 ts, 575 rew

agent-1: 22.0
agent-2: 28.0
agent-3: 23.0
agent-4: 16.0
agent-5: 31.0
agent-6: 40.0
agent-7: 30.0
agent-8: 19.0
agent-9: 18.0
agent-10: 27.0
agent-11: 26.0
agent-12: 19.0
agent-13: 23.0
agent-14: 31.0
agent-15: 30.0
agent-16: 38.0
agent-17: 19.0
agent-18: 28.0
agent-19: 28.0
agent-20: 31.0
Sum Reward: 527.0
Avg Reward: 26.35
Min Reward: 16.0
Max Reward: 40.0
Gini Coefficient: 0.1344402277039848
20:20 Ratio: 1.9444444444444444
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-38-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 575.07
  episode_reward_min: 507.0
  episodes_this_iter: 1
  episodes_total: 166
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.544
    dispatch_time_ms: 7.222
    learner:
      cur_lr: 0.001138887950219214
      grad_gnorm: 19.587766647338867
      policy_entropy: 308.85748291015625
      policy_loss: -6.490948677062988
      var_gnorm: 37.557193756103516
      vf_explained_var: 0.5057671070098877
      vf_loss: 1.2995845079421997
    num_steps_sampled: 3340000
    num_steps_trained: 3340000
    wait_time_ms: 343.61
  iterations_since_restore: 167
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 5825.14430642128
  time_this_iter_s: 34.67762351036072
  time_total_s: 5825.14430642128
  timestamp: 1594143489
  timesteps_since_restore: 3340000
  timesteps_this_iter: 20000
  timesteps_total: 3340000
  training_iteration: 167
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 5825 s, 167 iter, 3340000 ts, 575 rew

agent-1: 27.0
agent-2: 31.0
agent-3: 27.0
agent-4: 27.0
agent-5: 22.0
agent-6: 30.0
agent-7: 28.0
agent-8: 33.0
agent-9: 29.0
agent-10: 37.0
agent-11: 26.0
agent-12: 34.0
agent-13: 18.0
agent-14: 28.0
agent-15: 20.0
agent-16: 20.0
agent-17: 27.0
agent-18: 17.0
agent-19: 23.0
agent-20: 44.0
Sum Reward: 548.0
Avg Reward: 27.4
Min Reward: 17.0
Max Reward: 44.0
Gini Coefficient: 0.12828467153284673
20:20 Ratio: 1.9733333333333334
Max-min Ratio: 2.588235294117647
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-38-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 574.86
  episode_reward_min: 507.0
  episodes_this_iter: 1
  episodes_total: 167
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.658
    dispatch_time_ms: 6.352
    learner:
      cur_lr: 0.001137556042522192
      grad_gnorm: 1.1473701000213623
      policy_entropy: 377.4483337402344
      policy_loss: 2.275116205215454
      var_gnorm: 37.630577087402344
      vf_explained_var: 1.4901161193847656e-06
      vf_loss: 0.00017309469694737345
    num_steps_sampled: 3360000
    num_steps_trained: 3360000
    wait_time_ms: 339.277
  iterations_since_restore: 168
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 5859.955527544022
  time_this_iter_s: 34.8112211227417
  time_total_s: 5859.955527544022
  timestamp: 1594143524
  timesteps_since_restore: 3360000
  timesteps_this_iter: 20000
  timesteps_total: 3360000
  training_iteration: 168
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 5859 s, 168 iter, 3360000 ts, 575 rew

agent-1: 31.0
agent-2: 35.0
agent-3: 20.0
agent-4: 30.0
agent-5: 32.0
agent-6: 22.0
agent-7: 29.0
agent-8: 25.0
agent-9: 24.0
agent-10: 20.0
agent-11: 40.0
agent-12: 22.0
agent-13: 27.0
agent-14: 22.0
agent-15: 15.0
agent-16: 26.0
agent-17: 29.0
agent-18: 28.0
agent-19: 26.0
agent-20: 27.0
Sum Reward: 530.0
Avg Reward: 26.5
Min Reward: 15.0
Max Reward: 40.0
Gini Coefficient: 0.11622641509433962
20:20 Ratio: 1.7922077922077921
Max-min Ratio: 2.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-39-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 574.21
  episode_reward_min: 507.0
  episodes_this_iter: 1
  episodes_total: 168
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.674
    dispatch_time_ms: 6.588
    learner:
      cur_lr: 0.0011362240184098482
      grad_gnorm: 3.5102875232696533
      policy_entropy: 377.9029541015625
      policy_loss: -2.313488245010376
      var_gnorm: 37.63688278198242
      vf_explained_var: 2.3245811462402344e-05
      vf_loss: 0.003801929298788309
    num_steps_sampled: 3380000
    num_steps_trained: 3380000
    wait_time_ms: 492.55
  iterations_since_restore: 169
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 5896.032231807709
  time_this_iter_s: 36.076704263687134
  time_total_s: 5896.032231807709
  timestamp: 1594143560
  timesteps_since_restore: 3380000
  timesteps_this_iter: 20000
  timesteps_total: 3380000
  training_iteration: 169
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 5896 s, 169 iter, 3380000 ts, 574 rew

agent-1: 20.0
agent-2: 38.0
agent-3: 38.0
agent-4: 30.0
agent-5: 33.0
agent-6: 32.0
agent-7: 28.0
agent-8: 29.0
agent-9: 34.0
agent-10: 34.0
agent-11: 27.0
agent-12: 19.0
agent-13: 26.0
agent-14: 16.0
agent-15: 24.0
agent-16: 16.0
agent-17: 21.0
agent-18: 44.0
agent-19: 23.0
agent-20: 29.0
Sum Reward: 561.0
Avg Reward: 28.05
Min Reward: 16.0
Max Reward: 44.0
Gini Coefficient: 0.15053475935828878
20:20 Ratio: 2.1690140845070425
Max-min Ratio: 2.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-39-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 574.16
  episode_reward_min: 507.0
  episodes_this_iter: 1
  episodes_total: 169
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 4.245
    dispatch_time_ms: 7.738
    learner:
      cur_lr: 0.0011348919942975044
      grad_gnorm: 1.5229510068893433
      policy_entropy: 368.9566345214844
      policy_loss: 1.0845708847045898
      var_gnorm: 37.754756927490234
      vf_explained_var: 0.00039058923721313477
      vf_loss: 0.0006984025239944458
    num_steps_sampled: 3400000
    num_steps_trained: 3400000
    wait_time_ms: 345.172
  iterations_since_restore: 170
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 5929.538753271103
  time_this_iter_s: 33.506521463394165
  time_total_s: 5929.538753271103
  timestamp: 1594143593
  timesteps_since_restore: 3400000
  timesteps_this_iter: 20000
  timesteps_total: 3400000
  training_iteration: 170
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 5929 s, 170 iter, 3400000 ts, 574 rew

agent-1: 21.0
agent-2: 26.0
agent-3: 28.0
agent-4: 25.0
agent-5: 24.0
agent-6: 31.0
agent-7: 25.0
agent-8: 32.0
agent-9: 24.0
agent-10: 23.0
agent-11: 33.0
agent-12: 27.0
agent-13: 24.0
agent-14: 30.0
agent-15: 22.0
agent-16: 18.0
agent-17: 32.0
agent-18: 33.0
agent-19: 30.0
agent-20: 29.0
Sum Reward: 537.0
Avg Reward: 26.85
Min Reward: 18.0
Max Reward: 33.0
Gini Coefficient: 0.08929236499068902
20:20 Ratio: 1.5476190476190477
Max-min Ratio: 1.8333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-40-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 573.52
  episode_reward_min: 507.0
  episodes_this_iter: 1
  episodes_total: 170
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.643
    dispatch_time_ms: 5.798
    learner:
      cur_lr: 0.0011335599701851606
      grad_gnorm: 1.4918678998947144
      policy_entropy: 374.1995849609375
      policy_loss: -1.4048110246658325
      var_gnorm: 37.81917190551758
      vf_explained_var: 0.008182227611541748
      vf_loss: 0.000559108448214829
    num_steps_sampled: 3420000
    num_steps_trained: 3420000
    wait_time_ms: 353.46
  iterations_since_restore: 171
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 5963.81568479538
  time_this_iter_s: 34.27693152427673
  time_total_s: 5963.81568479538
  timestamp: 1594143628
  timesteps_since_restore: 3420000
  timesteps_this_iter: 20000
  timesteps_total: 3420000
  training_iteration: 171
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 5963 s, 171 iter, 3420000 ts, 574 rew

agent-1: 23.0
agent-2: 17.0
agent-3: 28.0
agent-4: 23.0
agent-5: 27.0
agent-6: 33.0
agent-7: 25.0
agent-8: 23.0
agent-9: 31.0
agent-10: 21.0
agent-11: 16.0
agent-12: 21.0
agent-13: 37.0
agent-14: 20.0
agent-15: 28.0
agent-16: 28.0
agent-17: 26.0
agent-18: 44.0
agent-19: 42.0
agent-20: 22.0
Sum Reward: 535.0
Avg Reward: 26.75
Min Reward: 16.0
Max Reward: 44.0
Gini Coefficient: 0.15
20:20 Ratio: 2.108108108108108
Max-min Ratio: 2.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-41-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 572.35
  episode_reward_min: 507.0
  episodes_this_iter: 1
  episodes_total: 171
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.666
    dispatch_time_ms: 5.469
    learner:
      cur_lr: 0.0011322279460728168
      grad_gnorm: 2.2273943424224854
      policy_entropy: 278.256591796875
      policy_loss: -0.040031448006629944
      var_gnorm: 37.95659637451172
      vf_explained_var: 0.0010744333267211914
      vf_loss: 0.0014299816684797406
    num_steps_sampled: 3440000
    num_steps_trained: 3440000
    wait_time_ms: 339.193
  iterations_since_restore: 172
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 5997.9669778347015
  time_this_iter_s: 34.1512930393219
  time_total_s: 5997.9669778347015
  timestamp: 1594143662
  timesteps_since_restore: 3440000
  timesteps_this_iter: 20000
  timesteps_total: 3440000
  training_iteration: 172
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 5997 s, 172 iter, 3440000 ts, 572 rew

agent-1: 37.0
agent-2: 35.0
agent-3: 26.0
agent-4: 28.0
agent-5: 28.0
agent-6: 55.0
agent-7: 30.0
agent-8: 31.0
agent-9: 37.0
agent-10: 17.0
agent-11: 39.0
agent-12: 41.0
agent-13: 40.0
agent-14: 34.0
agent-15: 30.0
agent-16: 40.0
agent-17: 20.0
agent-18: 34.0
agent-19: 28.0
agent-20: 42.0
Sum Reward: 672.0
Avg Reward: 33.6
Min Reward: 17.0
Max Reward: 55.0
Gini Coefficient: 0.13422619047619047
20:20 Ratio: 1.956043956043956
Max-min Ratio: 3.235294117647059
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-41-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 573.53
  episode_reward_min: 507.0
  episodes_this_iter: 1
  episodes_total: 172
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.548
    dispatch_time_ms: 5.516
    learner:
      cur_lr: 0.0011308960383757949
      grad_gnorm: 40.0
      policy_entropy: 253.1458282470703
      policy_loss: 3.954730987548828
      var_gnorm: 38.071556091308594
      vf_explained_var: 0.8763275146484375
      vf_loss: 10.243484497070312
    num_steps_sampled: 3460000
    num_steps_trained: 3460000
    wait_time_ms: 330.976
  iterations_since_restore: 173
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 6032.317312240601
  time_this_iter_s: 34.35033440589905
  time_total_s: 6032.317312240601
  timestamp: 1594143696
  timesteps_since_restore: 3460000
  timesteps_this_iter: 20000
  timesteps_total: 3460000
  training_iteration: 173
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 6032 s, 173 iter, 3460000 ts, 574 rew

agent-1: 33.0
agent-2: 39.0
agent-3: 46.0
agent-4: 34.0
agent-5: 39.0
agent-6: 35.0
agent-7: 31.0
agent-8: 32.0
agent-9: 24.0
agent-10: 18.0
agent-11: 16.0
agent-12: 37.0
agent-13: 28.0
agent-14: 48.0
agent-15: 39.0
agent-16: 33.0
agent-17: 17.0
agent-18: 22.0
agent-19: 32.0
agent-20: 51.0
Sum Reward: 654.0
Avg Reward: 32.7
Min Reward: 16.0
Max Reward: 51.0
Gini Coefficient: 0.1651376146788991
20:20 Ratio: 2.5205479452054793
Max-min Ratio: 3.1875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-42-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 574.26
  episode_reward_min: 507.0
  episodes_this_iter: 1
  episodes_total: 173
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.615
    dispatch_time_ms: 7.265
    learner:
      cur_lr: 0.001129564014263451
      grad_gnorm: 4.722350120544434
      policy_entropy: 369.9286193847656
      policy_loss: 0.3755033016204834
      var_gnorm: 38.148502349853516
      vf_explained_var: -1.0
      vf_loss: 0.16454383730888367
    num_steps_sampled: 3480000
    num_steps_trained: 3480000
    wait_time_ms: 340.568
  iterations_since_restore: 174
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 6066.59795498848
  time_this_iter_s: 34.28064274787903
  time_total_s: 6066.59795498848
  timestamp: 1594143731
  timesteps_since_restore: 3480000
  timesteps_this_iter: 20000
  timesteps_total: 3480000
  training_iteration: 174
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 6066 s, 174 iter, 3480000 ts, 574 rew

agent-1: 18.0
agent-2: 33.0
agent-3: 31.0
agent-4: 26.0
agent-5: 42.0
agent-6: 17.0
agent-7: 47.0
agent-8: 39.0
agent-9: 38.0
agent-10: 34.0
agent-11: 23.0
agent-12: 19.0
agent-13: 34.0
agent-14: 21.0
agent-15: 35.0
agent-16: 34.0
agent-17: 31.0
agent-18: 48.0
agent-19: 39.0
agent-20: 39.0
Sum Reward: 648.0
Avg Reward: 32.4
Min Reward: 17.0
Max Reward: 48.0
Gini Coefficient: 0.15632716049382717
20:20 Ratio: 2.3466666666666667
Max-min Ratio: 2.823529411764706
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-42-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 574.68
  episode_reward_min: 507.0
  episodes_this_iter: 1
  episodes_total: 174
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.395
    dispatch_time_ms: 6.231
    learner:
      cur_lr: 0.0011282319901511073
      grad_gnorm: 7.5961079597473145
      policy_entropy: 365.7834777832031
      policy_loss: -4.73198127746582
      var_gnorm: 38.24846649169922
      vf_explained_var: -0.6050372123718262
      vf_loss: 0.019427001476287842
    num_steps_sampled: 3500000
    num_steps_trained: 3500000
    wait_time_ms: 346.64
  iterations_since_restore: 175
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 6101.287904262543
  time_this_iter_s: 34.68994927406311
  time_total_s: 6101.287904262543
  timestamp: 1594143765
  timesteps_since_restore: 3500000
  timesteps_this_iter: 20000
  timesteps_total: 3500000
  training_iteration: 175
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 6101 s, 175 iter, 3500000 ts, 575 rew

agent-1: 31.0
agent-2: 40.0
agent-3: 40.0
agent-4: 26.0
agent-5: 24.0
agent-6: 30.0
agent-7: 26.0
agent-8: 47.0
agent-9: 30.0
agent-10: 26.0
agent-11: 13.0
agent-12: 21.0
agent-13: 41.0
agent-14: 29.0
agent-15: 35.0
agent-16: 37.0
agent-17: 31.0
agent-18: 28.0
agent-19: 25.0
agent-20: 33.0
Sum Reward: 613.0
Avg Reward: 30.65
Min Reward: 13.0
Max Reward: 47.0
Gini Coefficient: 0.13809135399673736
20:20 Ratio: 2.0240963855421685
Max-min Ratio: 3.6153846153846154
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-43-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 574.49
  episode_reward_min: 507.0
  episodes_this_iter: 1
  episodes_total: 175
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.763
    dispatch_time_ms: 39.596
    learner:
      cur_lr: 0.0011268999660387635
      grad_gnorm: 2.7031710147857666
      policy_entropy: 370.38018798828125
      policy_loss: -3.583054542541504
      var_gnorm: 38.201255798339844
      vf_explained_var: -1.0
      vf_loss: 0.04041570797562599
    num_steps_sampled: 3520000
    num_steps_trained: 3520000
    wait_time_ms: 322.343
  iterations_since_restore: 176
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 6136.911541700363
  time_this_iter_s: 35.623637437820435
  time_total_s: 6136.911541700363
  timestamp: 1594143801
  timesteps_since_restore: 3520000
  timesteps_this_iter: 20000
  timesteps_total: 3520000
  training_iteration: 176
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 6136 s, 176 iter, 3520000 ts, 574 rew

agent-1: 18.0
agent-2: 26.0
agent-3: 37.0
agent-4: 34.0
agent-5: 28.0
agent-6: 30.0
agent-7: 39.0
agent-8: 30.0
agent-9: 25.0
agent-10: 39.0
agent-11: 30.0
agent-12: 31.0
agent-13: 31.0
agent-14: 19.0
agent-15: 39.0
agent-16: 31.0
agent-17: 42.0
agent-18: 33.0
agent-19: 29.0
agent-20: 40.0
Sum Reward: 631.0
Avg Reward: 31.55
Min Reward: 18.0
Max Reward: 42.0
Gini Coefficient: 0.11339144215530904
20:20 Ratio: 1.8181818181818181
Max-min Ratio: 2.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-43-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 575.22
  episode_reward_min: 507.0
  episodes_this_iter: 1
  episodes_total: 176
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.393
    dispatch_time_ms: 5.827
    learner:
      cur_lr: 0.0011255679419264197
      grad_gnorm: 40.0
      policy_entropy: 343.5101013183594
      policy_loss: 2.505051612854004
      var_gnorm: 38.33427047729492
      vf_explained_var: 0.32832860946655273
      vf_loss: 9.627423286437988
    num_steps_sampled: 3540000
    num_steps_trained: 3540000
    wait_time_ms: 334.815
  iterations_since_restore: 177
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 6171.7188808918
  time_this_iter_s: 34.80733919143677
  time_total_s: 6171.7188808918
  timestamp: 1594143836
  timesteps_since_restore: 3540000
  timesteps_this_iter: 20000
  timesteps_total: 3540000
  training_iteration: 177
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 6171 s, 177 iter, 3540000 ts, 575 rew

agent-1: 34.0
agent-2: 40.0
agent-3: 32.0
agent-4: 26.0
agent-5: 28.0
agent-6: 33.0
agent-7: 18.0
agent-8: 26.0
agent-9: 41.0
agent-10: 11.0
agent-11: 31.0
agent-12: 37.0
agent-13: 35.0
agent-14: 39.0
agent-15: 28.0
agent-16: 19.0
agent-17: 17.0
agent-18: 38.0
agent-19: 49.0
agent-20: 25.0
Sum Reward: 607.0
Avg Reward: 30.35
Min Reward: 11.0
Max Reward: 49.0
Gini Coefficient: 0.17059308072487644
20:20 Ratio: 2.6
Max-min Ratio: 4.454545454545454
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-44-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 575.79
  episode_reward_min: 507.0
  episodes_this_iter: 1
  episodes_total: 177
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.618
    dispatch_time_ms: 7.461
    learner:
      cur_lr: 0.0011242360342293978
      grad_gnorm: 11.939399719238281
      policy_entropy: 372.728271484375
      policy_loss: 4.298982620239258
      var_gnorm: 38.445003509521484
      vf_explained_var: -1.0
      vf_loss: 0.15352211892604828
    num_steps_sampled: 3560000
    num_steps_trained: 3560000
    wait_time_ms: 344.191
  iterations_since_restore: 178
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 6206.374228715897
  time_this_iter_s: 34.65534782409668
  time_total_s: 6206.374228715897
  timestamp: 1594143871
  timesteps_since_restore: 3560000
  timesteps_this_iter: 20000
  timesteps_total: 3560000
  training_iteration: 178
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 6206 s, 178 iter, 3560000 ts, 576 rew

agent-1: 24.0
agent-2: 25.0
agent-3: 28.0
agent-4: 32.0
agent-5: 37.0
agent-6: 22.0
agent-7: 27.0
agent-8: 21.0
agent-9: 30.0
agent-10: 25.0
agent-11: 30.0
agent-12: 31.0
agent-13: 33.0
agent-14: 16.0
agent-15: 32.0
agent-16: 20.0
agent-17: 28.0
agent-18: 28.0
agent-19: 28.0
agent-20: 25.0
Sum Reward: 542.0
Avg Reward: 27.1
Min Reward: 16.0
Max Reward: 37.0
Gini Coefficient: 0.10055350553505535
20:20 Ratio: 1.6962025316455696
Max-min Ratio: 2.3125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-45-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 575.86
  episode_reward_min: 507.0
  episodes_this_iter: 1
  episodes_total: 178
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.715
    dispatch_time_ms: 7.467
    learner:
      cur_lr: 0.001122904010117054
      grad_gnorm: 12.194053649902344
      policy_entropy: 310.8771667480469
      policy_loss: -2.8846826553344727
      var_gnorm: 38.47539138793945
      vf_explained_var: 0.8957539796829224
      vf_loss: 0.15177011489868164
    num_steps_sampled: 3580000
    num_steps_trained: 3580000
    wait_time_ms: 147.905
  iterations_since_restore: 179
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 6255.837220430374
  time_this_iter_s: 49.46299171447754
  time_total_s: 6255.837220430374
  timestamp: 1594143920
  timesteps_since_restore: 3580000
  timesteps_this_iter: 20000
  timesteps_total: 3580000
  training_iteration: 179
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 6255 s, 179 iter, 3580000 ts, 576 rew

agent-1: 24.0
agent-2: 29.0
agent-3: 39.0
agent-4: 34.0
agent-5: 26.0
agent-6: 31.0
agent-7: 29.0
agent-8: 31.0
agent-9: 16.0
agent-10: 23.0
agent-11: 28.0
agent-12: 31.0
agent-13: 31.0
agent-14: 20.0
agent-15: 34.0
agent-16: 33.0
agent-17: 24.0
agent-18: 33.0
agent-19: 25.0
agent-20: 28.0
Sum Reward: 569.0
Avg Reward: 28.45
Min Reward: 16.0
Max Reward: 39.0
Gini Coefficient: 0.10272407732864675
20:20 Ratio: 1.6867469879518073
Max-min Ratio: 2.4375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-45-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 576.03
  episode_reward_min: 507.0
  episodes_this_iter: 1
  episodes_total: 179
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.495
    dispatch_time_ms: 5.632
    learner:
      cur_lr: 0.0011215719860047102
      grad_gnorm: 3.6374504566192627
      policy_entropy: 297.6524658203125
      policy_loss: 0.8572145700454712
      var_gnorm: 38.48139953613281
      vf_explained_var: 0.7825852632522583
      vf_loss: 0.16469064354896545
    num_steps_sampled: 3600000
    num_steps_trained: 3600000
    wait_time_ms: 337.434
  iterations_since_restore: 180
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 6290.777654409409
  time_this_iter_s: 34.940433979034424
  time_total_s: 6290.777654409409
  timestamp: 1594143955
  timesteps_since_restore: 3600000
  timesteps_this_iter: 20000
  timesteps_total: 3600000
  training_iteration: 180
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 6290 s, 180 iter, 3600000 ts, 576 rew

agent-1: 20.0
agent-2: 30.0
agent-3: 34.0
agent-4: 27.0
agent-5: 28.0
agent-6: 23.0
agent-7: 20.0
agent-8: 35.0
agent-9: 32.0
agent-10: 37.0
agent-11: 22.0
agent-12: 30.0
agent-13: 21.0
agent-14: 30.0
agent-15: 21.0
agent-16: 26.0
agent-17: 29.0
agent-18: 31.0
agent-19: 29.0
agent-20: 29.0
Sum Reward: 554.0
Avg Reward: 27.7
Min Reward: 20.0
Max Reward: 37.0
Gini Coefficient: 0.10144404332129964
20:20 Ratio: 1.6829268292682926
Max-min Ratio: 1.85
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-46-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 576.05
  episode_reward_min: 507.0
  episodes_this_iter: 1
  episodes_total: 180
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.474
    dispatch_time_ms: 5.917
    learner:
      cur_lr: 0.0011202399618923664
      grad_gnorm: 22.48685073852539
      policy_entropy: 227.78948974609375
      policy_loss: -1.226250410079956
      var_gnorm: 38.56814956665039
      vf_explained_var: -0.027987122535705566
      vf_loss: 0.416698694229126
    num_steps_sampled: 3620000
    num_steps_trained: 3620000
    wait_time_ms: 335.641
  iterations_since_restore: 181
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 6325.341464042664
  time_this_iter_s: 34.563809633255005
  time_total_s: 6325.341464042664
  timestamp: 1594143990
  timesteps_since_restore: 3620000
  timesteps_this_iter: 20000
  timesteps_total: 3620000
  training_iteration: 181
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 6325 s, 181 iter, 3620000 ts, 576 rew

agent-1: 21.0
agent-2: 18.0
agent-3: 32.0
agent-4: 28.0
agent-5: 34.0
agent-6: 33.0
agent-7: 28.0
agent-8: 27.0
agent-9: 16.0
agent-10: 41.0
agent-11: 31.0
agent-12: 30.0
agent-13: 29.0
agent-14: 22.0
agent-15: 21.0
agent-16: 33.0
agent-17: 42.0
agent-18: 25.0
agent-19: 32.0
agent-20: 25.0
Sum Reward: 568.0
Avg Reward: 28.4
Min Reward: 16.0
Max Reward: 42.0
Gini Coefficient: 0.1316901408450704
20:20 Ratio: 1.9736842105263157
Max-min Ratio: 2.625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-47-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 576.43
  episode_reward_min: 507.0
  episodes_this_iter: 1
  episodes_total: 181
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.786
    dispatch_time_ms: 4.998
    learner:
      cur_lr: 0.0011189080541953444
      grad_gnorm: 4.0560173988342285
      policy_entropy: 369.593017578125
      policy_loss: 1.6377099752426147
      var_gnorm: 38.66878890991211
      vf_explained_var: -1.0
      vf_loss: 0.010488970205187798
    num_steps_sampled: 3640000
    num_steps_trained: 3640000
    wait_time_ms: 340.057
  iterations_since_restore: 182
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 6359.7483859062195
  time_this_iter_s: 34.40692186355591
  time_total_s: 6359.7483859062195
  timestamp: 1594144024
  timesteps_since_restore: 3640000
  timesteps_this_iter: 20000
  timesteps_total: 3640000
  training_iteration: 182
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 6359 s, 182 iter, 3640000 ts, 576 rew

agent-1: 27.0
agent-2: 33.0
agent-3: 38.0
agent-4: 25.0
agent-5: 42.0
agent-6: 33.0
agent-7: 25.0
agent-8: 25.0
agent-9: 35.0
agent-10: 38.0
agent-11: 30.0
agent-12: 32.0
agent-13: 31.0
agent-14: 30.0
agent-15: 23.0
agent-16: 38.0
agent-17: 23.0
agent-18: 25.0
agent-19: 26.0
agent-20: 35.0
Sum Reward: 614.0
Avg Reward: 30.7
Min Reward: 23.0
Max Reward: 42.0
Gini Coefficient: 0.10309446254071661
20:20 Ratio: 1.625
Max-min Ratio: 1.826086956521739
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-47-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 576.88
  episode_reward_min: 507.0
  episodes_this_iter: 1
  episodes_total: 182
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.541
    dispatch_time_ms: 8.536
    learner:
      cur_lr: 0.0011175760300830007
      grad_gnorm: 0.8879208564758301
      policy_entropy: 378.4698181152344
      policy_loss: -0.21017280220985413
      var_gnorm: 38.65414810180664
      vf_explained_var: 0.10297638177871704
      vf_loss: 0.00021539427689276636
    num_steps_sampled: 3660000
    num_steps_trained: 3660000
    wait_time_ms: 338.524
  iterations_since_restore: 183
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 6394.251197338104
  time_this_iter_s: 34.502811431884766
  time_total_s: 6394.251197338104
  timestamp: 1594144059
  timesteps_since_restore: 3660000
  timesteps_this_iter: 20000
  timesteps_total: 3660000
  training_iteration: 183
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 6394 s, 183 iter, 3660000 ts, 577 rew

agent-1: 24.0
agent-2: 28.0
agent-3: 23.0
agent-4: 29.0
agent-5: 31.0
agent-6: 19.0
agent-7: 33.0
agent-8: 23.0
agent-9: 30.0
agent-10: 29.0
agent-11: 33.0
agent-12: 40.0
agent-13: 22.0
agent-14: 40.0
agent-15: 30.0
agent-16: 29.0
agent-17: 37.0
agent-18: 25.0
agent-19: 32.0
agent-20: 31.0
Sum Reward: 588.0
Avg Reward: 29.4
Min Reward: 19.0
Max Reward: 40.0
Gini Coefficient: 0.10561224489795919
20:20 Ratio: 1.7241379310344827
Max-min Ratio: 2.1052631578947367
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-48-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 576.33
  episode_reward_min: 507.0
  episodes_this_iter: 1
  episodes_total: 183
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.474
    dispatch_time_ms: 5.847
    learner:
      cur_lr: 0.0011162440059706569
      grad_gnorm: 6.42102575302124
      policy_entropy: 371.8934326171875
      policy_loss: 3.494103193283081
      var_gnorm: 38.71726608276367
      vf_explained_var: -1.0
      vf_loss: 0.021270524710416794
    num_steps_sampled: 3680000
    num_steps_trained: 3680000
    wait_time_ms: 336.33
  iterations_since_restore: 184
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 6428.697417974472
  time_this_iter_s: 34.4462206363678
  time_total_s: 6428.697417974472
  timestamp: 1594144093
  timesteps_since_restore: 3680000
  timesteps_this_iter: 20000
  timesteps_total: 3680000
  training_iteration: 184
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 6428 s, 184 iter, 3680000 ts, 576 rew

agent-1: 27.0
agent-2: 38.0
agent-3: 33.0
agent-4: 30.0
agent-5: 39.0
agent-6: 26.0
agent-7: 37.0
agent-8: 28.0
agent-9: 26.0
agent-10: 27.0
agent-11: 17.0
agent-12: 38.0
agent-13: 34.0
agent-14: 22.0
agent-15: 27.0
agent-16: 38.0
agent-17: 31.0
agent-18: 41.0
agent-19: 23.0
agent-20: 31.0
Sum Reward: 613.0
Avg Reward: 30.65
Min Reward: 17.0
Max Reward: 41.0
Gini Coefficient: 0.11721044045676998
20:20 Ratio: 1.7727272727272727
Max-min Ratio: 2.411764705882353
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-48-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 576.73
  episode_reward_min: 507.0
  episodes_this_iter: 1
  episodes_total: 184
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.521
    dispatch_time_ms: 5.694
    learner:
      cur_lr: 0.001114911981858313
      grad_gnorm: 8.671492576599121
      policy_entropy: 298.772705078125
      policy_loss: -4.357731819152832
      var_gnorm: 38.874794006347656
      vf_explained_var: 0.5919896364212036
      vf_loss: 0.15262404084205627
    num_steps_sampled: 3700000
    num_steps_trained: 3700000
    wait_time_ms: 350.734
  iterations_since_restore: 185
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 6463.423592090607
  time_this_iter_s: 34.726174116134644
  time_total_s: 6463.423592090607
  timestamp: 1594144128
  timesteps_since_restore: 3700000
  timesteps_this_iter: 20000
  timesteps_total: 3700000
  training_iteration: 185
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 6463 s, 185 iter, 3700000 ts, 577 rew

agent-1: 29.0
agent-2: 31.0
agent-3: 36.0
agent-4: 37.0
agent-5: 34.0
agent-6: 24.0
agent-7: 29.0
agent-8: 27.0
agent-9: 30.0
agent-10: 23.0
agent-11: 31.0
agent-12: 23.0
agent-13: 22.0
agent-14: 30.0
agent-15: 24.0
agent-16: 25.0
agent-17: 28.0
agent-18: 29.0
agent-19: 28.0
agent-20: 27.0
Sum Reward: 567.0
Avg Reward: 28.35
Min Reward: 22.0
Max Reward: 37.0
Gini Coefficient: 0.08104056437389771
20:20 Ratio: 1.5
Max-min Ratio: 1.6818181818181819
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-49-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 576.06
  episode_reward_min: 507.0
  episodes_this_iter: 1
  episodes_total: 185
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.379
    dispatch_time_ms: 5.532
    learner:
      cur_lr: 0.0011135799577459693
      grad_gnorm: 4.703769207000732
      policy_entropy: 382.44647216796875
      policy_loss: -3.4037599563598633
      var_gnorm: 38.91545104980469
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.006500322837382555
    num_steps_sampled: 3720000
    num_steps_trained: 3720000
    wait_time_ms: 340.213
  iterations_since_restore: 186
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 6497.952068328857
  time_this_iter_s: 34.52847623825073
  time_total_s: 6497.952068328857
  timestamp: 1594144163
  timesteps_since_restore: 3720000
  timesteps_this_iter: 20000
  timesteps_total: 3720000
  training_iteration: 186
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 6497 s, 186 iter, 3720000 ts, 576 rew

agent-1: 36.0
agent-2: 31.0
agent-3: 38.0
agent-4: 35.0
agent-5: 31.0
agent-6: 34.0
agent-7: 24.0
agent-8: 37.0
agent-9: 39.0
agent-10: 26.0
agent-11: 31.0
agent-12: 34.0
agent-13: 32.0
agent-14: 35.0
agent-15: 26.0
agent-16: 32.0
agent-17: 34.0
agent-18: 29.0
agent-19: 23.0
agent-20: 30.0
Sum Reward: 637.0
Avg Reward: 31.85
Min Reward: 23.0
Max Reward: 39.0
Gini Coefficient: 0.07794348508634223
20:20 Ratio: 1.5151515151515151
Max-min Ratio: 1.6956521739130435
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-49-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 886.0
  episode_reward_mean: 576.99
  episode_reward_min: 507.0
  episodes_this_iter: 1
  episodes_total: 186
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.526
    dispatch_time_ms: 5.639
    learner:
      cur_lr: 0.0011122480500489473
      grad_gnorm: 4.3748555183410645
      policy_entropy: 353.7976379394531
      policy_loss: 1.8119738101959229
      var_gnorm: 38.926822662353516
      vf_explained_var: -1.0
      vf_loss: 0.11834532022476196
    num_steps_sampled: 3740000
    num_steps_trained: 3740000
    wait_time_ms: 344.313
  iterations_since_restore: 187
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 6532.511161327362
  time_this_iter_s: 34.55909299850464
  time_total_s: 6532.511161327362
  timestamp: 1594144197
  timesteps_since_restore: 3740000
  timesteps_this_iter: 20000
  timesteps_total: 3740000
  training_iteration: 187
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 6532 s, 187 iter, 3740000 ts, 577 rew

agent-1: 31.0
agent-2: 25.0
agent-3: 15.0
agent-4: 30.0
agent-5: 51.0
agent-6: 35.0
agent-7: 32.0
agent-8: 17.0
agent-9: 38.0
agent-10: 21.0
agent-11: 19.0
agent-12: 26.0
agent-13: 32.0
agent-14: 22.0
agent-15: 26.0
agent-16: 30.0
agent-17: 38.0
agent-18: 40.0
agent-19: 31.0
agent-20: 27.0
Sum Reward: 586.0
Avg Reward: 29.3
Min Reward: 15.0
Max Reward: 51.0
Gini Coefficient: 0.15921501706484642
20:20 Ratio: 2.3194444444444446
Max-min Ratio: 3.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-50-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 806.0
  episode_reward_mean: 573.99
  episode_reward_min: 507.0
  episodes_this_iter: 1
  episodes_total: 187
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.347
    dispatch_time_ms: 5.289
    learner:
      cur_lr: 0.0011109160259366035
      grad_gnorm: 20.74526596069336
      policy_entropy: 242.80001831054688
      policy_loss: -9.028045654296875
      var_gnorm: 39.02758026123047
      vf_explained_var: 0.5725851655006409
      vf_loss: 0.3426186442375183
    num_steps_sampled: 3760000
    num_steps_trained: 3760000
    wait_time_ms: 347.086
  iterations_since_restore: 188
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 6567.073042869568
  time_this_iter_s: 34.56188154220581
  time_total_s: 6567.073042869568
  timestamp: 1594144232
  timesteps_since_restore: 3760000
  timesteps_this_iter: 20000
  timesteps_total: 3760000
  training_iteration: 188
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 6567 s, 188 iter, 3760000 ts, 574 rew

agent-1: 34.0
agent-2: 26.0
agent-3: 35.0
agent-4: 30.0
agent-5: 31.0
agent-6: 31.0
agent-7: 29.0
agent-8: 30.0
agent-9: 20.0
agent-10: 27.0
agent-11: 35.0
agent-12: 30.0
agent-13: 26.0
agent-14: 25.0
agent-15: 20.0
agent-16: 22.0
agent-17: 29.0
agent-18: 27.0
agent-19: 33.0
agent-20: 29.0
Sum Reward: 569.0
Avg Reward: 28.45
Min Reward: 20.0
Max Reward: 35.0
Gini Coefficient: 0.08462214411247804
20:20 Ratio: 1.5747126436781609
Max-min Ratio: 1.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-51-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 806.0
  episode_reward_mean: 573.33
  episode_reward_min: 507.0
  episodes_this_iter: 1
  episodes_total: 188
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.635
    dispatch_time_ms: 7.02
    learner:
      cur_lr: 0.0011095840018242598
      grad_gnorm: 1.314902424812317
      policy_entropy: 383.6929626464844
      policy_loss: -1.0758165121078491
      var_gnorm: 39.16763687133789
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.0005141525762155652
    num_steps_sampled: 3780000
    num_steps_trained: 3780000
    wait_time_ms: 341.401
  iterations_since_restore: 189
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 6601.3796944618225
  time_this_iter_s: 34.30665159225464
  time_total_s: 6601.3796944618225
  timestamp: 1594144266
  timesteps_since_restore: 3780000
  timesteps_this_iter: 20000
  timesteps_total: 3780000
  training_iteration: 189
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 6601 s, 189 iter, 3780000 ts, 573 rew

agent-1: 15.0
agent-2: 22.0
agent-3: 29.0
agent-4: 33.0
agent-5: 36.0
agent-6: 34.0
agent-7: 26.0
agent-8: 31.0
agent-9: 38.0
agent-10: 30.0
agent-11: 31.0
agent-12: 29.0
agent-13: 35.0
agent-14: 31.0
agent-15: 26.0
agent-16: 23.0
agent-17: 33.0
agent-18: 31.0
agent-19: 38.0
agent-20: 23.0
Sum Reward: 594.0
Avg Reward: 29.7
Min Reward: 15.0
Max Reward: 38.0
Gini Coefficient: 0.10538720538720539
20:20 Ratio: 1.7710843373493976
Max-min Ratio: 2.533333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-51-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 806.0
  episode_reward_mean: 572.86
  episode_reward_min: 507.0
  episodes_this_iter: 1
  episodes_total: 189
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.339
    dispatch_time_ms: 5.465
    learner:
      cur_lr: 0.001108251977711916
      grad_gnorm: 11.681299209594727
      policy_entropy: 270.78155517578125
      policy_loss: -4.069211959838867
      var_gnorm: 39.19361114501953
      vf_explained_var: 0.571746826171875
      vf_loss: 0.343228280544281
    num_steps_sampled: 3800000
    num_steps_trained: 3800000
    wait_time_ms: 346.722
  iterations_since_restore: 190
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 6636.1191511154175
  time_this_iter_s: 34.73945665359497
  time_total_s: 6636.1191511154175
  timestamp: 1594144301
  timesteps_since_restore: 3800000
  timesteps_this_iter: 20000
  timesteps_total: 3800000
  training_iteration: 190
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 6636 s, 190 iter, 3800000 ts, 573 rew

agent-1: 42.0
agent-2: 37.0
agent-3: 36.0
agent-4: 23.0
agent-5: 25.0
agent-6: 26.0
agent-7: 37.0
agent-8: 35.0
agent-9: 19.0
agent-10: 24.0
agent-11: 31.0
agent-12: 40.0
agent-13: 33.0
agent-14: 29.0
agent-15: 22.0
agent-16: 27.0
agent-17: 25.0
agent-18: 25.0
agent-19: 23.0
agent-20: 23.0
Sum Reward: 582.0
Avg Reward: 29.1
Min Reward: 19.0
Max Reward: 42.0
Gini Coefficient: 0.1268041237113402
20:20 Ratio: 1.793103448275862
Max-min Ratio: 2.210526315789474
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-52-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 806.0
  episode_reward_mean: 572.39
  episode_reward_min: 507.0
  episodes_this_iter: 1
  episodes_total: 190
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.71
    dispatch_time_ms: 7.173
    learner:
      cur_lr: 0.0011069199535995722
      grad_gnorm: 12.543042182922363
      policy_entropy: 384.2664489746094
      policy_loss: 8.222972869873047
      var_gnorm: 39.228294372558594
      vf_explained_var: 7.152557373046875e-07
      vf_loss: 0.04580960422754288
    num_steps_sampled: 3820000
    num_steps_trained: 3820000
    wait_time_ms: 344.108
  iterations_since_restore: 191
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 6670.882404565811
  time_this_iter_s: 34.76325345039368
  time_total_s: 6670.882404565811
  timestamp: 1594144336
  timesteps_since_restore: 3820000
  timesteps_this_iter: 20000
  timesteps_total: 3820000
  training_iteration: 191
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 6670 s, 191 iter, 3820000 ts, 572 rew

agent-1: 31.0
agent-2: 28.0
agent-3: 33.0
agent-4: 28.0
agent-5: 38.0
agent-6: 29.0
agent-7: 23.0
agent-8: 29.0
agent-9: 32.0
agent-10: 26.0
agent-11: 30.0
agent-12: 32.0
agent-13: 24.0
agent-14: 33.0
agent-15: 25.0
agent-16: 30.0
agent-17: 31.0
agent-18: 32.0
agent-19: 27.0
agent-20: 27.0
Sum Reward: 588.0
Avg Reward: 29.4
Min Reward: 23.0
Max Reward: 38.0
Gini Coefficient: 0.06598639455782312
20:20 Ratio: 1.3877551020408163
Max-min Ratio: 1.6521739130434783
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-52-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 806.0
  episode_reward_mean: 571.33
  episode_reward_min: 507.0
  episodes_this_iter: 1
  episodes_total: 191
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.391
    dispatch_time_ms: 14.492
    learner:
      cur_lr: 0.0011055880459025502
      grad_gnorm: 6.017735481262207
      policy_entropy: 328.6116638183594
      policy_loss: 2.480057716369629
      var_gnorm: 39.24811935424805
      vf_explained_var: 0.7193186283111572
      vf_loss: 0.07478436082601547
    num_steps_sampled: 3840000
    num_steps_trained: 3840000
    wait_time_ms: 335.52
  iterations_since_restore: 192
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 6709.520680427551
  time_this_iter_s: 38.63827586174011
  time_total_s: 6709.520680427551
  timestamp: 1594144374
  timesteps_since_restore: 3840000
  timesteps_this_iter: 20000
  timesteps_total: 3840000
  training_iteration: 192
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 6709 s, 192 iter, 3840000 ts, 571 rew

agent-1: 26.0
agent-2: 19.0
agent-3: 21.0
agent-4: 26.0
agent-5: 34.0
agent-6: 21.0
agent-7: 27.0
agent-8: 30.0
agent-9: 22.0
agent-10: 39.0
agent-11: 31.0
agent-12: 27.0
agent-13: 30.0
agent-14: 25.0
agent-15: 21.0
agent-16: 17.0
agent-17: 27.0
agent-18: 18.0
agent-19: 28.0
agent-20: 32.0
Sum Reward: 521.0
Avg Reward: 26.05
Min Reward: 17.0
Max Reward: 39.0
Gini Coefficient: 0.12005758157389636
20:20 Ratio: 1.8133333333333332
Max-min Ratio: 2.2941176470588234
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-53-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 568.48
  episode_reward_min: 507.0
  episodes_this_iter: 1
  episodes_total: 192
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.843
    dispatch_time_ms: 5.73
    learner:
      cur_lr: 0.0011042560217902064
      grad_gnorm: 1.0198744535446167
      policy_entropy: 372.2693176269531
      policy_loss: -0.45321616530418396
      var_gnorm: 39.314369201660156
      vf_explained_var: 0.9958720207214355
      vf_loss: 0.002270896453410387
    num_steps_sampled: 3860000
    num_steps_trained: 3860000
    wait_time_ms: 350.546
  iterations_since_restore: 193
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 6740.953242778778
  time_this_iter_s: 31.432562351226807
  time_total_s: 6740.953242778778
  timestamp: 1594144410
  timesteps_since_restore: 3860000
  timesteps_this_iter: 20000
  timesteps_total: 3860000
  training_iteration: 193
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 6740 s, 193 iter, 3860000 ts, 568 rew

agent-1: 19.0
agent-2: 21.0
agent-3: 21.0
agent-4: 40.0
agent-5: 27.0
agent-6: 25.0
agent-7: 29.0
agent-8: 25.0
agent-9: 17.0
agent-10: 30.0
agent-11: 27.0
agent-12: 27.0
agent-13: 19.0
agent-14: 28.0
agent-15: 30.0
agent-16: 18.0
agent-17: 28.0
agent-18: 32.0
agent-19: 23.0
agent-20: 25.0
Sum Reward: 511.0
Avg Reward: 25.55
Min Reward: 17.0
Max Reward: 40.0
Gini Coefficient: 0.11614481409001957
20:20 Ratio: 1.8082191780821917
Max-min Ratio: 2.3529411764705883
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-54-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 568.12
  episode_reward_min: 507.0
  episodes_this_iter: 1
  episodes_total: 193
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.658
    dispatch_time_ms: 8.28
    learner:
      cur_lr: 0.0011029239976778626
      grad_gnorm: 2.5369341373443604
      policy_entropy: 327.95306396484375
      policy_loss: 0.6114916801452637
      var_gnorm: 39.33140563964844
      vf_explained_var: 0.7459748983383179
      vf_loss: 0.013552682474255562
    num_steps_sampled: 3880000
    num_steps_trained: 3880000
    wait_time_ms: 343.951
  iterations_since_restore: 194
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 6775.547265768051
  time_this_iter_s: 34.59402298927307
  time_total_s: 6775.547265768051
  timestamp: 1594144445
  timesteps_since_restore: 3880000
  timesteps_this_iter: 20000
  timesteps_total: 3880000
  training_iteration: 194
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 6775 s, 194 iter, 3880000 ts, 568 rew

agent-1: 43.0
agent-2: 34.0
agent-3: 22.0
agent-4: 22.0
agent-5: 31.0
agent-6: 34.0
agent-7: 26.0
agent-8: 21.0
agent-9: 23.0
agent-10: 37.0
agent-11: 29.0
agent-12: 33.0
agent-13: 33.0
agent-14: 10.0
agent-15: 35.0
agent-16: 21.0
agent-17: 32.0
agent-18: 26.0
agent-19: 35.0
agent-20: 25.0
Sum Reward: 572.0
Avg Reward: 28.6
Min Reward: 10.0
Max Reward: 43.0
Gini Coefficient: 0.14160839160839161
20:20 Ratio: 2.027027027027027
Max-min Ratio: 4.3
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-54-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 567.5
  episode_reward_min: 507.0
  episodes_this_iter: 1
  episodes_total: 194
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.444
    dispatch_time_ms: 4.941
    learner:
      cur_lr: 0.0011015919735655189
      grad_gnorm: 3.152996778488159
      policy_entropy: 367.7787170410156
      policy_loss: 1.9675248861312866
      var_gnorm: 39.40809631347656
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.0031201988458633423
    num_steps_sampled: 3900000
    num_steps_trained: 3900000
    wait_time_ms: 342.635
  iterations_since_restore: 195
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 6810.274244785309
  time_this_iter_s: 34.72697901725769
  time_total_s: 6810.274244785309
  timestamp: 1594144480
  timesteps_since_restore: 3900000
  timesteps_this_iter: 20000
  timesteps_total: 3900000
  training_iteration: 195
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 6810 s, 195 iter, 3900000 ts, 568 rew

agent-1: 17.0
agent-2: 27.0
agent-3: 26.0
agent-4: 32.0
agent-5: 33.0
agent-6: 28.0
agent-7: 28.0
agent-8: 32.0
agent-9: 24.0
agent-10: 30.0
agent-11: 26.0
agent-12: 21.0
agent-13: 28.0
agent-14: 26.0
agent-15: 18.0
agent-16: 32.0
agent-17: 35.0
agent-18: 20.0
agent-19: 30.0
agent-20: 35.0
Sum Reward: 548.0
Avg Reward: 27.4
Min Reward: 17.0
Max Reward: 35.0
Gini Coefficient: 0.10602189781021898
20:20 Ratio: 1.7763157894736843
Max-min Ratio: 2.0588235294117645
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-55-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 567.13
  episode_reward_min: 507.0
  episodes_this_iter: 1
  episodes_total: 195
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.889
    dispatch_time_ms: 6.656
    learner:
      cur_lr: 0.001100259949453175
      grad_gnorm: 33.589473724365234
      policy_entropy: 281.49310302734375
      policy_loss: 11.925498962402344
      var_gnorm: 39.46084213256836
      vf_explained_var: 0.03614068031311035
      vf_loss: 11.172371864318848
    num_steps_sampled: 3920000
    num_steps_trained: 3920000
    wait_time_ms: 340.388
  iterations_since_restore: 196
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 6844.786354541779
  time_this_iter_s: 34.51210975646973
  time_total_s: 6844.786354541779
  timestamp: 1594144514
  timesteps_since_restore: 3920000
  timesteps_this_iter: 20000
  timesteps_total: 3920000
  training_iteration: 196
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 6844 s, 196 iter, 3920000 ts, 567 rew

agent-1: 24.0
agent-2: 33.0
agent-3: 27.0
agent-4: 32.0
agent-5: 39.0
agent-6: 24.0
agent-7: 28.0
agent-8: 31.0
agent-9: 35.0
agent-10: 33.0
agent-11: 25.0
agent-12: 21.0
agent-13: 28.0
agent-14: 23.0
agent-15: 28.0
agent-16: 24.0
agent-17: 35.0
agent-18: 30.0
agent-19: 32.0
agent-20: 25.0
Sum Reward: 577.0
Avg Reward: 28.85
Min Reward: 21.0
Max Reward: 39.0
Gini Coefficient: 0.09228769497400346
20:20 Ratio: 1.5434782608695652
Max-min Ratio: 1.8571428571428572
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-55-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 567.06
  episode_reward_min: 507.0
  episodes_this_iter: 1
  episodes_total: 196
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.525
    dispatch_time_ms: 5.759
    learner:
      cur_lr: 0.001098928041756153
      grad_gnorm: 2.585444927215576
      policy_entropy: 318.7735595703125
      policy_loss: 0.967837929725647
      var_gnorm: 39.506141662597656
      vf_explained_var: -1.0
      vf_loss: 0.020325029268860817
    num_steps_sampled: 3940000
    num_steps_trained: 3940000
    wait_time_ms: 345.757
  iterations_since_restore: 197
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 6879.591410636902
  time_this_iter_s: 34.80505609512329
  time_total_s: 6879.591410636902
  timestamp: 1594144549
  timesteps_since_restore: 3940000
  timesteps_this_iter: 20000
  timesteps_total: 3940000
  training_iteration: 197
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 6879 s, 197 iter, 3940000 ts, 567 rew

agent-1: 22.0
agent-2: 11.0
agent-3: 30.0
agent-4: 31.0
agent-5: 14.0
agent-6: 30.0
agent-7: 25.0
agent-8: 29.0
agent-9: 28.0
agent-10: 32.0
agent-11: 32.0
agent-12: 34.0
agent-13: 28.0
agent-14: 27.0
agent-15: 27.0
agent-16: 26.0
agent-17: 30.0
agent-18: 33.0
agent-19: 22.0
agent-20: 27.0
Sum Reward: 538.0
Avg Reward: 26.9
Min Reward: 11.0
Max Reward: 34.0
Gini Coefficient: 0.1100371747211896
20:20 Ratio: 1.8985507246376812
Max-min Ratio: 3.090909090909091
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-56-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 566.29
  episode_reward_min: 507.0
  episodes_this_iter: 1
  episodes_total: 197
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.387
    dispatch_time_ms: 8.214
    learner:
      cur_lr: 0.0010975960176438093
      grad_gnorm: 14.896085739135742
      policy_entropy: 251.36453247070312
      policy_loss: -6.56546688079834
      var_gnorm: 39.54107666015625
      vf_explained_var: 0.5203162431716919
      vf_loss: 0.25136202573776245
    num_steps_sampled: 3960000
    num_steps_trained: 3960000
    wait_time_ms: 343.215
  iterations_since_restore: 198
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 6914.187578678131
  time_this_iter_s: 34.59616804122925
  time_total_s: 6914.187578678131
  timestamp: 1594144584
  timesteps_since_restore: 3960000
  timesteps_this_iter: 20000
  timesteps_total: 3960000
  training_iteration: 198
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 6914 s, 198 iter, 3960000 ts, 566 rew

agent-1: 25.0
agent-2: 35.0
agent-3: 30.0
agent-4: 33.0
agent-5: 38.0
agent-6: 19.0
agent-7: 24.0
agent-8: 19.0
agent-9: 20.0
agent-10: 29.0
agent-11: 21.0
agent-12: 21.0
agent-13: 28.0
agent-14: 27.0
agent-15: 30.0
agent-16: 27.0
agent-17: 32.0
agent-18: 24.0
agent-19: 33.0
agent-20: 24.0
Sum Reward: 539.0
Avg Reward: 26.95
Min Reward: 19.0
Max Reward: 38.0
Gini Coefficient: 0.11456400742115028
20:20 Ratio: 1.759493670886076
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-56-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 565.01
  episode_reward_min: 507.0
  episodes_this_iter: 1
  episodes_total: 198
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.523
    dispatch_time_ms: 13.403
    learner:
      cur_lr: 0.0010962639935314655
      grad_gnorm: 2.6061625480651855
      policy_entropy: 375.6134338378906
      policy_loss: 0.01603429764509201
      var_gnorm: 39.64582061767578
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 0.00208020000718534
    num_steps_sampled: 3980000
    num_steps_trained: 3980000
    wait_time_ms: 334.042
  iterations_since_restore: 199
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 6949.509862661362
  time_this_iter_s: 35.32228398323059
  time_total_s: 6949.509862661362
  timestamp: 1594144619
  timesteps_since_restore: 3980000
  timesteps_this_iter: 20000
  timesteps_total: 3980000
  training_iteration: 199
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 6949 s, 199 iter, 3980000 ts, 565 rew

agent-1: 34.0
agent-2: 33.0
agent-3: 29.0
agent-4: 22.0
agent-5: 32.0
agent-6: 31.0
agent-7: 26.0
agent-8: 27.0
agent-9: 28.0
agent-10: 22.0
agent-11: 22.0
agent-12: 27.0
agent-13: 31.0
agent-14: 22.0
agent-15: 21.0
agent-16: 32.0
agent-17: 31.0
agent-18: 29.0
agent-19: 22.0
agent-20: 23.0
Sum Reward: 544.0
Avg Reward: 27.2
Min Reward: 21.0
Max Reward: 34.0
Gini Coefficient: 0.08933823529411765
20:20 Ratio: 1.5057471264367817
Max-min Ratio: 1.619047619047619
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-57-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 564.74
  episode_reward_min: 507.0
  episodes_this_iter: 1
  episodes_total: 199
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.435
    dispatch_time_ms: 19.763
    learner:
      cur_lr: 0.0010949319694191217
      grad_gnorm: 5.74737548828125
      policy_entropy: 383.50146484375
      policy_loss: -4.146714210510254
      var_gnorm: 39.66333770751953
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.010204397141933441
    num_steps_sampled: 4000000
    num_steps_trained: 4000000
    wait_time_ms: 338.189
  iterations_since_restore: 200
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 6985.2408015728
  time_this_iter_s: 35.73093891143799
  time_total_s: 6985.2408015728
  timestamp: 1594144655
  timesteps_since_restore: 4000000
  timesteps_this_iter: 20000
  timesteps_total: 4000000
  training_iteration: 200
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 6985 s, 200 iter, 4000000 ts, 565 rew

agent-1: 27.0
agent-2: 22.0
agent-3: 30.0
agent-4: 38.0
agent-5: 40.0
agent-6: 26.0
agent-7: 29.0
agent-8: 1.0
agent-9: 26.0
agent-10: 37.0
agent-11: 26.0
agent-12: 27.0
agent-13: 23.0
agent-14: 27.0
agent-15: 28.0
agent-16: 35.0
agent-17: 22.0
agent-18: 20.0
agent-19: 27.0
agent-20: 32.0
Sum Reward: 543.0
Avg Reward: 27.15
Min Reward: 1.0
Max Reward: 40.0
Gini Coefficient: 0.1479742173112339
20:20 Ratio: 2.3076923076923075
Max-min Ratio: 40.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-58-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 564.38
  episode_reward_min: 507.0
  episodes_this_iter: 1
  episodes_total: 200
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 4.294
    dispatch_time_ms: 29.636
    learner:
      cur_lr: 0.001093599945306778
      grad_gnorm: 1.530705451965332
      policy_entropy: 359.2162780761719
      policy_loss: 5.342655181884766
      var_gnorm: 39.71660614013672
      vf_explained_var: 0.0
      vf_loss: 2.2906022422830574e-05
    num_steps_sampled: 4020000
    num_steps_trained: 4020000
    wait_time_ms: 336.137
  iterations_since_restore: 201
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 7021.000904083252
  time_this_iter_s: 35.76010251045227
  time_total_s: 7021.000904083252
  timestamp: 1594144691
  timesteps_since_restore: 4020000
  timesteps_this_iter: 20000
  timesteps_total: 4020000
  training_iteration: 201
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 7021 s, 201 iter, 4020000 ts, 564 rew

agent-1: 23.0
agent-2: 41.0
agent-3: 2.0
agent-4: 36.0
agent-5: 31.0
agent-6: 31.0
agent-7: 33.0
agent-8: 11.0
agent-9: 10.0
agent-10: 40.0
agent-11: 26.0
agent-12: 34.0
agent-13: 42.0
agent-14: 41.0
agent-15: 29.0
agent-16: 30.0
agent-17: 40.0
agent-18: 47.0
agent-19: 37.0
agent-20: 39.0
Sum Reward: 623.0
Avg Reward: 31.15
Min Reward: 2.0
Max Reward: 47.0
Gini Coefficient: 0.1962279293739968
20:20 Ratio: 3.717391304347826
Max-min Ratio: 23.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-58-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 564.43
  episode_reward_min: 507.0
  episodes_this_iter: 1
  episodes_total: 201
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.238
    dispatch_time_ms: 17.889
    learner:
      cur_lr: 0.001092268037609756
      grad_gnorm: 20.336999893188477
      policy_entropy: 296.1062316894531
      policy_loss: -15.67850112915039
      var_gnorm: 39.71089172363281
      vf_explained_var: 0.684833288192749
      vf_loss: 0.5075591206550598
    num_steps_sampled: 4040000
    num_steps_trained: 4040000
    wait_time_ms: 379.416
  iterations_since_restore: 202
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 7057.402261734009
  time_this_iter_s: 36.401357650756836
  time_total_s: 7057.402261734009
  timestamp: 1594144728
  timesteps_since_restore: 4040000
  timesteps_this_iter: 20000
  timesteps_total: 4040000
  training_iteration: 202
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 7057 s, 202 iter, 4040000 ts, 564 rew

W0707 13:58:55.761179 17834 node_manager.cc:250] Last heartbeat was sent 2638 ms ago 
agent-1: 25.0
agent-2: 32.0
agent-3: 28.0
agent-4: 13.0
agent-5: 26.0
agent-6: 18.0
agent-7: 33.0
agent-8: 27.0
agent-9: 29.0
agent-10: 30.0
agent-11: 18.0
agent-12: 23.0
agent-13: 34.0
agent-14: 30.0
agent-15: 26.0
agent-16: 37.0
agent-17: 27.0
agent-18: 31.0
agent-19: 30.0
agent-20: 22.0
Sum Reward: 539.0
Avg Reward: 26.95
Min Reward: 13.0
Max Reward: 37.0
Gini Coefficient: 0.11790352504638218
20:20 Ratio: 1.9154929577464788
Max-min Ratio: 2.8461538461538463
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-59-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 563.89
  episode_reward_min: 507.0
  episodes_this_iter: 1
  episodes_total: 202
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.796
    dispatch_time_ms: 5.901
    learner:
      cur_lr: 0.0010909360134974122
      grad_gnorm: 1.7585046291351318
      policy_entropy: 245.96412658691406
      policy_loss: 1.6472266912460327
      var_gnorm: 39.80577850341797
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 0.0008427322027273476
    num_steps_sampled: 4060000
    num_steps_trained: 4060000
    wait_time_ms: 341.685
  iterations_since_restore: 203
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 7092.5120322704315
  time_this_iter_s: 35.10977053642273
  time_total_s: 7092.5120322704315
  timestamp: 1594144763
  timesteps_since_restore: 4060000
  timesteps_this_iter: 20000
  timesteps_total: 4060000
  training_iteration: 203
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 7092 s, 203 iter, 4060000 ts, 564 rew

agent-1: 21.0
agent-2: 29.0
agent-3: 29.0
agent-4: 29.0
agent-5: 21.0
agent-6: 16.0
agent-7: 26.0
agent-8: 33.0
agent-9: 23.0
agent-10: 26.0
agent-11: 39.0
agent-12: 37.0
agent-13: 23.0
agent-14: 26.0
agent-15: 18.0
agent-16: 30.0
agent-17: 18.0
agent-18: 14.0
agent-19: 31.0
agent-20: 27.0
Sum Reward: 516.0
Avg Reward: 25.8
Min Reward: 14.0
Max Reward: 39.0
Gini Coefficient: 0.14263565891472868
20:20 Ratio: 2.121212121212121
Max-min Ratio: 2.7857142857142856
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-59-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 563.21
  episode_reward_min: 507.0
  episodes_this_iter: 1
  episodes_total: 203
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.543
    dispatch_time_ms: 5.62
    learner:
      cur_lr: 0.0010896039893850684
      grad_gnorm: 40.000003814697266
      policy_entropy: 188.31063842773438
      policy_loss: 11.424210548400879
      var_gnorm: 39.79362106323242
      vf_explained_var: 0.7607104182243347
      vf_loss: 85.32955932617188
    num_steps_sampled: 4080000
    num_steps_trained: 4080000
    wait_time_ms: 342.935
  iterations_since_restore: 204
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 7127.354719877243
  time_this_iter_s: 34.84268760681152
  time_total_s: 7127.354719877243
  timestamp: 1594144798
  timesteps_since_restore: 4080000
  timesteps_this_iter: 20000
  timesteps_total: 4080000
  training_iteration: 204
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 7127 s, 204 iter, 4080000 ts, 563 rew

agent-1: 16.0
agent-2: 24.0
agent-3: 39.0
agent-4: 29.0
agent-5: 35.0
agent-6: 21.0
agent-7: 23.0
agent-8: 18.0
agent-9: 30.0
agent-10: 23.0
agent-11: 36.0
agent-12: 28.0
agent-13: 33.0
agent-14: 34.0
agent-15: 29.0
agent-16: 1.0
agent-17: 32.0
agent-18: 26.0
agent-19: 16.0
agent-20: 28.0
Sum Reward: 521.0
Avg Reward: 26.05
Min Reward: 1.0
Max Reward: 39.0
Gini Coefficient: 0.17763915547024953
20:20 Ratio: 2.823529411764706
Max-min Ratio: 39.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-00-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 562.01
  episode_reward_min: 507.0
  episodes_this_iter: 1
  episodes_total: 204
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.481
    dispatch_time_ms: 5.959
    learner:
      cur_lr: 0.0010882719652727246
      grad_gnorm: 1.4932955503463745
      policy_entropy: 360.81390380859375
      policy_loss: 1.323448896408081
      var_gnorm: 39.76111602783203
      vf_explained_var: 3.5762786865234375e-07
      vf_loss: 0.0006450810469686985
    num_steps_sampled: 4100000
    num_steps_trained: 4100000
    wait_time_ms: 338.878
  iterations_since_restore: 205
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 7161.840087890625
  time_this_iter_s: 34.48536801338196
  time_total_s: 7161.840087890625
  timestamp: 1594144832
  timesteps_since_restore: 4100000
  timesteps_this_iter: 20000
  timesteps_total: 4100000
  training_iteration: 205
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 7161 s, 205 iter, 4100000 ts, 562 rew

agent-1: 24.0
agent-2: 20.0
agent-3: 28.0
agent-4: 28.0
agent-5: 30.0
agent-6: 26.0
agent-7: 19.0
agent-8: 16.0
agent-9: 26.0
agent-10: 28.0
agent-11: 48.0
agent-12: 27.0
agent-13: 24.0
agent-14: 26.0
agent-15: 24.0
agent-16: 39.0
agent-17: 26.0
agent-18: 34.0
agent-19: 27.0
agent-20: 11.0
Sum Reward: 531.0
Avg Reward: 26.55
Min Reward: 11.0
Max Reward: 48.0
Gini Coefficient: 0.14736346516007534
20:20 Ratio: 2.287878787878788
Max-min Ratio: 4.363636363636363
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-01-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 561.85
  episode_reward_min: 507.0
  episodes_this_iter: 1
  episodes_total: 205
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.663
    dispatch_time_ms: 6.481
    learner:
      cur_lr: 0.0010869400575757027
      grad_gnorm: 40.000022888183594
      policy_entropy: 236.30340576171875
      policy_loss: -9.715482711791992
      var_gnorm: 39.793373107910156
      vf_explained_var: 0.9169720411300659
      vf_loss: 4.2938232421875
    num_steps_sampled: 4120000
    num_steps_trained: 4120000
    wait_time_ms: 348.31
  iterations_since_restore: 206
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 7196.548784732819
  time_this_iter_s: 34.7086968421936
  time_total_s: 7196.548784732819
  timestamp: 1594144867
  timesteps_since_restore: 4120000
  timesteps_this_iter: 20000
  timesteps_total: 4120000
  training_iteration: 206
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 7196 s, 206 iter, 4120000 ts, 562 rew

agent-1: 22.0
agent-2: 26.0
agent-3: 32.0
agent-4: 40.0
agent-5: 34.0
agent-6: 36.0
agent-7: 30.0
agent-8: 20.0
agent-9: 26.0
agent-10: 22.0
agent-11: 26.0
agent-12: 29.0
agent-13: 20.0
agent-14: 30.0
agent-15: 24.0
agent-16: 15.0
agent-17: 32.0
agent-18: 33.0
agent-19: 22.0
agent-20: 31.0
Sum Reward: 550.0
Avg Reward: 27.5
Min Reward: 15.0
Max Reward: 40.0
Gini Coefficient: 0.12581818181818183
20:20 Ratio: 1.8571428571428572
Max-min Ratio: 2.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-01-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 561.63
  episode_reward_min: 507.0
  episodes_this_iter: 1
  episodes_total: 206
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 4.158
    dispatch_time_ms: 5.905
    learner:
      cur_lr: 0.0010856080334633589
      grad_gnorm: 1.9264506101608276
      policy_entropy: 378.613037109375
      policy_loss: -0.6124396324157715
      var_gnorm: 39.84354782104492
      vf_explained_var: 1.2516975402832031e-06
      vf_loss: 0.0011347051477059722
    num_steps_sampled: 4140000
    num_steps_trained: 4140000
    wait_time_ms: 338.203
  iterations_since_restore: 207
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 7231.128914833069
  time_this_iter_s: 34.580130100250244
  time_total_s: 7231.128914833069
  timestamp: 1594144901
  timesteps_since_restore: 4140000
  timesteps_this_iter: 20000
  timesteps_total: 4140000
  training_iteration: 207
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 7231 s, 207 iter, 4140000 ts, 562 rew

agent-1: 22.0
agent-2: 23.0
agent-3: 27.0
agent-4: 30.0
agent-5: 32.0
agent-6: 27.0
agent-7: 30.0
agent-8: 34.0
agent-9: 24.0
agent-10: 22.0
agent-11: 28.0
agent-12: 29.0
agent-13: 20.0
agent-14: 25.0
agent-15: 30.0
agent-16: 18.0
agent-17: 29.0
agent-18: 22.0
agent-19: 31.0
agent-20: 29.0
Sum Reward: 532.0
Avg Reward: 26.6
Min Reward: 18.0
Max Reward: 34.0
Gini Coefficient: 0.09022556390977443
20:20 Ratio: 1.548780487804878
Max-min Ratio: 1.8888888888888888
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-02-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 561.11
  episode_reward_min: 507.0
  episodes_this_iter: 1
  episodes_total: 207
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.844
    dispatch_time_ms: 6.101
    learner:
      cur_lr: 0.001084276009351015
      grad_gnorm: 0.5591480135917664
      policy_entropy: 385.001953125
      policy_loss: -0.27776771783828735
      var_gnorm: 39.90996170043945
      vf_explained_var: 0.9956669807434082
      vf_loss: 0.00013247306924313307
    num_steps_sampled: 4160000
    num_steps_trained: 4160000
    wait_time_ms: 338.905
  iterations_since_restore: 208
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 7266.028669834137
  time_this_iter_s: 34.899755001068115
  time_total_s: 7266.028669834137
  timestamp: 1594144936
  timesteps_since_restore: 4160000
  timesteps_this_iter: 20000
  timesteps_total: 4160000
  training_iteration: 208
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 7266 s, 208 iter, 4160000 ts, 561 rew

agent-1: 24.0
agent-2: 32.0
agent-3: 35.0
agent-4: 26.0
agent-5: 23.0
agent-6: 28.0
agent-7: 19.0
agent-8: 29.0
agent-9: 19.0
agent-10: 20.0
agent-11: 24.0
agent-12: 26.0
agent-13: 18.0
agent-14: 23.0
agent-15: 22.0
agent-16: 22.0
agent-17: 26.0
agent-18: 33.0
agent-19: 23.0
agent-20: 28.0
Sum Reward: 500.0
Avg Reward: 25.0
Min Reward: 18.0
Max Reward: 35.0
Gini Coefficient: 0.1038
20:20 Ratio: 1.6973684210526316
Max-min Ratio: 1.9444444444444444
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-02-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 560.42
  episode_reward_min: 500.0
  episodes_this_iter: 1
  episodes_total: 208
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.181
    dispatch_time_ms: 5.887
    learner:
      cur_lr: 0.0010829439852386713
      grad_gnorm: 3.854147434234619
      policy_entropy: 376.18731689453125
      policy_loss: -0.25432538986206055
      var_gnorm: 39.978878021240234
      vf_explained_var: -0.16108167171478271
      vf_loss: 0.07461915910243988
    num_steps_sampled: 4180000
    num_steps_trained: 4180000
    wait_time_ms: 330.111
  iterations_since_restore: 209
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 7300.624806880951
  time_this_iter_s: 34.596137046813965
  time_total_s: 7300.624806880951
  timestamp: 1594144971
  timesteps_since_restore: 4180000
  timesteps_this_iter: 20000
  timesteps_total: 4180000
  training_iteration: 209
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 7300 s, 209 iter, 4180000 ts, 560 rew

agent-1: 28.0
agent-2: 26.0
agent-3: 32.0
agent-4: 20.0
agent-5: 21.0
agent-6: 27.0
agent-7: 24.0
agent-8: 18.0
agent-9: 35.0
agent-10: 33.0
agent-11: 15.0
agent-12: 24.0
agent-13: 29.0
agent-14: 23.0
agent-15: 33.0
agent-16: 36.0
agent-17: 23.0
agent-18: 28.0
agent-19: 25.0
agent-20: 29.0
Sum Reward: 529.0
Avg Reward: 26.45
Min Reward: 15.0
Max Reward: 36.0
Gini Coefficient: 0.11880907372400756
20:20 Ratio: 1.8513513513513513
Max-min Ratio: 2.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-03-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 560.22
  episode_reward_min: 500.0
  episodes_this_iter: 1
  episodes_total: 209
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.534
    dispatch_time_ms: 6.822
    learner:
      cur_lr: 0.0010816119611263275
      grad_gnorm: 40.00000762939453
      policy_entropy: 228.02484130859375
      policy_loss: 9.197967529296875
      var_gnorm: 39.988197326660156
      vf_explained_var: 0.6901227235794067
      vf_loss: 49.939247131347656
    num_steps_sampled: 4200000
    num_steps_trained: 4200000
    wait_time_ms: 337.165
  iterations_since_restore: 210
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 7335.387581586838
  time_this_iter_s: 34.76277470588684
  time_total_s: 7335.387581586838
  timestamp: 1594145006
  timesteps_since_restore: 4200000
  timesteps_this_iter: 20000
  timesteps_total: 4200000
  training_iteration: 210
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 7335 s, 210 iter, 4200000 ts, 560 rew

agent-1: 15.0
agent-2: 25.0
agent-3: 28.0
agent-4: 28.0
agent-5: 24.0
agent-6: 27.0
agent-7: 38.0
agent-8: 32.0
agent-9: 22.0
agent-10: 27.0
agent-11: 30.0
agent-12: 22.0
agent-13: 26.0
agent-14: 21.0
agent-15: 36.0
agent-16: 42.0
agent-17: 30.0
agent-18: 33.0
agent-19: 24.0
agent-20: 17.0
Sum Reward: 547.0
Avg Reward: 27.35
Min Reward: 15.0
Max Reward: 42.0
Gini Coefficient: 0.13391224862888482
20:20 Ratio: 1.9866666666666666
Max-min Ratio: 2.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-04-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 559.78
  episode_reward_min: 500.0
  episodes_this_iter: 1
  episodes_total: 210
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.635
    dispatch_time_ms: 6.037
    learner:
      cur_lr: 0.0010802800534293056
      grad_gnorm: 3.823782444000244
      policy_entropy: 340.698486328125
      policy_loss: -1.7192368507385254
      var_gnorm: 40.08297348022461
      vf_explained_var: 0.030358493328094482
      vf_loss: 0.0044230809435248375
    num_steps_sampled: 4220000
    num_steps_trained: 4220000
    wait_time_ms: 340.704
  iterations_since_restore: 211
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 7369.910609960556
  time_this_iter_s: 34.52302837371826
  time_total_s: 7369.910609960556
  timestamp: 1594145040
  timesteps_since_restore: 4220000
  timesteps_this_iter: 20000
  timesteps_total: 4220000
  training_iteration: 211
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 7369 s, 211 iter, 4220000 ts, 560 rew

agent-1: 30.0
agent-2: 43.0
agent-3: 32.0
agent-4: 21.0
agent-5: 15.0
agent-6: 28.0
agent-7: 32.0
agent-8: 26.0
agent-9: 24.0
agent-10: 35.0
agent-11: 23.0
agent-12: 22.0
agent-13: 35.0
agent-14: 23.0
agent-15: 12.0
agent-16: 40.0
agent-17: 23.0
agent-18: 38.0
agent-19: 28.0
agent-20: 26.0
Sum Reward: 556.0
Avg Reward: 27.8
Min Reward: 12.0
Max Reward: 43.0
Gini Coefficient: 0.15755395683453238
20:20 Ratio: 2.2285714285714286
Max-min Ratio: 3.5833333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-04-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 559.61
  episode_reward_min: 500.0
  episodes_this_iter: 1
  episodes_total: 211
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.806
    dispatch_time_ms: 7.333
    learner:
      cur_lr: 0.0010789480293169618
      grad_gnorm: 1.3103857040405273
      policy_entropy: 378.5868225097656
      policy_loss: -0.5442329049110413
      var_gnorm: 40.09477233886719
      vf_explained_var: 0.9471628665924072
      vf_loss: 0.0003749345778487623
    num_steps_sampled: 4240000
    num_steps_trained: 4240000
    wait_time_ms: 339.343
  iterations_since_restore: 212
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 7404.983339548111
  time_this_iter_s: 35.07272958755493
  time_total_s: 7404.983339548111
  timestamp: 1594145076
  timesteps_since_restore: 4240000
  timesteps_this_iter: 20000
  timesteps_total: 4240000
  training_iteration: 212
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 7404 s, 212 iter, 4240000 ts, 560 rew

agent-1: 23.0
agent-2: 29.0
agent-3: 22.0
agent-4: 33.0
agent-5: 26.0
agent-6: 36.0
agent-7: 28.0
agent-8: 28.0
agent-9: 21.0
agent-10: 24.0
agent-11: 20.0
agent-12: 35.0
agent-13: 27.0
agent-14: 27.0
agent-15: 28.0
agent-16: 28.0
agent-17: 27.0
agent-18: 27.0
agent-19: 31.0
agent-20: 23.0
Sum Reward: 543.0
Avg Reward: 27.15
Min Reward: 20.0
Max Reward: 36.0
Gini Coefficient: 0.08609576427255985
20:20 Ratio: 1.569767441860465
Max-min Ratio: 1.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-05-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 559.74
  episode_reward_min: 500.0
  episodes_this_iter: 1
  episodes_total: 212
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.58
    dispatch_time_ms: 5.153
    learner:
      cur_lr: 0.001077616005204618
      grad_gnorm: 10.90622329711914
      policy_entropy: 376.18414306640625
      policy_loss: 6.6221418380737305
      var_gnorm: 40.212120056152344
      vf_explained_var: 0.09580910205841064
      vf_loss: 1.0366127490997314
    num_steps_sampled: 4260000
    num_steps_trained: 4260000
    wait_time_ms: 345.308
  iterations_since_restore: 213
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 7439.43891954422
  time_this_iter_s: 34.45557999610901
  time_total_s: 7439.43891954422
  timestamp: 1594145110
  timesteps_since_restore: 4260000
  timesteps_this_iter: 20000
  timesteps_total: 4260000
  training_iteration: 213
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 7439 s, 213 iter, 4260000 ts, 560 rew

agent-1: 28.0
agent-2: 25.0
agent-3: 32.0
agent-4: 21.0
agent-5: 17.0
agent-6: 14.0
agent-7: 18.0
agent-8: 27.0
agent-9: 18.0
agent-10: 16.0
agent-11: 24.0
agent-12: 30.0
agent-13: 23.0
agent-14: 21.0
agent-15: 34.0
agent-16: 29.0
agent-17: 34.0
agent-18: 38.0
agent-19: 25.0
agent-20: 35.0
Sum Reward: 509.0
Avg Reward: 25.45
Min Reward: 14.0
Max Reward: 38.0
Gini Coefficient: 0.15392927308447937
20:20 Ratio: 2.169230769230769
Max-min Ratio: 2.7142857142857144
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-05-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 559.11
  episode_reward_min: 500.0
  episodes_this_iter: 1
  episodes_total: 213
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.587
    dispatch_time_ms: 5.593
    learner:
      cur_lr: 0.0010762839810922742
      grad_gnorm: 0.5161570310592651
      policy_entropy: 371.14068603515625
      policy_loss: -0.02432752400636673
      var_gnorm: 40.20547103881836
      vf_explained_var: 0.9821757674217224
      vf_loss: 6.304557609837502e-05
    num_steps_sampled: 4280000
    num_steps_trained: 4280000
    wait_time_ms: 336.991
  iterations_since_restore: 214
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 7475.197480678558
  time_this_iter_s: 35.75856113433838
  time_total_s: 7475.197480678558
  timestamp: 1594145146
  timesteps_since_restore: 4280000
  timesteps_this_iter: 20000
  timesteps_total: 4280000
  training_iteration: 214
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 7475 s, 214 iter, 4280000 ts, 559 rew

agent-1: 24.0
agent-2: 41.0
agent-3: 39.0
agent-4: 42.0
agent-5: 41.0
agent-6: 29.0
agent-7: 37.0
agent-8: 27.0
agent-9: 20.0
agent-10: 36.0
agent-11: 34.0
agent-12: 39.0
agent-13: 27.0
agent-14: 30.0
agent-15: 21.0
agent-16: 28.0
agent-17: 22.0
agent-18: 30.0
agent-19: 32.0
agent-20: 22.0
Sum Reward: 621.0
Avg Reward: 31.05
Min Reward: 20.0
Max Reward: 42.0
Gini Coefficient: 0.13051529790660227
20:20 Ratio: 1.9176470588235295
Max-min Ratio: 2.1
W0707 14:06:20.567167 17834 client_connection.cc:255] [worker]ProcessMessage with type 19 took 1027 ms.
W0707 14:06:20.597689 17834 node_manager.cc:250] Last heartbeat was sent 1086 ms ago 
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-06-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 559.17
  episode_reward_min: 500.0
  episodes_this_iter: 1
  episodes_total: 214
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.145
    dispatch_time_ms: 46.347
    learner:
      cur_lr: 0.0010749519569799304
      grad_gnorm: 1.9589935541152954
      policy_entropy: 366.4217224121094
      policy_loss: -6.052150726318359
      var_gnorm: 40.297576904296875
      vf_explained_var: 0.9904487729072571
      vf_loss: 0.0003339536488056183
    num_steps_sampled: 4300000
    num_steps_trained: 4300000
    wait_time_ms: 333.371
  iterations_since_restore: 215
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 7510.75391125679
  time_this_iter_s: 35.55643057823181
  time_total_s: 7510.75391125679
  timestamp: 1594145181
  timesteps_since_restore: 4300000
  timesteps_this_iter: 20000
  timesteps_total: 4300000
  training_iteration: 215
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 7510 s, 215 iter, 4300000 ts, 559 rew

agent-1: 29.0
agent-2: 30.0
agent-3: 31.0
agent-4: 28.0
agent-5: 26.0
agent-6: 27.0
agent-7: 33.0
agent-8: 29.0
agent-9: 32.0
agent-10: 31.0
agent-11: 26.0
agent-12: 34.0
agent-13: 24.0
agent-14: 21.0
agent-15: 23.0
agent-16: 35.0
agent-17: 31.0
agent-18: 30.0
agent-19: 21.0
agent-20: 26.0
Sum Reward: 567.0
Avg Reward: 28.35
Min Reward: 21.0
Max Reward: 35.0
Gini Coefficient: 0.0791005291005291
20:20 Ratio: 1.5056179775280898
Max-min Ratio: 1.6666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-06-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 559.21
  episode_reward_min: 500.0
  episodes_this_iter: 1
  episodes_total: 215
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.517
    dispatch_time_ms: 33.989
    learner:
      cur_lr: 0.0010736200492829084
      grad_gnorm: 40.0
      policy_entropy: 120.58953857421875
      policy_loss: -6.360532283782959
      var_gnorm: 40.320335388183594
      vf_explained_var: 0.8594151735305786
      vf_loss: 40.9920768737793
    num_steps_sampled: 4320000
    num_steps_trained: 4320000
    wait_time_ms: 315.536
  iterations_since_restore: 216
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 7544.944489955902
  time_this_iter_s: 34.19057869911194
  time_total_s: 7544.944489955902
  timestamp: 1594145217
  timesteps_since_restore: 4320000
  timesteps_this_iter: 20000
  timesteps_total: 4320000
  training_iteration: 216
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 7544 s, 216 iter, 4320000 ts, 559 rew

agent-1: 16.0
agent-2: 29.0
agent-3: 33.0
agent-4: 32.0
agent-5: 32.0
agent-6: 23.0
agent-7: 43.0
agent-8: 23.0
agent-9: 38.0
agent-10: 32.0
agent-11: 35.0
agent-12: 34.0
agent-13: 38.0
agent-14: 32.0
agent-15: 24.0
agent-16: 42.0
agent-17: 23.0
agent-18: 35.0
agent-19: 37.0
agent-20: 30.0
Sum Reward: 631.0
Avg Reward: 31.55
Min Reward: 16.0
Max Reward: 43.0
Gini Coefficient: 0.11893819334389857
20:20 Ratio: 1.8941176470588235
Max-min Ratio: 2.6875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-07-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 559.95
  episode_reward_min: 500.0
  episodes_this_iter: 1
  episodes_total: 216
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.278
    dispatch_time_ms: 23.011
    learner:
      cur_lr: 0.0010722880251705647
      grad_gnorm: 5.576073169708252
      policy_entropy: 376.3902587890625
      policy_loss: -4.4453582763671875
      var_gnorm: 40.37571716308594
      vf_explained_var: -9.739398956298828e-05
      vf_loss: 0.009103433229029179
    num_steps_sampled: 4340000
    num_steps_trained: 4340000
    wait_time_ms: 339.782
  iterations_since_restore: 217
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 7580.737380027771
  time_this_iter_s: 35.7928900718689
  time_total_s: 7580.737380027771
  timestamp: 1594145254
  timesteps_since_restore: 4340000
  timesteps_this_iter: 20000
  timesteps_total: 4340000
  training_iteration: 217
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 7580 s, 217 iter, 4340000 ts, 560 rew

agent-1: 35.0
agent-2: 44.0
agent-3: 37.0
agent-4: 27.0
agent-5: 26.0
agent-6: 30.0
agent-7: 30.0
agent-8: 21.0
agent-9: 29.0
agent-10: 30.0
agent-11: 40.0
agent-12: 27.0
agent-13: 24.0
agent-14: 26.0
agent-15: 26.0
agent-16: 25.0
agent-17: 21.0
agent-18: 29.0
agent-19: 38.0
agent-20: 22.0
Sum Reward: 587.0
Avg Reward: 29.35
Min Reward: 21.0
Max Reward: 44.0
Gini Coefficient: 0.11678023850085179
20:20 Ratio: 1.8068181818181819
Max-min Ratio: 2.0952380952380953
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-08-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 560.42
  episode_reward_min: 500.0
  episodes_this_iter: 1
  episodes_total: 217
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.766
    dispatch_time_ms: 5.834
    learner:
      cur_lr: 0.0010709560010582209
      grad_gnorm: 39.999977111816406
      policy_entropy: 159.94102478027344
      policy_loss: 7.008241653442383
      var_gnorm: 40.37480545043945
      vf_explained_var: 0.6847635507583618
      vf_loss: 114.62184143066406
    num_steps_sampled: 4360000
    num_steps_trained: 4360000
    wait_time_ms: 332.519
  iterations_since_restore: 218
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 7616.498184204102
  time_this_iter_s: 35.760804176330566
  time_total_s: 7616.498184204102
  timestamp: 1594145289
  timesteps_since_restore: 4360000
  timesteps_this_iter: 20000
  timesteps_total: 4360000
  training_iteration: 218
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 7616 s, 218 iter, 4360000 ts, 560 rew

agent-1: 22.0
agent-2: 27.0
agent-3: 31.0
agent-4: 38.0
agent-5: 21.0
agent-6: 35.0
agent-7: 27.0
agent-8: 23.0
agent-9: 28.0
agent-10: 18.0
agent-11: 25.0
agent-12: 30.0
agent-13: 34.0
agent-14: 19.0
agent-15: 26.0
agent-16: 25.0
agent-17: 24.0
agent-18: 25.0
agent-19: 34.0
agent-20: 16.0
Sum Reward: 528.0
Avg Reward: 26.4
Min Reward: 16.0
Max Reward: 38.0
Gini Coefficient: 0.12386363636363637
20:20 Ratio: 1.9054054054054055
Max-min Ratio: 2.375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-08-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 560.39
  episode_reward_min: 500.0
  episodes_this_iter: 1
  episodes_total: 218
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.712
    dispatch_time_ms: 5.563
    learner:
      cur_lr: 0.001069623976945877
      grad_gnorm: 1.5296200513839722
      policy_entropy: 374.2901916503906
      policy_loss: 1.329949140548706
      var_gnorm: 40.556190490722656
      vf_explained_var: -1.0
      vf_loss: 0.002911668736487627
    num_steps_sampled: 4380000
    num_steps_trained: 4380000
    wait_time_ms: 346.036
  iterations_since_restore: 219
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 7650.7417113780975
  time_this_iter_s: 34.24352717399597
  time_total_s: 7650.7417113780975
  timestamp: 1594145324
  timesteps_since_restore: 4380000
  timesteps_this_iter: 20000
  timesteps_total: 4380000
  training_iteration: 219
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 7650 s, 219 iter, 4380000 ts, 560 rew

agent-1: 32.0
agent-2: 17.0
agent-3: 38.0
agent-4: 25.0
agent-5: 21.0
agent-6: 25.0
agent-7: 29.0
agent-8: 27.0
agent-9: 28.0
agent-10: 38.0
agent-11: 32.0
agent-12: 31.0
agent-13: 39.0
agent-14: 22.0
agent-15: 23.0
agent-16: 20.0
agent-17: 25.0
agent-18: 24.0
agent-19: 21.0
agent-20: 30.0
Sum Reward: 547.0
Avg Reward: 27.35
Min Reward: 17.0
Max Reward: 39.0
Gini Coefficient: 0.12586837294332723
20:20 Ratio: 1.860759493670886
Max-min Ratio: 2.2941176470588234
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-09-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 560.31
  episode_reward_min: 500.0
  episodes_this_iter: 1
  episodes_total: 219
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.741
    dispatch_time_ms: 6.659
    learner:
      cur_lr: 0.0010682919528335333
      grad_gnorm: 40.0000114440918
      policy_entropy: 114.09516906738281
      policy_loss: -25.79071807861328
      var_gnorm: 40.54655838012695
      vf_explained_var: 0.7582541704177856
      vf_loss: 366.2173156738281
    num_steps_sampled: 4400000
    num_steps_trained: 4400000
    wait_time_ms: 309.338
  iterations_since_restore: 220
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 7685.259416341782
  time_this_iter_s: 34.51770496368408
  time_total_s: 7685.259416341782
  timestamp: 1594145358
  timesteps_since_restore: 4400000
  timesteps_this_iter: 20000
  timesteps_total: 4400000
  training_iteration: 220
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 7685 s, 220 iter, 4400000 ts, 560 rew

agent-1: 37.0
agent-2: 33.0
agent-3: 28.0
agent-4: 33.0
agent-5: 46.0
agent-6: 52.0
agent-7: 22.0
agent-8: 23.0
agent-9: 31.0
agent-10: 32.0
agent-11: 31.0
agent-12: 16.0
agent-13: 26.0
agent-14: 52.0
agent-15: 17.0
agent-16: 21.0
agent-17: 29.0
agent-18: 53.0
agent-19: 13.0
agent-20: 24.0
Sum Reward: 619.0
Avg Reward: 30.95
Min Reward: 13.0
Max Reward: 53.0
Gini Coefficient: 0.20848142164781908
20:20 Ratio: 3.029850746268657
Max-min Ratio: 4.076923076923077
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-09-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 561.12
  episode_reward_min: 500.0
  episodes_this_iter: 1
  episodes_total: 220
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.645
    dispatch_time_ms: 6.596
    learner:
      cur_lr: 0.0010669600451365113
      grad_gnorm: 0.24369755387306213
      policy_entropy: 387.3326110839844
      policy_loss: 0.19810211658477783
      var_gnorm: 40.61665725708008
      vf_explained_var: 0.4876646399497986
      vf_loss: 1.7948641470866278e-05
    num_steps_sampled: 4420000
    num_steps_trained: 4420000
    wait_time_ms: 347.822
  iterations_since_restore: 221
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 7719.6977553367615
  time_this_iter_s: 34.43833899497986
  time_total_s: 7719.6977553367615
  timestamp: 1594145393
  timesteps_since_restore: 4420000
  timesteps_this_iter: 20000
  timesteps_total: 4420000
  training_iteration: 221
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 7719 s, 221 iter, 4420000 ts, 561 rew

agent-1: 36.0
agent-2: 45.0
agent-3: 36.0
agent-4: 36.0
agent-5: 29.0
agent-6: 23.0
agent-7: 23.0
agent-8: 32.0
agent-9: 38.0
agent-10: 27.0
agent-11: 23.0
agent-12: 37.0
agent-13: 42.0
agent-14: 31.0
agent-15: 30.0
agent-16: 36.0
agent-17: 25.0
agent-18: 41.0
agent-19: 31.0
agent-20: 30.0
Sum Reward: 651.0
Avg Reward: 32.55
Min Reward: 23.0
Max Reward: 45.0
Gini Coefficient: 0.11067588325652841
20:20 Ratio: 1.7659574468085106
Max-min Ratio: 1.9565217391304348
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-10-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 561.62
  episode_reward_min: 500.0
  episodes_this_iter: 1
  episodes_total: 221
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.785
    dispatch_time_ms: 5.517
    learner:
      cur_lr: 0.0010656280210241675
      grad_gnorm: 40.00000762939453
      policy_entropy: 82.98554992675781
      policy_loss: 4.633435249328613
      var_gnorm: 40.598270416259766
      vf_explained_var: -0.35347092151641846
      vf_loss: 529.7901000976562
    num_steps_sampled: 4440000
    num_steps_trained: 4440000
    wait_time_ms: 324.188
  iterations_since_restore: 222
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 7754.374544382095
  time_this_iter_s: 34.67678904533386
  time_total_s: 7754.374544382095
  timestamp: 1594145428
  timesteps_since_restore: 4440000
  timesteps_this_iter: 20000
  timesteps_total: 4440000
  training_iteration: 222
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 7754 s, 222 iter, 4440000 ts, 562 rew

agent-1: 29.0
agent-2: 37.0
agent-3: 35.0
agent-4: 31.0
agent-5: 26.0
agent-6: 27.0
agent-7: 15.0
agent-8: 30.0
agent-9: 40.0
agent-10: 25.0
agent-11: 40.0
agent-12: 31.0
agent-13: 28.0
agent-14: 28.0
agent-15: 27.0
agent-16: 18.0
agent-17: 32.0
agent-18: 26.0
agent-19: 19.0
agent-20: 36.0
Sum Reward: 580.0
Avg Reward: 29.0
Min Reward: 15.0
Max Reward: 40.0
Gini Coefficient: 0.1267241379310345
20:20 Ratio: 1.9870129870129871
Max-min Ratio: 2.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-11-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 561.67
  episode_reward_min: 500.0
  episodes_this_iter: 1
  episodes_total: 222
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.465
    dispatch_time_ms: 7.57
    learner:
      cur_lr: 0.0010642959969118237
      grad_gnorm: 1.4704291820526123
      policy_entropy: 374.363037109375
      policy_loss: -1.1619818210601807
      var_gnorm: 40.767845153808594
      vf_explained_var: -1.0
      vf_loss: 0.0027368441224098206
    num_steps_sampled: 4460000
    num_steps_trained: 4460000
    wait_time_ms: 342.135
  iterations_since_restore: 223
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 7788.872119188309
  time_this_iter_s: 34.49757480621338
  time_total_s: 7788.872119188309
  timestamp: 1594145462
  timesteps_since_restore: 4460000
  timesteps_this_iter: 20000
  timesteps_total: 4460000
  training_iteration: 223
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 7788 s, 223 iter, 4460000 ts, 562 rew

agent-1: 38.0
agent-2: 25.0
agent-3: 29.0
agent-4: 26.0
agent-5: 31.0
agent-6: 23.0
agent-7: 29.0
agent-8: 41.0
agent-9: 21.0
agent-10: 31.0
agent-11: 18.0
agent-12: 33.0
agent-13: 24.0
agent-14: 35.0
agent-15: 26.0
agent-16: 23.0
agent-17: 39.0
agent-18: 23.0
agent-19: 28.0
agent-20: 41.0
Sum Reward: 584.0
Avg Reward: 29.2
Min Reward: 18.0
Max Reward: 41.0
Gini Coefficient: 0.1285958904109589
20:20 Ratio: 1.8705882352941177
Max-min Ratio: 2.2777777777777777
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-11-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 561.8
  episode_reward_min: 500.0
  episodes_this_iter: 1
  episodes_total: 223
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.555
    dispatch_time_ms: 6.036
    learner:
      cur_lr: 0.00106296397279948
      grad_gnorm: 3.164062976837158
      policy_entropy: 382.3309326171875
      policy_loss: -1.2420508861541748
      var_gnorm: 40.768733978271484
      vf_explained_var: -1.0
      vf_loss: 0.044398676604032516
    num_steps_sampled: 4480000
    num_steps_trained: 4480000
    wait_time_ms: 347.158
  iterations_since_restore: 224
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 7823.7735023498535
  time_this_iter_s: 34.9013831615448
  time_total_s: 7823.7735023498535
  timestamp: 1594145497
  timesteps_since_restore: 4480000
  timesteps_this_iter: 20000
  timesteps_total: 4480000
  training_iteration: 224
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 7823 s, 224 iter, 4480000 ts, 562 rew

agent-1: 32.0
agent-2: 16.0
agent-3: 21.0
agent-4: 30.0
agent-5: 40.0
agent-6: 34.0
agent-7: 25.0
agent-8: 32.0
agent-9: 24.0
agent-10: 30.0
agent-11: 27.0
agent-12: 40.0
agent-13: 32.0
agent-14: 31.0
agent-15: 35.0
agent-16: 29.0
agent-17: 15.0
agent-18: 20.0
agent-19: 23.0
agent-20: 26.0
Sum Reward: 562.0
Avg Reward: 28.1
Min Reward: 15.0
Max Reward: 40.0
Gini Coefficient: 0.13629893238434163
20:20 Ratio: 2.0694444444444446
Max-min Ratio: 2.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-12-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 561.38
  episode_reward_min: 500.0
  episodes_this_iter: 1
  episodes_total: 224
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.482
    dispatch_time_ms: 5.949
    learner:
      cur_lr: 0.0010616319486871362
      grad_gnorm: 12.514453887939453
      policy_entropy: 329.03070068359375
      policy_loss: -1.4859561920166016
      var_gnorm: 40.89451217651367
      vf_explained_var: -1.0
      vf_loss: 0.2809070646762848
    num_steps_sampled: 4500000
    num_steps_trained: 4500000
    wait_time_ms: 344.921
  iterations_since_restore: 225
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 7858.461332321167
  time_this_iter_s: 34.68782997131348
  time_total_s: 7858.461332321167
  timestamp: 1594145532
  timesteps_since_restore: 4500000
  timesteps_this_iter: 20000
  timesteps_total: 4500000
  training_iteration: 225
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 7858 s, 225 iter, 4500000 ts, 561 rew

agent-1: 22.0
agent-2: 27.0
agent-3: 33.0
agent-4: 35.0
agent-5: 30.0
agent-6: 31.0
agent-7: 20.0
agent-8: 38.0
agent-9: 29.0
agent-10: 17.0
agent-11: 18.0
agent-12: 11.0
agent-13: 31.0
agent-14: 23.0
agent-15: 32.0
agent-16: 32.0
agent-17: 26.0
agent-18: 32.0
agent-19: 29.0
agent-20: 26.0
Sum Reward: 542.0
Avg Reward: 27.1
Min Reward: 11.0
Max Reward: 38.0
Gini Coefficient: 0.13468634686346864
20:20 Ratio: 2.090909090909091
Max-min Ratio: 3.4545454545454546
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-12-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 561.61
  episode_reward_min: 500.0
  episodes_this_iter: 1
  episodes_total: 225
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.129
    dispatch_time_ms: 6.905
    learner:
      cur_lr: 0.0010603000409901142
      grad_gnorm: 2.803008794784546
      policy_entropy: 362.11676025390625
      policy_loss: -0.9752860069274902
      var_gnorm: 40.90310287475586
      vf_explained_var: 0.0
      vf_loss: 0.002378646284341812
    num_steps_sampled: 4520000
    num_steps_trained: 4520000
    wait_time_ms: 313.781
  iterations_since_restore: 226
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 7892.821273565292
  time_this_iter_s: 34.359941244125366
  time_total_s: 7892.821273565292
  timestamp: 1594145566
  timesteps_since_restore: 4520000
  timesteps_this_iter: 20000
  timesteps_total: 4520000
  training_iteration: 226
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 7892 s, 226 iter, 4520000 ts, 562 rew

agent-1: 37.0
agent-2: 25.0
agent-3: 35.0
agent-4: 31.0
agent-5: 15.0
agent-6: 26.0
agent-7: 33.0
agent-8: 19.0
agent-9: 29.0
agent-10: 36.0
agent-11: 18.0
agent-12: 25.0
agent-13: 19.0
agent-14: 38.0
agent-15: 26.0
agent-16: 32.0
agent-17: 32.0
agent-18: 33.0
agent-19: 15.0
agent-20: 23.0
Sum Reward: 547.0
Avg Reward: 27.35
Min Reward: 15.0
Max Reward: 38.0
Gini Coefficient: 0.14945155393053017
20:20 Ratio: 2.1791044776119404
Max-min Ratio: 2.533333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-13-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 561.39
  episode_reward_min: 500.0
  episodes_this_iter: 1
  episodes_total: 226
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.914
    dispatch_time_ms: 5.648
    learner:
      cur_lr: 0.0010589680168777704
      grad_gnorm: 2.9063351154327393
      policy_entropy: 353.54595947265625
      policy_loss: -0.6695047616958618
      var_gnorm: 41.050315856933594
      vf_explained_var: -1.0
      vf_loss: 0.02365094982087612
    num_steps_sampled: 4540000
    num_steps_trained: 4540000
    wait_time_ms: 342.591
  iterations_since_restore: 227
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 7927.288539171219
  time_this_iter_s: 34.467265605926514
  time_total_s: 7927.288539171219
  timestamp: 1594145601
  timesteps_since_restore: 4540000
  timesteps_this_iter: 20000
  timesteps_total: 4540000
  training_iteration: 227
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 7927 s, 227 iter, 4540000 ts, 561 rew

agent-1: 23.0
agent-2: 23.0
agent-3: 17.0
agent-4: 20.0
agent-5: 37.0
agent-6: 40.0
agent-7: 13.0
agent-8: 22.0
agent-9: 27.0
agent-10: 31.0
agent-11: 27.0
agent-12: 29.0
agent-13: 33.0
agent-14: 31.0
agent-15: 33.0
agent-16: 29.0
agent-17: 36.0
agent-18: 35.0
agent-19: 27.0
agent-20: 39.0
Sum Reward: 572.0
Avg Reward: 28.6
Min Reward: 13.0
Max Reward: 40.0
Gini Coefficient: 0.14160839160839161
20:20 Ratio: 2.111111111111111
Max-min Ratio: 3.076923076923077
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-13-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 561.27
  episode_reward_min: 500.0
  episodes_this_iter: 1
  episodes_total: 227
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.554
    dispatch_time_ms: 6.338
    learner:
      cur_lr: 0.0010576359927654266
      grad_gnorm: 20.16383934020996
      policy_entropy: 359.72406005859375
      policy_loss: -1.8213145732879639
      var_gnorm: 41.08114242553711
      vf_explained_var: -1.0
      vf_loss: 0.027389632537961006
    num_steps_sampled: 4560000
    num_steps_trained: 4560000
    wait_time_ms: 329.72
  iterations_since_restore: 228
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 7962.0325927734375
  time_this_iter_s: 34.74405360221863
  time_total_s: 7962.0325927734375
  timestamp: 1594145636
  timesteps_since_restore: 4560000
  timesteps_this_iter: 20000
  timesteps_total: 4560000
  training_iteration: 228
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 7962 s, 228 iter, 4560000 ts, 561 rew

agent-1: 23.0
agent-2: 25.0
agent-3: 31.0
agent-4: 29.0
agent-5: 28.0
agent-6: 16.0
agent-7: 27.0
agent-8: 34.0
agent-9: 21.0
agent-10: 28.0
agent-11: 32.0
agent-12: 34.0
agent-13: 32.0
agent-14: 19.0
agent-15: 38.0
agent-16: 25.0
agent-17: 45.0
agent-18: 20.0
agent-19: 38.0
agent-20: 27.0
Sum Reward: 572.0
Avg Reward: 28.6
Min Reward: 16.0
Max Reward: 45.0
Gini Coefficient: 0.1374125874125874
20:20 Ratio: 2.039473684210526
Max-min Ratio: 2.8125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-14-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 561.47
  episode_reward_min: 500.0
  episodes_this_iter: 1
  episodes_total: 228
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.382
    dispatch_time_ms: 5.827
    learner:
      cur_lr: 0.0010563039686530828
      grad_gnorm: 0.768097460269928
      policy_entropy: 363.1125793457031
      policy_loss: 0.039452239871025085
      var_gnorm: 41.10968017578125
      vf_explained_var: -1.0
      vf_loss: 0.004044332075864077
    num_steps_sampled: 4580000
    num_steps_trained: 4580000
    wait_time_ms: 336.944
  iterations_since_restore: 229
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 7996.5062663555145
  time_this_iter_s: 34.473673582077026
  time_total_s: 7996.5062663555145
  timestamp: 1594145670
  timesteps_since_restore: 4580000
  timesteps_this_iter: 20000
  timesteps_total: 4580000
  training_iteration: 229
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 7996 s, 229 iter, 4580000 ts, 561 rew

agent-1: 21.0
agent-2: 29.0
agent-3: 34.0
agent-4: 29.0
agent-5: 24.0
agent-6: 19.0
agent-7: 26.0
agent-8: 29.0
agent-9: 21.0
agent-10: 15.0
agent-11: 35.0
agent-12: 30.0
agent-13: 39.0
agent-14: 28.0
agent-15: 17.0
agent-16: 30.0
agent-17: 34.0
agent-18: 10.0
agent-19: 32.0
agent-20: 36.0
Sum Reward: 538.0
Avg Reward: 26.9
Min Reward: 10.0
Max Reward: 39.0
Gini Coefficient: 0.15613382899628253
20:20 Ratio: 2.360655737704918
Max-min Ratio: 3.9
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-15-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 561.7
  episode_reward_min: 500.0
  episodes_this_iter: 1
  episodes_total: 229
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.279
    dispatch_time_ms: 6.417
    learner:
      cur_lr: 0.001054971944540739
      grad_gnorm: 0.13520611822605133
      policy_entropy: 369.2244873046875
      policy_loss: -0.034972675144672394
      var_gnorm: 41.12803268432617
      vf_explained_var: 0.019399523735046387
      vf_loss: 2.6604625418258365e-06
    num_steps_sampled: 4600000
    num_steps_trained: 4600000
    wait_time_ms: 320.597
  iterations_since_restore: 230
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 8031.313979148865
  time_this_iter_s: 34.80771279335022
  time_total_s: 8031.313979148865
  timestamp: 1594145705
  timesteps_since_restore: 4600000
  timesteps_this_iter: 20000
  timesteps_total: 4600000
  training_iteration: 230
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 8031 s, 230 iter, 4600000 ts, 562 rew

agent-1: 33.0
agent-2: 29.0
agent-3: 34.0
agent-4: 16.0
agent-5: 26.0
agent-6: 18.0
agent-7: 29.0
agent-8: 34.0
agent-9: 22.0
agent-10: 19.0
agent-11: 29.0
agent-12: 30.0
agent-13: 35.0
agent-14: 18.0
agent-15: 37.0
agent-16: 35.0
agent-17: 24.0
agent-18: 30.0
agent-19: 34.0
agent-20: 24.0
Sum Reward: 556.0
Avg Reward: 27.8
Min Reward: 16.0
Max Reward: 37.0
Gini Coefficient: 0.13003597122302157
20:20 Ratio: 1.9859154929577465
Max-min Ratio: 2.3125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-15-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 561.63
  episode_reward_min: 500.0
  episodes_this_iter: 1
  episodes_total: 230
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.769
    dispatch_time_ms: 5.489
    learner:
      cur_lr: 0.001053640036843717
      grad_gnorm: 1.5652419328689575
      policy_entropy: 368.152587890625
      policy_loss: 0.8835419416427612
      var_gnorm: 41.16288757324219
      vf_explained_var: -0.8880048990249634
      vf_loss: 0.011977093294262886
    num_steps_sampled: 4620000
    num_steps_trained: 4620000
    wait_time_ms: 340.639
  iterations_since_restore: 231
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 8065.819286346436
  time_this_iter_s: 34.5053071975708
  time_total_s: 8065.819286346436
  timestamp: 1594145740
  timesteps_since_restore: 4620000
  timesteps_this_iter: 20000
  timesteps_total: 4620000
  training_iteration: 231
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 8065 s, 231 iter, 4620000 ts, 562 rew

agent-1: 26.0
agent-2: 22.0
agent-3: 34.0
agent-4: 21.0
agent-5: 34.0
agent-6: 25.0
agent-7: 28.0
agent-8: 24.0
agent-9: 22.0
agent-10: 27.0
agent-11: 15.0
agent-12: 23.0
agent-13: 26.0
agent-14: 22.0
agent-15: 24.0
agent-16: 30.0
agent-17: 30.0
agent-18: 33.0
agent-19: 33.0
agent-20: 20.0
Sum Reward: 519.0
Avg Reward: 25.95
Min Reward: 15.0
Max Reward: 34.0
Gini Coefficient: 0.10973025048169557
20:20 Ratio: 1.7179487179487178
Max-min Ratio: 2.2666666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-16-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 561.66
  episode_reward_min: 500.0
  episodes_this_iter: 1
  episodes_total: 231
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.615
    dispatch_time_ms: 6.293
    learner:
      cur_lr: 0.0010523080127313733
      grad_gnorm: 40.0
      policy_entropy: 36.05741500854492
      policy_loss: -49.17719650268555
      var_gnorm: 41.17216110229492
      vf_explained_var: 0.6346570253372192
      vf_loss: 602.074951171875
    num_steps_sampled: 4640000
    num_steps_trained: 4640000
    wait_time_ms: 335.343
  iterations_since_restore: 232
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 8100.668306589127
  time_this_iter_s: 34.84902024269104
  time_total_s: 8100.668306589127
  timestamp: 1594145774
  timesteps_since_restore: 4640000
  timesteps_this_iter: 20000
  timesteps_total: 4640000
  training_iteration: 232
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 8100 s, 232 iter, 4640000 ts, 562 rew

agent-1: 27.0
agent-2: 41.0
agent-3: 30.0
agent-4: 30.0
agent-5: 24.0
agent-6: 32.0
agent-7: 21.0
agent-8: 26.0
agent-9: 34.0
agent-10: 40.0
agent-11: 33.0
agent-12: 22.0
agent-13: 29.0
agent-14: 24.0
agent-15: 20.0
agent-16: 33.0
agent-17: 28.0
agent-18: 27.0
agent-19: 22.0
agent-20: 30.0
Sum Reward: 573.0
Avg Reward: 28.65
Min Reward: 20.0
Max Reward: 41.0
Gini Coefficient: 0.11073298429319371
20:20 Ratio: 1.7411764705882353
Max-min Ratio: 2.05
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-16-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 561.83
  episode_reward_min: 500.0
  episodes_this_iter: 1
  episodes_total: 232
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.646
    dispatch_time_ms: 6.118
    learner:
      cur_lr: 0.0010509759886190295
      grad_gnorm: 1.06523859500885
      policy_entropy: 373.6487731933594
      policy_loss: 1.1572189331054688
      var_gnorm: 41.31507110595703
      vf_explained_var: 0.0
      vf_loss: 0.00023782480275258422
    num_steps_sampled: 4660000
    num_steps_trained: 4660000
    wait_time_ms: 338.945
  iterations_since_restore: 233
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 8134.9890031814575
  time_this_iter_s: 34.32069659233093
  time_total_s: 8134.9890031814575
  timestamp: 1594145809
  timesteps_since_restore: 4660000
  timesteps_this_iter: 20000
  timesteps_total: 4660000
  training_iteration: 233
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 8134 s, 233 iter, 4660000 ts, 562 rew

agent-1: 33.0
agent-2: 28.0
agent-3: 28.0
agent-4: 29.0
agent-5: 25.0
agent-6: 37.0
agent-7: 29.0
agent-8: 30.0
agent-9: 28.0
agent-10: 13.0
agent-11: 42.0
agent-12: 34.0
agent-13: 19.0
agent-14: 27.0
agent-15: 23.0
agent-16: 37.0
agent-17: 18.0
agent-18: 14.0
agent-19: 19.0
agent-20: 17.0
Sum Reward: 530.0
Avg Reward: 26.5
Min Reward: 13.0
Max Reward: 42.0
Gini Coefficient: 0.16679245283018868
20:20 Ratio: 2.4193548387096775
Max-min Ratio: 3.230769230769231
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-17-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 561.53
  episode_reward_min: 500.0
  episodes_this_iter: 1
  episodes_total: 233
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.648
    dispatch_time_ms: 5.953
    learner:
      cur_lr: 0.0010496439645066857
      grad_gnorm: 3.302076578140259
      policy_entropy: 383.1337585449219
      policy_loss: -1.3363491296768188
      var_gnorm: 41.31524658203125
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.003307484555989504
    num_steps_sampled: 4680000
    num_steps_trained: 4680000
    wait_time_ms: 306.189
  iterations_since_restore: 234
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 8169.7305109500885
  time_this_iter_s: 34.74150776863098
  time_total_s: 8169.7305109500885
  timestamp: 1594145844
  timesteps_since_restore: 4680000
  timesteps_this_iter: 20000
  timesteps_total: 4680000
  training_iteration: 234
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 8169 s, 234 iter, 4680000 ts, 562 rew

agent-1: 30.0
agent-2: 25.0
agent-3: 25.0
agent-4: -24.0
agent-5: 31.0
agent-6: 32.0
agent-7: 12.0
agent-8: 26.0
agent-9: 30.0
agent-10: 30.0
agent-11: 37.0
agent-12: 23.0
agent-13: 41.0
agent-14: 23.0
agent-15: 29.0
agent-16: 19.0
agent-17: 20.0
agent-18: 33.0
agent-19: 29.0
agent-20: 32.0
Sum Reward: 503.0
Avg Reward: 25.15
Min Reward: -24.0
Max Reward: 41.0
Gini Coefficient: 0.22554671968190854
20:20 Ratio: 5.296296296296297
Max-min Ratio: -1.7083333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-17-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 560.95
  episode_reward_min: 500.0
  episodes_this_iter: 1
  episodes_total: 234
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.136
    dispatch_time_ms: 5.816
    learner:
      cur_lr: 0.0010483120568096638
      grad_gnorm: 1.35428786277771
      policy_entropy: 369.09332275390625
      policy_loss: 0.5198400020599365
      var_gnorm: 41.35549545288086
      vf_explained_var: 8.940696716308594e-07
      vf_loss: 0.0005520510603673756
    num_steps_sampled: 4700000
    num_steps_trained: 4700000
    wait_time_ms: 344.935
  iterations_since_restore: 235
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 8204.442247390747
  time_this_iter_s: 34.71173644065857
  time_total_s: 8204.442247390747
  timestamp: 1594145878
  timesteps_since_restore: 4700000
  timesteps_this_iter: 20000
  timesteps_total: 4700000
  training_iteration: 235
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 8204 s, 235 iter, 4700000 ts, 561 rew

agent-1: 35.0
agent-2: 29.0
agent-3: 26.0
agent-4: 33.0
agent-5: 29.0
agent-6: 21.0
agent-7: 25.0
agent-8: 13.0
agent-9: 19.0
agent-10: 31.0
agent-11: 33.0
agent-12: 26.0
agent-13: 36.0
agent-14: 23.0
agent-15: 12.0
agent-16: 22.0
agent-17: 25.0
agent-18: 35.0
agent-19: 30.0
agent-20: 16.0
Sum Reward: 519.0
Avg Reward: 25.95
Min Reward: 12.0
Max Reward: 36.0
Gini Coefficient: 0.15327552986512524
20:20 Ratio: 2.316666666666667
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-18-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 560.81
  episode_reward_min: 500.0
  episodes_this_iter: 1
  episodes_total: 235
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.54
    dispatch_time_ms: 6.412
    learner:
      cur_lr: 0.00104698003269732
      grad_gnorm: 39.99998474121094
      policy_entropy: 41.29694747924805
      policy_loss: -12.21859073638916
      var_gnorm: 41.36906814575195
      vf_explained_var: 0.36743563413619995
      vf_loss: 376.47552490234375
    num_steps_sampled: 4720000
    num_steps_trained: 4720000
    wait_time_ms: 331.474
  iterations_since_restore: 236
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 8239.332504749298
  time_this_iter_s: 34.890257358551025
  time_total_s: 8239.332504749298
  timestamp: 1594145913
  timesteps_since_restore: 4720000
  timesteps_this_iter: 20000
  timesteps_total: 4720000
  training_iteration: 236
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 8239 s, 236 iter, 4720000 ts, 561 rew

agent-1: 34.0
agent-2: 16.0
agent-3: 23.0
agent-4: 23.0
agent-5: 34.0
agent-6: 35.0
agent-7: 10.0
agent-8: 24.0
agent-9: 23.0
agent-10: 30.0
agent-11: 33.0
agent-12: 28.0
agent-13: 30.0
agent-14: 33.0
agent-15: 37.0
agent-16: 37.0
agent-17: 33.0
agent-18: 31.0
agent-19: 16.0
agent-20: 24.0
Sum Reward: 554.0
Avg Reward: 27.7
Min Reward: 10.0
Max Reward: 37.0
Gini Coefficient: 0.14675090252707582
20:20 Ratio: 2.2
Max-min Ratio: 3.7
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-19-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 560.17
  episode_reward_min: 500.0
  episodes_this_iter: 1
  episodes_total: 236
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.258
    dispatch_time_ms: 5.996
    learner:
      cur_lr: 0.0010456480085849762
      grad_gnorm: 1.331209659576416
      policy_entropy: 381.8966064453125
      policy_loss: 0.4892754554748535
      var_gnorm: 41.54365539550781
      vf_explained_var: -0.41270148754119873
      vf_loss: 0.0005696724401786923
    num_steps_sampled: 4740000
    num_steps_trained: 4740000
    wait_time_ms: 336.227
  iterations_since_restore: 237
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 8273.557587862015
  time_this_iter_s: 34.225083112716675
  time_total_s: 8273.557587862015
  timestamp: 1594145947
  timesteps_since_restore: 4740000
  timesteps_this_iter: 20000
  timesteps_total: 4740000
  training_iteration: 237
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 8273 s, 237 iter, 4740000 ts, 560 rew

agent-1: 37.0
agent-2: 10.0
agent-3: 38.0
agent-4: 35.0
agent-5: 21.0
agent-6: 20.0
agent-7: 21.0
agent-8: 45.0
agent-9: 37.0
agent-10: 20.0
agent-11: 24.0
agent-12: 32.0
agent-13: 21.0
agent-14: 22.0
agent-15: 32.0
agent-16: 17.0
agent-17: 27.0
agent-18: 19.0
agent-19: 30.0
agent-20: 40.0
Sum Reward: 548.0
Avg Reward: 27.4
Min Reward: 10.0
Max Reward: 45.0
Gini Coefficient: 0.1855839416058394
20:20 Ratio: 2.4242424242424243
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-19-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 560.46
  episode_reward_min: 500.0
  episodes_this_iter: 1
  episodes_total: 237
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.686
    dispatch_time_ms: 5.577
    learner:
      cur_lr: 0.0010443159844726324
      grad_gnorm: 1.2014602422714233
      policy_entropy: 386.09442138671875
      policy_loss: -0.1411476731300354
      var_gnorm: 41.54121017456055
      vf_explained_var: -1.0
      vf_loss: 0.0005616304697468877
    num_steps_sampled: 4760000
    num_steps_trained: 4760000
    wait_time_ms: 316.501
  iterations_since_restore: 238
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 8308.546311855316
  time_this_iter_s: 34.98872399330139
  time_total_s: 8308.546311855316
  timestamp: 1594145982
  timesteps_since_restore: 4760000
  timesteps_this_iter: 20000
  timesteps_total: 4760000
  training_iteration: 238
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 8308 s, 238 iter, 4760000 ts, 560 rew

agent-1: 23.0
agent-2: 31.0
agent-3: 19.0
agent-4: 31.0
agent-5: 36.0
agent-6: 41.0
agent-7: 24.0
agent-8: 28.0
agent-9: 30.0
agent-10: 28.0
agent-11: 50.0
agent-12: 14.0
agent-13: 32.0
agent-14: 20.0
agent-15: 3.0
agent-16: 25.0
agent-17: 42.0
agent-18: 41.0
agent-19: 8.0
agent-20: 19.0
Sum Reward: 545.0
Avg Reward: 27.25
Min Reward: 3.0
Max Reward: 50.0
Gini Coefficient: 0.23513761467889907
20:20 Ratio: 3.9545454545454546
Max-min Ratio: 16.666666666666668
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-20-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 560.65
  episode_reward_min: 500.0
  episodes_this_iter: 1
  episodes_total: 238
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.72
    dispatch_time_ms: 6.299
    learner:
      cur_lr: 0.0010429839603602886
      grad_gnorm: 0.7669879198074341
      policy_entropy: 361.77349853515625
      policy_loss: -0.5908065438270569
      var_gnorm: 41.584312438964844
      vf_explained_var: -0.9315415620803833
      vf_loss: 0.006693551316857338
    num_steps_sampled: 4780000
    num_steps_trained: 4780000
    wait_time_ms: 342.058
  iterations_since_restore: 239
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 8343.097551107407
  time_this_iter_s: 34.551239252090454
  time_total_s: 8343.097551107407
  timestamp: 1594146017
  timesteps_since_restore: 4780000
  timesteps_this_iter: 20000
  timesteps_total: 4780000
  training_iteration: 239
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 8343 s, 239 iter, 4780000 ts, 561 rew

agent-1: 22.0
agent-2: 31.0
agent-3: 29.0
agent-4: 28.0
agent-5: 29.0
agent-6: 24.0
agent-7: 20.0
agent-8: 39.0
agent-9: 31.0
agent-10: 17.0
agent-11: 28.0
agent-12: 25.0
agent-13: 35.0
agent-14: 24.0
agent-15: 17.0
agent-16: 19.0
agent-17: 31.0
agent-18: 22.0
agent-19: 36.0
agent-20: 30.0
Sum Reward: 537.0
Avg Reward: 26.85
Min Reward: 17.0
Max Reward: 39.0
Gini Coefficient: 0.12877094972067038
20:20 Ratio: 1.9315068493150684
Max-min Ratio: 2.2941176470588234
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-20-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 560.8
  episode_reward_min: 500.0
  episodes_this_iter: 1
  episodes_total: 239
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.666
    dispatch_time_ms: 6.336
    learner:
      cur_lr: 0.0010416520526632667
      grad_gnorm: 2.9306929111480713
      policy_entropy: 379.8745422363281
      policy_loss: -0.4991011321544647
      var_gnorm: 41.56892013549805
      vf_explained_var: -1.0
      vf_loss: 0.0038081773091107607
    num_steps_sampled: 4800000
    num_steps_trained: 4800000
    wait_time_ms: 343.289
  iterations_since_restore: 240
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 8378.165408372879
  time_this_iter_s: 35.06785726547241
  time_total_s: 8378.165408372879
  timestamp: 1594146052
  timesteps_since_restore: 4800000
  timesteps_this_iter: 20000
  timesteps_total: 4800000
  training_iteration: 240
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 8378 s, 240 iter, 4800000 ts, 561 rew

agent-1: 19.0
agent-2: 17.0
agent-3: 30.0
agent-4: 29.0
agent-5: 32.0
agent-6: 40.0
agent-7: 32.0
agent-8: 28.0
agent-9: 15.0
agent-10: 26.0
agent-11: 26.0
agent-12: 28.0
agent-13: 22.0
agent-14: 27.0
agent-15: 29.0
agent-16: 22.0
agent-17: 33.0
agent-18: 22.0
agent-19: 25.0
agent-20: 32.0
Sum Reward: 534.0
Avg Reward: 26.7
Min Reward: 15.0
Max Reward: 40.0
Gini Coefficient: 0.12209737827715356
20:20 Ratio: 1.8767123287671232
Max-min Ratio: 2.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-21-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 561.03
  episode_reward_min: 500.0
  episodes_this_iter: 1
  episodes_total: 240
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.534
    dispatch_time_ms: 6.077
    learner:
      cur_lr: 0.0010403200285509229
      grad_gnorm: 0.4936774969100952
      policy_entropy: 364.6820373535156
      policy_loss: 0.1764644980430603
      var_gnorm: 41.65727615356445
      vf_explained_var: -1.0
      vf_loss: 0.0016264020232483745
    num_steps_sampled: 4820000
    num_steps_trained: 4820000
    wait_time_ms: 343.847
  iterations_since_restore: 241
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 8412.659470796585
  time_this_iter_s: 34.494062423706055
  time_total_s: 8412.659470796585
  timestamp: 1594146087
  timesteps_since_restore: 4820000
  timesteps_this_iter: 20000
  timesteps_total: 4820000
  training_iteration: 241
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 8412 s, 241 iter, 4820000 ts, 561 rew

agent-1: 19.0
agent-2: 25.0
agent-3: 25.0
agent-4: 25.0
agent-5: 30.0
agent-6: 21.0
agent-7: 25.0
agent-8: 20.0
agent-9: 32.0
agent-10: 19.0
agent-11: 25.0
agent-12: 30.0
agent-13: 24.0
agent-14: 25.0
agent-15: 24.0
agent-16: 24.0
agent-17: 36.0
agent-18: 28.0
agent-19: 27.0
agent-20: 23.0
Sum Reward: 507.0
Avg Reward: 25.35
Min Reward: 19.0
Max Reward: 36.0
Gini Coefficient: 0.08925049309664694
20:20 Ratio: 1.620253164556962
Max-min Ratio: 1.894736842105263
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-22-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 560.79
  episode_reward_min: 500.0
  episodes_this_iter: 1
  episodes_total: 241
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.783
    dispatch_time_ms: 5.963
    learner:
      cur_lr: 0.001038988004438579
      grad_gnorm: 1.1431913375854492
      policy_entropy: 378.3846435546875
      policy_loss: 0.3047965168952942
      var_gnorm: 41.65659713745117
      vf_explained_var: 0.0013599395751953125
      vf_loss: 0.0002654372074175626
    num_steps_sampled: 4840000
    num_steps_trained: 4840000
    wait_time_ms: 338.088
  iterations_since_restore: 242
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 8447.523628234863
  time_this_iter_s: 34.8641574382782
  time_total_s: 8447.523628234863
  timestamp: 1594146122
  timesteps_since_restore: 4840000
  timesteps_this_iter: 20000
  timesteps_total: 4840000
  training_iteration: 242
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 8447 s, 242 iter, 4840000 ts, 561 rew

agent-1: 28.0
agent-2: 21.0
agent-3: 37.0
agent-4: 25.0
agent-5: 14.0
agent-6: 27.0
agent-7: 30.0
agent-8: 26.0
agent-9: 28.0
agent-10: 30.0
agent-11: 24.0
agent-12: 26.0
agent-13: 19.0
agent-14: 34.0
agent-15: 29.0
agent-16: 22.0
agent-17: 22.0
agent-18: 32.0
agent-19: 25.0
agent-20: 27.0
Sum Reward: 526.0
Avg Reward: 26.3
Min Reward: 14.0
Max Reward: 37.0
Gini Coefficient: 0.10779467680608365
20:20 Ratio: 1.75
Max-min Ratio: 2.642857142857143
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-22-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 560.86
  episode_reward_min: 500.0
  episodes_this_iter: 1
  episodes_total: 242
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.425
    dispatch_time_ms: 5.05
    learner:
      cur_lr: 0.0010376559803262353
      grad_gnorm: 0.6804274916648865
      policy_entropy: 383.6271057128906
      policy_loss: 0.2843916416168213
      var_gnorm: 41.772125244140625
      vf_explained_var: -0.15040111541748047
      vf_loss: 0.008154316805303097
    num_steps_sampled: 4860000
    num_steps_trained: 4860000
    wait_time_ms: 344.576
  iterations_since_restore: 243
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 8481.793910741806
  time_this_iter_s: 34.27028250694275
  time_total_s: 8481.793910741806
  timestamp: 1594146156
  timesteps_since_restore: 4860000
  timesteps_this_iter: 20000
  timesteps_total: 4860000
  training_iteration: 243
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 8481 s, 243 iter, 4860000 ts, 561 rew

agent-1: 23.0
agent-2: 35.0
agent-3: 28.0
agent-4: 37.0
agent-5: 22.0
agent-6: 37.0
agent-7: 23.0
agent-8: 27.0
agent-9: 23.0
agent-10: 26.0
agent-11: 21.0
agent-12: 30.0
agent-13: 20.0
agent-14: 27.0
agent-15: 18.0
agent-16: 31.0
agent-17: 18.0
agent-18: 23.0
agent-19: 30.0
agent-20: 27.0
Sum Reward: 526.0
Avg Reward: 26.3
Min Reward: 18.0
Max Reward: 37.0
Gini Coefficient: 0.11958174904942966
20:20 Ratio: 1.8181818181818181
Max-min Ratio: 2.0555555555555554
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-23-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 560.58
  episode_reward_min: 500.0
  episodes_this_iter: 1
  episodes_total: 243
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.685
    dispatch_time_ms: 6.419
    learner:
      cur_lr: 0.0010363239562138915
      grad_gnorm: 0.7470905780792236
      policy_entropy: 382.1724853515625
      policy_loss: 0.20041318237781525
      var_gnorm: 41.762210845947266
      vf_explained_var: -1.0
      vf_loss: 0.0014418561477214098
    num_steps_sampled: 4880000
    num_steps_trained: 4880000
    wait_time_ms: 333.04
  iterations_since_restore: 244
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 8516.781084775925
  time_this_iter_s: 34.98717403411865
  time_total_s: 8516.781084775925
  timestamp: 1594146191
  timesteps_since_restore: 4880000
  timesteps_this_iter: 20000
  timesteps_total: 4880000
  training_iteration: 244
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 8516 s, 244 iter, 4880000 ts, 561 rew

agent-1: 30.0
agent-2: 24.0
agent-3: 24.0
agent-4: 29.0
agent-5: 25.0
agent-6: 24.0
agent-7: 21.0
agent-8: 37.0
agent-9: 25.0
agent-10: 29.0
agent-11: 16.0
agent-12: 27.0
agent-13: 39.0
agent-14: 39.0
agent-15: 28.0
agent-16: 27.0
agent-17: 29.0
agent-18: 35.0
agent-19: 25.0
agent-20: 11.0
Sum Reward: 544.0
Avg Reward: 27.2
Min Reward: 11.0
Max Reward: 39.0
Gini Coefficient: 0.13547794117647058
20:20 Ratio: 2.0833333333333335
Max-min Ratio: 3.5454545454545454
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-23-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 560.76
  episode_reward_min: 500.0
  episodes_this_iter: 1
  episodes_total: 244
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.845
    dispatch_time_ms: 7.18
    learner:
      cur_lr: 0.0010349920485168695
      grad_gnorm: 0.6779741048812866
      policy_entropy: 382.29962158203125
      policy_loss: 0.517153799533844
      var_gnorm: 41.81951141357422
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.00013774776016362011
    num_steps_sampled: 4900000
    num_steps_trained: 4900000
    wait_time_ms: 335.651
  iterations_since_restore: 245
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 8551.173889160156
  time_this_iter_s: 34.39280438423157
  time_total_s: 8551.173889160156
  timestamp: 1594146225
  timesteps_since_restore: 4900000
  timesteps_this_iter: 20000
  timesteps_total: 4900000
  training_iteration: 245
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 8551 s, 245 iter, 4900000 ts, 561 rew

agent-1: 25.0
agent-2: 25.0
agent-3: 30.0
agent-4: 24.0
agent-5: 30.0
agent-6: 33.0
agent-7: 32.0
agent-8: 28.0
agent-9: 21.0
agent-10: 32.0
agent-11: 34.0
agent-12: 20.0
agent-13: 31.0
agent-14: 23.0
agent-15: 34.0
agent-16: 23.0
agent-17: 28.0
agent-18: 30.0
agent-19: 24.0
agent-20: 24.0
Sum Reward: 551.0
Avg Reward: 27.55
Min Reward: 20.0
Max Reward: 34.0
Gini Coefficient: 0.08956442831215972
20:20 Ratio: 1.528735632183908
Max-min Ratio: 1.7
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-24-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 560.45
  episode_reward_min: 500.0
  episodes_this_iter: 1
  episodes_total: 245
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.172
    dispatch_time_ms: 6.927
    learner:
      cur_lr: 0.0010336600244045258
      grad_gnorm: 0.9624119997024536
      policy_entropy: 386.7614440917969
      policy_loss: -0.16262555122375488
      var_gnorm: 41.822303771972656
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 0.0015998189337551594
    num_steps_sampled: 4920000
    num_steps_trained: 4920000
    wait_time_ms: 333.759
  iterations_since_restore: 246
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 8586.1235973835
  time_this_iter_s: 34.949708223342896
  time_total_s: 8586.1235973835
  timestamp: 1594146260
  timesteps_since_restore: 4920000
  timesteps_this_iter: 20000
  timesteps_total: 4920000
  training_iteration: 246
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 8586 s, 246 iter, 4920000 ts, 560 rew

agent-1: 29.0
agent-2: 25.0
agent-3: 32.0
agent-4: 23.0
agent-5: 24.0
agent-6: 31.0
agent-7: 24.0
agent-8: 36.0
agent-9: 39.0
agent-10: 31.0
agent-11: 49.0
agent-12: 11.0
agent-13: 27.0
agent-14: 36.0
agent-15: 23.0
agent-16: 32.0
agent-17: 29.0
agent-18: 32.0
agent-19: 14.0
agent-20: 26.0
Sum Reward: 573.0
Avg Reward: 28.65
Min Reward: 11.0
Max Reward: 49.0
Gini Coefficient: 0.15331588132635254
20:20 Ratio: 2.2535211267605635
Max-min Ratio: 4.454545454545454
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-24-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 560.85
  episode_reward_min: 500.0
  episodes_this_iter: 1
  episodes_total: 246
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.673
    dispatch_time_ms: 24.464
    learner:
      cur_lr: 0.001032328000292182
      grad_gnorm: 3.4455857276916504
      policy_entropy: 365.0556640625
      policy_loss: -2.396036386489868
      var_gnorm: 41.96995544433594
      vf_explained_var: -1.0
      vf_loss: 0.01990107260644436
    num_steps_sampled: 4940000
    num_steps_trained: 4940000
    wait_time_ms: 336.929
  iterations_since_restore: 247
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 8622.424872875214
  time_this_iter_s: 36.30127549171448
  time_total_s: 8622.424872875214
  timestamp: 1594146297
  timesteps_since_restore: 4940000
  timesteps_this_iter: 20000
  timesteps_total: 4940000
  training_iteration: 247
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 8622 s, 247 iter, 4940000 ts, 561 rew

agent-1: 32.0
agent-2: 20.0
agent-3: 13.0
agent-4: 30.0
agent-5: 29.0
agent-6: 25.0
agent-7: 19.0
agent-8: 27.0
agent-9: 32.0
agent-10: 27.0
agent-11: 29.0
agent-12: 17.0
agent-13: 28.0
agent-14: 26.0
agent-15: 34.0
agent-16: 13.0
agent-17: 20.0
agent-18: 31.0
agent-19: 25.0
agent-20: 29.0
Sum Reward: 506.0
Avg Reward: 25.3
Min Reward: 13.0
Max Reward: 34.0
Gini Coefficient: 0.133201581027668
20:20 Ratio: 2.0806451612903225
Max-min Ratio: 2.6153846153846154
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-25-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 560.4
  episode_reward_min: 500.0
  episodes_this_iter: 1
  episodes_total: 247
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.672
    dispatch_time_ms: 29.421
    learner:
      cur_lr: 0.0010309959761798382
      grad_gnorm: 40.0
      policy_entropy: 25.875553131103516
      policy_loss: 27.383193969726562
      var_gnorm: 41.97613525390625
      vf_explained_var: 0.4323421120643616
      vf_loss: 348.95306396484375
    num_steps_sampled: 4960000
    num_steps_trained: 4960000
    wait_time_ms: 315.569
  iterations_since_restore: 248
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 8659.048799276352
  time_this_iter_s: 36.623926401138306
  time_total_s: 8659.048799276352
  timestamp: 1594146334
  timesteps_since_restore: 4960000
  timesteps_this_iter: 20000
  timesteps_total: 4960000
  training_iteration: 248
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 8659 s, 248 iter, 4960000 ts, 560 rew

agent-1: 32.0
agent-2: 46.0
agent-3: 39.0
agent-4: 28.0
agent-5: 28.0
agent-6: 38.0
agent-7: 26.0
agent-8: 26.0
agent-9: 26.0
agent-10: 16.0
agent-11: 35.0
agent-12: 22.0
agent-13: 23.0
agent-14: 22.0
agent-15: 22.0
agent-16: 26.0
agent-17: 8.0
agent-18: 34.0
agent-19: 34.0
agent-20: 34.0
Sum Reward: 565.0
Avg Reward: 28.25
Min Reward: 8.0
Max Reward: 46.0
Gini Coefficient: 0.1634513274336283
20:20 Ratio: 2.323529411764706
Max-min Ratio: 5.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-26-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 560.0
  episode_reward_min: 500.0
  episodes_this_iter: 1
  episodes_total: 248
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.222
    dispatch_time_ms: 21.169
    learner:
      cur_lr: 0.0010296639520674944
      grad_gnorm: 1.554192304611206
      policy_entropy: 373.6725158691406
      policy_loss: 0.2804293930530548
      var_gnorm: 42.057106018066406
      vf_explained_var: -1.430511474609375e-06
      vf_loss: 0.006194930523633957
    num_steps_sampled: 4980000
    num_steps_trained: 4980000
    wait_time_ms: 340.235
  iterations_since_restore: 249
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 8694.64323592186
  time_this_iter_s: 35.59443664550781
  time_total_s: 8694.64323592186
  timestamp: 1594146369
  timesteps_since_restore: 4980000
  timesteps_this_iter: 20000
  timesteps_total: 4980000
  training_iteration: 249
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 8694 s, 249 iter, 4980000 ts, 560 rew

agent-1: 29.0
agent-2: 27.0
agent-3: 25.0
agent-4: 23.0
agent-5: 30.0
agent-6: 18.0
agent-7: 30.0
agent-8: 33.0
agent-9: 27.0
agent-10: 29.0
agent-11: 29.0
agent-12: 31.0
agent-13: 25.0
agent-14: 34.0
agent-15: 20.0
agent-16: 28.0
agent-17: 16.0
agent-18: 23.0
agent-19: 23.0
agent-20: 34.0
Sum Reward: 534.0
Avg Reward: 26.7
Min Reward: 16.0
Max Reward: 34.0
Gini Coefficient: 0.10374531835205993
20:20 Ratio: 1.7142857142857142
Max-min Ratio: 2.125
agent-1: 40.0
agent-2: 31.0
agent-3: 28.0
agent-4: 23.0
agent-5: 19.0
agent-6: 22.0
agent-7: 25.0
agent-8: 24.0
agent-9: 26.0
agent-10: 25.0
agent-11: 21.0
agent-12: 27.0
agent-13: 40.0
agent-14: 21.0
agent-15: 19.0
agent-16: 22.0
agent-17: 31.0
agent-18: 34.0
agent-19: 27.0
agent-20: 19.0
Sum Reward: 524.0
Avg Reward: 26.2
Min Reward: 19.0
Max Reward: 40.0
Gini Coefficient: 0.12748091603053435
20:20 Ratio: 1.858974358974359
Max-min Ratio: 2.1052631578947367
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-26-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 558.19
  episode_reward_min: 500.0
  episodes_this_iter: 2
  episodes_total: 250
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 4.219
    dispatch_time_ms: 22.177
    learner:
      cur_lr: 0.0010283320443704724
      grad_gnorm: 9.621981620788574
      policy_entropy: 380.77996826171875
      policy_loss: 3.5835952758789062
      var_gnorm: 42.056758880615234
      vf_explained_var: -1.0
      vf_loss: 0.012431442737579346
    num_steps_sampled: 5000000
    num_steps_trained: 5000000
    wait_time_ms: 353.992
  iterations_since_restore: 250
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 8731.399321556091
  time_this_iter_s: 36.75608563423157
  time_total_s: 8731.399321556091
  timestamp: 1594146406
  timesteps_since_restore: 5000000
  timesteps_this_iter: 20000
  timesteps_total: 5000000
  training_iteration: 250
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 8731 s, 250 iter, 5000000 ts, 558 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-27-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 558.19
  episode_reward_min: 500.0
  episodes_this_iter: 0
  episodes_total: 250
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.673
    dispatch_time_ms: 11.075
    learner:
      cur_lr: 0.0010270000202581286
      grad_gnorm: 40.000003814697266
      policy_entropy: 296.53387451171875
      policy_loss: 4.4920854568481445
      var_gnorm: 42.101104736328125
      vf_explained_var: -1.0
      vf_loss: 0.33640384674072266
    num_steps_sampled: 5020000
    num_steps_trained: 5020000
    wait_time_ms: 342.533
  iterations_since_restore: 251
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 8766.920499563217
  time_this_iter_s: 35.521178007125854
  time_total_s: 8766.920499563217
  timestamp: 1594146442
  timesteps_since_restore: 5020000
  timesteps_this_iter: 20000
  timesteps_total: 5020000
  training_iteration: 251
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 8766 s, 251 iter, 5020000 ts, 558 rew

agent-1: 19.0
agent-2: 20.0
agent-3: 33.0
agent-4: 34.0
agent-5: 43.0
agent-6: 29.0
agent-7: 22.0
agent-8: 25.0
agent-9: 22.0
agent-10: 33.0
agent-11: 33.0
agent-12: 28.0
agent-13: 33.0
agent-14: 28.0
agent-15: 24.0
agent-16: 20.0
agent-17: 20.0
agent-18: 24.0
agent-19: 13.0
agent-20: 31.0
Sum Reward: 534.0
Avg Reward: 26.7
Min Reward: 13.0
Max Reward: 43.0
Gini Coefficient: 0.14363295880149812
20:20 Ratio: 1.9861111111111112
Max-min Ratio: 3.3076923076923075
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-27-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 557.71
  episode_reward_min: 500.0
  episodes_this_iter: 1
  episodes_total: 251
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.796
    dispatch_time_ms: 6.537
    learner:
      cur_lr: 0.0010256679961457849
      grad_gnorm: 40.00000762939453
      policy_entropy: 51.83930969238281
      policy_loss: 97.92691802978516
      var_gnorm: 42.12311935424805
      vf_explained_var: -0.11848223209381104
      vf_loss: 619.6209716796875
    num_steps_sampled: 5040000
    num_steps_trained: 5040000
    wait_time_ms: 325.372
  iterations_since_restore: 252
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 8802.198453187943
  time_this_iter_s: 35.27795362472534
  time_total_s: 8802.198453187943
  timestamp: 1594146477
  timesteps_since_restore: 5040000
  timesteps_this_iter: 20000
  timesteps_total: 5040000
  training_iteration: 252
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 8802 s, 252 iter, 5040000 ts, 558 rew

agent-1: 35.0
agent-2: 33.0
agent-3: 22.0
agent-4: 34.0
agent-5: 17.0
agent-6: 29.0
agent-7: 25.0
agent-8: 25.0
agent-9: 15.0
agent-10: 27.0
agent-11: 30.0
agent-12: 25.0
agent-13: 20.0
agent-14: 14.0
agent-15: 39.0
agent-16: 27.0
agent-17: 25.0
agent-18: 26.0
agent-19: 31.0
agent-20: 23.0
Sum Reward: 522.0
Avg Reward: 26.1
Min Reward: 14.0
Max Reward: 39.0
Gini Coefficient: 0.1385057471264368
20:20 Ratio: 2.1363636363636362
Max-min Ratio: 2.7857142857142856
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-28-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 557.74
  episode_reward_min: 500.0
  episodes_this_iter: 1
  episodes_total: 252
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.673
    dispatch_time_ms: 4.885
    learner:
      cur_lr: 0.001024335972033441
      grad_gnorm: 1.0207810401916504
      policy_entropy: 344.98480224609375
      policy_loss: -1.0710554122924805
      var_gnorm: 42.194427490234375
      vf_explained_var: -1.0
      vf_loss: 0.0013096579350531101
    num_steps_sampled: 5060000
    num_steps_trained: 5060000
    wait_time_ms: 348.054
  iterations_since_restore: 253
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 8836.542217969894
  time_this_iter_s: 34.343764781951904
  time_total_s: 8836.542217969894
  timestamp: 1594146511
  timesteps_since_restore: 5060000
  timesteps_this_iter: 20000
  timesteps_total: 5060000
  training_iteration: 253
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 8836 s, 253 iter, 5060000 ts, 558 rew

agent-1: 48.0
agent-2: 17.0
agent-3: 27.0
agent-4: 27.0
agent-5: 33.0
agent-6: 22.0
agent-7: 33.0
agent-8: 26.0
agent-9: 26.0
agent-10: 42.0
agent-11: 29.0
agent-12: 22.0
agent-13: 22.0
agent-14: 37.0
agent-15: 7.0
agent-16: 34.0
agent-17: 34.0
agent-18: 30.0
agent-19: 7.0
agent-20: 12.0
Sum Reward: 535.0
Avg Reward: 26.75
Min Reward: 7.0
Max Reward: 48.0
Gini Coefficient: 0.21560747663551402
20:20 Ratio: 3.744186046511628
Max-min Ratio: 6.857142857142857
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-29-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 557.45
  episode_reward_min: 500.0
  episodes_this_iter: 1
  episodes_total: 253
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.829
    dispatch_time_ms: 12.405
    learner:
      cur_lr: 0.0010230039479210973
      grad_gnorm: 0.3336339294910431
      policy_entropy: 356.27447509765625
      policy_loss: -0.05873136967420578
      var_gnorm: 42.209346771240234
      vf_explained_var: 0.001130223274230957
      vf_loss: 3.294505222584121e-05
    num_steps_sampled: 5080000
    num_steps_trained: 5080000
    wait_time_ms: 347.893
  iterations_since_restore: 254
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 8871.701354980469
  time_this_iter_s: 35.15913701057434
  time_total_s: 8871.701354980469
  timestamp: 1594146547
  timesteps_since_restore: 5080000
  timesteps_this_iter: 20000
  timesteps_total: 5080000
  training_iteration: 254
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 8871 s, 254 iter, 5080000 ts, 557 rew

agent-1: 28.0
agent-2: 25.0
agent-3: 29.0
agent-4: 35.0
agent-5: 21.0
agent-6: 17.0
agent-7: 27.0
agent-8: 21.0
agent-9: 18.0
agent-10: 22.0
agent-11: 32.0
agent-12: 21.0
agent-13: 24.0
agent-14: 40.0
agent-15: 25.0
agent-16: 29.0
agent-17: 30.0
agent-18: 57.0
agent-19: 23.0
agent-20: 23.0
Sum Reward: 547.0
Avg Reward: 27.35
Min Reward: 17.0
Max Reward: 57.0
Gini Coefficient: 0.1576782449725777
20:20 Ratio: 2.1298701298701297
Max-min Ratio: 3.3529411764705883
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-29-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 557.85
  episode_reward_min: 500.0
  episodes_this_iter: 1
  episodes_total: 254
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.739
    dispatch_time_ms: 5.068
    learner:
      cur_lr: 0.0010216720402240753
      grad_gnorm: 2.2768101692199707
      policy_entropy: 338.5030212402344
      policy_loss: 1.5164213180541992
      var_gnorm: 42.34885787963867
      vf_explained_var: 0.9525753259658813
      vf_loss: 0.0026583047583699226
    num_steps_sampled: 5100000
    num_steps_trained: 5100000
    wait_time_ms: 334.442
  iterations_since_restore: 255
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 8906.017894744873
  time_this_iter_s: 34.3165397644043
  time_total_s: 8906.017894744873
  timestamp: 1594146581
  timesteps_since_restore: 5100000
  timesteps_this_iter: 20000
  timesteps_total: 5100000
  training_iteration: 255
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 8906 s, 255 iter, 5100000 ts, 558 rew

agent-1: 30.0
agent-2: 12.0
agent-3: 32.0
agent-4: 24.0
agent-5: 22.0
agent-6: 20.0
agent-7: 25.0
agent-8: 28.0
agent-9: 37.0
agent-10: 27.0
agent-11: 22.0
agent-12: 31.0
agent-13: 30.0
agent-14: 38.0
agent-15: 23.0
agent-16: 38.0
agent-17: 34.0
agent-18: 22.0
agent-19: 31.0
agent-20: 37.0
Sum Reward: 563.0
Avg Reward: 28.15
Min Reward: 12.0
Max Reward: 38.0
Gini Coefficient: 0.1352575488454707
20:20 Ratio: 1.9736842105263157
Max-min Ratio: 3.1666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-30-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 558.0
  episode_reward_min: 500.0
  episodes_this_iter: 1
  episodes_total: 255
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.481
    dispatch_time_ms: 5.425
    learner:
      cur_lr: 0.0010203400161117315
      grad_gnorm: 3.3050174713134766
      policy_entropy: 365.45440673828125
      policy_loss: 0.35142838954925537
      var_gnorm: 42.347450256347656
      vf_explained_var: 0.967454195022583
      vf_loss: 0.001564116682857275
    num_steps_sampled: 5120000
    num_steps_trained: 5120000
    wait_time_ms: 296.348
  iterations_since_restore: 256
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 8940.893508911133
  time_this_iter_s: 34.875614166259766
  time_total_s: 8940.893508911133
  timestamp: 1594146616
  timesteps_since_restore: 5120000
  timesteps_this_iter: 20000
  timesteps_total: 5120000
  training_iteration: 256
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 8940 s, 256 iter, 5120000 ts, 558 rew

agent-1: 33.0
agent-2: 26.0
agent-3: 32.0
agent-4: 29.0
agent-5: 32.0
agent-6: 34.0
agent-7: 26.0
agent-8: 29.0
agent-9: 23.0
agent-10: 22.0
agent-11: 22.0
agent-12: 18.0
agent-13: 27.0
agent-14: 29.0
agent-15: 31.0
agent-16: 40.0
agent-17: 33.0
agent-18: 16.0
agent-19: 13.0
agent-20: 30.0
Sum Reward: 545.0
Avg Reward: 27.25
Min Reward: 13.0
Max Reward: 40.0
Gini Coefficient: 0.1320183486238532
20:20 Ratio: 2.028985507246377
Max-min Ratio: 3.076923076923077
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-30-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 557.97
  episode_reward_min: 500.0
  episodes_this_iter: 1
  episodes_total: 256
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.803
    dispatch_time_ms: 6.079
    learner:
      cur_lr: 0.0010190079919993877
      grad_gnorm: 0.29527851939201355
      policy_entropy: 365.3865051269531
      policy_loss: 0.15966951847076416
      var_gnorm: 42.37510681152344
      vf_explained_var: 0.9863913059234619
      vf_loss: 0.0005581480800174177
    num_steps_sampled: 5140000
    num_steps_trained: 5140000
    wait_time_ms: 335.928
  iterations_since_restore: 257
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 8975.448550701141
  time_this_iter_s: 34.555041790008545
  time_total_s: 8975.448550701141
  timestamp: 1594146650
  timesteps_since_restore: 5140000
  timesteps_this_iter: 20000
  timesteps_total: 5140000
  training_iteration: 257
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 8975 s, 257 iter, 5140000 ts, 558 rew

agent-1: 29.0
agent-2: 32.0
agent-3: 30.0
agent-4: 23.0
agent-5: 38.0
agent-6: 29.0
agent-7: 20.0
agent-8: 38.0
agent-9: 31.0
agent-10: 34.0
agent-11: 18.0
agent-12: 30.0
agent-13: 28.0
agent-14: 22.0
agent-15: 19.0
agent-16: 25.0
agent-17: 10.0
agent-18: 36.0
agent-19: 28.0
agent-20: 17.0
Sum Reward: 537.0
Avg Reward: 26.85
Min Reward: 10.0
Max Reward: 38.0
Gini Coefficient: 0.1531657355679702
20:20 Ratio: 2.28125
Max-min Ratio: 3.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-31-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 557.47
  episode_reward_min: 500.0
  episodes_this_iter: 1
  episodes_total: 257
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.724
    dispatch_time_ms: 5.94
    learner:
      cur_lr: 0.001017675967887044
      grad_gnorm: 40.0
      policy_entropy: 19.90257453918457
      policy_loss: 22.12344741821289
      var_gnorm: 42.385047912597656
      vf_explained_var: 0.20273005962371826
      vf_loss: 871.2341918945312
    num_steps_sampled: 5160000
    num_steps_trained: 5160000
    wait_time_ms: 328.943
  iterations_since_restore: 258
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 9012.064336061478
  time_this_iter_s: 36.615785360336304
  time_total_s: 9012.064336061478
  timestamp: 1594146687
  timesteps_since_restore: 5160000
  timesteps_this_iter: 20000
  timesteps_total: 5160000
  training_iteration: 258
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 9012 s, 258 iter, 5160000 ts, 557 rew

agent-1: 7.0
agent-2: 26.0
agent-3: 26.0
agent-4: 21.0
agent-5: 36.0
agent-6: 28.0
agent-7: 20.0
agent-8: 31.0
agent-9: 30.0
agent-10: 33.0
agent-11: 14.0
agent-12: 31.0
agent-13: 20.0
agent-14: 25.0
agent-15: 19.0
agent-16: 29.0
agent-17: 20.0
agent-18: 1.0
agent-19: 33.0
agent-20: 29.0
Sum Reward: 479.0
Avg Reward: 23.95
Min Reward: 1.0
Max Reward: 36.0
Gini Coefficient: 0.1953027139874739
20:20 Ratio: 3.2439024390243905
Max-min Ratio: 36.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-32-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 557.13
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 258
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.503
    dispatch_time_ms: 4.766
    learner:
      cur_lr: 0.0010163439437747002
      grad_gnorm: 1.6719499826431274
      policy_entropy: 382.7215576171875
      policy_loss: -0.05347330495715141
      var_gnorm: 42.411197662353516
      vf_explained_var: 0.9851886630058289
      vf_loss: 0.00044715276453644037
    num_steps_sampled: 5180000
    num_steps_trained: 5180000
    wait_time_ms: 347.905
  iterations_since_restore: 259
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 9046.467761039734
  time_this_iter_s: 34.403424978256226
  time_total_s: 9046.467761039734
  timestamp: 1594146721
  timesteps_since_restore: 5180000
  timesteps_this_iter: 20000
  timesteps_total: 5180000
  training_iteration: 259
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 9046 s, 259 iter, 5180000 ts, 557 rew

agent-1: 18.0
agent-2: 34.0
agent-3: 24.0
agent-4: 21.0
agent-5: 37.0
agent-6: 25.0
agent-7: 29.0
agent-8: 32.0
agent-9: 37.0
agent-10: 30.0
agent-11: 28.0
agent-12: 21.0
agent-13: 33.0
agent-14: 11.0
agent-15: 23.0
agent-16: 27.0
agent-17: 15.0
agent-18: 21.0
agent-19: 41.0
agent-20: 27.0
Sum Reward: 534.0
Avg Reward: 26.7
Min Reward: 11.0
Max Reward: 41.0
Gini Coefficient: 0.16029962546816479
20:20 Ratio: 2.292307692307692
Max-min Ratio: 3.727272727272727
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-32-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 556.87
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 259
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.754
    dispatch_time_ms: 5.681
    learner:
      cur_lr: 0.0010150120360776782
      grad_gnorm: 2.8908331394195557
      policy_entropy: 387.325927734375
      policy_loss: -0.4053918421268463
      var_gnorm: 42.39564895629883
      vf_explained_var: 0.9844211339950562
      vf_loss: 0.001737835700623691
    num_steps_sampled: 5200000
    num_steps_trained: 5200000
    wait_time_ms: 294.415
  iterations_since_restore: 260
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 9081.31839632988
  time_this_iter_s: 34.850635290145874
  time_total_s: 9081.31839632988
  timestamp: 1594146756
  timesteps_since_restore: 5200000
  timesteps_this_iter: 20000
  timesteps_total: 5200000
  training_iteration: 260
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 9081 s, 260 iter, 5200000 ts, 557 rew

agent-1: 27.0
agent-2: 32.0
agent-3: 35.0
agent-4: 16.0
agent-5: 33.0
agent-6: 36.0
agent-7: 22.0
agent-8: 21.0
agent-9: 28.0
agent-10: 23.0
agent-11: 31.0
agent-12: 24.0
agent-13: 13.0
agent-14: 21.0
agent-15: 23.0
agent-16: 9.0
agent-17: 21.0
agent-18: 32.0
agent-19: 18.0
agent-20: 22.0
Sum Reward: 487.0
Avg Reward: 24.35
Min Reward: 9.0
Max Reward: 36.0
Gini Coefficient: 0.1658110882956879
20:20 Ratio: 2.4285714285714284
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-33-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 556.49
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 260
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.734
    dispatch_time_ms: 6.496
    learner:
      cur_lr: 0.0010136800119653344
      grad_gnorm: 2.016907215118408
      policy_entropy: 358.47943115234375
      policy_loss: -1.6202855110168457
      var_gnorm: 42.584346771240234
      vf_explained_var: 0.49817711114883423
      vf_loss: 0.007677307818084955
    num_steps_sampled: 5220000
    num_steps_trained: 5220000
    wait_time_ms: 343.286
  iterations_since_restore: 261
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 9115.675763130188
  time_this_iter_s: 34.35736680030823
  time_total_s: 9115.675763130188
  timestamp: 1594146791
  timesteps_since_restore: 5220000
  timesteps_this_iter: 20000
  timesteps_total: 5220000
  training_iteration: 261
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 9115 s, 261 iter, 5220000 ts, 556 rew

agent-1: 35.0
agent-2: 15.0
agent-3: 34.0
agent-4: 27.0
agent-5: 20.0
agent-6: 33.0
agent-7: 33.0
agent-8: 30.0
agent-9: 37.0
agent-10: 29.0
agent-11: 29.0
agent-12: 23.0
agent-13: 37.0
agent-14: 26.0
agent-15: 26.0
agent-16: 27.0
agent-17: 27.0
agent-18: 39.0
agent-19: 15.0
agent-20: 33.0
Sum Reward: 575.0
Avg Reward: 28.75
Min Reward: 15.0
Max Reward: 39.0
Gini Coefficient: 0.12808695652173913
20:20 Ratio: 2.0273972602739727
Max-min Ratio: 2.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-33-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 556.54
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 261
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.522
    dispatch_time_ms: 6.052
    learner:
      cur_lr: 0.0010123479878529906
      grad_gnorm: 1.805249571800232
      policy_entropy: 376.8489990234375
      policy_loss: -1.202961802482605
      var_gnorm: 42.59111404418945
      vf_explained_var: 0.9781565070152283
      vf_loss: 0.0010346469935029745
    num_steps_sampled: 5240000
    num_steps_trained: 5240000
    wait_time_ms: 352.034
  iterations_since_restore: 262
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 9150.959408283234
  time_this_iter_s: 35.283645153045654
  time_total_s: 9150.959408283234
  timestamp: 1594146826
  timesteps_since_restore: 5240000
  timesteps_this_iter: 20000
  timesteps_total: 5240000
  training_iteration: 262
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 9150 s, 262 iter, 5240000 ts, 557 rew

agent-1: 22.0
agent-2: 16.0
agent-3: 34.0
agent-4: 27.0
agent-5: 29.0
agent-6: 33.0
agent-7: 32.0
agent-8: 28.0
agent-9: 33.0
agent-10: 23.0
agent-11: 25.0
agent-12: 26.0
agent-13: 31.0
agent-14: 34.0
agent-15: 47.0
agent-16: 25.0
agent-17: 14.0
agent-18: 18.0
agent-19: 22.0
agent-20: 33.0
Sum Reward: 552.0
Avg Reward: 27.6
Min Reward: 14.0
Max Reward: 47.0
Gini Coefficient: 0.1463768115942029
20:20 Ratio: 2.1142857142857143
Max-min Ratio: 3.357142857142857
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-34-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 556.68
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 262
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.141
    dispatch_time_ms: 25.587
    learner:
      cur_lr: 0.0010110159637406468
      grad_gnorm: 2.029311418533325
      policy_entropy: 311.12353515625
      policy_loss: 0.4825247824192047
      var_gnorm: 42.640869140625
      vf_explained_var: 0.9730166792869568
      vf_loss: 0.0012326269643381238
    num_steps_sampled: 5260000
    num_steps_trained: 5260000
    wait_time_ms: 340.373
  iterations_since_restore: 263
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 9186.538972377777
  time_this_iter_s: 35.57956409454346
  time_total_s: 9186.538972377777
  timestamp: 1594146862
  timesteps_since_restore: 5260000
  timesteps_this_iter: 20000
  timesteps_total: 5260000
  training_iteration: 263
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 9186 s, 263 iter, 5260000 ts, 557 rew

agent-1: 29.0
agent-2: 24.0
agent-3: 20.0
agent-4: 24.0
agent-5: 24.0
agent-6: 36.0
agent-7: 25.0
agent-8: 27.0
agent-9: 11.0
agent-10: 27.0
agent-11: 27.0
agent-12: 13.0
agent-13: 26.0
agent-14: 29.0
agent-15: 23.0
agent-16: 20.0
agent-17: 25.0
agent-18: 17.0
agent-19: 42.0
agent-20: 28.0
Sum Reward: 497.0
Avg Reward: 24.85
Min Reward: 11.0
Max Reward: 42.0
Gini Coefficient: 0.14517102615694166
20:20 Ratio: 2.2295081967213113
Max-min Ratio: 3.8181818181818183
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-34-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 556.28
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 263
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.904
    dispatch_time_ms: 24.308
    learner:
      cur_lr: 0.0010096840560436249
      grad_gnorm: 40.0
      policy_entropy: 16.976085662841797
      policy_loss: 30.07384490966797
      var_gnorm: 42.60483932495117
      vf_explained_var: 0.7920079231262207
      vf_loss: 461.96282958984375
    num_steps_sampled: 5280000
    num_steps_trained: 5280000
    wait_time_ms: 320.397
  iterations_since_restore: 264
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 9223.078609466553
  time_this_iter_s: 36.539637088775635
  time_total_s: 9223.078609466553
  timestamp: 1594146898
  timesteps_since_restore: 5280000
  timesteps_this_iter: 20000
  timesteps_total: 5280000
  training_iteration: 264
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 9223 s, 264 iter, 5280000 ts, 556 rew

agent-1: 18.0
agent-2: 21.0
agent-3: 26.0
agent-4: 35.0
agent-5: 37.0
agent-6: 34.0
agent-7: 51.0
agent-8: 30.0
agent-9: 40.0
agent-10: 19.0
agent-11: 15.0
agent-12: 24.0
agent-13: 41.0
agent-14: 31.0
agent-15: 37.0
agent-16: 12.0
agent-17: 27.0
agent-18: 32.0
agent-19: 28.0
agent-20: 24.0
Sum Reward: 582.0
Avg Reward: 29.1
Min Reward: 12.0
Max Reward: 51.0
Gini Coefficient: 0.18350515463917524
20:20 Ratio: 2.640625
Max-min Ratio: 4.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-35-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 556.75
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 264
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.706
    dispatch_time_ms: 21.661
    learner:
      cur_lr: 0.001008352031931281
      grad_gnorm: 1.333223581314087
      policy_entropy: 368.91119384765625
      policy_loss: -1.2293435335159302
      var_gnorm: 42.76039505004883
      vf_explained_var: 0.9879657030105591
      vf_loss: 0.00045210638199932873
    num_steps_sampled: 5300000
    num_steps_trained: 5300000
    wait_time_ms: 331.147
  iterations_since_restore: 265
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 9258.987360715866
  time_this_iter_s: 35.908751249313354
  time_total_s: 9258.987360715866
  timestamp: 1594146934
  timesteps_since_restore: 5300000
  timesteps_this_iter: 20000
  timesteps_total: 5300000
  training_iteration: 265
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 9258 s, 265 iter, 5300000 ts, 557 rew

agent-1: 34.0
agent-2: 41.0
agent-3: 20.0
agent-4: 35.0
agent-5: 25.0
agent-6: 15.0
agent-7: 25.0
agent-8: 30.0
agent-9: 38.0
agent-10: 24.0
agent-11: 23.0
agent-12: 33.0
agent-13: 28.0
agent-14: 40.0
agent-15: 31.0
agent-16: 34.0
agent-17: 18.0
agent-18: 23.0
agent-19: 39.0
agent-20: 18.0
Sum Reward: 574.0
Avg Reward: 28.7
Min Reward: 15.0
Max Reward: 41.0
Gini Coefficient: 0.1548780487804878
20:20 Ratio: 2.2253521126760565
Max-min Ratio: 2.7333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-36-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 557.08
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 265
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.495
    dispatch_time_ms: 5.358
    learner:
      cur_lr: 0.0010070200078189373
      grad_gnorm: 1.4244292974472046
      policy_entropy: 382.02459716796875
      policy_loss: -1.0789763927459717
      var_gnorm: 42.78215026855469
      vf_explained_var: 0.9745678901672363
      vf_loss: 0.000632922281511128
    num_steps_sampled: 5320000
    num_steps_trained: 5320000
    wait_time_ms: 311.443
  iterations_since_restore: 266
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 9293.9332447052
  time_this_iter_s: 34.945883989334106
  time_total_s: 9293.9332447052
  timestamp: 1594146969
  timesteps_since_restore: 5320000
  timesteps_this_iter: 20000
  timesteps_total: 5320000
  training_iteration: 266
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 9293 s, 266 iter, 5320000 ts, 557 rew

agent-1: 46.0
agent-2: 24.0
agent-3: 28.0
agent-4: 28.0
agent-5: 47.0
agent-6: 32.0
agent-7: 15.0
agent-8: 45.0
agent-9: 5.0
agent-10: 35.0
agent-11: 50.0
agent-12: 17.0
agent-13: 35.0
agent-14: 32.0
agent-15: 25.0
agent-16: 31.0
agent-17: 29.0
agent-18: 26.0
agent-19: 26.0
agent-20: 26.0
Sum Reward: 602.0
Avg Reward: 30.1
Min Reward: 5.0
Max Reward: 50.0
Gini Coefficient: 0.19767441860465115
20:20 Ratio: 3.081967213114754
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-36-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 557.83
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 266
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.701
    dispatch_time_ms: 6.011
    learner:
      cur_lr: 0.0010056879837065935
      grad_gnorm: 0.6605342626571655
      policy_entropy: 363.63006591796875
      policy_loss: -0.9371107220649719
      var_gnorm: 42.878265380859375
      vf_explained_var: 0.9907410144805908
      vf_loss: 2.0347386453067884e-05
    num_steps_sampled: 5340000
    num_steps_trained: 5340000
    wait_time_ms: 351.432
  iterations_since_restore: 267
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 9328.368969202042
  time_this_iter_s: 34.43572449684143
  time_total_s: 9328.368969202042
  timestamp: 1594147004
  timesteps_since_restore: 5340000
  timesteps_this_iter: 20000
  timesteps_total: 5340000
  training_iteration: 267
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 9328 s, 267 iter, 5340000 ts, 558 rew

agent-1: 33.0
agent-2: 23.0
agent-3: 28.0
agent-4: 36.0
agent-5: 23.0
agent-6: 28.0
agent-7: 19.0
agent-8: 12.0
agent-9: 41.0
agent-10: 27.0
agent-11: 25.0
agent-12: 37.0
agent-13: 37.0
agent-14: 28.0
agent-15: 35.0
agent-16: 25.0
agent-17: 30.0
agent-18: 32.0
agent-19: 43.0
agent-20: 12.0
Sum Reward: 574.0
Avg Reward: 28.7
Min Reward: 12.0
Max Reward: 43.0
Gini Coefficient: 0.16149825783972124
20:20 Ratio: 2.393939393939394
Max-min Ratio: 3.5833333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-37-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 558.09
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 267
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.094
    dispatch_time_ms: 6.079
    learner:
      cur_lr: 0.0010043559595942497
      grad_gnorm: 0.41724997758865356
      policy_entropy: 366.53509521484375
      policy_loss: 0.43211859464645386
      var_gnorm: 42.894657135009766
      vf_explained_var: 0.9865994453430176
      vf_loss: 4.456416718312539e-05
    num_steps_sampled: 5360000
    num_steps_trained: 5360000
    wait_time_ms: 347.24
  iterations_since_restore: 268
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 9360.225108623505
  time_this_iter_s: 31.856139421463013
  time_total_s: 9360.225108623505
  timestamp: 1594147039
  timesteps_since_restore: 5360000
  timesteps_this_iter: 20000
  timesteps_total: 5360000
  training_iteration: 268
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 9360 s, 268 iter, 5360000 ts, 558 rew

agent-1: 33.0
agent-2: 28.0
agent-3: 19.0
agent-4: 29.0
agent-5: 30.0
agent-6: 27.0
agent-7: 24.0
agent-8: 25.0
agent-9: 27.0
agent-10: 38.0
agent-11: 19.0
agent-12: 32.0
agent-13: 12.0
agent-14: 32.0
agent-15: 33.0
agent-16: 35.0
agent-17: 29.0
agent-18: 11.0
agent-19: 28.0
agent-20: 11.0
Sum Reward: 522.0
Avg Reward: 26.1
Min Reward: 11.0
Max Reward: 38.0
Gini Coefficient: 0.16130268199233716
20:20 Ratio: 2.6226415094339623
Max-min Ratio: 3.4545454545454546
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-37-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 558.01
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 268
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.539
    dispatch_time_ms: 5.456
    learner:
      cur_lr: 0.0010030240518972278
      grad_gnorm: 2.658243179321289
      policy_entropy: 337.18212890625
      policy_loss: -1.980660080909729
      var_gnorm: 42.91477966308594
      vf_explained_var: 0.02149146795272827
      vf_loss: 0.001933525432832539
    num_steps_sampled: 5380000
    num_steps_trained: 5380000
    wait_time_ms: 357.239
  iterations_since_restore: 269
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 9395.640057086945
  time_this_iter_s: 35.41494846343994
  time_total_s: 9395.640057086945
  timestamp: 1594147075
  timesteps_since_restore: 5380000
  timesteps_this_iter: 20000
  timesteps_total: 5380000
  training_iteration: 269
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 9395 s, 269 iter, 5380000 ts, 558 rew

agent-1: 24.0
agent-2: 23.0
agent-3: 19.0
agent-4: 29.0
agent-5: 34.0
agent-6: 15.0
agent-7: 29.0
agent-8: 27.0
agent-9: 40.0
agent-10: 37.0
agent-11: 28.0
agent-12: 22.0
agent-13: 36.0
agent-14: 33.0
agent-15: 44.0
agent-16: 25.0
agent-17: 31.0
agent-18: 20.0
agent-19: 11.0
agent-20: 27.0
Sum Reward: 554.0
Avg Reward: 27.7
Min Reward: 11.0
Max Reward: 44.0
Gini Coefficient: 0.16498194945848377
20:20 Ratio: 2.4153846153846152
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-38-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 557.94
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 269
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.631
    dispatch_time_ms: 5.715
    learner:
      cur_lr: 0.001001692027784884
      grad_gnorm: 1.1434104442596436
      policy_entropy: 365.5983581542969
      policy_loss: -0.7320955991744995
      var_gnorm: 42.895469665527344
      vf_explained_var: 0.14013910293579102
      vf_loss: 0.00039454895886592567
    num_steps_sampled: 5400000
    num_steps_trained: 5400000
    wait_time_ms: 344.204
  iterations_since_restore: 270
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 9430.37532901764
  time_this_iter_s: 34.73527193069458
  time_total_s: 9430.37532901764
  timestamp: 1594147109
  timesteps_since_restore: 5400000
  timesteps_this_iter: 20000
  timesteps_total: 5400000
  training_iteration: 270
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 9430 s, 270 iter, 5400000 ts, 558 rew

agent-1: 23.0
agent-2: 30.0
agent-3: 23.0
agent-4: 36.0
agent-5: 20.0
agent-6: 32.0
agent-7: 34.0
agent-8: 34.0
agent-9: 17.0
agent-10: 26.0
agent-11: 29.0
agent-12: 11.0
agent-13: 23.0
agent-14: 38.0
agent-15: 25.0
agent-16: 12.0
agent-17: 31.0
agent-18: 20.0
agent-19: 31.0
agent-20: 31.0
Sum Reward: 526.0
Avg Reward: 26.3
Min Reward: 11.0
Max Reward: 38.0
Gini Coefficient: 0.15931558935361217
20:20 Ratio: 2.3666666666666667
Max-min Ratio: 3.4545454545454546
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-39-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 557.83
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 270
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.614
    dispatch_time_ms: 6.062
    learner:
      cur_lr: 0.0010003600036725402
      grad_gnorm: 1.261489987373352
      policy_entropy: 382.6937255859375
      policy_loss: 0.44189977645874023
      var_gnorm: 42.98356246948242
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.026358554139733315
    num_steps_sampled: 5420000
    num_steps_trained: 5420000
    wait_time_ms: 345.8
  iterations_since_restore: 271
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 9464.946372032166
  time_this_iter_s: 34.57104301452637
  time_total_s: 9464.946372032166
  timestamp: 1594147144
  timesteps_since_restore: 5420000
  timesteps_this_iter: 20000
  timesteps_total: 5420000
  training_iteration: 271
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 9464 s, 271 iter, 5420000 ts, 558 rew

agent-1: 20.0
agent-2: 30.0
agent-3: 26.0
agent-4: 22.0
agent-5: 37.0
agent-6: 25.0
agent-7: 43.0
agent-8: 25.0
agent-9: 39.0
agent-10: 40.0
agent-11: 18.0
agent-12: 33.0
agent-13: 15.0
agent-14: 27.0
agent-15: 26.0
agent-16: 24.0
agent-17: 35.0
agent-18: 28.0
agent-19: 16.0
agent-20: 34.0
Sum Reward: 563.0
Avg Reward: 28.15
Min Reward: 15.0
Max Reward: 43.0
Gini Coefficient: 0.15959147424511547
20:20 Ratio: 2.3043478260869565
Max-min Ratio: 2.8666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-39-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 672.0
  episode_reward_mean: 558.11
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 271
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 4.255
    dispatch_time_ms: 6.213
    learner:
      cur_lr: 0.0009990279795601964
      grad_gnorm: 3.2596230506896973
      policy_entropy: 381.465576171875
      policy_loss: -1.7462599277496338
      var_gnorm: 42.95861053466797
      vf_explained_var: 0.09722566604614258
      vf_loss: 0.0033657115418463945
    num_steps_sampled: 5440000
    num_steps_trained: 5440000
    wait_time_ms: 327.596
  iterations_since_restore: 272
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 9499.404418945312
  time_this_iter_s: 34.45804691314697
  time_total_s: 9499.404418945312
  timestamp: 1594147179
  timesteps_since_restore: 5440000
  timesteps_this_iter: 20000
  timesteps_total: 5440000
  training_iteration: 272
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 9499 s, 272 iter, 5440000 ts, 558 rew

agent-1: 19.0
agent-2: 31.0
agent-3: 27.0
agent-4: 40.0
agent-5: 25.0
agent-6: 20.0
agent-7: 35.0
agent-8: 36.0
agent-9: 9.0
agent-10: 33.0
agent-11: 22.0
agent-12: 15.0
agent-13: 37.0
agent-14: 26.0
agent-15: 28.0
agent-16: 27.0
agent-17: 31.0
agent-18: 35.0
agent-19: 18.0
agent-20: 24.0
Sum Reward: 538.0
Avg Reward: 26.9
Min Reward: 9.0
Max Reward: 40.0
Gini Coefficient: 0.16635687732342008
20:20 Ratio: 2.4262295081967213
Max-min Ratio: 4.444444444444445
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-40-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 654.0
  episode_reward_mean: 556.77
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 272
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.632
    dispatch_time_ms: 7.008
    learner:
      cur_lr: 0.0009976959554478526
      grad_gnorm: 2.111351728439331
      policy_entropy: 370.9180908203125
      policy_loss: 1.00452721118927
      var_gnorm: 43.09201431274414
      vf_explained_var: 0.019945263862609863
      vf_loss: 0.008062675595283508
    num_steps_sampled: 5460000
    num_steps_trained: 5460000
    wait_time_ms: 342.935
  iterations_since_restore: 273
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 9533.980954170227
  time_this_iter_s: 34.57653522491455
  time_total_s: 9533.980954170227
  timestamp: 1594147213
  timesteps_since_restore: 5460000
  timesteps_this_iter: 20000
  timesteps_total: 5460000
  training_iteration: 273
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 9533 s, 273 iter, 5460000 ts, 557 rew

agent-1: 42.0
agent-2: 33.0
agent-3: 42.0
agent-4: 37.0
agent-5: 22.0
agent-6: 34.0
agent-7: 40.0
agent-8: 24.0
agent-9: 23.0
agent-10: 30.0
agent-11: 44.0
agent-12: 27.0
agent-13: 24.0
agent-14: 37.0
agent-15: 34.0
agent-16: 35.0
agent-17: 23.0
agent-18: 38.0
agent-19: 25.0
agent-20: 42.0
Sum Reward: 656.0
Avg Reward: 32.8
Min Reward: 22.0
Max Reward: 44.0
Gini Coefficient: 0.12682926829268293
20:20 Ratio: 1.8478260869565217
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-40-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 556.79
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 273
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.712
    dispatch_time_ms: 6.287
    learner:
      cur_lr: 0.0009963640477508307
      grad_gnorm: 1.2286038398742676
      policy_entropy: 382.9532470703125
      policy_loss: -0.2728835344314575
      var_gnorm: 43.07933044433594
      vf_explained_var: 0.8231210708618164
      vf_loss: 0.0004851685662288219
    num_steps_sampled: 5480000
    num_steps_trained: 5480000
    wait_time_ms: 345.801
  iterations_since_restore: 274
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 9568.485328912735
  time_this_iter_s: 34.504374742507935
  time_total_s: 9568.485328912735
  timestamp: 1594147248
  timesteps_since_restore: 5480000
  timesteps_this_iter: 20000
  timesteps_total: 5480000
  training_iteration: 274
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 9568 s, 274 iter, 5480000 ts, 557 rew

agent-1: 29.0
agent-2: 20.0
agent-3: 39.0
agent-4: 40.0
agent-5: 29.0
agent-6: 28.0
agent-7: 33.0
agent-8: 16.0
agent-9: 44.0
agent-10: 29.0
agent-11: 22.0
agent-12: 32.0
agent-13: 37.0
agent-14: 29.0
agent-15: 53.0
agent-16: 32.0
agent-17: 18.0
agent-18: 21.0
agent-19: 24.0
agent-20: 15.0
Sum Reward: 590.0
Avg Reward: 29.5
Min Reward: 15.0
Max Reward: 53.0
Gini Coefficient: 0.18016949152542372
20:20 Ratio: 2.550724637681159
Max-min Ratio: 3.533333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-41-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 556.21
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 274
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.275
    dispatch_time_ms: 9.335
    learner:
      cur_lr: 0.0009950320236384869
      grad_gnorm: 3.3220696449279785
      policy_entropy: 382.0830993652344
      policy_loss: -1.4743435382843018
      var_gnorm: 43.13333511352539
      vf_explained_var: -1.0
      vf_loss: 0.0445265956223011
    num_steps_sampled: 5500000
    num_steps_trained: 5500000
    wait_time_ms: 345.297
  iterations_since_restore: 275
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 9602.785416126251
  time_this_iter_s: 34.300087213516235
  time_total_s: 9602.785416126251
  timestamp: 1594147282
  timesteps_since_restore: 5500000
  timesteps_this_iter: 20000
  timesteps_total: 5500000
  training_iteration: 275
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 9602 s, 275 iter, 5500000 ts, 556 rew

agent-1: 18.0
agent-2: 23.0
agent-3: 29.0
agent-4: 13.0
agent-5: 30.0
agent-6: 34.0
agent-7: 26.0
agent-8: 39.0
agent-9: 23.0
agent-10: 18.0
agent-11: 34.0
agent-12: 38.0
agent-13: 24.0
agent-14: 22.0
agent-15: 28.0
agent-16: 17.0
agent-17: 42.0
agent-18: 32.0
agent-19: 27.0
agent-20: 17.0
Sum Reward: 534.0
Avg Reward: 26.7
Min Reward: 13.0
Max Reward: 42.0
Gini Coefficient: 0.1691011235955056
20:20 Ratio: 2.353846153846154
Max-min Ratio: 3.230769230769231
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-41-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 555.42
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 275
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.562
    dispatch_time_ms: 7.266
    learner:
      cur_lr: 0.000993699999526143
      grad_gnorm: 39.99999237060547
      policy_entropy: 80.084228515625
      policy_loss: 14.474478721618652
      var_gnorm: 43.15379333496094
      vf_explained_var: 0.7085285186767578
      vf_loss: 80.74653625488281
    num_steps_sampled: 5520000
    num_steps_trained: 5520000
    wait_time_ms: 333.539
  iterations_since_restore: 276
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 9637.508103847504
  time_this_iter_s: 34.72268772125244
  time_total_s: 9637.508103847504
  timestamp: 1594147317
  timesteps_since_restore: 5520000
  timesteps_this_iter: 20000
  timesteps_total: 5520000
  training_iteration: 276
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 9637 s, 276 iter, 5520000 ts, 555 rew

agent-1: 19.0
agent-2: 33.0
agent-3: 38.0
agent-4: 19.0
agent-5: 17.0
agent-6: 32.0
agent-7: 22.0
agent-8: 26.0
agent-9: 36.0
agent-10: 30.0
agent-11: 31.0
agent-12: 25.0
agent-13: 27.0
agent-14: 22.0
agent-15: 26.0
agent-16: 21.0
agent-17: 32.0
agent-18: 24.0
agent-19: 27.0
agent-20: 22.0
Sum Reward: 529.0
Avg Reward: 26.45
Min Reward: 17.0
Max Reward: 38.0
Gini Coefficient: 0.12372400756143667
20:20 Ratio: 1.8289473684210527
Max-min Ratio: 2.235294117647059
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-42-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 554.4
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 276
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.761
    dispatch_time_ms: 16.038
    learner:
      cur_lr: 0.0009923679754137993
      grad_gnorm: 0.3453325927257538
      policy_entropy: 376.7443542480469
      policy_loss: 0.7450449466705322
      var_gnorm: 43.187374114990234
      vf_explained_var: 0.9947758913040161
      vf_loss: 1.4164666026772466e-06
    num_steps_sampled: 5540000
    num_steps_trained: 5540000
    wait_time_ms: 338.094
  iterations_since_restore: 277
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 9672.54685163498
  time_this_iter_s: 35.038747787475586
  time_total_s: 9672.54685163498
  timestamp: 1594147352
  timesteps_since_restore: 5540000
  timesteps_this_iter: 20000
  timesteps_total: 5540000
  training_iteration: 277
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 9672 s, 277 iter, 5540000 ts, 554 rew

agent-1: 31.0
agent-2: 32.0
agent-3: 35.0
agent-4: 15.0
agent-5: 21.0
agent-6: 34.0
agent-7: 14.0
agent-8: 36.0
agent-9: 39.0
agent-10: 23.0
agent-11: 21.0
agent-12: 28.0
agent-13: 29.0
agent-14: 47.0
agent-15: 28.0
agent-16: 26.0
agent-17: 30.0
agent-18: 44.0
agent-19: 28.0
agent-20: 34.0
Sum Reward: 595.0
Avg Reward: 29.75
Min Reward: 14.0
Max Reward: 47.0
Gini Coefficient: 0.15638655462184875
20:20 Ratio: 2.3380281690140845
Max-min Ratio: 3.357142857142857
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-43-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 554.28
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 277
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.783
    dispatch_time_ms: 27.114
    learner:
      cur_lr: 0.0009910359513014555
      grad_gnorm: 2.213491439819336
      policy_entropy: 386.51190185546875
      policy_loss: -1.351548671722412
      var_gnorm: 43.122684478759766
      vf_explained_var: 0.7741812467575073
      vf_loss: 0.0015137658920139074
    num_steps_sampled: 5560000
    num_steps_trained: 5560000
    wait_time_ms: 331.921
  iterations_since_restore: 278
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 9708.49825143814
  time_this_iter_s: 35.95139980316162
  time_total_s: 9708.49825143814
  timestamp: 1594147388
  timesteps_since_restore: 5560000
  timesteps_this_iter: 20000
  timesteps_total: 5560000
  training_iteration: 278
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 9708 s, 278 iter, 5560000 ts, 554 rew

agent-1: 28.0
agent-2: 33.0
agent-3: 28.0
agent-4: 18.0
agent-5: 20.0
agent-6: 36.0
agent-7: 40.0
agent-8: 11.0
agent-9: 25.0
agent-10: 25.0
agent-11: 37.0
agent-12: 36.0
agent-13: 12.0
agent-14: 34.0
agent-15: 14.0
agent-16: 29.0
agent-17: 29.0
agent-18: 38.0
agent-19: 37.0
agent-20: 32.0
Sum Reward: 562.0
Avg Reward: 28.1
Min Reward: 11.0
Max Reward: 40.0
Gini Coefficient: 0.17437722419928825
20:20 Ratio: 2.7636363636363637
Max-min Ratio: 3.6363636363636362
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-43-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 554.48
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 278
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.718
    dispatch_time_ms: 40.145
    learner:
      cur_lr: 0.0009897040436044335
      grad_gnorm: 1.1083452701568604
      policy_entropy: 377.13128662109375
      policy_loss: -2.7364461421966553
      var_gnorm: 43.20583724975586
      vf_explained_var: 0.9066051840782166
      vf_loss: 0.00026690392405726016
    num_steps_sampled: 5580000
    num_steps_trained: 5580000
    wait_time_ms: 331.812
  iterations_since_restore: 279
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 9744.92606472969
  time_this_iter_s: 36.42781329154968
  time_total_s: 9744.92606472969
  timestamp: 1594147424
  timesteps_since_restore: 5580000
  timesteps_this_iter: 20000
  timesteps_total: 5580000
  training_iteration: 279
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 9744 s, 279 iter, 5580000 ts, 554 rew

agent-1: 12.0
agent-2: 22.0
agent-3: 19.0
agent-4: 45.0
agent-5: 29.0
agent-6: 31.0
agent-7: 25.0
agent-8: 19.0
agent-9: 34.0
agent-10: 17.0
agent-11: 33.0
agent-12: 29.0
agent-13: 32.0
agent-14: 24.0
agent-15: 28.0
agent-16: 30.0
agent-17: 31.0
agent-18: 27.0
agent-19: 33.0
agent-20: 24.0
Sum Reward: 544.0
Avg Reward: 27.2
Min Reward: 12.0
Max Reward: 45.0
Gini Coefficient: 0.14356617647058822
20:20 Ratio: 2.1641791044776117
Max-min Ratio: 3.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-44-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 554.23
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 279
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.607
    dispatch_time_ms: 5.63
    learner:
      cur_lr: 0.0009883720194920897
      grad_gnorm: 1.4722591638565063
      policy_entropy: 387.206787109375
      policy_loss: 0.18745911121368408
      var_gnorm: 43.18360900878906
      vf_explained_var: 0.885100781917572
      vf_loss: 0.0006185912061482668
    num_steps_sampled: 5600000
    num_steps_trained: 5600000
    wait_time_ms: 345.123
  iterations_since_restore: 280
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 9780.839538097382
  time_this_iter_s: 35.91347336769104
  time_total_s: 9780.839538097382
  timestamp: 1594147460
  timesteps_since_restore: 5600000
  timesteps_this_iter: 20000
  timesteps_total: 5600000
  training_iteration: 280
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 9780 s, 280 iter, 5600000 ts, 554 rew

agent-1: 20.0
agent-2: 33.0
agent-3: 24.0
agent-4: 26.0
agent-5: 25.0
agent-6: 17.0
agent-7: 22.0
agent-8: 28.0
agent-9: 26.0
agent-10: 23.0
agent-11: 37.0
agent-12: 19.0
agent-13: 20.0
agent-14: 35.0
agent-15: 24.0
agent-16: 18.0
agent-17: 27.0
agent-18: 26.0
agent-19: 26.0
agent-20: 30.0
Sum Reward: 506.0
Avg Reward: 25.3
Min Reward: 17.0
Max Reward: 37.0
Gini Coefficient: 0.116600790513834
20:20 Ratio: 1.8243243243243243
Max-min Ratio: 2.176470588235294
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-44-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 553.75
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 280
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.688
    dispatch_time_ms: 5.556
    learner:
      cur_lr: 0.000987039995379746
      grad_gnorm: 9.96208667755127
      policy_entropy: 377.443603515625
      policy_loss: -5.014996528625488
      var_gnorm: 43.2837028503418
      vf_explained_var: 0.34326058626174927
      vf_loss: 0.030306339263916016
    num_steps_sampled: 5620000
    num_steps_trained: 5620000
    wait_time_ms: 350.714
  iterations_since_restore: 281
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 9815.412690639496
  time_this_iter_s: 34.57315254211426
  time_total_s: 9815.412690639496
  timestamp: 1594147495
  timesteps_since_restore: 5620000
  timesteps_this_iter: 20000
  timesteps_total: 5620000
  training_iteration: 281
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 9815 s, 281 iter, 5620000 ts, 554 rew

agent-1: 23.0
agent-2: 20.0
agent-3: 26.0
agent-4: 19.0
agent-5: 18.0
agent-6: 21.0
agent-7: 29.0
agent-8: 25.0
agent-9: 23.0
agent-10: 31.0
agent-11: 27.0
agent-12: 29.0
agent-13: 31.0
agent-14: 23.0
agent-15: 31.0
agent-16: 23.0
agent-17: 31.0
agent-18: 27.0
agent-19: 19.0
agent-20: 23.0
Sum Reward: 499.0
Avg Reward: 24.95
Min Reward: 18.0
Max Reward: 31.0
Gini Coefficient: 0.09769539078156313
20:20 Ratio: 1.631578947368421
Max-min Ratio: 1.7222222222222223
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-45-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 553.06
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 281
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.212
    dispatch_time_ms: 7.09
    learner:
      cur_lr: 0.0009857079712674022
      grad_gnorm: 14.621744155883789
      policy_entropy: 216.39422607421875
      policy_loss: 1.9534934759140015
      var_gnorm: 43.34999084472656
      vf_explained_var: 0.14525163173675537
      vf_loss: 2.024725914001465
    num_steps_sampled: 5640000
    num_steps_trained: 5640000
    wait_time_ms: 335.049
  iterations_since_restore: 282
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 9850.419520139694
  time_this_iter_s: 35.006829500198364
  time_total_s: 9850.419520139694
  timestamp: 1594147530
  timesteps_since_restore: 5640000
  timesteps_this_iter: 20000
  timesteps_total: 5640000
  training_iteration: 282
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 9850 s, 282 iter, 5640000 ts, 553 rew

agent-1: 25.0
agent-2: 21.0
agent-3: 23.0
agent-4: 23.0
agent-5: 38.0
agent-6: 23.0
agent-7: 32.0
agent-8: 35.0
agent-9: 27.0
agent-10: 28.0
agent-11: 30.0
agent-12: 30.0
agent-13: 25.0
agent-14: 24.0
agent-15: 21.0
agent-16: 23.0
agent-17: 29.0
agent-18: 25.0
agent-19: 36.0
agent-20: 17.0
Sum Reward: 535.0
Avg Reward: 26.75
Min Reward: 17.0
Max Reward: 38.0
Gini Coefficient: 0.1111214953271028
20:20 Ratio: 1.7195121951219512
Max-min Ratio: 2.235294117647059
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-46-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 552.27
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 282
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.431
    dispatch_time_ms: 8.572
    learner:
      cur_lr: 0.0009843759471550584
      grad_gnorm: 1.1971241235733032
      policy_entropy: 384.373779296875
      policy_loss: -0.4930017292499542
      var_gnorm: 43.4030876159668
      vf_explained_var: 0.9176458716392517
      vf_loss: 0.0004481250362005085
    num_steps_sampled: 5660000
    num_steps_trained: 5660000
    wait_time_ms: 337.127
  iterations_since_restore: 283
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 9885.45742225647
  time_this_iter_s: 35.03790211677551
  time_total_s: 9885.45742225647
  timestamp: 1594147565
  timesteps_since_restore: 5660000
  timesteps_this_iter: 20000
  timesteps_total: 5660000
  training_iteration: 283
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 9885 s, 283 iter, 5660000 ts, 552 rew

agent-1: 27.0
agent-2: 39.0
agent-3: 30.0
agent-4: 23.0
agent-5: 30.0
agent-6: 26.0
agent-7: 30.0
agent-8: 30.0
agent-9: 26.0
agent-10: 35.0
agent-11: 22.0
agent-12: 27.0
agent-13: 25.0
agent-14: 22.0
agent-15: 30.0
agent-16: 20.0
agent-17: 25.0
agent-18: 21.0
agent-19: 32.0
agent-20: 21.0
Sum Reward: 541.0
Avg Reward: 27.05
Min Reward: 20.0
Max Reward: 39.0
Gini Coefficient: 0.10009242144177449
20:20 Ratio: 1.619047619047619
Max-min Ratio: 1.95
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-46-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 551.8
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 283
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.473
    dispatch_time_ms: 5.462
    learner:
      cur_lr: 0.0009830440394580364
      grad_gnorm: 18.730247497558594
      policy_entropy: 223.46884155273438
      policy_loss: -6.00902795791626
      var_gnorm: 43.39317321777344
      vf_explained_var: 0.3031728267669678
      vf_loss: 0.2527063190937042
    num_steps_sampled: 5680000
    num_steps_trained: 5680000
    wait_time_ms: 339.734
  iterations_since_restore: 284
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 9919.897097349167
  time_this_iter_s: 34.439675092697144
  time_total_s: 9919.897097349167
  timestamp: 1594147599
  timesteps_since_restore: 5680000
  timesteps_this_iter: 20000
  timesteps_total: 5680000
  training_iteration: 284
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 9919 s, 284 iter, 5680000 ts, 552 rew

agent-1: 23.0
agent-2: 23.0
agent-3: 19.0
agent-4: 17.0
agent-5: 25.0
agent-6: 19.0
agent-7: 38.0
agent-8: 16.0
agent-9: 25.0
agent-10: 26.0
agent-11: 32.0
agent-12: 24.0
agent-13: 21.0
agent-14: 30.0
agent-15: 25.0
agent-16: 16.0
agent-17: 28.0
agent-18: 25.0
agent-19: 24.0
agent-20: 31.0
Sum Reward: 487.0
Avg Reward: 24.35
Min Reward: 16.0
Max Reward: 38.0
Gini Coefficient: 0.12474332648870637
20:20 Ratio: 1.9264705882352942
Max-min Ratio: 2.375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-47-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 550.54
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 284
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.77
    dispatch_time_ms: 5.672
    learner:
      cur_lr: 0.0009817120153456926
      grad_gnorm: 24.068941116333008
      policy_entropy: 378.279296875
      policy_loss: -0.3327237665653229
      var_gnorm: 43.43405532836914
      vf_explained_var: -1.0
      vf_loss: 0.03554962947964668
    num_steps_sampled: 5700000
    num_steps_trained: 5700000
    wait_time_ms: 353.47
  iterations_since_restore: 285
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 9954.676747322083
  time_this_iter_s: 34.77964997291565
  time_total_s: 9954.676747322083
  timestamp: 1594147634
  timesteps_since_restore: 5700000
  timesteps_this_iter: 20000
  timesteps_total: 5700000
  training_iteration: 285
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 9954 s, 285 iter, 5700000 ts, 551 rew

agent-1: 19.0
agent-2: 21.0
agent-3: 22.0
agent-4: 26.0
agent-5: 27.0
agent-6: 40.0
agent-7: 26.0
agent-8: 37.0
agent-9: 34.0
agent-10: 25.0
agent-11: 24.0
agent-12: 22.0
agent-13: 21.0
agent-14: 32.0
agent-15: 28.0
agent-16: 21.0
agent-17: 27.0
agent-18: 28.0
agent-19: 22.0
agent-20: 28.0
Sum Reward: 530.0
Avg Reward: 26.5
Min Reward: 19.0
Max Reward: 40.0
Gini Coefficient: 0.11245283018867924
20:20 Ratio: 1.7439024390243902
Max-min Ratio: 2.1052631578947367
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-47-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 550.17
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 285
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.065
    dispatch_time_ms: 6.634
    learner:
      cur_lr: 0.0009803799912333488
      grad_gnorm: 4.905594348907471
      policy_entropy: 382.9504089355469
      policy_loss: -2.5336008071899414
      var_gnorm: 43.492374420166016
      vf_explained_var: 0.8496373891830444
      vf_loss: 0.007655426859855652
    num_steps_sampled: 5720000
    num_steps_trained: 5720000
    wait_time_ms: 355.366
  iterations_since_restore: 286
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 9989.605705738068
  time_this_iter_s: 34.92895841598511
  time_total_s: 9989.605705738068
  timestamp: 1594147669
  timesteps_since_restore: 5720000
  timesteps_this_iter: 20000
  timesteps_total: 5720000
  training_iteration: 286
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 9989 s, 286 iter, 5720000 ts, 550 rew

agent-1: 17.0
agent-2: 21.0
agent-3: 17.0
agent-4: 23.0
agent-5: 23.0
agent-6: 19.0
agent-7: 28.0
agent-8: 31.0
agent-9: 21.0
agent-10: 20.0
agent-11: 32.0
agent-12: 38.0
agent-13: 28.0
agent-14: 35.0
agent-15: 27.0
agent-16: 24.0
agent-17: 26.0
agent-18: 26.0
agent-19: 27.0
agent-20: 19.0
Sum Reward: 502.0
Avg Reward: 25.1
Min Reward: 17.0
Max Reward: 38.0
Gini Coefficient: 0.12749003984063745
20:20 Ratio: 1.8888888888888888
Max-min Ratio: 2.235294117647059
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-48-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 548.82
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 286
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.577
    dispatch_time_ms: 5.342
    learner:
      cur_lr: 0.000979047967121005
      grad_gnorm: 30.905672073364258
      policy_entropy: 379.5647888183594
      policy_loss: 0.4584185481071472
      var_gnorm: 43.512672424316406
      vf_explained_var: 0.7622436881065369
      vf_loss: 0.0037137512117624283
    num_steps_sampled: 5740000
    num_steps_trained: 5740000
    wait_time_ms: 351.368
  iterations_since_restore: 287
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 10024.136613845825
  time_this_iter_s: 34.53090810775757
  time_total_s: 10024.136613845825
  timestamp: 1594147704
  timesteps_since_restore: 5740000
  timesteps_this_iter: 20000
  timesteps_total: 5740000
  training_iteration: 287
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 10024 s, 287 iter, 5740000 ts, 549 rew

agent-1: 31.0
agent-2: 31.0
agent-3: 42.0
agent-4: 26.0
agent-5: 26.0
agent-6: 23.0
agent-7: 23.0
agent-8: 28.0
agent-9: 26.0
agent-10: 24.0
agent-11: 24.0
agent-12: 21.0
agent-13: 27.0
agent-14: 23.0
agent-15: 35.0
agent-16: 32.0
agent-17: 27.0
agent-18: 22.0
agent-19: 24.0
agent-20: 24.0
Sum Reward: 539.0
Avg Reward: 26.95
Min Reward: 21.0
Max Reward: 42.0
Gini Coefficient: 0.0950834879406308
20:20 Ratio: 1.5730337078651686
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-49-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 548.35
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 287
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.708
    dispatch_time_ms: 21.369
    learner:
      cur_lr: 0.0009777159430086613
      grad_gnorm: 26.581457138061523
      policy_entropy: 272.6463928222656
      policy_loss: 3.691763401031494
      var_gnorm: 43.526588439941406
      vf_explained_var: 0.41414737701416016
      vf_loss: 5.635054588317871
    num_steps_sampled: 5760000
    num_steps_trained: 5760000
    wait_time_ms: 318.492
  iterations_since_restore: 288
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 10060.126375436783
  time_this_iter_s: 35.98976159095764
  time_total_s: 10060.126375436783
  timestamp: 1594147740
  timesteps_since_restore: 5760000
  timesteps_this_iter: 20000
  timesteps_total: 5760000
  training_iteration: 288
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 10060 s, 288 iter, 5760000 ts, 548 rew

agent-1: 27.0
agent-2: 29.0
agent-3: 34.0
agent-4: 28.0
agent-5: 21.0
agent-6: 38.0
agent-7: 21.0
agent-8: 27.0
agent-9: 22.0
agent-10: 38.0
agent-11: 28.0
agent-12: 23.0
agent-13: 28.0
agent-14: 20.0
agent-15: 28.0
agent-16: 32.0
agent-17: 19.0
agent-18: 27.0
agent-19: 33.0
agent-20: 33.0
Sum Reward: 556.0
Avg Reward: 27.8
Min Reward: 19.0
Max Reward: 38.0
Gini Coefficient: 0.11169064748201439
20:20 Ratio: 1.7654320987654322
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-49-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 548.22
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 288
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.903
    dispatch_time_ms: 33.371
    learner:
      cur_lr: 0.0009763839771039784
      grad_gnorm: 4.2471604347229
      policy_entropy: 283.323486328125
      policy_loss: 9.88762092590332
      var_gnorm: 43.64381790161133
      vf_explained_var: -1.0
      vf_loss: 0.010852005332708359
    num_steps_sampled: 5780000
    num_steps_trained: 5780000
    wait_time_ms: 336.416
  iterations_since_restore: 289
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 10096.107105731964
  time_this_iter_s: 35.980730295181274
  time_total_s: 10096.107105731964
  timestamp: 1594147776
  timesteps_since_restore: 5780000
  timesteps_this_iter: 20000
  timesteps_total: 5780000
  training_iteration: 289
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 10096 s, 289 iter, 5780000 ts, 548 rew

agent-1: 23.0
agent-2: 24.0
agent-3: 26.0
agent-4: 31.0
agent-5: 24.0
agent-6: 22.0
agent-7: 41.0
agent-8: 25.0
agent-9: 26.0
agent-10: 32.0
agent-11: 26.0
agent-12: 23.0
agent-13: 29.0
agent-14: 25.0
agent-15: 23.0
agent-16: 32.0
agent-17: 34.0
agent-18: 26.0
agent-19: 25.0
agent-20: 26.0
Sum Reward: 543.0
Avg Reward: 27.15
Min Reward: 22.0
Max Reward: 41.0
Gini Coefficient: 0.08627992633517495
20:20 Ratio: 1.5274725274725274
Max-min Ratio: 1.8636363636363635
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-50-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 547.71
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 289
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.637
    dispatch_time_ms: 25.866
    learner:
      cur_lr: 0.0009750520111992955
      grad_gnorm: 4.964785575866699
      policy_entropy: 365.23486328125
      policy_loss: -3.175739288330078
      var_gnorm: 43.70228958129883
      vf_explained_var: -1.0
      vf_loss: 0.1536465883255005
    num_steps_sampled: 5800000
    num_steps_trained: 5800000
    wait_time_ms: 334.11
  iterations_since_restore: 290
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 10131.981894493103
  time_this_iter_s: 35.874788761138916
  time_total_s: 10131.981894493103
  timestamp: 1594147812
  timesteps_since_restore: 5800000
  timesteps_this_iter: 20000
  timesteps_total: 5800000
  training_iteration: 290
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 10131 s, 290 iter, 5800000 ts, 548 rew

agent-1: 21.0
agent-2: 34.0
agent-3: 30.0
agent-4: 24.0
agent-5: 24.0
agent-6: 24.0
agent-7: 27.0
agent-8: 12.0
agent-9: 30.0
agent-10: 27.0
agent-11: 31.0
agent-12: 29.0
agent-13: 33.0
agent-14: 29.0
agent-15: 36.0
agent-16: 29.0
agent-17: 25.0
agent-18: 20.0
agent-19: 37.0
agent-20: 26.0
Sum Reward: 548.0
Avg Reward: 27.4
Min Reward: 12.0
Max Reward: 37.0
Gini Coefficient: 0.11386861313868613
20:20 Ratio: 1.8181818181818181
Max-min Ratio: 3.0833333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-50-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 547.37
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 290
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.481
    dispatch_time_ms: 5.985
    learner:
      cur_lr: 0.0009737199870869517
      grad_gnorm: 2.9413928985595703
      policy_entropy: 380.32476806640625
      policy_loss: 3.2154321670532227
      var_gnorm: 43.772918701171875
      vf_explained_var: 0.5824691653251648
      vf_loss: 0.002619901206344366
    num_steps_sampled: 5820000
    num_steps_trained: 5820000
    wait_time_ms: 331.586
  iterations_since_restore: 291
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 10166.77418756485
  time_this_iter_s: 34.792293071746826
  time_total_s: 10166.77418756485
  timestamp: 1594147847
  timesteps_since_restore: 5820000
  timesteps_this_iter: 20000
  timesteps_total: 5820000
  training_iteration: 291
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 10166 s, 291 iter, 5820000 ts, 547 rew

agent-1: 22.0
agent-2: 38.0
agent-3: 28.0
agent-4: 25.0
agent-5: 15.0
agent-6: 29.0
agent-7: 32.0
agent-8: 19.0
agent-9: 27.0
agent-10: 17.0
agent-11: 36.0
agent-12: 20.0
agent-13: 15.0
agent-14: 29.0
agent-15: 26.0
agent-16: 26.0
agent-17: 38.0
agent-18: 33.0
agent-19: 29.0
agent-20: 29.0
Sum Reward: 533.0
Avg Reward: 26.65
Min Reward: 15.0
Max Reward: 38.0
Gini Coefficient: 0.1447467166979362
20:20 Ratio: 2.196969696969697
Max-min Ratio: 2.533333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-51-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 546.82
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 291
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.135
    dispatch_time_ms: 6.464
    learner:
      cur_lr: 0.0009723880211822689
      grad_gnorm: 7.628276348114014
      policy_entropy: 254.50723266601562
      policy_loss: -3.167158842086792
      var_gnorm: 43.76395034790039
      vf_explained_var: 0.8431639671325684
      vf_loss: 0.060169465839862823
    num_steps_sampled: 5840000
    num_steps_trained: 5840000
    wait_time_ms: 330.348
  iterations_since_restore: 292
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 10201.298108816147
  time_this_iter_s: 34.523921251297
  time_total_s: 10201.298108816147
  timestamp: 1594147881
  timesteps_since_restore: 5840000
  timesteps_this_iter: 20000
  timesteps_total: 5840000
  training_iteration: 292
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 10201 s, 292 iter, 5840000 ts, 547 rew

agent-1: 30.0
agent-2: 39.0
agent-3: 30.0
agent-4: 30.0
agent-5: 25.0
agent-6: 23.0
agent-7: 29.0
agent-8: 22.0
agent-9: 22.0
agent-10: 26.0
agent-11: 26.0
agent-12: 31.0
agent-13: 31.0
agent-14: 28.0
agent-15: 25.0
agent-16: 27.0
agent-17: 22.0
agent-18: 34.0
agent-19: 19.0
agent-20: 36.0
Sum Reward: 555.0
Avg Reward: 27.75
Min Reward: 19.0
Max Reward: 39.0
Gini Coefficient: 0.10027027027027027
20:20 Ratio: 1.6470588235294117
Max-min Ratio: 2.0526315789473686
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-51-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 547.16
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 292
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.721
    dispatch_time_ms: 6.698
    learner:
      cur_lr: 0.0009710559970699251
      grad_gnorm: 3.211735486984253
      policy_entropy: 384.57427978515625
      policy_loss: -0.7208706140518188
      var_gnorm: 43.851043701171875
      vf_explained_var: 0.9094109535217285
      vf_loss: 0.0028002653270959854
    num_steps_sampled: 5860000
    num_steps_trained: 5860000
    wait_time_ms: 336.265
  iterations_since_restore: 293
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 10236.272847890854
  time_this_iter_s: 34.97473907470703
  time_total_s: 10236.272847890854
  timestamp: 1594147916
  timesteps_since_restore: 5860000
  timesteps_this_iter: 20000
  timesteps_total: 5860000
  training_iteration: 293
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 10236 s, 293 iter, 5860000 ts, 547 rew

agent-1: 30.0
agent-2: 25.0
agent-3: 22.0
agent-4: 26.0
agent-5: 19.0
agent-6: 23.0
agent-7: 26.0
agent-8: 15.0
agent-9: 22.0
agent-10: 41.0
agent-11: 22.0
agent-12: 34.0
agent-13: 26.0
agent-14: 22.0
agent-15: 33.0
agent-16: 35.0
agent-17: 22.0
agent-18: 29.0
agent-19: 29.0
agent-20: 38.0
Sum Reward: 539.0
Avg Reward: 26.95
Min Reward: 15.0
Max Reward: 41.0
Gini Coefficient: 0.13385899814471244
20:20 Ratio: 1.8974358974358974
Max-min Ratio: 2.7333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-52-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 547.44
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 293
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.467
    dispatch_time_ms: 7.541
    learner:
      cur_lr: 0.0009697239729575813
      grad_gnorm: 12.28818130493164
      policy_entropy: 229.94906616210938
      policy_loss: -3.6564676761627197
      var_gnorm: 43.917362213134766
      vf_explained_var: 0.9658067226409912
      vf_loss: 0.1863764524459839
    num_steps_sampled: 5880000
    num_steps_trained: 5880000
    wait_time_ms: 338.092
  iterations_since_restore: 294
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 10270.8636636734
  time_this_iter_s: 34.590815782547
  time_total_s: 10270.8636636734
  timestamp: 1594147951
  timesteps_since_restore: 5880000
  timesteps_this_iter: 20000
  timesteps_total: 5880000
  training_iteration: 294
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 10270 s, 294 iter, 5880000 ts, 547 rew

agent-1: 19.0
agent-2: 27.0
agent-3: 22.0
agent-4: 34.0
agent-5: 22.0
agent-6: 30.0
agent-7: 24.0
agent-8: 21.0
agent-9: 31.0
agent-10: 28.0
agent-11: 26.0
agent-12: 29.0
agent-13: 25.0
agent-14: 24.0
agent-15: 30.0
agent-16: 30.0
agent-17: 38.0
agent-18: 22.0
agent-19: 28.0
agent-20: 41.0
Sum Reward: 551.0
Avg Reward: 27.55
Min Reward: 19.0
Max Reward: 41.0
Gini Coefficient: 0.11025408348457351
20:20 Ratio: 1.7142857142857142
Max-min Ratio: 2.1578947368421053
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-53-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 547.23
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 294
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.036
    dispatch_time_ms: 5.909
    learner:
      cur_lr: 0.0009683920070528984
      grad_gnorm: 2.4047765731811523
      policy_entropy: 368.1630859375
      policy_loss: -2.599806308746338
      var_gnorm: 44.07413101196289
      vf_explained_var: -1.0
      vf_loss: 0.005169437732547522
    num_steps_sampled: 5900000
    num_steps_trained: 5900000
    wait_time_ms: 350.061
  iterations_since_restore: 295
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 10305.473586320877
  time_this_iter_s: 34.609922647476196
  time_total_s: 10305.473586320877
  timestamp: 1594147985
  timesteps_since_restore: 5900000
  timesteps_this_iter: 20000
  timesteps_total: 5900000
  training_iteration: 295
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 10305 s, 295 iter, 5900000 ts, 547 rew

agent-1: 24.0
agent-2: 42.0
agent-3: 31.0
agent-4: 33.0
agent-5: 18.0
agent-6: 33.0
agent-7: 40.0
agent-8: 30.0
agent-9: 30.0
agent-10: 22.0
agent-11: 14.0
agent-12: 29.0
agent-13: 26.0
agent-14: 41.0
agent-15: 23.0
agent-16: 14.0
agent-17: 29.0
agent-18: 39.0
agent-19: 30.0
agent-20: 34.0
Sum Reward: 582.0
Avg Reward: 29.1
Min Reward: 14.0
Max Reward: 42.0
Gini Coefficient: 0.15515463917525774
20:20 Ratio: 2.3823529411764706
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-53-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 547.57
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 295
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.658
    dispatch_time_ms: 6.884
    learner:
      cur_lr: 0.0009670599829405546
      grad_gnorm: 40.0
      policy_entropy: 275.37982177734375
      policy_loss: -25.03303337097168
      var_gnorm: 44.05550765991211
      vf_explained_var: 0.5995234847068787
      vf_loss: 6.7222466468811035
    num_steps_sampled: 5920000
    num_steps_trained: 5920000
    wait_time_ms: 342.465
  iterations_since_restore: 296
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 10339.985296726227
  time_this_iter_s: 34.51171040534973
  time_total_s: 10339.985296726227
  timestamp: 1594148020
  timesteps_since_restore: 5920000
  timesteps_this_iter: 20000
  timesteps_total: 5920000
  training_iteration: 296
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 10339 s, 296 iter, 5920000 ts, 548 rew

agent-1: 32.0
agent-2: 45.0
agent-3: 37.0
agent-4: 21.0
agent-5: 34.0
agent-6: 25.0
agent-7: 19.0
agent-8: 22.0
agent-9: 28.0
agent-10: 27.0
agent-11: 31.0
agent-12: 11.0
agent-13: 40.0
agent-14: 36.0
agent-15: 23.0
agent-16: 27.0
agent-17: 24.0
agent-18: 28.0
agent-19: 27.0
agent-20: 24.0
Sum Reward: 561.0
Avg Reward: 28.05
Min Reward: 11.0
Max Reward: 45.0
Gini Coefficient: 0.1501782531194296
20:20 Ratio: 2.164383561643836
Max-min Ratio: 4.090909090909091
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-54-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 547.41
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 296
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.994
    dispatch_time_ms: 5.75
    learner:
      cur_lr: 0.0009657280170358717
      grad_gnorm: 7.55051851272583
      policy_entropy: 340.88458251953125
      policy_loss: 7.170281410217285
      var_gnorm: 44.11304473876953
      vf_explained_var: 0.35271722078323364
      vf_loss: 0.017273975536227226
    num_steps_sampled: 5940000
    num_steps_trained: 5940000
    wait_time_ms: 340.619
  iterations_since_restore: 297
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 10374.6061065197
  time_this_iter_s: 34.62080979347229
  time_total_s: 10374.6061065197
  timestamp: 1594148055
  timesteps_since_restore: 5940000
  timesteps_this_iter: 20000
  timesteps_total: 5940000
  training_iteration: 297
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 10374 s, 297 iter, 5940000 ts, 547 rew

agent-1: 36.0
agent-2: 20.0
agent-3: 29.0
agent-4: 22.0
agent-5: 23.0
agent-6: 11.0
agent-7: 33.0
agent-8: 20.0
agent-9: 15.0
agent-10: 38.0
agent-11: 32.0
agent-12: 25.0
agent-13: 39.0
agent-14: 28.0
agent-15: 44.0
agent-16: 17.0
agent-17: 28.0
agent-18: 21.0
agent-19: 40.0
agent-20: 33.0
Sum Reward: 554.0
Avg Reward: 27.7
Min Reward: 11.0
Max Reward: 44.0
Gini Coefficient: 0.1835740072202166
20:20 Ratio: 2.5555555555555554
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-54-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 547.57
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 297
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.851
    dispatch_time_ms: 5.377
    learner:
      cur_lr: 0.000964395992923528
      grad_gnorm: 1.838931679725647
      policy_entropy: 360.75823974609375
      policy_loss: 0.08922004699707031
      var_gnorm: 44.13692855834961
      vf_explained_var: -0.9173617362976074
      vf_loss: 0.004592068959027529
    num_steps_sampled: 5960000
    num_steps_trained: 5960000
    wait_time_ms: 345.144
  iterations_since_restore: 298
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 10409.485174179077
  time_this_iter_s: 34.87906765937805
  time_total_s: 10409.485174179077
  timestamp: 1594148090
  timesteps_since_restore: 5960000
  timesteps_this_iter: 20000
  timesteps_total: 5960000
  training_iteration: 298
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 10409 s, 298 iter, 5960000 ts, 548 rew

agent-1: 27.0
agent-2: 30.0
agent-3: 33.0
agent-4: 22.0
agent-5: 26.0
agent-6: 19.0
agent-7: 25.0
agent-8: 34.0
agent-9: 23.0
agent-10: 20.0
agent-11: 19.0
agent-12: 22.0
agent-13: 21.0
agent-14: 24.0
agent-15: 35.0
agent-16: 33.0
agent-17: 34.0
agent-18: 27.0
agent-19: 29.0
agent-20: 33.0
Sum Reward: 536.0
Avg Reward: 26.8
Min Reward: 19.0
Max Reward: 35.0
Gini Coefficient: 0.11436567164179104
20:20 Ratio: 1.7215189873417722
Max-min Ratio: 1.8421052631578947
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-55-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 547.54
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 298
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.539
    dispatch_time_ms: 4.968
    learner:
      cur_lr: 0.0009630640270188451
      grad_gnorm: 4.946726322174072
      policy_entropy: 351.749267578125
      policy_loss: 3.8893048763275146
      var_gnorm: 44.186439514160156
      vf_explained_var: 0.36595577001571655
      vf_loss: 0.007190905977040529
    num_steps_sampled: 5980000
    num_steps_trained: 5980000
    wait_time_ms: 344.929
  iterations_since_restore: 299
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 10444.19261264801
  time_this_iter_s: 34.707438468933105
  time_total_s: 10444.19261264801
  timestamp: 1594148124
  timesteps_since_restore: 5980000
  timesteps_this_iter: 20000
  timesteps_total: 5980000
  training_iteration: 299
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 10444 s, 299 iter, 5980000 ts, 548 rew

agent-1: 32.0
agent-2: 25.0
agent-3: 33.0
agent-4: 28.0
agent-5: 42.0
agent-6: 22.0
agent-7: 25.0
agent-8: 16.0
agent-9: 21.0
agent-10: 26.0
agent-11: 29.0
agent-12: 29.0
agent-13: 29.0
agent-14: 31.0
agent-15: 20.0
agent-16: 30.0
agent-17: 28.0
agent-18: 32.0
agent-19: 26.0
agent-20: 30.0
Sum Reward: 554.0
Avg Reward: 27.7
Min Reward: 16.0
Max Reward: 42.0
Gini Coefficient: 0.10541516245487365
20:20 Ratio: 1.759493670886076
Max-min Ratio: 2.625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-55-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 547.64
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 299
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.419
    dispatch_time_ms: 5.124
    learner:
      cur_lr: 0.0009617320029065013
      grad_gnorm: 40.00000762939453
      policy_entropy: 249.28790283203125
      policy_loss: -16.048622131347656
      var_gnorm: 44.18763732910156
      vf_explained_var: 0.9036271572113037
      vf_loss: 4.550109386444092
    num_steps_sampled: 6000000
    num_steps_trained: 6000000
    wait_time_ms: 335.969
  iterations_since_restore: 300
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 10478.863594293594
  time_this_iter_s: 34.670981645584106
  time_total_s: 10478.863594293594
  timestamp: 1594148159
  timesteps_since_restore: 6000000
  timesteps_this_iter: 20000
  timesteps_total: 6000000
  training_iteration: 300
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 10478 s, 300 iter, 6000000 ts, 548 rew

agent-1: 26.0
agent-2: 24.0
agent-3: 26.0
agent-4: 47.0
agent-5: 29.0
agent-6: 32.0
agent-7: 33.0
agent-8: 30.0
agent-9: 23.0
agent-10: 27.0
agent-11: 28.0
agent-12: 17.0
agent-13: 31.0
agent-14: 29.0
agent-15: 17.0
agent-16: 25.0
agent-17: 29.0
agent-18: 36.0
agent-19: 35.0
agent-20: 25.0
Sum Reward: 569.0
Avg Reward: 28.45
Min Reward: 17.0
Max Reward: 47.0
Gini Coefficient: 0.12047451669595782
20:20 Ratio: 1.8641975308641976
Max-min Ratio: 2.764705882352941
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-56-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 547.9
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 300
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.495
    dispatch_time_ms: 5.335
    learner:
      cur_lr: 0.0009603999787941575
      grad_gnorm: 3.078033208847046
      policy_entropy: 382.7447509765625
      policy_loss: 2.3777503967285156
      var_gnorm: 44.2025032043457
      vf_explained_var: 0.004215717315673828
      vf_loss: 0.002658394630998373
    num_steps_sampled: 6020000
    num_steps_trained: 6020000
    wait_time_ms: 348.125
  iterations_since_restore: 301
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 10513.578913927078
  time_this_iter_s: 34.71531963348389
  time_total_s: 10513.578913927078
  timestamp: 1594148194
  timesteps_since_restore: 6020000
  timesteps_this_iter: 20000
  timesteps_total: 6020000
  training_iteration: 301
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 10513 s, 301 iter, 6020000 ts, 548 rew

agent-1: 24.0
agent-2: 29.0
agent-3: 29.0
agent-4: 27.0
agent-5: 30.0
agent-6: 35.0
agent-7: 28.0
agent-8: 26.0
agent-9: 26.0
agent-10: 30.0
agent-11: 35.0
agent-12: 21.0
agent-13: 35.0
agent-14: 30.0
agent-15: 23.0
agent-16: 37.0
agent-17: 34.0
agent-18: 20.0
agent-19: 22.0
agent-20: 37.0
Sum Reward: 578.0
Avg Reward: 28.9
Min Reward: 20.0
Max Reward: 37.0
Gini Coefficient: 0.1027681660899654
20:20 Ratio: 1.6744186046511629
Max-min Ratio: 1.85
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-57-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 547.45
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 301
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.846
    dispatch_time_ms: 18.607
    learner:
      cur_lr: 0.0009590680128894746
      grad_gnorm: 28.475767135620117
      policy_entropy: 351.677978515625
      policy_loss: 12.935833930969238
      var_gnorm: 44.23801803588867
      vf_explained_var: 0.33427995443344116
      vf_loss: 0.5032280087471008
    num_steps_sampled: 6040000
    num_steps_trained: 6040000
    wait_time_ms: 326.126
  iterations_since_restore: 302
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 10548.369146585464
  time_this_iter_s: 34.79023265838623
  time_total_s: 10548.369146585464
  timestamp: 1594148229
  timesteps_since_restore: 6040000
  timesteps_this_iter: 20000
  timesteps_total: 6040000
  training_iteration: 302
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 10548 s, 302 iter, 6040000 ts, 547 rew

agent-1: 20.0
agent-2: 31.0
agent-3: 30.0
agent-4: 33.0
agent-5: 33.0
agent-6: 28.0
agent-7: 28.0
agent-8: 23.0
agent-9: 35.0
agent-10: 28.0
agent-11: 29.0
agent-12: 31.0
agent-13: 22.0
agent-14: 27.0
agent-15: 25.0
agent-16: 13.0
agent-17: 22.0
agent-18: 23.0
agent-19: 24.0
agent-20: 21.0
Sum Reward: 526.0
Avg Reward: 26.3
Min Reward: 13.0
Max Reward: 35.0
Gini Coefficient: 0.1112167300380228
20:20 Ratio: 1.736842105263158
Max-min Ratio: 2.6923076923076925
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-57-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 547.32
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 302
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.478
    dispatch_time_ms: 8.894
    learner:
      cur_lr: 0.0009577359887771308
      grad_gnorm: 1.272917628288269
      policy_entropy: 388.63671875
      policy_loss: 0.5421974658966064
      var_gnorm: 44.22880554199219
      vf_explained_var: -1.0
      vf_loss: 0.004348726011812687
    num_steps_sampled: 6060000
    num_steps_trained: 6060000
    wait_time_ms: 335.16
  iterations_since_restore: 303
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 10584.18626332283
  time_this_iter_s: 35.81711673736572
  time_total_s: 10584.18626332283
  timestamp: 1594148265
  timesteps_since_restore: 6060000
  timesteps_this_iter: 20000
  timesteps_total: 6060000
  training_iteration: 303
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 10584 s, 303 iter, 6060000 ts, 547 rew

agent-1: 32.0
agent-2: 33.0
agent-3: 18.0
agent-4: 17.0
agent-5: 33.0
agent-6: 30.0
agent-7: 28.0
agent-8: 30.0
agent-9: 24.0
agent-10: 28.0
agent-11: 20.0
agent-12: 28.0
agent-13: 29.0
agent-14: 28.0
agent-15: 26.0
agent-16: 22.0
agent-17: 28.0
agent-18: 33.0
agent-19: 26.0
agent-20: 22.0
Sum Reward: 535.0
Avg Reward: 26.75
Min Reward: 17.0
Max Reward: 33.0
Gini Coefficient: 0.09878504672897197
20:20 Ratio: 1.7012987012987013
Max-min Ratio: 1.9411764705882353
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-58-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 547.51
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 303
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.457
    dispatch_time_ms: 6.795
    learner:
      cur_lr: 0.000956404022872448
      grad_gnorm: 1.8752206563949585
      policy_entropy: 388.06097412109375
      policy_loss: 0.6706179976463318
      var_gnorm: 44.25216293334961
      vf_explained_var: -1.0
      vf_loss: 0.004861731547862291
    num_steps_sampled: 6080000
    num_steps_trained: 6080000
    wait_time_ms: 354.898
  iterations_since_restore: 304
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 10618.595083713531
  time_this_iter_s: 34.408820390701294
  time_total_s: 10618.595083713531
  timestamp: 1594148299
  timesteps_since_restore: 6080000
  timesteps_this_iter: 20000
  timesteps_total: 6080000
  training_iteration: 304
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 10618 s, 304 iter, 6080000 ts, 548 rew

agent-1: 19.0
agent-2: 38.0
agent-3: 19.0
agent-4: 23.0
agent-5: 20.0
agent-6: 36.0
agent-7: 33.0
agent-8: 38.0
agent-9: 35.0
agent-10: 31.0
agent-11: 29.0
agent-12: 28.0
agent-13: 24.0
agent-14: 42.0
agent-15: 28.0
agent-16: 30.0
agent-17: 27.0
agent-18: 18.0
agent-19: 27.0
agent-20: 39.0
Sum Reward: 584.0
Avg Reward: 29.2
Min Reward: 18.0
Max Reward: 42.0
Gini Coefficient: 0.13921232876712328
20:20 Ratio: 2.0657894736842106
Max-min Ratio: 2.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-58-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 548.14
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 304
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.555
    dispatch_time_ms: 6.357
    learner:
      cur_lr: 0.0009550719987601042
      grad_gnorm: 9.827970504760742
      policy_entropy: 316.2672119140625
      policy_loss: -5.535406112670898
      var_gnorm: 44.29317092895508
      vf_explained_var: 0.4464606046676636
      vf_loss: 0.1661786437034607
    num_steps_sampled: 6100000
    num_steps_trained: 6100000
    wait_time_ms: 351.126
  iterations_since_restore: 305
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 10653.321944713593
  time_this_iter_s: 34.726861000061035
  time_total_s: 10653.321944713593
  timestamp: 1594148334
  timesteps_since_restore: 6100000
  timesteps_this_iter: 20000
  timesteps_total: 6100000
  training_iteration: 305
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 10653 s, 305 iter, 6100000 ts, 548 rew

agent-1: 27.0
agent-2: 30.0
agent-3: 24.0
agent-4: 29.0
agent-5: 34.0
agent-6: 24.0
agent-7: 28.0
agent-8: 41.0
agent-9: 38.0
agent-10: 24.0
agent-11: 28.0
agent-12: 34.0
agent-13: 18.0
agent-14: 24.0
agent-15: 27.0
agent-16: 28.0
agent-17: 43.0
agent-18: 29.0
agent-19: 29.0
agent-20: 18.0
Sum Reward: 577.0
Avg Reward: 28.85
Min Reward: 18.0
Max Reward: 43.0
Gini Coefficient: 0.12105719237435009
20:20 Ratio: 1.8571428571428572
Max-min Ratio: 2.388888888888889
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-59-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 548.6
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 305
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.482
    dispatch_time_ms: 5.716
    learner:
      cur_lr: 0.0009537399746477604
      grad_gnorm: 4.039909839630127
      policy_entropy: 338.49310302734375
      policy_loss: -1.113330364227295
      var_gnorm: 44.326961517333984
      vf_explained_var: 0.4785107970237732
      vf_loss: 0.05615852400660515
    num_steps_sampled: 6120000
    num_steps_trained: 6120000
    wait_time_ms: 336.98
  iterations_since_restore: 306
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 10687.724817752838
  time_this_iter_s: 34.402873039245605
  time_total_s: 10687.724817752838
  timestamp: 1594148368
  timesteps_since_restore: 6120000
  timesteps_this_iter: 20000
  timesteps_total: 6120000
  training_iteration: 306
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 10687 s, 306 iter, 6120000 ts, 549 rew

agent-1: 19.0
agent-2: 30.0
agent-3: 25.0
agent-4: 34.0
agent-5: 50.0
agent-6: 19.0
agent-7: 44.0
agent-8: 24.0
agent-9: 36.0
agent-10: 26.0
agent-11: 28.0
agent-12: 29.0
agent-13: 15.0
agent-14: 33.0
agent-15: 29.0
agent-16: 26.0
agent-17: 28.0
agent-18: 32.0
agent-19: 29.0
agent-20: 25.0
Sum Reward: 581.0
Avg Reward: 29.05
Min Reward: 15.0
Max Reward: 50.0
Gini Coefficient: 0.14397590361445783
20:20 Ratio: 2.1298701298701297
Max-min Ratio: 3.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-00-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 548.91
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 306
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.271
    dispatch_time_ms: 5.554
    learner:
      cur_lr: 0.0009524080087430775
      grad_gnorm: 1.213440179824829
      policy_entropy: 375.80499267578125
      policy_loss: 0.12328466773033142
      var_gnorm: 44.248924255371094
      vf_explained_var: -1.0
      vf_loss: 0.03221505135297775
    num_steps_sampled: 6140000
    num_steps_trained: 6140000
    wait_time_ms: 328.894
  iterations_since_restore: 307
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 10722.369534254074
  time_this_iter_s: 34.64471650123596
  time_total_s: 10722.369534254074
  timestamp: 1594148403
  timesteps_since_restore: 6140000
  timesteps_this_iter: 20000
  timesteps_total: 6140000
  training_iteration: 307
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 10722 s, 307 iter, 6140000 ts, 549 rew

agent-1: 35.0
agent-2: 18.0
agent-3: 30.0
agent-4: 20.0
agent-5: 40.0
agent-6: 23.0
agent-7: 25.0
agent-8: 31.0
agent-9: 29.0
agent-10: 33.0
agent-11: 28.0
agent-12: 32.0
agent-13: 22.0
agent-14: 29.0
agent-15: 36.0
agent-16: 18.0
agent-17: 23.0
agent-18: 21.0
agent-19: 24.0
agent-20: 16.0
Sum Reward: 533.0
Avg Reward: 26.65
Min Reward: 16.0
Max Reward: 40.0
Gini Coefficient: 0.13930581613508441
20:20 Ratio: 2.0
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-00-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 548.92
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 307
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.463
    dispatch_time_ms: 7.705
    learner:
      cur_lr: 0.0009510759846307337
      grad_gnorm: 2.1115610599517822
      policy_entropy: 215.92929077148438
      policy_loss: 0.9361398816108704
      var_gnorm: 44.37919998168945
      vf_explained_var: -1.0
      vf_loss: 0.012668066658079624
    num_steps_sampled: 6160000
    num_steps_trained: 6160000
    wait_time_ms: 353.32
  iterations_since_restore: 308
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 10756.900436639786
  time_this_iter_s: 34.53090238571167
  time_total_s: 10756.900436639786
  timestamp: 1594148438
  timesteps_since_restore: 6160000
  timesteps_this_iter: 20000
  timesteps_total: 6160000
  training_iteration: 308
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 10756 s, 308 iter, 6160000 ts, 549 rew

agent-1: 19.0
agent-2: 27.0
agent-3: 26.0
agent-4: 37.0
agent-5: 21.0
agent-6: 34.0
agent-7: 16.0
agent-8: 23.0
agent-9: 29.0
agent-10: 39.0
agent-11: 20.0
agent-12: 40.0
agent-13: 21.0
agent-14: 27.0
agent-15: 29.0
agent-16: 21.0
agent-17: 18.0
agent-18: 20.0
agent-19: 19.0
agent-20: 37.0
Sum Reward: 523.0
Avg Reward: 26.15
Min Reward: 16.0
Max Reward: 40.0
Gini Coefficient: 0.15860420650095602
20:20 Ratio: 2.125
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-01-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 549.15
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 308
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.604
    dispatch_time_ms: 6.613
    learner:
      cur_lr: 0.0009497440187260509
      grad_gnorm: 20.49468421936035
      policy_entropy: 370.3377685546875
      policy_loss: -2.0079307556152344
      var_gnorm: 44.46240997314453
      vf_explained_var: -1.0
      vf_loss: 0.014138933271169662
    num_steps_sampled: 6180000
    num_steps_trained: 6180000
    wait_time_ms: 341.823
  iterations_since_restore: 309
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 10791.241692304611
  time_this_iter_s: 34.34125566482544
  time_total_s: 10791.241692304611
  timestamp: 1594148472
  timesteps_since_restore: 6180000
  timesteps_this_iter: 20000
  timesteps_total: 6180000
  training_iteration: 309
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 10791 s, 309 iter, 6180000 ts, 549 rew

agent-1: 20.0
agent-2: 41.0
agent-3: 22.0
agent-4: 37.0
agent-5: 19.0
agent-6: 39.0
agent-7: 27.0
agent-8: 30.0
agent-9: 30.0
agent-10: 37.0
agent-11: 67.0
agent-12: 24.0
agent-13: 29.0
agent-14: 35.0
agent-15: 30.0
agent-16: 37.0
agent-17: 21.0
agent-18: 25.0
agent-19: 36.0
agent-20: 40.0
Sum Reward: 646.0
Avg Reward: 32.3
Min Reward: 19.0
Max Reward: 67.0
Gini Coefficient: 0.16609907120743034
20:20 Ratio: 2.2804878048780486
Max-min Ratio: 3.526315789473684
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-01-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 550.32
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 309
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.886
    dispatch_time_ms: 7.61
    learner:
      cur_lr: 0.0009484119946137071
      grad_gnorm: 3.352998971939087
      policy_entropy: 308.667236328125
      policy_loss: -1.266522765159607
      var_gnorm: 44.61021423339844
      vf_explained_var: -0.4406670331954956
      vf_loss: 0.27269247174263
    num_steps_sampled: 6200000
    num_steps_trained: 6200000
    wait_time_ms: 328.184
  iterations_since_restore: 310
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 10825.739731788635
  time_this_iter_s: 34.49803948402405
  time_total_s: 10825.739731788635
  timestamp: 1594148506
  timesteps_since_restore: 6200000
  timesteps_this_iter: 20000
  timesteps_total: 6200000
  training_iteration: 310
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 10825 s, 310 iter, 6200000 ts, 550 rew

agent-1: 29.0
agent-2: 23.0
agent-3: 26.0
agent-4: 27.0
agent-5: 33.0
agent-6: 28.0
agent-7: 41.0
agent-8: 40.0
agent-9: 29.0
agent-10: 20.0
agent-11: 26.0
agent-12: 31.0
agent-13: 33.0
agent-14: 32.0
agent-15: 29.0
agent-16: 30.0
agent-17: 25.0
agent-18: 17.0
agent-19: 21.0
agent-20: 33.0
Sum Reward: 573.0
Avg Reward: 28.65
Min Reward: 17.0
Max Reward: 41.0
Gini Coefficient: 0.11352530541012217
20:20 Ratio: 1.8148148148148149
Max-min Ratio: 2.411764705882353
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-02-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 550.58
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 310
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.022
    dispatch_time_ms: 4.512
    learner:
      cur_lr: 0.0009470800287090242
      grad_gnorm: 9.910805702209473
      policy_entropy: 341.8787841796875
      policy_loss: -5.242623329162598
      var_gnorm: 44.60197830200195
      vf_explained_var: -0.09384298324584961
      vf_loss: 0.20571115612983704
    num_steps_sampled: 6220000
    num_steps_trained: 6220000
    wait_time_ms: 350.281
  iterations_since_restore: 311
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 10860.531699180603
  time_this_iter_s: 34.79196739196777
  time_total_s: 10860.531699180603
  timestamp: 1594148541
  timesteps_since_restore: 6220000
  timesteps_this_iter: 20000
  timesteps_total: 6220000
  training_iteration: 311
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 10860 s, 311 iter, 6220000 ts, 551 rew

agent-1: 34.0
agent-2: 38.0
agent-3: 21.0
agent-4: 29.0
agent-5: 21.0
agent-6: 28.0
agent-7: 29.0
agent-8: 34.0
agent-9: 25.0
agent-10: 29.0
agent-11: 25.0
agent-12: 25.0
agent-13: 26.0
agent-14: 30.0
agent-15: 23.0
agent-16: 30.0
agent-17: 28.0
agent-18: 39.0
agent-19: 25.0
agent-20: 26.0
Sum Reward: 565.0
Avg Reward: 28.25
Min Reward: 21.0
Max Reward: 39.0
Gini Coefficient: 0.09424778761061947
20:20 Ratio: 1.6111111111111112
Max-min Ratio: 1.8571428571428572
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-02-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 550.67
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 311
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.59
    dispatch_time_ms: 6.582
    learner:
      cur_lr: 0.0009457480045966804
      grad_gnorm: 3.7050621509552
      policy_entropy: 370.33294677734375
      policy_loss: 2.5290393829345703
      var_gnorm: 44.60751724243164
      vf_explained_var: 0.2456674575805664
      vf_loss: 0.0050162444822490215
    num_steps_sampled: 6240000
    num_steps_trained: 6240000
    wait_time_ms: 342.542
  iterations_since_restore: 312
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 10895.29533982277
  time_this_iter_s: 34.76364064216614
  time_total_s: 10895.29533982277
  timestamp: 1594148576
  timesteps_since_restore: 6240000
  timesteps_this_iter: 20000
  timesteps_total: 6240000
  training_iteration: 312
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 10895 s, 312 iter, 6240000 ts, 551 rew

agent-1: 25.0
agent-2: 26.0
agent-3: 27.0
agent-4: 22.0
agent-5: 30.0
agent-6: 34.0
agent-7: 26.0
agent-8: 26.0
agent-9: 28.0
agent-10: 25.0
agent-11: 23.0
agent-12: 41.0
agent-13: 27.0
agent-14: 24.0
agent-15: 45.0
agent-16: 30.0
agent-17: 30.0
agent-18: 26.0
agent-19: 22.0
agent-20: 19.0
Sum Reward: 556.0
Avg Reward: 27.8
Min Reward: 19.0
Max Reward: 45.0
Gini Coefficient: 0.110431654676259
20:20 Ratio: 1.744186046511628
Max-min Ratio: 2.3684210526315788
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-03-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 550.8
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 312
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.635
    dispatch_time_ms: 23.418
    learner:
      cur_lr: 0.0009444159804843366
      grad_gnorm: 1.402921438217163
      policy_entropy: 363.52984619140625
      policy_loss: 3.0085020065307617
      var_gnorm: 44.66910934448242
      vf_explained_var: -1.0
      vf_loss: 0.001720762113109231
    num_steps_sampled: 6260000
    num_steps_trained: 6260000
    wait_time_ms: 355.74
  iterations_since_restore: 313
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 10930.772733688354
  time_this_iter_s: 35.47739386558533
  time_total_s: 10930.772733688354
  timestamp: 1594148612
  timesteps_since_restore: 6260000
  timesteps_this_iter: 20000
  timesteps_total: 6260000
  training_iteration: 313
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 10930 s, 313 iter, 6260000 ts, 551 rew

agent-1: 25.0
agent-2: 35.0
agent-3: 21.0
agent-4: 19.0
agent-5: 34.0
agent-6: 26.0
agent-7: 24.0
agent-8: 31.0
agent-9: 32.0
agent-10: 24.0
agent-11: 29.0
agent-12: 29.0
agent-13: 30.0
agent-14: 20.0
agent-15: 24.0
agent-16: 27.0
agent-17: 25.0
agent-18: 16.0
agent-19: 25.0
agent-20: 25.0
Sum Reward: 521.0
Avg Reward: 26.05
Min Reward: 16.0
Max Reward: 35.0
Gini Coefficient: 0.10412667946257198
20:20 Ratio: 1.736842105263158
Max-min Ratio: 2.1875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-04-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 550.92
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 313
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.085
    dispatch_time_ms: 5.117
    learner:
      cur_lr: 0.0009430840145796537
      grad_gnorm: 1.338770866394043
      policy_entropy: 368.36016845703125
      policy_loss: 1.7856465578079224
      var_gnorm: 44.697486877441406
      vf_explained_var: -1.0
      vf_loss: 0.000485737546114251
    num_steps_sampled: 6280000
    num_steps_trained: 6280000
    wait_time_ms: 341.801
  iterations_since_restore: 314
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 10965.757651090622
  time_this_iter_s: 34.984917402267456
  time_total_s: 10965.757651090622
  timestamp: 1594148647
  timesteps_since_restore: 6280000
  timesteps_this_iter: 20000
  timesteps_total: 6280000
  training_iteration: 314
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 10965 s, 314 iter, 6280000 ts, 551 rew

agent-1: 31.0
agent-2: 23.0
agent-3: 27.0
agent-4: 28.0
agent-5: 30.0
agent-6: 23.0
agent-7: 18.0
agent-8: 31.0
agent-9: 19.0
agent-10: 30.0
agent-11: 28.0
agent-12: 26.0
agent-13: 28.0
agent-14: 33.0
agent-15: 24.0
agent-16: 39.0
agent-17: 18.0
agent-18: 22.0
agent-19: 22.0
agent-20: 28.0
Sum Reward: 528.0
Avg Reward: 26.4
Min Reward: 18.0
Max Reward: 39.0
Gini Coefficient: 0.11022727272727273
20:20 Ratio: 1.7402597402597402
Max-min Ratio: 2.1666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-04-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 549.99
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 314
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.427
    dispatch_time_ms: 5.574
    learner:
      cur_lr: 0.00094175199046731
      grad_gnorm: 1.081432580947876
      policy_entropy: 379.457275390625
      policy_loss: -0.3768194317817688
      var_gnorm: 44.78428268432617
      vf_explained_var: 0.7934170365333557
      vf_loss: 0.00028245378052815795
    num_steps_sampled: 6300000
    num_steps_trained: 6300000
    wait_time_ms: 340.461
  iterations_since_restore: 315
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 11000.601196050644
  time_this_iter_s: 34.84354496002197
  time_total_s: 11000.601196050644
  timestamp: 1594148682
  timesteps_since_restore: 6300000
  timesteps_this_iter: 20000
  timesteps_total: 6300000
  training_iteration: 315
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 11000 s, 315 iter, 6300000 ts, 550 rew

agent-1: 20.0
agent-2: 30.0
agent-3: 35.0
agent-4: 27.0
agent-5: 25.0
agent-6: 17.0
agent-7: 28.0
agent-8: 25.0
agent-9: 26.0
agent-10: 28.0
agent-11: 25.0
agent-12: 29.0
agent-13: 22.0
agent-14: 31.0
agent-15: 15.0
agent-16: 32.0
agent-17: 20.0
agent-18: 28.0
agent-19: 32.0
agent-20: 29.0
Sum Reward: 524.0
Avg Reward: 26.2
Min Reward: 15.0
Max Reward: 35.0
Gini Coefficient: 0.10801526717557251
20:20 Ratio: 1.8055555555555556
Max-min Ratio: 2.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-05-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 549.56
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 315
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.514
    dispatch_time_ms: 6.448
    learner:
      cur_lr: 0.0009404200245626271
      grad_gnorm: 7.592286109924316
      policy_entropy: 349.4395751953125
      policy_loss: -3.7017126083374023
      var_gnorm: 44.833580017089844
      vf_explained_var: 0.8398262858390808
      vf_loss: 0.054800428450107574
    num_steps_sampled: 6320000
    num_steps_trained: 6320000
    wait_time_ms: 334.033
  iterations_since_restore: 316
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 11035.048707008362
  time_this_iter_s: 34.447510957717896
  time_total_s: 11035.048707008362
  timestamp: 1594148716
  timesteps_since_restore: 6320000
  timesteps_this_iter: 20000
  timesteps_total: 6320000
  training_iteration: 316
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 11035 s, 316 iter, 6320000 ts, 550 rew

agent-1: 25.0
agent-2: 37.0
agent-3: 18.0
agent-4: 22.0
agent-5: 32.0
agent-6: 32.0
agent-7: 27.0
agent-8: 44.0
agent-9: 26.0
agent-10: 33.0
agent-11: 18.0
agent-12: 23.0
agent-13: 27.0
agent-14: 26.0
agent-15: 30.0
agent-16: 30.0
agent-17: 31.0
agent-18: 30.0
agent-19: 29.0
agent-20: 24.0
Sum Reward: 564.0
Avg Reward: 28.2
Min Reward: 18.0
Max Reward: 44.0
Gini Coefficient: 0.11524822695035461
20:20 Ratio: 1.8024691358024691
Max-min Ratio: 2.4444444444444446
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-05-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 548.89
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 316
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.741
    dispatch_time_ms: 5.927
    learner:
      cur_lr: 0.0009390880004502833
      grad_gnorm: 7.971263885498047
      policy_entropy: 293.51318359375
      policy_loss: -2.6091344356536865
      var_gnorm: 44.85988998413086
      vf_explained_var: 0.8495116233825684
      vf_loss: 0.09013086557388306
    num_steps_sampled: 6340000
    num_steps_trained: 6340000
    wait_time_ms: 348.618
  iterations_since_restore: 317
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 11069.90273308754
  time_this_iter_s: 34.854026079177856
  time_total_s: 11069.90273308754
  timestamp: 1594148751
  timesteps_since_restore: 6340000
  timesteps_this_iter: 20000
  timesteps_total: 6340000
  training_iteration: 317
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 11069 s, 317 iter, 6340000 ts, 549 rew

agent-1: 33.0
agent-2: 36.0
agent-3: 23.0
agent-4: 41.0
agent-5: 25.0
agent-6: 39.0
agent-7: 14.0
agent-8: 3.0
agent-9: 38.0
agent-10: 43.0
agent-11: 30.0
agent-12: 25.0
agent-13: 31.0
agent-14: 30.0
agent-15: 22.0
agent-16: 31.0
agent-17: 5.0
agent-18: 35.0
agent-19: 30.0
agent-20: 27.0
Sum Reward: 561.0
Avg Reward: 28.05
Min Reward: 3.0
Max Reward: 43.0
Gini Coefficient: 0.2020499108734403
20:20 Ratio: 3.659090909090909
Max-min Ratio: 14.333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-06-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 548.63
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 317
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.362
    dispatch_time_ms: 6.37
    learner:
      cur_lr: 0.0009377559763379395
      grad_gnorm: 3.668865442276001
      policy_entropy: 386.90374755859375
      policy_loss: 2.3442130088806152
      var_gnorm: 44.998069763183594
      vf_explained_var: -0.8548990488052368
      vf_loss: 0.0047490475699305534
    num_steps_sampled: 6360000
    num_steps_trained: 6360000
    wait_time_ms: 345.027
  iterations_since_restore: 318
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 11104.36623120308
  time_this_iter_s: 34.46349811553955
  time_total_s: 11104.36623120308
  timestamp: 1594148785
  timesteps_since_restore: 6360000
  timesteps_this_iter: 20000
  timesteps_total: 6360000
  training_iteration: 318
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 11104 s, 318 iter, 6360000 ts, 549 rew

agent-1: 28.0
agent-2: 26.0
agent-3: 38.0
agent-4: 16.0
agent-5: 28.0
agent-6: 37.0
agent-7: 22.0
agent-8: 29.0
agent-9: 28.0
agent-10: 23.0
agent-11: 34.0
agent-12: 25.0
agent-13: 35.0
agent-14: 26.0
agent-15: 24.0
agent-16: 26.0
agent-17: 18.0
agent-18: 33.0
agent-19: 29.0
agent-20: 21.0
Sum Reward: 546.0
Avg Reward: 27.3
Min Reward: 16.0
Max Reward: 38.0
Gini Coefficient: 0.11978021978021978
20:20 Ratio: 1.87012987012987
Max-min Ratio: 2.375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-07-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 548.81
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 318
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.049
    dispatch_time_ms: 6.57
    learner:
      cur_lr: 0.0009364240104332566
      grad_gnorm: 2.163499593734741
      policy_entropy: 358.1785583496094
      policy_loss: 0.5863920450210571
      var_gnorm: 45.034149169921875
      vf_explained_var: -1.0
      vf_loss: 0.04543601721525192
    num_steps_sampled: 6380000
    num_steps_trained: 6380000
    wait_time_ms: 349.751
  iterations_since_restore: 319
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 11139.405440330505
  time_this_iter_s: 35.03920912742615
  time_total_s: 11139.405440330505
  timestamp: 1594148821
  timesteps_since_restore: 6380000
  timesteps_this_iter: 20000
  timesteps_total: 6380000
  training_iteration: 319
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 11139 s, 319 iter, 6380000 ts, 549 rew

agent-1: 33.0
agent-2: 25.0
agent-3: 37.0
agent-4: 11.0
agent-5: 21.0
agent-6: 40.0
agent-7: 30.0
agent-8: 22.0
agent-9: 14.0
agent-10: 29.0
agent-11: 18.0
agent-12: 23.0
agent-13: 26.0
agent-14: 32.0
agent-15: 27.0
agent-16: 27.0
agent-17: 27.0
agent-18: 29.0
agent-19: 33.0
agent-20: 18.0
Sum Reward: 522.0
Avg Reward: 26.1
Min Reward: 11.0
Max Reward: 40.0
Gini Coefficient: 0.15517241379310345
20:20 Ratio: 2.3442622950819674
Max-min Ratio: 3.6363636363636362
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-07-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 548.56
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 319
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.488
    dispatch_time_ms: 7.995
    learner:
      cur_lr: 0.0009350919863209128
      grad_gnorm: 5.508025646209717
      policy_entropy: 374.12359619140625
      policy_loss: -4.379019260406494
      var_gnorm: 45.00926971435547
      vf_explained_var: -0.00020360946655273438
      vf_loss: 0.009323745965957642
    num_steps_sampled: 6400000
    num_steps_trained: 6400000
    wait_time_ms: 338.305
  iterations_since_restore: 320
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 11174.028773069382
  time_this_iter_s: 34.62333273887634
  time_total_s: 11174.028773069382
  timestamp: 1594148855
  timesteps_since_restore: 6400000
  timesteps_this_iter: 20000
  timesteps_total: 6400000
  training_iteration: 320
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 11174 s, 320 iter, 6400000 ts, 549 rew

agent-1: 23.0
agent-2: 22.0
agent-3: 29.0
agent-4: 18.0
agent-5: 19.0
agent-6: 38.0
agent-7: 36.0
agent-8: 22.0
agent-9: 25.0
agent-10: 25.0
agent-11: 31.0
agent-12: 35.0
agent-13: 24.0
agent-14: 33.0
agent-15: 19.0
agent-16: 17.0
agent-17: 26.0
agent-18: 25.0
agent-19: 26.0
agent-20: 34.0
Sum Reward: 527.0
Avg Reward: 26.35
Min Reward: 17.0
Max Reward: 38.0
Gini Coefficient: 0.1325426944971537
20:20 Ratio: 1.9589041095890412
Max-min Ratio: 2.235294117647059
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-08-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 547.64
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 320
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.631
    dispatch_time_ms: 6.136
    learner:
      cur_lr: 0.00093376002041623
      grad_gnorm: 10.205581665039062
      policy_entropy: 222.6009063720703
      policy_loss: -3.2217257022857666
      var_gnorm: 45.05941390991211
      vf_explained_var: 0.8564636707305908
      vf_loss: 0.16446763277053833
    num_steps_sampled: 6420000
    num_steps_trained: 6420000
    wait_time_ms: 336.956
  iterations_since_restore: 321
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 11208.635122776031
  time_this_iter_s: 34.60634970664978
  time_total_s: 11208.635122776031
  timestamp: 1594148890
  timesteps_since_restore: 6420000
  timesteps_this_iter: 20000
  timesteps_total: 6420000
  training_iteration: 321
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 11208 s, 321 iter, 6420000 ts, 548 rew

agent-1: 30.0
agent-2: 27.0
agent-3: 25.0
agent-4: 29.0
agent-5: 32.0
agent-6: 20.0
agent-7: 30.0
agent-8: 25.0
agent-9: 34.0
agent-10: 34.0
agent-11: 28.0
agent-12: 27.0
agent-13: 19.0
agent-14: 12.0
agent-15: 25.0
agent-16: 26.0
agent-17: 23.0
agent-18: 39.0
agent-19: 22.0
agent-20: 26.0
Sum Reward: 533.0
Avg Reward: 26.65
Min Reward: 12.0
Max Reward: 39.0
Gini Coefficient: 0.1197936210131332
20:20 Ratio: 1.904109589041096
Max-min Ratio: 3.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-08-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 546.46
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 321
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.585
    dispatch_time_ms: 5.247
    learner:
      cur_lr: 0.0009324279963038862
      grad_gnorm: 2.0869300365448
      policy_entropy: 375.5599365234375
      policy_loss: 1.3740448951721191
      var_gnorm: 45.15375518798828
      vf_explained_var: -1.0
      vf_loss: 0.001309878658503294
    num_steps_sampled: 6440000
    num_steps_trained: 6440000
    wait_time_ms: 342.254
  iterations_since_restore: 322
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 11243.562772750854
  time_this_iter_s: 34.927649974823
  time_total_s: 11243.562772750854
  timestamp: 1594148925
  timesteps_since_restore: 6440000
  timesteps_this_iter: 20000
  timesteps_total: 6440000
  training_iteration: 322
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 11243 s, 322 iter, 6440000 ts, 546 rew

agent-1: 36.0
agent-2: 20.0
agent-3: 29.0
agent-4: 12.0
agent-5: 22.0
agent-6: 24.0
agent-7: 21.0
agent-8: 29.0
agent-9: 35.0
agent-10: 25.0
agent-11: 36.0
agent-12: 30.0
agent-13: 39.0
agent-14: 29.0
agent-15: 24.0
agent-16: 28.0
agent-17: 31.0
agent-18: 34.0
agent-19: 13.0
agent-20: 27.0
Sum Reward: 544.0
Avg Reward: 27.2
Min Reward: 12.0
Max Reward: 39.0
Gini Coefficient: 0.14613970588235295
20:20 Ratio: 2.212121212121212
Max-min Ratio: 3.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-09-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 546.1
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 322
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.704
    dispatch_time_ms: 21.594
    learner:
      cur_lr: 0.0009310959721915424
      grad_gnorm: 34.8162841796875
      policy_entropy: 276.886962890625
      policy_loss: 2.450894832611084
      var_gnorm: 45.12092971801758
      vf_explained_var: 0.9128963947296143
      vf_loss: 4.884125709533691
    num_steps_sampled: 6460000
    num_steps_trained: 6460000
    wait_time_ms: 336.833
  iterations_since_restore: 323
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 11278.562255859375
  time_this_iter_s: 34.99948310852051
  time_total_s: 11278.562255859375
  timestamp: 1594148960
  timesteps_since_restore: 6460000
  timesteps_this_iter: 20000
  timesteps_total: 6460000
  training_iteration: 323
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 11278 s, 323 iter, 6460000 ts, 546 rew

agent-1: 14.0
agent-2: 27.0
agent-3: 27.0
agent-4: 27.0
agent-5: 28.0
agent-6: 28.0
agent-7: 37.0
agent-8: 29.0
agent-9: 27.0
agent-10: 28.0
agent-11: 27.0
agent-12: 29.0
agent-13: 21.0
agent-14: 22.0
agent-15: 36.0
agent-16: 30.0
agent-17: 21.0
agent-18: 17.0
agent-19: 21.0
agent-20: 21.0
Sum Reward: 517.0
Avg Reward: 25.85
Min Reward: 14.0
Max Reward: 37.0
Gini Coefficient: 0.11576402321083172
20:20 Ratio: 1.8082191780821917
Max-min Ratio: 2.642857142857143
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-10-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 545.43
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 323
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.744
    dispatch_time_ms: 8.348
    learner:
      cur_lr: 0.0009297640062868595
      grad_gnorm: 3.651837110519409
      policy_entropy: 376.3778381347656
      policy_loss: 2.204047679901123
      var_gnorm: 45.24126434326172
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.003990997094660997
    num_steps_sampled: 6480000
    num_steps_trained: 6480000
    wait_time_ms: 338.63
  iterations_since_restore: 324
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 11313.972608327866
  time_this_iter_s: 35.4103524684906
  time_total_s: 11313.972608327866
  timestamp: 1594149001
  timesteps_since_restore: 6480000
  timesteps_this_iter: 20000
  timesteps_total: 6480000
  training_iteration: 324
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 11313 s, 324 iter, 6480000 ts, 545 rew

agent-1: 29.0
agent-2: 33.0
agent-3: 29.0
agent-4: 34.0
agent-5: 25.0
agent-6: 27.0
agent-7: 36.0
agent-8: 31.0
agent-9: 17.0
agent-10: 28.0
agent-11: 24.0
agent-12: 11.0
agent-13: 31.0
agent-14: 32.0
agent-15: 33.0
agent-16: 32.0
agent-17: 34.0
agent-18: 33.0
agent-19: 20.0
agent-20: 21.0
Sum Reward: 560.0
Avg Reward: 28.0
Min Reward: 11.0
Max Reward: 36.0
Gini Coefficient: 0.12178571428571429
20:20 Ratio: 1.9855072463768115
Max-min Ratio: 3.272727272727273
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-10-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 545.41
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 324
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.597
    dispatch_time_ms: 6.942
    learner:
      cur_lr: 0.0009284319821745157
      grad_gnorm: 18.264516830444336
      policy_entropy: 302.5257873535156
      policy_loss: 4.420339107513428
      var_gnorm: 45.221073150634766
      vf_explained_var: 0.553489089012146
      vf_loss: 3.0350236892700195
    num_steps_sampled: 6500000
    num_steps_trained: 6500000
    wait_time_ms: 358.425
  iterations_since_restore: 325
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 11345.585458040237
  time_this_iter_s: 31.612849712371826
  time_total_s: 11345.585458040237
  timestamp: 1594149033
  timesteps_since_restore: 6500000
  timesteps_this_iter: 20000
  timesteps_total: 6500000
  training_iteration: 325
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 11345 s, 325 iter, 6500000 ts, 545 rew

agent-1: 33.0
agent-2: 30.0
agent-3: 28.0
agent-4: 31.0
agent-5: 15.0
agent-6: 35.0
agent-7: 16.0
agent-8: 28.0
agent-9: 17.0
agent-10: 18.0
agent-11: 35.0
agent-12: 32.0
agent-13: 21.0
agent-14: 27.0
agent-15: 19.0
agent-16: 40.0
agent-17: 44.0
agent-18: 32.0
agent-19: 23.0
agent-20: 30.0
Sum Reward: 554.0
Avg Reward: 27.7
Min Reward: 15.0
Max Reward: 44.0
Gini Coefficient: 0.16191335740072202
20:20 Ratio: 2.3333333333333335
Max-min Ratio: 2.933333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-11-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 545.53
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 325
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.189
    dispatch_time_ms: 6.047
    learner:
      cur_lr: 0.0009271000162698328
      grad_gnorm: 2.3238654136657715
      policy_entropy: 367.2829284667969
      policy_loss: 0.7939637899398804
      var_gnorm: 45.35732650756836
      vf_explained_var: 0.883083164691925
      vf_loss: 0.003609956242144108
    num_steps_sampled: 6520000
    num_steps_trained: 6520000
    wait_time_ms: 349.05
  iterations_since_restore: 326
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 11379.998781204224
  time_this_iter_s: 34.413323163986206
  time_total_s: 11379.998781204224
  timestamp: 1594149067
  timesteps_since_restore: 6520000
  timesteps_this_iter: 20000
  timesteps_total: 6520000
  training_iteration: 326
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 11379 s, 326 iter, 6520000 ts, 546 rew

agent-1: 37.0
agent-2: 33.0
agent-3: 28.0
agent-4: 36.0
agent-5: 16.0
agent-6: 40.0
agent-7: 29.0
agent-8: 22.0
agent-9: 14.0
agent-10: 30.0
agent-11: 21.0
agent-12: 30.0
agent-13: 17.0
agent-14: 15.0
agent-15: 25.0
agent-16: 22.0
agent-17: 37.0
agent-18: 38.0
agent-19: 31.0
agent-20: 35.0
Sum Reward: 556.0
Avg Reward: 27.8
Min Reward: 14.0
Max Reward: 40.0
Gini Coefficient: 0.1669064748201439
20:20 Ratio: 2.4516129032258065
Max-min Ratio: 2.857142857142857
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-11-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 545.62
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 326
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.354
    dispatch_time_ms: 6.946
    learner:
      cur_lr: 0.0009257679921574891
      grad_gnorm: 2.771773338317871
      policy_entropy: 372.14776611328125
      policy_loss: -1.6730962991714478
      var_gnorm: 45.330345153808594
      vf_explained_var: -1.0
      vf_loss: 0.02877511829137802
    num_steps_sampled: 6540000
    num_steps_trained: 6540000
    wait_time_ms: 334.266
  iterations_since_restore: 327
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 11414.516132593155
  time_this_iter_s: 34.517351388931274
  time_total_s: 11414.516132593155
  timestamp: 1594149102
  timesteps_since_restore: 6540000
  timesteps_this_iter: 20000
  timesteps_total: 6540000
  training_iteration: 327
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 11414 s, 327 iter, 6540000 ts, 546 rew

agent-1: 31.0
agent-2: 33.0
agent-3: 34.0
agent-4: 24.0
agent-5: 24.0
agent-6: 32.0
agent-7: 26.0
agent-8: 27.0
agent-9: 38.0
agent-10: 21.0
agent-11: 29.0
agent-12: 36.0
agent-13: 40.0
agent-14: 15.0
agent-15: 18.0
agent-16: 26.0
agent-17: 31.0
agent-18: 35.0
agent-19: 45.0
agent-20: 22.0
Sum Reward: 587.0
Avg Reward: 29.35
Min Reward: 15.0
Max Reward: 45.0
Gini Coefficient: 0.14352640545144804
20:20 Ratio: 2.0921052631578947
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-12-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 545.77
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 327
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.77
    dispatch_time_ms: 5.842
    learner:
      cur_lr: 0.0009244360262528062
      grad_gnorm: 2.0557210445404053
      policy_entropy: 359.1292724609375
      policy_loss: 0.7532071471214294
      var_gnorm: 45.36883544921875
      vf_explained_var: 0.00015628337860107422
      vf_loss: 0.0013008182868361473
    num_steps_sampled: 6560000
    num_steps_trained: 6560000
    wait_time_ms: 341.399
  iterations_since_restore: 328
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 11449.153285980225
  time_this_iter_s: 34.6371533870697
  time_total_s: 11449.153285980225
  timestamp: 1594149136
  timesteps_since_restore: 6560000
  timesteps_this_iter: 20000
  timesteps_total: 6560000
  training_iteration: 328
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 11449 s, 328 iter, 6560000 ts, 546 rew

agent-1: 35.0
agent-2: 13.0
agent-3: 35.0
agent-4: 32.0
agent-5: 33.0
agent-6: 23.0
agent-7: 27.0
agent-8: 32.0
agent-9: 29.0
agent-10: 44.0
agent-11: 27.0
agent-12: 33.0
agent-13: 24.0
agent-14: 27.0
agent-15: 29.0
agent-16: 37.0
agent-17: 20.0
agent-18: 25.0
agent-19: 33.0
agent-20: 20.0
Sum Reward: 578.0
Avg Reward: 28.9
Min Reward: 13.0
Max Reward: 44.0
Gini Coefficient: 0.13079584775086506
20:20 Ratio: 1.986842105263158
Max-min Ratio: 3.3846153846153846
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-12-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 545.83
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 328
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.18
    dispatch_time_ms: 18.648
    learner:
      cur_lr: 0.0009231040021404624
      grad_gnorm: 9.607328414916992
      policy_entropy: 299.4146728515625
      policy_loss: -2.656717538833618
      var_gnorm: 45.3745002746582
      vf_explained_var: 0.8743388652801514
      vf_loss: 0.16368013620376587
    num_steps_sampled: 6580000
    num_steps_trained: 6580000
    wait_time_ms: 337.242
  iterations_since_restore: 329
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 11484.413751363754
  time_this_iter_s: 35.26046538352966
  time_total_s: 11484.413751363754
  timestamp: 1594149172
  timesteps_since_restore: 6580000
  timesteps_this_iter: 20000
  timesteps_total: 6580000
  training_iteration: 329
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 11484 s, 329 iter, 6580000 ts, 546 rew

agent-1: 32.0
agent-2: 34.0
agent-3: 36.0
agent-4: 36.0
agent-5: 18.0
agent-6: 32.0
agent-7: 36.0
agent-8: 16.0
agent-9: 37.0
agent-10: 25.0
agent-11: 38.0
agent-12: 19.0
agent-13: 21.0
agent-14: 23.0
agent-15: 25.0
agent-16: 31.0
agent-17: 26.0
agent-18: 34.0
agent-19: 34.0
agent-20: 23.0
Sum Reward: 576.0
Avg Reward: 28.8
Min Reward: 16.0
Max Reward: 38.0
Gini Coefficient: 0.13541666666666666
20:20 Ratio: 1.9864864864864864
Max-min Ratio: 2.375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-13-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 546.21
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 329
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.12
    dispatch_time_ms: 26.255
    learner:
      cur_lr: 0.0009217719780281186
      grad_gnorm: 0.5352370738983154
      policy_entropy: 375.4915771484375
      policy_loss: 0.9650095701217651
      var_gnorm: 45.4273796081543
      vf_explained_var: -1.5497207641601562e-06
      vf_loss: 7.736474799457937e-05
    num_steps_sampled: 6600000
    num_steps_trained: 6600000
    wait_time_ms: 327.216
  iterations_since_restore: 330
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 11520.192378282547
  time_this_iter_s: 35.778626918792725
  time_total_s: 11520.192378282547
  timestamp: 1594149208
  timesteps_since_restore: 6600000
  timesteps_this_iter: 20000
  timesteps_total: 6600000
  training_iteration: 330
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 11520 s, 330 iter, 6600000 ts, 546 rew

agent-1: 37.0
agent-2: 39.0
agent-3: 21.0
agent-4: 41.0
agent-5: 24.0
agent-6: 19.0
agent-7: 31.0
agent-8: 27.0
agent-9: 35.0
agent-10: 9.0
agent-11: 27.0
agent-12: 23.0
agent-13: 27.0
agent-14: 25.0
agent-15: 16.0
agent-16: 40.0
agent-17: 25.0
agent-18: 13.0
agent-19: 22.0
agent-20: 22.0
Sum Reward: 523.0
Avg Reward: 26.15
Min Reward: 9.0
Max Reward: 41.0
Gini Coefficient: 0.18594646271510518
20:20 Ratio: 2.754385964912281
Max-min Ratio: 4.555555555555555
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-14-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 545.88
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 330
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.477
    dispatch_time_ms: 6.529
    learner:
      cur_lr: 0.0009204400121234357
      grad_gnorm: 1.439307451248169
      policy_entropy: 380.5208740234375
      policy_loss: -1.7048486471176147
      var_gnorm: 45.49843978881836
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.00027212093118578196
    num_steps_sampled: 6620000
    num_steps_trained: 6620000
    wait_time_ms: 340.909
  iterations_since_restore: 331
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 11555.709713935852
  time_this_iter_s: 35.517335653305054
  time_total_s: 11555.709713935852
  timestamp: 1594149243
  timesteps_since_restore: 6620000
  timesteps_this_iter: 20000
  timesteps_total: 6620000
  training_iteration: 331
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 11555 s, 331 iter, 6620000 ts, 546 rew

agent-1: 32.0
agent-2: 39.0
agent-3: 39.0
agent-4: 31.0
agent-5: 34.0
agent-6: 39.0
agent-7: 18.0
agent-8: 18.0
agent-9: 39.0
agent-10: 30.0
agent-11: 15.0
agent-12: 35.0
agent-13: 25.0
agent-14: 31.0
agent-15: 28.0
agent-16: 29.0
agent-17: 17.0
agent-18: 35.0
agent-19: 31.0
agent-20: 33.0
Sum Reward: 598.0
Avg Reward: 29.9
Min Reward: 15.0
Max Reward: 39.0
Gini Coefficient: 0.1374581939799331
20:20 Ratio: 2.2941176470588234
Max-min Ratio: 2.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-14-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 546.67
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 331
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.971
    dispatch_time_ms: 6.664
    learner:
      cur_lr: 0.000919107988011092
      grad_gnorm: 1.201764702796936
      policy_entropy: 376.4329528808594
      policy_loss: 1.0090137720108032
      var_gnorm: 45.450138092041016
      vf_explained_var: -1.0
      vf_loss: 0.00745589891448617
    num_steps_sampled: 6640000
    num_steps_trained: 6640000
    wait_time_ms: 349.115
  iterations_since_restore: 332
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 11590.553777694702
  time_this_iter_s: 34.8440637588501
  time_total_s: 11590.553777694702
  timestamp: 1594149278
  timesteps_since_restore: 6640000
  timesteps_this_iter: 20000
  timesteps_total: 6640000
  training_iteration: 332
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 11590 s, 332 iter, 6640000 ts, 547 rew

agent-1: 23.0
agent-2: 25.0
agent-3: 28.0
agent-4: 26.0
agent-5: 37.0
agent-6: 26.0
agent-7: 24.0
agent-8: 24.0
agent-9: 20.0
agent-10: 31.0
agent-11: 34.0
agent-12: 34.0
agent-13: 32.0
agent-14: 19.0
agent-15: 31.0
agent-16: 25.0
agent-17: 45.0
agent-18: 30.0
agent-19: 26.0
agent-20: 27.0
Sum Reward: 567.0
Avg Reward: 28.35
Min Reward: 19.0
Max Reward: 45.0
Gini Coefficient: 0.113668430335097
20:20 Ratio: 1.744186046511628
Max-min Ratio: 2.3684210526315788
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-15-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 546.61
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 332
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.529
    dispatch_time_ms: 7.283
    learner:
      cur_lr: 0.0009177760221064091
      grad_gnorm: 5.379462718963623
      policy_entropy: 285.7353820800781
      policy_loss: -1.1170368194580078
      var_gnorm: 45.48295211791992
      vf_explained_var: 0.9329346418380737
      vf_loss: 0.05849791690707207
    num_steps_sampled: 6660000
    num_steps_trained: 6660000
    wait_time_ms: 342.053
  iterations_since_restore: 333
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 11624.930569648743
  time_this_iter_s: 34.37679195404053
  time_total_s: 11624.930569648743
  timestamp: 1594149312
  timesteps_since_restore: 6660000
  timesteps_this_iter: 20000
  timesteps_total: 6660000
  training_iteration: 333
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 11624 s, 333 iter, 6660000 ts, 547 rew

agent-1: 36.0
agent-2: 10.0
agent-3: 30.0
agent-4: 19.0
agent-5: 38.0
agent-6: 26.0
agent-7: 38.0
agent-8: 32.0
agent-9: 31.0
agent-10: 11.0
agent-11: 32.0
agent-12: 19.0
agent-13: 35.0
agent-14: 20.0
agent-15: 25.0
agent-16: 38.0
agent-17: 27.0
agent-18: 35.0
agent-19: 29.0
agent-20: 31.0
Sum Reward: 562.0
Avg Reward: 28.1
Min Reward: 10.0
Max Reward: 38.0
Gini Coefficient: 0.16245551601423489
20:20 Ratio: 2.542372881355932
Max-min Ratio: 3.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-15-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 546.93
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 333
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.0
    dispatch_time_ms: 6.538
    learner:
      cur_lr: 0.0009164439979940653
      grad_gnorm: 36.50293731689453
      policy_entropy: 374.65533447265625
      policy_loss: -1.9222369194030762
      var_gnorm: 45.54267120361328
      vf_explained_var: -1.0
      vf_loss: 0.028501665219664574
    num_steps_sampled: 6680000
    num_steps_trained: 6680000
    wait_time_ms: 347.331
  iterations_since_restore: 334
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 11659.591721057892
  time_this_iter_s: 34.66115140914917
  time_total_s: 11659.591721057892
  timestamp: 1594149347
  timesteps_since_restore: 6680000
  timesteps_this_iter: 20000
  timesteps_total: 6680000
  training_iteration: 334
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 11659 s, 334 iter, 6680000 ts, 547 rew

agent-1: 20.0
agent-2: 30.0
agent-3: 33.0
agent-4: 23.0
agent-5: 20.0
agent-6: 31.0
agent-7: 20.0
agent-8: 30.0
agent-9: 41.0
agent-10: 17.0
agent-11: 14.0
agent-12: 19.0
agent-13: 17.0
agent-14: 26.0
agent-15: 36.0
agent-16: 27.0
agent-17: 35.0
agent-18: 28.0
agent-19: 19.0
agent-20: 27.0
Sum Reward: 513.0
Avg Reward: 25.65
Min Reward: 14.0
Max Reward: 41.0
Gini Coefficient: 0.1591617933723197
20:20 Ratio: 2.1641791044776117
Max-min Ratio: 2.9285714285714284
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-16-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 547.03
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 334
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.387
    dispatch_time_ms: 5.263
    learner:
      cur_lr: 0.0009151119738817215
      grad_gnorm: 0.8877013325691223
      policy_entropy: 378.3673095703125
      policy_loss: 0.6017402410507202
      var_gnorm: 45.562259674072266
      vf_explained_var: -0.4926457405090332
      vf_loss: 0.002535490086302161
    num_steps_sampled: 6700000
    num_steps_trained: 6700000
    wait_time_ms: 330.688
  iterations_since_restore: 335
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 11694.612944841385
  time_this_iter_s: 35.02122378349304
  time_total_s: 11694.612944841385
  timestamp: 1594149382
  timesteps_since_restore: 6700000
  timesteps_this_iter: 20000
  timesteps_total: 6700000
  training_iteration: 335
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 11694 s, 335 iter, 6700000 ts, 547 rew

agent-1: 27.0
agent-2: 29.0
agent-3: 25.0
agent-4: 24.0
agent-5: 37.0
agent-6: 31.0
agent-7: 20.0
agent-8: 32.0
agent-9: 15.0
agent-10: 29.0
agent-11: 28.0
agent-12: 30.0
agent-13: 29.0
agent-14: 24.0
agent-15: 34.0
agent-16: 24.0
agent-17: 18.0
agent-18: 33.0
agent-19: 37.0
agent-20: 22.0
Sum Reward: 548.0
Avg Reward: 27.4
Min Reward: 15.0
Max Reward: 37.0
Gini Coefficient: 0.11989051094890511
20:20 Ratio: 1.88
Max-min Ratio: 2.466666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-16-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 547.32
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 335
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.885
    dispatch_time_ms: 6.823
    learner:
      cur_lr: 0.0009137800079770386
      grad_gnorm: 1.8015804290771484
      policy_entropy: 381.2933044433594
      policy_loss: 1.7430880069732666
      var_gnorm: 45.610897064208984
      vf_explained_var: -0.0005879402160644531
      vf_loss: 0.0008380037033930421
    num_steps_sampled: 6720000
    num_steps_trained: 6720000
    wait_time_ms: 333.106
  iterations_since_restore: 336
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 11729.151237726212
  time_this_iter_s: 34.53829288482666
  time_total_s: 11729.151237726212
  timestamp: 1594149417
  timesteps_since_restore: 6720000
  timesteps_this_iter: 20000
  timesteps_total: 6720000
  training_iteration: 336
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 11729 s, 336 iter, 6720000 ts, 547 rew

agent-1: 23.0
agent-2: 31.0
agent-3: 23.0
agent-4: 41.0
agent-5: 32.0
agent-6: 24.0
agent-7: 16.0
agent-8: 27.0
agent-9: 24.0
agent-10: 17.0
agent-11: 33.0
agent-12: 41.0
agent-13: 28.0
agent-14: 38.0
agent-15: 22.0
agent-16: 30.0
agent-17: 26.0
agent-18: 29.0
agent-19: 41.0
agent-20: 18.0
Sum Reward: 564.0
Avg Reward: 28.2
Min Reward: 16.0
Max Reward: 41.0
Gini Coefficient: 0.15212765957446808
20:20 Ratio: 2.2054794520547945
Max-min Ratio: 2.5625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-17-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 547.42
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 336
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.543
    dispatch_time_ms: 5.21
    learner:
      cur_lr: 0.0009124479838646948
      grad_gnorm: 40.0
      policy_entropy: 226.92755126953125
      policy_loss: 10.635421752929688
      var_gnorm: 45.68244934082031
      vf_explained_var: 0.18530333042144775
      vf_loss: 28.287952423095703
    num_steps_sampled: 6740000
    num_steps_trained: 6740000
    wait_time_ms: 338.017
  iterations_since_restore: 337
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 11763.719703674316
  time_this_iter_s: 34.56846594810486
  time_total_s: 11763.719703674316
  timestamp: 1594149451
  timesteps_since_restore: 6740000
  timesteps_this_iter: 20000
  timesteps_total: 6740000
  training_iteration: 337
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 11763 s, 337 iter, 6740000 ts, 547 rew

agent-1: 14.0
agent-2: 37.0
agent-3: 26.0
agent-4: 39.0
agent-5: 34.0
agent-6: 36.0
agent-7: 38.0
agent-8: 42.0
agent-9: 14.0
agent-10: 29.0
agent-11: 40.0
agent-12: 22.0
agent-13: 40.0
agent-14: 49.0
agent-15: 7.0
agent-16: 23.0
agent-17: 37.0
agent-18: 33.0
agent-19: 40.0
agent-20: 23.0
Sum Reward: 623.0
Avg Reward: 31.15
Min Reward: 7.0
Max Reward: 49.0
Gini Coefficient: 0.18996789727126806
20:20 Ratio: 3.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-18-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 548.17
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 337
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.299
    dispatch_time_ms: 8.024
    learner:
      cur_lr: 0.000911116017960012
      grad_gnorm: 2.4500653743743896
      policy_entropy: 361.638427734375
      policy_loss: -0.7850234508514404
      var_gnorm: 45.69519805908203
      vf_explained_var: -0.2618691921234131
      vf_loss: 0.004850132390856743
    num_steps_sampled: 6760000
    num_steps_trained: 6760000
    wait_time_ms: 337.739
  iterations_since_restore: 338
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 11798.314492225647
  time_this_iter_s: 34.594788551330566
  time_total_s: 11798.314492225647
  timestamp: 1594149486
  timesteps_since_restore: 6760000
  timesteps_this_iter: 20000
  timesteps_total: 6760000
  training_iteration: 338
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 11798 s, 338 iter, 6760000 ts, 548 rew

agent-1: 43.0
agent-2: 37.0
agent-3: 19.0
agent-4: 36.0
agent-5: 33.0
agent-6: 34.0
agent-7: 11.0
agent-8: 29.0
agent-9: 17.0
agent-10: 10.0
agent-11: 17.0
agent-12: 35.0
agent-13: 23.0
agent-14: 12.0
agent-15: 28.0
agent-16: 34.0
agent-17: 24.0
agent-18: 31.0
agent-19: 43.0
agent-20: 28.0
Sum Reward: 544.0
Avg Reward: 27.2
Min Reward: 10.0
Max Reward: 43.0
Gini Coefficient: 0.20753676470588237
20:20 Ratio: 3.18
Max-min Ratio: 4.3
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-18-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 548.16
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 338
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.5
    dispatch_time_ms: 5.878
    learner:
      cur_lr: 0.0009097839938476682
      grad_gnorm: 40.0
      policy_entropy: 174.44482421875
      policy_loss: 9.399351119995117
      var_gnorm: 45.6740837097168
      vf_explained_var: 0.6688250303268433
      vf_loss: 64.66072845458984
    num_steps_sampled: 6780000
    num_steps_trained: 6780000
    wait_time_ms: 328.454
  iterations_since_restore: 339
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 11832.712776899338
  time_this_iter_s: 34.398284673690796
  time_total_s: 11832.712776899338
  timestamp: 1594149520
  timesteps_since_restore: 6780000
  timesteps_this_iter: 20000
  timesteps_total: 6780000
  training_iteration: 339
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 11832 s, 339 iter, 6780000 ts, 548 rew

agent-1: 30.0
agent-2: 32.0
agent-3: 3.0
agent-4: 34.0
agent-5: 42.0
agent-6: 33.0
agent-7: 35.0
agent-8: 12.0
agent-9: 36.0
agent-10: 38.0
agent-11: 24.0
agent-12: 38.0
agent-13: 26.0
agent-14: 34.0
agent-15: 27.0
agent-16: 22.0
agent-17: 36.0
agent-18: 36.0
agent-19: 29.0
agent-20: 5.0
Sum Reward: 572.0
Avg Reward: 28.6
Min Reward: 3.0
Max Reward: 42.0
Gini Coefficient: 0.19143356643356643
20:20 Ratio: 3.6666666666666665
Max-min Ratio: 14.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-19-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 548.51
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 339
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.565
    dispatch_time_ms: 4.862
    learner:
      cur_lr: 0.0009084520279429853
      grad_gnorm: 1.144028902053833
      policy_entropy: 367.2353820800781
      policy_loss: 0.23213206231594086
      var_gnorm: 45.68498992919922
      vf_explained_var: -1.0
      vf_loss: 0.0016841406468302011
    num_steps_sampled: 6800000
    num_steps_trained: 6800000
    wait_time_ms: 344.486
  iterations_since_restore: 340
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 11867.381510257721
  time_this_iter_s: 34.66873335838318
  time_total_s: 11867.381510257721
  timestamp: 1594149555
  timesteps_since_restore: 6800000
  timesteps_this_iter: 20000
  timesteps_total: 6800000
  training_iteration: 340
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 11867 s, 340 iter, 6800000 ts, 549 rew

agent-1: 43.0
agent-2: 29.0
agent-3: 30.0
agent-4: 22.0
agent-5: 25.0
agent-6: 35.0
agent-7: 16.0
agent-8: 22.0
agent-9: 24.0
agent-10: 25.0
agent-11: 37.0
agent-12: 28.0
agent-13: 27.0
agent-14: 38.0
agent-15: 39.0
agent-16: 27.0
agent-17: 26.0
agent-18: 33.0
agent-19: 29.0
agent-20: 35.0
Sum Reward: 590.0
Avg Reward: 29.5
Min Reward: 16.0
Max Reward: 43.0
Gini Coefficient: 0.12559322033898304
20:20 Ratio: 1.869047619047619
Max-min Ratio: 2.6875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-19-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 549.07
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 340
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.485
    dispatch_time_ms: 5.681
    learner:
      cur_lr: 0.0009071200038306415
      grad_gnorm: 40.00000762939453
      policy_entropy: 112.69635772705078
      policy_loss: 12.658162117004395
      var_gnorm: 45.68197250366211
      vf_explained_var: 0.7808710336685181
      vf_loss: 186.428466796875
    num_steps_sampled: 6820000
    num_steps_trained: 6820000
    wait_time_ms: 324.773
  iterations_since_restore: 341
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 11901.770550727844
  time_this_iter_s: 34.38904047012329
  time_total_s: 11901.770550727844
  timestamp: 1594149590
  timesteps_since_restore: 6820000
  timesteps_this_iter: 20000
  timesteps_total: 6820000
  training_iteration: 341
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 11901 s, 341 iter, 6820000 ts, 549 rew

agent-1: 18.0
agent-2: 28.0
agent-3: 22.0
agent-4: 23.0
agent-5: 31.0
agent-6: 32.0
agent-7: 31.0
agent-8: 25.0
agent-9: 21.0
agent-10: 32.0
agent-11: 22.0
agent-12: 32.0
agent-13: 35.0
agent-14: 17.0
agent-15: 26.0
agent-16: 27.0
agent-17: 27.0
agent-18: 20.0
agent-19: 34.0
agent-20: 15.0
Sum Reward: 518.0
Avg Reward: 25.9
Min Reward: 15.0
Max Reward: 35.0
Gini Coefficient: 0.12857142857142856
20:20 Ratio: 1.9
Max-min Ratio: 2.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-20-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 549.18
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 341
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.494
    dispatch_time_ms: 5.28
    learner:
      cur_lr: 0.0009057879797182977
      grad_gnorm: 3.5008885860443115
      policy_entropy: 372.01385498046875
      policy_loss: 1.0714315176010132
      var_gnorm: 45.857078552246094
      vf_explained_var: 0.8803395628929138
      vf_loss: 0.005840458907186985
    num_steps_sampled: 6840000
    num_steps_trained: 6840000
    wait_time_ms: 345.795
  iterations_since_restore: 342
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 11936.341834783554
  time_this_iter_s: 34.57128405570984
  time_total_s: 11936.341834783554
  timestamp: 1594149624
  timesteps_since_restore: 6840000
  timesteps_this_iter: 20000
  timesteps_total: 6840000
  training_iteration: 342
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 11936 s, 342 iter, 6840000 ts, 549 rew

agent-1: 28.0
agent-2: 38.0
agent-3: 22.0
agent-4: 21.0
agent-5: 43.0
agent-6: 33.0
agent-7: 42.0
agent-8: 24.0
agent-9: 30.0
agent-10: 19.0
agent-11: 22.0
agent-12: 34.0
agent-13: 16.0
agent-14: 36.0
agent-15: 39.0
agent-16: 44.0
agent-17: 27.0
agent-18: 19.0
agent-19: 31.0
agent-20: 38.0
Sum Reward: 606.0
Avg Reward: 30.3
Min Reward: 16.0
Max Reward: 44.0
Gini Coefficient: 0.16287128712871288
20:20 Ratio: 2.24
Max-min Ratio: 2.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-20-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 549.98
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 342
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.084
    dispatch_time_ms: 7.993
    learner:
      cur_lr: 0.0009044560138136148
      grad_gnorm: 3.12113618850708
      policy_entropy: 367.7594909667969
      policy_loss: 1.3641499280929565
      var_gnorm: 45.84681701660156
      vf_explained_var: 3.6597251892089844e-05
      vf_loss: 0.0029399956110864878
    num_steps_sampled: 6860000
    num_steps_trained: 6860000
    wait_time_ms: 347.351
  iterations_since_restore: 343
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 11971.216275215149
  time_this_iter_s: 34.87444043159485
  time_total_s: 11971.216275215149
  timestamp: 1594149659
  timesteps_since_restore: 6860000
  timesteps_this_iter: 20000
  timesteps_total: 6860000
  training_iteration: 343
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 11971 s, 343 iter, 6860000 ts, 550 rew

agent-1: 27.0
agent-2: 10.0
agent-3: 14.0
agent-4: 37.0
agent-5: 38.0
agent-6: 29.0
agent-7: 33.0
agent-8: 20.0
agent-9: 39.0
agent-10: 27.0
agent-11: 30.0
agent-12: 29.0
agent-13: 31.0
agent-14: 27.0
agent-15: 37.0
agent-16: 33.0
agent-17: 38.0
agent-18: 21.0
agent-19: 27.0
agent-20: 42.0
Sum Reward: 589.0
Avg Reward: 29.45
Min Reward: 10.0
Max Reward: 42.0
Gini Coefficient: 0.15305602716468591
20:20 Ratio: 2.4153846153846152
Max-min Ratio: 4.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-21-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 550.61
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 343
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.787
    dispatch_time_ms: 8.319
    learner:
      cur_lr: 0.0009031239897012711
      grad_gnorm: 1.708681583404541
      policy_entropy: 368.56390380859375
      policy_loss: 0.2740396559238434
      var_gnorm: 45.955501556396484
      vf_explained_var: -1.0
      vf_loss: 0.004990932997316122
    num_steps_sampled: 6880000
    num_steps_trained: 6880000
    wait_time_ms: 341.514
  iterations_since_restore: 344
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 12005.490821123123
  time_this_iter_s: 34.27454590797424
  time_total_s: 12005.490821123123
  timestamp: 1594149693
  timesteps_since_restore: 6880000
  timesteps_this_iter: 20000
  timesteps_total: 6880000
  training_iteration: 344
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 12005 s, 344 iter, 6880000 ts, 551 rew

agent-1: 20.0
agent-2: 34.0
agent-3: 22.0
agent-4: 27.0
agent-5: 19.0
agent-6: 24.0
agent-7: 18.0
agent-8: 36.0
agent-9: 28.0
agent-10: 19.0
agent-11: 23.0
agent-12: 27.0
agent-13: 20.0
agent-14: 23.0
agent-15: 25.0
agent-16: 25.0
agent-17: 24.0
agent-18: 23.0
agent-19: 30.0
agent-20: 32.0
Sum Reward: 499.0
Avg Reward: 24.95
Min Reward: 18.0
Max Reward: 36.0
Gini Coefficient: 0.11012024048096192
20:20 Ratio: 1.736842105263158
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-22-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 550.16
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 344
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.559
    dispatch_time_ms: 5.712
    learner:
      cur_lr: 0.0009017920237965882
      grad_gnorm: 40.0
      policy_entropy: 144.90640258789062
      policy_loss: 16.560049057006836
      var_gnorm: 45.9582633972168
      vf_explained_var: 0.7319251894950867
      vf_loss: 164.55697631835938
    num_steps_sampled: 6900000
    num_steps_trained: 6900000
    wait_time_ms: 322.712
  iterations_since_restore: 345
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 12040.281938791275
  time_this_iter_s: 34.791117668151855
  time_total_s: 12040.281938791275
  timestamp: 1594149728
  timesteps_since_restore: 6900000
  timesteps_this_iter: 20000
  timesteps_total: 6900000
  training_iteration: 345
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 12040 s, 345 iter, 6900000 ts, 550 rew

agent-1: 28.0
agent-2: 24.0
agent-3: 34.0
agent-4: 30.0
agent-5: 26.0
agent-6: 21.0
agent-7: 37.0
agent-8: 19.0
agent-9: 13.0
agent-10: 17.0
agent-11: 41.0
agent-12: 21.0
agent-13: 38.0
agent-14: 26.0
agent-15: 23.0
agent-16: 26.0
agent-17: 39.0
agent-18: 24.0
agent-19: 43.0
agent-20: 34.0
Sum Reward: 564.0
Avg Reward: 28.2
Min Reward: 13.0
Max Reward: 43.0
Gini Coefficient: 0.16666666666666666
20:20 Ratio: 2.3
Max-min Ratio: 3.3076923076923075
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-22-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 550.29
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 345
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.336
    dispatch_time_ms: 7.375
    learner:
      cur_lr: 0.0009004599996842444
      grad_gnorm: 0.14169932901859283
      policy_entropy: 385.2600402832031
      policy_loss: -0.07926079630851746
      var_gnorm: 46.06774139404297
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 4.454795544006629e-06
    num_steps_sampled: 6920000
    num_steps_trained: 6920000
    wait_time_ms: 338.969
  iterations_since_restore: 346
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 12074.964981794357
  time_this_iter_s: 34.683043003082275
  time_total_s: 12074.964981794357
  timestamp: 1594149763
  timesteps_since_restore: 6920000
  timesteps_this_iter: 20000
  timesteps_total: 6920000
  training_iteration: 346
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 12074 s, 346 iter, 6920000 ts, 550 rew

agent-1: 27.0
agent-2: 32.0
agent-3: 26.0
agent-4: 29.0
agent-5: 38.0
agent-6: 25.0
agent-7: 33.0
agent-8: 18.0
agent-9: 31.0
agent-10: 15.0
agent-11: 26.0
agent-12: 23.0
agent-13: 12.0
agent-14: 29.0
agent-15: 30.0
agent-16: 33.0
agent-17: 38.0
agent-18: 11.0
agent-19: 33.0
agent-20: 24.0
Sum Reward: 533.0
Avg Reward: 26.65
Min Reward: 11.0
Max Reward: 38.0
Gini Coefficient: 0.1571294559099437
20:20 Ratio: 2.5357142857142856
Max-min Ratio: 3.4545454545454546
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-23-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 549.89
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 346
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.85
    dispatch_time_ms: 6.663
    learner:
      cur_lr: 0.0008991279755719006
      grad_gnorm: 40.0
      policy_entropy: 232.30923461914062
      policy_loss: 32.64551544189453
      var_gnorm: 46.105712890625
      vf_explained_var: 0.3791728615760803
      vf_loss: 24.645315170288086
    num_steps_sampled: 6940000
    num_steps_trained: 6940000
    wait_time_ms: 338.123
  iterations_since_restore: 347
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 12109.898489236832
  time_this_iter_s: 34.933507442474365
  time_total_s: 12109.898489236832
  timestamp: 1594149798
  timesteps_since_restore: 6940000
  timesteps_this_iter: 20000
  timesteps_total: 6940000
  training_iteration: 347
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 12109 s, 347 iter, 6940000 ts, 550 rew

agent-1: 34.0
agent-2: 39.0
agent-3: 31.0
agent-4: 20.0
agent-5: 29.0
agent-6: 25.0
agent-7: 27.0
agent-8: 20.0
agent-9: 23.0
agent-10: 31.0
agent-11: 24.0
agent-12: 22.0
agent-13: 31.0
agent-14: 19.0
agent-15: 29.0
agent-16: 14.0
agent-17: 38.0
agent-18: 25.0
agent-19: 26.0
agent-20: 25.0
Sum Reward: 532.0
Avg Reward: 26.6
Min Reward: 14.0
Max Reward: 39.0
Gini Coefficient: 0.13007518796992482
20:20 Ratio: 1.9452054794520548
Max-min Ratio: 2.7857142857142856
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-23-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 550.15
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 347
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.63
    dispatch_time_ms: 5.627
    learner:
      cur_lr: 0.0008977960096672177
      grad_gnorm: 0.36951348185539246
      policy_entropy: 369.74005126953125
      policy_loss: 0.5323702692985535
      var_gnorm: 46.19380569458008
      vf_explained_var: 0.0
      vf_loss: 1.545360390764472e-07
    num_steps_sampled: 6960000
    num_steps_trained: 6960000
    wait_time_ms: 338.595
  iterations_since_restore: 348
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 12144.449521303177
  time_this_iter_s: 34.551032066345215
  time_total_s: 12144.449521303177
  timestamp: 1594149833
  timesteps_since_restore: 6960000
  timesteps_this_iter: 20000
  timesteps_total: 6960000
  training_iteration: 348
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 12144 s, 348 iter, 6960000 ts, 550 rew

agent-1: 21.0
agent-2: 27.0
agent-3: 52.0
agent-4: 25.0
agent-5: 21.0
agent-6: 28.0
agent-7: 20.0
agent-8: 35.0
agent-9: 27.0
agent-10: 25.0
agent-11: 17.0
agent-12: 30.0
agent-13: 14.0
agent-14: 29.0
agent-15: 24.0
agent-16: 23.0
agent-17: 20.0
agent-18: 24.0
agent-19: 27.0
agent-20: 33.0
Sum Reward: 522.0
Avg Reward: 26.1
Min Reward: 14.0
Max Reward: 52.0
Gini Coefficient: 0.14904214559386972
20:20 Ratio: 2.112676056338028
Max-min Ratio: 3.7142857142857144
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-24-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 549.72
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 348
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.422
    dispatch_time_ms: 5.353
    learner:
      cur_lr: 0.0008964639855548739
      grad_gnorm: 39.9999885559082
      policy_entropy: 134.88607788085938
      policy_loss: -27.42375946044922
      var_gnorm: 46.14451217651367
      vf_explained_var: 0.7095740437507629
      vf_loss: 60.43849182128906
    num_steps_sampled: 6980000
    num_steps_trained: 6980000
    wait_time_ms: 326.239
  iterations_since_restore: 349
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 12179.181289196014
  time_this_iter_s: 34.731767892837524
  time_total_s: 12179.181289196014
  timestamp: 1594149867
  timesteps_since_restore: 6980000
  timesteps_this_iter: 20000
  timesteps_total: 6980000
  training_iteration: 349
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 12179 s, 349 iter, 6980000 ts, 550 rew

agent-1: 21.0
agent-2: 19.0
agent-3: 27.0
agent-4: 35.0
agent-5: 21.0
agent-6: 34.0
agent-7: 28.0
agent-8: 19.0
agent-9: 27.0
agent-10: 36.0
agent-11: 39.0
agent-12: 16.0
agent-13: 23.0
agent-14: 21.0
agent-15: 35.0
agent-16: 21.0
agent-17: 30.0
agent-18: 27.0
agent-19: 25.0
agent-20: 25.0
Sum Reward: 529.0
Avg Reward: 26.45
Min Reward: 16.0
Max Reward: 39.0
Gini Coefficient: 0.13695652173913042
20:20 Ratio: 1.9333333333333333
Max-min Ratio: 2.4375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-25-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 549.77
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 349
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.425
    dispatch_time_ms: 6.399
    learner:
      cur_lr: 0.0008951320196501911
      grad_gnorm: 0.7319253087043762
      policy_entropy: 380.6937255859375
      policy_loss: 0.47293755412101746
      var_gnorm: 46.132171630859375
      vf_explained_var: 0.0003806948661804199
      vf_loss: 3.8375445001292974e-05
    num_steps_sampled: 7000000
    num_steps_trained: 7000000
    wait_time_ms: 347.19
  iterations_since_restore: 350
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 12213.84518289566
  time_this_iter_s: 34.663893699645996
  time_total_s: 12213.84518289566
  timestamp: 1594149902
  timesteps_since_restore: 7000000
  timesteps_this_iter: 20000
  timesteps_total: 7000000
  training_iteration: 350
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 12213 s, 350 iter, 7000000 ts, 550 rew

agent-1: 25.0
agent-2: 21.0
agent-3: 31.0
agent-4: 29.0
agent-5: 31.0
agent-6: 17.0
agent-7: 19.0
agent-8: 17.0
agent-9: 16.0
agent-10: 32.0
agent-11: 31.0
agent-12: 26.0
agent-13: 23.0
agent-14: 22.0
agent-15: 26.0
agent-16: 23.0
agent-17: 35.0
agent-18: 28.0
agent-19: 27.0
agent-20: 24.0
Sum Reward: 503.0
Avg Reward: 25.15
Min Reward: 16.0
Max Reward: 35.0
Gini Coefficient: 0.1209741550695825
20:20 Ratio: 1.8695652173913044
Max-min Ratio: 2.1875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-25-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 549.46
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 350
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.822
    dispatch_time_ms: 6.554
    learner:
      cur_lr: 0.0008937999955378473
      grad_gnorm: 40.0
      policy_entropy: 79.70956420898438
      policy_loss: -7.310851097106934
      var_gnorm: 46.14509963989258
      vf_explained_var: 0.6070133447647095
      vf_loss: 385.44091796875
    num_steps_sampled: 7020000
    num_steps_trained: 7020000
    wait_time_ms: 318.733
  iterations_since_restore: 351
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 12248.58420085907
  time_this_iter_s: 34.739017963409424
  time_total_s: 12248.58420085907
  timestamp: 1594149937
  timesteps_since_restore: 7020000
  timesteps_this_iter: 20000
  timesteps_total: 7020000
  training_iteration: 351
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 12248 s, 351 iter, 7020000 ts, 549 rew

agent-1: 30.0
agent-2: 32.0
agent-3: 34.0
agent-4: 34.0
agent-5: 23.0
agent-6: 31.0
agent-7: 25.0
agent-8: 32.0
agent-9: 24.0
agent-10: 35.0
agent-11: 24.0
agent-12: 30.0
agent-13: 28.0
agent-14: 26.0
agent-15: 37.0
agent-16: 37.0
agent-17: 23.0
agent-18: 37.0
agent-19: 26.0
agent-20: 24.0
Sum Reward: 592.0
Avg Reward: 29.6
Min Reward: 23.0
Max Reward: 37.0
Gini Coefficient: 0.09408783783783783
20:20 Ratio: 1.553191489361702
Max-min Ratio: 1.608695652173913
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-26-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 550.04
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 351
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.505
    dispatch_time_ms: 5.563
    learner:
      cur_lr: 0.0008924679714255035
      grad_gnorm: 23.9769287109375
      policy_entropy: 350.23797607421875
      policy_loss: -1.6336452960968018
      var_gnorm: 46.18946838378906
      vf_explained_var: 0.7446277737617493
      vf_loss: 10.303309440612793
    num_steps_sampled: 7040000
    num_steps_trained: 7040000
    wait_time_ms: 336.067
  iterations_since_restore: 352
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 12283.207545995712
  time_this_iter_s: 34.623345136642456
  time_total_s: 12283.207545995712
  timestamp: 1594149971
  timesteps_since_restore: 7040000
  timesteps_this_iter: 20000
  timesteps_total: 7040000
  training_iteration: 352
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 12283 s, 352 iter, 7040000 ts, 550 rew

agent-1: 35.0
agent-2: 29.0
agent-3: 26.0
agent-4: 20.0
agent-5: 23.0
agent-6: 29.0
agent-7: 27.0
agent-8: 30.0
agent-9: 37.0
agent-10: 15.0
agent-11: 29.0
agent-12: 21.0
agent-13: 28.0
agent-14: 23.0
agent-15: 34.0
agent-16: 30.0
agent-17: 36.0
agent-18: 25.0
agent-19: 41.0
agent-20: 24.0
Sum Reward: 562.0
Avg Reward: 28.1
Min Reward: 15.0
Max Reward: 41.0
Gini Coefficient: 0.12419928825622775
20:20 Ratio: 1.8860759493670887
Max-min Ratio: 2.7333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-26-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 550.44
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 352
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 4.089
    dispatch_time_ms: 5.452
    learner:
      cur_lr: 0.0008911360055208206
      grad_gnorm: 39.9999885559082
      policy_entropy: 98.88191986083984
      policy_loss: -20.203975677490234
      var_gnorm: 46.20927047729492
      vf_explained_var: 0.2356014847755432
      vf_loss: 202.22921752929688
    num_steps_sampled: 7060000
    num_steps_trained: 7060000
    wait_time_ms: 326.33
  iterations_since_restore: 353
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 12317.870273590088
  time_this_iter_s: 34.66272759437561
  time_total_s: 12317.870273590088
  timestamp: 1594150006
  timesteps_since_restore: 7060000
  timesteps_this_iter: 20000
  timesteps_total: 7060000
  training_iteration: 353
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 12317 s, 353 iter, 7060000 ts, 550 rew

agent-1: 14.0
agent-2: 13.0
agent-3: 25.0
agent-4: 21.0
agent-5: 30.0
agent-6: 18.0
agent-7: 29.0
agent-8: 29.0
agent-9: 33.0
agent-10: 21.0
agent-11: 29.0
agent-12: 25.0
agent-13: 26.0
agent-14: 25.0
agent-15: 28.0
agent-16: 23.0
agent-17: 24.0
agent-18: 27.0
agent-19: 25.0
agent-20: 21.0
Sum Reward: 486.0
Avg Reward: 24.3
Min Reward: 13.0
Max Reward: 33.0
Gini Coefficient: 0.11419753086419752
20:20 Ratio: 1.8333333333333333
Max-min Ratio: 2.5384615384615383
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-27-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 549.95
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 353
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.803
    dispatch_time_ms: 6.164
    learner:
      cur_lr: 0.0008898039814084768
      grad_gnorm: 2.9387009143829346
      policy_entropy: 331.16156005859375
      policy_loss: 2.0002031326293945
      var_gnorm: 46.29799270629883
      vf_explained_var: -3.337860107421875e-06
      vf_loss: 0.0025688540190458298
    num_steps_sampled: 7080000
    num_steps_trained: 7080000
    wait_time_ms: 343.257
  iterations_since_restore: 354
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 12352.638693094254
  time_this_iter_s: 34.76841950416565
  time_total_s: 12352.638693094254
  timestamp: 1594150041
  timesteps_since_restore: 7080000
  timesteps_this_iter: 20000
  timesteps_total: 7080000
  training_iteration: 354
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 12352 s, 354 iter, 7080000 ts, 550 rew

agent-1: 13.0
agent-2: 17.0
agent-3: 14.0
agent-4: 24.0
agent-5: 17.0
agent-6: 22.0
agent-7: 38.0
agent-8: 32.0
agent-9: 21.0
agent-10: 32.0
agent-11: 35.0
agent-12: 32.0
agent-13: 32.0
agent-14: 30.0
agent-15: 34.0
agent-16: 22.0
agent-17: 26.0
agent-18: 27.0
agent-19: 30.0
agent-20: 29.0
Sum Reward: 527.0
Avg Reward: 26.35
Min Reward: 13.0
Max Reward: 38.0
Gini Coefficient: 0.15246679316888045
20:20 Ratio: 2.278688524590164
Max-min Ratio: 2.923076923076923
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-27-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 549.75
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 354
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.087
    dispatch_time_ms: 8.148
    learner:
      cur_lr: 0.000888472015503794
      grad_gnorm: 39.999996185302734
      policy_entropy: 100.20632934570312
      policy_loss: -0.3524909019470215
      var_gnorm: 46.27608108520508
      vf_explained_var: 0.774225652217865
      vf_loss: 281.4859619140625
    num_steps_sampled: 7100000
    num_steps_trained: 7100000
    wait_time_ms: 322.384
  iterations_since_restore: 355
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 12387.387581586838
  time_this_iter_s: 34.74888849258423
  time_total_s: 12387.387581586838
  timestamp: 1594150076
  timesteps_since_restore: 7100000
  timesteps_this_iter: 20000
  timesteps_total: 7100000
  training_iteration: 355
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 12387 s, 355 iter, 7100000 ts, 550 rew

agent-1: 30.0
agent-2: 25.0
agent-3: 25.0
agent-4: 25.0
agent-5: 30.0
agent-6: 42.0
agent-7: 28.0
agent-8: 15.0
agent-9: 28.0
agent-10: 21.0
agent-11: 22.0
agent-12: 28.0
agent-13: 25.0
agent-14: 17.0
agent-15: 29.0
agent-16: 21.0
agent-17: 18.0
agent-18: 28.0
agent-19: 27.0
agent-20: 36.0
Sum Reward: 520.0
Avg Reward: 26.0
Min Reward: 15.0
Max Reward: 42.0
Gini Coefficient: 0.1271153846153846
20:20 Ratio: 1.943661971830986
Max-min Ratio: 2.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-28-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 549.32
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 355
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.222
    dispatch_time_ms: 7.099
    learner:
      cur_lr: 0.0008871399913914502
      grad_gnorm: 11.711446762084961
      policy_entropy: 356.48284912109375
      policy_loss: 0.7729623913764954
      var_gnorm: 46.30867385864258
      vf_explained_var: -0.7755783796310425
      vf_loss: 0.14228281378746033
    num_steps_sampled: 7120000
    num_steps_trained: 7120000
    wait_time_ms: 342.875
  iterations_since_restore: 356
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 12421.747227191925
  time_this_iter_s: 34.35964560508728
  time_total_s: 12421.747227191925
  timestamp: 1594150110
  timesteps_since_restore: 7120000
  timesteps_this_iter: 20000
  timesteps_total: 7120000
  training_iteration: 356
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 12421 s, 356 iter, 7120000 ts, 549 rew

agent-1: 31.0
agent-2: 22.0
agent-3: 22.0
agent-4: 38.0
agent-5: 21.0
agent-6: 31.0
agent-7: 40.0
agent-8: 24.0
agent-9: 43.0
agent-10: 22.0
agent-11: 12.0
agent-12: 20.0
agent-13: 29.0
agent-14: 22.0
agent-15: 38.0
agent-16: 37.0
agent-17: 34.0
agent-18: 15.0
agent-19: 21.0
agent-20: 33.0
Sum Reward: 555.0
Avg Reward: 27.75
Min Reward: 12.0
Max Reward: 43.0
Gini Coefficient: 0.17504504504504503
20:20 Ratio: 2.338235294117647
Max-min Ratio: 3.5833333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-29-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 549.42
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 356
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.968
    dispatch_time_ms: 31.149
    learner:
      cur_lr: 0.0008858080254867673
      grad_gnorm: 39.999996185302734
      policy_entropy: 307.90008544921875
      policy_loss: 0.9986028671264648
      var_gnorm: 46.31913375854492
      vf_explained_var: -1.0
      vf_loss: 0.10665541887283325
    num_steps_sampled: 7140000
    num_steps_trained: 7140000
    wait_time_ms: 154.96
  iterations_since_restore: 357
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 12456.907878398895
  time_this_iter_s: 35.160651206970215
  time_total_s: 12456.907878398895
  timestamp: 1594150145
  timesteps_since_restore: 7140000
  timesteps_this_iter: 20000
  timesteps_total: 7140000
  training_iteration: 357
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 12456 s, 357 iter, 7140000 ts, 549 rew

agent-1: 30.0
agent-2: 14.0
agent-3: 32.0
agent-4: 24.0
agent-5: 19.0
agent-6: 27.0
agent-7: 26.0
agent-8: 23.0
agent-9: 23.0
agent-10: 21.0
agent-11: 21.0
agent-12: 35.0
agent-13: 29.0
agent-14: 35.0
agent-15: 39.0
agent-16: 35.0
agent-17: 27.0
agent-18: 27.0
agent-19: 33.0
agent-20: 27.0
Sum Reward: 547.0
Avg Reward: 27.35
Min Reward: 14.0
Max Reward: 39.0
Gini Coefficient: 0.12678244972577696
20:20 Ratio: 1.92
Max-min Ratio: 2.7857142857142856
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-29-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 549.52
  episode_reward_min: 479.0
  episodes_this_iter: 1
  episodes_total: 357
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.885
    dispatch_time_ms: 5.644
    learner:
      cur_lr: 0.0008844760013744235
      grad_gnorm: 13.980960845947266
      policy_entropy: 334.5904846191406
      policy_loss: -1.3280035257339478
      var_gnorm: 46.355987548828125
      vf_explained_var: -1.0
      vf_loss: 0.10207992792129517
    num_steps_sampled: 7160000
    num_steps_trained: 7160000
    wait_time_ms: 348.032
  iterations_since_restore: 358
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 12491.613453865051
  time_this_iter_s: 34.705575466156006
  time_total_s: 12491.613453865051
  timestamp: 1594150180
  timesteps_since_restore: 7160000
  timesteps_this_iter: 20000
  timesteps_total: 7160000
  training_iteration: 358
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 12491 s, 358 iter, 7160000 ts, 550 rew

agent-1: 25.0
agent-2: 29.0
agent-3: 23.0
agent-4: 27.0
agent-5: 23.0
agent-6: 28.0
agent-7: 26.0
agent-8: 30.0
agent-9: 20.0
agent-10: 31.0
agent-11: 22.0
agent-12: 24.0
agent-13: 31.0
agent-14: 29.0
agent-15: 26.0
agent-16: 21.0
agent-17: 30.0
agent-18: 30.0
agent-19: 24.0
agent-20: 21.0
Sum Reward: 520.0
Avg Reward: 26.0
Min Reward: 20.0
Max Reward: 31.0
Gini Coefficient: 0.07788461538461539
20:20 Ratio: 1.4523809523809523
Max-min Ratio: 1.55
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-30-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 549.93
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 358
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.87
    dispatch_time_ms: 6.186
    learner:
      cur_lr: 0.0008831439772620797
      grad_gnorm: 39.999996185302734
      policy_entropy: 64.60296630859375
      policy_loss: -23.65740966796875
      var_gnorm: 46.34553527832031
      vf_explained_var: 0.3489728569984436
      vf_loss: 332.52099609375
    num_steps_sampled: 7180000
    num_steps_trained: 7180000
    wait_time_ms: 298.098
  iterations_since_restore: 359
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 12526.149608135223
  time_this_iter_s: 34.53615427017212
  time_total_s: 12526.149608135223
  timestamp: 1594150215
  timesteps_since_restore: 7180000
  timesteps_this_iter: 20000
  timesteps_total: 7180000
  training_iteration: 359
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 12526 s, 359 iter, 7180000 ts, 550 rew

agent-1: 31.0
agent-2: 20.0
agent-3: 25.0
agent-4: 33.0
agent-5: 26.0
agent-6: 23.0
agent-7: 25.0
agent-8: 32.0
agent-9: 31.0
agent-10: 24.0
agent-11: 26.0
agent-12: 20.0
agent-13: 19.0
agent-14: 21.0
agent-15: 27.0
agent-16: 28.0
agent-17: 23.0
agent-18: 30.0
agent-19: 34.0
agent-20: 30.0
Sum Reward: 528.0
Avg Reward: 26.4
Min Reward: 19.0
Max Reward: 34.0
Gini Coefficient: 0.09753787878787878
20:20 Ratio: 1.625
Max-min Ratio: 1.7894736842105263
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-30-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 549.87
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 359
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.711
    dispatch_time_ms: 9.678
    learner:
      cur_lr: 0.0008818120113573968
      grad_gnorm: 2.015279531478882
      policy_entropy: 371.86309814453125
      policy_loss: -0.33707067370414734
      var_gnorm: 46.54237365722656
      vf_explained_var: -1.0
      vf_loss: 0.006366038229316473
    num_steps_sampled: 7200000
    num_steps_trained: 7200000
    wait_time_ms: 338.037
  iterations_since_restore: 360
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 12561.568095207214
  time_this_iter_s: 35.41848707199097
  time_total_s: 12561.568095207214
  timestamp: 1594150250
  timesteps_since_restore: 7200000
  timesteps_this_iter: 20000
  timesteps_total: 7200000
  training_iteration: 360
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 12561 s, 360 iter, 7200000 ts, 550 rew

agent-1: 31.0
agent-2: 27.0
agent-3: 31.0
agent-4: 16.0
agent-5: 23.0
agent-6: 19.0
agent-7: 27.0
agent-8: 26.0
agent-9: 22.0
agent-10: 27.0
agent-11: 34.0
agent-12: 34.0
agent-13: 35.0
agent-14: 25.0
agent-15: 31.0
agent-16: 30.0
agent-17: 30.0
agent-18: 34.0
agent-19: 28.0
agent-20: 35.0
Sum Reward: 565.0
Avg Reward: 28.25
Min Reward: 16.0
Max Reward: 35.0
Gini Coefficient: 0.10256637168141593
20:20 Ratio: 1.725
Max-min Ratio: 2.1875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-31-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 550.65
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 360
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.148
    dispatch_time_ms: 6.6
    learner:
      cur_lr: 0.000880479987245053
      grad_gnorm: 1.606221318244934
      policy_entropy: 380.1416320800781
      policy_loss: -0.691267728805542
      var_gnorm: 46.52093505859375
      vf_explained_var: -1.0
      vf_loss: 0.0016861374024301767
    num_steps_sampled: 7220000
    num_steps_trained: 7220000
    wait_time_ms: 347.764
  iterations_since_restore: 361
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 12596.316702842712
  time_this_iter_s: 34.74860763549805
  time_total_s: 12596.316702842712
  timestamp: 1594150285
  timesteps_since_restore: 7220000
  timesteps_this_iter: 20000
  timesteps_total: 7220000
  training_iteration: 361
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 12596 s, 361 iter, 7220000 ts, 551 rew

agent-1: 27.0
agent-2: 10.0
agent-3: 23.0
agent-4: 24.0
agent-5: 32.0
agent-6: 13.0
agent-7: 16.0
agent-8: 24.0
agent-9: 31.0
agent-10: 31.0
agent-11: 29.0
agent-12: 29.0
agent-13: 28.0
agent-14: 23.0
agent-15: 29.0
agent-16: 25.0
agent-17: 28.0
agent-18: 26.0
agent-19: 32.0
agent-20: 37.0
Sum Reward: 517.0
Avg Reward: 25.85
Min Reward: 10.0
Max Reward: 37.0
Gini Coefficient: 0.13297872340425532
20:20 Ratio: 2.129032258064516
Max-min Ratio: 3.7
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-32-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 550.07
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 361
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.189
    dispatch_time_ms: 19.48
    learner:
      cur_lr: 0.0008791480213403702
      grad_gnorm: 0.38091030716896057
      policy_entropy: 376.386474609375
      policy_loss: -0.5274975299835205
      var_gnorm: 46.62671661376953
      vf_explained_var: -1.0
      vf_loss: 0.0015572336269542575
    num_steps_sampled: 7240000
    num_steps_trained: 7240000
    wait_time_ms: 339.89
  iterations_since_restore: 362
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 12630.913886070251
  time_this_iter_s: 34.59718322753906
  time_total_s: 12630.913886070251
  timestamp: 1594150320
  timesteps_since_restore: 7240000
  timesteps_this_iter: 20000
  timesteps_total: 7240000
  training_iteration: 362
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 12630 s, 362 iter, 7240000 ts, 550 rew

agent-1: 25.0
agent-2: 20.0
agent-3: 34.0
agent-4: 24.0
agent-5: 27.0
agent-6: 20.0
agent-7: 31.0
agent-8: 30.0
agent-9: 34.0
agent-10: 29.0
agent-11: 32.0
agent-12: 24.0
agent-13: 18.0
agent-14: 35.0
agent-15: 30.0
agent-16: 22.0
agent-17: 26.0
agent-18: 14.0
agent-19: 25.0
agent-20: 29.0
Sum Reward: 529.0
Avg Reward: 26.45
Min Reward: 14.0
Max Reward: 35.0
Gini Coefficient: 0.11956521739130435
20:20 Ratio: 1.875
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-32-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 549.84
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 362
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.12
    dispatch_time_ms: 27.137
    learner:
      cur_lr: 0.0008778159972280264
      grad_gnorm: 0.640620231628418
      policy_entropy: 382.3390197753906
      policy_loss: 0.16848750412464142
      var_gnorm: 46.62820053100586
      vf_explained_var: -1.0
      vf_loss: 1.6128932429637644e-06
    num_steps_sampled: 7260000
    num_steps_trained: 7260000
    wait_time_ms: 1024.371
  iterations_since_restore: 363
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 12677.145702838898
  time_this_iter_s: 46.23181676864624
  time_total_s: 12677.145702838898
  timestamp: 1594150366
  timesteps_since_restore: 7260000
  timesteps_this_iter: 20000
  timesteps_total: 7260000
  training_iteration: 363
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 12677 s, 363 iter, 7260000 ts, 550 rew

agent-1: 32.0
agent-2: 25.0
agent-3: 22.0
agent-4: 18.0
agent-5: 23.0
agent-6: 32.0
agent-7: 28.0
agent-8: 28.0
agent-9: 26.0
agent-10: 35.0
agent-11: 19.0
agent-12: 33.0
agent-13: 25.0
agent-14: 19.0
agent-15: 37.0
agent-16: 25.0
agent-17: 28.0
agent-18: 31.0
agent-19: 24.0
agent-20: 35.0
Sum Reward: 545.0
Avg Reward: 27.25
Min Reward: 18.0
Max Reward: 37.0
Gini Coefficient: 0.11513761467889909
20:20 Ratio: 1.794871794871795
Max-min Ratio: 2.0555555555555554
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-33-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 550.32
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 363
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.727
    dispatch_time_ms: 13.751
    learner:
      cur_lr: 0.0008764839731156826
      grad_gnorm: 1.7860130071640015
      policy_entropy: 346.98272705078125
      policy_loss: 2.965359926223755
      var_gnorm: 46.6596794128418
      vf_explained_var: 0.48494821786880493
      vf_loss: 0.03912857919931412
    num_steps_sampled: 7280000
    num_steps_trained: 7280000
    wait_time_ms: 336.666
  iterations_since_restore: 364
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 12711.207976818085
  time_this_iter_s: 34.06227397918701
  time_total_s: 12711.207976818085
  timestamp: 1594150400
  timesteps_since_restore: 7280000
  timesteps_this_iter: 20000
  timesteps_total: 7280000
  training_iteration: 364
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 12711 s, 364 iter, 7280000 ts, 550 rew

agent-1: 17.0
agent-2: 35.0
agent-3: 27.0
agent-4: 17.0
agent-5: 23.0
agent-6: 20.0
agent-7: 21.0
agent-8: 18.0
agent-9: 27.0
agent-10: 21.0
agent-11: 24.0
agent-12: 24.0
agent-13: 16.0
agent-14: 22.0
agent-15: 23.0
agent-16: 32.0
agent-17: 33.0
agent-18: 27.0
agent-19: 41.0
agent-20: 23.0
Sum Reward: 491.0
Avg Reward: 24.55
Min Reward: 16.0
Max Reward: 41.0
Gini Coefficient: 0.1414460285132383
20:20 Ratio: 2.073529411764706
Max-min Ratio: 2.5625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-34-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 549.41
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 364
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.564
    dispatch_time_ms: 6.123
    learner:
      cur_lr: 0.0008751520072109997
      grad_gnorm: 1.1674249172210693
      policy_entropy: 361.858154296875
      policy_loss: -0.1088801771402359
      var_gnorm: 46.65961456298828
      vf_explained_var: 0.0003266334533691406
      vf_loss: 0.0003979918546974659
    num_steps_sampled: 7300000
    num_steps_trained: 7300000
    wait_time_ms: 282.689
  iterations_since_restore: 365
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 12752.022067785263
  time_this_iter_s: 40.814090967178345
  time_total_s: 12752.022067785263
  timestamp: 1594150448
  timesteps_since_restore: 7300000
  timesteps_this_iter: 20000
  timesteps_total: 7300000
  training_iteration: 365
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 12752 s, 365 iter, 7300000 ts, 549 rew

agent-1: 31.0
agent-2: 50.0
agent-3: 29.0
agent-4: 24.0
agent-5: 27.0
agent-6: 22.0
agent-7: 25.0
agent-8: 27.0
agent-9: 19.0
agent-10: 23.0
agent-11: 21.0
agent-12: 36.0
agent-13: 13.0
agent-14: 21.0
agent-15: 25.0
agent-16: 25.0
agent-17: 20.0
agent-18: 30.0
agent-19: 20.0
agent-20: 33.0
Sum Reward: 521.0
Avg Reward: 26.05
Min Reward: 13.0
Max Reward: 50.0
Gini Coefficient: 0.14961612284069098
20:20 Ratio: 2.0833333333333335
Max-min Ratio: 3.8461538461538463
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-34-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 548.88
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 365
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.807
    dispatch_time_ms: 6.716
    learner:
      cur_lr: 0.0008738199830986559
      grad_gnorm: 0.18347331881523132
      policy_entropy: 363.2752685546875
      policy_loss: -0.1862419843673706
      var_gnorm: 46.69690704345703
      vf_explained_var: -1.0
      vf_loss: 0.0009284939151257277
    num_steps_sampled: 7320000
    num_steps_trained: 7320000
    wait_time_ms: 347.7
  iterations_since_restore: 366
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 12786.059655666351
  time_this_iter_s: 34.03758788108826
  time_total_s: 12786.059655666351
  timestamp: 1594150482
  timesteps_since_restore: 7320000
  timesteps_this_iter: 20000
  timesteps_total: 7320000
  training_iteration: 366
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 12786 s, 366 iter, 7320000 ts, 549 rew

agent-1: 22.0
agent-2: 23.0
agent-3: 24.0
agent-4: 26.0
agent-5: 30.0
agent-6: 24.0
agent-7: 21.0
agent-8: 31.0
agent-9: 35.0
agent-10: 28.0
agent-11: 32.0
agent-12: 25.0
agent-13: 30.0
agent-14: 19.0
agent-15: 31.0
agent-16: 21.0
agent-17: 23.0
agent-18: 27.0
agent-19: 24.0
agent-20: 19.0
Sum Reward: 515.0
Avg Reward: 25.75
Min Reward: 19.0
Max Reward: 35.0
Gini Coefficient: 0.0983495145631068
20:20 Ratio: 1.6125
Max-min Ratio: 1.8421052631578947
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-35-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 548.01
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 366
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.819
    dispatch_time_ms: 6.633
    learner:
      cur_lr: 0.0008724880171939731
      grad_gnorm: 40.00000762939453
      policy_entropy: 38.350276947021484
      policy_loss: -42.97126388549805
      var_gnorm: 46.687416076660156
      vf_explained_var: 0.5510401725769043
      vf_loss: 768.2129516601562
    num_steps_sampled: 7340000
    num_steps_trained: 7340000
    wait_time_ms: 291.167
  iterations_since_restore: 367
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 12820.966839551926
  time_this_iter_s: 34.90718388557434
  time_total_s: 12820.966839551926
  timestamp: 1594150517
  timesteps_since_restore: 7340000
  timesteps_this_iter: 20000
  timesteps_total: 7340000
  training_iteration: 367
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 12820 s, 367 iter, 7340000 ts, 548 rew

agent-1: 27.0
agent-2: 32.0
agent-3: 23.0
agent-4: 23.0
agent-5: 20.0
agent-6: 22.0
agent-7: 23.0
agent-8: 21.0
agent-9: 28.0
agent-10: 31.0
agent-11: 33.0
agent-12: 28.0
agent-13: 31.0
agent-14: 31.0
agent-15: 26.0
agent-16: 33.0
agent-17: 23.0
agent-18: 20.0
agent-19: 35.0
agent-20: 26.0
Sum Reward: 536.0
Avg Reward: 26.8
Min Reward: 20.0
Max Reward: 35.0
Gini Coefficient: 0.09925373134328358
20:20 Ratio: 1.6024096385542168
Max-min Ratio: 1.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-35-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 547.63
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 367
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.391
    dispatch_time_ms: 9.837
    learner:
      cur_lr: 0.0008711559930816293
      grad_gnorm: 7.551748275756836
      policy_entropy: 376.1552734375
      policy_loss: 0.45027875900268555
      var_gnorm: 46.71366882324219
      vf_explained_var: -1.0
      vf_loss: 0.015789879485964775
    num_steps_sampled: 7360000
    num_steps_trained: 7360000
    wait_time_ms: 59.384
  iterations_since_restore: 368
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 12857.491863250732
  time_this_iter_s: 36.52502369880676
  time_total_s: 12857.491863250732
  timestamp: 1594150554
  timesteps_since_restore: 7360000
  timesteps_this_iter: 20000
  timesteps_total: 7360000
  training_iteration: 368
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 12857 s, 368 iter, 7360000 ts, 548 rew

agent-1: 31.0
agent-2: 24.0
agent-3: 37.0
agent-4: 26.0
agent-5: 32.0
agent-6: 35.0
agent-7: 26.0
agent-8: 31.0
agent-9: 29.0
agent-10: 27.0
agent-11: 37.0
agent-12: 24.0
agent-13: 31.0
agent-14: 22.0
agent-15: 28.0
agent-16: 22.0
agent-17: 33.0
agent-18: 20.0
agent-19: 12.0
agent-20: 31.0
Sum Reward: 558.0
Avg Reward: 27.9
Min Reward: 12.0
Max Reward: 37.0
Gini Coefficient: 0.11881720430107527
20:20 Ratio: 1.868421052631579
Max-min Ratio: 3.0833333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-36-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 547.99
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 368
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.151
    dispatch_time_ms: 7.784
    learner:
      cur_lr: 0.0008698240271769464
      grad_gnorm: 1.13089919090271
      policy_entropy: 381.2079772949219
      policy_loss: -0.026177167892456055
      var_gnorm: 46.71237564086914
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0003530156100168824
    num_steps_sampled: 7380000
    num_steps_trained: 7380000
    wait_time_ms: 278.68
  iterations_since_restore: 369
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 12891.589005947113
  time_this_iter_s: 34.097142696380615
  time_total_s: 12891.589005947113
  timestamp: 1594150588
  timesteps_since_restore: 7380000
  timesteps_this_iter: 20000
  timesteps_total: 7380000
  training_iteration: 369
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 12891 s, 369 iter, 7380000 ts, 548 rew

agent-1: 22.0
agent-2: 26.0
agent-3: 28.0
agent-4: 24.0
agent-5: 25.0
agent-6: 33.0
agent-7: 29.0
agent-8: 26.0
agent-9: 24.0
agent-10: 30.0
agent-11: 31.0
agent-12: 18.0
agent-13: 29.0
agent-14: 30.0
agent-15: 29.0
agent-16: 30.0
agent-17: 28.0
agent-18: 35.0
agent-19: 36.0
agent-20: 25.0
Sum Reward: 558.0
Avg Reward: 27.9
Min Reward: 18.0
Max Reward: 36.0
Gini Coefficient: 0.08387096774193549
20:20 Ratio: 1.5340909090909092
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-37-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 656.0
  episode_reward_mean: 548.03
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 369
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.394
    dispatch_time_ms: 35.726
    learner:
      cur_lr: 0.0008684920030646026
      grad_gnorm: 40.000003814697266
      policy_entropy: 170.6768341064453
      policy_loss: -37.9074821472168
      var_gnorm: 46.969730377197266
      vf_explained_var: 0.48188453912734985
      vf_loss: 79.30152893066406
    num_steps_sampled: 7400000
    num_steps_trained: 7400000
    wait_time_ms: 328.998
  iterations_since_restore: 370
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 12923.158692836761
  time_this_iter_s: 31.569686889648438
  time_total_s: 12923.158692836761
  timestamp: 1594150620
  timesteps_since_restore: 7400000
  timesteps_this_iter: 20000
  timesteps_total: 7400000
  training_iteration: 370
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 12923 s, 370 iter, 7400000 ts, 548 rew

agent-1: 51.0
agent-2: 51.0
agent-3: 52.0
agent-4: 38.0
agent-5: 77.0
agent-6: 41.0
agent-7: 52.0
agent-8: 52.0
agent-9: 48.0
agent-10: 55.0
agent-11: 48.0
agent-12: 45.0
agent-13: 62.0
agent-14: 44.0
agent-15: 73.0
agent-16: 68.0
agent-17: 71.0
agent-18: 48.0
agent-19: 57.0
agent-20: 64.0
Sum Reward: 1097.0
Avg Reward: 54.85
Min Reward: 38.0
Max Reward: 77.0
Gini Coefficient: 0.10834092980856883
20:20 Ratio: 1.7202380952380953
Max-min Ratio: 2.026315789473684
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-37-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 553.74
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 370
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.587
    dispatch_time_ms: 28.634
    learner:
      cur_lr: 0.0008671599789522588
      grad_gnorm: 2.0783321857452393
      policy_entropy: 378.2780456542969
      policy_loss: 1.075603723526001
      var_gnorm: 47.038692474365234
      vf_explained_var: 0.7540523409843445
      vf_loss: 0.0012575970031321049
    num_steps_sampled: 7420000
    num_steps_trained: 7420000
    wait_time_ms: 293.261
  iterations_since_restore: 371
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 12959.684678316116
  time_this_iter_s: 36.52598547935486
  time_total_s: 12959.684678316116
  timestamp: 1594150656
  timesteps_since_restore: 7420000
  timesteps_this_iter: 20000
  timesteps_total: 7420000
  training_iteration: 371
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 12959 s, 371 iter, 7420000 ts, 554 rew

agent-1: 26.0
agent-2: 40.0
agent-3: 23.0
agent-4: 38.0
agent-5: 19.0
agent-6: 34.0
agent-7: 26.0
agent-8: 18.0
agent-9: 25.0
agent-10: 38.0
agent-11: 36.0
agent-12: 61.0
agent-13: 33.0
agent-14: 38.0
agent-15: 42.0
agent-16: 45.0
agent-17: 29.0
agent-18: 36.0
agent-19: 55.0
agent-20: 42.0
Sum Reward: 704.0
Avg Reward: 35.2
Min Reward: 18.0
Max Reward: 61.0
Gini Coefficient: 0.16917613636363638
20:20 Ratio: 2.388235294117647
Max-min Ratio: 3.388888888888889
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-38-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 555.15
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 371
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.154
    dispatch_time_ms: 27.11
    learner:
      cur_lr: 0.000865828013047576
      grad_gnorm: 10.61948299407959
      policy_entropy: 310.7346496582031
      policy_loss: 5.464341163635254
      var_gnorm: 47.02267074584961
      vf_explained_var: 0.9249698519706726
      vf_loss: 0.06197783350944519
    num_steps_sampled: 7440000
    num_steps_trained: 7440000
    wait_time_ms: 346.9
  iterations_since_restore: 372
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 12995.209751844406
  time_this_iter_s: 35.525073528289795
  time_total_s: 12995.209751844406
  timestamp: 1594150692
  timesteps_since_restore: 7440000
  timesteps_this_iter: 20000
  timesteps_total: 7440000
  training_iteration: 372
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 12995 s, 372 iter, 7440000 ts, 555 rew

agent-1: 26.0
agent-2: 50.0
agent-3: 39.0
agent-4: 30.0
agent-5: 31.0
agent-6: 50.0
agent-7: 23.0
agent-8: 33.0
agent-9: 56.0
agent-10: 42.0
agent-11: 47.0
agent-12: 38.0
agent-13: 51.0
agent-14: 35.0
agent-15: 34.0
agent-16: 16.0
agent-17: 19.0
agent-18: 32.0
agent-19: 4.0
agent-20: 36.0
Sum Reward: 692.0
Avg Reward: 34.6
Min Reward: 4.0
Max Reward: 56.0
Gini Coefficient: 0.20476878612716762
20:20 Ratio: 3.338709677419355
Max-min Ratio: 14.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-38-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 556.69
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 372
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.56
    dispatch_time_ms: 5.912
    learner:
      cur_lr: 0.0008644959889352322
      grad_gnorm: 40.000022888183594
      policy_entropy: 29.609439849853516
      policy_loss: 42.735599517822266
      var_gnorm: 47.026947021484375
      vf_explained_var: 0.5727625489234924
      vf_loss: 208.71466064453125
    num_steps_sampled: 7460000
    num_steps_trained: 7460000
    wait_time_ms: 295.48
  iterations_since_restore: 373
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 13027.59862613678
  time_this_iter_s: 32.38887429237366
  time_total_s: 13027.59862613678
  timestamp: 1594150728
  timesteps_since_restore: 7460000
  timesteps_this_iter: 20000
  timesteps_total: 7460000
  training_iteration: 373
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 13027 s, 373 iter, 7460000 ts, 557 rew

agent-1: 21.0
agent-2: 31.0
agent-3: 22.0
agent-4: 35.0
agent-5: 46.0
agent-6: 40.0
agent-7: 39.0
agent-8: 25.0
agent-9: 32.0
agent-10: 29.0
agent-11: 35.0
agent-12: 33.0
agent-13: 31.0
agent-14: 42.0
agent-15: 42.0
agent-16: 41.0
agent-17: 26.0
agent-18: 33.0
agent-19: 45.0
agent-20: 36.0
Sum Reward: 684.0
Avg Reward: 34.2
Min Reward: 21.0
Max Reward: 46.0
Gini Coefficient: 0.11885964912280701
20:20 Ratio: 1.8617021276595744
Max-min Ratio: 2.1904761904761907
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-39-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 556.97
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 373
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.609
    dispatch_time_ms: 6.493
    learner:
      cur_lr: 0.0008631640230305493
      grad_gnorm: 5.70814847946167
      policy_entropy: 367.15289306640625
      policy_loss: 5.178787708282471
      var_gnorm: 47.202598571777344
      vf_explained_var: -1.0
      vf_loss: 0.010175630450248718
    num_steps_sampled: 7480000
    num_steps_trained: 7480000
    wait_time_ms: 347.89
  iterations_since_restore: 374
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 13061.295480966568
  time_this_iter_s: 33.69685482978821
  time_total_s: 13061.295480966568
  timestamp: 1594150762
  timesteps_since_restore: 7480000
  timesteps_this_iter: 20000
  timesteps_total: 7480000
  training_iteration: 374
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 13061 s, 374 iter, 7480000 ts, 557 rew

agent-1: 13.0
agent-2: 27.0
agent-3: 43.0
agent-4: 46.0
agent-5: 11.0
agent-6: 29.0
agent-7: 34.0
agent-8: 33.0
agent-9: 47.0
agent-10: 22.0
agent-11: 24.0
agent-12: 37.0
agent-13: 54.0
agent-14: 21.0
agent-15: 42.0
agent-16: 20.0
agent-17: 28.0
agent-18: 66.0
agent-19: 70.0
agent-20: 42.0
Sum Reward: 709.0
Avg Reward: 35.45
Min Reward: 11.0
Max Reward: 70.0
Gini Coefficient: 0.24717912552891397
20:20 Ratio: 3.646153846153846
Max-min Ratio: 6.363636363636363
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-39-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 558.16
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 374
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.366
    dispatch_time_ms: 5.504
    learner:
      cur_lr: 0.0008618319989182055
      grad_gnorm: 0.7565335631370544
      policy_entropy: 377.2242126464844
      policy_loss: -0.06632661819458008
      var_gnorm: 47.202720642089844
      vf_explained_var: -0.6785753965377808
      vf_loss: 0.0007282242877408862
    num_steps_sampled: 7500000
    num_steps_trained: 7500000
    wait_time_ms: 334.974
  iterations_since_restore: 375
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 13096.529141426086
  time_this_iter_s: 35.23366045951843
  time_total_s: 13096.529141426086
  timestamp: 1594150797
  timesteps_since_restore: 7500000
  timesteps_this_iter: 20000
  timesteps_total: 7500000
  training_iteration: 375
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 13096 s, 375 iter, 7500000 ts, 558 rew

agent-1: 26.0
agent-2: 17.0
agent-3: 31.0
agent-4: 54.0
agent-5: 30.0
agent-6: 52.0
agent-7: 21.0
agent-8: 41.0
agent-9: 24.0
agent-10: 49.0
agent-11: 30.0
agent-12: 24.0
agent-13: 40.0
agent-14: 27.0
agent-15: 45.0
agent-16: 17.0
agent-17: 40.0
agent-18: 40.0
agent-19: 47.0
agent-20: 47.0
Sum Reward: 702.0
Avg Reward: 35.1
Min Reward: 17.0
Max Reward: 54.0
Gini Coefficient: 0.18717948717948718
20:20 Ratio: 2.5569620253164556
Max-min Ratio: 3.176470588235294
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-40-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 559.84
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 375
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.902
    dispatch_time_ms: 5.51
    learner:
      cur_lr: 0.0008604999748058617
      grad_gnorm: 1.4446744918823242
      policy_entropy: 364.65533447265625
      policy_loss: -0.14957526326179504
      var_gnorm: 47.245513916015625
      vf_explained_var: -0.6778606176376343
      vf_loss: 0.0012835850939154625
    num_steps_sampled: 7520000
    num_steps_trained: 7520000
    wait_time_ms: 350.84
  iterations_since_restore: 376
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 13130.860613822937
  time_this_iter_s: 34.331472396850586
  time_total_s: 13130.860613822937
  timestamp: 1594150832
  timesteps_since_restore: 7520000
  timesteps_this_iter: 20000
  timesteps_total: 7520000
  training_iteration: 376
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 13130 s, 376 iter, 7520000 ts, 560 rew

agent-1: 14.0
agent-2: 32.0
agent-3: 29.0
agent-4: 25.0
agent-5: 32.0
agent-6: 35.0
agent-7: 25.0
agent-8: 36.0
agent-9: 20.0
agent-10: 21.0
agent-11: 29.0
agent-12: 33.0
agent-13: 37.0
agent-14: 33.0
agent-15: 28.0
agent-16: 20.0
agent-17: 31.0
agent-18: 37.0
agent-19: 21.0
agent-20: 30.0
Sum Reward: 568.0
Avg Reward: 28.4
Min Reward: 14.0
Max Reward: 37.0
Gini Coefficient: 0.12570422535211268
20:20 Ratio: 1.9333333333333333
Max-min Ratio: 2.642857142857143
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-41-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 560.23
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 376
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.671
    dispatch_time_ms: 5.663
    learner:
      cur_lr: 0.0008591680089011788
      grad_gnorm: 0.5045017004013062
      policy_entropy: 375.941650390625
      policy_loss: -0.21345265209674835
      var_gnorm: 47.247291564941406
      vf_explained_var: -0.8539983034133911
      vf_loss: 0.00014837831258773804
    num_steps_sampled: 7540000
    num_steps_trained: 7540000
    wait_time_ms: 344.052
  iterations_since_restore: 377
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 13166.004384040833
  time_this_iter_s: 35.14377021789551
  time_total_s: 13166.004384040833
  timestamp: 1594150867
  timesteps_since_restore: 7540000
  timesteps_this_iter: 20000
  timesteps_total: 7540000
  training_iteration: 377
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 13166 s, 377 iter, 7540000 ts, 560 rew

agent-1: 18.0
agent-2: 38.0
agent-3: 43.0
agent-4: 35.0
agent-5: 28.0
agent-6: 26.0
agent-7: 28.0
agent-8: 26.0
agent-9: 35.0
agent-10: 21.0
agent-11: 22.0
agent-12: 31.0
agent-13: 26.0
agent-14: 23.0
agent-15: 33.0
agent-16: 33.0
agent-17: 34.0
agent-18: 39.0
agent-19: 42.0
agent-20: 33.0
Sum Reward: 614.0
Avg Reward: 30.7
Min Reward: 18.0
Max Reward: 43.0
Gini Coefficient: 0.1270358306188925
20:20 Ratio: 1.9285714285714286
Max-min Ratio: 2.388888888888889
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-41-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 560.42
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 377
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.595
    dispatch_time_ms: 6.951
    learner:
      cur_lr: 0.000857835984788835
      grad_gnorm: 6.764298915863037
      policy_entropy: 372.35479736328125
      policy_loss: -0.6291587352752686
      var_gnorm: 47.326786041259766
      vf_explained_var: -1.0
      vf_loss: 0.001763966167345643
    num_steps_sampled: 7560000
    num_steps_trained: 7560000
    wait_time_ms: 344.745
  iterations_since_restore: 378
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 13200.015729665756
  time_this_iter_s: 34.011345624923706
  time_total_s: 13200.015729665756
  timestamp: 1594150901
  timesteps_since_restore: 7560000
  timesteps_this_iter: 20000
  timesteps_total: 7560000
  training_iteration: 378
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 13200 s, 378 iter, 7560000 ts, 560 rew

agent-1: 36.0
agent-2: 33.0
agent-3: 30.0
agent-4: 35.0
agent-5: 31.0
agent-6: 26.0
agent-7: 15.0
agent-8: 33.0
agent-9: 29.0
agent-10: 24.0
agent-11: 31.0
agent-12: 32.0
agent-13: 20.0
agent-14: 23.0
agent-15: 39.0
agent-16: 33.0
agent-17: 29.0
agent-18: 22.0
agent-19: 32.0
agent-20: 23.0
Sum Reward: 576.0
Avg Reward: 28.8
Min Reward: 15.0
Max Reward: 39.0
Gini Coefficient: 0.11354166666666667
20:20 Ratio: 1.7875
Max-min Ratio: 2.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-42-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 560.56
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 378
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.938
    dispatch_time_ms: 11.167
    learner:
      cur_lr: 0.0008565040188841522
      grad_gnorm: 0.2099040001630783
      policy_entropy: 380.1605529785156
      policy_loss: -0.3412349820137024
      var_gnorm: 47.34451675415039
      vf_explained_var: -5.4836273193359375e-06
      vf_loss: 1.8857239183489583e-06
    num_steps_sampled: 7580000
    num_steps_trained: 7580000
    wait_time_ms: 328.099
  iterations_since_restore: 379
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 13235.79247713089
  time_this_iter_s: 35.77674746513367
  time_total_s: 13235.79247713089
  timestamp: 1594150937
  timesteps_since_restore: 7580000
  timesteps_this_iter: 20000
  timesteps_total: 7580000
  training_iteration: 379
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 13235 s, 379 iter, 7580000 ts, 561 rew

agent-1: 38.0
agent-2: 31.0
agent-3: 27.0
agent-4: 35.0
agent-5: 29.0
agent-6: 27.0
agent-7: 35.0
agent-8: 19.0
agent-9: 34.0
agent-10: 30.0
agent-11: 31.0
agent-12: 10.0
agent-13: 23.0
agent-14: 19.0
agent-15: 31.0
agent-16: 27.0
agent-17: 34.0
agent-18: 29.0
agent-19: 18.0
agent-20: 27.0
Sum Reward: 554.0
Avg Reward: 27.7
Min Reward: 10.0
Max Reward: 38.0
Gini Coefficient: 0.13267148014440433
20:20 Ratio: 2.1515151515151514
Max-min Ratio: 3.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-42-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 560.66
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 379
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.53
    dispatch_time_ms: 5.591
    learner:
      cur_lr: 0.0008551719947718084
      grad_gnorm: 5.770451545715332
      policy_entropy: 343.91119384765625
      policy_loss: -0.8117688298225403
      var_gnorm: 47.38178253173828
      vf_explained_var: -0.21455514430999756
      vf_loss: 0.01344508957117796
    num_steps_sampled: 7600000
    num_steps_trained: 7600000
    wait_time_ms: 341.596
  iterations_since_restore: 380
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 13269.814914226532
  time_this_iter_s: 34.02243709564209
  time_total_s: 13269.814914226532
  timestamp: 1594150971
  timesteps_since_restore: 7600000
  timesteps_this_iter: 20000
  timesteps_total: 7600000
  training_iteration: 380
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 13269 s, 380 iter, 7600000 ts, 561 rew

agent-1: 10.0
agent-2: 28.0
agent-3: 32.0
agent-4: 32.0
agent-5: 28.0
agent-6: 27.0
agent-7: 21.0
agent-8: 27.0
agent-9: 37.0
agent-10: 26.0
agent-11: 37.0
agent-12: 31.0
agent-13: 26.0
agent-14: 34.0
agent-15: 35.0
agent-16: 11.0
agent-17: 22.0
agent-18: 28.0
agent-19: 22.0
agent-20: 39.0
Sum Reward: 553.0
Avg Reward: 27.65
Min Reward: 10.0
Max Reward: 39.0
Gini Coefficient: 0.14945750452079565
20:20 Ratio: 2.3125
Max-min Ratio: 3.9
agent-1: 36.0
agent-2: 38.0
agent-3: 45.0
agent-4: 6.0
agent-5: 31.0
agent-6: 39.0
agent-7: 55.0
agent-8: 30.0
agent-9: 23.0
agent-10: 25.0
agent-11: 25.0
agent-12: 23.0
agent-13: 31.0
agent-14: 28.0
agent-15: 39.0
agent-16: 39.0
agent-17: 17.0
agent-18: 33.0
agent-19: 30.0
agent-20: 25.0
Sum Reward: 618.0
Avg Reward: 30.9
Min Reward: 6.0
Max Reward: 55.0
Gini Coefficient: 0.18058252427184465
20:20 Ratio: 2.579710144927536
Max-min Ratio: 9.166666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-43-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 562.32
  episode_reward_min: 486.0
  episodes_this_iter: 2
  episodes_total: 381
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.348
    dispatch_time_ms: 5.766
    learner:
      cur_lr: 0.0008538400288671255
      grad_gnorm: 10.893011093139648
      policy_entropy: 332.55767822265625
      policy_loss: 3.0574843883514404
      var_gnorm: 47.38752746582031
      vf_explained_var: -1.0
      vf_loss: 0.055928051471710205
    num_steps_sampled: 7620000
    num_steps_trained: 7620000
    wait_time_ms: 343.438
  iterations_since_restore: 381
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 13305.076133728027
  time_this_iter_s: 35.26121950149536
  time_total_s: 13305.076133728027
  timestamp: 1594151006
  timesteps_since_restore: 7620000
  timesteps_this_iter: 20000
  timesteps_total: 7620000
  training_iteration: 381
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 13305 s, 381 iter, 7620000 ts, 562 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-44-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 562.32
  episode_reward_min: 486.0
  episodes_this_iter: 0
  episodes_total: 381
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.39
    dispatch_time_ms: 6.045
    learner:
      cur_lr: 0.0008525080047547817
      grad_gnorm: 8.24123477935791
      policy_entropy: 341.61627197265625
      policy_loss: -1.677441120147705
      var_gnorm: 47.41841125488281
      vf_explained_var: 0.3989047408103943
      vf_loss: 0.035283975303173065
    num_steps_sampled: 7640000
    num_steps_trained: 7640000
    wait_time_ms: 336.953
  iterations_since_restore: 382
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 13339.23699760437
  time_this_iter_s: 34.16086387634277
  time_total_s: 13339.23699760437
  timestamp: 1594151041
  timesteps_since_restore: 7640000
  timesteps_this_iter: 20000
  timesteps_total: 7640000
  training_iteration: 382
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 13339 s, 382 iter, 7640000 ts, 562 rew

agent-1: 33.0
agent-2: 32.0
agent-3: 28.0
agent-4: 34.0
agent-5: 16.0
agent-6: 29.0
agent-7: 23.0
agent-8: 18.0
agent-9: 31.0
agent-10: 37.0
agent-11: 18.0
agent-12: 34.0
agent-13: 33.0
agent-14: 25.0
agent-15: 23.0
agent-16: 19.0
agent-17: 26.0
agent-18: 35.0
agent-19: 31.0
agent-20: 27.0
Sum Reward: 552.0
Avg Reward: 27.6
Min Reward: 16.0
Max Reward: 37.0
Gini Coefficient: 0.12771739130434784
20:20 Ratio: 1.971830985915493
Max-min Ratio: 2.3125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-44-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 562.49
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 382
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.592
    dispatch_time_ms: 7.252
    learner:
      cur_lr: 0.0008511759806424379
      grad_gnorm: 40.0
      policy_entropy: 45.59812927246094
      policy_loss: -3.6307785511016846
      var_gnorm: 47.42421340942383
      vf_explained_var: 0.31090062856674194
      vf_loss: 461.7027587890625
    num_steps_sampled: 7660000
    num_steps_trained: 7660000
    wait_time_ms: 305.818
  iterations_since_restore: 383
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 13374.333973407745
  time_this_iter_s: 35.096975803375244
  time_total_s: 13374.333973407745
  timestamp: 1594151076
  timesteps_since_restore: 7660000
  timesteps_this_iter: 20000
  timesteps_total: 7660000
  training_iteration: 383
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 13374 s, 383 iter, 7660000 ts, 562 rew

agent-1: 44.0
agent-2: 25.0
agent-3: 19.0
agent-4: 39.0
agent-5: 30.0
agent-6: 29.0
agent-7: 27.0
agent-8: 29.0
agent-9: 29.0
agent-10: 23.0
agent-11: 22.0
agent-12: 31.0
agent-13: 18.0
agent-14: 35.0
agent-15: 41.0
agent-16: 30.0
agent-17: 34.0
agent-18: 38.0
agent-19: 30.0
agent-20: 41.0
Sum Reward: 614.0
Avg Reward: 30.7
Min Reward: 18.0
Max Reward: 44.0
Gini Coefficient: 0.13224755700325733
20:20 Ratio: 2.0121951219512195
Max-min Ratio: 2.4444444444444446
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-45-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 563.22
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 383
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.557
    dispatch_time_ms: 5.678
    learner:
      cur_lr: 0.0008498440147377551
      grad_gnorm: 1.6783230304718018
      policy_entropy: 373.3038330078125
      policy_loss: -0.49891287088394165
      var_gnorm: 47.51371765136719
      vf_explained_var: 0.9230796694755554
      vf_loss: 0.007967937737703323
    num_steps_sampled: 7680000
    num_steps_trained: 7680000
    wait_time_ms: 337.291
  iterations_since_restore: 384
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 13408.645803689957
  time_this_iter_s: 34.311830282211304
  time_total_s: 13408.645803689957
  timestamp: 1594151110
  timesteps_since_restore: 7680000
  timesteps_this_iter: 20000
  timesteps_total: 7680000
  training_iteration: 384
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 13408 s, 384 iter, 7680000 ts, 563 rew

agent-1: 28.0
agent-2: 36.0
agent-3: 31.0
agent-4: 25.0
agent-5: 38.0
agent-6: 30.0
agent-7: 36.0
agent-8: 24.0
agent-9: 24.0
agent-10: 20.0
agent-11: 28.0
agent-12: 28.0
agent-13: 14.0
agent-14: 21.0
agent-15: 27.0
agent-16: 23.0
agent-17: 30.0
agent-18: 19.0
agent-19: 34.0
agent-20: 33.0
Sum Reward: 549.0
Avg Reward: 27.45
Min Reward: 14.0
Max Reward: 38.0
Gini Coefficient: 0.1272313296903461
20:20 Ratio: 1.945945945945946
Max-min Ratio: 2.7142857142857144
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-45-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 563.84
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 384
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.527
    dispatch_time_ms: 6.434
    learner:
      cur_lr: 0.0008485119906254113
      grad_gnorm: 40.0
      policy_entropy: 50.02803039550781
      policy_loss: 34.95973205566406
      var_gnorm: 47.519752502441406
      vf_explained_var: 0.5031324625015259
      vf_loss: 205.29771423339844
    num_steps_sampled: 7700000
    num_steps_trained: 7700000
    wait_time_ms: 311.632
  iterations_since_restore: 385
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 13443.592479467392
  time_this_iter_s: 34.9466757774353
  time_total_s: 13443.592479467392
  timestamp: 1594151145
  timesteps_since_restore: 7700000
  timesteps_this_iter: 20000
  timesteps_total: 7700000
  training_iteration: 385
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 13443 s, 385 iter, 7700000 ts, 564 rew

agent-1: 20.0
agent-2: 27.0
agent-3: 31.0
agent-4: 39.0
agent-5: 23.0
agent-6: 29.0
agent-7: 19.0
agent-8: 33.0
agent-9: 27.0
agent-10: 23.0
agent-11: 36.0
agent-12: 25.0
agent-13: 34.0
agent-14: 37.0
agent-15: 16.0
agent-16: 31.0
agent-17: 36.0
agent-18: 34.0
agent-19: 20.0
agent-20: 21.0
Sum Reward: 561.0
Avg Reward: 28.05
Min Reward: 16.0
Max Reward: 39.0
Gini Coefficient: 0.13787878787878788
20:20 Ratio: 1.9733333333333334
Max-min Ratio: 2.4375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-46-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 564.15
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 385
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.327
    dispatch_time_ms: 5.443
    learner:
      cur_lr: 0.0008471800247207284
      grad_gnorm: 4.923089981079102
      policy_entropy: 341.8380432128906
      policy_loss: -2.031867742538452
      var_gnorm: 47.58365249633789
      vf_explained_var: 0.5444705486297607
      vf_loss: 0.0089208809658885
    num_steps_sampled: 7720000
    num_steps_trained: 7720000
    wait_time_ms: 346.153
  iterations_since_restore: 386
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 13477.849713087082
  time_this_iter_s: 34.25723361968994
  time_total_s: 13477.849713087082
  timestamp: 1594151179
  timesteps_since_restore: 7720000
  timesteps_this_iter: 20000
  timesteps_total: 7720000
  training_iteration: 386
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 13477 s, 386 iter, 7720000 ts, 564 rew

agent-1: 30.0
agent-2: 43.0
agent-3: 29.0
agent-4: 32.0
agent-5: 38.0
agent-6: 35.0
agent-7: 26.0
agent-8: 28.0
agent-9: 22.0
agent-10: 24.0
agent-11: 45.0
agent-12: 30.0
agent-13: 21.0
agent-14: 30.0
agent-15: 34.0
agent-16: 33.0
agent-17: 33.0
agent-18: 28.0
agent-19: 26.0
agent-20: 38.0
Sum Reward: 625.0
Avg Reward: 31.25
Min Reward: 21.0
Max Reward: 45.0
Gini Coefficient: 0.11144
20:20 Ratio: 1.7634408602150538
Max-min Ratio: 2.142857142857143
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-46-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 565.38
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 386
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.051
    dispatch_time_ms: 8.379
    learner:
      cur_lr: 0.0008458480006083846
      grad_gnorm: 0.6052815318107605
      policy_entropy: 365.70172119140625
      policy_loss: 0.07979167997837067
      var_gnorm: 47.59502410888672
      vf_explained_var: 0.9823728799819946
      vf_loss: 0.0009974392596632242
    num_steps_sampled: 7740000
    num_steps_trained: 7740000
    wait_time_ms: 296.587
  iterations_since_restore: 387
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 13512.696757793427
  time_this_iter_s: 34.847044706344604
  time_total_s: 13512.696757793427
  timestamp: 1594151214
  timesteps_since_restore: 7740000
  timesteps_this_iter: 20000
  timesteps_total: 7740000
  training_iteration: 387
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 13512 s, 387 iter, 7740000 ts, 565 rew

agent-1: 33.0
agent-2: 19.0
agent-3: 27.0
agent-4: 33.0
agent-5: 26.0
agent-6: 30.0
agent-7: 47.0
agent-8: 32.0
agent-9: 16.0
agent-10: 24.0
agent-11: 33.0
agent-12: 19.0
agent-13: 50.0
agent-14: 25.0
agent-15: 29.0
agent-16: 32.0
agent-17: 17.0
agent-18: 50.0
agent-19: 36.0
agent-20: 23.0
Sum Reward: 601.0
Avg Reward: 30.05
Min Reward: 16.0
Max Reward: 50.0
Gini Coefficient: 0.1781198003327787
20:20 Ratio: 2.5774647887323945
Max-min Ratio: 3.125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-47-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 566.0
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 387
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.904
    dispatch_time_ms: 5.853
    learner:
      cur_lr: 0.0008445159764960408
      grad_gnorm: 0.3313951790332794
      policy_entropy: 356.43505859375
      policy_loss: -0.27694451808929443
      var_gnorm: 47.61678695678711
      vf_explained_var: 0.9928597211837769
      vf_loss: 0.0009393882937729359
    num_steps_sampled: 7760000
    num_steps_trained: 7760000
    wait_time_ms: 342.625
  iterations_since_restore: 388
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 13547.093029737473
  time_this_iter_s: 34.39627194404602
  time_total_s: 13547.093029737473
  timestamp: 1594151249
  timesteps_since_restore: 7760000
  timesteps_this_iter: 20000
  timesteps_total: 7760000
  training_iteration: 388
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 13547 s, 388 iter, 7760000 ts, 566 rew

agent-1: 32.0
agent-2: 23.0
agent-3: 29.0
agent-4: 17.0
agent-5: 50.0
agent-6: 39.0
agent-7: 17.0
agent-8: 36.0
agent-9: 22.0
agent-10: 50.0
agent-11: 26.0
agent-12: 11.0
agent-13: 38.0
agent-14: 52.0
agent-15: 24.0
agent-16: 28.0
agent-17: 39.0
agent-18: 25.0
agent-19: 25.0
agent-20: 26.0
Sum Reward: 609.0
Avg Reward: 30.45
Min Reward: 11.0
Max Reward: 52.0
Gini Coefficient: 0.20369458128078818
20:20 Ratio: 2.8507462686567164
Max-min Ratio: 4.7272727272727275
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-48-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 566.53
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 388
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.043
    dispatch_time_ms: 6.179
    learner:
      cur_lr: 0.000843184010591358
      grad_gnorm: 40.000003814697266
      policy_entropy: 30.372026443481445
      policy_loss: -7.95997953414917
      var_gnorm: 47.62077331542969
      vf_explained_var: 0.6610269546508789
      vf_loss: 246.742431640625
    num_steps_sampled: 7780000
    num_steps_trained: 7780000
    wait_time_ms: 299.854
  iterations_since_restore: 389
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 13582.147916555405
  time_this_iter_s: 35.05488681793213
  time_total_s: 13582.147916555405
  timestamp: 1594151284
  timesteps_since_restore: 7780000
  timesteps_this_iter: 20000
  timesteps_total: 7780000
  training_iteration: 389
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 13582 s, 389 iter, 7780000 ts, 567 rew

agent-1: 23.0
agent-2: 22.0
agent-3: 18.0
agent-4: 31.0
agent-5: 32.0
agent-6: 9.0
agent-7: 13.0
agent-8: 28.0
agent-9: 35.0
agent-10: 28.0
agent-11: 36.0
agent-12: 26.0
agent-13: 26.0
agent-14: 39.0
agent-15: 21.0
agent-16: 23.0
agent-17: 28.0
agent-18: 17.0
agent-19: 28.0
agent-20: 28.0
Sum Reward: 511.0
Avg Reward: 25.55
Min Reward: 9.0
Max Reward: 39.0
Gini Coefficient: 0.16095890410958905
20:20 Ratio: 2.491228070175439
Max-min Ratio: 4.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-48-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 566.21
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 389
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.533
    dispatch_time_ms: 6.146
    learner:
      cur_lr: 0.0008418519864790142
      grad_gnorm: 6.248289108276367
      policy_entropy: 350.9194030761719
      policy_loss: 2.9319276809692383
      var_gnorm: 47.6702880859375
      vf_explained_var: 0.38088035583496094
      vf_loss: 0.075204037129879
    num_steps_sampled: 7800000
    num_steps_trained: 7800000
    wait_time_ms: 458.03
  iterations_since_restore: 390
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 13617.863276481628
  time_this_iter_s: 35.715359926223755
  time_total_s: 13617.863276481628
  timestamp: 1594151319
  timesteps_since_restore: 7800000
  timesteps_this_iter: 20000
  timesteps_total: 7800000
  training_iteration: 390
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 13617 s, 390 iter, 7800000 ts, 566 rew

agent-1: 25.0
agent-2: 32.0
agent-3: 29.0
agent-4: 17.0
agent-5: 36.0
agent-6: 19.0
agent-7: 37.0
agent-8: 20.0
agent-9: 22.0
agent-10: 26.0
agent-11: 17.0
agent-12: 28.0
agent-13: 29.0
agent-14: 36.0
agent-15: 42.0
agent-16: 12.0
agent-17: 40.0
agent-18: 25.0
agent-19: 29.0
agent-20: 34.0
Sum Reward: 555.0
Avg Reward: 27.75
Min Reward: 12.0
Max Reward: 42.0
Gini Coefficient: 0.1662162162162162
20:20 Ratio: 2.3846153846153846
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-49-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 566.28
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 390
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.115
    dispatch_time_ms: 8.035
    learner:
      cur_lr: 0.0008405200205743313
      grad_gnorm: 0.2287386655807495
      policy_entropy: 363.60675048828125
      policy_loss: -0.02239304967224598
      var_gnorm: 47.674949645996094
      vf_explained_var: -1.0
      vf_loss: 0.00019681963021866977
    num_steps_sampled: 7820000
    num_steps_trained: 7820000
    wait_time_ms: 305.526
  iterations_since_restore: 391
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 13651.755847215652
  time_this_iter_s: 33.89257073402405
  time_total_s: 13651.755847215652
  timestamp: 1594151353
  timesteps_since_restore: 7820000
  timesteps_this_iter: 20000
  timesteps_total: 7820000
  training_iteration: 391
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 13651 s, 391 iter, 7820000 ts, 566 rew

agent-1: 29.0
agent-2: 14.0
agent-3: 28.0
agent-4: 25.0
agent-5: 13.0
agent-6: 53.0
agent-7: 21.0
agent-8: 14.0
agent-9: 22.0
agent-10: 27.0
agent-11: 28.0
agent-12: 48.0
agent-13: 32.0
agent-14: 24.0
agent-15: 18.0
agent-16: 28.0
agent-17: 19.0
agent-18: 26.0
agent-19: 44.0
agent-20: 43.0
Sum Reward: 556.0
Avg Reward: 27.8
Min Reward: 13.0
Max Reward: 53.0
Gini Coefficient: 0.2158273381294964
20:20 Ratio: 3.1864406779661016
Max-min Ratio: 4.076923076923077
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-49-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 566.51
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 391
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.592
    dispatch_time_ms: 5.967
    learner:
      cur_lr: 0.0008391879964619875
      grad_gnorm: 15.308334350585938
      policy_entropy: 344.4365539550781
      policy_loss: 5.5847320556640625
      var_gnorm: 47.6759033203125
      vf_explained_var: 0.9037215709686279
      vf_loss: 1.6209697723388672
    num_steps_sampled: 7840000
    num_steps_trained: 7840000
    wait_time_ms: 340.83
  iterations_since_restore: 392
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 13686.181867837906
  time_this_iter_s: 34.42602062225342
  time_total_s: 13686.181867837906
  timestamp: 1594151388
  timesteps_since_restore: 7840000
  timesteps_this_iter: 20000
  timesteps_total: 7840000
  training_iteration: 392
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 13686 s, 392 iter, 7840000 ts, 567 rew

agent-1: 44.0
agent-2: 29.0
agent-3: 17.0
agent-4: 20.0
agent-5: 27.0
agent-6: 33.0
agent-7: 27.0
agent-8: 47.0
agent-9: 44.0
agent-10: 18.0
agent-11: 19.0
agent-12: 25.0
agent-13: 34.0
agent-14: 22.0
agent-15: 31.0
agent-16: 23.0
agent-17: 16.0
agent-18: 30.0
agent-19: 30.0
agent-20: 27.0
Sum Reward: 563.0
Avg Reward: 28.15
Min Reward: 16.0
Max Reward: 47.0
Gini Coefficient: 0.17202486678507992
20:20 Ratio: 2.414285714285714
Max-min Ratio: 2.9375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-50-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 566.59
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 392
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.941
    dispatch_time_ms: 6.94
    learner:
      cur_lr: 0.0008378559723496437
      grad_gnorm: 3.3660829067230225
      policy_entropy: 360.1492614746094
      policy_loss: 0.045021504163742065
      var_gnorm: 47.67508316040039
      vf_explained_var: -1.0
      vf_loss: 0.0032570085022598505
    num_steps_sampled: 7860000
    num_steps_trained: 7860000
    wait_time_ms: 283.841
  iterations_since_restore: 393
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 13721.08824133873
  time_this_iter_s: 34.906373500823975
  time_total_s: 13721.08824133873
  timestamp: 1594151423
  timesteps_since_restore: 7860000
  timesteps_this_iter: 20000
  timesteps_total: 7860000
  training_iteration: 393
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 13721 s, 393 iter, 7860000 ts, 567 rew

agent-1: 31.0
agent-2: 32.0
agent-3: 28.0
agent-4: 41.0
agent-5: 25.0
agent-6: 22.0
agent-7: 37.0
agent-8: 20.0
agent-9: 34.0
agent-10: 31.0
agent-11: 30.0
agent-12: 21.0
agent-13: 28.0
agent-14: 32.0
agent-15: 25.0
agent-16: 30.0
agent-17: 30.0
agent-18: 24.0
agent-19: 24.0
agent-20: 32.0
Sum Reward: 577.0
Avg Reward: 28.85
Min Reward: 20.0
Max Reward: 41.0
Gini Coefficient: 0.10129982668977469
20:20 Ratio: 1.6551724137931034
Max-min Ratio: 2.05
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-50-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 566.97
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 393
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.845
    dispatch_time_ms: 6.124
    learner:
      cur_lr: 0.0008365240064449608
      grad_gnorm: 4.133296966552734
      policy_entropy: 351.93292236328125
      policy_loss: -0.1654420793056488
      var_gnorm: 47.69319152832031
      vf_explained_var: -0.37738656997680664
      vf_loss: 0.0031383223831653595
    num_steps_sampled: 7880000
    num_steps_trained: 7880000
    wait_time_ms: 346.435
  iterations_since_restore: 394
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 13755.659420728683
  time_this_iter_s: 34.57117938995361
  time_total_s: 13755.659420728683
  timestamp: 1594151457
  timesteps_since_restore: 7880000
  timesteps_this_iter: 20000
  timesteps_total: 7880000
  training_iteration: 394
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 13755 s, 394 iter, 7880000 ts, 567 rew

agent-1: 28.0
agent-2: 35.0
agent-3: 36.0
agent-4: 35.0
agent-5: 34.0
agent-6: 19.0
agent-7: 29.0
agent-8: 30.0
agent-9: 29.0
agent-10: 23.0
agent-11: 36.0
agent-12: 28.0
agent-13: 15.0
agent-14: 30.0
agent-15: 23.0
agent-16: 30.0
agent-17: 22.0
agent-18: 31.0
agent-19: 20.0
agent-20: 24.0
Sum Reward: 557.0
Avg Reward: 27.85
Min Reward: 15.0
Max Reward: 36.0
Gini Coefficient: 0.1196588868940754
20:20 Ratio: 1.868421052631579
Max-min Ratio: 2.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-51-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 567.03
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 394
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.819
    dispatch_time_ms: 6.148
    learner:
      cur_lr: 0.000835191982332617
      grad_gnorm: 8.693832397460938
      policy_entropy: 358.61260986328125
      policy_loss: -0.10060124099254608
      var_gnorm: 47.70292282104492
      vf_explained_var: -1.0
      vf_loss: 0.009980855509638786
    num_steps_sampled: 7900000
    num_steps_trained: 7900000
    wait_time_ms: 312.898
  iterations_since_restore: 395
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 13790.58012509346
  time_this_iter_s: 34.92070436477661
  time_total_s: 13790.58012509346
  timestamp: 1594151492
  timesteps_since_restore: 7900000
  timesteps_this_iter: 20000
  timesteps_total: 7900000
  training_iteration: 395
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 13790 s, 395 iter, 7900000 ts, 567 rew

agent-1: 21.0
agent-2: 26.0
agent-3: 27.0
agent-4: 28.0
agent-5: 30.0
agent-6: 29.0
agent-7: 39.0
agent-8: 19.0
agent-9: 33.0
agent-10: 34.0
agent-11: 29.0
agent-12: 25.0
agent-13: 25.0
agent-14: 26.0
agent-15: 15.0
agent-16: 21.0
agent-17: 28.0
agent-18: 20.0
agent-19: 22.0
agent-20: 32.0
Sum Reward: 529.0
Avg Reward: 26.45
Min Reward: 15.0
Max Reward: 39.0
Gini Coefficient: 0.11918714555765596
20:20 Ratio: 1.84
Max-min Ratio: 2.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-52-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 566.5
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 395
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.723
    dispatch_time_ms: 6.67
    learner:
      cur_lr: 0.0008338600164279342
      grad_gnorm: 0.770359992980957
      policy_entropy: 360.05450439453125
      policy_loss: 0.27222684025764465
      var_gnorm: 47.84814453125
      vf_explained_var: -1.0
      vf_loss: 0.0012008531484752893
    num_steps_sampled: 7920000
    num_steps_trained: 7920000
    wait_time_ms: 344.626
  iterations_since_restore: 396
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 13824.89684510231
  time_this_iter_s: 34.3167200088501
  time_total_s: 13824.89684510231
  timestamp: 1594151527
  timesteps_since_restore: 7920000
  timesteps_this_iter: 20000
  timesteps_total: 7920000
  training_iteration: 396
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 13824 s, 396 iter, 7920000 ts, 566 rew

agent-1: 21.0
agent-2: 29.0
agent-3: 23.0
agent-4: 23.0
agent-5: 32.0
agent-6: 23.0
agent-7: 29.0
agent-8: 31.0
agent-9: 28.0
agent-10: 30.0
agent-11: 23.0
agent-12: 34.0
agent-13: 28.0
agent-14: 33.0
agent-15: 20.0
agent-16: 27.0
agent-17: 24.0
agent-18: 12.0
agent-19: 33.0
agent-20: 30.0
Sum Reward: 533.0
Avg Reward: 26.65
Min Reward: 12.0
Max Reward: 34.0
Gini Coefficient: 0.10947467166979362
20:20 Ratio: 1.736842105263158
Max-min Ratio: 2.8333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-52-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 566.22
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 396
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 4.16
    dispatch_time_ms: 6.015
    learner:
      cur_lr: 0.0008325279923155904
      grad_gnorm: 40.0
      policy_entropy: 43.929344177246094
      policy_loss: -120.40081787109375
      var_gnorm: 47.816307067871094
      vf_explained_var: 0.7189005613327026
      vf_loss: 653.42431640625
    num_steps_sampled: 7940000
    num_steps_trained: 7940000
    wait_time_ms: 290.744
  iterations_since_restore: 397
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 13859.690831184387
  time_this_iter_s: 34.793986082077026
  time_total_s: 13859.690831184387
  timestamp: 1594151562
  timesteps_since_restore: 7940000
  timesteps_this_iter: 20000
  timesteps_total: 7940000
  training_iteration: 397
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 13859 s, 397 iter, 7940000 ts, 566 rew

agent-1: 31.0
agent-2: 31.0
agent-3: 28.0
agent-4: 18.0
agent-5: 25.0
agent-6: 27.0
agent-7: 26.0
agent-8: 27.0
agent-9: 40.0
agent-10: 40.0
agent-11: 24.0
agent-12: 43.0
agent-13: 42.0
agent-14: 21.0
agent-15: 44.0
agent-16: 17.0
agent-17: 36.0
agent-18: 37.0
agent-19: 33.0
agent-20: 19.0
Sum Reward: 609.0
Avg Reward: 30.45
Min Reward: 17.0
Max Reward: 44.0
Gini Coefficient: 0.1583743842364532
20:20 Ratio: 2.2533333333333334
Max-min Ratio: 2.588235294117647
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-53-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 566.77
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 397
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.342
    dispatch_time_ms: 7.815
    learner:
      cur_lr: 0.0008311960264109075
      grad_gnorm: 0.5512234568595886
      policy_entropy: 364.0473937988281
      policy_loss: -0.1061234325170517
      var_gnorm: 47.86032485961914
      vf_explained_var: -0.2897719144821167
      vf_loss: 7.181520049925894e-05
    num_steps_sampled: 7960000
    num_steps_trained: 7960000
    wait_time_ms: 346.878
  iterations_since_restore: 398
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 13894.539257526398
  time_this_iter_s: 34.8484263420105
  time_total_s: 13894.539257526398
  timestamp: 1594151596
  timesteps_since_restore: 7960000
  timesteps_this_iter: 20000
  timesteps_total: 7960000
  training_iteration: 398
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 13894 s, 398 iter, 7960000 ts, 567 rew

agent-1: 31.0
agent-2: 23.0
agent-3: 17.0
agent-4: 41.0
agent-5: 24.0
agent-6: 33.0
agent-7: 26.0
agent-8: 25.0
agent-9: 27.0
agent-10: 22.0
agent-11: 28.0
agent-12: 25.0
agent-13: 6.0
agent-14: 34.0
agent-15: 34.0
agent-16: 8.0
agent-17: 25.0
agent-18: 36.0
agent-19: 25.0
agent-20: 32.0
Sum Reward: 522.0
Avg Reward: 26.1
Min Reward: 6.0
Max Reward: 41.0
Gini Coefficient: 0.17222222222222222
20:20 Ratio: 2.7358490566037736
Max-min Ratio: 6.833333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-53-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 566.63
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 398
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.572
    dispatch_time_ms: 5.95
    learner:
      cur_lr: 0.0008298640022985637
      grad_gnorm: 40.0
      policy_entropy: 55.044517517089844
      policy_loss: 23.15538215637207
      var_gnorm: 47.863372802734375
      vf_explained_var: 0.41038280725479126
      vf_loss: 386.010009765625
    num_steps_sampled: 7980000
    num_steps_trained: 7980000
    wait_time_ms: 310.087
  iterations_since_restore: 399
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 13929.189532518387
  time_this_iter_s: 34.650274991989136
  time_total_s: 13929.189532518387
  timestamp: 1594151631
  timesteps_since_restore: 7980000
  timesteps_this_iter: 20000
  timesteps_total: 7980000
  training_iteration: 399
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 13929 s, 399 iter, 7980000 ts, 567 rew

agent-1: 38.0
agent-2: 30.0
agent-3: 21.0
agent-4: 30.0
agent-5: 36.0
agent-6: 27.0
agent-7: 33.0
agent-8: 29.0
agent-9: 21.0
agent-10: 30.0
agent-11: 33.0
agent-12: 24.0
agent-13: 30.0
agent-14: 15.0
agent-15: 17.0
agent-16: 31.0
agent-17: 33.0
agent-18: 30.0
agent-19: 27.0
agent-20: 26.0
Sum Reward: 561.0
Avg Reward: 28.05
Min Reward: 15.0
Max Reward: 38.0
Gini Coefficient: 0.11399286987522282
20:20 Ratio: 1.8918918918918919
Max-min Ratio: 2.533333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-54-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 566.7
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 399
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.54
    dispatch_time_ms: 5.878
    learner:
      cur_lr: 0.0008285319781862199
      grad_gnorm: 3.8587653636932373
      policy_entropy: 350.8076171875
      policy_loss: -0.2725444436073303
      var_gnorm: 47.88471984863281
      vf_explained_var: -1.0
      vf_loss: 0.0019666841253638268
    num_steps_sampled: 8000000
    num_steps_trained: 8000000
    wait_time_ms: 342.491
  iterations_since_restore: 400
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 13963.854439258575
  time_this_iter_s: 34.6649067401886
  time_total_s: 13963.854439258575
  timestamp: 1594151666
  timesteps_since_restore: 8000000
  timesteps_this_iter: 20000
  timesteps_total: 8000000
  training_iteration: 400
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 13963 s, 400 iter, 8000000 ts, 567 rew

agent-1: 39.0
agent-2: 32.0
agent-3: 30.0
agent-4: 32.0
agent-5: 30.0
agent-6: 28.0
agent-7: 15.0
agent-8: 26.0
agent-9: 35.0
agent-10: 16.0
agent-11: 16.0
agent-12: 37.0
agent-13: 37.0
agent-14: 28.0
agent-15: 24.0
agent-16: 43.0
agent-17: 25.0
agent-18: 26.0
agent-19: 26.0
agent-20: 23.0
Sum Reward: 568.0
Avg Reward: 28.4
Min Reward: 15.0
Max Reward: 43.0
Gini Coefficient: 0.1477112676056338
20:20 Ratio: 2.2285714285714286
Max-min Ratio: 2.8666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-55-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 566.69
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 400
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.898
    dispatch_time_ms: 19.643
    learner:
      cur_lr: 0.0008272000122815371
      grad_gnorm: 39.99999237060547
      policy_entropy: 66.73529052734375
      policy_loss: -4.757214069366455
      var_gnorm: 47.90729904174805
      vf_explained_var: 0.4933195114135742
      vf_loss: 345.3450927734375
    num_steps_sampled: 8020000
    num_steps_trained: 8020000
    wait_time_ms: 321.237
  iterations_since_restore: 401
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 13999.210739850998
  time_this_iter_s: 35.356300592422485
  time_total_s: 13999.210739850998
  timestamp: 1594151701
  timesteps_since_restore: 8020000
  timesteps_this_iter: 20000
  timesteps_total: 8020000
  training_iteration: 401
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 13999 s, 401 iter, 8020000 ts, 567 rew

agent-1: 20.0
agent-2: 30.0
agent-3: 37.0
agent-4: 26.0
agent-5: 27.0
agent-6: 28.0
agent-7: 18.0
agent-8: 26.0
agent-9: 25.0
agent-10: 30.0
agent-11: 29.0
agent-12: 21.0
agent-13: 20.0
agent-14: 36.0
agent-15: 34.0
agent-16: 31.0
agent-17: 21.0
agent-18: 29.0
agent-19: 26.0
agent-20: 29.0
Sum Reward: 543.0
Avg Reward: 27.15
Min Reward: 18.0
Max Reward: 37.0
Gini Coefficient: 0.1070902394106814
20:20 Ratio: 1.7468354430379747
Max-min Ratio: 2.0555555555555554
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-55-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 566.34
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 401
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.485
    dispatch_time_ms: 6.203
    learner:
      cur_lr: 0.0008258679881691933
      grad_gnorm: 2.478426218032837
      policy_entropy: 365.24346923828125
      policy_loss: 0.7361277937889099
      var_gnorm: 48.00577926635742
      vf_explained_var: 0.0
      vf_loss: 0.0018574893474578857
    num_steps_sampled: 8040000
    num_steps_trained: 8040000
    wait_time_ms: 340.62
  iterations_since_restore: 402
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 14034.550976276398
  time_this_iter_s: 35.34023642539978
  time_total_s: 14034.550976276398
  timestamp: 1594151737
  timesteps_since_restore: 8040000
  timesteps_this_iter: 20000
  timesteps_total: 8040000
  training_iteration: 402
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 14034 s, 402 iter, 8040000 ts, 566 rew

agent-1: 25.0
agent-2: 40.0
agent-3: 43.0
agent-4: 43.0
agent-5: 31.0
agent-6: 20.0
agent-7: 36.0
agent-8: 37.0
agent-9: 23.0
agent-10: 31.0
agent-11: 18.0
agent-12: 30.0
agent-13: 31.0
agent-14: 25.0
agent-15: 30.0
agent-16: 31.0
agent-17: 45.0
agent-18: 25.0
agent-19: 32.0
agent-20: 24.0
Sum Reward: 620.0
Avg Reward: 31.0
Min Reward: 18.0
Max Reward: 45.0
Gini Coefficient: 0.13709677419354838
20:20 Ratio: 2.011764705882353
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-56-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 567.28
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 402
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.509
    dispatch_time_ms: 6.402
    learner:
      cur_lr: 0.0008245360222645104
      grad_gnorm: 39.999996185302734
      policy_entropy: 86.91748809814453
      policy_loss: 7.676403045654297
      var_gnorm: 48.017940521240234
      vf_explained_var: 0.6761332750320435
      vf_loss: 121.2542724609375
    num_steps_sampled: 8060000
    num_steps_trained: 8060000
    wait_time_ms: 318.353
  iterations_since_restore: 403
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 14069.129063606262
  time_this_iter_s: 34.5780873298645
  time_total_s: 14069.129063606262
  timestamp: 1594151771
  timesteps_since_restore: 8060000
  timesteps_this_iter: 20000
  timesteps_total: 8060000
  training_iteration: 403
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 14069 s, 403 iter, 8060000 ts, 567 rew

agent-1: 29.0
agent-2: 31.0
agent-3: 31.0
agent-4: 31.0
agent-5: 15.0
agent-6: 31.0
agent-7: 22.0
agent-8: 17.0
agent-9: 35.0
agent-10: 23.0
agent-11: 30.0
agent-12: 24.0
agent-13: 30.0
agent-14: 32.0
agent-15: 28.0
agent-16: 17.0
agent-17: 23.0
agent-18: 36.0
agent-19: 20.0
agent-20: 22.0
Sum Reward: 527.0
Avg Reward: 26.35
Min Reward: 15.0
Max Reward: 36.0
Gini Coefficient: 0.12931688804554078
20:20 Ratio: 1.9420289855072463
Max-min Ratio: 2.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-56-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 567.2
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 403
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.734
    dispatch_time_ms: 5.206
    learner:
      cur_lr: 0.0008232039981521666
      grad_gnorm: 9.79345417022705
      policy_entropy: 356.88079833984375
      policy_loss: -0.5514469146728516
      var_gnorm: 48.025081634521484
      vf_explained_var: -1.0
      vf_loss: 0.3228740692138672
    num_steps_sampled: 8080000
    num_steps_trained: 8080000
    wait_time_ms: 344.043
  iterations_since_restore: 404
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 14103.877269506454
  time_this_iter_s: 34.74820590019226
  time_total_s: 14103.877269506454
  timestamp: 1594151806
  timesteps_since_restore: 8080000
  timesteps_this_iter: 20000
  timesteps_total: 8080000
  training_iteration: 404
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 14103 s, 404 iter, 8080000 ts, 567 rew

agent-1: 24.0
agent-2: 37.0
agent-3: 16.0
agent-4: 33.0
agent-5: 26.0
agent-6: 23.0
agent-7: 28.0
agent-8: 17.0
agent-9: 24.0
agent-10: 22.0
agent-11: 29.0
agent-12: 32.0
agent-13: 27.0
agent-14: 35.0
agent-15: 27.0
agent-16: 36.0
agent-17: 30.0
agent-18: 25.0
agent-19: 38.0
agent-20: 26.0
Sum Reward: 555.0
Avg Reward: 27.75
Min Reward: 16.0
Max Reward: 38.0
Gini Coefficient: 0.12171171171171172
20:20 Ratio: 1.8717948717948718
Max-min Ratio: 2.375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-57-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 566.91
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 404
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.822
    dispatch_time_ms: 25.208
    learner:
      cur_lr: 0.0008218719740398228
      grad_gnorm: 39.999996185302734
      policy_entropy: 117.37385559082031
      policy_loss: 17.04535675048828
      var_gnorm: 48.01742935180664
      vf_explained_var: 0.3099697232246399
      vf_loss: 96.67417907714844
    num_steps_sampled: 8100000
    num_steps_trained: 8100000
    wait_time_ms: 321.252
  iterations_since_restore: 405
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 14139.606177806854
  time_this_iter_s: 35.72890830039978
  time_total_s: 14139.606177806854
  timestamp: 1594151842
  timesteps_since_restore: 8100000
  timesteps_this_iter: 20000
  timesteps_total: 8100000
  training_iteration: 405
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 14139 s, 405 iter, 8100000 ts, 567 rew

agent-1: 33.0
agent-2: 30.0
agent-3: 34.0
agent-4: 32.0
agent-5: 35.0
agent-6: 17.0
agent-7: 31.0
agent-8: 20.0
agent-9: 31.0
agent-10: 35.0
agent-11: 21.0
agent-12: 32.0
agent-13: 28.0
agent-14: 24.0
agent-15: 23.0
agent-16: 19.0
agent-17: 25.0
agent-18: 24.0
agent-19: 31.0
agent-20: 28.0
Sum Reward: 553.0
Avg Reward: 27.65
Min Reward: 17.0
Max Reward: 35.0
Gini Coefficient: 0.11220614828209764
20:20 Ratio: 1.7792207792207793
Max-min Ratio: 2.0588235294117645
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-57-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 566.67
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 405
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.57
    dispatch_time_ms: 25.427
    learner:
      cur_lr: 0.0008205400081351399
      grad_gnorm: 4.437840461730957
      policy_entropy: 365.9141845703125
      policy_loss: 2.42771053314209
      var_gnorm: 48.05152130126953
      vf_explained_var: -1.0
      vf_loss: 0.029742944985628128
    num_steps_sampled: 8120000
    num_steps_trained: 8120000
    wait_time_ms: 334.559
  iterations_since_restore: 406
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 14175.637951135635
  time_this_iter_s: 36.03177332878113
  time_total_s: 14175.637951135635
  timestamp: 1594151878
  timesteps_since_restore: 8120000
  timesteps_this_iter: 20000
  timesteps_total: 8120000
  training_iteration: 406
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 14175 s, 406 iter, 8120000 ts, 567 rew

agent-1: 35.0
agent-2: 33.0
agent-3: 17.0
agent-4: 31.0
agent-5: 22.0
agent-6: 26.0
agent-7: 23.0
agent-8: 32.0
agent-9: 32.0
agent-10: 20.0
agent-11: 30.0
agent-12: 21.0
agent-13: 28.0
agent-14: 25.0
agent-15: 25.0
agent-16: 31.0
agent-17: 18.0
agent-18: 29.0
agent-19: 14.0
agent-20: 34.0
Sum Reward: 526.0
Avg Reward: 26.3
Min Reward: 14.0
Max Reward: 35.0
Gini Coefficient: 0.12984790874524715
20:20 Ratio: 1.9420289855072463
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-58-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 566.12
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 406
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.714
    dispatch_time_ms: 5.822
    learner:
      cur_lr: 0.0008192079840227962
      grad_gnorm: 39.99998474121094
      policy_entropy: 122.13510131835938
      policy_loss: 8.236482620239258
      var_gnorm: 48.033287048339844
      vf_explained_var: 0.8280805945396423
      vf_loss: 118.66177368164062
    num_steps_sampled: 8140000
    num_steps_trained: 8140000
    wait_time_ms: 317.163
  iterations_since_restore: 407
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 14210.699187040329
  time_this_iter_s: 35.0612359046936
  time_total_s: 14210.699187040329
  timestamp: 1594151913
  timesteps_since_restore: 8140000
  timesteps_this_iter: 20000
  timesteps_total: 8140000
  training_iteration: 407
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 14210 s, 407 iter, 8140000 ts, 566 rew

agent-1: 36.0
agent-2: 17.0
agent-3: 43.0
agent-4: 31.0
agent-5: 23.0
agent-6: 10.0
agent-7: 33.0
agent-8: 36.0
agent-9: 21.0
agent-10: 25.0
agent-11: 33.0
agent-12: 24.0
agent-13: 31.0
agent-14: 26.0
agent-15: 30.0
agent-16: 32.0
agent-17: 31.0
agent-18: 34.0
agent-19: 22.0
agent-20: 27.0
Sum Reward: 565.0
Avg Reward: 28.25
Min Reward: 10.0
Max Reward: 43.0
Gini Coefficient: 0.14238938053097344
20:20 Ratio: 2.1285714285714286
Max-min Ratio: 4.3
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-59-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 566.44
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 407
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.674
    dispatch_time_ms: 7.436
    learner:
      cur_lr: 0.0008178760181181133
      grad_gnorm: 3.3998093605041504
      policy_entropy: 367.1730651855469
      policy_loss: -1.5799661874771118
      var_gnorm: 48.15826416015625
      vf_explained_var: -0.09396100044250488
      vf_loss: 0.01760893315076828
    num_steps_sampled: 8160000
    num_steps_trained: 8160000
    wait_time_ms: 340.594
  iterations_since_restore: 408
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 14245.375861883163
  time_this_iter_s: 34.67667484283447
  time_total_s: 14245.375861883163
  timestamp: 1594151948
  timesteps_since_restore: 8160000
  timesteps_this_iter: 20000
  timesteps_total: 8160000
  training_iteration: 408
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 14245 s, 408 iter, 8160000 ts, 566 rew

agent-1: 21.0
agent-2: 34.0
agent-3: 20.0
agent-4: 28.0
agent-5: 25.0
agent-6: 15.0
agent-7: 33.0
agent-8: 41.0
agent-9: 28.0
agent-10: 22.0
agent-11: 35.0
agent-12: 23.0
agent-13: 23.0
agent-14: 26.0
agent-15: 26.0
agent-16: 37.0
agent-17: 23.0
agent-18: 20.0
agent-19: 40.0
agent-20: 45.0
Sum Reward: 565.0
Avg Reward: 28.25
Min Reward: 15.0
Max Reward: 45.0
Gini Coefficient: 0.15761061946902655
20:20 Ratio: 2.1447368421052633
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-59-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 566.86
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 408
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.815
    dispatch_time_ms: 24.092
    learner:
      cur_lr: 0.0008165439940057695
      grad_gnorm: 39.999996185302734
      policy_entropy: 164.72982788085938
      policy_loss: 65.74067687988281
      var_gnorm: 48.16349792480469
      vf_explained_var: -0.043195486068725586
      vf_loss: 138.7663116455078
    num_steps_sampled: 8180000
    num_steps_trained: 8180000
    wait_time_ms: 326.715
  iterations_since_restore: 409
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 14280.61085820198
  time_this_iter_s: 35.23499631881714
  time_total_s: 14280.61085820198
  timestamp: 1594151983
  timesteps_since_restore: 8180000
  timesteps_this_iter: 20000
  timesteps_total: 8180000
  training_iteration: 409
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 14280 s, 409 iter, 8180000 ts, 567 rew

agent-1: 34.0
agent-2: 29.0
agent-3: 23.0
agent-4: 24.0
agent-5: 27.0
agent-6: 33.0
agent-7: 27.0
agent-8: 27.0
agent-9: 36.0
agent-10: 27.0
agent-11: 25.0
agent-12: 29.0
agent-13: 26.0
agent-14: 29.0
agent-15: 23.0
agent-16: 29.0
agent-17: 28.0
agent-18: 32.0
agent-19: 30.0
agent-20: 34.0
Sum Reward: 572.0
Avg Reward: 28.6
Min Reward: 23.0
Max Reward: 36.0
Gini Coefficient: 0.07097902097902098
20:20 Ratio: 1.4421052631578948
Max-min Ratio: 1.565217391304348
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-00-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 566.12
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 409
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.544
    dispatch_time_ms: 36.467
    learner:
      cur_lr: 0.0008152120281010866
      grad_gnorm: 1.8540122509002686
      policy_entropy: 359.50189208984375
      policy_loss: 0.833873987197876
      var_gnorm: 48.19915771484375
      vf_explained_var: 0.0003700852394104004
      vf_loss: 0.00104289292357862
    num_steps_sampled: 8200000
    num_steps_trained: 8200000
    wait_time_ms: 340.586
  iterations_since_restore: 410
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 14316.907656669617
  time_this_iter_s: 36.29679846763611
  time_total_s: 14316.907656669617
  timestamp: 1594152019
  timesteps_since_restore: 8200000
  timesteps_this_iter: 20000
  timesteps_total: 8200000
  training_iteration: 410
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 14316 s, 410 iter, 8200000 ts, 566 rew

agent-1: 24.0
agent-2: 23.0
agent-3: 31.0
agent-4: 34.0
agent-5: 24.0
agent-6: 27.0
agent-7: 18.0
agent-8: 24.0
agent-9: 27.0
agent-10: 22.0
agent-11: 31.0
agent-12: 20.0
agent-13: 26.0
agent-14: 37.0
agent-15: 35.0
agent-16: 24.0
agent-17: 29.0
agent-18: 36.0
agent-19: 25.0
agent-20: 19.0
Sum Reward: 536.0
Avg Reward: 26.8
Min Reward: 18.0
Max Reward: 37.0
Gini Coefficient: 0.11585820895522388
20:20 Ratio: 1.7974683544303798
Max-min Ratio: 2.0555555555555554
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-00-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 565.75
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 410
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.797
    dispatch_time_ms: 25.019
    learner:
      cur_lr: 0.0008138800039887428
      grad_gnorm: 13.247420310974121
      policy_entropy: 371.0771179199219
      policy_loss: -0.23934996128082275
      var_gnorm: 48.17023849487305
      vf_explained_var: -1.0
      vf_loss: 0.0024856021627783775
    num_steps_sampled: 8220000
    num_steps_trained: 8220000
    wait_time_ms: 327.308
  iterations_since_restore: 411
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 14352.854117631912
  time_this_iter_s: 35.94646096229553
  time_total_s: 14352.854117631912
  timestamp: 1594152055
  timesteps_since_restore: 8220000
  timesteps_this_iter: 20000
  timesteps_total: 8220000
  training_iteration: 411
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 14352 s, 411 iter, 8220000 ts, 566 rew

agent-1: 35.0
agent-2: 21.0
agent-3: 28.0
agent-4: 30.0
agent-5: 33.0
agent-6: 30.0
agent-7: 43.0
agent-8: 33.0
agent-9: 29.0
agent-10: 24.0
agent-11: 29.0
agent-12: 24.0
agent-13: 37.0
agent-14: 26.0
agent-15: 26.0
agent-16: 28.0
agent-17: 31.0
agent-18: 41.0
agent-19: 22.0
agent-20: 29.0
Sum Reward: 599.0
Avg Reward: 29.95
Min Reward: 21.0
Max Reward: 43.0
Gini Coefficient: 0.10459098497495826
20:20 Ratio: 1.7142857142857142
Max-min Ratio: 2.0476190476190474
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-01-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 566.09
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 411
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.51
    dispatch_time_ms: 13.944
    learner:
      cur_lr: 0.000812547979876399
      grad_gnorm: 3.1838219165802
      policy_entropy: 344.94415283203125
      policy_loss: -1.701709508895874
      var_gnorm: 48.19349670410156
      vf_explained_var: -0.16195082664489746
      vf_loss: 0.0032711117528378963
    num_steps_sampled: 8240000
    num_steps_trained: 8240000
    wait_time_ms: 325.757
  iterations_since_restore: 412
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 14389.104229927063
  time_this_iter_s: 36.25011229515076
  time_total_s: 14389.104229927063
  timestamp: 1594152092
  timesteps_since_restore: 8240000
  timesteps_this_iter: 20000
  timesteps_total: 8240000
  training_iteration: 412
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 14389 s, 412 iter, 8240000 ts, 566 rew

agent-1: 28.0
agent-2: 28.0
agent-3: 26.0
agent-4: 32.0
agent-5: 23.0
agent-6: 29.0
agent-7: 25.0
agent-8: 17.0
agent-9: 32.0
agent-10: 18.0
agent-11: 26.0
agent-12: 35.0
agent-13: 19.0
agent-14: 31.0
agent-15: 22.0
agent-16: 18.0
agent-17: 18.0
agent-18: 27.0
agent-19: 30.0
agent-20: 35.0
Sum Reward: 519.0
Avg Reward: 25.95
Min Reward: 17.0
Max Reward: 35.0
Gini Coefficient: 0.124373795761079
20:20 Ratio: 1.8873239436619718
Max-min Ratio: 2.0588235294117645
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-02-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 565.72
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 412
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.803
    dispatch_time_ms: 5.324
    learner:
      cur_lr: 0.0008112160139717162
      grad_gnorm: 0.707807719707489
      policy_entropy: 359.4976806640625
      policy_loss: -0.4731518030166626
      var_gnorm: 48.20168685913086
      vf_explained_var: -1.0
      vf_loss: 0.0005268368404358625
    num_steps_sampled: 8260000
    num_steps_trained: 8260000
    wait_time_ms: 338.63
  iterations_since_restore: 413
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 14424.712905406952
  time_this_iter_s: 35.608675479888916
  time_total_s: 14424.712905406952
  timestamp: 1594152127
  timesteps_since_restore: 8260000
  timesteps_this_iter: 20000
  timesteps_total: 8260000
  training_iteration: 413
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 14424 s, 413 iter, 8260000 ts, 566 rew

agent-1: 30.0
agent-2: 32.0
agent-3: 24.0
agent-4: 27.0
agent-5: 26.0
agent-6: 22.0
agent-7: 34.0
agent-8: 28.0
agent-9: 33.0
agent-10: 30.0
agent-11: 25.0
agent-12: 23.0
agent-13: 37.0
agent-14: 24.0
agent-15: 24.0
agent-16: 29.0
agent-17: 28.0
agent-18: 27.0
agent-19: 21.0
agent-20: 24.0
Sum Reward: 548.0
Avg Reward: 27.4
Min Reward: 21.0
Max Reward: 37.0
Gini Coefficient: 0.08558394160583942
20:20 Ratio: 1.511111111111111
Max-min Ratio: 1.7619047619047619
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-02-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 565.99
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 413
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.477
    dispatch_time_ms: 21.347
    learner:
      cur_lr: 0.0008098839898593724
      grad_gnorm: 0.9514521360397339
      policy_entropy: 343.2392578125
      policy_loss: 0.7004228234291077
      var_gnorm: 48.28837585449219
      vf_explained_var: 0.8347798585891724
      vf_loss: 0.00309240585193038
    num_steps_sampled: 8280000
    num_steps_trained: 8280000
    wait_time_ms: 341.194
  iterations_since_restore: 414
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 14460.41679406166
  time_this_iter_s: 35.70388865470886
  time_total_s: 14460.41679406166
  timestamp: 1594152163
  timesteps_since_restore: 8280000
  timesteps_this_iter: 20000
  timesteps_total: 8280000
  training_iteration: 414
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 14460 s, 414 iter, 8280000 ts, 566 rew

agent-1: 25.0
agent-2: 25.0
agent-3: 31.0
agent-4: 30.0
agent-5: 21.0
agent-6: 23.0
agent-7: 28.0
agent-8: 28.0
agent-9: 37.0
agent-10: 27.0
agent-11: 30.0
agent-12: 20.0
agent-13: 21.0
agent-14: 34.0
agent-15: 23.0
agent-16: 26.0
agent-17: 31.0
agent-18: 24.0
agent-19: 27.0
agent-20: 26.0
Sum Reward: 537.0
Avg Reward: 26.85
Min Reward: 20.0
Max Reward: 37.0
Gini Coefficient: 0.09022346368715084
20:20 Ratio: 1.5647058823529412
Max-min Ratio: 1.85
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-03-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 566.08
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 414
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.309
    dispatch_time_ms: 30.879
    learner:
      cur_lr: 0.0008085520239546895
      grad_gnorm: 37.68592071533203
      policy_entropy: 257.7650146484375
      policy_loss: 12.588371276855469
      var_gnorm: 48.317787170410156
      vf_explained_var: 0.5422054529190063
      vf_loss: 6.4835076332092285
    num_steps_sampled: 8300000
    num_steps_trained: 8300000
    wait_time_ms: 328.144
  iterations_since_restore: 415
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 14496.449815511703
  time_this_iter_s: 36.033021450042725
  time_total_s: 14496.449815511703
  timestamp: 1594152199
  timesteps_since_restore: 8300000
  timesteps_this_iter: 20000
  timesteps_total: 8300000
  training_iteration: 415
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 14496 s, 415 iter, 8300000 ts, 566 rew

agent-1: 33.0
agent-2: 31.0
agent-3: 28.0
agent-4: 30.0
agent-5: 35.0
agent-6: 28.0
agent-7: 35.0
agent-8: 22.0
agent-9: 26.0
agent-10: 36.0
agent-11: 23.0
agent-12: 32.0
agent-13: 27.0
agent-14: 37.0
agent-15: 18.0
agent-16: 16.0
agent-17: 29.0
agent-18: 29.0
agent-19: 26.0
agent-20: 28.0
Sum Reward: 569.0
Avg Reward: 28.45
Min Reward: 16.0
Max Reward: 37.0
Gini Coefficient: 0.10799648506151142
20:20 Ratio: 1.8101265822784811
Max-min Ratio: 2.3125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-03-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 566.53
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 415
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.298
    dispatch_time_ms: 9.443
    learner:
      cur_lr: 0.0008072199998423457
      grad_gnorm: 1.217274785041809
      policy_entropy: 362.99896240234375
      policy_loss: -1.2219587564468384
      var_gnorm: 48.317649841308594
      vf_explained_var: 0.36796194314956665
      vf_loss: 0.004537926055490971
    num_steps_sampled: 8320000
    num_steps_trained: 8320000
    wait_time_ms: 332.509
  iterations_since_restore: 416
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 14532.150354385376
  time_this_iter_s: 35.700538873672485
  time_total_s: 14532.150354385376
  timestamp: 1594152235
  timesteps_since_restore: 8320000
  timesteps_this_iter: 20000
  timesteps_total: 8320000
  training_iteration: 416
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 14532 s, 416 iter, 8320000 ts, 567 rew

agent-1: 20.0
agent-2: 21.0
agent-3: 22.0
agent-4: 20.0
agent-5: 24.0
agent-6: 25.0
agent-7: 22.0
agent-8: 27.0
agent-9: 26.0
agent-10: 21.0
agent-11: 24.0
agent-12: 35.0
agent-13: 21.0
agent-14: 23.0
agent-15: 33.0
agent-16: 38.0
agent-17: 23.0
agent-18: 20.0
agent-19: 23.0
agent-20: 30.0
Sum Reward: 498.0
Avg Reward: 24.9
Min Reward: 20.0
Max Reward: 38.0
Gini Coefficient: 0.10582329317269076
20:20 Ratio: 1.6790123456790123
Max-min Ratio: 1.9
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-04-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 565.87
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 416
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.128
    dispatch_time_ms: 6.473
    learner:
      cur_lr: 0.0008058879757300019
      grad_gnorm: 0.3206753134727478
      policy_entropy: 371.8401794433594
      policy_loss: -0.6199718117713928
      var_gnorm: 48.29804229736328
      vf_explained_var: -1.0
      vf_loss: 0.0007946895202621818
    num_steps_sampled: 8340000
    num_steps_trained: 8340000
    wait_time_ms: 337.644
  iterations_since_restore: 417
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 14567.514461994171
  time_this_iter_s: 35.364107608795166
  time_total_s: 14567.514461994171
  timestamp: 1594152270
  timesteps_since_restore: 8340000
  timesteps_this_iter: 20000
  timesteps_total: 8340000
  training_iteration: 417
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 14567 s, 417 iter, 8340000 ts, 566 rew

agent-1: 32.0
agent-2: 28.0
agent-3: 18.0
agent-4: 30.0
agent-5: 35.0
agent-6: 28.0
agent-7: 17.0
agent-8: 30.0
agent-9: 31.0
agent-10: 32.0
agent-11: 22.0
agent-12: 30.0
agent-13: 29.0
agent-14: 29.0
agent-15: 24.0
agent-16: 28.0
agent-17: 21.0
agent-18: 19.0
agent-19: 25.0
agent-20: 30.0
Sum Reward: 538.0
Avg Reward: 26.9
Min Reward: 17.0
Max Reward: 35.0
Gini Coefficient: 0.10185873605947955
20:20 Ratio: 1.7333333333333334
Max-min Ratio: 2.0588235294117645
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-05-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 565.64
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 417
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.35
    dispatch_time_ms: 6.334
    learner:
      cur_lr: 0.000804556009825319
      grad_gnorm: 0.5146559476852417
      policy_entropy: 377.6368408203125
      policy_loss: 0.31446966528892517
      var_gnorm: 48.33064651489258
      vf_explained_var: -0.4650869369506836
      vf_loss: 0.0061433324590325356
    num_steps_sampled: 8360000
    num_steps_trained: 8360000
    wait_time_ms: 338.772
  iterations_since_restore: 418
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 14602.398055553436
  time_this_iter_s: 34.88359355926514
  time_total_s: 14602.398055553436
  timestamp: 1594152305
  timesteps_since_restore: 8360000
  timesteps_this_iter: 20000
  timesteps_total: 8360000
  training_iteration: 418
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 14602 s, 418 iter, 8360000 ts, 566 rew

agent-1: 22.0
agent-2: 17.0
agent-3: 32.0
agent-4: 33.0
agent-5: 15.0
agent-6: 30.0
agent-7: 21.0
agent-8: 19.0
agent-9: 26.0
agent-10: 33.0
agent-11: 20.0
agent-12: 26.0
agent-13: 25.0
agent-14: 31.0
agent-15: 31.0
agent-16: 30.0
agent-17: 25.0
agent-18: 25.0
agent-19: 30.0
agent-20: 28.0
Sum Reward: 519.0
Avg Reward: 25.95
Min Reward: 15.0
Max Reward: 33.0
Gini Coefficient: 0.11589595375722543
20:20 Ratio: 1.8169014084507042
Max-min Ratio: 2.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-05-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 565.37
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 418
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.908
    dispatch_time_ms: 6.559
    learner:
      cur_lr: 0.0008032239857129753
      grad_gnorm: 1.1906492710113525
      policy_entropy: 382.05126953125
      policy_loss: 0.3233509361743927
      var_gnorm: 48.37971496582031
      vf_explained_var: -1.0
      vf_loss: 0.0019838635344058275
    num_steps_sampled: 8380000
    num_steps_trained: 8380000
    wait_time_ms: 348.023
  iterations_since_restore: 419
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 14637.217289447784
  time_this_iter_s: 34.819233894348145
  time_total_s: 14637.217289447784
  timestamp: 1594152340
  timesteps_since_restore: 8380000
  timesteps_this_iter: 20000
  timesteps_total: 8380000
  training_iteration: 419
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 14637 s, 419 iter, 8380000 ts, 565 rew

agent-1: 20.0
agent-2: 23.0
agent-3: 17.0
agent-4: 31.0
agent-5: 25.0
agent-6: 18.0
agent-7: 29.0
agent-8: 20.0
agent-9: 32.0
agent-10: 26.0
agent-11: 30.0
agent-12: 33.0
agent-13: 24.0
agent-14: 32.0
agent-15: 24.0
agent-16: 23.0
agent-17: 16.0
agent-18: 37.0
agent-19: 25.0
agent-20: 36.0
Sum Reward: 521.0
Avg Reward: 26.05
Min Reward: 16.0
Max Reward: 37.0
Gini Coefficient: 0.13310940499040308
20:20 Ratio: 1.943661971830986
Max-min Ratio: 2.3125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-06-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 565.36
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 419
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.59
    dispatch_time_ms: 27.796
    learner:
      cur_lr: 0.0008018920198082924
      grad_gnorm: 1.5366822481155396
      policy_entropy: 379.11456298828125
      policy_loss: 1.7421201467514038
      var_gnorm: 48.431480407714844
      vf_explained_var: -1.0
      vf_loss: 0.0007716306718066335
    num_steps_sampled: 8400000
    num_steps_trained: 8400000
    wait_time_ms: 333.764
  iterations_since_restore: 420
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 14672.282729625702
  time_this_iter_s: 35.06544017791748
  time_total_s: 14672.282729625702
  timestamp: 1594152375
  timesteps_since_restore: 8400000
  timesteps_this_iter: 20000
  timesteps_total: 8400000
  training_iteration: 420
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 14672 s, 420 iter, 8400000 ts, 565 rew

agent-1: 19.0
agent-2: 29.0
agent-3: 19.0
agent-4: 19.0
agent-5: 25.0
agent-6: 12.0
agent-7: 38.0
agent-8: 32.0
agent-9: 25.0
agent-10: 26.0
agent-11: 25.0
agent-12: 33.0
agent-13: 32.0
agent-14: 33.0
agent-15: 35.0
agent-16: 33.0
agent-17: 30.0
agent-18: 30.0
agent-19: 35.0
agent-20: 25.0
Sum Reward: 555.0
Avg Reward: 27.75
Min Reward: 12.0
Max Reward: 38.0
Gini Coefficient: 0.13018018018018018
20:20 Ratio: 2.0434782608695654
Max-min Ratio: 3.1666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-06-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 565.64
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 420
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.427
    dispatch_time_ms: 33.248
    learner:
      cur_lr: 0.0008005599956959486
      grad_gnorm: 1.9522424936294556
      policy_entropy: 384.6231384277344
      policy_loss: 0.851269006729126
      var_gnorm: 48.41497039794922
      vf_explained_var: -1.0
      vf_loss: 0.0018260161159560084
    num_steps_sampled: 8420000
    num_steps_trained: 8420000
    wait_time_ms: 328.52
  iterations_since_restore: 421
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 14704.555029630661
  time_this_iter_s: 32.272300004959106
  time_total_s: 14704.555029630661
  timestamp: 1594152418
  timesteps_since_restore: 8420000
  timesteps_this_iter: 20000
  timesteps_total: 8420000
  training_iteration: 421
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 14704 s, 421 iter, 8420000 ts, 566 rew

agent-1: 23.0
agent-2: 22.0
agent-3: 18.0
agent-4: 18.0
agent-5: 26.0
agent-6: 26.0
agent-7: 29.0
agent-8: 25.0
agent-9: 33.0
agent-10: 36.0
agent-11: 28.0
agent-12: 27.0
agent-13: 20.0
agent-14: 17.0
agent-15: 31.0
agent-16: 18.0
agent-17: 29.0
agent-18: 26.0
agent-19: 34.0
agent-20: 21.0
Sum Reward: 507.0
Avg Reward: 25.35
Min Reward: 17.0
Max Reward: 36.0
Gini Coefficient: 0.12455621301775148
20:20 Ratio: 1.8873239436619718
Max-min Ratio: 2.1176470588235294
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-07-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 565.38
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 421
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.098
    dispatch_time_ms: 25.505
    learner:
      cur_lr: 0.0007992279715836048
      grad_gnorm: 0.7838296890258789
      policy_entropy: 379.7823486328125
      policy_loss: -1.1709305047988892
      var_gnorm: 48.44533157348633
      vf_explained_var: -1.0
      vf_loss: 0.0010924693197011948
    num_steps_sampled: 8440000
    num_steps_trained: 8440000
    wait_time_ms: 162.333
  iterations_since_restore: 422
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 14740.460284948349
  time_this_iter_s: 35.90525531768799
  time_total_s: 14740.460284948349
  timestamp: 1594152454
  timesteps_since_restore: 8440000
  timesteps_this_iter: 20000
  timesteps_total: 8440000
  training_iteration: 422
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 14740 s, 422 iter, 8440000 ts, 565 rew

agent-1: 33.0
agent-2: 31.0
agent-3: 28.0
agent-4: 21.0
agent-5: 30.0
agent-6: 23.0
agent-7: 30.0
agent-8: 40.0
agent-9: 22.0
agent-10: 20.0
agent-11: 39.0
agent-12: 28.0
agent-13: 30.0
agent-14: 33.0
agent-15: 27.0
agent-16: 32.0
agent-17: 23.0
agent-18: 19.0
agent-19: 33.0
agent-20: 32.0
Sum Reward: 574.0
Avg Reward: 28.7
Min Reward: 19.0
Max Reward: 40.0
Gini Coefficient: 0.11254355400696864
20:20 Ratio: 1.7682926829268293
Max-min Ratio: 2.1052631578947367
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-08-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 565.68
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 422
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.46
    dispatch_time_ms: 19.696
    learner:
      cur_lr: 0.0007978960056789219
      grad_gnorm: 28.95075798034668
      policy_entropy: 336.26483154296875
      policy_loss: 10.712047576904297
      var_gnorm: 48.48707580566406
      vf_explained_var: 0.36389797925949097
      vf_loss: 3.0426535606384277
    num_steps_sampled: 8460000
    num_steps_trained: 8460000
    wait_time_ms: 329.489
  iterations_since_restore: 423
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 14776.80559849739
  time_this_iter_s: 36.34531354904175
  time_total_s: 14776.80559849739
  timestamp: 1594152490
  timesteps_since_restore: 8460000
  timesteps_this_iter: 20000
  timesteps_total: 8460000
  training_iteration: 423
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 14776 s, 423 iter, 8460000 ts, 566 rew

agent-1: 32.0
agent-2: 37.0
agent-3: 24.0
agent-4: 23.0
agent-5: 23.0
agent-6: 35.0
agent-7: 27.0
agent-8: 17.0
agent-9: 29.0
agent-10: 21.0
agent-11: 32.0
agent-12: 29.0
agent-13: 33.0
agent-14: 30.0
agent-15: 14.0
agent-16: 25.0
agent-17: 23.0
agent-18: 36.0
agent-19: 33.0
agent-20: 31.0
Sum Reward: 554.0
Avg Reward: 27.7
Min Reward: 14.0
Max Reward: 37.0
Gini Coefficient: 0.12509025270758123
20:20 Ratio: 1.88
Max-min Ratio: 2.642857142857143
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-08-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 566.05
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 423
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.936
    dispatch_time_ms: 6.51
    learner:
      cur_lr: 0.0007965639815665781
      grad_gnorm: 8.858360290527344
      policy_entropy: 377.7305603027344
      policy_loss: -4.5147786140441895
      var_gnorm: 48.5301628112793
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.024165328592061996
    num_steps_sampled: 8480000
    num_steps_trained: 8480000
    wait_time_ms: 337.229
  iterations_since_restore: 424
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 14811.217652082443
  time_this_iter_s: 34.41205358505249
  time_total_s: 14811.217652082443
  timestamp: 1594152525
  timesteps_since_restore: 8480000
  timesteps_this_iter: 20000
  timesteps_total: 8480000
  training_iteration: 424
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 14811 s, 424 iter, 8480000 ts, 566 rew

agent-1: 29.0
agent-2: 38.0
agent-3: 29.0
agent-4: 16.0
agent-5: 21.0
agent-6: 22.0
agent-7: 21.0
agent-8: 33.0
agent-9: 26.0
agent-10: 31.0
agent-11: 18.0
agent-12: 41.0
agent-13: 19.0
agent-14: 32.0
agent-15: 28.0
agent-16: 30.0
agent-17: 24.0
agent-18: 31.0
agent-19: 26.0
agent-20: 21.0
Sum Reward: 536.0
Avg Reward: 26.8
Min Reward: 16.0
Max Reward: 41.0
Gini Coefficient: 0.13619402985074627
20:20 Ratio: 1.945945945945946
Max-min Ratio: 2.5625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-09-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 565.81
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 424
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.535
    dispatch_time_ms: 6.366
    learner:
      cur_lr: 0.0007952320156618953
      grad_gnorm: 5.824412822723389
      policy_entropy: 375.0692138671875
      policy_loss: -3.041133403778076
      var_gnorm: 48.519405364990234
      vf_explained_var: -3.695487976074219e-05
      vf_loss: 0.010419918224215508
    num_steps_sampled: 8500000
    num_steps_trained: 8500000
    wait_time_ms: 329.053
  iterations_since_restore: 425
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 14846.093088388443
  time_this_iter_s: 34.875436305999756
  time_total_s: 14846.093088388443
  timestamp: 1594152560
  timesteps_since_restore: 8500000
  timesteps_this_iter: 20000
  timesteps_total: 8500000
  training_iteration: 425
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 14846 s, 425 iter, 8500000 ts, 566 rew

agent-1: 30.0
agent-2: 21.0
agent-3: 28.0
agent-4: 28.0
agent-5: 27.0
agent-6: 19.0
agent-7: 20.0
agent-8: 17.0
agent-9: 25.0
agent-10: 22.0
agent-11: 30.0
agent-12: 28.0
agent-13: 31.0
agent-14: 18.0
agent-15: 30.0
agent-16: 34.0
agent-17: 32.0
agent-18: 33.0
agent-19: 34.0
agent-20: 16.0
Sum Reward: 523.0
Avg Reward: 26.15
Min Reward: 16.0
Max Reward: 34.0
Gini Coefficient: 0.12533460803059274
20:20 Ratio: 1.9
Max-min Ratio: 2.125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-09-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 565.5
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 425
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.155
    dispatch_time_ms: 5.645
    learner:
      cur_lr: 0.0007938999915495515
      grad_gnorm: 3.6989054679870605
      policy_entropy: 370.6407470703125
      policy_loss: 2.033834218978882
      var_gnorm: 48.52197265625
      vf_explained_var: -1.0
      vf_loss: 0.020229510962963104
    num_steps_sampled: 8520000
    num_steps_trained: 8520000
    wait_time_ms: 340.07
  iterations_since_restore: 426
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 14880.92433333397
  time_this_iter_s: 34.83124494552612
  time_total_s: 14880.92433333397
  timestamp: 1594152595
  timesteps_since_restore: 8520000
  timesteps_this_iter: 20000
  timesteps_total: 8520000
  training_iteration: 426
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 14880 s, 426 iter, 8520000 ts, 566 rew

agent-1: 25.0
agent-2: 24.0
agent-3: 22.0
agent-4: 23.0
agent-5: 37.0
agent-6: 20.0
agent-7: 21.0
agent-8: 25.0
agent-9: 24.0
agent-10: 29.0
agent-11: 26.0
agent-12: 16.0
agent-13: 27.0
agent-14: 31.0
agent-15: 27.0
agent-16: 29.0
agent-17: 48.0
agent-18: 27.0
agent-19: 16.0
agent-20: 18.0
Sum Reward: 515.0
Avg Reward: 25.75
Min Reward: 16.0
Max Reward: 48.0
Gini Coefficient: 0.1416504854368932
20:20 Ratio: 2.0714285714285716
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-10-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 565.09
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 426
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.982
    dispatch_time_ms: 6.619
    learner:
      cur_lr: 0.0007925680256448686
      grad_gnorm: 19.56886100769043
      policy_entropy: 306.94622802734375
      policy_loss: -8.466318130493164
      var_gnorm: 48.560359954833984
      vf_explained_var: 0.5400757789611816
      vf_loss: 0.27635428309440613
    num_steps_sampled: 8540000
    num_steps_trained: 8540000
    wait_time_ms: 341.163
  iterations_since_restore: 427
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 14915.647454738617
  time_this_iter_s: 34.72312140464783
  time_total_s: 14915.647454738617
  timestamp: 1594152630
  timesteps_since_restore: 8540000
  timesteps_this_iter: 20000
  timesteps_total: 8540000
  training_iteration: 427
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 14915 s, 427 iter, 8540000 ts, 565 rew

agent-1: 32.0
agent-2: 39.0
agent-3: 32.0
agent-4: 27.0
agent-5: 32.0
agent-6: 34.0
agent-7: 47.0
agent-8: 26.0
agent-9: 28.0
agent-10: 20.0
agent-11: 39.0
agent-12: 23.0
agent-13: 35.0
agent-14: 21.0
agent-15: 28.0
agent-16: 26.0
agent-17: 28.0
agent-18: 20.0
agent-19: 27.0
agent-20: 28.0
Sum Reward: 592.0
Avg Reward: 29.6
Min Reward: 20.0
Max Reward: 47.0
Gini Coefficient: 0.12364864864864865
20:20 Ratio: 1.9047619047619047
Max-min Ratio: 2.35
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-11-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 565.14
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 427
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.453
    dispatch_time_ms: 24.568
    learner:
      cur_lr: 0.0007912360015325248
      grad_gnorm: 0.9425014853477478
      policy_entropy: 377.96368408203125
      policy_loss: -0.9869454503059387
      var_gnorm: 48.55104446411133
      vf_explained_var: 0.6910777688026428
      vf_loss: 0.01908341981470585
    num_steps_sampled: 8560000
    num_steps_trained: 8560000
    wait_time_ms: 338.495
  iterations_since_restore: 428
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 14950.7950694561
  time_this_iter_s: 35.14761471748352
  time_total_s: 14950.7950694561
  timestamp: 1594152665
  timesteps_since_restore: 8560000
  timesteps_this_iter: 20000
  timesteps_total: 8560000
  training_iteration: 428
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 14950 s, 428 iter, 8560000 ts, 565 rew

agent-1: 29.0
agent-2: 31.0
agent-3: 23.0
agent-4: 27.0
agent-5: 27.0
agent-6: 23.0
agent-7: 34.0
agent-8: 33.0
agent-9: 29.0
agent-10: 28.0
agent-11: 22.0
agent-12: 35.0
agent-13: 17.0
agent-14: 19.0
agent-15: 34.0
agent-16: 21.0
agent-17: 32.0
agent-18: 38.0
agent-19: 33.0
agent-20: 24.0
Sum Reward: 559.0
Avg Reward: 27.95
Min Reward: 17.0
Max Reward: 38.0
Gini Coefficient: 0.1167262969588551
20:20 Ratio: 1.7848101265822784
Max-min Ratio: 2.235294117647059
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-11-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 564.95
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 428
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.703
    dispatch_time_ms: 32.583
    learner:
      cur_lr: 0.000789903977420181
      grad_gnorm: 0.7959473133087158
      policy_entropy: 383.3172302246094
      policy_loss: -0.4451252818107605
      var_gnorm: 48.61082458496094
      vf_explained_var: 0.9894223213195801
      vf_loss: 0.0006902501918375492
    num_steps_sampled: 8580000
    num_steps_trained: 8580000
    wait_time_ms: 331.48
  iterations_since_restore: 429
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 14987.368364334106
  time_this_iter_s: 36.57329487800598
  time_total_s: 14987.368364334106
  timestamp: 1594152702
  timesteps_since_restore: 8580000
  timesteps_this_iter: 20000
  timesteps_total: 8580000
  training_iteration: 429
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 14987 s, 429 iter, 8580000 ts, 565 rew

agent-1: 29.0
agent-2: 23.0
agent-3: 15.0
agent-4: 34.0
agent-5: 25.0
agent-6: 32.0
agent-7: 29.0
agent-8: 25.0
agent-9: 23.0
agent-10: 29.0
agent-11: 31.0
agent-12: 34.0
agent-13: 28.0
agent-14: 33.0
agent-15: 39.0
agent-16: 28.0
agent-17: 29.0
agent-18: 34.0
agent-19: 29.0
agent-20: 26.0
Sum Reward: 575.0
Avg Reward: 28.75
Min Reward: 15.0
Max Reward: 39.0
Gini Coefficient: 0.09504347826086956
20:20 Ratio: 1.6395348837209303
Max-min Ratio: 2.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-12-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 564.94
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 429
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.612
    dispatch_time_ms: 24.54
    learner:
      cur_lr: 0.0007885720115154982
      grad_gnorm: 5.153936386108398
      policy_entropy: 384.14947509765625
      policy_loss: 6.568066120147705
      var_gnorm: 48.67510986328125
      vf_explained_var: 0.0889897346496582
      vf_loss: 0.00822378508746624
    num_steps_sampled: 8600000
    num_steps_trained: 8600000
    wait_time_ms: 328.877
  iterations_since_restore: 430
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 15030.40982055664
  time_this_iter_s: 43.04145622253418
  time_total_s: 15030.40982055664
  timestamp: 1594152745
  timesteps_since_restore: 8600000
  timesteps_this_iter: 20000
  timesteps_total: 8600000
  training_iteration: 430
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 15030 s, 430 iter, 8600000 ts, 565 rew

agent-1: 29.0
agent-2: 36.0
agent-3: 42.0
agent-4: 30.0
agent-5: 19.0
agent-6: 24.0
agent-7: 35.0
agent-8: 17.0
agent-9: 37.0
agent-10: 18.0
agent-11: 26.0
agent-12: 48.0
agent-13: 32.0
agent-14: 35.0
agent-15: 12.0
agent-16: 18.0
agent-17: 32.0
agent-18: 25.0
agent-19: 40.0
agent-20: 28.0
Sum Reward: 583.0
Avg Reward: 29.15
Min Reward: 12.0
Max Reward: 48.0
Gini Coefficient: 0.17881646655231562
20:20 Ratio: 2.5692307692307694
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-12-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 565.54
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 430
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.686
    dispatch_time_ms: 8.938
    learner:
      cur_lr: 0.0007872399874031544
      grad_gnorm: 40.0
      policy_entropy: 364.5754089355469
      policy_loss: -4.717502593994141
      var_gnorm: 48.700416564941406
      vf_explained_var: 0.8263506293296814
      vf_loss: 1.3163666725158691
    num_steps_sampled: 8620000
    num_steps_trained: 8620000
    wait_time_ms: 339.741
  iterations_since_restore: 431
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 15063.408140659332
  time_this_iter_s: 32.99832010269165
  time_total_s: 15063.408140659332
  timestamp: 1594152778
  timesteps_since_restore: 8620000
  timesteps_this_iter: 20000
  timesteps_total: 8620000
  training_iteration: 431
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 15063 s, 431 iter, 8620000 ts, 566 rew

agent-1: 34.0
agent-2: 36.0
agent-3: 26.0
agent-4: 33.0
agent-5: 28.0
agent-6: 21.0
agent-7: 26.0
agent-8: 35.0
agent-9: 17.0
agent-10: 25.0
agent-11: 38.0
agent-12: 32.0
agent-13: 42.0
agent-14: 34.0
agent-15: 32.0
agent-16: 20.0
agent-17: 16.0
agent-18: 25.0
agent-19: 30.0
agent-20: 41.0
Sum Reward: 591.0
Avg Reward: 29.55
Min Reward: 16.0
Max Reward: 42.0
Gini Coefficient: 0.1406937394247039
20:20 Ratio: 2.1216216216216215
Max-min Ratio: 2.625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-13-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 565.47
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 431
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.805
    dispatch_time_ms: 6.651
    learner:
      cur_lr: 0.0007859080214984715
      grad_gnorm: 4.992526531219482
      policy_entropy: 381.3685607910156
      policy_loss: 3.8913960456848145
      var_gnorm: 48.68124008178711
      vf_explained_var: -0.18088865280151367
      vf_loss: 0.0059115150943398476
    num_steps_sampled: 8640000
    num_steps_trained: 8640000
    wait_time_ms: 343.979
  iterations_since_restore: 432
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 15098.220556259155
  time_this_iter_s: 34.812415599823
  time_total_s: 15098.220556259155
  timestamp: 1594152813
  timesteps_since_restore: 8640000
  timesteps_this_iter: 20000
  timesteps_total: 8640000
  training_iteration: 432
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 15098 s, 432 iter, 8640000 ts, 565 rew

agent-1: 26.0
agent-2: 22.0
agent-3: 24.0
agent-4: 18.0
agent-5: 21.0
agent-6: 28.0
agent-7: 28.0
agent-8: 49.0
agent-9: 26.0
agent-10: 18.0
agent-11: 32.0
agent-12: 17.0
agent-13: 30.0
agent-14: 16.0
agent-15: 28.0
agent-16: 36.0
agent-17: 42.0
agent-18: 18.0
agent-19: 29.0
agent-20: 21.0
Sum Reward: 529.0
Avg Reward: 26.45
Min Reward: 16.0
Max Reward: 49.0
Gini Coefficient: 0.17003780718336484
20:20 Ratio: 2.3043478260869565
Max-min Ratio: 3.0625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-14-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 565.09
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 432
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.575
    dispatch_time_ms: 5.624
    learner:
      cur_lr: 0.0007845759973861277
      grad_gnorm: 1.0612720251083374
      policy_entropy: 379.31500244140625
      policy_loss: 0.5973067283630371
      var_gnorm: 48.727535247802734
      vf_explained_var: 0.023969829082489014
      vf_loss: 0.0003524029452819377
    num_steps_sampled: 8660000
    num_steps_trained: 8660000
    wait_time_ms: 340.372
  iterations_since_restore: 433
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 15133.058393239975
  time_this_iter_s: 34.8378369808197
  time_total_s: 15133.058393239975
  timestamp: 1594152848
  timesteps_since_restore: 8660000
  timesteps_this_iter: 20000
  timesteps_total: 8660000
  training_iteration: 433
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 15133 s, 433 iter, 8660000 ts, 565 rew

agent-1: 21.0
agent-2: 21.0
agent-3: 35.0
agent-4: 18.0
agent-5: 19.0
agent-6: 31.0
agent-7: 26.0
agent-8: 34.0
agent-9: 34.0
agent-10: 21.0
agent-11: 18.0
agent-12: 13.0
agent-13: 20.0
agent-14: 32.0
agent-15: 27.0
agent-16: 25.0
agent-17: 25.0
agent-18: 40.0
agent-19: 17.0
agent-20: 29.0
Sum Reward: 506.0
Avg Reward: 25.3
Min Reward: 13.0
Max Reward: 40.0
Gini Coefficient: 0.1590909090909091
20:20 Ratio: 2.1666666666666665
Max-min Ratio: 3.076923076923077
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-14-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 564.53
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 433
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.595
    dispatch_time_ms: 5.588
    learner:
      cur_lr: 0.0007832439732737839
      grad_gnorm: 0.43240782618522644
      policy_entropy: 377.5201721191406
      policy_loss: -0.5194911360740662
      var_gnorm: 48.74142837524414
      vf_explained_var: -1.0
      vf_loss: 7.229491166071966e-05
    num_steps_sampled: 8680000
    num_steps_trained: 8680000
    wait_time_ms: 345.305
  iterations_since_restore: 434
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 15167.816662549973
  time_this_iter_s: 34.75826930999756
  time_total_s: 15167.816662549973
  timestamp: 1594152883
  timesteps_since_restore: 8680000
  timesteps_this_iter: 20000
  timesteps_total: 8680000
  training_iteration: 434
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 15167 s, 434 iter, 8680000 ts, 565 rew

W0707 16:15:02.797103 17834 client_connection.cc:255] [worker]ProcessMessage with type 8 took 110 ms.
agent-1: 4.0
agent-2: 43.0
agent-3: 17.0
agent-4: 17.0
agent-5: 29.0
agent-6: 39.0
agent-7: 18.0
agent-8: 27.0
agent-9: 29.0
agent-10: 34.0
agent-11: 31.0
agent-12: 25.0
agent-13: 22.0
agent-14: 36.0
agent-15: 24.0
agent-16: 15.0
agent-17: 29.0
agent-18: 17.0
agent-19: 38.0
agent-20: 26.0
Sum Reward: 520.0
Avg Reward: 26.0
Min Reward: 4.0
Max Reward: 43.0
Gini Coefficient: 0.2021153846153846
20:20 Ratio: 2.943396226415094
Max-min Ratio: 10.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-15-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 564.6
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 434
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.748
    dispatch_time_ms: 6.082
    learner:
      cur_lr: 0.000781912007369101
      grad_gnorm: 2.974708080291748
      policy_entropy: 379.22418212890625
      policy_loss: -1.050196647644043
      var_gnorm: 48.6524772644043
      vf_explained_var: -0.25699901580810547
      vf_loss: 0.0028774067759513855
    num_steps_sampled: 8700000
    num_steps_trained: 8700000
    wait_time_ms: 346.198
  iterations_since_restore: 435
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 15202.834035634995
  time_this_iter_s: 35.01737308502197
  time_total_s: 15202.834035634995
  timestamp: 1594152918
  timesteps_since_restore: 8700000
  timesteps_this_iter: 20000
  timesteps_total: 8700000
  training_iteration: 435
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 15202 s, 435 iter, 8700000 ts, 565 rew

agent-1: 32.0
agent-2: 19.0
agent-3: 35.0
agent-4: 23.0
agent-5: 30.0
agent-6: 32.0
agent-7: 27.0
agent-8: 30.0
agent-9: 19.0
agent-10: 28.0
agent-11: 30.0
agent-12: 16.0
agent-13: 25.0
agent-14: 23.0
agent-15: 16.0
agent-16: 22.0
agent-17: 25.0
agent-18: 20.0
agent-19: 36.0
agent-20: 31.0
Sum Reward: 519.0
Avg Reward: 25.95
Min Reward: 16.0
Max Reward: 36.0
Gini Coefficient: 0.13053949903660886
20:20 Ratio: 1.9285714285714286
Max-min Ratio: 2.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-15-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 564.31
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 435
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.548
    dispatch_time_ms: 6.917
    learner:
      cur_lr: 0.0007805799832567573
      grad_gnorm: 5.470690727233887
      policy_entropy: 358.98846435546875
      policy_loss: 4.109622001647949
      var_gnorm: 48.73447799682617
      vf_explained_var: 0.9175716638565063
      vf_loss: 0.01026649959385395
    num_steps_sampled: 8720000
    num_steps_trained: 8720000
    wait_time_ms: 343.475
  iterations_since_restore: 436
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 15237.523344516754
  time_this_iter_s: 34.689308881759644
  time_total_s: 15237.523344516754
  timestamp: 1594152953
  timesteps_since_restore: 8720000
  timesteps_this_iter: 20000
  timesteps_total: 8720000
  training_iteration: 436
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 15237 s, 436 iter, 8720000 ts, 564 rew

agent-1: 24.0
agent-2: 35.0
agent-3: 27.0
agent-4: 24.0
agent-5: 24.0
agent-6: 22.0
agent-7: 28.0
agent-8: 30.0
agent-9: 31.0
agent-10: 38.0
agent-11: 26.0
agent-12: 39.0
agent-13: 47.0
agent-14: 30.0
agent-15: 28.0
agent-16: 22.0
agent-17: 24.0
agent-18: 25.0
agent-19: 18.0
agent-20: 22.0
Sum Reward: 564.0
Avg Reward: 28.2
Min Reward: 18.0
Max Reward: 47.0
Gini Coefficient: 0.12872340425531914
20:20 Ratio: 1.8928571428571428
Max-min Ratio: 2.611111111111111
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-16-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 564.31
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 436
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.709
    dispatch_time_ms: 6.099
    learner:
      cur_lr: 0.0007792480173520744
      grad_gnorm: 2.242436170578003
      policy_entropy: 354.9849853515625
      policy_loss: -0.5099523663520813
      var_gnorm: 48.75741958618164
      vf_explained_var: -1.0
      vf_loss: 0.006261048372834921
    num_steps_sampled: 8740000
    num_steps_trained: 8740000
    wait_time_ms: 353.012
  iterations_since_restore: 437
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 15272.159912347794
  time_this_iter_s: 34.63656783103943
  time_total_s: 15272.159912347794
  timestamp: 1594152987
  timesteps_since_restore: 8740000
  timesteps_this_iter: 20000
  timesteps_total: 8740000
  training_iteration: 437
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 15272 s, 437 iter, 8740000 ts, 564 rew

agent-1: 31.0
agent-2: 23.0
agent-3: 28.0
agent-4: 28.0
agent-5: 30.0
agent-6: 36.0
agent-7: 20.0
agent-8: 41.0
agent-9: 29.0
agent-10: 37.0
agent-11: 28.0
agent-12: 30.0
agent-13: 30.0
agent-14: 25.0
agent-15: 23.0
agent-16: 29.0
agent-17: 26.0
agent-18: 28.0
agent-19: 18.0
agent-20: 33.0
Sum Reward: 573.0
Avg Reward: 28.65
Min Reward: 18.0
Max Reward: 41.0
Gini Coefficient: 0.10305410122164049
20:20 Ratio: 1.75
Max-min Ratio: 2.2777777777777777
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-17-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 563.81
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 437
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.712
    dispatch_time_ms: 29.085
    learner:
      cur_lr: 0.0007779159932397306
      grad_gnorm: 3.6878912448883057
      policy_entropy: 364.9872131347656
      policy_loss: 1.7438123226165771
      var_gnorm: 48.80134201049805
      vf_explained_var: -1.0
      vf_loss: 0.017280999571084976
    num_steps_sampled: 8760000
    num_steps_trained: 8760000
    wait_time_ms: 341.297
  iterations_since_restore: 438
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 15307.861371278763
  time_this_iter_s: 35.70145893096924
  time_total_s: 15307.861371278763
  timestamp: 1594153023
  timesteps_since_restore: 8760000
  timesteps_this_iter: 20000
  timesteps_total: 8760000
  training_iteration: 438
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 15307 s, 438 iter, 8760000 ts, 564 rew

agent-1: 22.0
agent-2: 41.0
agent-3: 27.0
agent-4: 33.0
agent-5: 25.0
agent-6: 25.0
agent-7: 25.0
agent-8: 17.0
agent-9: 32.0
agent-10: 27.0
agent-11: 21.0
agent-12: 11.0
agent-13: 20.0
agent-14: 21.0
agent-15: 19.0
agent-16: 41.0
agent-17: 20.0
agent-18: 27.0
agent-19: 28.0
agent-20: 21.0
Sum Reward: 503.0
Avg Reward: 25.15
Min Reward: 11.0
Max Reward: 41.0
Gini Coefficient: 0.15576540755467197
20:20 Ratio: 2.1940298507462686
Max-min Ratio: 3.727272727272727
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-17-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 563.4
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 438
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.581
    dispatch_time_ms: 22.732
    learner:
      cur_lr: 0.0007765840273350477
      grad_gnorm: 2.8267555236816406
      policy_entropy: 351.8805847167969
      policy_loss: -0.4994890093803406
      var_gnorm: 48.878440856933594
      vf_explained_var: -1.0
      vf_loss: 0.04770372435450554
    num_steps_sampled: 8780000
    num_steps_trained: 8780000
    wait_time_ms: 334.072
  iterations_since_restore: 439
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 15343.954928398132
  time_this_iter_s: 36.09355711936951
  time_total_s: 15343.954928398132
  timestamp: 1594153059
  timesteps_since_restore: 8780000
  timesteps_this_iter: 20000
  timesteps_total: 8780000
  training_iteration: 439
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 15343 s, 439 iter, 8780000 ts, 563 rew

agent-1: 27.0
agent-2: 25.0
agent-3: 22.0
agent-4: 21.0
agent-5: 28.0
agent-6: 20.0
agent-7: 27.0
agent-8: 25.0
agent-9: 18.0
agent-10: 28.0
agent-11: 25.0
agent-12: 27.0
agent-13: 42.0
agent-14: 28.0
agent-15: 24.0
agent-16: 33.0
agent-17: 29.0
agent-18: 18.0
agent-19: 26.0
agent-20: 26.0
Sum Reward: 519.0
Avg Reward: 25.95
Min Reward: 18.0
Max Reward: 42.0
Gini Coefficient: 0.10298651252408478
20:20 Ratio: 1.7142857142857142
Max-min Ratio: 2.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-18-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 562.87
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 439
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.602
    dispatch_time_ms: 26.408
    learner:
      cur_lr: 0.0007752520032227039
      grad_gnorm: 20.91231918334961
      policy_entropy: 365.02703857421875
      policy_loss: 8.690292358398438
      var_gnorm: 48.86391830444336
      vf_explained_var: 0.4070669412612915
      vf_loss: 2.190830945968628
    num_steps_sampled: 8800000
    num_steps_trained: 8800000
    wait_time_ms: 335.882
  iterations_since_restore: 440
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 15380.354747772217
  time_this_iter_s: 36.39981937408447
  time_total_s: 15380.354747772217
  timestamp: 1594153096
  timesteps_since_restore: 8800000
  timesteps_this_iter: 20000
  timesteps_total: 8800000
  training_iteration: 440
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 15380 s, 440 iter, 8800000 ts, 563 rew

agent-1: 30.0
agent-2: 24.0
agent-3: 33.0
agent-4: 22.0
agent-5: 10.0
agent-6: 20.0
agent-7: 23.0
agent-8: 29.0
agent-9: 19.0
agent-10: 27.0
agent-11: 38.0
agent-12: 33.0
agent-13: 19.0
agent-14: 37.0
agent-15: 21.0
agent-16: 30.0
agent-17: 27.0
agent-18: 34.0
agent-19: 24.0
agent-20: 20.0
Sum Reward: 520.0
Avg Reward: 26.0
Min Reward: 10.0
Max Reward: 38.0
Gini Coefficient: 0.14942307692307694
20:20 Ratio: 2.088235294117647
Max-min Ratio: 3.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-18-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 562.17
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 440
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.572
    dispatch_time_ms: 6.115
    learner:
      cur_lr: 0.0007739199791103601
      grad_gnorm: 2.032968759536743
      policy_entropy: 368.62640380859375
      policy_loss: -2.103102922439575
      var_gnorm: 48.842552185058594
      vf_explained_var: 5.346536636352539e-05
      vf_loss: 0.0011777282925322652
    num_steps_sampled: 8820000
    num_steps_trained: 8820000
    wait_time_ms: 341.017
  iterations_since_restore: 441
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 15413.860093593597
  time_this_iter_s: 33.505345821380615
  time_total_s: 15413.860093593597
  timestamp: 1594153137
  timesteps_since_restore: 8820000
  timesteps_this_iter: 20000
  timesteps_total: 8820000
  training_iteration: 441
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 15413 s, 441 iter, 8820000 ts, 562 rew

agent-1: 26.0
agent-2: 20.0
agent-3: 34.0
agent-4: 18.0
agent-5: 25.0
agent-6: 30.0
agent-7: 29.0
agent-8: 17.0
agent-9: 26.0
agent-10: 28.0
agent-11: 26.0
agent-12: 31.0
agent-13: 21.0
agent-14: 23.0
agent-15: 19.0
agent-16: 26.0
agent-17: 30.0
agent-18: 20.0
agent-19: 29.0
agent-20: 27.0
Sum Reward: 505.0
Avg Reward: 25.25
Min Reward: 17.0
Max Reward: 34.0
Gini Coefficient: 0.10445544554455445
20:20 Ratio: 1.6891891891891893
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-19-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 562.04
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 441
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.669
    dispatch_time_ms: 6.355
    learner:
      cur_lr: 0.0007725880132056773
      grad_gnorm: 1.860181450843811
      policy_entropy: 371.8662109375
      policy_loss: 1.5752782821655273
      var_gnorm: 48.8205680847168
      vf_explained_var: -1.0
      vf_loss: 0.0036915685050189495
    num_steps_sampled: 8840000
    num_steps_trained: 8840000
    wait_time_ms: 348.275
  iterations_since_restore: 442
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 15448.710876703262
  time_this_iter_s: 34.85078310966492
  time_total_s: 15448.710876703262
  timestamp: 1594153172
  timesteps_since_restore: 8840000
  timesteps_this_iter: 20000
  timesteps_total: 8840000
  training_iteration: 442
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 15448 s, 442 iter, 8840000 ts, 562 rew

agent-1: 31.0
agent-2: 32.0
agent-3: 24.0
agent-4: 21.0
agent-5: 17.0
agent-6: 27.0
agent-7: 21.0
agent-8: 29.0
agent-9: 37.0
agent-10: 17.0
agent-11: 34.0
agent-12: 34.0
agent-13: 37.0
agent-14: 32.0
agent-15: 18.0
agent-16: 32.0
agent-17: 21.0
agent-18: 25.0
agent-19: 20.0
agent-20: 30.0
Sum Reward: 539.0
Avg Reward: 26.95
Min Reward: 17.0
Max Reward: 37.0
Gini Coefficient: 0.1383116883116883
20:20 Ratio: 1.9722222222222223
Max-min Ratio: 2.176470588235294
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-20-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 561.37
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 442
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.559
    dispatch_time_ms: 5.322
    learner:
      cur_lr: 0.0007712559890933335
      grad_gnorm: 2.75848388671875
      policy_entropy: 356.4745178222656
      policy_loss: 1.943780541419983
      var_gnorm: 48.85176086425781
      vf_explained_var: -0.6987534761428833
      vf_loss: 0.002616605721414089
    num_steps_sampled: 8860000
    num_steps_trained: 8860000
    wait_time_ms: 351.039
  iterations_since_restore: 443
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 15483.29710149765
  time_this_iter_s: 34.58622479438782
  time_total_s: 15483.29710149765
  timestamp: 1594153206
  timesteps_since_restore: 8860000
  timesteps_this_iter: 20000
  timesteps_total: 8860000
  training_iteration: 443
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 15483 s, 443 iter, 8860000 ts, 561 rew

agent-1: 35.0
agent-2: 29.0
agent-3: 32.0
agent-4: 12.0
agent-5: 19.0
agent-6: 26.0
agent-7: 35.0
agent-8: 26.0
agent-9: 33.0
agent-10: 30.0
agent-11: 25.0
agent-12: 32.0
agent-13: 18.0
agent-14: 30.0
agent-15: 23.0
agent-16: 33.0
agent-17: 21.0
agent-18: 24.0
agent-19: 31.0
agent-20: 29.0
Sum Reward: 543.0
Avg Reward: 27.15
Min Reward: 12.0
Max Reward: 35.0
Gini Coefficient: 0.12311233885819521
20:20 Ratio: 1.9428571428571428
Max-min Ratio: 2.9166666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-20-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 560.91
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 443
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.218
    dispatch_time_ms: 16.786
    learner:
      cur_lr: 0.0007699240231886506
      grad_gnorm: 2.948774814605713
      policy_entropy: 357.3857116699219
      policy_loss: 3.2064976692199707
      var_gnorm: 48.918663024902344
      vf_explained_var: -0.1466130018234253
      vf_loss: 0.04111252725124359
    num_steps_sampled: 8880000
    num_steps_trained: 8880000
    wait_time_ms: 352.603
  iterations_since_restore: 444
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 15518.3785674572
  time_this_iter_s: 35.08146595954895
  time_total_s: 15518.3785674572
  timestamp: 1594153241
  timesteps_since_restore: 8880000
  timesteps_this_iter: 20000
  timesteps_total: 8880000
  training_iteration: 444
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 15518 s, 444 iter, 8880000 ts, 561 rew

agent-1: 22.0
agent-2: 17.0
agent-3: 29.0
agent-4: 23.0
agent-5: 31.0
agent-6: 39.0
agent-7: 33.0
agent-8: 20.0
agent-9: 27.0
agent-10: 21.0
agent-11: 37.0
agent-12: 26.0
agent-13: 26.0
agent-14: 34.0
agent-15: 14.0
agent-16: 20.0
agent-17: 21.0
agent-18: 21.0
agent-19: 54.0
agent-20: 35.0
Sum Reward: 550.0
Avg Reward: 27.5
Min Reward: 14.0
Max Reward: 54.0
Gini Coefficient: 0.17745454545454545
20:20 Ratio: 2.323943661971831
Max-min Ratio: 3.857142857142857
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-21-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 561.42
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 444
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.82
    dispatch_time_ms: 5.859
    learner:
      cur_lr: 0.0007685919990763068
      grad_gnorm: 2.3452956676483154
      policy_entropy: 370.0876770019531
      policy_loss: -1.7628542184829712
      var_gnorm: 48.91764450073242
      vf_explained_var: -1.0
      vf_loss: 0.006346151232719421
    num_steps_sampled: 8900000
    num_steps_trained: 8900000
    wait_time_ms: 334.921
  iterations_since_restore: 445
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 15553.7553627491
  time_this_iter_s: 35.376795291900635
  time_total_s: 15553.7553627491
  timestamp: 1594153277
  timesteps_since_restore: 8900000
  timesteps_this_iter: 20000
  timesteps_total: 8900000
  training_iteration: 445
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 15553 s, 445 iter, 8900000 ts, 561 rew

agent-1: 20.0
agent-2: 27.0
agent-3: 29.0
agent-4: 25.0
agent-5: 28.0
agent-6: 32.0
agent-7: 31.0
agent-8: 12.0
agent-9: 32.0
agent-10: 27.0
agent-11: 28.0
agent-12: 28.0
agent-13: 23.0
agent-14: 27.0
agent-15: 23.0
agent-16: 22.0
agent-17: 18.0
agent-18: 27.0
agent-19: 30.0
agent-20: 21.0
Sum Reward: 510.0
Avg Reward: 25.5
Min Reward: 12.0
Max Reward: 32.0
Gini Coefficient: 0.10509803921568628
20:20 Ratio: 1.7605633802816902
Max-min Ratio: 2.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-21-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 560.88
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 445
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.742
    dispatch_time_ms: 7.498
    learner:
      cur_lr: 0.000767259974963963
      grad_gnorm: 7.642956733703613
      policy_entropy: 365.2559814453125
      policy_loss: -3.854736804962158
      var_gnorm: 48.96580505371094
      vf_explained_var: -1.0
      vf_loss: 0.04592369496822357
    num_steps_sampled: 8920000
    num_steps_trained: 8920000
    wait_time_ms: 348.589
  iterations_since_restore: 446
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 15588.51595878601
  time_this_iter_s: 34.76059603691101
  time_total_s: 15588.51595878601
  timestamp: 1594153312
  timesteps_since_restore: 8920000
  timesteps_this_iter: 20000
  timesteps_total: 8920000
  training_iteration: 446
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 15588 s, 446 iter, 8920000 ts, 561 rew

agent-1: 23.0
agent-2: 17.0
agent-3: 20.0
agent-4: 26.0
agent-5: 35.0
agent-6: 22.0
agent-7: 37.0
agent-8: 31.0
agent-9: 27.0
agent-10: 29.0
agent-11: 19.0
agent-12: 23.0
agent-13: 20.0
agent-14: 23.0
agent-15: 31.0
agent-16: 15.0
agent-17: 19.0
agent-18: 26.0
agent-19: 30.0
agent-20: 33.0
Sum Reward: 506.0
Avg Reward: 25.3
Min Reward: 15.0
Max Reward: 37.0
Gini Coefficient: 0.13656126482213438
20:20 Ratio: 1.9428571428571428
Max-min Ratio: 2.466666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-22-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 560.61
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 446
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.53
    dispatch_time_ms: 5.746
    learner:
      cur_lr: 0.0007659280090592802
      grad_gnorm: 6.364367961883545
      policy_entropy: 359.5987548828125
      policy_loss: 3.3980183601379395
      var_gnorm: 49.000953674316406
      vf_explained_var: 3.9458274841308594e-05
      vf_loss: 0.012963947840034962
    num_steps_sampled: 8940000
    num_steps_trained: 8940000
    wait_time_ms: 349.351
  iterations_since_restore: 447
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 15623.361955165863
  time_this_iter_s: 34.845996379852295
  time_total_s: 15623.361955165863
  timestamp: 1594153346
  timesteps_since_restore: 8940000
  timesteps_this_iter: 20000
  timesteps_total: 8940000
  training_iteration: 447
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 15623 s, 447 iter, 8940000 ts, 561 rew

agent-1: 18.0
agent-2: 40.0
agent-3: 22.0
agent-4: 22.0
agent-5: 22.0
agent-6: 32.0
agent-7: 23.0
agent-8: 30.0
agent-9: 25.0
agent-10: 22.0
agent-11: 25.0
agent-12: 29.0
agent-13: 24.0
agent-14: 22.0
agent-15: 25.0
agent-16: 25.0
agent-17: 24.0
agent-18: 24.0
agent-19: 35.0
agent-20: 32.0
Sum Reward: 521.0
Avg Reward: 26.05
Min Reward: 18.0
Max Reward: 40.0
Gini Coefficient: 0.10489443378119002
20:20 Ratio: 1.6547619047619047
Max-min Ratio: 2.2222222222222223
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-23-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 560.5
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 447
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.444
    dispatch_time_ms: 6.88
    learner:
      cur_lr: 0.0007645959849469364
      grad_gnorm: 0.37705913186073303
      policy_entropy: 370.23779296875
      policy_loss: -0.4670620858669281
      var_gnorm: 49.04398727416992
      vf_explained_var: -0.007717728614807129
      vf_loss: 8.534287189831957e-06
    num_steps_sampled: 8960000
    num_steps_trained: 8960000
    wait_time_ms: 335.045
  iterations_since_restore: 448
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 15658.033533334732
  time_this_iter_s: 34.67157816886902
  time_total_s: 15658.033533334732
  timestamp: 1594153381
  timesteps_since_restore: 8960000
  timesteps_this_iter: 20000
  timesteps_total: 8960000
  training_iteration: 448
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 15658 s, 448 iter, 8960000 ts, 560 rew

agent-1: 15.0
agent-2: 31.0
agent-3: 39.0
agent-4: 28.0
agent-5: 21.0
agent-6: 17.0
agent-7: 38.0
agent-8: 18.0
agent-9: 24.0
agent-10: 35.0
agent-11: 30.0
agent-12: 33.0
agent-13: 32.0
agent-14: 22.0
agent-15: 32.0
agent-16: 25.0
agent-17: 15.0
agent-18: 23.0
agent-19: 29.0
agent-20: 28.0
Sum Reward: 535.0
Avg Reward: 26.75
Min Reward: 15.0
Max Reward: 39.0
Gini Coefficient: 0.15149532710280375
20:20 Ratio: 2.230769230769231
Max-min Ratio: 2.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-23-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 560.63
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 448
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.726
    dispatch_time_ms: 8.024
    learner:
      cur_lr: 0.0007632640190422535
      grad_gnorm: 3.3345303535461426
      policy_entropy: 382.39312744140625
      policy_loss: 1.5120493173599243
      var_gnorm: 49.10447692871094
      vf_explained_var: 4.172325134277344e-06
      vf_loss: 0.003504883497953415
    num_steps_sampled: 8980000
    num_steps_trained: 8980000
    wait_time_ms: 340.784
  iterations_since_restore: 449
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 15692.626187562943
  time_this_iter_s: 34.59265422821045
  time_total_s: 15692.626187562943
  timestamp: 1594153416
  timesteps_since_restore: 8980000
  timesteps_this_iter: 20000
  timesteps_total: 8980000
  training_iteration: 449
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 15692 s, 449 iter, 8980000 ts, 561 rew

agent-1: 40.0
agent-2: 21.0
agent-3: 24.0
agent-4: 27.0
agent-5: 25.0
agent-6: 31.0
agent-7: 15.0
agent-8: 35.0
agent-9: 24.0
agent-10: 36.0
agent-11: 26.0
agent-12: 24.0
agent-13: 25.0
agent-14: 26.0
agent-15: 26.0
agent-16: 25.0
agent-17: 27.0
agent-18: 22.0
agent-19: 32.0
agent-20: 26.0
Sum Reward: 537.0
Avg Reward: 26.85
Min Reward: 15.0
Max Reward: 40.0
Gini Coefficient: 0.10754189944134078
20:20 Ratio: 1.7439024390243902
Max-min Ratio: 2.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-24-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 560.71
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 449
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.287
    dispatch_time_ms: 6.356
    learner:
      cur_lr: 0.0007619319949299097
      grad_gnorm: 20.677927017211914
      policy_entropy: 341.03070068359375
      policy_loss: -12.89361572265625
      var_gnorm: 49.11878204345703
      vf_explained_var: 0.7372308969497681
      vf_loss: 0.3190489411354065
    num_steps_sampled: 9000000
    num_steps_trained: 9000000
    wait_time_ms: 341.129
  iterations_since_restore: 450
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 15727.452294111252
  time_this_iter_s: 34.826106548309326
  time_total_s: 15727.452294111252
  timestamp: 1594153451
  timesteps_since_restore: 9000000
  timesteps_this_iter: 20000
  timesteps_total: 9000000
  training_iteration: 450
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 15727 s, 450 iter, 9000000 ts, 561 rew

agent-1: 28.0
agent-2: 43.0
agent-3: 19.0
agent-4: 27.0
agent-5: 34.0
agent-6: 23.0
agent-7: 27.0
agent-8: 28.0
agent-9: 24.0
agent-10: 16.0
agent-11: 33.0
agent-12: 32.0
agent-13: 28.0
agent-14: 23.0
agent-15: 29.0
agent-16: 32.0
agent-17: 26.0
agent-18: 26.0
agent-19: 31.0
agent-20: 21.0
Sum Reward: 550.0
Avg Reward: 27.5
Min Reward: 16.0
Max Reward: 43.0
Gini Coefficient: 0.11472727272727273
20:20 Ratio: 1.7974683544303798
Max-min Ratio: 2.6875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-24-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 561.18
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 450
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.923
    dispatch_time_ms: 5.243
    learner:
      cur_lr: 0.0007606000290252268
      grad_gnorm: 2.956315517425537
      policy_entropy: 377.9915771484375
      policy_loss: 2.4117932319641113
      var_gnorm: 49.1483039855957
      vf_explained_var: -1.0
      vf_loss: 0.006479357834905386
    num_steps_sampled: 9020000
    num_steps_trained: 9020000
    wait_time_ms: 350.779
  iterations_since_restore: 451
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 15762.412086486816
  time_this_iter_s: 34.959792375564575
  time_total_s: 15762.412086486816
  timestamp: 1594153486
  timesteps_since_restore: 9020000
  timesteps_this_iter: 20000
  timesteps_total: 9020000
  training_iteration: 451
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 15762 s, 451 iter, 9020000 ts, 561 rew

agent-1: 33.0
agent-2: 22.0
agent-3: 22.0
agent-4: 38.0
agent-5: 32.0
agent-6: 37.0
agent-7: 29.0
agent-8: 36.0
agent-9: 24.0
agent-10: 45.0
agent-11: 32.0
agent-12: 31.0
agent-13: 26.0
agent-14: 25.0
agent-15: 23.0
agent-16: 23.0
agent-17: 27.0
agent-18: 26.0
agent-19: 29.0
agent-20: 22.0
Sum Reward: 582.0
Avg Reward: 29.1
Min Reward: 22.0
Max Reward: 45.0
Gini Coefficient: 0.11769759450171821
20:20 Ratio: 1.752808988764045
Max-min Ratio: 2.0454545454545454
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-25-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 561.08
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 451
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.81
    dispatch_time_ms: 6.207
    learner:
      cur_lr: 0.000759268004912883
      grad_gnorm: 1.6121482849121094
      policy_entropy: 372.0845947265625
      policy_loss: -2.225853204727173
      var_gnorm: 49.18770980834961
      vf_explained_var: 0.9930875897407532
      vf_loss: 0.0009921558666974306
    num_steps_sampled: 9040000
    num_steps_trained: 9040000
    wait_time_ms: 345.968
  iterations_since_restore: 452
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 15797.13573884964
  time_this_iter_s: 34.723652362823486
  time_total_s: 15797.13573884964
  timestamp: 1594153520
  timesteps_since_restore: 9040000
  timesteps_this_iter: 20000
  timesteps_total: 9040000
  training_iteration: 452
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 15797 s, 452 iter, 9040000 ts, 561 rew

agent-1: 37.0
agent-2: 23.0
agent-3: 24.0
agent-4: 20.0
agent-5: 29.0
agent-6: 32.0
agent-7: 21.0
agent-8: 22.0
agent-9: 25.0
agent-10: 29.0
agent-11: 32.0
agent-12: 20.0
agent-13: 26.0
agent-14: 32.0
agent-15: 29.0
agent-16: 17.0
agent-17: 25.0
agent-18: 30.0
agent-19: 28.0
agent-20: 32.0
Sum Reward: 533.0
Avg Reward: 26.65
Min Reward: 17.0
Max Reward: 37.0
Gini Coefficient: 0.10778611632270169
20:20 Ratio: 1.705128205128205
Max-min Ratio: 2.176470588235294
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-25-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 560.79
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 452
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.557
    dispatch_time_ms: 6.081
    learner:
      cur_lr: 0.0007579359808005393
      grad_gnorm: 4.542937278747559
      policy_entropy: 381.48895263671875
      policy_loss: 2.4407286643981934
      var_gnorm: 49.25642776489258
      vf_explained_var: 0.29438620805740356
      vf_loss: 0.006534392014145851
    num_steps_sampled: 9060000
    num_steps_trained: 9060000
    wait_time_ms: 343.371
  iterations_since_restore: 453
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 15831.967891216278
  time_this_iter_s: 34.832152366638184
  time_total_s: 15831.967891216278
  timestamp: 1594153555
  timesteps_since_restore: 9060000
  timesteps_this_iter: 20000
  timesteps_total: 9060000
  training_iteration: 453
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 15831 s, 453 iter, 9060000 ts, 561 rew

agent-1: 26.0
agent-2: 24.0
agent-3: 26.0
agent-4: 10.0
agent-5: 21.0
agent-6: 28.0
agent-7: 30.0
agent-8: 20.0
agent-9: 30.0
agent-10: 35.0
agent-11: 25.0
agent-12: 32.0
agent-13: 32.0
agent-14: 33.0
agent-15: 23.0
agent-16: 28.0
agent-17: 21.0
agent-18: 32.0
agent-19: 30.0
agent-20: 22.0
Sum Reward: 528.0
Avg Reward: 26.4
Min Reward: 10.0
Max Reward: 35.0
Gini Coefficient: 0.11856060606060606
20:20 Ratio: 1.8333333333333333
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-26-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 561.21
  episode_reward_min: 491.0
  episodes_this_iter: 1
  episodes_total: 453
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.752
    dispatch_time_ms: 7.201
    learner:
      cur_lr: 0.0007566040148958564
      grad_gnorm: 3.333543062210083
      policy_entropy: 374.3018798828125
      policy_loss: -3.9698245525360107
      var_gnorm: 49.22845458984375
      vf_explained_var: 0.985988199710846
      vf_loss: 0.0029687019996345043
    num_steps_sampled: 9080000
    num_steps_trained: 9080000
    wait_time_ms: 351.527
  iterations_since_restore: 454
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 15866.632302761078
  time_this_iter_s: 34.664411544799805
  time_total_s: 15866.632302761078
  timestamp: 1594153590
  timesteps_since_restore: 9080000
  timesteps_this_iter: 20000
  timesteps_total: 9080000
  training_iteration: 454
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 15866 s, 454 iter, 9080000 ts, 561 rew

agent-1: 25.0
agent-2: 30.0
agent-3: 15.0
agent-4: 38.0
agent-5: 21.0
agent-6: 26.0
agent-7: 31.0
agent-8: 31.0
agent-9: 18.0
agent-10: 32.0
agent-11: 28.0
agent-12: 48.0
agent-13: 41.0
agent-14: 35.0
agent-15: 29.0
agent-16: 34.0
agent-17: 29.0
agent-18: 20.0
agent-19: 31.0
agent-20: 29.0
Sum Reward: 591.0
Avg Reward: 29.55
Min Reward: 15.0
Max Reward: 48.0
Gini Coefficient: 0.14052453468697124
20:20 Ratio: 2.189189189189189
Max-min Ratio: 3.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-27-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 561.85
  episode_reward_min: 491.0
  episodes_this_iter: 1
  episodes_total: 454
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.571
    dispatch_time_ms: 5.731
    learner:
      cur_lr: 0.0007552719907835126
      grad_gnorm: 5.9884419441223145
      policy_entropy: 357.11846923828125
      policy_loss: 3.7898600101470947
      var_gnorm: 49.24526596069336
      vf_explained_var: 0.9490898847579956
      vf_loss: 0.01144647877663374
    num_steps_sampled: 9100000
    num_steps_trained: 9100000
    wait_time_ms: 346.702
  iterations_since_restore: 455
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 15901.424080371857
  time_this_iter_s: 34.79177761077881
  time_total_s: 15901.424080371857
  timestamp: 1594153625
  timesteps_since_restore: 9100000
  timesteps_this_iter: 20000
  timesteps_total: 9100000
  training_iteration: 455
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 15901 s, 455 iter, 9100000 ts, 562 rew

agent-1: 33.0
agent-2: 27.0
agent-3: 32.0
agent-4: 25.0
agent-5: 23.0
agent-6: 24.0
agent-7: 32.0
agent-8: 32.0
agent-9: 26.0
agent-10: 25.0
agent-11: 32.0
agent-12: 22.0
agent-13: 24.0
agent-14: 28.0
agent-15: 35.0
agent-16: 34.0
agent-17: 20.0
agent-18: 26.0
agent-19: 27.0
agent-20: 32.0
Sum Reward: 559.0
Avg Reward: 27.95
Min Reward: 20.0
Max Reward: 35.0
Gini Coefficient: 0.08756708407871198
20:20 Ratio: 1.5056179775280898
Max-min Ratio: 1.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-27-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 562.24
  episode_reward_min: 491.0
  episodes_this_iter: 1
  episodes_total: 455
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.747
    dispatch_time_ms: 6.609
    learner:
      cur_lr: 0.0007539400248788297
      grad_gnorm: 5.0334858894348145
      policy_entropy: 366.64178466796875
      policy_loss: -3.6560540199279785
      var_gnorm: 49.181861877441406
      vf_explained_var: 0.581159770488739
      vf_loss: 0.00808969046920538
    num_steps_sampled: 9120000
    num_steps_trained: 9120000
    wait_time_ms: 343.449
  iterations_since_restore: 456
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 15936.078275442123
  time_this_iter_s: 34.654195070266724
  time_total_s: 15936.078275442123
  timestamp: 1594153660
  timesteps_since_restore: 9120000
  timesteps_this_iter: 20000
  timesteps_total: 9120000
  training_iteration: 456
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 15936 s, 456 iter, 9120000 ts, 562 rew

agent-1: 23.0
agent-2: 26.0
agent-3: 27.0
agent-4: 38.0
agent-5: 33.0
agent-6: 23.0
agent-7: 18.0
agent-8: 27.0
agent-9: 20.0
agent-10: 37.0
agent-11: 33.0
agent-12: 46.0
agent-13: 32.0
agent-14: 18.0
agent-15: 31.0
agent-16: 22.0
agent-17: 32.0
agent-18: 14.0
agent-19: 36.0
agent-20: 18.0
Sum Reward: 554.0
Avg Reward: 27.7
Min Reward: 14.0
Max Reward: 46.0
Gini Coefficient: 0.16534296028880865
20:20 Ratio: 2.3088235294117645
Max-min Ratio: 3.2857142857142856
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-28-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 562.23
  episode_reward_min: 491.0
  episodes_this_iter: 1
  episodes_total: 456
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.52
    dispatch_time_ms: 6.704
    learner:
      cur_lr: 0.0007526080007664859
      grad_gnorm: 0.23004624247550964
      policy_entropy: 363.978271484375
      policy_loss: -0.05158718302845955
      var_gnorm: 49.2233772277832
      vf_explained_var: 0.9957407116889954
      vf_loss: 2.2211988834897056e-05
    num_steps_sampled: 9140000
    num_steps_trained: 9140000
    wait_time_ms: 345.222
  iterations_since_restore: 457
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 15971.122630357742
  time_this_iter_s: 35.0443549156189
  time_total_s: 15971.122630357742
  timestamp: 1594153695
  timesteps_since_restore: 9140000
  timesteps_this_iter: 20000
  timesteps_total: 9140000
  training_iteration: 457
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 15971 s, 457 iter, 9140000 ts, 562 rew

agent-1: 28.0
agent-2: 26.0
agent-3: 31.0
agent-4: 34.0
agent-5: 34.0
agent-6: 22.0
agent-7: 29.0
agent-8: 33.0
agent-9: 24.0
agent-10: 20.0
agent-11: 16.0
agent-12: 21.0
agent-13: 22.0
agent-14: 28.0
agent-15: 25.0
agent-16: 17.0
agent-17: 38.0
agent-18: 27.0
agent-19: 34.0
agent-20: 30.0
Sum Reward: 539.0
Avg Reward: 26.95
Min Reward: 16.0
Max Reward: 38.0
Gini Coefficient: 0.1258812615955473
20:20 Ratio: 1.8918918918918919
Max-min Ratio: 2.375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-28-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 562.15
  episode_reward_min: 491.0
  episodes_this_iter: 1
  episodes_total: 457
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.017
    dispatch_time_ms: 7.951
    learner:
      cur_lr: 0.0007512759766541421
      grad_gnorm: 16.913911819458008
      policy_entropy: 304.29534912109375
      policy_loss: 6.355489730834961
      var_gnorm: 49.30424499511719
      vf_explained_var: 0.6421475410461426
      vf_loss: 3.247559070587158
    num_steps_sampled: 9160000
    num_steps_trained: 9160000
    wait_time_ms: 339.777
  iterations_since_restore: 458
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 16006.14842247963
  time_this_iter_s: 35.02579212188721
  time_total_s: 16006.14842247963
  timestamp: 1594153730
  timesteps_since_restore: 9160000
  timesteps_this_iter: 20000
  timesteps_total: 9160000
  training_iteration: 458
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 16006 s, 458 iter, 9160000 ts, 562 rew

agent-1: 15.0
agent-2: 33.0
agent-3: 27.0
agent-4: 33.0
agent-5: 31.0
agent-6: 41.0
agent-7: 14.0
agent-8: 23.0
agent-9: 23.0
agent-10: 27.0
agent-11: 27.0
agent-12: 31.0
agent-13: 21.0
agent-14: 21.0
agent-15: 21.0
agent-16: 25.0
agent-17: 26.0
agent-18: 29.0
agent-19: 24.0
agent-20: 19.0
Sum Reward: 511.0
Avg Reward: 25.55
Min Reward: 14.0
Max Reward: 41.0
Gini Coefficient: 0.13688845401174168
20:20 Ratio: 2.0
Max-min Ratio: 2.9285714285714284
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-29-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 562.06
  episode_reward_min: 491.0
  episodes_this_iter: 1
  episodes_total: 458
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.582
    dispatch_time_ms: 6.869
    learner:
      cur_lr: 0.0007499440107494593
      grad_gnorm: 3.362689733505249
      policy_entropy: 377.2269287109375
      policy_loss: 1.8875313997268677
      var_gnorm: 49.2996711730957
      vf_explained_var: -0.26750874519348145
      vf_loss: 0.0070235407911241055
    num_steps_sampled: 9180000
    num_steps_trained: 9180000
    wait_time_ms: 342.499
  iterations_since_restore: 459
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 16040.753828525543
  time_this_iter_s: 34.605406045913696
  time_total_s: 16040.753828525543
  timestamp: 1594153764
  timesteps_since_restore: 9180000
  timesteps_this_iter: 20000
  timesteps_total: 9180000
  training_iteration: 459
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 16040 s, 459 iter, 9180000 ts, 562 rew

agent-1: 28.0
agent-2: 25.0
agent-3: 32.0
agent-4: 23.0
agent-5: 22.0
agent-6: 14.0
agent-7: 31.0
agent-8: 23.0
agent-9: 24.0
agent-10: 27.0
agent-11: 31.0
agent-12: 24.0
agent-13: 32.0
agent-14: 22.0
agent-15: 30.0
agent-16: 25.0
agent-17: 34.0
agent-18: 37.0
agent-19: 39.0
agent-20: 20.0
Sum Reward: 543.0
Avg Reward: 27.15
Min Reward: 14.0
Max Reward: 39.0
Gini Coefficient: 0.12292817679558012
20:20 Ratio: 1.8205128205128205
Max-min Ratio: 2.7857142857142856
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-29-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 562.21
  episode_reward_min: 491.0
  episodes_this_iter: 1
  episodes_total: 459
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.797
    dispatch_time_ms: 5.735
    learner:
      cur_lr: 0.0007486119866371155
      grad_gnorm: 39.99999237060547
      policy_entropy: 282.54888916015625
      policy_loss: -5.210378170013428
      var_gnorm: 49.33762741088867
      vf_explained_var: 0.199571430683136
      vf_loss: 4.20444917678833
    num_steps_sampled: 9200000
    num_steps_trained: 9200000
    wait_time_ms: 346.221
  iterations_since_restore: 460
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 16075.26986026764
  time_this_iter_s: 34.51603174209595
  time_total_s: 16075.26986026764
  timestamp: 1594153799
  timesteps_since_restore: 9200000
  timesteps_this_iter: 20000
  timesteps_total: 9200000
  training_iteration: 460
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 16075 s, 460 iter, 9200000 ts, 562 rew

agent-1: 27.0
agent-2: 37.0
agent-3: 32.0
agent-4: 25.0
agent-5: 37.0
agent-6: 35.0
agent-7: 23.0
agent-8: 35.0
agent-9: 32.0
agent-10: 24.0
agent-11: 29.0
agent-12: 20.0
agent-13: 14.0
agent-14: 39.0
agent-15: 34.0
agent-16: 29.0
agent-17: 19.0
agent-18: 36.0
agent-19: 28.0
agent-20: 31.0
Sum Reward: 586.0
Avg Reward: 29.3
Min Reward: 14.0
Max Reward: 39.0
Gini Coefficient: 0.12764505119453926
20:20 Ratio: 1.9605263157894737
Max-min Ratio: 2.7857142857142856
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-30-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 562.42
  episode_reward_min: 491.0
  episodes_this_iter: 1
  episodes_total: 460
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.799
    dispatch_time_ms: 5.895
    learner:
      cur_lr: 0.0007472800207324326
      grad_gnorm: 1.764937162399292
      policy_entropy: 341.46221923828125
      policy_loss: 0.32561370730400085
      var_gnorm: 49.432029724121094
      vf_explained_var: 0.0
      vf_loss: 0.0009715187479741871
    num_steps_sampled: 9220000
    num_steps_trained: 9220000
    wait_time_ms: 347.056
  iterations_since_restore: 461
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 16110.132492780685
  time_this_iter_s: 34.862632513046265
  time_total_s: 16110.132492780685
  timestamp: 1594153834
  timesteps_since_restore: 9220000
  timesteps_this_iter: 20000
  timesteps_total: 9220000
  training_iteration: 461
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 16110 s, 461 iter, 9220000 ts, 562 rew

agent-1: 18.0
agent-2: 8.0
agent-3: 19.0
agent-4: 36.0
agent-5: 42.0
agent-6: 43.0
agent-7: 30.0
agent-8: 37.0
agent-9: 21.0
agent-10: 16.0
agent-11: 47.0
agent-12: 32.0
agent-13: 32.0
agent-14: 21.0
agent-15: 22.0
agent-16: 27.0
agent-17: 10.0
agent-18: 23.0
agent-19: 21.0
agent-20: 36.0
Sum Reward: 541.0
Avg Reward: 27.05
Min Reward: 8.0
Max Reward: 47.0
Gini Coefficient: 0.22375231053604436
20:20 Ratio: 3.25
Max-min Ratio: 5.875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-31-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 562.66
  episode_reward_min: 491.0
  episodes_this_iter: 1
  episodes_total: 461
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.705
    dispatch_time_ms: 7.693
    learner:
      cur_lr: 0.0007459479966200888
      grad_gnorm: 40.0
      policy_entropy: 271.1199951171875
      policy_loss: 10.177842140197754
      var_gnorm: 49.43909454345703
      vf_explained_var: 0.8678896427154541
      vf_loss: 16.22988510131836
    num_steps_sampled: 9240000
    num_steps_trained: 9240000
    wait_time_ms: 343.482
  iterations_since_restore: 462
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 16144.719944000244
  time_this_iter_s: 34.587451219558716
  time_total_s: 16144.719944000244
  timestamp: 1594153868
  timesteps_since_restore: 9240000
  timesteps_this_iter: 20000
  timesteps_total: 9240000
  training_iteration: 462
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 16144 s, 462 iter, 9240000 ts, 563 rew

agent-1: 11.0
agent-2: 23.0
agent-3: 32.0
agent-4: 31.0
agent-5: 17.0
agent-6: 39.0
agent-7: 49.0
agent-8: 47.0
agent-9: 33.0
agent-10: 19.0
agent-11: 33.0
agent-12: 31.0
agent-13: 20.0
agent-14: 39.0
agent-15: 20.0
agent-16: 32.0
agent-17: 26.0
agent-18: 27.0
agent-19: 15.0
agent-20: 37.0
Sum Reward: 581.0
Avg Reward: 29.05
Min Reward: 11.0
Max Reward: 49.0
Gini Coefficient: 0.19578313253012047
20:20 Ratio: 2.806451612903226
Max-min Ratio: 4.454545454545454
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-31-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 563.18
  episode_reward_min: 491.0
  episodes_this_iter: 1
  episodes_total: 462
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.466
    dispatch_time_ms: 7.1
    learner:
      cur_lr: 0.000744615972507745
      grad_gnorm: 0.672539234161377
      policy_entropy: 364.6872863769531
      policy_loss: 1.1612428426742554
      var_gnorm: 49.49734115600586
      vf_explained_var: 0.0
      vf_loss: 7.899153570178896e-05
    num_steps_sampled: 9260000
    num_steps_trained: 9260000
    wait_time_ms: 344.929
  iterations_since_restore: 463
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 16179.605839014053
  time_this_iter_s: 34.885895013809204
  time_total_s: 16179.605839014053
  timestamp: 1594153903
  timesteps_since_restore: 9260000
  timesteps_this_iter: 20000
  timesteps_total: 9260000
  training_iteration: 463
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 16179 s, 463 iter, 9260000 ts, 563 rew

agent-1: 16.0
agent-2: 24.0
agent-3: 13.0
agent-4: 20.0
agent-5: 30.0
agent-6: 27.0
agent-7: 22.0
agent-8: 44.0
agent-9: 28.0
agent-10: 30.0
agent-11: 30.0
agent-12: 22.0
agent-13: 25.0
agent-14: 30.0
agent-15: 27.0
agent-16: 34.0
agent-17: 28.0
agent-18: 37.0
agent-19: 25.0
agent-20: 34.0
Sum Reward: 546.0
Avg Reward: 27.3
Min Reward: 13.0
Max Reward: 44.0
Gini Coefficient: 0.13901098901098902
20:20 Ratio: 2.0985915492957745
Max-min Ratio: 3.3846153846153846
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-32-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 563.19
  episode_reward_min: 491.0
  episodes_this_iter: 1
  episodes_total: 463
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.708
    dispatch_time_ms: 6.304
    learner:
      cur_lr: 0.0007432840066030622
      grad_gnorm: 5.196016311645508
      policy_entropy: 372.0298156738281
      policy_loss: -2.457533121109009
      var_gnorm: 49.471290588378906
      vf_explained_var: 0.0
      vf_loss: 0.00865703821182251
    num_steps_sampled: 9280000
    num_steps_trained: 9280000
    wait_time_ms: 341.129
  iterations_since_restore: 464
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 16214.532536029816
  time_this_iter_s: 34.92669701576233
  time_total_s: 16214.532536029816
  timestamp: 1594153938
  timesteps_since_restore: 9280000
  timesteps_this_iter: 20000
  timesteps_total: 9280000
  training_iteration: 464
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 16214 s, 464 iter, 9280000 ts, 563 rew

agent-1: 24.0
agent-2: 21.0
agent-3: 25.0
agent-4: 36.0
agent-5: 28.0
agent-6: 25.0
agent-7: 21.0
agent-8: 43.0
agent-9: 28.0
agent-10: 26.0
agent-11: 24.0
agent-12: 27.0
agent-13: 38.0
agent-14: 27.0
agent-15: 30.0
agent-16: 25.0
agent-17: 35.0
agent-18: 17.0
agent-19: 17.0
agent-20: 40.0
Sum Reward: 557.0
Avg Reward: 27.85
Min Reward: 17.0
Max Reward: 43.0
Gini Coefficient: 0.13940754039497308
20:20 Ratio: 2.0657894736842106
Max-min Ratio: 2.5294117647058822
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-32-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 563.85
  episode_reward_min: 498.0
  episodes_this_iter: 1
  episodes_total: 464
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.502
    dispatch_time_ms: 6.448
    learner:
      cur_lr: 0.0007419519824907184
      grad_gnorm: 5.168749809265137
      policy_entropy: 358.17620849609375
      policy_loss: 3.1287882328033447
      var_gnorm: 49.45454788208008
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.008364633657038212
    num_steps_sampled: 9300000
    num_steps_trained: 9300000
    wait_time_ms: 343.963
  iterations_since_restore: 465
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 16248.881024599075
  time_this_iter_s: 34.348488569259644
  time_total_s: 16248.881024599075
  timestamp: 1594153973
  timesteps_since_restore: 9300000
  timesteps_this_iter: 20000
  timesteps_total: 9300000
  training_iteration: 465
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 16248 s, 465 iter, 9300000 ts, 564 rew

agent-1: 45.0
agent-2: 35.0
agent-3: 29.0
agent-4: 22.0
agent-5: 37.0
agent-6: 26.0
agent-7: 18.0
agent-8: 32.0
agent-9: 38.0
agent-10: 29.0
agent-11: 24.0
agent-12: 21.0
agent-13: 27.0
agent-14: 36.0
agent-15: 14.0
agent-16: 20.0
agent-17: 33.0
agent-18: 36.0
agent-19: 27.0
agent-20: 19.0
Sum Reward: 568.0
Avg Reward: 28.4
Min Reward: 14.0
Max Reward: 45.0
Gini Coefficient: 0.15757042253521128
20:20 Ratio: 2.1971830985915495
Max-min Ratio: 3.2142857142857144
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-33-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 564.32
  episode_reward_min: 498.0
  episodes_this_iter: 1
  episodes_total: 465
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.808
    dispatch_time_ms: 6.035
    learner:
      cur_lr: 0.0007406200165860355
      grad_gnorm: 40.00001525878906
      policy_entropy: 44.48554229736328
      policy_loss: 5.832324981689453
      var_gnorm: 49.41328430175781
      vf_explained_var: 0.7151125073432922
      vf_loss: 159.9033203125
    num_steps_sampled: 9320000
    num_steps_trained: 9320000
    wait_time_ms: 333.584
  iterations_since_restore: 466
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 16283.819341182709
  time_this_iter_s: 34.93831658363342
  time_total_s: 16283.819341182709
  timestamp: 1594154008
  timesteps_since_restore: 9320000
  timesteps_this_iter: 20000
  timesteps_total: 9320000
  training_iteration: 466
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 16283 s, 466 iter, 9320000 ts, 564 rew

agent-1: 27.0
agent-2: 28.0
agent-3: 38.0
agent-4: 34.0
agent-5: 31.0
agent-6: 38.0
agent-7: 33.0
agent-8: 43.0
agent-9: 39.0
agent-10: 20.0
agent-11: 21.0
agent-12: 22.0
agent-13: 18.0
agent-14: 18.0
agent-15: 40.0
agent-16: 31.0
agent-17: 24.0
agent-18: 47.0
agent-19: 32.0
agent-20: 27.0
Sum Reward: 611.0
Avg Reward: 30.55
Min Reward: 18.0
Max Reward: 47.0
Gini Coefficient: 0.15572831423895253
20:20 Ratio: 2.1948051948051948
Max-min Ratio: 2.611111111111111
W0707 16:34:27.926890 17834 client_connection.cc:255] [worker]ProcessMessage with type 1 took 4610 ms.
W0707 16:34:28.479838 17834 node_manager.cc:250] Last heartbeat was sent 5243 ms ago 
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-34-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 565.28
  episode_reward_min: 498.0
  episodes_this_iter: 1
  episodes_total: 466
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2285.199
    dispatch_time_ms: 58.272
    learner:
      cur_lr: 0.0007392879924736917
      grad_gnorm: 2.0257620811462402
      policy_entropy: 362.71337890625
      policy_loss: 0.1001940667629242
      var_gnorm: 49.53527069091797
      vf_explained_var: -1.0
      vf_loss: 0.00640742015093565
    num_steps_sampled: 9340000
    num_steps_trained: 9340000
    wait_time_ms: 621.885
  iterations_since_restore: 467
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 16344.618355035782
  time_this_iter_s: 60.79901385307312
  time_total_s: 16344.618355035782
  timestamp: 1594154069
  timesteps_since_restore: 9340000
  timesteps_this_iter: 20000
  timesteps_total: 9340000
  training_iteration: 467
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 16344 s, 467 iter, 9340000 ts, 565 rew

agent-1: 31.0
agent-2: 43.0
agent-3: 29.0
agent-4: 43.0
agent-5: 43.0
agent-6: 26.0
agent-7: 35.0
agent-8: 19.0
agent-9: 22.0
agent-10: 46.0
agent-11: 39.0
agent-12: 15.0
agent-13: 37.0
agent-14: 48.0
agent-15: 23.0
agent-16: 35.0
agent-17: 27.0
agent-18: 13.0
agent-19: 18.0
agent-20: 49.0
Sum Reward: 641.0
Avg Reward: 32.05
Min Reward: 13.0
Max Reward: 49.0
Gini Coefficient: 0.19898595943837755
20:20 Ratio: 2.8615384615384616
Max-min Ratio: 3.769230769230769
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-35-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 566.33
  episode_reward_min: 498.0
  episodes_this_iter: 1
  episodes_total: 467
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.586
    dispatch_time_ms: 22.126
    learner:
      cur_lr: 0.0007379560265690088
      grad_gnorm: 39.99999237060547
      policy_entropy: 302.29986572265625
      policy_loss: 74.23709869384766
      var_gnorm: 49.51215744018555
      vf_explained_var: 0.24799543619155884
      vf_loss: 47.99197769165039
    num_steps_sampled: 9360000
    num_steps_trained: 9360000
    wait_time_ms: 329.498
  iterations_since_restore: 468
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 16378.838786840439
  time_this_iter_s: 34.22043180465698
  time_total_s: 16378.838786840439
  timestamp: 1594154103
  timesteps_since_restore: 9360000
  timesteps_this_iter: 20000
  timesteps_total: 9360000
  training_iteration: 468
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 16378 s, 468 iter, 9360000 ts, 566 rew

agent-1: 17.0
agent-2: 32.0
agent-3: 22.0
agent-4: 31.0
agent-5: 16.0
agent-6: 33.0
agent-7: 27.0
agent-8: 18.0
agent-9: 37.0
agent-10: 35.0
agent-11: 28.0
agent-12: 35.0
agent-13: 25.0
agent-14: 26.0
agent-15: 24.0
agent-16: 21.0
agent-17: 44.0
agent-18: 26.0
agent-19: 34.0
agent-20: 38.0
Sum Reward: 569.0
Avg Reward: 28.45
Min Reward: 16.0
Max Reward: 44.0
Gini Coefficient: 0.1485940246045694
20:20 Ratio: 2.138888888888889
Max-min Ratio: 2.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-35-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 566.44
  episode_reward_min: 498.0
  episodes_this_iter: 1
  episodes_total: 468
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.561
    dispatch_time_ms: 36.106
    learner:
      cur_lr: 0.000736624002456665
      grad_gnorm: 2.5020580291748047
      policy_entropy: 359.7520751953125
      policy_loss: 2.3508856296539307
      var_gnorm: 49.48456573486328
      vf_explained_var: -0.05621981620788574
      vf_loss: 0.10707537829875946
    num_steps_sampled: 9380000
    num_steps_trained: 9380000
    wait_time_ms: 332.214
  iterations_since_restore: 469
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 16414.31560587883
  time_this_iter_s: 35.47681903839111
  time_total_s: 16414.31560587883
  timestamp: 1594154138
  timesteps_since_restore: 9380000
  timesteps_this_iter: 20000
  timesteps_total: 9380000
  training_iteration: 469
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 16414 s, 469 iter, 9380000 ts, 566 rew

agent-1: 13.0
agent-2: 34.0
agent-3: 26.0
agent-4: 43.0
agent-5: 12.0
agent-6: 25.0
agent-7: 17.0
agent-8: 23.0
agent-9: 27.0
agent-10: 24.0
agent-11: 29.0
agent-12: 30.0
agent-13: 20.0
agent-14: 45.0
agent-15: 20.0
agent-16: 24.0
agent-17: 22.0
agent-18: 37.0
agent-19: 29.0
agent-20: 27.0
Sum Reward: 527.0
Avg Reward: 26.35
Min Reward: 12.0
Max Reward: 45.0
Gini Coefficient: 0.17637571157495255
20:20 Ratio: 2.564516129032258
Max-min Ratio: 3.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-36-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1097.0
  episode_reward_mean: 566.13
  episode_reward_min: 498.0
  episodes_this_iter: 1
  episodes_total: 469
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.564
    dispatch_time_ms: 18.995
    learner:
      cur_lr: 0.0007352919783443213
      grad_gnorm: 0.9107093214988708
      policy_entropy: 370.4063415527344
      policy_loss: -2.8716020584106445
      var_gnorm: 49.51418685913086
      vf_explained_var: -1.0
      vf_loss: 0.0014464494306594133
    num_steps_sampled: 9400000
    num_steps_trained: 9400000
    wait_time_ms: 325.675
  iterations_since_restore: 470
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 16450.600064992905
  time_this_iter_s: 36.28445911407471
  time_total_s: 16450.600064992905
  timestamp: 1594154175
  timesteps_since_restore: 9400000
  timesteps_this_iter: 20000
  timesteps_total: 9400000
  training_iteration: 470
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 16450 s, 470 iter, 9400000 ts, 566 rew

agent-1: 19.0
agent-2: 13.0
agent-3: 31.0
agent-4: 31.0
agent-5: 42.0
agent-6: 36.0
agent-7: 19.0
agent-8: 42.0
agent-9: 27.0
agent-10: 27.0
agent-11: 36.0
agent-12: 22.0
agent-13: 27.0
agent-14: 31.0
agent-15: 36.0
agent-16: 33.0
agent-17: 11.0
agent-18: 15.0
agent-19: 28.0
agent-20: 17.0
Sum Reward: 543.0
Avg Reward: 27.15
Min Reward: 11.0
Max Reward: 42.0
Gini Coefficient: 0.18904235727440147
20:20 Ratio: 2.7857142857142856
Max-min Ratio: 3.8181818181818183
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-36-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 709.0
  episode_reward_mean: 560.59
  episode_reward_min: 498.0
  episodes_this_iter: 1
  episodes_total: 470
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.602
    dispatch_time_ms: 13.853
    learner:
      cur_lr: 0.0007339600124396384
      grad_gnorm: 2.5187911987304688
      policy_entropy: 375.58575439453125
      policy_loss: 0.7759007811546326
      var_gnorm: 49.64301681518555
      vf_explained_var: -1.0
      vf_loss: 0.001064747804775834
    num_steps_sampled: 9420000
    num_steps_trained: 9420000
    wait_time_ms: 350.905
  iterations_since_restore: 471
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 16486.600961446762
  time_this_iter_s: 36.00089645385742
  time_total_s: 16486.600961446762
  timestamp: 1594154211
  timesteps_since_restore: 9420000
  timesteps_this_iter: 20000
  timesteps_total: 9420000
  training_iteration: 471
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 16486 s, 471 iter, 9420000 ts, 561 rew

agent-1: 30.0
agent-2: 38.0
agent-3: 26.0
agent-4: 35.0
agent-5: 21.0
agent-6: 31.0
agent-7: 42.0
agent-8: 26.0
agent-9: 29.0
agent-10: 24.0
agent-11: 26.0
agent-12: 27.0
agent-13: 30.0
agent-14: 23.0
agent-15: 27.0
agent-16: 34.0
agent-17: 34.0
agent-18: 28.0
agent-19: 22.0
agent-20: 21.0
Sum Reward: 574.0
Avg Reward: 28.7
Min Reward: 21.0
Max Reward: 42.0
Gini Coefficient: 0.10766550522648084
20:20 Ratio: 1.7126436781609196
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-37-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 709.0
  episode_reward_mean: 559.29
  episode_reward_min: 498.0
  episodes_this_iter: 1
  episodes_total: 471
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.736
    dispatch_time_ms: 25.573
    learner:
      cur_lr: 0.0007326279883272946
      grad_gnorm: 1.3860760927200317
      policy_entropy: 382.00506591796875
      policy_loss: -0.052621424198150635
      var_gnorm: 49.645328521728516
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0005119950510561466
    num_steps_sampled: 9440000
    num_steps_trained: 9440000
    wait_time_ms: 328.646
  iterations_since_restore: 472
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 16523.056005954742
  time_this_iter_s: 36.45504450798035
  time_total_s: 16523.056005954742
  timestamp: 1594154248
  timesteps_since_restore: 9440000
  timesteps_this_iter: 20000
  timesteps_total: 9440000
  training_iteration: 472
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 16523 s, 472 iter, 9440000 ts, 559 rew

agent-1: 20.0
agent-2: 16.0
agent-3: 26.0
agent-4: 27.0
agent-5: 37.0
agent-6: 31.0
agent-7: 26.0
agent-8: 22.0
agent-9: 24.0
agent-10: 27.0
agent-11: 19.0
agent-12: 28.0
agent-13: 37.0
agent-14: 30.0
agent-15: 33.0
agent-16: 15.0
agent-17: 23.0
agent-18: 24.0
agent-19: 24.0
agent-20: 28.0
Sum Reward: 517.0
Avg Reward: 25.85
Min Reward: 15.0
Max Reward: 37.0
Gini Coefficient: 0.1269825918762089
20:20 Ratio: 1.9714285714285715
Max-min Ratio: 2.466666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-38-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 709.0
  episode_reward_mean: 557.54
  episode_reward_min: 498.0
  episodes_this_iter: 1
  episodes_total: 472
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.802
    dispatch_time_ms: 6.454
    learner:
      cur_lr: 0.0007312960224226117
      grad_gnorm: 1.0204322338104248
      policy_entropy: 378.1164855957031
      policy_loss: -0.42177045345306396
      var_gnorm: 49.61731719970703
      vf_explained_var: -1.0
      vf_loss: 0.0019274663645774126
    num_steps_sampled: 9460000
    num_steps_trained: 9460000
    wait_time_ms: 343.176
  iterations_since_restore: 473
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 16557.983201503754
  time_this_iter_s: 34.92719554901123
  time_total_s: 16557.983201503754
  timestamp: 1594154283
  timesteps_since_restore: 9460000
  timesteps_this_iter: 20000
  timesteps_total: 9460000
  training_iteration: 473
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 16557 s, 473 iter, 9460000 ts, 558 rew

agent-1: 19.0
agent-2: 15.0
agent-3: 32.0
agent-4: 37.0
agent-5: 19.0
agent-6: 31.0
agent-7: 29.0
agent-8: 30.0
agent-9: 30.0
agent-10: 28.0
agent-11: 30.0
agent-12: 35.0
agent-13: 17.0
agent-14: 23.0
agent-15: 30.0
agent-16: 15.0
agent-17: 29.0
agent-18: 20.0
agent-19: 19.0
agent-20: 27.0
Sum Reward: 515.0
Avg Reward: 25.75
Min Reward: 15.0
Max Reward: 37.0
Gini Coefficient: 0.14281553398058253
20:20 Ratio: 2.0454545454545454
Max-min Ratio: 2.466666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-38-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 709.0
  episode_reward_mean: 555.85
  episode_reward_min: 498.0
  episodes_this_iter: 1
  episodes_total: 473
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.54
    dispatch_time_ms: 6.912
    learner:
      cur_lr: 0.0007299639983102679
      grad_gnorm: 1.6294018030166626
      policy_entropy: 375.846923828125
      policy_loss: -0.905450165271759
      var_gnorm: 49.677955627441406
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0008250981336459517
    num_steps_sampled: 9480000
    num_steps_trained: 9480000
    wait_time_ms: 337.529
  iterations_since_restore: 474
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 16592.751792430878
  time_this_iter_s: 34.76859092712402
  time_total_s: 16592.751792430878
  timestamp: 1594154317
  timesteps_since_restore: 9480000
  timesteps_this_iter: 20000
  timesteps_total: 9480000
  training_iteration: 474
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 16592 s, 474 iter, 9480000 ts, 556 rew

agent-1: 30.0
agent-2: 38.0
agent-3: 17.0
agent-4: 37.0
agent-5: 28.0
agent-6: 20.0
agent-7: 35.0
agent-8: 28.0
agent-9: 28.0
agent-10: 29.0
agent-11: 36.0
agent-12: 23.0
agent-13: 22.0
agent-14: 23.0
agent-15: 25.0
agent-16: 27.0
agent-17: 25.0
agent-18: 29.0
agent-19: 23.0
agent-20: 21.0
Sum Reward: 544.0
Avg Reward: 27.2
Min Reward: 17.0
Max Reward: 38.0
Gini Coefficient: 0.11764705882352941
20:20 Ratio: 1.825
Max-min Ratio: 2.235294117647059
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-39-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 702.0
  episode_reward_mean: 554.2
  episode_reward_min: 498.0
  episodes_this_iter: 1
  episodes_total: 474
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.928
    dispatch_time_ms: 11.615
    learner:
      cur_lr: 0.0007286319741979241
      grad_gnorm: 3.4424712657928467
      policy_entropy: 364.7861328125
      policy_loss: 1.3253417015075684
      var_gnorm: 49.75858688354492
      vf_explained_var: -1.0
      vf_loss: 0.002471814164891839
    num_steps_sampled: 9500000
    num_steps_trained: 9500000
    wait_time_ms: 354.76
  iterations_since_restore: 475
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 16627.856278657913
  time_this_iter_s: 35.10448622703552
  time_total_s: 16627.856278657913
  timestamp: 1594154353
  timesteps_since_restore: 9500000
  timesteps_this_iter: 20000
  timesteps_total: 9500000
  training_iteration: 475
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 16627 s, 475 iter, 9500000 ts, 554 rew

agent-1: 37.0
agent-2: 30.0
agent-3: 15.0
agent-4: 33.0
agent-5: 27.0
agent-6: 41.0
agent-7: 45.0
agent-8: 16.0
agent-9: 39.0
agent-10: 20.0
agent-11: 15.0
agent-12: 28.0
agent-13: 12.0
agent-14: 37.0
agent-15: 25.0
agent-16: 13.0
agent-17: 23.0
agent-18: 26.0
agent-19: 34.0
agent-20: 40.0
Sum Reward: 556.0
Avg Reward: 27.8
Min Reward: 12.0
Max Reward: 45.0
Gini Coefficient: 0.20719424460431654
20:20 Ratio: 3.0
Max-min Ratio: 3.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-39-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 641.0
  episode_reward_mean: 552.74
  episode_reward_min: 498.0
  episodes_this_iter: 1
  episodes_total: 475
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.382
    dispatch_time_ms: 5.583
    learner:
      cur_lr: 0.0007273000082932413
      grad_gnorm: 2.0954442024230957
      policy_entropy: 371.585693359375
      policy_loss: -0.5528013706207275
      var_gnorm: 49.739601135253906
      vf_explained_var: 0.8748078346252441
      vf_loss: 0.0013175893109291792
    num_steps_sampled: 9520000
    num_steps_trained: 9520000
    wait_time_ms: 345.553
  iterations_since_restore: 476
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 16662.6076233387
  time_this_iter_s: 34.75134468078613
  time_total_s: 16662.6076233387
  timestamp: 1594154387
  timesteps_since_restore: 9520000
  timesteps_this_iter: 20000
  timesteps_total: 9520000
  training_iteration: 476
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 16662 s, 476 iter, 9520000 ts, 553 rew

agent-1: 28.0
agent-2: 31.0
agent-3: 24.0
agent-4: 30.0
agent-5: 37.0
agent-6: 30.0
agent-7: 30.0
agent-8: 27.0
agent-9: 16.0
agent-10: 30.0
agent-11: 24.0
agent-12: 26.0
agent-13: 32.0
agent-14: 23.0
agent-15: 28.0
agent-16: 26.0
agent-17: 29.0
agent-18: 24.0
agent-19: 24.0
agent-20: 20.0
Sum Reward: 539.0
Avg Reward: 26.95
Min Reward: 16.0
Max Reward: 37.0
Gini Coefficient: 0.09137291280148423
20:20 Ratio: 1.5662650602409638
Max-min Ratio: 2.3125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-40-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 641.0
  episode_reward_mean: 552.45
  episode_reward_min: 498.0
  episodes_this_iter: 1
  episodes_total: 476
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.616
    dispatch_time_ms: 5.586
    learner:
      cur_lr: 0.0007259679841808975
      grad_gnorm: 0.8095086812973022
      policy_entropy: 336.5882873535156
      policy_loss: -0.1694430112838745
      var_gnorm: 49.72337341308594
      vf_explained_var: -1.0
      vf_loss: 0.005680136848241091
    num_steps_sampled: 9540000
    num_steps_trained: 9540000
    wait_time_ms: 341.12
  iterations_since_restore: 477
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 16697.596959590912
  time_this_iter_s: 34.989336252212524
  time_total_s: 16697.596959590912
  timestamp: 1594154422
  timesteps_since_restore: 9540000
  timesteps_this_iter: 20000
  timesteps_total: 9540000
  training_iteration: 477
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 16697 s, 477 iter, 9540000 ts, 552 rew

agent-1: 27.0
agent-2: 29.0
agent-3: 36.0
agent-4: 27.0
agent-5: 31.0
agent-6: 34.0
agent-7: 27.0
agent-8: 28.0
agent-9: 28.0
agent-10: 25.0
agent-11: 33.0
agent-12: 18.0
agent-13: 25.0
agent-14: 26.0
agent-15: 35.0
agent-16: 20.0
agent-17: 20.0
agent-18: 23.0
agent-19: 35.0
agent-20: 25.0
Sum Reward: 552.0
Avg Reward: 27.6
Min Reward: 18.0
Max Reward: 36.0
Gini Coefficient: 0.10398550724637681
20:20 Ratio: 1.728395061728395
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-40-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 641.0
  episode_reward_mean: 551.83
  episode_reward_min: 498.0
  episodes_this_iter: 1
  episodes_total: 477
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.458
    dispatch_time_ms: 6.05
    learner:
      cur_lr: 0.0007246360182762146
      grad_gnorm: 40.0
      policy_entropy: 89.04939270019531
      policy_loss: 6.420331954956055
      var_gnorm: 49.716190338134766
      vf_explained_var: 0.805801510810852
      vf_loss: 223.53369140625
    num_steps_sampled: 9560000
    num_steps_trained: 9560000
    wait_time_ms: 315.638
  iterations_since_restore: 478
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 16732.239416122437
  time_this_iter_s: 34.64245653152466
  time_total_s: 16732.239416122437
  timestamp: 1594154457
  timesteps_since_restore: 9560000
  timesteps_this_iter: 20000
  timesteps_total: 9560000
  training_iteration: 478
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 16732 s, 478 iter, 9560000 ts, 552 rew

agent-1: 36.0
agent-2: 20.0
agent-3: 33.0
agent-4: 26.0
agent-5: 24.0
agent-6: 31.0
agent-7: 24.0
agent-8: 23.0
agent-9: 28.0
agent-10: 23.0
agent-11: 21.0
agent-12: 19.0
agent-13: 25.0
agent-14: 28.0
agent-15: 32.0
agent-16: 21.0
agent-17: 24.0
agent-18: 25.0
agent-19: 27.0
agent-20: 27.0
Sum Reward: 517.0
Avg Reward: 25.85
Min Reward: 19.0
Max Reward: 36.0
Gini Coefficient: 0.0948742746615087
20:20 Ratio: 1.6296296296296295
Max-min Ratio: 1.894736842105263
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-41-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 641.0
  episode_reward_mean: 551.24
  episode_reward_min: 498.0
  episodes_this_iter: 1
  episodes_total: 478
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.587
    dispatch_time_ms: 6.115
    learner:
      cur_lr: 0.0007233039941638708
      grad_gnorm: 0.7177847623825073
      policy_entropy: 360.242431640625
      policy_loss: 0.37800902128219604
      var_gnorm: 49.68968963623047
      vf_explained_var: -1.0
      vf_loss: 0.00029890728183090687
    num_steps_sampled: 9580000
    num_steps_trained: 9580000
    wait_time_ms: 345.136
  iterations_since_restore: 479
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 16768.570256471634
  time_this_iter_s: 36.33084034919739
  time_total_s: 16768.570256471634
  timestamp: 1594154493
  timesteps_since_restore: 9580000
  timesteps_this_iter: 20000
  timesteps_total: 9580000
  training_iteration: 479
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 16768 s, 479 iter, 9580000 ts, 551 rew

agent-1: 33.0
agent-2: 29.0
agent-3: 36.0
agent-4: 23.0
agent-5: 27.0
agent-6: 29.0
agent-7: 25.0
agent-8: 32.0
agent-9: 28.0
agent-10: 12.0
agent-11: 27.0
agent-12: 31.0
agent-13: 36.0
agent-14: 42.0
agent-15: 27.0
agent-16: 24.0
agent-17: 31.0
agent-18: 21.0
agent-19: 13.0
agent-20: 30.0
Sum Reward: 556.0
Avg Reward: 27.8
Min Reward: 12.0
Max Reward: 42.0
Gini Coefficient: 0.1356115107913669
20:20 Ratio: 2.130434782608696
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-42-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 641.0
  episode_reward_mean: 551.26
  episode_reward_min: 498.0
  episodes_this_iter: 1
  episodes_total: 479
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.646
    dispatch_time_ms: 31.959
    learner:
      cur_lr: 0.0007219720282591879
      grad_gnorm: 2.200198173522949
      policy_entropy: 373.80029296875
      policy_loss: -2.7038583755493164
      var_gnorm: 49.67574691772461
      vf_explained_var: -0.3178209066390991
      vf_loss: 0.0012859951239079237
    num_steps_sampled: 9600000
    num_steps_trained: 9600000
    wait_time_ms: 301.938
  iterations_since_restore: 480
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 16803.839241027832
  time_this_iter_s: 35.26898455619812
  time_total_s: 16803.839241027832
  timestamp: 1594154529
  timesteps_since_restore: 9600000
  timesteps_this_iter: 20000
  timesteps_total: 9600000
  training_iteration: 480
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 16803 s, 480 iter, 9600000 ts, 551 rew

agent-1: 31.0
agent-2: 21.0
agent-3: 16.0
agent-4: 25.0
agent-5: 19.0
agent-6: 25.0
agent-7: 26.0
agent-8: 28.0
agent-9: 23.0
agent-10: 20.0
agent-11: 29.0
agent-12: 21.0
agent-13: 33.0
agent-14: 38.0
agent-15: 41.0
agent-16: 28.0
agent-17: 28.0
agent-18: 28.0
agent-19: 30.0
agent-20: 26.0
Sum Reward: 536.0
Avg Reward: 26.8
Min Reward: 16.0
Max Reward: 41.0
Gini Coefficient: 0.12313432835820895
20:20 Ratio: 1.881578947368421
Max-min Ratio: 2.5625
W0707 16:42:49.036677 17834 client_connection.cc:255] [worker]ProcessMessage with type 8 took 190 ms.
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-42-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 641.0
  episode_reward_mean: 550.44
  episode_reward_min: 498.0
  episodes_this_iter: 1
  episodes_total: 480
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.817
    dispatch_time_ms: 25.113
    learner:
      cur_lr: 0.0007206400041468441
      grad_gnorm: 1.0452286005020142
      policy_entropy: 368.5362548828125
      policy_loss: -0.726402759552002
      var_gnorm: 49.74284362792969
      vf_explained_var: -1.0
      vf_loss: 0.005950383376330137
    num_steps_sampled: 9620000
    num_steps_trained: 9620000
    wait_time_ms: 345.253
  iterations_since_restore: 481
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 16839.79220557213
  time_this_iter_s: 35.952964544296265
  time_total_s: 16839.79220557213
  timestamp: 1594154565
  timesteps_since_restore: 9620000
  timesteps_this_iter: 20000
  timesteps_total: 9620000
  training_iteration: 481
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 16839 s, 481 iter, 9620000 ts, 550 rew

W0707 16:42:50.831763 17834 client_connection.cc:255] [worker]ProcessMessage with type 1 took 186 ms.
agent-1: 33.0
agent-2: 32.0
agent-3: 24.0
agent-4: 23.0
agent-5: 31.0
agent-6: 25.0
agent-7: 18.0
agent-8: 16.0
agent-9: 31.0
agent-10: 28.0
agent-11: 35.0
agent-12: 31.0
agent-13: 17.0
agent-14: 28.0
agent-15: 23.0
agent-16: 31.0
agent-17: 34.0
agent-18: 28.0
agent-19: 43.0
agent-20: 26.0
Sum Reward: 557.0
Avg Reward: 27.85
Min Reward: 16.0
Max Reward: 43.0
Gini Coefficient: 0.12809694793536805
20:20 Ratio: 1.9594594594594594
Max-min Ratio: 2.6875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-43-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 641.0
  episode_reward_mean: 550.48
  episode_reward_min: 498.0
  episodes_this_iter: 1
  episodes_total: 481
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.766
    dispatch_time_ms: 34.742
    learner:
      cur_lr: 0.0007193079800345004
      grad_gnorm: 1.302340030670166
      policy_entropy: 378.726318359375
      policy_loss: -1.273794174194336
      var_gnorm: 49.74880599975586
      vf_explained_var: -0.5462548732757568
      vf_loss: 0.000172484724316746
    num_steps_sampled: 9640000
    num_steps_trained: 9640000
    wait_time_ms: 337.337
  iterations_since_restore: 482
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 16873.032596826553
  time_this_iter_s: 33.24039125442505
  time_total_s: 16873.032596826553
  timestamp: 1594154603
  timesteps_since_restore: 9640000
  timesteps_this_iter: 20000
  timesteps_total: 9640000
  training_iteration: 482
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 16873 s, 482 iter, 9640000 ts, 550 rew

agent-1: 30.0
agent-2: 27.0
agent-3: 27.0
agent-4: 33.0
agent-5: 27.0
agent-6: 20.0
agent-7: 37.0
agent-8: 36.0
agent-9: 19.0
agent-10: 32.0
agent-11: 32.0
agent-12: 25.0
agent-13: 25.0
agent-14: 19.0
agent-15: 33.0
agent-16: 19.0
agent-17: 25.0
agent-18: 27.0
agent-19: 23.0
agent-20: 21.0
Sum Reward: 537.0
Avg Reward: 26.85
Min Reward: 19.0
Max Reward: 37.0
Gini Coefficient: 0.11759776536312849
20:20 Ratio: 1.8051948051948052
Max-min Ratio: 1.9473684210526316
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-43-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 641.0
  episode_reward_mean: 550.33
  episode_reward_min: 498.0
  episodes_this_iter: 1
  episodes_total: 482
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.958
    dispatch_time_ms: 29.153
    learner:
      cur_lr: 0.0007179760141298175
      grad_gnorm: 0.29587849974632263
      policy_entropy: 372.8260498046875
      policy_loss: -0.10880264639854431
      var_gnorm: 49.850242614746094
      vf_explained_var: -1.0
      vf_loss: 0.00016781417070887983
    num_steps_sampled: 9660000
    num_steps_trained: 9660000
    wait_time_ms: 305.313
  iterations_since_restore: 483
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 16909.01733970642
  time_this_iter_s: 35.984742879867554
  time_total_s: 16909.01733970642
  timestamp: 1594154639
  timesteps_since_restore: 9660000
  timesteps_this_iter: 20000
  timesteps_total: 9660000
  training_iteration: 483
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 16909 s, 483 iter, 9660000 ts, 550 rew

agent-1: 37.0
agent-2: 24.0
agent-3: 25.0
agent-4: 31.0
agent-5: 35.0
agent-6: 23.0
agent-7: 35.0
agent-8: 26.0
agent-9: 29.0
agent-10: 24.0
agent-11: 20.0
agent-12: 28.0
agent-13: 23.0
agent-14: 32.0
agent-15: 23.0
agent-16: 29.0
agent-17: 25.0
agent-18: 32.0
agent-19: 29.0
agent-20: 20.0
Sum Reward: 550.0
Avg Reward: 27.5
Min Reward: 20.0
Max Reward: 37.0
Gini Coefficient: 0.10054545454545455
20:20 Ratio: 1.6162790697674418
Max-min Ratio: 1.85
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-44-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 641.0
  episode_reward_mean: 549.69
  episode_reward_min: 498.0
  episodes_this_iter: 1
  episodes_total: 483
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.67
    dispatch_time_ms: 7.053
    learner:
      cur_lr: 0.0007166439900174737
      grad_gnorm: 0.4262252449989319
      policy_entropy: 381.4311218261719
      policy_loss: -0.12790778279304504
      var_gnorm: 49.841270446777344
      vf_explained_var: -0.04106879234313965
      vf_loss: 0.0002815904445014894
    num_steps_sampled: 9680000
    num_steps_trained: 9680000
    wait_time_ms: 340.333
  iterations_since_restore: 484
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 16944.20513153076
  time_this_iter_s: 35.18779182434082
  time_total_s: 16944.20513153076
  timestamp: 1594154674
  timesteps_since_restore: 9680000
  timesteps_this_iter: 20000
  timesteps_total: 9680000
  training_iteration: 484
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 16944 s, 484 iter, 9680000 ts, 550 rew

agent-1: 27.0
agent-2: 21.0
agent-3: 22.0
agent-4: 27.0
agent-5: 27.0
agent-6: 26.0
agent-7: 18.0
agent-8: 31.0
agent-9: 24.0
agent-10: 22.0
agent-11: 23.0
agent-12: 30.0
agent-13: 27.0
agent-14: 22.0
agent-15: 35.0
agent-16: 26.0
agent-17: 30.0
agent-18: 31.0
agent-19: 24.0
agent-20: 14.0
Sum Reward: 507.0
Avg Reward: 25.35
Min Reward: 14.0
Max Reward: 35.0
Gini Coefficient: 0.10443786982248521
20:20 Ratio: 1.6933333333333334
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-45-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 641.0
  episode_reward_mean: 549.27
  episode_reward_min: 498.0
  episodes_this_iter: 1
  episodes_total: 484
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.598
    dispatch_time_ms: 4.945
    learner:
      cur_lr: 0.0007153120241127908
      grad_gnorm: 1.3839666843414307
      policy_entropy: 375.24468994140625
      policy_loss: 1.1058348417282104
      var_gnorm: 49.867698669433594
      vf_explained_var: 2.980232238769531e-07
      vf_loss: 0.0011266848305240273
    num_steps_sampled: 9700000
    num_steps_trained: 9700000
    wait_time_ms: 344.596
  iterations_since_restore: 485
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 16978.773163557053
  time_this_iter_s: 34.568032026290894
  time_total_s: 16978.773163557053
  timestamp: 1594154709
  timesteps_since_restore: 9700000
  timesteps_this_iter: 20000
  timesteps_total: 9700000
  training_iteration: 485
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 16978 s, 485 iter, 9700000 ts, 549 rew

agent-1: 28.0
agent-2: 26.0
agent-3: 21.0
agent-4: 20.0
agent-5: 28.0
agent-6: 31.0
agent-7: 26.0
agent-8: 36.0
agent-9: 24.0
agent-10: 38.0
agent-11: 22.0
agent-12: 25.0
agent-13: 36.0
agent-14: 38.0
agent-15: 17.0
agent-16: 27.0
agent-17: 25.0
agent-18: 26.0
agent-19: 18.0
agent-20: 32.0
Sum Reward: 544.0
Avg Reward: 27.2
Min Reward: 17.0
Max Reward: 38.0
Gini Coefficient: 0.12738970588235293
20:20 Ratio: 1.9473684210526316
Max-min Ratio: 2.235294117647059
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-45-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 641.0
  episode_reward_mean: 549.1
  episode_reward_min: 498.0
  episodes_this_iter: 1
  episodes_total: 485
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.901
    dispatch_time_ms: 5.787
    learner:
      cur_lr: 0.000713980000000447
      grad_gnorm: 2.5194826126098633
      policy_entropy: 380.90289306640625
      policy_loss: -1.6464951038360596
      var_gnorm: 49.8768196105957
      vf_explained_var: 0.15856903791427612
      vf_loss: 0.0022881580516695976
    num_steps_sampled: 9720000
    num_steps_trained: 9720000
    wait_time_ms: 329.832
  iterations_since_restore: 486
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 17013.51916527748
  time_this_iter_s: 34.74600172042847
  time_total_s: 17013.51916527748
  timestamp: 1594154744
  timesteps_since_restore: 9720000
  timesteps_this_iter: 20000
  timesteps_total: 9720000
  training_iteration: 486
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 17013 s, 486 iter, 9720000 ts, 549 rew

agent-1: 22.0
agent-2: 41.0
agent-3: 13.0
agent-4: 12.0
agent-5: 41.0
agent-6: 20.0
agent-7: 33.0
agent-8: 48.0
agent-9: 11.0
agent-10: 29.0
agent-11: 12.0
agent-12: 33.0
agent-13: 30.0
agent-14: 35.0
agent-15: 54.0
agent-16: 19.0
agent-17: 17.0
agent-18: 23.0
agent-19: 38.0
agent-20: 20.0
Sum Reward: 551.0
Avg Reward: 27.55
Min Reward: 11.0
Max Reward: 54.0
Gini Coefficient: 0.2530852994555354
20:20 Ratio: 3.8333333333333335
Max-min Ratio: 4.909090909090909
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-46-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 641.0
  episode_reward_mean: 548.36
  episode_reward_min: 498.0
  episodes_this_iter: 1
  episodes_total: 486
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 4.14
    dispatch_time_ms: 5.656
    learner:
      cur_lr: 0.0007126479758881032
      grad_gnorm: 0.758813738822937
      policy_entropy: 339.9205627441406
      policy_loss: 0.08045950531959534
      var_gnorm: 50.04779052734375
      vf_explained_var: -1.0
      vf_loss: 0.00038904364919289947
    num_steps_sampled: 9740000
    num_steps_trained: 9740000
    wait_time_ms: 348.81
  iterations_since_restore: 487
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 17048.249034166336
  time_this_iter_s: 34.72986888885498
  time_total_s: 17048.249034166336
  timestamp: 1594154779
  timesteps_since_restore: 9740000
  timesteps_this_iter: 20000
  timesteps_total: 9740000
  training_iteration: 487
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 17048 s, 487 iter, 9740000 ts, 548 rew

agent-1: 41.0
agent-2: 38.0
agent-3: 26.0
agent-4: 14.0
agent-5: 30.0
agent-6: 24.0
agent-7: 23.0
agent-8: 23.0
agent-9: 40.0
agent-10: 33.0
agent-11: 12.0
agent-12: 28.0
agent-13: 31.0
agent-14: 46.0
agent-15: 35.0
agent-16: 22.0
agent-17: 12.0
agent-18: 32.0
agent-19: 29.0
agent-20: 35.0
Sum Reward: 574.0
Avg Reward: 28.7
Min Reward: 12.0
Max Reward: 46.0
Gini Coefficient: 0.18118466898954705
20:20 Ratio: 2.75
Max-min Ratio: 3.8333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-46-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 641.0
  episode_reward_mean: 548.09
  episode_reward_min: 498.0
  episodes_this_iter: 1
  episodes_total: 487
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.367
    dispatch_time_ms: 5.073
    learner:
      cur_lr: 0.0007113160099834204
      grad_gnorm: 40.00000762939453
      policy_entropy: 20.770652770996094
      policy_loss: 24.896421432495117
      var_gnorm: 50.061790466308594
      vf_explained_var: 0.21320778131484985
      vf_loss: 383.30816650390625
    num_steps_sampled: 9760000
    num_steps_trained: 9760000
    wait_time_ms: 300.887
  iterations_since_restore: 488
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 17083.1995742321
  time_this_iter_s: 34.95054006576538
  time_total_s: 17083.1995742321
  timestamp: 1594154814
  timesteps_since_restore: 9760000
  timesteps_this_iter: 20000
  timesteps_total: 9760000
  training_iteration: 488
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 17083 s, 488 iter, 9760000 ts, 548 rew

agent-1: 25.0
agent-2: 28.0
agent-3: 21.0
agent-4: 28.0
agent-5: 40.0
agent-6: 39.0
agent-7: 25.0
agent-8: 14.0
agent-9: 35.0
agent-10: 40.0
agent-11: 23.0
agent-12: 19.0
agent-13: 26.0
agent-14: 33.0
agent-15: 14.0
agent-16: 42.0
agent-17: 35.0
agent-18: 25.0
agent-19: 24.0
agent-20: 29.0
Sum Reward: 565.0
Avg Reward: 28.25
Min Reward: 14.0
Max Reward: 42.0
Gini Coefficient: 0.1629203539823009
20:20 Ratio: 2.3676470588235294
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-47-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 641.0
  episode_reward_mean: 547.65
  episode_reward_min: 498.0
  episodes_this_iter: 1
  episodes_total: 488
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.401
    dispatch_time_ms: 6.078
    learner:
      cur_lr: 0.0007099839858710766
      grad_gnorm: 4.21605920791626
      policy_entropy: 356.08306884765625
      policy_loss: 1.4969254732131958
      var_gnorm: 50.12627029418945
      vf_explained_var: 0.75896155834198
      vf_loss: 0.02202870137989521
    num_steps_sampled: 9780000
    num_steps_trained: 9780000
    wait_time_ms: 342.929
  iterations_since_restore: 489
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 17118.064870357513
  time_this_iter_s: 34.86529612541199
  time_total_s: 17118.064870357513
  timestamp: 1594154848
  timesteps_since_restore: 9780000
  timesteps_this_iter: 20000
  timesteps_total: 9780000
  training_iteration: 489
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 17118 s, 489 iter, 9780000 ts, 548 rew

agent-1: 26.0
agent-2: 22.0
agent-3: 26.0
agent-4: 24.0
agent-5: 36.0
agent-6: 15.0
agent-7: 28.0
agent-8: 28.0
agent-9: 28.0
agent-10: 29.0
agent-11: 31.0
agent-12: 30.0
agent-13: 29.0
agent-14: 24.0
agent-15: 30.0
agent-16: 25.0
agent-17: 19.0
agent-18: 22.0
agent-19: 34.0
agent-20: 29.0
Sum Reward: 535.0
Avg Reward: 26.75
Min Reward: 15.0
Max Reward: 36.0
Gini Coefficient: 0.09841121495327103
20:20 Ratio: 1.6794871794871795
Max-min Ratio: 2.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-48-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 641.0
  episode_reward_mean: 547.89
  episode_reward_min: 498.0
  episodes_this_iter: 1
  episodes_total: 489
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.847
    dispatch_time_ms: 6.183
    learner:
      cur_lr: 0.0007086520199663937
      grad_gnorm: 1.8438302278518677
      policy_entropy: 371.30657958984375
      policy_loss: -0.6181257367134094
      var_gnorm: 50.134178161621094
      vf_explained_var: -1.0
      vf_loss: 0.00253060320392251
    num_steps_sampled: 9800000
    num_steps_trained: 9800000
    wait_time_ms: 319.115
  iterations_since_restore: 490
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 17153.246852874756
  time_this_iter_s: 35.18198251724243
  time_total_s: 17153.246852874756
  timestamp: 1594154884
  timesteps_since_restore: 9800000
  timesteps_this_iter: 20000
  timesteps_total: 9800000
  training_iteration: 490
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 17153 s, 490 iter, 9800000 ts, 548 rew

agent-1: 29.0
agent-2: 38.0
agent-3: 23.0
agent-4: 27.0
agent-5: 46.0
agent-6: 15.0
agent-7: 40.0
agent-8: 22.0
agent-9: 16.0
agent-10: 16.0
agent-11: 21.0
agent-12: 36.0
agent-13: 50.0
agent-14: 18.0
agent-15: 16.0
agent-16: 53.0
agent-17: 26.0
agent-18: 39.0
agent-19: 25.0
agent-20: 23.0
Sum Reward: 579.0
Avg Reward: 28.95
Min Reward: 15.0
Max Reward: 53.0
Gini Coefficient: 0.22340241796200344
20:20 Ratio: 3.0
Max-min Ratio: 3.533333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-48-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 641.0
  episode_reward_mean: 548.13
  episode_reward_min: 498.0
  episodes_this_iter: 1
  episodes_total: 490
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.844
    dispatch_time_ms: 6.858
    learner:
      cur_lr: 0.0007073199958540499
      grad_gnorm: 0.48745885491371155
      policy_entropy: 372.4456481933594
      policy_loss: -0.325298547744751
      var_gnorm: 50.15302276611328
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 6.514278356917202e-05
    num_steps_sampled: 9820000
    num_steps_trained: 9820000
    wait_time_ms: 341.36
  iterations_since_restore: 491
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 17187.727004289627
  time_this_iter_s: 34.480151414871216
  time_total_s: 17187.727004289627
  timestamp: 1594154918
  timesteps_since_restore: 9820000
  timesteps_this_iter: 20000
  timesteps_total: 9820000
  training_iteration: 491
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 17187 s, 491 iter, 9820000 ts, 548 rew

agent-1: 35.0
agent-2: 24.0
agent-3: 32.0
agent-4: 35.0
agent-5: 34.0
agent-6: 24.0
agent-7: 23.0
agent-8: 38.0
agent-9: 36.0
agent-10: 26.0
agent-11: 23.0
agent-12: 16.0
agent-13: 22.0
agent-14: 23.0
agent-15: 28.0
agent-16: 25.0
agent-17: 37.0
agent-18: 21.0
agent-19: 21.0
agent-20: 28.0
Sum Reward: 551.0
Avg Reward: 27.55
Min Reward: 16.0
Max Reward: 38.0
Gini Coefficient: 0.1280399274047187
20:20 Ratio: 1.825
Max-min Ratio: 2.375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-49-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 641.0
  episode_reward_mean: 548.08
  episode_reward_min: 498.0
  episodes_this_iter: 1
  episodes_total: 491
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.822
    dispatch_time_ms: 7.213
    learner:
      cur_lr: 0.0007059879717417061
      grad_gnorm: 39.999996185302734
      policy_entropy: 15.169132232666016
      policy_loss: -3.6974825859069824
      var_gnorm: 50.1633186340332
      vf_explained_var: 0.7736827731132507
      vf_loss: 678.5051879882812
    num_steps_sampled: 9840000
    num_steps_trained: 9840000
    wait_time_ms: 318.608
  iterations_since_restore: 492
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 17222.719987630844
  time_this_iter_s: 34.99298334121704
  time_total_s: 17222.719987630844
  timestamp: 1594154953
  timesteps_since_restore: 9840000
  timesteps_this_iter: 20000
  timesteps_total: 9840000
  training_iteration: 492
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 17222 s, 492 iter, 9840000 ts, 548 rew

agent-1: 24.0
agent-2: 28.0
agent-3: 21.0
agent-4: 18.0
agent-5: 24.0
agent-6: 27.0
agent-7: 32.0
agent-8: 29.0
agent-9: 37.0
agent-10: 12.0
agent-11: 33.0
agent-12: 25.0
agent-13: 34.0
agent-14: 31.0
agent-15: 24.0
agent-16: 37.0
agent-17: 14.0
agent-18: 38.0
agent-19: 18.0
agent-20: 31.0
Sum Reward: 537.0
Avg Reward: 26.85
Min Reward: 12.0
Max Reward: 38.0
Gini Coefficient: 0.1563314711359404
20:20 Ratio: 2.3548387096774195
Max-min Ratio: 3.1666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-49-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 641.0
  episode_reward_mean: 547.82
  episode_reward_min: 498.0
  episodes_this_iter: 1
  episodes_total: 492
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.338
    dispatch_time_ms: 7.53
    learner:
      cur_lr: 0.0007046560058370233
      grad_gnorm: 2.7321438789367676
      policy_entropy: 364.3712463378906
      policy_loss: -2.373384475708008
      var_gnorm: 50.198020935058594
      vf_explained_var: 0.0
      vf_loss: 0.0022492315620183945
    num_steps_sampled: 9860000
    num_steps_trained: 9860000
    wait_time_ms: 350.095
  iterations_since_restore: 493
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 17257.491644859314
  time_this_iter_s: 34.77165722846985
  time_total_s: 17257.491644859314
  timestamp: 1594154988
  timesteps_since_restore: 9860000
  timesteps_this_iter: 20000
  timesteps_total: 9860000
  training_iteration: 493
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 17257 s, 493 iter, 9860000 ts, 548 rew

agent-1: 40.0
agent-2: 36.0
agent-3: 34.0
agent-4: 41.0
agent-5: 42.0
agent-6: 31.0
agent-7: 30.0
agent-8: 20.0
agent-9: 34.0
agent-10: 18.0
agent-11: 26.0
agent-12: 27.0
agent-13: 27.0
agent-14: 17.0
agent-15: 14.0
agent-16: 39.0
agent-17: 36.0
agent-18: 31.0
agent-19: 17.0
agent-20: 25.0
Sum Reward: 585.0
Avg Reward: 29.25
Min Reward: 14.0
Max Reward: 42.0
Gini Coefficient: 0.16555555555555557
20:20 Ratio: 2.4545454545454546
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-50-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 641.0
  episode_reward_mean: 547.9
  episode_reward_min: 498.0
  episodes_this_iter: 1
  episodes_total: 493
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.493
    dispatch_time_ms: 5.299
    learner:
      cur_lr: 0.0007033239817246795
      grad_gnorm: 0.7738476395606995
      policy_entropy: 380.2378234863281
      policy_loss: -0.48378169536590576
      var_gnorm: 50.18657684326172
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 0.0001805954525480047
    num_steps_sampled: 9880000
    num_steps_trained: 9880000
    wait_time_ms: 310.445
  iterations_since_restore: 494
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 17292.227560520172
  time_this_iter_s: 34.735915660858154
  time_total_s: 17292.227560520172
  timestamp: 1594155023
  timesteps_since_restore: 9880000
  timesteps_this_iter: 20000
  timesteps_total: 9880000
  training_iteration: 494
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 17292 s, 494 iter, 9880000 ts, 548 rew

agent-1: 31.0
agent-2: 25.0
agent-3: 18.0
agent-4: 23.0
agent-5: 16.0
agent-6: 31.0
agent-7: 30.0
agent-8: 27.0
agent-9: 25.0
agent-10: 26.0
agent-11: 19.0
agent-12: 25.0
agent-13: 30.0
agent-14: 17.0
agent-15: 26.0
agent-16: 32.0
agent-17: 31.0
agent-18: 23.0
agent-19: 24.0
agent-20: 19.0
Sum Reward: 498.0
Avg Reward: 24.9
Min Reward: 16.0
Max Reward: 32.0
Gini Coefficient: 0.11224899598393574
20:20 Ratio: 1.7857142857142858
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-50-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 641.0
  episode_reward_mean: 547.31
  episode_reward_min: 498.0
  episodes_this_iter: 1
  episodes_total: 494
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.634
    dispatch_time_ms: 6.344
    learner:
      cur_lr: 0.0007019920158199966
      grad_gnorm: 0.8349300622940063
      policy_entropy: 379.1124267578125
      policy_loss: -0.24473199248313904
      var_gnorm: 50.29947280883789
      vf_explained_var: 0.0
      vf_loss: 0.00021757939248345792
    num_steps_sampled: 9900000
    num_steps_trained: 9900000
    wait_time_ms: 346.108
  iterations_since_restore: 495
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 17326.876762628555
  time_this_iter_s: 34.64920210838318
  time_total_s: 17326.876762628555
  timestamp: 1594155058
  timesteps_since_restore: 9900000
  timesteps_this_iter: 20000
  timesteps_total: 9900000
  training_iteration: 495
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 17326 s, 495 iter, 9900000 ts, 547 rew

agent-1: 24.0
agent-2: 19.0
agent-3: 32.0
agent-4: 20.0
agent-5: 27.0
agent-6: 29.0
agent-7: 22.0
agent-8: 25.0
agent-9: 28.0
agent-10: 29.0
agent-11: 24.0
agent-12: 29.0
agent-13: 30.0
agent-14: 36.0
agent-15: 26.0
agent-16: 21.0
agent-17: 30.0
agent-18: 32.0
agent-19: 19.0
agent-20: 27.0
Sum Reward: 529.0
Avg Reward: 26.45
Min Reward: 19.0
Max Reward: 36.0
Gini Coefficient: 0.09782608695652174
20:20 Ratio: 1.6455696202531647
Max-min Ratio: 1.894736842105263
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-51-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 641.0
  episode_reward_mean: 547.31
  episode_reward_min: 498.0
  episodes_this_iter: 1
  episodes_total: 495
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.746
    dispatch_time_ms: 6.807
    learner:
      cur_lr: 0.0007006599917076528
      grad_gnorm: 40.00000762939453
      policy_entropy: 6.260939598083496
      policy_loss: 12.416600227355957
      var_gnorm: 50.29502487182617
      vf_explained_var: 0.24983030557632446
      vf_loss: 409.76702880859375
    num_steps_sampled: 9920000
    num_steps_trained: 9920000
    wait_time_ms: 313.175
  iterations_since_restore: 496
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 17361.83678007126
  time_this_iter_s: 34.96001744270325
  time_total_s: 17361.83678007126
  timestamp: 1594155093
  timesteps_since_restore: 9920000
  timesteps_this_iter: 20000
  timesteps_total: 9920000
  training_iteration: 496
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 17361 s, 496 iter, 9920000 ts, 547 rew

agent-1: 29.0
agent-2: 36.0
agent-3: 18.0
agent-4: 31.0
agent-5: 25.0
agent-6: 32.0
agent-7: 32.0
agent-8: 31.0
agent-9: 32.0
agent-10: 26.0
agent-11: 22.0
agent-12: 32.0
agent-13: 23.0
agent-14: 24.0
agent-15: 30.0
agent-16: 34.0
agent-17: 32.0
agent-18: 47.0
agent-19: 34.0
agent-20: 30.0
Sum Reward: 600.0
Avg Reward: 30.0
Min Reward: 18.0
Max Reward: 47.0
Gini Coefficient: 0.10433333333333333
20:20 Ratio: 1.735632183908046
Max-min Ratio: 2.611111111111111
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-52-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 641.0
  episode_reward_mean: 547.98
  episode_reward_min: 498.0
  episodes_this_iter: 1
  episodes_total: 496
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.894
    dispatch_time_ms: 6.243
    learner:
      cur_lr: 0.0006993280258029699
      grad_gnorm: 0.9064499735832214
      policy_entropy: 363.12054443359375
      policy_loss: -0.2977571487426758
      var_gnorm: 50.330509185791016
      vf_explained_var: 0.0019176602363586426
      vf_loss: 0.00023899730877019465
    num_steps_sampled: 9940000
    num_steps_trained: 9940000
    wait_time_ms: 345.196
  iterations_since_restore: 497
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 17396.412210702896
  time_this_iter_s: 34.57543063163757
  time_total_s: 17396.412210702896
  timestamp: 1594155127
  timesteps_since_restore: 9940000
  timesteps_this_iter: 20000
  timesteps_total: 9940000
  training_iteration: 497
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 17396 s, 497 iter, 9940000 ts, 548 rew

agent-1: 40.0
agent-2: 26.0
agent-3: 29.0
agent-4: 27.0
agent-5: 24.0
agent-6: 23.0
agent-7: 26.0
agent-8: 25.0
agent-9: 32.0
agent-10: 27.0
agent-11: 23.0
agent-12: 26.0
agent-13: 29.0
agent-14: 29.0
agent-15: 23.0
agent-16: 30.0
agent-17: 27.0
agent-18: 22.0
agent-19: 23.0
agent-20: 15.0
Sum Reward: 526.0
Avg Reward: 26.3
Min Reward: 15.0
Max Reward: 40.0
Gini Coefficient: 0.09334600760456274
20:20 Ratio: 1.5783132530120483
Max-min Ratio: 2.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-52-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 641.0
  episode_reward_mean: 547.15
  episode_reward_min: 498.0
  episodes_this_iter: 1
  episodes_total: 497
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.76
    dispatch_time_ms: 26.448
    learner:
      cur_lr: 0.0006979960016906261
      grad_gnorm: 0.46820998191833496
      policy_entropy: 376.1896667480469
      policy_loss: 0.2988247275352478
      var_gnorm: 50.33079528808594
      vf_explained_var: 1.9073486328125e-06
      vf_loss: 6.021186709403992e-05
    num_steps_sampled: 9960000
    num_steps_trained: 9960000
    wait_time_ms: 339.387
  iterations_since_restore: 498
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 17433.007736682892
  time_this_iter_s: 36.59552597999573
  time_total_s: 17433.007736682892
  timestamp: 1594155164
  timesteps_since_restore: 9960000
  timesteps_this_iter: 20000
  timesteps_total: 9960000
  training_iteration: 498
  
W0707 16:52:45.061532 17834 node_manager.cc:250] Last heartbeat was sent 524 ms ago 
W0707 16:52:45.576645 17834 node_manager.cc:250] Last heartbeat was sent 602 ms ago 
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 17433 s, 498 iter, 9960000 ts, 547 rew

agent-1: 28.0
agent-2: 24.0
agent-3: 27.0
agent-4: 21.0
agent-5: 38.0
agent-6: 15.0
agent-7: 38.0
agent-8: 36.0
agent-9: 13.0
agent-10: 25.0
agent-11: 30.0
agent-12: 22.0
agent-13: 21.0
agent-14: 36.0
agent-15: 22.0
agent-16: 18.0
agent-17: 31.0
agent-18: 19.0
agent-19: 28.0
agent-20: 31.0
Sum Reward: 523.0
Avg Reward: 26.15
Min Reward: 13.0
Max Reward: 38.0
Gini Coefficient: 0.15841300191204588
20:20 Ratio: 2.276923076923077
Max-min Ratio: 2.923076923076923
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-53-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 641.0
  episode_reward_mean: 547.16
  episode_reward_min: 498.0
  episodes_this_iter: 1
  episodes_total: 498
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 3.345
    dispatch_time_ms: 8.669
    learner:
      cur_lr: 0.0006966639775782824
      grad_gnorm: 1.1735875606536865
      policy_entropy: 377.0194396972656
      policy_loss: -1.1067067384719849
      var_gnorm: 50.312564849853516
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.0004170892061665654
    num_steps_sampled: 9980000
    num_steps_trained: 9980000
    wait_time_ms: 341.522
  iterations_since_restore: 499
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 17469.70842218399
  time_this_iter_s: 36.70068550109863
  time_total_s: 17469.70842218399
  timestamp: 1594155202
  timesteps_since_restore: 9980000
  timesteps_this_iter: 20000
  timesteps_total: 9980000
  training_iteration: 499
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=17839], 17469 s, 499 iter, 9980000 ts, 547 rew

agent-1: 30.0
agent-2: 25.0
agent-3: 31.0
agent-4: 32.0
agent-5: 14.0
agent-6: 33.0
agent-7: 21.0
agent-8: 29.0
agent-9: 31.0
agent-10: 40.0
agent-11: 25.0
agent-12: 18.0
agent-13: 26.0
agent-14: 24.0
agent-15: 36.0
agent-16: 25.0
agent-17: 22.0
agent-18: 25.0
agent-19: 19.0
agent-20: 23.0
Sum Reward: 529.0
Avg Reward: 26.45
Min Reward: 14.0
Max Reward: 40.0
Gini Coefficient: 0.13128544423440452
20:20 Ratio: 1.9583333333333333
Max-min Ratio: 2.857142857142857
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-53-57
  done: true
  episode_len_mean: 1000.0
  episode_reward_max: 641.0
  episode_reward_mean: 546.84
  episode_reward_min: 498.0
  episodes_this_iter: 1
  episodes_total: 499
  experiment_id: 4193de3400954868a72d25c03e1766ba
  hostname: gpu051
  info:
    apply_time_ms: 2.572
    dispatch_time_ms: 16.177
    learner:
      cur_lr: 0.0006953320116735995
      grad_gnorm: 1.4775422811508179
      policy_entropy: 381.47174072265625
      policy_loss: 1.7432236671447754
      var_gnorm: 50.319828033447266
      vf_explained_var: -0.00628662109375
      vf_loss: 0.0004501162329688668
    num_steps_sampled: 10000000
    num_steps_trained: 10000000
    wait_time_ms: 301.543
  iterations_since_restore: 500
  node_ip: 172.17.8.51
  num_metric_batches_dropped: 0
  pid: 17839
  policy_reward_mean: {}
  time_since_restore: 17504.875191926956
  time_this_iter_s: 35.1667697429657
  time_total_s: 17504.875191926956
  timestamp: 1594155237
  timesteps_since_restore: 10000000
  timesteps_this_iter: 20000
  timesteps_total: 10000000
  training_iteration: 500
  
W0707 16:53:58.149374 17834 client_connection.cc:255] [worker]ProcessMessage with type 7 took 134 ms.
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
W0707 16:53:58.451308 17834 client_connection.cc:255] [worker]ProcessMessage with type 7 took 181 ms.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
TERMINATED trials:
 - A3C_harvest_env_0:	TERMINATED [pid=17839], 17504 s, 500 iter, 10000000 ts, 547 rew

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
TERMINATED trials:
 - A3C_harvest_env_0:	TERMINATED [pid=17839], 17504 s, 500 iter, 10000000 ts, 547 rew

Commencing experiment harvest_A3C
