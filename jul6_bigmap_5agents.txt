/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Process STDOUT and STDERR is being redirected to /tmp/ray/session_2020-07-06_22-08-29_13191/logs.
Waiting for redis server at 127.0.0.1:64334 to respond...
Waiting for redis server at 127.0.0.1:42207 to respond...
Warning: Capping object memory store to 20.0GB. To increase this further, specify `object_store_memory` when calling ray.init() or ray start.
Starting the Plasma object store with 20.0 GB memory using /dev/shm.

======================================================================
View the web UI at http://localhost:8888/notebooks/ray_ui.ipynb?token=20f194303772d1d1a0b38b2c02e79b73ceca0e63d61eec49
======================================================================

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0/2 CPUs, 0/1 GPUs
Memory usage on this node: 6.7/202.5 GB

Created LogSyncer for /h/zhaostep/ray_results/harvest_A3C/A3C_harvest_env_0_2020-07-06_22-08-30wmcptns1 -> 
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 6.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING

/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-06 22:08:43,125	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 0 on CPU (please ignore any CUDA init errors)
2020-07-06 22:08:43.125951: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-06 22:08:55,218	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 2 on CPU (please ignore any CUDA init errors)
2020-07-06 22:08:55.219486: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-06 22:08:55,253	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 1 on CPU (please ignore any CUDA init errors)
2020-07-06 22:08:55.254333: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-09-08
  done: false
  episode_len_mean: .nan
  episode_reward_max: .nan
  episode_reward_mean: .nan
  episode_reward_min: .nan
  episodes_this_iter: 0
  episodes_total: 0
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 3.563
    dispatch_time_ms: 7.222
    learner:
      cur_lr: 0.0013599999947473407
      grad_gnorm: 40.000003814697266
      policy_entropy: 65.68306732177734
      policy_loss: 61.26900863647461
      var_gnorm: 18.064346313476562
      vf_explained_var: 0.017676949501037598
      vf_loss: 92.56584167480469
    num_steps_sampled: 5000
    num_steps_trained: 5000
    wait_time_ms: 95.658
  iterations_since_restore: 1
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 23.859226942062378
  time_this_iter_s: 23.859226942062378
  time_total_s: 23.859226942062378
  timestamp: 1594087748
  timesteps_since_restore: 5000
  timesteps_this_iter: 5000
  timesteps_total: 5000
  training_iteration: 1
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 23 s, 1 iter, 5000 ts, nan rew

[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
agent-1: 79.0
agent-2: 103.0
agent-3: 117.0
agent-4: 34.0
agent-5: 74.0
Sum Reward: 407.0
Avg Reward: 81.4
Min Reward: 34.0
Max Reward: 117.0
Gini Coefficient: 0.19164619164619165
20:20 Ratio: 3.4411764705882355
Max-min Ratio: 3.4411764705882355
[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
agent-1: -152.0
agent-2: 156.0
agent-3: -50.0
agent-4: 16.0
agent-5: 57.0
Sum Reward: 27.0
Avg Reward: 5.4
Min Reward: -152.0
Max Reward: 156.0
Gini Coefficient: 10.71111111111111
20:20 Ratio: -1.0263157894736843
Max-min Ratio: -1.0263157894736843
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-09-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 407.0
  episode_reward_mean: 217.0
  episode_reward_min: 27.0
  episodes_this_iter: 2
  episodes_total: 2
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 3.982
    dispatch_time_ms: 9.592
    learner:
      cur_lr: 0.0013596670469269156
      grad_gnorm: 39.99999237060547
      policy_entropy: 67.25615692138672
      policy_loss: -359.0471496582031
      var_gnorm: 18.200305938720703
      vf_explained_var: 0.12215077877044678
      vf_loss: 831.9779052734375
    num_steps_sampled: 10000
    num_steps_trained: 10000
    wait_time_ms: 100.361
  iterations_since_restore: 2
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 34.59124732017517
  time_this_iter_s: 10.732020378112793
  time_total_s: 34.59124732017517
  timestamp: 1594087759
  timesteps_since_restore: 10000
  timesteps_this_iter: 5000
  timesteps_total: 10000
  training_iteration: 2
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 34 s, 2 iter, 10000 ts, 217 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-09-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 407.0
  episode_reward_mean: 217.0
  episode_reward_min: 27.0
  episodes_this_iter: 0
  episodes_total: 2
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 2.874
    dispatch_time_ms: 9.246
    learner:
      cur_lr: 0.0013593339826911688
      grad_gnorm: 40.00000762939453
      policy_entropy: 52.76521682739258
      policy_loss: 13.594985961914062
      var_gnorm: 18.367868423461914
      vf_explained_var: -0.06158947944641113
      vf_loss: 20.375362396240234
    num_steps_sampled: 15000
    num_steps_trained: 15000
    wait_time_ms: 95.334
  iterations_since_restore: 3
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 45.004271268844604
  time_this_iter_s: 10.413023948669434
  time_total_s: 45.004271268844604
  timestamp: 1594087769
  timesteps_since_restore: 15000
  timesteps_this_iter: 5000
  timesteps_total: 15000
  training_iteration: 3
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 45 s, 3 iter, 15000 ts, 217 rew

agent-1: 160.0
agent-2: 199.0
agent-3: 115.0
agent-4: 196.0
agent-5: 73.0
Sum Reward: 743.0
Avg Reward: 148.6
Min Reward: 73.0
Max Reward: 199.0
Gini Coefficient: 0.17927321668909826
20:20 Ratio: 2.7260273972602738
Max-min Ratio: 2.7260273972602738
agent-1: 87.0
agent-2: 159.0
agent-3: 123.0
agent-4: 193.0
agent-5: 147.0
Sum Reward: 709.0
Avg Reward: 141.8
Min Reward: 87.0
Max Reward: 193.0
Gini Coefficient: 0.1399153737658674
20:20 Ratio: 2.218390804597701
Max-min Ratio: 2.218390804597701
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-09-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 743.0
  episode_reward_mean: 471.5
  episode_reward_min: 27.0
  episodes_this_iter: 2
  episodes_total: 4
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 3.419
    dispatch_time_ms: 9.565
    learner:
      cur_lr: 0.0013590010348707438
      grad_gnorm: 40.00001525878906
      policy_entropy: 56.130584716796875
      policy_loss: -679.3036499023438
      var_gnorm: 18.573469161987305
      vf_explained_var: -0.0826869010925293
      vf_loss: 3259.85498046875
    num_steps_sampled: 20000
    num_steps_trained: 20000
    wait_time_ms: 103.383
  iterations_since_restore: 4
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 56.213720083236694
  time_this_iter_s: 11.20944881439209
  time_total_s: 56.213720083236694
  timestamp: 1594087780
  timesteps_since_restore: 20000
  timesteps_this_iter: 5000
  timesteps_total: 20000
  training_iteration: 4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 56 s, 4 iter, 20000 ts, 472 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-09-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 743.0
  episode_reward_mean: 471.5
  episode_reward_min: 27.0
  episodes_this_iter: 0
  episodes_total: 4
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 2.71
    dispatch_time_ms: 7.724
    learner:
      cur_lr: 0.0013586679706349969
      grad_gnorm: 39.9999885559082
      policy_entropy: 41.666343688964844
      policy_loss: 10.817752838134766
      var_gnorm: 18.70941162109375
      vf_explained_var: -0.32633233070373535
      vf_loss: 61.60359573364258
    num_steps_sampled: 25000
    num_steps_trained: 25000
    wait_time_ms: 107.612
  iterations_since_restore: 5
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 67.33112907409668
  time_this_iter_s: 11.117408990859985
  time_total_s: 67.33112907409668
  timestamp: 1594087791
  timesteps_since_restore: 25000
  timesteps_this_iter: 5000
  timesteps_total: 25000
  training_iteration: 5
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 67 s, 5 iter, 25000 ts, 472 rew

agent-1: 231.0
agent-2: 238.0
agent-3: 204.0
agent-4: 223.0
agent-5: 241.0
Sum Reward: 1137.0
Avg Reward: 227.4
Min Reward: 204.0
Max Reward: 241.0
Gini Coefficient: 0.031310466138962184
20:20 Ratio: 1.1813725490196079
Max-min Ratio: 1.1813725490196079
agent-1: 214.0
agent-2: 187.0
agent-3: 277.0
agent-4: 185.0
agent-5: 154.0
Sum Reward: 1017.0
Avg Reward: 203.4
Min Reward: 154.0
Max Reward: 277.0
Gini Coefficient: 0.10816125860373647
20:20 Ratio: 1.7987012987012987
Max-min Ratio: 1.7987012987012987
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-10-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1137.0
  episode_reward_mean: 673.3333333333334
  episode_reward_min: 27.0
  episodes_this_iter: 2
  episodes_total: 6
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 2.705
    dispatch_time_ms: 6.291
    learner:
      cur_lr: 0.0013583350228145719
      grad_gnorm: 39.99999237060547
      policy_entropy: 34.52968215942383
      policy_loss: -643.89208984375
      var_gnorm: 18.882061004638672
      vf_explained_var: -0.03739464282989502
      vf_loss: 7742.13037109375
    num_steps_sampled: 30000
    num_steps_trained: 30000
    wait_time_ms: 112.047
  iterations_since_restore: 6
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 79.28941345214844
  time_this_iter_s: 11.958284378051758
  time_total_s: 79.28941345214844
  timestamp: 1594087803
  timesteps_since_restore: 30000
  timesteps_this_iter: 5000
  timesteps_total: 30000
  training_iteration: 6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 79 s, 6 iter, 30000 ts, 673 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-10-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1137.0
  episode_reward_mean: 673.3333333333334
  episode_reward_min: 27.0
  episodes_this_iter: 0
  episodes_total: 6
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 2.743
    dispatch_time_ms: 6.492
    learner:
      cur_lr: 0.001358001958578825
      grad_gnorm: 40.0
      policy_entropy: 43.40488815307617
      policy_loss: -22.273035049438477
      var_gnorm: 19.176523208618164
      vf_explained_var: -0.009515881538391113
      vf_loss: 23.37734603881836
    num_steps_sampled: 35000
    num_steps_trained: 35000
    wait_time_ms: 116.477
  iterations_since_restore: 7
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 90.49854278564453
  time_this_iter_s: 11.209129333496094
  time_total_s: 90.49854278564453
  timestamp: 1594087815
  timesteps_since_restore: 35000
  timesteps_this_iter: 5000
  timesteps_total: 35000
  training_iteration: 7
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 11.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 90 s, 7 iter, 35000 ts, 673 rew

agent-1: 244.0
agent-2: 265.0
agent-3: 220.0
agent-4: 237.0
agent-5: 210.0
Sum Reward: 1176.0
Avg Reward: 235.2
Min Reward: 210.0
Max Reward: 265.0
Gini Coefficient: 0.04557823129251701
20:20 Ratio: 1.2619047619047619
Max-min Ratio: 1.2619047619047619
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-10-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1176.0
  episode_reward_mean: 745.1428571428571
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 7
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 2.568
    dispatch_time_ms: 5.847
    learner:
      cur_lr: 0.0013576690107584
      grad_gnorm: 40.00001907348633
      policy_entropy: 49.55517578125
      policy_loss: 2.492417335510254
      var_gnorm: 19.410938262939453
      vf_explained_var: 0.2903394103050232
      vf_loss: 89.62084197998047
    num_steps_sampled: 40000
    num_steps_trained: 40000
    wait_time_ms: 111.586
  iterations_since_restore: 8
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 102.51448392868042
  time_this_iter_s: 12.015941143035889
  time_total_s: 102.51448392868042
  timestamp: 1594087827
  timesteps_since_restore: 40000
  timesteps_this_iter: 5000
  timesteps_total: 40000
  training_iteration: 8
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 11.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 102 s, 8 iter, 40000 ts, 745 rew

agent-1: 259.0
agent-2: 214.0
agent-3: 268.0
agent-4: 240.0
agent-5: 246.0
Sum Reward: 1227.0
Avg Reward: 245.4
Min Reward: 214.0
Max Reward: 268.0
Gini Coefficient: 0.041401792991035045
20:20 Ratio: 1.2523364485981308
Max-min Ratio: 1.2523364485981308
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-10-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1227.0
  episode_reward_mean: 805.375
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 8
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 2.806
    dispatch_time_ms: 11.857
    learner:
      cur_lr: 0.001357335946522653
      grad_gnorm: 40.0
      policy_entropy: 46.242271423339844
      policy_loss: 10.182591438293457
      var_gnorm: 19.663375854492188
      vf_explained_var: 0.23002773523330688
      vf_loss: 46.72175979614258
    num_steps_sampled: 45000
    num_steps_trained: 45000
    wait_time_ms: 99.72
  iterations_since_restore: 9
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 113.49865555763245
  time_this_iter_s: 10.984171628952026
  time_total_s: 113.49865555763245
  timestamp: 1594087838
  timesteps_since_restore: 45000
  timesteps_this_iter: 5000
  timesteps_total: 45000
  training_iteration: 9
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 11.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 113 s, 9 iter, 45000 ts, 805 rew

agent-1: 278.0
agent-2: 285.0
agent-3: 261.0
agent-4: 251.0
agent-5: 218.0
Sum Reward: 1293.0
Avg Reward: 258.6
Min Reward: 218.0
Max Reward: 285.0
Gini Coefficient: 0.04980665119876257
20:20 Ratio: 1.3073394495412844
Max-min Ratio: 1.3073394495412844
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-10-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1293.0
  episode_reward_mean: 859.5555555555555
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 9
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 2.72
    dispatch_time_ms: 6.794
    learner:
      cur_lr: 0.001357002998702228
      grad_gnorm: 40.000003814697266
      policy_entropy: 42.336753845214844
      policy_loss: 30.957796096801758
      var_gnorm: 19.773752212524414
      vf_explained_var: 0.7276321649551392
      vf_loss: 120.37896728515625
    num_steps_sampled: 50000
    num_steps_trained: 50000
    wait_time_ms: 104.416
  iterations_since_restore: 10
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 125.32741355895996
  time_this_iter_s: 11.828758001327515
  time_total_s: 125.32741355895996
  timestamp: 1594087850
  timesteps_since_restore: 50000
  timesteps_this_iter: 5000
  timesteps_total: 50000
  training_iteration: 10
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 11.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 125 s, 10 iter, 50000 ts, 860 rew

agent-1: 216.0
agent-2: 298.0
agent-3: 246.0
agent-4: 263.0
agent-5: 226.0
Sum Reward: 1249.0
Avg Reward: 249.8
Min Reward: 216.0
Max Reward: 298.0
Gini Coefficient: 0.06437149719775821
20:20 Ratio: 1.3796296296296295
Max-min Ratio: 1.3796296296296295
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-11-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1293.0
  episode_reward_mean: 898.5
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 10
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 2.871
    dispatch_time_ms: 8.105
    learner:
      cur_lr: 0.001356670050881803
      grad_gnorm: 40.0
      policy_entropy: 48.9879035949707
      policy_loss: 2.841742992401123
      var_gnorm: 19.931354522705078
      vf_explained_var: 0.19706308841705322
      vf_loss: 17.228466033935547
    num_steps_sampled: 55000
    num_steps_trained: 55000
    wait_time_ms: 111.169
  iterations_since_restore: 11
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 136.7769260406494
  time_this_iter_s: 11.449512481689453
  time_total_s: 136.7769260406494
  timestamp: 1594087861
  timesteps_since_restore: 55000
  timesteps_this_iter: 5000
  timesteps_total: 55000
  training_iteration: 11
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 12.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 136 s, 11 iter, 55000 ts, 898 rew

agent-1: 234.0
agent-2: 231.0
agent-3: 237.0
agent-4: 251.0
agent-5: 241.0
Sum Reward: 1194.0
Avg Reward: 238.8
Min Reward: 231.0
Max Reward: 251.0
Gini Coefficient: 0.01574539363484087
20:20 Ratio: 1.0865800865800865
Max-min Ratio: 1.0865800865800865
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-11-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1293.0
  episode_reward_mean: 925.3636363636364
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 11
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 3.165
    dispatch_time_ms: 6.258
    learner:
      cur_lr: 0.0013563369866460562
      grad_gnorm: 40.00000762939453
      policy_entropy: 43.9899787902832
      policy_loss: -6.019004821777344
      var_gnorm: 20.044361114501953
      vf_explained_var: 0.29398036003112793
      vf_loss: 16.096948623657227
    num_steps_sampled: 60000
    num_steps_trained: 60000
    wait_time_ms: 104.489
  iterations_since_restore: 12
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 148.9235818386078
  time_this_iter_s: 12.146655797958374
  time_total_s: 148.9235818386078
  timestamp: 1594087873
  timesteps_since_restore: 60000
  timesteps_this_iter: 5000
  timesteps_total: 60000
  training_iteration: 12
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 12.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 148 s, 12 iter, 60000 ts, 925 rew

agent-1: 224.0
agent-2: 268.0
agent-3: 249.0
agent-4: 253.0
agent-5: 247.0
Sum Reward: 1241.0
Avg Reward: 248.2
Min Reward: 224.0
Max Reward: 268.0
Gini Coefficient: 0.030298146655922644
20:20 Ratio: 1.1964285714285714
Max-min Ratio: 1.1964285714285714
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-11-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1293.0
  episode_reward_mean: 951.6666666666666
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 12
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 2.932
    dispatch_time_ms: 11.197
    learner:
      cur_lr: 0.0013560040388256311
      grad_gnorm: 40.00001525878906
      policy_entropy: 42.45665740966797
      policy_loss: 5.114043712615967
      var_gnorm: 20.163761138916016
      vf_explained_var: 0.2976940870285034
      vf_loss: 17.675003051757812
    num_steps_sampled: 65000
    num_steps_trained: 65000
    wait_time_ms: 101.192
  iterations_since_restore: 13
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 160.13677740097046
  time_this_iter_s: 11.213195562362671
  time_total_s: 160.13677740097046
  timestamp: 1594087884
  timesteps_since_restore: 65000
  timesteps_this_iter: 5000
  timesteps_total: 65000
  training_iteration: 13
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 12.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 160 s, 13 iter, 65000 ts, 952 rew

agent-1: 204.0
agent-2: 241.0
agent-3: 245.0
agent-4: 197.0
agent-5: 188.0
Sum Reward: 1075.0
Avg Reward: 215.0
Min Reward: 188.0
Max Reward: 245.0
Gini Coefficient: 0.05879069767441861
20:20 Ratio: 1.303191489361702
Max-min Ratio: 1.303191489361702
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-11-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1293.0
  episode_reward_mean: 961.1538461538462
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 13
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 2.997
    dispatch_time_ms: 6.442
    learner:
      cur_lr: 0.0013556709745898843
      grad_gnorm: 40.00001525878906
      policy_entropy: 39.90974044799805
      policy_loss: 12.714814186096191
      var_gnorm: 20.337003707885742
      vf_explained_var: 0.34377121925354004
      vf_loss: 25.53116798400879
    num_steps_sampled: 70000
    num_steps_trained: 70000
    wait_time_ms: 98.697
  iterations_since_restore: 14
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 171.404771566391
  time_this_iter_s: 11.267994165420532
  time_total_s: 171.404771566391
  timestamp: 1594087896
  timesteps_since_restore: 70000
  timesteps_this_iter: 5000
  timesteps_total: 70000
  training_iteration: 14
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 171 s, 14 iter, 70000 ts, 961 rew

agent-1: 199.0
agent-2: 209.0
agent-3: 156.0
agent-4: 215.0
agent-5: 198.0
Sum Reward: 977.0
Avg Reward: 195.4
Min Reward: 156.0
Max Reward: 215.0
Gini Coefficient: 0.05281473899692937
20:20 Ratio: 1.3782051282051282
Max-min Ratio: 1.3782051282051282
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-11-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1293.0
  episode_reward_mean: 962.2857142857143
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 14
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 3.111
    dispatch_time_ms: 6.402
    learner:
      cur_lr: 0.0013553380267694592
      grad_gnorm: 39.999996185302734
      policy_entropy: 37.797603607177734
      policy_loss: -0.903307318687439
      var_gnorm: 20.46063232421875
      vf_explained_var: 0.14089417457580566
      vf_loss: 59.94721221923828
    num_steps_sampled: 75000
    num_steps_trained: 75000
    wait_time_ms: 107.927
  iterations_since_restore: 15
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 182.8057825565338
  time_this_iter_s: 11.401010990142822
  time_total_s: 182.8057825565338
  timestamp: 1594087907
  timesteps_since_restore: 75000
  timesteps_this_iter: 5000
  timesteps_total: 75000
  training_iteration: 15
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 182 s, 15 iter, 75000 ts, 962 rew

agent-1: 263.0
agent-2: 268.0
agent-3: 283.0
agent-4: 219.0
agent-5: 236.0
Sum Reward: 1269.0
Avg Reward: 253.8
Min Reward: 219.0
Max Reward: 283.0
Gini Coefficient: 0.0504334121355398
20:20 Ratio: 1.2922374429223744
Max-min Ratio: 1.2922374429223744
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-11-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1293.0
  episode_reward_mean: 982.7333333333333
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 15
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 3.022
    dispatch_time_ms: 6.833
    learner:
      cur_lr: 0.0013550049625337124
      grad_gnorm: 31.415456771850586
      policy_entropy: 30.416217803955078
      policy_loss: -9.922346115112305
      var_gnorm: 20.60112762451172
      vf_explained_var: 0.06458455324172974
      vf_loss: 31.66587257385254
    num_steps_sampled: 80000
    num_steps_trained: 80000
    wait_time_ms: 109.6
  iterations_since_restore: 16
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 195.0243308544159
  time_this_iter_s: 12.21854829788208
  time_total_s: 195.0243308544159
  timestamp: 1594087919
  timesteps_since_restore: 80000
  timesteps_this_iter: 5000
  timesteps_total: 80000
  training_iteration: 16
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 195 s, 16 iter, 80000 ts, 983 rew

agent-1: 241.0
agent-2: 250.0
agent-3: 254.0
agent-4: 270.0
agent-5: 287.0
Sum Reward: 1302.0
Avg Reward: 260.4
Min Reward: 241.0
Max Reward: 287.0
Gini Coefficient: 0.034408602150537634
20:20 Ratio: 1.1908713692946058
Max-min Ratio: 1.1908713692946058
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-12-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1302.0
  episode_reward_mean: 1002.6875
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 16
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 2.754
    dispatch_time_ms: 5.804
    learner:
      cur_lr: 0.0013546720147132874
      grad_gnorm: 39.999996185302734
      policy_entropy: 38.3721809387207
      policy_loss: 2.7854528427124023
      var_gnorm: 20.948942184448242
      vf_explained_var: 0.6217262744903564
      vf_loss: 47.91544723510742
    num_steps_sampled: 85000
    num_steps_trained: 85000
    wait_time_ms: 104.503
  iterations_since_restore: 17
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 205.96925497055054
  time_this_iter_s: 10.944924116134644
  time_total_s: 205.96925497055054
  timestamp: 1594087930
  timesteps_since_restore: 85000
  timesteps_this_iter: 5000
  timesteps_total: 85000
  training_iteration: 17
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 205 s, 17 iter, 85000 ts, 1e+03 rew

agent-1: 236.0
agent-2: 236.0
agent-3: 208.0
agent-4: 286.0
agent-5: 170.0
Sum Reward: 1136.0
Avg Reward: 227.2
Min Reward: 170.0
Max Reward: 286.0
Gini Coefficient: 0.09154929577464789
20:20 Ratio: 1.6823529411764706
Max-min Ratio: 1.6823529411764706
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-12-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1302.0
  episode_reward_mean: 1010.5294117647059
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 17
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 2.827
    dispatch_time_ms: 9.056
    learner:
      cur_lr: 0.0013543389504775405
      grad_gnorm: 39.99998092651367
      policy_entropy: 23.04538917541504
      policy_loss: -1.9537585973739624
      var_gnorm: 21.190969467163086
      vf_explained_var: 0.5926365852355957
      vf_loss: 124.24791717529297
    num_steps_sampled: 90000
    num_steps_trained: 90000
    wait_time_ms: 97.85
  iterations_since_restore: 18
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 217.4146556854248
  time_this_iter_s: 11.445400714874268
  time_total_s: 217.4146556854248
  timestamp: 1594087942
  timesteps_since_restore: 90000
  timesteps_this_iter: 5000
  timesteps_total: 90000
  training_iteration: 18
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 217 s, 18 iter, 90000 ts, 1.01e+03 rew

agent-1: 277.0
agent-2: 244.0
agent-3: 174.0
agent-4: 233.0
agent-5: 242.0
Sum Reward: 1170.0
Avg Reward: 234.0
Min Reward: 174.0
Max Reward: 277.0
Gini Coefficient: 0.07418803418803419
20:20 Ratio: 1.5919540229885059
Max-min Ratio: 1.5919540229885059
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-12-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1302.0
  episode_reward_mean: 1019.3888888888889
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 18
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 2.539
    dispatch_time_ms: 10.479
    learner:
      cur_lr: 0.0013540060026571155
      grad_gnorm: 40.00000762939453
      policy_entropy: 25.15833282470703
      policy_loss: -3.728792667388916
      var_gnorm: 21.396240234375
      vf_explained_var: 0.16369867324829102
      vf_loss: 41.24257278442383
    num_steps_sampled: 95000
    num_steps_trained: 95000
    wait_time_ms: 105.727
  iterations_since_restore: 19
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 228.73250699043274
  time_this_iter_s: 11.317851305007935
  time_total_s: 228.73250699043274
  timestamp: 1594087953
  timesteps_since_restore: 95000
  timesteps_this_iter: 5000
  timesteps_total: 95000
  training_iteration: 19
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 228 s, 19 iter, 95000 ts, 1.02e+03 rew

agent-1: 265.0
agent-2: 285.0
agent-3: 277.0
agent-4: 296.0
agent-5: 268.0
Sum Reward: 1391.0
Avg Reward: 278.2
Min Reward: 265.0
Max Reward: 296.0
Gini Coefficient: 0.02271746944644141
20:20 Ratio: 1.1169811320754717
Max-min Ratio: 1.1169811320754717
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-12-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1391.0
  episode_reward_mean: 1038.9473684210527
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 19
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 3.261
    dispatch_time_ms: 7.884
    learner:
      cur_lr: 0.0013536730548366904
      grad_gnorm: 39.9999885559082
      policy_entropy: 39.58450698852539
      policy_loss: -58.41526794433594
      var_gnorm: 21.525684356689453
      vf_explained_var: 0.09807080030441284
      vf_loss: 41.775726318359375
    num_steps_sampled: 100000
    num_steps_trained: 100000
    wait_time_ms: 84.645
  iterations_since_restore: 20
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 240.4884696006775
  time_this_iter_s: 11.755962610244751
  time_total_s: 240.4884696006775
  timestamp: 1594087965
  timesteps_since_restore: 100000
  timesteps_this_iter: 5000
  timesteps_total: 100000
  training_iteration: 20
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 240 s, 20 iter, 100000 ts, 1.04e+03 rew

agent-1: 265.0
agent-2: 272.0
agent-3: 306.0
agent-4: 235.0
agent-5: 279.0
Sum Reward: 1357.0
Avg Reward: 271.4
Min Reward: 235.0
Max Reward: 306.0
Gini Coefficient: 0.04598378776713338
20:20 Ratio: 1.3021276595744682
Max-min Ratio: 1.3021276595744682
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-12-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1391.0
  episode_reward_mean: 1054.85
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 20
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 2.636
    dispatch_time_ms: 9.305
    learner:
      cur_lr: 0.0013533399906009436
      grad_gnorm: 39.99999237060547
      policy_entropy: 31.163978576660156
      policy_loss: 19.684829711914062
      var_gnorm: 21.63619613647461
      vf_explained_var: 0.041699349880218506
      vf_loss: 31.733814239501953
    num_steps_sampled: 105000
    num_steps_trained: 105000
    wait_time_ms: 114.671
  iterations_since_restore: 21
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 252.03695368766785
  time_this_iter_s: 11.548484086990356
  time_total_s: 252.03695368766785
  timestamp: 1594087977
  timesteps_since_restore: 105000
  timesteps_this_iter: 5000
  timesteps_total: 105000
  training_iteration: 21
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 252 s, 21 iter, 105000 ts, 1.05e+03 rew

agent-1: 311.0
agent-2: 284.0
agent-3: 289.0
agent-4: 287.0
agent-5: 248.0
Sum Reward: 1419.0
Avg Reward: 283.8
Min Reward: 248.0
Max Reward: 311.0
Gini Coefficient: 0.03692741367159972
20:20 Ratio: 1.2540322580645162
Max-min Ratio: 1.2540322580645162
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-13-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1419.0
  episode_reward_mean: 1072.1904761904761
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 21
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 2.936
    dispatch_time_ms: 6.417
    learner:
      cur_lr: 0.0013530070427805185
      grad_gnorm: 40.000022888183594
      policy_entropy: 30.498971939086914
      policy_loss: -1.2509958744049072
      var_gnorm: 21.751497268676758
      vf_explained_var: 0.16885137557983398
      vf_loss: 35.301513671875
    num_steps_sampled: 110000
    num_steps_trained: 110000
    wait_time_ms: 106.76
  iterations_since_restore: 22
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 264.55356335639954
  time_this_iter_s: 12.51660966873169
  time_total_s: 264.55356335639954
  timestamp: 1594087989
  timesteps_since_restore: 110000
  timesteps_this_iter: 5000
  timesteps_total: 110000
  training_iteration: 22
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 264 s, 22 iter, 110000 ts, 1.07e+03 rew

agent-1: 311.0
agent-2: 302.0
agent-3: 314.0
agent-4: 277.0
agent-5: 320.0
Sum Reward: 1524.0
Avg Reward: 304.8
Min Reward: 277.0
Max Reward: 320.0
Gini Coefficient: 0.025721784776902887
20:20 Ratio: 1.1552346570397112
Max-min Ratio: 1.1552346570397112
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-13-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1524.0
  episode_reward_mean: 1092.7272727272727
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 22
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 2.581
    dispatch_time_ms: 5.894
    learner:
      cur_lr: 0.0013526739785447717
      grad_gnorm: 40.00000762939453
      policy_entropy: 21.933063507080078
      policy_loss: -5.505971908569336
      var_gnorm: 21.90584373474121
      vf_explained_var: 0.22401416301727295
      vf_loss: 37.69855499267578
    num_steps_sampled: 115000
    num_steps_trained: 115000
    wait_time_ms: 113.534
  iterations_since_restore: 23
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 275.85816073417664
  time_this_iter_s: 11.3045973777771
  time_total_s: 275.85816073417664
  timestamp: 1594088000
  timesteps_since_restore: 115000
  timesteps_this_iter: 5000
  timesteps_total: 115000
  training_iteration: 23
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 275 s, 23 iter, 115000 ts, 1.09e+03 rew

agent-1: 330.0
agent-2: 313.0
agent-3: 278.0
agent-4: 294.0
agent-5: 289.0
Sum Reward: 1504.0
Avg Reward: 300.8
Min Reward: 278.0
Max Reward: 330.0
Gini Coefficient: 0.03404255319148936
20:20 Ratio: 1.1870503597122302
Max-min Ratio: 1.1870503597122302
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-13-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1524.0
  episode_reward_mean: 1110.608695652174
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 23
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 2.726
    dispatch_time_ms: 8.286
    learner:
      cur_lr: 0.0013523410307243466
      grad_gnorm: 39.999996185302734
      policy_entropy: 16.584745407104492
      policy_loss: -0.7168599367141724
      var_gnorm: 22.01105499267578
      vf_explained_var: 0.02244853973388672
      vf_loss: 21.40263557434082
    num_steps_sampled: 120000
    num_steps_trained: 120000
    wait_time_ms: 93.098
  iterations_since_restore: 24
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 288.2074439525604
  time_this_iter_s: 12.349283218383789
  time_total_s: 288.2074439525604
  timestamp: 1594088013
  timesteps_since_restore: 120000
  timesteps_this_iter: 5000
  timesteps_total: 120000
  training_iteration: 24
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 288 s, 24 iter, 120000 ts, 1.11e+03 rew

agent-1: 340.0
agent-2: 285.0
agent-3: 249.0
agent-4: 307.0
agent-5: 310.0
Sum Reward: 1491.0
Avg Reward: 298.2
Min Reward: 249.0
Max Reward: 340.0
Gini Coefficient: 0.055533199195171024
20:20 Ratio: 1.3654618473895583
Max-min Ratio: 1.3654618473895583
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-13-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1524.0
  episode_reward_mean: 1126.4583333333333
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 24
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 3.451
    dispatch_time_ms: 7.733
    learner:
      cur_lr: 0.0013520079664885998
      grad_gnorm: 39.999996185302734
      policy_entropy: 13.69894790649414
      policy_loss: 8.585253715515137
      var_gnorm: 22.124588012695312
      vf_explained_var: -0.051963210105895996
      vf_loss: 20.190404891967773
    num_steps_sampled: 125000
    num_steps_trained: 125000
    wait_time_ms: 111.84
  iterations_since_restore: 25
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 299.875696182251
  time_this_iter_s: 11.668252229690552
  time_total_s: 299.875696182251
  timestamp: 1594088025
  timesteps_since_restore: 125000
  timesteps_this_iter: 5000
  timesteps_total: 125000
  training_iteration: 25
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 299 s, 25 iter, 125000 ts, 1.13e+03 rew

agent-1: 286.0
agent-2: 287.0
agent-3: 288.0
agent-4: 282.0
agent-5: 256.0
Sum Reward: 1399.0
Avg Reward: 279.8
Min Reward: 256.0
Max Reward: 288.0
Gini Coefficient: 0.019728377412437454
20:20 Ratio: 1.125
Max-min Ratio: 1.125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-13-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1524.0
  episode_reward_mean: 1137.36
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 25
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 3.144
    dispatch_time_ms: 7.869
    learner:
      cur_lr: 0.0013516750186681747
      grad_gnorm: 39.99999237060547
      policy_entropy: 38.44920349121094
      policy_loss: -12.102279663085938
      var_gnorm: 22.11886978149414
      vf_explained_var: 0.2208092212677002
      vf_loss: 18.053653717041016
    num_steps_sampled: 130000
    num_steps_trained: 130000
    wait_time_ms: 88.712
  iterations_since_restore: 26
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 311.363317489624
  time_this_iter_s: 11.487621307373047
  time_total_s: 311.363317489624
  timestamp: 1594088036
  timesteps_since_restore: 130000
  timesteps_this_iter: 5000
  timesteps_total: 130000
  training_iteration: 26
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 311 s, 26 iter, 130000 ts, 1.14e+03 rew

agent-1: 282.0
agent-2: 274.0
agent-3: 259.0
agent-4: 256.0
agent-5: 237.0
Sum Reward: 1308.0
Avg Reward: 261.6
Min Reward: 237.0
Max Reward: 282.0
Gini Coefficient: 0.03302752293577982
20:20 Ratio: 1.1898734177215189
Max-min Ratio: 1.1898734177215189
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-14-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1524.0
  episode_reward_mean: 1143.923076923077
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 26
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 2.782
    dispatch_time_ms: 8.737
    learner:
      cur_lr: 0.0013513419544324279
      grad_gnorm: 40.0
      policy_entropy: 33.46952819824219
      policy_loss: -1.7001357078552246
      var_gnorm: 22.218048095703125
      vf_explained_var: 0.22433435916900635
      vf_loss: 42.08466720581055
    num_steps_sampled: 135000
    num_steps_trained: 135000
    wait_time_ms: 102.05
  iterations_since_restore: 27
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 322.02100682258606
  time_this_iter_s: 10.657689332962036
  time_total_s: 322.02100682258606
  timestamp: 1594088047
  timesteps_since_restore: 135000
  timesteps_this_iter: 5000
  timesteps_total: 135000
  training_iteration: 27
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 322 s, 27 iter, 135000 ts, 1.14e+03 rew

agent-1: 219.0
agent-2: 242.0
agent-3: 234.0
agent-4: 224.0
agent-5: 278.0
Sum Reward: 1197.0
Avg Reward: 239.4
Min Reward: 219.0
Max Reward: 278.0
Gini Coefficient: 0.045446950710108604
20:20 Ratio: 1.269406392694064
Max-min Ratio: 1.269406392694064
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-14-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1524.0
  episode_reward_mean: 1145.888888888889
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 27
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 3.158
    dispatch_time_ms: 10.991
    learner:
      cur_lr: 0.0013510090066120028
      grad_gnorm: 39.999969482421875
      policy_entropy: 24.454771041870117
      policy_loss: -10.979989051818848
      var_gnorm: 22.41954803466797
      vf_explained_var: 0.4389369487762451
      vf_loss: 66.99766540527344
    num_steps_sampled: 140000
    num_steps_trained: 140000
    wait_time_ms: 98.076
  iterations_since_restore: 28
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 333.7216546535492
  time_this_iter_s: 11.700647830963135
  time_total_s: 333.7216546535492
  timestamp: 1594088058
  timesteps_since_restore: 140000
  timesteps_this_iter: 5000
  timesteps_total: 140000
  training_iteration: 28
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 333 s, 28 iter, 140000 ts, 1.15e+03 rew

agent-1: 226.0
agent-2: 326.0
agent-3: 274.0
agent-4: 275.0
agent-5: 284.0
Sum Reward: 1385.0
Avg Reward: 277.0
Min Reward: 226.0
Max Reward: 326.0
Gini Coefficient: 0.06064981949458484
20:20 Ratio: 1.4424778761061947
Max-min Ratio: 1.4424778761061947
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-14-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1524.0
  episode_reward_mean: 1154.4285714285713
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 28
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 3.756
    dispatch_time_ms: 9.087
    learner:
      cur_lr: 0.001350675942376256
      grad_gnorm: 40.000030517578125
      policy_entropy: 14.282343864440918
      policy_loss: -11.01274299621582
      var_gnorm: 22.600543975830078
      vf_explained_var: 0.1445203423500061
      vf_loss: 18.006364822387695
    num_steps_sampled: 145000
    num_steps_trained: 145000
    wait_time_ms: 106.759
  iterations_since_restore: 29
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 345.3094220161438
  time_this_iter_s: 11.587767362594604
  time_total_s: 345.3094220161438
  timestamp: 1594088070
  timesteps_since_restore: 145000
  timesteps_this_iter: 5000
  timesteps_total: 145000
  training_iteration: 29
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 345 s, 29 iter, 145000 ts, 1.15e+03 rew

agent-1: 279.0
agent-2: 312.0
agent-3: 314.0
agent-4: 322.0
agent-5: 291.0
Sum Reward: 1518.0
Avg Reward: 303.6
Min Reward: 279.0
Max Reward: 322.0
Gini Coefficient: 0.028722002635046113
20:20 Ratio: 1.1541218637992832
Max-min Ratio: 1.1541218637992832
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-14-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1524.0
  episode_reward_mean: 1166.9655172413793
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 29
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 2.608
    dispatch_time_ms: 6.586
    learner:
      cur_lr: 0.001350342994555831
      grad_gnorm: 39.999996185302734
      policy_entropy: 34.54667282104492
      policy_loss: 26.324298858642578
      var_gnorm: 22.783634185791016
      vf_explained_var: 0.6122417449951172
      vf_loss: 52.486175537109375
    num_steps_sampled: 150000
    num_steps_trained: 150000
    wait_time_ms: 102.249
  iterations_since_restore: 30
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 357.7340159416199
  time_this_iter_s: 12.424593925476074
  time_total_s: 357.7340159416199
  timestamp: 1594088083
  timesteps_since_restore: 150000
  timesteps_this_iter: 5000
  timesteps_total: 150000
  training_iteration: 30
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 357 s, 30 iter, 150000 ts, 1.17e+03 rew

agent-1: 300.0
agent-2: 269.0
agent-3: 244.0
agent-4: 310.0
agent-5: 281.0
Sum Reward: 1404.0
Avg Reward: 280.8
Min Reward: 244.0
Max Reward: 310.0
Gini Coefficient: 0.04643874643874644
20:20 Ratio: 1.2704918032786885
Max-min Ratio: 1.2704918032786885
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-14-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1524.0
  episode_reward_mean: 1174.8666666666666
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 30
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 2.797
    dispatch_time_ms: 6.06
    learner:
      cur_lr: 0.001350010046735406
      grad_gnorm: 39.99995803833008
      policy_entropy: 7.93754243850708
      policy_loss: 2.7129387855529785
      var_gnorm: 22.942182540893555
      vf_explained_var: 0.38153594732284546
      vf_loss: 14.640793800354004
    num_steps_sampled: 155000
    num_steps_trained: 155000
    wait_time_ms: 109.258
  iterations_since_restore: 31
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 368.65626287460327
  time_this_iter_s: 10.922246932983398
  time_total_s: 368.65626287460327
  timestamp: 1594088093
  timesteps_since_restore: 155000
  timesteps_this_iter: 5000
  timesteps_total: 155000
  training_iteration: 31
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 368 s, 31 iter, 155000 ts, 1.17e+03 rew

agent-1: 122.0
agent-2: 305.0
agent-3: 222.0
agent-4: 309.0
agent-5: 272.0
Sum Reward: 1230.0
Avg Reward: 246.0
Min Reward: 122.0
Max Reward: 309.0
Gini Coefficient: 0.1486178861788618
20:20 Ratio: 2.5327868852459017
Max-min Ratio: 2.5327868852459017
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-15-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1524.0
  episode_reward_mean: 1176.6451612903227
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 31
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 2.57
    dispatch_time_ms: 6.666
    learner:
      cur_lr: 0.001349676982499659
      grad_gnorm: 39.999996185302734
      policy_entropy: 14.039426803588867
      policy_loss: 8.952009201049805
      var_gnorm: 23.116840362548828
      vf_explained_var: 0.5779297351837158
      vf_loss: 18.11933135986328
    num_steps_sampled: 160000
    num_steps_trained: 160000
    wait_time_ms: 108.187
  iterations_since_restore: 32
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 380.4803047180176
  time_this_iter_s: 11.824041843414307
  time_total_s: 380.4803047180176
  timestamp: 1594088105
  timesteps_since_restore: 160000
  timesteps_this_iter: 5000
  timesteps_total: 160000
  training_iteration: 32
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 380 s, 32 iter, 160000 ts, 1.18e+03 rew

agent-1: 338.0
agent-2: 285.0
agent-3: 335.0
agent-4: 219.0
agent-5: 243.0
Sum Reward: 1420.0
Avg Reward: 284.0
Min Reward: 219.0
Max Reward: 338.0
Gini Coefficient: 0.09295774647887324
20:20 Ratio: 1.54337899543379
Max-min Ratio: 1.54337899543379
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-15-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1524.0
  episode_reward_mean: 1184.25
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 32
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 2.485
    dispatch_time_ms: 5.993
    learner:
      cur_lr: 0.001349344034679234
      grad_gnorm: 40.000003814697266
      policy_entropy: 16.85357093811035
      policy_loss: 9.472319602966309
      var_gnorm: 23.321800231933594
      vf_explained_var: 0.6808905601501465
      vf_loss: 122.35382843017578
    num_steps_sampled: 165000
    num_steps_trained: 165000
    wait_time_ms: 112.239
  iterations_since_restore: 33
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 392.53908491134644
  time_this_iter_s: 12.058780193328857
  time_total_s: 392.53908491134644
  timestamp: 1594088117
  timesteps_since_restore: 165000
  timesteps_this_iter: 5000
  timesteps_total: 165000
  training_iteration: 33
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 392 s, 33 iter, 165000 ts, 1.18e+03 rew

agent-1: 273.0
agent-2: 253.0
agent-3: 239.0
agent-4: 225.0
agent-5: 263.0
Sum Reward: 1253.0
Avg Reward: 250.6
Min Reward: 225.0
Max Reward: 273.0
Gini Coefficient: 0.03830806065442937
20:20 Ratio: 1.2133333333333334
Max-min Ratio: 1.2133333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-15-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1524.0
  episode_reward_mean: 1186.3333333333333
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 33
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 3.847
    dispatch_time_ms: 8.12
    learner:
      cur_lr: 0.0013490109704434872
      grad_gnorm: 40.0
      policy_entropy: 23.193641662597656
      policy_loss: -18.568544387817383
      var_gnorm: 23.384389877319336
      vf_explained_var: 0.1770845651626587
      vf_loss: 18.163047790527344
    num_steps_sampled: 170000
    num_steps_trained: 170000
    wait_time_ms: 82.341
  iterations_since_restore: 34
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 403.01767897605896
  time_this_iter_s: 10.478594064712524
  time_total_s: 403.01767897605896
  timestamp: 1594088128
  timesteps_since_restore: 170000
  timesteps_this_iter: 5000
  timesteps_total: 170000
  training_iteration: 34
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 403 s, 34 iter, 170000 ts, 1.19e+03 rew

agent-1: 153.0
agent-2: 191.0
agent-3: 175.0
agent-4: 155.0
agent-5: 177.0
Sum Reward: 851.0
Avg Reward: 170.2
Min Reward: 153.0
Max Reward: 191.0
Gini Coefficient: 0.046063454759106934
20:20 Ratio: 1.2483660130718954
Max-min Ratio: 1.2483660130718954
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-15-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1524.0
  episode_reward_mean: 1176.4705882352941
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 34
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 3.116
    dispatch_time_ms: 6.834
    learner:
      cur_lr: 0.0013486780226230621
      grad_gnorm: 40.000003814697266
      policy_entropy: 24.132726669311523
      policy_loss: 11.522821426391602
      var_gnorm: 23.396142959594727
      vf_explained_var: -0.2818857431411743
      vf_loss: 67.89901733398438
    num_steps_sampled: 175000
    num_steps_trained: 175000
    wait_time_ms: 96.968
  iterations_since_restore: 35
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 412.6057679653168
  time_this_iter_s: 9.588088989257812
  time_total_s: 412.6057679653168
  timestamp: 1594088138
  timesteps_since_restore: 175000
  timesteps_this_iter: 5000
  timesteps_total: 175000
  training_iteration: 35
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 412 s, 35 iter, 175000 ts, 1.18e+03 rew

agent-1: 71.0
agent-2: 107.0
agent-3: 80.0
agent-4: 86.0
agent-5: 87.0
Sum Reward: 431.0
Avg Reward: 86.2
Min Reward: 71.0
Max Reward: 107.0
Gini Coefficient: 0.07331786542923434
20:20 Ratio: 1.5070422535211268
Max-min Ratio: 1.5070422535211268
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-15-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1524.0
  episode_reward_mean: 1155.1714285714286
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 35
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 3.0
    dispatch_time_ms: 7.55
    learner:
      cur_lr: 0.0013483449583873153
      grad_gnorm: 39.999996185302734
      policy_entropy: 22.123897552490234
      policy_loss: -3.626302719116211
      var_gnorm: 23.440752029418945
      vf_explained_var: 0.03195059299468994
      vf_loss: 14.02974796295166
    num_steps_sampled: 180000
    num_steps_trained: 180000
    wait_time_ms: 95.453
  iterations_since_restore: 36
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 423.03099751472473
  time_this_iter_s: 10.425229549407959
  time_total_s: 423.03099751472473
  timestamp: 1594088148
  timesteps_since_restore: 180000
  timesteps_this_iter: 5000
  timesteps_total: 180000
  training_iteration: 36
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 423 s, 36 iter, 180000 ts, 1.16e+03 rew

agent-1: 147.0
agent-2: 125.0
agent-3: 150.0
agent-4: 137.0
agent-5: 112.0
Sum Reward: 671.0
Avg Reward: 134.2
Min Reward: 112.0
Max Reward: 150.0
Gini Coefficient: 0.058420268256333834
20:20 Ratio: 1.3392857142857142
Max-min Ratio: 1.3392857142857142
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-15-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1524.0
  episode_reward_mean: 1141.7222222222222
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 36
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 2.821
    dispatch_time_ms: 9.332
    learner:
      cur_lr: 0.0013480120105668902
      grad_gnorm: 27.47034454345703
      policy_entropy: 42.544898986816406
      policy_loss: -7.247574806213379
      var_gnorm: 23.4740047454834
      vf_explained_var: -0.34945249557495117
      vf_loss: 21.053794860839844
    num_steps_sampled: 185000
    num_steps_trained: 185000
    wait_time_ms: 90.844
  iterations_since_restore: 37
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 433.3526062965393
  time_this_iter_s: 10.321608781814575
  time_total_s: 433.3526062965393
  timestamp: 1594088158
  timesteps_since_restore: 185000
  timesteps_this_iter: 5000
  timesteps_total: 185000
  training_iteration: 37
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 433 s, 37 iter, 185000 ts, 1.14e+03 rew

agent-1: 164.0
agent-2: 152.0
agent-3: 154.0
agent-4: 105.0
agent-5: 130.0
Sum Reward: 705.0
Avg Reward: 141.0
Min Reward: 105.0
Max Reward: 164.0
Gini Coefficient: 0.08056737588652482
20:20 Ratio: 1.561904761904762
Max-min Ratio: 1.561904761904762
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-16-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1524.0
  episode_reward_mean: 1129.918918918919
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 37
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 2.858
    dispatch_time_ms: 10.964
    learner:
      cur_lr: 0.0013476789463311434
      grad_gnorm: 29.92852783203125
      policy_entropy: 16.318071365356445
      policy_loss: -6.527622699737549
      var_gnorm: 23.543344497680664
      vf_explained_var: -0.637018084526062
      vf_loss: 26.989559173583984
    num_steps_sampled: 190000
    num_steps_trained: 190000
    wait_time_ms: 92.978
  iterations_since_restore: 38
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 443.7221667766571
  time_this_iter_s: 10.369560480117798
  time_total_s: 443.7221667766571
  timestamp: 1594088169
  timesteps_since_restore: 190000
  timesteps_this_iter: 5000
  timesteps_total: 190000
  training_iteration: 38
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 443 s, 38 iter, 190000 ts, 1.13e+03 rew

agent-1: 133.0
agent-2: 116.0
agent-3: 136.0
agent-4: 189.0
agent-5: 95.0
Sum Reward: 669.0
Avg Reward: 133.8
Min Reward: 95.0
Max Reward: 189.0
Gini Coefficient: 0.12436472346786248
20:20 Ratio: 1.9894736842105263
Max-min Ratio: 1.9894736842105263
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-16-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1524.0
  episode_reward_mean: 1117.7894736842106
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 38
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 2.634
    dispatch_time_ms: 7.093
    learner:
      cur_lr: 0.0013473459985107183
      grad_gnorm: 39.99999237060547
      policy_entropy: 14.812911033630371
      policy_loss: -5.670600414276123
      var_gnorm: 23.86800765991211
      vf_explained_var: 0.45871031284332275
      vf_loss: 16.94646644592285
    num_steps_sampled: 195000
    num_steps_trained: 195000
    wait_time_ms: 102.958
  iterations_since_restore: 39
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 454.3343291282654
  time_this_iter_s: 10.612162351608276
  time_total_s: 454.3343291282654
  timestamp: 1594088179
  timesteps_since_restore: 195000
  timesteps_this_iter: 5000
  timesteps_total: 195000
  training_iteration: 39
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 454 s, 39 iter, 195000 ts, 1.12e+03 rew

agent-1: 182.0
agent-2: 151.0
agent-3: 207.0
agent-4: 169.0
agent-5: 198.0
Sum Reward: 907.0
Avg Reward: 181.4
Min Reward: 151.0
Max Reward: 207.0
Gini Coefficient: 0.06218302094818082
20:20 Ratio: 1.3708609271523178
Max-min Ratio: 1.3708609271523178
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-16-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1524.0
  episode_reward_mean: 1112.3846153846155
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 39
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 2.908
    dispatch_time_ms: 8.376
    learner:
      cur_lr: 0.0013470130506902933
      grad_gnorm: 40.0
      policy_entropy: 9.326292991638184
      policy_loss: -4.513669490814209
      var_gnorm: 24.03396987915039
      vf_explained_var: 0.10046470165252686
      vf_loss: 77.3296890258789
    num_steps_sampled: 200000
    num_steps_trained: 200000
    wait_time_ms: 105.884
  iterations_since_restore: 40
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 465.39219427108765
  time_this_iter_s: 11.057865142822266
  time_total_s: 465.39219427108765
  timestamp: 1594088190
  timesteps_since_restore: 200000
  timesteps_this_iter: 5000
  timesteps_total: 200000
  training_iteration: 40
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 465 s, 40 iter, 200000 ts, 1.11e+03 rew

agent-1: 253.0
agent-2: 240.0
agent-3: 258.0
agent-4: 226.0
agent-5: 235.0
Sum Reward: 1212.0
Avg Reward: 242.4
Min Reward: 226.0
Max Reward: 258.0
Gini Coefficient: 0.02706270627062706
20:20 Ratio: 1.1415929203539823
Max-min Ratio: 1.1415929203539823
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-16-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1524.0
  episode_reward_mean: 1114.875
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 40
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 2.726
    dispatch_time_ms: 5.574
    learner:
      cur_lr: 0.0013466799864545465
      grad_gnorm: 40.0
      policy_entropy: 16.89571189880371
      policy_loss: -19.488035202026367
      var_gnorm: 24.198030471801758
      vf_explained_var: 0.0832139253616333
      vf_loss: 46.61006546020508
    num_steps_sampled: 205000
    num_steps_trained: 205000
    wait_time_ms: 113.187
  iterations_since_restore: 41
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 476.9241669178009
  time_this_iter_s: 11.531972646713257
  time_total_s: 476.9241669178009
  timestamp: 1594088202
  timesteps_since_restore: 205000
  timesteps_this_iter: 5000
  timesteps_total: 205000
  training_iteration: 41
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 476 s, 41 iter, 205000 ts, 1.11e+03 rew

agent-1: 277.0
agent-2: 299.0
agent-3: 279.0
agent-4: 260.0
agent-5: 285.0
Sum Reward: 1400.0
Avg Reward: 280.0
Min Reward: 260.0
Max Reward: 299.0
Gini Coefficient: 0.02457142857142857
20:20 Ratio: 1.15
Max-min Ratio: 1.15
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-16-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1524.0
  episode_reward_mean: 1121.8292682926829
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 41
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 4.262
    dispatch_time_ms: 7.434
    learner:
      cur_lr: 0.0013463470386341214
      grad_gnorm: 40.0
      policy_entropy: 16.78996467590332
      policy_loss: 5.897006034851074
      var_gnorm: 24.32081413269043
      vf_explained_var: 0.49493253231048584
      vf_loss: 59.37689208984375
    num_steps_sampled: 210000
    num_steps_trained: 210000
    wait_time_ms: 102.278
  iterations_since_restore: 42
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 488.75875425338745
  time_this_iter_s: 11.834587335586548
  time_total_s: 488.75875425338745
  timestamp: 1594088214
  timesteps_since_restore: 210000
  timesteps_this_iter: 5000
  timesteps_total: 210000
  training_iteration: 42
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 488 s, 42 iter, 210000 ts, 1.12e+03 rew

agent-1: 257.0
agent-2: 310.0
agent-3: 292.0
agent-4: 273.0
agent-5: 272.0
Sum Reward: 1404.0
Avg Reward: 280.8
Min Reward: 257.0
Max Reward: 310.0
Gini Coefficient: 0.035897435897435895
20:20 Ratio: 1.206225680933852
Max-min Ratio: 1.206225680933852
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-17-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1524.0
  episode_reward_mean: 1128.547619047619
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 42
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 3.603
    dispatch_time_ms: 8.435
    learner:
      cur_lr: 0.0013460139743983746
      grad_gnorm: 39.999996185302734
      policy_entropy: 23.702470779418945
      policy_loss: 15.2356595993042
      var_gnorm: 24.4700984954834
      vf_explained_var: 0.4568915367126465
      vf_loss: 46.626773834228516
    num_steps_sampled: 215000
    num_steps_trained: 215000
    wait_time_ms: 107.782
  iterations_since_restore: 43
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 500.7229745388031
  time_this_iter_s: 11.96422028541565
  time_total_s: 500.7229745388031
  timestamp: 1594088226
  timesteps_since_restore: 215000
  timesteps_this_iter: 5000
  timesteps_total: 215000
  training_iteration: 43
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 500 s, 43 iter, 215000 ts, 1.13e+03 rew

agent-1: 297.0
agent-2: 323.0
agent-3: 335.0
agent-4: 309.0
agent-5: 290.0
Sum Reward: 1554.0
Avg Reward: 310.8
Min Reward: 290.0
Max Reward: 335.0
Gini Coefficient: 0.029858429858429857
20:20 Ratio: 1.1551724137931034
Max-min Ratio: 1.1551724137931034
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-17-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1554.0
  episode_reward_mean: 1138.4418604651162
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 43
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 2.418
    dispatch_time_ms: 5.715
    learner:
      cur_lr: 0.0013456810265779495
      grad_gnorm: 39.99998092651367
      policy_entropy: 13.143016815185547
      policy_loss: 0.7066463232040405
      var_gnorm: 24.6501522064209
      vf_explained_var: -0.06732416152954102
      vf_loss: 38.65770721435547
    num_steps_sampled: 220000
    num_steps_trained: 220000
    wait_time_ms: 120.604
  iterations_since_restore: 44
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 512.9629991054535
  time_this_iter_s: 12.24002456665039
  time_total_s: 512.9629991054535
  timestamp: 1594088238
  timesteps_since_restore: 220000
  timesteps_this_iter: 5000
  timesteps_total: 220000
  training_iteration: 44
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 512 s, 44 iter, 220000 ts, 1.14e+03 rew

agent-1: 277.0
agent-2: 333.0
agent-3: 316.0
agent-4: 304.0
agent-5: 297.0
Sum Reward: 1527.0
Avg Reward: 305.4
Min Reward: 277.0
Max Reward: 333.0
Gini Coefficient: 0.03431565160445318
20:20 Ratio: 1.2021660649819494
Max-min Ratio: 1.2021660649819494
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-17-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1554.0
  episode_reward_mean: 1147.2727272727273
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 44
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 2.621
    dispatch_time_ms: 6.583
    learner:
      cur_lr: 0.0013453479623422027
      grad_gnorm: 40.0
      policy_entropy: 11.278255462646484
      policy_loss: 2.908831834793091
      var_gnorm: 24.752931594848633
      vf_explained_var: 0.6409182548522949
      vf_loss: 29.456411361694336
    num_steps_sampled: 225000
    num_steps_trained: 225000
    wait_time_ms: 103.091
  iterations_since_restore: 45
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 524.5673549175262
  time_this_iter_s: 11.604355812072754
  time_total_s: 524.5673549175262
  timestamp: 1594088250
  timesteps_since_restore: 225000
  timesteps_this_iter: 5000
  timesteps_total: 225000
  training_iteration: 45
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 524 s, 45 iter, 225000 ts, 1.15e+03 rew

agent-1: 290.0
agent-2: 341.0
agent-3: 277.0
agent-4: 323.0
agent-5: 298.0
Sum Reward: 1529.0
Avg Reward: 305.8
Min Reward: 277.0
Max Reward: 341.0
Gini Coefficient: 0.042119032047089604
20:20 Ratio: 1.2310469314079422
Max-min Ratio: 1.2310469314079422
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-17-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1554.0
  episode_reward_mean: 1155.7555555555555
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 45
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 2.775
    dispatch_time_ms: 7.01
    learner:
      cur_lr: 0.0013450150145217776
      grad_gnorm: 39.999996185302734
      policy_entropy: 26.525327682495117
      policy_loss: -21.14874839782715
      var_gnorm: 24.911697387695312
      vf_explained_var: -1.0
      vf_loss: 34.404273986816406
    num_steps_sampled: 230000
    num_steps_trained: 230000
    wait_time_ms: 115.037
  iterations_since_restore: 46
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 536.5231239795685
  time_this_iter_s: 11.955769062042236
  time_total_s: 536.5231239795685
  timestamp: 1594088262
  timesteps_since_restore: 230000
  timesteps_this_iter: 5000
  timesteps_total: 230000
  training_iteration: 46
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 536 s, 46 iter, 230000 ts, 1.16e+03 rew

agent-1: 298.0
agent-2: 291.0
agent-3: 264.0
agent-4: 285.0
agent-5: 267.0
Sum Reward: 1405.0
Avg Reward: 281.0
Min Reward: 264.0
Max Reward: 298.0
Gini Coefficient: 0.026192170818505337
20:20 Ratio: 1.128787878787879
Max-min Ratio: 1.128787878787879
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-17-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1554.0
  episode_reward_mean: 1161.1739130434783
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 46
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 2.613
    dispatch_time_ms: 6.627
    learner:
      cur_lr: 0.0013446819502860308
      grad_gnorm: 40.000003814697266
      policy_entropy: 24.881145477294922
      policy_loss: 9.476069450378418
      var_gnorm: 25.085525512695312
      vf_explained_var: 0.7592080235481262
      vf_loss: 43.635841369628906
    num_steps_sampled: 235000
    num_steps_trained: 235000
    wait_time_ms: 110.012
  iterations_since_restore: 47
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 548.4324316978455
  time_this_iter_s: 11.909307718276978
  time_total_s: 548.4324316978455
  timestamp: 1594088274
  timesteps_since_restore: 235000
  timesteps_this_iter: 5000
  timesteps_total: 235000
  training_iteration: 47
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 548 s, 47 iter, 235000 ts, 1.16e+03 rew

agent-1: 259.0
agent-2: 293.0
agent-3: 269.0
agent-4: 298.0
agent-5: 273.0
Sum Reward: 1392.0
Avg Reward: 278.4
Min Reward: 259.0
Max Reward: 298.0
Gini Coefficient: 0.029310344827586206
20:20 Ratio: 1.1505791505791505
Max-min Ratio: 1.1505791505791505
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-18-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1554.0
  episode_reward_mean: 1166.0851063829787
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 47
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 2.64
    dispatch_time_ms: 7.683
    learner:
      cur_lr: 0.0013443490024656057
      grad_gnorm: 39.99998474121094
      policy_entropy: 30.976486206054688
      policy_loss: -19.2514705657959
      var_gnorm: 25.180583953857422
      vf_explained_var: 0.17579686641693115
      vf_loss: 114.55191802978516
    num_steps_sampled: 240000
    num_steps_trained: 240000
    wait_time_ms: 113.889
  iterations_since_restore: 48
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 560.2660179138184
  time_this_iter_s: 11.8335862159729
  time_total_s: 560.2660179138184
  timestamp: 1594088286
  timesteps_since_restore: 240000
  timesteps_this_iter: 5000
  timesteps_total: 240000
  training_iteration: 48
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 560 s, 48 iter, 240000 ts, 1.17e+03 rew

agent-1: 296.0
agent-2: 312.0
agent-3: 276.0
agent-4: 245.0
agent-5: 276.0
Sum Reward: 1405.0
Avg Reward: 281.0
Min Reward: 245.0
Max Reward: 312.0
Gini Coefficient: 0.04384341637010676
20:20 Ratio: 1.273469387755102
Max-min Ratio: 1.273469387755102
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-18-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1554.0
  episode_reward_mean: 1171.0625
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 48
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 2.692
    dispatch_time_ms: 10.032
    learner:
      cur_lr: 0.0013440160546451807
      grad_gnorm: 40.000038146972656
      policy_entropy: 32.450496673583984
      policy_loss: 15.239325523376465
      var_gnorm: 25.2865047454834
      vf_explained_var: 0.7157355546951294
      vf_loss: 42.22677993774414
    num_steps_sampled: 245000
    num_steps_trained: 245000
    wait_time_ms: 96.677
  iterations_since_restore: 49
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 572.2915136814117
  time_this_iter_s: 12.025495767593384
  time_total_s: 572.2915136814117
  timestamp: 1594088298
  timesteps_since_restore: 245000
  timesteps_this_iter: 5000
  timesteps_total: 245000
  training_iteration: 49
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 572 s, 49 iter, 245000 ts, 1.17e+03 rew

agent-1: 294.0
agent-2: 289.0
agent-3: 242.0
agent-4: 273.0
agent-5: 258.0
Sum Reward: 1356.0
Avg Reward: 271.2
Min Reward: 242.0
Max Reward: 294.0
Gini Coefficient: 0.03982300884955752
20:20 Ratio: 1.2148760330578512
Max-min Ratio: 1.2148760330578512
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-18-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1554.0
  episode_reward_mean: 1174.8367346938776
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 49
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 2.807
    dispatch_time_ms: 7.838
    learner:
      cur_lr: 0.0013436829904094338
      grad_gnorm: 40.0
      policy_entropy: 35.33522033691406
      policy_loss: -23.510908126831055
      var_gnorm: 25.426010131835938
      vf_explained_var: 0.17622441053390503
      vf_loss: 43.970306396484375
    num_steps_sampled: 250000
    num_steps_trained: 250000
    wait_time_ms: 114.633
  iterations_since_restore: 50
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 584.2225399017334
  time_this_iter_s: 11.931026220321655
  time_total_s: 584.2225399017334
  timestamp: 1594088310
  timesteps_since_restore: 250000
  timesteps_this_iter: 5000
  timesteps_total: 250000
  training_iteration: 50
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 584 s, 50 iter, 250000 ts, 1.17e+03 rew

agent-1: 272.0
agent-2: 255.0
agent-3: 275.0
agent-4: 325.0
agent-5: 294.0
Sum Reward: 1421.0
Avg Reward: 284.2
Min Reward: 255.0
Max Reward: 325.0
Gini Coefficient: 0.04560168895144265
20:20 Ratio: 1.2745098039215685
Max-min Ratio: 1.2745098039215685
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-18-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1554.0
  episode_reward_mean: 1179.76
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 50
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 2.969
    dispatch_time_ms: 6.804
    learner:
      cur_lr: 0.0013433500425890088
      grad_gnorm: 39.99998092651367
      policy_entropy: 31.684446334838867
      policy_loss: -15.776315689086914
      var_gnorm: 25.486536026000977
      vf_explained_var: -0.25650131702423096
      vf_loss: 51.33726119995117
    num_steps_sampled: 255000
    num_steps_trained: 255000
    wait_time_ms: 117.711
  iterations_since_restore: 51
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 596.5133426189423
  time_this_iter_s: 12.290802717208862
  time_total_s: 596.5133426189423
  timestamp: 1594088322
  timesteps_since_restore: 255000
  timesteps_this_iter: 5000
  timesteps_total: 255000
  training_iteration: 51
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 596 s, 51 iter, 255000 ts, 1.18e+03 rew

agent-1: 292.0
agent-2: 328.0
agent-3: 346.0
agent-4: 305.0
agent-5: 344.0
Sum Reward: 1615.0
Avg Reward: 323.0
Min Reward: 292.0
Max Reward: 346.0
Gini Coefficient: 0.03640866873065016
20:20 Ratio: 1.1849315068493151
Max-min Ratio: 1.1849315068493151
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-18-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1615.0
  episode_reward_mean: 1188.2941176470588
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 51
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 2.811
    dispatch_time_ms: 8.005
    learner:
      cur_lr: 0.001343016978353262
      grad_gnorm: 40.000003814697266
      policy_entropy: 20.01829719543457
      policy_loss: -28.9423885345459
      var_gnorm: 25.591632843017578
      vf_explained_var: 0.4484708309173584
      vf_loss: 67.69092559814453
    num_steps_sampled: 260000
    num_steps_trained: 260000
    wait_time_ms: 113.473
  iterations_since_restore: 52
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 608.8007001876831
  time_this_iter_s: 12.287357568740845
  time_total_s: 608.8007001876831
  timestamp: 1594088334
  timesteps_since_restore: 260000
  timesteps_this_iter: 5000
  timesteps_total: 260000
  training_iteration: 52
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 608 s, 52 iter, 260000 ts, 1.19e+03 rew

agent-1: 316.0
agent-2: 275.0
agent-3: 329.0
agent-4: 247.0
agent-5: 308.0
Sum Reward: 1475.0
Avg Reward: 295.0
Min Reward: 247.0
Max Reward: 329.0
Gini Coefficient: 0.05559322033898305
20:20 Ratio: 1.3319838056680162
Max-min Ratio: 1.3319838056680162
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-19-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1615.0
  episode_reward_mean: 1193.8076923076924
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 52
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 2.735
    dispatch_time_ms: 9.178
    learner:
      cur_lr: 0.001342684030532837
      grad_gnorm: 40.0
      policy_entropy: 32.24143981933594
      policy_loss: 8.921961784362793
      var_gnorm: 25.749446868896484
      vf_explained_var: 0.26159924268722534
      vf_loss: 62.89149475097656
    num_steps_sampled: 265000
    num_steps_trained: 265000
    wait_time_ms: 107.415
  iterations_since_restore: 53
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 621.2315499782562
  time_this_iter_s: 12.43084979057312
  time_total_s: 621.2315499782562
  timestamp: 1594088347
  timesteps_since_restore: 265000
  timesteps_this_iter: 5000
  timesteps_total: 265000
  training_iteration: 53
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 621 s, 53 iter, 265000 ts, 1.19e+03 rew

agent-1: 292.0
agent-2: 335.0
agent-3: 253.0
agent-4: 290.0
agent-5: 298.0
Sum Reward: 1468.0
Avg Reward: 293.6
Min Reward: 253.0
Max Reward: 335.0
Gini Coefficient: 0.046866485013623976
20:20 Ratio: 1.3241106719367588
Max-min Ratio: 1.3241106719367588
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-19-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1615.0
  episode_reward_mean: 1198.9811320754718
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 53
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 2.914
    dispatch_time_ms: 6.362
    learner:
      cur_lr: 0.00134235096629709
      grad_gnorm: 39.999996185302734
      policy_entropy: 39.72597122192383
      policy_loss: -26.199766159057617
      var_gnorm: 25.817485809326172
      vf_explained_var: 0.4143075942993164
      vf_loss: 71.05134582519531
    num_steps_sampled: 270000
    num_steps_trained: 270000
    wait_time_ms: 110.038
  iterations_since_restore: 54
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 633.1533300876617
  time_this_iter_s: 11.921780109405518
  time_total_s: 633.1533300876617
  timestamp: 1594088359
  timesteps_since_restore: 270000
  timesteps_this_iter: 5000
  timesteps_total: 270000
  training_iteration: 54
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 633 s, 54 iter, 270000 ts, 1.2e+03 rew

agent-1: 305.0
agent-2: 307.0
agent-3: 286.0
agent-4: 281.0
agent-5: 316.0
Sum Reward: 1495.0
Avg Reward: 299.0
Min Reward: 281.0
Max Reward: 316.0
Gini Coefficient: 0.02434782608695652
20:20 Ratio: 1.1245551601423487
Max-min Ratio: 1.1245551601423487
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-19-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1615.0
  episode_reward_mean: 1204.462962962963
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 54
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 2.623
    dispatch_time_ms: 6.482
    learner:
      cur_lr: 0.001342018018476665
      grad_gnorm: 39.999977111816406
      policy_entropy: 23.227420806884766
      policy_loss: 1.6716125011444092
      var_gnorm: 25.944561004638672
      vf_explained_var: -0.15158593654632568
      vf_loss: 21.956701278686523
    num_steps_sampled: 275000
    num_steps_trained: 275000
    wait_time_ms: 123.778
  iterations_since_restore: 55
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 645.4769515991211
  time_this_iter_s: 12.32362151145935
  time_total_s: 645.4769515991211
  timestamp: 1594088371
  timesteps_since_restore: 275000
  timesteps_this_iter: 5000
  timesteps_total: 275000
  training_iteration: 55
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 645 s, 55 iter, 275000 ts, 1.2e+03 rew

agent-1: 318.0
agent-2: 306.0
agent-3: 295.0
agent-4: 279.0
agent-5: 299.0
Sum Reward: 1497.0
Avg Reward: 299.4
Min Reward: 279.0
Max Reward: 318.0
Gini Coefficient: 0.023780895123580493
20:20 Ratio: 1.1397849462365592
Max-min Ratio: 1.1397849462365592
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-19-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1615.0
  episode_reward_mean: 1209.7818181818182
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 55
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 3.364
    dispatch_time_ms: 5.874
    learner:
      cur_lr: 0.0013416849542409182
      grad_gnorm: 40.000003814697266
      policy_entropy: 23.239591598510742
      policy_loss: 12.399194717407227
      var_gnorm: 25.985042572021484
      vf_explained_var: -0.16658616065979004
      vf_loss: 92.86936950683594
    num_steps_sampled: 280000
    num_steps_trained: 280000
    wait_time_ms: 122.489
  iterations_since_restore: 56
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 657.5337250232697
  time_this_iter_s: 12.05677342414856
  time_total_s: 657.5337250232697
  timestamp: 1594088383
  timesteps_since_restore: 280000
  timesteps_this_iter: 5000
  timesteps_total: 280000
  training_iteration: 56
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 657 s, 56 iter, 280000 ts, 1.21e+03 rew

agent-1: 331.0
agent-2: 333.0
agent-3: 338.0
agent-4: 298.0
agent-5: 305.0
Sum Reward: 1605.0
Avg Reward: 321.0
Min Reward: 298.0
Max Reward: 338.0
Gini Coefficient: 0.02691588785046729
20:20 Ratio: 1.1342281879194631
Max-min Ratio: 1.1342281879194631
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-19-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1615.0
  episode_reward_mean: 1216.8392857142858
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 56
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 2.557
    dispatch_time_ms: 6.12
    learner:
      cur_lr: 0.0013413520064204931
      grad_gnorm: 40.00001525878906
      policy_entropy: 34.77171325683594
      policy_loss: -7.22280740737915
      var_gnorm: 26.12547492980957
      vf_explained_var: 0.5892146825790405
      vf_loss: 35.01631546020508
    num_steps_sampled: 285000
    num_steps_trained: 285000
    wait_time_ms: 114.278
  iterations_since_restore: 57
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 670.1867971420288
  time_this_iter_s: 12.653072118759155
  time_total_s: 670.1867971420288
  timestamp: 1594088396
  timesteps_since_restore: 285000
  timesteps_this_iter: 5000
  timesteps_total: 285000
  training_iteration: 57
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 670 s, 57 iter, 285000 ts, 1.22e+03 rew

agent-1: 294.0
agent-2: 334.0
agent-3: 315.0
agent-4: 322.0
agent-5: 274.0
Sum Reward: 1539.0
Avg Reward: 307.8
Min Reward: 274.0
Max Reward: 334.0
Gini Coefficient: 0.03846653671215075
20:20 Ratio: 1.218978102189781
Max-min Ratio: 1.218978102189781
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-20-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1615.0
  episode_reward_mean: 1222.4912280701753
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 57
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 2.771
    dispatch_time_ms: 11.321
    learner:
      cur_lr: 0.0013410189421847463
      grad_gnorm: 40.0
      policy_entropy: 31.539936065673828
      policy_loss: 10.793932914733887
      var_gnorm: 26.164499282836914
      vf_explained_var: 0.17639636993408203
      vf_loss: 65.94239044189453
    num_steps_sampled: 290000
    num_steps_trained: 290000
    wait_time_ms: 102.891
  iterations_since_restore: 58
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 681.8494679927826
  time_this_iter_s: 11.662670850753784
  time_total_s: 681.8494679927826
  timestamp: 1594088407
  timesteps_since_restore: 290000
  timesteps_this_iter: 5000
  timesteps_total: 290000
  training_iteration: 58
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 681 s, 58 iter, 290000 ts, 1.22e+03 rew

agent-1: 289.0
agent-2: 308.0
agent-3: 303.0
agent-4: 282.0
agent-5: 276.0
Sum Reward: 1458.0
Avg Reward: 291.6
Min Reward: 276.0
Max Reward: 308.0
Gini Coefficient: 0.023319615912208505
20:20 Ratio: 1.1159420289855073
Max-min Ratio: 1.1159420289855073
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-20-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1615.0
  episode_reward_mean: 1226.551724137931
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 58
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 3.939
    dispatch_time_ms: 7.235
    learner:
      cur_lr: 0.0013406859943643212
      grad_gnorm: 40.000022888183594
      policy_entropy: 31.245525360107422
      policy_loss: 2.36820912361145
      var_gnorm: 26.207082748413086
      vf_explained_var: -0.006224274635314941
      vf_loss: 66.14913177490234
    num_steps_sampled: 295000
    num_steps_trained: 295000
    wait_time_ms: 111.903
  iterations_since_restore: 59
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 693.6306746006012
  time_this_iter_s: 11.781206607818604
  time_total_s: 693.6306746006012
  timestamp: 1594088419
  timesteps_since_restore: 295000
  timesteps_this_iter: 5000
  timesteps_total: 295000
  training_iteration: 59
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 693 s, 59 iter, 295000 ts, 1.23e+03 rew

agent-1: 275.0
agent-2: 268.0
agent-3: 225.0
agent-4: 310.0
agent-5: 286.0
Sum Reward: 1364.0
Avg Reward: 272.8
Min Reward: 225.0
Max Reward: 310.0
Gini Coefficient: 0.05513196480938416
20:20 Ratio: 1.3777777777777778
Max-min Ratio: 1.3777777777777778
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-20-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1615.0
  episode_reward_mean: 1228.8813559322034
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 59
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 2.827
    dispatch_time_ms: 7.683
    learner:
      cur_lr: 0.0013403530465438962
      grad_gnorm: 40.0
      policy_entropy: 23.994888305664062
      policy_loss: 4.518458843231201
      var_gnorm: 26.264680862426758
      vf_explained_var: 0.362549364566803
      vf_loss: 34.55963897705078
    num_steps_sampled: 300000
    num_steps_trained: 300000
    wait_time_ms: 113.703
  iterations_since_restore: 60
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 706.0384955406189
  time_this_iter_s: 12.4078209400177
  time_total_s: 706.0384955406189
  timestamp: 1594088432
  timesteps_since_restore: 300000
  timesteps_this_iter: 5000
  timesteps_total: 300000
  training_iteration: 60
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 706 s, 60 iter, 300000 ts, 1.23e+03 rew

agent-1: 270.0
agent-2: 346.0
agent-3: 299.0
agent-4: 226.0
agent-5: 281.0
Sum Reward: 1422.0
Avg Reward: 284.4
Min Reward: 226.0
Max Reward: 346.0
Gini Coefficient: 0.07566807313642757
20:20 Ratio: 1.5309734513274336
Max-min Ratio: 1.5309734513274336
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-20-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1615.0
  episode_reward_mean: 1232.1
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 60
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 2.514
    dispatch_time_ms: 5.732
    learner:
      cur_lr: 0.0013400199823081493
      grad_gnorm: 40.0
      policy_entropy: 24.522621154785156
      policy_loss: -0.385698139667511
      var_gnorm: 26.344297409057617
      vf_explained_var: 0.3304672837257385
      vf_loss: 50.740631103515625
    num_steps_sampled: 305000
    num_steps_trained: 305000
    wait_time_ms: 113.374
  iterations_since_restore: 61
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 718.7431144714355
  time_this_iter_s: 12.70461893081665
  time_total_s: 718.7431144714355
  timestamp: 1594088444
  timesteps_since_restore: 305000
  timesteps_this_iter: 5000
  timesteps_total: 305000
  training_iteration: 61
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 718 s, 61 iter, 305000 ts, 1.23e+03 rew

agent-1: 354.0
agent-2: 334.0
agent-3: 232.0
agent-4: 292.0
agent-5: 303.0
Sum Reward: 1515.0
Avg Reward: 303.0
Min Reward: 232.0
Max Reward: 354.0
Gini Coefficient: 0.07551155115511551
20:20 Ratio: 1.5258620689655173
Max-min Ratio: 1.5258620689655173
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-20-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1615.0
  episode_reward_mean: 1236.7377049180327
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 61
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 3.116
    dispatch_time_ms: 6.32
    learner:
      cur_lr: 0.0013396870344877243
      grad_gnorm: 40.00000762939453
      policy_entropy: 33.06625747680664
      policy_loss: -4.028938293457031
      var_gnorm: 26.426109313964844
      vf_explained_var: 0.5067570209503174
      vf_loss: 53.3094367980957
    num_steps_sampled: 310000
    num_steps_trained: 310000
    wait_time_ms: 131.785
  iterations_since_restore: 62
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 731.887624502182
  time_this_iter_s: 13.14451003074646
  time_total_s: 731.887624502182
  timestamp: 1594088458
  timesteps_since_restore: 310000
  timesteps_this_iter: 5000
  timesteps_total: 310000
  training_iteration: 62
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 731 s, 62 iter, 310000 ts, 1.24e+03 rew

agent-1: 289.0
agent-2: 316.0
agent-3: 287.0
agent-4: 305.0
agent-5: 323.0
Sum Reward: 1520.0
Avg Reward: 304.0
Min Reward: 287.0
Max Reward: 323.0
Gini Coefficient: 0.02605263157894737
20:20 Ratio: 1.1254355400696865
Max-min Ratio: 1.1254355400696865
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-21-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1615.0
  episode_reward_mean: 1241.3064516129032
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 62
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 2.464
    dispatch_time_ms: 6.265
    learner:
      cur_lr: 0.0013393539702519774
      grad_gnorm: 39.999996185302734
      policy_entropy: 36.84407424926758
      policy_loss: -23.328950881958008
      var_gnorm: 26.52548599243164
      vf_explained_var: 0.13398224115371704
      vf_loss: 35.501075744628906
    num_steps_sampled: 315000
    num_steps_trained: 315000
    wait_time_ms: 119.311
  iterations_since_restore: 63
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 744.3995726108551
  time_this_iter_s: 12.511948108673096
  time_total_s: 744.3995726108551
  timestamp: 1594088470
  timesteps_since_restore: 315000
  timesteps_this_iter: 5000
  timesteps_total: 315000
  training_iteration: 63
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 744 s, 63 iter, 315000 ts, 1.24e+03 rew

agent-1: 289.0
agent-2: 280.0
agent-3: 296.0
agent-4: 286.0
agent-5: 233.0
Sum Reward: 1384.0
Avg Reward: 276.8
Min Reward: 233.0
Max Reward: 296.0
Gini Coefficient: 0.03901734104046243
20:20 Ratio: 1.2703862660944205
Max-min Ratio: 1.2703862660944205
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-21-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1615.0
  episode_reward_mean: 1243.5714285714287
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 63
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 2.76
    dispatch_time_ms: 6.439
    learner:
      cur_lr: 0.0013390210224315524
      grad_gnorm: 39.999996185302734
      policy_entropy: 34.20314407348633
      policy_loss: -8.440068244934082
      var_gnorm: 26.549222946166992
      vf_explained_var: 0.5626951456069946
      vf_loss: 14.778780937194824
    num_steps_sampled: 320000
    num_steps_trained: 320000
    wait_time_ms: 105.233
  iterations_since_restore: 64
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 756.0664582252502
  time_this_iter_s: 11.666885614395142
  time_total_s: 756.0664582252502
  timestamp: 1594088482
  timesteps_since_restore: 320000
  timesteps_this_iter: 5000
  timesteps_total: 320000
  training_iteration: 64
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 756 s, 64 iter, 320000 ts, 1.24e+03 rew

agent-1: 270.0
agent-2: 282.0
agent-3: 258.0
agent-4: 278.0
agent-5: 226.0
Sum Reward: 1314.0
Avg Reward: 262.8
Min Reward: 226.0
Max Reward: 282.0
Gini Coefficient: 0.04018264840182648
20:20 Ratio: 1.247787610619469
Max-min Ratio: 1.247787610619469
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-21-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1615.0
  episode_reward_mean: 1244.671875
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 64
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 2.668
    dispatch_time_ms: 6.563
    learner:
      cur_lr: 0.0013386879581958055
      grad_gnorm: 40.00000762939453
      policy_entropy: 45.6055793762207
      policy_loss: -34.49095153808594
      var_gnorm: 26.50383758544922
      vf_explained_var: 0.5888248085975647
      vf_loss: 31.03489112854004
    num_steps_sampled: 325000
    num_steps_trained: 325000
    wait_time_ms: 94.493
  iterations_since_restore: 65
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 767.1377367973328
  time_this_iter_s: 11.07127857208252
  time_total_s: 767.1377367973328
  timestamp: 1594088493
  timesteps_since_restore: 325000
  timesteps_this_iter: 5000
  timesteps_total: 325000
  training_iteration: 65
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 767 s, 65 iter, 325000 ts, 1.24e+03 rew

agent-1: 244.0
agent-2: 212.0
agent-3: 180.0
agent-4: 222.0
agent-5: 256.0
Sum Reward: 1114.0
Avg Reward: 222.8
Min Reward: 180.0
Max Reward: 256.0
Gini Coefficient: 0.06606822262118492
20:20 Ratio: 1.4222222222222223
Max-min Ratio: 1.4222222222222223
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-21-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1615.0
  episode_reward_mean: 1242.6615384615384
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 65
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 2.898
    dispatch_time_ms: 10.804
    learner:
      cur_lr: 0.0013383550103753805
      grad_gnorm: 39.999996185302734
      policy_entropy: 7.118274688720703
      policy_loss: 5.543445587158203
      var_gnorm: 26.500343322753906
      vf_explained_var: 0.21537739038467407
      vf_loss: 31.320079803466797
    num_steps_sampled: 330000
    num_steps_trained: 330000
    wait_time_ms: 111.331
  iterations_since_restore: 66
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 778.6673290729523
  time_this_iter_s: 11.529592275619507
  time_total_s: 778.6673290729523
  timestamp: 1594088505
  timesteps_since_restore: 330000
  timesteps_this_iter: 5000
  timesteps_total: 330000
  training_iteration: 66
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 778 s, 66 iter, 330000 ts, 1.24e+03 rew

agent-1: 260.0
agent-2: 237.0
agent-3: 238.0
agent-4: 285.0
agent-5: 234.0
Sum Reward: 1254.0
Avg Reward: 250.8
Min Reward: 234.0
Max Reward: 285.0
Gini Coefficient: 0.03987240829346093
20:20 Ratio: 1.2179487179487178
Max-min Ratio: 1.2179487179487178
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-21-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1615.0
  episode_reward_mean: 1242.8333333333333
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 66
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 2.664
    dispatch_time_ms: 6.351
    learner:
      cur_lr: 0.0013380219461396337
      grad_gnorm: 40.00005340576172
      policy_entropy: 13.90802001953125
      policy_loss: 7.368113040924072
      var_gnorm: 26.59038543701172
      vf_explained_var: 0.2703734040260315
      vf_loss: 58.78611373901367
    num_steps_sampled: 335000
    num_steps_trained: 335000
    wait_time_ms: 117.906
  iterations_since_restore: 67
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 790.9250862598419
  time_this_iter_s: 12.257757186889648
  time_total_s: 790.9250862598419
  timestamp: 1594088517
  timesteps_since_restore: 335000
  timesteps_this_iter: 5000
  timesteps_total: 335000
  training_iteration: 67
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 790 s, 67 iter, 335000 ts, 1.24e+03 rew

agent-1: 343.0
agent-2: 303.0
agent-3: 369.0
agent-4: 337.0
agent-5: 327.0
Sum Reward: 1679.0
Avg Reward: 335.8
Min Reward: 303.0
Max Reward: 369.0
Gini Coefficient: 0.035259082787373434
20:20 Ratio: 1.2178217821782178
Max-min Ratio: 1.2178217821782178
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-22-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1679.0
  episode_reward_mean: 1249.3432835820895
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 67
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 2.537
    dispatch_time_ms: 6.775
    learner:
      cur_lr: 0.0013376889983192086
      grad_gnorm: 22.84642791748047
      policy_entropy: 16.22823715209961
      policy_loss: -6.063224792480469
      var_gnorm: 26.66267204284668
      vf_explained_var: 0.27629363536834717
      vf_loss: 32.71421813964844
    num_steps_sampled: 340000
    num_steps_trained: 340000
    wait_time_ms: 105.775
  iterations_since_restore: 68
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 802.8972089290619
  time_this_iter_s: 11.97212266921997
  time_total_s: 802.8972089290619
  timestamp: 1594088529
  timesteps_since_restore: 340000
  timesteps_this_iter: 5000
  timesteps_total: 340000
  training_iteration: 68
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 802 s, 68 iter, 340000 ts, 1.25e+03 rew

agent-1: 345.0
agent-2: 300.0
agent-3: 338.0
agent-4: 317.0
agent-5: 298.0
Sum Reward: 1598.0
Avg Reward: 319.6
Min Reward: 298.0
Max Reward: 345.0
Gini Coefficient: 0.033041301627033795
20:20 Ratio: 1.157718120805369
Max-min Ratio: 1.157718120805369
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-22-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1679.0
  episode_reward_mean: 1254.4705882352941
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 68
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 3.573
    dispatch_time_ms: 10.061
    learner:
      cur_lr: 0.0013373560504987836
      grad_gnorm: 40.0
      policy_entropy: 16.05282211303711
      policy_loss: -5.874026775360107
      var_gnorm: 26.694265365600586
      vf_explained_var: 0.08034014701843262
      vf_loss: 33.74080276489258
    num_steps_sampled: 345000
    num_steps_trained: 345000
    wait_time_ms: 109.166
  iterations_since_restore: 69
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 815.2610111236572
  time_this_iter_s: 12.363802194595337
  time_total_s: 815.2610111236572
  timestamp: 1594088541
  timesteps_since_restore: 345000
  timesteps_this_iter: 5000
  timesteps_total: 345000
  training_iteration: 69
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 815 s, 69 iter, 345000 ts, 1.25e+03 rew

agent-1: 326.0
agent-2: 283.0
agent-3: 289.0
agent-4: 343.0
agent-5: 296.0
Sum Reward: 1537.0
Avg Reward: 307.4
Min Reward: 283.0
Max Reward: 343.0
Gini Coefficient: 0.04085881587508133
20:20 Ratio: 1.2120141342756183
Max-min Ratio: 1.2120141342756183
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-22-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1679.0
  episode_reward_mean: 1258.5652173913043
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 69
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 2.979
    dispatch_time_ms: 11.456
    learner:
      cur_lr: 0.0013370229862630367
      grad_gnorm: 40.0
      policy_entropy: 17.006807327270508
      policy_loss: 15.822649002075195
      var_gnorm: 26.803714752197266
      vf_explained_var: 0.17008250951766968
      vf_loss: 41.26268768310547
    num_steps_sampled: 350000
    num_steps_trained: 350000
    wait_time_ms: 114.402
  iterations_since_restore: 70
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 827.6025848388672
  time_this_iter_s: 12.341573715209961
  time_total_s: 827.6025848388672
  timestamp: 1594088554
  timesteps_since_restore: 350000
  timesteps_this_iter: 5000
  timesteps_total: 350000
  training_iteration: 70
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 827 s, 70 iter, 350000 ts, 1.26e+03 rew

agent-1: 319.0
agent-2: 330.0
agent-3: 336.0
agent-4: 329.0
agent-5: 307.0
Sum Reward: 1621.0
Avg Reward: 324.2
Min Reward: 307.0
Max Reward: 336.0
Gini Coefficient: 0.01702652683528686
20:20 Ratio: 1.0944625407166124
Max-min Ratio: 1.0944625407166124
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-22-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1679.0
  episode_reward_mean: 1263.7428571428572
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 70
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 2.805
    dispatch_time_ms: 6.649
    learner:
      cur_lr: 0.0013366900384426117
      grad_gnorm: 40.0
      policy_entropy: 23.3051815032959
      policy_loss: 12.215370178222656
      var_gnorm: 26.903169631958008
      vf_explained_var: -0.07503795623779297
      vf_loss: 50.02554702758789
    num_steps_sampled: 355000
    num_steps_trained: 355000
    wait_time_ms: 121.304
  iterations_since_restore: 71
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 839.8676674365997
  time_this_iter_s: 12.265082597732544
  time_total_s: 839.8676674365997
  timestamp: 1594088566
  timesteps_since_restore: 355000
  timesteps_this_iter: 5000
  timesteps_total: 355000
  training_iteration: 71
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 839 s, 71 iter, 355000 ts, 1.26e+03 rew

agent-1: 349.0
agent-2: 303.0
agent-3: 306.0
agent-4: 296.0
agent-5: 274.0
Sum Reward: 1528.0
Avg Reward: 305.6
Min Reward: 274.0
Max Reward: 349.0
Gini Coefficient: 0.041884816753926704
20:20 Ratio: 1.2737226277372262
Max-min Ratio: 1.2737226277372262
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-22-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1679.0
  episode_reward_mean: 1267.4647887323943
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 71
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 3.489
    dispatch_time_ms: 9.489
    learner:
      cur_lr: 0.0013363569742068648
      grad_gnorm: 40.0
      policy_entropy: 32.536293029785156
      policy_loss: -5.8433098793029785
      var_gnorm: 26.97759437561035
      vf_explained_var: 0.7588850855827332
      vf_loss: 45.74160385131836
    num_steps_sampled: 360000
    num_steps_trained: 360000
    wait_time_ms: 107.029
  iterations_since_restore: 72
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 852.0138611793518
  time_this_iter_s: 12.146193742752075
  time_total_s: 852.0138611793518
  timestamp: 1594088578
  timesteps_since_restore: 360000
  timesteps_this_iter: 5000
  timesteps_total: 360000
  training_iteration: 72
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 852 s, 72 iter, 360000 ts, 1.27e+03 rew

agent-1: 316.0
agent-2: 325.0
agent-3: 311.0
agent-4: 305.0
agent-5: 321.0
Sum Reward: 1578.0
Avg Reward: 315.6
Min Reward: 305.0
Max Reward: 325.0
Gini Coefficient: 0.012674271229404309
20:20 Ratio: 1.0655737704918034
Max-min Ratio: 1.0655737704918034
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-23-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1679.0
  episode_reward_mean: 1271.7777777777778
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 72
  experiment_id: 34530a1f74dd4b359df0c54c2d622f6a
  hostname: gpu011
  info:
    apply_time_ms: 2.96
    dispatch_time_ms: 8.463
    learner:
      cur_lr: 0.0013360240263864398
      grad_gnorm: 40.0
      policy_entropy: 35.51654815673828
      policy_loss: -4.469695568084717
      var_gnorm: 27.01179313659668
      vf_explained_var: 0.37706607580184937
      vf_loss: 26.559158325195312
    num_steps_sampled: 365000
    num_steps_trained: 365000
    wait_time_ms: 120.415
  iterations_since_restore: 73
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 13284
  policy_reward_mean: {}
  time_since_restore: 864.0787532329559
  time_this_iter_s: 12.064892053604126
  time_total_s: 864.0787532329559
  timestamp: 1594088590
  timesteps_since_restore: 365000
  timesteps_this_iter: 5000
  timesteps_total: 365000
  training_iteration: 73
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13284], 864 s, 73 iter, 365000 ts, 1.27e+03 rew

Fatal Python error: Bus error

Stack (most recent call first):
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/utils.py", line 418 in _wrapper
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/worker.py", line 291 in store_and_register
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/worker.py", line 356 in put_object
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/worker.py", line 755 in _store_outputs_in_object_store
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/worker.py", line 840 in _process_task
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/worker.py", line 919 in _wait_for_and_process_task
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/worker.py", line 962 in main_loop
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/workers/default_worker.py", line 107 in <module>
WARNING: Logging before InitGoogleLogging() is written to STDERR
F0706 22:23:14.518509 13191 raylet_extension.cc:190]  Check failed: _s.ok() [RayletClient] Failed to wait for objects.: IOError: [RayletClient] Raylet connection closed.
WARNING: Logging before InitGoogleLogging() is written to STDERR
F0706 22:23:14.518532 13284 raylet_extension.cc:190]  Check failed: _s.ok() [RayletClient] Failed to wait for objects.: IOError: [RayletClient] Raylet connection closed.
*** Check failure stack trace: ***
*** Check failure stack trace: ***
Fatal Python error: AbortedFatal Python error: 

Aborted

Stack (most recent call first):
Stack (most recent call first):
  File   File ""//hh//zzhhaaoosstteepp//..ccoonnddaa//eennvvss//ccaauussaall//lliibb//ppyytthhoonn33..66//ssiittee--ppaacckkaaggeess//rraayy//wwoorrkkeerr..ppyy"", line , line 24852485 in  in wwaaiitt

  File   File "/h"//zhh/azohsatoespt/e.pc/o.ncdoan/dean/vesn/vcsa/ucsaauls/alli/bl/ipby/tphyotnh3o.n63/.s6i/tsei-tpea-cpkaacgkeasg/ersa/yr/atyu/nrel/lriaby/_otprtiiamli_zeexresc/uatsoyrn.cp_yg"ra, line d199i in egnetts__noepxtti_maivzaeirl.apbyl"e_t, line r46i in aslt
e  File p
"/  File h/z"h/aho/sztheapo/s.tceopn/d.ac/oenndvas//ecnavuss/acla/ulsiabl//plyitbh/opny3t.h6o/ns3i.t6e/-spiatcek-apgaecsk/argaeys//truanye//rtlrliiabl/_arguennntesr/.ap3yc"/, line a2593 in c_.ppryo"c, line e68s in s__tervaeinnt
s
  File   File ""//hh//zzhhaaoosstteepp//..ccoonnddaa//eennvvss//ccaauussaall//lliibb//ppyytthhoonn33..66//ssiittee--ppaacckkaaggeess//rraayy//ttuunnee//ttrraiianla_brluen.npeyr".py", line , line 146118 in  in tsrtaeipn

  File   File ""//hh//zzhhaaoosstteepp//..ccoonnddaa//eennvvss//ccaauussaall//lliibb//ppyytthhoonn33..66//ssiittee--ppaacckkaaggeess//rraayy//trulnlei/bt/uangee.nptys"/a, line g108e in ntr.upny_"ex, line p279e in rtirmaeinnt
s  File 
  File "/"ht/rzahiano_satgeepn/t.sc.opnyd"a, line /216e in nvmsa/icna
usa  File l"/tlriabi/np_yatgheonnt3s..6p/ys"it, line e238- in p<amcokdauglees>/
ray/function_manager.py", line 713 in actor_method_executor
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/worker.py", line 820 in _process_task
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/worker.py", line 919 in _wait_for_and_process_task
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/worker.py", line 962 in main_loop
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/workers/default_worker.py", line 107 in <module>
srun: error: gpu011: task 0: Aborted
