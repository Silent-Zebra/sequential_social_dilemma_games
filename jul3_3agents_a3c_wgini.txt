/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Process STDOUT and STDERR is being redirected to /tmp/ray/session_2020-07-03_20-04-44_25111/logs.
Waiting for redis server at 127.0.0.1:36157 to respond...
Waiting for redis server at 127.0.0.1:55605 to respond...
Warning: Capping object memory store to 20.0GB. To increase this further, specify `object_store_memory` when calling ray.init() or ray start.
Starting the Plasma object store with 20.0 GB memory using /dev/shm.

======================================================================
View the web UI at http://localhost:8888/notebooks/ray_ui.ipynb?token=3ecc3961533c15e1d496ca33ad1698703f451135f7b4b447
======================================================================

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.0/202.5 GB

Created LogSyncer for /h/zhaostep/ray_results/harvest_A3C/A3C_harvest_env_0_2020-07-03_20-04-45d03wbnpg -> 
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING

/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-03 20:04:57,390	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 0 on CPU (please ignore any CUDA init errors)
2020-07-03 20:04:57.391812: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-03 20:05:08,978	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 1 on CPU (please ignore any CUDA init errors)
2020-07-03 20:05:08.979328: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-03 20:05:09,257	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 2 on CPU (please ignore any CUDA init errors)
2020-07-03 20:05:09.259085: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-05-18
  done: false
  episode_len_mean: .nan
  episode_reward_max: .nan
  episode_reward_mean: .nan
  episode_reward_min: .nan
  episodes_this_iter: 0
  episodes_total: 0
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 3.319
    dispatch_time_ms: 7.173
    learner:
      cur_lr: 0.0013599999947473407
      grad_gnorm: 39.99999237060547
      policy_entropy: 46.196109771728516
      policy_loss: -773.6132202148438
      var_gnorm: 17.97963523864746
      vf_explained_var: 0.0003592967987060547
      vf_loss: 10407.4306640625
    num_steps_sampled: 3000
    num_steps_trained: 3000
    wait_time_ms: 57.907
  iterations_since_restore: 1
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 20.041779279708862
  time_this_iter_s: 20.041779279708862
  time_total_s: 20.041779279708862
  timestamp: 1593821118
  timesteps_since_restore: 3000
  timesteps_this_iter: 3000
  timesteps_total: 3000
  training_iteration: 1
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 11.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 20 s, 1 iter, 3000 ts, nan rew

[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
agent-1: 63.0
agent-2: 61.0
agent-3: 69.0
Sum Reward: 193.0
Avg Reward: 64.33333333333333
Min Reward: 61.0
Gini Coefficient 0.027633851468048358
[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
agent-1: 78.0
agent-2: 80.0
agent-3: 67.0
Sum Reward: 225.0
Avg Reward: 75.0
Min Reward: 67.0
Gini Coefficient 0.03851851851851852
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-05-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 225.0
  episode_reward_mean: 209.0
  episode_reward_min: 193.0
  episodes_this_iter: 2
  episodes_total: 2
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 3.138
    dispatch_time_ms: 9.161
    learner:
      cur_lr: 0.0013598002260550857
      grad_gnorm: 40.0
      policy_entropy: 44.46446228027344
      policy_loss: -109.15755462646484
      var_gnorm: 18.081846237182617
      vf_explained_var: -0.18870270252227783
      vf_loss: 124.34962463378906
    num_steps_sampled: 6000
    num_steps_trained: 6000
    wait_time_ms: 58.102
  iterations_since_restore: 2
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 27.11126971244812
  time_this_iter_s: 7.069490432739258
  time_total_s: 27.11126971244812
  timestamp: 1593821125
  timesteps_since_restore: 6000
  timesteps_this_iter: 3000
  timesteps_total: 6000
  training_iteration: 2
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 12.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 27 s, 2 iter, 6000 ts, 209 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-05-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 225.0
  episode_reward_mean: 209.0
  episode_reward_min: 193.0
  episodes_this_iter: 0
  episodes_total: 2
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 2.7
    dispatch_time_ms: 8.976
    learner:
      cur_lr: 0.0013596004573628306
      grad_gnorm: 39.99999237060547
      policy_entropy: 40.7531852722168
      policy_loss: 49.066192626953125
      var_gnorm: 18.265607833862305
      vf_explained_var: 0.37119847536087036
      vf_loss: 39.472747802734375
    num_steps_sampled: 9000
    num_steps_trained: 9000
    wait_time_ms: 60.887
  iterations_since_restore: 3
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 34.014020919799805
  time_this_iter_s: 6.902751207351685
  time_total_s: 34.014020919799805
  timestamp: 1593821132
  timesteps_since_restore: 9000
  timesteps_this_iter: 3000
  timesteps_total: 9000
  training_iteration: 3
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 12.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 34 s, 3 iter, 9000 ts, 209 rew

agent-1: 108.0
agent-2: -6.0
agent-3: 24.0
Sum Reward: 126.0
Avg Reward: 42.0
Min Reward: -6.0
Gini Coefficient 0.6031746031746031
agent-1: 40.0
agent-2: 118.0
agent-3: 145.0
Sum Reward: 303.0
Avg Reward: 101.0
Min Reward: 40.0
Gini Coefficient 0.23102310231023102
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-05-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 303.0
  episode_reward_mean: 211.75
  episode_reward_min: 126.0
  episodes_this_iter: 2
  episodes_total: 4
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 2.749
    dispatch_time_ms: 9.605
    learner:
      cur_lr: 0.0013594005722552538
      grad_gnorm: 40.0
      policy_entropy: 37.76544189453125
      policy_loss: -340.8888244628906
      var_gnorm: 18.469411849975586
      vf_explained_var: -0.33058953285217285
      vf_loss: 1362.9515380859375
    num_steps_sampled: 12000
    num_steps_trained: 12000
    wait_time_ms: 62.22
  iterations_since_restore: 4
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 41.29620885848999
  time_this_iter_s: 7.2821879386901855
  time_total_s: 41.29620885848999
  timestamp: 1593821140
  timesteps_since_restore: 12000
  timesteps_this_iter: 3000
  timesteps_total: 12000
  training_iteration: 4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 12.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 41 s, 4 iter, 12000 ts, 212 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-05-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 303.0
  episode_reward_mean: 211.75
  episode_reward_min: 126.0
  episodes_this_iter: 0
  episodes_total: 4
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 3.231
    dispatch_time_ms: 7.341
    learner:
      cur_lr: 0.0013592008035629988
      grad_gnorm: 39.999996185302734
      policy_entropy: 27.867752075195312
      policy_loss: -10.824804306030273
      var_gnorm: 18.738906860351562
      vf_explained_var: -0.0962914228439331
      vf_loss: 11.84528923034668
    num_steps_sampled: 15000
    num_steps_trained: 15000
    wait_time_ms: 64.061
  iterations_since_restore: 5
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 48.65322184562683
  time_this_iter_s: 7.357012987136841
  time_total_s: 48.65322184562683
  timestamp: 1593821147
  timesteps_since_restore: 15000
  timesteps_this_iter: 3000
  timesteps_total: 15000
  training_iteration: 5
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 48 s, 5 iter, 15000 ts, 212 rew

agent-1: 175.0
agent-2: 177.0
agent-3: 165.0
Sum Reward: 517.0
Avg Reward: 172.33333333333334
Min Reward: 165.0
Gini Coefficient 0.015473887814313346
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-05-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 517.0
  episode_reward_mean: 272.8
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 5
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 2.682
    dispatch_time_ms: 10.087
    learner:
      cur_lr: 0.0013590010348707438
      grad_gnorm: 40.00002670288086
      policy_entropy: 37.48497009277344
      policy_loss: 1.4253129959106445
      var_gnorm: 18.97035026550293
      vf_explained_var: -0.525488018989563
      vf_loss: 7.531201362609863
    num_steps_sampled: 18000
    num_steps_trained: 18000
    wait_time_ms: 65.005
  iterations_since_restore: 6
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 56.38182616233826
  time_this_iter_s: 7.728604316711426
  time_total_s: 56.38182616233826
  timestamp: 1593821155
  timesteps_since_restore: 18000
  timesteps_this_iter: 3000
  timesteps_total: 18000
  training_iteration: 6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 56 s, 6 iter, 18000 ts, 273 rew

agent-1: 169.0
agent-2: 144.0
agent-3: 155.0
Sum Reward: 468.0
Avg Reward: 156.0
Min Reward: 144.0
Gini Coefficient 0.03561253561253561
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-06-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 517.0
  episode_reward_mean: 305.3333333333333
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 6
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 3.692
    dispatch_time_ms: 6.832
    learner:
      cur_lr: 0.001358801149763167
      grad_gnorm: 40.00001525878906
      policy_entropy: 29.15936279296875
      policy_loss: -9.128825187683105
      var_gnorm: 19.127216339111328
      vf_explained_var: -0.023737072944641113
      vf_loss: 13.278827667236328
    num_steps_sampled: 21000
    num_steps_trained: 21000
    wait_time_ms: 68.826
  iterations_since_restore: 7
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 63.68321108818054
  time_this_iter_s: 7.301384925842285
  time_total_s: 63.68321108818054
  timestamp: 1593821162
  timesteps_since_restore: 21000
  timesteps_this_iter: 3000
  timesteps_total: 21000
  training_iteration: 7
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 63 s, 7 iter, 21000 ts, 305 rew

agent-1: 209.0
agent-2: 217.0
agent-3: 252.0
Sum Reward: 678.0
Avg Reward: 226.0
Min Reward: 209.0
Gini Coefficient 0.04228121927236971
agent-1: 191.0
agent-2: 215.0
agent-3: 213.0
Sum Reward: 619.0
Avg Reward: 206.33333333333334
Min Reward: 191.0
Gini Coefficient 0.025848142164781908
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-06-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 678.0
  episode_reward_mean: 391.125
  episode_reward_min: 126.0
  episodes_this_iter: 2
  episodes_total: 8
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 3.421
    dispatch_time_ms: 9.054
    learner:
      cur_lr: 0.0013586013810709119
      grad_gnorm: 40.00001525878906
      policy_entropy: 31.031497955322266
      policy_loss: -6.121461391448975
      var_gnorm: 19.314105987548828
      vf_explained_var: 0.3048652410507202
      vf_loss: 19.987878799438477
    num_steps_sampled: 24000
    num_steps_trained: 24000
    wait_time_ms: 65.203
  iterations_since_restore: 8
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 71.41107726097107
  time_this_iter_s: 7.727866172790527
  time_total_s: 71.41107726097107
  timestamp: 1593821170
  timesteps_since_restore: 24000
  timesteps_this_iter: 3000
  timesteps_total: 24000
  training_iteration: 8
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 71 s, 8 iter, 24000 ts, 391 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-06-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 678.0
  episode_reward_mean: 391.125
  episode_reward_min: 126.0
  episodes_this_iter: 0
  episodes_total: 8
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 4.072
    dispatch_time_ms: 9.48
    learner:
      cur_lr: 0.0013584016123786569
      grad_gnorm: 34.35772705078125
      policy_entropy: 23.71396827697754
      policy_loss: -5.241077423095703
      var_gnorm: 19.420286178588867
      vf_explained_var: 0.40818601846694946
      vf_loss: 7.906785488128662
    num_steps_sampled: 27000
    num_steps_trained: 27000
    wait_time_ms: 62.652
  iterations_since_restore: 9
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 78.56678676605225
  time_this_iter_s: 7.155709505081177
  time_total_s: 78.56678676605225
  timestamp: 1593821177
  timesteps_since_restore: 27000
  timesteps_this_iter: 3000
  timesteps_total: 27000
  training_iteration: 9
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 78 s, 9 iter, 27000 ts, 391 rew

agent-1: 241.0
agent-2: 210.0
agent-3: 223.0
Sum Reward: 674.0
Avg Reward: 224.66666666666666
Min Reward: 210.0
Gini Coefficient 0.03066271018793274
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-06-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 678.0
  episode_reward_mean: 422.55555555555554
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 9
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 3.287
    dispatch_time_ms: 8.224
    learner:
      cur_lr: 0.0013582018436864018
      grad_gnorm: 40.0
      policy_entropy: 28.305191040039062
      policy_loss: 18.38601303100586
      var_gnorm: 19.53070068359375
      vf_explained_var: -0.25328660011291504
      vf_loss: 56.469444274902344
    num_steps_sampled: 30000
    num_steps_trained: 30000
    wait_time_ms: 65.963
  iterations_since_restore: 10
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 86.30429363250732
  time_this_iter_s: 7.737506866455078
  time_total_s: 86.30429363250732
  timestamp: 1593821185
  timesteps_since_restore: 30000
  timesteps_this_iter: 3000
  timesteps_total: 30000
  training_iteration: 10
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 86 s, 10 iter, 30000 ts, 423 rew

agent-1: 240.0
agent-2: 197.0
agent-3: 199.0
Sum Reward: 636.0
Avg Reward: 212.0
Min Reward: 197.0
Gini Coefficient 0.04507337526205451
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-06-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 678.0
  episode_reward_mean: 443.9
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 10
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 2.613
    dispatch_time_ms: 10.158
    learner:
      cur_lr: 0.001358001958578825
      grad_gnorm: 40.0
      policy_entropy: 30.02301788330078
      policy_loss: -26.918228149414062
      var_gnorm: 19.592205047607422
      vf_explained_var: 0.11337870359420776
      vf_loss: 20.339065551757812
    num_steps_sampled: 33000
    num_steps_trained: 33000
    wait_time_ms: 65.639
  iterations_since_restore: 11
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 93.93056607246399
  time_this_iter_s: 7.626272439956665
  time_total_s: 93.93056607246399
  timestamp: 1593821192
  timesteps_since_restore: 33000
  timesteps_this_iter: 3000
  timesteps_total: 33000
  training_iteration: 11
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 93 s, 11 iter, 33000 ts, 444 rew

agent-1: 162.0
agent-2: 199.0
agent-3: 222.0
Sum Reward: 583.0
Avg Reward: 194.33333333333334
Min Reward: 162.0
Gini Coefficient 0.0686106346483705
agent-1: 136.0
agent-2: 203.0
agent-3: 192.0
Sum Reward: 531.0
Avg Reward: 177.0
Min Reward: 136.0
Gini Coefficient 0.08411801632140616
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-06-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 678.0
  episode_reward_mean: 462.75
  episode_reward_min: 126.0
  episodes_this_iter: 2
  episodes_total: 12
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 3.197
    dispatch_time_ms: 8.239
    learner:
      cur_lr: 0.00135780218988657
      grad_gnorm: 39.9999885559082
      policy_entropy: 26.032773971557617
      policy_loss: -392.10833740234375
      var_gnorm: 19.75298309326172
      vf_explained_var: 0.5805039405822754
      vf_loss: 4064.646240234375
    num_steps_sampled: 36000
    num_steps_trained: 36000
    wait_time_ms: 76.447
  iterations_since_restore: 12
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 102.35946106910706
  time_this_iter_s: 8.428894996643066
  time_total_s: 102.35946106910706
  timestamp: 1593821201
  timesteps_since_restore: 36000
  timesteps_this_iter: 3000
  timesteps_total: 36000
  training_iteration: 12
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 102 s, 12 iter, 36000 ts, 463 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-06-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 678.0
  episode_reward_mean: 462.75
  episode_reward_min: 126.0
  episodes_this_iter: 0
  episodes_total: 12
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 2.709
    dispatch_time_ms: 8.124
    learner:
      cur_lr: 0.001357602421194315
      grad_gnorm: 40.0
      policy_entropy: 25.696569442749023
      policy_loss: 18.037662506103516
      var_gnorm: 19.96967887878418
      vf_explained_var: 0.35060012340545654
      vf_loss: 37.84040069580078
    num_steps_sampled: 39000
    num_steps_trained: 39000
    wait_time_ms: 62.523
  iterations_since_restore: 13
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 109.60774278640747
  time_this_iter_s: 7.248281717300415
  time_total_s: 109.60774278640747
  timestamp: 1593821208
  timesteps_since_restore: 39000
  timesteps_this_iter: 3000
  timesteps_total: 39000
  training_iteration: 13
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 109 s, 13 iter, 39000 ts, 463 rew

agent-1: 260.0
agent-2: 225.0
agent-3: 269.0
Sum Reward: 754.0
Avg Reward: 251.33333333333334
Min Reward: 225.0
Gini Coefficient 0.038903625110521665
agent-1: 257.0
agent-2: 177.0
agent-3: 239.0
Sum Reward: 673.0
Avg Reward: 224.33333333333334
Min Reward: 177.0
Gini Coefficient 0.079247152055473
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-06-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 754.0
  episode_reward_mean: 498.57142857142856
  episode_reward_min: 126.0
  episodes_this_iter: 2
  episodes_total: 14
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 3.79
    dispatch_time_ms: 6.485
    learner:
      cur_lr: 0.00135740265250206
      grad_gnorm: 40.000003814697266
      policy_entropy: 31.06138038635254
      policy_loss: -730.5953979492188
      var_gnorm: 20.12947654724121
      vf_explained_var: 0.1221194863319397
      vf_loss: 6261.306640625
    num_steps_sampled: 42000
    num_steps_trained: 42000
    wait_time_ms: 70.7
  iterations_since_restore: 14
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 117.48134136199951
  time_this_iter_s: 7.873598575592041
  time_total_s: 117.48134136199951
  timestamp: 1593821216
  timesteps_since_restore: 42000
  timesteps_this_iter: 3000
  timesteps_total: 42000
  training_iteration: 14
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 117 s, 14 iter, 42000 ts, 499 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-07-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 754.0
  episode_reward_mean: 498.57142857142856
  episode_reward_min: 126.0
  episodes_this_iter: 0
  episodes_total: 14
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 3.319
    dispatch_time_ms: 6.671
    learner:
      cur_lr: 0.001357202767394483
      grad_gnorm: 40.00001525878906
      policy_entropy: 22.55888557434082
      policy_loss: 10.02126407623291
      var_gnorm: 20.25167465209961
      vf_explained_var: 0.26178300380706787
      vf_loss: 31.414051055908203
    num_steps_sampled: 45000
    num_steps_trained: 45000
    wait_time_ms: 68.622
  iterations_since_restore: 15
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 124.90858817100525
  time_this_iter_s: 7.427246809005737
  time_total_s: 124.90858817100525
  timestamp: 1593821224
  timesteps_since_restore: 45000
  timesteps_this_iter: 3000
  timesteps_total: 45000
  training_iteration: 15
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 124 s, 15 iter, 45000 ts, 499 rew

agent-1: 230.0
agent-2: 255.0
agent-3: 236.0
Sum Reward: 721.0
Avg Reward: 240.33333333333334
Min Reward: 230.0
Gini Coefficient 0.02311604253351826
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-07-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 754.0
  episode_reward_mean: 513.4
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 15
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 2.941
    dispatch_time_ms: 6.651
    learner:
      cur_lr: 0.001357002998702228
      grad_gnorm: 40.00001525878906
      policy_entropy: 17.162174224853516
      policy_loss: -3.185271739959717
      var_gnorm: 20.350696563720703
      vf_explained_var: 0.3625726103782654
      vf_loss: 7.083258628845215
    num_steps_sampled: 48000
    num_steps_trained: 48000
    wait_time_ms: 69.733
  iterations_since_restore: 16
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 132.6679184436798
  time_this_iter_s: 7.7593302726745605
  time_total_s: 132.6679184436798
  timestamp: 1593821231
  timesteps_since_restore: 48000
  timesteps_this_iter: 3000
  timesteps_total: 48000
  training_iteration: 16
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 132 s, 16 iter, 48000 ts, 513 rew

agent-1: 249.0
agent-2: 240.0
agent-3: 246.0
Sum Reward: 735.0
Avg Reward: 245.0
Min Reward: 240.0
Gini Coefficient 0.00816326530612245
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-07-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 754.0
  episode_reward_mean: 527.25
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 16
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 3.098
    dispatch_time_ms: 11.892
    learner:
      cur_lr: 0.001356803230009973
      grad_gnorm: 39.99999237060547
      policy_entropy: 23.272581100463867
      policy_loss: 5.594995021820068
      var_gnorm: 20.461341857910156
      vf_explained_var: 0.0007268190383911133
      vf_loss: 11.064971923828125
    num_steps_sampled: 51000
    num_steps_trained: 51000
    wait_time_ms: 62.598
  iterations_since_restore: 17
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 140.0129909515381
  time_this_iter_s: 7.345072507858276
  time_total_s: 140.0129909515381
  timestamp: 1593821239
  timesteps_since_restore: 51000
  timesteps_this_iter: 3000
  timesteps_total: 51000
  training_iteration: 17
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 140 s, 17 iter, 51000 ts, 527 rew

agent-1: 266.0
agent-2: 260.0
agent-3: 251.0
Sum Reward: 777.0
Avg Reward: 259.0
Min Reward: 251.0
Gini Coefficient 0.01287001287001287
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-07-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 777.0
  episode_reward_mean: 541.9411764705883
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 17
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 2.937
    dispatch_time_ms: 9.324
    learner:
      cur_lr: 0.0013566033449023962
      grad_gnorm: 40.00000762939453
      policy_entropy: 22.40226173400879
      policy_loss: 3.628619909286499
      var_gnorm: 20.566316604614258
      vf_explained_var: 0.18771004676818848
      vf_loss: 24.711034774780273
    num_steps_sampled: 54000
    num_steps_trained: 54000
    wait_time_ms: 65.334
  iterations_since_restore: 18
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 148.01907658576965
  time_this_iter_s: 8.006085634231567
  time_total_s: 148.01907658576965
  timestamp: 1593821247
  timesteps_since_restore: 54000
  timesteps_this_iter: 3000
  timesteps_total: 54000
  training_iteration: 18
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 148 s, 18 iter, 54000 ts, 542 rew

agent-1: 234.0
agent-2: 222.0
agent-3: 256.0
Sum Reward: 712.0
Avg Reward: 237.33333333333334
Min Reward: 222.0
Gini Coefficient 0.031835205992509365
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-07-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 777.0
  episode_reward_mean: 551.3888888888889
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 18
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 3.721
    dispatch_time_ms: 6.022
    learner:
      cur_lr: 0.0013564035762101412
      grad_gnorm: 40.0
      policy_entropy: 16.62164306640625
      policy_loss: 18.07415199279785
      var_gnorm: 20.666316986083984
      vf_explained_var: -0.08734333515167236
      vf_loss: 33.078975677490234
    num_steps_sampled: 57000
    num_steps_trained: 57000
    wait_time_ms: 70.116
  iterations_since_restore: 19
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 155.784982919693
  time_this_iter_s: 7.76590633392334
  time_total_s: 155.784982919693
  timestamp: 1593821255
  timesteps_since_restore: 57000
  timesteps_this_iter: 3000
  timesteps_total: 57000
  training_iteration: 19
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 155 s, 19 iter, 57000 ts, 551 rew

agent-1: 265.0
agent-2: 264.0
agent-3: 234.0
Sum Reward: 763.0
Avg Reward: 254.33333333333334
Min Reward: 234.0
Gini Coefficient 0.02708606378331149
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-07-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 777.0
  episode_reward_mean: 562.5263157894736
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 19
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 3.783
    dispatch_time_ms: 8.986
    learner:
      cur_lr: 0.0013562038075178862
      grad_gnorm: 40.000003814697266
      policy_entropy: 23.097469329833984
      policy_loss: -13.205080032348633
      var_gnorm: 20.762386322021484
      vf_explained_var: 0.2671395540237427
      vf_loss: 36.66184997558594
    num_steps_sampled: 60000
    num_steps_trained: 60000
    wait_time_ms: 68.122
  iterations_since_restore: 20
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 163.76490902900696
  time_this_iter_s: 7.979926109313965
  time_total_s: 163.76490902900696
  timestamp: 1593821263
  timesteps_since_restore: 60000
  timesteps_this_iter: 3000
  timesteps_total: 60000
  training_iteration: 20
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 163 s, 20 iter, 60000 ts, 563 rew

agent-1: 259.0
agent-2: 208.0
agent-3: 244.0
Sum Reward: 711.0
Avg Reward: 237.0
Min Reward: 208.0
Gini Coefficient 0.04781997187060478
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-07-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 777.0
  episode_reward_mean: 569.95
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 20
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 2.975
    dispatch_time_ms: 9.262
    learner:
      cur_lr: 0.0013560040388256311
      grad_gnorm: 40.0
      policy_entropy: 14.367135047912598
      policy_loss: 12.041860580444336
      var_gnorm: 20.892662048339844
      vf_explained_var: 0.00119858980178833
      vf_loss: 16.454872131347656
    num_steps_sampled: 63000
    num_steps_trained: 63000
    wait_time_ms: 68.352
  iterations_since_restore: 21
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 171.3322536945343
  time_this_iter_s: 7.567344665527344
  time_total_s: 171.3322536945343
  timestamp: 1593821270
  timesteps_since_restore: 63000
  timesteps_this_iter: 3000
  timesteps_total: 63000
  training_iteration: 21
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 171 s, 21 iter, 63000 ts, 570 rew

agent-1: 247.0
agent-2: 248.0
agent-3: 277.0
Sum Reward: 772.0
Avg Reward: 257.3333333333333
Min Reward: 247.0
Gini Coefficient 0.025906735751295335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-07-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 777.0
  episode_reward_mean: 579.5714285714286
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 21
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 3.179
    dispatch_time_ms: 10.232
    learner:
      cur_lr: 0.0013558041537180543
      grad_gnorm: 40.00003433227539
      policy_entropy: 17.673290252685547
      policy_loss: -9.749046325683594
      var_gnorm: 21.06851577758789
      vf_explained_var: 0.2571954131126404
      vf_loss: 28.564456939697266
    num_steps_sampled: 66000
    num_steps_trained: 66000
    wait_time_ms: 66.216
  iterations_since_restore: 22
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 179.47275590896606
  time_this_iter_s: 8.140502214431763
  time_total_s: 179.47275590896606
  timestamp: 1593821278
  timesteps_since_restore: 66000
  timesteps_this_iter: 3000
  timesteps_total: 66000
  training_iteration: 22
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 179 s, 22 iter, 66000 ts, 580 rew

agent-1: 243.0
agent-2: 196.0
agent-3: 256.0
Sum Reward: 695.0
Avg Reward: 231.66666666666666
Min Reward: 196.0
Gini Coefficient 0.05755395683453238
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-08-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 777.0
  episode_reward_mean: 584.8181818181819
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 22
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 2.578
    dispatch_time_ms: 10.728
    learner:
      cur_lr: 0.0013556043850257993
      grad_gnorm: 40.00000762939453
      policy_entropy: 23.41352081298828
      policy_loss: -14.740365028381348
      var_gnorm: 21.25670623779297
      vf_explained_var: -0.09772300720214844
      vf_loss: 15.956537246704102
    num_steps_sampled: 69000
    num_steps_trained: 69000
    wait_time_ms: 66.095
  iterations_since_restore: 23
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 187.11382603645325
  time_this_iter_s: 7.641070127487183
  time_total_s: 187.11382603645325
  timestamp: 1593821286
  timesteps_since_restore: 69000
  timesteps_this_iter: 3000
  timesteps_total: 69000
  training_iteration: 23
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 187 s, 23 iter, 69000 ts, 585 rew

agent-1: 249.0
agent-2: 182.0
agent-3: 261.0
Sum Reward: 692.0
Avg Reward: 230.66666666666666
Min Reward: 182.0
Gini Coefficient 0.07610789980732177
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-08-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 777.0
  episode_reward_mean: 589.4782608695652
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 23
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 2.564
    dispatch_time_ms: 9.736
    learner:
      cur_lr: 0.0013554046163335443
      grad_gnorm: 40.00001525878906
      policy_entropy: 13.872742652893066
      policy_loss: 0.0361170768737793
      var_gnorm: 21.513147354125977
      vf_explained_var: 0.6663011312484741
      vf_loss: 31.90241813659668
    num_steps_sampled: 72000
    num_steps_trained: 72000
    wait_time_ms: 68.009
  iterations_since_restore: 24
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 195.44440412521362
  time_this_iter_s: 8.330578088760376
  time_total_s: 195.44440412521362
  timestamp: 1593821294
  timesteps_since_restore: 72000
  timesteps_this_iter: 3000
  timesteps_total: 72000
  training_iteration: 24
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 195 s, 24 iter, 72000 ts, 589 rew

agent-1: 211.0
agent-2: 244.0
agent-3: 287.0
Sum Reward: 742.0
Avg Reward: 247.33333333333334
Min Reward: 211.0
Gini Coefficient 0.06828391734052111
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-08-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 777.0
  episode_reward_mean: 595.8333333333334
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 24
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 3.569
    dispatch_time_ms: 11.319
    learner:
      cur_lr: 0.0013552048476412892
      grad_gnorm: 39.9999885559082
      policy_entropy: 17.069629669189453
      policy_loss: -10.416221618652344
      var_gnorm: 21.835947036743164
      vf_explained_var: -0.24540770053863525
      vf_loss: 38.961402893066406
    num_steps_sampled: 75000
    num_steps_trained: 75000
    wait_time_ms: 64.218
  iterations_since_restore: 25
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 203.19184851646423
  time_this_iter_s: 7.74744439125061
  time_total_s: 203.19184851646423
  timestamp: 1593821302
  timesteps_since_restore: 75000
  timesteps_this_iter: 3000
  timesteps_total: 75000
  training_iteration: 25
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 203 s, 25 iter, 75000 ts, 596 rew

agent-1: 277.0
agent-2: 255.0
agent-3: 285.0
Sum Reward: 817.0
Avg Reward: 272.3333333333333
Min Reward: 255.0
Gini Coefficient 0.02447980416156671
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-08-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 817.0
  episode_reward_mean: 604.68
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 25
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 2.911
    dispatch_time_ms: 8.325
    learner:
      cur_lr: 0.0013550049625337124
      grad_gnorm: 39.999996185302734
      policy_entropy: 27.441354751586914
      policy_loss: 5.525314807891846
      var_gnorm: 22.216205596923828
      vf_explained_var: 0.5463395118713379
      vf_loss: 37.49371337890625
    num_steps_sampled: 78000
    num_steps_trained: 78000
    wait_time_ms: 74.314
  iterations_since_restore: 26
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 211.55241990089417
  time_this_iter_s: 8.360571384429932
  time_total_s: 211.55241990089417
  timestamp: 1593821311
  timesteps_since_restore: 78000
  timesteps_this_iter: 3000
  timesteps_total: 78000
  training_iteration: 26
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 211 s, 26 iter, 78000 ts, 605 rew

agent-1: 257.0
agent-2: 229.0
agent-3: 239.0
Sum Reward: 725.0
Avg Reward: 241.66666666666666
Min Reward: 229.0
Gini Coefficient 0.02574712643678161
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-08-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 817.0
  episode_reward_mean: 609.3076923076923
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 26
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 3.388
    dispatch_time_ms: 9.67
    learner:
      cur_lr: 0.0013548051938414574
      grad_gnorm: 39.99999237060547
      policy_entropy: 21.855594635009766
      policy_loss: 17.667165756225586
      var_gnorm: 22.3631591796875
      vf_explained_var: 0.4885234832763672
      vf_loss: 17.066585540771484
    num_steps_sampled: 81000
    num_steps_trained: 81000
    wait_time_ms: 63.807
  iterations_since_restore: 27
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 219.10695719718933
  time_this_iter_s: 7.554537296295166
  time_total_s: 219.10695719718933
  timestamp: 1593821318
  timesteps_since_restore: 81000
  timesteps_this_iter: 3000
  timesteps_total: 81000
  training_iteration: 27
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 219 s, 27 iter, 81000 ts, 609 rew

agent-1: 228.0
agent-2: 265.0
agent-3: 297.0
Sum Reward: 790.0
Avg Reward: 263.3333333333333
Min Reward: 228.0
Gini Coefficient 0.05822784810126582
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-08-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 817.0
  episode_reward_mean: 616.0
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 27
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 2.434
    dispatch_time_ms: 7.387
    learner:
      cur_lr: 0.0013546054251492023
      grad_gnorm: 40.000038146972656
      policy_entropy: 19.076343536376953
      policy_loss: -1.0055487155914307
      var_gnorm: 22.47215461730957
      vf_explained_var: 0.1805827021598816
      vf_loss: 13.238093376159668
    num_steps_sampled: 84000
    num_steps_trained: 84000
    wait_time_ms: 69.966
  iterations_since_restore: 28
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 227.32720232009888
  time_this_iter_s: 8.220245122909546
  time_total_s: 227.32720232009888
  timestamp: 1593821326
  timesteps_since_restore: 84000
  timesteps_this_iter: 3000
  timesteps_total: 84000
  training_iteration: 28
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 227 s, 28 iter, 84000 ts, 616 rew

agent-1: 249.0
agent-2: 269.0
agent-3: 188.0
Sum Reward: 706.0
Avg Reward: 235.33333333333334
Min Reward: 188.0
Gini Coefficient 0.0764872521246459
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-08-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 817.0
  episode_reward_mean: 619.2142857142857
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 28
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 2.641
    dispatch_time_ms: 9.688
    learner:
      cur_lr: 0.0013544056564569473
      grad_gnorm: 40.00000762939453
      policy_entropy: 13.267511367797852
      policy_loss: -21.748682022094727
      var_gnorm: 22.593149185180664
      vf_explained_var: -0.2586466073989868
      vf_loss: 46.40269470214844
    num_steps_sampled: 87000
    num_steps_trained: 87000
    wait_time_ms: 70.627
  iterations_since_restore: 29
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 235.25521731376648
  time_this_iter_s: 7.9280149936676025
  time_total_s: 235.25521731376648
  timestamp: 1593821334
  timesteps_since_restore: 87000
  timesteps_this_iter: 3000
  timesteps_total: 87000
  training_iteration: 29
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 235 s, 29 iter, 87000 ts, 619 rew

agent-1: 220.0
agent-2: 273.0
agent-3: 279.0
Sum Reward: 772.0
Avg Reward: 257.3333333333333
Min Reward: 220.0
Gini Coefficient 0.05094991364421416
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-09-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 817.0
  episode_reward_mean: 624.4827586206897
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 29
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 3.224
    dispatch_time_ms: 8.527
    learner:
      cur_lr: 0.0013542057713493705
      grad_gnorm: 39.99999237060547
      policy_entropy: 13.448362350463867
      policy_loss: -0.9624550342559814
      var_gnorm: 22.669954299926758
      vf_explained_var: 0.72554612159729
      vf_loss: 23.428171157836914
    num_steps_sampled: 90000
    num_steps_trained: 90000
    wait_time_ms: 62.827
  iterations_since_restore: 30
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 243.38160490989685
  time_this_iter_s: 8.126387596130371
  time_total_s: 243.38160490989685
  timestamp: 1593821343
  timesteps_since_restore: 90000
  timesteps_this_iter: 3000
  timesteps_total: 90000
  training_iteration: 30
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 243 s, 30 iter, 90000 ts, 624 rew

agent-1: 234.0
agent-2: 242.0
agent-3: 280.0
Sum Reward: 756.0
Avg Reward: 252.0
Min Reward: 234.0
Gini Coefficient 0.04056437389770723
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-09-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 817.0
  episode_reward_mean: 628.8666666666667
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 30
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 3.173
    dispatch_time_ms: 5.81
    learner:
      cur_lr: 0.0013540060026571155
      grad_gnorm: 40.000030517578125
      policy_entropy: 26.37232208251953
      policy_loss: 11.335981369018555
      var_gnorm: 22.807626724243164
      vf_explained_var: 0.06557482481002808
      vf_loss: 23.127363204956055
    num_steps_sampled: 93000
    num_steps_trained: 93000
    wait_time_ms: 71.818
  iterations_since_restore: 31
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 251.2366156578064
  time_this_iter_s: 7.855010747909546
  time_total_s: 251.2366156578064
  timestamp: 1593821350
  timesteps_since_restore: 93000
  timesteps_this_iter: 3000
  timesteps_total: 93000
  training_iteration: 31
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 251 s, 31 iter, 93000 ts, 629 rew

agent-1: 249.0
agent-2: 261.0
agent-3: 284.0
Sum Reward: 794.0
Avg Reward: 264.6666666666667
Min Reward: 249.0
Gini Coefficient 0.02938706968933669
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-09-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 817.0
  episode_reward_mean: 634.1935483870968
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 31
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 3.198
    dispatch_time_ms: 8.708
    learner:
      cur_lr: 0.0013538062339648604
      grad_gnorm: 39.9999885559082
      policy_entropy: 5.323705673217773
      policy_loss: -12.958840370178223
      var_gnorm: 22.911678314208984
      vf_explained_var: 0.3128291964530945
      vf_loss: 13.899271011352539
    num_steps_sampled: 96000
    num_steps_trained: 96000
    wait_time_ms: 72.854
  iterations_since_restore: 32
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 259.76369166374207
  time_this_iter_s: 8.527076005935669
  time_total_s: 259.76369166374207
  timestamp: 1593821359
  timesteps_since_restore: 96000
  timesteps_this_iter: 3000
  timesteps_total: 96000
  training_iteration: 32
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 259 s, 32 iter, 96000 ts, 634 rew

agent-1: 198.0
agent-2: 211.0
agent-3: 262.0
Sum Reward: 671.0
Avg Reward: 223.66666666666666
Min Reward: 198.0
Gini Coefficient 0.06358668653750621
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-09-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 817.0
  episode_reward_mean: 635.34375
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 32
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 2.381
    dispatch_time_ms: 9.171
    learner:
      cur_lr: 0.0013536063488572836
      grad_gnorm: 40.0000114440918
      policy_entropy: 23.55529022216797
      policy_loss: -16.619338989257812
      var_gnorm: 23.124826431274414
      vf_explained_var: 0.09389960765838623
      vf_loss: 29.028671264648438
    num_steps_sampled: 99000
    num_steps_trained: 99000
    wait_time_ms: 64.933
  iterations_since_restore: 33
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 267.6888692378998
  time_this_iter_s: 7.925177574157715
  time_total_s: 267.6888692378998
  timestamp: 1593821367
  timesteps_since_restore: 99000
  timesteps_this_iter: 3000
  timesteps_total: 99000
  training_iteration: 33
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 267 s, 33 iter, 99000 ts, 635 rew

agent-1: 220.0
agent-2: 269.0
agent-3: 251.0
Sum Reward: 740.0
Avg Reward: 246.66666666666666
Min Reward: 220.0
Gini Coefficient 0.044144144144144144
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-09-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 817.0
  episode_reward_mean: 638.5151515151515
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 33
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 2.464
    dispatch_time_ms: 7.422
    learner:
      cur_lr: 0.0013534065801650286
      grad_gnorm: 40.0
      policy_entropy: 8.28326416015625
      policy_loss: 11.141704559326172
      var_gnorm: 23.257570266723633
      vf_explained_var: 0.1957486867904663
      vf_loss: 38.62138748168945
    num_steps_sampled: 102000
    num_steps_trained: 102000
    wait_time_ms: 70.998
  iterations_since_restore: 34
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 275.6074755191803
  time_this_iter_s: 7.918606281280518
  time_total_s: 275.6074755191803
  timestamp: 1593821375
  timesteps_since_restore: 102000
  timesteps_this_iter: 3000
  timesteps_total: 102000
  training_iteration: 34
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 275 s, 34 iter, 102000 ts, 639 rew

agent-1: 258.0
agent-2: 274.0
agent-3: 260.0
Sum Reward: 792.0
Avg Reward: 264.0
Min Reward: 258.0
Gini Coefficient 0.013468013468013467
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-09-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 817.0
  episode_reward_mean: 643.0294117647059
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 34
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 3.026
    dispatch_time_ms: 10.131
    learner:
      cur_lr: 0.0013532068114727736
      grad_gnorm: 40.00000762939453
      policy_entropy: 21.08074378967285
      policy_loss: -0.31600716710090637
      var_gnorm: 23.352985382080078
      vf_explained_var: 0.7453294992446899
      vf_loss: 15.747499465942383
    num_steps_sampled: 105000
    num_steps_trained: 105000
    wait_time_ms: 69.835
  iterations_since_restore: 35
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 283.41453409194946
  time_this_iter_s: 7.807058572769165
  time_total_s: 283.41453409194946
  timestamp: 1593821383
  timesteps_since_restore: 105000
  timesteps_this_iter: 3000
  timesteps_total: 105000
  training_iteration: 35
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 283 s, 35 iter, 105000 ts, 643 rew

agent-1: 297.0
agent-2: 277.0
agent-3: 266.0
Sum Reward: 840.0
Avg Reward: 280.0
Min Reward: 266.0
Gini Coefficient 0.024603174603174603
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-09-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 840.0
  episode_reward_mean: 648.6571428571428
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 35
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 3.252
    dispatch_time_ms: 7.178
    learner:
      cur_lr: 0.0013530070427805185
      grad_gnorm: 40.0
      policy_entropy: 23.996660232543945
      policy_loss: -13.80124282836914
      var_gnorm: 23.50423240661621
      vf_explained_var: 0.6516777276992798
      vf_loss: 36.83705139160156
    num_steps_sampled: 108000
    num_steps_trained: 108000
    wait_time_ms: 74.99
  iterations_since_restore: 36
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 291.6900703907013
  time_this_iter_s: 8.275536298751831
  time_total_s: 291.6900703907013
  timestamp: 1593821391
  timesteps_since_restore: 108000
  timesteps_this_iter: 3000
  timesteps_total: 108000
  training_iteration: 36
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 291 s, 36 iter, 108000 ts, 649 rew

agent-1: 229.0
agent-2: 214.0
agent-3: 232.0
Sum Reward: 675.0
Avg Reward: 225.0
Min Reward: 214.0
Gini Coefficient 0.017777777777777778
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-09-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 840.0
  episode_reward_mean: 649.3888888888889
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 36
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 3.316
    dispatch_time_ms: 8.268
    learner:
      cur_lr: 0.0013528071576729417
      grad_gnorm: 40.000003814697266
      policy_entropy: 19.5465030670166
      policy_loss: -14.921570777893066
      var_gnorm: 23.5531005859375
      vf_explained_var: 0.5855671167373657
      vf_loss: 43.29868698120117
    num_steps_sampled: 111000
    num_steps_trained: 111000
    wait_time_ms: 66.467
  iterations_since_restore: 37
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 299.5520589351654
  time_this_iter_s: 7.861988544464111
  time_total_s: 299.5520589351654
  timestamp: 1593821399
  timesteps_since_restore: 111000
  timesteps_this_iter: 3000
  timesteps_total: 111000
  training_iteration: 37
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 299 s, 37 iter, 111000 ts, 649 rew

agent-1: 261.0
agent-2: 265.0
agent-3: 250.0
Sum Reward: 776.0
Avg Reward: 258.6666666666667
Min Reward: 250.0
Gini Coefficient 0.01288659793814433
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-10-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 840.0
  episode_reward_mean: 652.8108108108108
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 37
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 2.807
    dispatch_time_ms: 6.892
    learner:
      cur_lr: 0.0013526073889806867
      grad_gnorm: 39.9999885559082
      policy_entropy: 24.182479858398438
      policy_loss: -10.788566589355469
      var_gnorm: 23.68308448791504
      vf_explained_var: 0.46734726428985596
      vf_loss: 21.160194396972656
    num_steps_sampled: 114000
    num_steps_trained: 114000
    wait_time_ms: 77.513
  iterations_since_restore: 38
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 307.95943212509155
  time_this_iter_s: 8.407373189926147
  time_total_s: 307.95943212509155
  timestamp: 1593821407
  timesteps_since_restore: 114000
  timesteps_this_iter: 3000
  timesteps_total: 114000
  training_iteration: 38
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 307 s, 38 iter, 114000 ts, 653 rew

agent-1: 236.0
agent-2: 232.0
agent-3: 218.0
Sum Reward: 686.0
Avg Reward: 228.66666666666666
Min Reward: 218.0
Gini Coefficient 0.01749271137026239
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-10-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 840.0
  episode_reward_mean: 653.6842105263158
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 38
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 2.703
    dispatch_time_ms: 10.249
    learner:
      cur_lr: 0.0013524076202884316
      grad_gnorm: 39.99998474121094
      policy_entropy: 15.04688549041748
      policy_loss: -6.354727745056152
      var_gnorm: 23.74404525756836
      vf_explained_var: 0.6824963688850403
      vf_loss: 20.60776138305664
    num_steps_sampled: 117000
    num_steps_trained: 117000
    wait_time_ms: 67.37
  iterations_since_restore: 39
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 315.84190583229065
  time_this_iter_s: 7.882473707199097
  time_total_s: 315.84190583229065
  timestamp: 1593821415
  timesteps_since_restore: 117000
  timesteps_this_iter: 3000
  timesteps_total: 117000
  training_iteration: 39
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 315 s, 39 iter, 117000 ts, 654 rew

agent-1: 231.0
agent-2: 285.0
agent-3: 291.0
Sum Reward: 807.0
Avg Reward: 269.0
Min Reward: 231.0
Gini Coefficient 0.04956629491945477
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-10-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 840.0
  episode_reward_mean: 657.6153846153846
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 39
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 3.66
    dispatch_time_ms: 8.753
    learner:
      cur_lr: 0.0013522078515961766
      grad_gnorm: 39.99999237060547
      policy_entropy: 16.44256019592285
      policy_loss: -4.457660675048828
      var_gnorm: 23.884639739990234
      vf_explained_var: 0.12140560150146484
      vf_loss: 30.6385440826416
    num_steps_sampled: 120000
    num_steps_trained: 120000
    wait_time_ms: 78.095
  iterations_since_restore: 40
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 324.02724146842957
  time_this_iter_s: 8.185335636138916
  time_total_s: 324.02724146842957
  timestamp: 1593821423
  timesteps_since_restore: 120000
  timesteps_this_iter: 3000
  timesteps_total: 120000
  training_iteration: 40
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 324 s, 40 iter, 120000 ts, 658 rew

agent-1: 272.0
agent-2: 263.0
agent-3: 245.0
Sum Reward: 780.0
Avg Reward: 260.0
Min Reward: 245.0
Gini Coefficient 0.023076923076923078
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-10-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 840.0
  episode_reward_mean: 660.675
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 40
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 2.432
    dispatch_time_ms: 6.276
    learner:
      cur_lr: 0.0013520079664885998
      grad_gnorm: 27.095016479492188
      policy_entropy: 23.692289352416992
      policy_loss: -6.5341668128967285
      var_gnorm: 23.943946838378906
      vf_explained_var: 0.9341251254081726
      vf_loss: 5.6363019943237305
    num_steps_sampled: 123000
    num_steps_trained: 123000
    wait_time_ms: 83.599
  iterations_since_restore: 41
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 332.53842091560364
  time_this_iter_s: 8.511179447174072
  time_total_s: 332.53842091560364
  timestamp: 1593821432
  timesteps_since_restore: 123000
  timesteps_this_iter: 3000
  timesteps_total: 123000
  training_iteration: 41
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 332 s, 41 iter, 123000 ts, 661 rew

agent-1: 207.0
agent-2: 223.0
agent-3: 257.0
Sum Reward: 687.0
Avg Reward: 229.0
Min Reward: 207.0
Gini Coefficient 0.048520135856380396
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-10-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 840.0
  episode_reward_mean: 661.3170731707318
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 41
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 3.44
    dispatch_time_ms: 9.012
    learner:
      cur_lr: 0.0013518081977963448
      grad_gnorm: 39.99999237060547
      policy_entropy: 7.078275680541992
      policy_loss: -2.965029716491699
      var_gnorm: 24.01079750061035
      vf_explained_var: 0.35427212715148926
      vf_loss: 22.817441940307617
    num_steps_sampled: 126000
    num_steps_trained: 126000
    wait_time_ms: 67.977
  iterations_since_restore: 42
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 340.7277548313141
  time_this_iter_s: 8.18933391571045
  time_total_s: 340.7277548313141
  timestamp: 1593821440
  timesteps_since_restore: 126000
  timesteps_this_iter: 3000
  timesteps_total: 126000
  training_iteration: 42
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 340 s, 42 iter, 126000 ts, 661 rew

agent-1: 254.0
agent-2: 284.0
agent-3: 269.0
Sum Reward: 807.0
Avg Reward: 269.0
Min Reward: 254.0
Gini Coefficient 0.024783147459727387
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-10-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 840.0
  episode_reward_mean: 664.7857142857143
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 42
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 2.427
    dispatch_time_ms: 6.264
    learner:
      cur_lr: 0.0013516084291040897
      grad_gnorm: 39.999996185302734
      policy_entropy: 4.565083980560303
      policy_loss: -0.297666072845459
      var_gnorm: 24.072011947631836
      vf_explained_var: -0.13432550430297852
      vf_loss: 29.09389877319336
    num_steps_sampled: 129000
    num_steps_trained: 129000
    wait_time_ms: 70.582
  iterations_since_restore: 43
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 348.5685577392578
  time_this_iter_s: 7.840802907943726
  time_total_s: 348.5685577392578
  timestamp: 1593821448
  timesteps_since_restore: 129000
  timesteps_this_iter: 3000
  timesteps_total: 129000
  training_iteration: 43
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 348 s, 43 iter, 129000 ts, 665 rew

agent-1: 308.0
agent-2: 327.0
agent-3: 282.0
Sum Reward: 917.0
Avg Reward: 305.6666666666667
Min Reward: 282.0
Gini Coefficient 0.03271537622682661
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-10-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 917.0
  episode_reward_mean: 670.6511627906976
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 43
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 2.786
    dispatch_time_ms: 6.544
    learner:
      cur_lr: 0.0013514085439965129
      grad_gnorm: 40.0
      policy_entropy: 13.144306182861328
      policy_loss: -19.13776969909668
      var_gnorm: 24.170766830444336
      vf_explained_var: 0.770788848400116
      vf_loss: 50.480812072753906
    num_steps_sampled: 132000
    num_steps_trained: 132000
    wait_time_ms: 71.173
  iterations_since_restore: 44
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 356.63513112068176
  time_this_iter_s: 8.06657338142395
  time_total_s: 356.63513112068176
  timestamp: 1593821456
  timesteps_since_restore: 132000
  timesteps_this_iter: 3000
  timesteps_total: 132000
  training_iteration: 44
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 356 s, 44 iter, 132000 ts, 671 rew

agent-1: 264.0
agent-2: 247.0
agent-3: 226.0
Sum Reward: 737.0
Avg Reward: 245.66666666666666
Min Reward: 226.0
Gini Coefficient 0.034373586612392586
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-11-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 917.0
  episode_reward_mean: 672.1590909090909
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 44
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 2.562
    dispatch_time_ms: 9.827
    learner:
      cur_lr: 0.0013512087753042579
      grad_gnorm: 40.000003814697266
      policy_entropy: 15.431282043457031
      policy_loss: -14.280800819396973
      var_gnorm: 24.239822387695312
      vf_explained_var: 0.7991653680801392
      vf_loss: 16.62980079650879
    num_steps_sampled: 135000
    num_steps_trained: 135000
    wait_time_ms: 69.405
  iterations_since_restore: 45
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 364.8070833683014
  time_this_iter_s: 8.171952247619629
  time_total_s: 364.8070833683014
  timestamp: 1593821464
  timesteps_since_restore: 135000
  timesteps_this_iter: 3000
  timesteps_total: 135000
  training_iteration: 45
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 364 s, 45 iter, 135000 ts, 672 rew

agent-1: 222.0
agent-2: 219.0
agent-3: 223.0
Sum Reward: 664.0
Avg Reward: 221.33333333333334
Min Reward: 219.0
Gini Coefficient 0.004016064257028112
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-11-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 917.0
  episode_reward_mean: 671.9777777777778
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 45
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 3.574
    dispatch_time_ms: 8.896
    learner:
      cur_lr: 0.0013510090066120028
      grad_gnorm: 40.000003814697266
      policy_entropy: 12.83684253692627
      policy_loss: -5.645784378051758
      var_gnorm: 24.244129180908203
      vf_explained_var: 0.7899723052978516
      vf_loss: 17.312889099121094
    num_steps_sampled: 138000
    num_steps_trained: 138000
    wait_time_ms: 70.04
  iterations_since_restore: 46
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 372.9196979999542
  time_this_iter_s: 8.112614631652832
  time_total_s: 372.9196979999542
  timestamp: 1593821473
  timesteps_since_restore: 138000
  timesteps_this_iter: 3000
  timesteps_total: 138000
  training_iteration: 46
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 372 s, 46 iter, 138000 ts, 672 rew

agent-1: 222.0
agent-2: 261.0
agent-3: 277.0
Sum Reward: 760.0
Avg Reward: 253.33333333333334
Min Reward: 222.0
Gini Coefficient 0.04824561403508772
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-11-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 917.0
  episode_reward_mean: 673.8913043478261
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 46
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 3.017
    dispatch_time_ms: 6.104
    learner:
      cur_lr: 0.0013508092379197478
      grad_gnorm: 40.00000762939453
      policy_entropy: 6.271919250488281
      policy_loss: 3.157475709915161
      var_gnorm: 24.255640029907227
      vf_explained_var: -0.39531099796295166
      vf_loss: 25.2961368560791
    num_steps_sampled: 141000
    num_steps_trained: 141000
    wait_time_ms: 73.55
  iterations_since_restore: 47
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 381.0785367488861
  time_this_iter_s: 8.158838748931885
  time_total_s: 381.0785367488861
  timestamp: 1593821481
  timesteps_since_restore: 141000
  timesteps_this_iter: 3000
  timesteps_total: 141000
  training_iteration: 47
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 381 s, 47 iter, 141000 ts, 674 rew

agent-1: 218.0
agent-2: 223.0
agent-3: 212.0
Sum Reward: 653.0
Avg Reward: 217.66666666666666
Min Reward: 212.0
Gini Coefficient 0.011230219499744768
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-11-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 917.0
  episode_reward_mean: 673.4468085106383
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 47
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 2.614
    dispatch_time_ms: 10.024
    learner:
      cur_lr: 0.001350609352812171
      grad_gnorm: 39.99999237060547
      policy_entropy: 11.94161319732666
      policy_loss: -4.289616584777832
      var_gnorm: 24.326391220092773
      vf_explained_var: -0.7866296768188477
      vf_loss: 14.72691822052002
    num_steps_sampled: 144000
    num_steps_trained: 144000
    wait_time_ms: 68.083
  iterations_since_restore: 48
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 389.38985419273376
  time_this_iter_s: 8.311317443847656
  time_total_s: 389.38985419273376
  timestamp: 1593821489
  timesteps_since_restore: 144000
  timesteps_this_iter: 3000
  timesteps_total: 144000
  training_iteration: 48
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 389 s, 48 iter, 144000 ts, 673 rew

agent-1: 275.0
agent-2: 306.0
agent-3: 309.0
Sum Reward: 890.0
Avg Reward: 296.6666666666667
Min Reward: 275.0
Gini Coefficient 0.02546816479400749
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-11-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 917.0
  episode_reward_mean: 677.9583333333334
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 48
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 2.89
    dispatch_time_ms: 9.978
    learner:
      cur_lr: 0.001350409584119916
      grad_gnorm: 31.892892837524414
      policy_entropy: 12.494521141052246
      policy_loss: -15.18574333190918
      var_gnorm: 24.4001522064209
      vf_explained_var: 0.8865011930465698
      vf_loss: 16.034896850585938
    num_steps_sampled: 147000
    num_steps_trained: 147000
    wait_time_ms: 77.775
  iterations_since_restore: 49
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 397.59621834754944
  time_this_iter_s: 8.206364154815674
  time_total_s: 397.59621834754944
  timestamp: 1593821497
  timesteps_since_restore: 147000
  timesteps_this_iter: 3000
  timesteps_total: 147000
  training_iteration: 49
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 397 s, 49 iter, 147000 ts, 678 rew

agent-1: 210.0
agent-2: 266.0
agent-3: 238.0
Sum Reward: 714.0
Avg Reward: 238.0
Min Reward: 210.0
Gini Coefficient 0.05228758169934641
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-11-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 917.0
  episode_reward_mean: 678.6938775510204
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 49
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 2.948
    dispatch_time_ms: 7.581
    learner:
      cur_lr: 0.001350209815427661
      grad_gnorm: 39.99999237060547
      policy_entropy: 6.8386030197143555
      policy_loss: -6.3317790031433105
      var_gnorm: 24.498443603515625
      vf_explained_var: 0.10409647226333618
      vf_loss: 8.790542602539062
    num_steps_sampled: 150000
    num_steps_trained: 150000
    wait_time_ms: 73.341
  iterations_since_restore: 50
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 406.1101026535034
  time_this_iter_s: 8.51388430595398
  time_total_s: 406.1101026535034
  timestamp: 1593821506
  timesteps_since_restore: 150000
  timesteps_this_iter: 3000
  timesteps_total: 150000
  training_iteration: 50
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 406 s, 50 iter, 150000 ts, 679 rew

agent-1: 239.0
agent-2: 170.0
agent-3: 246.0
Sum Reward: 655.0
Avg Reward: 218.33333333333334
Min Reward: 170.0
Gini Coefficient 0.07735368956743002
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-11-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 917.0
  episode_reward_mean: 678.22
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 50
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 2.443
    dispatch_time_ms: 9.783
    learner:
      cur_lr: 0.001350010046735406
      grad_gnorm: 40.000003814697266
      policy_entropy: 9.125308990478516
      policy_loss: 2.3422651290893555
      var_gnorm: 24.60501480102539
      vf_explained_var: 0.300981342792511
      vf_loss: 51.20146560668945
    num_steps_sampled: 153000
    num_steps_trained: 153000
    wait_time_ms: 67.074
  iterations_since_restore: 51
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 414.45149397850037
  time_this_iter_s: 8.341391324996948
  time_total_s: 414.45149397850037
  timestamp: 1593821514
  timesteps_since_restore: 153000
  timesteps_this_iter: 3000
  timesteps_total: 153000
  training_iteration: 51
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 414 s, 51 iter, 153000 ts, 678 rew

agent-1: 272.0
agent-2: 254.0
agent-3: 235.0
Sum Reward: 761.0
Avg Reward: 253.66666666666666
Min Reward: 235.0
Gini Coefficient 0.032413491020586944
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-12-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 917.0
  episode_reward_mean: 679.843137254902
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 51
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 3.283
    dispatch_time_ms: 5.97
    learner:
      cur_lr: 0.001349810161627829
      grad_gnorm: 39.99998474121094
      policy_entropy: 9.410346984863281
      policy_loss: 0.8117946982383728
      var_gnorm: 24.61687660217285
      vf_explained_var: 0.600705623626709
      vf_loss: 34.09811782836914
    num_steps_sampled: 156000
    num_steps_trained: 156000
    wait_time_ms: 75.466
  iterations_since_restore: 52
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 422.3537538051605
  time_this_iter_s: 7.902259826660156
  time_total_s: 422.3537538051605
  timestamp: 1593821522
  timesteps_since_restore: 156000
  timesteps_this_iter: 3000
  timesteps_total: 156000
  training_iteration: 52
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 422 s, 52 iter, 156000 ts, 680 rew

agent-1: 260.0
agent-2: 275.0
agent-3: 280.0
Sum Reward: 815.0
Avg Reward: 271.6666666666667
Min Reward: 260.0
Gini Coefficient 0.016359918200409
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-12-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 917.0
  episode_reward_mean: 682.4423076923077
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 52
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 3.719
    dispatch_time_ms: 9.637
    learner:
      cur_lr: 0.001349610392935574
      grad_gnorm: 39.9999885559082
      policy_entropy: 10.706515312194824
      policy_loss: -3.068946599960327
      var_gnorm: 24.656675338745117
      vf_explained_var: 0.08300697803497314
      vf_loss: 31.994401931762695
    num_steps_sampled: 159000
    num_steps_trained: 159000
    wait_time_ms: 71.58
  iterations_since_restore: 53
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 430.3228762149811
  time_this_iter_s: 7.969122409820557
  time_total_s: 430.3228762149811
  timestamp: 1593821530
  timesteps_since_restore: 159000
  timesteps_this_iter: 3000
  timesteps_total: 159000
  training_iteration: 53
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 430 s, 53 iter, 159000 ts, 682 rew

agent-1: 286.0
agent-2: 315.0
agent-3: 288.0
Sum Reward: 889.0
Avg Reward: 296.3333333333333
Min Reward: 286.0
Gini Coefficient 0.021747281589801274
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-12-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 917.0
  episode_reward_mean: 686.3396226415094
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 53
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 3.528
    dispatch_time_ms: 7.579
    learner:
      cur_lr: 0.001349410624243319
      grad_gnorm: 39.9999885559082
      policy_entropy: 6.878992080688477
      policy_loss: 3.4053444862365723
      var_gnorm: 24.74683952331543
      vf_explained_var: 0.6764289736747742
      vf_loss: 4.378726482391357
    num_steps_sampled: 162000
    num_steps_trained: 162000
    wait_time_ms: 76.146
  iterations_since_restore: 54
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 438.49779868125916
  time_this_iter_s: 8.174922466278076
  time_total_s: 438.49779868125916
  timestamp: 1593821538
  timesteps_since_restore: 162000
  timesteps_this_iter: 3000
  timesteps_total: 162000
  training_iteration: 54
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 438 s, 54 iter, 162000 ts, 686 rew

agent-1: 283.0
agent-2: 217.0
agent-3: 229.0
Sum Reward: 729.0
Avg Reward: 243.0
Min Reward: 217.0
Gini Coefficient 0.06035665294924554
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-12-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 917.0
  episode_reward_mean: 687.1296296296297
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 54
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 2.528
    dispatch_time_ms: 7.926
    learner:
      cur_lr: 0.001349210855551064
      grad_gnorm: 39.999996185302734
      policy_entropy: 14.57108211517334
      policy_loss: 5.321072578430176
      var_gnorm: 24.81474494934082
      vf_explained_var: 0.6143643856048584
      vf_loss: 17.95477294921875
    num_steps_sampled: 165000
    num_steps_trained: 165000
    wait_time_ms: 77.595
  iterations_since_restore: 55
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 446.91085267066956
  time_this_iter_s: 8.4130539894104
  time_total_s: 446.91085267066956
  timestamp: 1593821547
  timesteps_since_restore: 165000
  timesteps_this_iter: 3000
  timesteps_total: 165000
  training_iteration: 55
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 446 s, 55 iter, 165000 ts, 687 rew

agent-1: 290.0
agent-2: 264.0
agent-3: 259.0
Sum Reward: 813.0
Avg Reward: 271.0
Min Reward: 259.0
Gini Coefficient 0.025420254202542025
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-12-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 917.0
  episode_reward_mean: 689.4181818181818
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 55
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 3.302
    dispatch_time_ms: 9.998
    learner:
      cur_lr: 0.0013490109704434872
      grad_gnorm: 39.99999237060547
      policy_entropy: 10.6156005859375
      policy_loss: -15.755918502807617
      var_gnorm: 24.877168655395508
      vf_explained_var: -0.13461852073669434
      vf_loss: 26.36456298828125
    num_steps_sampled: 168000
    num_steps_trained: 168000
    wait_time_ms: 66.742
  iterations_since_restore: 56
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 455.1558561325073
  time_this_iter_s: 8.245003461837769
  time_total_s: 455.1558561325073
  timestamp: 1593821555
  timesteps_since_restore: 168000
  timesteps_this_iter: 3000
  timesteps_total: 168000
  training_iteration: 56
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 455 s, 56 iter, 168000 ts, 689 rew

agent-1: 272.0
agent-2: 273.0
agent-3: 302.0
Sum Reward: 847.0
Avg Reward: 282.3333333333333
Min Reward: 272.0
Gini Coefficient 0.023612750885478158
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-12-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 917.0
  episode_reward_mean: 692.2321428571429
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 56
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 3.726
    dispatch_time_ms: 6.881
    learner:
      cur_lr: 0.0013488112017512321
      grad_gnorm: 40.000003814697266
      policy_entropy: 17.582887649536133
      policy_loss: 7.635519504547119
      var_gnorm: 24.991750717163086
      vf_explained_var: 0.6661968231201172
      vf_loss: 16.567058563232422
    num_steps_sampled: 171000
    num_steps_trained: 171000
    wait_time_ms: 69.255
  iterations_since_restore: 57
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 463.4851861000061
  time_this_iter_s: 8.32932996749878
  time_total_s: 463.4851861000061
  timestamp: 1593821563
  timesteps_since_restore: 171000
  timesteps_this_iter: 3000
  timesteps_total: 171000
  training_iteration: 57
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 463 s, 57 iter, 171000 ts, 692 rew

agent-1: 232.0
agent-2: 258.0
agent-3: 309.0
Sum Reward: 799.0
Avg Reward: 266.3333333333333
Min Reward: 232.0
Gini Coefficient 0.06424697538589905
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-12-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 917.0
  episode_reward_mean: 694.1052631578947
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 57
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 3.228
    dispatch_time_ms: 6.899
    learner:
      cur_lr: 0.0013486114330589771
      grad_gnorm: 40.000003814697266
      policy_entropy: 16.73756217956543
      policy_loss: -12.826676368713379
      var_gnorm: 25.065473556518555
      vf_explained_var: 0.39095866680145264
      vf_loss: 27.610883712768555
    num_steps_sampled: 174000
    num_steps_trained: 174000
    wait_time_ms: 85.041
  iterations_since_restore: 58
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 472.01834750175476
  time_this_iter_s: 8.533161401748657
  time_total_s: 472.01834750175476
  timestamp: 1593821572
  timesteps_since_restore: 174000
  timesteps_this_iter: 3000
  timesteps_total: 174000
  training_iteration: 58
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 472 s, 58 iter, 174000 ts, 694 rew

agent-1: 219.0
agent-2: 195.0
agent-3: 200.0
Sum Reward: 614.0
Avg Reward: 204.66666666666666
Min Reward: 195.0
Gini Coefficient 0.026058631921824105
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-13-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 917.0
  episode_reward_mean: 692.7241379310345
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 58
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 3.094
    dispatch_time_ms: 11.792
    learner:
      cur_lr: 0.0013484115479514003
      grad_gnorm: 40.00001525878906
      policy_entropy: 17.71824836730957
      policy_loss: -4.584946632385254
      var_gnorm: 25.017812728881836
      vf_explained_var: 0.2519257664680481
      vf_loss: 11.431901931762695
    num_steps_sampled: 177000
    num_steps_trained: 177000
    wait_time_ms: 75.625
  iterations_since_restore: 59
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 480.88188338279724
  time_this_iter_s: 8.86353588104248
  time_total_s: 480.88188338279724
  timestamp: 1593821581
  timesteps_since_restore: 177000
  timesteps_this_iter: 3000
  timesteps_total: 177000
  training_iteration: 59
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 480 s, 59 iter, 177000 ts, 693 rew

agent-1: 192.0
agent-2: 219.0
agent-3: 250.0
Sum Reward: 661.0
Avg Reward: 220.33333333333334
Min Reward: 192.0
Gini Coefficient 0.05849722642460918
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-13-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 917.0
  episode_reward_mean: 692.1864406779661
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 59
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 3.058
    dispatch_time_ms: 10.577
    learner:
      cur_lr: 0.0013482117792591453
      grad_gnorm: 40.00001525878906
      policy_entropy: 6.525686264038086
      policy_loss: -21.72745704650879
      var_gnorm: 25.048295974731445
      vf_explained_var: 0.05005842447280884
      vf_loss: 27.712158203125
    num_steps_sampled: 180000
    num_steps_trained: 180000
    wait_time_ms: 65.352
  iterations_since_restore: 60
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 488.8825891017914
  time_this_iter_s: 8.00070571899414
  time_total_s: 488.8825891017914
  timestamp: 1593821589
  timesteps_since_restore: 180000
  timesteps_this_iter: 3000
  timesteps_total: 180000
  training_iteration: 60
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 488 s, 60 iter, 180000 ts, 692 rew

agent-1: 277.0
agent-2: 298.0
agent-3: 325.0
Sum Reward: 900.0
Avg Reward: 300.0
Min Reward: 277.0
Gini Coefficient 0.035555555555555556
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-13-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 917.0
  episode_reward_mean: 695.65
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 60
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 3.091
    dispatch_time_ms: 7.989
    learner:
      cur_lr: 0.0013480120105668902
      grad_gnorm: 39.99998474121094
      policy_entropy: 2.6950888633728027
      policy_loss: 0.5497207641601562
      var_gnorm: 25.16043472290039
      vf_explained_var: 0.4807540774345398
      vf_loss: 11.121126174926758
    num_steps_sampled: 183000
    num_steps_trained: 183000
    wait_time_ms: 67.821
  iterations_since_restore: 61
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 497.11699652671814
  time_this_iter_s: 8.234407424926758
  time_total_s: 497.11699652671814
  timestamp: 1593821597
  timesteps_since_restore: 183000
  timesteps_this_iter: 3000
  timesteps_total: 183000
  training_iteration: 61
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 497 s, 61 iter, 183000 ts, 696 rew

agent-1: 202.0
agent-2: 242.0
agent-3: 229.0
Sum Reward: 673.0
Avg Reward: 224.33333333333334
Min Reward: 202.0
Gini Coefficient 0.0396235760277365
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-13-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 917.0
  episode_reward_mean: 695.2786885245902
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 61
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 2.445
    dispatch_time_ms: 6.575
    learner:
      cur_lr: 0.0013478122418746352
      grad_gnorm: 40.00000762939453
      policy_entropy: 11.401910781860352
      policy_loss: 14.89062786102295
      var_gnorm: 25.255767822265625
      vf_explained_var: -1.0
      vf_loss: 46.64520263671875
    num_steps_sampled: 186000
    num_steps_trained: 186000
    wait_time_ms: 82.01
  iterations_since_restore: 62
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 505.63633942604065
  time_this_iter_s: 8.51934289932251
  time_total_s: 505.63633942604065
  timestamp: 1593821606
  timesteps_since_restore: 186000
  timesteps_this_iter: 3000
  timesteps_total: 186000
  training_iteration: 62
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 505 s, 62 iter, 186000 ts, 695 rew

agent-1: 285.0
agent-2: 252.0
agent-3: 268.0
Sum Reward: 805.0
Avg Reward: 268.3333333333333
Min Reward: 252.0
Gini Coefficient 0.02732919254658385
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-13-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 917.0
  episode_reward_mean: 697.0483870967741
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 62
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 3.095
    dispatch_time_ms: 7.197
    learner:
      cur_lr: 0.0013476123567670584
      grad_gnorm: 40.000003814697266
      policy_entropy: 27.954456329345703
      policy_loss: -24.162471771240234
      var_gnorm: 25.370323181152344
      vf_explained_var: 0.17221760749816895
      vf_loss: 17.55980110168457
    num_steps_sampled: 189000
    num_steps_trained: 189000
    wait_time_ms: 74.695
  iterations_since_restore: 63
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 514.0452432632446
  time_this_iter_s: 8.40890383720398
  time_total_s: 514.0452432632446
  timestamp: 1593821614
  timesteps_since_restore: 189000
  timesteps_this_iter: 3000
  timesteps_total: 189000
  training_iteration: 63
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 514 s, 63 iter, 189000 ts, 697 rew

agent-1: 264.0
agent-2: 202.0
agent-3: 229.0
Sum Reward: 695.0
Avg Reward: 231.66666666666666
Min Reward: 202.0
Gini Coefficient 0.05947242206235012
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-13-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 917.0
  episode_reward_mean: 697.015873015873
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 63
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 3.145
    dispatch_time_ms: 8.713
    learner:
      cur_lr: 0.0013474125880748034
      grad_gnorm: 39.99999237060547
      policy_entropy: 4.532303810119629
      policy_loss: 3.32592511177063
      var_gnorm: 25.49170684814453
      vf_explained_var: -1.0
      vf_loss: 12.349382400512695
    num_steps_sampled: 192000
    num_steps_trained: 192000
    wait_time_ms: 78.388
  iterations_since_restore: 64
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 522.3932301998138
  time_this_iter_s: 8.347986936569214
  time_total_s: 522.3932301998138
  timestamp: 1593821623
  timesteps_since_restore: 192000
  timesteps_this_iter: 3000
  timesteps_total: 192000
  training_iteration: 64
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 522 s, 64 iter, 192000 ts, 697 rew

agent-1: 242.0
agent-2: 236.0
agent-3: 225.0
Sum Reward: 703.0
Avg Reward: 234.33333333333334
Min Reward: 225.0
Gini Coefficient 0.016121384542437174
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-13-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 917.0
  episode_reward_mean: 697.109375
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 64
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 2.74
    dispatch_time_ms: 7.014
    learner:
      cur_lr: 0.0013472128193825483
      grad_gnorm: 39.99999237060547
      policy_entropy: 8.842525482177734
      policy_loss: 4.518129348754883
      var_gnorm: 25.59581756591797
      vf_explained_var: 0.4113534092903137
      vf_loss: 19.802385330200195
    num_steps_sampled: 195000
    num_steps_trained: 195000
    wait_time_ms: 66.737
  iterations_since_restore: 65
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 530.6858415603638
  time_this_iter_s: 8.292611360549927
  time_total_s: 530.6858415603638
  timestamp: 1593821631
  timesteps_since_restore: 195000
  timesteps_this_iter: 3000
  timesteps_total: 195000
  training_iteration: 65
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 530 s, 65 iter, 195000 ts, 697 rew

agent-1: 258.0
agent-2: 297.0
agent-3: 263.0
Sum Reward: 818.0
Avg Reward: 272.6666666666667
Min Reward: 258.0
Gini Coefficient 0.03178484107579462
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-13-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 917.0
  episode_reward_mean: 698.9692307692308
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 65
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 2.633
    dispatch_time_ms: 7.386
    learner:
      cur_lr: 0.0013470130506902933
      grad_gnorm: 40.0
      policy_entropy: 14.411808013916016
      policy_loss: -2.131960391998291
      var_gnorm: 25.68357276916504
      vf_explained_var: -1.0
      vf_loss: 30.49546241760254
    num_steps_sampled: 198000
    num_steps_trained: 198000
    wait_time_ms: 73.101
  iterations_since_restore: 66
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 538.8092584609985
  time_this_iter_s: 8.123416900634766
  time_total_s: 538.8092584609985
  timestamp: 1593821639
  timesteps_since_restore: 198000
  timesteps_this_iter: 3000
  timesteps_total: 198000
  training_iteration: 66
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 538 s, 66 iter, 198000 ts, 699 rew

agent-1: 207.0
agent-2: 252.0
agent-3: 248.0
Sum Reward: 707.0
Avg Reward: 235.66666666666666
Min Reward: 207.0
Gini Coefficient 0.042432814710042434
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-14-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 917.0
  episode_reward_mean: 699.0909090909091
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 66
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 3.306
    dispatch_time_ms: 6.171
    learner:
      cur_lr: 0.0013468131655827165
      grad_gnorm: 40.000003814697266
      policy_entropy: 9.500967979431152
      policy_loss: -8.607986450195312
      var_gnorm: 25.76235008239746
      vf_explained_var: 0.40945178270339966
      vf_loss: 69.05754852294922
    num_steps_sampled: 201000
    num_steps_trained: 201000
    wait_time_ms: 73.89
  iterations_since_restore: 67
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 547.5201222896576
  time_this_iter_s: 8.710863828659058
  time_total_s: 547.5201222896576
  timestamp: 1593821648
  timesteps_since_restore: 201000
  timesteps_this_iter: 3000
  timesteps_total: 201000
  training_iteration: 67
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 547 s, 67 iter, 201000 ts, 699 rew

agent-1: 233.0
agent-2: 209.0
agent-3: 224.0
Sum Reward: 666.0
Avg Reward: 222.0
Min Reward: 209.0
Gini Coefficient 0.024024024024024024
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-14-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 917.0
  episode_reward_mean: 698.5970149253732
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 67
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 3.273
    dispatch_time_ms: 7.711
    learner:
      cur_lr: 0.0013466133968904614
      grad_gnorm: 40.000003814697266
      policy_entropy: 6.9435529708862305
      policy_loss: 1.635066270828247
      var_gnorm: 25.864046096801758
      vf_explained_var: 0.5788343548774719
      vf_loss: 27.35481071472168
    num_steps_sampled: 204000
    num_steps_trained: 204000
    wait_time_ms: 70.51
  iterations_since_restore: 68
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 555.67826628685
  time_this_iter_s: 8.158143997192383
  time_total_s: 555.67826628685
  timestamp: 1593821656
  timesteps_since_restore: 204000
  timesteps_this_iter: 3000
  timesteps_total: 204000
  training_iteration: 68
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 555 s, 68 iter, 204000 ts, 699 rew

agent-1: 301.0
agent-2: 254.0
agent-3: 262.0
Sum Reward: 817.0
Avg Reward: 272.3333333333333
Min Reward: 254.0
Gini Coefficient 0.03835169318645451
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-14-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 917.0
  episode_reward_mean: 700.3382352941177
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 68
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 2.81
    dispatch_time_ms: 6.814
    learner:
      cur_lr: 0.0013464136281982064
      grad_gnorm: 39.99999237060547
      policy_entropy: 14.213258743286133
      policy_loss: -29.975133895874023
      var_gnorm: 25.95163917541504
      vf_explained_var: 0.010344445705413818
      vf_loss: 119.55790710449219
    num_steps_sampled: 207000
    num_steps_trained: 207000
    wait_time_ms: 77.418
  iterations_since_restore: 69
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 564.1600680351257
  time_this_iter_s: 8.481801748275757
  time_total_s: 564.1600680351257
  timestamp: 1593821664
  timesteps_since_restore: 207000
  timesteps_this_iter: 3000
  timesteps_total: 207000
  training_iteration: 69
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 564 s, 69 iter, 207000 ts, 700 rew

agent-1: 252.0
agent-2: 267.0
agent-3: 274.0
Sum Reward: 793.0
Avg Reward: 264.3333333333333
Min Reward: 252.0
Gini Coefficient 0.018495166036149643
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-14-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 917.0
  episode_reward_mean: 701.6811594202899
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 69
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 2.881
    dispatch_time_ms: 9.182
    learner:
      cur_lr: 0.0013462137430906296
      grad_gnorm: 39.99999237060547
      policy_entropy: 8.820218086242676
      policy_loss: 15.272686004638672
      var_gnorm: 26.01127052307129
      vf_explained_var: -1.0
      vf_loss: 71.6408462524414
    num_steps_sampled: 210000
    num_steps_trained: 210000
    wait_time_ms: 71.431
  iterations_since_restore: 70
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 572.2548787593842
  time_this_iter_s: 8.094810724258423
  time_total_s: 572.2548787593842
  timestamp: 1593821673
  timesteps_since_restore: 210000
  timesteps_this_iter: 3000
  timesteps_total: 210000
  training_iteration: 70
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 572 s, 70 iter, 210000 ts, 702 rew

agent-1: 305.0
agent-2: 301.0
agent-3: 304.0
Sum Reward: 910.0
Avg Reward: 303.3333333333333
Min Reward: 301.0
Gini Coefficient 0.0029304029304029304
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-14-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 917.0
  episode_reward_mean: 704.6571428571428
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 70
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 3.897
    dispatch_time_ms: 9.059
    learner:
      cur_lr: 0.0013460139743983746
      grad_gnorm: 40.0
      policy_entropy: 19.85250473022461
      policy_loss: -14.558734893798828
      var_gnorm: 26.079833984375
      vf_explained_var: 0.33822184801101685
      vf_loss: 34.38948059082031
    num_steps_sampled: 213000
    num_steps_trained: 213000
    wait_time_ms: 68.644
  iterations_since_restore: 71
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 580.5806658267975
  time_this_iter_s: 8.32578706741333
  time_total_s: 580.5806658267975
  timestamp: 1593821681
  timesteps_since_restore: 213000
  timesteps_this_iter: 3000
  timesteps_total: 213000
  training_iteration: 71
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 580 s, 71 iter, 213000 ts, 705 rew

agent-1: 219.0
agent-2: 180.0
agent-3: 203.0
Sum Reward: 602.0
Avg Reward: 200.66666666666666
Min Reward: 180.0
Gini Coefficient 0.04318936877076412
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-14-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 917.0
  episode_reward_mean: 703.2112676056338
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 71
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 3.01
    dispatch_time_ms: 8.427
    learner:
      cur_lr: 0.0013458142057061195
      grad_gnorm: 40.0
      policy_entropy: 3.81463623046875
      policy_loss: 0.7206123471260071
      var_gnorm: 26.141048431396484
      vf_explained_var: -0.008267045021057129
      vf_loss: 19.28008270263672
    num_steps_sampled: 216000
    num_steps_trained: 216000
    wait_time_ms: 66.664
  iterations_since_restore: 72
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 588.9025254249573
  time_this_iter_s: 8.32185959815979
  time_total_s: 588.9025254249573
  timestamp: 1593821689
  timesteps_since_restore: 216000
  timesteps_this_iter: 3000
  timesteps_total: 216000
  training_iteration: 72
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 588 s, 72 iter, 216000 ts, 703 rew

agent-1: 283.0
agent-2: 295.0
agent-3: 317.0
Sum Reward: 895.0
Avg Reward: 298.3333333333333
Min Reward: 283.0
Gini Coefficient 0.02532588454376164
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-14-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 917.0
  episode_reward_mean: 705.875
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 72
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 2.687
    dispatch_time_ms: 7.611
    learner:
      cur_lr: 0.0013456144370138645
      grad_gnorm: 36.88827133178711
      policy_entropy: 8.263267517089844
      policy_loss: 2.6288607120513916
      var_gnorm: 26.201126098632812
      vf_explained_var: 0.038910090923309326
      vf_loss: 10.109111785888672
    num_steps_sampled: 219000
    num_steps_trained: 219000
    wait_time_ms: 75.295
  iterations_since_restore: 73
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 597.1126384735107
  time_this_iter_s: 8.210113048553467
  time_total_s: 597.1126384735107
  timestamp: 1593821698
  timesteps_since_restore: 219000
  timesteps_this_iter: 3000
  timesteps_total: 219000
  training_iteration: 73
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 597 s, 73 iter, 219000 ts, 706 rew

agent-1: 246.0
agent-2: 228.0
agent-3: 263.0
Sum Reward: 737.0
Avg Reward: 245.66666666666666
Min Reward: 228.0
Gini Coefficient 0.031659882406151064
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-15-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 917.0
  episode_reward_mean: 706.3013698630137
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 73
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 2.922
    dispatch_time_ms: 8.91
    learner:
      cur_lr: 0.0013454145519062877
      grad_gnorm: 40.000022888183594
      policy_entropy: 6.394992351531982
      policy_loss: -0.060271233320236206
      var_gnorm: 26.31842041015625
      vf_explained_var: -0.8762781620025635
      vf_loss: 39.061492919921875
    num_steps_sampled: 222000
    num_steps_trained: 222000
    wait_time_ms: 70.058
  iterations_since_restore: 74
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 605.5312316417694
  time_this_iter_s: 8.418593168258667
  time_total_s: 605.5312316417694
  timestamp: 1593821706
  timesteps_since_restore: 222000
  timesteps_this_iter: 3000
  timesteps_total: 222000
  training_iteration: 74
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 605 s, 74 iter, 222000 ts, 706 rew

agent-1: 272.0
agent-2: 295.0
agent-3: 288.0
Sum Reward: 855.0
Avg Reward: 285.0
Min Reward: 272.0
Gini Coefficient 0.01793372319688109
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-15-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 917.0
  episode_reward_mean: 708.3108108108108
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 74
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 2.397
    dispatch_time_ms: 7.366
    learner:
      cur_lr: 0.0013452147832140326
      grad_gnorm: 39.999996185302734
      policy_entropy: 7.3364644050598145
      policy_loss: -0.11060520261526108
      var_gnorm: 26.411203384399414
      vf_explained_var: -0.47434234619140625
      vf_loss: 14.060447692871094
    num_steps_sampled: 225000
    num_steps_trained: 225000
    wait_time_ms: 68.435
  iterations_since_restore: 75
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 613.4881763458252
  time_this_iter_s: 7.956944704055786
  time_total_s: 613.4881763458252
  timestamp: 1593821714
  timesteps_since_restore: 225000
  timesteps_this_iter: 3000
  timesteps_total: 225000
  training_iteration: 75
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 613 s, 75 iter, 225000 ts, 708 rew

agent-1: 292.0
agent-2: 318.0
agent-3: 349.0
Sum Reward: 959.0
Avg Reward: 319.6666666666667
Min Reward: 292.0
Gini Coefficient 0.03962460896767466
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-15-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 959.0
  episode_reward_mean: 711.6533333333333
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 75
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 3.49
    dispatch_time_ms: 9.458
    learner:
      cur_lr: 0.0013450150145217776
      grad_gnorm: 40.000022888183594
      policy_entropy: 4.382336139678955
      policy_loss: -0.14919982850551605
      var_gnorm: 26.490306854248047
      vf_explained_var: 0.11516368389129639
      vf_loss: 24.100234985351562
    num_steps_sampled: 228000
    num_steps_trained: 228000
    wait_time_ms: 65.491
  iterations_since_restore: 76
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 621.5161981582642
  time_this_iter_s: 8.028021812438965
  time_total_s: 621.5161981582642
  timestamp: 1593821722
  timesteps_since_restore: 228000
  timesteps_this_iter: 3000
  timesteps_total: 228000
  training_iteration: 76
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 621 s, 76 iter, 228000 ts, 712 rew

agent-1: 278.0
agent-2: 307.0
agent-3: 316.0
Sum Reward: 901.0
Avg Reward: 300.3333333333333
Min Reward: 278.0
Gini Coefficient 0.028116907140214576
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-15-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 959.0
  episode_reward_mean: 714.1447368421053
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 76
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 2.851
    dispatch_time_ms: 7.364
    learner:
      cur_lr: 0.0013448152458295226
      grad_gnorm: 40.0
      policy_entropy: 22.750537872314453
      policy_loss: -19.93797492980957
      var_gnorm: 26.577808380126953
      vf_explained_var: -0.5084900856018066
      vf_loss: 78.93107604980469
    num_steps_sampled: 231000
    num_steps_trained: 231000
    wait_time_ms: 67.676
  iterations_since_restore: 77
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 629.4352624416351
  time_this_iter_s: 7.919064283370972
  time_total_s: 629.4352624416351
  timestamp: 1593821730
  timesteps_since_restore: 231000
  timesteps_this_iter: 3000
  timesteps_total: 231000
  training_iteration: 77
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 629 s, 77 iter, 231000 ts, 714 rew

agent-1: 303.0
agent-2: 294.0
agent-3: 265.0
Sum Reward: 862.0
Avg Reward: 287.3333333333333
Min Reward: 265.0
Gini Coefficient 0.029389017788089715
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-15-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 959.0
  episode_reward_mean: 716.0649350649351
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 77
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 2.92
    dispatch_time_ms: 10.371
    learner:
      cur_lr: 0.0013446153607219458
      grad_gnorm: 40.000003814697266
      policy_entropy: 9.172207832336426
      policy_loss: -39.67466735839844
      var_gnorm: 26.6345272064209
      vf_explained_var: 0.5155408382415771
      vf_loss: 114.39080047607422
    num_steps_sampled: 234000
    num_steps_trained: 234000
    wait_time_ms: 67.569
  iterations_since_restore: 78
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 637.6041567325592
  time_this_iter_s: 8.168894290924072
  time_total_s: 637.6041567325592
  timestamp: 1593821738
  timesteps_since_restore: 234000
  timesteps_this_iter: 3000
  timesteps_total: 234000
  training_iteration: 78
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 637 s, 78 iter, 234000 ts, 716 rew

agent-1: 322.0
agent-2: 269.0
agent-3: 278.0
Sum Reward: 869.0
Avg Reward: 289.6666666666667
Min Reward: 269.0
Gini Coefficient 0.04065976217874952
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-15-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 959.0
  episode_reward_mean: 718.025641025641
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 78
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 3.962
    dispatch_time_ms: 8.298
    learner:
      cur_lr: 0.0013444155920296907
      grad_gnorm: 40.0000114440918
      policy_entropy: 9.372810363769531
      policy_loss: 8.512130737304688
      var_gnorm: 26.77032470703125
      vf_explained_var: 0.160231351852417
      vf_loss: 17.866596221923828
    num_steps_sampled: 237000
    num_steps_trained: 237000
    wait_time_ms: 71.703
  iterations_since_restore: 79
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 645.887589931488
  time_this_iter_s: 8.283433198928833
  time_total_s: 645.887589931488
  timestamp: 1593821747
  timesteps_since_restore: 237000
  timesteps_this_iter: 3000
  timesteps_total: 237000
  training_iteration: 79
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 645 s, 79 iter, 237000 ts, 718 rew

agent-1: 244.0
agent-2: 223.0
agent-3: 248.0
Sum Reward: 715.0
Avg Reward: 238.33333333333334
Min Reward: 223.0
Gini Coefficient 0.023310023310023312
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-15-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 959.0
  episode_reward_mean: 717.9873417721519
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 79
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 2.628
    dispatch_time_ms: 9.603
    learner:
      cur_lr: 0.0013442158233374357
      grad_gnorm: 40.000003814697266
      policy_entropy: 8.805245399475098
      policy_loss: 3.519782781600952
      var_gnorm: 26.815704345703125
      vf_explained_var: -0.4984731674194336
      vf_loss: 51.806175231933594
    num_steps_sampled: 240000
    num_steps_trained: 240000
    wait_time_ms: 64.989
  iterations_since_restore: 80
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 653.8357410430908
  time_this_iter_s: 7.948151111602783
  time_total_s: 653.8357410430908
  timestamp: 1593821755
  timesteps_since_restore: 240000
  timesteps_this_iter: 3000
  timesteps_total: 240000
  training_iteration: 80
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 653 s, 80 iter, 240000 ts, 718 rew

agent-1: 163.0
agent-2: 286.0
agent-3: 238.0
Sum Reward: 687.0
Avg Reward: 229.0
Min Reward: 163.0
Gini Coefficient 0.11935953420669577
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-16-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 959.0
  episode_reward_mean: 717.6
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 80
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 2.933
    dispatch_time_ms: 7.268
    learner:
      cur_lr: 0.0013440160546451807
      grad_gnorm: 40.000003814697266
      policy_entropy: 13.551219940185547
      policy_loss: 15.277129173278809
      var_gnorm: 26.876585006713867
      vf_explained_var: 0.1945943832397461
      vf_loss: 31.92795181274414
    num_steps_sampled: 243000
    num_steps_trained: 243000
    wait_time_ms: 70.623
  iterations_since_restore: 81
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 661.6986608505249
  time_this_iter_s: 7.862919807434082
  time_total_s: 661.6986608505249
  timestamp: 1593821762
  timesteps_since_restore: 243000
  timesteps_this_iter: 3000
  timesteps_total: 243000
  training_iteration: 81
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 661 s, 81 iter, 243000 ts, 718 rew

agent-1: 278.0
agent-2: 273.0
agent-3: 237.0
Sum Reward: 788.0
Avg Reward: 262.6666666666667
Min Reward: 237.0
Gini Coefficient 0.03468697123519458
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-16-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 959.0
  episode_reward_mean: 718.4691358024692
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 81
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 2.812
    dispatch_time_ms: 8.154
    learner:
      cur_lr: 0.0013438161695376039
      grad_gnorm: 23.368417739868164
      policy_entropy: 5.171015739440918
      policy_loss: 2.7785885334014893
      var_gnorm: 26.92458152770996
      vf_explained_var: 0.13474500179290771
      vf_loss: 9.884601593017578
    num_steps_sampled: 246000
    num_steps_trained: 246000
    wait_time_ms: 69.31
  iterations_since_restore: 82
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 669.6791334152222
  time_this_iter_s: 7.980472564697266
  time_total_s: 669.6791334152222
  timestamp: 1593821770
  timesteps_since_restore: 246000
  timesteps_this_iter: 3000
  timesteps_total: 246000
  training_iteration: 82
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 669 s, 82 iter, 246000 ts, 718 rew

agent-1: 246.0
agent-2: 304.0
agent-3: 255.0
Sum Reward: 805.0
Avg Reward: 268.3333333333333
Min Reward: 246.0
Gini Coefficient 0.04803312629399586
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-16-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 959.0
  episode_reward_mean: 719.5243902439024
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 82
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 3.261
    dispatch_time_ms: 9.3
    learner:
      cur_lr: 0.0013436164008453488
      grad_gnorm: 39.99999237060547
      policy_entropy: 7.960412979125977
      policy_loss: 7.316561222076416
      var_gnorm: 27.051259994506836
      vf_explained_var: 0.45397889614105225
      vf_loss: 8.042381286621094
    num_steps_sampled: 249000
    num_steps_trained: 249000
    wait_time_ms: 68.43
  iterations_since_restore: 83
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 677.7841994762421
  time_this_iter_s: 8.105066061019897
  time_total_s: 677.7841994762421
  timestamp: 1593821779
  timesteps_since_restore: 249000
  timesteps_this_iter: 3000
  timesteps_total: 249000
  training_iteration: 83
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 677 s, 83 iter, 249000 ts, 720 rew

agent-1: 248.0
agent-2: 283.0
agent-3: 287.0
Sum Reward: 818.0
Avg Reward: 272.6666666666667
Min Reward: 248.0
Gini Coefficient 0.03178484107579462
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-16-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 959.0
  episode_reward_mean: 720.710843373494
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 83
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 2.896
    dispatch_time_ms: 11.208
    learner:
      cur_lr: 0.0013434166321530938
      grad_gnorm: 11.981243133544922
      policy_entropy: 14.99029541015625
      policy_loss: -1.6174843311309814
      var_gnorm: 27.096508026123047
      vf_explained_var: 0.4742891192436218
      vf_loss: 9.729235649108887
    num_steps_sampled: 252000
    num_steps_trained: 252000
    wait_time_ms: 64.232
  iterations_since_restore: 84
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 685.780567407608
  time_this_iter_s: 7.996367931365967
  time_total_s: 685.780567407608
  timestamp: 1593821787
  timesteps_since_restore: 252000
  timesteps_this_iter: 3000
  timesteps_total: 252000
  training_iteration: 84
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 685 s, 84 iter, 252000 ts, 721 rew

agent-1: 273.0
agent-2: 263.0
agent-3: 289.0
Sum Reward: 825.0
Avg Reward: 275.0
Min Reward: 263.0
Gini Coefficient 0.02101010101010101
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-16-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 959.0
  episode_reward_mean: 721.952380952381
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 84
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 2.759
    dispatch_time_ms: 7.263
    learner:
      cur_lr: 0.001343216747045517
      grad_gnorm: 39.999996185302734
      policy_entropy: 10.87990951538086
      policy_loss: -7.888472080230713
      var_gnorm: 27.148868560791016
      vf_explained_var: 0.8655433058738708
      vf_loss: 21.736740112304688
    num_steps_sampled: 255000
    num_steps_trained: 255000
    wait_time_ms: 69.135
  iterations_since_restore: 85
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 693.8771026134491
  time_this_iter_s: 8.096535205841064
  time_total_s: 693.8771026134491
  timestamp: 1593821795
  timesteps_since_restore: 255000
  timesteps_this_iter: 3000
  timesteps_total: 255000
  training_iteration: 85
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 693 s, 85 iter, 255000 ts, 722 rew

agent-1: 240.0
agent-2: 227.0
agent-3: 214.0
Sum Reward: 681.0
Avg Reward: 227.0
Min Reward: 214.0
Gini Coefficient 0.025452765540871267
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_20-16-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 959.0
  episode_reward_mean: 721.4705882352941
  episode_reward_min: 126.0
  episodes_this_iter: 1
  episodes_total: 85
  experiment_id: a2eee274e0b44dbb9db1ea5edc950231
  hostname: gpu019
  info:
    apply_time_ms: 3.486
    dispatch_time_ms: 8.709
    learner:
      cur_lr: 0.001343016978353262
      grad_gnorm: 40.0
      policy_entropy: 8.696060180664062
      policy_loss: 2.813105821609497
      var_gnorm: 27.111488342285156
      vf_explained_var: 0.23588889837265015
      vf_loss: 32.98845672607422
    num_steps_sampled: 258000
    num_steps_trained: 258000
    wait_time_ms: 66.8
  iterations_since_restore: 86
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 25207
  policy_reward_mean: {}
  time_since_restore: 701.8709402084351
  time_this_iter_s: 7.993837594985962
  time_total_s: 701.8709402084351
  timestamp: 1593821803
  timesteps_since_restore: 258000
  timesteps_this_iter: 3000
  timesteps_total: 258000
  training_iteration: 86
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25207], 701 s, 86 iter, 258000 ts, 721 rew

agent-1: 244.0
agent-2: 311.0
agent-3: 224.0
Sum Reward: 779.0
Avg Reward: 259.6666666666667
Min Reward: 224.0
Gini Coefficient 0.07445442875481387
F0703 20:16:49.637948 25200 node_manager.cc:1149]  Check failed: _s.ok() Bad status: IOError: Connection reset by peer
*** Check failure stack trace: ***
    @           0x5b1006  google::LogMessage::Fail()
    @           0x5b0f52  google::LogMessage::SendToLog()
    @           0x5b08d6  google::LogMessage::Flush()
    @           0x5b06e5  google::LogMessage::~LogMessage()
    @           0x5a3d68  arrow::util::ArrowLog::~ArrowLog()
    @           0x53a18d  ray::raylet::NodeManager::TreatTaskAsFailed()
    @           0x543dd6  ray::raylet::NodeManager::ProcessDisconnectClientMessage()
    @           0x545185  ray::raylet::NodeManager::ProcessClientMessage()
    @           0x4c09c9  _ZNSt17_Function_handlerIFvSt10shared_ptrIN3ray16ClientConnectionIN5boost4asio5local15stream_protocolEEEElPKhEZNS1_6raylet6Raylet12HandleAcceptERKNS3_6system10error_codeEEUlS8_lSA_E0_E9_M_invokeERKSt9_Any_dataS8_lSA_
    @           0x509c63  ray::ClientConnection<>::ProcessMessage()
    @           0x50a093  ray::ClientConnection<>::ProcessMessageHeader()
    @           0x507b12  boost::asio::detail::read_op<>::operator()()
    @           0x5080cd  boost::asio::detail::reactive_socket_recv_op<>::do_complete()
    @           0x4bb41d  boost::asio::detail::scheduler::run()
    @           0x4b1bc7  main
    @     0x7f9c2ea97b97  __libc_start_main
    @           0x4b7311  (unknown)
WARNING: Logging before InitGoogleLogging() is written to STDERR
F0703 20:16:50.487481 25207 raylet_extension.cc:190]  Check failed: _s.ok() [RayletClient] Failed to wait for objects.: IOError: [RayletClient] Raylet connection closed.
*** Check failure stack trace: ***
Fatal Python error: Aborted

Stack (most recent call first):
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/worker.py", line 2485 in wait
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/optimizers/async_gradients_optimizer.py", line 46 in step
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/agents/a3c/a3c.py", line 68 in _train
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/tune/trainable.py", line 146 in train
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/agents/agent.py", line 279 in train
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/function_manager.py", line 713 in actor_method_executor
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/worker.py", line 820 in _process_task
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/worker.py", line 919 in _wait_for_and_process_task
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/worker.py", line 962 in main_loop
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/workers/default_worker.py", line 107 in <module>
WARNING: Logging before InitGoogleLogging() is written to STDERR
F0703 20:16:50.488495 25111 raylet_extension.cc:190]  Check failed: _s.ok() [RayletClient] Failed to wait for objects.: IOError: [RayletClient] Raylet connection closed.
*** Check failure stack trace: ***
Fatal Python error: Aborted

Stack (most recent call first):
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/worker.py", line 2485 in wait
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 199 in get_next_available_trial
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 259 in _process_events
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 118 in step
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/tune/tune.py", line 108 in run_experiments
  File "train_agents.py", line 201 in main
  File "train_agents.py", line 223 in <module>
srun: error: gpu019: task 0: Aborted
