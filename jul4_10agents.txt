/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Process STDOUT and STDERR is being redirected to /tmp/ray/session_2020-07-04_13-40-33_31856/logs.
Waiting for redis server at 127.0.0.1:35789 to respond...
Waiting for redis server at 127.0.0.1:39328 to respond...
Warning: Capping object memory store to 20.0GB. To increase this further, specify `object_store_memory` when calling ray.init() or ray start.
Starting the Plasma object store with 20.0 GB memory using /dev/shm.

======================================================================
View the web UI at http://localhost:8888/notebooks/ray_ui.ipynb?token=24e75f9cec3565ec5af684b24a90f665fbd92f0d5efa0e65
======================================================================

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0/2 CPUs, 0/1 GPUs
Memory usage on this node: 11.8/202.5 GB

Created LogSyncer for /h/zhaostep/ray_results/harvest_A3C/A3C_harvest_env_0_2020-07-04_13-40-339n1a79jl -> 
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 11.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING

/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-04 13:40:45,979	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 0 on CPU (please ignore any CUDA init errors)
2020-07-04 13:40:45.980588: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-04 13:40:57,501	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 1 on CPU (please ignore any CUDA init errors)
2020-07-04 13:40:57.502778: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-04 13:40:57,522	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 2 on CPU (please ignore any CUDA init errors)
2020-07-04 13:40:57.524057: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-41-16
  done: false
  episode_len_mean: .nan
  episode_reward_max: .nan
  episode_reward_mean: .nan
  episode_reward_min: .nan
  episodes_this_iter: 0
  episodes_total: 0
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.929
    dispatch_time_ms: 10.51
    learner:
      cur_lr: 0.0013599999947473407
      grad_gnorm: 40.0
      policy_entropy: 171.53750610351562
      policy_loss: -122.48590850830078
      var_gnorm: 18.147424697875977
      vf_explained_var: 0.0011501312255859375
      vf_loss: 4822.0458984375
    num_steps_sampled: 10000
    num_steps_trained: 10000
    wait_time_ms: 155.149
  iterations_since_restore: 1
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 28.715946435928345
  time_this_iter_s: 28.715946435928345
  time_total_s: 28.715946435928345
  timestamp: 1593884476
  timesteps_since_restore: 10000
  timesteps_this_iter: 10000
  timesteps_total: 10000
  training_iteration: 1
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 6.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 28 s, 1 iter, 10000 ts, nan rew

[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
agent-1: -286.0
agent-2: -526.0
agent-3: -228.0
agent-4: -842.0
agent-5: -957.0
agent-6: -170.0
agent-7: -133.0
agent-8: -364.0
agent-9: -927.0
agent-10: -1273.0
Sum Reward: -5706.0
Avg Reward: -570.6
Min Reward: -1273.0
Gini Coefficient: -0.36968103750438136
20:20 Ratio: 0.1358744394618834
Max-min Ratio: 0.1044776119402985
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-41-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -5706.0
  episode_reward_mean: -5706.0
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 1
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.571
    dispatch_time_ms: 6.895
    learner:
      cur_lr: 0.0013593339826911688
      grad_gnorm: 40.000003814697266
      policy_entropy: 123.31808471679688
      policy_loss: 62.74787139892578
      var_gnorm: 18.202184677124023
      vf_explained_var: 0.009143471717834473
      vf_loss: 45.414310455322266
    num_steps_sampled: 20000
    num_steps_trained: 20000
    wait_time_ms: 150.606
  iterations_since_restore: 2
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 45.31247639656067
  time_this_iter_s: 16.596529960632324
  time_total_s: 45.31247639656067
  timestamp: 1593884492
  timesteps_since_restore: 20000
  timesteps_this_iter: 10000
  timesteps_total: 20000
  training_iteration: 2
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 7.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 45 s, 2 iter, 20000 ts, -5.71e+03 rew

[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
agent-1: -414.0
agent-2: -71.0
agent-3: -261.0
agent-4: -28.0
agent-5: -585.0
agent-6: -333.0
agent-7: -382.0
agent-8: -180.0
agent-9: -12.0
agent-10: -353.0
Sum Reward: -2619.0
Avg Reward: -261.9
Min Reward: -585.0
Gini Coefficient: -0.3820160366552119
20:20 Ratio: 0.04004004004004004
Max-min Ratio: 0.020512820512820513
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-41-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2619.0
  episode_reward_mean: -4162.5
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 2
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.674
    dispatch_time_ms: 6.914
    learner:
      cur_lr: 0.0013586679706349969
      grad_gnorm: 40.00001525878906
      policy_entropy: 137.42970275878906
      policy_loss: 28.212614059448242
      var_gnorm: 18.578350067138672
      vf_explained_var: 0.06590503454208374
      vf_loss: 37.88132095336914
    num_steps_sampled: 30000
    num_steps_trained: 30000
    wait_time_ms: 149.942
  iterations_since_restore: 3
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 60.92300486564636
  time_this_iter_s: 15.610528469085693
  time_total_s: 60.92300486564636
  timestamp: 1593884508
  timesteps_since_restore: 30000
  timesteps_this_iter: 10000
  timesteps_total: 30000
  training_iteration: 3
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 7.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 60 s, 3 iter, 30000 ts, -4.16e+03 rew

agent-1: 77.0
agent-2: 12.0
agent-3: -3.0
agent-4: 24.0
agent-5: 1.0
agent-6: 35.0
agent-7: 18.0
agent-8: 7.0
agent-9: 51.0
agent-10: 46.0
Sum Reward: 268.0
Avg Reward: 26.8
Min Reward: -3.0
Gini Coefficient: 0.5
20:20 Ratio: -64.0
Max-min Ratio: -25.666666666666668
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-42-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 268.0
  episode_reward_mean: -2685.6666666666665
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 3
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.255
    dispatch_time_ms: 7.021
    learner:
      cur_lr: 0.001358001958578825
      grad_gnorm: 40.0
      policy_entropy: 124.78659057617188
      policy_loss: -27.282909393310547
      var_gnorm: 19.767030715942383
      vf_explained_var: -0.03609049320220947
      vf_loss: 4.361754894256592
    num_steps_sampled: 40000
    num_steps_trained: 40000
    wait_time_ms: 169.437
  iterations_since_restore: 4
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 78.35419392585754
  time_this_iter_s: 17.43118906021118
  time_total_s: 78.35419392585754
  timestamp: 1593884525
  timesteps_since_restore: 40000
  timesteps_this_iter: 10000
  timesteps_total: 40000
  training_iteration: 4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 8.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 78 s, 4 iter, 40000 ts, -2.69e+03 rew

agent-1: 48.0
agent-2: 43.0
agent-3: -7.0
agent-4: -6.0
agent-5: 64.0
agent-6: 40.0
agent-7: 63.0
agent-8: 27.0
agent-9: 56.0
agent-10: 54.0
Sum Reward: 382.0
Avg Reward: 38.2
Min Reward: -7.0
Gini Coefficient: 0.34397905759162306
20:20 Ratio: -9.76923076923077
Max-min Ratio: -9.142857142857142
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-42-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: -1918.75
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 4
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.784
    dispatch_time_ms: 9.669
    learner:
      cur_lr: 0.001357335946522653
      grad_gnorm: 30.51927947998047
      policy_entropy: 87.6174087524414
      policy_loss: -7.408213138580322
      var_gnorm: 20.518098831176758
      vf_explained_var: 0.8452017307281494
      vf_loss: 0.4415287971496582
    num_steps_sampled: 50000
    num_steps_trained: 50000
    wait_time_ms: 168.167
  iterations_since_restore: 5
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 95.28011536598206
  time_this_iter_s: 16.92592144012451
  time_total_s: 95.28011536598206
  timestamp: 1593884542
  timesteps_since_restore: 50000
  timesteps_this_iter: 10000
  timesteps_total: 50000
  training_iteration: 5
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 95 s, 5 iter, 50000 ts, -1.92e+03 rew

agent-1: 51.0
agent-2: 39.0
agent-3: 29.0
agent-4: 36.0
agent-5: 59.0
agent-6: 53.0
agent-7: -13.0
agent-8: 27.0
agent-9: 32.0
agent-10: 38.0
Sum Reward: 351.0
Avg Reward: 35.1
Min Reward: -13.0
Gini Coefficient: 0.2743589743589744
20:20 Ratio: 8.0
Max-min Ratio: -4.538461538461538
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-42-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: -1464.8
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 5
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.42
    dispatch_time_ms: 7.398
    learner:
      cur_lr: 0.001356670050881803
      grad_gnorm: 4.51741361618042
      policy_entropy: 108.96568298339844
      policy_loss: -2.199333667755127
      var_gnorm: 20.920394897460938
      vf_explained_var: 0.3575039505958557
      vf_loss: 0.01968229003250599
    num_steps_sampled: 60000
    num_steps_trained: 60000
    wait_time_ms: 155.848
  iterations_since_restore: 6
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 113.00804495811462
  time_this_iter_s: 17.72792959213257
  time_total_s: 113.00804495811462
  timestamp: 1593884560
  timesteps_since_restore: 60000
  timesteps_this_iter: 10000
  timesteps_total: 60000
  training_iteration: 6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 113 s, 6 iter, 60000 ts, -1.46e+03 rew

agent-1: 37.0
agent-2: 46.0
agent-3: -5.0
agent-4: 6.0
agent-5: 41.0
agent-6: 24.0
agent-7: 40.0
agent-8: 33.0
agent-9: 30.0
agent-10: 48.0
Sum Reward: 300.0
Avg Reward: 30.0
Min Reward: -5.0
Gini Coefficient: 0.292
20:20 Ratio: 94.0
Max-min Ratio: -9.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-42-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: -1170.6666666666667
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 6
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.681
    dispatch_time_ms: 6.039
    learner:
      cur_lr: 0.0013560040388256311
      grad_gnorm: 8.383441925048828
      policy_entropy: 164.21568298339844
      policy_loss: 6.230273723602295
      var_gnorm: 21.74228858947754
      vf_explained_var: -0.35103070735931396
      vf_loss: 0.14686831831932068
    num_steps_sampled: 70000
    num_steps_trained: 70000
    wait_time_ms: 160.16
  iterations_since_restore: 7
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 130.175062417984
  time_this_iter_s: 17.167017459869385
  time_total_s: 130.175062417984
  timestamp: 1593884577
  timesteps_since_restore: 70000
  timesteps_this_iter: 10000
  timesteps_total: 70000
  training_iteration: 7
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 130 s, 7 iter, 70000 ts, -1.17e+03 rew

agent-1: 37.0
agent-2: 29.0
agent-3: 35.0
agent-4: 42.0
agent-5: 39.0
agent-6: -7.0
agent-7: -15.0
agent-8: 18.0
agent-9: 25.0
agent-10: 34.0
Sum Reward: 237.0
Avg Reward: 23.7
Min Reward: -15.0
Gini Coefficient: 0.40717299578059074
20:20 Ratio: -3.6818181818181817
Max-min Ratio: -2.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-43-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: -969.5714285714286
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 7
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.837
    dispatch_time_ms: 6.226
    learner:
      cur_lr: 0.0013553380267694592
      grad_gnorm: 5.15447998046875
      policy_entropy: 170.4736328125
      policy_loss: 3.827606201171875
      var_gnorm: 21.87005615234375
      vf_explained_var: -1.0
      vf_loss: 0.1323041468858719
    num_steps_sampled: 80000
    num_steps_trained: 80000
    wait_time_ms: 143.732
  iterations_since_restore: 8
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 147.77349019050598
  time_this_iter_s: 17.598427772521973
  time_total_s: 147.77349019050598
  timestamp: 1593884595
  timesteps_since_restore: 80000
  timesteps_this_iter: 10000
  timesteps_total: 80000
  training_iteration: 8
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 147 s, 8 iter, 80000 ts, -970 rew

agent-1: -33.0
agent-2: 17.0
agent-3: 19.0
agent-4: 35.0
agent-5: 36.0
agent-6: -22.0
agent-7: 38.0
agent-8: -24.0
agent-9: 26.0
agent-10: -28.0
Sum Reward: 64.0
Avg Reward: 6.4
Min Reward: -33.0
Gini Coefficient: 2.3875
20:20 Ratio: -1.2131147540983607
Max-min Ratio: -1.1515151515151516
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-43-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: -840.375
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 8
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.146
    dispatch_time_ms: 10.199
    learner:
      cur_lr: 0.0013546720147132874
      grad_gnorm: 40.0
      policy_entropy: 141.29791259765625
      policy_loss: -18.350135803222656
      var_gnorm: 22.647884368896484
      vf_explained_var: 0.6898408532142639
      vf_loss: 5.755011081695557
    num_steps_sampled: 90000
    num_steps_trained: 90000
    wait_time_ms: 163.476
  iterations_since_restore: 9
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 164.9670135974884
  time_this_iter_s: 17.193523406982422
  time_total_s: 164.9670135974884
  timestamp: 1593884612
  timesteps_since_restore: 90000
  timesteps_this_iter: 10000
  timesteps_total: 90000
  training_iteration: 9
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 164 s, 9 iter, 90000 ts, -840 rew

agent-1: 34.0
agent-2: 22.0
agent-3: 23.0
agent-4: 25.0
agent-5: -15.0
agent-6: 42.0
agent-7: 33.0
agent-8: 43.0
agent-9: -10.0
agent-10: 37.0
Sum Reward: 234.0
Avg Reward: 23.4
Min Reward: -15.0
Gini Coefficient: 0.4282051282051282
20:20 Ratio: -3.4
Max-min Ratio: -2.8666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-43-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: -721.0
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 9
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.495
    dispatch_time_ms: 6.178
    learner:
      cur_lr: 0.0013540060026571155
      grad_gnorm: 5.171862602233887
      policy_entropy: 127.57669067382812
      policy_loss: -2.3855621814727783
      var_gnorm: 22.786888122558594
      vf_explained_var: -1.0
      vf_loss: 0.05618072301149368
    num_steps_sampled: 100000
    num_steps_trained: 100000
    wait_time_ms: 139.749
  iterations_since_restore: 10
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 182.54922819137573
  time_this_iter_s: 17.58221459388733
  time_total_s: 182.54922819137573
  timestamp: 1593884630
  timesteps_since_restore: 100000
  timesteps_this_iter: 10000
  timesteps_total: 100000
  training_iteration: 10
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 182 s, 10 iter, 100000 ts, -721 rew

agent-1: 31.0
agent-2: 31.0
agent-3: 27.0
agent-4: 26.0
agent-5: 53.0
agent-6: 34.0
agent-7: 35.0
agent-8: 29.0
agent-9: 21.0
agent-10: 34.0
Sum Reward: 321.0
Avg Reward: 32.1
Min Reward: 21.0
Gini Coefficient: 0.1249221183800623
20:20 Ratio: 1.872340425531915
Max-min Ratio: 2.5238095238095237
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-44-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: -616.8
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 10
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.22
    dispatch_time_ms: 6.64
    learner:
      cur_lr: 0.0013533399906009436
      grad_gnorm: 2.123058319091797
      policy_entropy: 120.10214233398438
      policy_loss: -0.21675920486450195
      var_gnorm: 23.543495178222656
      vf_explained_var: -1.0
      vf_loss: 0.020346302539110184
    num_steps_sampled: 110000
    num_steps_trained: 110000
    wait_time_ms: 171.061
  iterations_since_restore: 11
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 199.9281575679779
  time_this_iter_s: 17.378929376602173
  time_total_s: 199.9281575679779
  timestamp: 1593884647
  timesteps_since_restore: 110000
  timesteps_this_iter: 10000
  timesteps_total: 110000
  training_iteration: 11
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 199 s, 11 iter, 110000 ts, -617 rew

agent-1: 29.0
agent-2: 36.0
agent-3: 15.0
agent-4: 26.0
agent-5: 20.0
agent-6: 26.0
agent-7: 28.0
agent-8: 25.0
agent-9: 22.0
agent-10: 27.0
Sum Reward: 254.0
Avg Reward: 25.4
Min Reward: 15.0
Gini Coefficient: 0.11338582677165354
20:20 Ratio: 1.8571428571428572
Max-min Ratio: 2.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-44-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: -537.6363636363636
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 11
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.781
    dispatch_time_ms: 6.275
    learner:
      cur_lr: 0.0013526739785447717
      grad_gnorm: 0.9517269134521484
      policy_entropy: 131.5072479248047
      policy_loss: 0.30106183886528015
      var_gnorm: 23.54014778137207
      vf_explained_var: -0.35943639278411865
      vf_loss: 0.0019219856476411223
    num_steps_sampled: 120000
    num_steps_trained: 120000
    wait_time_ms: 151.012
  iterations_since_restore: 12
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 217.46719646453857
  time_this_iter_s: 17.53903889656067
  time_total_s: 217.46719646453857
  timestamp: 1593884665
  timesteps_since_restore: 120000
  timesteps_this_iter: 10000
  timesteps_total: 120000
  training_iteration: 12
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 217 s, 12 iter, 120000 ts, -538 rew

agent-1: 19.0
agent-2: 32.0
agent-3: 28.0
agent-4: 24.0
agent-5: 22.0
agent-6: 20.0
agent-7: 21.0
agent-8: 26.0
agent-9: 23.0
agent-10: 29.0
Sum Reward: 244.0
Avg Reward: 24.4
Min Reward: 19.0
Gini Coefficient: 0.09344262295081968
20:20 Ratio: 1.564102564102564
Max-min Ratio: 1.6842105263157894
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-44-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: -472.5
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 12
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.673
    dispatch_time_ms: 8.103
    learner:
      cur_lr: 0.0013520079664885998
      grad_gnorm: 2.9596428871154785
      policy_entropy: 136.1255340576172
      policy_loss: 1.172764778137207
      var_gnorm: 24.205957412719727
      vf_explained_var: 0.13556861877441406
      vf_loss: 0.005773601122200489
    num_steps_sampled: 130000
    num_steps_trained: 130000
    wait_time_ms: 176.924
  iterations_since_restore: 13
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 235.22113847732544
  time_this_iter_s: 17.753942012786865
  time_total_s: 235.22113847732544
  timestamp: 1593884682
  timesteps_since_restore: 130000
  timesteps_this_iter: 10000
  timesteps_total: 130000
  training_iteration: 13
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 235 s, 13 iter, 130000 ts, -472 rew

agent-1: 51.0
agent-2: 21.0
agent-3: 31.0
agent-4: 29.0
agent-5: 31.0
agent-6: 22.0
agent-7: 32.0
agent-8: 22.0
agent-9: 28.0
agent-10: 18.0
Sum Reward: 285.0
Avg Reward: 28.5
Min Reward: 18.0
Gini Coefficient: 0.1568421052631579
20:20 Ratio: 2.128205128205128
Max-min Ratio: 2.8333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-45-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: -414.2307692307692
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 13
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.886
    dispatch_time_ms: 8.794
    learner:
      cur_lr: 0.0013513419544324279
      grad_gnorm: 1.5576258897781372
      policy_entropy: 141.4483642578125
      policy_loss: -0.6420732736587524
      var_gnorm: 24.21371841430664
      vf_explained_var: -1.0
      vf_loss: 0.0026396282482892275
    num_steps_sampled: 140000
    num_steps_trained: 140000
    wait_time_ms: 147.404
  iterations_since_restore: 14
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 252.6845350265503
  time_this_iter_s: 17.463396549224854
  time_total_s: 252.6845350265503
  timestamp: 1593884700
  timesteps_since_restore: 140000
  timesteps_this_iter: 10000
  timesteps_total: 140000
  training_iteration: 14
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 252 s, 14 iter, 140000 ts, -414 rew

agent-1: 27.0
agent-2: 30.0
agent-3: 31.0
agent-4: 10.0
agent-5: 18.0
agent-6: 36.0
agent-7: 28.0
agent-8: 31.0
agent-9: 28.0
agent-10: 20.0
Sum Reward: 259.0
Avg Reward: 25.9
Min Reward: 10.0
Gini Coefficient: 0.15019305019305018
20:20 Ratio: 2.392857142857143
Max-min Ratio: 3.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-45-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: -366.14285714285717
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 14
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.894
    dispatch_time_ms: 8.504
    learner:
      cur_lr: 0.001350675942376256
      grad_gnorm: 5.504685878753662
      policy_entropy: 137.92066955566406
      policy_loss: 1.494222640991211
      var_gnorm: 24.85443115234375
      vf_explained_var: -0.28815197944641113
      vf_loss: 0.021563608199357986
    num_steps_sampled: 150000
    num_steps_trained: 150000
    wait_time_ms: 163.318
  iterations_since_restore: 15
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 270.1318008899689
  time_this_iter_s: 17.44726586341858
  time_total_s: 270.1318008899689
  timestamp: 1593884717
  timesteps_since_restore: 150000
  timesteps_this_iter: 10000
  timesteps_total: 150000
  training_iteration: 15
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 270 s, 15 iter, 150000 ts, -366 rew

agent-1: 17.0
agent-2: 36.0
agent-3: 36.0
agent-4: 38.0
agent-5: 35.0
agent-6: 15.0
agent-7: 26.0
agent-8: 33.0
agent-9: 24.0
agent-10: 28.0
Sum Reward: 288.0
Avg Reward: 28.8
Min Reward: 15.0
Gini Coefficient: 0.15
20:20 Ratio: 2.3125
Max-min Ratio: 2.533333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-45-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: -322.53333333333336
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 15
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 5.014
    dispatch_time_ms: 7.104
    learner:
      cur_lr: 0.001350010046735406
      grad_gnorm: 40.0000114440918
      policy_entropy: 77.25225067138672
      policy_loss: 8.552412033081055
      var_gnorm: 24.850919723510742
      vf_explained_var: 0.5851140022277832
      vf_loss: 124.3775634765625
    num_steps_sampled: 160000
    num_steps_trained: 160000
    wait_time_ms: 144.676
  iterations_since_restore: 16
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 287.6147243976593
  time_this_iter_s: 17.48292350769043
  time_total_s: 287.6147243976593
  timestamp: 1593884735
  timesteps_since_restore: 160000
  timesteps_this_iter: 10000
  timesteps_total: 160000
  training_iteration: 16
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 287 s, 16 iter, 160000 ts, -323 rew

agent-1: 26.0
agent-2: 25.0
agent-3: 32.0
agent-4: 34.0
agent-5: 34.0
agent-6: 24.0
agent-7: 15.0
agent-8: 33.0
agent-9: 27.0
agent-10: 32.0
Sum Reward: 282.0
Avg Reward: 28.2
Min Reward: 15.0
Gini Coefficient: 0.10780141843971631
20:20 Ratio: 1.7435897435897436
Max-min Ratio: 2.2666666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-45-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: -284.75
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 16
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.783
    dispatch_time_ms: 5.72
    learner:
      cur_lr: 0.001349344034679234
      grad_gnorm: 5.7802228927612305
      policy_entropy: 119.87037658691406
      policy_loss: -3.298309803009033
      var_gnorm: 25.16469383239746
      vf_explained_var: 0.9830661416053772
      vf_loss: 0.02823702245950699
    num_steps_sampled: 170000
    num_steps_trained: 170000
    wait_time_ms: 172.706
  iterations_since_restore: 17
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 305.38433051109314
  time_this_iter_s: 17.769606113433838
  time_total_s: 305.38433051109314
  timestamp: 1593884753
  timesteps_since_restore: 170000
  timesteps_this_iter: 10000
  timesteps_total: 170000
  training_iteration: 17
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 305 s, 17 iter, 170000 ts, -285 rew

agent-1: 39.0
agent-2: 26.0
agent-3: 32.0
agent-4: 43.0
agent-5: 28.0
agent-6: 20.0
agent-7: 24.0
agent-8: 15.0
agent-9: 15.0
agent-10: 24.0
Sum Reward: 266.0
Avg Reward: 26.6
Min Reward: 15.0
Gini Coefficient: 0.18571428571428572
20:20 Ratio: 2.7333333333333334
Max-min Ratio: 2.8666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-46-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: -252.35294117647058
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 17
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.081
    dispatch_time_ms: 6.883
    learner:
      cur_lr: 0.0013486780226230621
      grad_gnorm: 40.0
      policy_entropy: 79.38084411621094
      policy_loss: 1.670759916305542
      var_gnorm: 25.16603660583496
      vf_explained_var: 0.6728331446647644
      vf_loss: 136.67430114746094
    num_steps_sampled: 180000
    num_steps_trained: 180000
    wait_time_ms: 161.897
  iterations_since_restore: 18
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 323.012499332428
  time_this_iter_s: 17.62816882133484
  time_total_s: 323.012499332428
  timestamp: 1593884770
  timesteps_since_restore: 180000
  timesteps_this_iter: 10000
  timesteps_total: 180000
  training_iteration: 18
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 323 s, 18 iter, 180000 ts, -252 rew

agent-1: 28.0
agent-2: 27.0
agent-3: 23.0
agent-4: 23.0
agent-5: 22.0
agent-6: 27.0
agent-7: 22.0
agent-8: 21.0
agent-9: 34.0
agent-10: 12.0
Sum Reward: 239.0
Avg Reward: 23.9
Min Reward: 12.0
Gini Coefficient: 0.1200836820083682
20:20 Ratio: 1.878787878787879
Max-min Ratio: 2.8333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-46-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: -225.05555555555554
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 18
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.754
    dispatch_time_ms: 6.617
    learner:
      cur_lr: 0.0013480120105668902
      grad_gnorm: 4.4722900390625
      policy_entropy: 129.58206176757812
      policy_loss: -1.4830809831619263
      var_gnorm: 25.606115341186523
      vf_explained_var: 0.8843228816986084
      vf_loss: 0.03140294924378395
    num_steps_sampled: 190000
    num_steps_trained: 190000
    wait_time_ms: 169.432
  iterations_since_restore: 19
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 340.4436538219452
  time_this_iter_s: 17.431154489517212
  time_total_s: 340.4436538219452
  timestamp: 1593884788
  timesteps_since_restore: 190000
  timesteps_this_iter: 10000
  timesteps_total: 190000
  training_iteration: 19
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 340 s, 19 iter, 190000 ts, -225 rew

agent-1: 25.0
agent-2: 31.0
agent-3: 22.0
agent-4: 27.0
agent-5: 23.0
agent-6: 28.0
agent-7: 24.0
agent-8: 20.0
agent-9: 38.0
agent-10: 29.0
Sum Reward: 267.0
Avg Reward: 26.7
Min Reward: 20.0
Gini Coefficient: 0.10074906367041199
20:20 Ratio: 1.6428571428571428
Max-min Ratio: 1.9
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-46-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: -199.1578947368421
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 19
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.482
    dispatch_time_ms: 8.036
    learner:
      cur_lr: 0.0013473459985107183
      grad_gnorm: 39.999996185302734
      policy_entropy: 80.03111267089844
      policy_loss: 10.796785354614258
      var_gnorm: 25.593347549438477
      vf_explained_var: 0.05348074436187744
      vf_loss: 100.16033172607422
    num_steps_sampled: 200000
    num_steps_trained: 200000
    wait_time_ms: 168.584
  iterations_since_restore: 20
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 358.04131412506104
  time_this_iter_s: 17.597660303115845
  time_total_s: 358.04131412506104
  timestamp: 1593884806
  timesteps_since_restore: 200000
  timesteps_this_iter: 10000
  timesteps_total: 200000
  training_iteration: 20
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 358 s, 20 iter, 200000 ts, -199 rew

agent-1: 32.0
agent-2: 23.0
agent-3: 27.0
agent-4: 36.0
agent-5: 34.0
agent-6: 14.0
agent-7: 35.0
agent-8: 44.0
agent-9: 26.0
agent-10: 45.0
Sum Reward: 316.0
Avg Reward: 31.6
Min Reward: 14.0
Gini Coefficient: 0.15886075949367087
20:20 Ratio: 2.4054054054054053
Max-min Ratio: 3.2142857142857144
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-47-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: -173.4
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 20
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.504
    dispatch_time_ms: 7.864
    learner:
      cur_lr: 0.0013466799864545465
      grad_gnorm: 1.2594349384307861
      policy_entropy: 125.39620971679688
      policy_loss: 0.6212121844291687
      var_gnorm: 25.90751838684082
      vf_explained_var: -0.0869741439819336
      vf_loss: 0.0023142327554523945
    num_steps_sampled: 210000
    num_steps_trained: 210000
    wait_time_ms: 165.742
  iterations_since_restore: 21
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 375.8927619457245
  time_this_iter_s: 17.851447820663452
  time_total_s: 375.8927619457245
  timestamp: 1593884823
  timesteps_since_restore: 210000
  timesteps_this_iter: 10000
  timesteps_total: 210000
  training_iteration: 21
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 375 s, 21 iter, 210000 ts, -173 rew

agent-1: 18.0
agent-2: 20.0
agent-3: 17.0
agent-4: 18.0
agent-5: 19.0
agent-6: 26.0
agent-7: 26.0
agent-8: 25.0
agent-9: 23.0
agent-10: 27.0
Sum Reward: 219.0
Avg Reward: 21.9
Min Reward: 17.0
Gini Coefficient: 0.09452054794520548
20:20 Ratio: 1.5142857142857142
Max-min Ratio: 1.588235294117647
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-47-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: -154.71428571428572
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 21
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.287
    dispatch_time_ms: 7.559
    learner:
      cur_lr: 0.0013460139743983746
      grad_gnorm: 39.999996185302734
      policy_entropy: 40.500972747802734
      policy_loss: 29.622085571289062
      var_gnorm: 25.895244598388672
      vf_explained_var: 0.9204044938087463
      vf_loss: 50.384681701660156
    num_steps_sampled: 220000
    num_steps_trained: 220000
    wait_time_ms: 161.627
  iterations_since_restore: 22
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 393.4924666881561
  time_this_iter_s: 17.59970474243164
  time_total_s: 393.4924666881561
  timestamp: 1593884841
  timesteps_since_restore: 220000
  timesteps_this_iter: 10000
  timesteps_total: 220000
  training_iteration: 22
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 393 s, 22 iter, 220000 ts, -155 rew

agent-1: 20.0
agent-2: 22.0
agent-3: 22.0
agent-4: 13.0
agent-5: 19.0
agent-6: 11.0
agent-7: 26.0
agent-8: 22.0
agent-9: 28.0
agent-10: 24.0
Sum Reward: 207.0
Avg Reward: 20.7
Min Reward: 11.0
Gini Coefficient: 0.13285024154589373
20:20 Ratio: 2.25
Max-min Ratio: 2.5454545454545454
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-47-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: -138.27272727272728
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 22
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.972
    dispatch_time_ms: 8.873
    learner:
      cur_lr: 0.0013453479623422027
      grad_gnorm: 4.085192680358887
      policy_entropy: 96.16771697998047
      policy_loss: 1.1834073066711426
      var_gnorm: 26.195383071899414
      vf_explained_var: 0.6343400478363037
      vf_loss: 0.025556553155183792
    num_steps_sampled: 230000
    num_steps_trained: 230000
    wait_time_ms: 166.757
  iterations_since_restore: 23
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 410.81000661849976
  time_this_iter_s: 17.317539930343628
  time_total_s: 410.81000661849976
  timestamp: 1593884858
  timesteps_since_restore: 230000
  timesteps_this_iter: 10000
  timesteps_total: 230000
  training_iteration: 23
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 410 s, 23 iter, 230000 ts, -138 rew

agent-1: 32.0
agent-2: 24.0
agent-3: 19.0
agent-4: 26.0
agent-5: 27.0
agent-6: 21.0
agent-7: 19.0
agent-8: 25.0
agent-9: 14.0
agent-10: 36.0
Sum Reward: 243.0
Avg Reward: 24.3
Min Reward: 14.0
Gini Coefficient: 0.1419753086419753
20:20 Ratio: 2.0606060606060606
Max-min Ratio: 2.5714285714285716
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-47-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: -121.69565217391305
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 23
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.91
    dispatch_time_ms: 7.772
    learner:
      cur_lr: 0.0013446819502860308
      grad_gnorm: 2.135883331298828
      policy_entropy: 109.62397766113281
      policy_loss: -0.38895517587661743
      var_gnorm: 26.18463134765625
      vf_explained_var: 0.8539493083953857
      vf_loss: 0.006065028719604015
    num_steps_sampled: 240000
    num_steps_trained: 240000
    wait_time_ms: 172.253
  iterations_since_restore: 24
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 428.5738124847412
  time_this_iter_s: 17.763805866241455
  time_total_s: 428.5738124847412
  timestamp: 1593884876
  timesteps_since_restore: 240000
  timesteps_this_iter: 10000
  timesteps_total: 240000
  training_iteration: 24
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 428 s, 24 iter, 240000 ts, -122 rew

agent-1: 31.0
agent-2: 18.0
agent-3: 31.0
agent-4: 36.0
agent-5: 19.0
agent-6: 40.0
agent-7: 29.0
agent-8: 23.0
agent-9: 25.0
agent-10: 19.0
Sum Reward: 271.0
Avg Reward: 27.1
Min Reward: 18.0
Gini Coefficient: 0.14944649446494465
20:20 Ratio: 2.054054054054054
Max-min Ratio: 2.2222222222222223
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-48-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: -105.33333333333333
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 24
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.012
    dispatch_time_ms: 7.213
    learner:
      cur_lr: 0.0013440160546451807
      grad_gnorm: 0.6420911550521851
      policy_entropy: 81.27545928955078
      policy_loss: 0.27256813645362854
      var_gnorm: 26.629919052124023
      vf_explained_var: 0.704795241355896
      vf_loss: 0.0010643068235367537
    num_steps_sampled: 250000
    num_steps_trained: 250000
    wait_time_ms: 164.1
  iterations_since_restore: 25
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 446.1423907279968
  time_this_iter_s: 17.568578243255615
  time_total_s: 446.1423907279968
  timestamp: 1593884894
  timesteps_since_restore: 250000
  timesteps_this_iter: 10000
  timesteps_total: 250000
  training_iteration: 25
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 446 s, 25 iter, 250000 ts, -105 rew

agent-1: 14.0
agent-2: 38.0
agent-3: 14.0
agent-4: 27.0
agent-5: 16.0
agent-6: 21.0
agent-7: 28.0
agent-8: 29.0
agent-9: 25.0
agent-10: 23.0
Sum Reward: 235.0
Avg Reward: 23.5
Min Reward: 14.0
Gini Coefficient: 0.17063829787234042
20:20 Ratio: 2.392857142857143
Max-min Ratio: 2.7142857142857144
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-48-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: -91.72
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 25
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.062
    dispatch_time_ms: 9.104
    learner:
      cur_lr: 0.0013433500425890088
      grad_gnorm: 1.5936765670776367
      policy_entropy: 101.9183349609375
      policy_loss: 0.11013989895582199
      var_gnorm: 26.639951705932617
      vf_explained_var: 0.6481834650039673
      vf_loss: 0.0024259283673018217
    num_steps_sampled: 260000
    num_steps_trained: 260000
    wait_time_ms: 142.192
  iterations_since_restore: 26
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 463.62180638313293
  time_this_iter_s: 17.47941565513611
  time_total_s: 463.62180638313293
  timestamp: 1593884911
  timesteps_since_restore: 260000
  timesteps_this_iter: 10000
  timesteps_total: 260000
  training_iteration: 26
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 463 s, 26 iter, 260000 ts, -91.7 rew

agent-1: 27.0
agent-2: 28.0
agent-3: 35.0
agent-4: 28.0
agent-5: 32.0
agent-6: 19.0
agent-7: 23.0
agent-8: 17.0
agent-9: 34.0
agent-10: 32.0
Sum Reward: 275.0
Avg Reward: 27.5
Min Reward: 17.0
Gini Coefficient: 0.11890909090909091
20:20 Ratio: 1.9166666666666667
Max-min Ratio: 2.0588235294117645
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-48-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: -77.61538461538461
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 26
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.543
    dispatch_time_ms: 9.028
    learner:
      cur_lr: 0.001342684030532837
      grad_gnorm: 3.0738866329193115
      policy_entropy: 105.1644058227539
      policy_loss: 0.558345377445221
      var_gnorm: 26.94628143310547
      vf_explained_var: -0.3190804719924927
      vf_loss: 0.02863270789384842
    num_steps_sampled: 270000
    num_steps_trained: 270000
    wait_time_ms: 165.439
  iterations_since_restore: 27
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 481.1773624420166
  time_this_iter_s: 17.555556058883667
  time_total_s: 481.1773624420166
  timestamp: 1593884929
  timesteps_since_restore: 270000
  timesteps_this_iter: 10000
  timesteps_total: 270000
  training_iteration: 27
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 481 s, 27 iter, 270000 ts, -77.6 rew

agent-1: 22.0
agent-2: 18.0
agent-3: 30.0
agent-4: 25.0
agent-5: 22.0
agent-6: 19.0
agent-7: 28.0
agent-8: 23.0
agent-9: 16.0
agent-10: 27.0
Sum Reward: 230.0
Avg Reward: 23.0
Min Reward: 16.0
Gini Coefficient: 0.10695652173913044
20:20 Ratio: 1.7058823529411764
Max-min Ratio: 1.875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-49-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: -66.22222222222223
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 27
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.727
    dispatch_time_ms: 6.793
    learner:
      cur_lr: 0.001342018018476665
      grad_gnorm: 3.1567392349243164
      policy_entropy: 108.8995590209961
      policy_loss: 0.7527190446853638
      var_gnorm: 26.954696655273438
      vf_explained_var: 0.6292222738265991
      vf_loss: 0.03218544274568558
    num_steps_sampled: 280000
    num_steps_trained: 280000
    wait_time_ms: 157.161
  iterations_since_restore: 28
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 498.7052803039551
  time_this_iter_s: 17.527917861938477
  time_total_s: 498.7052803039551
  timestamp: 1593884946
  timesteps_since_restore: 280000
  timesteps_this_iter: 10000
  timesteps_total: 280000
  training_iteration: 28
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 498 s, 28 iter, 280000 ts, -66.2 rew

agent-1: 33.0
agent-2: 29.0
agent-3: 24.0
agent-4: 28.0
agent-5: 20.0
agent-6: 18.0
agent-7: 27.0
agent-8: 31.0
agent-9: 16.0
agent-10: 23.0
Sum Reward: 249.0
Avg Reward: 24.9
Min Reward: 16.0
Gini Coefficient: 0.12329317269076305
20:20 Ratio: 1.8823529411764706
Max-min Ratio: 2.0625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-49-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: -54.964285714285715
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 28
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 4.043
    dispatch_time_ms: 7.706
    learner:
      cur_lr: 0.0013413520064204931
      grad_gnorm: 1.110921859741211
      policy_entropy: 105.09420013427734
      policy_loss: -0.02902495674788952
      var_gnorm: 27.196765899658203
      vf_explained_var: 0.9542438983917236
      vf_loss: 0.0037373534869402647
    num_steps_sampled: 290000
    num_steps_trained: 290000
    wait_time_ms: 163.535
  iterations_since_restore: 29
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 516.2424509525299
  time_this_iter_s: 17.53717064857483
  time_total_s: 516.2424509525299
  timestamp: 1593884964
  timesteps_since_restore: 290000
  timesteps_this_iter: 10000
  timesteps_total: 290000
  training_iteration: 29
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 516 s, 29 iter, 290000 ts, -55 rew

agent-1: 31.0
agent-2: 23.0
agent-3: 18.0
agent-4: 30.0
agent-5: 22.0
agent-6: 31.0
agent-7: 16.0
agent-8: 31.0
agent-9: 40.0
agent-10: 29.0
Sum Reward: 271.0
Avg Reward: 27.1
Min Reward: 16.0
Gini Coefficient: 0.13911439114391144
20:20 Ratio: 2.088235294117647
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-49-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: -43.724137931034484
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 29
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.608
    dispatch_time_ms: 7.721
    learner:
      cur_lr: 0.0013406859943643212
      grad_gnorm: 40.000003814697266
      policy_entropy: 72.09474182128906
      policy_loss: -19.207185745239258
      var_gnorm: 27.193279266357422
      vf_explained_var: 0.23484200239181519
      vf_loss: 100.53616333007812
    num_steps_sampled: 300000
    num_steps_trained: 300000
    wait_time_ms: 162.328
  iterations_since_restore: 30
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 533.831239938736
  time_this_iter_s: 17.588788986206055
  time_total_s: 533.831239938736
  timestamp: 1593884982
  timesteps_since_restore: 300000
  timesteps_this_iter: 10000
  timesteps_total: 300000
  training_iteration: 30
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 533 s, 30 iter, 300000 ts, -43.7 rew

agent-1: 20.0
agent-2: 25.0
agent-3: 28.0
agent-4: 13.0
agent-5: 23.0
agent-6: 27.0
agent-7: 16.0
agent-8: 23.0
agent-9: 30.0
agent-10: 25.0
Sum Reward: 230.0
Avg Reward: 23.0
Min Reward: 13.0
Gini Coefficient: 0.12173913043478261
20:20 Ratio: 2.0
Max-min Ratio: 2.3076923076923075
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-49-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: -34.6
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 30
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.768
    dispatch_time_ms: 8.239
    learner:
      cur_lr: 0.0013400199823081493
      grad_gnorm: 2.0291991233825684
      policy_entropy: 104.49198913574219
      policy_loss: 0.5127925276756287
      var_gnorm: 27.578567504882812
      vf_explained_var: -0.4133293628692627
      vf_loss: 0.019933514297008514
    num_steps_sampled: 310000
    num_steps_trained: 310000
    wait_time_ms: 165.162
  iterations_since_restore: 31
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 551.2445201873779
  time_this_iter_s: 17.413280248641968
  time_total_s: 551.2445201873779
  timestamp: 1593884999
  timesteps_since_restore: 310000
  timesteps_this_iter: 10000
  timesteps_total: 310000
  training_iteration: 31
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 551 s, 31 iter, 310000 ts, -34.6 rew

agent-1: 32.0
agent-2: 23.0
agent-3: 32.0
agent-4: 19.0
agent-5: 21.0
agent-6: 26.0
agent-7: 21.0
agent-8: 26.0
agent-9: 9.0
agent-10: 17.0
Sum Reward: 226.0
Avg Reward: 22.6
Min Reward: 9.0
Gini Coefficient: 0.16106194690265488
20:20 Ratio: 2.4615384615384617
Max-min Ratio: 3.5555555555555554
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-50-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: -26.193548387096776
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 31
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.899
    dispatch_time_ms: 6.901
    learner:
      cur_lr: 0.0013393539702519774
      grad_gnorm: 39.99999237060547
      policy_entropy: 63.16197967529297
      policy_loss: -3.8833017349243164
      var_gnorm: 27.557985305786133
      vf_explained_var: -0.259982705116272
      vf_loss: 96.18894958496094
    num_steps_sampled: 320000
    num_steps_trained: 320000
    wait_time_ms: 152.424
  iterations_since_restore: 32
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 568.9236257076263
  time_this_iter_s: 17.679105520248413
  time_total_s: 568.9236257076263
  timestamp: 1593885017
  timesteps_since_restore: 320000
  timesteps_this_iter: 10000
  timesteps_total: 320000
  training_iteration: 32
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 568 s, 32 iter, 320000 ts, -26.2 rew

agent-1: 28.0
agent-2: 23.0
agent-3: 21.0
agent-4: 25.0
agent-5: 25.0
agent-6: 29.0
agent-7: 27.0
agent-8: 18.0
agent-9: 27.0
agent-10: 31.0
Sum Reward: 254.0
Avg Reward: 25.4
Min Reward: 18.0
Gini Coefficient: 0.08110236220472442
20:20 Ratio: 1.5384615384615385
Max-min Ratio: 1.7222222222222223
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-50-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: -17.4375
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 32
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 4.024
    dispatch_time_ms: 6.495
    learner:
      cur_lr: 0.0013386879581958055
      grad_gnorm: 2.6707351207733154
      policy_entropy: 74.59619903564453
      policy_loss: -0.10543176531791687
      var_gnorm: 28.320497512817383
      vf_explained_var: 0.661592960357666
      vf_loss: 0.016332486644387245
    num_steps_sampled: 330000
    num_steps_trained: 330000
    wait_time_ms: 173.231
  iterations_since_restore: 33
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 586.4470729827881
  time_this_iter_s: 17.523447275161743
  time_total_s: 586.4470729827881
  timestamp: 1593885034
  timesteps_since_restore: 330000
  timesteps_this_iter: 10000
  timesteps_total: 330000
  training_iteration: 33
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 586 s, 33 iter, 330000 ts, -17.4 rew

agent-1: 27.0
agent-2: 43.0
agent-3: 32.0
agent-4: 22.0
agent-5: 32.0
agent-6: 29.0
agent-7: 34.0
agent-8: 27.0
agent-9: 33.0
agent-10: 24.0
Sum Reward: 303.0
Avg Reward: 30.3
Min Reward: 22.0
Gini Coefficient: 0.10132013201320132
20:20 Ratio: 1.673913043478261
Max-min Ratio: 1.9545454545454546
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-50-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: -7.7272727272727275
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 33
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.403
    dispatch_time_ms: 6.289
    learner:
      cur_lr: 0.0013380219461396337
      grad_gnorm: 4.0995941162109375
      policy_entropy: 101.73145294189453
      policy_loss: -0.8499857783317566
      var_gnorm: 28.308237075805664
      vf_explained_var: 0.9445062875747681
      vf_loss: 0.011667749844491482
    num_steps_sampled: 340000
    num_steps_trained: 340000
    wait_time_ms: 162.912
  iterations_since_restore: 34
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 603.7032454013824
  time_this_iter_s: 17.25617241859436
  time_total_s: 603.7032454013824
  timestamp: 1593885052
  timesteps_since_restore: 340000
  timesteps_this_iter: 10000
  timesteps_total: 340000
  training_iteration: 34
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 603 s, 34 iter, 340000 ts, -7.73 rew

agent-1: 29.0
agent-2: 24.0
agent-3: 32.0
agent-4: 26.0
agent-5: 27.0
agent-6: 18.0
agent-7: 29.0
agent-8: 23.0
agent-9: 20.0
agent-10: 25.0
Sum Reward: 253.0
Avg Reward: 25.3
Min Reward: 18.0
Gini Coefficient: 0.09051383399209487
20:20 Ratio: 1.605263157894737
Max-min Ratio: 1.7777777777777777
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-51-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: -0.058823529411764705
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 34
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.505
    dispatch_time_ms: 8.67
    learner:
      cur_lr: 0.0013373560504987836
      grad_gnorm: 1.947687029838562
      policy_entropy: 96.52922058105469
      policy_loss: -1.2166788578033447
      var_gnorm: 28.6214542388916
      vf_explained_var: 0.5640333890914917
      vf_loss: 0.002175926696509123
    num_steps_sampled: 350000
    num_steps_trained: 350000
    wait_time_ms: 165.773
  iterations_since_restore: 35
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 620.9110050201416
  time_this_iter_s: 17.207759618759155
  time_total_s: 620.9110050201416
  timestamp: 1593885069
  timesteps_since_restore: 350000
  timesteps_this_iter: 10000
  timesteps_total: 350000
  training_iteration: 35
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 620 s, 35 iter, 350000 ts, -0.0588 rew

agent-1: 36.0
agent-2: 28.0
agent-3: 24.0
agent-4: 26.0
agent-5: 18.0
agent-6: 28.0
agent-7: 15.0
agent-8: 27.0
agent-9: 35.0
agent-10: 29.0
Sum Reward: 266.0
Avg Reward: 26.6
Min Reward: 15.0
Gini Coefficient: 0.12781954887218044
20:20 Ratio: 2.1515151515151514
Max-min Ratio: 2.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-51-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 7.542857142857143
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 35
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.804
    dispatch_time_ms: 6.481
    learner:
      cur_lr: 0.0013366900384426117
      grad_gnorm: 3.2345807552337646
      policy_entropy: 123.42518615722656
      policy_loss: -1.2591701745986938
      var_gnorm: 28.600772857666016
      vf_explained_var: 0.9519908428192139
      vf_loss: 0.00949647556990385
    num_steps_sampled: 360000
    num_steps_trained: 360000
    wait_time_ms: 175.726
  iterations_since_restore: 36
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 638.7742083072662
  time_this_iter_s: 17.863203287124634
  time_total_s: 638.7742083072662
  timestamp: 1593885087
  timesteps_since_restore: 360000
  timesteps_this_iter: 10000
  timesteps_total: 360000
  training_iteration: 36
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 638 s, 36 iter, 360000 ts, 7.54 rew

agent-1: 17.0
agent-2: 32.0
agent-3: 38.0
agent-4: 26.0
agent-5: 20.0
agent-6: 19.0
agent-7: 37.0
agent-8: 29.0
agent-9: 25.0
agent-10: 27.0
Sum Reward: 270.0
Avg Reward: 27.0
Min Reward: 17.0
Gini Coefficient: 0.1437037037037037
20:20 Ratio: 2.0833333333333335
Max-min Ratio: 2.235294117647059
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-51-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 14.833333333333334
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 36
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.062
    dispatch_time_ms: 6.614
    learner:
      cur_lr: 0.0013360240263864398
      grad_gnorm: 0.8177595138549805
      policy_entropy: 115.399658203125
      policy_loss: -0.31450754404067993
      var_gnorm: 28.953018188476562
      vf_explained_var: 0.4970475435256958
      vf_loss: 0.00045785732800140977
    num_steps_sampled: 370000
    num_steps_trained: 370000
    wait_time_ms: 169.756
  iterations_since_restore: 37
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 656.2995891571045
  time_this_iter_s: 17.525380849838257
  time_total_s: 656.2995891571045
  timestamp: 1593885104
  timesteps_since_restore: 370000
  timesteps_this_iter: 10000
  timesteps_total: 370000
  training_iteration: 37
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 656 s, 37 iter, 370000 ts, 14.8 rew

agent-1: 24.0
agent-2: 15.0
agent-3: 25.0
agent-4: 30.0
agent-5: 25.0
agent-6: 22.0
agent-7: 22.0
agent-8: 22.0
agent-9: 23.0
agent-10: 21.0
Sum Reward: 229.0
Avg Reward: 22.9
Min Reward: 15.0
Gini Coefficient: 0.08078602620087336
20:20 Ratio: 1.5277777777777777
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-52-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 20.62162162162162
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 37
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.772
    dispatch_time_ms: 5.777
    learner:
      cur_lr: 0.001335358014330268
      grad_gnorm: 40.00000762939453
      policy_entropy: 117.78279113769531
      policy_loss: 19.36480712890625
      var_gnorm: 28.99750328063965
      vf_explained_var: 0.5541082620620728
      vf_loss: 26.292238235473633
    num_steps_sampled: 380000
    num_steps_trained: 380000
    wait_time_ms: 161.161
  iterations_since_restore: 38
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 673.7934212684631
  time_this_iter_s: 17.493832111358643
  time_total_s: 673.7934212684631
  timestamp: 1593885122
  timesteps_since_restore: 380000
  timesteps_this_iter: 10000
  timesteps_total: 380000
  training_iteration: 38
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 673 s, 38 iter, 380000 ts, 20.6 rew

agent-1: 16.0
agent-2: 26.0
agent-3: 20.0
agent-4: 25.0
agent-5: 17.0
agent-6: 18.0
agent-7: 21.0
agent-8: 21.0
agent-9: 30.0
agent-10: 21.0
Sum Reward: 215.0
Avg Reward: 21.5
Min Reward: 16.0
Gini Coefficient: 0.1055813953488372
20:20 Ratio: 1.696969696969697
Max-min Ratio: 1.875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-52-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 25.736842105263158
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 38
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.554
    dispatch_time_ms: 9.55
    learner:
      cur_lr: 0.001334692002274096
      grad_gnorm: 1.5641355514526367
      policy_entropy: 127.88014221191406
      policy_loss: -0.5964099168777466
      var_gnorm: 29.144031524658203
      vf_explained_var: -0.5774703025817871
      vf_loss: 0.005007835570722818
    num_steps_sampled: 390000
    num_steps_trained: 390000
    wait_time_ms: 166.542
  iterations_since_restore: 39
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 691.4532599449158
  time_this_iter_s: 17.659838676452637
  time_total_s: 691.4532599449158
  timestamp: 1593885140
  timesteps_since_restore: 390000
  timesteps_this_iter: 10000
  timesteps_total: 390000
  training_iteration: 39
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 691 s, 39 iter, 390000 ts, 25.7 rew

agent-1: 20.0
agent-2: 17.0
agent-3: 21.0
agent-4: 27.0
agent-5: 23.0
agent-6: 29.0
agent-7: 18.0
agent-8: 20.0
agent-9: 13.0
agent-10: 19.0
Sum Reward: 207.0
Avg Reward: 20.7
Min Reward: 13.0
Gini Coefficient: 0.11835748792270531
20:20 Ratio: 1.8666666666666667
Max-min Ratio: 2.230769230769231
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-52-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 30.384615384615383
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 39
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.936
    dispatch_time_ms: 6.888
    learner:
      cur_lr: 0.0013340259902179241
      grad_gnorm: 2.0137100219726562
      policy_entropy: 137.3603973388672
      policy_loss: -0.7306947708129883
      var_gnorm: 29.191112518310547
      vf_explained_var: 0.9555315971374512
      vf_loss: 0.002543035428971052
    num_steps_sampled: 400000
    num_steps_trained: 400000
    wait_time_ms: 173.772
  iterations_since_restore: 40
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 709.2326164245605
  time_this_iter_s: 17.779356479644775
  time_total_s: 709.2326164245605
  timestamp: 1593885157
  timesteps_since_restore: 400000
  timesteps_this_iter: 10000
  timesteps_total: 400000
  training_iteration: 40
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 709 s, 40 iter, 400000 ts, 30.4 rew

agent-1: 26.0
agent-2: 21.0
agent-3: 30.0
agent-4: 23.0
agent-5: 20.0
agent-6: 25.0
agent-7: 20.0
agent-8: 17.0
agent-9: 19.0
agent-10: 19.0
Sum Reward: 220.0
Avg Reward: 22.0
Min Reward: 17.0
Gini Coefficient: 0.09363636363636364
20:20 Ratio: 1.5555555555555556
Max-min Ratio: 1.7647058823529411
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-52-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 35.125
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 40
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.666
    dispatch_time_ms: 7.092
    learner:
      cur_lr: 0.0013333599781617522
      grad_gnorm: 4.551310062408447
      policy_entropy: 114.34098815917969
      policy_loss: 1.4122058153152466
      var_gnorm: 29.4815731048584
      vf_explained_var: 0.3944457769393921
      vf_loss: 0.02219102904200554
    num_steps_sampled: 410000
    num_steps_trained: 410000
    wait_time_ms: 165.476
  iterations_since_restore: 41
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 726.7904140949249
  time_this_iter_s: 17.55779767036438
  time_total_s: 726.7904140949249
  timestamp: 1593885175
  timesteps_since_restore: 410000
  timesteps_this_iter: 10000
  timesteps_total: 410000
  training_iteration: 41
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 726 s, 41 iter, 410000 ts, 35.1 rew

agent-1: 24.0
agent-2: 21.0
agent-3: 25.0
agent-4: 26.0
agent-5: 22.0
agent-6: 22.0
agent-7: 25.0
agent-8: 20.0
agent-9: 22.0
agent-10: 19.0
Sum Reward: 226.0
Avg Reward: 22.6
Min Reward: 19.0
Gini Coefficient: 0.05486725663716814
20:20 Ratio: 1.3076923076923077
Max-min Ratio: 1.368421052631579
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-53-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 39.78048780487805
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 41
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.461
    dispatch_time_ms: 7.336
    learner:
      cur_lr: 0.0013326939661055803
      grad_gnorm: 40.000003814697266
      policy_entropy: 82.3641128540039
      policy_loss: -35.36526107788086
      var_gnorm: 29.395092010498047
      vf_explained_var: 0.35533928871154785
      vf_loss: 79.32904815673828
    num_steps_sampled: 420000
    num_steps_trained: 420000
    wait_time_ms: 166.106
  iterations_since_restore: 42
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 744.3552687168121
  time_this_iter_s: 17.564854621887207
  time_total_s: 744.3552687168121
  timestamp: 1593885193
  timesteps_since_restore: 420000
  timesteps_this_iter: 10000
  timesteps_total: 420000
  training_iteration: 42
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 744 s, 42 iter, 420000 ts, 39.8 rew

agent-1: 22.0
agent-2: 32.0
agent-3: 13.0
agent-4: 22.0
agent-5: 25.0
agent-6: 24.0
agent-7: 32.0
agent-8: 24.0
agent-9: 31.0
agent-10: 22.0
Sum Reward: 247.0
Avg Reward: 24.7
Min Reward: 13.0
Gini Coefficient: 0.1194331983805668
20:20 Ratio: 1.8285714285714285
Max-min Ratio: 2.4615384615384617
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-53-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 44.714285714285715
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 42
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.678
    dispatch_time_ms: 7.583
    learner:
      cur_lr: 0.0013320279540494084
      grad_gnorm: 1.1244078874588013
      policy_entropy: 127.17720794677734
      policy_loss: -0.6004524827003479
      var_gnorm: 29.75775909423828
      vf_explained_var: 0.9895445704460144
      vf_loss: 0.0009887508349493146
    num_steps_sampled: 430000
    num_steps_trained: 430000
    wait_time_ms: 163.573
  iterations_since_restore: 43
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 761.8162198066711
  time_this_iter_s: 17.46095108985901
  time_total_s: 761.8162198066711
  timestamp: 1593885210
  timesteps_since_restore: 430000
  timesteps_this_iter: 10000
  timesteps_total: 430000
  training_iteration: 43
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 761 s, 43 iter, 430000 ts, 44.7 rew

agent-1: 19.0
agent-2: 27.0
agent-3: 22.0
agent-4: 29.0
agent-5: 30.0
agent-6: 33.0
agent-7: 32.0
agent-8: 19.0
agent-9: 35.0
agent-10: 24.0
Sum Reward: 270.0
Avg Reward: 27.0
Min Reward: 19.0
Gini Coefficient: 0.11555555555555555
20:20 Ratio: 1.7894736842105263
Max-min Ratio: 1.8421052631578947
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-53-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 49.95348837209303
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 43
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.817
    dispatch_time_ms: 7.053
    learner:
      cur_lr: 0.0013313619419932365
      grad_gnorm: 39.99999237060547
      policy_entropy: 91.64788055419922
      policy_loss: 32.52440643310547
      var_gnorm: 29.780351638793945
      vf_explained_var: 0.8934093117713928
      vf_loss: 40.8618278503418
    num_steps_sampled: 440000
    num_steps_trained: 440000
    wait_time_ms: 161.341
  iterations_since_restore: 44
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 779.4120540618896
  time_this_iter_s: 17.595834255218506
  time_total_s: 779.4120540618896
  timestamp: 1593885228
  timesteps_since_restore: 440000
  timesteps_this_iter: 10000
  timesteps_total: 440000
  training_iteration: 44
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 779 s, 44 iter, 440000 ts, 50 rew

agent-1: 19.0
agent-2: 21.0
agent-3: 13.0
agent-4: 21.0
agent-5: 28.0
agent-6: 29.0
agent-7: 26.0
agent-8: 23.0
agent-9: 28.0
agent-10: 17.0
Sum Reward: 225.0
Avg Reward: 22.5
Min Reward: 13.0
Gini Coefficient: 0.12577777777777777
20:20 Ratio: 1.9
Max-min Ratio: 2.230769230769231
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-54-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 53.93181818181818
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 44
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.784
    dispatch_time_ms: 7.693
    learner:
      cur_lr: 0.0013306960463523865
      grad_gnorm: 1.4153028726577759
      policy_entropy: 129.9520263671875
      policy_loss: 0.8980710506439209
      var_gnorm: 30.081968307495117
      vf_explained_var: 0.541994571685791
      vf_loss: 0.001069570193067193
    num_steps_sampled: 450000
    num_steps_trained: 450000
    wait_time_ms: 164.783
  iterations_since_restore: 45
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 796.9520998001099
  time_this_iter_s: 17.540045738220215
  time_total_s: 796.9520998001099
  timestamp: 1593885245
  timesteps_since_restore: 450000
  timesteps_this_iter: 10000
  timesteps_total: 450000
  training_iteration: 45
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 796 s, 45 iter, 450000 ts, 53.9 rew

agent-1: 18.0
agent-2: 30.0
agent-3: 23.0
agent-4: 13.0
agent-5: 28.0
agent-6: 23.0
agent-7: 26.0
agent-8: 31.0
agent-9: 18.0
agent-10: 17.0
Sum Reward: 227.0
Avg Reward: 22.7
Min Reward: 13.0
Gini Coefficient: 0.14405286343612334
20:20 Ratio: 2.033333333333333
Max-min Ratio: 2.3846153846153846
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-54-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 57.77777777777778
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 45
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.799
    dispatch_time_ms: 7.8
    learner:
      cur_lr: 0.0013300300342962146
      grad_gnorm: 2.7626075744628906
      policy_entropy: 133.41326904296875
      policy_loss: -1.1216027736663818
      var_gnorm: 30.10284996032715
      vf_explained_var: -0.08220160007476807
      vf_loss: 0.005268039647489786
    num_steps_sampled: 460000
    num_steps_trained: 460000
    wait_time_ms: 170.601
  iterations_since_restore: 46
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 814.5433447360992
  time_this_iter_s: 17.59124493598938
  time_total_s: 814.5433447360992
  timestamp: 1593885263
  timesteps_since_restore: 460000
  timesteps_this_iter: 10000
  timesteps_total: 460000
  training_iteration: 46
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 814 s, 46 iter, 460000 ts, 57.8 rew

agent-1: 26.0
agent-2: 28.0
agent-3: 9.0
agent-4: 21.0
agent-5: 28.0
agent-6: 31.0
agent-7: 22.0
agent-8: 27.0
agent-9: 23.0
agent-10: 22.0
Sum Reward: 237.0
Avg Reward: 23.7
Min Reward: 9.0
Gini Coefficient: 0.12447257383966245
20:20 Ratio: 1.9666666666666666
Max-min Ratio: 3.4444444444444446
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-54-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 61.67391304347826
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 46
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.445
    dispatch_time_ms: 5.885
    learner:
      cur_lr: 0.0013293640222400427
      grad_gnorm: 2.566878318786621
      policy_entropy: 104.47318267822266
      policy_loss: -0.5594122409820557
      var_gnorm: 30.454788208007812
      vf_explained_var: 0.986973762512207
      vf_loss: 0.004256664775311947
    num_steps_sampled: 470000
    num_steps_trained: 470000
    wait_time_ms: 174.301
  iterations_since_restore: 47
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 832.0643861293793
  time_this_iter_s: 17.52104139328003
  time_total_s: 832.0643861293793
  timestamp: 1593885280
  timesteps_since_restore: 470000
  timesteps_this_iter: 10000
  timesteps_total: 470000
  training_iteration: 47
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 832 s, 47 iter, 470000 ts, 61.7 rew

agent-1: 33.0
agent-2: 32.0
agent-3: 22.0
agent-4: 29.0
agent-5: 13.0
agent-6: 22.0
agent-7: 27.0
agent-8: 28.0
agent-9: 26.0
agent-10: 26.0
Sum Reward: 258.0
Avg Reward: 25.8
Min Reward: 13.0
Gini Coefficient: 0.11317829457364341
20:20 Ratio: 1.8571428571428572
Max-min Ratio: 2.5384615384615383
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-54-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 65.85106382978724
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 47
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.774
    dispatch_time_ms: 7.025
    learner:
      cur_lr: 0.0013286980101838708
      grad_gnorm: 23.212495803833008
      policy_entropy: 125.15052032470703
      policy_loss: 0.21009373664855957
      var_gnorm: 30.48685646057129
      vf_explained_var: 0.45187920331954956
      vf_loss: 2.977134943008423
    num_steps_sampled: 480000
    num_steps_trained: 480000
    wait_time_ms: 162.314
  iterations_since_restore: 48
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 849.7056283950806
  time_this_iter_s: 17.641242265701294
  time_total_s: 849.7056283950806
  timestamp: 1593885298
  timesteps_since_restore: 480000
  timesteps_this_iter: 10000
  timesteps_total: 480000
  training_iteration: 48
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 849 s, 48 iter, 480000 ts, 65.9 rew

agent-1: 18.0
agent-2: 20.0
agent-3: 22.0
agent-4: 16.0
agent-5: 17.0
agent-6: 29.0
agent-7: 27.0
agent-8: 23.0
agent-9: 26.0
agent-10: 18.0
Sum Reward: 216.0
Avg Reward: 21.6
Min Reward: 16.0
Gini Coefficient: 0.11296296296296296
20:20 Ratio: 1.696969696969697
Max-min Ratio: 1.8125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-55-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 68.97916666666667
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 48
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.57
    dispatch_time_ms: 8.002
    learner:
      cur_lr: 0.001328031998127699
      grad_gnorm: 0.9465321898460388
      policy_entropy: 134.27093505859375
      policy_loss: -0.20014752447605133
      var_gnorm: 30.771074295043945
      vf_explained_var: 0.9262536764144897
      vf_loss: 0.005211245268583298
    num_steps_sampled: 490000
    num_steps_trained: 490000
    wait_time_ms: 167.54
  iterations_since_restore: 49
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 867.1859803199768
  time_this_iter_s: 17.48035192489624
  time_total_s: 867.1859803199768
  timestamp: 1593885316
  timesteps_since_restore: 490000
  timesteps_this_iter: 10000
  timesteps_total: 490000
  training_iteration: 49
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 867 s, 49 iter, 490000 ts, 69 rew

agent-1: 23.0
agent-2: 26.0
agent-3: 22.0
agent-4: 21.0
agent-5: 22.0
agent-6: 23.0
agent-7: 20.0
agent-8: 29.0
agent-9: 20.0
agent-10: 20.0
Sum Reward: 226.0
Avg Reward: 22.6
Min Reward: 20.0
Gini Coefficient: 0.06371681415929203
20:20 Ratio: 1.375
Max-min Ratio: 1.45
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-55-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 72.18367346938776
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 49
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.707
    dispatch_time_ms: 6.73
    learner:
      cur_lr: 0.001327365986071527
      grad_gnorm: 3.4354772567749023
      policy_entropy: 137.05059814453125
      policy_loss: -0.8324910998344421
      var_gnorm: 30.758012771606445
      vf_explained_var: 0.9667530655860901
      vf_loss: 0.007650040090084076
    num_steps_sampled: 500000
    num_steps_trained: 500000
    wait_time_ms: 167.062
  iterations_since_restore: 50
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 884.7738101482391
  time_this_iter_s: 17.58782982826233
  time_total_s: 884.7738101482391
  timestamp: 1593885333
  timesteps_since_restore: 500000
  timesteps_this_iter: 10000
  timesteps_total: 500000
  training_iteration: 50
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 884 s, 50 iter, 500000 ts, 72.2 rew

agent-1: 30.0
agent-2: 13.0
agent-3: 19.0
agent-4: 23.0
agent-5: 20.0
agent-6: 28.0
agent-7: 27.0
agent-8: 18.0
agent-9: 28.0
agent-10: 24.0
Sum Reward: 230.0
Avg Reward: 23.0
Min Reward: 13.0
Gini Coefficient: 0.12608695652173912
20:20 Ratio: 1.8709677419354838
Max-min Ratio: 2.3076923076923075
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-55-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 75.34
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 50
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.022
    dispatch_time_ms: 7.22
    learner:
      cur_lr: 0.0013266999740153551
      grad_gnorm: 21.709617614746094
      policy_entropy: 138.97222900390625
      policy_loss: -1.333778977394104
      var_gnorm: 31.106300354003906
      vf_explained_var: 0.30115973949432373
      vf_loss: 0.11853775382041931
    num_steps_sampled: 510000
    num_steps_trained: 510000
    wait_time_ms: 170.782
  iterations_since_restore: 51
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 902.2988114356995
  time_this_iter_s: 17.525001287460327
  time_total_s: 902.2988114356995
  timestamp: 1593885351
  timesteps_since_restore: 510000
  timesteps_this_iter: 10000
  timesteps_total: 510000
  training_iteration: 51
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 902 s, 51 iter, 510000 ts, 75.3 rew

agent-1: 16.0
agent-2: 33.0
agent-3: 17.0
agent-4: 32.0
agent-5: 24.0
agent-6: 27.0
agent-7: 20.0
agent-8: 26.0
agent-9: 28.0
agent-10: 24.0
Sum Reward: 247.0
Avg Reward: 24.7
Min Reward: 16.0
Gini Coefficient: 0.12510121457489878
20:20 Ratio: 1.9696969696969697
Max-min Ratio: 2.0625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-56-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 78.70588235294117
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 51
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.71
    dispatch_time_ms: 7.328
    learner:
      cur_lr: 0.0013260339619591832
      grad_gnorm: 40.000003814697266
      policy_entropy: 93.64520263671875
      policy_loss: -16.308473587036133
      var_gnorm: 31.359291076660156
      vf_explained_var: -0.2006438970565796
      vf_loss: 2.5811197757720947
    num_steps_sampled: 520000
    num_steps_trained: 520000
    wait_time_ms: 173.849
  iterations_since_restore: 52
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 920.0422022342682
  time_this_iter_s: 17.743390798568726
  time_total_s: 920.0422022342682
  timestamp: 1593885369
  timesteps_since_restore: 520000
  timesteps_this_iter: 10000
  timesteps_total: 520000
  training_iteration: 52
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 920 s, 52 iter, 520000 ts, 78.7 rew

agent-1: 28.0
agent-2: 22.0
agent-3: 27.0
agent-4: 26.0
agent-5: 9.0
agent-6: 21.0
agent-7: 23.0
agent-8: 17.0
agent-9: 30.0
agent-10: 19.0
Sum Reward: 222.0
Avg Reward: 22.2
Min Reward: 9.0
Gini Coefficient: 0.14504504504504503
20:20 Ratio: 2.230769230769231
Max-min Ratio: 3.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-56-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 81.46153846153847
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 52
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.924
    dispatch_time_ms: 6.682
    learner:
      cur_lr: 0.0013253679499030113
      grad_gnorm: 8.865467071533203
      policy_entropy: 147.14862060546875
      policy_loss: 3.123899459838867
      var_gnorm: 31.57242202758789
      vf_explained_var: 0.1646783947944641
      vf_loss: 0.14573021233081818
    num_steps_sampled: 530000
    num_steps_trained: 530000
    wait_time_ms: 175.774
  iterations_since_restore: 53
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 937.6557805538177
  time_this_iter_s: 17.61357831954956
  time_total_s: 937.6557805538177
  timestamp: 1593885386
  timesteps_since_restore: 530000
  timesteps_this_iter: 10000
  timesteps_total: 530000
  training_iteration: 53
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 937 s, 53 iter, 530000 ts, 81.5 rew

agent-1: 11.0
agent-2: 27.0
agent-3: 33.0
agent-4: 28.0
agent-5: 30.0
agent-6: 17.0
agent-7: 29.0
agent-8: 25.0
agent-9: 15.0
agent-10: 28.0
Sum Reward: 243.0
Avg Reward: 24.3
Min Reward: 11.0
Gini Coefficient: 0.1534979423868313
20:20 Ratio: 2.423076923076923
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-56-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 84.50943396226415
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 53
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.652
    dispatch_time_ms: 7.747
    learner:
      cur_lr: 0.0013247020542621613
      grad_gnorm: 4.9656805992126465
      policy_entropy: 146.48800659179688
      policy_loss: -1.4909193515777588
      var_gnorm: 31.649839401245117
      vf_explained_var: -1.0
      vf_loss: 0.043067917227745056
    num_steps_sampled: 540000
    num_steps_trained: 540000
    wait_time_ms: 173.583
  iterations_since_restore: 54
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 955.1270215511322
  time_this_iter_s: 17.471240997314453
  time_total_s: 955.1270215511322
  timestamp: 1593885404
  timesteps_since_restore: 540000
  timesteps_this_iter: 10000
  timesteps_total: 540000
  training_iteration: 54
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 955 s, 54 iter, 540000 ts, 84.5 rew

agent-1: 9.0
agent-2: 38.0
agent-3: 33.0
agent-4: 10.0
agent-5: 13.0
agent-6: 25.0
agent-7: 19.0
agent-8: 27.0
agent-9: 21.0
agent-10: 23.0
Sum Reward: 218.0
Avg Reward: 21.8
Min Reward: 9.0
Gini Coefficient: 0.23486238532110093
20:20 Ratio: 3.736842105263158
Max-min Ratio: 4.222222222222222
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-57-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 86.98148148148148
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 54
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.975
    dispatch_time_ms: 10.161
    learner:
      cur_lr: 0.0013240360422059894
      grad_gnorm: 4.400909900665283
      policy_entropy: 125.18059539794922
      policy_loss: 1.5398772954940796
      var_gnorm: 31.884828567504883
      vf_explained_var: 0.6274334192276001
      vf_loss: 0.020902538672089577
    num_steps_sampled: 550000
    num_steps_trained: 550000
    wait_time_ms: 162.754
  iterations_since_restore: 55
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 972.7036168575287
  time_this_iter_s: 17.576595306396484
  time_total_s: 972.7036168575287
  timestamp: 1593885421
  timesteps_since_restore: 550000
  timesteps_this_iter: 10000
  timesteps_total: 550000
  training_iteration: 55
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 972 s, 55 iter, 550000 ts, 87 rew

agent-1: 32.0
agent-2: 18.0
agent-3: 29.0
agent-4: 35.0
agent-5: 17.0
agent-6: 24.0
agent-7: 29.0
agent-8: 17.0
agent-9: 9.0
agent-10: 24.0
Sum Reward: 234.0
Avg Reward: 23.4
Min Reward: 9.0
Gini Coefficient: 0.18461538461538463
20:20 Ratio: 2.576923076923077
Max-min Ratio: 3.888888888888889
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-57-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 89.65454545454546
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 55
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.896
    dispatch_time_ms: 6.186
    learner:
      cur_lr: 0.0013233700301498175
      grad_gnorm: 26.888357162475586
      policy_entropy: 124.68498992919922
      policy_loss: -5.226868152618408
      var_gnorm: 31.907135009765625
      vf_explained_var: 0.7845597267150879
      vf_loss: 2.3687655925750732
    num_steps_sampled: 560000
    num_steps_trained: 560000
    wait_time_ms: 173.024
  iterations_since_restore: 56
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 990.1654427051544
  time_this_iter_s: 17.461825847625732
  time_total_s: 990.1654427051544
  timestamp: 1593885439
  timesteps_since_restore: 560000
  timesteps_this_iter: 10000
  timesteps_total: 560000
  training_iteration: 56
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 990 s, 56 iter, 560000 ts, 89.7 rew

agent-1: 13.0
agent-2: 18.0
agent-3: 23.0
agent-4: 29.0
agent-5: 24.0
agent-6: 24.0
agent-7: 30.0
agent-8: 30.0
agent-9: 18.0
agent-10: 21.0
Sum Reward: 230.0
Avg Reward: 23.0
Min Reward: 13.0
Gini Coefficient: 0.13130434782608696
20:20 Ratio: 1.935483870967742
Max-min Ratio: 2.3076923076923075
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-57-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 92.16071428571429
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 56
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.752
    dispatch_time_ms: 7.54
    learner:
      cur_lr: 0.0013227040180936456
      grad_gnorm: 0.6347909569740295
      policy_entropy: 124.27812194824219
      policy_loss: 0.38970789313316345
      var_gnorm: 32.12730026245117
      vf_explained_var: 0.9140774011611938
      vf_loss: 0.0007190643227659166
    num_steps_sampled: 570000
    num_steps_trained: 570000
    wait_time_ms: 167.152
  iterations_since_restore: 57
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 1007.5377833843231
  time_this_iter_s: 17.3723406791687
  time_total_s: 1007.5377833843231
  timestamp: 1593885456
  timesteps_since_restore: 570000
  timesteps_this_iter: 10000
  timesteps_total: 570000
  training_iteration: 57
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 1007 s, 57 iter, 570000 ts, 92.2 rew

agent-1: 18.0
agent-2: 20.0
agent-3: 18.0
agent-4: 36.0
agent-5: 24.0
agent-6: 22.0
agent-7: 31.0
agent-8: 34.0
agent-9: 21.0
agent-10: 26.0
Sum Reward: 250.0
Avg Reward: 25.0
Min Reward: 18.0
Gini Coefficient: 0.1384
20:20 Ratio: 1.9444444444444444
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-57-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 94.9298245614035
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 57
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.776
    dispatch_time_ms: 6.748
    learner:
      cur_lr: 0.0013220380060374737
      grad_gnorm: 4.79871940612793
      policy_entropy: 131.92295837402344
      policy_loss: 0.8318917751312256
      var_gnorm: 32.27214431762695
      vf_explained_var: 0.21693158149719238
      vf_loss: 0.046339794993400574
    num_steps_sampled: 580000
    num_steps_trained: 580000
    wait_time_ms: 173.027
  iterations_since_restore: 58
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 1025.0957624912262
  time_this_iter_s: 17.557979106903076
  time_total_s: 1025.0957624912262
  timestamp: 1593885474
  timesteps_since_restore: 580000
  timesteps_this_iter: 10000
  timesteps_total: 580000
  training_iteration: 58
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 1025 s, 58 iter, 580000 ts, 94.9 rew

agent-1: 25.0
agent-2: 22.0
agent-3: 23.0
agent-4: 16.0
agent-5: 22.0
agent-6: 24.0
agent-7: 20.0
agent-8: 25.0
agent-9: 12.0
agent-10: 21.0
Sum Reward: 210.0
Avg Reward: 21.0
Min Reward: 12.0
Gini Coefficient: 0.0980952380952381
20:20 Ratio: 1.7857142857142858
Max-min Ratio: 2.0833333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-58-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 96.91379310344827
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 58
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.924
    dispatch_time_ms: 7.828
    learner:
      cur_lr: 0.0013213719939813018
      grad_gnorm: 0.26276469230651855
      policy_entropy: 123.41215515136719
      policy_loss: 0.07121454924345016
      var_gnorm: 32.482276916503906
      vf_explained_var: 0.9089338779449463
      vf_loss: 0.0004923358792439103
    num_steps_sampled: 590000
    num_steps_trained: 590000
    wait_time_ms: 166.91
  iterations_since_restore: 59
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 1042.8819086551666
  time_this_iter_s: 17.78614616394043
  time_total_s: 1042.8819086551666
  timestamp: 1593885492
  timesteps_since_restore: 590000
  timesteps_this_iter: 10000
  timesteps_total: 590000
  training_iteration: 59
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 1042 s, 59 iter, 590000 ts, 96.9 rew

agent-1: 21.0
agent-2: 25.0
agent-3: 23.0
agent-4: 24.0
agent-5: 27.0
agent-6: 18.0
agent-7: 19.0
agent-8: 19.0
agent-9: 17.0
agent-10: 25.0
Sum Reward: 218.0
Avg Reward: 21.8
Min Reward: 17.0
Gini Coefficient: 0.0853211009174312
20:20 Ratio: 1.4857142857142858
Max-min Ratio: 1.588235294117647
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-58-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 98.96610169491525
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 59
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.013
    dispatch_time_ms: 6.753
    learner:
      cur_lr: 0.0013207059819251299
      grad_gnorm: 13.3593111038208
      policy_entropy: 150.9517364501953
      policy_loss: 1.4432076215744019
      var_gnorm: 32.61397171020508
      vf_explained_var: 0.38691651821136475
      vf_loss: 1.746475100517273
    num_steps_sampled: 600000
    num_steps_trained: 600000
    wait_time_ms: 173.688
  iterations_since_restore: 60
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 1060.6172235012054
  time_this_iter_s: 17.73531484603882
  time_total_s: 1060.6172235012054
  timestamp: 1593885509
  timesteps_since_restore: 600000
  timesteps_this_iter: 10000
  timesteps_total: 600000
  training_iteration: 60
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 1060 s, 60 iter, 600000 ts, 99 rew

agent-1: 20.0
agent-2: 21.0
agent-3: 21.0
agent-4: 27.0
agent-5: 15.0
agent-6: 20.0
agent-7: 25.0
agent-8: 21.0
agent-9: 20.0
agent-10: 23.0
Sum Reward: 213.0
Avg Reward: 21.3
Min Reward: 15.0
Gini Coefficient: 0.0755868544600939
20:20 Ratio: 1.4857142857142858
Max-min Ratio: 1.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-58-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 100.86666666666666
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 60
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.948
    dispatch_time_ms: 7.964
    learner:
      cur_lr: 0.001320039969868958
      grad_gnorm: 0.6644262075424194
      policy_entropy: 139.88330078125
      policy_loss: 0.5321797132492065
      var_gnorm: 32.717464447021484
      vf_explained_var: 0.9791443347930908
      vf_loss: 0.0002817645436152816
    num_steps_sampled: 610000
    num_steps_trained: 610000
    wait_time_ms: 168.164
  iterations_since_restore: 61
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 1078.3294553756714
  time_this_iter_s: 17.712231874465942
  time_total_s: 1078.3294553756714
  timestamp: 1593885527
  timesteps_since_restore: 610000
  timesteps_this_iter: 10000
  timesteps_total: 610000
  training_iteration: 61
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 1078 s, 61 iter, 610000 ts, 101 rew

agent-1: 16.0
agent-2: 25.0
agent-3: 23.0
agent-4: 21.0
agent-5: 22.0
agent-6: 20.0
agent-7: 22.0
agent-8: 24.0
agent-9: 27.0
agent-10: 29.0
Sum Reward: 229.0
Avg Reward: 22.9
Min Reward: 16.0
Gini Coefficient: 0.08427947598253276
20:20 Ratio: 1.5555555555555556
Max-min Ratio: 1.8125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-59-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 102.9672131147541
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 61
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.855
    dispatch_time_ms: 8.602
    learner:
      cur_lr: 0.001319373957812786
      grad_gnorm: 6.494960784912109
      policy_entropy: 146.6810760498047
      policy_loss: -1.429524540901184
      var_gnorm: 32.799896240234375
      vf_explained_var: -1.0
      vf_loss: 0.018971629440784454
    num_steps_sampled: 620000
    num_steps_trained: 620000
    wait_time_ms: 170.301
  iterations_since_restore: 62
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 1096.1248416900635
  time_this_iter_s: 17.79538631439209
  time_total_s: 1096.1248416900635
  timestamp: 1593885545
  timesteps_since_restore: 620000
  timesteps_this_iter: 10000
  timesteps_total: 620000
  training_iteration: 62
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 1096 s, 62 iter, 620000 ts, 103 rew

agent-1: 23.0
agent-2: 23.0
agent-3: 27.0
agent-4: 16.0
agent-5: 24.0
agent-6: 27.0
agent-7: 22.0
agent-8: 20.0
agent-9: 17.0
agent-10: 21.0
Sum Reward: 220.0
Avg Reward: 22.0
Min Reward: 16.0
Gini Coefficient: 0.0890909090909091
20:20 Ratio: 1.6363636363636365
Max-min Ratio: 1.6875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-59-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 104.85483870967742
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 62
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.315
    dispatch_time_ms: 6.427
    learner:
      cur_lr: 0.0013187079457566142
      grad_gnorm: 4.839974403381348
      policy_entropy: 121.25721740722656
      policy_loss: 2.5158112049102783
      var_gnorm: 32.950523376464844
      vf_explained_var: -0.1225200891494751
      vf_loss: 0.026314720511436462
    num_steps_sampled: 630000
    num_steps_trained: 630000
    wait_time_ms: 172.685
  iterations_since_restore: 63
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 1113.8910825252533
  time_this_iter_s: 17.76624083518982
  time_total_s: 1113.8910825252533
  timestamp: 1593885563
  timesteps_since_restore: 630000
  timesteps_this_iter: 10000
  timesteps_total: 630000
  training_iteration: 63
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 1113 s, 63 iter, 630000 ts, 105 rew

agent-1: 25.0
agent-2: 28.0
agent-3: 23.0
agent-4: 3.0
agent-5: 24.0
agent-6: 22.0
agent-7: 19.0
agent-8: 23.0
agent-9: 36.0
agent-10: 24.0
Sum Reward: 227.0
Avg Reward: 22.7
Min Reward: 3.0
Gini Coefficient: 0.1669603524229075
20:20 Ratio: 2.909090909090909
Max-min Ratio: 12.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-59-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 106.7936507936508
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 63
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.784
    dispatch_time_ms: 6.236
    learner:
      cur_lr: 0.0013180420501157641
      grad_gnorm: 13.617382049560547
      policy_entropy: 154.3839111328125
      policy_loss: 5.5155229568481445
      var_gnorm: 33.1624870300293
      vf_explained_var: 0.22053825855255127
      vf_loss: 0.18840999901294708
    num_steps_sampled: 640000
    num_steps_trained: 640000
    wait_time_ms: 166.17
  iterations_since_restore: 64
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 1131.5576374530792
  time_this_iter_s: 17.666554927825928
  time_total_s: 1131.5576374530792
  timestamp: 1593885581
  timesteps_since_restore: 640000
  timesteps_this_iter: 10000
  timesteps_total: 640000
  training_iteration: 64
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 1131 s, 64 iter, 640000 ts, 107 rew

agent-1: 31.0
agent-2: 22.0
agent-3: 26.0
agent-4: 27.0
agent-5: 29.0
agent-6: 22.0
agent-7: 20.0
agent-8: 22.0
agent-9: 22.0
agent-10: 9.0
Sum Reward: 230.0
Avg Reward: 23.0
Min Reward: 9.0
Gini Coefficient: 0.12956521739130436
20:20 Ratio: 2.0689655172413794
Max-min Ratio: 3.4444444444444446
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-59-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 108.71875
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 64
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.085
    dispatch_time_ms: 6.607
    learner:
      cur_lr: 0.0013173760380595922
      grad_gnorm: 2.4675967693328857
      policy_entropy: 148.85101318359375
      policy_loss: 0.28823336958885193
      var_gnorm: 33.27488708496094
      vf_explained_var: 0.10825449228286743
      vf_loss: 0.012353695929050446
    num_steps_sampled: 650000
    num_steps_trained: 650000
    wait_time_ms: 167.197
  iterations_since_restore: 65
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 1149.4073259830475
  time_this_iter_s: 17.84968852996826
  time_total_s: 1149.4073259830475
  timestamp: 1593885598
  timesteps_since_restore: 650000
  timesteps_this_iter: 10000
  timesteps_total: 650000
  training_iteration: 65
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 1149 s, 65 iter, 650000 ts, 109 rew

agent-1: 17.0
agent-2: 32.0
agent-3: 25.0
agent-4: 16.0
agent-5: 20.0
agent-6: 20.0
agent-7: 29.0
agent-8: 24.0
agent-9: 22.0
agent-10: 19.0
Sum Reward: 224.0
Avg Reward: 22.4
Min Reward: 16.0
Gini Coefficient: 0.12142857142857143
20:20 Ratio: 1.8484848484848484
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-00-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 110.49230769230769
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 65
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.896
    dispatch_time_ms: 6.632
    learner:
      cur_lr: 0.0013167100260034204
      grad_gnorm: 6.683737277984619
      policy_entropy: 144.34268188476562
      policy_loss: 1.4547227621078491
      var_gnorm: 33.35440444946289
      vf_explained_var: -1.0
      vf_loss: 0.03011879324913025
    num_steps_sampled: 660000
    num_steps_trained: 660000
    wait_time_ms: 171.979
  iterations_since_restore: 66
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 1167.3055539131165
  time_this_iter_s: 17.89822793006897
  time_total_s: 1167.3055539131165
  timestamp: 1593885616
  timesteps_since_restore: 660000
  timesteps_this_iter: 10000
  timesteps_total: 660000
  training_iteration: 66
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 1167 s, 66 iter, 660000 ts, 110 rew

agent-1: 12.0
agent-2: 23.0
agent-3: 23.0
agent-4: 22.0
agent-5: 23.0
agent-6: 20.0
agent-7: 18.0
agent-8: 23.0
agent-9: 23.0
agent-10: 19.0
Sum Reward: 206.0
Avg Reward: 20.6
Min Reward: 12.0
Gini Coefficient: 0.07961165048543689
20:20 Ratio: 1.5333333333333334
Max-min Ratio: 1.9166666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-00-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 111.93939393939394
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 66
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.465
    dispatch_time_ms: 6.616
    learner:
      cur_lr: 0.0013160440139472485
      grad_gnorm: 5.543017387390137
      policy_entropy: 138.9819793701172
      policy_loss: -0.30316096544265747
      var_gnorm: 33.545875549316406
      vf_explained_var: -0.08303475379943848
      vf_loss: 0.03090730309486389
    num_steps_sampled: 670000
    num_steps_trained: 670000
    wait_time_ms: 166.077
  iterations_since_restore: 67
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 1184.9483654499054
  time_this_iter_s: 17.64281153678894
  time_total_s: 1184.9483654499054
  timestamp: 1593885634
  timesteps_since_restore: 670000
  timesteps_this_iter: 10000
  timesteps_total: 670000
  training_iteration: 67
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 1184 s, 67 iter, 670000 ts, 112 rew

agent-1: 25.0
agent-2: 30.0
agent-3: 30.0
agent-4: 19.0
agent-5: 20.0
agent-6: 20.0
agent-7: 14.0
agent-8: 21.0
agent-9: 12.0
agent-10: 22.0
Sum Reward: 213.0
Avg Reward: 21.3
Min Reward: 12.0
Gini Coefficient: 0.1460093896713615
20:20 Ratio: 2.3076923076923075
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-00-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 113.44776119402985
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 67
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.671
    dispatch_time_ms: 5.935
    learner:
      cur_lr: 0.0013153780018910766
      grad_gnorm: 4.808577060699463
      policy_entropy: 156.36209106445312
      policy_loss: -0.538760781288147
      var_gnorm: 33.75388717651367
      vf_explained_var: -1.0
      vf_loss: 0.008508670143783092
    num_steps_sampled: 680000
    num_steps_trained: 680000
    wait_time_ms: 165.655
  iterations_since_restore: 68
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 1202.7460346221924
  time_this_iter_s: 17.797669172286987
  time_total_s: 1202.7460346221924
  timestamp: 1593885652
  timesteps_since_restore: 680000
  timesteps_this_iter: 10000
  timesteps_total: 680000
  training_iteration: 68
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 1202 s, 68 iter, 680000 ts, 113 rew

W0704 14:01:13.265805 32047 node_manager.cc:250] Last heartbeat was sent 11589 ms ago 
W0704 14:01:19.922859 32047 node_manager.cc:250] Last heartbeat was sent 6657 ms ago 
agent-1: 26.0
agent-2: 14.0
agent-3: 23.0
agent-4: 16.0
agent-5: 33.0
agent-6: 13.0
agent-7: 21.0
agent-8: 22.0
agent-9: 24.0
agent-10: 20.0
Sum Reward: 212.0
Avg Reward: 21.2
Min Reward: 13.0
Gini Coefficient: 0.1481132075471698
20:20 Ratio: 2.185185185185185
Max-min Ratio: 2.5384615384615383
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-01-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 114.8970588235294
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 68
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.258
    dispatch_time_ms: 8.082
    learner:
      cur_lr: 0.0013147119898349047
      grad_gnorm: 14.379261016845703
      policy_entropy: 112.67644500732422
      policy_loss: -5.226413249969482
      var_gnorm: 33.84532928466797
      vf_explained_var: -0.28389036655426025
      vf_loss: 0.3837435841560364
    num_steps_sampled: 690000
    num_steps_trained: 690000
    wait_time_ms: 170.071
  iterations_since_restore: 69
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 1245.485008239746
  time_this_iter_s: 42.73897361755371
  time_total_s: 1245.485008239746
  timestamp: 1593885695
  timesteps_since_restore: 690000
  timesteps_this_iter: 10000
  timesteps_total: 690000
  training_iteration: 69
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 1245 s, 69 iter, 690000 ts, 115 rew

agent-1: 17.0
agent-2: 22.0
agent-3: 23.0
agent-4: 18.0
agent-5: 16.0
agent-6: 18.0
agent-7: 16.0
agent-8: 14.0
agent-9: 20.0
agent-10: 29.0
Sum Reward: 193.0
Avg Reward: 19.3
Min Reward: 14.0
Gini Coefficient: 0.11554404145077721
20:20 Ratio: 1.7333333333333334
Max-min Ratio: 2.0714285714285716
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-01-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 116.02898550724638
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 69
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 4.475
    dispatch_time_ms: 7.345
    learner:
      cur_lr: 0.0013140459777787328
      grad_gnorm: 4.390736103057861
      policy_entropy: 58.19132995605469
      policy_loss: 0.6503986716270447
      var_gnorm: 33.97507858276367
      vf_explained_var: 0.12030589580535889
      vf_loss: 0.026350729167461395
    num_steps_sampled: 700000
    num_steps_trained: 700000
    wait_time_ms: 170.702
  iterations_since_restore: 70
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 1261.8669652938843
  time_this_iter_s: 16.381957054138184
  time_total_s: 1261.8669652938843
  timestamp: 1593885713
  timesteps_since_restore: 700000
  timesteps_this_iter: 10000
  timesteps_total: 700000
  training_iteration: 70
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 1261 s, 70 iter, 700000 ts, 116 rew

agent-1: 29.0
agent-2: 16.0
agent-3: 34.0
agent-4: 7.0
agent-5: 23.0
agent-6: 13.0
agent-7: 31.0
agent-8: 20.0
agent-9: 18.0
agent-10: 24.0
Sum Reward: 215.0
Avg Reward: 21.5
Min Reward: 7.0
Gini Coefficient: 0.2116279069767442
20:20 Ratio: 3.25
Max-min Ratio: 4.857142857142857
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-02-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 117.44285714285714
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 70
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.471
    dispatch_time_ms: 7.585
    learner:
      cur_lr: 0.0013133799657225609
      grad_gnorm: 1.0464621782302856
      policy_entropy: 85.04266357421875
      policy_loss: 0.36708998680114746
      var_gnorm: 34.313053131103516
      vf_explained_var: 0.9687134027481079
      vf_loss: 0.0011694013373926282
    num_steps_sampled: 710000
    num_steps_trained: 710000
    wait_time_ms: 172.308
  iterations_since_restore: 71
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 1279.6245374679565
  time_this_iter_s: 17.757572174072266
  time_total_s: 1279.6245374679565
  timestamp: 1593885731
  timesteps_since_restore: 710000
  timesteps_this_iter: 10000
  timesteps_total: 710000
  training_iteration: 71
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 1279 s, 71 iter, 710000 ts, 117 rew

agent-1: 28.0
agent-2: 17.0
agent-3: 28.0
agent-4: 16.0
agent-5: 20.0
agent-6: 31.0
agent-7: 27.0
agent-8: 22.0
agent-9: 28.0
agent-10: 25.0
Sum Reward: 242.0
Avg Reward: 24.2
Min Reward: 16.0
Gini Coefficient: 0.11239669421487604
20:20 Ratio: 1.7878787878787878
Max-min Ratio: 1.9375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-02-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 119.19718309859155
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 71
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.413
    dispatch_time_ms: 15.501
    learner:
      cur_lr: 0.001312713953666389
      grad_gnorm: 6.6196608543396
      policy_entropy: 123.1526870727539
      policy_loss: -2.3739118576049805
      var_gnorm: 34.54484176635742
      vf_explained_var: 0.9009630680084229
      vf_loss: 0.05137054622173309
    num_steps_sampled: 720000
    num_steps_trained: 720000
    wait_time_ms: 165.104
  iterations_since_restore: 72
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 1297.557697057724
  time_this_iter_s: 17.933159589767456
  time_total_s: 1297.557697057724
  timestamp: 1593885749
  timesteps_since_restore: 720000
  timesteps_this_iter: 10000
  timesteps_total: 720000
  training_iteration: 72
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 1297 s, 72 iter, 720000 ts, 119 rew

agent-1: 26.0
agent-2: 22.0
agent-3: 18.0
agent-4: 31.0
agent-5: 24.0
agent-6: 20.0
agent-7: 17.0
agent-8: 21.0
agent-9: 26.0
agent-10: 12.0
Sum Reward: 217.0
Avg Reward: 21.7
Min Reward: 12.0
Gini Coefficient: 0.13225806451612904
20:20 Ratio: 1.9655172413793103
Max-min Ratio: 2.5833333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-02-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 120.55555555555556
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 72
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.573
    dispatch_time_ms: 11.326
    learner:
      cur_lr: 0.001312048058025539
      grad_gnorm: 3.6333024501800537
      policy_entropy: 181.983642578125
      policy_loss: 1.6995099782943726
      var_gnorm: 34.6435661315918
      vf_explained_var: -0.47031450271606445
      vf_loss: 0.010201963596045971
    num_steps_sampled: 730000
    num_steps_trained: 730000
    wait_time_ms: 169.013
  iterations_since_restore: 73
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 1315.7925472259521
  time_this_iter_s: 18.23485016822815
  time_total_s: 1315.7925472259521
  timestamp: 1593885767
  timesteps_since_restore: 730000
  timesteps_this_iter: 10000
  timesteps_total: 730000
  training_iteration: 73
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 1315 s, 73 iter, 730000 ts, 121 rew

agent-1: 6.0
agent-2: 26.0
agent-3: 24.0
agent-4: 21.0
agent-5: 25.0
agent-6: 32.0
agent-7: 33.0
agent-8: 25.0
agent-9: 37.0
agent-10: 22.0
Sum Reward: 251.0
Avg Reward: 25.1
Min Reward: 6.0
Gini Coefficient: 0.16693227091633467
20:20 Ratio: 2.5925925925925926
Max-min Ratio: 6.166666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-03-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 122.34246575342466
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 73
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.977
    dispatch_time_ms: 47.353
    learner:
      cur_lr: 0.001311382045969367
      grad_gnorm: 17.18347930908203
      policy_entropy: 162.05075073242188
      policy_loss: -1.9903920888900757
      var_gnorm: 34.857669830322266
      vf_explained_var: 0.7930886149406433
      vf_loss: 0.15788564085960388
    num_steps_sampled: 740000
    num_steps_trained: 740000
    wait_time_ms: 67.576
  iterations_since_restore: 74
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 1336.137186050415
  time_this_iter_s: 20.34463882446289
  time_total_s: 1336.137186050415
  timestamp: 1593885788
  timesteps_since_restore: 740000
  timesteps_this_iter: 10000
  timesteps_total: 740000
  training_iteration: 74
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 1336 s, 74 iter, 740000 ts, 122 rew

agent-1: 30.0
agent-2: 33.0
agent-3: 15.0
agent-4: 23.0
agent-5: 26.0
agent-6: 22.0
agent-7: 29.0
agent-8: 22.0
agent-9: 26.0
agent-10: 18.0
Sum Reward: 244.0
Avg Reward: 24.4
Min Reward: 15.0
Gini Coefficient: 0.12131147540983607
20:20 Ratio: 1.9090909090909092
Max-min Ratio: 2.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-03-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 123.98648648648648
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 74
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.923
    dispatch_time_ms: 20.249
    learner:
      cur_lr: 0.0013107160339131951
      grad_gnorm: 10.450927734375
      policy_entropy: 146.67405700683594
      policy_loss: 2.5495948791503906
      var_gnorm: 35.07976531982422
      vf_explained_var: 0.052856385707855225
      vf_loss: 0.11344196647405624
    num_steps_sampled: 750000
    num_steps_trained: 750000
    wait_time_ms: 163.006
  iterations_since_restore: 75
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 1354.3654191493988
  time_this_iter_s: 18.228233098983765
  time_total_s: 1354.3654191493988
  timestamp: 1593885806
  timesteps_since_restore: 750000
  timesteps_this_iter: 10000
  timesteps_total: 750000
  training_iteration: 75
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 1354 s, 75 iter, 750000 ts, 124 rew

agent-1: 29.0
agent-2: 27.0
agent-3: 18.0
agent-4: 23.0
agent-5: 29.0
agent-6: 22.0
agent-7: 17.0
agent-8: 20.0
agent-9: 27.0
agent-10: 23.0
Sum Reward: 235.0
Avg Reward: 23.5
Min Reward: 17.0
Gini Coefficient: 0.1
20:20 Ratio: 1.6571428571428573
Max-min Ratio: 1.7058823529411764
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-03-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 125.46666666666667
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 75
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.832
    dispatch_time_ms: 24.116
    learner:
      cur_lr: 0.0013100500218570232
      grad_gnorm: 1.2082651853561401
      policy_entropy: 134.95701599121094
      policy_loss: -2.5429859161376953
      var_gnorm: 35.24095916748047
      vf_explained_var: -1.0
      vf_loss: 0.0003439809079281986
    num_steps_sampled: 760000
    num_steps_trained: 760000
    wait_time_ms: 164.636
  iterations_since_restore: 76
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 1372.956975221634
  time_this_iter_s: 18.591556072235107
  time_total_s: 1372.956975221634
  timestamp: 1593885825
  timesteps_since_restore: 760000
  timesteps_this_iter: 10000
  timesteps_total: 760000
  training_iteration: 76
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 1372 s, 76 iter, 760000 ts, 125 rew

agent-1: 22.0
agent-2: 23.0
agent-3: 16.0
agent-4: 30.0
agent-5: 20.0
agent-6: 30.0
agent-7: 20.0
agent-8: 15.0
agent-9: 38.0
agent-10: 25.0
Sum Reward: 239.0
Avg Reward: 23.9
Min Reward: 15.0
Gini Coefficient: 0.15523012552301255
20:20 Ratio: 2.193548387096774
Max-min Ratio: 2.533333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-04-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 126.96052631578948
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 76
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.504
    dispatch_time_ms: 34.24
    learner:
      cur_lr: 0.0013093840098008513
      grad_gnorm: 7.761972904205322
      policy_entropy: 107.0837631225586
      policy_loss: -2.2936742305755615
      var_gnorm: 35.359413146972656
      vf_explained_var: -1.0
      vf_loss: 0.06125066056847572
    num_steps_sampled: 770000
    num_steps_trained: 770000
    wait_time_ms: 156.895
  iterations_since_restore: 77
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 1391.5009191036224
  time_this_iter_s: 18.543943881988525
  time_total_s: 1391.5009191036224
  timestamp: 1593885843
  timesteps_since_restore: 770000
  timesteps_this_iter: 10000
  timesteps_total: 770000
  training_iteration: 77
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 1391 s, 77 iter, 770000 ts, 127 rew

agent-1: 26.0
agent-2: 14.0
agent-3: 24.0
agent-4: 17.0
agent-5: 16.0
agent-6: 25.0
agent-7: 16.0
agent-8: 22.0
agent-9: 21.0
agent-10: 23.0
Sum Reward: 204.0
Avg Reward: 20.4
Min Reward: 14.0
Gini Coefficient: 0.11274509803921569
20:20 Ratio: 1.7
Max-min Ratio: 1.8571428571428572
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-04-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 127.96103896103897
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 77
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 4.004
    dispatch_time_ms: 23.385
    learner:
      cur_lr: 0.0013087179977446795
      grad_gnorm: 3.1861965656280518
      policy_entropy: 135.79220581054688
      policy_loss: 1.7266817092895508
      var_gnorm: 35.464515686035156
      vf_explained_var: 0.9489437341690063
      vf_loss: 0.0064795855432748795
    num_steps_sampled: 780000
    num_steps_trained: 780000
    wait_time_ms: 173.367
  iterations_since_restore: 78
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 1409.8289670944214
  time_this_iter_s: 18.32804799079895
  time_total_s: 1409.8289670944214
  timestamp: 1593885862
  timesteps_since_restore: 780000
  timesteps_this_iter: 10000
  timesteps_total: 780000
  training_iteration: 78
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 1409 s, 78 iter, 780000 ts, 128 rew

agent-1: 21.0
agent-2: 13.0
agent-3: 17.0
agent-4: 16.0
agent-5: 32.0
agent-6: 24.0
agent-7: 17.0
agent-8: 33.0
agent-9: 25.0
agent-10: 18.0
Sum Reward: 216.0
Avg Reward: 21.6
Min Reward: 13.0
Gini Coefficient: 0.1648148148148148
20:20 Ratio: 2.2413793103448274
Max-min Ratio: 2.5384615384615383
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-04-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 129.0897435897436
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 78
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.821
    dispatch_time_ms: 18.556
    learner:
      cur_lr: 0.0013080519856885076
      grad_gnorm: 3.4780240058898926
      policy_entropy: 133.3308868408203
      policy_loss: -2.727144956588745
      var_gnorm: 35.64939880371094
      vf_explained_var: -1.0
      vf_loss: 0.022011160850524902
    num_steps_sampled: 790000
    num_steps_trained: 790000
    wait_time_ms: 139.45
  iterations_since_restore: 79
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 1428.0916583538055
  time_this_iter_s: 18.262691259384155
  time_total_s: 1428.0916583538055
  timestamp: 1593885880
  timesteps_since_restore: 790000
  timesteps_this_iter: 10000
  timesteps_total: 790000
  training_iteration: 79
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 1428 s, 79 iter, 790000 ts, 129 rew

agent-1: 28.0
agent-2: 31.0
agent-3: 15.0
agent-4: 27.0
agent-5: 17.0
agent-6: 19.0
agent-7: 20.0
agent-8: 19.0
agent-9: 30.0
agent-10: 15.0
Sum Reward: 221.0
Avg Reward: 22.1
Min Reward: 15.0
Gini Coefficient: 0.14886877828054298
20:20 Ratio: 2.033333333333333
Max-min Ratio: 2.066666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-04-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 130.25316455696202
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 79
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.797
    dispatch_time_ms: 21.95
    learner:
      cur_lr: 0.0013073859736323357
      grad_gnorm: 6.587831020355225
      policy_entropy: 168.43203735351562
      policy_loss: -1.023423194885254
      var_gnorm: 35.8481330871582
      vf_explained_var: -1.0
      vf_loss: 0.11754204332828522
    num_steps_sampled: 800000
    num_steps_trained: 800000
    wait_time_ms: 158.163
  iterations_since_restore: 80
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 1446.7201375961304
  time_this_iter_s: 18.62847924232483
  time_total_s: 1446.7201375961304
  timestamp: 1593885899
  timesteps_since_restore: 800000
  timesteps_this_iter: 10000
  timesteps_total: 800000
  training_iteration: 80
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 1446 s, 80 iter, 800000 ts, 130 rew

agent-1: 23.0
agent-2: 17.0
agent-3: 20.0
agent-4: 22.0
agent-5: 25.0
agent-6: 22.0
agent-7: 31.0
agent-8: 23.0
agent-9: 24.0
agent-10: 29.0
Sum Reward: 236.0
Avg Reward: 23.6
Min Reward: 17.0
Gini Coefficient: 0.08898305084745763
20:20 Ratio: 1.6216216216216217
Max-min Ratio: 1.8235294117647058
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-05-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 131.575
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 80
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.791
    dispatch_time_ms: 23.612
    learner:
      cur_lr: 0.0013067199615761638
      grad_gnorm: 11.155460357666016
      policy_entropy: 181.44700622558594
      policy_loss: -8.272090911865234
      var_gnorm: 36.041053771972656
      vf_explained_var: -1.0
      vf_loss: 0.22642803192138672
    num_steps_sampled: 810000
    num_steps_trained: 810000
    wait_time_ms: 153.907
  iterations_since_restore: 81
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 1464.6665647029877
  time_this_iter_s: 17.9464271068573
  time_total_s: 1464.6665647029877
  timestamp: 1593885917
  timesteps_since_restore: 810000
  timesteps_this_iter: 10000
  timesteps_total: 810000
  training_iteration: 81
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 1464 s, 81 iter, 810000 ts, 132 rew

agent-1: 24.0
agent-2: 20.0
agent-3: 30.0
agent-4: 26.0
agent-5: 22.0
agent-6: 25.0
agent-7: 23.0
agent-8: 23.0
agent-9: 20.0
agent-10: 28.0
Sum Reward: 241.0
Avg Reward: 24.1
Min Reward: 20.0
Gini Coefficient: 0.07178423236514522
20:20 Ratio: 1.45
Max-min Ratio: 1.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-05-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 132.92592592592592
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 81
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.632
    dispatch_time_ms: 27.815
    learner:
      cur_lr: 0.0013060539495199919
      grad_gnorm: 9.86894416809082
      policy_entropy: 167.81216430664062
      policy_loss: 13.958541870117188
      var_gnorm: 36.12054443359375
      vf_explained_var: 0.11477339267730713
      vf_loss: 0.17529696226119995
    num_steps_sampled: 820000
    num_steps_trained: 820000
    wait_time_ms: 155.039
  iterations_since_restore: 82
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 1482.9498941898346
  time_this_iter_s: 18.283329486846924
  time_total_s: 1482.9498941898346
  timestamp: 1593885935
  timesteps_since_restore: 820000
  timesteps_this_iter: 10000
  timesteps_total: 820000
  training_iteration: 82
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 1482 s, 82 iter, 820000 ts, 133 rew

agent-1: 33.0
agent-2: 15.0
agent-3: 27.0
agent-4: 27.0
agent-5: 24.0
agent-6: 22.0
agent-7: 22.0
agent-8: 38.0
agent-9: 27.0
agent-10: 27.0
Sum Reward: 262.0
Avg Reward: 26.2
Min Reward: 15.0
Gini Coefficient: 0.12137404580152672
20:20 Ratio: 1.9189189189189189
Max-min Ratio: 2.533333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-05-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 134.5
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 82
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.796
    dispatch_time_ms: 27.054
    learner:
      cur_lr: 0.0013053880538791418
      grad_gnorm: 2.76716685295105
      policy_entropy: 177.37939453125
      policy_loss: -1.1861226558685303
      var_gnorm: 36.25067138671875
      vf_explained_var: 0.6501139402389526
      vf_loss: 0.036413125693798065
    num_steps_sampled: 830000
    num_steps_trained: 830000
    wait_time_ms: 157.746
  iterations_since_restore: 83
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 1501.5041780471802
  time_this_iter_s: 18.55428385734558
  time_total_s: 1501.5041780471802
  timestamp: 1593885954
  timesteps_since_restore: 830000
  timesteps_this_iter: 10000
  timesteps_total: 830000
  training_iteration: 83
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 1501 s, 83 iter, 830000 ts, 134 rew

agent-1: 23.0
agent-2: 17.0
agent-3: 19.0
agent-4: 16.0
agent-5: 23.0
agent-6: 28.0
agent-7: 20.0
agent-8: 16.0
agent-9: 21.0
agent-10: 17.0
Sum Reward: 200.0
Avg Reward: 20.0
Min Reward: 16.0
Gini Coefficient: 0.1
20:20 Ratio: 1.59375
Max-min Ratio: 1.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-06-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 135.289156626506
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 83
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.612
    dispatch_time_ms: 33.419
    learner:
      cur_lr: 0.00130472204182297
      grad_gnorm: 3.7109925746917725
      policy_entropy: 184.31707763671875
      policy_loss: -0.46883150935173035
      var_gnorm: 36.40719985961914
      vf_explained_var: -1.0
      vf_loss: 0.024078194051980972
    num_steps_sampled: 840000
    num_steps_trained: 840000
    wait_time_ms: 148.92
  iterations_since_restore: 84
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 1520.0645053386688
  time_this_iter_s: 18.560327291488647
  time_total_s: 1520.0645053386688
  timestamp: 1593885973
  timesteps_since_restore: 840000
  timesteps_this_iter: 10000
  timesteps_total: 840000
  training_iteration: 84
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 1520 s, 84 iter, 840000 ts, 135 rew

agent-1: 27.0
agent-2: 18.0
agent-3: 18.0
agent-4: 25.0
agent-5: 22.0
agent-6: 18.0
agent-7: 37.0
agent-8: 27.0
agent-9: 10.0
agent-10: 23.0
Sum Reward: 225.0
Avg Reward: 22.5
Min Reward: 10.0
Gini Coefficient: 0.16577777777777777
20:20 Ratio: 2.2857142857142856
Max-min Ratio: 3.7
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-06-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 136.35714285714286
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 84
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.552
    dispatch_time_ms: 31.176
    learner:
      cur_lr: 0.001304056029766798
      grad_gnorm: 6.198091506958008
      policy_entropy: 174.0500946044922
      policy_loss: 2.5844829082489014
      var_gnorm: 36.58879852294922
      vf_explained_var: 0.9152112007141113
      vf_loss: 0.02304658852517605
    num_steps_sampled: 850000
    num_steps_trained: 850000
    wait_time_ms: 154.926
  iterations_since_restore: 85
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 1538.572955608368
  time_this_iter_s: 18.508450269699097
  time_total_s: 1538.572955608368
  timestamp: 1593885991
  timesteps_since_restore: 850000
  timesteps_this_iter: 10000
  timesteps_total: 850000
  training_iteration: 85
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 1538 s, 85 iter, 850000 ts, 136 rew

agent-1: 18.0
agent-2: 30.0
agent-3: 19.0
agent-4: 38.0
agent-5: 14.0
agent-6: 25.0
agent-7: 19.0
agent-8: 28.0
agent-9: 21.0
agent-10: 22.0
Sum Reward: 234.0
Avg Reward: 23.4
Min Reward: 14.0
Gini Coefficient: 0.15555555555555556
20:20 Ratio: 2.125
Max-min Ratio: 2.7142857142857144
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-06-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 137.50588235294117
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 85
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.232
    dispatch_time_ms: 26.957
    learner:
      cur_lr: 0.0013033900177106261
      grad_gnorm: 1.9096583127975464
      policy_entropy: 183.04347229003906
      policy_loss: 1.9300920963287354
      var_gnorm: 36.66645050048828
      vf_explained_var: 0.9901708960533142
      vf_loss: 0.004284127149730921
    num_steps_sampled: 860000
    num_steps_trained: 860000
    wait_time_ms: 159.944
  iterations_since_restore: 86
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 1557.2289943695068
  time_this_iter_s: 18.656038761138916
  time_total_s: 1557.2289943695068
  timestamp: 1593886010
  timesteps_since_restore: 860000
  timesteps_this_iter: 10000
  timesteps_total: 860000
  training_iteration: 86
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 1557 s, 86 iter, 860000 ts, 138 rew

agent-1: 25.0
agent-2: 6.0
agent-3: 28.0
agent-4: 29.0
agent-5: 22.0
agent-6: 22.0
agent-7: 35.0
agent-8: 17.0
agent-9: 22.0
agent-10: 28.0
Sum Reward: 234.0
Avg Reward: 23.4
Min Reward: 6.0
Gini Coefficient: 0.16923076923076924
20:20 Ratio: 2.782608695652174
Max-min Ratio: 5.833333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-07-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 138.62790697674419
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 86
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.681
    dispatch_time_ms: 22.186
    learner:
      cur_lr: 0.0013027240056544542
      grad_gnorm: 1.4410942792892456
      policy_entropy: 179.68951416015625
      policy_loss: -1.802061676979065
      var_gnorm: 36.7925910949707
      vf_explained_var: 0.9958550930023193
      vf_loss: 0.0016088462434709072
    num_steps_sampled: 870000
    num_steps_trained: 870000
    wait_time_ms: 159.926
  iterations_since_restore: 87
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 1575.6809701919556
  time_this_iter_s: 18.45197582244873
  time_total_s: 1575.6809701919556
  timestamp: 1593886028
  timesteps_since_restore: 870000
  timesteps_this_iter: 10000
  timesteps_total: 870000
  training_iteration: 87
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 1575 s, 87 iter, 870000 ts, 139 rew

agent-1: 27.0
agent-2: 22.0
agent-3: 22.0
agent-4: 34.0
agent-5: 22.0
agent-6: 21.0
agent-7: 22.0
agent-8: 16.0
agent-9: 20.0
agent-10: 11.0
Sum Reward: 217.0
Avg Reward: 21.7
Min Reward: 11.0
Gini Coefficient: 0.13686635944700462
20:20 Ratio: 2.259259259259259
Max-min Ratio: 3.090909090909091
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-07-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 139.5287356321839
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 87
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.35
    dispatch_time_ms: 38.814
    learner:
      cur_lr: 0.0013020579935982823
      grad_gnorm: 2.075552225112915
      policy_entropy: 178.7431182861328
      policy_loss: 5.0495147705078125
      var_gnorm: 36.95673751831055
      vf_explained_var: 0.9703337550163269
      vf_loss: 0.0008349150302819908
    num_steps_sampled: 880000
    num_steps_trained: 880000
    wait_time_ms: 149.037
  iterations_since_restore: 88
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 1593.9420638084412
  time_this_iter_s: 18.261093616485596
  time_total_s: 1593.9420638084412
  timestamp: 1593886047
  timesteps_since_restore: 880000
  timesteps_this_iter: 10000
  timesteps_total: 880000
  training_iteration: 88
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 1593 s, 88 iter, 880000 ts, 140 rew

agent-1: 28.0
agent-2: 23.0
agent-3: 32.0
agent-4: 22.0
agent-5: 14.0
agent-6: 30.0
agent-7: 24.0
agent-8: 19.0
agent-9: 20.0
agent-10: 14.0
Sum Reward: 226.0
Avg Reward: 22.6
Min Reward: 14.0
Gini Coefficient: 0.14690265486725665
20:20 Ratio: 2.2142857142857144
Max-min Ratio: 2.2857142857142856
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-07-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 140.51136363636363
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 88
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.197
    dispatch_time_ms: 26.36
    learner:
      cur_lr: 0.0013013919815421104
      grad_gnorm: 0.6066989302635193
      policy_entropy: 178.24557495117188
      policy_loss: -2.8738415241241455
      var_gnorm: 37.08272171020508
      vf_explained_var: 0.9668452143669128
      vf_loss: 0.0016951102297753096
    num_steps_sampled: 890000
    num_steps_trained: 890000
    wait_time_ms: 157.217
  iterations_since_restore: 89
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 1612.3053154945374
  time_this_iter_s: 18.36325168609619
  time_total_s: 1612.3053154945374
  timestamp: 1593886065
  timesteps_since_restore: 890000
  timesteps_this_iter: 10000
  timesteps_total: 890000
  training_iteration: 89
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 1612 s, 89 iter, 890000 ts, 141 rew

agent-1: 37.0
agent-2: 14.0
agent-3: 22.0
agent-4: 18.0
agent-5: 22.0
agent-6: 19.0
agent-7: 26.0
agent-8: 27.0
agent-9: 18.0
agent-10: 14.0
Sum Reward: 217.0
Avg Reward: 21.7
Min Reward: 14.0
Gini Coefficient: 0.16267281105990783
20:20 Ratio: 2.2857142857142856
Max-min Ratio: 2.642857142857143
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-08-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 141.37078651685394
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 89
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.674
    dispatch_time_ms: 28.712
    learner:
      cur_lr: 0.0013007259694859385
      grad_gnorm: 1.9744012355804443
      policy_entropy: 170.2781219482422
      policy_loss: 0.09694460779428482
      var_gnorm: 37.269554138183594
      vf_explained_var: 0.9914925694465637
      vf_loss: 0.0025365259498357773
    num_steps_sampled: 900000
    num_steps_trained: 900000
    wait_time_ms: 1055.054
  iterations_since_restore: 90
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 1639.7779924869537
  time_this_iter_s: 27.472676992416382
  time_total_s: 1639.7779924869537
  timestamp: 1593886093
  timesteps_since_restore: 900000
  timesteps_this_iter: 10000
  timesteps_total: 900000
  training_iteration: 90
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 1639 s, 90 iter, 900000 ts, 141 rew

agent-1: 16.0
agent-2: 17.0
agent-3: 22.0
agent-4: 25.0
agent-5: 15.0
agent-6: 15.0
agent-7: 20.0
agent-8: 33.0
agent-9: 26.0
agent-10: 26.0
Sum Reward: 215.0
Avg Reward: 21.5
Min Reward: 15.0
Gini Coefficient: 0.14651162790697675
20:20 Ratio: 1.9666666666666666
Max-min Ratio: 2.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-08-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 142.1888888888889
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 90
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.971
    dispatch_time_ms: 15.112
    learner:
      cur_lr: 0.0013000599574297667
      grad_gnorm: 14.972039222717285
      policy_entropy: 163.87893676757812
      policy_loss: -0.6030027866363525
      var_gnorm: 37.32295227050781
      vf_explained_var: 0.9855422973632812
      vf_loss: 0.12200438231229782
    num_steps_sampled: 910000
    num_steps_trained: 910000
    wait_time_ms: 402.812
  iterations_since_restore: 91
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 1658.6720473766327
  time_this_iter_s: 18.894054889678955
  time_total_s: 1658.6720473766327
  timestamp: 1593886112
  timesteps_since_restore: 910000
  timesteps_this_iter: 10000
  timesteps_total: 910000
  training_iteration: 91
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 1658 s, 91 iter, 910000 ts, 142 rew

agent-1: 18.0
agent-2: 21.0
agent-3: 16.0
agent-4: 22.0
agent-5: 17.0
agent-6: 17.0
agent-7: 16.0
agent-8: 16.0
agent-9: 25.0
agent-10: 22.0
Sum Reward: 190.0
Avg Reward: 19.0
Min Reward: 16.0
Gini Coefficient: 0.08736842105263158
20:20 Ratio: 1.46875
Max-min Ratio: 1.5625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-08-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 142.71428571428572
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 91
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.562
    dispatch_time_ms: 26.182
    learner:
      cur_lr: 0.0012993939453735948
      grad_gnorm: 1.234817385673523
      policy_entropy: 170.54473876953125
      policy_loss: -0.0519925132393837
      var_gnorm: 37.44641876220703
      vf_explained_var: 0.9578441977500916
      vf_loss: 0.002516768407076597
    num_steps_sampled: 920000
    num_steps_trained: 920000
    wait_time_ms: 158.701
  iterations_since_restore: 92
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 1675.726071357727
  time_this_iter_s: 17.05402398109436
  time_total_s: 1675.726071357727
  timestamp: 1593886129
  timesteps_since_restore: 920000
  timesteps_this_iter: 10000
  timesteps_total: 920000
  training_iteration: 92
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 1675 s, 92 iter, 920000 ts, 143 rew

agent-1: 20.0
agent-2: 24.0
agent-3: 24.0
agent-4: 21.0
agent-5: 20.0
agent-6: 19.0
agent-7: 24.0
agent-8: 18.0
agent-9: 16.0
agent-10: 22.0
Sum Reward: 208.0
Avg Reward: 20.8
Min Reward: 16.0
Gini Coefficient: 0.07019230769230769
20:20 Ratio: 1.411764705882353
Max-min Ratio: 1.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-09-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 143.42391304347825
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 92
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.795
    dispatch_time_ms: 38.076
    learner:
      cur_lr: 0.0012987280497327447
      grad_gnorm: 4.34682559967041
      policy_entropy: 177.61553955078125
      policy_loss: 1.8720343112945557
      var_gnorm: 37.53483200073242
      vf_explained_var: 0.945925772190094
      vf_loss: 0.015370205976068974
    num_steps_sampled: 930000
    num_steps_trained: 930000
    wait_time_ms: 145.691
  iterations_since_restore: 93
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 1694.1258668899536
  time_this_iter_s: 18.399795532226562
  time_total_s: 1694.1258668899536
  timestamp: 1593886147
  timesteps_since_restore: 930000
  timesteps_this_iter: 10000
  timesteps_total: 930000
  training_iteration: 93
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 1694 s, 93 iter, 930000 ts, 143 rew

agent-1: 18.0
agent-2: 26.0
agent-3: 15.0
agent-4: 20.0
agent-5: 24.0
agent-6: 20.0
agent-7: 22.0
agent-8: 17.0
agent-9: 26.0
agent-10: 21.0
Sum Reward: 209.0
Avg Reward: 20.9
Min Reward: 15.0
Gini Coefficient: 0.09521531100478468
20:20 Ratio: 1.625
Max-min Ratio: 1.7333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-09-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 144.1290322580645
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 93
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.141
    dispatch_time_ms: 27.282
    learner:
      cur_lr: 0.0012980620376765728
      grad_gnorm: 5.410073757171631
      policy_entropy: 174.84066772460938
      policy_loss: 0.8589987754821777
      var_gnorm: 37.62451171875
      vf_explained_var: 0.6894763112068176
      vf_loss: 0.01085176132619381
    num_steps_sampled: 940000
    num_steps_trained: 940000
    wait_time_ms: 154.458
  iterations_since_restore: 94
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 1712.6099212169647
  time_this_iter_s: 18.48405432701111
  time_total_s: 1712.6099212169647
  timestamp: 1593886166
  timesteps_since_restore: 940000
  timesteps_this_iter: 10000
  timesteps_total: 940000
  training_iteration: 94
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 1712 s, 94 iter, 940000 ts, 144 rew

agent-1: 13.0
agent-2: 9.0
agent-3: 24.0
agent-4: 20.0
agent-5: 21.0
agent-6: 22.0
agent-7: 30.0
agent-8: 20.0
agent-9: 18.0
agent-10: 22.0
Sum Reward: 199.0
Avg Reward: 19.9
Min Reward: 9.0
Gini Coefficient: 0.14723618090452262
20:20 Ratio: 2.4545454545454546
Max-min Ratio: 3.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-09-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 144.7127659574468
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 94
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.071
    dispatch_time_ms: 30.358
    learner:
      cur_lr: 0.001297396025620401
      grad_gnorm: 3.9704999923706055
      policy_entropy: 179.1944122314453
      policy_loss: 1.9641609191894531
      var_gnorm: 37.69919967651367
      vf_explained_var: -0.021944522857666016
      vf_loss: 0.010220833122730255
    num_steps_sampled: 950000
    num_steps_trained: 950000
    wait_time_ms: 149.948
  iterations_since_restore: 95
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 1731.1257202625275
  time_this_iter_s: 18.515799045562744
  time_total_s: 1731.1257202625275
  timestamp: 1593886184
  timesteps_since_restore: 950000
  timesteps_this_iter: 10000
  timesteps_total: 950000
  training_iteration: 95
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 1731 s, 95 iter, 950000 ts, 145 rew

agent-1: 21.0
agent-2: 25.0
agent-3: 21.0
agent-4: 14.0
agent-5: 22.0
agent-6: 22.0
agent-7: 37.0
agent-8: 20.0
agent-9: 18.0
agent-10: 18.0
Sum Reward: 218.0
Avg Reward: 21.8
Min Reward: 14.0
Gini Coefficient: 0.12935779816513762
20:20 Ratio: 1.9375
Max-min Ratio: 2.642857142857143
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-10-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 145.4842105263158
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 95
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.168
    dispatch_time_ms: 26.774
    learner:
      cur_lr: 0.001296730013564229
      grad_gnorm: 15.22739315032959
      policy_entropy: 170.19097900390625
      policy_loss: 0.18891049921512604
      var_gnorm: 37.95821762084961
      vf_explained_var: -1.0
      vf_loss: 0.15709181129932404
    num_steps_sampled: 960000
    num_steps_trained: 960000
    wait_time_ms: 154.781
  iterations_since_restore: 96
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 1749.9335696697235
  time_this_iter_s: 18.807849407196045
  time_total_s: 1749.9335696697235
  timestamp: 1593886203
  timesteps_since_restore: 960000
  timesteps_this_iter: 10000
  timesteps_total: 960000
  training_iteration: 96
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 1749 s, 96 iter, 960000 ts, 145 rew

agent-1: 26.0
agent-2: 21.0
agent-3: 15.0
agent-4: 17.0
agent-5: 30.0
agent-6: 21.0
agent-7: 20.0
agent-8: 25.0
agent-9: 14.0
agent-10: 19.0
Sum Reward: 208.0
Avg Reward: 20.8
Min Reward: 14.0
Gini Coefficient: 0.12884615384615383
20:20 Ratio: 1.9310344827586208
Max-min Ratio: 2.142857142857143
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-10-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 146.13541666666666
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 96
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.814
    dispatch_time_ms: 30.341
    learner:
      cur_lr: 0.0012960640015080571
      grad_gnorm: 40.000003814697266
      policy_entropy: 183.04502868652344
      policy_loss: -3.7427783012390137
      var_gnorm: 38.073699951171875
      vf_explained_var: -0.8384178876876831
      vf_loss: 0.1277347356081009
    num_steps_sampled: 970000
    num_steps_trained: 970000
    wait_time_ms: 150.383
  iterations_since_restore: 97
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 1768.1414036750793
  time_this_iter_s: 18.207834005355835
  time_total_s: 1768.1414036750793
  timestamp: 1593886221
  timesteps_since_restore: 970000
  timesteps_this_iter: 10000
  timesteps_total: 970000
  training_iteration: 97
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 1768 s, 97 iter, 970000 ts, 146 rew

agent-1: 11.0
agent-2: 8.0
agent-3: 22.0
agent-4: 17.0
agent-5: 36.0
agent-6: 31.0
agent-7: 20.0
agent-8: 28.0
agent-9: 41.0
agent-10: 26.0
Sum Reward: 240.0
Avg Reward: 24.0
Min Reward: 8.0
Gini Coefficient: 0.2375
20:20 Ratio: 4.052631578947368
Max-min Ratio: 5.125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-10-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 147.10309278350516
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 97
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.272
    dispatch_time_ms: 25.402
    learner:
      cur_lr: 0.0012953979894518852
      grad_gnorm: 0.40118053555488586
      policy_entropy: 187.13768005371094
      policy_loss: -0.7568947076797485
      var_gnorm: 38.07419967651367
      vf_explained_var: 0.9870721101760864
      vf_loss: 0.00010643111454555765
    num_steps_sampled: 980000
    num_steps_trained: 980000
    wait_time_ms: 161.174
  iterations_since_restore: 98
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 1786.5268366336823
  time_this_iter_s: 18.385432958602905
  time_total_s: 1786.5268366336823
  timestamp: 1593886240
  timesteps_since_restore: 980000
  timesteps_this_iter: 10000
  timesteps_total: 980000
  training_iteration: 98
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 1786 s, 98 iter, 980000 ts, 147 rew

agent-1: 21.0
agent-2: 23.0
agent-3: 29.0
agent-4: 9.0
agent-5: 19.0
agent-6: 17.0
agent-7: 24.0
agent-8: 17.0
agent-9: 19.0
agent-10: 20.0
Sum Reward: 198.0
Avg Reward: 19.8
Min Reward: 9.0
Gini Coefficient: 0.13434343434343435
20:20 Ratio: 2.0384615384615383
Max-min Ratio: 3.2222222222222223
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-10-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 147.62244897959184
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 98
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.926
    dispatch_time_ms: 28.316
    learner:
      cur_lr: 0.0012947319773957133
      grad_gnorm: 1.4400464296340942
      policy_entropy: 187.32843017578125
      policy_loss: 2.249143600463867
      var_gnorm: 38.265384674072266
      vf_explained_var: 0.9427862167358398
      vf_loss: 0.001363885821774602
    num_steps_sampled: 990000
    num_steps_trained: 990000
    wait_time_ms: 155.194
  iterations_since_restore: 99
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 1805.0277783870697
  time_this_iter_s: 18.50094175338745
  time_total_s: 1805.0277783870697
  timestamp: 1593886258
  timesteps_since_restore: 990000
  timesteps_this_iter: 10000
  timesteps_total: 990000
  training_iteration: 99
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 1805 s, 99 iter, 990000 ts, 148 rew

agent-1: 30.0
agent-2: 23.0
agent-3: 24.0
agent-4: 18.0
agent-5: 25.0
agent-6: 15.0
agent-7: 28.0
agent-8: 20.0
agent-9: 19.0
agent-10: 30.0
Sum Reward: 232.0
Avg Reward: 23.2
Min Reward: 15.0
Gini Coefficient: 0.1206896551724138
20:20 Ratio: 1.8181818181818181
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-11-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 148.4747474747475
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 99
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.905
    dispatch_time_ms: 29.142
    learner:
      cur_lr: 0.0012940659653395414
      grad_gnorm: 1.3367022275924683
      policy_entropy: 162.83384704589844
      policy_loss: 1.5438605546951294
      var_gnorm: 38.392555236816406
      vf_explained_var: 0.8157998323440552
      vf_loss: 0.0011823087697848678
    num_steps_sampled: 1000000
    num_steps_trained: 1000000
    wait_time_ms: 155.049
  iterations_since_restore: 100
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 1823.3775918483734
  time_this_iter_s: 18.34981346130371
  time_total_s: 1823.3775918483734
  timestamp: 1593886277
  timesteps_since_restore: 1000000
  timesteps_this_iter: 10000
  timesteps_total: 1000000
  training_iteration: 100
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 1823 s, 100 iter, 1000000 ts, 148 rew

agent-1: 19.0
agent-2: 23.0
agent-3: 17.0
agent-4: 21.0
agent-5: 24.0
agent-6: 21.0
agent-7: 22.0
agent-8: 23.0
agent-9: 24.0
agent-10: 27.0
Sum Reward: 221.0
Avg Reward: 22.1
Min Reward: 17.0
Gini Coefficient: 0.0665158371040724
20:20 Ratio: 1.4166666666666667
Max-min Ratio: 1.588235294117647
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-11-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 149.2
  episode_reward_min: -5706.0
  episodes_this_iter: 1
  episodes_total: 100
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.303
    dispatch_time_ms: 40.677
    learner:
      cur_lr: 0.0012933999532833695
      grad_gnorm: 1.6709067821502686
      policy_entropy: 181.8008270263672
      policy_loss: -1.7780237197875977
      var_gnorm: 38.63357162475586
      vf_explained_var: 0.5726290941238403
      vf_loss: 0.003566744504496455
    num_steps_sampled: 1010000
    num_steps_trained: 1010000
    wait_time_ms: 140.372
  iterations_since_restore: 101
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 1841.8656980991364
  time_this_iter_s: 18.48810625076294
  time_total_s: 1841.8656980991364
  timestamp: 1593886295
  timesteps_since_restore: 1010000
  timesteps_this_iter: 10000
  timesteps_total: 1010000
  training_iteration: 101
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 1841 s, 101 iter, 1010000 ts, 149 rew

agent-1: 24.0
agent-2: 15.0
agent-3: 18.0
agent-4: 28.0
agent-5: 12.0
agent-6: 15.0
agent-7: 15.0
agent-8: 36.0
agent-9: 30.0
agent-10: 26.0
Sum Reward: 219.0
Avg Reward: 21.9
Min Reward: 12.0
Gini Coefficient: 0.19406392694063926
20:20 Ratio: 2.4444444444444446
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-11-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 208.45
  episode_reward_min: -2619.0
  episodes_this_iter: 1
  episodes_total: 101
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 4.662
    dispatch_time_ms: 39.613
    learner:
      cur_lr: 0.0012927340576425195
      grad_gnorm: 1.4595710039138794
      policy_entropy: 160.59178161621094
      policy_loss: -2.8482651710510254
      var_gnorm: 38.71318435668945
      vf_explained_var: 0.44386863708496094
      vf_loss: 0.0041531831957399845
    num_steps_sampled: 1020000
    num_steps_trained: 1020000
    wait_time_ms: 146.087
  iterations_since_restore: 102
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 1860.3896162509918
  time_this_iter_s: 18.52391815185547
  time_total_s: 1860.3896162509918
  timestamp: 1593886314
  timesteps_since_restore: 1020000
  timesteps_this_iter: 10000
  timesteps_total: 1020000
  training_iteration: 102
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 1860 s, 102 iter, 1020000 ts, 208 rew

agent-1: 17.0
agent-2: 22.0
agent-3: 18.0
agent-4: 34.0
agent-5: 19.0
agent-6: 27.0
agent-7: 9.0
agent-8: 25.0
agent-9: 27.0
agent-10: 21.0
Sum Reward: 219.0
Avg Reward: 21.9
Min Reward: 9.0
Gini Coefficient: 0.1639269406392694
20:20 Ratio: 2.3461538461538463
Max-min Ratio: 3.7777777777777777
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-12-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 236.83
  episode_reward_min: 64.0
  episodes_this_iter: 1
  episodes_total: 102
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.751
    dispatch_time_ms: 30.847
    learner:
      cur_lr: 0.0012920680455863476
      grad_gnorm: 4.113616943359375
      policy_entropy: 164.5862274169922
      policy_loss: -4.772126197814941
      var_gnorm: 38.79975509643555
      vf_explained_var: 0.6156060695648193
      vf_loss: 0.012285925447940826
    num_steps_sampled: 1030000
    num_steps_trained: 1030000
    wait_time_ms: 146.662
  iterations_since_restore: 103
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 1878.9189720153809
  time_this_iter_s: 18.529355764389038
  time_total_s: 1878.9189720153809
  timestamp: 1593886332
  timesteps_since_restore: 1030000
  timesteps_this_iter: 10000
  timesteps_total: 1030000
  training_iteration: 103
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 1878 s, 103 iter, 1030000 ts, 237 rew

agent-1: 25.0
agent-2: 32.0
agent-3: 40.0
agent-4: 21.0
agent-5: -22.0
agent-6: 25.0
agent-7: 30.0
agent-8: 11.0
agent-9: 19.0
agent-10: 22.0
Sum Reward: 203.0
Avg Reward: 20.3
Min Reward: -22.0
Gini Coefficient: 0.3817733990147783
20:20 Ratio: -6.545454545454546
Max-min Ratio: -1.8181818181818181
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-12-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 382.0
  episode_reward_mean: 236.18
  episode_reward_min: 64.0
  episodes_this_iter: 1
  episodes_total: 103
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.977
    dispatch_time_ms: 25.334
    learner:
      cur_lr: 0.0012914020335301757
      grad_gnorm: 5.603070259094238
      policy_entropy: 151.82901000976562
      policy_loss: 0.3027382493019104
      var_gnorm: 39.13888931274414
      vf_explained_var: 0.7560199499130249
      vf_loss: 0.006818206515163183
    num_steps_sampled: 1040000
    num_steps_trained: 1040000
    wait_time_ms: 161.954
  iterations_since_restore: 104
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 1897.4660000801086
  time_this_iter_s: 18.547028064727783
  time_total_s: 1897.4660000801086
  timestamp: 1593886351
  timesteps_since_restore: 1040000
  timesteps_this_iter: 10000
  timesteps_total: 1040000
  training_iteration: 104
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 1897 s, 104 iter, 1040000 ts, 236 rew

agent-1: 29.0
agent-2: 26.0
agent-3: 29.0
agent-4: 24.0
agent-5: 23.0
agent-6: 30.0
agent-7: 21.0
agent-8: 25.0
agent-9: 17.0
agent-10: 10.0
Sum Reward: 234.0
Avg Reward: 23.4
Min Reward: 10.0
Gini Coefficient: 0.13418803418803418
20:20 Ratio: 2.185185185185185
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-12-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 351.0
  episode_reward_mean: 234.7
  episode_reward_min: 64.0
  episodes_this_iter: 1
  episodes_total: 104
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.531
    dispatch_time_ms: 23.243
    learner:
      cur_lr: 0.0012907360214740038
      grad_gnorm: 7.306427478790283
      policy_entropy: 179.50132751464844
      policy_loss: -1.2876397371292114
      var_gnorm: 39.301856994628906
      vf_explained_var: 0.260897696018219
      vf_loss: 0.07202424854040146
    num_steps_sampled: 1050000
    num_steps_trained: 1050000
    wait_time_ms: 152.38
  iterations_since_restore: 105
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 1916.0006303787231
  time_this_iter_s: 18.534630298614502
  time_total_s: 1916.0006303787231
  timestamp: 1593886369
  timesteps_since_restore: 1050000
  timesteps_this_iter: 10000
  timesteps_total: 1050000
  training_iteration: 105
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 1916 s, 105 iter, 1050000 ts, 235 rew

agent-1: 15.0
agent-2: 27.0
agent-3: 28.0
agent-4: 24.0
agent-5: 27.0
agent-6: 18.0
agent-7: 21.0
agent-8: 24.0
agent-9: 15.0
agent-10: 23.0
Sum Reward: 222.0
Avg Reward: 22.2
Min Reward: 15.0
Gini Coefficient: 0.11531531531531532
20:20 Ratio: 1.8333333333333333
Max-min Ratio: 1.8666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-13-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 321.0
  episode_reward_mean: 233.41
  episode_reward_min: 64.0
  episodes_this_iter: 1
  episodes_total: 105
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.782
    dispatch_time_ms: 30.458
    learner:
      cur_lr: 0.001290070009417832
      grad_gnorm: 0.3376220166683197
      policy_entropy: 172.1085662841797
      policy_loss: 0.8669962882995605
      var_gnorm: 39.4061164855957
      vf_explained_var: 0.9274160265922546
      vf_loss: 0.0020320259500294924
    num_steps_sampled: 1060000
    num_steps_trained: 1060000
    wait_time_ms: 154.928
  iterations_since_restore: 106
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 1934.2466850280762
  time_this_iter_s: 18.246054649353027
  time_total_s: 1934.2466850280762
  timestamp: 1593886388
  timesteps_since_restore: 1060000
  timesteps_this_iter: 10000
  timesteps_total: 1060000
  training_iteration: 106
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 1934 s, 106 iter, 1060000 ts, 233 rew

agent-1: 18.0
agent-2: 20.0
agent-3: 17.0
agent-4: 15.0
agent-5: 16.0
agent-6: 21.0
agent-7: 23.0
agent-8: 27.0
agent-9: 27.0
agent-10: 26.0
Sum Reward: 210.0
Avg Reward: 21.0
Min Reward: 15.0
Gini Coefficient: 0.11714285714285715
20:20 Ratio: 1.7419354838709677
Max-min Ratio: 1.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-13-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 321.0
  episode_reward_mean: 232.51
  episode_reward_min: 64.0
  episodes_this_iter: 1
  episodes_total: 106
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.024
    dispatch_time_ms: 29.599
    learner:
      cur_lr: 0.00128940399736166
      grad_gnorm: 3.575841188430786
      policy_entropy: 148.5667724609375
      policy_loss: 0.5289710760116577
      var_gnorm: 39.45610427856445
      vf_explained_var: 0.7964360117912292
      vf_loss: 0.008858568035066128
    num_steps_sampled: 1070000
    num_steps_trained: 1070000
    wait_time_ms: 1617.528
  iterations_since_restore: 107
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 1967.3607144355774
  time_this_iter_s: 33.11402940750122
  time_total_s: 1967.3607144355774
  timestamp: 1593886421
  timesteps_since_restore: 1070000
  timesteps_this_iter: 10000
  timesteps_total: 1070000
  training_iteration: 107
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 1967 s, 107 iter, 1070000 ts, 233 rew

agent-1: 27.0
agent-2: 28.0
agent-3: 25.0
agent-4: 30.0
agent-5: 18.0
agent-6: 26.0
agent-7: 19.0
agent-8: 20.0
agent-9: 14.0
agent-10: 29.0
Sum Reward: 236.0
Avg Reward: 23.6
Min Reward: 14.0
Gini Coefficient: 0.12203389830508475
20:20 Ratio: 1.84375
Max-min Ratio: 2.142857142857143
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-13-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 321.0
  episode_reward_mean: 232.5
  episode_reward_min: 64.0
  episodes_this_iter: 1
  episodes_total: 107
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.964
    dispatch_time_ms: 17.144
    learner:
      cur_lr: 0.0012887379853054881
      grad_gnorm: 0.4436141550540924
      policy_entropy: 153.82200622558594
      policy_loss: 0.15532603859901428
      var_gnorm: 39.59111785888672
      vf_explained_var: 0.21639567613601685
      vf_loss: 0.00028946870588697493
    num_steps_sampled: 1080000
    num_steps_trained: 1080000
    wait_time_ms: 159.083
  iterations_since_restore: 108
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 1983.945698261261
  time_this_iter_s: 16.584983825683594
  time_total_s: 1983.945698261261
  timestamp: 1593886438
  timesteps_since_restore: 1080000
  timesteps_this_iter: 10000
  timesteps_total: 1080000
  training_iteration: 108
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 1983 s, 108 iter, 1080000 ts, 232 rew

agent-1: 17.0
agent-2: 22.0
agent-3: 21.0
agent-4: 24.0
agent-5: 27.0
agent-6: 18.0
agent-7: 15.0
agent-8: 25.0
agent-9: 18.0
agent-10: 18.0
Sum Reward: 205.0
Avg Reward: 20.5
Min Reward: 15.0
Gini Coefficient: 0.10195121951219512
20:20 Ratio: 1.625
Max-min Ratio: 1.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-14-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 321.0
  episode_reward_mean: 233.91
  episode_reward_min: 190.0
  episodes_this_iter: 1
  episodes_total: 108
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.689
    dispatch_time_ms: 7.118
    learner:
      cur_lr: 0.0012880719732493162
      grad_gnorm: 0.7766239643096924
      policy_entropy: 173.5123748779297
      policy_loss: -0.4697935879230499
      var_gnorm: 39.613826751708984
      vf_explained_var: -0.6770282983779907
      vf_loss: 0.0011021665995940566
    num_steps_sampled: 1090000
    num_steps_trained: 1090000
    wait_time_ms: 166.038
  iterations_since_restore: 109
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 2003.1751084327698
  time_this_iter_s: 19.22941017150879
  time_total_s: 2003.1751084327698
  timestamp: 1593886457
  timesteps_since_restore: 1090000
  timesteps_this_iter: 10000
  timesteps_total: 1090000
  training_iteration: 109
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 2003 s, 109 iter, 1090000 ts, 234 rew

agent-1: 19.0
agent-2: 15.0
agent-3: 21.0
agent-4: 20.0
agent-5: 21.0
agent-6: 14.0
agent-7: 23.0
agent-8: 18.0
agent-9: 21.0
agent-10: 25.0
Sum Reward: 197.0
Avg Reward: 19.7
Min Reward: 14.0
Gini Coefficient: 0.08984771573604061
20:20 Ratio: 1.6551724137931034
Max-min Ratio: 1.7857142857142858
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-14-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 321.0
  episode_reward_mean: 233.54
  episode_reward_min: 190.0
  episodes_this_iter: 1
  episodes_total: 109
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.839
    dispatch_time_ms: 6.868
    learner:
      cur_lr: 0.0012874059611931443
      grad_gnorm: 0.6489759683609009
      policy_entropy: 161.69276428222656
      policy_loss: 0.16330371797084808
      var_gnorm: 39.78013610839844
      vf_explained_var: 0.5442667007446289
      vf_loss: 0.00027602730551734567
    num_steps_sampled: 1100000
    num_steps_trained: 1100000
    wait_time_ms: 170.809
  iterations_since_restore: 110
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 2021.0431687831879
  time_this_iter_s: 17.86806035041809
  time_total_s: 2021.0431687831879
  timestamp: 1593886475
  timesteps_since_restore: 1100000
  timesteps_this_iter: 10000
  timesteps_total: 1100000
  training_iteration: 110
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 2021 s, 110 iter, 1100000 ts, 234 rew

agent-1: 19.0
agent-2: 21.0
agent-3: 19.0
agent-4: 22.0
agent-5: 20.0
agent-6: 19.0
agent-7: 24.0
agent-8: 18.0
agent-9: 21.0
agent-10: 21.0
Sum Reward: 204.0
Avg Reward: 20.4
Min Reward: 18.0
Gini Coefficient: 0.045098039215686274
20:20 Ratio: 1.2432432432432432
Max-min Ratio: 1.3333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-14-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 316.0
  episode_reward_mean: 232.37
  episode_reward_min: 190.0
  episodes_this_iter: 1
  episodes_total: 110
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.98
    dispatch_time_ms: 13.187
    learner:
      cur_lr: 0.0012867399491369724
      grad_gnorm: 1.2953873872756958
      policy_entropy: 181.2322235107422
      policy_loss: -1.6152663230895996
      var_gnorm: 39.81596755981445
      vf_explained_var: 0.9898080229759216
      vf_loss: 0.0004333490796852857
    num_steps_sampled: 1110000
    num_steps_trained: 1110000
    wait_time_ms: 165.9
  iterations_since_restore: 111
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 2043.092766046524
  time_this_iter_s: 22.04959726333618
  time_total_s: 2043.092766046524
  timestamp: 1593886497
  timesteps_since_restore: 1110000
  timesteps_this_iter: 10000
  timesteps_total: 1110000
  training_iteration: 111
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 2043 s, 111 iter, 1110000 ts, 232 rew

agent-1: 15.0
agent-2: 19.0
agent-3: 17.0
agent-4: 19.0
agent-5: 14.0
agent-6: 16.0
agent-7: 27.0
agent-8: 20.0
agent-9: 29.0
agent-10: 26.0
Sum Reward: 202.0
Avg Reward: 20.2
Min Reward: 14.0
Gini Coefficient: 0.13762376237623763
20:20 Ratio: 1.9310344827586208
Max-min Ratio: 2.0714285714285716
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-15-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 316.0
  episode_reward_mean: 231.85
  episode_reward_min: 190.0
  episodes_this_iter: 1
  episodes_total: 111
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.688
    dispatch_time_ms: 20.781
    learner:
      cur_lr: 0.0012860740534961224
      grad_gnorm: 0.1773143857717514
      policy_entropy: 183.7755889892578
      policy_loss: 0.48846834897994995
      var_gnorm: 40.23844909667969
      vf_explained_var: 0.9953415393829346
      vf_loss: 2.5310608180006966e-05
    num_steps_sampled: 1120000
    num_steps_trained: 1120000
    wait_time_ms: 173.99
  iterations_since_restore: 112
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 2061.3845789432526
  time_this_iter_s: 18.291812896728516
  time_total_s: 2061.3845789432526
  timestamp: 1593886515
  timesteps_since_restore: 1120000
  timesteps_this_iter: 10000
  timesteps_total: 1120000
  training_iteration: 112
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 2061 s, 112 iter, 1120000 ts, 232 rew

agent-1: 11.0
agent-2: 27.0
agent-3: 24.0
agent-4: 13.0
agent-5: 33.0
agent-6: 8.0
agent-7: 25.0
agent-8: 29.0
agent-9: 16.0
agent-10: 20.0
Sum Reward: 206.0
Avg Reward: 20.6
Min Reward: 8.0
Gini Coefficient: 0.21941747572815534
20:20 Ratio: 3.263157894736842
Max-min Ratio: 4.125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-15-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 316.0
  episode_reward_mean: 231.47
  episode_reward_min: 190.0
  episodes_this_iter: 1
  episodes_total: 112
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.957
    dispatch_time_ms: 31.293
    learner:
      cur_lr: 0.0012854080414399505
      grad_gnorm: 27.62624740600586
      policy_entropy: 172.2165985107422
      policy_loss: 0.04700762778520584
      var_gnorm: 40.38141632080078
      vf_explained_var: 0.7126022577285767
      vf_loss: 1.3557206392288208
    num_steps_sampled: 1130000
    num_steps_trained: 1130000
    wait_time_ms: 152.493
  iterations_since_restore: 113
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 2079.7646811008453
  time_this_iter_s: 18.380102157592773
  time_total_s: 2079.7646811008453
  timestamp: 1593886534
  timesteps_since_restore: 1130000
  timesteps_this_iter: 10000
  timesteps_total: 1130000
  training_iteration: 113
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 2079 s, 113 iter, 1130000 ts, 231 rew

agent-1: 35.0
agent-2: 35.0
agent-3: 34.0
agent-4: 15.0
agent-5: 21.0
agent-6: 23.0
agent-7: 21.0
agent-8: 30.0
agent-9: 10.0
agent-10: 6.0
Sum Reward: 230.0
Avg Reward: 23.0
Min Reward: 6.0
Gini Coefficient: 0.24347826086956523
20:20 Ratio: 4.375
Max-min Ratio: 5.833333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-15-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 316.0
  episode_reward_mean: 230.92
  episode_reward_min: 190.0
  episodes_this_iter: 1
  episodes_total: 113
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.851
    dispatch_time_ms: 31.282
    learner:
      cur_lr: 0.0012847420293837786
      grad_gnorm: 3.324723958969116
      policy_entropy: 185.6660614013672
      policy_loss: 6.904322624206543
      var_gnorm: 40.566139221191406
      vf_explained_var: 0.8185104131698608
      vf_loss: 0.0006305855931714177
    num_steps_sampled: 1140000
    num_steps_trained: 1140000
    wait_time_ms: 164.123
  iterations_since_restore: 114
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 2098.327948331833
  time_this_iter_s: 18.56326723098755
  time_total_s: 2098.327948331833
  timestamp: 1593886552
  timesteps_since_restore: 1140000
  timesteps_this_iter: 10000
  timesteps_total: 1140000
  training_iteration: 114
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 2098 s, 114 iter, 1140000 ts, 231 rew

agent-1: 20.0
agent-2: 27.0
agent-3: 9.0
agent-4: 23.0
agent-5: 19.0
agent-6: 19.0
agent-7: 30.0
agent-8: 24.0
agent-9: 14.0
agent-10: 29.0
Sum Reward: 214.0
Avg Reward: 21.4
Min Reward: 9.0
Gini Coefficient: 0.16448598130841122
20:20 Ratio: 2.5652173913043477
Max-min Ratio: 3.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-16-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 316.0
  episode_reward_mean: 230.47
  episode_reward_min: 190.0
  episodes_this_iter: 1
  episodes_total: 114
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.72
    dispatch_time_ms: 19.159
    learner:
      cur_lr: 0.0012840760173276067
      grad_gnorm: 39.99999237060547
      policy_entropy: 176.9698944091797
      policy_loss: -2.3902320861816406
      var_gnorm: 40.48818588256836
      vf_explained_var: -0.177412748336792
      vf_loss: 4.117327690124512
    num_steps_sampled: 1150000
    num_steps_trained: 1150000
    wait_time_ms: 160.24
  iterations_since_restore: 115
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 2123.805569410324
  time_this_iter_s: 25.47762107849121
  time_total_s: 2123.805569410324
  timestamp: 1593886578
  timesteps_since_restore: 1150000
  timesteps_this_iter: 10000
  timesteps_total: 1150000
  training_iteration: 115
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 2123 s, 115 iter, 1150000 ts, 230 rew

agent-1: 15.0
agent-2: 24.0
agent-3: 29.0
agent-4: 30.0
agent-5: 46.0
agent-6: 13.0
agent-7: 15.0
agent-8: 32.0
agent-9: 33.0
agent-10: 27.0
Sum Reward: 264.0
Avg Reward: 26.4
Min Reward: 13.0
Gini Coefficient: 0.2
20:20 Ratio: 2.8214285714285716
Max-min Ratio: 3.5384615384615383
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-16-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 316.0
  episode_reward_mean: 230.23
  episode_reward_min: 190.0
  episodes_this_iter: 1
  episodes_total: 115
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 9.762
    dispatch_time_ms: 13.205
    learner:
      cur_lr: 0.0012834100052714348
      grad_gnorm: 8.528312683105469
      policy_entropy: 176.9529571533203
      policy_loss: -1.9209932088851929
      var_gnorm: 40.78710174560547
      vf_explained_var: -1.0
      vf_loss: 0.3232705593109131
    num_steps_sampled: 1160000
    num_steps_trained: 1160000
    wait_time_ms: 153.032
  iterations_since_restore: 116
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 2141.7156817913055
  time_this_iter_s: 17.910112380981445
  time_total_s: 2141.7156817913055
  timestamp: 1593886596
  timesteps_since_restore: 1160000
  timesteps_this_iter: 10000
  timesteps_total: 1160000
  training_iteration: 116
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 2141 s, 116 iter, 1160000 ts, 230 rew

agent-1: 29.0
agent-2: 20.0
agent-3: 26.0
agent-4: 30.0
agent-5: 21.0
agent-6: 29.0
agent-7: 18.0
agent-8: 22.0
agent-9: 24.0
agent-10: 21.0
Sum Reward: 240.0
Avg Reward: 24.0
Min Reward: 18.0
Gini Coefficient: 0.095
20:20 Ratio: 1.5526315789473684
Max-min Ratio: 1.6666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-16-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 316.0
  episode_reward_mean: 229.81
  episode_reward_min: 190.0
  episodes_this_iter: 1
  episodes_total: 116
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 4.048
    dispatch_time_ms: 29.541
    learner:
      cur_lr: 0.0012827439932152629
      grad_gnorm: 1.8585257530212402
      policy_entropy: 184.5906219482422
      policy_loss: 3.9501702785491943
      var_gnorm: 40.857421875
      vf_explained_var: 0.987602949142456
      vf_loss: 0.0005308062536641955
    num_steps_sampled: 1170000
    num_steps_trained: 1170000
    wait_time_ms: 151.629
  iterations_since_restore: 117
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 2159.9850113391876
  time_this_iter_s: 18.26932954788208
  time_total_s: 2159.9850113391876
  timestamp: 1593886614
  timesteps_since_restore: 1170000
  timesteps_this_iter: 10000
  timesteps_total: 1170000
  training_iteration: 117
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 2159 s, 117 iter, 1170000 ts, 230 rew

agent-1: 21.0
agent-2: 27.0
agent-3: 26.0
agent-4: 21.0
agent-5: 30.0
agent-6: 37.0
agent-7: 24.0
agent-8: 31.0
agent-9: 14.0
agent-10: 20.0
Sum Reward: 251.0
Avg Reward: 25.1
Min Reward: 14.0
Gini Coefficient: 0.13904382470119522
20:20 Ratio: 2.0
Max-min Ratio: 2.642857142857143
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-17-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 316.0
  episode_reward_mean: 229.66
  episode_reward_min: 190.0
  episodes_this_iter: 1
  episodes_total: 117
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 4.115
    dispatch_time_ms: 30.97
    learner:
      cur_lr: 0.001282077981159091
      grad_gnorm: 6.350226879119873
      policy_entropy: 174.3704071044922
      policy_loss: 2.5131680965423584
      var_gnorm: 40.96270751953125
      vf_explained_var: -1.0
      vf_loss: 0.07562819123268127
    num_steps_sampled: 1180000
    num_steps_trained: 1180000
    wait_time_ms: 147.178
  iterations_since_restore: 118
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 2178.3697035312653
  time_this_iter_s: 18.384692192077637
  time_total_s: 2178.3697035312653
  timestamp: 1593886632
  timesteps_since_restore: 1180000
  timesteps_this_iter: 10000
  timesteps_total: 1180000
  training_iteration: 118
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 2178 s, 118 iter, 1180000 ts, 230 rew

agent-1: 25.0
agent-2: 17.0
agent-3: 24.0
agent-4: 21.0
agent-5: 21.0
agent-6: 17.0
agent-7: 16.0
agent-8: 22.0
agent-9: 21.0
agent-10: 16.0
Sum Reward: 200.0
Avg Reward: 20.0
Min Reward: 16.0
Gini Coefficient: 0.087
20:20 Ratio: 1.53125
Max-min Ratio: 1.5625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-17-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 316.0
  episode_reward_mean: 229.27
  episode_reward_min: 190.0
  episodes_this_iter: 1
  episodes_total: 118
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.078
    dispatch_time_ms: 29.025
    learner:
      cur_lr: 0.001281411969102919
      grad_gnorm: 39.999996185302734
      policy_entropy: 157.9674072265625
      policy_loss: 27.621381759643555
      var_gnorm: 41.007293701171875
      vf_explained_var: 0.09264415502548218
      vf_loss: 13.569928169250488
    num_steps_sampled: 1190000
    num_steps_trained: 1190000
    wait_time_ms: 155.48
  iterations_since_restore: 119
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 2196.7810578346252
  time_this_iter_s: 18.411354303359985
  time_total_s: 2196.7810578346252
  timestamp: 1593886651
  timesteps_since_restore: 1190000
  timesteps_this_iter: 10000
  timesteps_total: 1190000
  training_iteration: 119
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 2196 s, 119 iter, 1190000 ts, 229 rew

agent-1: 26.0
agent-2: 25.0
agent-3: 27.0
agent-4: 9.0
agent-5: 25.0
agent-6: 20.0
agent-7: 24.0
agent-8: 27.0
agent-9: 27.0
agent-10: 29.0
Sum Reward: 239.0
Avg Reward: 23.9
Min Reward: 9.0
Gini Coefficient: 0.10502092050209205
20:20 Ratio: 1.9310344827586208
Max-min Ratio: 3.2222222222222223
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-17-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 316.0
  episode_reward_mean: 228.99
  episode_reward_min: 190.0
  episodes_this_iter: 1
  episodes_total: 119
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.098
    dispatch_time_ms: 27.063
    learner:
      cur_lr: 0.0012807459570467472
      grad_gnorm: 2.0456955432891846
      policy_entropy: 158.8094940185547
      policy_loss: 1.1827160120010376
      var_gnorm: 41.15658187866211
      vf_explained_var: 0.9042066335678101
      vf_loss: 0.004739806987345219
    num_steps_sampled: 1200000
    num_steps_trained: 1200000
    wait_time_ms: 182.551
  iterations_since_restore: 120
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 2215.52006983757
  time_this_iter_s: 18.739012002944946
  time_total_s: 2215.52006983757
  timestamp: 1593886670
  timesteps_since_restore: 1200000
  timesteps_this_iter: 10000
  timesteps_total: 1200000
  training_iteration: 120
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 2215 s, 120 iter, 1200000 ts, 229 rew

agent-1: 30.0
agent-2: 21.0
agent-3: 15.0
agent-4: 29.0
agent-5: 24.0
agent-6: 21.0
agent-7: 22.0
agent-8: 10.0
agent-9: 24.0
agent-10: 24.0
Sum Reward: 220.0
Avg Reward: 22.0
Min Reward: 10.0
Gini Coefficient: 0.13818181818181818
20:20 Ratio: 2.36
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-18-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 303.0
  episode_reward_mean: 228.03
  episode_reward_min: 190.0
  episodes_this_iter: 1
  episodes_total: 120
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.114
    dispatch_time_ms: 30.813
    learner:
      cur_lr: 0.0012800799449905753
      grad_gnorm: 39.99999237060547
      policy_entropy: 135.60472106933594
      policy_loss: 8.397467613220215
      var_gnorm: 41.25448226928711
      vf_explained_var: -0.6190447807312012
      vf_loss: 42.62531661987305
    num_steps_sampled: 1210000
    num_steps_trained: 1210000
    wait_time_ms: 152.783
  iterations_since_restore: 121
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 2233.887049674988
  time_this_iter_s: 18.366979837417603
  time_total_s: 2233.887049674988
  timestamp: 1593886688
  timesteps_since_restore: 1210000
  timesteps_this_iter: 10000
  timesteps_total: 1210000
  training_iteration: 121
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 2233 s, 121 iter, 1210000 ts, 228 rew

agent-1: 14.0
agent-2: 20.0
agent-3: 14.0
agent-4: 28.0
agent-5: 33.0
agent-6: 24.0
agent-7: 24.0
agent-8: 40.0
agent-9: 20.0
agent-10: 16.0
Sum Reward: 233.0
Avg Reward: 23.3
Min Reward: 14.0
Gini Coefficient: 0.19012875536480686
20:20 Ratio: 2.607142857142857
Max-min Ratio: 2.857142857142857
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-18-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 303.0
  episode_reward_mean: 228.17
  episode_reward_min: 190.0
  episodes_this_iter: 1
  episodes_total: 121
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.734
    dispatch_time_ms: 13.947
    learner:
      cur_lr: 0.0012794140493497252
      grad_gnorm: 0.744214653968811
      policy_entropy: 174.8870086669922
      policy_loss: -0.4444287419319153
      var_gnorm: 41.427223205566406
      vf_explained_var: 0.8496379256248474
      vf_loss: 0.0008778845658525825
    num_steps_sampled: 1220000
    num_steps_trained: 1220000
    wait_time_ms: 170.5
  iterations_since_restore: 122
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 2252.200409889221
  time_this_iter_s: 18.3133602142334
  time_total_s: 2252.200409889221
  timestamp: 1593886706
  timesteps_since_restore: 1220000
  timesteps_this_iter: 10000
  timesteps_total: 1220000
  training_iteration: 122
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 2252 s, 122 iter, 1220000 ts, 228 rew

agent-1: 13.0
agent-2: 13.0
agent-3: 20.0
agent-4: 22.0
agent-5: 24.0
agent-6: 13.0
agent-7: 30.0
agent-8: 23.0
agent-9: 11.0
agent-10: 22.0
Sum Reward: 191.0
Avg Reward: 19.1
Min Reward: 11.0
Gini Coefficient: 0.1712041884816754
20:20 Ratio: 2.25
Max-min Ratio: 2.727272727272727
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-18-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 303.0
  episode_reward_mean: 228.01
  episode_reward_min: 190.0
  episodes_this_iter: 1
  episodes_total: 122
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 4.646
    dispatch_time_ms: 25.725
    learner:
      cur_lr: 0.0012787480372935534
      grad_gnorm: 40.0
      policy_entropy: 104.15899658203125
      policy_loss: -18.57481575012207
      var_gnorm: 41.378623962402344
      vf_explained_var: 0.4166734218597412
      vf_loss: 49.159358978271484
    num_steps_sampled: 1230000
    num_steps_trained: 1230000
    wait_time_ms: 152.522
  iterations_since_restore: 123
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 2270.3034937381744
  time_this_iter_s: 18.103083848953247
  time_total_s: 2270.3034937381744
  timestamp: 1593886725
  timesteps_since_restore: 1230000
  timesteps_this_iter: 10000
  timesteps_total: 1230000
  training_iteration: 123
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 2270 s, 123 iter, 1230000 ts, 228 rew

agent-1: 15.0
agent-2: 20.0
agent-3: 15.0
agent-4: 10.0
agent-5: 26.0
agent-6: 27.0
agent-7: 20.0
agent-8: 31.0
agent-9: 31.0
agent-10: 20.0
Sum Reward: 215.0
Avg Reward: 21.5
Min Reward: 10.0
Gini Coefficient: 0.17627906976744187
20:20 Ratio: 2.48
Max-min Ratio: 3.1
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-19-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 303.0
  episode_reward_mean: 227.73
  episode_reward_min: 190.0
  episodes_this_iter: 1
  episodes_total: 123
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.995
    dispatch_time_ms: 34.416
    learner:
      cur_lr: 0.0012780820252373815
      grad_gnorm: 1.2124665975570679
      policy_entropy: 177.07559204101562
      policy_loss: -2.263545513153076
      var_gnorm: 41.64584732055664
      vf_explained_var: 0.825499951839447
      vf_loss: 0.001062085386365652
    num_steps_sampled: 1240000
    num_steps_trained: 1240000
    wait_time_ms: 150.112
  iterations_since_restore: 124
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 2288.574500322342
  time_this_iter_s: 18.27100658416748
  time_total_s: 2288.574500322342
  timestamp: 1593886743
  timesteps_since_restore: 1240000
  timesteps_this_iter: 10000
  timesteps_total: 1240000
  training_iteration: 124
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 2288 s, 124 iter, 1240000 ts, 228 rew

agent-1: 24.0
agent-2: 21.0
agent-3: 23.0
agent-4: 23.0
agent-5: 21.0
agent-6: 30.0
agent-7: 31.0
agent-8: 21.0
agent-9: 16.0
agent-10: 21.0
Sum Reward: 231.0
Avg Reward: 23.1
Min Reward: 16.0
Gini Coefficient: 0.09567099567099567
20:20 Ratio: 1.6486486486486487
Max-min Ratio: 1.9375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-19-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 303.0
  episode_reward_mean: 227.33
  episode_reward_min: 190.0
  episodes_this_iter: 1
  episodes_total: 124
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.694
    dispatch_time_ms: 28.614
    learner:
      cur_lr: 0.0012774160131812096
      grad_gnorm: 2.0431880950927734
      policy_entropy: 185.05641174316406
      policy_loss: 1.9876211881637573
      var_gnorm: 41.700477600097656
      vf_explained_var: 0.4885157346725464
      vf_loss: 0.0017216620035469532
    num_steps_sampled: 1250000
    num_steps_trained: 1250000
    wait_time_ms: 152.221
  iterations_since_restore: 125
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 2306.8718757629395
  time_this_iter_s: 18.297375440597534
  time_total_s: 2306.8718757629395
  timestamp: 1593886761
  timesteps_since_restore: 1250000
  timesteps_this_iter: 10000
  timesteps_total: 1250000
  training_iteration: 125
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 2306 s, 125 iter, 1250000 ts, 227 rew

agent-1: 19.0
agent-2: 24.0
agent-3: 23.0
agent-4: 25.0
agent-5: 24.0
agent-6: 13.0
agent-7: 23.0
agent-8: 23.0
agent-9: 21.0
agent-10: 28.0
Sum Reward: 223.0
Avg Reward: 22.3
Min Reward: 13.0
Gini Coefficient: 0.08744394618834081
20:20 Ratio: 1.65625
Max-min Ratio: 2.1538461538461537
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-19-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 303.0
  episode_reward_mean: 227.21
  episode_reward_min: 190.0
  episodes_this_iter: 1
  episodes_total: 125
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.954
    dispatch_time_ms: 32.358
    learner:
      cur_lr: 0.0012767500011250377
      grad_gnorm: 0.17644235491752625
      policy_entropy: 149.3355712890625
      policy_loss: 0.5089590549468994
      var_gnorm: 42.00398635864258
      vf_explained_var: 0.46000128984451294
      vf_loss: 1.6557447452214547e-05
    num_steps_sampled: 1260000
    num_steps_trained: 1260000
    wait_time_ms: 153.716
  iterations_since_restore: 126
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 2328.675595521927
  time_this_iter_s: 21.803719758987427
  time_total_s: 2328.675595521927
  timestamp: 1593886783
  timesteps_since_restore: 1260000
  timesteps_this_iter: 10000
  timesteps_total: 1260000
  training_iteration: 126
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 2328 s, 126 iter, 1260000 ts, 227 rew

agent-1: 18.0
agent-2: 20.0
agent-3: 16.0
agent-4: 21.0
agent-5: 22.0
agent-6: 24.0
agent-7: 30.0
agent-8: 23.0
agent-9: 20.0
agent-10: 23.0
Sum Reward: 217.0
Avg Reward: 21.7
Min Reward: 16.0
Gini Coefficient: 0.08894009216589861
20:20 Ratio: 1.588235294117647
Max-min Ratio: 1.875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-20-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 303.0
  episode_reward_mean: 226.63
  episode_reward_min: 190.0
  episodes_this_iter: 1
  episodes_total: 126
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.207
    dispatch_time_ms: 30.279
    learner:
      cur_lr: 0.0012760839890688658
      grad_gnorm: 39.99999237060547
      policy_entropy: 45.883174896240234
      policy_loss: 7.752129077911377
      var_gnorm: 42.011573791503906
      vf_explained_var: 0.32820814847946167
      vf_loss: 76.31475067138672
    num_steps_sampled: 1270000
    num_steps_trained: 1270000
    wait_time_ms: 156.137
  iterations_since_restore: 127
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 2346.1818974018097
  time_this_iter_s: 17.506301879882812
  time_total_s: 2346.1818974018097
  timestamp: 1593886802
  timesteps_since_restore: 1270000
  timesteps_this_iter: 10000
  timesteps_total: 1270000
  training_iteration: 127
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 2346 s, 127 iter, 1270000 ts, 227 rew

agent-1: 30.0
agent-2: 15.0
agent-3: 21.0
agent-4: 33.0
agent-5: 15.0
agent-6: 18.0
agent-7: 17.0
agent-8: 18.0
agent-9: 20.0
agent-10: 20.0
Sum Reward: 207.0
Avg Reward: 20.7
Min Reward: 15.0
Gini Coefficient: 0.14251207729468598
20:20 Ratio: 2.1
Max-min Ratio: 2.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-20-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 303.0
  episode_reward_mean: 226.4
  episode_reward_min: 190.0
  episodes_this_iter: 1
  episodes_total: 127
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.946
    dispatch_time_ms: 29.259
    learner:
      cur_lr: 0.0012754179770126939
      grad_gnorm: 3.5299665927886963
      policy_entropy: 173.07208251953125
      policy_loss: -0.5996736288070679
      var_gnorm: 42.27981948852539
      vf_explained_var: -1.0
      vf_loss: 0.02301957830786705
    num_steps_sampled: 1280000
    num_steps_trained: 1280000
    wait_time_ms: 158.588
  iterations_since_restore: 128
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 2364.5781672000885
  time_this_iter_s: 18.39626979827881
  time_total_s: 2364.5781672000885
  timestamp: 1593886820
  timesteps_since_restore: 1280000
  timesteps_this_iter: 10000
  timesteps_total: 1280000
  training_iteration: 128
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 2364 s, 128 iter, 1280000 ts, 226 rew

agent-1: 19.0
agent-2: 25.0
agent-3: 29.0
agent-4: 19.0
agent-5: 20.0
agent-6: 22.0
agent-7: 14.0
agent-8: 20.0
agent-9: 12.0
agent-10: 23.0
Sum Reward: 203.0
Avg Reward: 20.3
Min Reward: 12.0
Gini Coefficient: 0.12758620689655173
20:20 Ratio: 2.076923076923077
Max-min Ratio: 2.4166666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-20-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 303.0
  episode_reward_mean: 225.94
  episode_reward_min: 190.0
  episodes_this_iter: 1
  episodes_total: 128
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.658
    dispatch_time_ms: 27.515
    learner:
      cur_lr: 0.001274751964956522
      grad_gnorm: 3.451716184616089
      policy_entropy: 177.45155334472656
      policy_loss: -1.2205793857574463
      var_gnorm: 42.240779876708984
      vf_explained_var: -0.8733005523681641
      vf_loss: 0.01927574723958969
    num_steps_sampled: 1290000
    num_steps_trained: 1290000
    wait_time_ms: 158.142
  iterations_since_restore: 129
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 2383.1485800743103
  time_this_iter_s: 18.5704128742218
  time_total_s: 2383.1485800743103
  timestamp: 1593886839
  timesteps_since_restore: 1290000
  timesteps_this_iter: 10000
  timesteps_total: 1290000
  training_iteration: 129
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 2383 s, 129 iter, 1290000 ts, 226 rew

agent-1: 22.0
agent-2: 11.0
agent-3: 20.0
agent-4: 22.0
agent-5: 13.0
agent-6: 16.0
agent-7: 18.0
agent-8: 25.0
agent-9: 21.0
agent-10: 18.0
Sum Reward: 186.0
Avg Reward: 18.6
Min Reward: 11.0
Gini Coefficient: 0.12365591397849462
20:20 Ratio: 1.9583333333333333
Max-min Ratio: 2.272727272727273
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-20-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 303.0
  episode_reward_mean: 225.09
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 129
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.659
    dispatch_time_ms: 27.421
    learner:
      cur_lr: 0.00127408595290035
      grad_gnorm: 0.4438894987106323
      policy_entropy: 176.47084045410156
      policy_loss: -0.427936315536499
      var_gnorm: 42.4521484375
      vf_explained_var: 0.7967394590377808
      vf_loss: 0.0004759182338602841
    num_steps_sampled: 1300000
    num_steps_trained: 1300000
    wait_time_ms: 157.372
  iterations_since_restore: 130
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 2401.772777080536
  time_this_iter_s: 18.624197006225586
  time_total_s: 2401.772777080536
  timestamp: 1593886857
  timesteps_since_restore: 1300000
  timesteps_this_iter: 10000
  timesteps_total: 1300000
  training_iteration: 130
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 2401 s, 130 iter, 1300000 ts, 225 rew

agent-1: 22.0
agent-2: 13.0
agent-3: 17.0
agent-4: 25.0
agent-5: 26.0
agent-6: 23.0
agent-7: 24.0
agent-8: 23.0
agent-9: 14.0
agent-10: 18.0
Sum Reward: 205.0
Avg Reward: 20.5
Min Reward: 13.0
Gini Coefficient: 0.11951219512195121
20:20 Ratio: 1.8888888888888888
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-21-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 303.0
  episode_reward_mean: 224.84
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 130
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.837
    dispatch_time_ms: 40.08
    learner:
      cur_lr: 0.0012734200572595
      grad_gnorm: 39.999996185302734
      policy_entropy: 30.570926666259766
      policy_loss: 0.47282761335372925
      var_gnorm: 42.5150146484375
      vf_explained_var: 0.4135180115699768
      vf_loss: 64.83767700195312
    num_steps_sampled: 1310000
    num_steps_trained: 1310000
    wait_time_ms: 164.311
  iterations_since_restore: 131
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 2420.4782450199127
  time_this_iter_s: 18.70546793937683
  time_total_s: 2420.4782450199127
  timestamp: 1593886876
  timesteps_since_restore: 1310000
  timesteps_this_iter: 10000
  timesteps_total: 1310000
  training_iteration: 131
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 2420 s, 131 iter, 1310000 ts, 225 rew

agent-1: 31.0
agent-2: 28.0
agent-3: 25.0
agent-4: 15.0
agent-5: 23.0
agent-6: 30.0
agent-7: 34.0
agent-8: 9.0
agent-9: 16.0
agent-10: 21.0
Sum Reward: 232.0
Avg Reward: 23.2
Min Reward: 9.0
Gini Coefficient: 0.1853448275862069
20:20 Ratio: 2.7083333333333335
Max-min Ratio: 3.7777777777777777
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-21-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 303.0
  episode_reward_mean: 224.9
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 131
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.484
    dispatch_time_ms: 30.642
    learner:
      cur_lr: 0.0012727540452033281
      grad_gnorm: 6.225050449371338
      policy_entropy: 187.87716674804688
      policy_loss: -0.4566085636615753
      var_gnorm: 42.76695251464844
      vf_explained_var: -1.0
      vf_loss: 0.007852020673453808
    num_steps_sampled: 1320000
    num_steps_trained: 1320000
    wait_time_ms: 150.573
  iterations_since_restore: 132
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 2438.9972355365753
  time_this_iter_s: 18.518990516662598
  time_total_s: 2438.9972355365753
  timestamp: 1593886895
  timesteps_since_restore: 1320000
  timesteps_this_iter: 10000
  timesteps_total: 1320000
  training_iteration: 132
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 2438 s, 132 iter, 1320000 ts, 225 rew

agent-1: 17.0
agent-2: 19.0
agent-3: 26.0
agent-4: 24.0
agent-5: 16.0
agent-6: 24.0
agent-7: 15.0
agent-8: 22.0
agent-9: 24.0
agent-10: 20.0
Sum Reward: 207.0
Avg Reward: 20.7
Min Reward: 15.0
Gini Coefficient: 0.1
20:20 Ratio: 1.6129032258064515
Max-min Ratio: 1.7333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-21-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 303.0
  episode_reward_mean: 224.43
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 132
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.929
    dispatch_time_ms: 19.027
    learner:
      cur_lr: 0.0012720880331471562
      grad_gnorm: 40.0
      policy_entropy: 30.350826263427734
      policy_loss: -8.754965782165527
      var_gnorm: 42.764244079589844
      vf_explained_var: 0.2926533818244934
      vf_loss: 49.652931213378906
    num_steps_sampled: 1330000
    num_steps_trained: 1330000
    wait_time_ms: 138.724
  iterations_since_restore: 133
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 2457.352073431015
  time_this_iter_s: 18.354837894439697
  time_total_s: 2457.352073431015
  timestamp: 1593886913
  timesteps_since_restore: 1330000
  timesteps_this_iter: 10000
  timesteps_total: 1330000
  training_iteration: 133
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 2457 s, 133 iter, 1330000 ts, 224 rew

agent-1: 28.0
agent-2: 23.0
agent-3: 20.0
agent-4: 25.0
agent-5: 18.0
agent-6: 26.0
agent-7: 22.0
agent-8: 18.0
agent-9: 21.0
agent-10: 21.0
Sum Reward: 222.0
Avg Reward: 22.2
Min Reward: 18.0
Gini Coefficient: 0.08018018018018018
20:20 Ratio: 1.5
Max-min Ratio: 1.5555555555555556
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-22-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 270.0
  episode_reward_mean: 223.62
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 133
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.746
    dispatch_time_ms: 38.165
    learner:
      cur_lr: 0.0012714220210909843
      grad_gnorm: 0.5861097574234009
      policy_entropy: 185.54525756835938
      policy_loss: 0.6527315974235535
      var_gnorm: 42.92045974731445
      vf_explained_var: -0.13472223281860352
      vf_loss: 0.0030162923503667116
    num_steps_sampled: 1340000
    num_steps_trained: 1340000
    wait_time_ms: 150.879
  iterations_since_restore: 134
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 2475.8559198379517
  time_this_iter_s: 18.503846406936646
  time_total_s: 2475.8559198379517
  timestamp: 1593886932
  timesteps_since_restore: 1340000
  timesteps_this_iter: 10000
  timesteps_total: 1340000
  training_iteration: 134
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 2475 s, 134 iter, 1340000 ts, 224 rew

agent-1: 21.0
agent-2: 28.0
agent-3: 35.0
agent-4: 22.0
agent-5: 21.0
agent-6: 20.0
agent-7: 24.0
agent-8: 17.0
agent-9: 14.0
agent-10: 26.0
Sum Reward: 228.0
Avg Reward: 22.8
Min Reward: 14.0
Gini Coefficient: 0.13421052631578947
20:20 Ratio: 2.032258064516129
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-22-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 270.0
  episode_reward_mean: 223.37
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 134
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.604
    dispatch_time_ms: 35.745
    learner:
      cur_lr: 0.0012707560090348125
      grad_gnorm: 1.433868408203125
      policy_entropy: 188.55291748046875
      policy_loss: -0.17117317020893097
      var_gnorm: 42.881622314453125
      vf_explained_var: 0.5193783044815063
      vf_loss: 0.00227444083429873
    num_steps_sampled: 1350000
    num_steps_trained: 1350000
    wait_time_ms: 135.372
  iterations_since_restore: 135
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 2494.1649420261383
  time_this_iter_s: 18.309022188186646
  time_total_s: 2494.1649420261383
  timestamp: 1593886950
  timesteps_since_restore: 1350000
  timesteps_this_iter: 10000
  timesteps_total: 1350000
  training_iteration: 135
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 2494 s, 135 iter, 1350000 ts, 223 rew

agent-1: 27.0
agent-2: 29.0
agent-3: 24.0
agent-4: 24.0
agent-5: 18.0
agent-6: 27.0
agent-7: 21.0
agent-8: 37.0
agent-9: 21.0
agent-10: 27.0
Sum Reward: 255.0
Avg Reward: 25.5
Min Reward: 18.0
Gini Coefficient: 0.10549019607843137
20:20 Ratio: 1.6923076923076923
Max-min Ratio: 2.0555555555555554
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-22-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 270.0
  episode_reward_mean: 223.26
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 135
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.843
    dispatch_time_ms: 28.383
    learner:
      cur_lr: 0.0012700899969786406
      grad_gnorm: 1.7850191593170166
      policy_entropy: 164.30581665039062
      policy_loss: 0.38644587993621826
      var_gnorm: 43.050254821777344
      vf_explained_var: 0.7975367307662964
      vf_loss: 0.013033109717071056
    num_steps_sampled: 1360000
    num_steps_trained: 1360000
    wait_time_ms: 149.791
  iterations_since_restore: 136
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 2512.512105703354
  time_this_iter_s: 18.347163677215576
  time_total_s: 2512.512105703354
  timestamp: 1593886968
  timesteps_since_restore: 1360000
  timesteps_this_iter: 10000
  timesteps_total: 1360000
  training_iteration: 136
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 2512 s, 136 iter, 1360000 ts, 223 rew

agent-1: 19.0
agent-2: 25.0
agent-3: 17.0
agent-4: 17.0
agent-5: 23.0
agent-6: 28.0
agent-7: 24.0
agent-8: 22.0
agent-9: 25.0
agent-10: 14.0
Sum Reward: 214.0
Avg Reward: 21.4
Min Reward: 14.0
Gini Coefficient: 0.11121495327102804
20:20 Ratio: 1.7096774193548387
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-23-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 270.0
  episode_reward_mean: 222.7
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 136
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.216
    dispatch_time_ms: 43.852
    learner:
      cur_lr: 0.0012694239849224687
      grad_gnorm: 2.173776626586914
      policy_entropy: 182.35934448242188
      policy_loss: 0.15581420063972473
      var_gnorm: 43.09064483642578
      vf_explained_var: 0.7760570049285889
      vf_loss: 0.036622218787670135
    num_steps_sampled: 1370000
    num_steps_trained: 1370000
    wait_time_ms: 129.997
  iterations_since_restore: 137
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 2531.236253976822
  time_this_iter_s: 18.724148273468018
  time_total_s: 2531.236253976822
  timestamp: 1593886987
  timesteps_since_restore: 1370000
  timesteps_this_iter: 10000
  timesteps_total: 1370000
  training_iteration: 137
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 2531 s, 137 iter, 1370000 ts, 223 rew

agent-1: 10.0
agent-2: 21.0
agent-3: 26.0
agent-4: 15.0
agent-5: 27.0
agent-6: 20.0
agent-7: 26.0
agent-8: 24.0
agent-9: 22.0
agent-10: 21.0
Sum Reward: 212.0
Avg Reward: 21.2
Min Reward: 10.0
Gini Coefficient: 0.12735849056603774
20:20 Ratio: 2.12
Max-min Ratio: 2.7
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-23-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 270.0
  episode_reward_mean: 222.53
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 137
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.945
    dispatch_time_ms: 33.434
    learner:
      cur_lr: 0.0012687579728662968
      grad_gnorm: 0.6221007108688354
      policy_entropy: 176.9031982421875
      policy_loss: -0.45247992873191833
      var_gnorm: 43.50798034667969
      vf_explained_var: -1.0
      vf_loss: 0.0005566622712649405
    num_steps_sampled: 1380000
    num_steps_trained: 1380000
    wait_time_ms: 150.791
  iterations_since_restore: 138
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 2549.764286994934
  time_this_iter_s: 18.528033018112183
  time_total_s: 2549.764286994934
  timestamp: 1593887006
  timesteps_since_restore: 1380000
  timesteps_this_iter: 10000
  timesteps_total: 1380000
  training_iteration: 138
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 2549 s, 138 iter, 1380000 ts, 223 rew

agent-1: 22.0
agent-2: 17.0
agent-3: 23.0
agent-4: 19.0
agent-5: 31.0
agent-6: 27.0
agent-7: 24.0
agent-8: 14.0
agent-9: 28.0
agent-10: 14.0
Sum Reward: 219.0
Avg Reward: 21.9
Min Reward: 14.0
Gini Coefficient: 0.14474885844748858
20:20 Ratio: 2.107142857142857
Max-min Ratio: 2.2142857142857144
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-23-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 270.0
  episode_reward_mean: 222.57
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 138
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 4.653
    dispatch_time_ms: 29.461
    learner:
      cur_lr: 0.0012680919608101249
      grad_gnorm: 0.7963197231292725
      policy_entropy: 183.6179656982422
      policy_loss: 0.7225911617279053
      var_gnorm: 43.533390045166016
      vf_explained_var: -1.0
      vf_loss: 0.0033977555576711893
    num_steps_sampled: 1390000
    num_steps_trained: 1390000
    wait_time_ms: 142.696
  iterations_since_restore: 139
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 2568.2096967697144
  time_this_iter_s: 18.445409774780273
  time_total_s: 2568.2096967697144
  timestamp: 1593887024
  timesteps_since_restore: 1390000
  timesteps_this_iter: 10000
  timesteps_total: 1390000
  training_iteration: 139
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 2568 s, 139 iter, 1390000 ts, 223 rew

agent-1: 29.0
agent-2: 18.0
agent-3: 16.0
agent-4: 32.0
agent-5: 23.0
agent-6: 11.0
agent-7: 33.0
agent-8: 13.0
agent-9: 36.0
agent-10: 24.0
Sum Reward: 235.0
Avg Reward: 23.5
Min Reward: 11.0
Gini Coefficient: 0.20382978723404255
20:20 Ratio: 2.875
Max-min Ratio: 3.272727272727273
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-24-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 270.0
  episode_reward_mean: 222.85
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 139
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.45
    dispatch_time_ms: 55.455
    learner:
      cur_lr: 0.001267425948753953
      grad_gnorm: 0.19316206872463226
      policy_entropy: 183.25209045410156
      policy_loss: 0.2655981481075287
      var_gnorm: 43.59026336669922
      vf_explained_var: 0.9951337575912476
      vf_loss: 8.235616405727342e-05
    num_steps_sampled: 1400000
    num_steps_trained: 1400000
    wait_time_ms: 130.003
  iterations_since_restore: 140
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 2586.7275443077087
  time_this_iter_s: 18.517847537994385
  time_total_s: 2586.7275443077087
  timestamp: 1593887043
  timesteps_since_restore: 1400000
  timesteps_this_iter: 10000
  timesteps_total: 1400000
  training_iteration: 140
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 2586 s, 140 iter, 1400000 ts, 223 rew

agent-1: 17.0
agent-2: 23.0
agent-3: 32.0
agent-4: 23.0
agent-5: 24.0
agent-6: 15.0
agent-7: 26.0
agent-8: 24.0
agent-9: 19.0
agent-10: 17.0
Sum Reward: 220.0
Avg Reward: 22.0
Min Reward: 15.0
Gini Coefficient: 0.12090909090909091
20:20 Ratio: 1.8125
Max-min Ratio: 2.1333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-24-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 270.0
  episode_reward_mean: 222.85
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 140
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.694
    dispatch_time_ms: 31.276
    learner:
      cur_lr: 0.001266760053113103
      grad_gnorm: 0.5393542647361755
      policy_entropy: 186.25958251953125
      policy_loss: -0.32954928278923035
      var_gnorm: 43.59048080444336
      vf_explained_var: 0.9936538338661194
      vf_loss: 0.00026542891282588243
    num_steps_sampled: 1410000
    num_steps_trained: 1410000
    wait_time_ms: 151.44
  iterations_since_restore: 141
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 2605.282372713089
  time_this_iter_s: 18.55482840538025
  time_total_s: 2605.282372713089
  timestamp: 1593887061
  timesteps_since_restore: 1410000
  timesteps_this_iter: 10000
  timesteps_total: 1410000
  training_iteration: 141
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 2605 s, 141 iter, 1410000 ts, 223 rew

agent-1: 30.0
agent-2: 27.0
agent-3: 17.0
agent-4: 14.0
agent-5: 27.0
agent-6: 24.0
agent-7: 18.0
agent-8: 11.0
agent-9: 32.0
agent-10: 20.0
Sum Reward: 220.0
Avg Reward: 22.0
Min Reward: 11.0
Gini Coefficient: 0.17363636363636364
20:20 Ratio: 2.48
Max-min Ratio: 2.909090909090909
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-24-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 270.0
  episode_reward_mean: 222.79
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 141
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.055
    dispatch_time_ms: 33.446
    learner:
      cur_lr: 0.001266094041056931
      grad_gnorm: 0.776721715927124
      policy_entropy: 147.74737548828125
      policy_loss: 0.1626214236021042
      var_gnorm: 43.8135871887207
      vf_explained_var: -1.0
      vf_loss: 0.0007459488115273416
    num_steps_sampled: 1420000
    num_steps_trained: 1420000
    wait_time_ms: 137.213
  iterations_since_restore: 142
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 2623.886148929596
  time_this_iter_s: 18.603776216506958
  time_total_s: 2623.886148929596
  timestamp: 1593887080
  timesteps_since_restore: 1420000
  timesteps_this_iter: 10000
  timesteps_total: 1420000
  training_iteration: 142
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 2623 s, 142 iter, 1420000 ts, 223 rew

agent-1: 24.0
agent-2: 18.0
agent-3: 20.0
agent-4: 15.0
agent-5: 27.0
agent-6: 21.0
agent-7: 24.0
agent-8: 20.0
agent-9: 28.0
agent-10: 18.0
Sum Reward: 215.0
Avg Reward: 21.5
Min Reward: 15.0
Gini Coefficient: 0.10372093023255814
20:20 Ratio: 1.6666666666666667
Max-min Ratio: 1.8666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-25-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 270.0
  episode_reward_mean: 222.47
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 142
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.688
    dispatch_time_ms: 7.42
    learner:
      cur_lr: 0.0012654280290007591
      grad_gnorm: 40.000003814697266
      policy_entropy: 7.948357105255127
      policy_loss: 8.093076705932617
      var_gnorm: 43.79485321044922
      vf_explained_var: 0.3818228840827942
      vf_loss: 152.7556915283203
    num_steps_sampled: 1430000
    num_steps_trained: 1430000
    wait_time_ms: 146.578
  iterations_since_restore: 143
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 2643.620040655136
  time_this_iter_s: 19.73389172554016
  time_total_s: 2643.620040655136
  timestamp: 1593887100
  timesteps_since_restore: 1430000
  timesteps_this_iter: 10000
  timesteps_total: 1430000
  training_iteration: 143
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 2643 s, 143 iter, 1430000 ts, 222 rew

agent-1: 21.0
agent-2: 19.0
agent-3: 23.0
agent-4: 21.0
agent-5: 22.0
agent-6: 28.0
agent-7: 16.0
agent-8: 20.0
agent-9: 18.0
agent-10: 19.0
Sum Reward: 207.0
Avg Reward: 20.7
Min Reward: 16.0
Gini Coefficient: 0.07971014492753623
20:20 Ratio: 1.5
Max-min Ratio: 1.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-25-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 221.84
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 143
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 4.1
    dispatch_time_ms: 7.601
    learner:
      cur_lr: 0.0012647620169445872
      grad_gnorm: 0.4912102222442627
      policy_entropy: 173.8189239501953
      policy_loss: -0.1168624758720398
      var_gnorm: 44.0797119140625
      vf_explained_var: -0.2987633943557739
      vf_loss: 0.0016977404011413455
    num_steps_sampled: 1440000
    num_steps_trained: 1440000
    wait_time_ms: 170.115
  iterations_since_restore: 144
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 2661.213517189026
  time_this_iter_s: 17.59347653388977
  time_total_s: 2661.213517189026
  timestamp: 1593887117
  timesteps_since_restore: 1440000
  timesteps_this_iter: 10000
  timesteps_total: 1440000
  training_iteration: 144
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 2661 s, 144 iter, 1440000 ts, 222 rew

agent-1: 9.0
agent-2: 24.0
agent-3: 19.0
agent-4: 25.0
agent-5: 24.0
agent-6: 22.0
agent-7: 20.0
agent-8: 18.0
agent-9: 22.0
agent-10: 21.0
Sum Reward: 204.0
Avg Reward: 20.4
Min Reward: 9.0
Gini Coefficient: 0.10686274509803921
20:20 Ratio: 1.8148148148148149
Max-min Ratio: 2.7777777777777777
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-25-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 221.63
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 144
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.908
    dispatch_time_ms: 7.189
    learner:
      cur_lr: 0.0012640960048884153
      grad_gnorm: 40.00000762939453
      policy_entropy: 5.874655246734619
      policy_loss: 6.291718482971191
      var_gnorm: 44.08525848388672
      vf_explained_var: 0.35439151525497437
      vf_loss: 275.5772705078125
    num_steps_sampled: 1450000
    num_steps_trained: 1450000
    wait_time_ms: 141.055
  iterations_since_restore: 145
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 2678.772436141968
  time_this_iter_s: 17.558918952941895
  time_total_s: 2678.772436141968
  timestamp: 1593887135
  timesteps_since_restore: 1450000
  timesteps_this_iter: 10000
  timesteps_total: 1450000
  training_iteration: 145
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 2678 s, 145 iter, 1450000 ts, 222 rew

agent-1: 23.0
agent-2: 28.0
agent-3: 36.0
agent-4: 33.0
agent-5: 5.0
agent-6: 15.0
agent-7: 17.0
agent-8: 29.0
agent-9: 14.0
agent-10: 31.0
Sum Reward: 231.0
Avg Reward: 23.1
Min Reward: 5.0
Gini Coefficient: 0.23073593073593074
20:20 Ratio: 3.6315789473684212
Max-min Ratio: 7.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-25-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 221.67
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 145
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.384
    dispatch_time_ms: 6.188
    learner:
      cur_lr: 0.0012634299928322434
      grad_gnorm: 4.694568634033203
      policy_entropy: 180.66790771484375
      policy_loss: -0.22380366921424866
      var_gnorm: 44.23284912109375
      vf_explained_var: 0.6663162112236023
      vf_loss: 0.0010513276793062687
    num_steps_sampled: 1460000
    num_steps_trained: 1460000
    wait_time_ms: 161.741
  iterations_since_restore: 146
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 2696.387235879898
  time_this_iter_s: 17.614799737930298
  time_total_s: 2696.387235879898
  timestamp: 1593887153
  timesteps_since_restore: 1460000
  timesteps_this_iter: 10000
  timesteps_total: 1460000
  training_iteration: 146
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 2696 s, 146 iter, 1460000 ts, 222 rew

agent-1: 25.0
agent-2: 7.0
agent-3: 15.0
agent-4: 13.0
agent-5: 30.0
agent-6: 26.0
agent-7: 26.0
agent-8: 33.0
agent-9: 25.0
agent-10: 21.0
Sum Reward: 221.0
Avg Reward: 22.1
Min Reward: 7.0
Gini Coefficient: 0.19140271493212668
20:20 Ratio: 3.15
Max-min Ratio: 4.714285714285714
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-26-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 221.51
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 146
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.84
    dispatch_time_ms: 6.552
    learner:
      cur_lr: 0.0012627639807760715
      grad_gnorm: 4.260539531707764
      policy_entropy: 185.26589965820312
      policy_loss: -0.10372261703014374
      var_gnorm: 44.23527908325195
      vf_explained_var: -0.9483369588851929
      vf_loss: 0.005419520195573568
    num_steps_sampled: 1470000
    num_steps_trained: 1470000
    wait_time_ms: 166.23
  iterations_since_restore: 147
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 2714.1985223293304
  time_this_iter_s: 17.811286449432373
  time_total_s: 2714.1985223293304
  timestamp: 1593887171
  timesteps_since_restore: 1470000
  timesteps_this_iter: 10000
  timesteps_total: 1470000
  training_iteration: 147
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 2714 s, 147 iter, 1470000 ts, 222 rew

agent-1: 27.0
agent-2: 28.0
agent-3: 25.0
agent-4: 27.0
agent-5: 9.0
agent-6: 18.0
agent-7: 30.0
agent-8: 19.0
agent-9: 12.0
agent-10: 18.0
Sum Reward: 213.0
Avg Reward: 21.3
Min Reward: 9.0
Gini Coefficient: 0.1779342723004695
20:20 Ratio: 2.761904761904762
Max-min Ratio: 3.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-26-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 221.06
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 147
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.708
    dispatch_time_ms: 6.251
    learner:
      cur_lr: 0.0012620979687198997
      grad_gnorm: 1.8990226984024048
      policy_entropy: 160.16314697265625
      policy_loss: -1.054209589958191
      var_gnorm: 44.52757263183594
      vf_explained_var: 0.7914712429046631
      vf_loss: 0.009814837016165257
    num_steps_sampled: 1480000
    num_steps_trained: 1480000
    wait_time_ms: 169.757
  iterations_since_restore: 148
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 2731.8035979270935
  time_this_iter_s: 17.60507559776306
  time_total_s: 2731.8035979270935
  timestamp: 1593887188
  timesteps_since_restore: 1480000
  timesteps_this_iter: 10000
  timesteps_total: 1480000
  training_iteration: 148
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 2731 s, 148 iter, 1480000 ts, 221 rew

agent-1: 14.0
agent-2: 32.0
agent-3: 17.0
agent-4: 25.0
agent-5: 32.0
agent-6: 18.0
agent-7: 2.0
agent-8: 28.0
agent-9: 19.0
agent-10: 19.0
Sum Reward: 206.0
Avg Reward: 20.6
Min Reward: 2.0
Gini Coefficient: 0.229126213592233
20:20 Ratio: 4.0
Max-min Ratio: 16.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-26-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 220.96
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 148
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.742
    dispatch_time_ms: 5.918
    learner:
      cur_lr: 0.0012614319566637278
      grad_gnorm: 40.0
      policy_entropy: 5.77958345413208
      policy_loss: 13.541641235351562
      var_gnorm: 44.529056549072266
      vf_explained_var: 0.47676920890808105
      vf_loss: 281.3925476074219
    num_steps_sampled: 1490000
    num_steps_trained: 1490000
    wait_time_ms: 164.617
  iterations_since_restore: 149
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 2749.5707659721375
  time_this_iter_s: 17.767168045043945
  time_total_s: 2749.5707659721375
  timestamp: 1593887206
  timesteps_since_restore: 1490000
  timesteps_this_iter: 10000
  timesteps_total: 1490000
  training_iteration: 149
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 2749 s, 149 iter, 1490000 ts, 221 rew

agent-1: 18.0
agent-2: 23.0
agent-3: 25.0
agent-4: 27.0
agent-5: 3.0
agent-6: 28.0
agent-7: 26.0
agent-8: 23.0
agent-9: 25.0
agent-10: 23.0
Sum Reward: 221.0
Avg Reward: 22.1
Min Reward: 3.0
Gini Coefficient: 0.1407239819004525
20:20 Ratio: 2.619047619047619
Max-min Ratio: 9.333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-27-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 220.91
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 149
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.93
    dispatch_time_ms: 7.941
    learner:
      cur_lr: 0.0012607659446075559
      grad_gnorm: 1.0562498569488525
      policy_entropy: 154.52027893066406
      policy_loss: 0.5729452967643738
      var_gnorm: 44.69536590576172
      vf_explained_var: -0.2998182773590088
      vf_loss: 0.0011191167868673801
    num_steps_sampled: 1500000
    num_steps_trained: 1500000
    wait_time_ms: 171.575
  iterations_since_restore: 150
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 2767.274573802948
  time_this_iter_s: 17.703807830810547
  time_total_s: 2767.274573802948
  timestamp: 1593887224
  timesteps_since_restore: 1500000
  timesteps_this_iter: 10000
  timesteps_total: 1500000
  training_iteration: 150
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 2767 s, 150 iter, 1500000 ts, 221 rew

agent-1: 14.0
agent-2: 24.0
agent-3: 20.0
agent-4: 24.0
agent-5: 20.0
agent-6: 20.0
agent-7: 21.0
agent-8: 11.0
agent-9: 18.0
agent-10: 34.0
Sum Reward: 206.0
Avg Reward: 20.6
Min Reward: 11.0
Gini Coefficient: 0.15048543689320387
20:20 Ratio: 2.32
Max-min Ratio: 3.090909090909091
agent-1: 19.0
agent-2: 24.0
agent-3: 25.0
agent-4: 23.0
agent-5: 17.0
agent-6: 11.0
agent-7: 21.0
agent-8: 20.0
agent-9: 22.0
agent-10: 12.0
Sum Reward: 194.0
Avg Reward: 19.4
Min Reward: 11.0
Gini Coefficient: 0.12886597938144329
20:20 Ratio: 2.130434782608696
Max-min Ratio: 2.272727272727273
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-27-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 220.14
  episode_reward_min: 186.0
  episodes_this_iter: 2
  episodes_total: 151
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 4.243
    dispatch_time_ms: 6.868
    learner:
      cur_lr: 0.0012601000489667058
      grad_gnorm: 1.2543069124221802
      policy_entropy: 182.90023803710938
      policy_loss: 0.8150619268417358
      var_gnorm: 44.70136260986328
      vf_explained_var: -1.0
      vf_loss: 0.0014108287869021297
    num_steps_sampled: 1510000
    num_steps_trained: 1510000
    wait_time_ms: 166.969
  iterations_since_restore: 151
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 2785.060809612274
  time_this_iter_s: 17.786235809326172
  time_total_s: 2785.060809612274
  timestamp: 1593887242
  timesteps_since_restore: 1510000
  timesteps_this_iter: 10000
  timesteps_total: 1510000
  training_iteration: 151
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 2785 s, 151 iter, 1510000 ts, 220 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-27-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 220.14
  episode_reward_min: 186.0
  episodes_this_iter: 0
  episodes_total: 151
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.724
    dispatch_time_ms: 5.251
    learner:
      cur_lr: 0.001259434036910534
      grad_gnorm: 3.3634493350982666
      policy_entropy: 126.46810913085938
      policy_loss: -1.4648381471633911
      var_gnorm: 44.89386749267578
      vf_explained_var: -0.11468935012817383
      vf_loss: 0.015688981860876083
    num_steps_sampled: 1520000
    num_steps_trained: 1520000
    wait_time_ms: 167.923
  iterations_since_restore: 152
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 2802.474322080612
  time_this_iter_s: 17.413512468338013
  time_total_s: 2802.474322080612
  timestamp: 1593887259
  timesteps_since_restore: 1520000
  timesteps_this_iter: 10000
  timesteps_total: 1520000
  training_iteration: 152
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 2802 s, 152 iter, 1520000 ts, 220 rew

agent-1: 22.0
agent-2: 25.0
agent-3: 24.0
agent-4: 5.0
agent-5: 20.0
agent-6: 27.0
agent-7: 14.0
agent-8: 27.0
agent-9: 28.0
agent-10: 27.0
Sum Reward: 219.0
Avg Reward: 21.9
Min Reward: 5.0
Gini Coefficient: 0.1593607305936073
20:20 Ratio: 2.8947368421052633
Max-min Ratio: 5.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-27-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 220.11
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 152
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.746
    dispatch_time_ms: 6.38
    learner:
      cur_lr: 0.001258768024854362
      grad_gnorm: 40.00000762939453
      policy_entropy: 5.146739482879639
      policy_loss: 11.601218223571777
      var_gnorm: 44.89603042602539
      vf_explained_var: 0.20853030681610107
      vf_loss: 234.64572143554688
    num_steps_sampled: 1530000
    num_steps_trained: 1530000
    wait_time_ms: 159.894
  iterations_since_restore: 153
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 2820.0998418331146
  time_this_iter_s: 17.62551975250244
  time_total_s: 2820.0998418331146
  timestamp: 1593887277
  timesteps_since_restore: 1530000
  timesteps_this_iter: 10000
  timesteps_total: 1530000
  training_iteration: 153
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 2820 s, 153 iter, 1530000 ts, 220 rew

agent-1: 21.0
agent-2: 27.0
agent-3: 21.0
agent-4: 23.0
agent-5: 31.0
agent-6: 29.0
agent-7: 8.0
agent-8: 28.0
agent-9: 21.0
agent-10: 29.0
Sum Reward: 238.0
Avg Reward: 23.8
Min Reward: 8.0
Gini Coefficient: 0.13781512605042018
20:20 Ratio: 2.0689655172413794
Max-min Ratio: 3.875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-28-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 220.06
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 153
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.488
    dispatch_time_ms: 6.478
    learner:
      cur_lr: 0.0012581020127981901
      grad_gnorm: 2.768049955368042
      policy_entropy: 166.04847717285156
      policy_loss: -0.2389291673898697
      var_gnorm: 45.03434371948242
      vf_explained_var: -1.0
      vf_loss: 0.03437359258532524
    num_steps_sampled: 1540000
    num_steps_trained: 1540000
    wait_time_ms: 163.406
  iterations_since_restore: 154
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 2837.541145324707
  time_this_iter_s: 17.441303491592407
  time_total_s: 2837.541145324707
  timestamp: 1593887294
  timesteps_since_restore: 1540000
  timesteps_this_iter: 10000
  timesteps_total: 1540000
  training_iteration: 154
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 2837 s, 154 iter, 1540000 ts, 220 rew

agent-1: 18.0
agent-2: 15.0
agent-3: 11.0
agent-4: 14.0
agent-5: 19.0
agent-6: 28.0
agent-7: 34.0
agent-8: 21.0
agent-9: 11.0
agent-10: 26.0
Sum Reward: 197.0
Avg Reward: 19.7
Min Reward: 11.0
Gini Coefficient: 0.20558375634517767
20:20 Ratio: 2.8181818181818183
Max-min Ratio: 3.090909090909091
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-28-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 219.85
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 154
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.871
    dispatch_time_ms: 23.254
    learner:
      cur_lr: 0.0012574360007420182
      grad_gnorm: 0.4231513440608978
      policy_entropy: 175.0955352783203
      policy_loss: 0.35303908586502075
      var_gnorm: 45.03889465332031
      vf_explained_var: -1.0
      vf_loss: 0.0004444096121005714
    num_steps_sampled: 1550000
    num_steps_trained: 1550000
    wait_time_ms: 162.765
  iterations_since_restore: 155
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 2855.7872977256775
  time_this_iter_s: 18.24615240097046
  time_total_s: 2855.7872977256775
  timestamp: 1593887312
  timesteps_since_restore: 1550000
  timesteps_this_iter: 10000
  timesteps_total: 1550000
  training_iteration: 155
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 2855 s, 155 iter, 1550000 ts, 220 rew

agent-1: 21.0
agent-2: 22.0
agent-3: 18.0
agent-4: 24.0
agent-5: 25.0
agent-6: 14.0
agent-7: 18.0
agent-8: 25.0
agent-9: 22.0
agent-10: 22.0
Sum Reward: 211.0
Avg Reward: 21.1
Min Reward: 14.0
Gini Coefficient: 0.08578199052132701
20:20 Ratio: 1.5625
Max-min Ratio: 1.7857142857142858
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-28-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 219.62
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 155
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.708
    dispatch_time_ms: 28.909
    learner:
      cur_lr: 0.0012567699886858463
      grad_gnorm: 0.9617600440979004
      policy_entropy: 166.4042510986328
      policy_loss: 0.7802754044532776
      var_gnorm: 45.19602584838867
      vf_explained_var: 0.9113974571228027
      vf_loss: 0.0021321438252925873
    num_steps_sampled: 1560000
    num_steps_trained: 1560000
    wait_time_ms: 155.835
  iterations_since_restore: 156
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 2874.030816555023
  time_this_iter_s: 18.243518829345703
  time_total_s: 2874.030816555023
  timestamp: 1593887331
  timesteps_since_restore: 1560000
  timesteps_this_iter: 10000
  timesteps_total: 1560000
  training_iteration: 156
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 2874 s, 156 iter, 1560000 ts, 220 rew

agent-1: 26.0
agent-2: 16.0
agent-3: 22.0
agent-4: 18.0
agent-5: 22.0
agent-6: 23.0
agent-7: 20.0
agent-8: 23.0
agent-9: 23.0
agent-10: 24.0
Sum Reward: 217.0
Avg Reward: 21.7
Min Reward: 16.0
Gini Coefficient: 0.0695852534562212
20:20 Ratio: 1.4705882352941178
Max-min Ratio: 1.625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-29-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 219.49
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 156
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 4.319
    dispatch_time_ms: 34.046
    learner:
      cur_lr: 0.0012561039766296744
      grad_gnorm: 40.000003814697266
      policy_entropy: 3.8075506687164307
      policy_loss: 12.123588562011719
      var_gnorm: 45.191707611083984
      vf_explained_var: 0.15877926349639893
      vf_loss: 245.36605834960938
    num_steps_sampled: 1570000
    num_steps_trained: 1570000
    wait_time_ms: 134.09
  iterations_since_restore: 157
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 2892.616299390793
  time_this_iter_s: 18.585482835769653
  time_total_s: 2892.616299390793
  timestamp: 1593887349
  timesteps_since_restore: 1570000
  timesteps_this_iter: 10000
  timesteps_total: 1570000
  training_iteration: 157
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 2892 s, 157 iter, 1570000 ts, 219 rew

agent-1: 19.0
agent-2: 24.0
agent-3: 25.0
agent-4: 18.0
agent-5: 34.0
agent-6: 24.0
agent-7: 26.0
agent-8: 20.0
agent-9: 16.0
agent-10: 19.0
Sum Reward: 225.0
Avg Reward: 22.5
Min Reward: 16.0
Gini Coefficient: 0.11866666666666667
20:20 Ratio: 1.7647058823529411
Max-min Ratio: 2.125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-29-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 219.24
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 157
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.39
    dispatch_time_ms: 28.575
    learner:
      cur_lr: 0.0012554379645735025
      grad_gnorm: 1.873834490776062
      policy_entropy: 184.32882690429688
      policy_loss: -0.039151567965745926
      var_gnorm: 45.440738677978516
      vf_explained_var: 0.9918220639228821
      vf_loss: 0.003448719624429941
    num_steps_sampled: 1580000
    num_steps_trained: 1580000
    wait_time_ms: 153.098
  iterations_since_restore: 158
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 2911.374532222748
  time_this_iter_s: 18.758232831954956
  time_total_s: 2911.374532222748
  timestamp: 1593887368
  timesteps_since_restore: 1580000
  timesteps_this_iter: 10000
  timesteps_total: 1580000
  training_iteration: 158
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 2911 s, 158 iter, 1580000 ts, 219 rew

agent-1: 31.0
agent-2: 20.0
agent-3: 22.0
agent-4: 12.0
agent-5: 23.0
agent-6: 20.0
agent-7: 33.0
agent-8: 24.0
agent-9: 12.0
agent-10: 23.0
Sum Reward: 220.0
Avg Reward: 22.0
Min Reward: 12.0
Gini Coefficient: 0.16
20:20 Ratio: 2.6666666666666665
Max-min Ratio: 2.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-29-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 219.34
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 158
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.022
    dispatch_time_ms: 35.427
    learner:
      cur_lr: 0.0012547719525173306
      grad_gnorm: 40.000003814697266
      policy_entropy: 7.803804397583008
      policy_loss: -8.486063003540039
      var_gnorm: 45.42985534667969
      vf_explained_var: 0.45750415325164795
      vf_loss: 244.59039306640625
    num_steps_sampled: 1590000
    num_steps_trained: 1590000
    wait_time_ms: 139.807
  iterations_since_restore: 159
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 2930.0418350696564
  time_this_iter_s: 18.66730284690857
  time_total_s: 2930.0418350696564
  timestamp: 1593887387
  timesteps_since_restore: 1590000
  timesteps_this_iter: 10000
  timesteps_total: 1590000
  training_iteration: 159
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 2930 s, 159 iter, 1590000 ts, 219 rew

agent-1: 18.0
agent-2: 22.0
agent-3: 22.0
agent-4: 22.0
agent-5: 21.0
agent-6: 20.0
agent-7: 27.0
agent-8: 17.0
agent-9: 26.0
agent-10: 19.0
Sum Reward: 214.0
Avg Reward: 21.4
Min Reward: 17.0
Gini Coefficient: 0.07850467289719626
20:20 Ratio: 1.5142857142857142
Max-min Ratio: 1.588235294117647
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-30-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 219.3
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 159
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.432
    dispatch_time_ms: 11.801
    learner:
      cur_lr: 0.0012541060568764806
      grad_gnorm: 5.11500358581543
      policy_entropy: 4.3614301681518555
      policy_loss: 1.692833423614502
      var_gnorm: 45.77083206176758
      vf_explained_var: 0.6215223073959351
      vf_loss: 0.1197790652513504
    num_steps_sampled: 1600000
    num_steps_trained: 1600000
    wait_time_ms: 170.069
  iterations_since_restore: 160
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 2948.6717677116394
  time_this_iter_s: 18.629932641983032
  time_total_s: 2948.6717677116394
  timestamp: 1593887406
  timesteps_since_restore: 1600000
  timesteps_this_iter: 10000
  timesteps_total: 1600000
  training_iteration: 160
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 2948 s, 160 iter, 1600000 ts, 219 rew

agent-1: 26.0
agent-2: 25.0
agent-3: 23.0
agent-4: 11.0
agent-5: 23.0
agent-6: 21.0
agent-7: 21.0
agent-8: 20.0
agent-9: 25.0
agent-10: 18.0
Sum Reward: 213.0
Avg Reward: 21.3
Min Reward: 11.0
Gini Coefficient: 0.10187793427230046
20:20 Ratio: 1.7586206896551724
Max-min Ratio: 2.3636363636363638
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-30-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 219.3
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 160
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.878
    dispatch_time_ms: 6.818
    learner:
      cur_lr: 0.0012534400448203087
      grad_gnorm: 40.0
      policy_entropy: 9.36558723449707
      policy_loss: -0.7359291315078735
      var_gnorm: 45.77978515625
      vf_explained_var: 0.6427916884422302
      vf_loss: 95.7713394165039
    num_steps_sampled: 1610000
    num_steps_trained: 1610000
    wait_time_ms: 145.792
  iterations_since_restore: 161
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 2966.668839931488
  time_this_iter_s: 17.997072219848633
  time_total_s: 2966.668839931488
  timestamp: 1593887424
  timesteps_since_restore: 1610000
  timesteps_this_iter: 10000
  timesteps_total: 1610000
  training_iteration: 161
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 2966 s, 161 iter, 1610000 ts, 219 rew

agent-1: 20.0
agent-2: 17.0
agent-3: 18.0
agent-4: 27.0
agent-5: 9.0
agent-6: 18.0
agent-7: 29.0
agent-8: 26.0
agent-9: 23.0
agent-10: 30.0
Sum Reward: 217.0
Avg Reward: 21.7
Min Reward: 9.0
Gini Coefficient: 0.15898617511520738
20:20 Ratio: 2.269230769230769
Max-min Ratio: 3.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-30-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 219.18
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 161
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.531
    dispatch_time_ms: 6.988
    learner:
      cur_lr: 0.0012527740327641368
      grad_gnorm: 0.2733749449253082
      policy_entropy: 174.2540740966797
      policy_loss: -0.2349974811077118
      var_gnorm: 45.853233337402344
      vf_explained_var: 0.9959422945976257
      vf_loss: 0.0006315776263363659
    num_steps_sampled: 1620000
    num_steps_trained: 1620000
    wait_time_ms: 166.703
  iterations_since_restore: 162
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 2984.4459533691406
  time_this_iter_s: 17.777113437652588
  time_total_s: 2984.4459533691406
  timestamp: 1593887441
  timesteps_since_restore: 1620000
  timesteps_this_iter: 10000
  timesteps_total: 1620000
  training_iteration: 162
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 2984 s, 162 iter, 1620000 ts, 219 rew

agent-1: 30.0
agent-2: 25.0
agent-3: 26.0
agent-4: 4.0
agent-5: 16.0
agent-6: 20.0
agent-7: 30.0
agent-8: 19.0
agent-9: 22.0
agent-10: 33.0
Sum Reward: 225.0
Avg Reward: 22.5
Min Reward: 4.0
Gini Coefficient: 0.19333333333333333
20:20 Ratio: 3.15
Max-min Ratio: 8.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-30-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 219.23
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 162
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.335
    dispatch_time_ms: 6.605
    learner:
      cur_lr: 0.001252108020707965
      grad_gnorm: 0.15591983497142792
      policy_entropy: 180.72640991210938
      policy_loss: 0.29509347677230835
      var_gnorm: 45.84446716308594
      vf_explained_var: 0.9941049218177795
      vf_loss: 5.080898063170025e-06
    num_steps_sampled: 1630000
    num_steps_trained: 1630000
    wait_time_ms: 154.649
  iterations_since_restore: 163
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3002.1434371471405
  time_this_iter_s: 17.697483777999878
  time_total_s: 3002.1434371471405
  timestamp: 1593887459
  timesteps_since_restore: 1630000
  timesteps_this_iter: 10000
  timesteps_total: 1630000
  training_iteration: 163
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3002 s, 163 iter, 1630000 ts, 219 rew

agent-1: 27.0
agent-2: 19.0
agent-3: 29.0
agent-4: 18.0
agent-5: 17.0
agent-6: 33.0
agent-7: 26.0
agent-8: 9.0
agent-9: 27.0
agent-10: 22.0
Sum Reward: 227.0
Avg Reward: 22.7
Min Reward: 9.0
Gini Coefficient: 0.16431718061674008
20:20 Ratio: 2.3846153846153846
Max-min Ratio: 3.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-31-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 219.23
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 163
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.731
    dispatch_time_ms: 7.14
    learner:
      cur_lr: 0.001251442008651793
      grad_gnorm: 0.9759940505027771
      policy_entropy: 163.81283569335938
      policy_loss: 0.30035072565078735
      var_gnorm: 45.94711685180664
      vf_explained_var: 0.9717974662780762
      vf_loss: 0.0035795336589217186
    num_steps_sampled: 1640000
    num_steps_trained: 1640000
    wait_time_ms: 168.827
  iterations_since_restore: 164
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3019.967041492462
  time_this_iter_s: 17.823604345321655
  time_total_s: 3019.967041492462
  timestamp: 1593887477
  timesteps_since_restore: 1640000
  timesteps_this_iter: 10000
  timesteps_total: 1640000
  training_iteration: 164
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3019 s, 164 iter, 1640000 ts, 219 rew

agent-1: 10.0
agent-2: 26.0
agent-3: 26.0
agent-4: 24.0
agent-5: 20.0
agent-6: 20.0
agent-7: 16.0
agent-8: 13.0
agent-9: 16.0
agent-10: 20.0
Sum Reward: 191.0
Avg Reward: 19.1
Min Reward: 10.0
Gini Coefficient: 0.15026178010471203
20:20 Ratio: 2.260869565217391
Max-min Ratio: 2.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-31-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 218.84
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 164
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.0
    dispatch_time_ms: 6.675
    learner:
      cur_lr: 0.0012507759965956211
      grad_gnorm: 0.909515380859375
      policy_entropy: 165.92417907714844
      policy_loss: -0.013377644121646881
      var_gnorm: 45.93411636352539
      vf_explained_var: 0.9944216012954712
      vf_loss: 0.000982927973382175
    num_steps_sampled: 1650000
    num_steps_trained: 1650000
    wait_time_ms: 151.023
  iterations_since_restore: 165
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3037.76460146904
  time_this_iter_s: 17.79755997657776
  time_total_s: 3037.76460146904
  timestamp: 1593887495
  timesteps_since_restore: 1650000
  timesteps_this_iter: 10000
  timesteps_total: 1650000
  training_iteration: 165
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3037 s, 165 iter, 1650000 ts, 219 rew

agent-1: 16.0
agent-2: 25.0
agent-3: 29.0
agent-4: 26.0
agent-5: 17.0
agent-6: 11.0
agent-7: 22.0
agent-8: 21.0
agent-9: 20.0
agent-10: 28.0
Sum Reward: 215.0
Avg Reward: 21.5
Min Reward: 11.0
Gini Coefficient: 0.1427906976744186
20:20 Ratio: 2.111111111111111
Max-min Ratio: 2.6363636363636362
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-31-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 218.75
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 165
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.299
    dispatch_time_ms: 7.815
    learner:
      cur_lr: 0.0012501099845394492
      grad_gnorm: 0.2406887412071228
      policy_entropy: 166.51168823242188
      policy_loss: 0.1549025923013687
      var_gnorm: 46.177330017089844
      vf_explained_var: 0.9952401518821716
      vf_loss: 7.681831630179659e-05
    num_steps_sampled: 1660000
    num_steps_trained: 1660000
    wait_time_ms: 169.807
  iterations_since_restore: 166
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3055.568911075592
  time_this_iter_s: 17.804309606552124
  time_total_s: 3055.568911075592
  timestamp: 1593887513
  timesteps_since_restore: 1660000
  timesteps_this_iter: 10000
  timesteps_total: 1660000
  training_iteration: 166
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3055 s, 166 iter, 1660000 ts, 219 rew

agent-1: 20.0
agent-2: 18.0
agent-3: 23.0
agent-4: 25.0
agent-5: 21.0
agent-6: 28.0
agent-7: 19.0
agent-8: 17.0
agent-9: 23.0
agent-10: 14.0
Sum Reward: 208.0
Avg Reward: 20.8
Min Reward: 14.0
Gini Coefficient: 0.10576923076923077
20:20 Ratio: 1.7096774193548387
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-32-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 218.77
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 166
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.622
    dispatch_time_ms: 6.508
    learner:
      cur_lr: 0.0012494439724832773
      grad_gnorm: 39.999996185302734
      policy_entropy: 11.070374488830566
      policy_loss: -46.62410354614258
      var_gnorm: 46.15224075317383
      vf_explained_var: 0.702525794506073
      vf_loss: 301.1737976074219
    num_steps_sampled: 1670000
    num_steps_trained: 1670000
    wait_time_ms: 145.907
  iterations_since_restore: 167
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3073.4963245391846
  time_this_iter_s: 17.92741346359253
  time_total_s: 3073.4963245391846
  timestamp: 1593887531
  timesteps_since_restore: 1670000
  timesteps_this_iter: 10000
  timesteps_total: 1670000
  training_iteration: 167
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3073 s, 167 iter, 1670000 ts, 219 rew

agent-1: 23.0
agent-2: 31.0
agent-3: 16.0
agent-4: 20.0
agent-5: 20.0
agent-6: 19.0
agent-7: 14.0
agent-8: 19.0
agent-9: 17.0
agent-10: 19.0
Sum Reward: 198.0
Avg Reward: 19.8
Min Reward: 14.0
Gini Coefficient: 0.1111111111111111
20:20 Ratio: 1.8
Max-min Ratio: 2.2142857142857144
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-32-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 218.62
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 167
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.069
    dispatch_time_ms: 6.687
    learner:
      cur_lr: 0.0012487779604271054
      grad_gnorm: 5.751301288604736
      policy_entropy: 173.30116271972656
      policy_loss: -0.2701473832130432
      var_gnorm: 46.541561126708984
      vf_explained_var: -1.0
      vf_loss: 0.0024782116524875164
    num_steps_sampled: 1680000
    num_steps_trained: 1680000
    wait_time_ms: 169.365
  iterations_since_restore: 168
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3091.3512761592865
  time_this_iter_s: 17.85495162010193
  time_total_s: 3091.3512761592865
  timestamp: 1593887549
  timesteps_since_restore: 1680000
  timesteps_this_iter: 10000
  timesteps_total: 1680000
  training_iteration: 168
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3091 s, 168 iter, 1680000 ts, 219 rew

agent-1: 26.0
agent-2: 30.0
agent-3: 31.0
agent-4: 10.0
agent-5: 22.0
agent-6: 20.0
agent-7: 15.0
agent-8: 24.0
agent-9: 18.0
agent-10: 27.0
Sum Reward: 223.0
Avg Reward: 22.3
Min Reward: 10.0
Gini Coefficient: 0.1609865470852018
20:20 Ratio: 2.44
Max-min Ratio: 3.1
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-32-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 218.73
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 168
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.131
    dispatch_time_ms: 6.56
    learner:
      cur_lr: 0.0012481119483709335
      grad_gnorm: 0.3020172715187073
      policy_entropy: 179.8533172607422
      policy_loss: 0.05176354944705963
      var_gnorm: 46.5369873046875
      vf_explained_var: 0.9120615720748901
      vf_loss: 0.00011951720080105588
    num_steps_sampled: 1690000
    num_steps_trained: 1690000
    wait_time_ms: 177.292
  iterations_since_restore: 169
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3109.441926717758
  time_this_iter_s: 18.09065055847168
  time_total_s: 3109.441926717758
  timestamp: 1593887567
  timesteps_since_restore: 1690000
  timesteps_this_iter: 10000
  timesteps_total: 1690000
  training_iteration: 169
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3109 s, 169 iter, 1690000 ts, 219 rew

agent-1: 14.0
agent-2: 28.0
agent-3: 13.0
agent-4: 27.0
agent-5: 17.0
agent-6: 24.0
agent-7: 15.0
agent-8: 16.0
agent-9: 23.0
agent-10: 20.0
Sum Reward: 197.0
Avg Reward: 19.7
Min Reward: 13.0
Gini Coefficient: 0.14974619289340102
20:20 Ratio: 2.037037037037037
Max-min Ratio: 2.1538461538461537
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-33-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 218.77
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 169
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.662
    dispatch_time_ms: 7.133
    learner:
      cur_lr: 0.0012474460527300835
      grad_gnorm: 8.531015396118164
      policy_entropy: 141.62799072265625
      policy_loss: 1.7759050130844116
      var_gnorm: 46.776554107666016
      vf_explained_var: -0.669314980506897
      vf_loss: 0.22635623812675476
    num_steps_sampled: 1700000
    num_steps_trained: 1700000
    wait_time_ms: 174.257
  iterations_since_restore: 170
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3127.244327068329
  time_this_iter_s: 17.80240035057068
  time_total_s: 3127.244327068329
  timestamp: 1593887585
  timesteps_since_restore: 1700000
  timesteps_this_iter: 10000
  timesteps_total: 1700000
  training_iteration: 170
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3127 s, 170 iter, 1700000 ts, 219 rew

agent-1: 16.0
agent-2: 16.0
agent-3: 26.0
agent-4: 27.0
agent-5: 22.0
agent-6: 18.0
agent-7: 17.0
agent-8: 30.0
agent-9: 19.0
agent-10: 20.0
Sum Reward: 211.0
Avg Reward: 21.1
Min Reward: 16.0
Gini Coefficient: 0.12369668246445498
20:20 Ratio: 1.78125
Max-min Ratio: 1.875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-33-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 218.73
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 170
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.315
    dispatch_time_ms: 6.373
    learner:
      cur_lr: 0.0012467800406739116
      grad_gnorm: 3.679455041885376
      policy_entropy: 149.3624267578125
      policy_loss: -0.5595524907112122
      var_gnorm: 46.80633544921875
      vf_explained_var: 0.15316706895828247
      vf_loss: 0.013949654065072536
    num_steps_sampled: 1710000
    num_steps_trained: 1710000
    wait_time_ms: 146.859
  iterations_since_restore: 171
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3145.0424842834473
  time_this_iter_s: 17.798157215118408
  time_total_s: 3145.0424842834473
  timestamp: 1593887602
  timesteps_since_restore: 1710000
  timesteps_this_iter: 10000
  timesteps_total: 1710000
  training_iteration: 171
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3145 s, 171 iter, 1710000 ts, 219 rew

agent-1: 24.0
agent-2: 23.0
agent-3: 25.0
agent-4: 18.0
agent-5: 23.0
agent-6: 27.0
agent-7: 15.0
agent-8: 20.0
agent-9: 20.0
agent-10: 18.0
Sum Reward: 213.0
Avg Reward: 21.3
Min Reward: 15.0
Gini Coefficient: 0.09342723004694836
20:20 Ratio: 1.5757575757575757
Max-min Ratio: 1.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-33-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 218.44
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 171
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.556
    dispatch_time_ms: 8.368
    learner:
      cur_lr: 0.0012461140286177397
      grad_gnorm: 1.1324259042739868
      policy_entropy: 162.166748046875
      policy_loss: 0.4223250448703766
      var_gnorm: 47.036922454833984
      vf_explained_var: 0.7466205358505249
      vf_loss: 0.002528743352741003
    num_steps_sampled: 1720000
    num_steps_trained: 1720000
    wait_time_ms: 167.905
  iterations_since_restore: 172
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3162.8638837337494
  time_this_iter_s: 17.821399450302124
  time_total_s: 3162.8638837337494
  timestamp: 1593887620
  timesteps_since_restore: 1720000
  timesteps_this_iter: 10000
  timesteps_total: 1720000
  training_iteration: 172
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3162 s, 172 iter, 1720000 ts, 218 rew

agent-1: 19.0
agent-2: 30.0
agent-3: 9.0
agent-4: 18.0
agent-5: 20.0
agent-6: 32.0
agent-7: 28.0
agent-8: 33.0
agent-9: 6.0
agent-10: 19.0
Sum Reward: 214.0
Avg Reward: 21.4
Min Reward: 6.0
Gini Coefficient: 0.22990654205607478
20:20 Ratio: 4.333333333333333
Max-min Ratio: 5.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-33-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 218.41
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 172
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.251
    dispatch_time_ms: 6.283
    learner:
      cur_lr: 0.0012454480165615678
      grad_gnorm: 39.99999237060547
      policy_entropy: 5.721047401428223
      policy_loss: -1.7528365850448608
      var_gnorm: 47.07763671875
      vf_explained_var: -0.4885413646697998
      vf_loss: 119.13716888427734
    num_steps_sampled: 1730000
    num_steps_trained: 1730000
    wait_time_ms: 172.914
  iterations_since_restore: 173
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3180.7673964500427
  time_this_iter_s: 17.903512716293335
  time_total_s: 3180.7673964500427
  timestamp: 1593887638
  timesteps_since_restore: 1730000
  timesteps_this_iter: 10000
  timesteps_total: 1730000
  training_iteration: 173
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3180 s, 173 iter, 1730000 ts, 218 rew

agent-1: 20.0
agent-2: 24.0
agent-3: 21.0
agent-4: 23.0
agent-5: 15.0
agent-6: 25.0
agent-7: 15.0
agent-8: 23.0
agent-9: 20.0
agent-10: 24.0
Sum Reward: 210.0
Avg Reward: 21.0
Min Reward: 15.0
Gini Coefficient: 0.08761904761904762
20:20 Ratio: 1.6333333333333333
Max-min Ratio: 1.6666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-34-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 218.0
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 173
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.845
    dispatch_time_ms: 7.893
    learner:
      cur_lr: 0.0012447820045053959
      grad_gnorm: 0.9522854089736938
      policy_entropy: 176.68487548828125
      policy_loss: -0.25321170687675476
      var_gnorm: 47.377132415771484
      vf_explained_var: 0.3804917335510254
      vf_loss: 0.0033797449432313442
    num_steps_sampled: 1740000
    num_steps_trained: 1740000
    wait_time_ms: 169.77
  iterations_since_restore: 174
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3198.5364282131195
  time_this_iter_s: 17.769031763076782
  time_total_s: 3198.5364282131195
  timestamp: 1593887656
  timesteps_since_restore: 1740000
  timesteps_this_iter: 10000
  timesteps_total: 1740000
  training_iteration: 174
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3198 s, 174 iter, 1740000 ts, 218 rew

agent-1: 25.0
agent-2: 18.0
agent-3: 20.0
agent-4: 17.0
agent-5: 19.0
agent-6: 26.0
agent-7: 24.0
agent-8: 14.0
agent-9: 24.0
agent-10: 19.0
Sum Reward: 206.0
Avg Reward: 20.6
Min Reward: 14.0
Gini Coefficient: 0.10194174757281553
20:20 Ratio: 1.6451612903225807
Max-min Ratio: 1.8571428571428572
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-34-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 217.62
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 174
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.944
    dispatch_time_ms: 6.087
    learner:
      cur_lr: 0.001244115992449224
      grad_gnorm: 40.000003814697266
      policy_entropy: 6.502196788787842
      policy_loss: 0.8725860118865967
      var_gnorm: 47.35439682006836
      vf_explained_var: 0.3474428653717041
      vf_loss: 64.9552001953125
    num_steps_sampled: 1750000
    num_steps_trained: 1750000
    wait_time_ms: 170.609
  iterations_since_restore: 175
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3216.6094114780426
  time_this_iter_s: 18.072983264923096
  time_total_s: 3216.6094114780426
  timestamp: 1593887674
  timesteps_since_restore: 1750000
  timesteps_this_iter: 10000
  timesteps_total: 1750000
  training_iteration: 175
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3216 s, 175 iter, 1750000 ts, 218 rew

agent-1: 26.0
agent-2: 17.0
agent-3: 22.0
agent-4: 20.0
agent-5: 17.0
agent-6: 22.0
agent-7: 22.0
agent-8: 20.0
agent-9: 19.0
agent-10: 19.0
Sum Reward: 204.0
Avg Reward: 20.4
Min Reward: 17.0
Gini Coefficient: 0.06862745098039216
20:20 Ratio: 1.411764705882353
Max-min Ratio: 1.5294117647058822
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-34-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 217.31
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 175
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.591
    dispatch_time_ms: 7.247
    learner:
      cur_lr: 0.001243449980393052
      grad_gnorm: 0.2730760872364044
      policy_entropy: 179.69741821289062
      policy_loss: 0.13333675265312195
      var_gnorm: 47.621849060058594
      vf_explained_var: 0.8785524368286133
      vf_loss: 0.0014782201033085585
    num_steps_sampled: 1760000
    num_steps_trained: 1760000
    wait_time_ms: 175.277
  iterations_since_restore: 176
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3234.401426553726
  time_this_iter_s: 17.792015075683594
  time_total_s: 3234.401426553726
  timestamp: 1593887692
  timesteps_since_restore: 1760000
  timesteps_this_iter: 10000
  timesteps_total: 1760000
  training_iteration: 176
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3234 s, 176 iter, 1760000 ts, 217 rew

agent-1: 15.0
agent-2: 27.0
agent-3: 18.0
agent-4: 21.0
agent-5: 23.0
agent-6: 22.0
agent-7: 15.0
agent-8: 20.0
agent-9: 21.0
agent-10: 20.0
Sum Reward: 202.0
Avg Reward: 20.2
Min Reward: 15.0
Gini Coefficient: 0.09306930693069307
20:20 Ratio: 1.6666666666666667
Max-min Ratio: 1.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-35-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 216.94
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 176
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.607
    dispatch_time_ms: 6.959
    learner:
      cur_lr: 0.0012427839683368802
      grad_gnorm: 0.6233454942703247
      policy_entropy: 162.9872589111328
      policy_loss: 0.06835045665502548
      var_gnorm: 47.7441291809082
      vf_explained_var: 0.7102615833282471
      vf_loss: 0.007034475915133953
    num_steps_sampled: 1770000
    num_steps_trained: 1770000
    wait_time_ms: 168.944
  iterations_since_restore: 177
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3252.6338968276978
  time_this_iter_s: 18.232470273971558
  time_total_s: 3252.6338968276978
  timestamp: 1593887710
  timesteps_since_restore: 1770000
  timesteps_this_iter: 10000
  timesteps_total: 1770000
  training_iteration: 177
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3252 s, 177 iter, 1770000 ts, 217 rew

agent-1: 32.0
agent-2: 29.0
agent-3: 29.0
agent-4: 16.0
agent-5: 18.0
agent-6: 14.0
agent-7: 22.0
agent-8: 23.0
agent-9: 13.0
agent-10: 25.0
Sum Reward: 221.0
Avg Reward: 22.1
Min Reward: 13.0
Gini Coefficient: 0.16425339366515837
20:20 Ratio: 2.259259259259259
Max-min Ratio: 2.4615384615384617
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-35-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 217.11
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 177
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.635
    dispatch_time_ms: 9.075
    learner:
      cur_lr: 0.0012421179562807083
      grad_gnorm: 3.15981388092041
      policy_entropy: 120.25741577148438
      policy_loss: 0.48136791586875916
      var_gnorm: 48.140045166015625
      vf_explained_var: 0.24200987815856934
      vf_loss: 0.05820678174495697
    num_steps_sampled: 1780000
    num_steps_trained: 1780000
    wait_time_ms: 170.528
  iterations_since_restore: 178
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3270.633775949478
  time_this_iter_s: 17.999879121780396
  time_total_s: 3270.633775949478
  timestamp: 1593887728
  timesteps_since_restore: 1780000
  timesteps_this_iter: 10000
  timesteps_total: 1780000
  training_iteration: 178
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3270 s, 178 iter, 1780000 ts, 217 rew

agent-1: 24.0
agent-2: 20.0
agent-3: 29.0
agent-4: 5.0
agent-5: 17.0
agent-6: 24.0
agent-7: 25.0
agent-8: 13.0
agent-9: 29.0
agent-10: 17.0
Sum Reward: 203.0
Avg Reward: 20.3
Min Reward: 5.0
Gini Coefficient: 0.1935960591133005
20:20 Ratio: 3.2222222222222223
Max-min Ratio: 5.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-35-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 216.98
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 178
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.278
    dispatch_time_ms: 9.274
    learner:
      cur_lr: 0.0012414519442245364
      grad_gnorm: 5.634389877319336
      policy_entropy: 75.965576171875
      policy_loss: -0.3997999131679535
      var_gnorm: 48.268707275390625
      vf_explained_var: -0.11465585231781006
      vf_loss: 0.05096025764942169
    num_steps_sampled: 1790000
    num_steps_trained: 1790000
    wait_time_ms: 168.522
  iterations_since_restore: 179
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3288.5564551353455
  time_this_iter_s: 17.92267918586731
  time_total_s: 3288.5564551353455
  timestamp: 1593887746
  timesteps_since_restore: 1790000
  timesteps_this_iter: 10000
  timesteps_total: 1790000
  training_iteration: 179
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3288 s, 179 iter, 1790000 ts, 217 rew

agent-1: 24.0
agent-2: 19.0
agent-3: 25.0
agent-4: 23.0
agent-5: 23.0
agent-6: 19.0
agent-7: 34.0
agent-8: 17.0
agent-9: 22.0
agent-10: 32.0
Sum Reward: 238.0
Avg Reward: 23.8
Min Reward: 17.0
Gini Coefficient: 0.11764705882352941
20:20 Ratio: 1.8333333333333333
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-36-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 217.15
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 179
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.238
    dispatch_time_ms: 7.77
    learner:
      cur_lr: 0.0012407860485836864
      grad_gnorm: 4.792098522186279
      policy_entropy: 113.32134246826172
      policy_loss: 1.3211777210235596
      var_gnorm: 48.47241973876953
      vf_explained_var: 0.3524625301361084
      vf_loss: 0.12872406840324402
    num_steps_sampled: 1800000
    num_steps_trained: 1800000
    wait_time_ms: 171.801
  iterations_since_restore: 180
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3306.577656984329
  time_this_iter_s: 18.021201848983765
  time_total_s: 3306.577656984329
  timestamp: 1593887764
  timesteps_since_restore: 1800000
  timesteps_this_iter: 10000
  timesteps_total: 1800000
  training_iteration: 180
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3306 s, 180 iter, 1800000 ts, 217 rew

agent-1: 27.0
agent-2: 28.0
agent-3: 15.0
agent-4: 12.0
agent-5: 32.0
agent-6: 23.0
agent-7: 19.0
agent-8: 23.0
agent-9: 20.0
agent-10: 17.0
Sum Reward: 216.0
Avg Reward: 21.6
Min Reward: 12.0
Gini Coefficient: 0.15555555555555556
20:20 Ratio: 2.2222222222222223
Max-min Ratio: 2.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-36-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 216.95
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 180
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.904
    dispatch_time_ms: 8.6
    learner:
      cur_lr: 0.0012401200365275145
      grad_gnorm: 40.0
      policy_entropy: 12.29903507232666
      policy_loss: 0.4167974293231964
      var_gnorm: 48.50695037841797
      vf_explained_var: 0.5285676121711731
      vf_loss: 73.0709457397461
    num_steps_sampled: 1810000
    num_steps_trained: 1810000
    wait_time_ms: 150.845
  iterations_since_restore: 181
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3324.320772409439
  time_this_iter_s: 17.743115425109863
  time_total_s: 3324.320772409439
  timestamp: 1593887782
  timesteps_since_restore: 1810000
  timesteps_this_iter: 10000
  timesteps_total: 1810000
  training_iteration: 181
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3324 s, 181 iter, 1810000 ts, 217 rew

agent-1: 26.0
agent-2: 23.0
agent-3: 19.0
agent-4: 24.0
agent-5: 25.0
agent-6: 29.0
agent-7: 19.0
agent-8: 12.0
agent-9: 16.0
agent-10: 20.0
Sum Reward: 213.0
Avg Reward: 21.3
Min Reward: 12.0
Gini Coefficient: 0.1272300469483568
20:20 Ratio: 1.9642857142857142
Max-min Ratio: 2.4166666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-36-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 216.67
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 181
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 4.231
    dispatch_time_ms: 6.516
    learner:
      cur_lr: 0.0012394540244713426
      grad_gnorm: 1.2950671911239624
      policy_entropy: 159.54795837402344
      policy_loss: -0.06057358533143997
      var_gnorm: 48.69482421875
      vf_explained_var: 0.2971053123474121
      vf_loss: 0.014140898361802101
    num_steps_sampled: 1820000
    num_steps_trained: 1820000
    wait_time_ms: 169.068
  iterations_since_restore: 182
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3361.6913571357727
  time_this_iter_s: 37.37058472633362
  time_total_s: 3361.6913571357727
  timestamp: 1593887819
  timesteps_since_restore: 1820000
  timesteps_this_iter: 10000
  timesteps_total: 1820000
  training_iteration: 182
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3361 s, 182 iter, 1820000 ts, 217 rew

agent-1: 24.0
agent-2: 24.0
agent-3: 21.0
agent-4: 22.0
agent-5: 18.0
agent-6: 20.0
agent-7: 18.0
agent-8: 21.0
agent-9: 18.0
agent-10: 20.0
Sum Reward: 206.0
Avg Reward: 20.6
Min Reward: 18.0
Gini Coefficient: 0.05825242718446602
20:20 Ratio: 1.3333333333333333
Max-min Ratio: 1.3333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-37-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 216.11
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 182
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.575
    dispatch_time_ms: 5.494
    learner:
      cur_lr: 0.0012387880124151707
      grad_gnorm: 1.9209494590759277
      policy_entropy: 141.8543701171875
      policy_loss: -0.5638696551322937
      var_gnorm: 48.66803741455078
      vf_explained_var: -1.0
      vf_loss: 0.008967363275587559
    num_steps_sampled: 1830000
    num_steps_trained: 1830000
    wait_time_ms: 155.791
  iterations_since_restore: 183
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3379.4405615329742
  time_this_iter_s: 17.749204397201538
  time_total_s: 3379.4405615329742
  timestamp: 1593887837
  timesteps_since_restore: 1830000
  timesteps_this_iter: 10000
  timesteps_total: 1830000
  training_iteration: 183
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3379 s, 183 iter, 1830000 ts, 216 rew

agent-1: 16.0
agent-2: 21.0
agent-3: 22.0
agent-4: 23.0
agent-5: 27.0
agent-6: 18.0
agent-7: 26.0
agent-8: 17.0
agent-9: 21.0
agent-10: 19.0
Sum Reward: 210.0
Avg Reward: 21.0
Min Reward: 16.0
Gini Coefficient: 0.09333333333333334
20:20 Ratio: 1.606060606060606
Max-min Ratio: 1.6875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-37-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 216.21
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 183
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.995
    dispatch_time_ms: 6.19
    learner:
      cur_lr: 0.0012381220003589988
      grad_gnorm: 1.3766801357269287
      policy_entropy: 177.7834930419922
      policy_loss: -0.05950799584388733
      var_gnorm: 48.857017517089844
      vf_explained_var: 0.3821825385093689
      vf_loss: 0.0028109820559620857
    num_steps_sampled: 1840000
    num_steps_trained: 1840000
    wait_time_ms: 177.27
  iterations_since_restore: 184
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3397.403647661209
  time_this_iter_s: 17.963086128234863
  time_total_s: 3397.403647661209
  timestamp: 1593887855
  timesteps_since_restore: 1840000
  timesteps_this_iter: 10000
  timesteps_total: 1840000
  training_iteration: 184
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3397 s, 184 iter, 1840000 ts, 216 rew

agent-1: 17.0
agent-2: 24.0
agent-3: 16.0
agent-4: 29.0
agent-5: 25.0
agent-6: 23.0
agent-7: 19.0
agent-8: 20.0
agent-9: 19.0
agent-10: 21.0
Sum Reward: 213.0
Avg Reward: 21.3
Min Reward: 16.0
Gini Coefficient: 0.09906103286384976
20:20 Ratio: 1.6363636363636365
Max-min Ratio: 1.8125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-37-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 216.09
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 184
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.689
    dispatch_time_ms: 6.903
    learner:
      cur_lr: 0.0012374559883028269
      grad_gnorm: 9.749411582946777
      policy_entropy: 189.18896484375
      policy_loss: -2.3093671798706055
      var_gnorm: 48.80881118774414
      vf_explained_var: -1.0
      vf_loss: 0.06736016273498535
    num_steps_sampled: 1850000
    num_steps_trained: 1850000
    wait_time_ms: 170.185
  iterations_since_restore: 185
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3415.4123814105988
  time_this_iter_s: 18.00873374938965
  time_total_s: 3415.4123814105988
  timestamp: 1593887873
  timesteps_since_restore: 1850000
  timesteps_this_iter: 10000
  timesteps_total: 1850000
  training_iteration: 185
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3415 s, 185 iter, 1850000 ts, 216 rew

agent-1: 26.0
agent-2: 14.0
agent-3: 22.0
agent-4: 18.0
agent-5: 20.0
agent-6: 17.0
agent-7: 21.0
agent-8: 24.0
agent-9: 29.0
agent-10: 29.0
Sum Reward: 220.0
Avg Reward: 22.0
Min Reward: 14.0
Gini Coefficient: 0.12363636363636364
20:20 Ratio: 1.8709677419354838
Max-min Ratio: 2.0714285714285716
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-38-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 215.95
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 185
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 4.001
    dispatch_time_ms: 6.673
    learner:
      cur_lr: 0.001236789976246655
      grad_gnorm: 1.659829020500183
      policy_entropy: 167.46072387695312
      policy_loss: 0.24403437972068787
      var_gnorm: 48.852474212646484
      vf_explained_var: 0.7387414574623108
      vf_loss: 0.011393742635846138
    num_steps_sampled: 1860000
    num_steps_trained: 1860000
    wait_time_ms: 173.748
  iterations_since_restore: 186
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3433.386685848236
  time_this_iter_s: 17.97430443763733
  time_total_s: 3433.386685848236
  timestamp: 1593887891
  timesteps_since_restore: 1860000
  timesteps_this_iter: 10000
  timesteps_total: 1860000
  training_iteration: 186
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3433 s, 186 iter, 1860000 ts, 216 rew

agent-1: 17.0
agent-2: 23.0
agent-3: 13.0
agent-4: 18.0
agent-5: 29.0
agent-6: 24.0
agent-7: 26.0
agent-8: 19.0
agent-9: 17.0
agent-10: 11.0
Sum Reward: 197.0
Avg Reward: 19.7
Min Reward: 11.0
Gini Coefficient: 0.15583756345177666
20:20 Ratio: 2.2916666666666665
Max-min Ratio: 2.6363636363636362
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-38-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 215.58
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 186
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.053
    dispatch_time_ms: 6.335
    learner:
      cur_lr: 0.001236123964190483
      grad_gnorm: 2.376943349838257
      policy_entropy: 189.84938049316406
      policy_loss: 0.1308426409959793
      var_gnorm: 48.93183135986328
      vf_explained_var: 0.9826461672782898
      vf_loss: 0.0038611851632595062
    num_steps_sampled: 1870000
    num_steps_trained: 1870000
    wait_time_ms: 175.877
  iterations_since_restore: 187
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3451.228801012039
  time_this_iter_s: 17.8421151638031
  time_total_s: 3451.228801012039
  timestamp: 1593887909
  timesteps_since_restore: 1870000
  timesteps_this_iter: 10000
  timesteps_total: 1870000
  training_iteration: 187
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3451 s, 187 iter, 1870000 ts, 216 rew

agent-1: 26.0
agent-2: 14.0
agent-3: 23.0
agent-4: 15.0
agent-5: 20.0
agent-6: 20.0
agent-7: 16.0
agent-8: 20.0
agent-9: 21.0
agent-10: 26.0
Sum Reward: 201.0
Avg Reward: 20.1
Min Reward: 14.0
Gini Coefficient: 0.1109452736318408
20:20 Ratio: 1.793103448275862
Max-min Ratio: 1.8571428571428572
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-38-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 215.42
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 187
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 5.643
    dispatch_time_ms: 9.855
    learner:
      cur_lr: 0.0012354579521343112
      grad_gnorm: 0.26291847229003906
      policy_entropy: 178.97744750976562
      policy_loss: 0.19184379279613495
      var_gnorm: 49.04584884643555
      vf_explained_var: 0.9940090775489807
      vf_loss: 2.7786551072495058e-05
    num_steps_sampled: 1880000
    num_steps_trained: 1880000
    wait_time_ms: 168.231
  iterations_since_restore: 188
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3469.1038558483124
  time_this_iter_s: 17.875054836273193
  time_total_s: 3469.1038558483124
  timestamp: 1593887927
  timesteps_since_restore: 1880000
  timesteps_this_iter: 10000
  timesteps_total: 1880000
  training_iteration: 188
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3469 s, 188 iter, 1880000 ts, 215 rew

agent-1: 24.0
agent-2: 21.0
agent-3: 22.0
agent-4: 21.0
agent-5: 27.0
agent-6: 18.0
agent-7: 17.0
agent-8: 15.0
agent-9: 12.0
agent-10: 20.0
Sum Reward: 197.0
Avg Reward: 19.7
Min Reward: 12.0
Gini Coefficient: 0.1182741116751269
20:20 Ratio: 1.8888888888888888
Max-min Ratio: 2.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-39-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 215.13
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 188
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 4.04
    dispatch_time_ms: 5.992
    learner:
      cur_lr: 0.0012347920564934611
      grad_gnorm: 39.999996185302734
      policy_entropy: 162.25262451171875
      policy_loss: 25.239177703857422
      var_gnorm: 49.062740325927734
      vf_explained_var: 0.12276202440261841
      vf_loss: 13.172307968139648
    num_steps_sampled: 1890000
    num_steps_trained: 1890000
    wait_time_ms: 164.651
  iterations_since_restore: 189
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3486.9672803878784
  time_this_iter_s: 17.86342453956604
  time_total_s: 3486.9672803878784
  timestamp: 1593887945
  timesteps_since_restore: 1890000
  timesteps_this_iter: 10000
  timesteps_total: 1890000
  training_iteration: 189
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3486 s, 189 iter, 1890000 ts, 215 rew

agent-1: 15.0
agent-2: 22.0
agent-3: 27.0
agent-4: 18.0
agent-5: 25.0
agent-6: 18.0
agent-7: 21.0
agent-8: 11.0
agent-9: 19.0
agent-10: 25.0
Sum Reward: 201.0
Avg Reward: 20.1
Min Reward: 11.0
Gini Coefficient: 0.13084577114427862
20:20 Ratio: 2.0
Max-min Ratio: 2.4545454545454546
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-39-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 214.97
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 189
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.072
    dispatch_time_ms: 9.014
    learner:
      cur_lr: 0.0012341260444372892
      grad_gnorm: 0.185560941696167
      policy_entropy: 183.06427001953125
      policy_loss: 0.019167833030223846
      var_gnorm: 49.16145324707031
      vf_explained_var: 0.9957488775253296
      vf_loss: 7.900561467977241e-05
    num_steps_sampled: 1900000
    num_steps_trained: 1900000
    wait_time_ms: 166.823
  iterations_since_restore: 190
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3504.892431974411
  time_this_iter_s: 17.925151586532593
  time_total_s: 3504.892431974411
  timestamp: 1593887963
  timesteps_since_restore: 1900000
  timesteps_this_iter: 10000
  timesteps_total: 1900000
  training_iteration: 190
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3504 s, 190 iter, 1900000 ts, 215 rew

agent-1: 18.0
agent-2: 30.0
agent-3: 19.0
agent-4: 19.0
agent-5: 14.0
agent-6: 14.0
agent-7: 26.0
agent-8: 21.0
agent-9: 23.0
agent-10: 17.0
Sum Reward: 201.0
Avg Reward: 20.1
Min Reward: 14.0
Gini Coefficient: 0.1328358208955224
20:20 Ratio: 2.0
Max-min Ratio: 2.142857142857143
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-39-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 214.83
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 190
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.117
    dispatch_time_ms: 6.796
    learner:
      cur_lr: 0.0012334600323811173
      grad_gnorm: 1.697287917137146
      policy_entropy: 189.81809997558594
      policy_loss: -1.0115338563919067
      var_gnorm: 49.1729736328125
      vf_explained_var: 0.807794988155365
      vf_loss: 0.002151193330064416
    num_steps_sampled: 1910000
    num_steps_trained: 1910000
    wait_time_ms: 161.995
  iterations_since_restore: 191
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3522.4794120788574
  time_this_iter_s: 17.58698010444641
  time_total_s: 3522.4794120788574
  timestamp: 1593887981
  timesteps_since_restore: 1910000
  timesteps_this_iter: 10000
  timesteps_total: 1910000
  training_iteration: 191
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3522 s, 191 iter, 1910000 ts, 215 rew

agent-1: 25.0
agent-2: 24.0
agent-3: 24.0
agent-4: 17.0
agent-5: 24.0
agent-6: 20.0
agent-7: 23.0
agent-8: 20.0
agent-9: 15.0
agent-10: 20.0
Sum Reward: 212.0
Avg Reward: 21.2
Min Reward: 15.0
Gini Coefficient: 0.0820754716981132
20:20 Ratio: 1.53125
Max-min Ratio: 1.6666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-39-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 215.05
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 191
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.604
    dispatch_time_ms: 9.237
    learner:
      cur_lr: 0.0012327940203249454
      grad_gnorm: 3.233937978744507
      policy_entropy: 161.879638671875
      policy_loss: -0.1933652013540268
      var_gnorm: 49.29966354370117
      vf_explained_var: -1.0
      vf_loss: 0.0688825473189354
    num_steps_sampled: 1920000
    num_steps_trained: 1920000
    wait_time_ms: 169.347
  iterations_since_restore: 192
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3540.46759557724
  time_this_iter_s: 17.98818349838257
  time_total_s: 3540.46759557724
  timestamp: 1593887999
  timesteps_since_restore: 1920000
  timesteps_this_iter: 10000
  timesteps_total: 1920000
  training_iteration: 192
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3540 s, 192 iter, 1920000 ts, 215 rew

agent-1: 25.0
agent-2: 27.0
agent-3: 13.0
agent-4: 29.0
agent-5: 20.0
agent-6: 22.0
agent-7: 21.0
agent-8: 20.0
agent-9: 22.0
agent-10: 15.0
Sum Reward: 214.0
Avg Reward: 21.4
Min Reward: 13.0
Gini Coefficient: 0.12149532710280374
20:20 Ratio: 2.0
Max-min Ratio: 2.230769230769231
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-40-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 215.11
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 192
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.526
    dispatch_time_ms: 6.105
    learner:
      cur_lr: 0.0012321280082687736
      grad_gnorm: 3.7860395908355713
      policy_entropy: 144.10049438476562
      policy_loss: -1.0087776184082031
      var_gnorm: 49.388004302978516
      vf_explained_var: 0.2437313199043274
      vf_loss: 0.021598966792225838
    num_steps_sampled: 1930000
    num_steps_trained: 1930000
    wait_time_ms: 166.174
  iterations_since_restore: 193
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3558.340230703354
  time_this_iter_s: 17.87263512611389
  time_total_s: 3558.340230703354
  timestamp: 1593888017
  timesteps_since_restore: 1930000
  timesteps_this_iter: 10000
  timesteps_total: 1930000
  training_iteration: 193
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3558 s, 193 iter, 1930000 ts, 215 rew

agent-1: 19.0
agent-2: 15.0
agent-3: 27.0
agent-4: 17.0
agent-5: 18.0
agent-6: 21.0
agent-7: 24.0
agent-8: 19.0
agent-9: 22.0
agent-10: 15.0
Sum Reward: 197.0
Avg Reward: 19.7
Min Reward: 15.0
Gini Coefficient: 0.10406091370558376
20:20 Ratio: 1.7
Max-min Ratio: 1.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-40-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 214.99
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 193
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.119
    dispatch_time_ms: 10.354
    learner:
      cur_lr: 0.0012314619962126017
      grad_gnorm: 2.602944850921631
      policy_entropy: 182.10704040527344
      policy_loss: 0.2751706540584564
      var_gnorm: 49.56437683105469
      vf_explained_var: 0.49586939811706543
      vf_loss: 0.01128413900732994
    num_steps_sampled: 1940000
    num_steps_trained: 1940000
    wait_time_ms: 167.551
  iterations_since_restore: 194
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3576.2948727607727
  time_this_iter_s: 17.954642057418823
  time_total_s: 3576.2948727607727
  timestamp: 1593888035
  timesteps_since_restore: 1940000
  timesteps_this_iter: 10000
  timesteps_total: 1940000
  training_iteration: 194
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3576 s, 194 iter, 1940000 ts, 215 rew

agent-1: 15.0
agent-2: 16.0
agent-3: 25.0
agent-4: 22.0
agent-5: 20.0
agent-6: 19.0
agent-7: 25.0
agent-8: 15.0
agent-9: 15.0
agent-10: 20.0
Sum Reward: 192.0
Avg Reward: 19.2
Min Reward: 15.0
Gini Coefficient: 0.10833333333333334
20:20 Ratio: 1.6666666666666667
Max-min Ratio: 1.6666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-40-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 214.92
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 194
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.784
    dispatch_time_ms: 8.53
    learner:
      cur_lr: 0.0012307959841564298
      grad_gnorm: 23.59715461730957
      policy_entropy: 158.88983154296875
      policy_loss: -0.22676439583301544
      var_gnorm: 49.65115737915039
      vf_explained_var: 0.8140624761581421
      vf_loss: 2.3184375762939453
    num_steps_sampled: 1950000
    num_steps_trained: 1950000
    wait_time_ms: 166.723
  iterations_since_restore: 195
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3594.3605999946594
  time_this_iter_s: 18.06572723388672
  time_total_s: 3594.3605999946594
  timestamp: 1593888053
  timesteps_since_restore: 1950000
  timesteps_this_iter: 10000
  timesteps_total: 1950000
  training_iteration: 195
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3594 s, 195 iter, 1950000 ts, 215 rew

agent-1: 12.0
agent-2: 29.0
agent-3: 18.0
agent-4: 26.0
agent-5: 14.0
agent-6: 21.0
agent-7: 33.0
agent-8: 21.0
agent-9: 23.0
agent-10: 15.0
Sum Reward: 212.0
Avg Reward: 21.2
Min Reward: 12.0
Gini Coefficient: 0.17169811320754716
20:20 Ratio: 2.3846153846153846
Max-min Ratio: 2.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-41-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 214.86
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 195
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.173
    dispatch_time_ms: 7.531
    learner:
      cur_lr: 0.0012301299721002579
      grad_gnorm: 4.31197452545166
      policy_entropy: 165.27468872070312
      policy_loss: -0.08210812509059906
      var_gnorm: 49.89393615722656
      vf_explained_var: -0.6972364187240601
      vf_loss: 0.008127572946250439
    num_steps_sampled: 1960000
    num_steps_trained: 1960000
    wait_time_ms: 172.506
  iterations_since_restore: 196
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3612.300163269043
  time_this_iter_s: 17.939563274383545
  time_total_s: 3612.300163269043
  timestamp: 1593888071
  timesteps_since_restore: 1960000
  timesteps_this_iter: 10000
  timesteps_total: 1960000
  training_iteration: 196
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3612 s, 196 iter, 1960000 ts, 215 rew

agent-1: 33.0
agent-2: 23.0
agent-3: 27.0
agent-4: 14.0
agent-5: 24.0
agent-6: 14.0
agent-7: 22.0
agent-8: 30.0
agent-9: 25.0
agent-10: 12.0
Sum Reward: 224.0
Avg Reward: 22.4
Min Reward: 12.0
Gini Coefficient: 0.16785714285714284
20:20 Ratio: 2.423076923076923
Max-min Ratio: 2.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-41-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 215.02
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 196
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.715
    dispatch_time_ms: 6.196
    learner:
      cur_lr: 0.001229463960044086
      grad_gnorm: 6.426268100738525
      policy_entropy: 167.6689910888672
      policy_loss: -0.3466726839542389
      var_gnorm: 49.92863464355469
      vf_explained_var: 0.022990643978118896
      vf_loss: 0.006578126456588507
    num_steps_sampled: 1970000
    num_steps_trained: 1970000
    wait_time_ms: 169.057
  iterations_since_restore: 197
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3630.0700635910034
  time_this_iter_s: 17.76990032196045
  time_total_s: 3630.0700635910034
  timestamp: 1593888088
  timesteps_since_restore: 1970000
  timesteps_this_iter: 10000
  timesteps_total: 1970000
  training_iteration: 197
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3630 s, 197 iter, 1970000 ts, 215 rew

agent-1: 19.0
agent-2: 16.0
agent-3: 23.0
agent-4: 26.0
agent-5: 9.0
agent-6: 26.0
agent-7: 18.0
agent-8: 16.0
agent-9: 23.0
agent-10: 28.0
Sum Reward: 204.0
Avg Reward: 20.4
Min Reward: 9.0
Gini Coefficient: 0.15196078431372548
20:20 Ratio: 2.16
Max-min Ratio: 3.111111111111111
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-41-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 214.66
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 197
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.595
    dispatch_time_ms: 6.3
    learner:
      cur_lr: 0.001228797947987914
      grad_gnorm: 10.452723503112793
      policy_entropy: 146.05804443359375
      policy_loss: -0.5009868144989014
      var_gnorm: 50.03199768066406
      vf_explained_var: -1.0
      vf_loss: 0.016344180330634117
    num_steps_sampled: 1980000
    num_steps_trained: 1980000
    wait_time_ms: 164.532
  iterations_since_restore: 198
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3648.0639979839325
  time_this_iter_s: 17.993934392929077
  time_total_s: 3648.0639979839325
  timestamp: 1593888106
  timesteps_since_restore: 1980000
  timesteps_this_iter: 10000
  timesteps_total: 1980000
  training_iteration: 198
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3648 s, 198 iter, 1980000 ts, 215 rew

agent-1: 24.0
agent-2: 21.0
agent-3: 20.0
agent-4: 18.0
agent-5: 22.0
agent-6: 18.0
agent-7: 25.0
agent-8: 21.0
agent-9: 22.0
agent-10: 24.0
Sum Reward: 215.0
Avg Reward: 21.5
Min Reward: 18.0
Gini Coefficient: 0.06
20:20 Ratio: 1.3611111111111112
Max-min Ratio: 1.3888888888888888
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-42-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 214.83
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 198
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.859
    dispatch_time_ms: 7.248
    learner:
      cur_lr: 0.001228132052347064
      grad_gnorm: 39.999996185302734
      policy_entropy: 150.58737182617188
      policy_loss: -0.7826844453811646
      var_gnorm: 50.01038360595703
      vf_explained_var: 0.9167771339416504
      vf_loss: 3.1942763328552246
    num_steps_sampled: 1990000
    num_steps_trained: 1990000
    wait_time_ms: 165.544
  iterations_since_restore: 199
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3665.930962085724
  time_this_iter_s: 17.866964101791382
  time_total_s: 3665.930962085724
  timestamp: 1593888124
  timesteps_since_restore: 1990000
  timesteps_this_iter: 10000
  timesteps_total: 1990000
  training_iteration: 199
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3665 s, 199 iter, 1990000 ts, 215 rew

agent-1: 18.0
agent-2: 26.0
agent-3: 26.0
agent-4: 29.0
agent-5: 27.0
agent-6: 20.0
agent-7: 19.0
agent-8: 18.0
agent-9: 26.0
agent-10: 27.0
Sum Reward: 236.0
Avg Reward: 23.6
Min Reward: 18.0
Gini Coefficient: 0.09322033898305085
20:20 Ratio: 1.5555555555555556
Max-min Ratio: 1.6111111111111112
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-42-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 214.87
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 199
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.801
    dispatch_time_ms: 7.704
    learner:
      cur_lr: 0.0012274660402908921
      grad_gnorm: 4.371414661407471
      policy_entropy: 154.75204467773438
      policy_loss: -1.274999976158142
      var_gnorm: 50.14024353027344
      vf_explained_var: 0.926063597202301
      vf_loss: 0.040287572890520096
    num_steps_sampled: 2000000
    num_steps_trained: 2000000
    wait_time_ms: 169.159
  iterations_since_restore: 200
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3683.9155325889587
  time_this_iter_s: 17.984570503234863
  time_total_s: 3683.9155325889587
  timestamp: 1593888142
  timesteps_since_restore: 2000000
  timesteps_this_iter: 10000
  timesteps_total: 2000000
  training_iteration: 200
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3683 s, 200 iter, 2000000 ts, 215 rew

agent-1: 26.0
agent-2: 25.0
agent-3: 21.0
agent-4: 23.0
agent-5: 28.0
agent-6: 16.0
agent-7: 13.0
agent-8: 20.0
agent-9: 22.0
agent-10: 20.0
Sum Reward: 214.0
Avg Reward: 21.4
Min Reward: 13.0
Gini Coefficient: 0.11214953271028037
20:20 Ratio: 1.8620689655172413
Max-min Ratio: 2.1538461538461537
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-42-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 214.8
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 200
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.87
    dispatch_time_ms: 6.379
    learner:
      cur_lr: 0.0012268000282347202
      grad_gnorm: 1.0417554378509521
      policy_entropy: 166.8968505859375
      policy_loss: 0.43493521213531494
      var_gnorm: 50.18977737426758
      vf_explained_var: 0.06388795375823975
      vf_loss: 0.017625877633690834
    num_steps_sampled: 2010000
    num_steps_trained: 2010000
    wait_time_ms: 170.41
  iterations_since_restore: 201
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3701.623809814453
  time_this_iter_s: 17.708277225494385
  time_total_s: 3701.623809814453
  timestamp: 1593888160
  timesteps_since_restore: 2010000
  timesteps_this_iter: 10000
  timesteps_total: 2010000
  training_iteration: 201
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3701 s, 201 iter, 2010000 ts, 215 rew

agent-1: 22.0
agent-2: 20.0
agent-3: 17.0
agent-4: 15.0
agent-5: 26.0
agent-6: 19.0
agent-7: 22.0
agent-8: 18.0
agent-9: 26.0
agent-10: 13.0
Sum Reward: 198.0
Avg Reward: 19.8
Min Reward: 13.0
Gini Coefficient: 0.11717171717171718
20:20 Ratio: 1.8571428571428572
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-42-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 214.59
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 201
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.119
    dispatch_time_ms: 10.645
    learner:
      cur_lr: 0.0012261340161785483
      grad_gnorm: 1.3640198707580566
      policy_entropy: 175.94862365722656
      policy_loss: -0.8802854418754578
      var_gnorm: 50.36669158935547
      vf_explained_var: -0.10785996913909912
      vf_loss: 0.028290100395679474
    num_steps_sampled: 2020000
    num_steps_trained: 2020000
    wait_time_ms: 164.792
  iterations_since_restore: 202
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3719.5076220035553
  time_this_iter_s: 17.883812189102173
  time_total_s: 3719.5076220035553
  timestamp: 1593888178
  timesteps_since_restore: 2020000
  timesteps_this_iter: 10000
  timesteps_total: 2020000
  training_iteration: 202
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3719 s, 202 iter, 2020000 ts, 215 rew

agent-1: 21.0
agent-2: 20.0
agent-3: 15.0
agent-4: 28.0
agent-5: 25.0
agent-6: 21.0
agent-7: 20.0
agent-8: 32.0
agent-9: 32.0
agent-10: 18.0
Sum Reward: 232.0
Avg Reward: 23.2
Min Reward: 15.0
Gini Coefficient: 0.13189655172413794
20:20 Ratio: 1.9393939393939394
Max-min Ratio: 2.1333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-43-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 214.72
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 202
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.448
    dispatch_time_ms: 7.277
    learner:
      cur_lr: 0.0012254680041223764
      grad_gnorm: 7.983366012573242
      policy_entropy: 164.5559539794922
      policy_loss: 1.2447797060012817
      var_gnorm: 50.36835861206055
      vf_explained_var: 0.007698118686676025
      vf_loss: 0.05708390474319458
    num_steps_sampled: 2030000
    num_steps_trained: 2030000
    wait_time_ms: 172.516
  iterations_since_restore: 203
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3737.3171303272247
  time_this_iter_s: 17.809508323669434
  time_total_s: 3737.3171303272247
  timestamp: 1593888196
  timesteps_since_restore: 2030000
  timesteps_this_iter: 10000
  timesteps_total: 2030000
  training_iteration: 203
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3737 s, 203 iter, 2030000 ts, 215 rew

agent-1: 27.0
agent-2: 16.0
agent-3: 19.0
agent-4: 17.0
agent-5: 28.0
agent-6: 22.0
agent-7: 25.0
agent-8: 20.0
agent-9: 20.0
agent-10: 19.0
Sum Reward: 213.0
Avg Reward: 21.3
Min Reward: 16.0
Gini Coefficient: 0.10187793427230046
20:20 Ratio: 1.6666666666666667
Max-min Ratio: 1.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-43-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 214.82
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 203
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.971
    dispatch_time_ms: 6.296
    learner:
      cur_lr: 0.0012248019920662045
      grad_gnorm: 3.7006003856658936
      policy_entropy: 17.055028915405273
      policy_loss: 0.20885556936264038
      var_gnorm: 50.570133209228516
      vf_explained_var: 0.634300947189331
      vf_loss: 0.03662363812327385
    num_steps_sampled: 2040000
    num_steps_trained: 2040000
    wait_time_ms: 177.56
  iterations_since_restore: 204
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3755.3166263103485
  time_this_iter_s: 17.99949598312378
  time_total_s: 3755.3166263103485
  timestamp: 1593888214
  timesteps_since_restore: 2040000
  timesteps_this_iter: 10000
  timesteps_total: 2040000
  training_iteration: 204
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3755 s, 204 iter, 2040000 ts, 215 rew

agent-1: 38.0
agent-2: 22.0
agent-3: 24.0
agent-4: 16.0
agent-5: 28.0
agent-6: 21.0
agent-7: 22.0
agent-8: 21.0
agent-9: 15.0
agent-10: 19.0
Sum Reward: 226.0
Avg Reward: 22.6
Min Reward: 15.0
Gini Coefficient: 0.1415929203539823
20:20 Ratio: 2.129032258064516
Max-min Ratio: 2.533333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-43-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 214.74
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 204
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.319
    dispatch_time_ms: 7.039
    learner:
      cur_lr: 0.0012241359800100327
      grad_gnorm: 0.2796632647514343
      policy_entropy: 9.182853698730469
      policy_loss: -0.004502665251493454
      var_gnorm: 50.61996078491211
      vf_explained_var: 0.9957865476608276
      vf_loss: 0.00010547538113314658
    num_steps_sampled: 2050000
    num_steps_trained: 2050000
    wait_time_ms: 168.037
  iterations_since_restore: 205
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3773.241788625717
  time_this_iter_s: 17.925162315368652
  time_total_s: 3773.241788625717
  timestamp: 1593888232
  timesteps_since_restore: 2050000
  timesteps_this_iter: 10000
  timesteps_total: 2050000
  training_iteration: 205
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3773 s, 205 iter, 2050000 ts, 215 rew

agent-1: 19.0
agent-2: 19.0
agent-3: 20.0
agent-4: 23.0
agent-5: 17.0
agent-6: 33.0
agent-7: 23.0
agent-8: 16.0
agent-9: 21.0
agent-10: 22.0
Sum Reward: 213.0
Avg Reward: 21.3
Min Reward: 16.0
Gini Coefficient: 0.1056338028169014
20:20 Ratio: 1.696969696969697
Max-min Ratio: 2.0625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-44-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 214.65
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 205
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.995
    dispatch_time_ms: 8.27
    learner:
      cur_lr: 0.0012234699679538608
      grad_gnorm: 5.210300922393799
      policy_entropy: 171.33493041992188
      policy_loss: 0.5689795613288879
      var_gnorm: 50.680747985839844
      vf_explained_var: 0.9572473168373108
      vf_loss: 0.010531064122915268
    num_steps_sampled: 2060000
    num_steps_trained: 2060000
    wait_time_ms: 165.133
  iterations_since_restore: 206
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3791.3393132686615
  time_this_iter_s: 18.097524642944336
  time_total_s: 3791.3393132686615
  timestamp: 1593888250
  timesteps_since_restore: 2060000
  timesteps_this_iter: 10000
  timesteps_total: 2060000
  training_iteration: 206
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3791 s, 206 iter, 2060000 ts, 215 rew

agent-1: 22.0
agent-2: 23.0
agent-3: 16.0
agent-4: 18.0
agent-5: 21.0
agent-6: 23.0
agent-7: 16.0
agent-8: 22.0
agent-9: 14.0
agent-10: 26.0
Sum Reward: 201.0
Avg Reward: 20.1
Min Reward: 14.0
Gini Coefficient: 0.10199004975124377
20:20 Ratio: 1.6333333333333333
Max-min Ratio: 1.8571428571428572
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-44-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 214.56
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 206
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.068
    dispatch_time_ms: 8.491
    learner:
      cur_lr: 0.0012228039558976889
      grad_gnorm: 40.0
      policy_entropy: 133.1964569091797
      policy_loss: 8.227201461791992
      var_gnorm: 50.72621536254883
      vf_explained_var: 0.18326425552368164
      vf_loss: 4.937747001647949
    num_steps_sampled: 2070000
    num_steps_trained: 2070000
    wait_time_ms: 174.444
  iterations_since_restore: 207
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3809.296861410141
  time_this_iter_s: 17.957548141479492
  time_total_s: 3809.296861410141
  timestamp: 1593888268
  timesteps_since_restore: 2070000
  timesteps_this_iter: 10000
  timesteps_total: 2070000
  training_iteration: 207
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3809 s, 207 iter, 2070000 ts, 215 rew

agent-1: 18.0
agent-2: 20.0
agent-3: 18.0
agent-4: 22.0
agent-5: 22.0
agent-6: 28.0
agent-7: 19.0
agent-8: 18.0
agent-9: 18.0
agent-10: 25.0
Sum Reward: 208.0
Avg Reward: 20.8
Min Reward: 18.0
Gini Coefficient: 0.08269230769230769
20:20 Ratio: 1.4722222222222223
Max-min Ratio: 1.5555555555555556
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-44-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 214.28
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 207
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.546
    dispatch_time_ms: 9.052
    learner:
      cur_lr: 0.001222137943841517
      grad_gnorm: 1.2413499355316162
      policy_entropy: 138.63824462890625
      policy_loss: -0.08668198436498642
      var_gnorm: 50.84363555908203
      vf_explained_var: 0.9658316373825073
      vf_loss: 0.0038222773000597954
    num_steps_sampled: 2080000
    num_steps_trained: 2080000
    wait_time_ms: 168.881
  iterations_since_restore: 208
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3827.135424375534
  time_this_iter_s: 17.838562965393066
  time_total_s: 3827.135424375534
  timestamp: 1593888286
  timesteps_since_restore: 2080000
  timesteps_this_iter: 10000
  timesteps_total: 2080000
  training_iteration: 208
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3827 s, 208 iter, 2080000 ts, 214 rew

agent-1: 8.0
agent-2: 28.0
agent-3: 12.0
agent-4: 20.0
agent-5: 20.0
agent-6: 24.0
agent-7: 22.0
agent-8: 24.0
agent-9: 23.0
agent-10: 19.0
Sum Reward: 200.0
Avg Reward: 20.0
Min Reward: 8.0
Gini Coefficient: 0.15
20:20 Ratio: 2.6
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-45-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 214.23
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 208
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 4.059
    dispatch_time_ms: 7.05
    learner:
      cur_lr: 0.001221472048200667
      grad_gnorm: 24.737014770507812
      policy_entropy: 163.46978759765625
      policy_loss: 9.0374174118042
      var_gnorm: 50.833091735839844
      vf_explained_var: -0.01013481616973877
      vf_loss: 1.3912371397018433
    num_steps_sampled: 2090000
    num_steps_trained: 2090000
    wait_time_ms: 171.069
  iterations_since_restore: 209
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3844.903207063675
  time_this_iter_s: 17.76778268814087
  time_total_s: 3844.903207063675
  timestamp: 1593888304
  timesteps_since_restore: 2090000
  timesteps_this_iter: 10000
  timesteps_total: 2090000
  training_iteration: 209
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3844 s, 209 iter, 2090000 ts, 214 rew

agent-1: 21.0
agent-2: 20.0
agent-3: 21.0
agent-4: 22.0
agent-5: 12.0
agent-6: 22.0
agent-7: 31.0
agent-8: 27.0
agent-9: 26.0
agent-10: 21.0
Sum Reward: 223.0
Avg Reward: 22.3
Min Reward: 12.0
Gini Coefficient: 0.11165919282511211
20:20 Ratio: 1.8125
Max-min Ratio: 2.5833333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-45-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 214.49
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 209
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.988
    dispatch_time_ms: 6.574
    learner:
      cur_lr: 0.001220806036144495
      grad_gnorm: 0.9191575646400452
      policy_entropy: 172.07806396484375
      policy_loss: -0.23809105157852173
      var_gnorm: 50.9804801940918
      vf_explained_var: 0.7507253885269165
      vf_loss: 0.0016015945002436638
    num_steps_sampled: 2100000
    num_steps_trained: 2100000
    wait_time_ms: 164.495
  iterations_since_restore: 210
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3862.625405073166
  time_this_iter_s: 17.722198009490967
  time_total_s: 3862.625405073166
  timestamp: 1593888321
  timesteps_since_restore: 2100000
  timesteps_this_iter: 10000
  timesteps_total: 2100000
  training_iteration: 210
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3862 s, 210 iter, 2100000 ts, 214 rew

agent-1: 21.0
agent-2: 19.0
agent-3: 21.0
agent-4: 18.0
agent-5: 16.0
agent-6: 19.0
agent-7: 23.0
agent-8: 12.0
agent-9: 21.0
agent-10: 16.0
Sum Reward: 186.0
Avg Reward: 18.6
Min Reward: 12.0
Gini Coefficient: 0.09032258064516129
20:20 Ratio: 1.5714285714285714
Max-min Ratio: 1.9166666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-45-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 214.31
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 210
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.784
    dispatch_time_ms: 7.448
    learner:
      cur_lr: 0.0012201400240883231
      grad_gnorm: 6.407063961029053
      policy_entropy: 183.57266235351562
      policy_loss: -3.896505355834961
      var_gnorm: 50.980224609375
      vf_explained_var: 0.8747546076774597
      vf_loss: 0.0336306095123291
    num_steps_sampled: 2110000
    num_steps_trained: 2110000
    wait_time_ms: 158.496
  iterations_since_restore: 211
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3880.426292657852
  time_this_iter_s: 17.80088758468628
  time_total_s: 3880.426292657852
  timestamp: 1593888339
  timesteps_since_restore: 2110000
  timesteps_this_iter: 10000
  timesteps_total: 2110000
  training_iteration: 211
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3880 s, 211 iter, 2110000 ts, 214 rew

agent-1: 22.0
agent-2: 22.0
agent-3: 21.0
agent-4: 22.0
agent-5: 31.0
agent-6: 19.0
agent-7: 20.0
agent-8: 20.0
agent-9: 24.0
agent-10: 17.0
Sum Reward: 218.0
Avg Reward: 21.8
Min Reward: 17.0
Gini Coefficient: 0.081651376146789
20:20 Ratio: 1.5277777777777777
Max-min Ratio: 1.8235294117647058
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-46-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 214.47
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 211
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.224
    dispatch_time_ms: 6.184
    learner:
      cur_lr: 0.0012194740120321512
      grad_gnorm: 13.309538841247559
      policy_entropy: 152.4617919921875
      policy_loss: 0.7365500926971436
      var_gnorm: 51.090599060058594
      vf_explained_var: -0.06819772720336914
      vf_loss: 0.2036745250225067
    num_steps_sampled: 2120000
    num_steps_trained: 2120000
    wait_time_ms: 167.5
  iterations_since_restore: 212
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3900.889345884323
  time_this_iter_s: 20.463053226470947
  time_total_s: 3900.889345884323
  timestamp: 1593888360
  timesteps_since_restore: 2120000
  timesteps_this_iter: 10000
  timesteps_total: 2120000
  training_iteration: 212
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3900 s, 212 iter, 2120000 ts, 214 rew

agent-1: 11.0
agent-2: 14.0
agent-3: 28.0
agent-4: 25.0
agent-5: 22.0
agent-6: 14.0
agent-7: 26.0
agent-8: 24.0
agent-9: 27.0
agent-10: 16.0
Sum Reward: 207.0
Avg Reward: 20.7
Min Reward: 11.0
Gini Coefficient: 0.1608695652173913
20:20 Ratio: 2.2
Max-min Ratio: 2.5454545454545454
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-46-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 214.48
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 212
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.711
    dispatch_time_ms: 31.414
    learner:
      cur_lr: 0.0012188079999759793
      grad_gnorm: 5.986817836761475
      policy_entropy: 172.35360717773438
      policy_loss: -1.826604962348938
      var_gnorm: 51.20053482055664
      vf_explained_var: 0.9794685244560242
      vf_loss: 0.0048002698458731174
    num_steps_sampled: 2130000
    num_steps_trained: 2130000
    wait_time_ms: 156.803
  iterations_since_restore: 213
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3918.9967200756073
  time_this_iter_s: 18.10737419128418
  time_total_s: 3918.9967200756073
  timestamp: 1593888378
  timesteps_since_restore: 2130000
  timesteps_this_iter: 10000
  timesteps_total: 2130000
  training_iteration: 213
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3918 s, 213 iter, 2130000 ts, 214 rew

agent-1: 26.0
agent-2: 24.0
agent-3: 25.0
agent-4: 19.0
agent-5: 13.0
agent-6: 27.0
agent-7: 16.0
agent-8: 29.0
agent-9: 27.0
agent-10: 19.0
Sum Reward: 225.0
Avg Reward: 22.5
Min Reward: 13.0
Gini Coefficient: 0.12577777777777777
20:20 Ratio: 1.9310344827586208
Max-min Ratio: 2.230769230769231
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-46-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 214.43
  episode_reward_min: 186.0
  episodes_this_iter: 1
  episodes_total: 213
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 5.508
    dispatch_time_ms: 27.911
    learner:
      cur_lr: 0.0012181419879198074
      grad_gnorm: 3.729978322982788
      policy_entropy: 131.77529907226562
      policy_loss: 1.0256004333496094
      var_gnorm: 51.32624816894531
      vf_explained_var: 0.6763278245925903
      vf_loss: 0.028066640719771385
    num_steps_sampled: 2140000
    num_steps_trained: 2140000
    wait_time_ms: 156.311
  iterations_since_restore: 214
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3937.868589401245
  time_this_iter_s: 18.871869325637817
  time_total_s: 3937.868589401245
  timestamp: 1593888397
  timesteps_since_restore: 2140000
  timesteps_this_iter: 10000
  timesteps_total: 2140000
  training_iteration: 214
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3937 s, 214 iter, 2140000 ts, 214 rew

agent-1: 15.0
agent-2: 12.0
agent-3: 15.0
agent-4: 20.0
agent-5: 19.0
agent-6: 16.0
agent-7: 14.0
agent-8: 26.0
agent-9: 20.0
agent-10: 22.0
Sum Reward: 179.0
Avg Reward: 17.9
Min Reward: 12.0
Gini Coefficient: 0.12569832402234637
20:20 Ratio: 1.8461538461538463
Max-min Ratio: 2.1666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-46-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 264.0
  episode_reward_mean: 214.08
  episode_reward_min: 179.0
  episodes_this_iter: 1
  episodes_total: 214
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 4.606
    dispatch_time_ms: 30.701
    learner:
      cur_lr: 0.0012174759758636355
      grad_gnorm: 2.2008326053619385
      policy_entropy: 178.18992614746094
      policy_loss: -2.1164398193359375
      var_gnorm: 51.299129486083984
      vf_explained_var: -1.0
      vf_loss: 0.014103003777563572
    num_steps_sampled: 2150000
    num_steps_trained: 2150000
    wait_time_ms: 160.407
  iterations_since_restore: 215
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3956.522541999817
  time_this_iter_s: 18.653952598571777
  time_total_s: 3956.522541999817
  timestamp: 1593888416
  timesteps_since_restore: 2150000
  timesteps_this_iter: 10000
  timesteps_total: 2150000
  training_iteration: 215
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3956 s, 215 iter, 2150000 ts, 214 rew

agent-1: 25.0
agent-2: 15.0
agent-3: 22.0
agent-4: 10.0
agent-5: 23.0
agent-6: 17.0
agent-7: 23.0
agent-8: 22.0
agent-9: 24.0
agent-10: 24.0
Sum Reward: 205.0
Avg Reward: 20.5
Min Reward: 10.0
Gini Coefficient: 0.11560975609756098
20:20 Ratio: 1.96
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-47-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 213.49
  episode_reward_min: 179.0
  episodes_this_iter: 1
  episodes_total: 215
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.591
    dispatch_time_ms: 6.038
    learner:
      cur_lr: 0.0012168099638074636
      grad_gnorm: 1.051991581916809
      policy_entropy: 179.8488311767578
      policy_loss: -0.009456194937229156
      var_gnorm: 51.40553665161133
      vf_explained_var: 0.9928672909736633
      vf_loss: 0.0001943520619533956
    num_steps_sampled: 2160000
    num_steps_trained: 2160000
    wait_time_ms: 175.821
  iterations_since_restore: 216
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3975.0666847229004
  time_this_iter_s: 18.544142723083496
  time_total_s: 3975.0666847229004
  timestamp: 1593888434
  timesteps_since_restore: 2160000
  timesteps_this_iter: 10000
  timesteps_total: 2160000
  training_iteration: 216
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3975 s, 216 iter, 2160000 ts, 213 rew

agent-1: 20.0
agent-2: 19.0
agent-3: 20.0
agent-4: 22.0
agent-5: 25.0
agent-6: 24.0
agent-7: 20.0
agent-8: 24.0
agent-9: 21.0
agent-10: 26.0
Sum Reward: 221.0
Avg Reward: 22.1
Min Reward: 19.0
Gini Coefficient: 0.05927601809954751
20:20 Ratio: 1.3076923076923077
Max-min Ratio: 1.368421052631579
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-47-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 213.3
  episode_reward_min: 179.0
  episodes_this_iter: 1
  episodes_total: 216
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.772
    dispatch_time_ms: 10.278
    learner:
      cur_lr: 0.0012161439517512918
      grad_gnorm: 0.974815845489502
      policy_entropy: 172.5894775390625
      policy_loss: -0.36910146474838257
      var_gnorm: 51.43967056274414
      vf_explained_var: 0.888945460319519
      vf_loss: 0.0013103201054036617
    num_steps_sampled: 2170000
    num_steps_trained: 2170000
    wait_time_ms: 164.6
  iterations_since_restore: 217
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 3992.880715608597
  time_this_iter_s: 17.81403088569641
  time_total_s: 3992.880715608597
  timestamp: 1593888452
  timesteps_since_restore: 2170000
  timesteps_this_iter: 10000
  timesteps_total: 2170000
  training_iteration: 217
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 3992 s, 217 iter, 2170000 ts, 213 rew

agent-1: 28.0
agent-2: 13.0
agent-3: -35.0
agent-4: 28.0
agent-5: 26.0
agent-6: 32.0
agent-7: 14.0
agent-8: 16.0
agent-9: 24.0
agent-10: 10.0
Sum Reward: 156.0
Avg Reward: 15.6
Min Reward: -35.0
Gini Coefficient: 0.5435897435897435
20:20 Ratio: -2.4
Max-min Ratio: -0.9142857142857143
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-47-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 212.35
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 217
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.567
    dispatch_time_ms: 6.826
    learner:
      cur_lr: 0.0012154780561104417
      grad_gnorm: 0.5286563634872437
      policy_entropy: 182.83993530273438
      policy_loss: 0.3513261377811432
      var_gnorm: 51.46688461303711
      vf_explained_var: 0.9940504431724548
      vf_loss: 0.000494818261358887
    num_steps_sampled: 2180000
    num_steps_trained: 2180000
    wait_time_ms: 169.586
  iterations_since_restore: 218
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4010.7668583393097
  time_this_iter_s: 17.88614273071289
  time_total_s: 4010.7668583393097
  timestamp: 1593888470
  timesteps_since_restore: 2180000
  timesteps_this_iter: 10000
  timesteps_total: 2180000
  training_iteration: 218
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4010 s, 218 iter, 2180000 ts, 212 rew

agent-1: 20.0
agent-2: 21.0
agent-3: 21.0
agent-4: 16.0
agent-5: 22.0
agent-6: 18.0
agent-7: 20.0
agent-8: 18.0
agent-9: 25.0
agent-10: 17.0
Sum Reward: 198.0
Avg Reward: 19.8
Min Reward: 16.0
Gini Coefficient: 0.0707070707070707
20:20 Ratio: 1.4242424242424243
Max-min Ratio: 1.5625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-48-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 212.33
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 218
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.68
    dispatch_time_ms: 24.996
    learner:
      cur_lr: 0.0012148120440542698
      grad_gnorm: 4.061192035675049
      policy_entropy: 188.6473846435547
      policy_loss: -3.9937686920166016
      var_gnorm: 51.55719757080078
      vf_explained_var: 0.9486333131790161
      vf_loss: 0.012268302962183952
    num_steps_sampled: 2190000
    num_steps_trained: 2190000
    wait_time_ms: 1124.234
  iterations_since_restore: 219
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4038.494476556778
  time_this_iter_s: 27.72761821746826
  time_total_s: 4038.494476556778
  timestamp: 1593888498
  timesteps_since_restore: 2190000
  timesteps_this_iter: 10000
  timesteps_total: 2190000
  training_iteration: 219
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4038 s, 219 iter, 2190000 ts, 212 rew

agent-1: 11.0
agent-2: 27.0
agent-3: 27.0
agent-4: 22.0
agent-5: 18.0
agent-6: 19.0
agent-7: 16.0
agent-8: 18.0
agent-9: 15.0
agent-10: 22.0
Sum Reward: 195.0
Avg Reward: 19.5
Min Reward: 11.0
Gini Coefficient: 0.13897435897435897
20:20 Ratio: 2.076923076923077
Max-min Ratio: 2.4545454545454546
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-48-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 211.89
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 219
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.096
    dispatch_time_ms: 20.933
    learner:
      cur_lr: 0.001214146031998098
      grad_gnorm: 8.690571784973145
      policy_entropy: 150.8055419921875
      policy_loss: 2.644530773162842
      var_gnorm: 51.66347122192383
      vf_explained_var: 0.3253556489944458
      vf_loss: 0.02392641082406044
    num_steps_sampled: 2200000
    num_steps_trained: 2200000
    wait_time_ms: 157.468
  iterations_since_restore: 220
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4055.114850282669
  time_this_iter_s: 16.620373725891113
  time_total_s: 4055.114850282669
  timestamp: 1593888514
  timesteps_since_restore: 2200000
  timesteps_this_iter: 10000
  timesteps_total: 2200000
  training_iteration: 220
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4055 s, 220 iter, 2200000 ts, 212 rew

agent-1: 23.0
agent-2: 27.0
agent-3: 21.0
agent-4: 15.0
agent-5: 20.0
agent-6: 12.0
agent-7: 23.0
agent-8: 27.0
agent-9: 18.0
agent-10: 22.0
Sum Reward: 208.0
Avg Reward: 20.8
Min Reward: 12.0
Gini Coefficient: 0.12211538461538461
20:20 Ratio: 2.0
Max-min Ratio: 2.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-48-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 211.77
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 220
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.279
    dispatch_time_ms: 15.067
    learner:
      cur_lr: 0.001213480019941926
      grad_gnorm: 0.769010066986084
      policy_entropy: 175.276611328125
      policy_loss: 0.531822681427002
      var_gnorm: 51.67461013793945
      vf_explained_var: 0.9369367361068726
      vf_loss: 0.0006696341442875564
    num_steps_sampled: 2210000
    num_steps_trained: 2210000
    wait_time_ms: 172.335
  iterations_since_restore: 221
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4073.5453867912292
  time_this_iter_s: 18.43053650856018
  time_total_s: 4073.5453867912292
  timestamp: 1593888533
  timesteps_since_restore: 2210000
  timesteps_this_iter: 10000
  timesteps_total: 2210000
  training_iteration: 221
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4073 s, 221 iter, 2210000 ts, 212 rew

agent-1: 15.0
agent-2: 20.0
agent-3: 22.0
agent-4: 15.0
agent-5: 22.0
agent-6: 15.0
agent-7: 25.0
agent-8: 20.0
agent-9: 23.0
agent-10: 19.0
Sum Reward: 196.0
Avg Reward: 19.6
Min Reward: 15.0
Gini Coefficient: 0.09693877551020408
20:20 Ratio: 1.6
Max-min Ratio: 1.6666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-49-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 211.4
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 221
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.585
    dispatch_time_ms: 23.299
    learner:
      cur_lr: 0.0012128140078857541
      grad_gnorm: 1.5702039003372192
      policy_entropy: 183.440185546875
      policy_loss: 0.19199465215206146
      var_gnorm: 51.748817443847656
      vf_explained_var: 0.9598866701126099
      vf_loss: 0.002421768382191658
    num_steps_sampled: 2220000
    num_steps_trained: 2220000
    wait_time_ms: 172.436
  iterations_since_restore: 222
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4092.1933085918427
  time_this_iter_s: 18.647921800613403
  time_total_s: 4092.1933085918427
  timestamp: 1593888551
  timesteps_since_restore: 2220000
  timesteps_this_iter: 10000
  timesteps_total: 2220000
  training_iteration: 222
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4092 s, 222 iter, 2220000 ts, 211 rew

agent-1: 26.0
agent-2: 20.0
agent-3: 22.0
agent-4: 35.0
agent-5: 28.0
agent-6: 23.0
agent-7: 23.0
agent-8: 12.0
agent-9: 11.0
agent-10: 20.0
Sum Reward: 220.0
Avg Reward: 22.0
Min Reward: 11.0
Gini Coefficient: 0.16727272727272727
20:20 Ratio: 2.739130434782609
Max-min Ratio: 3.1818181818181817
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-49-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 211.69
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 222
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.608
    dispatch_time_ms: 29.658
    learner:
      cur_lr: 0.0012121479958295822
      grad_gnorm: 5.868514060974121
      policy_entropy: 179.113037109375
      policy_loss: -5.1125969886779785
      var_gnorm: 51.86712646484375
      vf_explained_var: -0.37356364727020264
      vf_loss: 0.02877660281956196
    num_steps_sampled: 2230000
    num_steps_trained: 2230000
    wait_time_ms: 168.576
  iterations_since_restore: 223
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4111.064940929413
  time_this_iter_s: 18.87163233757019
  time_total_s: 4111.064940929413
  timestamp: 1593888570
  timesteps_since_restore: 2230000
  timesteps_this_iter: 10000
  timesteps_total: 2230000
  training_iteration: 223
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4111 s, 223 iter, 2230000 ts, 212 rew

agent-1: 26.0
agent-2: 23.0
agent-3: 30.0
agent-4: 24.0
agent-5: 12.0
agent-6: 26.0
agent-7: 17.0
agent-8: 29.0
agent-9: 19.0
agent-10: 23.0
Sum Reward: 229.0
Avg Reward: 22.9
Min Reward: 12.0
Gini Coefficient: 0.12707423580786026
20:20 Ratio: 2.0344827586206895
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-49-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 211.83
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 223
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.338
    dispatch_time_ms: 7.212
    learner:
      cur_lr: 0.0012114819837734103
      grad_gnorm: 0.4855823814868927
      policy_entropy: 172.5066375732422
      policy_loss: 0.44878292083740234
      var_gnorm: 51.98469543457031
      vf_explained_var: -0.5794579982757568
      vf_loss: 0.0005392502644099295
    num_steps_sampled: 2240000
    num_steps_trained: 2240000
    wait_time_ms: 169.146
  iterations_since_restore: 224
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4128.999349117279
  time_this_iter_s: 17.93440818786621
  time_total_s: 4128.999349117279
  timestamp: 1593888588
  timesteps_since_restore: 2240000
  timesteps_this_iter: 10000
  timesteps_total: 2240000
  training_iteration: 224
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4128 s, 224 iter, 2240000 ts, 212 rew

agent-1: 23.0
agent-2: 24.0
agent-3: 23.0
agent-4: 28.0
agent-5: 19.0
agent-6: 21.0
agent-7: 16.0
agent-8: 16.0
agent-9: 24.0
agent-10: 18.0
Sum Reward: 212.0
Avg Reward: 21.2
Min Reward: 16.0
Gini Coefficient: 0.09811320754716982
20:20 Ratio: 1.625
Max-min Ratio: 1.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-50-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 211.64
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 224
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.904
    dispatch_time_ms: 6.64
    learner:
      cur_lr: 0.0012108159717172384
      grad_gnorm: 12.908271789550781
      policy_entropy: 170.59646606445312
      policy_loss: -1.3908231258392334
      var_gnorm: 52.116981506347656
      vf_explained_var: 0.7402336001396179
      vf_loss: 0.02015356905758381
    num_steps_sampled: 2250000
    num_steps_trained: 2250000
    wait_time_ms: 165.938
  iterations_since_restore: 225
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4146.928746938705
  time_this_iter_s: 17.92939782142639
  time_total_s: 4146.928746938705
  timestamp: 1593888606
  timesteps_since_restore: 2250000
  timesteps_this_iter: 10000
  timesteps_total: 2250000
  training_iteration: 225
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4146 s, 225 iter, 2250000 ts, 212 rew

agent-1: 30.0
agent-2: 21.0
agent-3: 15.0
agent-4: 25.0
agent-5: 18.0
agent-6: 30.0
agent-7: 21.0
agent-8: 19.0
agent-9: 23.0
agent-10: 17.0
Sum Reward: 219.0
Avg Reward: 21.9
Min Reward: 15.0
Gini Coefficient: 0.12465753424657534
20:20 Ratio: 1.875
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-50-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 211.6
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 225
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.768
    dispatch_time_ms: 6.42
    learner:
      cur_lr: 0.0012101499596610665
      grad_gnorm: 3.2098021507263184
      policy_entropy: 177.9993896484375
      policy_loss: 1.9265413284301758
      var_gnorm: 52.21003723144531
      vf_explained_var: 0.8094301223754883
      vf_loss: 0.021009348332881927
    num_steps_sampled: 2260000
    num_steps_trained: 2260000
    wait_time_ms: 171.258
  iterations_since_restore: 226
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4164.881890296936
  time_this_iter_s: 17.95314335823059
  time_total_s: 4164.881890296936
  timestamp: 1593888624
  timesteps_since_restore: 2260000
  timesteps_this_iter: 10000
  timesteps_total: 2260000
  training_iteration: 226
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4164 s, 226 iter, 2260000 ts, 212 rew

agent-1: 31.0
agent-2: 9.0
agent-3: 25.0
agent-4: 27.0
agent-5: 14.0
agent-6: 25.0
agent-7: 26.0
agent-8: 20.0
agent-9: 12.0
agent-10: 19.0
Sum Reward: 208.0
Avg Reward: 20.8
Min Reward: 9.0
Gini Coefficient: 0.18557692307692308
20:20 Ratio: 2.761904761904762
Max-min Ratio: 3.4444444444444446
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-50-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 211.51
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 226
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.538
    dispatch_time_ms: 6.94
    learner:
      cur_lr: 0.0012094839476048946
      grad_gnorm: 0.5025469064712524
      policy_entropy: 178.36553955078125
      policy_loss: -0.033930256962776184
      var_gnorm: 52.23893737792969
      vf_explained_var: 0.9939664602279663
      vf_loss: 0.00011063666170230135
    num_steps_sampled: 2270000
    num_steps_trained: 2270000
    wait_time_ms: 169.403
  iterations_since_restore: 227
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4182.792186021805
  time_this_iter_s: 17.910295724868774
  time_total_s: 4182.792186021805
  timestamp: 1593888642
  timesteps_since_restore: 2270000
  timesteps_this_iter: 10000
  timesteps_total: 2270000
  training_iteration: 227
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4182 s, 227 iter, 2270000 ts, 212 rew

agent-1: 24.0
agent-2: 14.0
agent-3: 22.0
agent-4: 29.0
agent-5: 19.0
agent-6: 14.0
agent-7: 32.0
agent-8: 21.0
agent-9: 17.0
agent-10: 20.0
Sum Reward: 212.0
Avg Reward: 21.2
Min Reward: 14.0
Gini Coefficient: 0.1471698113207547
20:20 Ratio: 2.1785714285714284
Max-min Ratio: 2.2857142857142856
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-51-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 211.56
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 227
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.492
    dispatch_time_ms: 6.619
    learner:
      cur_lr: 0.0012088180519640446
      grad_gnorm: 4.007479190826416
      policy_entropy: 171.6120147705078
      policy_loss: 1.5564243793487549
      var_gnorm: 52.36876678466797
      vf_explained_var: -1.0
      vf_loss: 0.17175284028053284
    num_steps_sampled: 2280000
    num_steps_trained: 2280000
    wait_time_ms: 166.352
  iterations_since_restore: 228
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4200.606235980988
  time_this_iter_s: 17.81404995918274
  time_total_s: 4200.606235980988
  timestamp: 1593888660
  timesteps_since_restore: 2280000
  timesteps_this_iter: 10000
  timesteps_total: 2280000
  training_iteration: 228
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4200 s, 228 iter, 2280000 ts, 212 rew

agent-1: 16.0
agent-2: 24.0
agent-3: 20.0
agent-4: 16.0
agent-5: 19.0
agent-6: 15.0
agent-7: 30.0
agent-8: 20.0
agent-9: 22.0
agent-10: 20.0
Sum Reward: 202.0
Avg Reward: 20.2
Min Reward: 15.0
Gini Coefficient: 0.11089108910891089
20:20 Ratio: 1.7419354838709677
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-51-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 211.55
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 228
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.356
    dispatch_time_ms: 8.318
    learner:
      cur_lr: 0.0012081520399078727
      grad_gnorm: 1.3516805171966553
      policy_entropy: 156.6986846923828
      policy_loss: -0.6925444602966309
      var_gnorm: 52.47583770751953
      vf_explained_var: 0.8733721971511841
      vf_loss: 0.0019645614083856344
    num_steps_sampled: 2290000
    num_steps_trained: 2290000
    wait_time_ms: 168.997
  iterations_since_restore: 229
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4218.6302580833435
  time_this_iter_s: 18.024022102355957
  time_total_s: 4218.6302580833435
  timestamp: 1593888678
  timesteps_since_restore: 2290000
  timesteps_this_iter: 10000
  timesteps_total: 2290000
  training_iteration: 229
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4218 s, 229 iter, 2290000 ts, 212 rew

agent-1: 10.0
agent-2: 16.0
agent-3: 23.0
agent-4: 27.0
agent-5: 19.0
agent-6: 37.0
agent-7: 27.0
agent-8: 12.0
agent-9: 17.0
agent-10: 19.0
Sum Reward: 207.0
Avg Reward: 20.7
Min Reward: 10.0
Gini Coefficient: 0.2033816425120773
20:20 Ratio: 2.909090909090909
Max-min Ratio: 3.7
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-51-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 211.76
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 229
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.984
    dispatch_time_ms: 6.278
    learner:
      cur_lr: 0.0012074860278517008
      grad_gnorm: 3.414841651916504
      policy_entropy: 175.7086944580078
      policy_loss: 1.9829754829406738
      var_gnorm: 52.545196533203125
      vf_explained_var: 0.4007720351219177
      vf_loss: 0.02199692465364933
    num_steps_sampled: 2300000
    num_steps_trained: 2300000
    wait_time_ms: 175.106
  iterations_since_restore: 230
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4236.577943563461
  time_this_iter_s: 17.947685480117798
  time_total_s: 4236.577943563461
  timestamp: 1593888696
  timesteps_since_restore: 2300000
  timesteps_this_iter: 10000
  timesteps_total: 2300000
  training_iteration: 230
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4236 s, 230 iter, 2300000 ts, 212 rew

agent-1: 18.0
agent-2: 13.0
agent-3: 17.0
agent-4: 24.0
agent-5: 26.0
agent-6: 23.0
agent-7: 22.0
agent-8: 18.0
agent-9: 20.0
agent-10: 21.0
Sum Reward: 202.0
Avg Reward: 20.2
Min Reward: 13.0
Gini Coefficient: 0.100990099009901
20:20 Ratio: 1.6666666666666667
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-51-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 211.73
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 230
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.729
    dispatch_time_ms: 6.219
    learner:
      cur_lr: 0.0012068200157955289
      grad_gnorm: 2.7495458126068115
      policy_entropy: 173.71038818359375
      policy_loss: -0.13142932951450348
      var_gnorm: 52.531742095947266
      vf_explained_var: -1.0
      vf_loss: 0.013755536638200283
    num_steps_sampled: 2310000
    num_steps_trained: 2310000
    wait_time_ms: 171.306
  iterations_since_restore: 231
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4254.3733496665955
  time_this_iter_s: 17.795406103134155
  time_total_s: 4254.3733496665955
  timestamp: 1593888714
  timesteps_since_restore: 2310000
  timesteps_this_iter: 10000
  timesteps_total: 2310000
  training_iteration: 231
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4254 s, 231 iter, 2310000 ts, 212 rew

agent-1: 17.0
agent-2: 17.0
agent-3: 12.0
agent-4: 25.0
agent-5: 28.0
agent-6: 18.0
agent-7: 24.0
agent-8: 21.0
agent-9: 21.0
agent-10: 21.0
Sum Reward: 204.0
Avg Reward: 20.4
Min Reward: 12.0
Gini Coefficient: 0.11960784313725491
20:20 Ratio: 1.8275862068965518
Max-min Ratio: 2.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-52-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 211.45
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 231
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.732
    dispatch_time_ms: 7.419
    learner:
      cur_lr: 0.001206154003739357
      grad_gnorm: 8.126017570495605
      policy_entropy: 168.2882537841797
      policy_loss: 0.9055606722831726
      var_gnorm: 52.86264419555664
      vf_explained_var: -1.0
      vf_loss: 0.041910674422979355
    num_steps_sampled: 2320000
    num_steps_trained: 2320000
    wait_time_ms: 169.811
  iterations_since_restore: 232
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4272.298990011215
  time_this_iter_s: 17.92564034461975
  time_total_s: 4272.298990011215
  timestamp: 1593888732
  timesteps_since_restore: 2320000
  timesteps_this_iter: 10000
  timesteps_total: 2320000
  training_iteration: 232
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4272 s, 232 iter, 2320000 ts, 211 rew

agent-1: 24.0
agent-2: 24.0
agent-3: 23.0
agent-4: 20.0
agent-5: 17.0
agent-6: 30.0
agent-7: 16.0
agent-8: 16.0
agent-9: 31.0
agent-10: 17.0
Sum Reward: 218.0
Avg Reward: 21.8
Min Reward: 16.0
Gini Coefficient: 0.13394495412844037
20:20 Ratio: 1.90625
Max-min Ratio: 1.9375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-52-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 211.56
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 232
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.55
    dispatch_time_ms: 8.356
    learner:
      cur_lr: 0.001205487991683185
      grad_gnorm: 2.701336622238159
      policy_entropy: 172.79904174804688
      policy_loss: -2.305354356765747
      var_gnorm: 52.935428619384766
      vf_explained_var: 0.7002416849136353
      vf_loss: 0.005740950349718332
    num_steps_sampled: 2330000
    num_steps_trained: 2330000
    wait_time_ms: 170.733
  iterations_since_restore: 233
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4290.18399477005
  time_this_iter_s: 17.88500475883484
  time_total_s: 4290.18399477005
  timestamp: 1593888750
  timesteps_since_restore: 2330000
  timesteps_this_iter: 10000
  timesteps_total: 2330000
  training_iteration: 233
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4290 s, 233 iter, 2330000 ts, 212 rew

agent-1: 22.0
agent-2: 27.0
agent-3: 23.0
agent-4: 17.0
agent-5: 10.0
agent-6: 21.0
agent-7: 23.0
agent-8: 16.0
agent-9: 29.0
agent-10: 20.0
Sum Reward: 208.0
Avg Reward: 20.8
Min Reward: 10.0
Gini Coefficient: 0.13846153846153847
20:20 Ratio: 2.1538461538461537
Max-min Ratio: 2.9
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-52-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 211.42
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 233
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.812
    dispatch_time_ms: 5.547
    learner:
      cur_lr: 0.0012048219796270132
      grad_gnorm: 7.510889053344727
      policy_entropy: 187.16848754882812
      policy_loss: -0.8153990507125854
      var_gnorm: 53.00012969970703
      vf_explained_var: -1.0
      vf_loss: 0.016474807634949684
    num_steps_sampled: 2340000
    num_steps_trained: 2340000
    wait_time_ms: 172.872
  iterations_since_restore: 234
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4308.03870677948
  time_this_iter_s: 17.85471200942993
  time_total_s: 4308.03870677948
  timestamp: 1593888768
  timesteps_since_restore: 2340000
  timesteps_this_iter: 10000
  timesteps_total: 2340000
  training_iteration: 234
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4308 s, 234 iter, 2340000 ts, 211 rew

agent-1: 16.0
agent-2: 29.0
agent-3: 28.0
agent-4: 18.0
agent-5: 21.0
agent-6: 16.0
agent-7: 12.0
agent-8: 16.0
agent-9: 28.0
agent-10: 20.0
Sum Reward: 204.0
Avg Reward: 20.4
Min Reward: 12.0
Gini Coefficient: 0.153921568627451
20:20 Ratio: 2.0357142857142856
Max-min Ratio: 2.4166666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-53-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 211.18
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 234
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.709
    dispatch_time_ms: 32.326
    learner:
      cur_lr: 0.0012041559675708413
      grad_gnorm: 3.2046635150909424
      policy_entropy: 162.59800720214844
      policy_loss: -2.345285415649414
      var_gnorm: 53.129756927490234
      vf_explained_var: -1.0
      vf_loss: 0.00834363978356123
    num_steps_sampled: 2350000
    num_steps_trained: 2350000
    wait_time_ms: 170.09
  iterations_since_restore: 235
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4326.724542140961
  time_this_iter_s: 18.685835361480713
  time_total_s: 4326.724542140961
  timestamp: 1593888787
  timesteps_since_restore: 2350000
  timesteps_this_iter: 10000
  timesteps_total: 2350000
  training_iteration: 235
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4326 s, 235 iter, 2350000 ts, 211 rew

agent-1: 13.0
agent-2: 21.0
agent-3: 27.0
agent-4: 24.0
agent-5: 25.0
agent-6: 23.0
agent-7: 22.0
agent-8: 16.0
agent-9: 27.0
agent-10: 16.0
Sum Reward: 214.0
Avg Reward: 21.4
Min Reward: 13.0
Gini Coefficient: 0.1205607476635514
20:20 Ratio: 1.8620689655172413
Max-min Ratio: 2.076923076923077
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-53-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 238.0
  episode_reward_mean: 210.77
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 235
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.824
    dispatch_time_ms: 22.002
    learner:
      cur_lr: 0.0012034899555146694
      grad_gnorm: 0.8083162307739258
      policy_entropy: 180.52301025390625
      policy_loss: -0.6752189993858337
      var_gnorm: 53.38176345825195
      vf_explained_var: -1.0
      vf_loss: 0.0027530393563210964
    num_steps_sampled: 2360000
    num_steps_trained: 2360000
    wait_time_ms: 163.601
  iterations_since_restore: 236
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4345.539627790451
  time_this_iter_s: 18.815085649490356
  time_total_s: 4345.539627790451
  timestamp: 1593888805
  timesteps_since_restore: 2360000
  timesteps_this_iter: 10000
  timesteps_total: 2360000
  training_iteration: 236
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4345 s, 236 iter, 2360000 ts, 211 rew

agent-1: 27.0
agent-2: 27.0
agent-3: 19.0
agent-4: 15.0
agent-5: 23.0
agent-6: 20.0
agent-7: 22.0
agent-8: 27.0
agent-9: 21.0
agent-10: 19.0
Sum Reward: 220.0
Avg Reward: 22.0
Min Reward: 15.0
Gini Coefficient: 0.09727272727272727
20:20 Ratio: 1.588235294117647
Max-min Ratio: 1.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-53-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 238.0
  episode_reward_mean: 210.83
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 236
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.78
    dispatch_time_ms: 26.76
    learner:
      cur_lr: 0.0012028239434584975
      grad_gnorm: 3.123448610305786
      policy_entropy: 183.42662048339844
      policy_loss: -5.786988258361816
      var_gnorm: 53.48521423339844
      vf_explained_var: -0.13063526153564453
      vf_loss: 0.009156201966106892
    num_steps_sampled: 2370000
    num_steps_trained: 2370000
    wait_time_ms: 154.625
  iterations_since_restore: 237
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4364.314205169678
  time_this_iter_s: 18.774577379226685
  time_total_s: 4364.314205169678
  timestamp: 1593888824
  timesteps_since_restore: 2370000
  timesteps_this_iter: 10000
  timesteps_total: 2370000
  training_iteration: 237
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4364 s, 237 iter, 2370000 ts, 211 rew

agent-1: 23.0
agent-2: 20.0
agent-3: 20.0
agent-4: 29.0
agent-5: 22.0
agent-6: 22.0
agent-7: 26.0
agent-8: 10.0
agent-9: 23.0
agent-10: 16.0
Sum Reward: 211.0
Avg Reward: 21.1
Min Reward: 10.0
Gini Coefficient: 0.12559241706161137
20:20 Ratio: 2.1153846153846154
Max-min Ratio: 2.9
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-54-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 238.0
  episode_reward_mean: 210.82
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 237
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.259
    dispatch_time_ms: 27.733
    learner:
      cur_lr: 0.0012021580478176475
      grad_gnorm: 7.367431163787842
      policy_entropy: 180.03274536132812
      policy_loss: -1.9413812160491943
      var_gnorm: 53.60625457763672
      vf_explained_var: 0.526145339012146
      vf_loss: 0.0010818131268024445
    num_steps_sampled: 2380000
    num_steps_trained: 2380000
    wait_time_ms: 159.738
  iterations_since_restore: 238
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4382.994484901428
  time_this_iter_s: 18.68027973175049
  time_total_s: 4382.994484901428
  timestamp: 1593888843
  timesteps_since_restore: 2380000
  timesteps_this_iter: 10000
  timesteps_total: 2380000
  training_iteration: 238
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4382 s, 238 iter, 2380000 ts, 211 rew

agent-1: 22.0
agent-2: 23.0
agent-3: 24.0
agent-4: 9.0
agent-5: 25.0
agent-6: 25.0
agent-7: 26.0
agent-8: 23.0
agent-9: 19.0
agent-10: 24.0
Sum Reward: 220.0
Avg Reward: 22.0
Min Reward: 9.0
Gini Coefficient: 0.09727272727272727
20:20 Ratio: 1.8214285714285714
Max-min Ratio: 2.888888888888889
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-54-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 238.0
  episode_reward_mean: 210.83
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 238
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.596
    dispatch_time_ms: 28.596
    learner:
      cur_lr: 0.0012014920357614756
      grad_gnorm: 1.5002861022949219
      policy_entropy: 178.3911590576172
      policy_loss: -2.608774185180664
      var_gnorm: 53.75288772583008
      vf_explained_var: -0.07238197326660156
      vf_loss: 0.0014070930192247033
    num_steps_sampled: 2390000
    num_steps_trained: 2390000
    wait_time_ms: 155.275
  iterations_since_restore: 239
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4401.641640663147
  time_this_iter_s: 18.64715576171875
  time_total_s: 4401.641640663147
  timestamp: 1593888862
  timesteps_since_restore: 2390000
  timesteps_this_iter: 10000
  timesteps_total: 2390000
  training_iteration: 239
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4401 s, 239 iter, 2390000 ts, 211 rew

agent-1: 22.0
agent-2: 15.0
agent-3: 27.0
agent-4: 24.0
agent-5: 26.0
agent-6: 22.0
agent-7: 16.0
agent-8: 15.0
agent-9: 16.0
agent-10: 14.0
Sum Reward: 197.0
Avg Reward: 19.7
Min Reward: 14.0
Gini Coefficient: 0.133502538071066
20:20 Ratio: 1.8275862068965518
Max-min Ratio: 1.9285714285714286
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-54-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 238.0
  episode_reward_mean: 210.45
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 239
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.881
    dispatch_time_ms: 25.613
    learner:
      cur_lr: 0.0012008260237053037
      grad_gnorm: 4.608874320983887
      policy_entropy: 176.37355041503906
      policy_loss: -2.1278140544891357
      var_gnorm: 53.89357376098633
      vf_explained_var: -0.5279427766799927
      vf_loss: 0.017879171296954155
    num_steps_sampled: 2400000
    num_steps_trained: 2400000
    wait_time_ms: 167.027
  iterations_since_restore: 240
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4420.418421506882
  time_this_iter_s: 18.77678084373474
  time_total_s: 4420.418421506882
  timestamp: 1593888880
  timesteps_since_restore: 2400000
  timesteps_this_iter: 10000
  timesteps_total: 2400000
  training_iteration: 240
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4420 s, 240 iter, 2400000 ts, 210 rew

agent-1: 12.0
agent-2: 15.0
agent-3: 19.0
agent-4: 26.0
agent-5: 24.0
agent-6: 18.0
agent-7: 28.0
agent-8: 24.0
agent-9: 21.0
agent-10: 22.0
Sum Reward: 209.0
Avg Reward: 20.9
Min Reward: 12.0
Gini Coefficient: 0.1277511961722488
20:20 Ratio: 2.0
Max-min Ratio: 2.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-54-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 238.0
  episode_reward_mean: 210.34
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 240
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.093
    dispatch_time_ms: 9.11
    learner:
      cur_lr: 0.0012001600116491318
      grad_gnorm: 5.59210729598999
      policy_entropy: 183.99851989746094
      policy_loss: -2.5034148693084717
      var_gnorm: 53.90251159667969
      vf_explained_var: 0.6887391805648804
      vf_loss: 0.04323595017194748
    num_steps_sampled: 2410000
    num_steps_trained: 2410000
    wait_time_ms: 170.265
  iterations_since_restore: 241
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4438.756098747253
  time_this_iter_s: 18.337677240371704
  time_total_s: 4438.756098747253
  timestamp: 1593888899
  timesteps_since_restore: 2410000
  timesteps_this_iter: 10000
  timesteps_total: 2410000
  training_iteration: 241
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4438 s, 241 iter, 2410000 ts, 210 rew

agent-1: 21.0
agent-2: 21.0
agent-3: 21.0
agent-4: 17.0
agent-5: 13.0
agent-6: 16.0
agent-7: 24.0
agent-8: 19.0
agent-9: 22.0
agent-10: 16.0
Sum Reward: 190.0
Avg Reward: 19.0
Min Reward: 13.0
Gini Coefficient: 0.09473684210526316
20:20 Ratio: 1.5862068965517242
Max-min Ratio: 1.8461538461538463
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-55-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 238.0
  episode_reward_mean: 210.04
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 241
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.491
    dispatch_time_ms: 8.566
    learner:
      cur_lr: 0.0011994939995929599
      grad_gnorm: 6.635283470153809
      policy_entropy: 176.87307739257812
      policy_loss: -2.077975273132324
      var_gnorm: 53.90073776245117
      vf_explained_var: -1.0
      vf_loss: 0.022956984117627144
    num_steps_sampled: 2420000
    num_steps_trained: 2420000
    wait_time_ms: 170.13
  iterations_since_restore: 242
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4456.486162662506
  time_this_iter_s: 17.730063915252686
  time_total_s: 4456.486162662506
  timestamp: 1593888917
  timesteps_since_restore: 2420000
  timesteps_this_iter: 10000
  timesteps_total: 2420000
  training_iteration: 242
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4456 s, 242 iter, 2420000 ts, 210 rew

agent-1: 22.0
agent-2: 27.0
agent-3: 20.0
agent-4: 20.0
agent-5: 16.0
agent-6: 21.0
agent-7: 27.0
agent-8: 23.0
agent-9: 19.0
agent-10: 17.0
Sum Reward: 212.0
Avg Reward: 21.2
Min Reward: 16.0
Gini Coefficient: 0.09245283018867924
20:20 Ratio: 1.6363636363636365
Max-min Ratio: 1.6875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-55-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 238.0
  episode_reward_mean: 210.01
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 242
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.919
    dispatch_time_ms: 6.964
    learner:
      cur_lr: 0.001198827987536788
      grad_gnorm: 1.0672353506088257
      policy_entropy: 175.71420288085938
      policy_loss: -0.02001848816871643
      var_gnorm: 53.99705123901367
      vf_explained_var: 0.45423972606658936
      vf_loss: 0.0030653546564280987
    num_steps_sampled: 2430000
    num_steps_trained: 2430000
    wait_time_ms: 168.124
  iterations_since_restore: 243
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4474.421172618866
  time_this_iter_s: 17.935009956359863
  time_total_s: 4474.421172618866
  timestamp: 1593888935
  timesteps_since_restore: 2430000
  timesteps_this_iter: 10000
  timesteps_total: 2430000
  training_iteration: 243
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4474 s, 243 iter, 2430000 ts, 210 rew

agent-1: 19.0
agent-2: 28.0
agent-3: 25.0
agent-4: 27.0
agent-5: 27.0
agent-6: 12.0
agent-7: 24.0
agent-8: 26.0
agent-9: 28.0
agent-10: 26.0
Sum Reward: 242.0
Avg Reward: 24.2
Min Reward: 12.0
Gini Coefficient: 0.09421487603305785
20:20 Ratio: 1.8064516129032258
Max-min Ratio: 2.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-55-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 242.0
  episode_reward_mean: 210.36
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 243
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.638
    dispatch_time_ms: 8.817
    learner:
      cur_lr: 0.001198161975480616
      grad_gnorm: 2.599863290786743
      policy_entropy: 181.59210205078125
      policy_loss: -1.4918471574783325
      var_gnorm: 54.14875793457031
      vf_explained_var: 0.12834495306015015
      vf_loss: 0.005173207726329565
    num_steps_sampled: 2440000
    num_steps_trained: 2440000
    wait_time_ms: 169.711
  iterations_since_restore: 244
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4492.207775115967
  time_this_iter_s: 17.78660249710083
  time_total_s: 4492.207775115967
  timestamp: 1593888952
  timesteps_since_restore: 2440000
  timesteps_this_iter: 10000
  timesteps_total: 2440000
  training_iteration: 244
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4492 s, 244 iter, 2440000 ts, 210 rew

agent-1: 27.0
agent-2: 34.0
agent-3: 16.0
agent-4: 18.0
agent-5: 22.0
agent-6: 25.0
agent-7: 30.0
agent-8: 15.0
agent-9: 15.0
agent-10: 18.0
Sum Reward: 220.0
Avg Reward: 22.0
Min Reward: 15.0
Gini Coefficient: 0.1618181818181818
20:20 Ratio: 2.1333333333333333
Max-min Ratio: 2.2666666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-56-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 242.0
  episode_reward_mean: 210.52
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 244
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.506
    dispatch_time_ms: 7.35
    learner:
      cur_lr: 0.0011974959634244442
      grad_gnorm: 0.8695323467254639
      policy_entropy: 172.4862518310547
      policy_loss: 0.0913286805152893
      var_gnorm: 54.20720291137695
      vf_explained_var: -0.48564612865448
      vf_loss: 0.0009842708241194487
    num_steps_sampled: 2450000
    num_steps_trained: 2450000
    wait_time_ms: 169.045
  iterations_since_restore: 245
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4510.171943187714
  time_this_iter_s: 17.964168071746826
  time_total_s: 4510.171943187714
  timestamp: 1593888970
  timesteps_since_restore: 2450000
  timesteps_this_iter: 10000
  timesteps_total: 2450000
  training_iteration: 245
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4510 s, 245 iter, 2450000 ts, 211 rew

agent-1: 24.0
agent-2: 19.0
agent-3: 17.0
agent-4: 17.0
agent-5: 21.0
agent-6: 24.0
agent-7: 17.0
agent-8: 17.0
agent-9: 24.0
agent-10: 28.0
Sum Reward: 208.0
Avg Reward: 20.8
Min Reward: 17.0
Gini Coefficient: 0.09903846153846153
20:20 Ratio: 1.5294117647058822
Max-min Ratio: 1.6470588235294117
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-56-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 242.0
  episode_reward_mean: 210.29
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 245
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.843
    dispatch_time_ms: 6.057
    learner:
      cur_lr: 0.0011968299513682723
      grad_gnorm: 1.6905262470245361
      policy_entropy: 164.28614807128906
      policy_loss: 0.18372565507888794
      var_gnorm: 54.223514556884766
      vf_explained_var: -1.0
      vf_loss: 0.0024737389758229256
    num_steps_sampled: 2460000
    num_steps_trained: 2460000
    wait_time_ms: 176.662
  iterations_since_restore: 246
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4528.44565486908
  time_this_iter_s: 18.273711681365967
  time_total_s: 4528.44565486908
  timestamp: 1593888989
  timesteps_since_restore: 2460000
  timesteps_this_iter: 10000
  timesteps_total: 2460000
  training_iteration: 246
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4528 s, 246 iter, 2460000 ts, 210 rew

agent-1: 20.0
agent-2: 22.0
agent-3: 14.0
agent-4: 23.0
agent-5: 18.0
agent-6: 20.0
agent-7: 23.0
agent-8: 29.0
agent-9: 19.0
agent-10: 17.0
Sum Reward: 205.0
Avg Reward: 20.5
Min Reward: 14.0
Gini Coefficient: 0.10292682926829268
20:20 Ratio: 1.6774193548387097
Max-min Ratio: 2.0714285714285716
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-56-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 242.0
  episode_reward_mean: 210.13
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 246
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.789
    dispatch_time_ms: 5.84
    learner:
      cur_lr: 0.0011961640557274222
      grad_gnorm: 1.9470981359481812
      policy_entropy: 157.14328002929688
      policy_loss: -1.4561512470245361
      var_gnorm: 54.391780853271484
      vf_explained_var: 0.941240668296814
      vf_loss: 0.002724675927311182
    num_steps_sampled: 2470000
    num_steps_trained: 2470000
    wait_time_ms: 168.712
  iterations_since_restore: 247
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4546.211682796478
  time_this_iter_s: 17.76602792739868
  time_total_s: 4546.211682796478
  timestamp: 1593889007
  timesteps_since_restore: 2470000
  timesteps_this_iter: 10000
  timesteps_total: 2470000
  training_iteration: 247
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4546 s, 247 iter, 2470000 ts, 210 rew

agent-1: 19.0
agent-2: 23.0
agent-3: 17.0
agent-4: 29.0
agent-5: 15.0
agent-6: 14.0
agent-7: 17.0
agent-8: 23.0
agent-9: 17.0
agent-10: 23.0
Sum Reward: 197.0
Avg Reward: 19.7
Min Reward: 14.0
Gini Coefficient: 0.12233502538071066
20:20 Ratio: 1.793103448275862
Max-min Ratio: 2.0714285714285716
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-57-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 242.0
  episode_reward_mean: 209.97
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 247
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.906
    dispatch_time_ms: 7.394
    learner:
      cur_lr: 0.0011954980436712503
      grad_gnorm: 6.603663444519043
      policy_entropy: 167.0196075439453
      policy_loss: 2.2685725688934326
      var_gnorm: 54.421966552734375
      vf_explained_var: 0.02620077133178711
      vf_loss: 0.3059154450893402
    num_steps_sampled: 2480000
    num_steps_trained: 2480000
    wait_time_ms: 168.089
  iterations_since_restore: 248
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4564.05176448822
  time_this_iter_s: 17.840081691741943
  time_total_s: 4564.05176448822
  timestamp: 1593889024
  timesteps_since_restore: 2480000
  timesteps_this_iter: 10000
  timesteps_total: 2480000
  training_iteration: 248
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4564 s, 248 iter, 2480000 ts, 210 rew

agent-1: 17.0
agent-2: 23.0
agent-3: 23.0
agent-4: 21.0
agent-5: 11.0
agent-6: 15.0
agent-7: 16.0
agent-8: 29.0
agent-9: 14.0
agent-10: 19.0
Sum Reward: 188.0
Avg Reward: 18.8
Min Reward: 11.0
Gini Coefficient: 0.15
20:20 Ratio: 2.08
Max-min Ratio: 2.6363636363636362
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-57-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 242.0
  episode_reward_mean: 209.79
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 248
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.431
    dispatch_time_ms: 9.361
    learner:
      cur_lr: 0.0011948320316150784
      grad_gnorm: 10.768852233886719
      policy_entropy: 129.0489959716797
      policy_loss: -0.060065846890211105
      var_gnorm: 54.47726058959961
      vf_explained_var: 0.9511687159538269
      vf_loss: 0.002724073128774762
    num_steps_sampled: 2490000
    num_steps_trained: 2490000
    wait_time_ms: 166.987
  iterations_since_restore: 249
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4581.793020486832
  time_this_iter_s: 17.74125599861145
  time_total_s: 4581.793020486832
  timestamp: 1593889042
  timesteps_since_restore: 2490000
  timesteps_this_iter: 10000
  timesteps_total: 2490000
  training_iteration: 249
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4581 s, 249 iter, 2490000 ts, 210 rew

agent-1: 15.0
agent-2: 22.0
agent-3: 12.0
agent-4: 22.0
agent-5: 18.0
agent-6: 25.0
agent-7: 16.0
agent-8: 22.0
agent-9: 19.0
agent-10: 24.0
Sum Reward: 195.0
Avg Reward: 19.5
Min Reward: 12.0
Gini Coefficient: 0.11538461538461539
20:20 Ratio: 1.8148148148148149
Max-min Ratio: 2.0833333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-57-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 242.0
  episode_reward_mean: 209.53
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 249
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.801
    dispatch_time_ms: 6.542
    learner:
      cur_lr: 0.0011941660195589066
      grad_gnorm: 1.1677993535995483
      policy_entropy: 167.6068115234375
      policy_loss: -1.4183077812194824
      var_gnorm: 54.68031311035156
      vf_explained_var: 0.7501351833343506
      vf_loss: 0.0003397587570361793
    num_steps_sampled: 2500000
    num_steps_trained: 2500000
    wait_time_ms: 171.804
  iterations_since_restore: 250
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4599.393348455429
  time_this_iter_s: 17.600327968597412
  time_total_s: 4599.393348455429
  timestamp: 1593889060
  timesteps_since_restore: 2500000
  timesteps_this_iter: 10000
  timesteps_total: 2500000
  training_iteration: 250
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4599 s, 250 iter, 2500000 ts, 210 rew

agent-1: 27.0
agent-2: 31.0
agent-3: 9.0
agent-4: 23.0
agent-5: 26.0
agent-6: 26.0
agent-7: 20.0
agent-8: 22.0
agent-9: 32.0
agent-10: 15.0
Sum Reward: 231.0
Avg Reward: 23.1
Min Reward: 9.0
Gini Coefficient: 0.15974025974025974
20:20 Ratio: 2.625
Max-min Ratio: 3.5555555555555554
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-57-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 242.0
  episode_reward_mean: 209.78
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 250
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.752
    dispatch_time_ms: 7.236
    learner:
      cur_lr: 0.0011935000075027347
      grad_gnorm: 8.852717399597168
      policy_entropy: 173.29783630371094
      policy_loss: -1.281568169593811
      var_gnorm: 54.65256118774414
      vf_explained_var: -1.0
      vf_loss: 0.025533247739076614
    num_steps_sampled: 2510000
    num_steps_trained: 2510000
    wait_time_ms: 170.579
  iterations_since_restore: 251
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4617.340307235718
  time_this_iter_s: 17.946958780288696
  time_total_s: 4617.340307235718
  timestamp: 1593889078
  timesteps_since_restore: 2510000
  timesteps_this_iter: 10000
  timesteps_total: 2510000
  training_iteration: 251
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4617 s, 251 iter, 2510000 ts, 210 rew

agent-1: 17.0
agent-2: 26.0
agent-3: 19.0
agent-4: 34.0
agent-5: 22.0
agent-6: 16.0
agent-7: 23.0
agent-8: 25.0
agent-9: 14.0
agent-10: 21.0
Sum Reward: 217.0
Avg Reward: 21.7
Min Reward: 14.0
Gini Coefficient: 0.13963133640552997
20:20 Ratio: 2.0
Max-min Ratio: 2.4285714285714284
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-58-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 242.0
  episode_reward_mean: 210.01
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 251
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 4.397
    dispatch_time_ms: 8.246
    learner:
      cur_lr: 0.0011928339954465628
      grad_gnorm: 0.6435606479644775
      policy_entropy: 177.69451904296875
      policy_loss: -0.2316739410161972
      var_gnorm: 54.68423080444336
      vf_explained_var: -1.0
      vf_loss: 0.002893500728532672
    num_steps_sampled: 2520000
    num_steps_trained: 2520000
    wait_time_ms: 165.149
  iterations_since_restore: 252
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4634.9992072582245
  time_this_iter_s: 17.658900022506714
  time_total_s: 4634.9992072582245
  timestamp: 1593889096
  timesteps_since_restore: 2520000
  timesteps_this_iter: 10000
  timesteps_total: 2520000
  training_iteration: 252
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4634 s, 252 iter, 2520000 ts, 210 rew

agent-1: 32.0
agent-2: 8.0
agent-3: 16.0
agent-4: 14.0
agent-5: 31.0
agent-6: 19.0
agent-7: 17.0
agent-8: 17.0
agent-9: 24.0
agent-10: 21.0
Sum Reward: 199.0
Avg Reward: 19.9
Min Reward: 8.0
Gini Coefficient: 0.19547738693467337
20:20 Ratio: 2.8636363636363638
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-58-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 242.0
  episode_reward_mean: 209.81
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 252
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.817
    dispatch_time_ms: 6.262
    learner:
      cur_lr: 0.0011921679833903909
      grad_gnorm: 0.5987462997436523
      policy_entropy: 169.3435516357422
      policy_loss: -0.02146291732788086
      var_gnorm: 54.808746337890625
      vf_explained_var: -1.0
      vf_loss: 0.004007446579635143
    num_steps_sampled: 2530000
    num_steps_trained: 2530000
    wait_time_ms: 171.142
  iterations_since_restore: 253
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4652.919414997101
  time_this_iter_s: 17.920207738876343
  time_total_s: 4652.919414997101
  timestamp: 1593889114
  timesteps_since_restore: 2530000
  timesteps_this_iter: 10000
  timesteps_total: 2530000
  training_iteration: 253
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4652 s, 253 iter, 2530000 ts, 210 rew

agent-1: 17.0
agent-2: 21.0
agent-3: 21.0
agent-4: 15.0
agent-5: 28.0
agent-6: 17.0
agent-7: 25.0
agent-8: 21.0
agent-9: 22.0
agent-10: 16.0
Sum Reward: 203.0
Avg Reward: 20.3
Min Reward: 15.0
Gini Coefficient: 0.10689655172413794
20:20 Ratio: 1.7096774193548387
Max-min Ratio: 1.8666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-58-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 242.0
  episode_reward_mean: 209.46
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 253
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 4.549
    dispatch_time_ms: 9.773
    learner:
      cur_lr: 0.001191501971334219
      grad_gnorm: 4.4026970863342285
      policy_entropy: 157.10536193847656
      policy_loss: -1.6722004413604736
      var_gnorm: 54.85881042480469
      vf_explained_var: -1.0
      vf_loss: 0.022167937830090523
    num_steps_sampled: 2540000
    num_steps_trained: 2540000
    wait_time_ms: 167.7
  iterations_since_restore: 254
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4670.720789194107
  time_this_iter_s: 17.801374197006226
  time_total_s: 4670.720789194107
  timestamp: 1593889131
  timesteps_since_restore: 2540000
  timesteps_this_iter: 10000
  timesteps_total: 2540000
  training_iteration: 254
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4670 s, 254 iter, 2540000 ts, 209 rew

agent-1: 21.0
agent-2: 20.0
agent-3: 22.0
agent-4: 22.0
agent-5: 6.0
agent-6: 19.0
agent-7: 20.0
agent-8: 29.0
agent-9: 21.0
agent-10: 26.0
Sum Reward: 206.0
Avg Reward: 20.6
Min Reward: 6.0
Gini Coefficient: 0.13203883495145632
20:20 Ratio: 2.2
Max-min Ratio: 4.833333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-59-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 242.0
  episode_reward_mean: 209.55
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 254
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.83
    dispatch_time_ms: 7.798
    learner:
      cur_lr: 0.001190835959278047
      grad_gnorm: 1.602108120918274
      policy_entropy: 165.7334747314453
      policy_loss: 0.5545840859413147
      var_gnorm: 55.03556823730469
      vf_explained_var: -1.0
      vf_loss: 0.002873761113733053
    num_steps_sampled: 2550000
    num_steps_trained: 2550000
    wait_time_ms: 174.781
  iterations_since_restore: 255
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4688.716662168503
  time_this_iter_s: 17.995872974395752
  time_total_s: 4688.716662168503
  timestamp: 1593889149
  timesteps_since_restore: 2550000
  timesteps_this_iter: 10000
  timesteps_total: 2550000
  training_iteration: 255
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4688 s, 255 iter, 2550000 ts, 210 rew

agent-1: 18.0
agent-2: 25.0
agent-3: 18.0
agent-4: 14.0
agent-5: 24.0
agent-6: 17.0
agent-7: 12.0
agent-8: 15.0
agent-9: 24.0
agent-10: 23.0
Sum Reward: 190.0
Avg Reward: 19.0
Min Reward: 12.0
Gini Coefficient: 0.13157894736842105
20:20 Ratio: 1.8846153846153846
Max-min Ratio: 2.0833333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-59-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 242.0
  episode_reward_mean: 209.34
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 255
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.798
    dispatch_time_ms: 6.311
    learner:
      cur_lr: 0.0011901699472218752
      grad_gnorm: 3.3771326541900635
      policy_entropy: 163.37615966796875
      policy_loss: -0.4657403528690338
      var_gnorm: 55.067909240722656
      vf_explained_var: -1.0
      vf_loss: 0.024359021335840225
    num_steps_sampled: 2560000
    num_steps_trained: 2560000
    wait_time_ms: 172.114
  iterations_since_restore: 256
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4706.475860595703
  time_this_iter_s: 17.759198427200317
  time_total_s: 4706.475860595703
  timestamp: 1593889167
  timesteps_since_restore: 2560000
  timesteps_this_iter: 10000
  timesteps_total: 2560000
  training_iteration: 256
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4706 s, 256 iter, 2560000 ts, 209 rew

agent-1: 21.0
agent-2: 24.0
agent-3: 18.0
agent-4: 21.0
agent-5: 25.0
agent-6: 21.0
agent-7: 14.0
agent-8: 11.0
agent-9: 23.0
agent-10: 18.0
Sum Reward: 196.0
Avg Reward: 19.6
Min Reward: 11.0
Gini Coefficient: 0.11734693877551021
20:20 Ratio: 1.96
Max-min Ratio: 2.272727272727273
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-59-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 242.0
  episode_reward_mean: 209.13
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 256
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.023
    dispatch_time_ms: 6.534
    learner:
      cur_lr: 0.0011895040515810251
      grad_gnorm: 3.3812766075134277
      policy_entropy: 169.45606994628906
      policy_loss: -2.9449565410614014
      var_gnorm: 55.18213653564453
      vf_explained_var: -1.0
      vf_loss: 0.00798828061670065
    num_steps_sampled: 2570000
    num_steps_trained: 2570000
    wait_time_ms: 169.451
  iterations_since_restore: 257
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4724.060837030411
  time_this_iter_s: 17.58497643470764
  time_total_s: 4724.060837030411
  timestamp: 1593889185
  timesteps_since_restore: 2570000
  timesteps_this_iter: 10000
  timesteps_total: 2570000
  training_iteration: 257
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4724 s, 257 iter, 2570000 ts, 209 rew

agent-1: 16.0
agent-2: 25.0
agent-3: 22.0
agent-4: 26.0
agent-5: 21.0
agent-6: 20.0
agent-7: 21.0
agent-8: 27.0
agent-9: 20.0
agent-10: 13.0
Sum Reward: 211.0
Avg Reward: 21.1
Min Reward: 13.0
Gini Coefficient: 0.10758293838862559
20:20 Ratio: 1.8275862068965518
Max-min Ratio: 2.076923076923077
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-00-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 242.0
  episode_reward_mean: 208.99
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 257
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 5.036
    dispatch_time_ms: 6.502
    learner:
      cur_lr: 0.0011888380395248532
      grad_gnorm: 0.2746463418006897
      policy_entropy: 171.1539764404297
      policy_loss: 0.10210585594177246
      var_gnorm: 55.31595230102539
      vf_explained_var: -1.0
      vf_loss: 0.00026678229914978147
    num_steps_sampled: 2580000
    num_steps_trained: 2580000
    wait_time_ms: 168.316
  iterations_since_restore: 258
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4741.892982244492
  time_this_iter_s: 17.83214521408081
  time_total_s: 4741.892982244492
  timestamp: 1593889203
  timesteps_since_restore: 2580000
  timesteps_this_iter: 10000
  timesteps_total: 2580000
  training_iteration: 258
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4741 s, 258 iter, 2580000 ts, 209 rew

agent-1: 27.0
agent-2: 24.0
agent-3: 32.0
agent-4: 24.0
agent-5: 29.0
agent-6: 19.0
agent-7: 34.0
agent-8: 29.0
agent-9: 29.0
agent-10: 27.0
Sum Reward: 274.0
Avg Reward: 27.4
Min Reward: 19.0
Gini Coefficient: 0.08175182481751825
20:20 Ratio: 1.5348837209302326
Max-min Ratio: 1.7894736842105263
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-00-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 209.53
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 258
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.913
    dispatch_time_ms: 6.425
    learner:
      cur_lr: 0.0011881720274686813
      grad_gnorm: 2.0283381938934326
      policy_entropy: 150.49603271484375
      policy_loss: 1.1651959419250488
      var_gnorm: 55.53412628173828
      vf_explained_var: 0.9948076605796814
      vf_loss: 0.006096040830016136
    num_steps_sampled: 2590000
    num_steps_trained: 2590000
    wait_time_ms: 167.844
  iterations_since_restore: 259
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4759.633161067963
  time_this_iter_s: 17.74017882347107
  time_total_s: 4759.633161067963
  timestamp: 1593889220
  timesteps_since_restore: 2590000
  timesteps_this_iter: 10000
  timesteps_total: 2590000
  training_iteration: 259
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4759 s, 259 iter, 2590000 ts, 210 rew

agent-1: 23.0
agent-2: 25.0
agent-3: 23.0
agent-4: 28.0
agent-5: 31.0
agent-6: 25.0
agent-7: 29.0
agent-8: 9.0
agent-9: 21.0
agent-10: 26.0
Sum Reward: 240.0
Avg Reward: 24.0
Min Reward: 9.0
Gini Coefficient: 0.12
20:20 Ratio: 2.0
Max-min Ratio: 3.4444444444444446
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-00-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 209.79
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 259
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.512
    dispatch_time_ms: 7.962
    learner:
      cur_lr: 0.0011875060154125094
      grad_gnorm: 3.207672119140625
      policy_entropy: 169.55361938476562
      policy_loss: -1.6792430877685547
      var_gnorm: 55.608489990234375
      vf_explained_var: 0.9932241439819336
      vf_loss: 0.010041817091405392
    num_steps_sampled: 2600000
    num_steps_trained: 2600000
    wait_time_ms: 169.093
  iterations_since_restore: 260
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4777.531929016113
  time_this_iter_s: 17.898767948150635
  time_total_s: 4777.531929016113
  timestamp: 1593889238
  timesteps_since_restore: 2600000
  timesteps_this_iter: 10000
  timesteps_total: 2600000
  training_iteration: 260
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4777 s, 260 iter, 2600000 ts, 210 rew

agent-1: 21.0
agent-2: 16.0
agent-3: 23.0
agent-4: 27.0
agent-5: 16.0
agent-6: 16.0
agent-7: 31.0
agent-8: 27.0
agent-9: 17.0
agent-10: 21.0
Sum Reward: 215.0
Avg Reward: 21.5
Min Reward: 16.0
Gini Coefficient: 0.1325581395348837
20:20 Ratio: 1.8125
Max-min Ratio: 1.9375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-00-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 209.81
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 260
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.212
    dispatch_time_ms: 8.806
    learner:
      cur_lr: 0.0011868400033563375
      grad_gnorm: 0.7895199656486511
      policy_entropy: 176.35841369628906
      policy_loss: 0.016549725085496902
      var_gnorm: 55.77312469482422
      vf_explained_var: -1.0
      vf_loss: 0.005011772736907005
    num_steps_sampled: 2610000
    num_steps_trained: 2610000
    wait_time_ms: 169.778
  iterations_since_restore: 261
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4795.111464500427
  time_this_iter_s: 17.579535484313965
  time_total_s: 4795.111464500427
  timestamp: 1593889256
  timesteps_since_restore: 2610000
  timesteps_this_iter: 10000
  timesteps_total: 2610000
  training_iteration: 261
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4795 s, 261 iter, 2610000 ts, 210 rew

agent-1: 29.0
agent-2: 28.0
agent-3: 10.0
agent-4: 26.0
agent-5: 9.0
agent-6: 21.0
agent-7: 34.0
agent-8: 10.0
agent-9: 24.0
agent-10: 19.0
Sum Reward: 210.0
Avg Reward: 21.0
Min Reward: 9.0
Gini Coefficient: 0.22476190476190477
20:20 Ratio: 3.3157894736842106
Max-min Ratio: 3.7777777777777777
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-01-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 209.74
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 261
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.709
    dispatch_time_ms: 6.651
    learner:
      cur_lr: 0.0011861739913001657
      grad_gnorm: 2.5739290714263916
      policy_entropy: 175.12649536132812
      policy_loss: 1.0156502723693848
      var_gnorm: 55.74997329711914
      vf_explained_var: -0.3137054443359375
      vf_loss: 0.020359257236123085
    num_steps_sampled: 2620000
    num_steps_trained: 2620000
    wait_time_ms: 170.814
  iterations_since_restore: 262
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4812.935337781906
  time_this_iter_s: 17.823873281478882
  time_total_s: 4812.935337781906
  timestamp: 1593889274
  timesteps_since_restore: 2620000
  timesteps_this_iter: 10000
  timesteps_total: 2620000
  training_iteration: 262
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4812 s, 262 iter, 2620000 ts, 210 rew

agent-1: 9.0
agent-2: 20.0
agent-3: 23.0
agent-4: 29.0
agent-5: 24.0
agent-6: 24.0
agent-7: 24.0
agent-8: 29.0
agent-9: 20.0
agent-10: 25.0
Sum Reward: 227.0
Avg Reward: 22.7
Min Reward: 9.0
Gini Coefficient: 0.11938325991189427
20:20 Ratio: 2.0
Max-min Ratio: 3.2222222222222223
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-01-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 209.76
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 262
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.6
    dispatch_time_ms: 6.252
    learner:
      cur_lr: 0.0011855079792439938
      grad_gnorm: 1.0719612836837769
      policy_entropy: 166.88966369628906
      policy_loss: -0.24592936038970947
      var_gnorm: 55.774932861328125
      vf_explained_var: 0.8586040139198303
      vf_loss: 0.002305692294612527
    num_steps_sampled: 2630000
    num_steps_trained: 2630000
    wait_time_ms: 171.949
  iterations_since_restore: 263
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4831.02765750885
  time_this_iter_s: 18.09231972694397
  time_total_s: 4831.02765750885
  timestamp: 1593889292
  timesteps_since_restore: 2630000
  timesteps_this_iter: 10000
  timesteps_total: 2630000
  training_iteration: 263
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4831 s, 263 iter, 2630000 ts, 210 rew

agent-1: 18.0
agent-2: 15.0
agent-3: 17.0
agent-4: 23.0
agent-5: 26.0
agent-6: 25.0
agent-7: 22.0
agent-8: 21.0
agent-9: 26.0
agent-10: 27.0
Sum Reward: 220.0
Avg Reward: 22.0
Min Reward: 15.0
Gini Coefficient: 0.10181818181818182
20:20 Ratio: 1.65625
Max-min Ratio: 1.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-01-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 209.69
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 263
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.926
    dispatch_time_ms: 6.985
    learner:
      cur_lr: 0.0011848419671878219
      grad_gnorm: 1.9990100860595703
      policy_entropy: 171.43724060058594
      policy_loss: -0.945514440536499
      var_gnorm: 55.98808288574219
      vf_explained_var: 0.5776015520095825
      vf_loss: 0.008024443872272968
    num_steps_sampled: 2640000
    num_steps_trained: 2640000
    wait_time_ms: 166.896
  iterations_since_restore: 264
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4848.718900680542
  time_this_iter_s: 17.691243171691895
  time_total_s: 4848.718900680542
  timestamp: 1593889310
  timesteps_since_restore: 2640000
  timesteps_this_iter: 10000
  timesteps_total: 2640000
  training_iteration: 264
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4848 s, 264 iter, 2640000 ts, 210 rew

agent-1: 19.0
agent-2: 16.0
agent-3: 23.0
agent-4: 16.0
agent-5: 19.0
agent-6: 20.0
agent-7: 31.0
agent-8: 19.0
agent-9: 21.0
agent-10: 20.0
Sum Reward: 204.0
Avg Reward: 20.4
Min Reward: 16.0
Gini Coefficient: 0.09705882352941177
20:20 Ratio: 1.6875
Max-min Ratio: 1.9375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-02-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 209.82
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 264
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.627
    dispatch_time_ms: 9.638
    learner:
      cur_lr: 0.00118417595513165
      grad_gnorm: 0.3727869987487793
      policy_entropy: 156.7915802001953
      policy_loss: 0.3175337016582489
      var_gnorm: 56.14603805541992
      vf_explained_var: 0.9532821178436279
      vf_loss: 0.0001345268974546343
    num_steps_sampled: 2650000
    num_steps_trained: 2650000
    wait_time_ms: 167.82
  iterations_since_restore: 265
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4866.537171840668
  time_this_iter_s: 17.818271160125732
  time_total_s: 4866.537171840668
  timestamp: 1593889328
  timesteps_since_restore: 2650000
  timesteps_this_iter: 10000
  timesteps_total: 2650000
  training_iteration: 265
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4866 s, 265 iter, 2650000 ts, 210 rew

agent-1: 24.0
agent-2: 17.0
agent-3: 12.0
agent-4: 17.0
agent-5: 22.0
agent-6: 21.0
agent-7: 14.0
agent-8: 27.0
agent-9: 28.0
agent-10: 27.0
Sum Reward: 209.0
Avg Reward: 20.9
Min Reward: 12.0
Gini Coefficient: 0.14688995215311004
20:20 Ratio: 2.1153846153846154
Max-min Ratio: 2.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-02-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 209.76
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 265
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.952
    dispatch_time_ms: 8.149
    learner:
      cur_lr: 0.001183509943075478
      grad_gnorm: 3.4870262145996094
      policy_entropy: 167.61647033691406
      policy_loss: -1.0505574941635132
      var_gnorm: 56.27870559692383
      vf_explained_var: -0.27524447441101074
      vf_loss: 0.006973216310143471
    num_steps_sampled: 2660000
    num_steps_trained: 2660000
    wait_time_ms: 167.914
  iterations_since_restore: 266
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4884.5057826042175
  time_this_iter_s: 17.968610763549805
  time_total_s: 4884.5057826042175
  timestamp: 1593889346
  timesteps_since_restore: 2660000
  timesteps_this_iter: 10000
  timesteps_total: 2660000
  training_iteration: 266
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4884 s, 266 iter, 2660000 ts, 210 rew

agent-1: 29.0
agent-2: 25.0
agent-3: 22.0
agent-4: 22.0
agent-5: 12.0
agent-6: 17.0
agent-7: 25.0
agent-8: 16.0
agent-9: 29.0
agent-10: 28.0
Sum Reward: 225.0
Avg Reward: 22.5
Min Reward: 12.0
Gini Coefficient: 0.13822222222222222
20:20 Ratio: 2.0714285714285716
Max-min Ratio: 2.4166666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-02-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 209.93
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 266
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.025
    dispatch_time_ms: 6.312
    learner:
      cur_lr: 0.001182844047434628
      grad_gnorm: 1.0774283409118652
      policy_entropy: 168.39341735839844
      policy_loss: 0.3667272627353668
      var_gnorm: 56.465492248535156
      vf_explained_var: 0.49700385332107544
      vf_loss: 0.001244892948307097
    num_steps_sampled: 2670000
    num_steps_trained: 2670000
    wait_time_ms: 170.217
  iterations_since_restore: 267
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4902.311900854111
  time_this_iter_s: 17.80611824989319
  time_total_s: 4902.311900854111
  timestamp: 1593889363
  timesteps_since_restore: 2670000
  timesteps_this_iter: 10000
  timesteps_total: 2670000
  training_iteration: 267
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4902 s, 267 iter, 2670000 ts, 210 rew

agent-1: 10.0
agent-2: 16.0
agent-3: 35.0
agent-4: 19.0
agent-5: 27.0
agent-6: 28.0
agent-7: 16.0
agent-8: 18.0
agent-9: 21.0
agent-10: 19.0
Sum Reward: 209.0
Avg Reward: 20.9
Min Reward: 10.0
Gini Coefficient: 0.1784688995215311
20:20 Ratio: 2.423076923076923
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-03-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 210.04
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 267
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.751
    dispatch_time_ms: 6.786
    learner:
      cur_lr: 0.0011821780353784561
      grad_gnorm: 2.730339288711548
      policy_entropy: 168.88031005859375
      policy_loss: -1.8907661437988281
      var_gnorm: 56.47351837158203
      vf_explained_var: -0.021875500679016113
      vf_loss: 0.006680983118712902
    num_steps_sampled: 2680000
    num_steps_trained: 2680000
    wait_time_ms: 172.772
  iterations_since_restore: 268
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4920.241629123688
  time_this_iter_s: 17.929728269577026
  time_total_s: 4920.241629123688
  timestamp: 1593889381
  timesteps_since_restore: 2680000
  timesteps_this_iter: 10000
  timesteps_total: 2680000
  training_iteration: 268
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4920 s, 268 iter, 2680000 ts, 210 rew

agent-1: 22.0
agent-2: 24.0
agent-3: 32.0
agent-4: 12.0
agent-5: 27.0
agent-6: 18.0
agent-7: 11.0
agent-8: 19.0
agent-9: 30.0
agent-10: 10.0
Sum Reward: 205.0
Avg Reward: 20.5
Min Reward: 10.0
Gini Coefficient: 0.20829268292682926
20:20 Ratio: 2.9523809523809526
Max-min Ratio: 3.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-03-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 209.86
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 268
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 4.178
    dispatch_time_ms: 10.626
    learner:
      cur_lr: 0.0011815120233222842
      grad_gnorm: 0.2390662133693695
      policy_entropy: 171.60577392578125
      policy_loss: 0.13105922937393188
      var_gnorm: 56.593257904052734
      vf_explained_var: -0.11317694187164307
      vf_loss: 0.00014960189582780004
    num_steps_sampled: 2690000
    num_steps_trained: 2690000
    wait_time_ms: 165.352
  iterations_since_restore: 269
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4937.715656280518
  time_this_iter_s: 17.474027156829834
  time_total_s: 4937.715656280518
  timestamp: 1593889399
  timesteps_since_restore: 2690000
  timesteps_this_iter: 10000
  timesteps_total: 2690000
  training_iteration: 269
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4937 s, 269 iter, 2690000 ts, 210 rew

agent-1: 22.0
agent-2: 22.0
agent-3: 25.0
agent-4: 19.0
agent-5: 22.0
agent-6: 22.0
agent-7: 19.0
agent-8: 23.0
agent-9: 30.0
agent-10: 19.0
Sum Reward: 223.0
Avg Reward: 22.3
Min Reward: 19.0
Gini Coefficient: 0.07219730941704036
20:20 Ratio: 1.4473684210526316
Max-min Ratio: 1.5789473684210527
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-03-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 210.12
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 269
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.263
    dispatch_time_ms: 11.44
    learner:
      cur_lr: 0.0011808460112661123
      grad_gnorm: 4.226897239685059
      policy_entropy: 168.72964477539062
      policy_loss: -2.0775318145751953
      var_gnorm: 56.64727783203125
      vf_explained_var: 0.992738664150238
      vf_loss: 0.026477886363863945
    num_steps_sampled: 2700000
    num_steps_trained: 2700000
    wait_time_ms: 168.526
  iterations_since_restore: 270
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4955.679000139236
  time_this_iter_s: 17.963343858718872
  time_total_s: 4955.679000139236
  timestamp: 1593889417
  timesteps_since_restore: 2700000
  timesteps_this_iter: 10000
  timesteps_total: 2700000
  training_iteration: 270
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4955 s, 270 iter, 2700000 ts, 210 rew

agent-1: 29.0
agent-2: 29.0
agent-3: 22.0
agent-4: 25.0
agent-5: 20.0
agent-6: 18.0
agent-7: 27.0
agent-8: 29.0
agent-9: 23.0
agent-10: 25.0
Sum Reward: 247.0
Avg Reward: 24.7
Min Reward: 18.0
Gini Coefficient: 0.08461538461538462
20:20 Ratio: 1.5263157894736843
Max-min Ratio: 1.6111111111111112
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-03-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 210.48
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 270
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.388
    dispatch_time_ms: 8.445
    learner:
      cur_lr: 0.0011801799992099404
      grad_gnorm: 5.2051310539245605
      policy_entropy: 153.70924377441406
      policy_loss: 0.4339855909347534
      var_gnorm: 56.804412841796875
      vf_explained_var: 0.7513794898986816
      vf_loss: 0.11064863204956055
    num_steps_sampled: 2710000
    num_steps_trained: 2710000
    wait_time_ms: 166.253
  iterations_since_restore: 271
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4973.50986790657
  time_this_iter_s: 17.830867767333984
  time_total_s: 4973.50986790657
  timestamp: 1593889435
  timesteps_since_restore: 2710000
  timesteps_this_iter: 10000
  timesteps_total: 2710000
  training_iteration: 271
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4973 s, 271 iter, 2710000 ts, 210 rew

agent-1: 17.0
agent-2: 16.0
agent-3: 13.0
agent-4: 23.0
agent-5: 18.0
agent-6: 22.0
agent-7: 17.0
agent-8: 23.0
agent-9: 24.0
agent-10: 19.0
Sum Reward: 192.0
Avg Reward: 19.2
Min Reward: 13.0
Gini Coefficient: 0.10104166666666667
20:20 Ratio: 1.6206896551724137
Max-min Ratio: 1.8461538461538463
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-04-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 210.27
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 271
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.981
    dispatch_time_ms: 6.063
    learner:
      cur_lr: 0.0011795139871537685
      grad_gnorm: 17.84929656982422
      policy_entropy: 97.77513122558594
      policy_loss: -0.40096545219421387
      var_gnorm: 56.90004348754883
      vf_explained_var: 0.7051314115524292
      vf_loss: 1.4910759925842285
    num_steps_sampled: 2720000
    num_steps_trained: 2720000
    wait_time_ms: 171.156
  iterations_since_restore: 272
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 4991.329545259476
  time_this_iter_s: 17.819677352905273
  time_total_s: 4991.329545259476
  timestamp: 1593889453
  timesteps_since_restore: 2720000
  timesteps_this_iter: 10000
  timesteps_total: 2720000
  training_iteration: 272
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 4991 s, 272 iter, 2720000 ts, 210 rew

agent-1: 20.0
agent-2: 25.0
agent-3: 21.0
agent-4: 9.0
agent-5: 25.0
agent-6: 14.0
agent-7: 25.0
agent-8: 19.0
agent-9: 11.0
agent-10: 25.0
Sum Reward: 194.0
Avg Reward: 19.4
Min Reward: 9.0
Gini Coefficient: 0.16288659793814433
20:20 Ratio: 2.5
Max-min Ratio: 2.7777777777777777
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-04-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 210.07
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 272
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.214
    dispatch_time_ms: 5.838
    learner:
      cur_lr: 0.0011788479750975966
      grad_gnorm: 2.1060194969177246
      policy_entropy: 166.43740844726562
      policy_loss: -0.08435691893100739
      var_gnorm: 57.04808044433594
      vf_explained_var: -0.8591008186340332
      vf_loss: 0.032200075685977936
    num_steps_sampled: 2730000
    num_steps_trained: 2730000
    wait_time_ms: 172.13
  iterations_since_restore: 273
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5009.156700372696
  time_this_iter_s: 17.827155113220215
  time_total_s: 5009.156700372696
  timestamp: 1593889470
  timesteps_since_restore: 2730000
  timesteps_this_iter: 10000
  timesteps_total: 2730000
  training_iteration: 273
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5009 s, 273 iter, 2730000 ts, 210 rew

agent-1: 28.0
agent-2: 19.0
agent-3: 19.0
agent-4: 23.0
agent-5: 32.0
agent-6: 27.0
agent-7: 26.0
agent-8: 17.0
agent-9: 22.0
agent-10: 15.0
Sum Reward: 228.0
Avg Reward: 22.8
Min Reward: 15.0
Gini Coefficient: 0.1280701754385965
20:20 Ratio: 1.875
Max-min Ratio: 2.1333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-04-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 210.25
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 273
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.187
    dispatch_time_ms: 6.096
    learner:
      cur_lr: 0.0011781819630414248
      grad_gnorm: 1.6102315187454224
      policy_entropy: 173.7415008544922
      policy_loss: -0.3963414430618286
      var_gnorm: 57.13850021362305
      vf_explained_var: 0.9693486094474792
      vf_loss: 0.004559027496725321
    num_steps_sampled: 2740000
    num_steps_trained: 2740000
    wait_time_ms: 171.76
  iterations_since_restore: 274
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5026.978735923767
  time_this_iter_s: 17.822035551071167
  time_total_s: 5026.978735923767
  timestamp: 1593889488
  timesteps_since_restore: 2740000
  timesteps_this_iter: 10000
  timesteps_total: 2740000
  training_iteration: 274
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5026 s, 274 iter, 2740000 ts, 210 rew

agent-1: 11.0
agent-2: 16.0
agent-3: 21.0
agent-4: 32.0
agent-5: 38.0
agent-6: 20.0
agent-7: 12.0
agent-8: 32.0
agent-9: 36.0
agent-10: 21.0
Sum Reward: 239.0
Avg Reward: 23.9
Min Reward: 11.0
Gini Coefficient: 0.2205020920502092
20:20 Ratio: 3.217391304347826
Max-min Ratio: 3.4545454545454546
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-05-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 210.58
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 274
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.447
    dispatch_time_ms: 6.238
    learner:
      cur_lr: 0.0011775159509852529
      grad_gnorm: 1.1495810747146606
      policy_entropy: 187.21275329589844
      policy_loss: -0.41761016845703125
      var_gnorm: 57.234832763671875
      vf_explained_var: 0.4904748201370239
      vf_loss: 0.007761274464428425
    num_steps_sampled: 2750000
    num_steps_trained: 2750000
    wait_time_ms: 174.042
  iterations_since_restore: 275
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5045.032480716705
  time_this_iter_s: 18.053744792938232
  time_total_s: 5045.032480716705
  timestamp: 1593889506
  timesteps_since_restore: 2750000
  timesteps_this_iter: 10000
  timesteps_total: 2750000
  training_iteration: 275
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5045 s, 275 iter, 2750000 ts, 211 rew

agent-1: 14.0
agent-2: 22.0
agent-3: 29.0
agent-4: 33.0
agent-5: 15.0
agent-6: 27.0
agent-7: 24.0
agent-8: 23.0
agent-9: 18.0
agent-10: 26.0
Sum Reward: 231.0
Avg Reward: 23.1
Min Reward: 14.0
Gini Coefficient: 0.14155844155844155
20:20 Ratio: 2.1379310344827585
Max-min Ratio: 2.357142857142857
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-05-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 210.85
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 275
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.634
    dispatch_time_ms: 6.916
    learner:
      cur_lr: 0.0011768500553444028
      grad_gnorm: 1.444046974182129
      policy_entropy: 192.9320831298828
      policy_loss: -0.05276550352573395
      var_gnorm: 57.2719612121582
      vf_explained_var: 0.9625275135040283
      vf_loss: 0.001579095609486103
    num_steps_sampled: 2760000
    num_steps_trained: 2760000
    wait_time_ms: 169.402
  iterations_since_restore: 276
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5062.853037595749
  time_this_iter_s: 17.82055687904358
  time_total_s: 5062.853037595749
  timestamp: 1593889524
  timesteps_since_restore: 2760000
  timesteps_this_iter: 10000
  timesteps_total: 2760000
  training_iteration: 276
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5062 s, 276 iter, 2760000 ts, 211 rew

agent-1: 25.0
agent-2: 29.0
agent-3: 24.0
agent-4: 16.0
agent-5: 11.0
agent-6: 18.0
agent-7: 20.0
agent-8: 20.0
agent-9: 18.0
agent-10: 17.0
Sum Reward: 198.0
Avg Reward: 19.8
Min Reward: 11.0
Gini Coefficient: 0.13535353535353536
20:20 Ratio: 2.0
Max-min Ratio: 2.6363636363636362
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-05-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 210.81
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 276
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.545
    dispatch_time_ms: 7.223
    learner:
      cur_lr: 0.001176184043288231
      grad_gnorm: 0.4548412561416626
      policy_entropy: 185.1712188720703
      policy_loss: -0.20759478211402893
      var_gnorm: 57.34543228149414
      vf_explained_var: 0.9897499084472656
      vf_loss: 0.0015085249906405807
    num_steps_sampled: 2770000
    num_steps_trained: 2770000
    wait_time_ms: 169.405
  iterations_since_restore: 277
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5080.776851892471
  time_this_iter_s: 17.923814296722412
  time_total_s: 5080.776851892471
  timestamp: 1593889542
  timesteps_since_restore: 2770000
  timesteps_this_iter: 10000
  timesteps_total: 2770000
  training_iteration: 277
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5080 s, 277 iter, 2770000 ts, 211 rew

agent-1: 17.0
agent-2: 15.0
agent-3: 11.0
agent-4: 27.0
agent-5: 16.0
agent-6: 29.0
agent-7: 18.0
agent-8: 20.0
agent-9: 27.0
agent-10: 32.0
Sum Reward: 212.0
Avg Reward: 21.2
Min Reward: 11.0
Gini Coefficient: 0.17641509433962263
20:20 Ratio: 2.3461538461538463
Max-min Ratio: 2.909090909090909
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-06-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 210.72
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 277
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.693
    dispatch_time_ms: 7.53
    learner:
      cur_lr: 0.001175518031232059
      grad_gnorm: 29.25922393798828
      policy_entropy: 177.83648681640625
      policy_loss: 1.7377971410751343
      var_gnorm: 57.39339065551758
      vf_explained_var: 0.48680514097213745
      vf_loss: 2.02247953414917
    num_steps_sampled: 2780000
    num_steps_trained: 2780000
    wait_time_ms: 165.469
  iterations_since_restore: 278
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5098.537242412567
  time_this_iter_s: 17.760390520095825
  time_total_s: 5098.537242412567
  timestamp: 1593889560
  timesteps_since_restore: 2780000
  timesteps_this_iter: 10000
  timesteps_total: 2780000
  training_iteration: 278
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5098 s, 278 iter, 2780000 ts, 211 rew

agent-1: 25.0
agent-2: 24.0
agent-3: 26.0
agent-4: 14.0
agent-5: 14.0
agent-6: 32.0
agent-7: 15.0
agent-8: 38.0
agent-9: 18.0
agent-10: 20.0
Sum Reward: 226.0
Avg Reward: 22.6
Min Reward: 14.0
Gini Coefficient: 0.18672566371681415
20:20 Ratio: 2.5
Max-min Ratio: 2.7142857142857144
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-06-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 210.95
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 278
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.803
    dispatch_time_ms: 6.577
    learner:
      cur_lr: 0.001174852019175887
      grad_gnorm: 1.2981815338134766
      policy_entropy: 172.34959411621094
      policy_loss: 0.16263194382190704
      var_gnorm: 57.56060028076172
      vf_explained_var: 0.9722204208374023
      vf_loss: 0.0026102946139872074
    num_steps_sampled: 2790000
    num_steps_trained: 2790000
    wait_time_ms: 170.863
  iterations_since_restore: 279
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5116.375395536423
  time_this_iter_s: 17.83815312385559
  time_total_s: 5116.375395536423
  timestamp: 1593889578
  timesteps_since_restore: 2790000
  timesteps_this_iter: 10000
  timesteps_total: 2790000
  training_iteration: 279
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5116 s, 279 iter, 2790000 ts, 211 rew

agent-1: 26.0
agent-2: 25.0
agent-3: 17.0
agent-4: 14.0
agent-5: 20.0
agent-6: 16.0
agent-7: 30.0
agent-8: 33.0
agent-9: 10.0
agent-10: 37.0
Sum Reward: 228.0
Avg Reward: 22.8
Min Reward: 10.0
Gini Coefficient: 0.20964912280701756
20:20 Ratio: 2.9166666666666665
Max-min Ratio: 3.7
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-06-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 210.85
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 279
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.199
    dispatch_time_ms: 8.289
    learner:
      cur_lr: 0.0011741860071197152
      grad_gnorm: 39.99999237060547
      policy_entropy: 154.06802368164062
      policy_loss: -6.938716888427734
      var_gnorm: 57.57937240600586
      vf_explained_var: 0.8381996750831604
      vf_loss: 3.6435787677764893
    num_steps_sampled: 2800000
    num_steps_trained: 2800000
    wait_time_ms: 375.239
  iterations_since_restore: 280
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5136.092254400253
  time_this_iter_s: 19.716858863830566
  time_total_s: 5136.092254400253
  timestamp: 1593889598
  timesteps_since_restore: 2800000
  timesteps_this_iter: 10000
  timesteps_total: 2800000
  training_iteration: 280
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5136 s, 280 iter, 2800000 ts, 211 rew

agent-1: 25.0
agent-2: 22.0
agent-3: 21.0
agent-4: 24.0
agent-5: 26.0
agent-6: 21.0
agent-7: 21.0
agent-8: 22.0
agent-9: 22.0
agent-10: 23.0
Sum Reward: 227.0
Avg Reward: 22.7
Min Reward: 21.0
Gini Coefficient: 0.04008810572687225
20:20 Ratio: 1.2142857142857142
Max-min Ratio: 1.2380952380952381
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-06-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 210.96
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 280
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.311
    dispatch_time_ms: 6.104
    learner:
      cur_lr: 0.0011735199950635433
      grad_gnorm: 32.52226638793945
      policy_entropy: 187.37644958496094
      policy_loss: 7.315966606140137
      var_gnorm: 57.73664093017578
      vf_explained_var: -0.026892781257629395
      vf_loss: 0.8729744553565979
    num_steps_sampled: 2810000
    num_steps_trained: 2810000
    wait_time_ms: 170.458
  iterations_since_restore: 281
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5153.17910695076
  time_this_iter_s: 17.086852550506592
  time_total_s: 5153.17910695076
  timestamp: 1593889615
  timesteps_since_restore: 2810000
  timesteps_this_iter: 10000
  timesteps_total: 2810000
  training_iteration: 281
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5153 s, 281 iter, 2810000 ts, 211 rew

agent-1: 33.0
agent-2: 27.0
agent-3: 22.0
agent-4: 18.0
agent-5: 13.0
agent-6: 26.0
agent-7: 11.0
agent-8: 28.0
agent-9: 37.0
agent-10: 27.0
Sum Reward: 242.0
Avg Reward: 24.2
Min Reward: 11.0
Gini Coefficient: 0.18181818181818182
20:20 Ratio: 2.9166666666666665
Max-min Ratio: 3.3636363636363638
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-07-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 211.25
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 281
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.71
    dispatch_time_ms: 5.947
    learner:
      cur_lr: 0.0011728539830073714
      grad_gnorm: 2.53054141998291
      policy_entropy: 188.3119354248047
      policy_loss: -0.9205432534217834
      var_gnorm: 57.813087463378906
      vf_explained_var: 0.9659469127655029
      vf_loss: 0.007728775031864643
    num_steps_sampled: 2820000
    num_steps_trained: 2820000
    wait_time_ms: 172.833
  iterations_since_restore: 282
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5171.099045276642
  time_this_iter_s: 17.919938325881958
  time_total_s: 5171.099045276642
  timestamp: 1593889633
  timesteps_since_restore: 2820000
  timesteps_this_iter: 10000
  timesteps_total: 2820000
  training_iteration: 282
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5171 s, 282 iter, 2820000 ts, 211 rew

agent-1: 19.0
agent-2: 20.0
agent-3: 22.0
agent-4: 25.0
agent-5: 19.0
agent-6: 20.0
agent-7: 22.0
agent-8: 23.0
agent-9: 21.0
agent-10: 17.0
Sum Reward: 208.0
Avg Reward: 20.8
Min Reward: 17.0
Gini Coefficient: 0.058653846153846154
20:20 Ratio: 1.3333333333333333
Max-min Ratio: 1.4705882352941178
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-07-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 211.27
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 282
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.553
    dispatch_time_ms: 8.242
    learner:
      cur_lr: 0.0011721879709511995
      grad_gnorm: 2.8685479164123535
      policy_entropy: 183.5398712158203
      policy_loss: 0.08912047743797302
      var_gnorm: 57.8701286315918
      vf_explained_var: 0.9895766973495483
      vf_loss: 0.0009262328967452049
    num_steps_sampled: 2830000
    num_steps_trained: 2830000
    wait_time_ms: 171.644
  iterations_since_restore: 283
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5188.920041561127
  time_this_iter_s: 17.820996284484863
  time_total_s: 5188.920041561127
  timestamp: 1593889651
  timesteps_since_restore: 2830000
  timesteps_this_iter: 10000
  timesteps_total: 2830000
  training_iteration: 283
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5188 s, 283 iter, 2830000 ts, 211 rew

agent-1: 18.0
agent-2: 30.0
agent-3: 24.0
agent-4: 19.0
agent-5: 22.0
agent-6: 21.0
agent-7: 19.0
agent-8: 26.0
agent-9: 21.0
agent-10: 24.0
Sum Reward: 224.0
Avg Reward: 22.4
Min Reward: 18.0
Gini Coefficient: 0.08571428571428572
20:20 Ratio: 1.5135135135135136
Max-min Ratio: 1.6666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-07-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 211.41
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 283
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.594
    dispatch_time_ms: 6.106
    learner:
      cur_lr: 0.0011715219588950276
      grad_gnorm: 0.9113680720329285
      policy_entropy: 185.48548889160156
      policy_loss: -0.5150799751281738
      var_gnorm: 57.86119842529297
      vf_explained_var: 0.9911593794822693
      vf_loss: 0.0012032113736495376
    num_steps_sampled: 2840000
    num_steps_trained: 2840000
    wait_time_ms: 169.028
  iterations_since_restore: 284
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5206.907746553421
  time_this_iter_s: 17.98770499229431
  time_total_s: 5206.907746553421
  timestamp: 1593889669
  timesteps_since_restore: 2840000
  timesteps_this_iter: 10000
  timesteps_total: 2840000
  training_iteration: 284
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5206 s, 284 iter, 2840000 ts, 211 rew

agent-1: 22.0
agent-2: 25.0
agent-3: 16.0
agent-4: 17.0
agent-5: 21.0
agent-6: 24.0
agent-7: 22.0
agent-8: 22.0
agent-9: 28.0
agent-10: 25.0
Sum Reward: 222.0
Avg Reward: 22.2
Min Reward: 16.0
Gini Coefficient: 0.08558558558558559
20:20 Ratio: 1.606060606060606
Max-min Ratio: 1.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-08-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 211.5
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 284
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.434
    dispatch_time_ms: 7.865
    learner:
      cur_lr: 0.0011708559468388557
      grad_gnorm: 5.171988487243652
      policy_entropy: 166.78382873535156
      policy_loss: -0.2848575711250305
      var_gnorm: 58.04308319091797
      vf_explained_var: 0.9486920833587646
      vf_loss: 0.0033267659600824118
    num_steps_sampled: 2850000
    num_steps_trained: 2850000
    wait_time_ms: 169.142
  iterations_since_restore: 285
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5224.712297916412
  time_this_iter_s: 17.804551362991333
  time_total_s: 5224.712297916412
  timestamp: 1593889687
  timesteps_since_restore: 2850000
  timesteps_this_iter: 10000
  timesteps_total: 2850000
  training_iteration: 285
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5224 s, 285 iter, 2850000 ts, 212 rew

agent-1: 18.0
agent-2: 24.0
agent-3: 22.0
agent-4: 16.0
agent-5: 23.0
agent-6: 18.0
agent-7: 22.0
agent-8: 26.0
agent-9: 22.0
agent-10: 15.0
Sum Reward: 206.0
Avg Reward: 20.6
Min Reward: 15.0
Gini Coefficient: 0.09320388349514563
20:20 Ratio: 1.6129032258064515
Max-min Ratio: 1.7333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-08-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 211.36
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 285
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.78
    dispatch_time_ms: 24.814
    learner:
      cur_lr: 0.0011701900511980057
      grad_gnorm: 1.559977650642395
      policy_entropy: 181.4380645751953
      policy_loss: 0.24231503903865814
      var_gnorm: 58.01564025878906
      vf_explained_var: 0.9136483073234558
      vf_loss: 0.0119651323184371
    num_steps_sampled: 2860000
    num_steps_trained: 2860000
    wait_time_ms: 149.819
  iterations_since_restore: 286
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5243.336980581284
  time_this_iter_s: 18.624682664871216
  time_total_s: 5243.336980581284
  timestamp: 1593889705
  timesteps_since_restore: 2860000
  timesteps_this_iter: 10000
  timesteps_total: 2860000
  training_iteration: 286
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5243 s, 286 iter, 2860000 ts, 211 rew

agent-1: 28.0
agent-2: 24.0
agent-3: 27.0
agent-4: 20.0
agent-5: 17.0
agent-6: 22.0
agent-7: 22.0
agent-8: 25.0
agent-9: 28.0
agent-10: 18.0
Sum Reward: 231.0
Avg Reward: 23.1
Min Reward: 17.0
Gini Coefficient: 0.09307359307359307
20:20 Ratio: 1.6
Max-min Ratio: 1.6470588235294117
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-08-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 211.7
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 286
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.028
    dispatch_time_ms: 24.296
    learner:
      cur_lr: 0.0011695240391418338
      grad_gnorm: 4.85075044631958
      policy_entropy: 168.1451873779297
      policy_loss: 0.0030458439141511917
      var_gnorm: 58.091514587402344
      vf_explained_var: 0.7097746133804321
      vf_loss: 0.0691041350364685
    num_steps_sampled: 2870000
    num_steps_trained: 2870000
    wait_time_ms: 156.101
  iterations_since_restore: 287
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5262.161283493042
  time_this_iter_s: 18.824302911758423
  time_total_s: 5262.161283493042
  timestamp: 1593889724
  timesteps_since_restore: 2870000
  timesteps_this_iter: 10000
  timesteps_total: 2870000
  training_iteration: 287
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5262 s, 287 iter, 2870000 ts, 212 rew

agent-1: 27.0
agent-2: 14.0
agent-3: 17.0
agent-4: 33.0
agent-5: 21.0
agent-6: 33.0
agent-7: 18.0
agent-8: 13.0
agent-9: 21.0
agent-10: 28.0
Sum Reward: 225.0
Avg Reward: 22.5
Min Reward: 13.0
Gini Coefficient: 0.17555555555555555
20:20 Ratio: 2.4444444444444446
Max-min Ratio: 2.5384615384615383
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-09-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 211.94
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 287
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.242
    dispatch_time_ms: 9.34
    learner:
      cur_lr: 0.0011688580270856619
      grad_gnorm: 1.6426496505737305
      policy_entropy: 177.86834716796875
      policy_loss: -0.689767599105835
      var_gnorm: 58.13127136230469
      vf_explained_var: 0.9677364230155945
      vf_loss: 0.005396460648626089
    num_steps_sampled: 2880000
    num_steps_trained: 2880000
    wait_time_ms: 164.136
  iterations_since_restore: 288
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5280.350216150284
  time_this_iter_s: 18.18893265724182
  time_total_s: 5280.350216150284
  timestamp: 1593889742
  timesteps_since_restore: 2880000
  timesteps_this_iter: 10000
  timesteps_total: 2880000
  training_iteration: 288
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5280 s, 288 iter, 2880000 ts, 212 rew

agent-1: 17.0
agent-2: 11.0
agent-3: 19.0
agent-4: 26.0
agent-5: 15.0
agent-6: 20.0
agent-7: 20.0
agent-8: 19.0
agent-9: 20.0
agent-10: 30.0
Sum Reward: 197.0
Avg Reward: 19.7
Min Reward: 11.0
Gini Coefficient: 0.13553299492385787
20:20 Ratio: 2.1538461538461537
Max-min Ratio: 2.727272727272727
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-09-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 211.94
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 288
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.943
    dispatch_time_ms: 6.729
    learner:
      cur_lr: 0.00116819201502949
      grad_gnorm: 6.229362964630127
      policy_entropy: 183.519287109375
      policy_loss: 0.28837206959724426
      var_gnorm: 58.33814239501953
      vf_explained_var: 0.7918686866760254
      vf_loss: 0.015388373285531998
    num_steps_sampled: 2890000
    num_steps_trained: 2890000
    wait_time_ms: 168.945
  iterations_since_restore: 289
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5297.974463701248
  time_this_iter_s: 17.624247550964355
  time_total_s: 5297.974463701248
  timestamp: 1593889760
  timesteps_since_restore: 2890000
  timesteps_this_iter: 10000
  timesteps_total: 2890000
  training_iteration: 289
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5297 s, 289 iter, 2890000 ts, 212 rew

agent-1: 27.0
agent-2: 22.0
agent-3: 22.0
agent-4: 16.0
agent-5: 13.0
agent-6: 23.0
agent-7: 23.0
agent-8: 30.0
agent-9: 22.0
agent-10: 27.0
Sum Reward: 225.0
Avg Reward: 22.5
Min Reward: 13.0
Gini Coefficient: 0.11511111111111111
20:20 Ratio: 1.9655172413793103
Max-min Ratio: 2.3076923076923075
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-09-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 212.18
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 289
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.66
    dispatch_time_ms: 6.796
    learner:
      cur_lr: 0.001167526002973318
      grad_gnorm: 1.6928167343139648
      policy_entropy: 185.8241424560547
      policy_loss: -0.29799607396125793
      var_gnorm: 58.378448486328125
      vf_explained_var: 0.9515458941459656
      vf_loss: 0.002195755485445261
    num_steps_sampled: 2900000
    num_steps_trained: 2900000
    wait_time_ms: 167.245
  iterations_since_restore: 290
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5315.847331285477
  time_this_iter_s: 17.872867584228516
  time_total_s: 5315.847331285477
  timestamp: 1593889778
  timesteps_since_restore: 2900000
  timesteps_this_iter: 10000
  timesteps_total: 2900000
  training_iteration: 290
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5315 s, 290 iter, 2900000 ts, 212 rew

agent-1: 21.0
agent-2: 22.0
agent-3: 17.0
agent-4: 24.0
agent-5: 23.0
agent-6: 28.0
agent-7: 15.0
agent-8: 22.0
agent-9: 17.0
agent-10: 23.0
Sum Reward: 212.0
Avg Reward: 21.2
Min Reward: 15.0
Gini Coefficient: 0.09528301886792453
20:20 Ratio: 1.625
Max-min Ratio: 1.8666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-09-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 212.29
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 290
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.923
    dispatch_time_ms: 5.469
    learner:
      cur_lr: 0.0011668599909171462
      grad_gnorm: 1.9850221872329712
      policy_entropy: 181.9832763671875
      policy_loss: -0.2578650712966919
      var_gnorm: 58.52812576293945
      vf_explained_var: 0.9900770783424377
      vf_loss: 0.0010236222296953201
    num_steps_sampled: 2910000
    num_steps_trained: 2910000
    wait_time_ms: 165.268
  iterations_since_restore: 291
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5333.646530866623
  time_this_iter_s: 17.79919958114624
  time_total_s: 5333.646530866623
  timestamp: 1593889796
  timesteps_since_restore: 2910000
  timesteps_this_iter: 10000
  timesteps_total: 2910000
  training_iteration: 291
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5333 s, 291 iter, 2910000 ts, 212 rew

agent-1: 26.0
agent-2: 19.0
agent-3: 23.0
agent-4: 17.0
agent-5: 25.0
agent-6: 19.0
agent-7: 20.0
agent-8: 24.0
agent-9: 17.0
agent-10: 19.0
Sum Reward: 209.0
Avg Reward: 20.9
Min Reward: 17.0
Gini Coefficient: 0.08373205741626795
20:20 Ratio: 1.5
Max-min Ratio: 1.5294117647058822
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-10-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 212.26
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 291
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.911
    dispatch_time_ms: 6.452
    learner:
      cur_lr: 0.0011661939788609743
      grad_gnorm: 2.888315200805664
      policy_entropy: 187.16465759277344
      policy_loss: -1.3603547811508179
      var_gnorm: 58.53121566772461
      vf_explained_var: 0.9518855810165405
      vf_loss: 0.006867017596960068
    num_steps_sampled: 2920000
    num_steps_trained: 2920000
    wait_time_ms: 162.441
  iterations_since_restore: 292
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5351.584955453873
  time_this_iter_s: 17.938424587249756
  time_total_s: 5351.584955453873
  timestamp: 1593889814
  timesteps_since_restore: 2920000
  timesteps_this_iter: 10000
  timesteps_total: 2920000
  training_iteration: 292
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5351 s, 292 iter, 2920000 ts, 212 rew

agent-1: 26.0
agent-2: 15.0
agent-3: 33.0
agent-4: 16.0
agent-5: 27.0
agent-6: 25.0
agent-7: 23.0
agent-8: 22.0
agent-9: 18.0
agent-10: 26.0
Sum Reward: 231.0
Avg Reward: 23.1
Min Reward: 15.0
Gini Coefficient: 0.12683982683982684
20:20 Ratio: 1.935483870967742
Max-min Ratio: 2.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-10-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 212.43
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 292
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 4.027
    dispatch_time_ms: 7.061
    learner:
      cur_lr: 0.0011655279668048024
      grad_gnorm: 7.4268646240234375
      policy_entropy: 168.736083984375
      policy_loss: -0.945506751537323
      var_gnorm: 58.7078742980957
      vf_explained_var: 0.4038183093070984
      vf_loss: 0.015623873099684715
    num_steps_sampled: 2930000
    num_steps_trained: 2930000
    wait_time_ms: 169.117
  iterations_since_restore: 293
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5369.4091629981995
  time_this_iter_s: 17.824207544326782
  time_total_s: 5369.4091629981995
  timestamp: 1593889832
  timesteps_since_restore: 2930000
  timesteps_this_iter: 10000
  timesteps_total: 2930000
  training_iteration: 293
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5369 s, 293 iter, 2930000 ts, 212 rew

agent-1: 32.0
agent-2: 24.0
agent-3: 21.0
agent-4: 6.0
agent-5: 19.0
agent-6: 20.0
agent-7: 22.0
agent-8: 28.0
agent-9: 21.0
agent-10: 21.0
Sum Reward: 214.0
Avg Reward: 21.4
Min Reward: 6.0
Gini Coefficient: 0.14953271028037382
20:20 Ratio: 2.4
Max-min Ratio: 5.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-10-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 212.6
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 293
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.164
    dispatch_time_ms: 6.46
    learner:
      cur_lr: 0.0011648619547486305
      grad_gnorm: 1.0890960693359375
      policy_entropy: 180.93576049804688
      policy_loss: -0.4665818214416504
      var_gnorm: 58.79572296142578
      vf_explained_var: 0.5914262533187866
      vf_loss: 0.004667570348829031
    num_steps_sampled: 2940000
    num_steps_trained: 2940000
    wait_time_ms: 164.448
  iterations_since_restore: 294
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5387.331206083298
  time_this_iter_s: 17.922043085098267
  time_total_s: 5387.331206083298
  timestamp: 1593889850
  timesteps_since_restore: 2940000
  timesteps_this_iter: 10000
  timesteps_total: 2940000
  training_iteration: 294
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5387 s, 294 iter, 2940000 ts, 213 rew

agent-1: 25.0
agent-2: 27.0
agent-3: 16.0
agent-4: 22.0
agent-5: 22.0
agent-6: 23.0
agent-7: 23.0
agent-8: 26.0
agent-9: 34.0
agent-10: 5.0
Sum Reward: 223.0
Avg Reward: 22.3
Min Reward: 5.0
Gini Coefficient: 0.16457399103139014
20:20 Ratio: 2.9047619047619047
Max-min Ratio: 6.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-11-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 212.91
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 294
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.538
    dispatch_time_ms: 7.104
    learner:
      cur_lr: 0.0011641959426924586
      grad_gnorm: 10.802325248718262
      policy_entropy: 169.80902099609375
      policy_loss: -0.8764350414276123
      var_gnorm: 58.84867477416992
      vf_explained_var: -0.2774101495742798
      vf_loss: 0.05415834113955498
    num_steps_sampled: 2950000
    num_steps_trained: 2950000
    wait_time_ms: 167.607
  iterations_since_restore: 295
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5405.137141704559
  time_this_iter_s: 17.805935621261597
  time_total_s: 5405.137141704559
  timestamp: 1593889867
  timesteps_since_restore: 2950000
  timesteps_this_iter: 10000
  timesteps_total: 2950000
  training_iteration: 295
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5405 s, 295 iter, 2950000 ts, 213 rew

agent-1: 22.0
agent-2: 18.0
agent-3: 4.0
agent-4: 34.0
agent-5: 30.0
agent-6: 17.0
agent-7: 28.0
agent-8: 30.0
agent-9: 23.0
agent-10: 29.0
Sum Reward: 235.0
Avg Reward: 23.5
Min Reward: 4.0
Gini Coefficient: 0.19021276595744682
20:20 Ratio: 3.0476190476190474
Max-min Ratio: 8.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-11-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 213.14
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 295
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.579
    dispatch_time_ms: 6.052
    learner:
      cur_lr: 0.0011635300470516086
      grad_gnorm: 1.9345998764038086
      policy_entropy: 183.805419921875
      policy_loss: 0.13053660094738007
      var_gnorm: 58.84394836425781
      vf_explained_var: -0.18475937843322754
      vf_loss: 0.003287095343694091
    num_steps_sampled: 2960000
    num_steps_trained: 2960000
    wait_time_ms: 175.709
  iterations_since_restore: 296
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5423.093023300171
  time_this_iter_s: 17.955881595611572
  time_total_s: 5423.093023300171
  timestamp: 1593889885
  timesteps_since_restore: 2960000
  timesteps_this_iter: 10000
  timesteps_total: 2960000
  training_iteration: 296
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5423 s, 296 iter, 2960000 ts, 213 rew

agent-1: 16.0
agent-2: 20.0
agent-3: 21.0
agent-4: 24.0
agent-5: 17.0
agent-6: 17.0
agent-7: 24.0
agent-8: 21.0
agent-9: 28.0
agent-10: 18.0
Sum Reward: 206.0
Avg Reward: 20.6
Min Reward: 16.0
Gini Coefficient: 0.09805825242718447
20:20 Ratio: 1.5757575757575757
Max-min Ratio: 1.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-11-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 212.96
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 296
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.659
    dispatch_time_ms: 7.578
    learner:
      cur_lr: 0.0011628640349954367
      grad_gnorm: 0.23346909880638123
      policy_entropy: 175.2657012939453
      policy_loss: 0.10716140270233154
      var_gnorm: 59.07838439941406
      vf_explained_var: 0.9794405102729797
      vf_loss: 0.00016642555419821292
    num_steps_sampled: 2970000
    num_steps_trained: 2970000
    wait_time_ms: 166.156
  iterations_since_restore: 297
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5440.91978096962
  time_this_iter_s: 17.826757669448853
  time_total_s: 5440.91978096962
  timestamp: 1593889903
  timesteps_since_restore: 2970000
  timesteps_this_iter: 10000
  timesteps_total: 2970000
  training_iteration: 297
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5440 s, 297 iter, 2970000 ts, 213 rew

agent-1: 25.0
agent-2: 15.0
agent-3: 22.0
agent-4: 23.0
agent-5: 20.0
agent-6: 32.0
agent-7: 17.0
agent-8: 19.0
agent-9: 26.0
agent-10: 24.0
Sum Reward: 223.0
Avg Reward: 22.3
Min Reward: 15.0
Gini Coefficient: 0.11614349775784753
20:20 Ratio: 1.8125
Max-min Ratio: 2.1333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-12-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 213.15
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 297
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.534
    dispatch_time_ms: 6.321
    learner:
      cur_lr: 0.0011621980229392648
      grad_gnorm: 40.0
      policy_entropy: 89.61089324951172
      policy_loss: 4.466508388519287
      var_gnorm: 59.077598571777344
      vf_explained_var: 0.7341694831848145
      vf_loss: 24.27530288696289
    num_steps_sampled: 2980000
    num_steps_trained: 2980000
    wait_time_ms: 159.001
  iterations_since_restore: 298
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5461.99005484581
  time_this_iter_s: 21.070273876190186
  time_total_s: 5461.99005484581
  timestamp: 1593889924
  timesteps_since_restore: 2980000
  timesteps_this_iter: 10000
  timesteps_total: 2980000
  training_iteration: 298
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5461 s, 298 iter, 2980000 ts, 213 rew

agent-1: 21.0
agent-2: 22.0
agent-3: 21.0
agent-4: 10.0
agent-5: 21.0
agent-6: 28.0
agent-7: 17.0
agent-8: 26.0
agent-9: 24.0
agent-10: 27.0
Sum Reward: 217.0
Avg Reward: 21.7
Min Reward: 10.0
Gini Coefficient: 0.12304147465437788
20:20 Ratio: 2.037037037037037
Max-min Ratio: 2.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-12-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 213.17
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 298
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.758
    dispatch_time_ms: 8.817
    learner:
      cur_lr: 0.0011615320108830929
      grad_gnorm: 0.4292614161968231
      policy_entropy: 164.93479919433594
      policy_loss: -0.259319007396698
      var_gnorm: 59.07341766357422
      vf_explained_var: 0.9294816851615906
      vf_loss: 0.0010361724998801947
    num_steps_sampled: 2990000
    num_steps_trained: 2990000
    wait_time_ms: 168.875
  iterations_since_restore: 299
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5479.785587787628
  time_this_iter_s: 17.795532941818237
  time_total_s: 5479.785587787628
  timestamp: 1593889942
  timesteps_since_restore: 2990000
  timesteps_this_iter: 10000
  timesteps_total: 2990000
  training_iteration: 299
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5479 s, 299 iter, 2990000 ts, 213 rew

agent-1: 20.0
agent-2: 15.0
agent-3: 26.0
agent-4: 20.0
agent-5: 16.0
agent-6: 18.0
agent-7: 29.0
agent-8: 19.0
agent-9: 25.0
agent-10: 26.0
Sum Reward: 214.0
Avg Reward: 21.4
Min Reward: 15.0
Gini Coefficient: 0.11869158878504672
20:20 Ratio: 1.7741935483870968
Max-min Ratio: 1.9333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-12-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 212.95
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 299
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.68
    dispatch_time_ms: 7.224
    learner:
      cur_lr: 0.001160865998826921
      grad_gnorm: 1.0052428245544434
      policy_entropy: 178.0712127685547
      policy_loss: -0.44223135709762573
      var_gnorm: 59.04386901855469
      vf_explained_var: 0.8611202239990234
      vf_loss: 0.0011058143572881818
    num_steps_sampled: 3000000
    num_steps_trained: 3000000
    wait_time_ms: 171.227
  iterations_since_restore: 300
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5497.568022251129
  time_this_iter_s: 17.782434463500977
  time_total_s: 5497.568022251129
  timestamp: 1593889960
  timesteps_since_restore: 3000000
  timesteps_this_iter: 10000
  timesteps_total: 3000000
  training_iteration: 300
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5497 s, 300 iter, 3000000 ts, 213 rew

agent-1: 20.0
agent-2: 27.0
agent-3: 24.0
agent-4: 18.0
agent-5: 19.0
agent-6: 17.0
agent-7: 25.0
agent-8: 25.0
agent-9: 13.0
agent-10: 30.0
Sum Reward: 218.0
Avg Reward: 21.8
Min Reward: 13.0
Gini Coefficient: 0.12844036697247707
20:20 Ratio: 1.9
Max-min Ratio: 2.3076923076923075
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-12-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 212.99
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 300
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.856
    dispatch_time_ms: 6.322
    learner:
      cur_lr: 0.001160199986770749
      grad_gnorm: 1.4903453588485718
      policy_entropy: 170.71066284179688
      policy_loss: 0.6043121814727783
      var_gnorm: 59.15578079223633
      vf_explained_var: 0.6216872930526733
      vf_loss: 0.0056342510506510735
    num_steps_sampled: 3010000
    num_steps_trained: 3010000
    wait_time_ms: 174.232
  iterations_since_restore: 301
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5515.238571405411
  time_this_iter_s: 17.670549154281616
  time_total_s: 5515.238571405411
  timestamp: 1593889978
  timesteps_since_restore: 3010000
  timesteps_this_iter: 10000
  timesteps_total: 3010000
  training_iteration: 301
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5515 s, 301 iter, 3010000 ts, 213 rew

agent-1: 16.0
agent-2: 28.0
agent-3: 21.0
agent-4: 19.0
agent-5: 21.0
agent-6: 23.0
agent-7: 12.0
agent-8: 25.0
agent-9: 19.0
agent-10: 19.0
Sum Reward: 203.0
Avg Reward: 20.3
Min Reward: 12.0
Gini Coefficient: 0.11576354679802955
20:20 Ratio: 1.8928571428571428
Max-min Ratio: 2.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-13-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 213.04
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 301
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.615
    dispatch_time_ms: 5.71
    learner:
      cur_lr: 0.0011595339747145772
      grad_gnorm: 40.00000762939453
      policy_entropy: 87.100830078125
      policy_loss: -15.319709777832031
      var_gnorm: 59.16395950317383
      vf_explained_var: 0.686606228351593
      vf_loss: 30.508371353149414
    num_steps_sampled: 3020000
    num_steps_trained: 3020000
    wait_time_ms: 161.683
  iterations_since_restore: 302
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5533.03667473793
  time_this_iter_s: 17.79810333251953
  time_total_s: 5533.03667473793
  timestamp: 1593889996
  timesteps_since_restore: 3020000
  timesteps_this_iter: 10000
  timesteps_total: 3020000
  training_iteration: 302
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5533 s, 302 iter, 3020000 ts, 213 rew

agent-1: 29.0
agent-2: 22.0
agent-3: 20.0
agent-4: 21.0
agent-5: 14.0
agent-6: 16.0
agent-7: 20.0
agent-8: 20.0
agent-9: 28.0
agent-10: 20.0
Sum Reward: 210.0
Avg Reward: 21.0
Min Reward: 14.0
Gini Coefficient: 0.11047619047619048
20:20 Ratio: 1.9
Max-min Ratio: 2.0714285714285716
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-13-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 212.82
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 302
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.361
    dispatch_time_ms: 32.345
    learner:
      cur_lr: 0.0011588679626584053
      grad_gnorm: 1.1982049942016602
      policy_entropy: 182.6620330810547
      policy_loss: -0.239132821559906
      var_gnorm: 59.2936897277832
      vf_explained_var: 0.5980105400085449
      vf_loss: 0.0041548409499228
    num_steps_sampled: 3030000
    num_steps_trained: 3030000
    wait_time_ms: 171.092
  iterations_since_restore: 303
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5551.809211015701
  time_this_iter_s: 18.772536277770996
  time_total_s: 5551.809211015701
  timestamp: 1593890014
  timesteps_since_restore: 3030000
  timesteps_this_iter: 10000
  timesteps_total: 3030000
  training_iteration: 303
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5551 s, 303 iter, 3030000 ts, 213 rew

agent-1: 14.0
agent-2: 22.0
agent-3: 21.0
agent-4: 19.0
agent-5: 16.0
agent-6: 16.0
agent-7: 23.0
agent-8: 24.0
agent-9: 20.0
agent-10: 26.0
Sum Reward: 201.0
Avg Reward: 20.1
Min Reward: 14.0
Gini Coefficient: 0.10398009950248756
20:20 Ratio: 1.6666666666666667
Max-min Ratio: 1.8571428571428572
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-13-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 212.7
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 303
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.824
    dispatch_time_ms: 27.631
    learner:
      cur_lr: 0.0011582019506022334
      grad_gnorm: 0.19929106533527374
      policy_entropy: 185.72967529296875
      policy_loss: -0.10917297750711441
      var_gnorm: 59.28410720825195
      vf_explained_var: 0.992793083190918
      vf_loss: 7.94890001998283e-05
    num_steps_sampled: 3040000
    num_steps_trained: 3040000
    wait_time_ms: 158.817
  iterations_since_restore: 304
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5570.579116344452
  time_this_iter_s: 18.76990532875061
  time_total_s: 5570.579116344452
  timestamp: 1593890033
  timesteps_since_restore: 3040000
  timesteps_this_iter: 10000
  timesteps_total: 3040000
  training_iteration: 304
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5570 s, 304 iter, 3040000 ts, 213 rew

agent-1: 22.0
agent-2: 21.0
agent-3: 16.0
agent-4: 21.0
agent-5: 25.0
agent-6: 22.0
agent-7: 17.0
agent-8: 18.0
agent-9: 22.0
agent-10: 23.0
Sum Reward: 207.0
Avg Reward: 20.7
Min Reward: 16.0
Gini Coefficient: 0.07101449275362319
20:20 Ratio: 1.4545454545454546
Max-min Ratio: 1.5625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-14-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 212.51
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 304
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.777
    dispatch_time_ms: 32.246
    learner:
      cur_lr: 0.0011575360549613833
      grad_gnorm: 5.314821720123291
      policy_entropy: 176.94815063476562
      policy_loss: 0.39800623059272766
      var_gnorm: 59.41672134399414
      vf_explained_var: -1.0
      vf_loss: 0.1975783109664917
    num_steps_sampled: 3050000
    num_steps_trained: 3050000
    wait_time_ms: 154.024
  iterations_since_restore: 305
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5589.360844612122
  time_this_iter_s: 18.781728267669678
  time_total_s: 5589.360844612122
  timestamp: 1593890052
  timesteps_since_restore: 3050000
  timesteps_this_iter: 10000
  timesteps_total: 3050000
  training_iteration: 305
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5589 s, 305 iter, 3050000 ts, 213 rew

agent-1: 19.0
agent-2: 20.0
agent-3: 21.0
agent-4: 15.0
agent-5: 24.0
agent-6: 23.0
agent-7: 31.0
agent-8: 15.0
agent-9: 12.0
agent-10: 20.0
Sum Reward: 200.0
Avg Reward: 20.0
Min Reward: 12.0
Gini Coefficient: 0.14
20:20 Ratio: 2.037037037037037
Max-min Ratio: 2.5833333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-14-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 212.38
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 305
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.39
    dispatch_time_ms: 32.254
    learner:
      cur_lr: 0.0011568700429052114
      grad_gnorm: 6.472617149353027
      policy_entropy: 184.11419677734375
      policy_loss: 0.06334439665079117
      var_gnorm: 59.43764114379883
      vf_explained_var: 0.2963966131210327
      vf_loss: 0.031225524842739105
    num_steps_sampled: 3060000
    num_steps_trained: 3060000
    wait_time_ms: 158.333
  iterations_since_restore: 306
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5608.247733831406
  time_this_iter_s: 18.886889219284058
  time_total_s: 5608.247733831406
  timestamp: 1593890071
  timesteps_since_restore: 3060000
  timesteps_this_iter: 10000
  timesteps_total: 3060000
  training_iteration: 306
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5608 s, 306 iter, 3060000 ts, 212 rew

agent-1: 17.0
agent-2: 20.0
agent-3: 25.0
agent-4: 16.0
agent-5: 12.0
agent-6: 17.0
agent-7: 30.0
agent-8: 23.0
agent-9: 23.0
agent-10: 25.0
Sum Reward: 208.0
Avg Reward: 20.8
Min Reward: 12.0
Gini Coefficient: 0.1375
20:20 Ratio: 1.9642857142857142
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-14-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 212.45
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 306
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.998
    dispatch_time_ms: 27.625
    learner:
      cur_lr: 0.0011562040308490396
      grad_gnorm: 6.920210838317871
      policy_entropy: 174.64779663085938
      policy_loss: -0.8529227375984192
      var_gnorm: 59.550811767578125
      vf_explained_var: -1.0
      vf_loss: 0.03912758082151413
    num_steps_sampled: 3070000
    num_steps_trained: 3070000
    wait_time_ms: 166.065
  iterations_since_restore: 307
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5627.144816875458
  time_this_iter_s: 18.897083044052124
  time_total_s: 5627.144816875458
  timestamp: 1593890090
  timesteps_since_restore: 3070000
  timesteps_this_iter: 10000
  timesteps_total: 3070000
  training_iteration: 307
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5627 s, 307 iter, 3070000 ts, 212 rew

agent-1: 21.0
agent-2: 28.0
agent-3: 22.0
agent-4: 29.0
agent-5: 21.0
agent-6: 14.0
agent-7: 23.0
agent-8: 19.0
agent-9: 16.0
agent-10: 20.0
Sum Reward: 213.0
Avg Reward: 21.3
Min Reward: 14.0
Gini Coefficient: 0.11502347417840375
20:20 Ratio: 1.9
Max-min Ratio: 2.0714285714285716
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-15-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 212.5
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 307
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.764
    dispatch_time_ms: 26.614
    learner:
      cur_lr: 0.0011555380187928677
      grad_gnorm: 39.99998092651367
      policy_entropy: 12.74267578125
      policy_loss: -8.036096572875977
      var_gnorm: 59.53022384643555
      vf_explained_var: 0.2655002474784851
      vf_loss: 122.25518035888672
    num_steps_sampled: 3080000
    num_steps_trained: 3080000
    wait_time_ms: 127.371
  iterations_since_restore: 308
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5645.58771777153
  time_this_iter_s: 18.442900896072388
  time_total_s: 5645.58771777153
  timestamp: 1593890108
  timesteps_since_restore: 3080000
  timesteps_this_iter: 10000
  timesteps_total: 3080000
  training_iteration: 308
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5645 s, 308 iter, 3080000 ts, 212 rew

agent-1: 24.0
agent-2: 20.0
agent-3: 19.0
agent-4: 25.0
agent-5: 24.0
agent-6: 20.0
agent-7: 24.0
agent-8: 23.0
agent-9: 21.0
agent-10: 26.0
Sum Reward: 226.0
Avg Reward: 22.6
Min Reward: 19.0
Gini Coefficient: 0.05663716814159292
20:20 Ratio: 1.3076923076923077
Max-min Ratio: 1.368421052631579
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-15-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 212.76
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 308
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.33
    dispatch_time_ms: 7.754
    learner:
      cur_lr: 0.0011548720067366958
      grad_gnorm: 0.3661656081676483
      policy_entropy: 190.96401977539062
      policy_loss: 0.03548697009682655
      var_gnorm: 59.728824615478516
      vf_explained_var: 0.8721218705177307
      vf_loss: 0.00037241828977130353
    num_steps_sampled: 3090000
    num_steps_trained: 3090000
    wait_time_ms: 165.22
  iterations_since_restore: 309
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5663.373158693314
  time_this_iter_s: 17.785440921783447
  time_total_s: 5663.373158693314
  timestamp: 1593890126
  timesteps_since_restore: 3090000
  timesteps_this_iter: 10000
  timesteps_total: 3090000
  training_iteration: 309
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5663 s, 309 iter, 3090000 ts, 213 rew

agent-1: 18.0
agent-2: 22.0
agent-3: 17.0
agent-4: 24.0
agent-5: 24.0
agent-6: 16.0
agent-7: 21.0
agent-8: 18.0
agent-9: 14.0
agent-10: 19.0
Sum Reward: 193.0
Avg Reward: 19.3
Min Reward: 14.0
Gini Coefficient: 0.09378238341968911
20:20 Ratio: 1.6
Max-min Ratio: 1.7142857142857142
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-15-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 212.46
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 309
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.896
    dispatch_time_ms: 6.811
    learner:
      cur_lr: 0.0011542059946805239
      grad_gnorm: 0.3845323622226715
      policy_entropy: 192.75245666503906
      policy_loss: -0.15029209852218628
      var_gnorm: 59.71916961669922
      vf_explained_var: -1.0
      vf_loss: 0.0020257802680134773
    num_steps_sampled: 3100000
    num_steps_trained: 3100000
    wait_time_ms: 169.19
  iterations_since_restore: 310
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5681.338662385941
  time_this_iter_s: 17.965503692626953
  time_total_s: 5681.338662385941
  timestamp: 1593890144
  timesteps_since_restore: 3100000
  timesteps_this_iter: 10000
  timesteps_total: 3100000
  training_iteration: 310
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5681 s, 310 iter, 3100000 ts, 212 rew

agent-1: 22.0
agent-2: 26.0
agent-3: 24.0
agent-4: 18.0
agent-5: 13.0
agent-6: 22.0
agent-7: 23.0
agent-8: 24.0
agent-9: 18.0
agent-10: 22.0
Sum Reward: 212.0
Avg Reward: 21.2
Min Reward: 13.0
Gini Coefficient: 0.09056603773584905
20:20 Ratio: 1.6129032258064515
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-16-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 212.72
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 310
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.615
    dispatch_time_ms: 6.082
    learner:
      cur_lr: 0.001153539982624352
      grad_gnorm: 2.8982391357421875
      policy_entropy: 167.10789489746094
      policy_loss: -1.033715009689331
      var_gnorm: 59.92047119140625
      vf_explained_var: -1.0
      vf_loss: 0.014764071442186832
    num_steps_sampled: 3110000
    num_steps_trained: 3110000
    wait_time_ms: 176.669
  iterations_since_restore: 311
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5699.195691585541
  time_this_iter_s: 17.85702919960022
  time_total_s: 5699.195691585541
  timestamp: 1593890162
  timesteps_since_restore: 3110000
  timesteps_this_iter: 10000
  timesteps_total: 3110000
  training_iteration: 311
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5699 s, 311 iter, 3110000 ts, 213 rew

agent-1: 17.0
agent-2: 19.0
agent-3: 23.0
agent-4: 20.0
agent-5: 21.0
agent-6: 21.0
agent-7: 14.0
agent-8: 24.0
agent-9: 25.0
agent-10: 19.0
Sum Reward: 203.0
Avg Reward: 20.3
Min Reward: 14.0
Gini Coefficient: 0.08620689655172414
20:20 Ratio: 1.5806451612903225
Max-min Ratio: 1.7857142857142858
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-16-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 212.57
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 311
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.297
    dispatch_time_ms: 7.037
    learner:
      cur_lr: 0.00115287397056818
      grad_gnorm: 39.999996185302734
      policy_entropy: 6.426519393920898
      policy_loss: -0.3038378953933716
      var_gnorm: 59.921913146972656
      vf_explained_var: -0.11553657054901123
      vf_loss: 183.12962341308594
    num_steps_sampled: 3120000
    num_steps_trained: 3120000
    wait_time_ms: 162.768
  iterations_since_restore: 312
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5717.1418471336365
  time_this_iter_s: 17.946155548095703
  time_total_s: 5717.1418471336365
  timestamp: 1593890180
  timesteps_since_restore: 3120000
  timesteps_this_iter: 10000
  timesteps_total: 3120000
  training_iteration: 312
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5717 s, 312 iter, 3120000 ts, 213 rew

agent-1: 10.0
agent-2: 30.0
agent-3: 22.0
agent-4: 24.0
agent-5: 18.0
agent-6: 20.0
agent-7: 15.0
agent-8: 21.0
agent-9: 23.0
agent-10: 18.0
Sum Reward: 201.0
Avg Reward: 20.1
Min Reward: 10.0
Gini Coefficient: 0.1398009950248756
20:20 Ratio: 2.16
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-16-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 212.51
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 312
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.998
    dispatch_time_ms: 6.927
    learner:
      cur_lr: 0.0011522079585120082
      grad_gnorm: 0.8278924822807312
      policy_entropy: 186.70860290527344
      policy_loss: -0.09665196388959885
      var_gnorm: 59.95392990112305
      vf_explained_var: -1.0
      vf_loss: 0.0010770774679258466
    num_steps_sampled: 3130000
    num_steps_trained: 3130000
    wait_time_ms: 165.355
  iterations_since_restore: 313
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5734.951692581177
  time_this_iter_s: 17.809845447540283
  time_total_s: 5734.951692581177
  timestamp: 1593890198
  timesteps_since_restore: 3130000
  timesteps_this_iter: 10000
  timesteps_total: 3130000
  training_iteration: 313
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5734 s, 313 iter, 3130000 ts, 213 rew

agent-1: 11.0
agent-2: 18.0
agent-3: 24.0
agent-4: 19.0
agent-5: 22.0
agent-6: 17.0
agent-7: 24.0
agent-8: 19.0
agent-9: 22.0
agent-10: 24.0
Sum Reward: 200.0
Avg Reward: 20.0
Min Reward: 11.0
Gini Coefficient: 0.104
20:20 Ratio: 1.7142857142857142
Max-min Ratio: 2.1818181818181817
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-16-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 212.26
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 313
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.586
    dispatch_time_ms: 6.241
    learner:
      cur_lr: 0.0011515419464558363
      grad_gnorm: 40.00000762939453
      policy_entropy: 7.651069641113281
      policy_loss: 7.609794616699219
      var_gnorm: 59.961544036865234
      vf_explained_var: 0.5724096298217773
      vf_loss: 84.0367202758789
    num_steps_sampled: 3140000
    num_steps_trained: 3140000
    wait_time_ms: 153.643
  iterations_since_restore: 314
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5752.8100962638855
  time_this_iter_s: 17.85840368270874
  time_total_s: 5752.8100962638855
  timestamp: 1593890216
  timesteps_since_restore: 3140000
  timesteps_this_iter: 10000
  timesteps_total: 3140000
  training_iteration: 314
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5752 s, 314 iter, 3140000 ts, 212 rew

agent-1: 20.0
agent-2: 24.0
agent-3: 19.0
agent-4: 20.0
agent-5: 23.0
agent-6: 19.0
agent-7: 29.0
agent-8: 28.0
agent-9: 13.0
agent-10: 30.0
Sum Reward: 225.0
Avg Reward: 22.5
Min Reward: 13.0
Gini Coefficient: 0.12577777777777777
20:20 Ratio: 1.84375
Max-min Ratio: 2.3076923076923075
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-17-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 212.72
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 314
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.93
    dispatch_time_ms: 6.768
    learner:
      cur_lr: 0.0011508760508149862
      grad_gnorm: 0.48860225081443787
      policy_entropy: 186.14068603515625
      policy_loss: -0.28760603070259094
      var_gnorm: 60.06393051147461
      vf_explained_var: -0.5356587171554565
      vf_loss: 0.00020580545242410153
    num_steps_sampled: 3150000
    num_steps_trained: 3150000
    wait_time_ms: 175.17
  iterations_since_restore: 315
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5773.951494216919
  time_this_iter_s: 21.141397953033447
  time_total_s: 5773.951494216919
  timestamp: 1593890237
  timesteps_since_restore: 3150000
  timesteps_this_iter: 10000
  timesteps_total: 3150000
  training_iteration: 315
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5773 s, 315 iter, 3150000 ts, 213 rew

agent-1: 19.0
agent-2: 22.0
agent-3: 24.0
agent-4: 24.0
agent-5: 20.0
agent-6: 17.0
agent-7: 17.0
agent-8: 13.0
agent-9: 19.0
agent-10: 23.0
Sum Reward: 198.0
Avg Reward: 19.8
Min Reward: 13.0
Gini Coefficient: 0.09494949494949495
20:20 Ratio: 1.6
Max-min Ratio: 1.8461538461538463
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-17-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 212.65
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 315
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.935
    dispatch_time_ms: 7.492
    learner:
      cur_lr: 0.0011502100387588143
      grad_gnorm: 0.3074527978897095
      policy_entropy: 191.8936767578125
      policy_loss: 0.24405710399150848
      var_gnorm: 60.065425872802734
      vf_explained_var: -0.914513349533081
      vf_loss: 0.00013303273590281606
    num_steps_sampled: 3160000
    num_steps_trained: 3160000
    wait_time_ms: 165.69
  iterations_since_restore: 316
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5792.061978816986
  time_this_iter_s: 18.11048460006714
  time_total_s: 5792.061978816986
  timestamp: 1593890255
  timesteps_since_restore: 3160000
  timesteps_this_iter: 10000
  timesteps_total: 3160000
  training_iteration: 316
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5792 s, 316 iter, 3160000 ts, 213 rew

agent-1: 19.0
agent-2: 15.0
agent-3: 25.0
agent-4: 17.0
agent-5: 23.0
agent-6: 24.0
agent-7: 21.0
agent-8: 12.0
agent-9: 19.0
agent-10: 20.0
Sum Reward: 195.0
Avg Reward: 19.5
Min Reward: 12.0
Gini Coefficient: 0.11128205128205128
20:20 Ratio: 1.8148148148148149
Max-min Ratio: 2.0833333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-17-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 212.39
  episode_reward_min: 156.0
  episodes_this_iter: 1
  episodes_total: 316
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.694
    dispatch_time_ms: 8.817
    learner:
      cur_lr: 0.0011495440267026424
      grad_gnorm: 0.20473513007164001
      policy_entropy: 190.5287628173828
      policy_loss: 0.1025022640824318
      var_gnorm: 60.255863189697266
      vf_explained_var: -1.0
      vf_loss: 0.0001696155668469146
    num_steps_sampled: 3170000
    num_steps_trained: 3170000
    wait_time_ms: 169.43
  iterations_since_restore: 317
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5809.838317155838
  time_this_iter_s: 17.77633833885193
  time_total_s: 5809.838317155838
  timestamp: 1593890273
  timesteps_since_restore: 3170000
  timesteps_this_iter: 10000
  timesteps_total: 3170000
  training_iteration: 317
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5809 s, 317 iter, 3170000 ts, 212 rew

agent-1: 22.0
agent-2: 24.0
agent-3: 25.0
agent-4: 17.0
agent-5: 20.0
agent-6: 21.0
agent-7: 30.0
agent-8: 31.0
agent-9: 23.0
agent-10: 20.0
Sum Reward: 233.0
Avg Reward: 23.3
Min Reward: 17.0
Gini Coefficient: 0.09914163090128755
20:20 Ratio: 1.6486486486486487
Max-min Ratio: 1.8235294117647058
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-18-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 213.16
  episode_reward_min: 188.0
  episodes_this_iter: 1
  episodes_total: 317
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 4.659
    dispatch_time_ms: 6.931
    learner:
      cur_lr: 0.0011488780146464705
      grad_gnorm: 39.999996185302734
      policy_entropy: 9.574411392211914
      policy_loss: -5.583184719085693
      var_gnorm: 60.261138916015625
      vf_explained_var: -0.23102843761444092
      vf_loss: 119.78241729736328
    num_steps_sampled: 3180000
    num_steps_trained: 3180000
    wait_time_ms: 161.048
  iterations_since_restore: 318
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5827.7234880924225
  time_this_iter_s: 17.885170936584473
  time_total_s: 5827.7234880924225
  timestamp: 1593890291
  timesteps_since_restore: 3180000
  timesteps_this_iter: 10000
  timesteps_total: 3180000
  training_iteration: 318
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5827 s, 318 iter, 3180000 ts, 213 rew

agent-1: 23.0
agent-2: 18.0
agent-3: 24.0
agent-4: 18.0
agent-5: 15.0
agent-6: 18.0
agent-7: 23.0
agent-8: 19.0
agent-9: 21.0
agent-10: 23.0
Sum Reward: 202.0
Avg Reward: 20.2
Min Reward: 15.0
Gini Coefficient: 0.07821782178217822
20:20 Ratio: 1.4242424242424243
Max-min Ratio: 1.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-18-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 213.2
  episode_reward_min: 188.0
  episodes_this_iter: 1
  episodes_total: 318
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.861
    dispatch_time_ms: 7.479
    learner:
      cur_lr: 0.0011482120025902987
      grad_gnorm: 1.075720191001892
      policy_entropy: 140.7053680419922
      policy_loss: -0.5808979868888855
      var_gnorm: 60.32638931274414
      vf_explained_var: -1.0
      vf_loss: 0.0022265661973506212
    num_steps_sampled: 3190000
    num_steps_trained: 3190000
    wait_time_ms: 167.522
  iterations_since_restore: 319
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5845.235396146774
  time_this_iter_s: 17.511908054351807
  time_total_s: 5845.235396146774
  timestamp: 1593890308
  timesteps_since_restore: 3190000
  timesteps_this_iter: 10000
  timesteps_total: 3190000
  training_iteration: 319
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5845 s, 319 iter, 3190000 ts, 213 rew

agent-1: 23.0
agent-2: 22.0
agent-3: 20.0
agent-4: 23.0
agent-5: 21.0
agent-6: 27.0
agent-7: 15.0
agent-8: 28.0
agent-9: 19.0
agent-10: 28.0
Sum Reward: 226.0
Avg Reward: 22.6
Min Reward: 15.0
Gini Coefficient: 0.09823008849557523
20:20 Ratio: 1.6470588235294117
Max-min Ratio: 1.8666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-18-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 213.51
  episode_reward_min: 188.0
  episodes_this_iter: 1
  episodes_total: 319
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.05
    dispatch_time_ms: 6.791
    learner:
      cur_lr: 0.0011475459905341268
      grad_gnorm: 0.2164810299873352
      policy_entropy: 159.89414978027344
      policy_loss: -0.11612938344478607
      var_gnorm: 60.32695007324219
      vf_explained_var: -0.15241026878356934
      vf_loss: 7.135600026231259e-05
    num_steps_sampled: 3200000
    num_steps_trained: 3200000
    wait_time_ms: 173.517
  iterations_since_restore: 320
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5863.2423577308655
  time_this_iter_s: 18.006961584091187
  time_total_s: 5863.2423577308655
  timestamp: 1593890326
  timesteps_since_restore: 3200000
  timesteps_this_iter: 10000
  timesteps_total: 3200000
  training_iteration: 320
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5863 s, 320 iter, 3200000 ts, 214 rew

agent-1: 25.0
agent-2: 22.0
agent-3: 17.0
agent-4: 21.0
agent-5: 16.0
agent-6: 14.0
agent-7: 25.0
agent-8: 17.0
agent-9: 23.0
agent-10: 27.0
Sum Reward: 207.0
Avg Reward: 20.7
Min Reward: 14.0
Gini Coefficient: 0.11545893719806763
20:20 Ratio: 1.7333333333333334
Max-min Ratio: 1.9285714285714286
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-19-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 213.5
  episode_reward_min: 188.0
  episodes_this_iter: 1
  episodes_total: 320
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.605
    dispatch_time_ms: 8.003
    learner:
      cur_lr: 0.0011468799784779549
      grad_gnorm: 6.1245293617248535
      policy_entropy: 151.3263702392578
      policy_loss: 0.98627108335495
      var_gnorm: 60.39231491088867
      vf_explained_var: -0.9211132526397705
      vf_loss: 0.07848429679870605
    num_steps_sampled: 3210000
    num_steps_trained: 3210000
    wait_time_ms: 167.999
  iterations_since_restore: 321
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5881.046537399292
  time_this_iter_s: 17.804179668426514
  time_total_s: 5881.046537399292
  timestamp: 1593890344
  timesteps_since_restore: 3210000
  timesteps_this_iter: 10000
  timesteps_total: 3210000
  training_iteration: 321
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5881 s, 321 iter, 3210000 ts, 214 rew

agent-1: 25.0
agent-2: 26.0
agent-3: 22.0
agent-4: 17.0
agent-5: 15.0
agent-6: 29.0
agent-7: 29.0
agent-8: 20.0
agent-9: 25.0
agent-10: 19.0
Sum Reward: 227.0
Avg Reward: 22.7
Min Reward: 15.0
Gini Coefficient: 0.11585903083700441
20:20 Ratio: 1.8125
Max-min Ratio: 1.9333333333333333
agent-1: 19.0
agent-2: 26.0
agent-3: 30.0
agent-4: 28.0
agent-5: 21.0
agent-6: 11.0
agent-7: 23.0
agent-8: 13.0
agent-9: 14.0
agent-10: 24.0
Sum Reward: 209.0
Avg Reward: 20.9
Min Reward: 11.0
Gini Coefficient: 0.16889952153110047
20:20 Ratio: 2.4166666666666665
Max-min Ratio: 2.727272727272727
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-19-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 213.7
  episode_reward_min: 188.0
  episodes_this_iter: 2
  episodes_total: 322
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.031
    dispatch_time_ms: 30.075
    learner:
      cur_lr: 0.001146213966421783
      grad_gnorm: 0.555158793926239
      policy_entropy: 176.15936279296875
      policy_loss: -0.34497833251953125
      var_gnorm: 60.40840530395508
      vf_explained_var: -1.0
      vf_loss: 0.0004648198082577437
    num_steps_sampled: 3220000
    num_steps_trained: 3220000
    wait_time_ms: 167.098
  iterations_since_restore: 322
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5899.739192724228
  time_this_iter_s: 18.692655324935913
  time_total_s: 5899.739192724228
  timestamp: 1593890363
  timesteps_since_restore: 3220000
  timesteps_this_iter: 10000
  timesteps_total: 3220000
  training_iteration: 322
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5899 s, 322 iter, 3220000 ts, 214 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-19-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 213.7
  episode_reward_min: 188.0
  episodes_this_iter: 0
  episodes_total: 322
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.63
    dispatch_time_ms: 40.238
    learner:
      cur_lr: 0.001145547954365611
      grad_gnorm: 13.527358055114746
      policy_entropy: 166.34112548828125
      policy_loss: 1.153839349746704
      var_gnorm: 60.72637176513672
      vf_explained_var: -1.0
      vf_loss: 0.018180545419454575
    num_steps_sampled: 3230000
    num_steps_trained: 3230000
    wait_time_ms: 146.348
  iterations_since_restore: 323
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5918.255040168762
  time_this_iter_s: 18.5158474445343
  time_total_s: 5918.255040168762
  timestamp: 1593890382
  timesteps_since_restore: 3230000
  timesteps_this_iter: 10000
  timesteps_total: 3230000
  training_iteration: 323
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5918 s, 323 iter, 3230000 ts, 214 rew

agent-1: 20.0
agent-2: 25.0
agent-3: 13.0
agent-4: 17.0
agent-5: 19.0
agent-6: 18.0
agent-7: 22.0
agent-8: 27.0
agent-9: 29.0
agent-10: 13.0
Sum Reward: 203.0
Avg Reward: 20.3
Min Reward: 13.0
Gini Coefficient: 0.14532019704433496
20:20 Ratio: 2.1538461538461537
Max-min Ratio: 2.230769230769231
agent-1: 21.0
agent-2: 21.0
agent-3: 27.0
agent-4: 24.0
agent-5: 20.0
agent-6: 20.0
agent-7: 19.0
agent-8: 14.0
agent-9: 29.0
agent-10: 17.0
Sum Reward: 212.0
Avg Reward: 21.2
Min Reward: 14.0
Gini Coefficient: 0.11037735849056604
20:20 Ratio: 1.8064516129032258
Max-min Ratio: 2.0714285714285716
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-20-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 213.44
  episode_reward_min: 188.0
  episodes_this_iter: 2
  episodes_total: 324
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.336
    dispatch_time_ms: 33.051
    learner:
      cur_lr: 0.0011448819423094392
      grad_gnorm: 8.53866958618164
      policy_entropy: 180.53639221191406
      policy_loss: 1.7422082424163818
      var_gnorm: 60.73040008544922
      vf_explained_var: -1.0
      vf_loss: 0.010784303769469261
    num_steps_sampled: 3240000
    num_steps_trained: 3240000
    wait_time_ms: 148.588
  iterations_since_restore: 324
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5937.2220730781555
  time_this_iter_s: 18.96703290939331
  time_total_s: 5937.2220730781555
  timestamp: 1593890401
  timesteps_since_restore: 3240000
  timesteps_this_iter: 10000
  timesteps_total: 3240000
  training_iteration: 324
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5937 s, 324 iter, 3240000 ts, 213 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-20-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 213.44
  episode_reward_min: 188.0
  episodes_this_iter: 0
  episodes_total: 324
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.965
    dispatch_time_ms: 31.394
    learner:
      cur_lr: 0.0011442160466685891
      grad_gnorm: 0.7246255278587341
      policy_entropy: 150.41433715820312
      policy_loss: -0.8770650029182434
      var_gnorm: 61.01811218261719
      vf_explained_var: 0.9786688685417175
      vf_loss: 0.0003374690131749958
    num_steps_sampled: 3250000
    num_steps_trained: 3250000
    wait_time_ms: 128.44
  iterations_since_restore: 325
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5955.883527755737
  time_this_iter_s: 18.661454677581787
  time_total_s: 5955.883527755737
  timestamp: 1593890419
  timesteps_since_restore: 3250000
  timesteps_this_iter: 10000
  timesteps_total: 3250000
  training_iteration: 325
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5955 s, 325 iter, 3250000 ts, 213 rew

agent-1: 27.0
agent-2: 20.0
agent-3: 32.0
agent-4: 24.0
agent-5: 31.0
agent-6: 11.0
agent-7: 22.0
agent-8: 11.0
agent-9: 17.0
agent-10: 24.0
Sum Reward: 219.0
Avg Reward: 21.9
Min Reward: 11.0
Gini Coefficient: 0.17945205479452056
20:20 Ratio: 2.8636363636363638
Max-min Ratio: 2.909090909090909
agent-1: 19.0
agent-2: 19.0
agent-3: 30.0
agent-4: 19.0
agent-5: 23.0
agent-6: 19.0
agent-7: 20.0
agent-8: 22.0
agent-9: 21.0
agent-10: 23.0
Sum Reward: 215.0
Avg Reward: 21.5
Min Reward: 19.0
Gini Coefficient: 0.07302325581395348
20:20 Ratio: 1.394736842105263
Max-min Ratio: 1.5789473684210527
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-20-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 213.51
  episode_reward_min: 188.0
  episodes_this_iter: 2
  episodes_total: 326
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 4.117
    dispatch_time_ms: 20.957
    learner:
      cur_lr: 0.0011435500346124172
      grad_gnorm: 2.438551425933838
      policy_entropy: 173.84860229492188
      policy_loss: -1.2867956161499023
      var_gnorm: 61.021392822265625
      vf_explained_var: -1.0
      vf_loss: 0.005211076699197292
    num_steps_sampled: 3260000
    num_steps_trained: 3260000
    wait_time_ms: 165.458
  iterations_since_restore: 326
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5975.064284563065
  time_this_iter_s: 19.18075680732727
  time_total_s: 5975.064284563065
  timestamp: 1593890439
  timesteps_since_restore: 3260000
  timesteps_this_iter: 10000
  timesteps_total: 3260000
  training_iteration: 326
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5975 s, 326 iter, 3260000 ts, 214 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-20-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 213.51
  episode_reward_min: 188.0
  episodes_this_iter: 0
  episodes_total: 326
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.461
    dispatch_time_ms: 9.653
    learner:
      cur_lr: 0.0011428840225562453
      grad_gnorm: 1.3401967287063599
      policy_entropy: 170.06419372558594
      policy_loss: -0.605747401714325
      var_gnorm: 61.34489059448242
      vf_explained_var: 0.31107866764068604
      vf_loss: 0.00547159556299448
    num_steps_sampled: 3270000
    num_steps_trained: 3270000
    wait_time_ms: 168.338
  iterations_since_restore: 327
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 5992.96005320549
  time_this_iter_s: 17.895768642425537
  time_total_s: 5992.96005320549
  timestamp: 1593890457
  timesteps_since_restore: 3270000
  timesteps_this_iter: 10000
  timesteps_total: 3270000
  training_iteration: 327
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 5992 s, 327 iter, 3270000 ts, 214 rew

agent-1: 24.0
agent-2: 23.0
agent-3: 14.0
agent-4: 19.0
agent-5: 15.0
agent-6: 14.0
agent-7: 26.0
agent-8: 16.0
agent-9: 26.0
agent-10: 21.0
Sum Reward: 198.0
Avg Reward: 19.8
Min Reward: 14.0
Gini Coefficient: 0.13131313131313133
20:20 Ratio: 1.8571428571428572
Max-min Ratio: 1.8571428571428572
agent-1: 14.0
agent-2: 29.0
agent-3: 25.0
agent-4: 12.0
agent-5: 17.0
agent-6: 28.0
agent-7: 28.0
agent-8: 31.0
agent-9: 28.0
agent-10: 30.0
Sum Reward: 242.0
Avg Reward: 24.2
Min Reward: 12.0
Gini Coefficient: 0.14545454545454545
20:20 Ratio: 2.3461538461538463
Max-min Ratio: 2.5833333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-21-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 213.77
  episode_reward_min: 188.0
  episodes_this_iter: 2
  episodes_total: 328
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.846
    dispatch_time_ms: 8.208
    learner:
      cur_lr: 0.0011422180105000734
      grad_gnorm: 3.299240827560425
      policy_entropy: 183.81089782714844
      policy_loss: 1.9984323978424072
      var_gnorm: 61.355506896972656
      vf_explained_var: -1.0
      vf_loss: 0.0088294493034482
    num_steps_sampled: 3280000
    num_steps_trained: 3280000
    wait_time_ms: 171.417
  iterations_since_restore: 328
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6010.8811938762665
  time_this_iter_s: 17.921140670776367
  time_total_s: 6010.8811938762665
  timestamp: 1593890474
  timesteps_since_restore: 3280000
  timesteps_this_iter: 10000
  timesteps_total: 3280000
  training_iteration: 328
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6010 s, 328 iter, 3280000 ts, 214 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-21-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 213.77
  episode_reward_min: 188.0
  episodes_this_iter: 0
  episodes_total: 328
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.812
    dispatch_time_ms: 9.07
    learner:
      cur_lr: 0.0011415519984439015
      grad_gnorm: 0.08777158707380295
      policy_entropy: 185.95431518554688
      policy_loss: -0.05722573772072792
      var_gnorm: 61.517433166503906
      vf_explained_var: 0.9955306053161621
      vf_loss: 9.66122024692595e-06
    num_steps_sampled: 3290000
    num_steps_trained: 3290000
    wait_time_ms: 178.438
  iterations_since_restore: 329
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6028.671533823013
  time_this_iter_s: 17.790339946746826
  time_total_s: 6028.671533823013
  timestamp: 1593890492
  timesteps_since_restore: 3290000
  timesteps_this_iter: 10000
  timesteps_total: 3290000
  training_iteration: 329
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6028 s, 329 iter, 3290000 ts, 214 rew

agent-1: 16.0
agent-2: 22.0
agent-3: 28.0
agent-4: 22.0
agent-5: 21.0
agent-6: 20.0
agent-7: 18.0
agent-8: 33.0
agent-9: 8.0
agent-10: 27.0
Sum Reward: 215.0
Avg Reward: 21.5
Min Reward: 8.0
Gini Coefficient: 0.16790697674418606
20:20 Ratio: 2.5416666666666665
Max-min Ratio: 4.125
agent-1: 18.0
agent-2: 15.0
agent-3: 22.0
agent-4: 21.0
agent-5: 25.0
agent-6: 20.0
agent-7: 25.0
agent-8: 23.0
agent-9: 13.0
agent-10: 22.0
Sum Reward: 204.0
Avg Reward: 20.4
Min Reward: 13.0
Gini Coefficient: 0.10294117647058823
20:20 Ratio: 1.7857142857142858
Max-min Ratio: 1.9230769230769231
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-21-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 213.87
  episode_reward_min: 188.0
  episodes_this_iter: 2
  episodes_total: 330
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.258
    dispatch_time_ms: 8.818
    learner:
      cur_lr: 0.0011408859863877296
      grad_gnorm: 0.4573572278022766
      policy_entropy: 190.29676818847656
      policy_loss: -0.22442811727523804
      var_gnorm: 61.51762390136719
      vf_explained_var: -1.0
      vf_loss: 0.0012489726068452
    num_steps_sampled: 3300000
    num_steps_trained: 3300000
    wait_time_ms: 167.291
  iterations_since_restore: 330
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6046.6811735630035
  time_this_iter_s: 18.009639739990234
  time_total_s: 6046.6811735630035
  timestamp: 1593890510
  timesteps_since_restore: 3300000
  timesteps_this_iter: 10000
  timesteps_total: 3300000
  training_iteration: 330
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6046 s, 330 iter, 3300000 ts, 214 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-22-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 213.87
  episode_reward_min: 188.0
  episodes_this_iter: 0
  episodes_total: 330
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.542
    dispatch_time_ms: 5.78
    learner:
      cur_lr: 0.0011402199743315578
      grad_gnorm: 0.13001464307308197
      policy_entropy: 163.68527221679688
      policy_loss: 0.06182898208498955
      var_gnorm: 61.749271392822266
      vf_explained_var: 0.9955874681472778
      vf_loss: 1.1780048225773498e-05
    num_steps_sampled: 3310000
    num_steps_trained: 3310000
    wait_time_ms: 171.201
  iterations_since_restore: 331
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6064.395484685898
  time_this_iter_s: 17.714311122894287
  time_total_s: 6064.395484685898
  timestamp: 1593890528
  timesteps_since_restore: 3310000
  timesteps_this_iter: 10000
  timesteps_total: 3310000
  training_iteration: 331
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6064 s, 331 iter, 3310000 ts, 214 rew

agent-1: 18.0
agent-2: 9.0
agent-3: 18.0
agent-4: 27.0
agent-5: 18.0
agent-6: 26.0
agent-7: 20.0
agent-8: 29.0
agent-9: 19.0
agent-10: 17.0
Sum Reward: 201.0
Avg Reward: 20.1
Min Reward: 9.0
Gini Coefficient: 0.14776119402985075
20:20 Ratio: 2.1538461538461537
Max-min Ratio: 3.2222222222222223
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-22-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 213.84
  episode_reward_min: 188.0
  episodes_this_iter: 1
  episodes_total: 331
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.544
    dispatch_time_ms: 9.353
    learner:
      cur_lr: 0.0011395539622753859
      grad_gnorm: 39.99999237060547
      policy_entropy: 6.185129165649414
      policy_loss: -24.927522659301758
      var_gnorm: 61.74692153930664
      vf_explained_var: -0.055370330810546875
      vf_loss: 308.8486022949219
    num_steps_sampled: 3320000
    num_steps_trained: 3320000
    wait_time_ms: 158.278
  iterations_since_restore: 332
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6085.340798616409
  time_this_iter_s: 20.945313930511475
  time_total_s: 6085.340798616409
  timestamp: 1593890549
  timesteps_since_restore: 3320000
  timesteps_this_iter: 10000
  timesteps_total: 3320000
  training_iteration: 332
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6085 s, 332 iter, 3320000 ts, 214 rew

agent-1: 17.0
agent-2: 23.0
agent-3: 18.0
agent-4: 17.0
agent-5: 16.0
agent-6: 20.0
agent-7: 24.0
agent-8: 13.0
agent-9: 17.0
agent-10: 23.0
Sum Reward: 188.0
Avg Reward: 18.8
Min Reward: 13.0
Gini Coefficient: 0.1
20:20 Ratio: 1.6206896551724137
Max-min Ratio: 1.8461538461538463
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-22-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 213.54
  episode_reward_min: 188.0
  episodes_this_iter: 1
  episodes_total: 332
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.2
    dispatch_time_ms: 6.691
    learner:
      cur_lr: 0.001138887950219214
      grad_gnorm: 0.43520012497901917
      policy_entropy: 173.26036071777344
      policy_loss: 0.1451803594827652
      var_gnorm: 61.973350524902344
      vf_explained_var: -0.6031146049499512
      vf_loss: 0.0010441991034895182
    num_steps_sampled: 3330000
    num_steps_trained: 3330000
    wait_time_ms: 172.782
  iterations_since_restore: 333
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6103.077125549316
  time_this_iter_s: 17.736326932907104
  time_total_s: 6103.077125549316
  timestamp: 1593890567
  timesteps_since_restore: 3330000
  timesteps_this_iter: 10000
  timesteps_total: 3330000
  training_iteration: 333
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6103 s, 333 iter, 3330000 ts, 214 rew

agent-1: 23.0
agent-2: 22.0
agent-3: 21.0
agent-4: 19.0
agent-5: 25.0
agent-6: 18.0
agent-7: 17.0
agent-8: 16.0
agent-9: 23.0
agent-10: 22.0
Sum Reward: 206.0
Avg Reward: 20.6
Min Reward: 16.0
Gini Coefficient: 0.0766990291262136
20:20 Ratio: 1.4545454545454546
Max-min Ratio: 1.5625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-23-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 213.52
  episode_reward_min: 188.0
  episodes_this_iter: 1
  episodes_total: 333
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.226
    dispatch_time_ms: 7.273
    learner:
      cur_lr: 0.001138222054578364
      grad_gnorm: 40.0000114440918
      policy_entropy: 4.024664402008057
      policy_loss: 2.70599627494812
      var_gnorm: 61.974178314208984
      vf_explained_var: 0.4938458204269409
      vf_loss: 267.4326477050781
    num_steps_sampled: 3340000
    num_steps_trained: 3340000
    wait_time_ms: 157.494
  iterations_since_restore: 334
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6121.038831233978
  time_this_iter_s: 17.961705684661865
  time_total_s: 6121.038831233978
  timestamp: 1593890585
  timesteps_since_restore: 3340000
  timesteps_this_iter: 10000
  timesteps_total: 3340000
  training_iteration: 334
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6121 s, 334 iter, 3340000 ts, 214 rew

agent-1: 29.0
agent-2: 13.0
agent-3: 16.0
agent-4: 25.0
agent-5: 24.0
agent-6: 18.0
agent-7: 15.0
agent-8: 28.0
agent-9: 16.0
agent-10: 21.0
Sum Reward: 205.0
Avg Reward: 20.5
Min Reward: 13.0
Gini Coefficient: 0.1497560975609756
20:20 Ratio: 2.0357142857142856
Max-min Ratio: 2.230769230769231
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-23-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 213.53
  episode_reward_min: 188.0
  episodes_this_iter: 1
  episodes_total: 334
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.579
    dispatch_time_ms: 6.664
    learner:
      cur_lr: 0.001137556042522192
      grad_gnorm: 0.2407693862915039
      policy_entropy: 163.29434204101562
      policy_loss: 0.07156480103731155
      var_gnorm: 62.01823806762695
      vf_explained_var: 0.989096462726593
      vf_loss: 4.43867284047883e-05
    num_steps_sampled: 3350000
    num_steps_trained: 3350000
    wait_time_ms: 168.922
  iterations_since_restore: 335
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6138.747890472412
  time_this_iter_s: 17.709059238433838
  time_total_s: 6138.747890472412
  timestamp: 1593890603
  timesteps_since_restore: 3350000
  timesteps_this_iter: 10000
  timesteps_total: 3350000
  training_iteration: 335
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6138 s, 335 iter, 3350000 ts, 214 rew

agent-1: 19.0
agent-2: 26.0
agent-3: 13.0
agent-4: 25.0
agent-5: 17.0
agent-6: 13.0
agent-7: 23.0
agent-8: 17.0
agent-9: 24.0
agent-10: 14.0
Sum Reward: 191.0
Avg Reward: 19.1
Min Reward: 13.0
Gini Coefficient: 0.1418848167539267
20:20 Ratio: 1.9615384615384615
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-23-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 213.3
  episode_reward_min: 188.0
  episodes_this_iter: 1
  episodes_total: 335
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.533
    dispatch_time_ms: 7.286
    learner:
      cur_lr: 0.00113689003046602
      grad_gnorm: 40.00000762939453
      policy_entropy: 13.123743057250977
      policy_loss: -15.051774978637695
      var_gnorm: 62.01242446899414
      vf_explained_var: 0.20985865592956543
      vf_loss: 144.69338989257812
    num_steps_sampled: 3360000
    num_steps_trained: 3360000
    wait_time_ms: 152.826
  iterations_since_restore: 336
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6156.707140207291
  time_this_iter_s: 17.95924973487854
  time_total_s: 6156.707140207291
  timestamp: 1593890621
  timesteps_since_restore: 3360000
  timesteps_this_iter: 10000
  timesteps_total: 3360000
  training_iteration: 336
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6156 s, 336 iter, 3360000 ts, 213 rew

agent-1: 20.0
agent-2: 28.0
agent-3: 25.0
agent-4: 23.0
agent-5: 22.0
agent-6: 24.0
agent-7: 20.0
agent-8: 19.0
agent-9: 26.0
agent-10: 16.0
Sum Reward: 223.0
Avg Reward: 22.3
Min Reward: 16.0
Gini Coefficient: 0.08744394618834081
20:20 Ratio: 1.542857142857143
Max-min Ratio: 1.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-23-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 213.33
  episode_reward_min: 188.0
  episodes_this_iter: 1
  episodes_total: 336
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.116
    dispatch_time_ms: 6.411
    learner:
      cur_lr: 0.0011362240184098482
      grad_gnorm: 0.2217927873134613
      policy_entropy: 176.13076782226562
      policy_loss: -0.1022009328007698
      var_gnorm: 62.204017639160156
      vf_explained_var: 0.9579633474349976
      vf_loss: 2.5161942176055163e-05
    num_steps_sampled: 3370000
    num_steps_trained: 3370000
    wait_time_ms: 172.714
  iterations_since_restore: 337
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6174.605756759644
  time_this_iter_s: 17.898616552352905
  time_total_s: 6174.605756759644
  timestamp: 1593890639
  timesteps_since_restore: 3370000
  timesteps_this_iter: 10000
  timesteps_total: 3370000
  training_iteration: 337
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6174 s, 337 iter, 3370000 ts, 213 rew

agent-1: 13.0
agent-2: 24.0
agent-3: 26.0
agent-4: 15.0
agent-5: 28.0
agent-6: 13.0
agent-7: 18.0
agent-8: 26.0
agent-9: 27.0
agent-10: 30.0
Sum Reward: 220.0
Avg Reward: 22.0
Min Reward: 13.0
Gini Coefficient: 0.15636363636363637
20:20 Ratio: 2.230769230769231
Max-min Ratio: 2.3076923076923075
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-24-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 213.42
  episode_reward_min: 188.0
  episodes_this_iter: 1
  episodes_total: 337
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.166
    dispatch_time_ms: 7.351
    learner:
      cur_lr: 0.0011355580063536763
      grad_gnorm: 40.000003814697266
      policy_entropy: 3.996283531188965
      policy_loss: -3.5568058490753174
      var_gnorm: 62.19680404663086
      vf_explained_var: 0.25051170587539673
      vf_loss: 66.27532958984375
    num_steps_sampled: 3380000
    num_steps_trained: 3380000
    wait_time_ms: 151.806
  iterations_since_restore: 338
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6192.337721347809
  time_this_iter_s: 17.731964588165283
  time_total_s: 6192.337721347809
  timestamp: 1593890656
  timesteps_since_restore: 3380000
  timesteps_this_iter: 10000
  timesteps_total: 3380000
  training_iteration: 338
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6192 s, 338 iter, 3380000 ts, 213 rew

agent-1: 18.0
agent-2: 19.0
agent-3: 26.0
agent-4: 17.0
agent-5: 16.0
agent-6: 19.0
agent-7: 19.0
agent-8: 23.0
agent-9: 18.0
agent-10: 25.0
Sum Reward: 200.0
Avg Reward: 20.0
Min Reward: 16.0
Gini Coefficient: 0.087
20:20 Ratio: 1.5454545454545454
Max-min Ratio: 1.625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-24-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 213.22
  episode_reward_min: 188.0
  episodes_this_iter: 1
  episodes_total: 338
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.959
    dispatch_time_ms: 29.314
    learner:
      cur_lr: 0.0011348919942975044
      grad_gnorm: 1.8436589241027832
      policy_entropy: 155.2936248779297
      policy_loss: 0.9926971197128296
      var_gnorm: 62.198551177978516
      vf_explained_var: 0.9958775043487549
      vf_loss: 0.0178334079682827
    num_steps_sampled: 3390000
    num_steps_trained: 3390000
    wait_time_ms: 161.383
  iterations_since_restore: 339
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6210.627461433411
  time_this_iter_s: 18.289740085601807
  time_total_s: 6210.627461433411
  timestamp: 1593890675
  timesteps_since_restore: 3390000
  timesteps_this_iter: 10000
  timesteps_total: 3390000
  training_iteration: 339
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6210 s, 339 iter, 3390000 ts, 213 rew

agent-1: 20.0
agent-2: 31.0
agent-3: 18.0
agent-4: 25.0
agent-5: 19.0
agent-6: 31.0
agent-7: 22.0
agent-8: 22.0
agent-9: 18.0
agent-10: 26.0
Sum Reward: 232.0
Avg Reward: 23.2
Min Reward: 18.0
Gini Coefficient: 0.11120689655172414
20:20 Ratio: 1.7222222222222223
Max-min Ratio: 1.7222222222222223
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-24-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 213.57
  episode_reward_min: 188.0
  episodes_this_iter: 1
  episodes_total: 339
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 4.496
    dispatch_time_ms: 33.056
    learner:
      cur_lr: 0.0011342259822413325
      grad_gnorm: 39.9999885559082
      policy_entropy: 3.0818874835968018
      policy_loss: 3.709984540939331
      var_gnorm: 62.19009780883789
      vf_explained_var: 0.5030372142791748
      vf_loss: 115.84614562988281
    num_steps_sampled: 3400000
    num_steps_trained: 3400000
    wait_time_ms: 127.215
  iterations_since_restore: 340
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6229.3517599105835
  time_this_iter_s: 18.72429847717285
  time_total_s: 6229.3517599105835
  timestamp: 1593890693
  timesteps_since_restore: 3400000
  timesteps_this_iter: 10000
  timesteps_total: 3400000
  training_iteration: 340
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6229 s, 340 iter, 3400000 ts, 214 rew

agent-1: 20.0
agent-2: 16.0
agent-3: 15.0
agent-4: 21.0
agent-5: 22.0
agent-6: 18.0
agent-7: 34.0
agent-8: 23.0
agent-9: 22.0
agent-10: 28.0
Sum Reward: 219.0
Avg Reward: 21.9
Min Reward: 15.0
Gini Coefficient: 0.13105022831050228
20:20 Ratio: 2.0
Max-min Ratio: 2.2666666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-25-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 213.67
  episode_reward_min: 188.0
  episodes_this_iter: 1
  episodes_total: 340
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.903
    dispatch_time_ms: 33.906
    learner:
      cur_lr: 0.0011335599701851606
      grad_gnorm: 1.773818016052246
      policy_entropy: 102.2669906616211
      policy_loss: 0.10333296656608582
      var_gnorm: 62.440940856933594
      vf_explained_var: 0.9931967258453369
      vf_loss: 0.0028511255513876677
    num_steps_sampled: 3410000
    num_steps_trained: 3410000
    wait_time_ms: 159.496
  iterations_since_restore: 341
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6248.1183178424835
  time_this_iter_s: 18.766557931900024
  time_total_s: 6248.1183178424835
  timestamp: 1593890712
  timesteps_since_restore: 3410000
  timesteps_this_iter: 10000
  timesteps_total: 3410000
  training_iteration: 341
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6248 s, 341 iter, 3410000 ts, 214 rew

agent-1: 23.0
agent-2: 26.0
agent-3: 26.0
agent-4: 16.0
agent-5: 13.0
agent-6: 24.0
agent-7: 10.0
agent-8: 20.0
agent-9: 31.0
agent-10: 24.0
Sum Reward: 213.0
Avg Reward: 21.3
Min Reward: 10.0
Gini Coefficient: 0.16103286384976526
20:20 Ratio: 2.4782608695652173
Max-min Ratio: 3.1
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-25-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 213.9
  episode_reward_min: 188.0
  episodes_this_iter: 1
  episodes_total: 341
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.22
    dispatch_time_ms: 36.993
    learner:
      cur_lr: 0.0011328939581289887
      grad_gnorm: 0.4589126408100128
      policy_entropy: 135.516357421875
      policy_loss: 0.319873183965683
      var_gnorm: 62.43722915649414
      vf_explained_var: 0.9963054656982422
      vf_loss: 0.004423406906425953
    num_steps_sampled: 3420000
    num_steps_trained: 3420000
    wait_time_ms: 153.467
  iterations_since_restore: 342
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6266.899068117142
  time_this_iter_s: 18.780750274658203
  time_total_s: 6266.899068117142
  timestamp: 1593890731
  timesteps_since_restore: 3420000
  timesteps_this_iter: 10000
  timesteps_total: 3420000
  training_iteration: 342
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6266 s, 342 iter, 3420000 ts, 214 rew

agent-1: 16.0
agent-2: 24.0
agent-3: 21.0
agent-4: 20.0
agent-5: 18.0
agent-6: 19.0
agent-7: 26.0
agent-8: 23.0
agent-9: 5.0
agent-10: 25.0
Sum Reward: 197.0
Avg Reward: 19.7
Min Reward: 5.0
Gini Coefficient: 0.14974619289340102
20:20 Ratio: 2.4285714285714284
Max-min Ratio: 5.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-25-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 213.75
  episode_reward_min: 188.0
  episodes_this_iter: 1
  episodes_total: 342
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.213
    dispatch_time_ms: 37.87
    learner:
      cur_lr: 0.0011322279460728168
      grad_gnorm: 2.448214054107666
      policy_entropy: 152.48794555664062
      policy_loss: 1.6942001581192017
      var_gnorm: 62.63228225708008
      vf_explained_var: 0.9956262707710266
      vf_loss: 0.009090379811823368
    num_steps_sampled: 3430000
    num_steps_trained: 3430000
    wait_time_ms: 141.29
  iterations_since_restore: 343
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6285.771713018417
  time_this_iter_s: 18.872644901275635
  time_total_s: 6285.771713018417
  timestamp: 1593890750
  timesteps_since_restore: 3430000
  timesteps_this_iter: 10000
  timesteps_total: 3430000
  training_iteration: 343
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6285 s, 343 iter, 3430000 ts, 214 rew

agent-1: 17.0
agent-2: 22.0
agent-3: 25.0
agent-4: 19.0
agent-5: 15.0
agent-6: 19.0
agent-7: 18.0
agent-8: 19.0
agent-9: 23.0
agent-10: 14.0
Sum Reward: 191.0
Avg Reward: 19.1
Min Reward: 14.0
Gini Coefficient: 0.09581151832460733
20:20 Ratio: 1.6551724137931034
Max-min Ratio: 1.7857142857142858
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-26-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 213.24
  episode_reward_min: 188.0
  episodes_this_iter: 1
  episodes_total: 343
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.656
    dispatch_time_ms: 6.647
    learner:
      cur_lr: 0.0011315620504319668
      grad_gnorm: 1.9384714365005493
      policy_entropy: 157.82742309570312
      policy_loss: -0.9353209733963013
      var_gnorm: 62.63094711303711
      vf_explained_var: 0.9954873919487
      vf_loss: 0.010554433800280094
    num_steps_sampled: 3440000
    num_steps_trained: 3440000
    wait_time_ms: 147.084
  iterations_since_restore: 344
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6304.2191734313965
  time_this_iter_s: 18.447460412979126
  time_total_s: 6304.2191734313965
  timestamp: 1593890768
  timesteps_since_restore: 3440000
  timesteps_this_iter: 10000
  timesteps_total: 3440000
  training_iteration: 344
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6304 s, 344 iter, 3440000 ts, 213 rew

agent-1: 19.0
agent-2: 16.0
agent-3: 17.0
agent-4: 22.0
agent-5: 20.0
agent-6: 25.0
agent-7: 23.0
agent-8: 20.0
agent-9: 18.0
agent-10: 24.0
Sum Reward: 204.0
Avg Reward: 20.4
Min Reward: 16.0
Gini Coefficient: 0.0803921568627451
20:20 Ratio: 1.4848484848484849
Max-min Ratio: 1.5625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-26-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 213.08
  episode_reward_min: 188.0
  episodes_this_iter: 1
  episodes_total: 344
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.942
    dispatch_time_ms: 6.871
    learner:
      cur_lr: 0.0011308960383757949
      grad_gnorm: 1.974491834640503
      policy_entropy: 153.9197540283203
      policy_loss: 0.25169384479522705
      var_gnorm: 62.74452590942383
      vf_explained_var: 0.9921867251396179
      vf_loss: 0.012296022847294807
    num_steps_sampled: 3450000
    num_steps_trained: 3450000
    wait_time_ms: 170.556
  iterations_since_restore: 345
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6322.234477758408
  time_this_iter_s: 18.01530432701111
  time_total_s: 6322.234477758408
  timestamp: 1593890787
  timesteps_since_restore: 3450000
  timesteps_this_iter: 10000
  timesteps_total: 3450000
  training_iteration: 345
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6322 s, 345 iter, 3450000 ts, 213 rew

agent-1: 22.0
agent-2: 19.0
agent-3: 14.0
agent-4: 15.0
agent-5: 24.0
agent-6: 16.0
agent-7: 22.0
agent-8: 20.0
agent-9: 23.0
agent-10: 27.0
Sum Reward: 202.0
Avg Reward: 20.2
Min Reward: 14.0
Gini Coefficient: 0.11188118811881188
20:20 Ratio: 1.7586206896551724
Max-min Ratio: 1.9285714285714286
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-26-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 213.02
  episode_reward_min: 188.0
  episodes_this_iter: 1
  episodes_total: 345
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.861
    dispatch_time_ms: 6.327
    learner:
      cur_lr: 0.001130230026319623
      grad_gnorm: 39.9999885559082
      policy_entropy: 4.657949447631836
      policy_loss: -6.556334495544434
      var_gnorm: 62.72425842285156
      vf_explained_var: 0.025583922863006592
      vf_loss: 299.4595642089844
    num_steps_sampled: 3460000
    num_steps_trained: 3460000
    wait_time_ms: 148.5
  iterations_since_restore: 346
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6340.075009346008
  time_this_iter_s: 17.840531587600708
  time_total_s: 6340.075009346008
  timestamp: 1593890804
  timesteps_since_restore: 3460000
  timesteps_this_iter: 10000
  timesteps_total: 3460000
  training_iteration: 346
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6340 s, 346 iter, 3460000 ts, 213 rew

agent-1: 18.0
agent-2: 28.0
agent-3: 22.0
agent-4: 15.0
agent-5: 17.0
agent-6: 29.0
agent-7: 21.0
agent-8: 26.0
agent-9: 9.0
agent-10: 19.0
Sum Reward: 204.0
Avg Reward: 20.4
Min Reward: 9.0
Gini Coefficient: 0.16176470588235295
20:20 Ratio: 2.375
Max-min Ratio: 3.2222222222222223
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-27-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 213.01
  episode_reward_min: 188.0
  episodes_this_iter: 1
  episodes_total: 346
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.303
    dispatch_time_ms: 6.472
    learner:
      cur_lr: 0.001129564014263451
      grad_gnorm: 0.6627303957939148
      policy_entropy: 168.97601318359375
      policy_loss: -0.16528287529945374
      var_gnorm: 62.90263366699219
      vf_explained_var: 0.9920717477798462
      vf_loss: 0.006424965802580118
    num_steps_sampled: 3470000
    num_steps_trained: 3470000
    wait_time_ms: 177.771
  iterations_since_restore: 347
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6357.939287900925
  time_this_iter_s: 17.864278554916382
  time_total_s: 6357.939287900925
  timestamp: 1593890822
  timesteps_since_restore: 3470000
  timesteps_this_iter: 10000
  timesteps_total: 3470000
  training_iteration: 347
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6357 s, 347 iter, 3470000 ts, 213 rew

agent-1: 22.0
agent-2: 7.0
agent-3: 34.0
agent-4: 11.0
agent-5: 24.0
agent-6: 16.0
agent-7: 17.0
agent-8: 20.0
agent-9: 24.0
agent-10: 17.0
Sum Reward: 192.0
Avg Reward: 19.2
Min Reward: 7.0
Gini Coefficient: 0.20416666666666666
20:20 Ratio: 3.2222222222222223
Max-min Ratio: 4.857142857142857
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-27-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 212.96
  episode_reward_min: 188.0
  episodes_this_iter: 1
  episodes_total: 347
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.869
    dispatch_time_ms: 6.486
    learner:
      cur_lr: 0.0011288980022072792
      grad_gnorm: 2.4293010234832764
      policy_entropy: 175.66848754882812
      policy_loss: -1.090972900390625
      var_gnorm: 62.91615295410156
      vf_explained_var: 0.9917923212051392
      vf_loss: 0.007725179195404053
    num_steps_sampled: 3480000
    num_steps_trained: 3480000
    wait_time_ms: 164.986
  iterations_since_restore: 348
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6375.7057955265045
  time_this_iter_s: 17.766507625579834
  time_total_s: 6375.7057955265045
  timestamp: 1593890840
  timesteps_since_restore: 3480000
  timesteps_this_iter: 10000
  timesteps_total: 3480000
  training_iteration: 348
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6375 s, 348 iter, 3480000 ts, 213 rew

agent-1: 20.0
agent-2: 20.0
agent-3: 21.0
agent-4: 16.0
agent-5: 29.0
agent-6: 11.0
agent-7: 25.0
agent-8: 39.0
agent-9: 25.0
agent-10: 20.0
Sum Reward: 226.0
Avg Reward: 22.6
Min Reward: 11.0
Gini Coefficient: 0.16991150442477876
20:20 Ratio: 2.5185185185185186
Max-min Ratio: 3.5454545454545454
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-27-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 213.34
  episode_reward_min: 188.0
  episodes_this_iter: 1
  episodes_total: 348
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.304
    dispatch_time_ms: 6.903
    learner:
      cur_lr: 0.0011282319901511073
      grad_gnorm: 2.8115084171295166
      policy_entropy: 144.0984344482422
      policy_loss: -0.11212412267923355
      var_gnorm: 63.110801696777344
      vf_explained_var: 0.6979274749755859
      vf_loss: 0.004388102795928717
    num_steps_sampled: 3490000
    num_steps_trained: 3490000
    wait_time_ms: 170.398
  iterations_since_restore: 349
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6393.5429611206055
  time_this_iter_s: 17.837165594100952
  time_total_s: 6393.5429611206055
  timestamp: 1593890858
  timesteps_since_restore: 3490000
  timesteps_this_iter: 10000
  timesteps_total: 3490000
  training_iteration: 349
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6393 s, 349 iter, 3490000 ts, 213 rew

agent-1: 22.0
agent-2: 11.0
agent-3: 24.0
agent-4: 23.0
agent-5: 26.0
agent-6: 27.0
agent-7: 7.0
agent-8: 30.0
agent-9: 12.0
agent-10: 29.0
Sum Reward: 211.0
Avg Reward: 21.1
Min Reward: 7.0
Gini Coefficient: 0.1995260663507109
20:20 Ratio: 3.2777777777777777
Max-min Ratio: 4.285714285714286
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-27-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 213.5
  episode_reward_min: 188.0
  episodes_this_iter: 1
  episodes_total: 349
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.996
    dispatch_time_ms: 6.19
    learner:
      cur_lr: 0.0011275659780949354
      grad_gnorm: 40.0
      policy_entropy: 8.35184097290039
      policy_loss: -15.373157501220703
      var_gnorm: 63.10921859741211
      vf_explained_var: 0.2883463501930237
      vf_loss: 328.3943176269531
    num_steps_sampled: 3500000
    num_steps_trained: 3500000
    wait_time_ms: 162.404
  iterations_since_restore: 350
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6411.400111436844
  time_this_iter_s: 17.857150316238403
  time_total_s: 6411.400111436844
  timestamp: 1593890876
  timesteps_since_restore: 3500000
  timesteps_this_iter: 10000
  timesteps_total: 3500000
  training_iteration: 350
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6411 s, 350 iter, 3500000 ts, 214 rew

agent-1: 20.0
agent-2: 24.0
agent-3: 38.0
agent-4: 16.0
agent-5: 15.0
agent-6: 17.0
agent-7: 17.0
agent-8: 21.0
agent-9: 34.0
agent-10: 19.0
Sum Reward: 221.0
Avg Reward: 22.1
Min Reward: 15.0
Gini Coefficient: 0.17239819004524887
20:20 Ratio: 2.3225806451612905
Max-min Ratio: 2.533333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-28-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 213.4
  episode_reward_min: 188.0
  episodes_this_iter: 1
  episodes_total: 350
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 4.055
    dispatch_time_ms: 9.08
    learner:
      cur_lr: 0.0011268999660387635
      grad_gnorm: 2.5062003135681152
      policy_entropy: 163.3515167236328
      policy_loss: -0.4761124551296234
      var_gnorm: 63.29666519165039
      vf_explained_var: -1.0
      vf_loss: 0.012032080441713333
    num_steps_sampled: 3510000
    num_steps_trained: 3510000
    wait_time_ms: 165.726
  iterations_since_restore: 351
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6429.234117746353
  time_this_iter_s: 17.834006309509277
  time_total_s: 6429.234117746353
  timestamp: 1593890894
  timesteps_since_restore: 3510000
  timesteps_this_iter: 10000
  timesteps_total: 3510000
  training_iteration: 351
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6429 s, 351 iter, 3510000 ts, 213 rew

agent-1: 11.0
agent-2: 23.0
agent-3: 21.0
agent-4: 23.0
agent-5: 14.0
agent-6: 25.0
agent-7: 19.0
agent-8: 23.0
agent-9: 22.0
agent-10: 22.0
Sum Reward: 203.0
Avg Reward: 20.3
Min Reward: 11.0
Gini Coefficient: 0.10591133004926108
20:20 Ratio: 1.92
Max-min Ratio: 2.272727272727273
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-28-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 213.26
  episode_reward_min: 188.0
  episodes_this_iter: 1
  episodes_total: 351
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.512
    dispatch_time_ms: 7.358
    learner:
      cur_lr: 0.0011262339539825916
      grad_gnorm: 1.1941258907318115
      policy_entropy: 161.16250610351562
      policy_loss: 0.000878429040312767
      var_gnorm: 63.3118896484375
      vf_explained_var: 0.703247606754303
      vf_loss: 0.003341065486893058
    num_steps_sampled: 3520000
    num_steps_trained: 3520000
    wait_time_ms: 150.109
  iterations_since_restore: 352
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6446.929845094681
  time_this_iter_s: 17.695727348327637
  time_total_s: 6446.929845094681
  timestamp: 1593890911
  timesteps_since_restore: 3520000
  timesteps_this_iter: 10000
  timesteps_total: 3520000
  training_iteration: 352
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6446 s, 352 iter, 3520000 ts, 213 rew

agent-1: 12.0
agent-2: 23.0
agent-3: 20.0
agent-4: 22.0
agent-5: 19.0
agent-6: 20.0
agent-7: 14.0
agent-8: 19.0
agent-9: 15.0
agent-10: 16.0
Sum Reward: 180.0
Avg Reward: 18.0
Min Reward: 12.0
Gini Coefficient: 0.10666666666666667
20:20 Ratio: 1.7307692307692308
Max-min Ratio: 1.9166666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-28-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 213.07
  episode_reward_min: 180.0
  episodes_this_iter: 1
  episodes_total: 352
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.856
    dispatch_time_ms: 6.417
    learner:
      cur_lr: 0.0011255679419264197
      grad_gnorm: 0.16167034208774567
      policy_entropy: 164.89378356933594
      policy_loss: -0.003745701164007187
      var_gnorm: 63.46158981323242
      vf_explained_var: 0.9885562658309937
      vf_loss: 1.699745553196408e-05
    num_steps_sampled: 3530000
    num_steps_trained: 3530000
    wait_time_ms: 177.818
  iterations_since_restore: 353
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6464.817364215851
  time_this_iter_s: 17.887519121170044
  time_total_s: 6464.817364215851
  timestamp: 1593890929
  timesteps_since_restore: 3530000
  timesteps_this_iter: 10000
  timesteps_total: 3530000
  training_iteration: 353
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6464 s, 353 iter, 3530000 ts, 213 rew

agent-1: 16.0
agent-2: 25.0
agent-3: 15.0
agent-4: 24.0
agent-5: 23.0
agent-6: 13.0
agent-7: 20.0
agent-8: 17.0
agent-9: 27.0
agent-10: 19.0
Sum Reward: 199.0
Avg Reward: 19.9
Min Reward: 13.0
Gini Coefficient: 0.12814070351758794
20:20 Ratio: 1.8571428571428572
Max-min Ratio: 2.076923076923077
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-29-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 213.03
  episode_reward_min: 180.0
  episodes_this_iter: 1
  episodes_total: 353
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.091
    dispatch_time_ms: 5.731
    learner:
      cur_lr: 0.0011249020462855697
      grad_gnorm: 3.551131010055542
      policy_entropy: 176.25387573242188
      policy_loss: -0.573027491569519
      var_gnorm: 63.43913269042969
      vf_explained_var: 0.6921474933624268
      vf_loss: 0.00046057740109972656
    num_steps_sampled: 3540000
    num_steps_trained: 3540000
    wait_time_ms: 170.8
  iterations_since_restore: 354
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6482.675976037979
  time_this_iter_s: 17.858611822128296
  time_total_s: 6482.675976037979
  timestamp: 1593890947
  timesteps_since_restore: 3540000
  timesteps_this_iter: 10000
  timesteps_total: 3540000
  training_iteration: 354
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6482 s, 354 iter, 3540000 ts, 213 rew

agent-1: 17.0
agent-2: 23.0
agent-3: 16.0
agent-4: 22.0
agent-5: 21.0
agent-6: 18.0
agent-7: 19.0
agent-8: 23.0
agent-9: 25.0
agent-10: 23.0
Sum Reward: 207.0
Avg Reward: 20.7
Min Reward: 16.0
Gini Coefficient: 0.07777777777777778
20:20 Ratio: 1.4545454545454546
Max-min Ratio: 1.5625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-29-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 213.04
  episode_reward_min: 180.0
  episodes_this_iter: 1
  episodes_total: 354
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.526
    dispatch_time_ms: 9.092
    learner:
      cur_lr: 0.0011242360342293978
      grad_gnorm: 1.225948452949524
      policy_entropy: 169.0428466796875
      policy_loss: 0.0581233985722065
      var_gnorm: 63.56680679321289
      vf_explained_var: -0.3037240505218506
      vf_loss: 0.00634360034018755
    num_steps_sampled: 3550000
    num_steps_trained: 3550000
    wait_time_ms: 167.992
  iterations_since_restore: 355
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6500.610752820969
  time_this_iter_s: 17.934776782989502
  time_total_s: 6500.610752820969
  timestamp: 1593890965
  timesteps_since_restore: 3550000
  timesteps_this_iter: 10000
  timesteps_total: 3550000
  training_iteration: 355
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6500 s, 355 iter, 3550000 ts, 213 rew

agent-1: 24.0
agent-2: 12.0
agent-3: 19.0
agent-4: 22.0
agent-5: 23.0
agent-6: 23.0
agent-7: 23.0
agent-8: 22.0
agent-9: 18.0
agent-10: 22.0
Sum Reward: 208.0
Avg Reward: 20.8
Min Reward: 12.0
Gini Coefficient: 0.0798076923076923
20:20 Ratio: 1.5666666666666667
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-29-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 213.22
  episode_reward_min: 180.0
  episodes_this_iter: 1
  episodes_total: 355
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.928
    dispatch_time_ms: 7.489
    learner:
      cur_lr: 0.0011235700221732259
      grad_gnorm: 27.786273956298828
      policy_entropy: 137.16041564941406
      policy_loss: 0.6989579200744629
      var_gnorm: 63.5479736328125
      vf_explained_var: 0.8414642810821533
      vf_loss: 3.3106369972229004
    num_steps_sampled: 3560000
    num_steps_trained: 3560000
    wait_time_ms: 175.639
  iterations_since_restore: 356
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6518.492983341217
  time_this_iter_s: 17.882230520248413
  time_total_s: 6518.492983341217
  timestamp: 1593890983
  timesteps_since_restore: 3560000
  timesteps_this_iter: 10000
  timesteps_total: 3560000
  training_iteration: 356
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6518 s, 356 iter, 3560000 ts, 213 rew

agent-1: 15.0
agent-2: 20.0
agent-3: 31.0
agent-4: 17.0
agent-5: 28.0
agent-6: 31.0
agent-7: 16.0
agent-8: 15.0
agent-9: 29.0
agent-10: 17.0
Sum Reward: 219.0
Avg Reward: 21.9
Min Reward: 15.0
Gini Coefficient: 0.16301369863013698
20:20 Ratio: 2.066666666666667
Max-min Ratio: 2.066666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-30-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 213.45
  episode_reward_min: 180.0
  episodes_this_iter: 1
  episodes_total: 356
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.25
    dispatch_time_ms: 8.17
    learner:
      cur_lr: 0.001122904010117054
      grad_gnorm: 0.2227620929479599
      policy_entropy: 182.39181518554688
      policy_loss: 0.17812548577785492
      var_gnorm: 63.59393310546875
      vf_explained_var: 0.9936155080795288
      vf_loss: 4.570129749481566e-05
    num_steps_sampled: 3570000
    num_steps_trained: 3570000
    wait_time_ms: 170.835
  iterations_since_restore: 357
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6536.252733230591
  time_this_iter_s: 17.75974988937378
  time_total_s: 6536.252733230591
  timestamp: 1593891001
  timesteps_since_restore: 3570000
  timesteps_this_iter: 10000
  timesteps_total: 3570000
  training_iteration: 357
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6536 s, 357 iter, 3570000 ts, 213 rew

agent-1: 20.0
agent-2: 19.0
agent-3: 28.0
agent-4: 18.0
agent-5: 20.0
agent-6: 13.0
agent-7: 16.0
agent-8: 15.0
agent-9: 23.0
agent-10: 20.0
Sum Reward: 192.0
Avg Reward: 19.2
Min Reward: 13.0
Gini Coefficient: 0.11354166666666667
20:20 Ratio: 1.8214285714285714
Max-min Ratio: 2.1538461538461537
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-30-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 274.0
  episode_reward_mean: 213.26
  episode_reward_min: 180.0
  episodes_this_iter: 1
  episodes_total: 357
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.012
    dispatch_time_ms: 5.737
    learner:
      cur_lr: 0.001122237998060882
      grad_gnorm: 40.0
      policy_entropy: 5.958516597747803
      policy_loss: 4.580803871154785
      var_gnorm: 63.5767936706543
      vf_explained_var: 0.5301392674446106
      vf_loss: 89.82887268066406
    num_steps_sampled: 3580000
    num_steps_trained: 3580000
    wait_time_ms: 155.917
  iterations_since_restore: 358
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6553.930119276047
  time_this_iter_s: 17.677386045455933
  time_total_s: 6553.930119276047
  timestamp: 1593891019
  timesteps_since_restore: 3580000
  timesteps_this_iter: 10000
  timesteps_total: 3580000
  training_iteration: 358
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6553 s, 358 iter, 3580000 ts, 213 rew

agent-1: 23.0
agent-2: 6.0
agent-3: 31.0
agent-4: 7.0
agent-5: 26.0
agent-6: 19.0
agent-7: 25.0
agent-8: 22.0
agent-9: 23.0
agent-10: 23.0
Sum Reward: 205.0
Avg Reward: 20.5
Min Reward: 6.0
Gini Coefficient: 0.19073170731707317
20:20 Ratio: 4.384615384615385
Max-min Ratio: 5.166666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-30-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 247.0
  episode_reward_mean: 212.57
  episode_reward_min: 180.0
  episodes_this_iter: 1
  episodes_total: 358
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.97
    dispatch_time_ms: 6.956
    learner:
      cur_lr: 0.0011215719860047102
      grad_gnorm: 0.5203559994697571
      policy_entropy: 160.57322692871094
      policy_loss: -0.17274978756904602
      var_gnorm: 63.72545623779297
      vf_explained_var: 0.917209267616272
      vf_loss: 0.0007533709285780787
    num_steps_sampled: 3590000
    num_steps_trained: 3590000
    wait_time_ms: 170.164
  iterations_since_restore: 359
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6571.787575006485
  time_this_iter_s: 17.857455730438232
  time_total_s: 6571.787575006485
  timestamp: 1593891037
  timesteps_since_restore: 3590000
  timesteps_this_iter: 10000
  timesteps_total: 3590000
  training_iteration: 359
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6571 s, 359 iter, 3590000 ts, 213 rew

agent-1: 35.0
agent-2: 33.0
agent-3: 26.0
agent-4: 15.0
agent-5: 27.0
agent-6: 23.0
agent-7: 28.0
agent-8: 23.0
agent-9: 25.0
agent-10: 15.0
Sum Reward: 250.0
Avg Reward: 25.0
Min Reward: 15.0
Gini Coefficient: 0.1376
20:20 Ratio: 2.2666666666666666
Max-min Ratio: 2.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-30-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 250.0
  episode_reward_mean: 212.67
  episode_reward_min: 180.0
  episodes_this_iter: 1
  episodes_total: 359
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.861
    dispatch_time_ms: 7.067
    learner:
      cur_lr: 0.0011209059739485383
      grad_gnorm: 0.5403804779052734
      policy_entropy: 170.8667449951172
      policy_loss: -0.8044061064720154
      var_gnorm: 63.7143440246582
      vf_explained_var: 0.5693715810775757
      vf_loss: 0.0014019481604918838
    num_steps_sampled: 3600000
    num_steps_trained: 3600000
    wait_time_ms: 172.456
  iterations_since_restore: 360
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6589.593898534775
  time_this_iter_s: 17.806323528289795
  time_total_s: 6589.593898534775
  timestamp: 1593891054
  timesteps_since_restore: 3600000
  timesteps_this_iter: 10000
  timesteps_total: 3600000
  training_iteration: 360
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6589 s, 360 iter, 3600000 ts, 213 rew

agent-1: 33.0
agent-2: 14.0
agent-3: 15.0
agent-4: 18.0
agent-5: 8.0
agent-6: 33.0
agent-7: 27.0
agent-8: 15.0
agent-9: 25.0
agent-10: 34.0
Sum Reward: 222.0
Avg Reward: 22.2
Min Reward: 8.0
Gini Coefficient: 0.22522522522522523
20:20 Ratio: 3.0454545454545454
Max-min Ratio: 4.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-31-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 250.0
  episode_reward_mean: 212.74
  episode_reward_min: 180.0
  episodes_this_iter: 1
  episodes_total: 360
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.968
    dispatch_time_ms: 8.13
    learner:
      cur_lr: 0.0011202399618923664
      grad_gnorm: 0.733440637588501
      policy_entropy: 128.1759796142578
      policy_loss: 0.01871948130428791
      var_gnorm: 63.872344970703125
      vf_explained_var: 0.6069126129150391
      vf_loss: 0.009655634872615337
    num_steps_sampled: 3610000
    num_steps_trained: 3610000
    wait_time_ms: 170.464
  iterations_since_restore: 361
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6607.426373243332
  time_this_iter_s: 17.83247470855713
  time_total_s: 6607.426373243332
  timestamp: 1593891072
  timesteps_since_restore: 3610000
  timesteps_this_iter: 10000
  timesteps_total: 3610000
  training_iteration: 361
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6607 s, 361 iter, 3610000 ts, 213 rew

agent-1: 18.0
agent-2: 19.0
agent-3: 27.0
agent-4: 25.0
agent-5: 17.0
agent-6: 20.0
agent-7: 17.0
agent-8: 21.0
agent-9: 23.0
agent-10: 17.0
Sum Reward: 204.0
Avg Reward: 20.4
Min Reward: 17.0
Gini Coefficient: 0.09117647058823529
20:20 Ratio: 1.5294117647058822
Max-min Ratio: 1.588235294117647
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-31-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 250.0
  episode_reward_mean: 212.68
  episode_reward_min: 180.0
  episodes_this_iter: 1
  episodes_total: 361
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.653
    dispatch_time_ms: 6.282
    learner:
      cur_lr: 0.0011195739498361945
      grad_gnorm: 32.23843002319336
      policy_entropy: 158.42633056640625
      policy_loss: 12.199636459350586
      var_gnorm: 63.883262634277344
      vf_explained_var: 0.7161110043525696
      vf_loss: 3.3845033645629883
    num_steps_sampled: 3620000
    num_steps_trained: 3620000
    wait_time_ms: 166.734
  iterations_since_restore: 362
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6625.44496178627
  time_this_iter_s: 18.018588542938232
  time_total_s: 6625.44496178627
  timestamp: 1593891090
  timesteps_since_restore: 3620000
  timesteps_this_iter: 10000
  timesteps_total: 3620000
  training_iteration: 362
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6625 s, 362 iter, 3620000 ts, 213 rew

agent-1: 23.0
agent-2: 26.0
agent-3: 16.0
agent-4: 27.0
agent-5: 22.0
agent-6: 13.0
agent-7: 25.0
agent-8: 14.0
agent-9: 26.0
agent-10: 23.0
Sum Reward: 215.0
Avg Reward: 21.5
Min Reward: 13.0
Gini Coefficient: 0.12511627906976744
20:20 Ratio: 1.962962962962963
Max-min Ratio: 2.076923076923077
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-31-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 250.0
  episode_reward_mean: 212.56
  episode_reward_min: 180.0
  episodes_this_iter: 1
  episodes_total: 362
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 4.11
    dispatch_time_ms: 6.025
    learner:
      cur_lr: 0.0011189080541953444
      grad_gnorm: 0.2239394634962082
      policy_entropy: 178.32510375976562
      policy_loss: 0.13923706114292145
      var_gnorm: 64.08429718017578
      vf_explained_var: 0.9228869080543518
      vf_loss: 0.00018050531798508018
    num_steps_sampled: 3630000
    num_steps_trained: 3630000
    wait_time_ms: 169.556
  iterations_since_restore: 363
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6643.269529342651
  time_this_iter_s: 17.824567556381226
  time_total_s: 6643.269529342651
  timestamp: 1593891108
  timesteps_since_restore: 3630000
  timesteps_this_iter: 10000
  timesteps_total: 3630000
  training_iteration: 363
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6643 s, 363 iter, 3630000 ts, 213 rew

agent-1: 17.0
agent-2: 24.0
agent-3: 12.0
agent-4: 30.0
agent-5: 24.0
agent-6: 21.0
agent-7: 24.0
agent-8: 19.0
agent-9: 21.0
agent-10: 13.0
Sum Reward: 205.0
Avg Reward: 20.5
Min Reward: 12.0
Gini Coefficient: 0.14097560975609755
20:20 Ratio: 2.16
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-32-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 250.0
  episode_reward_mean: 212.41
  episode_reward_min: 180.0
  episodes_this_iter: 1
  episodes_total: 363
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.377
    dispatch_time_ms: 7.486
    learner:
      cur_lr: 0.0011182420421391726
      grad_gnorm: 3.79097843170166
      policy_entropy: 166.90518188476562
      policy_loss: 0.9950329065322876
      var_gnorm: 64.0841064453125
      vf_explained_var: 0.96974116563797
      vf_loss: 0.1261308640241623
    num_steps_sampled: 3640000
    num_steps_trained: 3640000
    wait_time_ms: 165.912
  iterations_since_restore: 364
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6661.272986412048
  time_this_iter_s: 18.003457069396973
  time_total_s: 6661.272986412048
  timestamp: 1593891126
  timesteps_since_restore: 3640000
  timesteps_this_iter: 10000
  timesteps_total: 3640000
  training_iteration: 364
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6661 s, 364 iter, 3640000 ts, 212 rew

agent-1: 21.0
agent-2: 12.0
agent-3: 11.0
agent-4: 25.0
agent-5: 35.0
agent-6: 18.0
agent-7: 16.0
agent-8: 13.0
agent-9: 23.0
agent-10: 31.0
Sum Reward: 205.0
Avg Reward: 20.5
Min Reward: 11.0
Gini Coefficient: 0.21121951219512194
20:20 Ratio: 2.869565217391304
Max-min Ratio: 3.1818181818181817
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-32-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 250.0
  episode_reward_mean: 212.42
  episode_reward_min: 180.0
  episodes_this_iter: 1
  episodes_total: 364
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.983
    dispatch_time_ms: 5.351
    learner:
      cur_lr: 0.0011175760300830007
      grad_gnorm: 2.2561042308807373
      policy_entropy: 179.42724609375
      policy_loss: 0.6808091998100281
      var_gnorm: 64.218994140625
      vf_explained_var: -0.203987717628479
      vf_loss: 0.015316611155867577
    num_steps_sampled: 3650000
    num_steps_trained: 3650000
    wait_time_ms: 172.419
  iterations_since_restore: 365
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6679.073913097382
  time_this_iter_s: 17.800926685333252
  time_total_s: 6679.073913097382
  timestamp: 1593891144
  timesteps_since_restore: 3650000
  timesteps_this_iter: 10000
  timesteps_total: 3650000
  training_iteration: 365
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6679 s, 365 iter, 3650000 ts, 212 rew

agent-1: 18.0
agent-2: 19.0
agent-3: 18.0
agent-4: 23.0
agent-5: 19.0
agent-6: 14.0
agent-7: 30.0
agent-8: 22.0
agent-9: 20.0
agent-10: 17.0
Sum Reward: 200.0
Avg Reward: 20.0
Min Reward: 14.0
Gini Coefficient: 0.106
20:20 Ratio: 1.7096774193548387
Max-min Ratio: 2.142857142857143
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-32-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 250.0
  episode_reward_mean: 212.33
  episode_reward_min: 180.0
  episodes_this_iter: 1
  episodes_total: 365
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.812
    dispatch_time_ms: 6.638
    learner:
      cur_lr: 0.0011169100180268288
      grad_gnorm: 1.3681083917617798
      policy_entropy: 184.94224548339844
      policy_loss: -0.44431358575820923
      var_gnorm: 64.25646209716797
      vf_explained_var: 0.08754318952560425
      vf_loss: 0.002863746602088213
    num_steps_sampled: 3660000
    num_steps_trained: 3660000
    wait_time_ms: 170.014
  iterations_since_restore: 366
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6697.256941318512
  time_this_iter_s: 18.18302822113037
  time_total_s: 6697.256941318512
  timestamp: 1593891162
  timesteps_since_restore: 3660000
  timesteps_this_iter: 10000
  timesteps_total: 3660000
  training_iteration: 366
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6697 s, 366 iter, 3660000 ts, 212 rew

agent-1: 13.0
agent-2: 24.0
agent-3: 23.0
agent-4: 24.0
agent-5: 22.0
agent-6: 18.0
agent-7: 22.0
agent-8: 23.0
agent-9: 16.0
agent-10: 14.0
Sum Reward: 199.0
Avg Reward: 19.9
Min Reward: 13.0
Gini Coefficient: 0.1100502512562814
20:20 Ratio: 1.7777777777777777
Max-min Ratio: 1.8461538461538463
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-33-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 250.0
  episode_reward_mean: 212.07
  episode_reward_min: 180.0
  episodes_this_iter: 1
  episodes_total: 366
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.2
    dispatch_time_ms: 5.772
    learner:
      cur_lr: 0.0011162440059706569
      grad_gnorm: 0.45763906836509705
      policy_entropy: 178.93118286132812
      policy_loss: -0.14133025705814362
      var_gnorm: 64.45185852050781
      vf_explained_var: 0.9747995734214783
      vf_loss: 0.0005176987033337355
    num_steps_sampled: 3670000
    num_steps_trained: 3670000
    wait_time_ms: 175.311
  iterations_since_restore: 367
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6715.212992668152
  time_this_iter_s: 17.956051349639893
  time_total_s: 6715.212992668152
  timestamp: 1593891180
  timesteps_since_restore: 3670000
  timesteps_this_iter: 10000
  timesteps_total: 3670000
  training_iteration: 367
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6715 s, 367 iter, 3670000 ts, 212 rew

agent-1: 7.0
agent-2: 28.0
agent-3: 22.0
agent-4: 13.0
agent-5: 26.0
agent-6: 15.0
agent-7: 28.0
agent-8: 22.0
agent-9: 23.0
agent-10: 33.0
Sum Reward: 217.0
Avg Reward: 21.7
Min Reward: 7.0
Gini Coefficient: 0.19216589861751152
20:20 Ratio: 3.05
Max-min Ratio: 4.714285714285714
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-33-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 250.0
  episode_reward_mean: 212.15
  episode_reward_min: 180.0
  episodes_this_iter: 1
  episodes_total: 367
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.543
    dispatch_time_ms: 5.618
    learner:
      cur_lr: 0.001115577993914485
      grad_gnorm: 8.077397346496582
      policy_entropy: 186.265869140625
      policy_loss: -2.388592004776001
      var_gnorm: 64.4567642211914
      vf_explained_var: 0.8943573236465454
      vf_loss: 0.13235588371753693
    num_steps_sampled: 3680000
    num_steps_trained: 3680000
    wait_time_ms: 169.298
  iterations_since_restore: 368
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6732.9610686302185
  time_this_iter_s: 17.74807596206665
  time_total_s: 6732.9610686302185
  timestamp: 1593891198
  timesteps_since_restore: 3680000
  timesteps_this_iter: 10000
  timesteps_total: 3680000
  training_iteration: 368
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6732 s, 368 iter, 3680000 ts, 212 rew

agent-1: 12.0
agent-2: 22.0
agent-3: 20.0
agent-4: 25.0
agent-5: 22.0
agent-6: 16.0
agent-7: 14.0
agent-8: 20.0
agent-9: 25.0
agent-10: 22.0
Sum Reward: 198.0
Avg Reward: 19.8
Min Reward: 12.0
Gini Coefficient: 0.11717171717171718
20:20 Ratio: 1.9230769230769231
Max-min Ratio: 2.0833333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-33-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 250.0
  episode_reward_mean: 212.08
  episode_reward_min: 180.0
  episodes_this_iter: 1
  episodes_total: 368
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.972
    dispatch_time_ms: 6.456
    learner:
      cur_lr: 0.001114911981858313
      grad_gnorm: 2.369835615158081
      policy_entropy: 175.99278259277344
      policy_loss: -0.09724694490432739
      var_gnorm: 64.49176025390625
      vf_explained_var: 0.5858958959579468
      vf_loss: 0.007867163047194481
    num_steps_sampled: 3690000
    num_steps_trained: 3690000
    wait_time_ms: 168.323
  iterations_since_restore: 369
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6750.869204998016
  time_this_iter_s: 17.90813636779785
  time_total_s: 6750.869204998016
  timestamp: 1593891216
  timesteps_since_restore: 3690000
  timesteps_this_iter: 10000
  timesteps_total: 3690000
  training_iteration: 369
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6750 s, 369 iter, 3690000 ts, 212 rew

agent-1: 14.0
agent-2: 22.0
agent-3: 17.0
agent-4: 20.0
agent-5: 21.0
agent-6: 23.0
agent-7: 20.0
agent-8: 25.0
agent-9: 22.0
agent-10: 22.0
Sum Reward: 206.0
Avg Reward: 20.6
Min Reward: 14.0
Gini Coefficient: 0.0766990291262136
20:20 Ratio: 1.5483870967741935
Max-min Ratio: 1.7857142857142858
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-33-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 250.0
  episode_reward_mean: 211.91
  episode_reward_min: 180.0
  episodes_this_iter: 1
  episodes_total: 369
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.732
    dispatch_time_ms: 6.229
    learner:
      cur_lr: 0.0011142459698021412
      grad_gnorm: 26.035911560058594
      policy_entropy: 177.03680419921875
      policy_loss: 3.629586935043335
      var_gnorm: 64.52356719970703
      vf_explained_var: 0.6254405379295349
      vf_loss: 0.8639194369316101
    num_steps_sampled: 3700000
    num_steps_trained: 3700000
    wait_time_ms: 174.702
  iterations_since_restore: 370
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6768.76419711113
  time_this_iter_s: 17.894992113113403
  time_total_s: 6768.76419711113
  timestamp: 1593891234
  timesteps_since_restore: 3700000
  timesteps_this_iter: 10000
  timesteps_total: 3700000
  training_iteration: 370
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6768 s, 370 iter, 3700000 ts, 212 rew

agent-1: 18.0
agent-2: 22.0
agent-3: 21.0
agent-4: 21.0
agent-5: 11.0
agent-6: 20.0
agent-7: 22.0
agent-8: 22.0
agent-9: 22.0
agent-10: 17.0
Sum Reward: 196.0
Avg Reward: 19.6
Min Reward: 11.0
Gini Coefficient: 0.08163265306122448
20:20 Ratio: 1.5714285714285714
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-34-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 250.0
  episode_reward_mean: 211.4
  episode_reward_min: 180.0
  episodes_this_iter: 1
  episodes_total: 370
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.74
    dispatch_time_ms: 7.543
    learner:
      cur_lr: 0.0011135799577459693
      grad_gnorm: 1.5191576480865479
      policy_entropy: 149.80787658691406
      policy_loss: -0.7304293513298035
      var_gnorm: 64.61881256103516
      vf_explained_var: -0.19911277294158936
      vf_loss: 0.0074763912707567215
    num_steps_sampled: 3710000
    num_steps_trained: 3710000
    wait_time_ms: 171.579
  iterations_since_restore: 371
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6786.698549747467
  time_this_iter_s: 17.93435263633728
  time_total_s: 6786.698549747467
  timestamp: 1593891252
  timesteps_since_restore: 3710000
  timesteps_this_iter: 10000
  timesteps_total: 3710000
  training_iteration: 371
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6786 s, 371 iter, 3710000 ts, 211 rew

agent-1: 21.0
agent-2: 23.0
agent-3: 15.0
agent-4: 22.0
agent-5: 22.0
agent-6: 23.0
agent-7: 14.0
agent-8: 24.0
agent-9: 33.0
agent-10: 22.0
Sum Reward: 219.0
Avg Reward: 21.9
Min Reward: 14.0
Gini Coefficient: 0.11278538812785388
20:20 Ratio: 1.9655172413793103
Max-min Ratio: 2.357142857142857
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-34-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 250.0
  episode_reward_mean: 211.67
  episode_reward_min: 180.0
  episodes_this_iter: 1
  episodes_total: 371
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.976
    dispatch_time_ms: 8.032
    learner:
      cur_lr: 0.0011129139456897974
      grad_gnorm: 1.8189082145690918
      policy_entropy: 150.5391082763672
      policy_loss: 1.3033617734909058
      var_gnorm: 64.65604400634766
      vf_explained_var: -0.5265564918518066
      vf_loss: 0.028093857690691948
    num_steps_sampled: 3720000
    num_steps_trained: 3720000
    wait_time_ms: 168.284
  iterations_since_restore: 372
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6804.379342556
  time_this_iter_s: 17.680792808532715
  time_total_s: 6804.379342556
  timestamp: 1593891270
  timesteps_since_restore: 3720000
  timesteps_this_iter: 10000
  timesteps_total: 3720000
  training_iteration: 372
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6804 s, 372 iter, 3720000 ts, 212 rew

agent-1: 18.0
agent-2: 23.0
agent-3: 15.0
agent-4: 18.0
agent-5: 25.0
agent-6: 16.0
agent-7: 27.0
agent-8: 22.0
agent-9: 19.0
agent-10: 22.0
Sum Reward: 205.0
Avg Reward: 20.5
Min Reward: 15.0
Gini Coefficient: 0.10292682926829268
20:20 Ratio: 1.6774193548387097
Max-min Ratio: 1.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-34-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 250.0
  episode_reward_mean: 211.78
  episode_reward_min: 180.0
  episodes_this_iter: 1
  episodes_total: 372
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.971
    dispatch_time_ms: 6.254
    learner:
      cur_lr: 0.0011122480500489473
      grad_gnorm: 3.562138557434082
      policy_entropy: 159.77706909179688
      policy_loss: -0.7204254865646362
      var_gnorm: 64.77415466308594
      vf_explained_var: 0.7622818350791931
      vf_loss: 0.10657379776239395
    num_steps_sampled: 3730000
    num_steps_trained: 3730000
    wait_time_ms: 174.615
  iterations_since_restore: 373
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6822.397536039352
  time_this_iter_s: 18.01819348335266
  time_total_s: 6822.397536039352
  timestamp: 1593891288
  timesteps_since_restore: 3730000
  timesteps_this_iter: 10000
  timesteps_total: 3730000
  training_iteration: 373
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6822 s, 373 iter, 3730000 ts, 212 rew

agent-1: 22.0
agent-2: 19.0
agent-3: 21.0
agent-4: 23.0
agent-5: 22.0
agent-6: 10.0
agent-7: 15.0
agent-8: 26.0
agent-9: 27.0
agent-10: 12.0
Sum Reward: 197.0
Avg Reward: 19.7
Min Reward: 10.0
Gini Coefficient: 0.15279187817258882
20:20 Ratio: 2.409090909090909
Max-min Ratio: 2.7
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-35-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 250.0
  episode_reward_mean: 211.47
  episode_reward_min: 180.0
  episodes_this_iter: 1
  episodes_total: 373
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.898
    dispatch_time_ms: 7.147
    learner:
      cur_lr: 0.0011115820379927754
      grad_gnorm: 0.9348465204238892
      policy_entropy: 184.14556884765625
      policy_loss: -0.48908528685569763
      var_gnorm: 64.7717514038086
      vf_explained_var: -1.0
      vf_loss: 0.001769126858562231
    num_steps_sampled: 3740000
    num_steps_trained: 3740000
    wait_time_ms: 170.722
  iterations_since_restore: 374
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6840.170139074326
  time_this_iter_s: 17.772603034973145
  time_total_s: 6840.170139074326
  timestamp: 1593891306
  timesteps_since_restore: 3740000
  timesteps_this_iter: 10000
  timesteps_total: 3740000
  training_iteration: 374
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6840 s, 374 iter, 3740000 ts, 211 rew

agent-1: 21.0
agent-2: 14.0
agent-3: 28.0
agent-4: 11.0
agent-5: 14.0
agent-6: 21.0
agent-7: 26.0
agent-8: 21.0
agent-9: 34.0
agent-10: 16.0
Sum Reward: 206.0
Avg Reward: 20.6
Min Reward: 11.0
Gini Coefficient: 0.18446601941747573
20:20 Ratio: 2.48
Max-min Ratio: 3.090909090909091
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-35-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 250.0
  episode_reward_mean: 211.14
  episode_reward_min: 180.0
  episodes_this_iter: 1
  episodes_total: 374
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.552
    dispatch_time_ms: 8.823
    learner:
      cur_lr: 0.0011109160259366035
      grad_gnorm: 6.55838680267334
      policy_entropy: 81.45759582519531
      policy_loss: 0.7095743417739868
      var_gnorm: 64.99449920654297
      vf_explained_var: -0.32304537296295166
      vf_loss: 0.02781408280134201
    num_steps_sampled: 3750000
    num_steps_trained: 3750000
    wait_time_ms: 172.883
  iterations_since_restore: 375
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6858.094752788544
  time_this_iter_s: 17.92461371421814
  time_total_s: 6858.094752788544
  timestamp: 1593891324
  timesteps_since_restore: 3750000
  timesteps_this_iter: 10000
  timesteps_total: 3750000
  training_iteration: 375
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6858 s, 375 iter, 3750000 ts, 211 rew

agent-1: 28.0
agent-2: 23.0
agent-3: 33.0
agent-4: 16.0
agent-5: 14.0
agent-6: 26.0
agent-7: 23.0
agent-8: 17.0
agent-9: 19.0
agent-10: 20.0
Sum Reward: 219.0
Avg Reward: 21.9
Min Reward: 14.0
Gini Coefficient: 0.14383561643835616
20:20 Ratio: 2.033333333333333
Max-min Ratio: 2.357142857142857
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-35-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 250.0
  episode_reward_mean: 211.02
  episode_reward_min: 180.0
  episodes_this_iter: 1
  episodes_total: 375
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.395
    dispatch_time_ms: 5.995
    learner:
      cur_lr: 0.0011102500138804317
      grad_gnorm: 10.666964530944824
      policy_entropy: 182.34539794921875
      policy_loss: 0.47065478563308716
      var_gnorm: 65.08251953125
      vf_explained_var: -1.0
      vf_loss: 0.0042717186734080315
    num_steps_sampled: 3760000
    num_steps_trained: 3760000
    wait_time_ms: 174.149
  iterations_since_restore: 376
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6876.1199243068695
  time_this_iter_s: 18.025171518325806
  time_total_s: 6876.1199243068695
  timestamp: 1593891342
  timesteps_since_restore: 3760000
  timesteps_this_iter: 10000
  timesteps_total: 3760000
  training_iteration: 376
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6876 s, 376 iter, 3760000 ts, 211 rew

agent-1: 21.0
agent-2: 10.0
agent-3: 25.0
agent-4: 22.0
agent-5: 22.0
agent-6: 21.0
agent-7: 19.0
agent-8: 22.0
agent-9: 18.0
agent-10: 26.0
Sum Reward: 206.0
Avg Reward: 20.6
Min Reward: 10.0
Gini Coefficient: 0.1029126213592233
20:20 Ratio: 1.8214285714285714
Max-min Ratio: 2.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-36-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 250.0
  episode_reward_mean: 211.1
  episode_reward_min: 180.0
  episodes_this_iter: 1
  episodes_total: 376
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 4.001
    dispatch_time_ms: 6.452
    learner:
      cur_lr: 0.0011095840018242598
      grad_gnorm: 1.8849941492080688
      policy_entropy: 183.42840576171875
      policy_loss: 0.4282107353210449
      var_gnorm: 65.19512176513672
      vf_explained_var: 0.954800546169281
      vf_loss: 0.011516150087118149
    num_steps_sampled: 3770000
    num_steps_trained: 3770000
    wait_time_ms: 167.891
  iterations_since_restore: 377
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6894.0027005672455
  time_this_iter_s: 17.882776260375977
  time_total_s: 6894.0027005672455
  timestamp: 1593891360
  timesteps_since_restore: 3770000
  timesteps_this_iter: 10000
  timesteps_total: 3770000
  training_iteration: 377
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6894 s, 377 iter, 3770000 ts, 211 rew

agent-1: 25.0
agent-2: 7.0
agent-3: 26.0
agent-4: 21.0
agent-5: 17.0
agent-6: 26.0
agent-7: 21.0
agent-8: 12.0
agent-9: 21.0
agent-10: 24.0
Sum Reward: 200.0
Avg Reward: 20.0
Min Reward: 7.0
Gini Coefficient: 0.159
20:20 Ratio: 2.736842105263158
Max-min Ratio: 3.7142857142857144
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-36-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 250.0
  episode_reward_mean: 210.98
  episode_reward_min: 180.0
  episodes_this_iter: 1
  episodes_total: 377
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.041
    dispatch_time_ms: 6.374
    learner:
      cur_lr: 0.0011089179897680879
      grad_gnorm: 2.276076078414917
      policy_entropy: 187.9703826904297
      policy_loss: -0.7272070050239563
      var_gnorm: 65.22825622558594
      vf_explained_var: 0.9857195615768433
      vf_loss: 0.0048232595436275005
    num_steps_sampled: 3780000
    num_steps_trained: 3780000
    wait_time_ms: 170.005
  iterations_since_restore: 378
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6911.794843196869
  time_this_iter_s: 17.792142629623413
  time_total_s: 6911.794843196869
  timestamp: 1593891377
  timesteps_since_restore: 3780000
  timesteps_this_iter: 10000
  timesteps_total: 3780000
  training_iteration: 378
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6911 s, 378 iter, 3780000 ts, 211 rew

agent-1: 11.0
agent-2: 28.0
agent-3: 20.0
agent-4: 20.0
agent-5: 19.0
agent-6: 27.0
agent-7: 20.0
agent-8: 24.0
agent-9: 28.0
agent-10: 19.0
Sum Reward: 216.0
Avg Reward: 21.6
Min Reward: 11.0
Gini Coefficient: 0.12407407407407407
20:20 Ratio: 1.8666666666666667
Max-min Ratio: 2.5454545454545454
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-36-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 250.0
  episode_reward_mean: 210.88
  episode_reward_min: 180.0
  episodes_this_iter: 1
  episodes_total: 378
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.981
    dispatch_time_ms: 8.165
    learner:
      cur_lr: 0.001108251977711916
      grad_gnorm: 0.9759659171104431
      policy_entropy: 179.80345153808594
      policy_loss: -0.28944867849349976
      var_gnorm: 65.21871948242188
      vf_explained_var: 0.990245521068573
      vf_loss: 0.0022347173653542995
    num_steps_sampled: 3790000
    num_steps_trained: 3790000
    wait_time_ms: 169.663
  iterations_since_restore: 379
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6929.716211557388
  time_this_iter_s: 17.92136836051941
  time_total_s: 6929.716211557388
  timestamp: 1593891395
  timesteps_since_restore: 3790000
  timesteps_this_iter: 10000
  timesteps_total: 3790000
  training_iteration: 379
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6929 s, 379 iter, 3790000 ts, 211 rew

agent-1: 37.0
agent-2: 18.0
agent-3: 20.0
agent-4: 17.0
agent-5: 24.0
agent-6: 26.0
agent-7: 21.0
agent-8: 20.0
agent-9: 15.0
agent-10: 10.0
Sum Reward: 208.0
Avg Reward: 20.8
Min Reward: 10.0
Gini Coefficient: 0.175
20:20 Ratio: 2.52
Max-min Ratio: 3.7
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-36-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 250.0
  episode_reward_mean: 210.68
  episode_reward_min: 180.0
  episodes_this_iter: 1
  episodes_total: 379
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 4.014
    dispatch_time_ms: 8.155
    learner:
      cur_lr: 0.001107585965655744
      grad_gnorm: 2.790680170059204
      policy_entropy: 182.0652618408203
      policy_loss: 0.06381084769964218
      var_gnorm: 65.29957580566406
      vf_explained_var: 0.7904477119445801
      vf_loss: 0.12728291749954224
    num_steps_sampled: 3800000
    num_steps_trained: 3800000
    wait_time_ms: 175.23
  iterations_since_restore: 380
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6947.612100124359
  time_this_iter_s: 17.895888566970825
  time_total_s: 6947.612100124359
  timestamp: 1593891413
  timesteps_since_restore: 3800000
  timesteps_this_iter: 10000
  timesteps_total: 3800000
  training_iteration: 380
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6947 s, 380 iter, 3800000 ts, 211 rew

agent-1: 22.0
agent-2: 11.0
agent-3: 18.0
agent-4: 24.0
agent-5: 26.0
agent-6: 34.0
agent-7: 10.0
agent-8: 18.0
agent-9: 18.0
agent-10: 16.0
Sum Reward: 197.0
Avg Reward: 19.7
Min Reward: 10.0
Gini Coefficient: 0.18934010152284264
20:20 Ratio: 2.857142857142857
Max-min Ratio: 3.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-37-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 250.0
  episode_reward_mean: 210.38
  episode_reward_min: 180.0
  episodes_this_iter: 1
  episodes_total: 380
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.657
    dispatch_time_ms: 8.46
    learner:
      cur_lr: 0.0011069199535995722
      grad_gnorm: 0.7810957431793213
      policy_entropy: 189.61639404296875
      policy_loss: 0.3793184459209442
      var_gnorm: 65.37088012695312
      vf_explained_var: 0.9605906009674072
      vf_loss: 0.0044861785136163235
    num_steps_sampled: 3810000
    num_steps_trained: 3810000
    wait_time_ms: 172.763
  iterations_since_restore: 381
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6965.481392145157
  time_this_iter_s: 17.86929202079773
  time_total_s: 6965.481392145157
  timestamp: 1593891431
  timesteps_since_restore: 3810000
  timesteps_this_iter: 10000
  timesteps_total: 3810000
  training_iteration: 381
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6965 s, 381 iter, 3810000 ts, 210 rew

agent-1: 16.0
agent-2: 13.0
agent-3: 22.0
agent-4: 22.0
agent-5: 19.0
agent-6: 15.0
agent-7: 26.0
agent-8: 19.0
agent-9: 17.0
agent-10: 21.0
Sum Reward: 190.0
Avg Reward: 19.0
Min Reward: 13.0
Gini Coefficient: 0.10947368421052632
20:20 Ratio: 1.7142857142857142
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-37-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 250.0
  episode_reward_mean: 209.86
  episode_reward_min: 180.0
  episodes_this_iter: 1
  episodes_total: 381
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.708
    dispatch_time_ms: 6.032
    learner:
      cur_lr: 0.0011062540579587221
      grad_gnorm: 2.6117372512817383
      policy_entropy: 187.45924377441406
      policy_loss: -1.611026644706726
      var_gnorm: 65.44880676269531
      vf_explained_var: 0.98850017786026
      vf_loss: 0.005198861472308636
    num_steps_sampled: 3820000
    num_steps_trained: 3820000
    wait_time_ms: 173.628
  iterations_since_restore: 382
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 6983.273516893387
  time_this_iter_s: 17.79212474822998
  time_total_s: 6983.273516893387
  timestamp: 1593891449
  timesteps_since_restore: 3820000
  timesteps_this_iter: 10000
  timesteps_total: 3820000
  training_iteration: 382
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 6983 s, 382 iter, 3820000 ts, 210 rew

agent-1: 18.0
agent-2: 11.0
agent-3: 17.0
agent-4: 21.0
agent-5: 27.0
agent-6: 25.0
agent-7: 23.0
agent-8: 21.0
agent-9: 24.0
agent-10: 24.0
Sum Reward: 211.0
Avg Reward: 21.1
Min Reward: 11.0
Gini Coefficient: 0.11421800947867299
20:20 Ratio: 1.8571428571428572
Max-min Ratio: 2.4545454545454546
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-37-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 250.0
  episode_reward_mean: 209.89
  episode_reward_min: 180.0
  episodes_this_iter: 1
  episodes_total: 382
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 4.346
    dispatch_time_ms: 6.98
    learner:
      cur_lr: 0.0011055880459025502
      grad_gnorm: 1.0623812675476074
      policy_entropy: 167.91990661621094
      policy_loss: 0.34026700258255005
      var_gnorm: 65.5270004272461
      vf_explained_var: 0.9895308613777161
      vf_loss: 0.0013486642856150866
    num_steps_sampled: 3830000
    num_steps_trained: 3830000
    wait_time_ms: 748.223
  iterations_since_restore: 383
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7006.9599986076355
  time_this_iter_s: 23.686481714248657
  time_total_s: 7006.9599986076355
  timestamp: 1593891473
  timesteps_since_restore: 3830000
  timesteps_this_iter: 10000
  timesteps_total: 3830000
  training_iteration: 383
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7006 s, 383 iter, 3830000 ts, 210 rew

agent-1: 6.0
agent-2: 9.0
agent-3: 27.0
agent-4: 14.0
agent-5: 21.0
agent-6: 27.0
agent-7: 25.0
agent-8: 21.0
agent-9: 18.0
agent-10: 29.0
Sum Reward: 197.0
Avg Reward: 19.7
Min Reward: 6.0
Gini Coefficient: 0.21269035532994923
20:20 Ratio: 3.7333333333333334
Max-min Ratio: 4.833333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-38-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 250.0
  episode_reward_mean: 209.62
  episode_reward_min: 180.0
  episodes_this_iter: 1
  episodes_total: 383
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 4.036
    dispatch_time_ms: 38.872
    learner:
      cur_lr: 0.0011049220338463783
      grad_gnorm: 11.282888412475586
      policy_entropy: 174.0113983154297
      policy_loss: -3.5919277667999268
      var_gnorm: 65.55258178710938
      vf_explained_var: 0.863584578037262
      vf_loss: 0.010646103881299496
    num_steps_sampled: 3840000
    num_steps_trained: 3840000
    wait_time_ms: 135.61
  iterations_since_restore: 384
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7024.258740663528
  time_this_iter_s: 17.298742055892944
  time_total_s: 7024.258740663528
  timestamp: 1593891490
  timesteps_since_restore: 3840000
  timesteps_this_iter: 10000
  timesteps_total: 3840000
  training_iteration: 384
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7024 s, 384 iter, 3840000 ts, 210 rew

agent-1: 17.0
agent-2: 21.0
agent-3: 19.0
agent-4: 23.0
agent-5: 25.0
agent-6: 15.0
agent-7: 26.0
agent-8: 17.0
agent-9: 18.0
agent-10: 19.0
Sum Reward: 200.0
Avg Reward: 20.0
Min Reward: 15.0
Gini Coefficient: 0.097
20:20 Ratio: 1.59375
Max-min Ratio: 1.7333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-38-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 250.0
  episode_reward_mean: 209.4
  episode_reward_min: 180.0
  episodes_this_iter: 1
  episodes_total: 384
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.841
    dispatch_time_ms: 44.099
    learner:
      cur_lr: 0.0011042560217902064
      grad_gnorm: 7.277677059173584
      policy_entropy: 171.66966247558594
      policy_loss: 0.984583854675293
      var_gnorm: 65.6195297241211
      vf_explained_var: 0.8119683265686035
      vf_loss: 0.015476341359317303
    num_steps_sampled: 3850000
    num_steps_trained: 3850000
    wait_time_ms: 144.43
  iterations_since_restore: 385
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7043.271087169647
  time_this_iter_s: 19.012346506118774
  time_total_s: 7043.271087169647
  timestamp: 1593891509
  timesteps_since_restore: 3850000
  timesteps_this_iter: 10000
  timesteps_total: 3850000
  training_iteration: 385
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7043 s, 385 iter, 3850000 ts, 209 rew

agent-1: 23.0
agent-2: 14.0
agent-3: 19.0
agent-4: 23.0
agent-5: 14.0
agent-6: 25.0
agent-7: 23.0
agent-8: 21.0
agent-9: 16.0
agent-10: 22.0
Sum Reward: 200.0
Avg Reward: 20.0
Min Reward: 14.0
Gini Coefficient: 0.105
20:20 Ratio: 1.7142857142857142
Max-min Ratio: 1.7857142857142858
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-38-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 250.0
  episode_reward_mean: 209.34
  episode_reward_min: 180.0
  episodes_this_iter: 1
  episodes_total: 385
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.906
    dispatch_time_ms: 40.574
    learner:
      cur_lr: 0.0011035900097340345
      grad_gnorm: 3.1268200874328613
      policy_entropy: 187.97686767578125
      policy_loss: -3.2063066959381104
      var_gnorm: 65.65641784667969
      vf_explained_var: 0.9820709228515625
      vf_loss: 0.009337682276964188
    num_steps_sampled: 3860000
    num_steps_trained: 3860000
    wait_time_ms: 151.357
  iterations_since_restore: 386
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7061.97171163559
  time_this_iter_s: 18.700624465942383
  time_total_s: 7061.97171163559
  timestamp: 1593891528
  timesteps_since_restore: 3860000
  timesteps_this_iter: 10000
  timesteps_total: 3860000
  training_iteration: 386
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7061 s, 386 iter, 3860000 ts, 209 rew

agent-1: 27.0
agent-2: 21.0
agent-3: 20.0
agent-4: 21.0
agent-5: 15.0
agent-6: 20.0
agent-7: 24.0
agent-8: 22.0
agent-9: 23.0
agent-10: 13.0
Sum Reward: 206.0
Avg Reward: 20.6
Min Reward: 13.0
Gini Coefficient: 0.10194174757281553
20:20 Ratio: 1.8214285714285714
Max-min Ratio: 2.076923076923077
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-39-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 250.0
  episode_reward_mean: 209.09
  episode_reward_min: 180.0
  episodes_this_iter: 1
  episodes_total: 386
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.009
    dispatch_time_ms: 29.329
    learner:
      cur_lr: 0.0011029239976778626
      grad_gnorm: 1.537462592124939
      policy_entropy: 188.971923828125
      policy_loss: -2.1300244331359863
      var_gnorm: 65.70960998535156
      vf_explained_var: 0.8968015313148499
      vf_loss: 0.024217117577791214
    num_steps_sampled: 3870000
    num_steps_trained: 3870000
    wait_time_ms: 155.698
  iterations_since_restore: 387
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7080.888387441635
  time_this_iter_s: 18.916675806045532
  time_total_s: 7080.888387441635
  timestamp: 1593891547
  timesteps_since_restore: 3870000
  timesteps_this_iter: 10000
  timesteps_total: 3870000
  training_iteration: 387
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7080 s, 387 iter, 3870000 ts, 209 rew

agent-1: 21.0
agent-2: 23.0
agent-3: 20.0
agent-4: 18.0
agent-5: 24.0
agent-6: 19.0
agent-7: 20.0
agent-8: 31.0
agent-9: 18.0
agent-10: 11.0
Sum Reward: 205.0
Avg Reward: 20.5
Min Reward: 11.0
Gini Coefficient: 0.12341463414634146
20:20 Ratio: 1.896551724137931
Max-min Ratio: 2.8181818181818183
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-39-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 250.0
  episode_reward_mean: 208.89
  episode_reward_min: 180.0
  episodes_this_iter: 1
  episodes_total: 387
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.799
    dispatch_time_ms: 26.224
    learner:
      cur_lr: 0.0011022579856216908
      grad_gnorm: 0.6114740371704102
      policy_entropy: 184.55166625976562
      policy_loss: -0.9026616811752319
      var_gnorm: 65.80403137207031
      vf_explained_var: 0.9793386459350586
      vf_loss: 0.0004128730215597898
    num_steps_sampled: 3880000
    num_steps_trained: 3880000
    wait_time_ms: 144.594
  iterations_since_restore: 388
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7099.630933523178
  time_this_iter_s: 18.74254608154297
  time_total_s: 7099.630933523178
  timestamp: 1593891566
  timesteps_since_restore: 3880000
  timesteps_this_iter: 10000
  timesteps_total: 3880000
  training_iteration: 388
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7099 s, 388 iter, 3880000 ts, 209 rew

agent-1: 19.0
agent-2: 13.0
agent-3: 32.0
agent-4: 15.0
agent-5: 20.0
agent-6: 22.0
agent-7: 29.0
agent-8: 28.0
agent-9: 24.0
agent-10: 27.0
Sum Reward: 229.0
Avg Reward: 22.9
Min Reward: 13.0
Gini Coefficient: 0.14716157205240174
20:20 Ratio: 2.1785714285714284
Max-min Ratio: 2.4615384615384617
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-39-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 250.0
  episode_reward_mean: 209.21
  episode_reward_min: 180.0
  episodes_this_iter: 1
  episodes_total: 388
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.1
    dispatch_time_ms: 31.628
    learner:
      cur_lr: 0.0011015919735655189
      grad_gnorm: 1.1304763555526733
      policy_entropy: 151.1484832763672
      policy_loss: -3.843075752258301
      var_gnorm: 65.90872955322266
      vf_explained_var: 0.9934199452400208
      vf_loss: 0.00038135339855216444
    num_steps_sampled: 3890000
    num_steps_trained: 3890000
    wait_time_ms: 153.348
  iterations_since_restore: 389
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7118.4024748802185
  time_this_iter_s: 18.771541357040405
  time_total_s: 7118.4024748802185
  timestamp: 1593891584
  timesteps_since_restore: 3890000
  timesteps_this_iter: 10000
  timesteps_total: 3890000
  training_iteration: 389
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7118 s, 389 iter, 3890000 ts, 209 rew

agent-1: 34.0
agent-2: 17.0
agent-3: 25.0
agent-4: 21.0
agent-5: 35.0
agent-6: 19.0
agent-7: 23.0
agent-8: 12.0
agent-9: 24.0
agent-10: 30.0
Sum Reward: 240.0
Avg Reward: 24.0
Min Reward: 12.0
Gini Coefficient: 0.16416666666666666
20:20 Ratio: 2.3793103448275863
Max-min Ratio: 2.9166666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-40-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 250.0
  episode_reward_mean: 209.36
  episode_reward_min: 180.0
  episodes_this_iter: 1
  episodes_total: 389
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.002
    dispatch_time_ms: 35.723
    learner:
      cur_lr: 0.001100925961509347
      grad_gnorm: 6.260417461395264
      policy_entropy: 183.37879943847656
      policy_loss: -6.241010665893555
      var_gnorm: 65.94284057617188
      vf_explained_var: 0.9630205035209656
      vf_loss: 0.024926450103521347
    num_steps_sampled: 3900000
    num_steps_trained: 3900000
    wait_time_ms: 149.437
  iterations_since_restore: 390
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7137.255996227264
  time_this_iter_s: 18.8535213470459
  time_total_s: 7137.255996227264
  timestamp: 1593891603
  timesteps_since_restore: 3900000
  timesteps_this_iter: 10000
  timesteps_total: 3900000
  training_iteration: 390
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7137 s, 390 iter, 3900000 ts, 209 rew

agent-1: 24.0
agent-2: 20.0
agent-3: 26.0
agent-4: 7.0
agent-5: 27.0
agent-6: 16.0
agent-7: 25.0
agent-8: 21.0
agent-9: 26.0
agent-10: 15.0
Sum Reward: 207.0
Avg Reward: 20.7
Min Reward: 7.0
Gini Coefficient: 0.1570048309178744
20:20 Ratio: 2.409090909090909
Max-min Ratio: 3.857142857142857
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-40-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 250.0
  episode_reward_mean: 209.31
  episode_reward_min: 180.0
  episodes_this_iter: 1
  episodes_total: 390
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.163
    dispatch_time_ms: 9.658
    learner:
      cur_lr: 0.001100259949453175
      grad_gnorm: 2.073291301727295
      policy_entropy: 177.25010681152344
      policy_loss: 0.46875250339508057
      var_gnorm: 65.96456909179688
      vf_explained_var: 0.9917150139808655
      vf_loss: 0.0037242097314447165
    num_steps_sampled: 3910000
    num_steps_trained: 3910000
    wait_time_ms: 168.011
  iterations_since_restore: 391
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7155.063140153885
  time_this_iter_s: 17.807143926620483
  time_total_s: 7155.063140153885
  timestamp: 1593891621
  timesteps_since_restore: 3910000
  timesteps_this_iter: 10000
  timesteps_total: 3910000
  training_iteration: 391
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7155 s, 391 iter, 3910000 ts, 209 rew

agent-1: 25.0
agent-2: 22.0
agent-3: 16.0
agent-4: 19.0
agent-5: 11.0
agent-6: 25.0
agent-7: 21.0
agent-8: 25.0
agent-9: 22.0
agent-10: 17.0
Sum Reward: 203.0
Avg Reward: 20.3
Min Reward: 11.0
Gini Coefficient: 0.11773399014778325
20:20 Ratio: 1.8518518518518519
Max-min Ratio: 2.272727272727273
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-40-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 250.0
  episode_reward_mean: 209.25
  episode_reward_min: 180.0
  episodes_this_iter: 1
  episodes_total: 391
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.907
    dispatch_time_ms: 6.415
    learner:
      cur_lr: 0.001099594053812325
      grad_gnorm: 6.128642559051514
      policy_entropy: 171.2383575439453
      policy_loss: -3.687544345855713
      var_gnorm: 66.0052490234375
      vf_explained_var: -1.0
      vf_loss: 0.10004760324954987
    num_steps_sampled: 3920000
    num_steps_trained: 3920000
    wait_time_ms: 169.322
  iterations_since_restore: 392
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7173.002819061279
  time_this_iter_s: 17.93967890739441
  time_total_s: 7173.002819061279
  timestamp: 1593891639
  timesteps_since_restore: 3920000
  timesteps_this_iter: 10000
  timesteps_total: 3920000
  training_iteration: 392
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7173 s, 392 iter, 3920000 ts, 209 rew

agent-1: 20.0
agent-2: 20.0
agent-3: 33.0
agent-4: 21.0
agent-5: 28.0
agent-6: 28.0
agent-7: 23.0
agent-8: 13.0
agent-9: 16.0
agent-10: 15.0
Sum Reward: 217.0
Avg Reward: 21.7
Min Reward: 13.0
Gini Coefficient: 0.15714285714285714
20:20 Ratio: 2.1785714285714284
Max-min Ratio: 2.5384615384615383
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-40-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 250.0
  episode_reward_mean: 209.11
  episode_reward_min: 180.0
  episodes_this_iter: 1
  episodes_total: 392
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.848
    dispatch_time_ms: 7.568
    learner:
      cur_lr: 0.001098928041756153
      grad_gnorm: 1.5575112104415894
      policy_entropy: 140.16773986816406
      policy_loss: 0.4140738546848297
      var_gnorm: 65.98639678955078
      vf_explained_var: 0.9898685812950134
      vf_loss: 0.002109166234731674
    num_steps_sampled: 3930000
    num_steps_trained: 3930000
    wait_time_ms: 172.4
  iterations_since_restore: 393
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7190.984288930893
  time_this_iter_s: 17.981469869613647
  time_total_s: 7190.984288930893
  timestamp: 1593891657
  timesteps_since_restore: 3930000
  timesteps_this_iter: 10000
  timesteps_total: 3930000
  training_iteration: 393
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7190 s, 393 iter, 3930000 ts, 209 rew

agent-1: 19.0
agent-2: 18.0
agent-3: 14.0
agent-4: 24.0
agent-5: 24.0
agent-6: 21.0
agent-7: 18.0
agent-8: 23.0
agent-9: 12.0
agent-10: 24.0
Sum Reward: 197.0
Avg Reward: 19.7
Min Reward: 12.0
Gini Coefficient: 0.11421319796954314
20:20 Ratio: 1.8461538461538463
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-41-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 250.0
  episode_reward_mean: 208.94
  episode_reward_min: 180.0
  episodes_this_iter: 1
  episodes_total: 393
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.137
    dispatch_time_ms: 5.915
    learner:
      cur_lr: 0.0010982620296999812
      grad_gnorm: 0.19777971506118774
      policy_entropy: 174.9614715576172
      policy_loss: -0.13553982973098755
      var_gnorm: 66.07603454589844
      vf_explained_var: 0.9959899187088013
      vf_loss: 0.0006723862607032061
    num_steps_sampled: 3940000
    num_steps_trained: 3940000
    wait_time_ms: 171.078
  iterations_since_restore: 394
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7208.7955441474915
  time_this_iter_s: 17.81125521659851
  time_total_s: 7208.7955441474915
  timestamp: 1593891675
  timesteps_since_restore: 3940000
  timesteps_this_iter: 10000
  timesteps_total: 3940000
  training_iteration: 394
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7208 s, 394 iter, 3940000 ts, 209 rew

agent-1: 29.0
agent-2: 22.0
agent-3: 19.0
agent-4: 31.0
agent-5: 17.0
agent-6: 9.0
agent-7: 25.0
agent-8: 11.0
agent-9: 29.0
agent-10: 18.0
Sum Reward: 210.0
Avg Reward: 21.0
Min Reward: 9.0
Gini Coefficient: 0.19428571428571428
20:20 Ratio: 3.0
Max-min Ratio: 3.4444444444444446
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-41-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 250.0
  episode_reward_mean: 208.81
  episode_reward_min: 180.0
  episodes_this_iter: 1
  episodes_total: 394
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.811
    dispatch_time_ms: 7.901
    learner:
      cur_lr: 0.0010975960176438093
      grad_gnorm: 1.0459810495376587
      policy_entropy: 164.93405151367188
      policy_loss: 0.30069470405578613
      var_gnorm: 66.14234924316406
      vf_explained_var: 0.9934249520301819
      vf_loss: 0.00146862689871341
    num_steps_sampled: 3950000
    num_steps_trained: 3950000
    wait_time_ms: 167.501
  iterations_since_restore: 395
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7226.702693462372
  time_this_iter_s: 17.90714931488037
  time_total_s: 7226.702693462372
  timestamp: 1593891693
  timesteps_since_restore: 3950000
  timesteps_this_iter: 10000
  timesteps_total: 3950000
  training_iteration: 395
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7226 s, 395 iter, 3950000 ts, 209 rew

agent-1: 11.0
agent-2: 29.0
agent-3: 22.0
agent-4: 16.0
agent-5: 17.0
agent-6: 14.0
agent-7: 25.0
agent-8: 27.0
agent-9: 26.0
agent-10: 18.0
Sum Reward: 205.0
Avg Reward: 20.5
Min Reward: 11.0
Gini Coefficient: 0.16146341463414635
20:20 Ratio: 2.24
Max-min Ratio: 2.6363636363636362
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-41-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 250.0
  episode_reward_mean: 208.51
  episode_reward_min: 180.0
  episodes_this_iter: 1
  episodes_total: 395
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.473
    dispatch_time_ms: 7.517
    learner:
      cur_lr: 0.0010969300055876374
      grad_gnorm: 1.0477808713912964
      policy_entropy: 172.6920166015625
      policy_loss: -0.46503984928131104
      var_gnorm: 66.24504089355469
      vf_explained_var: 0.9915473461151123
      vf_loss: 0.0017015027115121484
    num_steps_sampled: 3960000
    num_steps_trained: 3960000
    wait_time_ms: 167.701
  iterations_since_restore: 396
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7244.650399446487
  time_this_iter_s: 17.9477059841156
  time_total_s: 7244.650399446487
  timestamp: 1593891711
  timesteps_since_restore: 3960000
  timesteps_this_iter: 10000
  timesteps_total: 3960000
  training_iteration: 396
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7244 s, 396 iter, 3960000 ts, 209 rew

agent-1: 18.0
agent-2: 23.0
agent-3: 26.0
agent-4: 29.0
agent-5: 19.0
agent-6: 20.0
agent-7: 10.0
agent-8: 22.0
agent-9: 16.0
agent-10: 22.0
Sum Reward: 205.0
Avg Reward: 20.5
Min Reward: 10.0
Gini Coefficient: 0.1351219512195122
20:20 Ratio: 2.1153846153846154
Max-min Ratio: 2.9
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-42-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 250.0
  episode_reward_mean: 208.5
  episode_reward_min: 180.0
  episodes_this_iter: 1
  episodes_total: 396
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.762
    dispatch_time_ms: 7.566
    learner:
      cur_lr: 0.0010962639935314655
      grad_gnorm: 3.55027174949646
      policy_entropy: 168.46051025390625
      policy_loss: -1.2227363586425781
      var_gnorm: 66.23332977294922
      vf_explained_var: -1.0
      vf_loss: 0.001553588081151247
    num_steps_sampled: 3970000
    num_steps_trained: 3970000
    wait_time_ms: 171.65
  iterations_since_restore: 397
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7262.54359459877
  time_this_iter_s: 17.893195152282715
  time_total_s: 7262.54359459877
  timestamp: 1593891729
  timesteps_since_restore: 3970000
  timesteps_this_iter: 10000
  timesteps_total: 3970000
  training_iteration: 397
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7262 s, 397 iter, 3970000 ts, 208 rew

agent-1: 26.0
agent-2: 13.0
agent-3: 19.0
agent-4: 14.0
agent-5: 23.0
agent-6: 28.0
agent-7: 21.0
agent-8: 14.0
agent-9: 26.0
agent-10: 17.0
Sum Reward: 201.0
Avg Reward: 20.1
Min Reward: 13.0
Gini Coefficient: 0.14875621890547264
20:20 Ratio: 2.0
Max-min Ratio: 2.1538461538461537
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-42-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 250.0
  episode_reward_mean: 208.28
  episode_reward_min: 180.0
  episodes_this_iter: 1
  episodes_total: 397
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.096
    dispatch_time_ms: 8.838
    learner:
      cur_lr: 0.0010955979814752936
      grad_gnorm: 3.422363519668579
      policy_entropy: 155.75892639160156
      policy_loss: -1.2276941537857056
      var_gnorm: 66.37734985351562
      vf_explained_var: 0.9709342122077942
      vf_loss: 0.006245741620659828
    num_steps_sampled: 3980000
    num_steps_trained: 3980000
    wait_time_ms: 171.528
  iterations_since_restore: 398
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7280.400100946426
  time_this_iter_s: 17.85650634765625
  time_total_s: 7280.400100946426
  timestamp: 1593891747
  timesteps_since_restore: 3980000
  timesteps_this_iter: 10000
  timesteps_total: 3980000
  training_iteration: 398
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7280 s, 398 iter, 3980000 ts, 208 rew

agent-1: 19.0
agent-2: 22.0
agent-3: 18.0
agent-4: 15.0
agent-5: 21.0
agent-6: 25.0
agent-7: 28.0
agent-8: 15.0
agent-9: 20.0
agent-10: 26.0
Sum Reward: 209.0
Avg Reward: 20.9
Min Reward: 15.0
Gini Coefficient: 0.11435406698564593
20:20 Ratio: 1.8
Max-min Ratio: 1.8666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-42-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 250.0
  episode_reward_mean: 208.2
  episode_reward_min: 180.0
  episodes_this_iter: 1
  episodes_total: 398
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.737
    dispatch_time_ms: 7.453
    learner:
      cur_lr: 0.0010949319694191217
      grad_gnorm: 0.6394234299659729
      policy_entropy: 171.20094299316406
      policy_loss: 0.3077361285686493
      var_gnorm: 66.47838592529297
      vf_explained_var: 0.9761211276054382
      vf_loss: 0.0013298093108460307
    num_steps_sampled: 3990000
    num_steps_trained: 3990000
    wait_time_ms: 174.721
  iterations_since_restore: 399
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7298.168774604797
  time_this_iter_s: 17.76867365837097
  time_total_s: 7298.168774604797
  timestamp: 1593891765
  timesteps_since_restore: 3990000
  timesteps_this_iter: 10000
  timesteps_total: 3990000
  training_iteration: 399
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7298 s, 399 iter, 3990000 ts, 208 rew

agent-1: 22.0
agent-2: 25.0
agent-3: 33.0
agent-4: 27.0
agent-5: 13.0
agent-6: 25.0
agent-7: 32.0
agent-8: 13.0
agent-9: 18.0
agent-10: 15.0
Sum Reward: 223.0
Avg Reward: 22.3
Min Reward: 13.0
Gini Coefficient: 0.1780269058295964
20:20 Ratio: 2.5
Max-min Ratio: 2.5384615384615383
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-43-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 250.0
  episode_reward_mean: 208.29
  episode_reward_min: 180.0
  episodes_this_iter: 1
  episodes_total: 399
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.486
    dispatch_time_ms: 7.973
    learner:
      cur_lr: 0.0010942659573629498
      grad_gnorm: 2.4023473262786865
      policy_entropy: 172.49110412597656
      policy_loss: -2.0945487022399902
      var_gnorm: 66.54530334472656
      vf_explained_var: 0.7554820775985718
      vf_loss: 0.010355139151215553
    num_steps_sampled: 4000000
    num_steps_trained: 4000000
    wait_time_ms: 165.665
  iterations_since_restore: 400
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7315.856499195099
  time_this_iter_s: 17.687724590301514
  time_total_s: 7315.856499195099
  timestamp: 1593891782
  timesteps_since_restore: 4000000
  timesteps_this_iter: 10000
  timesteps_total: 4000000
  training_iteration: 400
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7315 s, 400 iter, 4000000 ts, 208 rew

agent-1: 17.0
agent-2: -24.0
agent-3: 23.0
agent-4: 26.0
agent-5: 13.0
agent-6: 15.0
agent-7: 23.0
agent-8: 29.0
agent-9: 18.0
agent-10: 22.0
Sum Reward: 162.0
Avg Reward: 16.2
Min Reward: -24.0
Gini Coefficient: 0.3888888888888889
20:20 Ratio: -5.0
Max-min Ratio: -1.2083333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-43-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 250.0
  episode_reward_mean: 207.73
  episode_reward_min: 162.0
  episodes_this_iter: 1
  episodes_total: 400
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.947
    dispatch_time_ms: 6.278
    learner:
      cur_lr: 0.001093599945306778
      grad_gnorm: 20.483776092529297
      policy_entropy: 151.05274963378906
      policy_loss: -1.789475679397583
      var_gnorm: 66.52967834472656
      vf_explained_var: -1.0
      vf_loss: 0.010900340043008327
    num_steps_sampled: 4010000
    num_steps_trained: 4010000
    wait_time_ms: 170.72
  iterations_since_restore: 401
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7337.786713838577
  time_this_iter_s: 21.930214643478394
  time_total_s: 7337.786713838577
  timestamp: 1593891804
  timesteps_since_restore: 4010000
  timesteps_this_iter: 10000
  timesteps_total: 4010000
  training_iteration: 401
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7337 s, 401 iter, 4010000 ts, 208 rew

agent-1: -25.0
agent-2: 22.0
agent-3: 27.0
agent-4: 19.0
agent-5: 17.0
agent-6: 22.0
agent-7: 20.0
agent-8: 18.0
agent-9: 21.0
agent-10: 16.0
Sum Reward: 157.0
Avg Reward: 15.7
Min Reward: -25.0
Gini Coefficient: 0.3471337579617834
20:20 Ratio: -5.444444444444445
Max-min Ratio: -1.08
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-43-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 250.0
  episode_reward_mean: 207.27
  episode_reward_min: 157.0
  episodes_this_iter: 1
  episodes_total: 401
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.465
    dispatch_time_ms: 6.284
    learner:
      cur_lr: 0.0010929340496659279
      grad_gnorm: 4.8491740226745605
      policy_entropy: 123.48745727539062
      policy_loss: -0.2295389026403427
      var_gnorm: 66.60870361328125
      vf_explained_var: -1.0
      vf_loss: 0.023559605702757835
    num_steps_sampled: 4020000
    num_steps_trained: 4020000
    wait_time_ms: 179.273
  iterations_since_restore: 402
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7355.8239941596985
  time_this_iter_s: 18.037280321121216
  time_total_s: 7355.8239941596985
  timestamp: 1593891822
  timesteps_since_restore: 4020000
  timesteps_this_iter: 10000
  timesteps_total: 4020000
  training_iteration: 402
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7355 s, 402 iter, 4020000 ts, 207 rew

agent-1: 23.0
agent-2: 32.0
agent-3: 17.0
agent-4: 18.0
agent-5: 24.0
agent-6: 22.0
agent-7: 11.0
agent-8: 31.0
agent-9: 23.0
agent-10: 13.0
Sum Reward: 214.0
Avg Reward: 21.4
Min Reward: 11.0
Gini Coefficient: 0.17102803738317757
20:20 Ratio: 2.625
Max-min Ratio: 2.909090909090909
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-44-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 250.0
  episode_reward_mean: 207.31
  episode_reward_min: 157.0
  episodes_this_iter: 1
  episodes_total: 402
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.315
    dispatch_time_ms: 32.643
    learner:
      cur_lr: 0.001092268037609756
      grad_gnorm: 20.8174991607666
      policy_entropy: 124.73173522949219
      policy_loss: -1.4585857391357422
      var_gnorm: 66.61334228515625
      vf_explained_var: -1.0
      vf_loss: 0.09493578225374222
    num_steps_sampled: 4030000
    num_steps_trained: 4030000
    wait_time_ms: 154.569
  iterations_since_restore: 403
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7374.438872098923
  time_this_iter_s: 18.614877939224243
  time_total_s: 7374.438872098923
  timestamp: 1593891841
  timesteps_since_restore: 4030000
  timesteps_this_iter: 10000
  timesteps_total: 4030000
  training_iteration: 403
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7374 s, 403 iter, 4030000 ts, 207 rew

agent-1: 24.0
agent-2: 30.0
agent-3: 24.0
agent-4: 16.0
agent-5: 19.0
agent-6: 15.0
agent-7: 17.0
agent-8: 25.0
agent-9: 22.0
agent-10: 19.0
Sum Reward: 211.0
Avg Reward: 21.1
Min Reward: 15.0
Gini Coefficient: 0.11895734597156397
20:20 Ratio: 1.7741935483870968
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-44-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 250.0
  episode_reward_mean: 207.41
  episode_reward_min: 157.0
  episodes_this_iter: 1
  episodes_total: 403
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 4.499
    dispatch_time_ms: 34.407
    learner:
      cur_lr: 0.001091602025553584
      grad_gnorm: 2.348271608352661
      policy_entropy: 135.5641632080078
      policy_loss: 0.6314445734024048
      var_gnorm: 66.6697006225586
      vf_explained_var: -0.42283594608306885
      vf_loss: 0.017803184688091278
    num_steps_sampled: 4040000
    num_steps_trained: 4040000
    wait_time_ms: 143.983
  iterations_since_restore: 404
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7393.197438716888
  time_this_iter_s: 18.7585666179657
  time_total_s: 7393.197438716888
  timestamp: 1593891860
  timesteps_since_restore: 4040000
  timesteps_this_iter: 10000
  timesteps_total: 4040000
  training_iteration: 404
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7393 s, 404 iter, 4040000 ts, 207 rew

agent-1: 21.0
agent-2: 21.0
agent-3: 26.0
agent-4: 21.0
agent-5: 14.0
agent-6: 17.0
agent-7: 26.0
agent-8: 19.0
agent-9: 18.0
agent-10: 24.0
Sum Reward: 207.0
Avg Reward: 20.7
Min Reward: 14.0
Gini Coefficient: 0.1
20:20 Ratio: 1.6774193548387097
Max-min Ratio: 1.8571428571428572
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-44-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 250.0
  episode_reward_mean: 207.41
  episode_reward_min: 157.0
  episodes_this_iter: 1
  episodes_total: 404
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.698
    dispatch_time_ms: 28.883
    learner:
      cur_lr: 0.0010909360134974122
      grad_gnorm: 0.20669208467006683
      policy_entropy: 156.2282257080078
      policy_loss: -0.373052716255188
      var_gnorm: 66.73168182373047
      vf_explained_var: -1.0
      vf_loss: 1.80974711838644e-05
    num_steps_sampled: 4050000
    num_steps_trained: 4050000
    wait_time_ms: 165.647
  iterations_since_restore: 405
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7412.175539493561
  time_this_iter_s: 18.978100776672363
  time_total_s: 7412.175539493561
  timestamp: 1593891879
  timesteps_since_restore: 4050000
  timesteps_this_iter: 10000
  timesteps_total: 4050000
  training_iteration: 405
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7412 s, 405 iter, 4050000 ts, 207 rew

agent-1: 26.0
agent-2: 21.0
agent-3: 20.0
agent-4: 19.0
agent-5: 25.0
agent-6: 22.0
agent-7: 19.0
agent-8: 30.0
agent-9: 23.0
agent-10: 25.0
Sum Reward: 230.0
Avg Reward: 23.0
Min Reward: 19.0
Gini Coefficient: 0.0808695652173913
20:20 Ratio: 1.4736842105263157
Max-min Ratio: 1.5789473684210527
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-44-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 250.0
  episode_reward_mean: 207.71
  episode_reward_min: 157.0
  episodes_this_iter: 1
  episodes_total: 405
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.633
    dispatch_time_ms: 37.824
    learner:
      cur_lr: 0.0010902700014412403
      grad_gnorm: 1.1475967168807983
      policy_entropy: 164.73065185546875
      policy_loss: 0.21722295880317688
      var_gnorm: 66.71292114257812
      vf_explained_var: -1.0
      vf_loss: 0.0014618179993703961
    num_steps_sampled: 4060000
    num_steps_trained: 4060000
    wait_time_ms: 155.336
  iterations_since_restore: 406
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7431.040933609009
  time_this_iter_s: 18.865394115447998
  time_total_s: 7431.040933609009
  timestamp: 1593891898
  timesteps_since_restore: 4060000
  timesteps_this_iter: 10000
  timesteps_total: 4060000
  training_iteration: 406
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7431 s, 406 iter, 4060000 ts, 208 rew

agent-1: 23.0
agent-2: 19.0
agent-3: 27.0
agent-4: 26.0
agent-5: 22.0
agent-6: 11.0
agent-7: 16.0
agent-8: 28.0
agent-9: 14.0
agent-10: 31.0
Sum Reward: 217.0
Avg Reward: 21.7
Min Reward: 11.0
Gini Coefficient: 0.16359447004608296
20:20 Ratio: 2.36
Max-min Ratio: 2.8181818181818183
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-45-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 250.0
  episode_reward_mean: 207.8
  episode_reward_min: 157.0
  episodes_this_iter: 1
  episodes_total: 406
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.311
    dispatch_time_ms: 40.762
    learner:
      cur_lr: 0.0010896039893850684
      grad_gnorm: 0.5805550217628479
      policy_entropy: 153.9481201171875
      policy_loss: -0.6256551742553711
      var_gnorm: 66.82674407958984
      vf_explained_var: 0.08405804634094238
      vf_loss: 0.006046151742339134
    num_steps_sampled: 4070000
    num_steps_trained: 4070000
    wait_time_ms: 141.26
  iterations_since_restore: 407
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7449.957176685333
  time_this_iter_s: 18.916243076324463
  time_total_s: 7449.957176685333
  timestamp: 1593891917
  timesteps_since_restore: 4070000
  timesteps_this_iter: 10000
  timesteps_total: 4070000
  training_iteration: 407
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7449 s, 407 iter, 4070000 ts, 208 rew

agent-1: 12.0
agent-2: 25.0
agent-3: 28.0
agent-4: 16.0
agent-5: 28.0
agent-6: 22.0
agent-7: 18.0
agent-8: 19.0
agent-9: 28.0
agent-10: 14.0
Sum Reward: 210.0
Avg Reward: 21.0
Min Reward: 12.0
Gini Coefficient: 0.15523809523809523
20:20 Ratio: 2.1538461538461537
Max-min Ratio: 2.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-45-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 250.0
  episode_reward_mean: 207.77
  episode_reward_min: 157.0
  episodes_this_iter: 1
  episodes_total: 407
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.281
    dispatch_time_ms: 6.674
    learner:
      cur_lr: 0.0010889379773288965
      grad_gnorm: 1.0495915412902832
      policy_entropy: 158.5411834716797
      policy_loss: -0.03361170366406441
      var_gnorm: 66.85375213623047
      vf_explained_var: -0.8865693807601929
      vf_loss: 0.001895800931379199
    num_steps_sampled: 4080000
    num_steps_trained: 4080000
    wait_time_ms: 173.502
  iterations_since_restore: 408
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7467.912182331085
  time_this_iter_s: 17.955005645751953
  time_total_s: 7467.912182331085
  timestamp: 1593891935
  timesteps_since_restore: 4080000
  timesteps_this_iter: 10000
  timesteps_total: 4080000
  training_iteration: 408
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7467 s, 408 iter, 4080000 ts, 208 rew

agent-1: 20.0
agent-2: 19.0
agent-3: 23.0
agent-4: 22.0
agent-5: 19.0
agent-6: 18.0
agent-7: 27.0
agent-8: 23.0
agent-9: 21.0
agent-10: 22.0
Sum Reward: 214.0
Avg Reward: 21.4
Min Reward: 18.0
Gini Coefficient: 0.06355140186915888
20:20 Ratio: 1.3513513513513513
Max-min Ratio: 1.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-45-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 250.0
  episode_reward_mean: 207.65
  episode_reward_min: 157.0
  episodes_this_iter: 1
  episodes_total: 408
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.326
    dispatch_time_ms: 7.175
    learner:
      cur_lr: 0.0010882719652727246
      grad_gnorm: 11.08913803100586
      policy_entropy: 164.29627990722656
      policy_loss: -2.392808675765991
      var_gnorm: 66.79710388183594
      vf_explained_var: -0.0433192253112793
      vf_loss: 0.32350319623947144
    num_steps_sampled: 4090000
    num_steps_trained: 4090000
    wait_time_ms: 170.621
  iterations_since_restore: 409
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7485.622977018356
  time_this_iter_s: 17.710794687271118
  time_total_s: 7485.622977018356
  timestamp: 1593891953
  timesteps_since_restore: 4090000
  timesteps_this_iter: 10000
  timesteps_total: 4090000
  training_iteration: 409
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7485 s, 409 iter, 4090000 ts, 208 rew

agent-1: 19.0
agent-2: 21.0
agent-3: 25.0
agent-4: 17.0
agent-5: 15.0
agent-6: 23.0
agent-7: 21.0
agent-8: 26.0
agent-9: 22.0
agent-10: 22.0
Sum Reward: 211.0
Avg Reward: 21.1
Min Reward: 15.0
Gini Coefficient: 0.08483412322274882
20:20 Ratio: 1.59375
Max-min Ratio: 1.7333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-46-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 250.0
  episode_reward_mean: 207.83
  episode_reward_min: 157.0
  episodes_this_iter: 1
  episodes_total: 409
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.749
    dispatch_time_ms: 6.068
    learner:
      cur_lr: 0.0010876059532165527
      grad_gnorm: 2.8891422748565674
      policy_entropy: 155.63778686523438
      policy_loss: -0.0018822811543941498
      var_gnorm: 66.83477783203125
      vf_explained_var: 0.9823575615882874
      vf_loss: 0.0021899680141359568
    num_steps_sampled: 4100000
    num_steps_trained: 4100000
    wait_time_ms: 171.705
  iterations_since_restore: 410
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7503.536784887314
  time_this_iter_s: 17.91380786895752
  time_total_s: 7503.536784887314
  timestamp: 1593891971
  timesteps_since_restore: 4100000
  timesteps_this_iter: 10000
  timesteps_total: 4100000
  training_iteration: 410
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7503 s, 410 iter, 4100000 ts, 208 rew

agent-1: 22.0
agent-2: 16.0
agent-3: 24.0
agent-4: 15.0
agent-5: 20.0
agent-6: 22.0
agent-7: 21.0
agent-8: 39.0
agent-9: 24.0
agent-10: 13.0
Sum Reward: 216.0
Avg Reward: 21.6
Min Reward: 13.0
Gini Coefficient: 0.15925925925925927
20:20 Ratio: 2.25
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-46-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 250.0
  episode_reward_mean: 207.87
  episode_reward_min: 157.0
  episodes_this_iter: 1
  episodes_total: 410
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.119
    dispatch_time_ms: 7.046
    learner:
      cur_lr: 0.0010869400575757027
      grad_gnorm: 4.417667388916016
      policy_entropy: 170.344970703125
      policy_loss: 0.20622111856937408
      var_gnorm: 66.99475860595703
      vf_explained_var: 0.9954078197479248
      vf_loss: 0.0005799897480756044
    num_steps_sampled: 4110000
    num_steps_trained: 4110000
    wait_time_ms: 165.302
  iterations_since_restore: 411
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7521.413541316986
  time_this_iter_s: 17.87675642967224
  time_total_s: 7521.413541316986
  timestamp: 1593891988
  timesteps_since_restore: 4110000
  timesteps_this_iter: 10000
  timesteps_total: 4110000
  training_iteration: 411
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7521 s, 411 iter, 4110000 ts, 208 rew

agent-1: 18.0
agent-2: 23.0
agent-3: 20.0
agent-4: 20.0
agent-5: 21.0
agent-6: 17.0
agent-7: 22.0
agent-8: 30.0
agent-9: 18.0
agent-10: 21.0
Sum Reward: 210.0
Avg Reward: 21.0
Min Reward: 17.0
Gini Coefficient: 0.0838095238095238
20:20 Ratio: 1.5142857142857142
Max-min Ratio: 1.7647058823529411
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-46-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 250.0
  episode_reward_mean: 207.94
  episode_reward_min: 157.0
  episodes_this_iter: 1
  episodes_total: 411
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.662
    dispatch_time_ms: 5.542
    learner:
      cur_lr: 0.0010862740455195308
      grad_gnorm: 1.3699113130569458
      policy_entropy: 178.4559326171875
      policy_loss: 0.23957493901252747
      var_gnorm: 67.0678482055664
      vf_explained_var: 0.9940952062606812
      vf_loss: 0.0010824199998751283
    num_steps_sampled: 4120000
    num_steps_trained: 4120000
    wait_time_ms: 169.95
  iterations_since_restore: 412
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7539.253089189529
  time_this_iter_s: 17.839547872543335
  time_total_s: 7539.253089189529
  timestamp: 1593892006
  timesteps_since_restore: 4120000
  timesteps_this_iter: 10000
  timesteps_total: 4120000
  training_iteration: 412
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7539 s, 412 iter, 4120000 ts, 208 rew

agent-1: 31.0
agent-2: 26.0
agent-3: 18.0
agent-4: 32.0
agent-5: 22.0
agent-6: 31.0
agent-7: 25.0
agent-8: 26.0
agent-9: 13.0
agent-10: 31.0
Sum Reward: 255.0
Avg Reward: 25.5
Min Reward: 13.0
Gini Coefficient: 0.12745098039215685
20:20 Ratio: 2.032258064516129
Max-min Ratio: 2.4615384615384617
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-47-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.48
  episode_reward_min: 157.0
  episodes_this_iter: 1
  episodes_total: 412
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.505
    dispatch_time_ms: 5.989
    learner:
      cur_lr: 0.0010856080334633589
      grad_gnorm: 4.339807033538818
      policy_entropy: 169.2139434814453
      policy_loss: -2.1784677505493164
      var_gnorm: 67.09174346923828
      vf_explained_var: 0.9730168581008911
      vf_loss: 0.011530758813023567
    num_steps_sampled: 4130000
    num_steps_trained: 4130000
    wait_time_ms: 166.242
  iterations_since_restore: 413
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7557.201959371567
  time_this_iter_s: 17.948870182037354
  time_total_s: 7557.201959371567
  timestamp: 1593892024
  timesteps_since_restore: 4130000
  timesteps_this_iter: 10000
  timesteps_total: 4130000
  training_iteration: 413
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7557 s, 413 iter, 4130000 ts, 208 rew

agent-1: 20.0
agent-2: 17.0
agent-3: 20.0
agent-4: 22.0
agent-5: 19.0
agent-6: 19.0
agent-7: 22.0
agent-8: 24.0
agent-9: 24.0
agent-10: 19.0
Sum Reward: 206.0
Avg Reward: 20.6
Min Reward: 17.0
Gini Coefficient: 0.059223300970873784
20:20 Ratio: 1.3333333333333333
Max-min Ratio: 1.411764705882353
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-47-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.54
  episode_reward_min: 157.0
  episodes_this_iter: 1
  episodes_total: 413
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.483
    dispatch_time_ms: 7.312
    learner:
      cur_lr: 0.001084942021407187
      grad_gnorm: 8.099181175231934
      policy_entropy: 169.60935974121094
      policy_loss: -0.3071804344654083
      var_gnorm: 67.11215209960938
      vf_explained_var: -1.0
      vf_loss: 0.017992638051509857
    num_steps_sampled: 4140000
    num_steps_trained: 4140000
    wait_time_ms: 171.866
  iterations_since_restore: 414
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7575.151086568832
  time_this_iter_s: 17.949127197265625
  time_total_s: 7575.151086568832
  timestamp: 1593892042
  timesteps_since_restore: 4140000
  timesteps_this_iter: 10000
  timesteps_total: 4140000
  training_iteration: 414
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7575 s, 414 iter, 4140000 ts, 209 rew

agent-1: 16.0
agent-2: 25.0
agent-3: 28.0
agent-4: 22.0
agent-5: 15.0
agent-6: 23.0
agent-7: 13.0
agent-8: 25.0
agent-9: 18.0
agent-10: 38.0
Sum Reward: 223.0
Avg Reward: 22.3
Min Reward: 13.0
Gini Coefficient: 0.1717488789237668
20:20 Ratio: 2.357142857142857
Max-min Ratio: 2.923076923076923
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-47-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.52
  episode_reward_min: 157.0
  episodes_this_iter: 1
  episodes_total: 414
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.794
    dispatch_time_ms: 7.871
    learner:
      cur_lr: 0.001084276009351015
      grad_gnorm: 4.255214691162109
      policy_entropy: 166.76397705078125
      policy_loss: -2.1836063861846924
      var_gnorm: 67.13349151611328
      vf_explained_var: 0.24046295881271362
      vf_loss: 0.019383270293474197
    num_steps_sampled: 4150000
    num_steps_trained: 4150000
    wait_time_ms: 166.488
  iterations_since_restore: 415
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7592.874060153961
  time_this_iter_s: 17.722973585128784
  time_total_s: 7592.874060153961
  timestamp: 1593892060
  timesteps_since_restore: 4150000
  timesteps_this_iter: 10000
  timesteps_total: 4150000
  training_iteration: 415
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7592 s, 415 iter, 4150000 ts, 209 rew

agent-1: 22.0
agent-2: 18.0
agent-3: 24.0
agent-4: 14.0
agent-5: 23.0
agent-6: 25.0
agent-7: 26.0
agent-8: 21.0
agent-9: 18.0
agent-10: 17.0
Sum Reward: 208.0
Avg Reward: 20.8
Min Reward: 14.0
Gini Coefficient: 0.10096153846153846
20:20 Ratio: 1.6451612903225807
Max-min Ratio: 1.8571428571428572
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-47-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.62
  episode_reward_min: 157.0
  episodes_this_iter: 1
  episodes_total: 415
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.193
    dispatch_time_ms: 7.758
    learner:
      cur_lr: 0.0010836099972948432
      grad_gnorm: 0.5522944331169128
      policy_entropy: 170.0413055419922
      policy_loss: 0.15301522612571716
      var_gnorm: 67.09712219238281
      vf_explained_var: 0.7914725542068481
      vf_loss: 0.00022542329679708928
    num_steps_sampled: 4160000
    num_steps_trained: 4160000
    wait_time_ms: 169.733
  iterations_since_restore: 416
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7610.794145584106
  time_this_iter_s: 17.920085430145264
  time_total_s: 7610.794145584106
  timestamp: 1593892078
  timesteps_since_restore: 4160000
  timesteps_this_iter: 10000
  timesteps_total: 4160000
  training_iteration: 416
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7610 s, 416 iter, 4160000 ts, 209 rew

agent-1: 30.0
agent-2: 16.0
agent-3: 17.0
agent-4: 21.0
agent-5: 27.0
agent-6: 28.0
agent-7: 24.0
agent-8: 24.0
agent-9: 26.0
agent-10: 18.0
Sum Reward: 231.0
Avg Reward: 23.1
Min Reward: 16.0
Gini Coefficient: 0.11385281385281386
20:20 Ratio: 1.7575757575757576
Max-min Ratio: 1.875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-48-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.98
  episode_reward_min: 157.0
  episodes_this_iter: 1
  episodes_total: 416
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.975
    dispatch_time_ms: 6.413
    learner:
      cur_lr: 0.0010829439852386713
      grad_gnorm: 1.626599907875061
      policy_entropy: 175.1064910888672
      policy_loss: -1.2804055213928223
      var_gnorm: 67.15145111083984
      vf_explained_var: 0.9151148796081543
      vf_loss: 0.001766145578585565
    num_steps_sampled: 4170000
    num_steps_trained: 4170000
    wait_time_ms: 169.394
  iterations_since_restore: 417
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7628.6565935611725
  time_this_iter_s: 17.86244797706604
  time_total_s: 7628.6565935611725
  timestamp: 1593892096
  timesteps_since_restore: 4170000
  timesteps_this_iter: 10000
  timesteps_total: 4170000
  training_iteration: 417
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7628 s, 417 iter, 4170000 ts, 209 rew

agent-1: 26.0
agent-2: 29.0
agent-3: 17.0
agent-4: 23.0
agent-5: 21.0
agent-6: 18.0
agent-7: 18.0
agent-8: 21.0
agent-9: 23.0
agent-10: 23.0
Sum Reward: 219.0
Avg Reward: 21.9
Min Reward: 17.0
Gini Coefficient: 0.08995433789954338
20:20 Ratio: 1.5714285714285714
Max-min Ratio: 1.7058823529411764
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-48-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.84
  episode_reward_min: 157.0
  episodes_this_iter: 1
  episodes_total: 417
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.742
    dispatch_time_ms: 6.052
    learner:
      cur_lr: 0.0010822779731824994
      grad_gnorm: 0.45085713267326355
      policy_entropy: 175.2668914794922
      policy_loss: -0.13549603521823883
      var_gnorm: 67.22513580322266
      vf_explained_var: 0.9740626811981201
      vf_loss: 0.0026614018715918064
    num_steps_sampled: 4180000
    num_steps_trained: 4180000
    wait_time_ms: 170.773
  iterations_since_restore: 418
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7650.693331480026
  time_this_iter_s: 22.03673791885376
  time_total_s: 7650.693331480026
  timestamp: 1593892118
  timesteps_since_restore: 4180000
  timesteps_this_iter: 10000
  timesteps_total: 4180000
  training_iteration: 418
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7650 s, 418 iter, 4180000 ts, 209 rew

agent-1: 29.0
agent-2: 16.0
agent-3: 28.0
agent-4: 24.0
agent-5: 24.0
agent-6: 28.0
agent-7: 33.0
agent-8: 19.0
agent-9: 22.0
agent-10: 25.0
Sum Reward: 248.0
Avg Reward: 24.8
Min Reward: 16.0
Gini Coefficient: 0.10725806451612903
20:20 Ratio: 1.7714285714285714
Max-min Ratio: 2.0625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-48-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 209.3
  episode_reward_min: 157.0
  episodes_this_iter: 1
  episodes_total: 418
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.939
    dispatch_time_ms: 7.574
    learner:
      cur_lr: 0.0010816119611263275
      grad_gnorm: 4.979606628417969
      policy_entropy: 147.8790283203125
      policy_loss: -3.196089267730713
      var_gnorm: 67.30738067626953
      vf_explained_var: 0.6305866837501526
      vf_loss: 0.016408856958150864
    num_steps_sampled: 4190000
    num_steps_trained: 4190000
    wait_time_ms: 175.297
  iterations_since_restore: 419
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7668.508186817169
  time_this_iter_s: 17.814855337142944
  time_total_s: 7668.508186817169
  timestamp: 1593892136
  timesteps_since_restore: 4190000
  timesteps_this_iter: 10000
  timesteps_total: 4190000
  training_iteration: 419
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7668 s, 419 iter, 4190000 ts, 209 rew

agent-1: 26.0
agent-2: 21.0
agent-3: 19.0
agent-4: 23.0
agent-5: 14.0
agent-6: 20.0
agent-7: 30.0
agent-8: 11.0
agent-9: 14.0
agent-10: 21.0
Sum Reward: 199.0
Avg Reward: 19.9
Min Reward: 11.0
Gini Coefficient: 0.1542713567839196
20:20 Ratio: 2.24
Max-min Ratio: 2.727272727272727
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-49-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 209.03
  episode_reward_min: 157.0
  episodes_this_iter: 1
  episodes_total: 419
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.59
    dispatch_time_ms: 7.756
    learner:
      cur_lr: 0.0010809459490701556
      grad_gnorm: 3.2879650592803955
      policy_entropy: 144.8321533203125
      policy_loss: -0.08986379206180573
      var_gnorm: 67.40300750732422
      vf_explained_var: -1.0
      vf_loss: 0.0033488906919956207
    num_steps_sampled: 4200000
    num_steps_trained: 4200000
    wait_time_ms: 175.084
  iterations_since_restore: 420
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7686.547977685928
  time_this_iter_s: 18.039790868759155
  time_total_s: 7686.547977685928
  timestamp: 1593892154
  timesteps_since_restore: 4200000
  timesteps_this_iter: 10000
  timesteps_total: 4200000
  training_iteration: 420
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7686 s, 420 iter, 4200000 ts, 209 rew

agent-1: 27.0
agent-2: 23.0
agent-3: 20.0
agent-4: 19.0
agent-5: 15.0
agent-6: 22.0
agent-7: 17.0
agent-8: 23.0
agent-9: 19.0
agent-10: 16.0
Sum Reward: 201.0
Avg Reward: 20.1
Min Reward: 15.0
Gini Coefficient: 0.09800995024875622
20:20 Ratio: 1.6129032258064515
Max-min Ratio: 1.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-49-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.97
  episode_reward_min: 157.0
  episodes_this_iter: 1
  episodes_total: 420
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.743
    dispatch_time_ms: 7.945
    learner:
      cur_lr: 0.0010802800534293056
      grad_gnorm: 0.7246602773666382
      policy_entropy: 174.80654907226562
      policy_loss: -0.11026258021593094
      var_gnorm: 67.41584014892578
      vf_explained_var: 0.9840404987335205
      vf_loss: 0.00020514652715064585
    num_steps_sampled: 4210000
    num_steps_trained: 4210000
    wait_time_ms: 166.839
  iterations_since_restore: 421
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7702.938758850098
  time_this_iter_s: 16.39078116416931
  time_total_s: 7702.938758850098
  timestamp: 1593892182
  timesteps_since_restore: 4210000
  timesteps_this_iter: 10000
  timesteps_total: 4210000
  training_iteration: 421
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7702 s, 421 iter, 4210000 ts, 209 rew

agent-1: 25.0
agent-2: 18.0
agent-3: 12.0
agent-4: 21.0
agent-5: 24.0
agent-6: 21.0
agent-7: 15.0
agent-8: 24.0
agent-9: 8.0
agent-10: 21.0
Sum Reward: 189.0
Avg Reward: 18.9
Min Reward: 8.0
Gini Coefficient: 0.15396825396825398
20:20 Ratio: 2.45
Max-min Ratio: 3.125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-50-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.77
  episode_reward_min: 157.0
  episodes_this_iter: 1
  episodes_total: 421
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.558
    dispatch_time_ms: 7.287
    learner:
      cur_lr: 0.0010796140413731337
      grad_gnorm: 0.5118957161903381
      policy_entropy: 160.7391357421875
      policy_loss: -0.22585394978523254
      var_gnorm: 67.47960662841797
      vf_explained_var: 0.9929913282394409
      vf_loss: 0.0007584767881780863
    num_steps_sampled: 4220000
    num_steps_trained: 4220000
    wait_time_ms: 161.28
  iterations_since_restore: 422
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7720.684008359909
  time_this_iter_s: 17.7452495098114
  time_total_s: 7720.684008359909
  timestamp: 1593892200
  timesteps_since_restore: 4220000
  timesteps_this_iter: 10000
  timesteps_total: 4220000
  training_iteration: 422
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7720 s, 422 iter, 4220000 ts, 209 rew

agent-1: 23.0
agent-2: 22.0
agent-3: 23.0
agent-4: 12.0
agent-5: 27.0
agent-6: 24.0
agent-7: 19.0
agent-8: 23.0
agent-9: 22.0
agent-10: 18.0
Sum Reward: 213.0
Avg Reward: 21.3
Min Reward: 12.0
Gini Coefficient: 0.09436619718309859
20:20 Ratio: 1.7
Max-min Ratio: 2.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-50-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.63
  episode_reward_min: 157.0
  episodes_this_iter: 1
  episodes_total: 422
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.362
    dispatch_time_ms: 7.54
    learner:
      cur_lr: 0.0010789480293169618
      grad_gnorm: 4.5773186683654785
      policy_entropy: 145.6351776123047
      policy_loss: -3.2936503887176514
      var_gnorm: 67.60501861572266
      vf_explained_var: 0.008397817611694336
      vf_loss: 0.031001949682831764
    num_steps_sampled: 4230000
    num_steps_trained: 4230000
    wait_time_ms: 172.316
  iterations_since_restore: 423
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7738.6984350681305
  time_this_iter_s: 18.014426708221436
  time_total_s: 7738.6984350681305
  timestamp: 1593892218
  timesteps_since_restore: 4230000
  timesteps_this_iter: 10000
  timesteps_total: 4230000
  training_iteration: 423
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7738 s, 423 iter, 4230000 ts, 209 rew

agent-1: 15.0
agent-2: 28.0
agent-3: 27.0
agent-4: 11.0
agent-5: 19.0
agent-6: 20.0
agent-7: 18.0
agent-8: 19.0
agent-9: 25.0
agent-10: 21.0
Sum Reward: 203.0
Avg Reward: 20.3
Min Reward: 11.0
Gini Coefficient: 0.1374384236453202
20:20 Ratio: 2.1153846153846154
Max-min Ratio: 2.5454545454545454
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-50-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.63
  episode_reward_min: 157.0
  episodes_this_iter: 1
  episodes_total: 423
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 4.093
    dispatch_time_ms: 6.644
    learner:
      cur_lr: 0.0010782820172607899
      grad_gnorm: 2.9676144123077393
      policy_entropy: 156.39096069335938
      policy_loss: 1.714661717414856
      var_gnorm: 67.62175750732422
      vf_explained_var: -0.05331981182098389
      vf_loss: 0.016758691519498825
    num_steps_sampled: 4240000
    num_steps_trained: 4240000
    wait_time_ms: 166.592
  iterations_since_restore: 424
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7756.633574962616
  time_this_iter_s: 17.935139894485474
  time_total_s: 7756.633574962616
  timestamp: 1593892236
  timesteps_since_restore: 4240000
  timesteps_this_iter: 10000
  timesteps_total: 4240000
  training_iteration: 424
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7756 s, 424 iter, 4240000 ts, 209 rew

agent-1: 30.0
agent-2: 17.0
agent-3: 22.0
agent-4: 19.0
agent-5: 30.0
agent-6: 27.0
agent-7: 21.0
agent-8: 15.0
agent-9: 41.0
agent-10: 24.0
Sum Reward: 246.0
Avg Reward: 24.6
Min Reward: 15.0
Gini Coefficient: 0.16260162601626016
20:20 Ratio: 2.21875
Max-min Ratio: 2.7333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-50-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.97
  episode_reward_min: 157.0
  episodes_this_iter: 1
  episodes_total: 424
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.758
    dispatch_time_ms: 10.489
    learner:
      cur_lr: 0.001077616005204618
      grad_gnorm: 0.534129798412323
      policy_entropy: 153.47210693359375
      policy_loss: -0.38090696930885315
      var_gnorm: 67.59745025634766
      vf_explained_var: 0.9959869384765625
      vf_loss: 0.0003660666407085955
    num_steps_sampled: 4250000
    num_steps_trained: 4250000
    wait_time_ms: 168.089
  iterations_since_restore: 425
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7774.550512313843
  time_this_iter_s: 17.916937351226807
  time_total_s: 7774.550512313843
  timestamp: 1593892254
  timesteps_since_restore: 4250000
  timesteps_this_iter: 10000
  timesteps_total: 4250000
  training_iteration: 425
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7774 s, 425 iter, 4250000 ts, 209 rew

agent-1: 26.0
agent-2: 19.0
agent-3: 19.0
agent-4: 19.0
agent-5: 24.0
agent-6: 17.0
agent-7: 15.0
agent-8: 21.0
agent-9: 20.0
agent-10: 19.0
Sum Reward: 199.0
Avg Reward: 19.9
Min Reward: 15.0
Gini Coefficient: 0.08090452261306533
20:20 Ratio: 1.5625
Max-min Ratio: 1.7333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-51-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.77
  episode_reward_min: 157.0
  episodes_this_iter: 1
  episodes_total: 425
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.091
    dispatch_time_ms: 7.28
    learner:
      cur_lr: 0.001076949993148446
      grad_gnorm: 0.27479884028434753
      policy_entropy: 165.73988342285156
      policy_loss: -0.10985837876796722
      var_gnorm: 67.65533447265625
      vf_explained_var: 0.21912962198257446
      vf_loss: 0.00015330706082750112
    num_steps_sampled: 4260000
    num_steps_trained: 4260000
    wait_time_ms: 164.463
  iterations_since_restore: 426
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7792.514131069183
  time_this_iter_s: 17.963618755340576
  time_total_s: 7792.514131069183
  timestamp: 1593892272
  timesteps_since_restore: 4260000
  timesteps_this_iter: 10000
  timesteps_total: 4260000
  training_iteration: 426
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7792 s, 426 iter, 4260000 ts, 209 rew

agent-1: 15.0
agent-2: 22.0
agent-3: 20.0
agent-4: 17.0
agent-5: 19.0
agent-6: 18.0
agent-7: 29.0
agent-8: 22.0
agent-9: 26.0
agent-10: 33.0
Sum Reward: 221.0
Avg Reward: 22.1
Min Reward: 15.0
Gini Coefficient: 0.1343891402714932
20:20 Ratio: 1.9375
Max-min Ratio: 2.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-51-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.83
  episode_reward_min: 157.0
  episodes_this_iter: 1
  episodes_total: 426
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.863
    dispatch_time_ms: 7.721
    learner:
      cur_lr: 0.0010762839810922742
      grad_gnorm: 2.675095796585083
      policy_entropy: 149.27169799804688
      policy_loss: -0.4076191782951355
      var_gnorm: 67.6970443725586
      vf_explained_var: -1.0
      vf_loss: 0.001781908213160932
    num_steps_sampled: 4270000
    num_steps_trained: 4270000
    wait_time_ms: 169.321
  iterations_since_restore: 427
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7810.354615926743
  time_this_iter_s: 17.840484857559204
  time_total_s: 7810.354615926743
  timestamp: 1593892290
  timesteps_since_restore: 4270000
  timesteps_this_iter: 10000
  timesteps_total: 4270000
  training_iteration: 427
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7810 s, 427 iter, 4270000 ts, 209 rew

agent-1: 21.0
agent-2: 15.0
agent-3: 15.0
agent-4: 25.0
agent-5: 32.0
agent-6: 15.0
agent-7: 30.0
agent-8: 26.0
agent-9: 22.0
agent-10: 25.0
Sum Reward: 226.0
Avg Reward: 22.6
Min Reward: 15.0
Gini Coefficient: 0.14513274336283186
20:20 Ratio: 2.066666666666667
Max-min Ratio: 2.1333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-51-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.67
  episode_reward_min: 157.0
  episodes_this_iter: 1
  episodes_total: 427
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.345
    dispatch_time_ms: 6.076
    learner:
      cur_lr: 0.0010756179690361023
      grad_gnorm: 0.6940941214561462
      policy_entropy: 178.54190063476562
      policy_loss: -0.39714768528938293
      var_gnorm: 67.81595611572266
      vf_explained_var: 0.9895107746124268
      vf_loss: 0.0004031473072245717
    num_steps_sampled: 4280000
    num_steps_trained: 4280000
    wait_time_ms: 180.652
  iterations_since_restore: 428
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7828.204092502594
  time_this_iter_s: 17.84947657585144
  time_total_s: 7828.204092502594
  timestamp: 1593892308
  timesteps_since_restore: 4280000
  timesteps_this_iter: 10000
  timesteps_total: 4280000
  training_iteration: 428
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7828 s, 428 iter, 4280000 ts, 209 rew

agent-1: 15.0
agent-2: 27.0
agent-3: 25.0
agent-4: 23.0
agent-5: 26.0
agent-6: 20.0
agent-7: 13.0
agent-8: 26.0
agent-9: 19.0
agent-10: 21.0
Sum Reward: 215.0
Avg Reward: 21.5
Min Reward: 13.0
Gini Coefficient: 0.1186046511627907
20:20 Ratio: 1.8928571428571428
Max-min Ratio: 2.076923076923077
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-52-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.84
  episode_reward_min: 157.0
  episodes_this_iter: 1
  episodes_total: 428
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.91
    dispatch_time_ms: 7.09
    learner:
      cur_lr: 0.0010749519569799304
      grad_gnorm: 1.6782406568527222
      policy_entropy: 174.10475158691406
      policy_loss: 0.8873311877250671
      var_gnorm: 67.90548706054688
      vf_explained_var: 0.8578014969825745
      vf_loss: 0.001914800493977964
    num_steps_sampled: 4290000
    num_steps_trained: 4290000
    wait_time_ms: 167.688
  iterations_since_restore: 429
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7845.877737998962
  time_this_iter_s: 17.673645496368408
  time_total_s: 7845.877737998962
  timestamp: 1593892325
  timesteps_since_restore: 4290000
  timesteps_this_iter: 10000
  timesteps_total: 4290000
  training_iteration: 429
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7845 s, 429 iter, 4290000 ts, 209 rew

agent-1: 20.0
agent-2: 14.0
agent-3: 14.0
agent-4: 34.0
agent-5: 18.0
agent-6: 21.0
agent-7: 26.0
agent-8: 16.0
agent-9: 20.0
agent-10: 30.0
Sum Reward: 213.0
Avg Reward: 21.3
Min Reward: 14.0
Gini Coefficient: 0.1647887323943662
20:20 Ratio: 2.2857142857142856
Max-min Ratio: 2.4285714285714284
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-52-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.82
  episode_reward_min: 157.0
  episodes_this_iter: 1
  episodes_total: 429
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.854
    dispatch_time_ms: 15.701
    learner:
      cur_lr: 0.0010742859449237585
      grad_gnorm: 3.6245877742767334
      policy_entropy: 155.2936248779297
      policy_loss: -1.0210976600646973
      var_gnorm: 68.01913452148438
      vf_explained_var: -1.0
      vf_loss: 0.058008529245853424
    num_steps_sampled: 4300000
    num_steps_trained: 4300000
    wait_time_ms: 172.961
  iterations_since_restore: 430
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7864.122798919678
  time_this_iter_s: 18.245060920715332
  time_total_s: 7864.122798919678
  timestamp: 1593892344
  timesteps_since_restore: 4300000
  timesteps_this_iter: 10000
  timesteps_total: 4300000
  training_iteration: 430
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7864 s, 430 iter, 4300000 ts, 209 rew

agent-1: 20.0
agent-2: 16.0
agent-3: 22.0
agent-4: 29.0
agent-5: 27.0
agent-6: 19.0
agent-7: 23.0
agent-8: 19.0
agent-9: 24.0
agent-10: 15.0
Sum Reward: 214.0
Avg Reward: 21.4
Min Reward: 15.0
Gini Coefficient: 0.1130841121495327
20:20 Ratio: 1.8064516129032258
Max-min Ratio: 1.9333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-52-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.92
  episode_reward_min: 157.0
  episodes_this_iter: 1
  episodes_total: 430
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.042
    dispatch_time_ms: 16.852
    learner:
      cur_lr: 0.0010736200492829084
      grad_gnorm: 5.961514949798584
      policy_entropy: 173.877685546875
      policy_loss: 2.920152187347412
      var_gnorm: 68.05856323242188
      vf_explained_var: 0.9901628494262695
      vf_loss: 0.00444026431068778
    num_steps_sampled: 4310000
    num_steps_trained: 4310000
    wait_time_ms: 161.405
  iterations_since_restore: 431
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7882.507203578949
  time_this_iter_s: 18.38440465927124
  time_total_s: 7882.507203578949
  timestamp: 1593892362
  timesteps_since_restore: 4310000
  timesteps_this_iter: 10000
  timesteps_total: 4310000
  training_iteration: 431
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7882 s, 431 iter, 4310000 ts, 209 rew

agent-1: 20.0
agent-2: 32.0
agent-3: 20.0
agent-4: 21.0
agent-5: 12.0
agent-6: 20.0
agent-7: 24.0
agent-8: 29.0
agent-9: 24.0
agent-10: 18.0
Sum Reward: 220.0
Avg Reward: 22.0
Min Reward: 12.0
Gini Coefficient: 0.1318181818181818
20:20 Ratio: 2.033333333333333
Max-min Ratio: 2.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-53-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 209.11
  episode_reward_min: 157.0
  episodes_this_iter: 1
  episodes_total: 431
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.004
    dispatch_time_ms: 19.973
    learner:
      cur_lr: 0.0010729540372267365
      grad_gnorm: 22.830636978149414
      policy_entropy: 175.75711059570312
      policy_loss: -0.30423223972320557
      var_gnorm: 68.0963134765625
      vf_explained_var: -1.0
      vf_loss: 0.017885277047753334
    num_steps_sampled: 4320000
    num_steps_trained: 4320000
    wait_time_ms: 163.303
  iterations_since_restore: 432
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7900.622580766678
  time_this_iter_s: 18.115377187728882
  time_total_s: 7900.622580766678
  timestamp: 1593892380
  timesteps_since_restore: 4320000
  timesteps_this_iter: 10000
  timesteps_total: 4320000
  training_iteration: 432
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7900 s, 432 iter, 4320000 ts, 209 rew

agent-1: 20.0
agent-2: 18.0
agent-3: 18.0
agent-4: 21.0
agent-5: 18.0
agent-6: 24.0
agent-7: 26.0
agent-8: 13.0
agent-9: 18.0
agent-10: 16.0
Sum Reward: 192.0
Avg Reward: 19.2
Min Reward: 13.0
Gini Coefficient: 0.10104166666666667
20:20 Ratio: 1.7241379310344827
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-53-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 209.15
  episode_reward_min: 157.0
  episodes_this_iter: 1
  episodes_total: 432
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.075
    dispatch_time_ms: 35.612
    learner:
      cur_lr: 0.0010722880251705647
      grad_gnorm: 2.9554202556610107
      policy_entropy: 183.9717254638672
      policy_loss: -1.8632104396820068
      var_gnorm: 68.08977508544922
      vf_explained_var: -0.24740135669708252
      vf_loss: 0.0035948259755969048
    num_steps_sampled: 4330000
    num_steps_trained: 4330000
    wait_time_ms: 145.884
  iterations_since_restore: 433
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7919.487755060196
  time_this_iter_s: 18.865174293518066
  time_total_s: 7919.487755060196
  timestamp: 1593892399
  timesteps_since_restore: 4330000
  timesteps_this_iter: 10000
  timesteps_total: 4330000
  training_iteration: 433
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7919 s, 433 iter, 4330000 ts, 209 rew

agent-1: 21.0
agent-2: 21.0
agent-3: 18.0
agent-4: 17.0
agent-5: 21.0
agent-6: 22.0
agent-7: 30.0
agent-8: 23.0
agent-9: 20.0
agent-10: 16.0
Sum Reward: 209.0
Avg Reward: 20.9
Min Reward: 16.0
Gini Coefficient: 0.09138755980861243
20:20 Ratio: 1.606060606060606
Max-min Ratio: 1.875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-53-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 209.18
  episode_reward_min: 157.0
  episodes_this_iter: 1
  episodes_total: 433
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.745
    dispatch_time_ms: 30.596
    learner:
      cur_lr: 0.0010716220131143928
      grad_gnorm: 1.2170065641403198
      policy_entropy: 183.6056365966797
      policy_loss: 0.9405121207237244
      var_gnorm: 68.24264526367188
      vf_explained_var: -0.022124528884887695
      vf_loss: 0.00467590382322669
    num_steps_sampled: 4340000
    num_steps_trained: 4340000
    wait_time_ms: 154.787
  iterations_since_restore: 434
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7938.360749006271
  time_this_iter_s: 18.87299394607544
  time_total_s: 7938.360749006271
  timestamp: 1593892418
  timesteps_since_restore: 4340000
  timesteps_this_iter: 10000
  timesteps_total: 4340000
  training_iteration: 434
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7938 s, 434 iter, 4340000 ts, 209 rew

agent-1: 24.0
agent-2: 19.0
agent-3: 26.0
agent-4: 22.0
agent-5: 16.0
agent-6: 17.0
agent-7: 21.0
agent-8: 20.0
agent-9: 27.0
agent-10: 16.0
Sum Reward: 208.0
Avg Reward: 20.8
Min Reward: 16.0
Gini Coefficient: 0.10288461538461538
20:20 Ratio: 1.65625
Max-min Ratio: 1.6875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-53-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 209.21
  episode_reward_min: 157.0
  episodes_this_iter: 1
  episodes_total: 434
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.127
    dispatch_time_ms: 7.203
    learner:
      cur_lr: 0.0010709560010582209
      grad_gnorm: 6.734618186950684
      policy_entropy: 185.278564453125
      policy_loss: -3.513401985168457
      var_gnorm: 68.32745361328125
      vf_explained_var: -1.0
      vf_loss: 0.13484247028827667
    num_steps_sampled: 4350000
    num_steps_trained: 4350000
    wait_time_ms: 174.918
  iterations_since_restore: 435
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7957.700770378113
  time_this_iter_s: 19.34002137184143
  time_total_s: 7957.700770378113
  timestamp: 1593892437
  timesteps_since_restore: 4350000
  timesteps_this_iter: 10000
  timesteps_total: 4350000
  training_iteration: 435
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7957 s, 435 iter, 4350000 ts, 209 rew

agent-1: 27.0
agent-2: 25.0
agent-3: 21.0
agent-4: 28.0
agent-5: 17.0
agent-6: 26.0
agent-7: 31.0
agent-8: 30.0
agent-9: 24.0
agent-10: 25.0
Sum Reward: 254.0
Avg Reward: 25.4
Min Reward: 17.0
Gini Coefficient: 0.08503937007874016
20:20 Ratio: 1.605263157894737
Max-min Ratio: 1.8235294117647058
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-54-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 209.84
  episode_reward_min: 157.0
  episodes_this_iter: 1
  episodes_total: 435
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.725
    dispatch_time_ms: 7.564
    learner:
      cur_lr: 0.001070289989002049
      grad_gnorm: 5.675472259521484
      policy_entropy: 178.67837524414062
      policy_loss: 3.023364782333374
      var_gnorm: 68.39224243164062
      vf_explained_var: -0.05135047435760498
      vf_loss: 0.026041602715849876
    num_steps_sampled: 4360000
    num_steps_trained: 4360000
    wait_time_ms: 166.673
  iterations_since_restore: 436
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7975.442836999893
  time_this_iter_s: 17.742066621780396
  time_total_s: 7975.442836999893
  timestamp: 1593892455
  timesteps_since_restore: 4360000
  timesteps_this_iter: 10000
  timesteps_total: 4360000
  training_iteration: 436
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7975 s, 436 iter, 4360000 ts, 210 rew

agent-1: 24.0
agent-2: -24.0
agent-3: 31.0
agent-4: 22.0
agent-5: 18.0
agent-6: 27.0
agent-7: -30.0
agent-8: 30.0
agent-9: 18.0
agent-10: 24.0
Sum Reward: 140.0
Avg Reward: 14.0
Min Reward: -30.0
Gini Coefficient: 0.7085714285714285
20:20 Ratio: -1.1296296296296295
Max-min Ratio: -1.0333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-54-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 209.01
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 436
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.38
    dispatch_time_ms: 7.493
    learner:
      cur_lr: 0.001069623976945877
      grad_gnorm: 0.8820464015007019
      policy_entropy: 174.3384552001953
      policy_loss: 0.16707801818847656
      var_gnorm: 68.43551635742188
      vf_explained_var: 0.881846010684967
      vf_loss: 0.003134981030598283
    num_steps_sampled: 4370000
    num_steps_trained: 4370000
    wait_time_ms: 172.026
  iterations_since_restore: 437
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 7993.4192543029785
  time_this_iter_s: 17.976417303085327
  time_total_s: 7993.4192543029785
  timestamp: 1593892473
  timesteps_since_restore: 4370000
  timesteps_this_iter: 10000
  timesteps_total: 4370000
  training_iteration: 437
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 7993 s, 437 iter, 4370000 ts, 209 rew

agent-1: 16.0
agent-2: 20.0
agent-3: 26.0
agent-4: 25.0
agent-5: 26.0
agent-6: 18.0
agent-7: 19.0
agent-8: 17.0
agent-9: 22.0
agent-10: 22.0
Sum Reward: 211.0
Avg Reward: 21.1
Min Reward: 16.0
Gini Coefficient: 0.09431279620853081
20:20 Ratio: 1.5757575757575757
Max-min Ratio: 1.625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-54-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.92
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 437
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.413
    dispatch_time_ms: 6.086
    learner:
      cur_lr: 0.0010689579648897052
      grad_gnorm: 0.31061622500419617
      policy_entropy: 179.76693725585938
      policy_loss: 0.4035482704639435
      var_gnorm: 68.50495147705078
      vf_explained_var: 0.9948379397392273
      vf_loss: 0.00038948646397329867
    num_steps_sampled: 4380000
    num_steps_trained: 4380000
    wait_time_ms: 177.718
  iterations_since_restore: 438
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8011.047117471695
  time_this_iter_s: 17.62786316871643
  time_total_s: 8011.047117471695
  timestamp: 1593892491
  timesteps_since_restore: 4380000
  timesteps_this_iter: 10000
  timesteps_total: 4380000
  training_iteration: 438
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8011 s, 438 iter, 4380000 ts, 209 rew

agent-1: 24.0
agent-2: 16.0
agent-3: 25.0
agent-4: 16.0
agent-5: 18.0
agent-6: 23.0
agent-7: 19.0
agent-8: 19.0
agent-9: 14.0
agent-10: 20.0
Sum Reward: 194.0
Avg Reward: 19.4
Min Reward: 14.0
Gini Coefficient: 0.10103092783505155
20:20 Ratio: 1.6333333333333333
Max-min Ratio: 1.7857142857142858
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-55-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.86
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 438
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.349
    dispatch_time_ms: 8.414
    learner:
      cur_lr: 0.0010682919528335333
      grad_gnorm: 0.7711905241012573
      policy_entropy: 193.03079223632812
      policy_loss: 0.4206486642360687
      var_gnorm: 68.55870056152344
      vf_explained_var: 0.8037271499633789
      vf_loss: 0.002305152826011181
    num_steps_sampled: 4390000
    num_steps_trained: 4390000
    wait_time_ms: 172.992
  iterations_since_restore: 439
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8028.989742040634
  time_this_iter_s: 17.94262456893921
  time_total_s: 8028.989742040634
  timestamp: 1593892509
  timesteps_since_restore: 4390000
  timesteps_this_iter: 10000
  timesteps_total: 4390000
  training_iteration: 439
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8028 s, 439 iter, 4390000 ts, 209 rew

agent-1: 22.0
agent-2: 27.0
agent-3: 23.0
agent-4: 25.0
agent-5: 16.0
agent-6: 25.0
agent-7: 19.0
agent-8: 23.0
agent-9: 22.0
agent-10: 19.0
Sum Reward: 221.0
Avg Reward: 22.1
Min Reward: 16.0
Gini Coefficient: 0.07918552036199095
20:20 Ratio: 1.4857142857142858
Max-min Ratio: 1.6875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-55-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.75
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 439
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.693
    dispatch_time_ms: 6.312
    learner:
      cur_lr: 0.0010676260571926832
      grad_gnorm: 1.4327104091644287
      policy_entropy: 172.692138671875
      policy_loss: 0.481618732213974
      var_gnorm: 68.58300018310547
      vf_explained_var: 0.6081535816192627
      vf_loss: 0.004026086535304785
    num_steps_sampled: 4400000
    num_steps_trained: 4400000
    wait_time_ms: 171.355
  iterations_since_restore: 440
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8046.81013917923
  time_this_iter_s: 17.82039713859558
  time_total_s: 8046.81013917923
  timestamp: 1593892527
  timesteps_since_restore: 4400000
  timesteps_this_iter: 10000
  timesteps_total: 4400000
  training_iteration: 440
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8046 s, 440 iter, 4400000 ts, 209 rew

agent-1: 22.0
agent-2: 19.0
agent-3: 18.0
agent-4: 18.0
agent-5: 21.0
agent-6: 20.0
agent-7: 22.0
agent-8: 16.0
agent-9: 14.0
agent-10: 21.0
Sum Reward: 191.0
Avg Reward: 19.1
Min Reward: 14.0
Gini Coefficient: 0.07277486910994764
20:20 Ratio: 1.4666666666666666
Max-min Ratio: 1.5714285714285714
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-55-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.47
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 440
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.831
    dispatch_time_ms: 7.82
    learner:
      cur_lr: 0.0010669600451365113
      grad_gnorm: 1.2890164852142334
      policy_entropy: 175.44744873046875
      policy_loss: 0.7495003342628479
      var_gnorm: 68.63082122802734
      vf_explained_var: -1.0
      vf_loss: 0.01007040124386549
    num_steps_sampled: 4410000
    num_steps_trained: 4410000
    wait_time_ms: 177.289
  iterations_since_restore: 441
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8064.543498754501
  time_this_iter_s: 17.733359575271606
  time_total_s: 8064.543498754501
  timestamp: 1593892544
  timesteps_since_restore: 4410000
  timesteps_this_iter: 10000
  timesteps_total: 4410000
  training_iteration: 441
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8064 s, 441 iter, 4410000 ts, 208 rew

agent-1: 26.0
agent-2: 24.0
agent-3: 13.0
agent-4: 25.0
agent-5: 23.0
agent-6: 26.0
agent-7: 19.0
agent-8: 30.0
agent-9: 10.0
agent-10: 30.0
Sum Reward: 226.0
Avg Reward: 22.6
Min Reward: 10.0
Gini Coefficient: 0.15221238938053097
20:20 Ratio: 2.608695652173913
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-56-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.6
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 441
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.199
    dispatch_time_ms: 8.644
    learner:
      cur_lr: 0.0010662940330803394
      grad_gnorm: 0.6968560814857483
      policy_entropy: 184.06533813476562
      policy_loss: -0.2955469489097595
      var_gnorm: 68.70149993896484
      vf_explained_var: 0.9265226125717163
      vf_loss: 0.0006924931658431888
    num_steps_sampled: 4420000
    num_steps_trained: 4420000
    wait_time_ms: 170.248
  iterations_since_restore: 442
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8082.563488483429
  time_this_iter_s: 18.019989728927612
  time_total_s: 8082.563488483429
  timestamp: 1593892563
  timesteps_since_restore: 4420000
  timesteps_this_iter: 10000
  timesteps_total: 4420000
  training_iteration: 442
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8082 s, 442 iter, 4420000 ts, 209 rew

agent-1: 21.0
agent-2: 26.0
agent-3: 23.0
agent-4: 20.0
agent-5: 16.0
agent-6: 24.0
agent-7: 22.0
agent-8: 27.0
agent-9: 8.0
agent-10: 19.0
Sum Reward: 206.0
Avg Reward: 20.6
Min Reward: 8.0
Gini Coefficient: 0.13398058252427184
20:20 Ratio: 2.2083333333333335
Max-min Ratio: 3.375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-56-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.69
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 442
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.991
    dispatch_time_ms: 7.658
    learner:
      cur_lr: 0.0010656280210241675
      grad_gnorm: 4.999502658843994
      policy_entropy: 175.6713409423828
      policy_loss: -2.7878036499023438
      var_gnorm: 68.74541473388672
      vf_explained_var: 0.2836766242980957
      vf_loss: 0.10083713382482529
    num_steps_sampled: 4430000
    num_steps_trained: 4430000
    wait_time_ms: 164.393
  iterations_since_restore: 443
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8100.2549068927765
  time_this_iter_s: 17.691418409347534
  time_total_s: 8100.2549068927765
  timestamp: 1593892580
  timesteps_since_restore: 4430000
  timesteps_this_iter: 10000
  timesteps_total: 4430000
  training_iteration: 443
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8100 s, 443 iter, 4430000 ts, 209 rew

agent-1: 28.0
agent-2: 23.0
agent-3: 16.0
agent-4: 20.0
agent-5: 19.0
agent-6: 24.0
agent-7: 14.0
agent-8: 21.0
agent-9: 20.0
agent-10: 11.0
Sum Reward: 196.0
Avg Reward: 19.6
Min Reward: 11.0
Gini Coefficient: 0.1346938775510204
20:20 Ratio: 2.08
Max-min Ratio: 2.5454545454545454
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-56-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.74
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 443
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.642
    dispatch_time_ms: 8.634
    learner:
      cur_lr: 0.0010649620089679956
      grad_gnorm: 1.0233114957809448
      policy_entropy: 188.05140686035156
      policy_loss: -0.8330311179161072
      var_gnorm: 68.84345245361328
      vf_explained_var: 0.35382580757141113
      vf_loss: 0.0007957861525937915
    num_steps_sampled: 4440000
    num_steps_trained: 4440000
    wait_time_ms: 166.838
  iterations_since_restore: 444
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8118.251717090607
  time_this_iter_s: 17.9968101978302
  time_total_s: 8118.251717090607
  timestamp: 1593892598
  timesteps_since_restore: 4440000
  timesteps_this_iter: 10000
  timesteps_total: 4440000
  training_iteration: 444
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8118 s, 444 iter, 4440000 ts, 209 rew

agent-1: 17.0
agent-2: 11.0
agent-3: 18.0
agent-4: 26.0
agent-5: 32.0
agent-6: 19.0
agent-7: 26.0
agent-8: 26.0
agent-9: 18.0
agent-10: 21.0
Sum Reward: 214.0
Avg Reward: 21.4
Min Reward: 11.0
Gini Coefficient: 0.1485981308411215
20:20 Ratio: 2.0714285714285716
Max-min Ratio: 2.909090909090909
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-56-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.84
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 444
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.828
    dispatch_time_ms: 8.714
    learner:
      cur_lr: 0.0010642959969118237
      grad_gnorm: 0.46233218908309937
      policy_entropy: 185.7880401611328
      policy_loss: -0.6192554831504822
      var_gnorm: 68.80208587646484
      vf_explained_var: 0.9660503268241882
      vf_loss: 0.00012876598339062184
    num_steps_sampled: 4450000
    num_steps_trained: 4450000
    wait_time_ms: 173.682
  iterations_since_restore: 445
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8136.000828504562
  time_this_iter_s: 17.74911141395569
  time_total_s: 8136.000828504562
  timestamp: 1593892616
  timesteps_since_restore: 4450000
  timesteps_this_iter: 10000
  timesteps_total: 4450000
  training_iteration: 445
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8136 s, 445 iter, 4450000 ts, 209 rew

agent-1: 26.0
agent-2: 26.0
agent-3: 13.0
agent-4: 11.0
agent-5: 24.0
agent-6: 27.0
agent-7: 17.0
agent-8: 26.0
agent-9: 23.0
agent-10: 32.0
Sum Reward: 225.0
Avg Reward: 22.5
Min Reward: 11.0
Gini Coefficient: 0.15244444444444444
20:20 Ratio: 2.4583333333333335
Max-min Ratio: 2.909090909090909
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-57-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 209.07
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 445
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.079
    dispatch_time_ms: 6.917
    learner:
      cur_lr: 0.0010636299848556519
      grad_gnorm: 0.3271997272968292
      policy_entropy: 185.24884033203125
      policy_loss: 0.3118731677532196
      var_gnorm: 68.90753936767578
      vf_explained_var: 0.9844498634338379
      vf_loss: 6.919450243003666e-05
    num_steps_sampled: 4460000
    num_steps_trained: 4460000
    wait_time_ms: 169.156
  iterations_since_restore: 446
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8153.967917442322
  time_this_iter_s: 17.9670889377594
  time_total_s: 8153.967917442322
  timestamp: 1593892634
  timesteps_since_restore: 4460000
  timesteps_this_iter: 10000
  timesteps_total: 4460000
  training_iteration: 446
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8153 s, 446 iter, 4460000 ts, 209 rew

agent-1: 28.0
agent-2: 22.0
agent-3: 28.0
agent-4: 21.0
agent-5: 19.0
agent-6: 21.0
agent-7: 27.0
agent-8: 29.0
agent-9: 14.0
agent-10: 18.0
Sum Reward: 227.0
Avg Reward: 22.7
Min Reward: 14.0
Gini Coefficient: 0.11850220264317181
20:20 Ratio: 1.78125
Max-min Ratio: 2.0714285714285716
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-57-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 209.3
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 446
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.636
    dispatch_time_ms: 53.353
    learner:
      cur_lr: 0.00106296397279948
      grad_gnorm: 19.572622299194336
      policy_entropy: 189.81954956054688
      policy_loss: -0.2138364613056183
      var_gnorm: 68.97227478027344
      vf_explained_var: 0.960917055606842
      vf_loss: 0.21796740591526031
    num_steps_sampled: 4470000
    num_steps_trained: 4470000
    wait_time_ms: 91.834
  iterations_since_restore: 447
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8177.526747226715
  time_this_iter_s: 23.55882978439331
  time_total_s: 8177.526747226715
  timestamp: 1593892658
  timesteps_since_restore: 4470000
  timesteps_this_iter: 10000
  timesteps_total: 4470000
  training_iteration: 447
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8177 s, 447 iter, 4470000 ts, 209 rew

agent-1: 18.0
agent-2: 21.0
agent-3: 16.0
agent-4: 20.0
agent-5: 22.0
agent-6: 23.0
agent-7: 17.0
agent-8: 20.0
agent-9: 19.0
agent-10: 17.0
Sum Reward: 193.0
Avg Reward: 19.3
Min Reward: 16.0
Gini Coefficient: 0.06476683937823834
20:20 Ratio: 1.3636363636363635
Max-min Ratio: 1.4375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-57-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 209.31
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 447
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.658
    dispatch_time_ms: 16.967
    learner:
      cur_lr: 0.001062297960743308
      grad_gnorm: 2.6294636726379395
      policy_entropy: 149.70651245117188
      policy_loss: 1.0251045227050781
      var_gnorm: 68.98275756835938
      vf_explained_var: -0.5305072069168091
      vf_loss: 0.03903081640601158
    num_steps_sampled: 4480000
    num_steps_trained: 4480000
    wait_time_ms: 161.861
  iterations_since_restore: 448
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8194.33245921135
  time_this_iter_s: 16.8057119846344
  time_total_s: 8194.33245921135
  timestamp: 1593892675
  timesteps_since_restore: 4480000
  timesteps_this_iter: 10000
  timesteps_total: 4480000
  training_iteration: 448
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8194 s, 448 iter, 4480000 ts, 209 rew

agent-1: 21.0
agent-2: 20.0
agent-3: 15.0
agent-4: 20.0
agent-5: 19.0
agent-6: 25.0
agent-7: 20.0
agent-8: 19.0
agent-9: 21.0
agent-10: 19.0
Sum Reward: 199.0
Avg Reward: 19.9
Min Reward: 15.0
Gini Coefficient: 0.05879396984924623
20:20 Ratio: 1.3529411764705883
Max-min Ratio: 1.6666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-58-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 209.04
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 448
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.032
    dispatch_time_ms: 30.666
    learner:
      cur_lr: 0.0010616319486871362
      grad_gnorm: 40.000003814697266
      policy_entropy: 141.04486083984375
      policy_loss: 0.1853419840335846
      var_gnorm: 69.01004028320312
      vf_explained_var: 0.8373227715492249
      vf_loss: 8.349401473999023
    num_steps_sampled: 4490000
    num_steps_trained: 4490000
    wait_time_ms: 160.386
  iterations_since_restore: 449
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8213.045126914978
  time_this_iter_s: 18.71266770362854
  time_total_s: 8213.045126914978
  timestamp: 1593892693
  timesteps_since_restore: 4490000
  timesteps_this_iter: 10000
  timesteps_total: 4490000
  training_iteration: 449
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8213 s, 449 iter, 4490000 ts, 209 rew

agent-1: 10.0
agent-2: 18.0
agent-3: 20.0
agent-4: 31.0
agent-5: 25.0
agent-6: 20.0
agent-7: 16.0
agent-8: 9.0
agent-9: 20.0
agent-10: 13.0
Sum Reward: 182.0
Avg Reward: 18.2
Min Reward: 9.0
Gini Coefficient: 0.1934065934065934
20:20 Ratio: 2.9473684210526314
Max-min Ratio: 3.4444444444444446
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-58-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.75
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 449
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 4.043
    dispatch_time_ms: 26.669
    learner:
      cur_lr: 0.001060966053046286
      grad_gnorm: 1.1255289316177368
      policy_entropy: 178.67807006835938
      policy_loss: 0.312198281288147
      var_gnorm: 69.01847076416016
      vf_explained_var: 0.9916872382164001
      vf_loss: 0.0003229668363928795
    num_steps_sampled: 4500000
    num_steps_trained: 4500000
    wait_time_ms: 160.292
  iterations_since_restore: 450
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8231.673514127731
  time_this_iter_s: 18.628387212753296
  time_total_s: 8231.673514127731
  timestamp: 1593892712
  timesteps_since_restore: 4500000
  timesteps_this_iter: 10000
  timesteps_total: 4500000
  training_iteration: 450
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8231 s, 450 iter, 4500000 ts, 209 rew

agent-1: 22.0
agent-2: 13.0
agent-3: 19.0
agent-4: 17.0
agent-5: 14.0
agent-6: 21.0
agent-7: 18.0
agent-8: 23.0
agent-9: 19.0
agent-10: 23.0
Sum Reward: 189.0
Avg Reward: 18.9
Min Reward: 13.0
Gini Coefficient: 0.09894179894179894
20:20 Ratio: 1.7037037037037037
Max-min Ratio: 1.7692307692307692
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-58-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.43
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 450
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 4.159
    dispatch_time_ms: 15.461
    learner:
      cur_lr: 0.0010603000409901142
      grad_gnorm: 0.39325687289237976
      policy_entropy: 185.21803283691406
      policy_loss: -0.2866567075252533
      var_gnorm: 69.02352905273438
      vf_explained_var: 0.8120948076248169
      vf_loss: 0.0009975067805498838
    num_steps_sampled: 4510000
    num_steps_trained: 4510000
    wait_time_ms: 172.841
  iterations_since_restore: 451
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8250.717931747437
  time_this_iter_s: 19.0444176197052
  time_total_s: 8250.717931747437
  timestamp: 1593892731
  timesteps_since_restore: 4510000
  timesteps_this_iter: 10000
  timesteps_total: 4510000
  training_iteration: 451
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8250 s, 451 iter, 4510000 ts, 208 rew

agent-1: 20.0
agent-2: 19.0
agent-3: 20.0
agent-4: 19.0
agent-5: 21.0
agent-6: 18.0
agent-7: 20.0
agent-8: 17.0
agent-9: 31.0
agent-10: 25.0
Sum Reward: 210.0
Avg Reward: 21.0
Min Reward: 17.0
Gini Coefficient: 0.08952380952380952
20:20 Ratio: 1.6
Max-min Ratio: 1.8235294117647058
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-59-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.5
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 451
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.706
    dispatch_time_ms: 9.013
    learner:
      cur_lr: 0.0010596340289339423
      grad_gnorm: 0.5817562937736511
      policy_entropy: 189.0433349609375
      policy_loss: -0.1248999759554863
      var_gnorm: 69.00434875488281
      vf_explained_var: -1.0
      vf_loss: 0.00029355494189076126
    num_steps_sampled: 4520000
    num_steps_trained: 4520000
    wait_time_ms: 171.041
  iterations_since_restore: 452
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8269.597162246704
  time_this_iter_s: 18.879230499267578
  time_total_s: 8269.597162246704
  timestamp: 1593892750
  timesteps_since_restore: 4520000
  timesteps_this_iter: 10000
  timesteps_total: 4520000
  training_iteration: 452
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8269 s, 452 iter, 4520000 ts, 208 rew

agent-1: 24.0
agent-2: 16.0
agent-3: 20.0
agent-4: 21.0
agent-5: 26.0
agent-6: 11.0
agent-7: 19.0
agent-8: 19.0
agent-9: 25.0
agent-10: 19.0
Sum Reward: 200.0
Avg Reward: 20.0
Min Reward: 11.0
Gini Coefficient: 0.115
20:20 Ratio: 1.8888888888888888
Max-min Ratio: 2.3636363636363638
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-59-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.7
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 452
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.623
    dispatch_time_ms: 6.627
    learner:
      cur_lr: 0.0010589680168777704
      grad_gnorm: 1.6350867748260498
      policy_entropy: 189.0124969482422
      policy_loss: 1.0185641050338745
      var_gnorm: 69.03478240966797
      vf_explained_var: 0.9802035093307495
      vf_loss: 0.002721597207710147
    num_steps_sampled: 4530000
    num_steps_trained: 4530000
    wait_time_ms: 172.328
  iterations_since_restore: 453
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8287.448158979416
  time_this_iter_s: 17.850996732711792
  time_total_s: 8287.448158979416
  timestamp: 1593892768
  timesteps_since_restore: 4530000
  timesteps_this_iter: 10000
  timesteps_total: 4530000
  training_iteration: 453
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8287 s, 453 iter, 4530000 ts, 209 rew

agent-1: 25.0
agent-2: 22.0
agent-3: 23.0
agent-4: 18.0
agent-5: 18.0
agent-6: 28.0
agent-7: 15.0
agent-8: 23.0
agent-9: 18.0
agent-10: 18.0
Sum Reward: 208.0
Avg Reward: 20.8
Min Reward: 15.0
Gini Coefficient: 0.10096153846153846
20:20 Ratio: 1.606060606060606
Max-min Ratio: 1.8666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_15-59-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.79
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 453
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.696
    dispatch_time_ms: 6.12
    learner:
      cur_lr: 0.0010583020048215985
      grad_gnorm: 1.195785641670227
      policy_entropy: 170.64605712890625
      policy_loss: 0.4538591206073761
      var_gnorm: 69.13947296142578
      vf_explained_var: 0.015176773071289062
      vf_loss: 0.0047516291961073875
    num_steps_sampled: 4540000
    num_steps_trained: 4540000
    wait_time_ms: 169.169
  iterations_since_restore: 454
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8305.44654750824
  time_this_iter_s: 17.998388528823853
  time_total_s: 8305.44654750824
  timestamp: 1593892786
  timesteps_since_restore: 4540000
  timesteps_this_iter: 10000
  timesteps_total: 4540000
  training_iteration: 454
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8305 s, 454 iter, 4540000 ts, 209 rew

agent-1: 19.0
agent-2: 14.0
agent-3: 19.0
agent-4: 19.0
agent-5: 25.0
agent-6: 18.0
agent-7: 20.0
agent-8: 24.0
agent-9: 23.0
agent-10: 12.0
Sum Reward: 193.0
Avg Reward: 19.3
Min Reward: 12.0
Gini Coefficient: 0.11139896373056994
20:20 Ratio: 1.8846153846153846
Max-min Ratio: 2.0833333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_16-00-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.65
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 454
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.266
    dispatch_time_ms: 5.695
    learner:
      cur_lr: 0.0010576359927654266
      grad_gnorm: 0.25359466671943665
      policy_entropy: 190.88687133789062
      policy_loss: 0.12314998358488083
      var_gnorm: 69.18163299560547
      vf_explained_var: 0.9909306764602661
      vf_loss: 4.6606059186160564e-05
    num_steps_sampled: 4550000
    num_steps_trained: 4550000
    wait_time_ms: 167.45
  iterations_since_restore: 455
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8323.35916352272
  time_this_iter_s: 17.91261601448059
  time_total_s: 8323.35916352272
  timestamp: 1593892804
  timesteps_since_restore: 4550000
  timesteps_this_iter: 10000
  timesteps_total: 4550000
  training_iteration: 455
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8323 s, 455 iter, 4550000 ts, 209 rew

agent-1: 22.0
agent-2: 20.0
agent-3: 18.0
agent-4: 19.0
agent-5: 20.0
agent-6: 18.0
agent-7: 12.0
agent-8: 25.0
agent-9: 25.0
agent-10: 21.0
Sum Reward: 200.0
Avg Reward: 20.0
Min Reward: 12.0
Gini Coefficient: 0.096
20:20 Ratio: 1.6666666666666667
Max-min Ratio: 2.0833333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_16-00-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.57
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 455
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.344
    dispatch_time_ms: 8.684
    learner:
      cur_lr: 0.0010569699807092547
      grad_gnorm: 0.6318032145500183
      policy_entropy: 179.43373107910156
      policy_loss: 0.35249051451683044
      var_gnorm: 69.3306655883789
      vf_explained_var: 0.6741341352462769
      vf_loss: 0.000300112267723307
    num_steps_sampled: 4560000
    num_steps_trained: 4560000
    wait_time_ms: 171.378
  iterations_since_restore: 456
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8341.483883619308
  time_this_iter_s: 18.124720096588135
  time_total_s: 8341.483883619308
  timestamp: 1593892822
  timesteps_since_restore: 4560000
  timesteps_this_iter: 10000
  timesteps_total: 4560000
  training_iteration: 456
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8341 s, 456 iter, 4560000 ts, 209 rew

agent-1: 24.0
agent-2: 16.0
agent-3: 28.0
agent-4: 36.0
agent-5: 18.0
agent-6: 21.0
agent-7: 12.0
agent-8: 17.0
agent-9: 22.0
agent-10: 13.0
Sum Reward: 207.0
Avg Reward: 20.7
Min Reward: 12.0
Gini Coefficient: 0.18309178743961352
20:20 Ratio: 2.56
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_16-00-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.45
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 456
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.398
    dispatch_time_ms: 8.582
    learner:
      cur_lr: 0.0010563039686530828
      grad_gnorm: 2.476483106613159
      policy_entropy: 181.75473022460938
      policy_loss: -1.475578784942627
      var_gnorm: 69.3451156616211
      vf_explained_var: -0.09900224208831787
      vf_loss: 0.004120079800486565
    num_steps_sampled: 4570000
    num_steps_trained: 4570000
    wait_time_ms: 165.639
  iterations_since_restore: 457
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8359.327052354813
  time_this_iter_s: 17.84316873550415
  time_total_s: 8359.327052354813
  timestamp: 1593892840
  timesteps_since_restore: 4570000
  timesteps_this_iter: 10000
  timesteps_total: 4570000
  training_iteration: 457
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8359 s, 457 iter, 4570000 ts, 208 rew

agent-1: 24.0
agent-2: 20.0
agent-3: 16.0
agent-4: 18.0
agent-5: 20.0
agent-6: 24.0
agent-7: 15.0
agent-8: 19.0
agent-9: 24.0
agent-10: 16.0
Sum Reward: 196.0
Avg Reward: 19.6
Min Reward: 15.0
Gini Coefficient: 0.09387755102040816
20:20 Ratio: 1.5483870967741935
Max-min Ratio: 1.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_16-00-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.49
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 457
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 4.63
    dispatch_time_ms: 7.72
    learner:
      cur_lr: 0.001055637956596911
      grad_gnorm: 0.3873918354511261
      policy_entropy: 182.90232849121094
      policy_loss: -0.28872451186180115
      var_gnorm: 69.4332275390625
      vf_explained_var: 0.9947350025177002
      vf_loss: 0.00019754313689190894
    num_steps_sampled: 4580000
    num_steps_trained: 4580000
    wait_time_ms: 167.551
  iterations_since_restore: 458
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8377.062976121902
  time_this_iter_s: 17.735923767089844
  time_total_s: 8377.062976121902
  timestamp: 1593892858
  timesteps_since_restore: 4580000
  timesteps_this_iter: 10000
  timesteps_total: 4580000
  training_iteration: 458
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8377 s, 458 iter, 4580000 ts, 208 rew

agent-1: 29.0
agent-2: 23.0
agent-3: 21.0
agent-4: 21.0
agent-5: 20.0
agent-6: 17.0
agent-7: 22.0
agent-8: 22.0
agent-9: 21.0
agent-10: 18.0
Sum Reward: 214.0
Avg Reward: 21.4
Min Reward: 17.0
Gini Coefficient: 0.07289719626168224
20:20 Ratio: 1.4857142857142858
Max-min Ratio: 1.7058823529411764
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_16-01-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.58
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 458
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.861
    dispatch_time_ms: 7.901
    learner:
      cur_lr: 0.001054971944540739
      grad_gnorm: 3.076497793197632
      policy_entropy: 189.14498901367188
      policy_loss: -1.5509309768676758
      var_gnorm: 69.43435668945312
      vf_explained_var: -0.06013226509094238
      vf_loss: 0.012088067829608917
    num_steps_sampled: 4590000
    num_steps_trained: 4590000
    wait_time_ms: 171.141
  iterations_since_restore: 459
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8395.01289486885
  time_this_iter_s: 17.949918746948242
  time_total_s: 8395.01289486885
  timestamp: 1593892876
  timesteps_since_restore: 4590000
  timesteps_this_iter: 10000
  timesteps_total: 4590000
  training_iteration: 459
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8395 s, 459 iter, 4590000 ts, 209 rew

agent-1: 23.0
agent-2: 22.0
agent-3: 17.0
agent-4: 15.0
agent-5: 19.0
agent-6: 20.0
agent-7: 21.0
agent-8: 25.0
agent-9: 26.0
agent-10: 17.0
Sum Reward: 205.0
Avg Reward: 20.5
Min Reward: 15.0
Gini Coefficient: 0.0951219512195122
20:20 Ratio: 1.59375
Max-min Ratio: 1.7333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_16-01-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.13
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 459
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 4.122
    dispatch_time_ms: 6.976
    learner:
      cur_lr: 0.001054306048899889
      grad_gnorm: 0.7258597612380981
      policy_entropy: 175.64883422851562
      policy_loss: 0.2442040741443634
      var_gnorm: 69.53424835205078
      vf_explained_var: 0.7633616924285889
      vf_loss: 0.0009454090613871813
    num_steps_sampled: 4600000
    num_steps_trained: 4600000
    wait_time_ms: 169.922
  iterations_since_restore: 460
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8412.947139501572
  time_this_iter_s: 17.934244632720947
  time_total_s: 8412.947139501572
  timestamp: 1593892894
  timesteps_since_restore: 4600000
  timesteps_this_iter: 10000
  timesteps_total: 4600000
  training_iteration: 460
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8412 s, 460 iter, 4600000 ts, 208 rew

agent-1: 22.0
agent-2: 19.0
agent-3: 23.0
agent-4: 17.0
agent-5: 19.0
agent-6: 26.0
agent-7: 17.0
agent-8: 27.0
agent-9: 17.0
agent-10: 22.0
Sum Reward: 209.0
Avg Reward: 20.9
Min Reward: 17.0
Gini Coefficient: 0.09330143540669857
20:20 Ratio: 1.5588235294117647
Max-min Ratio: 1.588235294117647
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_16-01-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.0
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 460
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.933
    dispatch_time_ms: 6.383
    learner:
      cur_lr: 0.001053640036843717
      grad_gnorm: 3.4950051307678223
      policy_entropy: 183.25003051757812
      policy_loss: -2.2108278274536133
      var_gnorm: 69.51803588867188
      vf_explained_var: 0.8944039940834045
      vf_loss: 0.00987662561237812
    num_steps_sampled: 4610000
    num_steps_trained: 4610000
    wait_time_ms: 169.757
  iterations_since_restore: 461
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8430.906534194946
  time_this_iter_s: 17.959394693374634
  time_total_s: 8430.906534194946
  timestamp: 1593892912
  timesteps_since_restore: 4610000
  timesteps_this_iter: 10000
  timesteps_total: 4610000
  training_iteration: 461
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8430 s, 461 iter, 4610000 ts, 208 rew

agent-1: 21.0
agent-2: 22.0
agent-3: 15.0
agent-4: 26.0
agent-5: 20.0
agent-6: 14.0
agent-7: 22.0
agent-8: 20.0
agent-9: 19.0
agent-10: 23.0
Sum Reward: 202.0
Avg Reward: 20.2
Min Reward: 14.0
Gini Coefficient: 0.09207920792079208
20:20 Ratio: 1.6896551724137931
Max-min Ratio: 1.8571428571428572
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_16-02-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 207.98
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 461
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.89
    dispatch_time_ms: 7.787
    learner:
      cur_lr: 0.0010529740247875452
      grad_gnorm: 0.9939398169517517
      policy_entropy: 188.83502197265625
      policy_loss: 0.5410372018814087
      var_gnorm: 69.6236572265625
      vf_explained_var: 0.08512657880783081
      vf_loss: 0.004250388592481613
    num_steps_sampled: 4620000
    num_steps_trained: 4620000
    wait_time_ms: 169.615
  iterations_since_restore: 462
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8448.72844862938
  time_this_iter_s: 17.821914434432983
  time_total_s: 8448.72844862938
  timestamp: 1593892930
  timesteps_since_restore: 4620000
  timesteps_this_iter: 10000
  timesteps_total: 4620000
  training_iteration: 462
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8448 s, 462 iter, 4620000 ts, 208 rew

agent-1: 20.0
agent-2: 16.0
agent-3: 21.0
agent-4: 18.0
agent-5: 30.0
agent-6: 22.0
agent-7: 18.0
agent-8: 20.0
agent-9: 22.0
agent-10: 18.0
Sum Reward: 205.0
Avg Reward: 20.5
Min Reward: 16.0
Gini Coefficient: 0.08926829268292683
20:20 Ratio: 1.5294117647058822
Max-min Ratio: 1.875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_16-02-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 207.88
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 462
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.879
    dispatch_time_ms: 8.893
    learner:
      cur_lr: 0.0010523080127313733
      grad_gnorm: 0.18289801478385925
      policy_entropy: 192.57676696777344
      policy_loss: 0.0777008906006813
      var_gnorm: 69.60880279541016
      vf_explained_var: 0.9947040677070618
      vf_loss: 3.6112338420934975e-05
    num_steps_sampled: 4630000
    num_steps_trained: 4630000
    wait_time_ms: 170.918
  iterations_since_restore: 463
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8466.811594247818
  time_this_iter_s: 18.08314561843872
  time_total_s: 8466.811594247818
  timestamp: 1593892948
  timesteps_since_restore: 4630000
  timesteps_this_iter: 10000
  timesteps_total: 4630000
  training_iteration: 463
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8466 s, 463 iter, 4630000 ts, 208 rew

agent-1: 24.0
agent-2: 20.0
agent-3: 24.0
agent-4: 24.0
agent-5: 16.0
agent-6: 20.0
agent-7: 19.0
agent-8: 20.0
agent-9: 18.0
agent-10: 24.0
Sum Reward: 209.0
Avg Reward: 20.9
Min Reward: 16.0
Gini Coefficient: 0.0722488038277512
20:20 Ratio: 1.411764705882353
Max-min Ratio: 1.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_16-02-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 207.92
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 463
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.588
    dispatch_time_ms: 10.073
    learner:
      cur_lr: 0.0010516420006752014
      grad_gnorm: 0.8329440355300903
      policy_entropy: 180.6328125
      policy_loss: 0.6035335063934326
      var_gnorm: 69.7156982421875
      vf_explained_var: 0.9720169305801392
      vf_loss: 0.00044460740173235536
    num_steps_sampled: 4640000
    num_steps_trained: 4640000
    wait_time_ms: 168.285
  iterations_since_restore: 464
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8484.524398088455
  time_this_iter_s: 17.712803840637207
  time_total_s: 8484.524398088455
  timestamp: 1593892965
  timesteps_since_restore: 4640000
  timesteps_this_iter: 10000
  timesteps_total: 4640000
  training_iteration: 464
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8484 s, 464 iter, 4640000 ts, 208 rew

agent-1: 19.0
agent-2: 24.0
agent-3: 21.0
agent-4: 22.0
agent-5: 18.0
agent-6: 13.0
agent-7: 22.0
agent-8: 20.0
agent-9: 23.0
agent-10: 20.0
Sum Reward: 202.0
Avg Reward: 20.2
Min Reward: 13.0
Gini Coefficient: 0.07722772277227723
20:20 Ratio: 1.5161290322580645
Max-min Ratio: 1.8461538461538463
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_16-03-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 207.89
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 464
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.851
    dispatch_time_ms: 5.754
    learner:
      cur_lr: 0.0010509759886190295
      grad_gnorm: 1.8502893447875977
      policy_entropy: 187.1664276123047
      policy_loss: -0.7610241174697876
      var_gnorm: 69.71851348876953
      vf_explained_var: 0.010183155536651611
      vf_loss: 0.0023846817202866077
    num_steps_sampled: 4650000
    num_steps_trained: 4650000
    wait_time_ms: 172.181
  iterations_since_restore: 465
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8502.506265163422
  time_this_iter_s: 17.98186707496643
  time_total_s: 8502.506265163422
  timestamp: 1593892983
  timesteps_since_restore: 4650000
  timesteps_this_iter: 10000
  timesteps_total: 4650000
  training_iteration: 465
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8502 s, 465 iter, 4650000 ts, 208 rew

agent-1: 29.0
agent-2: 20.0
agent-3: 19.0
agent-4: 24.0
agent-5: 19.0
agent-6: 21.0
agent-7: 15.0
agent-8: 27.0
agent-9: 22.0
agent-10: 18.0
Sum Reward: 214.0
Avg Reward: 21.4
Min Reward: 15.0
Gini Coefficient: 0.10467289719626169
20:20 Ratio: 1.696969696969697
Max-min Ratio: 1.9333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_16-03-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.03
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 465
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.992
    dispatch_time_ms: 6.677
    learner:
      cur_lr: 0.0010503099765628576
      grad_gnorm: 0.1840600222349167
      policy_entropy: 188.85418701171875
      policy_loss: 0.18755213916301727
      var_gnorm: 69.8295669555664
      vf_explained_var: 0.9570707082748413
      vf_loss: 3.683512477437034e-05
    num_steps_sampled: 4660000
    num_steps_trained: 4660000
    wait_time_ms: 166.17
  iterations_since_restore: 466
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8520.489428758621
  time_this_iter_s: 17.983163595199585
  time_total_s: 8520.489428758621
  timestamp: 1593893001
  timesteps_since_restore: 4660000
  timesteps_this_iter: 10000
  timesteps_total: 4660000
  training_iteration: 466
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8520 s, 466 iter, 4660000 ts, 208 rew

agent-1: 17.0
agent-2: 34.0
agent-3: 23.0
agent-4: 24.0
agent-5: 27.0
agent-6: 15.0
agent-7: 24.0
agent-8: 17.0
agent-9: 24.0
agent-10: 17.0
Sum Reward: 222.0
Avg Reward: 22.2
Min Reward: 15.0
Gini Coefficient: 0.13423423423423422
20:20 Ratio: 1.90625
Max-min Ratio: 2.2666666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_16-03-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.26
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 466
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.503
    dispatch_time_ms: 6.294
    learner:
      cur_lr: 0.0010496439645066857
      grad_gnorm: 1.3782787322998047
      policy_entropy: 191.69078063964844
      policy_loss: -0.6549450159072876
      var_gnorm: 69.7922592163086
      vf_explained_var: 0.19763535261154175
      vf_loss: 0.00149641337338835
    num_steps_sampled: 4670000
    num_steps_trained: 4670000
    wait_time_ms: 172.932
  iterations_since_restore: 467
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8538.417010307312
  time_this_iter_s: 17.927581548690796
  time_total_s: 8538.417010307312
  timestamp: 1593893019
  timesteps_since_restore: 4670000
  timesteps_this_iter: 10000
  timesteps_total: 4670000
  training_iteration: 467
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8538 s, 467 iter, 4670000 ts, 208 rew

agent-1: 25.0
agent-2: 20.0
agent-3: 16.0
agent-4: 21.0
agent-5: 29.0
agent-6: 16.0
agent-7: 23.0
agent-8: 23.0
agent-9: 22.0
agent-10: 21.0
Sum Reward: 216.0
Avg Reward: 21.6
Min Reward: 16.0
Gini Coefficient: 0.09351851851851851
20:20 Ratio: 1.6875
Max-min Ratio: 1.8125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_16-03-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.25
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 467
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.846
    dispatch_time_ms: 6.152
    learner:
      cur_lr: 0.0010489779524505138
      grad_gnorm: 0.6406263709068298
      policy_entropy: 181.55615234375
      policy_loss: 0.38018670678138733
      var_gnorm: 69.92048645019531
      vf_explained_var: 0.7626665830612183
      vf_loss: 0.0009189543197862804
    num_steps_sampled: 4680000
    num_steps_trained: 4680000
    wait_time_ms: 170.903
  iterations_since_restore: 468
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8556.18077659607
  time_this_iter_s: 17.763766288757324
  time_total_s: 8556.18077659607
  timestamp: 1593893037
  timesteps_since_restore: 4680000
  timesteps_this_iter: 10000
  timesteps_total: 4680000
  training_iteration: 468
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8556 s, 468 iter, 4680000 ts, 208 rew

agent-1: 21.0
agent-2: 14.0
agent-3: 20.0
agent-4: 19.0
agent-5: 27.0
agent-6: 18.0
agent-7: 24.0
agent-8: 19.0
agent-9: 14.0
agent-10: 18.0
Sum Reward: 194.0
Avg Reward: 19.4
Min Reward: 14.0
Gini Coefficient: 0.10721649484536082
20:20 Ratio: 1.8214285714285714
Max-min Ratio: 1.9285714285714286
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_16-04-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.21
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 468
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.149
    dispatch_time_ms: 26.804
    learner:
      cur_lr: 0.0010483120568096638
      grad_gnorm: 37.784698486328125
      policy_entropy: 163.9126434326172
      policy_loss: -0.5148125290870667
      var_gnorm: 69.9840316772461
      vf_explained_var: 0.8344821929931641
      vf_loss: 4.35251522064209
    num_steps_sampled: 4690000
    num_steps_trained: 4690000
    wait_time_ms: 68.027
  iterations_since_restore: 469
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8576.184589624405
  time_this_iter_s: 20.00381302833557
  time_total_s: 8576.184589624405
  timestamp: 1593893057
  timesteps_since_restore: 4690000
  timesteps_this_iter: 10000
  timesteps_total: 4690000
  training_iteration: 469
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8576 s, 469 iter, 4690000 ts, 208 rew

agent-1: 24.0
agent-2: 17.0
agent-3: 23.0
agent-4: 20.0
agent-5: 21.0
agent-6: 19.0
agent-7: 17.0
agent-8: 16.0
agent-9: 17.0
agent-10: 24.0
Sum Reward: 198.0
Avg Reward: 19.8
Min Reward: 16.0
Gini Coefficient: 0.08282828282828283
20:20 Ratio: 1.4545454545454546
Max-min Ratio: 1.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_16-04-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.13
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 469
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.15
    dispatch_time_ms: 21.836
    learner:
      cur_lr: 0.0010476460447534919
      grad_gnorm: 18.469459533691406
      policy_entropy: 178.35064697265625
      policy_loss: -0.11442068219184875
      var_gnorm: 70.04611206054688
      vf_explained_var: 0.10278695821762085
      vf_loss: 0.026357747614383698
    num_steps_sampled: 4700000
    num_steps_trained: 4700000
    wait_time_ms: 169.903
  iterations_since_restore: 470
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8594.51912021637
  time_this_iter_s: 18.33453059196472
  time_total_s: 8594.51912021637
  timestamp: 1593893076
  timesteps_since_restore: 4700000
  timesteps_this_iter: 10000
  timesteps_total: 4700000
  training_iteration: 470
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8594 s, 470 iter, 4700000 ts, 208 rew

agent-1: 17.0
agent-2: 22.0
agent-3: 17.0
agent-4: 22.0
agent-5: 21.0
agent-6: 22.0
agent-7: 29.0
agent-8: 22.0
agent-9: 21.0
agent-10: 11.0
Sum Reward: 204.0
Avg Reward: 20.4
Min Reward: 11.0
Gini Coefficient: 0.11078431372549019
20:20 Ratio: 1.8214285714285714
Max-min Ratio: 2.6363636363636362
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_16-04-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.21
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 470
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.886
    dispatch_time_ms: 10.501
    learner:
      cur_lr: 0.00104698003269732
      grad_gnorm: 0.8581560850143433
      policy_entropy: 181.28858947753906
      policy_loss: -0.13301050662994385
      var_gnorm: 70.08174896240234
      vf_explained_var: 0.9381992220878601
      vf_loss: 0.0006559243192896247
    num_steps_sampled: 4710000
    num_steps_trained: 4710000
    wait_time_ms: 163.107
  iterations_since_restore: 471
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8613.120497465134
  time_this_iter_s: 18.601377248764038
  time_total_s: 8613.120497465134
  timestamp: 1593893094
  timesteps_since_restore: 4710000
  timesteps_this_iter: 10000
  timesteps_total: 4710000
  training_iteration: 471
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8613 s, 471 iter, 4710000 ts, 208 rew

agent-1: 21.0
agent-2: 17.0
agent-3: 21.0
agent-4: 28.0
agent-5: 23.0
agent-6: 23.0
agent-7: 20.0
agent-8: 21.0
agent-9: 13.0
agent-10: 25.0
Sum Reward: 212.0
Avg Reward: 21.2
Min Reward: 13.0
Gini Coefficient: 0.1
20:20 Ratio: 1.7666666666666666
Max-min Ratio: 2.1538461538461537
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_16-05-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.14
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 471
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.94
    dispatch_time_ms: 6.477
    learner:
      cur_lr: 0.001046314020641148
      grad_gnorm: 0.20164428651332855
      policy_entropy: 180.4351348876953
      policy_loss: 0.06879027932882309
      var_gnorm: 70.2894515991211
      vf_explained_var: 0.9952350854873657
      vf_loss: 0.00014687345537822694
    num_steps_sampled: 4720000
    num_steps_trained: 4720000
    wait_time_ms: 164.67
  iterations_since_restore: 472
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8630.927694797516
  time_this_iter_s: 17.807197332382202
  time_total_s: 8630.927694797516
  timestamp: 1593893112
  timesteps_since_restore: 4720000
  timesteps_this_iter: 10000
  timesteps_total: 4720000
  training_iteration: 472
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8630 s, 472 iter, 4720000 ts, 208 rew

agent-1: 15.0
agent-2: 32.0
agent-3: 24.0
agent-4: 28.0
agent-5: 25.0
agent-6: 24.0
agent-7: 24.0
agent-8: 28.0
agent-9: 10.0
agent-10: 11.0
Sum Reward: 221.0
Avg Reward: 22.1
Min Reward: 10.0
Gini Coefficient: 0.17420814479638008
20:20 Ratio: 2.857142857142857
Max-min Ratio: 3.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_16-05-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.3
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 472
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.439
    dispatch_time_ms: 6.587
    learner:
      cur_lr: 0.0010456480085849762
      grad_gnorm: 0.5340191721916199
      policy_entropy: 187.18280029296875
      policy_loss: -0.2561311721801758
      var_gnorm: 70.25791931152344
      vf_explained_var: 0.9879825115203857
      vf_loss: 0.00035386779927648604
    num_steps_sampled: 4730000
    num_steps_trained: 4730000
    wait_time_ms: 162.476
  iterations_since_restore: 473
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8648.80643081665
  time_this_iter_s: 17.87873601913452
  time_total_s: 8648.80643081665
  timestamp: 1593893130
  timesteps_since_restore: 4730000
  timesteps_this_iter: 10000
  timesteps_total: 4730000
  training_iteration: 473
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8648 s, 473 iter, 4730000 ts, 208 rew

agent-1: 34.0
agent-2: 14.0
agent-3: 22.0
agent-4: 25.0
agent-5: 8.0
agent-6: 27.0
agent-7: 20.0
agent-8: 20.0
agent-9: 12.0
agent-10: 23.0
Sum Reward: 205.0
Avg Reward: 20.5
Min Reward: 8.0
Gini Coefficient: 0.1975609756097561
20:20 Ratio: 3.05
Max-min Ratio: 4.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_16-05-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.38
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 473
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.25
    dispatch_time_ms: 7.048
    learner:
      cur_lr: 0.0010449819965288043
      grad_gnorm: 0.10403290390968323
      policy_entropy: 191.8040313720703
      policy_loss: 0.05827907472848892
      var_gnorm: 70.37567138671875
      vf_explained_var: 0.9959572553634644
      vf_loss: 8.032634650589898e-05
    num_steps_sampled: 4740000
    num_steps_trained: 4740000
    wait_time_ms: 166.477
  iterations_since_restore: 474
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8666.761255264282
  time_this_iter_s: 17.954824447631836
  time_total_s: 8666.761255264282
  timestamp: 1593893148
  timesteps_since_restore: 4740000
  timesteps_this_iter: 10000
  timesteps_total: 4740000
  training_iteration: 474
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8666 s, 474 iter, 4740000 ts, 208 rew

agent-1: 13.0
agent-2: 28.0
agent-3: 18.0
agent-4: 22.0
agent-5: 30.0
agent-6: 21.0
agent-7: 28.0
agent-8: 14.0
agent-9: 20.0
agent-10: 24.0
Sum Reward: 218.0
Avg Reward: 21.8
Min Reward: 13.0
Gini Coefficient: 0.14403669724770643
20:20 Ratio: 2.1481481481481484
Max-min Ratio: 2.3076923076923075
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_16-06-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.5
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 474
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.413
    dispatch_time_ms: 6.264
    learner:
      cur_lr: 0.0010443159844726324
      grad_gnorm: 40.00000762939453
      policy_entropy: 7.623335838317871
      policy_loss: 5.862133979797363
      var_gnorm: 70.36502838134766
      vf_explained_var: -0.0034335851669311523
      vf_loss: 217.57691955566406
    num_steps_sampled: 4750000
    num_steps_trained: 4750000
    wait_time_ms: 152.164
  iterations_since_restore: 475
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8684.682837247849
  time_this_iter_s: 17.921581983566284
  time_total_s: 8684.682837247849
  timestamp: 1593893166
  timesteps_since_restore: 4750000
  timesteps_this_iter: 10000
  timesteps_total: 4750000
  training_iteration: 475
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8684 s, 475 iter, 4750000 ts, 208 rew

agent-1: 27.0
agent-2: 28.0
agent-3: 23.0
agent-4: 20.0
agent-5: 26.0
agent-6: 26.0
agent-7: 23.0
agent-8: 19.0
agent-9: 20.0
agent-10: 16.0
Sum Reward: 228.0
Avg Reward: 22.8
Min Reward: 16.0
Gini Coefficient: 0.09298245614035087
20:20 Ratio: 1.5714285714285714
Max-min Ratio: 1.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_16-06-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.59
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 475
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.712
    dispatch_time_ms: 6.479
    learner:
      cur_lr: 0.0010436499724164605
      grad_gnorm: 0.10909448564052582
      policy_entropy: 182.49441528320312
      policy_loss: -0.01040865108370781
      var_gnorm: 70.38928985595703
      vf_explained_var: 0.9955534934997559
      vf_loss: 1.597047048562672e-05
    num_steps_sampled: 4760000
    num_steps_trained: 4760000
    wait_time_ms: 174.698
  iterations_since_restore: 476
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8702.64273238182
  time_this_iter_s: 17.959895133972168
  time_total_s: 8702.64273238182
  timestamp: 1593893184
  timesteps_since_restore: 4760000
  timesteps_this_iter: 10000
  timesteps_total: 4760000
  training_iteration: 476
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8702 s, 476 iter, 4760000 ts, 209 rew

agent-1: 23.0
agent-2: 17.0
agent-3: 21.0
agent-4: 23.0
agent-5: 18.0
agent-6: 26.0
agent-7: 16.0
agent-8: 26.0
agent-9: 31.0
agent-10: 19.0
Sum Reward: 220.0
Avg Reward: 22.0
Min Reward: 16.0
Gini Coefficient: 0.11454545454545455
20:20 Ratio: 1.7272727272727273
Max-min Ratio: 1.9375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_16-06-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.73
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 476
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.74
    dispatch_time_ms: 5.878
    learner:
      cur_lr: 0.0010429839603602886
      grad_gnorm: 39.999996185302734
      policy_entropy: 3.7957303524017334
      policy_loss: -49.79711151123047
      var_gnorm: 70.41468048095703
      vf_explained_var: -0.23180389404296875
      vf_loss: 576.9485473632812
    num_steps_sampled: 4770000
    num_steps_trained: 4770000
    wait_time_ms: 144.862
  iterations_since_restore: 477
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8720.454668045044
  time_this_iter_s: 17.811935663223267
  time_total_s: 8720.454668045044
  timestamp: 1593893202
  timesteps_since_restore: 4770000
  timesteps_this_iter: 10000
  timesteps_total: 4770000
  training_iteration: 477
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8720 s, 477 iter, 4770000 ts, 209 rew

agent-1: 23.0
agent-2: 23.0
agent-3: 21.0
agent-4: 29.0
agent-5: 23.0
agent-6: 24.0
agent-7: 24.0
agent-8: 27.0
agent-9: 30.0
agent-10: 27.0
Sum Reward: 251.0
Avg Reward: 25.1
Min Reward: 21.0
Gini Coefficient: 0.061752988047808766
20:20 Ratio: 1.3409090909090908
Max-min Ratio: 1.4285714285714286
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_16-07-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 209.24
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 477
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 4.024
    dispatch_time_ms: 6.721
    learner:
      cur_lr: 0.0010423179483041167
      grad_gnorm: 0.5762680768966675
      policy_entropy: 138.17190551757812
      policy_loss: -0.21602989733219147
      var_gnorm: 70.57374572753906
      vf_explained_var: 0.8638592958450317
      vf_loss: 0.0024391866754740477
    num_steps_sampled: 4780000
    num_steps_trained: 4780000
    wait_time_ms: 161.441
  iterations_since_restore: 478
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8738.23364853859
  time_this_iter_s: 17.778980493545532
  time_total_s: 8738.23364853859
  timestamp: 1593893220
  timesteps_since_restore: 4780000
  timesteps_this_iter: 10000
  timesteps_total: 4780000
  training_iteration: 478
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8738 s, 478 iter, 4780000 ts, 209 rew

agent-1: 25.0
agent-2: 23.0
agent-3: 20.0
agent-4: 21.0
agent-5: 26.0
agent-6: 20.0
agent-7: 9.0
agent-8: 16.0
agent-9: 24.0
agent-10: 20.0
Sum Reward: 204.0
Avg Reward: 20.4
Min Reward: 9.0
Gini Coefficient: 0.12058823529411765
20:20 Ratio: 2.04
Max-min Ratio: 2.888888888888889
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_16-07-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 209.12
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 478
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.999
    dispatch_time_ms: 6.033
    learner:
      cur_lr: 0.0010416520526632667
      grad_gnorm: 0.17498227953910828
      policy_entropy: 180.88241577148438
      policy_loss: -0.13441762328147888
      var_gnorm: 70.55276489257812
      vf_explained_var: 0.9668900370597839
      vf_loss: 3.5021479561692104e-05
    num_steps_sampled: 4790000
    num_steps_trained: 4790000
    wait_time_ms: 153.84
  iterations_since_restore: 479
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8756.090763807297
  time_this_iter_s: 17.857115268707275
  time_total_s: 8756.090763807297
  timestamp: 1593893238
  timesteps_since_restore: 4790000
  timesteps_this_iter: 10000
  timesteps_total: 4790000
  training_iteration: 479
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8756 s, 479 iter, 4790000 ts, 209 rew

agent-1: 26.0
agent-2: 18.0
agent-3: 14.0
agent-4: 16.0
agent-5: 17.0
agent-6: 26.0
agent-7: 11.0
agent-8: 23.0
agent-9: 33.0
agent-10: 23.0
Sum Reward: 207.0
Avg Reward: 20.7
Min Reward: 11.0
Gini Coefficient: 0.17149758454106281
20:20 Ratio: 2.36
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_16-07-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 209.11
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 479
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.67
    dispatch_time_ms: 6.753
    learner:
      cur_lr: 0.0010409860406070948
      grad_gnorm: 0.03886998072266579
      policy_entropy: 192.39015197753906
      policy_loss: -0.02848570980131626
      var_gnorm: 70.67302703857422
      vf_explained_var: 0.9958742260932922
      vf_loss: 4.191606876702281e-06
    num_steps_sampled: 4800000
    num_steps_trained: 4800000
    wait_time_ms: 175.131
  iterations_since_restore: 480
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8774.039462804794
  time_this_iter_s: 17.94869899749756
  time_total_s: 8774.039462804794
  timestamp: 1593893256
  timesteps_since_restore: 4800000
  timesteps_this_iter: 10000
  timesteps_total: 4800000
  training_iteration: 480
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8774 s, 480 iter, 4800000 ts, 209 rew

agent-1: 22.0
agent-2: 27.0
agent-3: 12.0
agent-4: 22.0
agent-5: 25.0
agent-6: 15.0
agent-7: 27.0
agent-8: 15.0
agent-9: 15.0
agent-10: 21.0
Sum Reward: 201.0
Avg Reward: 20.1
Min Reward: 12.0
Gini Coefficient: 0.14477611940298507
20:20 Ratio: 2.0
Max-min Ratio: 2.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_16-07-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 209.15
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 480
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.886
    dispatch_time_ms: 7.572
    learner:
      cur_lr: 0.0010403200285509229
      grad_gnorm: 39.999996185302734
      policy_entropy: 9.234258651733398
      policy_loss: -7.541416168212891
      var_gnorm: 70.67437744140625
      vf_explained_var: 0.5386432409286499
      vf_loss: 79.89698028564453
    num_steps_sampled: 4810000
    num_steps_trained: 4810000
    wait_time_ms: 144.758
  iterations_since_restore: 481
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8791.774945735931
  time_this_iter_s: 17.735482931137085
  time_total_s: 8791.774945735931
  timestamp: 1593893273
  timesteps_since_restore: 4810000
  timesteps_this_iter: 10000
  timesteps_total: 4810000
  training_iteration: 481
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8791 s, 481 iter, 4810000 ts, 209 rew

agent-1: 23.0
agent-2: 21.0
agent-3: 23.0
agent-4: 20.0
agent-5: 21.0
agent-6: 21.0
agent-7: 19.0
agent-8: 27.0
agent-9: 17.0
agent-10: 25.0
Sum Reward: 217.0
Avg Reward: 21.7
Min Reward: 17.0
Gini Coefficient: 0.07050691244239632
20:20 Ratio: 1.4444444444444444
Max-min Ratio: 1.588235294117647
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_16-08-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 209.42
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 481
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.891
    dispatch_time_ms: 6.68
    learner:
      cur_lr: 0.001039654016494751
      grad_gnorm: 0.1835145652294159
      policy_entropy: 183.72398376464844
      policy_loss: -0.08269805461168289
      var_gnorm: 70.8134536743164
      vf_explained_var: 0.9429912567138672
      vf_loss: 2.9698248908971436e-05
    num_steps_sampled: 4820000
    num_steps_trained: 4820000
    wait_time_ms: 173.289
  iterations_since_restore: 482
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8809.678611755371
  time_this_iter_s: 17.903666019439697
  time_total_s: 8809.678611755371
  timestamp: 1593893291
  timesteps_since_restore: 4820000
  timesteps_this_iter: 10000
  timesteps_total: 4820000
  training_iteration: 482
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8809 s, 482 iter, 4820000 ts, 209 rew

agent-1: 23.0
agent-2: 27.0
agent-3: 25.0
agent-4: 18.0
agent-5: 23.0
agent-6: 17.0
agent-7: 23.0
agent-8: 24.0
agent-9: 17.0
agent-10: 21.0
Sum Reward: 218.0
Avg Reward: 21.8
Min Reward: 17.0
Gini Coefficient: 0.0834862385321101
20:20 Ratio: 1.5294117647058822
Max-min Ratio: 1.588235294117647
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_16-08-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 209.49
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 482
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.049
    dispatch_time_ms: 7.533
    learner:
      cur_lr: 0.001038988004438579
      grad_gnorm: 40.000003814697266
      policy_entropy: 3.2234630584716797
      policy_loss: -0.7215766906738281
      var_gnorm: 70.81438446044922
      vf_explained_var: 0.7178714275360107
      vf_loss: 69.23065185546875
    num_steps_sampled: 4830000
    num_steps_trained: 4830000
    wait_time_ms: 141.395
  iterations_since_restore: 483
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8827.411198854446
  time_this_iter_s: 17.732587099075317
  time_total_s: 8827.411198854446
  timestamp: 1593893309
  timesteps_since_restore: 4830000
  timesteps_this_iter: 10000
  timesteps_total: 4830000
  training_iteration: 483
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8827 s, 483 iter, 4830000 ts, 209 rew

agent-1: 18.0
agent-2: 16.0
agent-3: 24.0
agent-4: 20.0
agent-5: 22.0
agent-6: 23.0
agent-7: 20.0
agent-8: 24.0
agent-9: 12.0
agent-10: 16.0
Sum Reward: 195.0
Avg Reward: 19.5
Min Reward: 12.0
Gini Coefficient: 0.1082051282051282
20:20 Ratio: 1.7142857142857142
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_16-08-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 209.47
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 483
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.013
    dispatch_time_ms: 10.128
    learner:
      cur_lr: 0.0010383219923824072
      grad_gnorm: 3.386871337890625
      policy_entropy: 179.49496459960938
      policy_loss: -0.6299711465835571
      var_gnorm: 71.00445556640625
      vf_explained_var: -1.0
      vf_loss: 0.003076312132179737
    num_steps_sampled: 4840000
    num_steps_trained: 4840000
    wait_time_ms: 163.951
  iterations_since_restore: 484
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8845.36411690712
  time_this_iter_s: 17.95291805267334
  time_total_s: 8845.36411690712
  timestamp: 1593893327
  timesteps_since_restore: 4840000
  timesteps_this_iter: 10000
  timesteps_total: 4840000
  training_iteration: 484
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8845 s, 484 iter, 4840000 ts, 209 rew

agent-1: 22.0
agent-2: 22.0
agent-3: 27.0
agent-4: 16.0
agent-5: 27.0
agent-6: 17.0
agent-7: 22.0
agent-8: 23.0
agent-9: 23.0
agent-10: 15.0
Sum Reward: 214.0
Avg Reward: 21.4
Min Reward: 15.0
Gini Coefficient: 0.10186915887850467
20:20 Ratio: 1.7419354838709677
Max-min Ratio: 1.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_16-09-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 209.61
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 484
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.929
    dispatch_time_ms: 6.587
    learner:
      cur_lr: 0.0010376559803262353
      grad_gnorm: 39.9999885559082
      policy_entropy: 4.874500274658203
      policy_loss: -0.13107551634311676
      var_gnorm: 71.01378631591797
      vf_explained_var: 0.7101977467536926
      vf_loss: 69.52013397216797
    num_steps_sampled: 4850000
    num_steps_trained: 4850000
    wait_time_ms: 149.963
  iterations_since_restore: 485
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8863.16287946701
  time_this_iter_s: 17.798762559890747
  time_total_s: 8863.16287946701
  timestamp: 1593893345
  timesteps_since_restore: 4850000
  timesteps_this_iter: 10000
  timesteps_total: 4850000
  training_iteration: 485
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8863 s, 485 iter, 4850000 ts, 210 rew

agent-1: 21.0
agent-2: 25.0
agent-3: 17.0
agent-4: 21.0
agent-5: 15.0
agent-6: 25.0
agent-7: 11.0
agent-8: 18.0
agent-9: 25.0
agent-10: 29.0
Sum Reward: 207.0
Avg Reward: 20.7
Min Reward: 11.0
Gini Coefficient: 0.14154589371980678
20:20 Ratio: 2.076923076923077
Max-min Ratio: 2.6363636363636362
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_16-09-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 209.68
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 485
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.502
    dispatch_time_ms: 6.012
    learner:
      cur_lr: 0.0010369899682700634
      grad_gnorm: 1.4158486127853394
      policy_entropy: 167.68789672851562
      policy_loss: 0.024045802652835846
      var_gnorm: 71.08879089355469
      vf_explained_var: -1.0
      vf_loss: 0.0011241747997701168
    num_steps_sampled: 4860000
    num_steps_trained: 4860000
    wait_time_ms: 170.478
  iterations_since_restore: 486
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8880.93494272232
  time_this_iter_s: 17.77206325531006
  time_total_s: 8880.93494272232
  timestamp: 1593893363
  timesteps_since_restore: 4860000
  timesteps_this_iter: 10000
  timesteps_total: 4860000
  training_iteration: 486
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8880 s, 486 iter, 4860000 ts, 210 rew

agent-1: 20.0
agent-2: 11.0
agent-3: 16.0
agent-4: 18.0
agent-5: 25.0
agent-6: 27.0
agent-7: 19.0
agent-8: 19.0
agent-9: 5.0
agent-10: 31.0
Sum Reward: 191.0
Avg Reward: 19.1
Min Reward: 5.0
Gini Coefficient: 0.20785340314136125
20:20 Ratio: 3.625
Max-min Ratio: 6.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_16-09-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 209.53
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 486
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.752
    dispatch_time_ms: 7.077
    learner:
      cur_lr: 0.0010363239562138915
      grad_gnorm: 0.14142464101314545
      policy_entropy: 179.2552947998047
      policy_loss: 0.05531015247106552
      var_gnorm: 71.08539581298828
      vf_explained_var: 0.990788996219635
      vf_loss: 4.820401045435574e-06
    num_steps_sampled: 4870000
    num_steps_trained: 4870000
    wait_time_ms: 170.292
  iterations_since_restore: 487
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8899.057138204575
  time_this_iter_s: 18.12219548225403
  time_total_s: 8899.057138204575
  timestamp: 1593893381
  timesteps_since_restore: 4870000
  timesteps_this_iter: 10000
  timesteps_total: 4870000
  training_iteration: 487
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8899 s, 487 iter, 4870000 ts, 210 rew

agent-1: 17.0
agent-2: 19.0
agent-3: 19.0
agent-4: 23.0
agent-5: 20.0
agent-6: 23.0
agent-7: 23.0
agent-8: 21.0
agent-9: 17.0
agent-10: 22.0
Sum Reward: 204.0
Avg Reward: 20.4
Min Reward: 17.0
Gini Coefficient: 0.061764705882352944
20:20 Ratio: 1.3529411764705883
Max-min Ratio: 1.3529411764705883
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_16-09-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 209.52
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 487
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 4.117
    dispatch_time_ms: 7.903
    learner:
      cur_lr: 0.0010356579441577196
      grad_gnorm: 1.5004812479019165
      policy_entropy: 171.81817626953125
      policy_loss: 0.566521942615509
      var_gnorm: 71.17828369140625
      vf_explained_var: -0.06394803524017334
      vf_loss: 0.020321911200881004
    num_steps_sampled: 4880000
    num_steps_trained: 4880000
    wait_time_ms: 169.276
  iterations_since_restore: 488
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8916.676285266876
  time_this_iter_s: 17.619147062301636
  time_total_s: 8916.676285266876
  timestamp: 1593893399
  timesteps_since_restore: 4880000
  timesteps_this_iter: 10000
  timesteps_total: 4880000
  training_iteration: 488
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8916 s, 488 iter, 4880000 ts, 210 rew

agent-1: 24.0
agent-2: 13.0
agent-3: 17.0
agent-4: 24.0
agent-5: 25.0
agent-6: 21.0
agent-7: 34.0
agent-8: 23.0
agent-9: 14.0
agent-10: 20.0
Sum Reward: 215.0
Avg Reward: 21.5
Min Reward: 13.0
Gini Coefficient: 0.14651162790697675
20:20 Ratio: 2.185185185185185
Max-min Ratio: 2.6153846153846154
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_16-10-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 209.38
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 488
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.683
    dispatch_time_ms: 8.241
    learner:
      cur_lr: 0.0010349920485168695
      grad_gnorm: 1.1785129308700562
      policy_entropy: 175.851318359375
      policy_loss: 0.3844291865825653
      var_gnorm: 71.18592071533203
      vf_explained_var: 0.5874009132385254
      vf_loss: 0.0008474835776723921
    num_steps_sampled: 4890000
    num_steps_trained: 4890000
    wait_time_ms: 168.231
  iterations_since_restore: 489
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8934.579642772675
  time_this_iter_s: 17.90335750579834
  time_total_s: 8934.579642772675
  timestamp: 1593893416
  timesteps_since_restore: 4890000
  timesteps_this_iter: 10000
  timesteps_total: 4890000
  training_iteration: 489
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8934 s, 489 iter, 4890000 ts, 209 rew

agent-1: 17.0
agent-2: 17.0
agent-3: 26.0
agent-4: 28.0
agent-5: 22.0
agent-6: 12.0
agent-7: 22.0
agent-8: 24.0
agent-9: 14.0
agent-10: 13.0
Sum Reward: 195.0
Avg Reward: 19.5
Min Reward: 12.0
Gini Coefficient: 0.1564102564102564
20:20 Ratio: 2.16
Max-min Ratio: 2.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_16-10-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.93
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 489
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.632
    dispatch_time_ms: 9.474
    learner:
      cur_lr: 0.0010343260364606977
      grad_gnorm: 0.25125962495803833
      policy_entropy: 180.60072326660156
      policy_loss: 0.09198733419179916
      var_gnorm: 71.31694793701172
      vf_explained_var: 0.5248702764511108
      vf_loss: 0.0008501397678628564
    num_steps_sampled: 4900000
    num_steps_trained: 4900000
    wait_time_ms: 164.837
  iterations_since_restore: 490
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8952.350118637085
  time_this_iter_s: 17.7704758644104
  time_total_s: 8952.350118637085
  timestamp: 1593893434
  timesteps_since_restore: 4900000
  timesteps_this_iter: 10000
  timesteps_total: 4900000
  training_iteration: 490
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8952 s, 490 iter, 4900000 ts, 209 rew

agent-1: 17.0
agent-2: 17.0
agent-3: 27.0
agent-4: 16.0
agent-5: 18.0
agent-6: 20.0
agent-7: 19.0
agent-8: 23.0
agent-9: 20.0
agent-10: 20.0
Sum Reward: 197.0
Avg Reward: 19.7
Min Reward: 16.0
Gini Coefficient: 0.08274111675126904
20:20 Ratio: 1.5151515151515151
Max-min Ratio: 1.6875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_16-10-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.83
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 490
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.871
    dispatch_time_ms: 5.964
    learner:
      cur_lr: 0.0010336600244045258
      grad_gnorm: 40.0
      policy_entropy: 0.9704948663711548
      policy_loss: 0.16366590559482574
      var_gnorm: 71.31661224365234
      vf_explained_var: 0.3094903230667114
      vf_loss: 180.18675231933594
    num_steps_sampled: 4910000
    num_steps_trained: 4910000
    wait_time_ms: 148.216
  iterations_since_restore: 491
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8970.088337898254
  time_this_iter_s: 17.738219261169434
  time_total_s: 8970.088337898254
  timestamp: 1593893452
  timesteps_since_restore: 4910000
  timesteps_this_iter: 10000
  timesteps_total: 4910000
  training_iteration: 491
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8970 s, 491 iter, 4910000 ts, 209 rew

agent-1: 17.0
agent-2: 17.0
agent-3: 19.0
agent-4: 27.0
agent-5: 14.0
agent-6: 20.0
agent-7: 22.0
agent-8: 17.0
agent-9: 16.0
agent-10: 24.0
Sum Reward: 193.0
Avg Reward: 19.3
Min Reward: 14.0
Gini Coefficient: 0.10829015544041451
20:20 Ratio: 1.7
Max-min Ratio: 1.9285714285714286
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_16-11-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.73
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 491
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.361
    dispatch_time_ms: 9.584
    learner:
      cur_lr: 0.0010329940123483539
      grad_gnorm: 3.6222879886627197
      policy_entropy: 184.03076171875
      policy_loss: 0.05948185920715332
      var_gnorm: 71.38904571533203
      vf_explained_var: -1.0
      vf_loss: 0.005786560475826263
    num_steps_sampled: 4920000
    num_steps_trained: 4920000
    wait_time_ms: 168.323
  iterations_since_restore: 492
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 8987.991228818893
  time_this_iter_s: 17.902890920639038
  time_total_s: 8987.991228818893
  timestamp: 1593893470
  timesteps_since_restore: 4920000
  timesteps_this_iter: 10000
  timesteps_total: 4920000
  training_iteration: 492
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 8987 s, 492 iter, 4920000 ts, 209 rew

agent-1: 23.0
agent-2: 18.0
agent-3: 20.0
agent-4: 21.0
agent-5: 26.0
agent-6: 16.0
agent-7: 29.0
agent-8: 23.0
agent-9: 22.0
agent-10: 20.0
Sum Reward: 218.0
Avg Reward: 21.8
Min Reward: 16.0
Gini Coefficient: 0.0908256880733945
20:20 Ratio: 1.6176470588235294
Max-min Ratio: 1.8125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_16-11-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.74
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 492
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.072
    dispatch_time_ms: 7.71
    learner:
      cur_lr: 0.001032328000292182
      grad_gnorm: 0.6689499616622925
      policy_entropy: 189.14138793945312
      policy_loss: 0.112738698720932
      var_gnorm: 71.38264465332031
      vf_explained_var: 0.38546764850616455
      vf_loss: 0.0009469127980992198
    num_steps_sampled: 4930000
    num_steps_trained: 4930000
    wait_time_ms: 172.825
  iterations_since_restore: 493
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 9005.879026174545
  time_this_iter_s: 17.887797355651855
  time_total_s: 9005.879026174545
  timestamp: 1593893488
  timesteps_since_restore: 4930000
  timesteps_this_iter: 10000
  timesteps_total: 4930000
  training_iteration: 493
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 9005 s, 493 iter, 4930000 ts, 209 rew

agent-1: 19.0
agent-2: 14.0
agent-3: 21.0
agent-4: 20.0
agent-5: 25.0
agent-6: 19.0
agent-7: 22.0
agent-8: 17.0
agent-9: 19.0
agent-10: 17.0
Sum Reward: 193.0
Avg Reward: 19.3
Min Reward: 14.0
Gini Coefficient: 0.08134715025906736
20:20 Ratio: 1.5161290322580645
Max-min Ratio: 1.7857142857142858
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_16-11-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.7
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 493
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.75
    dispatch_time_ms: 6.866
    learner:
      cur_lr: 0.00103166198823601
      grad_gnorm: 0.8230171203613281
      policy_entropy: 187.4035186767578
      policy_loss: -0.12970620393753052
      var_gnorm: 71.54373168945312
      vf_explained_var: -0.46838486194610596
      vf_loss: 0.0034836267586797476
    num_steps_sampled: 4940000
    num_steps_trained: 4940000
    wait_time_ms: 166.399
  iterations_since_restore: 494
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 9023.610469579697
  time_this_iter_s: 17.731443405151367
  time_total_s: 9023.610469579697
  timestamp: 1593893506
  timesteps_since_restore: 4940000
  timesteps_this_iter: 10000
  timesteps_total: 4940000
  training_iteration: 494
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 9023 s, 494 iter, 4940000 ts, 209 rew

agent-1: 17.0
agent-2: 18.0
agent-3: 23.0
agent-4: 18.0
agent-5: 16.0
agent-6: 19.0
agent-7: 22.0
agent-8: 18.0
agent-9: 17.0
agent-10: 23.0
Sum Reward: 191.0
Avg Reward: 19.1
Min Reward: 16.0
Gini Coefficient: 0.06963350785340314
20:20 Ratio: 1.393939393939394
Max-min Ratio: 1.4375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_16-12-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.51
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 494
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.685
    dispatch_time_ms: 6.878
    learner:
      cur_lr: 0.0010309959761798382
      grad_gnorm: 3.2611889839172363
      policy_entropy: 188.7282257080078
      policy_loss: -0.7779306769371033
      var_gnorm: 71.56439208984375
      vf_explained_var: -1.0
      vf_loss: 0.006272917613387108
    num_steps_sampled: 4950000
    num_steps_trained: 4950000
    wait_time_ms: 168.445
  iterations_since_restore: 495
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 9041.543085098267
  time_this_iter_s: 17.932615518569946
  time_total_s: 9041.543085098267
  timestamp: 1593893524
  timesteps_since_restore: 4950000
  timesteps_this_iter: 10000
  timesteps_total: 4950000
  training_iteration: 495
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 9041 s, 495 iter, 4950000 ts, 209 rew

agent-1: 25.0
agent-2: 17.0
agent-3: 28.0
agent-4: 19.0
agent-5: 20.0
agent-6: 16.0
agent-7: 23.0
agent-8: 19.0
agent-9: 18.0
agent-10: 18.0
Sum Reward: 203.0
Avg Reward: 20.3
Min Reward: 16.0
Gini Coefficient: 0.0960591133004926
20:20 Ratio: 1.606060606060606
Max-min Ratio: 1.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_16-12-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.49
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 495
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.818
    dispatch_time_ms: 6.347
    learner:
      cur_lr: 0.0010303299641236663
      grad_gnorm: 0.21728946268558502
      policy_entropy: 184.16159057617188
      policy_loss: -0.05721215158700943
      var_gnorm: 71.58319091796875
      vf_explained_var: 0.9895509481430054
      vf_loss: 2.6692003302741796e-05
    num_steps_sampled: 4960000
    num_steps_trained: 4960000
    wait_time_ms: 175.346
  iterations_since_restore: 496
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 9059.383063077927
  time_this_iter_s: 17.839977979660034
  time_total_s: 9059.383063077927
  timestamp: 1593893542
  timesteps_since_restore: 4960000
  timesteps_this_iter: 10000
  timesteps_total: 4960000
  training_iteration: 496
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 9059 s, 496 iter, 4960000 ts, 208 rew

agent-1: 22.0
agent-2: 13.0
agent-3: 20.0
agent-4: 16.0
agent-5: 22.0
agent-6: 10.0
agent-7: 20.0
agent-8: 18.0
agent-9: 25.0
agent-10: 24.0
Sum Reward: 190.0
Avg Reward: 19.0
Min Reward: 10.0
Gini Coefficient: 0.1336842105263158
20:20 Ratio: 2.130434782608696
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_16-12-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.34
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 496
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.263
    dispatch_time_ms: 7.086
    learner:
      cur_lr: 0.0010296639520674944
      grad_gnorm: 0.31622228026390076
      policy_entropy: 188.5266876220703
      policy_loss: 0.1227286159992218
      var_gnorm: 71.58445739746094
      vf_explained_var: 0.5048232078552246
      vf_loss: 0.0004840383189730346
    num_steps_sampled: 4970000
    num_steps_trained: 4970000
    wait_time_ms: 166.797
  iterations_since_restore: 497
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 9077.318303108215
  time_this_iter_s: 17.935240030288696
  time_total_s: 9077.318303108215
  timestamp: 1593893560
  timesteps_since_restore: 4970000
  timesteps_this_iter: 10000
  timesteps_total: 4970000
  training_iteration: 497
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 9077 s, 497 iter, 4970000 ts, 208 rew

agent-1: 25.0
agent-2: 16.0
agent-3: 12.0
agent-4: 14.0
agent-5: 30.0
agent-6: 14.0
agent-7: 35.0
agent-8: 18.0
agent-9: 23.0
agent-10: 38.0
Sum Reward: 225.0
Avg Reward: 22.5
Min Reward: 12.0
Gini Coefficient: 0.21911111111111112
20:20 Ratio: 2.8076923076923075
Max-min Ratio: 3.1666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_16-12-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.58
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 497
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.084
    dispatch_time_ms: 5.834
    learner:
      cur_lr: 0.0010289980564266443
      grad_gnorm: 0.06887621432542801
      policy_entropy: 190.3137664794922
      policy_loss: 0.023916393518447876
      var_gnorm: 71.74139404296875
      vf_explained_var: 0.9959956407546997
      vf_loss: 6.631186261074618e-05
    num_steps_sampled: 4980000
    num_steps_trained: 4980000
    wait_time_ms: 168.612
  iterations_since_restore: 498
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 9095.138188362122
  time_this_iter_s: 17.81988525390625
  time_total_s: 9095.138188362122
  timestamp: 1593893577
  timesteps_since_restore: 4980000
  timesteps_this_iter: 10000
  timesteps_total: 4980000
  training_iteration: 498
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 9095 s, 498 iter, 4980000 ts, 209 rew

agent-1: 25.0
agent-2: 14.0
agent-3: 21.0
agent-4: 17.0
agent-5: 19.0
agent-6: 17.0
agent-7: 19.0
agent-8: 19.0
agent-9: 22.0
agent-10: 16.0
Sum Reward: 189.0
Avg Reward: 18.9
Min Reward: 14.0
Gini Coefficient: 0.08835978835978836
20:20 Ratio: 1.5666666666666667
Max-min Ratio: 1.7857142857142858
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_16-13-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.38
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 498
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 3.07
    dispatch_time_ms: 7.832
    learner:
      cur_lr: 0.0010283320443704724
      grad_gnorm: 1.5469214916229248
      policy_entropy: 175.49517822265625
      policy_loss: 0.06629770994186401
      var_gnorm: 71.74331665039062
      vf_explained_var: 0.9171727895736694
      vf_loss: 0.00011487863230286166
    num_steps_sampled: 4990000
    num_steps_trained: 4990000
    wait_time_ms: 158.655
  iterations_since_restore: 499
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 9112.95887041092
  time_this_iter_s: 17.820682048797607
  time_total_s: 9112.95887041092
  timestamp: 1593893595
  timesteps_since_restore: 4990000
  timesteps_this_iter: 10000
  timesteps_total: 4990000
  training_iteration: 499
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=32054], 9112 s, 499 iter, 4990000 ts, 208 rew

agent-1: 14.0
agent-2: 23.0
agent-3: 28.0
agent-4: 22.0
agent-5: 24.0
agent-6: 22.0
agent-7: 30.0
agent-8: 20.0
agent-9: 17.0
agent-10: 24.0
Sum Reward: 224.0
Avg Reward: 22.4
Min Reward: 14.0
Gini Coefficient: 0.11071428571428571
20:20 Ratio: 1.8709677419354838
Max-min Ratio: 2.142857142857143
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_16-13-33
  done: true
  episode_len_mean: 1000.0
  episode_reward_max: 255.0
  episode_reward_mean: 208.39
  episode_reward_min: 140.0
  episodes_this_iter: 1
  episodes_total: 499
  experiment_id: 63691fe4102f4d129ac2133e9c6b8e8d
  hostname: gpu008
  info:
    apply_time_ms: 2.807
    dispatch_time_ms: 5.8
    learner:
      cur_lr: 0.0010276660323143005
      grad_gnorm: 0.3386753797531128
      policy_entropy: 190.29750061035156
      policy_loss: -0.2290487289428711
      var_gnorm: 71.9000244140625
      vf_explained_var: 0.9946969747543335
      vf_loss: 8.377480844501406e-05
    num_steps_sampled: 5000000
    num_steps_trained: 5000000
    wait_time_ms: 174.872
  iterations_since_restore: 500
  node_ip: 172.17.8.8
  num_metric_batches_dropped: 0
  pid: 32054
  policy_reward_mean: {}
  time_since_restore: 9130.786000490189
  time_this_iter_s: 17.82713007926941
  time_total_s: 9130.786000490189
  timestamp: 1593893613
  timesteps_since_restore: 5000000
  timesteps_this_iter: 10000
  timesteps_total: 5000000
  training_iteration: 500
  
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
TERMINATED trials:
 - A3C_harvest_env_0:	TERMINATED [pid=32054], 9130 s, 500 iter, 5000000 ts, 208 rew

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
TERMINATED trials:
 - A3C_harvest_env_0:	TERMINATED [pid=32054], 9130 s, 500 iter, 5000000 ts, 208 rew

WARNING: Logging before InitGoogleLogging() is written to STDERR
E0704 16:13:34.230998 32068 raylet_client.cc:345] IOError: [RayletClient] Connection closed unexpectedly. [RayletClient] Failed to push profile events.
WARNING: Logging before InitGoogleLogging() is written to STDERR
E0704 16:13:34.238519 32081 raylet_client.cc:345] IOError: [RayletClient] Connection closed unexpectedly. [RayletClient] Failed to push profile events.
Commencing experiment harvest_A3C
E0704 16:13:35.285614 32068 raylet_client.cc:345] IOError: [RayletClient] Connection closed unexpectedly. [RayletClient] Failed to push profile events.
E0704 16:13:35.332152 32081 raylet_client.cc:345] IOError: [RayletClient] Connection closed unexpectedly. [RayletClient] Failed to push profile events.
