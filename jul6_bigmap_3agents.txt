/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Process STDOUT and STDERR is being redirected to /tmp/ray/session_2020-07-06_22-08-57_23570/logs.
Waiting for redis server at 127.0.0.1:13355 to respond...
Waiting for redis server at 127.0.0.1:10478 to respond...
Warning: Capping object memory store to 20.0GB. To increase this further, specify `object_store_memory` when calling ray.init() or ray start.
Starting the Plasma object store with 20.0 GB memory using /dev/shm.

======================================================================
View the web UI at http://localhost:8889/notebooks/ray_ui.ipynb?token=8fdca8f66363f4aba633808017110b103b89c898cc29206e
======================================================================

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0/2 CPUs, 0/1 GPUs
Memory usage on this node: 12.3/202.5 GB

Created LogSyncer for /h/zhaostep/ray_results/harvest_A3C/A3C_harvest_env_0_2020-07-06_22-08-581h8eav0w -> 
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 12.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING

/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-06 22:09:12,304	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 0 on CPU (please ignore any CUDA init errors)
2020-07-06 22:09:12.304848: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-06 22:09:23,709	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 2 on CPU (please ignore any CUDA init errors)
2020-07-06 22:09:23.710689: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-06 22:09:23,736	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 1 on CPU (please ignore any CUDA init errors)
2020-07-06 22:09:23.737219: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-09-36
  done: false
  episode_len_mean: .nan
  episode_reward_max: .nan
  episode_reward_mean: .nan
  episode_reward_min: .nan
  episodes_this_iter: 0
  episodes_total: 0
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.52
    dispatch_time_ms: 7.077
    learner:
      cur_lr: 0.0013599999947473407
      grad_gnorm: 40.000003814697266
      policy_entropy: 38.5654411315918
      policy_loss: 32.56268310546875
      var_gnorm: 18.000181198120117
      vf_explained_var: 0.27528178691864014
      vf_loss: 26.999486923217773
    num_steps_sampled: 3000
    num_steps_trained: 3000
    wait_time_ms: 85.373
  iterations_since_restore: 1
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 22.85932183265686
  time_this_iter_s: 22.85932183265686
  time_total_s: 22.85932183265686
  timestamp: 1594087776
  timesteps_since_restore: 3000
  timesteps_this_iter: 3000
  timesteps_total: 3000
  training_iteration: 1
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 22 s, 1 iter, 3000 ts, nan rew

[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
agent-1: 168.0
agent-2: 114.0
agent-3: 29.0
Sum Reward: 311.0
Avg Reward: 103.66666666666667
Min Reward: 29.0
Max Reward: 168.0
Gini Coefficient: 0.2979635584137192
20:20 Ratio: 5.793103448275862
Max-min Ratio: 5.793103448275862
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-09-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 311.0
  episode_reward_mean: 311.0
  episode_reward_min: 311.0
  episodes_this_iter: 1
  episodes_total: 1
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.582
    dispatch_time_ms: 10.045
    learner:
      cur_lr: 0.0013598002260550857
      grad_gnorm: 39.99999237060547
      policy_entropy: 34.709068298339844
      policy_loss: -14.367488861083984
      var_gnorm: 18.102210998535156
      vf_explained_var: 0.49032026529312134
      vf_loss: 15.124517440795898
    num_steps_sampled: 6000
    num_steps_trained: 6000
    wait_time_ms: 82.493
  iterations_since_restore: 2
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 32.751646995544434
  time_this_iter_s: 9.892325162887573
  time_total_s: 32.751646995544434
  timestamp: 1594087786
  timesteps_since_restore: 6000
  timesteps_this_iter: 3000
  timesteps_total: 6000
  training_iteration: 2
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 32 s, 2 iter, 6000 ts, 311 rew

[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
agent-1: 44.0
agent-2: 139.0
agent-3: 144.0
Sum Reward: 327.0
Avg Reward: 109.0
Min Reward: 44.0
Max Reward: 144.0
Gini Coefficient: 0.2038735983690112
20:20 Ratio: 3.272727272727273
Max-min Ratio: 3.272727272727273
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-09-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 327.0
  episode_reward_mean: 319.0
  episode_reward_min: 311.0
  episodes_this_iter: 1
  episodes_total: 2
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.87
    dispatch_time_ms: 10.448
    learner:
      cur_lr: 0.0013596004573628306
      grad_gnorm: 40.000030517578125
      policy_entropy: 37.15769577026367
      policy_loss: 49.138641357421875
      var_gnorm: 18.352651596069336
      vf_explained_var: 0.4619484543800354
      vf_loss: 47.148189544677734
    num_steps_sampled: 9000
    num_steps_trained: 9000
    wait_time_ms: 63.783
  iterations_since_restore: 3
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 40.708582162857056
  time_this_iter_s: 7.956935167312622
  time_total_s: 40.708582162857056
  timestamp: 1594087794
  timesteps_since_restore: 9000
  timesteps_this_iter: 3000
  timesteps_total: 9000
  training_iteration: 3
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 40 s, 3 iter, 9000 ts, 319 rew

agent-1: 201.0
agent-2: 202.0
agent-3: 192.0
Sum Reward: 595.0
Avg Reward: 198.33333333333334
Min Reward: 192.0
Max Reward: 202.0
Gini Coefficient: 0.011204481792717087
20:20 Ratio: 1.0520833333333333
Max-min Ratio: 1.0520833333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-10-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 595.0
  episode_reward_mean: 411.0
  episode_reward_min: 311.0
  episodes_this_iter: 1
  episodes_total: 3
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.411
    dispatch_time_ms: 7.565
    learner:
      cur_lr: 0.0013594005722552538
      grad_gnorm: 39.999996185302734
      policy_entropy: 19.351930618286133
      policy_loss: 44.694759368896484
      var_gnorm: 18.58302116394043
      vf_explained_var: 0.1289847493171692
      vf_loss: 50.972103118896484
    num_steps_sampled: 12000
    num_steps_trained: 12000
    wait_time_ms: 67.877
  iterations_since_restore: 4
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 48.77302145957947
  time_this_iter_s: 8.064439296722412
  time_total_s: 48.77302145957947
  timestamp: 1594087802
  timesteps_since_restore: 12000
  timesteps_this_iter: 3000
  timesteps_total: 12000
  training_iteration: 4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 48 s, 4 iter, 12000 ts, 411 rew

agent-1: 163.0
agent-2: 175.0
agent-3: 205.0
Sum Reward: 543.0
Avg Reward: 181.0
Min Reward: 163.0
Max Reward: 205.0
Gini Coefficient: 0.05156537753222836
20:20 Ratio: 1.2576687116564418
Max-min Ratio: 1.2576687116564418
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-10-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 595.0
  episode_reward_mean: 444.0
  episode_reward_min: 311.0
  episodes_this_iter: 1
  episodes_total: 4
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.84
    dispatch_time_ms: 8.327
    learner:
      cur_lr: 0.0013592008035629988
      grad_gnorm: 40.0
      policy_entropy: 22.17780876159668
      policy_loss: -14.780449867248535
      var_gnorm: 18.769956588745117
      vf_explained_var: -0.0203322172164917
      vf_loss: 30.95149040222168
    num_steps_sampled: 15000
    num_steps_trained: 15000
    wait_time_ms: 71.343
  iterations_since_restore: 5
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 56.565853118896484
  time_this_iter_s: 7.792831659317017
  time_total_s: 56.565853118896484
  timestamp: 1594087810
  timesteps_since_restore: 15000
  timesteps_this_iter: 3000
  timesteps_total: 15000
  training_iteration: 5
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 56 s, 5 iter, 15000 ts, 444 rew

agent-1: 218.0
agent-2: 206.0
agent-3: 223.0
Sum Reward: 647.0
Avg Reward: 215.66666666666666
Min Reward: 206.0
Max Reward: 223.0
Gini Coefficient: 0.01751674394641937
20:20 Ratio: 1.0825242718446602
Max-min Ratio: 1.0825242718446602
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-10-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 647.0
  episode_reward_mean: 484.6
  episode_reward_min: 311.0
  episodes_this_iter: 1
  episodes_total: 5
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.572
    dispatch_time_ms: 6.103
    learner:
      cur_lr: 0.0013590010348707438
      grad_gnorm: 40.0
      policy_entropy: 25.035945892333984
      policy_loss: 21.181840896606445
      var_gnorm: 18.92542266845703
      vf_explained_var: -0.13456904888153076
      vf_loss: 32.51029586791992
    num_steps_sampled: 18000
    num_steps_trained: 18000
    wait_time_ms: 75.948
  iterations_since_restore: 6
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 64.74336051940918
  time_this_iter_s: 8.177507400512695
  time_total_s: 64.74336051940918
  timestamp: 1594087818
  timesteps_since_restore: 18000
  timesteps_this_iter: 3000
  timesteps_total: 18000
  training_iteration: 6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 64 s, 6 iter, 18000 ts, 485 rew

agent-1: 235.0
agent-2: 249.0
agent-3: 228.0
Sum Reward: 712.0
Avg Reward: 237.33333333333334
Min Reward: 228.0
Max Reward: 249.0
Gini Coefficient: 0.019662921348314606
20:20 Ratio: 1.0921052631578947
Max-min Ratio: 1.0921052631578947
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-10-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 712.0
  episode_reward_mean: 522.5
  episode_reward_min: 311.0
  episodes_this_iter: 1
  episodes_total: 6
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.771
    dispatch_time_ms: 8.533
    learner:
      cur_lr: 0.001358801149763167
      grad_gnorm: 40.00002670288086
      policy_entropy: 32.74671173095703
      policy_loss: -24.857833862304688
      var_gnorm: 19.076250076293945
      vf_explained_var: 0.519351601600647
      vf_loss: 15.981760025024414
    num_steps_sampled: 21000
    num_steps_trained: 21000
    wait_time_ms: 71.392
  iterations_since_restore: 7
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 72.42678761482239
  time_this_iter_s: 7.683427095413208
  time_total_s: 72.42678761482239
  timestamp: 1594087826
  timesteps_since_restore: 21000
  timesteps_this_iter: 3000
  timesteps_total: 21000
  training_iteration: 7
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 72 s, 7 iter, 21000 ts, 522 rew

agent-1: 184.0
agent-2: 215.0
agent-3: 210.0
Sum Reward: 609.0
Avg Reward: 203.0
Min Reward: 184.0
Max Reward: 215.0
Gini Coefficient: 0.03393541324575807
20:20 Ratio: 1.1684782608695652
Max-min Ratio: 1.1684782608695652
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-10-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 712.0
  episode_reward_mean: 534.8571428571429
  episode_reward_min: 311.0
  episodes_this_iter: 1
  episodes_total: 7
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.751
    dispatch_time_ms: 6.751
    learner:
      cur_lr: 0.0013586013810709119
      grad_gnorm: 39.999969482421875
      policy_entropy: 29.021013259887695
      policy_loss: 8.40382194519043
      var_gnorm: 19.300928115844727
      vf_explained_var: 0.46237897872924805
      vf_loss: 62.20768737792969
    num_steps_sampled: 24000
    num_steps_trained: 24000
    wait_time_ms: 66.938
  iterations_since_restore: 8
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 80.44853353500366
  time_this_iter_s: 8.021745920181274
  time_total_s: 80.44853353500366
  timestamp: 1594087834
  timesteps_since_restore: 24000
  timesteps_this_iter: 3000
  timesteps_total: 24000
  training_iteration: 8
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 80 s, 8 iter, 24000 ts, 535 rew

agent-1: 221.0
agent-2: 235.0
agent-3: 207.0
Sum Reward: 663.0
Avg Reward: 221.0
Min Reward: 207.0
Max Reward: 235.0
Gini Coefficient: 0.02815485168426345
20:20 Ratio: 1.1352657004830917
Max-min Ratio: 1.1352657004830917
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-10-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 712.0
  episode_reward_mean: 550.875
  episode_reward_min: 311.0
  episodes_this_iter: 1
  episodes_total: 8
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.585
    dispatch_time_ms: 6.871
    learner:
      cur_lr: 0.0013584016123786569
      grad_gnorm: 39.99998474121094
      policy_entropy: 26.733348846435547
      policy_loss: -19.73422622680664
      var_gnorm: 19.51181411743164
      vf_explained_var: -1.0
      vf_loss: 21.84832763671875
    num_steps_sampled: 27000
    num_steps_trained: 27000
    wait_time_ms: 77.662
  iterations_since_restore: 9
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 88.59229493141174
  time_this_iter_s: 8.143761396408081
  time_total_s: 88.59229493141174
  timestamp: 1594087842
  timesteps_since_restore: 27000
  timesteps_this_iter: 3000
  timesteps_total: 27000
  training_iteration: 9
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 88 s, 9 iter, 27000 ts, 551 rew

agent-1: 265.0
agent-2: 235.0
agent-3: 227.0
Sum Reward: 727.0
Avg Reward: 242.33333333333334
Min Reward: 227.0
Max Reward: 265.0
Gini Coefficient: 0.03484640073360844
20:20 Ratio: 1.1674008810572687
Max-min Ratio: 1.1674008810572687
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-10-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 727.0
  episode_reward_mean: 570.4444444444445
  episode_reward_min: 311.0
  episodes_this_iter: 1
  episodes_total: 9
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.854
    dispatch_time_ms: 8.817
    learner:
      cur_lr: 0.0013582018436864018
      grad_gnorm: 39.9999885559082
      policy_entropy: 23.323284149169922
      policy_loss: -8.677176475524902
      var_gnorm: 19.703020095825195
      vf_explained_var: 0.5337295532226562
      vf_loss: 35.961429595947266
    num_steps_sampled: 30000
    num_steps_trained: 30000
    wait_time_ms: 62.759
  iterations_since_restore: 10
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 96.74704790115356
  time_this_iter_s: 8.154752969741821
  time_total_s: 96.74704790115356
  timestamp: 1594087850
  timesteps_since_restore: 30000
  timesteps_this_iter: 3000
  timesteps_total: 30000
  training_iteration: 10
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 96 s, 10 iter, 30000 ts, 570 rew

agent-1: 270.0
agent-2: 245.0
agent-3: 270.0
Sum Reward: 785.0
Avg Reward: 261.6666666666667
Min Reward: 245.0
Max Reward: 270.0
Gini Coefficient: 0.021231422505307854
20:20 Ratio: 1.1020408163265305
Max-min Ratio: 1.1020408163265305
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-10-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 785.0
  episode_reward_mean: 591.9
  episode_reward_min: 311.0
  episodes_this_iter: 1
  episodes_total: 10
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.56
    dispatch_time_ms: 7.84
    learner:
      cur_lr: 0.001358001958578825
      grad_gnorm: 40.00001525878906
      policy_entropy: 27.308727264404297
      policy_loss: -17.84676742553711
      var_gnorm: 20.242597579956055
      vf_explained_var: 0.5510272979736328
      vf_loss: 13.03414535522461
    num_steps_sampled: 33000
    num_steps_trained: 33000
    wait_time_ms: 64.145
  iterations_since_restore: 11
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 104.16307282447815
  time_this_iter_s: 7.416024923324585
  time_total_s: 104.16307282447815
  timestamp: 1594087857
  timesteps_since_restore: 33000
  timesteps_this_iter: 3000
  timesteps_total: 33000
  training_iteration: 11
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 104 s, 11 iter, 33000 ts, 592 rew

agent-1: 206.0
agent-2: 150.0
agent-3: 191.0
Sum Reward: 547.0
Avg Reward: 182.33333333333334
Min Reward: 150.0
Max Reward: 206.0
Gini Coefficient: 0.06825106642291286
20:20 Ratio: 1.3733333333333333
Max-min Ratio: 1.3733333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-11-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 785.0
  episode_reward_mean: 587.8181818181819
  episode_reward_min: 311.0
  episodes_this_iter: 1
  episodes_total: 11
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 4.145
    dispatch_time_ms: 8.663
    learner:
      cur_lr: 0.00135780218988657
      grad_gnorm: 39.99999237060547
      policy_entropy: 30.724098205566406
      policy_loss: -10.93812084197998
      var_gnorm: 20.411006927490234
      vf_explained_var: -0.1750504970550537
      vf_loss: 10.10816478729248
    num_steps_sampled: 36000
    num_steps_trained: 36000
    wait_time_ms: 63.425
  iterations_since_restore: 12
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 112.03023672103882
  time_this_iter_s: 7.867163896560669
  time_total_s: 112.03023672103882
  timestamp: 1594087865
  timesteps_since_restore: 36000
  timesteps_this_iter: 3000
  timesteps_total: 36000
  training_iteration: 12
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 112 s, 12 iter, 36000 ts, 588 rew

agent-1: 177.0
agent-2: 185.0
agent-3: 143.0
Sum Reward: 505.0
Avg Reward: 168.33333333333334
Min Reward: 143.0
Max Reward: 185.0
Gini Coefficient: 0.055445544554455446
20:20 Ratio: 1.2937062937062938
Max-min Ratio: 1.2937062937062938
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-11-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 785.0
  episode_reward_mean: 580.9166666666666
  episode_reward_min: 311.0
  episodes_this_iter: 1
  episodes_total: 12
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.664
    dispatch_time_ms: 7.49
    learner:
      cur_lr: 0.001357602421194315
      grad_gnorm: 40.0
      policy_entropy: 24.89741325378418
      policy_loss: 35.654205322265625
      var_gnorm: 20.56664276123047
      vf_explained_var: 0.26872700452804565
      vf_loss: 50.63254165649414
    num_steps_sampled: 39000
    num_steps_trained: 39000
    wait_time_ms: 67.114
  iterations_since_restore: 13
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 119.54166150093079
  time_this_iter_s: 7.511424779891968
  time_total_s: 119.54166150093079
  timestamp: 1594087873
  timesteps_since_restore: 39000
  timesteps_this_iter: 3000
  timesteps_total: 39000
  training_iteration: 13
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 119 s, 13 iter, 39000 ts, 581 rew

agent-1: 230.0
agent-2: 297.0
agent-3: 229.0
Sum Reward: 756.0
Avg Reward: 252.0
Min Reward: 229.0
Max Reward: 297.0
Gini Coefficient: 0.059964726631393295
20:20 Ratio: 1.296943231441048
Max-min Ratio: 1.296943231441048
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-11-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 785.0
  episode_reward_mean: 594.3846153846154
  episode_reward_min: 311.0
  episodes_this_iter: 1
  episodes_total: 13
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.61
    dispatch_time_ms: 8.913
    learner:
      cur_lr: 0.00135740265250206
      grad_gnorm: 40.00002670288086
      policy_entropy: 13.796972274780273
      policy_loss: 3.2019028663635254
      var_gnorm: 20.760173797607422
      vf_explained_var: 0.20753854513168335
      vf_loss: 23.415000915527344
    num_steps_sampled: 42000
    num_steps_trained: 42000
    wait_time_ms: 63.65
  iterations_since_restore: 14
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 127.77003812789917
  time_this_iter_s: 8.228376626968384
  time_total_s: 127.77003812789917
  timestamp: 1594087881
  timesteps_since_restore: 42000
  timesteps_this_iter: 3000
  timesteps_total: 42000
  training_iteration: 14
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 127 s, 14 iter, 42000 ts, 594 rew

agent-1: 252.0
agent-2: 267.0
agent-3: 298.0
Sum Reward: 817.0
Avg Reward: 272.3333333333333
Min Reward: 252.0
Max Reward: 298.0
Gini Coefficient: 0.037535699714402286
20:20 Ratio: 1.1825396825396826
Max-min Ratio: 1.1825396825396826
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-11-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 817.0
  episode_reward_mean: 610.2857142857143
  episode_reward_min: 311.0
  episodes_this_iter: 1
  episodes_total: 14
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.532
    dispatch_time_ms: 9.427
    learner:
      cur_lr: 0.001357202767394483
      grad_gnorm: 40.0
      policy_entropy: 12.326018333435059
      policy_loss: 37.1181526184082
      var_gnorm: 20.906421661376953
      vf_explained_var: 0.26648247241973877
      vf_loss: 35.855712890625
    num_steps_sampled: 45000
    num_steps_trained: 45000
    wait_time_ms: 72.473
  iterations_since_restore: 15
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 135.79750752449036
  time_this_iter_s: 8.027469396591187
  time_total_s: 135.79750752449036
  timestamp: 1594087889
  timesteps_since_restore: 45000
  timesteps_this_iter: 3000
  timesteps_total: 45000
  training_iteration: 15
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 135 s, 15 iter, 45000 ts, 610 rew

agent-1: 295.0
agent-2: 329.0
agent-3: 320.0
Sum Reward: 944.0
Avg Reward: 314.6666666666667
Min Reward: 295.0
Max Reward: 329.0
Gini Coefficient: 0.02401129943502825
20:20 Ratio: 1.1152542372881356
Max-min Ratio: 1.1152542372881356
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-11-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 944.0
  episode_reward_mean: 632.5333333333333
  episode_reward_min: 311.0
  episodes_this_iter: 1
  episodes_total: 15
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.452
    dispatch_time_ms: 7.244
    learner:
      cur_lr: 0.001357002998702228
      grad_gnorm: 39.99999237060547
      policy_entropy: 19.276657104492188
      policy_loss: -16.521631240844727
      var_gnorm: 21.060060501098633
      vf_explained_var: 0.035189151763916016
      vf_loss: 17.537038803100586
    num_steps_sampled: 48000
    num_steps_trained: 48000
    wait_time_ms: 75.748
  iterations_since_restore: 16
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 144.2138180732727
  time_this_iter_s: 8.416310548782349
  time_total_s: 144.2138180732727
  timestamp: 1594087898
  timesteps_since_restore: 48000
  timesteps_this_iter: 3000
  timesteps_total: 48000
  training_iteration: 16
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 144 s, 16 iter, 48000 ts, 633 rew

agent-1: 335.0
agent-2: 317.0
agent-3: 310.0
Sum Reward: 962.0
Avg Reward: 320.6666666666667
Min Reward: 310.0
Max Reward: 335.0
Gini Coefficient: 0.017325017325017324
20:20 Ratio: 1.0806451612903225
Max-min Ratio: 1.0806451612903225
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-11-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 962.0
  episode_reward_mean: 653.125
  episode_reward_min: 311.0
  episodes_this_iter: 1
  episodes_total: 16
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.663
    dispatch_time_ms: 5.962
    learner:
      cur_lr: 0.001356803230009973
      grad_gnorm: 39.999996185302734
      policy_entropy: 7.584412574768066
      policy_loss: 5.388242721557617
      var_gnorm: 21.263715744018555
      vf_explained_var: -1.0
      vf_loss: 38.69069290161133
    num_steps_sampled: 51000
    num_steps_trained: 51000
    wait_time_ms: 72.677
  iterations_since_restore: 17
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 152.1414978504181
  time_this_iter_s: 7.927679777145386
  time_total_s: 152.1414978504181
  timestamp: 1594087906
  timesteps_since_restore: 51000
  timesteps_this_iter: 3000
  timesteps_total: 51000
  training_iteration: 17
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 152 s, 17 iter, 51000 ts, 653 rew

agent-1: 314.0
agent-2: 340.0
agent-3: 327.0
Sum Reward: 981.0
Avg Reward: 327.0
Min Reward: 314.0
Max Reward: 340.0
Gini Coefficient: 0.01766904519198097
20:20 Ratio: 1.0828025477707006
Max-min Ratio: 1.0828025477707006
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-11-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 981.0
  episode_reward_mean: 672.4117647058823
  episode_reward_min: 311.0
  episodes_this_iter: 1
  episodes_total: 17
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.476
    dispatch_time_ms: 7.167
    learner:
      cur_lr: 0.0013566033449023962
      grad_gnorm: 40.00000762939453
      policy_entropy: 10.605204582214355
      policy_loss: 3.764881134033203
      var_gnorm: 21.366151809692383
      vf_explained_var: 0.0796242356300354
      vf_loss: 13.417505264282227
    num_steps_sampled: 54000
    num_steps_trained: 54000
    wait_time_ms: 65.256
  iterations_since_restore: 18
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 160.3931667804718
  time_this_iter_s: 8.251668930053711
  time_total_s: 160.3931667804718
  timestamp: 1594087914
  timesteps_since_restore: 54000
  timesteps_this_iter: 3000
  timesteps_total: 54000
  training_iteration: 18
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 160 s, 18 iter, 54000 ts, 672 rew

agent-1: 328.0
agent-2: 332.0
agent-3: 332.0
Sum Reward: 992.0
Avg Reward: 330.6666666666667
Min Reward: 328.0
Max Reward: 332.0
Gini Coefficient: 0.002688172043010753
20:20 Ratio: 1.0121951219512195
Max-min Ratio: 1.0121951219512195
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-12-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 690.1666666666666
  episode_reward_min: 311.0
  episodes_this_iter: 1
  episodes_total: 18
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.069
    dispatch_time_ms: 8.174
    learner:
      cur_lr: 0.0013564035762101412
      grad_gnorm: 39.999996185302734
      policy_entropy: 9.489912033081055
      policy_loss: -5.529305934906006
      var_gnorm: 21.478458404541016
      vf_explained_var: 0.32624751329421997
      vf_loss: 51.84635543823242
    num_steps_sampled: 57000
    num_steps_trained: 57000
    wait_time_ms: 66.16
  iterations_since_restore: 19
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 168.2203848361969
  time_this_iter_s: 7.827218055725098
  time_total_s: 168.2203848361969
  timestamp: 1594087922
  timesteps_since_restore: 57000
  timesteps_this_iter: 3000
  timesteps_total: 57000
  training_iteration: 19
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 168 s, 19 iter, 57000 ts, 690 rew

agent-1: 116.0
agent-2: 355.0
agent-3: 268.0
Sum Reward: 739.0
Avg Reward: 246.33333333333334
Min Reward: 116.0
Max Reward: 355.0
Gini Coefficient: 0.21560667568786648
20:20 Ratio: 3.060344827586207
Max-min Ratio: 3.060344827586207
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-12-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 692.7368421052631
  episode_reward_min: 311.0
  episodes_this_iter: 1
  episodes_total: 19
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.831
    dispatch_time_ms: 8.081
    learner:
      cur_lr: 0.0013562038075178862
      grad_gnorm: 40.00000762939453
      policy_entropy: 11.074398040771484
      policy_loss: 1.0252318382263184
      var_gnorm: 21.556991577148438
      vf_explained_var: 0.7504070401191711
      vf_loss: 93.89388275146484
    num_steps_sampled: 60000
    num_steps_trained: 60000
    wait_time_ms: 66.456
  iterations_since_restore: 20
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 175.96061444282532
  time_this_iter_s: 7.740229606628418
  time_total_s: 175.96061444282532
  timestamp: 1594087930
  timesteps_since_restore: 60000
  timesteps_this_iter: 3000
  timesteps_total: 60000
  training_iteration: 20
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 175 s, 20 iter, 60000 ts, 693 rew

agent-1: 204.0
agent-2: 289.0
agent-3: 307.0
Sum Reward: 800.0
Avg Reward: 266.6666666666667
Min Reward: 204.0
Max Reward: 307.0
Gini Coefficient: 0.08583333333333333
20:20 Ratio: 1.5049019607843137
Max-min Ratio: 1.5049019607843137
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-12-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 698.1
  episode_reward_min: 311.0
  episodes_this_iter: 1
  episodes_total: 20
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.502
    dispatch_time_ms: 9.776
    learner:
      cur_lr: 0.0013560040388256311
      grad_gnorm: 40.0
      policy_entropy: 47.167823791503906
      policy_loss: 45.43073272705078
      var_gnorm: 21.794740676879883
      vf_explained_var: 0.0026186108589172363
      vf_loss: 30.25420379638672
    num_steps_sampled: 63000
    num_steps_trained: 63000
    wait_time_ms: 59.238
  iterations_since_restore: 21
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 182.65127086639404
  time_this_iter_s: 6.690656423568726
  time_total_s: 182.65127086639404
  timestamp: 1594087936
  timesteps_since_restore: 63000
  timesteps_this_iter: 3000
  timesteps_total: 63000
  training_iteration: 21
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 182 s, 21 iter, 63000 ts, 698 rew

agent-1: 41.0
agent-2: 39.0
agent-3: 48.0
Sum Reward: 128.0
Avg Reward: 42.666666666666664
Min Reward: 39.0
Max Reward: 48.0
Gini Coefficient: 0.046875
20:20 Ratio: 1.2307692307692308
Max-min Ratio: 1.2307692307692308
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-12-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 670.952380952381
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 21
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.7
    dispatch_time_ms: 9.089
    learner:
      cur_lr: 0.0013558041537180543
      grad_gnorm: 21.406185150146484
      policy_entropy: 2.528607130050659
      policy_loss: -1.8739110231399536
      var_gnorm: 21.817541122436523
      vf_explained_var: 0.6425988674163818
      vf_loss: 1.0844309329986572
    num_steps_sampled: 66000
    num_steps_trained: 66000
    wait_time_ms: 58.044
  iterations_since_restore: 22
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 189.7442262172699
  time_this_iter_s: 7.0929553508758545
  time_total_s: 189.7442262172699
  timestamp: 1594087943
  timesteps_since_restore: 66000
  timesteps_this_iter: 3000
  timesteps_total: 66000
  training_iteration: 22
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 189 s, 22 iter, 66000 ts, 671 rew

agent-1: 33.0
agent-2: 44.0
agent-3: 63.0
Sum Reward: 140.0
Avg Reward: 46.666666666666664
Min Reward: 33.0
Max Reward: 63.0
Gini Coefficient: 0.14285714285714285
20:20 Ratio: 1.9090909090909092
Max-min Ratio: 1.9090909090909092
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-12-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 646.8181818181819
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 22
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.366
    dispatch_time_ms: 9.907
    learner:
      cur_lr: 0.0013556043850257993
      grad_gnorm: 40.000003814697266
      policy_entropy: 12.992804527282715
      policy_loss: 27.343923568725586
      var_gnorm: 21.807825088500977
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 45.748775482177734
    num_steps_sampled: 69000
    num_steps_trained: 69000
    wait_time_ms: 61.674
  iterations_since_restore: 23
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 196.79516077041626
  time_this_iter_s: 7.050934553146362
  time_total_s: 196.79516077041626
  timestamp: 1594087950
  timesteps_since_restore: 69000
  timesteps_this_iter: 3000
  timesteps_total: 69000
  training_iteration: 23
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 196 s, 23 iter, 69000 ts, 647 rew

agent-1: 123.0
agent-2: 65.0
agent-3: 74.0
Sum Reward: 262.0
Avg Reward: 87.33333333333333
Min Reward: 65.0
Max Reward: 123.0
Gini Coefficient: 0.1475826972010178
20:20 Ratio: 1.8923076923076922
Max-min Ratio: 1.8923076923076922
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-12-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 630.0869565217391
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 23
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.492
    dispatch_time_ms: 6.265
    learner:
      cur_lr: 0.0013554046163335443
      grad_gnorm: 40.0
      policy_entropy: 15.000494003295898
      policy_loss: 3.2643179893493652
      var_gnorm: 21.842247009277344
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 73.90058898925781
    num_steps_sampled: 72000
    num_steps_trained: 72000
    wait_time_ms: 69.146
  iterations_since_restore: 24
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 204.16064357757568
  time_this_iter_s: 7.365482807159424
  time_total_s: 204.16064357757568
  timestamp: 1594087958
  timesteps_since_restore: 72000
  timesteps_this_iter: 3000
  timesteps_total: 72000
  training_iteration: 24
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 204 s, 24 iter, 72000 ts, 630 rew

agent-1: 68.0
agent-2: 135.0
agent-3: 104.0
Sum Reward: 307.0
Avg Reward: 102.33333333333333
Min Reward: 68.0
Max Reward: 135.0
Gini Coefficient: 0.1454940282301846
20:20 Ratio: 1.9852941176470589
Max-min Ratio: 1.9852941176470589
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-12-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 616.625
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 24
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.284
    dispatch_time_ms: 6.206
    learner:
      cur_lr: 0.0013552048476412892
      grad_gnorm: 10.030684471130371
      policy_entropy: 19.88611602783203
      policy_loss: 0.167283296585083
      var_gnorm: 21.899925231933594
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 9.611917495727539
    num_steps_sampled: 75000
    num_steps_trained: 75000
    wait_time_ms: 74.814
  iterations_since_restore: 25
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 211.72315764427185
  time_this_iter_s: 7.562514066696167
  time_total_s: 211.72315764427185
  timestamp: 1594087965
  timesteps_since_restore: 75000
  timesteps_this_iter: 3000
  timesteps_total: 75000
  training_iteration: 25
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 211 s, 25 iter, 75000 ts, 617 rew

agent-1: 115.0
agent-2: 154.0
agent-3: 127.0
Sum Reward: 396.0
Avg Reward: 132.0
Min Reward: 115.0
Max Reward: 154.0
Gini Coefficient: 0.06565656565656566
20:20 Ratio: 1.3391304347826087
Max-min Ratio: 1.3391304347826087
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-12-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 607.8
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 25
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.56
    dispatch_time_ms: 6.163
    learner:
      cur_lr: 0.0013550049625337124
      grad_gnorm: 40.0
      policy_entropy: 6.617016792297363
      policy_loss: -0.6953895092010498
      var_gnorm: 21.87204360961914
      vf_explained_var: 0.0
      vf_loss: 5.982808589935303
    num_steps_sampled: 78000
    num_steps_trained: 78000
    wait_time_ms: 64.415
  iterations_since_restore: 26
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 219.19892239570618
  time_this_iter_s: 7.475764751434326
  time_total_s: 219.19892239570618
  timestamp: 1594087973
  timesteps_since_restore: 78000
  timesteps_this_iter: 3000
  timesteps_total: 78000
  training_iteration: 26
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 219 s, 26 iter, 78000 ts, 608 rew

agent-1: 138.0
agent-2: 128.0
agent-3: 95.0
Sum Reward: 361.0
Avg Reward: 120.33333333333333
Min Reward: 95.0
Max Reward: 138.0
Gini Coefficient: 0.07940904893813482
20:20 Ratio: 1.4526315789473685
Max-min Ratio: 1.4526315789473685
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-13-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 598.3076923076923
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 26
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.974
    dispatch_time_ms: 8.429
    learner:
      cur_lr: 0.0013548051938414574
      grad_gnorm: 32.62826919555664
      policy_entropy: 13.653797149658203
      policy_loss: -3.9757561683654785
      var_gnorm: 21.828710556030273
      vf_explained_var: 0.0
      vf_loss: 2.603971481323242
    num_steps_sampled: 81000
    num_steps_trained: 81000
    wait_time_ms: 57.615
  iterations_since_restore: 27
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 226.40083074569702
  time_this_iter_s: 7.201908349990845
  time_total_s: 226.40083074569702
  timestamp: 1594087980
  timesteps_since_restore: 81000
  timesteps_this_iter: 3000
  timesteps_total: 81000
  training_iteration: 27
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 226 s, 27 iter, 81000 ts, 598 rew

agent-1: 59.0
agent-2: 104.0
agent-3: 86.0
Sum Reward: 249.0
Avg Reward: 83.0
Min Reward: 59.0
Max Reward: 104.0
Gini Coefficient: 0.12048192771084337
20:20 Ratio: 1.7627118644067796
Max-min Ratio: 1.7627118644067796
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-13-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 585.3703703703703
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 27
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.487
    dispatch_time_ms: 6.242
    learner:
      cur_lr: 0.0013546054251492023
      grad_gnorm: 36.94732666015625
      policy_entropy: 14.472461700439453
      policy_loss: 6.248348712921143
      var_gnorm: 21.85363006591797
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 29.86499786376953
    num_steps_sampled: 84000
    num_steps_trained: 84000
    wait_time_ms: 70.84
  iterations_since_restore: 28
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 233.8813772201538
  time_this_iter_s: 7.480546474456787
  time_total_s: 233.8813772201538
  timestamp: 1594087988
  timesteps_since_restore: 84000
  timesteps_this_iter: 3000
  timesteps_total: 84000
  training_iteration: 28
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 233 s, 28 iter, 84000 ts, 585 rew

agent-1: 134.0
agent-2: 101.0
agent-3: 87.0
Sum Reward: 322.0
Avg Reward: 107.33333333333333
Min Reward: 87.0
Max Reward: 134.0
Gini Coefficient: 0.09730848861283643
20:20 Ratio: 1.5402298850574712
Max-min Ratio: 1.5402298850574712
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-13-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 575.9642857142857
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 28
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.394
    dispatch_time_ms: 8.706
    learner:
      cur_lr: 0.0013544056564569473
      grad_gnorm: 39.999996185302734
      policy_entropy: 25.282127380371094
      policy_loss: 12.848471641540527
      var_gnorm: 21.87009620666504
      vf_explained_var: 0.0
      vf_loss: 22.392974853515625
    num_steps_sampled: 87000
    num_steps_trained: 87000
    wait_time_ms: 63.093
  iterations_since_restore: 29
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 241.216002702713
  time_this_iter_s: 7.334625482559204
  time_total_s: 241.216002702713
  timestamp: 1594087995
  timesteps_since_restore: 87000
  timesteps_this_iter: 3000
  timesteps_total: 87000
  training_iteration: 29
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 241 s, 29 iter, 87000 ts, 576 rew

agent-1: 127.0
agent-2: 168.0
agent-3: 155.0
Sum Reward: 450.0
Avg Reward: 150.0
Min Reward: 127.0
Max Reward: 168.0
Gini Coefficient: 0.06074074074074074
20:20 Ratio: 1.3228346456692914
Max-min Ratio: 1.3228346456692914
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-13-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 571.6206896551724
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 29
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.053
    dispatch_time_ms: 6.293
    learner:
      cur_lr: 0.0013542057713493705
      grad_gnorm: 35.9734992980957
      policy_entropy: 19.12395668029785
      policy_loss: -2.200817584991455
      var_gnorm: 21.895898818969727
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 7.4630842208862305
    num_steps_sampled: 90000
    num_steps_trained: 90000
    wait_time_ms: 61.134
  iterations_since_restore: 30
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 248.72523856163025
  time_this_iter_s: 7.509235858917236
  time_total_s: 248.72523856163025
  timestamp: 1594088003
  timesteps_since_restore: 90000
  timesteps_this_iter: 3000
  timesteps_total: 90000
  training_iteration: 30
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 248 s, 30 iter, 90000 ts, 572 rew

agent-1: 115.0
agent-2: 154.0
agent-3: 147.0
Sum Reward: 416.0
Avg Reward: 138.66666666666666
Min Reward: 115.0
Max Reward: 154.0
Gini Coefficient: 0.0625
20:20 Ratio: 1.3391304347826087
Max-min Ratio: 1.3391304347826087
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-13-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 566.4333333333333
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 30
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.418
    dispatch_time_ms: 8.098
    learner:
      cur_lr: 0.0013540060026571155
      grad_gnorm: 9.789833068847656
      policy_entropy: 12.535320281982422
      policy_loss: 0.49331754446029663
      var_gnorm: 21.938257217407227
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 6.956083297729492
    num_steps_sampled: 93000
    num_steps_trained: 93000
    wait_time_ms: 65.091
  iterations_since_restore: 31
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 256.2069990634918
  time_this_iter_s: 7.481760501861572
  time_total_s: 256.2069990634918
  timestamp: 1594088010
  timesteps_since_restore: 93000
  timesteps_this_iter: 3000
  timesteps_total: 93000
  training_iteration: 31
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 256 s, 31 iter, 93000 ts, 566 rew

agent-1: 152.0
agent-2: 148.0
agent-3: 201.0
Sum Reward: 501.0
Avg Reward: 167.0
Min Reward: 148.0
Max Reward: 201.0
Gini Coefficient: 0.07052561543579508
20:20 Ratio: 1.3581081081081081
Max-min Ratio: 1.3581081081081081
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-13-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 564.3225806451613
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 31
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.574
    dispatch_time_ms: 8.566
    learner:
      cur_lr: 0.0013538062339648604
      grad_gnorm: 15.45306396484375
      policy_entropy: 20.56262969970703
      policy_loss: -1.3584551811218262
      var_gnorm: 21.9431209564209
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 31.018569946289062
    num_steps_sampled: 96000
    num_steps_trained: 96000
    wait_time_ms: 67.614
  iterations_since_restore: 32
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 263.71450114250183
  time_this_iter_s: 7.50750207901001
  time_total_s: 263.71450114250183
  timestamp: 1594088018
  timesteps_since_restore: 96000
  timesteps_this_iter: 3000
  timesteps_total: 96000
  training_iteration: 32
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 263 s, 32 iter, 96000 ts, 564 rew

agent-1: 152.0
agent-2: 199.0
agent-3: 174.0
Sum Reward: 525.0
Avg Reward: 175.0
Min Reward: 152.0
Max Reward: 199.0
Gini Coefficient: 0.059682539682539684
20:20 Ratio: 1.3092105263157894
Max-min Ratio: 1.3092105263157894
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-13-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 563.09375
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 32
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.74
    dispatch_time_ms: 5.8
    learner:
      cur_lr: 0.0013536063488572836
      grad_gnorm: 40.000003814697266
      policy_entropy: 22.352771759033203
      policy_loss: 14.539449691772461
      var_gnorm: 21.972442626953125
      vf_explained_var: 0.0
      vf_loss: 27.054977416992188
    num_steps_sampled: 99000
    num_steps_trained: 99000
    wait_time_ms: 71.128
  iterations_since_restore: 33
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 271.24655508995056
  time_this_iter_s: 7.5320539474487305
  time_total_s: 271.24655508995056
  timestamp: 1594088025
  timesteps_since_restore: 99000
  timesteps_this_iter: 3000
  timesteps_total: 99000
  training_iteration: 33
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 271 s, 33 iter, 99000 ts, 563 rew

agent-1: 165.0
agent-2: 203.0
agent-3: 171.0
Sum Reward: 539.0
Avg Reward: 179.66666666666666
Min Reward: 165.0
Max Reward: 203.0
Gini Coefficient: 0.04700061842918986
20:20 Ratio: 1.2303030303030302
Max-min Ratio: 1.2303030303030302
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-13-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 562.3636363636364
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 33
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.98
    dispatch_time_ms: 8.229
    learner:
      cur_lr: 0.0013534065801650286
      grad_gnorm: 26.27750587463379
      policy_entropy: 23.749656677246094
      policy_loss: -5.775914669036865
      var_gnorm: 21.967018127441406
      vf_explained_var: 0.0
      vf_loss: 6.608571529388428
    num_steps_sampled: 102000
    num_steps_trained: 102000
    wait_time_ms: 67.456
  iterations_since_restore: 34
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 278.9497504234314
  time_this_iter_s: 7.703195333480835
  time_total_s: 278.9497504234314
  timestamp: 1594088033
  timesteps_since_restore: 102000
  timesteps_this_iter: 3000
  timesteps_total: 102000
  training_iteration: 34
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 278 s, 34 iter, 102000 ts, 562 rew

agent-1: 187.0
agent-2: 123.0
agent-3: 164.0
Sum Reward: 474.0
Avg Reward: 158.0
Min Reward: 123.0
Max Reward: 187.0
Gini Coefficient: 0.090014064697609
20:20 Ratio: 1.5203252032520325
Max-min Ratio: 1.5203252032520325
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-14-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 559.7647058823529
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 34
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.014
    dispatch_time_ms: 8.197
    learner:
      cur_lr: 0.0013532068114727736
      grad_gnorm: 40.0
      policy_entropy: 23.45045280456543
      policy_loss: -12.54836368560791
      var_gnorm: 21.932422637939453
      vf_explained_var: 0.0
      vf_loss: 9.771623611450195
    num_steps_sampled: 105000
    num_steps_trained: 105000
    wait_time_ms: 63.563
  iterations_since_restore: 35
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 286.3862781524658
  time_this_iter_s: 7.436527729034424
  time_total_s: 286.3862781524658
  timestamp: 1594088040
  timesteps_since_restore: 105000
  timesteps_this_iter: 3000
  timesteps_total: 105000
  training_iteration: 35
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 286 s, 35 iter, 105000 ts, 560 rew

agent-1: 137.0
agent-2: 123.0
agent-3: 156.0
Sum Reward: 416.0
Avg Reward: 138.66666666666666
Min Reward: 123.0
Max Reward: 156.0
Gini Coefficient: 0.052884615384615384
20:20 Ratio: 1.2682926829268293
Max-min Ratio: 1.2682926829268293
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-14-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 555.6571428571428
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 35
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.041
    dispatch_time_ms: 9.119
    learner:
      cur_lr: 0.0013530070427805185
      grad_gnorm: 40.0
      policy_entropy: 24.069782257080078
      policy_loss: 45.882728576660156
      var_gnorm: 21.927715301513672
      vf_explained_var: 0.0
      vf_loss: 92.8843002319336
    num_steps_sampled: 108000
    num_steps_trained: 108000
    wait_time_ms: 63.522
  iterations_since_restore: 36
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 293.88884139060974
  time_this_iter_s: 7.502563238143921
  time_total_s: 293.88884139060974
  timestamp: 1594088048
  timesteps_since_restore: 108000
  timesteps_this_iter: 3000
  timesteps_total: 108000
  training_iteration: 36
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 293 s, 36 iter, 108000 ts, 556 rew

agent-1: 103.0
agent-2: 109.0
agent-3: 174.0
Sum Reward: 386.0
Avg Reward: 128.66666666666666
Min Reward: 103.0
Max Reward: 174.0
Gini Coefficient: 0.1226252158894646
20:20 Ratio: 1.6893203883495145
Max-min Ratio: 1.6893203883495145
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-14-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 550.9444444444445
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 36
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.761
    dispatch_time_ms: 9.315
    learner:
      cur_lr: 0.0013528071576729417
      grad_gnorm: 40.0
      policy_entropy: 25.632558822631836
      policy_loss: 38.61427307128906
      var_gnorm: 21.92894172668457
      vf_explained_var: 0.0
      vf_loss: 68.81237030029297
    num_steps_sampled: 111000
    num_steps_trained: 111000
    wait_time_ms: 61.17
  iterations_since_restore: 37
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 301.29851484298706
  time_this_iter_s: 7.409673452377319
  time_total_s: 301.29851484298706
  timestamp: 1594088055
  timesteps_since_restore: 111000
  timesteps_this_iter: 3000
  timesteps_total: 111000
  training_iteration: 37
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 301 s, 37 iter, 111000 ts, 551 rew

agent-1: 231.0
agent-2: 118.0
agent-3: 108.0
Sum Reward: 457.0
Avg Reward: 152.33333333333334
Min Reward: 108.0
Max Reward: 231.0
Gini Coefficient: 0.17943107221006566
20:20 Ratio: 2.138888888888889
Max-min Ratio: 2.138888888888889
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-14-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 548.4054054054054
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 37
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.829
    dispatch_time_ms: 7.745
    learner:
      cur_lr: 0.0013526073889806867
      grad_gnorm: 10.673175811767578
      policy_entropy: 23.494243621826172
      policy_loss: 0.6358799934387207
      var_gnorm: 21.934846878051758
      vf_explained_var: -1.7881393432617188e-06
      vf_loss: 11.234017372131348
    num_steps_sampled: 114000
    num_steps_trained: 114000
    wait_time_ms: 61.491
  iterations_since_restore: 38
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 308.7684004306793
  time_this_iter_s: 7.469885587692261
  time_total_s: 308.7684004306793
  timestamp: 1594088063
  timesteps_since_restore: 114000
  timesteps_this_iter: 3000
  timesteps_total: 114000
  training_iteration: 38
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 308 s, 38 iter, 114000 ts, 548 rew

agent-1: 152.0
agent-2: 182.0
agent-3: 141.0
Sum Reward: 475.0
Avg Reward: 158.33333333333334
Min Reward: 141.0
Max Reward: 182.0
Gini Coefficient: 0.05754385964912281
20:20 Ratio: 1.2907801418439717
Max-min Ratio: 1.2907801418439717
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-14-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 546.4736842105264
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 38
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.572
    dispatch_time_ms: 9.8
    learner:
      cur_lr: 0.0013524076202884316
      grad_gnorm: 34.63497543334961
      policy_entropy: 20.67203140258789
      policy_loss: -8.526357650756836
      var_gnorm: 21.932918548583984
      vf_explained_var: 0.0
      vf_loss: 10.140936851501465
    num_steps_sampled: 117000
    num_steps_trained: 117000
    wait_time_ms: 61.483
  iterations_since_restore: 39
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 316.09734869003296
  time_this_iter_s: 7.328948259353638
  time_total_s: 316.09734869003296
  timestamp: 1594088070
  timesteps_since_restore: 117000
  timesteps_this_iter: 3000
  timesteps_total: 117000
  training_iteration: 39
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 316 s, 39 iter, 117000 ts, 546 rew

agent-1: 163.0
agent-2: 183.0
agent-3: 106.0
Sum Reward: 452.0
Avg Reward: 150.66666666666666
Min Reward: 106.0
Max Reward: 183.0
Gini Coefficient: 0.11356932153392331
20:20 Ratio: 1.7264150943396226
Max-min Ratio: 1.7264150943396226
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-14-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 544.0512820512821
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 39
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.825
    dispatch_time_ms: 6.093
    learner:
      cur_lr: 0.0013522078515961766
      grad_gnorm: 40.0
      policy_entropy: 15.580375671386719
      policy_loss: -4.765870094299316
      var_gnorm: 21.91862678527832
      vf_explained_var: 0.0
      vf_loss: 8.470791816711426
    num_steps_sampled: 120000
    num_steps_trained: 120000
    wait_time_ms: 69.082
  iterations_since_restore: 40
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 323.58992862701416
  time_this_iter_s: 7.492579936981201
  time_total_s: 323.58992862701416
  timestamp: 1594088078
  timesteps_since_restore: 120000
  timesteps_this_iter: 3000
  timesteps_total: 120000
  training_iteration: 40
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 323 s, 40 iter, 120000 ts, 544 rew

agent-1: 94.0
agent-2: 142.0
agent-3: 108.0
Sum Reward: 344.0
Avg Reward: 114.66666666666667
Min Reward: 94.0
Max Reward: 142.0
Gini Coefficient: 0.09302325581395349
20:20 Ratio: 1.5106382978723405
Max-min Ratio: 1.5106382978723405
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-14-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 539.05
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 40
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.642
    dispatch_time_ms: 7.093
    learner:
      cur_lr: 0.0013520079664885998
      grad_gnorm: 40.0
      policy_entropy: 20.395524978637695
      policy_loss: 31.216266632080078
      var_gnorm: 21.916091918945312
      vf_explained_var: 0.0
      vf_loss: 33.81663513183594
    num_steps_sampled: 123000
    num_steps_trained: 123000
    wait_time_ms: 66.142
  iterations_since_restore: 41
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 330.9785873889923
  time_this_iter_s: 7.388658761978149
  time_total_s: 330.9785873889923
  timestamp: 1594088085
  timesteps_since_restore: 123000
  timesteps_this_iter: 3000
  timesteps_total: 123000
  training_iteration: 41
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 330 s, 41 iter, 123000 ts, 539 rew

agent-1: 142.0
agent-2: 149.0
agent-3: 144.0
Sum Reward: 435.0
Avg Reward: 145.0
Min Reward: 142.0
Max Reward: 149.0
Gini Coefficient: 0.010727969348659003
20:20 Ratio: 1.0492957746478873
Max-min Ratio: 1.0492957746478873
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-14-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 536.5121951219512
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 41
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.135
    dispatch_time_ms: 8.797
    learner:
      cur_lr: 0.0013518081977963448
      grad_gnorm: 30.230480194091797
      policy_entropy: 14.98079776763916
      policy_loss: 0.9521230459213257
      var_gnorm: 21.913265228271484
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 9.489302635192871
    num_steps_sampled: 126000
    num_steps_trained: 126000
    wait_time_ms: 61.398
  iterations_since_restore: 42
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 338.5075659751892
  time_this_iter_s: 7.528978586196899
  time_total_s: 338.5075659751892
  timestamp: 1594088093
  timesteps_since_restore: 126000
  timesteps_this_iter: 3000
  timesteps_total: 126000
  training_iteration: 42
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 338 s, 42 iter, 126000 ts, 537 rew

agent-1: 110.0
agent-2: 151.0
agent-3: 143.0
Sum Reward: 404.0
Avg Reward: 134.66666666666666
Min Reward: 110.0
Max Reward: 151.0
Gini Coefficient: 0.06765676567656766
20:20 Ratio: 1.3727272727272728
Max-min Ratio: 1.3727272727272728
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-15-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 533.3571428571429
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 42
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.803
    dispatch_time_ms: 7.094
    learner:
      cur_lr: 0.0013516084291040897
      grad_gnorm: 40.000003814697266
      policy_entropy: 23.640064239501953
      policy_loss: 37.20439910888672
      var_gnorm: 21.918779373168945
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 87.77203369140625
    num_steps_sampled: 129000
    num_steps_trained: 129000
    wait_time_ms: 66.812
  iterations_since_restore: 43
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 345.94427585601807
  time_this_iter_s: 7.436709880828857
  time_total_s: 345.94427585601807
  timestamp: 1594088100
  timesteps_since_restore: 129000
  timesteps_this_iter: 3000
  timesteps_total: 129000
  training_iteration: 43
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 345 s, 43 iter, 129000 ts, 533 rew

agent-1: 185.0
agent-2: 198.0
agent-3: 135.0
Sum Reward: 518.0
Avg Reward: 172.66666666666666
Min Reward: 135.0
Max Reward: 198.0
Gini Coefficient: 0.08108108108108109
20:20 Ratio: 1.4666666666666666
Max-min Ratio: 1.4666666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-15-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 533.0
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 43
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.682
    dispatch_time_ms: 7.145
    learner:
      cur_lr: 0.0013514085439965129
      grad_gnorm: 11.756613731384277
      policy_entropy: 21.9219970703125
      policy_loss: -2.6581108570098877
      var_gnorm: 21.945707321166992
      vf_explained_var: 0.0
      vf_loss: 9.190886497497559
    num_steps_sampled: 132000
    num_steps_trained: 132000
    wait_time_ms: 63.967
  iterations_since_restore: 44
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 353.5875475406647
  time_this_iter_s: 7.6432716846466064
  time_total_s: 353.5875475406647
  timestamp: 1594088108
  timesteps_since_restore: 132000
  timesteps_this_iter: 3000
  timesteps_total: 132000
  training_iteration: 44
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 353 s, 44 iter, 132000 ts, 533 rew

agent-1: 138.0
agent-2: 155.0
agent-3: 192.0
Sum Reward: 485.0
Avg Reward: 161.66666666666666
Min Reward: 138.0
Max Reward: 192.0
Gini Coefficient: 0.07422680412371134
20:20 Ratio: 1.391304347826087
Max-min Ratio: 1.391304347826087
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-15-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 531.9090909090909
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 44
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.607
    dispatch_time_ms: 7.544
    learner:
      cur_lr: 0.0013512087753042579
      grad_gnorm: 40.000003814697266
      policy_entropy: 25.588655471801758
      policy_loss: -3.7330403327941895
      var_gnorm: 21.981182098388672
      vf_explained_var: 0.0
      vf_loss: 21.445505142211914
    num_steps_sampled: 135000
    num_steps_trained: 135000
    wait_time_ms: 72.324
  iterations_since_restore: 45
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 361.16853308677673
  time_this_iter_s: 7.5809855461120605
  time_total_s: 361.16853308677673
  timestamp: 1594088116
  timesteps_since_restore: 135000
  timesteps_this_iter: 3000
  timesteps_total: 135000
  training_iteration: 45
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 361 s, 45 iter, 135000 ts, 532 rew

agent-1: 175.0
agent-2: 223.0
agent-3: 192.0
Sum Reward: 590.0
Avg Reward: 196.66666666666666
Min Reward: 175.0
Max Reward: 223.0
Gini Coefficient: 0.05423728813559322
20:20 Ratio: 1.2742857142857142
Max-min Ratio: 1.2742857142857142
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-15-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 533.2
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 45
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.983
    dispatch_time_ms: 7.745
    learner:
      cur_lr: 0.0013510090066120028
      grad_gnorm: 40.0
      policy_entropy: 13.102394104003906
      policy_loss: -5.716203212738037
      var_gnorm: 22.001380920410156
      vf_explained_var: 0.0
      vf_loss: 11.185198783874512
    num_steps_sampled: 138000
    num_steps_trained: 138000
    wait_time_ms: 64.49
  iterations_since_restore: 46
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 369.154709815979
  time_this_iter_s: 7.9861767292022705
  time_total_s: 369.154709815979
  timestamp: 1594088124
  timesteps_since_restore: 138000
  timesteps_this_iter: 3000
  timesteps_total: 138000
  training_iteration: 46
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 369 s, 46 iter, 138000 ts, 533 rew

agent-1: 161.0
agent-2: 177.0
agent-3: 185.0
Sum Reward: 523.0
Avg Reward: 174.33333333333334
Min Reward: 161.0
Max Reward: 185.0
Gini Coefficient: 0.030592734225621414
20:20 Ratio: 1.1490683229813665
Max-min Ratio: 1.1490683229813665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-15-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 532.9782608695652
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 46
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.932
    dispatch_time_ms: 8.519
    learner:
      cur_lr: 0.0013508092379197478
      grad_gnorm: 29.059837341308594
      policy_entropy: 19.05857276916504
      policy_loss: 16.39086151123047
      var_gnorm: 21.986835479736328
      vf_explained_var: 0.0
      vf_loss: 33.358863830566406
    num_steps_sampled: 141000
    num_steps_trained: 141000
    wait_time_ms: 64.479
  iterations_since_restore: 47
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 376.5902998447418
  time_this_iter_s: 7.435590028762817
  time_total_s: 376.5902998447418
  timestamp: 1594088131
  timesteps_since_restore: 141000
  timesteps_this_iter: 3000
  timesteps_total: 141000
  training_iteration: 47
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 376 s, 47 iter, 141000 ts, 533 rew

agent-1: 209.0
agent-2: 103.0
agent-3: 155.0
Sum Reward: 467.0
Avg Reward: 155.66666666666666
Min Reward: 103.0
Max Reward: 209.0
Gini Coefficient: 0.15132048536759457
20:20 Ratio: 2.029126213592233
Max-min Ratio: 2.029126213592233
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-15-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 531.5744680851063
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 47
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.651
    dispatch_time_ms: 6.539
    learner:
      cur_lr: 0.001350609352812171
      grad_gnorm: 40.0
      policy_entropy: 20.02491569519043
      policy_loss: 7.48508882522583
      var_gnorm: 21.990081787109375
      vf_explained_var: -0.20116126537322998
      vf_loss: 34.35459899902344
    num_steps_sampled: 144000
    num_steps_trained: 144000
    wait_time_ms: 64.459
  iterations_since_restore: 48
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 384.1161892414093
  time_this_iter_s: 7.5258893966674805
  time_total_s: 384.1161892414093
  timestamp: 1594088139
  timesteps_since_restore: 144000
  timesteps_this_iter: 3000
  timesteps_total: 144000
  training_iteration: 48
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 384 s, 48 iter, 144000 ts, 532 rew

agent-1: 162.0
agent-2: 167.0
agent-3: 197.0
Sum Reward: 526.0
Avg Reward: 175.33333333333334
Min Reward: 162.0
Max Reward: 197.0
Gini Coefficient: 0.044359949302915085
20:20 Ratio: 1.2160493827160495
Max-min Ratio: 1.2160493827160495
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-15-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 531.4583333333334
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 48
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.81
    dispatch_time_ms: 8.893
    learner:
      cur_lr: 0.001350409584119916
      grad_gnorm: 40.0
      policy_entropy: 14.593060493469238
      policy_loss: -9.630374908447266
      var_gnorm: 21.99063491821289
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 12.743311882019043
    num_steps_sampled: 147000
    num_steps_trained: 147000
    wait_time_ms: 62.311
  iterations_since_restore: 49
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 391.6676344871521
  time_this_iter_s: 7.551445245742798
  time_total_s: 391.6676344871521
  timestamp: 1594088146
  timesteps_since_restore: 147000
  timesteps_this_iter: 3000
  timesteps_total: 147000
  training_iteration: 49
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 391 s, 49 iter, 147000 ts, 531 rew

agent-1: 134.0
agent-2: 122.0
agent-3: 174.0
Sum Reward: 430.0
Avg Reward: 143.33333333333334
Min Reward: 122.0
Max Reward: 174.0
Gini Coefficient: 0.08062015503875969
20:20 Ratio: 1.4262295081967213
Max-min Ratio: 1.4262295081967213
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-15-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 529.3877551020408
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 49
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.732
    dispatch_time_ms: 8.189
    learner:
      cur_lr: 0.001350209815427661
      grad_gnorm: 15.307098388671875
      policy_entropy: 22.958765029907227
      policy_loss: 2.020273447036743
      var_gnorm: 21.952064514160156
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 21.402677536010742
    num_steps_sampled: 150000
    num_steps_trained: 150000
    wait_time_ms: 67.031
  iterations_since_restore: 50
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 399.00155234336853
  time_this_iter_s: 7.333917856216431
  time_total_s: 399.00155234336853
  timestamp: 1594088153
  timesteps_since_restore: 150000
  timesteps_this_iter: 3000
  timesteps_total: 150000
  training_iteration: 50
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 399 s, 50 iter, 150000 ts, 529 rew

agent-1: 150.0
agent-2: 169.0
agent-3: 77.0
Sum Reward: 396.0
Avg Reward: 132.0
Min Reward: 77.0
Max Reward: 169.0
Gini Coefficient: 0.15488215488215487
20:20 Ratio: 2.1948051948051948
Max-min Ratio: 2.1948051948051948
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-16-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 526.72
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 50
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.986
    dispatch_time_ms: 11.939
    learner:
      cur_lr: 0.001350010046735406
      grad_gnorm: 40.0
      policy_entropy: 27.817649841308594
      policy_loss: 26.623693466186523
      var_gnorm: 21.975244522094727
      vf_explained_var: 0.0
      vf_loss: 47.51661682128906
    num_steps_sampled: 153000
    num_steps_trained: 153000
    wait_time_ms: 64.19
  iterations_since_restore: 51
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 406.56272649765015
  time_this_iter_s: 7.561174154281616
  time_total_s: 406.56272649765015
  timestamp: 1594088161
  timesteps_since_restore: 153000
  timesteps_this_iter: 3000
  timesteps_total: 153000
  training_iteration: 51
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 406 s, 51 iter, 153000 ts, 527 rew

agent-1: 187.0
agent-2: 165.0
agent-3: 132.0
Sum Reward: 484.0
Avg Reward: 161.33333333333334
Min Reward: 132.0
Max Reward: 187.0
Gini Coefficient: 0.07575757575757576
20:20 Ratio: 1.4166666666666667
Max-min Ratio: 1.4166666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-16-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 525.8823529411765
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 51
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.638
    dispatch_time_ms: 9.685
    learner:
      cur_lr: 0.001349810161627829
      grad_gnorm: 40.0
      policy_entropy: 25.676420211791992
      policy_loss: 37.808021545410156
      var_gnorm: 22.004714965820312
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 89.97425079345703
    num_steps_sampled: 156000
    num_steps_trained: 156000
    wait_time_ms: 62.682
  iterations_since_restore: 52
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 414.3663520812988
  time_this_iter_s: 7.803625583648682
  time_total_s: 414.3663520812988
  timestamp: 1594088169
  timesteps_since_restore: 156000
  timesteps_this_iter: 3000
  timesteps_total: 156000
  training_iteration: 52
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 414 s, 52 iter, 156000 ts, 526 rew

agent-1: 259.0
agent-2: 157.0
agent-3: 211.0
Sum Reward: 627.0
Avg Reward: 209.0
Min Reward: 157.0
Max Reward: 259.0
Gini Coefficient: 0.10845295055821372
20:20 Ratio: 1.6496815286624205
Max-min Ratio: 1.6496815286624205
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-16-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 527.8269230769231
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 52
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.377
    dispatch_time_ms: 11.038
    learner:
      cur_lr: 0.001349610392935574
      grad_gnorm: 39.999996185302734
      policy_entropy: 13.112106323242188
      policy_loss: -2.5773732662200928
      var_gnorm: 21.99016571044922
      vf_explained_var: 0.0
      vf_loss: 8.896330833435059
    num_steps_sampled: 159000
    num_steps_trained: 159000
    wait_time_ms: 61.236
  iterations_since_restore: 53
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 421.9601957798004
  time_this_iter_s: 7.593843698501587
  time_total_s: 421.9601957798004
  timestamp: 1594088177
  timesteps_since_restore: 159000
  timesteps_this_iter: 3000
  timesteps_total: 159000
  training_iteration: 53
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 421 s, 53 iter, 159000 ts, 528 rew

agent-1: 159.0
agent-2: 168.0
agent-3: 183.0
Sum Reward: 510.0
Avg Reward: 170.0
Min Reward: 159.0
Max Reward: 183.0
Gini Coefficient: 0.03137254901960784
20:20 Ratio: 1.150943396226415
Max-min Ratio: 1.150943396226415
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-16-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 527.4905660377359
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 53
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.006
    dispatch_time_ms: 9.216
    learner:
      cur_lr: 0.001349410624243319
      grad_gnorm: 34.54251480102539
      policy_entropy: 17.051712036132812
      policy_loss: 6.14673376083374
      var_gnorm: 21.987812042236328
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 15.768054962158203
    num_steps_sampled: 162000
    num_steps_trained: 162000
    wait_time_ms: 68.279
  iterations_since_restore: 54
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 429.6839282512665
  time_this_iter_s: 7.7237324714660645
  time_total_s: 429.6839282512665
  timestamp: 1594088184
  timesteps_since_restore: 162000
  timesteps_this_iter: 3000
  timesteps_total: 162000
  training_iteration: 54
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 429 s, 54 iter, 162000 ts, 527 rew

agent-1: 131.0
agent-2: 144.0
agent-3: 138.0
Sum Reward: 413.0
Avg Reward: 137.66666666666666
Min Reward: 131.0
Max Reward: 144.0
Gini Coefficient: 0.020984665052461663
20:20 Ratio: 1.099236641221374
Max-min Ratio: 1.099236641221374
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-16-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 525.3703703703703
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 54
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.422
    dispatch_time_ms: 8.503
    learner:
      cur_lr: 0.001349210855551064
      grad_gnorm: 32.07390213012695
      policy_entropy: 25.21295166015625
      policy_loss: 8.423341751098633
      var_gnorm: 21.985729217529297
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 9.602335929870605
    num_steps_sampled: 165000
    num_steps_trained: 165000
    wait_time_ms: 62.989
  iterations_since_restore: 55
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 437.14795088768005
  time_this_iter_s: 7.464022636413574
  time_total_s: 437.14795088768005
  timestamp: 1594088192
  timesteps_since_restore: 165000
  timesteps_this_iter: 3000
  timesteps_total: 165000
  training_iteration: 55
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 437 s, 55 iter, 165000 ts, 525 rew

agent-1: 221.0
agent-2: 189.0
agent-3: 126.0
Sum Reward: 536.0
Avg Reward: 178.66666666666666
Min Reward: 126.0
Max Reward: 221.0
Gini Coefficient: 0.1181592039800995
20:20 Ratio: 1.753968253968254
Max-min Ratio: 1.753968253968254
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-16-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 525.5636363636364
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 55
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.937
    dispatch_time_ms: 7.809
    learner:
      cur_lr: 0.0013490109704434872
      grad_gnorm: 40.00000762939453
      policy_entropy: 22.76183319091797
      policy_loss: 32.58964538574219
      var_gnorm: 22.26434898376465
      vf_explained_var: 0.038012802600860596
      vf_loss: 52.51804733276367
    num_steps_sampled: 168000
    num_steps_trained: 168000
    wait_time_ms: 63.937
  iterations_since_restore: 56
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 445.0344023704529
  time_this_iter_s: 7.886451482772827
  time_total_s: 445.0344023704529
  timestamp: 1594088200
  timesteps_since_restore: 168000
  timesteps_this_iter: 3000
  timesteps_total: 168000
  training_iteration: 56
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 445 s, 56 iter, 168000 ts, 526 rew

agent-1: 154.0
agent-2: 169.0
agent-3: 180.0
Sum Reward: 503.0
Avg Reward: 167.66666666666666
Min Reward: 154.0
Max Reward: 180.0
Gini Coefficient: 0.03445990722332671
20:20 Ratio: 1.1688311688311688
Max-min Ratio: 1.1688311688311688
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-16-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 525.1607142857143
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 56
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.791
    dispatch_time_ms: 5.915
    learner:
      cur_lr: 0.0013488112017512321
      grad_gnorm: 40.0
      policy_entropy: 25.268022537231445
      policy_loss: 3.6215429306030273
      var_gnorm: 22.8591365814209
      vf_explained_var: 0.19426816701889038
      vf_loss: 20.594558715820312
    num_steps_sampled: 171000
    num_steps_trained: 171000
    wait_time_ms: 74.102
  iterations_since_restore: 57
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 452.7472894191742
  time_this_iter_s: 7.7128870487213135
  time_total_s: 452.7472894191742
  timestamp: 1594088207
  timesteps_since_restore: 171000
  timesteps_this_iter: 3000
  timesteps_total: 171000
  training_iteration: 57
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 452 s, 57 iter, 171000 ts, 525 rew

agent-1: 205.0
agent-2: 179.0
agent-3: 263.0
Sum Reward: 647.0
Avg Reward: 215.66666666666666
Min Reward: 179.0
Max Reward: 263.0
Gini Coefficient: 0.0865533230293663
20:20 Ratio: 1.4692737430167597
Max-min Ratio: 1.4692737430167597
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-16-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 527.2982456140351
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 57
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.634
    dispatch_time_ms: 6.602
    learner:
      cur_lr: 0.0013486114330589771
      grad_gnorm: 40.0
      policy_entropy: 14.80271053314209
      policy_loss: -3.851440906524658
      var_gnorm: 23.1583251953125
      vf_explained_var: 0.5026367902755737
      vf_loss: 18.180761337280273
    num_steps_sampled: 174000
    num_steps_trained: 174000
    wait_time_ms: 71.043
  iterations_since_restore: 58
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 461.08408522605896
  time_this_iter_s: 8.336795806884766
  time_total_s: 461.08408522605896
  timestamp: 1594088216
  timesteps_since_restore: 174000
  timesteps_this_iter: 3000
  timesteps_total: 174000
  training_iteration: 58
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 461 s, 58 iter, 174000 ts, 527 rew

agent-1: 205.0
agent-2: 259.0
agent-3: 243.0
Sum Reward: 707.0
Avg Reward: 235.66666666666666
Min Reward: 205.0
Max Reward: 259.0
Gini Coefficient: 0.05091937765205092
20:20 Ratio: 1.2634146341463415
Max-min Ratio: 1.2634146341463415
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-17-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 530.3965517241379
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 58
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.405
    dispatch_time_ms: 5.673
    learner:
      cur_lr: 0.0013484115479514003
      grad_gnorm: 40.000003814697266
      policy_entropy: 10.789188385009766
      policy_loss: 11.256003379821777
      var_gnorm: 23.32604217529297
      vf_explained_var: 0.20337730646133423
      vf_loss: 30.070343017578125
    num_steps_sampled: 177000
    num_steps_trained: 177000
    wait_time_ms: 67.838
  iterations_since_restore: 59
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 468.8899681568146
  time_this_iter_s: 7.805882930755615
  time_total_s: 468.8899681568146
  timestamp: 1594088224
  timesteps_since_restore: 177000
  timesteps_this_iter: 3000
  timesteps_total: 177000
  training_iteration: 59
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 468 s, 59 iter, 177000 ts, 530 rew

agent-1: 306.0
agent-2: 293.0
agent-3: 281.0
Sum Reward: 880.0
Avg Reward: 293.3333333333333
Min Reward: 281.0
Max Reward: 306.0
Gini Coefficient: 0.01893939393939394
20:20 Ratio: 1.0889679715302492
Max-min Ratio: 1.0889679715302492
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-17-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 536.3220338983051
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 59
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.526
    dispatch_time_ms: 7.907
    learner:
      cur_lr: 0.0013482117792591453
      grad_gnorm: 39.99999237060547
      policy_entropy: 13.057845115661621
      policy_loss: 0.7874853610992432
      var_gnorm: 23.409770965576172
      vf_explained_var: 0.07216441631317139
      vf_loss: 30.49579429626465
    num_steps_sampled: 180000
    num_steps_trained: 180000
    wait_time_ms: 79.569
  iterations_since_restore: 60
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 477.0663902759552
  time_this_iter_s: 8.176422119140625
  time_total_s: 477.0663902759552
  timestamp: 1594088232
  timesteps_since_restore: 180000
  timesteps_this_iter: 3000
  timesteps_total: 180000
  training_iteration: 60
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 477 s, 60 iter, 180000 ts, 536 rew

agent-1: 329.0
agent-2: 305.0
agent-3: 278.0
Sum Reward: 912.0
Avg Reward: 304.0
Min Reward: 278.0
Max Reward: 329.0
Gini Coefficient: 0.03728070175438596
20:20 Ratio: 1.183453237410072
Max-min Ratio: 1.183453237410072
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-17-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 542.5833333333334
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 60
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.46
    dispatch_time_ms: 7.897
    learner:
      cur_lr: 0.0013480120105668902
      grad_gnorm: 40.0
      policy_entropy: 9.925809860229492
      policy_loss: 15.138304710388184
      var_gnorm: 23.563417434692383
      vf_explained_var: 0.10033422708511353
      vf_loss: 15.095503807067871
    num_steps_sampled: 183000
    num_steps_trained: 183000
    wait_time_ms: 70.395
  iterations_since_restore: 61
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 484.9693145751953
  time_this_iter_s: 7.902924299240112
  time_total_s: 484.9693145751953
  timestamp: 1594088240
  timesteps_since_restore: 183000
  timesteps_this_iter: 3000
  timesteps_total: 183000
  training_iteration: 61
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 484 s, 61 iter, 183000 ts, 543 rew

agent-1: 254.0
agent-2: 321.0
agent-3: 275.0
Sum Reward: 850.0
Avg Reward: 283.3333333333333
Min Reward: 254.0
Max Reward: 321.0
Gini Coefficient: 0.05254901960784314
20:20 Ratio: 1.263779527559055
Max-min Ratio: 1.263779527559055
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-17-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 547.6229508196722
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 61
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.518
    dispatch_time_ms: 7.026
    learner:
      cur_lr: 0.0013478122418746352
      grad_gnorm: 39.999996185302734
      policy_entropy: 6.328610420227051
      policy_loss: 1.222121238708496
      var_gnorm: 23.73526954650879
      vf_explained_var: 0.32203996181488037
      vf_loss: 37.094234466552734
    num_steps_sampled: 186000
    num_steps_trained: 186000
    wait_time_ms: 65.724
  iterations_since_restore: 62
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 493.0853044986725
  time_this_iter_s: 8.115989923477173
  time_total_s: 493.0853044986725
  timestamp: 1594088248
  timesteps_since_restore: 186000
  timesteps_this_iter: 3000
  timesteps_total: 186000
  training_iteration: 62
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 493 s, 62 iter, 186000 ts, 548 rew

agent-1: 310.0
agent-2: 256.0
agent-3: 281.0
Sum Reward: 847.0
Avg Reward: 282.3333333333333
Min Reward: 256.0
Max Reward: 310.0
Gini Coefficient: 0.04250295159386069
20:20 Ratio: 1.2109375
Max-min Ratio: 1.2109375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-17-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 552.4516129032259
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 62
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.658
    dispatch_time_ms: 6.977
    learner:
      cur_lr: 0.0013476123567670584
      grad_gnorm: 40.000003814697266
      policy_entropy: 10.965063095092773
      policy_loss: 5.011927604675293
      var_gnorm: 23.975101470947266
      vf_explained_var: 0.3367053270339966
      vf_loss: 18.916616439819336
    num_steps_sampled: 189000
    num_steps_trained: 189000
    wait_time_ms: 74.078
  iterations_since_restore: 63
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 501.02574038505554
  time_this_iter_s: 7.940435886383057
  time_total_s: 501.02574038505554
  timestamp: 1594088256
  timesteps_since_restore: 189000
  timesteps_this_iter: 3000
  timesteps_total: 189000
  training_iteration: 63
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 501 s, 63 iter, 189000 ts, 552 rew

agent-1: 298.0
agent-2: 303.0
agent-3: 294.0
Sum Reward: 895.0
Avg Reward: 298.3333333333333
Min Reward: 294.0
Max Reward: 303.0
Gini Coefficient: 0.0067039106145251395
20:20 Ratio: 1.030612244897959
Max-min Ratio: 1.030612244897959
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-17-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 557.8888888888889
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 63
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.63
    dispatch_time_ms: 6.062
    learner:
      cur_lr: 0.0013474125880748034
      grad_gnorm: 39.999996185302734
      policy_entropy: 3.5565359592437744
      policy_loss: 1.073540210723877
      var_gnorm: 24.163101196289062
      vf_explained_var: 0.06690305471420288
      vf_loss: 54.79733657836914
    num_steps_sampled: 192000
    num_steps_trained: 192000
    wait_time_ms: 73.778
  iterations_since_restore: 64
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 509.1148352622986
  time_this_iter_s: 8.089094877243042
  time_total_s: 509.1148352622986
  timestamp: 1594088264
  timesteps_since_restore: 192000
  timesteps_this_iter: 3000
  timesteps_total: 192000
  training_iteration: 64
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 509 s, 64 iter, 192000 ts, 558 rew

agent-1: 306.0
agent-2: 337.0
agent-3: 244.0
Sum Reward: 887.0
Avg Reward: 295.6666666666667
Min Reward: 244.0
Max Reward: 337.0
Gini Coefficient: 0.06989853438556934
20:20 Ratio: 1.3811475409836065
Max-min Ratio: 1.3811475409836065
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-17-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 563.03125
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 64
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.981
    dispatch_time_ms: 8.031
    learner:
      cur_lr: 0.0013472128193825483
      grad_gnorm: 40.00001525878906
      policy_entropy: 17.3265323638916
      policy_loss: -2.385432243347168
      var_gnorm: 24.473854064941406
      vf_explained_var: 0.6571958065032959
      vf_loss: 9.840319633483887
    num_steps_sampled: 195000
    num_steps_trained: 195000
    wait_time_ms: 68.706
  iterations_since_restore: 65
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 517.111394405365
  time_this_iter_s: 7.996559143066406
  time_total_s: 517.111394405365
  timestamp: 1594088272
  timesteps_since_restore: 195000
  timesteps_this_iter: 3000
  timesteps_total: 195000
  training_iteration: 65
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 517 s, 65 iter, 195000 ts, 563 rew

agent-1: 279.0
agent-2: 269.0
agent-3: 331.0
Sum Reward: 879.0
Avg Reward: 293.0
Min Reward: 269.0
Max Reward: 331.0
Gini Coefficient: 0.04702313234736443
20:20 Ratio: 1.2304832713754648
Max-min Ratio: 1.2304832713754648
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-18-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 567.8923076923077
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 65
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.583
    dispatch_time_ms: 6.037
    learner:
      cur_lr: 0.0013470130506902933
      grad_gnorm: 39.9999885559082
      policy_entropy: 20.44106674194336
      policy_loss: 12.905448913574219
      var_gnorm: 24.676664352416992
      vf_explained_var: -1.0
      vf_loss: 17.4260196685791
    num_steps_sampled: 198000
    num_steps_trained: 198000
    wait_time_ms: 76.275
  iterations_since_restore: 66
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 525.1128616333008
  time_this_iter_s: 8.001467227935791
  time_total_s: 525.1128616333008
  timestamp: 1594088280
  timesteps_since_restore: 198000
  timesteps_this_iter: 3000
  timesteps_total: 198000
  training_iteration: 66
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 525 s, 66 iter, 198000 ts, 568 rew

agent-1: 295.0
agent-2: 268.0
agent-3: 290.0
Sum Reward: 853.0
Avg Reward: 284.3333333333333
Min Reward: 268.0
Max Reward: 295.0
Gini Coefficient: 0.021101992966002344
20:20 Ratio: 1.1007462686567164
Max-min Ratio: 1.1007462686567164
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-18-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 572.2121212121212
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 66
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.644
    dispatch_time_ms: 9.216
    learner:
      cur_lr: 0.0013468131655827165
      grad_gnorm: 40.00000762939453
      policy_entropy: 7.5512871742248535
      policy_loss: 3.7708966732025146
      var_gnorm: 24.815031051635742
      vf_explained_var: 0.2331743836402893
      vf_loss: 30.550399780273438
    num_steps_sampled: 201000
    num_steps_trained: 201000
    wait_time_ms: 70.528
  iterations_since_restore: 67
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 533.0213868618011
  time_this_iter_s: 7.908525228500366
  time_total_s: 533.0213868618011
  timestamp: 1594088288
  timesteps_since_restore: 201000
  timesteps_this_iter: 3000
  timesteps_total: 201000
  training_iteration: 67
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 533 s, 67 iter, 201000 ts, 572 rew

agent-1: 349.0
agent-2: 294.0
agent-3: 297.0
Sum Reward: 940.0
Avg Reward: 313.3333333333333
Min Reward: 294.0
Max Reward: 349.0
Gini Coefficient: 0.03900709219858156
20:20 Ratio: 1.1870748299319729
Max-min Ratio: 1.1870748299319729
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-18-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 577.7014925373135
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 67
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.979
    dispatch_time_ms: 9.044
    learner:
      cur_lr: 0.0013466133968904614
      grad_gnorm: 40.0000114440918
      policy_entropy: 17.86202049255371
      policy_loss: -9.513786315917969
      var_gnorm: 25.036808013916016
      vf_explained_var: 0.39289629459381104
      vf_loss: 8.519609451293945
    num_steps_sampled: 204000
    num_steps_trained: 204000
    wait_time_ms: 69.37
  iterations_since_restore: 68
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 541.220379114151
  time_this_iter_s: 8.198992252349854
  time_total_s: 541.220379114151
  timestamp: 1594088296
  timesteps_since_restore: 204000
  timesteps_this_iter: 3000
  timesteps_total: 204000
  training_iteration: 68
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 541 s, 68 iter, 204000 ts, 578 rew

agent-1: 315.0
agent-2: 343.0
agent-3: 327.0
Sum Reward: 985.0
Avg Reward: 328.3333333333333
Min Reward: 315.0
Max Reward: 343.0
Gini Coefficient: 0.01895093062605753
20:20 Ratio: 1.0888888888888888
Max-min Ratio: 1.0888888888888888
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-18-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 583.6911764705883
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 68
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.627
    dispatch_time_ms: 9.854
    learner:
      cur_lr: 0.0013464136281982064
      grad_gnorm: 39.99995803833008
      policy_entropy: 7.474911212921143
      policy_loss: -4.322672367095947
      var_gnorm: 25.2923526763916
      vf_explained_var: 0.14960640668869019
      vf_loss: 23.946834564208984
    num_steps_sampled: 207000
    num_steps_trained: 207000
    wait_time_ms: 71.394
  iterations_since_restore: 69
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 549.358757019043
  time_this_iter_s: 8.138377904891968
  time_total_s: 549.358757019043
  timestamp: 1594088304
  timesteps_since_restore: 207000
  timesteps_this_iter: 3000
  timesteps_total: 207000
  training_iteration: 69
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 549 s, 69 iter, 207000 ts, 584 rew

agent-1: 311.0
agent-2: 304.0
agent-3: 338.0
Sum Reward: 953.0
Avg Reward: 317.6666666666667
Min Reward: 304.0
Max Reward: 338.0
Gini Coefficient: 0.02378454004896817
20:20 Ratio: 1.111842105263158
Max-min Ratio: 1.111842105263158
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-18-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 589.0434782608696
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 69
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.093
    dispatch_time_ms: 9.843
    learner:
      cur_lr: 0.0013462137430906296
      grad_gnorm: 14.757737159729004
      policy_entropy: 9.608671188354492
      policy_loss: -0.9281384944915771
      var_gnorm: 25.431325912475586
      vf_explained_var: 0.304047167301178
      vf_loss: 6.55728816986084
    num_steps_sampled: 210000
    num_steps_trained: 210000
    wait_time_ms: 70.899
  iterations_since_restore: 70
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 557.5906257629395
  time_this_iter_s: 8.231868743896484
  time_total_s: 557.5906257629395
  timestamp: 1594088313
  timesteps_since_restore: 210000
  timesteps_this_iter: 3000
  timesteps_total: 210000
  training_iteration: 70
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 557 s, 70 iter, 210000 ts, 589 rew

agent-1: 342.0
agent-2: 278.0
agent-3: 322.0
Sum Reward: 942.0
Avg Reward: 314.0
Min Reward: 278.0
Max Reward: 342.0
Gini Coefficient: 0.04529370134465676
20:20 Ratio: 1.2302158273381294
Max-min Ratio: 1.2302158273381294
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-18-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 594.0857142857143
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 70
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.603
    dispatch_time_ms: 7.934
    learner:
      cur_lr: 0.0013460139743983746
      grad_gnorm: 39.999996185302734
      policy_entropy: 11.193416595458984
      policy_loss: -12.615948677062988
      var_gnorm: 25.624080657958984
      vf_explained_var: 0.6184510588645935
      vf_loss: 21.774383544921875
    num_steps_sampled: 213000
    num_steps_trained: 213000
    wait_time_ms: 68.152
  iterations_since_restore: 71
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 565.1672191619873
  time_this_iter_s: 7.576593399047852
  time_total_s: 565.1672191619873
  timestamp: 1594088320
  timesteps_since_restore: 213000
  timesteps_this_iter: 3000
  timesteps_total: 213000
  training_iteration: 71
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 565 s, 71 iter, 213000 ts, 594 rew

agent-1: 318.0
agent-2: 294.0
agent-3: 291.0
Sum Reward: 903.0
Avg Reward: 301.0
Min Reward: 291.0
Max Reward: 318.0
Gini Coefficient: 0.019933554817275746
20:20 Ratio: 1.092783505154639
Max-min Ratio: 1.092783505154639
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-18-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 598.4366197183099
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 71
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.962
    dispatch_time_ms: 6.457
    learner:
      cur_lr: 0.0013458142057061195
      grad_gnorm: 40.00000762939453
      policy_entropy: 8.054476737976074
      policy_loss: -23.581008911132812
      var_gnorm: 25.78507423400879
      vf_explained_var: 0.390791654586792
      vf_loss: 36.959136962890625
    num_steps_sampled: 216000
    num_steps_trained: 216000
    wait_time_ms: 73.935
  iterations_since_restore: 72
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 573.3249514102936
  time_this_iter_s: 8.157732248306274
  time_total_s: 573.3249514102936
  timestamp: 1594088328
  timesteps_since_restore: 216000
  timesteps_this_iter: 3000
  timesteps_total: 216000
  training_iteration: 72
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 573 s, 72 iter, 216000 ts, 598 rew

agent-1: 299.0
agent-2: 336.0
agent-3: 314.0
Sum Reward: 949.0
Avg Reward: 316.3333333333333
Min Reward: 299.0
Max Reward: 336.0
Gini Coefficient: 0.02599227256761503
20:20 Ratio: 1.1237458193979932
Max-min Ratio: 1.1237458193979932
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-18-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 992.0
  episode_reward_mean: 603.3055555555555
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 72
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.438
    dispatch_time_ms: 7.805
    learner:
      cur_lr: 0.0013456144370138645
      grad_gnorm: 33.2789192199707
      policy_entropy: 6.367942810058594
      policy_loss: 3.4780795574188232
      var_gnorm: 25.956687927246094
      vf_explained_var: 0.640949547290802
      vf_loss: 9.355217933654785
    num_steps_sampled: 219000
    num_steps_trained: 219000
    wait_time_ms: 72.114
  iterations_since_restore: 73
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 581.5394525527954
  time_this_iter_s: 8.214501142501831
  time_total_s: 581.5394525527954
  timestamp: 1594088337
  timesteps_since_restore: 219000
  timesteps_this_iter: 3000
  timesteps_total: 219000
  training_iteration: 73
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 581 s, 73 iter, 219000 ts, 603 rew

agent-1: 344.0
agent-2: 366.0
agent-3: 360.0
Sum Reward: 1070.0
Avg Reward: 356.6666666666667
Min Reward: 344.0
Max Reward: 366.0
Gini Coefficient: 0.013707165109034268
20:20 Ratio: 1.063953488372093
Max-min Ratio: 1.063953488372093
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-19-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.0
  episode_reward_mean: 609.6986301369863
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 73
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.766
    dispatch_time_ms: 9.104
    learner:
      cur_lr: 0.0013454145519062877
      grad_gnorm: 40.000022888183594
      policy_entropy: 6.57870626449585
      policy_loss: 6.29793643951416
      var_gnorm: 26.042173385620117
      vf_explained_var: 0.43023329973220825
      vf_loss: 9.759857177734375
    num_steps_sampled: 222000
    num_steps_trained: 222000
    wait_time_ms: 70.492
  iterations_since_restore: 74
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 589.6798830032349
  time_this_iter_s: 8.140430450439453
  time_total_s: 589.6798830032349
  timestamp: 1594088345
  timesteps_since_restore: 222000
  timesteps_this_iter: 3000
  timesteps_total: 222000
  training_iteration: 74
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 589 s, 74 iter, 222000 ts, 610 rew

agent-1: 377.0
agent-2: 352.0
agent-3: 375.0
Sum Reward: 1104.0
Avg Reward: 368.0
Min Reward: 352.0
Max Reward: 377.0
Gini Coefficient: 0.015096618357487922
20:20 Ratio: 1.0710227272727273
Max-min Ratio: 1.0710227272727273
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-19-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1104.0
  episode_reward_mean: 616.3783783783783
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 74
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.794
    dispatch_time_ms: 9.329
    learner:
      cur_lr: 0.0013452147832140326
      grad_gnorm: 40.00000762939453
      policy_entropy: 5.760259628295898
      policy_loss: 2.1505143642425537
      var_gnorm: 26.159976959228516
      vf_explained_var: 0.21391654014587402
      vf_loss: 34.41499328613281
    num_steps_sampled: 225000
    num_steps_trained: 225000
    wait_time_ms: 68.857
  iterations_since_restore: 75
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 598.0244717597961
  time_this_iter_s: 8.34458875656128
  time_total_s: 598.0244717597961
  timestamp: 1594088353
  timesteps_since_restore: 225000
  timesteps_this_iter: 3000
  timesteps_total: 225000
  training_iteration: 75
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 598 s, 75 iter, 225000 ts, 616 rew

agent-1: 366.0
agent-2: 380.0
agent-3: 363.0
Sum Reward: 1109.0
Avg Reward: 369.6666666666667
Min Reward: 363.0
Max Reward: 380.0
Gini Coefficient: 0.01021941689209498
20:20 Ratio: 1.046831955922865
Max-min Ratio: 1.046831955922865
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-19-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 622.9466666666667
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 75
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.575
    dispatch_time_ms: 9.213
    learner:
      cur_lr: 0.0013450150145217776
      grad_gnorm: 40.000022888183594
      policy_entropy: 21.27501678466797
      policy_loss: -20.454267501831055
      var_gnorm: 26.448711395263672
      vf_explained_var: -0.6107896566390991
      vf_loss: 65.65485382080078
    num_steps_sampled: 228000
    num_steps_trained: 228000
    wait_time_ms: 67.616
  iterations_since_restore: 76
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 605.9578192234039
  time_this_iter_s: 7.933347463607788
  time_total_s: 605.9578192234039
  timestamp: 1594088361
  timesteps_since_restore: 228000
  timesteps_this_iter: 3000
  timesteps_total: 228000
  training_iteration: 76
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 605 s, 76 iter, 228000 ts, 623 rew

agent-1: 260.0
agent-2: 201.0
agent-3: 256.0
Sum Reward: 717.0
Avg Reward: 239.0
Min Reward: 201.0
Max Reward: 260.0
Gini Coefficient: 0.05485820548582055
20:20 Ratio: 1.2935323383084578
Max-min Ratio: 1.2935323383084578
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-19-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 624.1842105263158
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 76
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.933
    dispatch_time_ms: 9.519
    learner:
      cur_lr: 0.0013448152458295226
      grad_gnorm: 40.000003814697266
      policy_entropy: 6.271971225738525
      policy_loss: -2.9978280067443848
      var_gnorm: 26.437084197998047
      vf_explained_var: -0.07664620876312256
      vf_loss: 17.694522857666016
    num_steps_sampled: 231000
    num_steps_trained: 231000
    wait_time_ms: 59.133
  iterations_since_restore: 77
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 613.2833738327026
  time_this_iter_s: 7.325554609298706
  time_total_s: 613.2833738327026
  timestamp: 1594088369
  timesteps_since_restore: 231000
  timesteps_this_iter: 3000
  timesteps_total: 231000
  training_iteration: 77
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 613 s, 77 iter, 231000 ts, 624 rew

agent-1: 79.0
agent-2: 121.0
agent-3: 140.0
Sum Reward: 340.0
Avg Reward: 113.33333333333333
Min Reward: 79.0
Max Reward: 140.0
Gini Coefficient: 0.11960784313725491
20:20 Ratio: 1.7721518987341771
Max-min Ratio: 1.7721518987341771
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-19-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 620.4935064935065
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 77
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.601
    dispatch_time_ms: 10.128
    learner:
      cur_lr: 0.0013446153607219458
      grad_gnorm: 40.000003814697266
      policy_entropy: 6.874942779541016
      policy_loss: 2.8045477867126465
      var_gnorm: 26.36018943786621
      vf_explained_var: 5.7220458984375e-06
      vf_loss: 24.82586097717285
    num_steps_sampled: 234000
    num_steps_trained: 234000
    wait_time_ms: 60.455
  iterations_since_restore: 78
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 620.569961309433
  time_this_iter_s: 7.286587476730347
  time_total_s: 620.569961309433
  timestamp: 1594088376
  timesteps_since_restore: 234000
  timesteps_this_iter: 3000
  timesteps_total: 234000
  training_iteration: 78
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 620 s, 78 iter, 234000 ts, 620 rew

agent-1: 161.0
agent-2: 88.0
agent-3: 96.0
Sum Reward: 345.0
Avg Reward: 115.0
Min Reward: 88.0
Max Reward: 161.0
Gini Coefficient: 0.14106280193236714
20:20 Ratio: 1.8295454545454546
Max-min Ratio: 1.8295454545454546
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-19-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 616.9615384615385
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 78
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.691
    dispatch_time_ms: 8.933
    learner:
      cur_lr: 0.0013444155920296907
      grad_gnorm: 7.101737022399902
      policy_entropy: 12.641544342041016
      policy_loss: 1.1807223558425903
      var_gnorm: 26.31360626220703
      vf_explained_var: 0.0
      vf_loss: 6.4002275466918945
    num_steps_sampled: 237000
    num_steps_trained: 237000
    wait_time_ms: 62.939
  iterations_since_restore: 79
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 627.8951525688171
  time_this_iter_s: 7.325191259384155
  time_total_s: 627.8951525688171
  timestamp: 1594088383
  timesteps_since_restore: 237000
  timesteps_this_iter: 3000
  timesteps_total: 237000
  training_iteration: 79
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 627 s, 79 iter, 237000 ts, 617 rew

agent-1: 117.0
agent-2: 104.0
agent-3: 98.0
Sum Reward: 319.0
Avg Reward: 106.33333333333333
Min Reward: 98.0
Max Reward: 117.0
Gini Coefficient: 0.03970741901776385
20:20 Ratio: 1.1938775510204083
Max-min Ratio: 1.1938775510204083
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-19-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 613.1898734177215
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 79
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.737
    dispatch_time_ms: 7.417
    learner:
      cur_lr: 0.0013442158233374357
      grad_gnorm: 7.779818534851074
      policy_entropy: 4.970831394195557
      policy_loss: 0.08428876847028732
      var_gnorm: 26.287431716918945
      vf_explained_var: 0.0
      vf_loss: 18.847475051879883
    num_steps_sampled: 240000
    num_steps_trained: 240000
    wait_time_ms: 64.497
  iterations_since_restore: 80
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 635.187844991684
  time_this_iter_s: 7.292692422866821
  time_total_s: 635.187844991684
  timestamp: 1594088391
  timesteps_since_restore: 240000
  timesteps_this_iter: 3000
  timesteps_total: 240000
  training_iteration: 80
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 635 s, 80 iter, 240000 ts, 613 rew

agent-1: 148.0
agent-2: 115.0
agent-3: 118.0
Sum Reward: 381.0
Avg Reward: 127.0
Min Reward: 115.0
Max Reward: 148.0
Gini Coefficient: 0.05774278215223097
20:20 Ratio: 1.2869565217391303
Max-min Ratio: 1.2869565217391303
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-19-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 610.2875
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 80
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.586
    dispatch_time_ms: 12.003
    learner:
      cur_lr: 0.0013440160546451807
      grad_gnorm: 30.324499130249023
      policy_entropy: 9.466618537902832
      policy_loss: 0.9401174187660217
      var_gnorm: 26.309078216552734
      vf_explained_var: 0.0
      vf_loss: 18.158103942871094
    num_steps_sampled: 243000
    num_steps_trained: 243000
    wait_time_ms: 62.989
  iterations_since_restore: 81
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 642.5090618133545
  time_this_iter_s: 7.321216821670532
  time_total_s: 642.5090618133545
  timestamp: 1594088398
  timesteps_since_restore: 243000
  timesteps_this_iter: 3000
  timesteps_total: 243000
  training_iteration: 81
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 642 s, 81 iter, 243000 ts, 610 rew

agent-1: 146.0
agent-2: 121.0
agent-3: 185.0
Sum Reward: 452.0
Avg Reward: 150.66666666666666
Min Reward: 121.0
Max Reward: 185.0
Gini Coefficient: 0.0943952802359882
20:20 Ratio: 1.5289256198347108
Max-min Ratio: 1.5289256198347108
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-20-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 608.3333333333334
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 81
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.824
    dispatch_time_ms: 9.446
    learner:
      cur_lr: 0.0013438161695376039
      grad_gnorm: 40.0
      policy_entropy: 11.067429542541504
      policy_loss: 18.970558166503906
      var_gnorm: 26.333349227905273
      vf_explained_var: -0.0008149147033691406
      vf_loss: 43.49245071411133
    num_steps_sampled: 246000
    num_steps_trained: 246000
    wait_time_ms: 64.22
  iterations_since_restore: 82
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 650.1234154701233
  time_this_iter_s: 7.614353656768799
  time_total_s: 650.1234154701233
  timestamp: 1594088406
  timesteps_since_restore: 246000
  timesteps_this_iter: 3000
  timesteps_total: 246000
  training_iteration: 82
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 650 s, 82 iter, 246000 ts, 608 rew

agent-1: 197.0
agent-2: 182.0
agent-3: 151.0
Sum Reward: 530.0
Avg Reward: 176.66666666666666
Min Reward: 151.0
Max Reward: 197.0
Gini Coefficient: 0.05786163522012579
20:20 Ratio: 1.304635761589404
Max-min Ratio: 1.304635761589404
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-20-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 607.3780487804878
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 82
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.073
    dispatch_time_ms: 7.6
    learner:
      cur_lr: 0.0013436164008453488
      grad_gnorm: 40.0
      policy_entropy: 8.584577560424805
      policy_loss: -3.4536070823669434
      var_gnorm: 26.339902877807617
      vf_explained_var: 0.0
      vf_loss: 6.876605033874512
    num_steps_sampled: 249000
    num_steps_trained: 249000
    wait_time_ms: 60.594
  iterations_since_restore: 83
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 657.6359491348267
  time_this_iter_s: 7.512533664703369
  time_total_s: 657.6359491348267
  timestamp: 1594088413
  timesteps_since_restore: 249000
  timesteps_this_iter: 3000
  timesteps_total: 249000
  training_iteration: 83
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 657 s, 83 iter, 249000 ts, 607 rew

agent-1: 188.0
agent-2: 190.0
agent-3: 144.0
Sum Reward: 522.0
Avg Reward: 174.0
Min Reward: 144.0
Max Reward: 190.0
Gini Coefficient: 0.05874840357598978
20:20 Ratio: 1.3194444444444444
Max-min Ratio: 1.3194444444444444
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-20-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 606.3493975903615
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 83
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.146
    dispatch_time_ms: 8.953
    learner:
      cur_lr: 0.0013434166321530938
      grad_gnorm: 39.99999237060547
      policy_entropy: 7.636432647705078
      policy_loss: 6.5629425048828125
      var_gnorm: 26.27686309814453
      vf_explained_var: 0.6498896479606628
      vf_loss: 128.88330078125
    num_steps_sampled: 252000
    num_steps_trained: 252000
    wait_time_ms: 63.078
  iterations_since_restore: 84
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 665.1095688343048
  time_this_iter_s: 7.473619699478149
  time_total_s: 665.1095688343048
  timestamp: 1594088421
  timesteps_since_restore: 252000
  timesteps_this_iter: 3000
  timesteps_total: 252000
  training_iteration: 84
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 665 s, 84 iter, 252000 ts, 606 rew

agent-1: 176.0
agent-2: 216.0
agent-3: 202.0
Sum Reward: 594.0
Avg Reward: 198.0
Min Reward: 176.0
Max Reward: 216.0
Gini Coefficient: 0.04489337822671156
20:20 Ratio: 1.2272727272727273
Max-min Ratio: 1.2272727272727273
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-20-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 606.202380952381
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 84
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.438
    dispatch_time_ms: 7.717
    learner:
      cur_lr: 0.001343216747045517
      grad_gnorm: 39.11989212036133
      policy_entropy: 3.810887336730957
      policy_loss: -7.727930068969727
      var_gnorm: 26.38738441467285
      vf_explained_var: 0.24592459201812744
      vf_loss: 15.797030448913574
    num_steps_sampled: 255000
    num_steps_trained: 255000
    wait_time_ms: 73.078
  iterations_since_restore: 85
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 673.1618130207062
  time_this_iter_s: 8.052244186401367
  time_total_s: 673.1618130207062
  timestamp: 1594088429
  timesteps_since_restore: 255000
  timesteps_this_iter: 3000
  timesteps_total: 255000
  training_iteration: 85
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 673 s, 85 iter, 255000 ts, 606 rew

agent-1: 260.0
agent-2: 219.0
agent-3: 303.0
Sum Reward: 782.0
Avg Reward: 260.6666666666667
Min Reward: 219.0
Max Reward: 303.0
Gini Coefficient: 0.07161125319693094
20:20 Ratio: 1.3835616438356164
Max-min Ratio: 1.3835616438356164
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-20-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 608.2705882352941
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 85
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.73
    dispatch_time_ms: 6.812
    learner:
      cur_lr: 0.001343016978353262
      grad_gnorm: 40.0
      policy_entropy: 9.234244346618652
      policy_loss: -5.56667947769165
      var_gnorm: 26.527536392211914
      vf_explained_var: 0.38383322954177856
      vf_loss: 17.726303100585938
    num_steps_sampled: 258000
    num_steps_trained: 258000
    wait_time_ms: 68.241
  iterations_since_restore: 86
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 681.1927237510681
  time_this_iter_s: 8.030910730361938
  time_total_s: 681.1927237510681
  timestamp: 1594088437
  timesteps_since_restore: 258000
  timesteps_this_iter: 3000
  timesteps_total: 258000
  training_iteration: 86
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 681 s, 86 iter, 258000 ts, 608 rew

agent-1: 287.0
agent-2: 311.0
agent-3: 318.0
Sum Reward: 916.0
Avg Reward: 305.3333333333333
Min Reward: 287.0
Max Reward: 318.0
Gini Coefficient: 0.022561863173216887
20:20 Ratio: 1.10801393728223
Max-min Ratio: 1.10801393728223
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-20-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 611.8488372093024
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 86
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.121
    dispatch_time_ms: 8.758
    learner:
      cur_lr: 0.001342817209661007
      grad_gnorm: 39.999996185302734
      policy_entropy: 6.365584373474121
      policy_loss: -3.9989848136901855
      var_gnorm: 26.564783096313477
      vf_explained_var: 0.06042224168777466
      vf_loss: 20.569612503051758
    num_steps_sampled: 261000
    num_steps_trained: 261000
    wait_time_ms: 67.079
  iterations_since_restore: 87
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 689.1374747753143
  time_this_iter_s: 7.944751024246216
  time_total_s: 689.1374747753143
  timestamp: 1594088445
  timesteps_since_restore: 261000
  timesteps_this_iter: 3000
  timesteps_total: 261000
  training_iteration: 87
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 689 s, 87 iter, 261000 ts, 612 rew

agent-1: 303.0
agent-2: 270.0
agent-3: 324.0
Sum Reward: 897.0
Avg Reward: 299.0
Min Reward: 270.0
Max Reward: 324.0
Gini Coefficient: 0.04013377926421405
20:20 Ratio: 1.2
Max-min Ratio: 1.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-20-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 615.1264367816092
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 87
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.542
    dispatch_time_ms: 7.278
    learner:
      cur_lr: 0.001342617440968752
      grad_gnorm: 21.474634170532227
      policy_entropy: 7.7563796043396
      policy_loss: 0.6156813502311707
      var_gnorm: 26.72005271911621
      vf_explained_var: 0.3428438901901245
      vf_loss: 3.811936140060425
    num_steps_sampled: 264000
    num_steps_trained: 264000
    wait_time_ms: 78.265
  iterations_since_restore: 88
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 697.4236633777618
  time_this_iter_s: 8.28618860244751
  time_total_s: 697.4236633777618
  timestamp: 1594088453
  timesteps_since_restore: 264000
  timesteps_this_iter: 3000
  timesteps_total: 264000
  training_iteration: 88
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 697 s, 88 iter, 264000 ts, 615 rew

agent-1: 371.0
agent-2: 329.0
agent-3: 368.0
Sum Reward: 1068.0
Avg Reward: 356.0
Min Reward: 329.0
Max Reward: 371.0
Gini Coefficient: 0.026217228464419477
20:20 Ratio: 1.127659574468085
Max-min Ratio: 1.127659574468085
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-21-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 620.2727272727273
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 88
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.599
    dispatch_time_ms: 6.47
    learner:
      cur_lr: 0.001342417555861175
      grad_gnorm: 40.00001525878906
      policy_entropy: 12.848392486572266
      policy_loss: 7.304976463317871
      var_gnorm: 26.893943786621094
      vf_explained_var: 0.4140810966491699
      vf_loss: 10.19093132019043
    num_steps_sampled: 267000
    num_steps_trained: 267000
    wait_time_ms: 80.291
  iterations_since_restore: 89
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 706.0598919391632
  time_this_iter_s: 8.636228561401367
  time_total_s: 706.0598919391632
  timestamp: 1594088462
  timesteps_since_restore: 267000
  timesteps_this_iter: 3000
  timesteps_total: 267000
  training_iteration: 89
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 706 s, 89 iter, 267000 ts, 620 rew

agent-1: 342.0
agent-2: 376.0
agent-3: 366.0
Sum Reward: 1084.0
Avg Reward: 361.3333333333333
Min Reward: 342.0
Max Reward: 376.0
Gini Coefficient: 0.020910209102091022
20:20 Ratio: 1.0994152046783625
Max-min Ratio: 1.0994152046783625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-21-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 625.4831460674158
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 89
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.824
    dispatch_time_ms: 8.898
    learner:
      cur_lr: 0.00134221778716892
      grad_gnorm: 16.410137176513672
      policy_entropy: 4.630548000335693
      policy_loss: -2.1746373176574707
      var_gnorm: 27.027027130126953
      vf_explained_var: -0.021446824073791504
      vf_loss: 19.38896369934082
    num_steps_sampled: 270000
    num_steps_trained: 270000
    wait_time_ms: 68.442
  iterations_since_restore: 90
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 714.370997428894
  time_this_iter_s: 8.311105489730835
  time_total_s: 714.370997428894
  timestamp: 1594088470
  timesteps_since_restore: 270000
  timesteps_this_iter: 3000
  timesteps_total: 270000
  training_iteration: 90
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 714 s, 90 iter, 270000 ts, 625 rew

agent-1: 343.0
agent-2: 336.0
agent-3: 355.0
Sum Reward: 1034.0
Avg Reward: 344.6666666666667
Min Reward: 336.0
Max Reward: 355.0
Gini Coefficient: 0.012250161186331399
20:20 Ratio: 1.056547619047619
Max-min Ratio: 1.056547619047619
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-21-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 630.0222222222222
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 90
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.167
    dispatch_time_ms: 9.832
    learner:
      cur_lr: 0.001342018018476665
      grad_gnorm: 40.0
      policy_entropy: 15.68122673034668
      policy_loss: -17.24190330505371
      var_gnorm: 27.1212215423584
      vf_explained_var: 0.5585570335388184
      vf_loss: 27.508153915405273
    num_steps_sampled: 273000
    num_steps_trained: 273000
    wait_time_ms: 63.756
  iterations_since_restore: 91
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 722.4395532608032
  time_this_iter_s: 8.06855583190918
  time_total_s: 722.4395532608032
  timestamp: 1594088478
  timesteps_since_restore: 273000
  timesteps_this_iter: 3000
  timesteps_total: 273000
  training_iteration: 91
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 722 s, 91 iter, 273000 ts, 630 rew

agent-1: 315.0
agent-2: 309.0
agent-3: 286.0
Sum Reward: 910.0
Avg Reward: 303.3333333333333
Min Reward: 286.0
Max Reward: 315.0
Gini Coefficient: 0.021245421245421246
20:20 Ratio: 1.1013986013986015
Max-min Ratio: 1.1013986013986015
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-21-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 633.0989010989011
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 91
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.628
    dispatch_time_ms: 7.904
    learner:
      cur_lr: 0.00134181824978441
      grad_gnorm: 40.000038146972656
      policy_entropy: 19.067684173583984
      policy_loss: -2.1884984970092773
      var_gnorm: 27.236557006835938
      vf_explained_var: 0.34885233640670776
      vf_loss: 46.04302978515625
    num_steps_sampled: 276000
    num_steps_trained: 276000
    wait_time_ms: 68.826
  iterations_since_restore: 92
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 730.2293026447296
  time_this_iter_s: 7.789749383926392
  time_total_s: 730.2293026447296
  timestamp: 1594088486
  timesteps_since_restore: 276000
  timesteps_this_iter: 3000
  timesteps_total: 276000
  training_iteration: 92
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 730 s, 92 iter, 276000 ts, 633 rew

agent-1: 253.0
agent-2: 286.0
agent-3: 244.0
Sum Reward: 783.0
Avg Reward: 261.0
Min Reward: 244.0
Max Reward: 286.0
Gini Coefficient: 0.035759897828863345
20:20 Ratio: 1.1721311475409837
Max-min Ratio: 1.1721311475409837
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-21-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 634.7282608695652
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 92
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.368
    dispatch_time_ms: 9.256
    learner:
      cur_lr: 0.0013416183646768332
      grad_gnorm: 40.0
      policy_entropy: 14.060541152954102
      policy_loss: 0.3493051528930664
      var_gnorm: 27.26215934753418
      vf_explained_var: 0.4981600046157837
      vf_loss: 9.12812328338623
    num_steps_sampled: 279000
    num_steps_trained: 279000
    wait_time_ms: 64.4
  iterations_since_restore: 93
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 737.9385743141174
  time_this_iter_s: 7.709271669387817
  time_total_s: 737.9385743141174
  timestamp: 1594088494
  timesteps_since_restore: 279000
  timesteps_this_iter: 3000
  timesteps_total: 279000
  training_iteration: 93
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 737 s, 93 iter, 279000 ts, 635 rew

agent-1: 202.0
agent-2: 178.0
agent-3: 285.0
Sum Reward: 665.0
Avg Reward: 221.66666666666666
Min Reward: 178.0
Max Reward: 285.0
Gini Coefficient: 0.10726817042606517
20:20 Ratio: 1.601123595505618
Max-min Ratio: 1.601123595505618
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-21-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 635.0537634408602
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 93
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.909
    dispatch_time_ms: 6.988
    learner:
      cur_lr: 0.0013414185959845781
      grad_gnorm: 39.999977111816406
      policy_entropy: 8.242535591125488
      policy_loss: 5.634285926818848
      var_gnorm: 27.312236785888672
      vf_explained_var: 0.7218286991119385
      vf_loss: 35.88725280761719
    num_steps_sampled: 282000
    num_steps_trained: 282000
    wait_time_ms: 73.962
  iterations_since_restore: 94
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 745.7828998565674
  time_this_iter_s: 7.844325542449951
  time_total_s: 745.7828998565674
  timestamp: 1594088502
  timesteps_since_restore: 282000
  timesteps_this_iter: 3000
  timesteps_total: 282000
  training_iteration: 94
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 745 s, 94 iter, 282000 ts, 635 rew

agent-1: 222.0
agent-2: 271.0
agent-3: 227.0
Sum Reward: 720.0
Avg Reward: 240.0
Min Reward: 222.0
Max Reward: 271.0
Gini Coefficient: 0.04537037037037037
20:20 Ratio: 1.2207207207207207
Max-min Ratio: 1.2207207207207207
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-21-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 635.9574468085107
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 94
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.459
    dispatch_time_ms: 7.35
    learner:
      cur_lr: 0.0013412188272923231
      grad_gnorm: 39.999996185302734
      policy_entropy: 15.437225341796875
      policy_loss: 6.697141647338867
      var_gnorm: 27.459503173828125
      vf_explained_var: 0.28893864154815674
      vf_loss: 127.00867462158203
    num_steps_sampled: 285000
    num_steps_trained: 285000
    wait_time_ms: 69.328
  iterations_since_restore: 95
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 753.6163182258606
  time_this_iter_s: 7.833418369293213
  time_total_s: 753.6163182258606
  timestamp: 1594088510
  timesteps_since_restore: 285000
  timesteps_this_iter: 3000
  timesteps_total: 285000
  training_iteration: 95
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 753 s, 95 iter, 285000 ts, 636 rew

agent-1: 275.0
agent-2: 271.0
agent-3: 267.0
Sum Reward: 813.0
Avg Reward: 271.0
Min Reward: 267.0
Max Reward: 275.0
Gini Coefficient: 0.006560065600656006
20:20 Ratio: 1.0299625468164795
Max-min Ratio: 1.0299625468164795
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-21-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 637.8210526315789
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 95
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.654
    dispatch_time_ms: 5.664
    learner:
      cur_lr: 0.0013410189421847463
      grad_gnorm: 40.0
      policy_entropy: 6.638422012329102
      policy_loss: 13.147285461425781
      var_gnorm: 27.525259017944336
      vf_explained_var: -0.1370028257369995
      vf_loss: 58.01913070678711
    num_steps_sampled: 288000
    num_steps_trained: 288000
    wait_time_ms: 71.379
  iterations_since_restore: 96
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 761.6143355369568
  time_this_iter_s: 7.998017311096191
  time_total_s: 761.6143355369568
  timestamp: 1594088518
  timesteps_since_restore: 288000
  timesteps_this_iter: 3000
  timesteps_total: 288000
  training_iteration: 96
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 761 s, 96 iter, 288000 ts, 638 rew

agent-1: 306.0
agent-2: 346.0
agent-3: 312.0
Sum Reward: 964.0
Avg Reward: 321.3333333333333
Min Reward: 306.0
Max Reward: 346.0
Gini Coefficient: 0.027662517289073305
20:20 Ratio: 1.130718954248366
Max-min Ratio: 1.130718954248366
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-22-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 641.21875
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 96
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.68
    dispatch_time_ms: 5.641
    learner:
      cur_lr: 0.0013408191734924912
      grad_gnorm: 39.999996185302734
      policy_entropy: 9.011008262634277
      policy_loss: 16.211727142333984
      var_gnorm: 27.672311782836914
      vf_explained_var: -0.9812794923782349
      vf_loss: 32.6463508605957
    num_steps_sampled: 291000
    num_steps_trained: 291000
    wait_time_ms: 73.94
  iterations_since_restore: 97
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 769.7126426696777
  time_this_iter_s: 8.098307132720947
  time_total_s: 769.7126426696777
  timestamp: 1594088526
  timesteps_since_restore: 291000
  timesteps_this_iter: 3000
  timesteps_total: 291000
  training_iteration: 97
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 769 s, 97 iter, 291000 ts, 641 rew

agent-1: 348.0
agent-2: 299.0
agent-3: 320.0
Sum Reward: 967.0
Avg Reward: 322.3333333333333
Min Reward: 299.0
Max Reward: 348.0
Gini Coefficient: 0.03378145467080317
20:20 Ratio: 1.1638795986622072
Max-min Ratio: 1.1638795986622072
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-22-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 644.5773195876288
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 97
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.728
    dispatch_time_ms: 6.275
    learner:
      cur_lr: 0.0013406194048002362
      grad_gnorm: 40.000003814697266
      policy_entropy: 14.733270645141602
      policy_loss: -19.48979949951172
      var_gnorm: 27.7558536529541
      vf_explained_var: 0.3015540838241577
      vf_loss: 45.779869079589844
    num_steps_sampled: 294000
    num_steps_trained: 294000
    wait_time_ms: 75.682
  iterations_since_restore: 98
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 777.8444783687592
  time_this_iter_s: 8.131835699081421
  time_total_s: 777.8444783687592
  timestamp: 1594088534
  timesteps_since_restore: 294000
  timesteps_this_iter: 3000
  timesteps_total: 294000
  training_iteration: 98
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 777 s, 98 iter, 294000 ts, 645 rew

agent-1: 346.0
agent-2: 337.0
agent-3: 323.0
Sum Reward: 1006.0
Avg Reward: 335.3333333333333
Min Reward: 323.0
Max Reward: 346.0
Gini Coefficient: 0.015241882041086813
20:20 Ratio: 1.0712074303405572
Max-min Ratio: 1.0712074303405572
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-22-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 648.265306122449
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 98
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.405
    dispatch_time_ms: 6.413
    learner:
      cur_lr: 0.0013404196361079812
      grad_gnorm: 40.0
      policy_entropy: 14.061368942260742
      policy_loss: -4.69081974029541
      var_gnorm: 27.83853530883789
      vf_explained_var: 0.3392385244369507
      vf_loss: 26.124296188354492
    num_steps_sampled: 297000
    num_steps_trained: 297000
    wait_time_ms: 72.337
  iterations_since_restore: 99
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 786.024765253067
  time_this_iter_s: 8.180286884307861
  time_total_s: 786.024765253067
  timestamp: 1594088542
  timesteps_since_restore: 297000
  timesteps_this_iter: 3000
  timesteps_total: 297000
  training_iteration: 99
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 786 s, 99 iter, 297000 ts, 648 rew

agent-1: 316.0
agent-2: 350.0
agent-3: 326.0
Sum Reward: 992.0
Avg Reward: 330.6666666666667
Min Reward: 316.0
Max Reward: 350.0
Gini Coefficient: 0.0228494623655914
20:20 Ratio: 1.1075949367088607
Max-min Ratio: 1.1075949367088607
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-22-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 651.7373737373738
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 99
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.884
    dispatch_time_ms: 7.443
    learner:
      cur_lr: 0.0013402197510004044
      grad_gnorm: 40.0000114440918
      policy_entropy: 9.040628433227539
      policy_loss: 9.712383270263672
      var_gnorm: 27.91644287109375
      vf_explained_var: 0.3237801790237427
      vf_loss: 29.446910858154297
    num_steps_sampled: 300000
    num_steps_trained: 300000
    wait_time_ms: 72.817
  iterations_since_restore: 100
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 794.1052725315094
  time_this_iter_s: 8.080507278442383
  time_total_s: 794.1052725315094
  timestamp: 1594088550
  timesteps_since_restore: 300000
  timesteps_this_iter: 3000
  timesteps_total: 300000
  training_iteration: 100
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 794 s, 100 iter, 300000 ts, 652 rew

agent-1: 314.0
agent-2: 339.0
agent-3: 356.0
Sum Reward: 1009.0
Avg Reward: 336.3333333333333
Min Reward: 314.0
Max Reward: 356.0
Gini Coefficient: 0.027750247770069375
20:20 Ratio: 1.1337579617834395
Max-min Ratio: 1.1337579617834395
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-22-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 655.31
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 100
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.609
    dispatch_time_ms: 9.312
    learner:
      cur_lr: 0.0013400199823081493
      grad_gnorm: 40.0
      policy_entropy: 9.560754776000977
      policy_loss: 5.878303050994873
      var_gnorm: 28.094581604003906
      vf_explained_var: 0.19858956336975098
      vf_loss: 55.15238571166992
    num_steps_sampled: 303000
    num_steps_trained: 303000
    wait_time_ms: 69.325
  iterations_since_restore: 101
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 802.3122344017029
  time_this_iter_s: 8.206961870193481
  time_total_s: 802.3122344017029
  timestamp: 1594088558
  timesteps_since_restore: 303000
  timesteps_this_iter: 3000
  timesteps_total: 303000
  training_iteration: 101
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 802 s, 101 iter, 303000 ts, 655 rew

agent-1: 331.0
agent-2: 337.0
agent-3: 361.0
Sum Reward: 1029.0
Avg Reward: 343.0
Min Reward: 331.0
Max Reward: 361.0
Gini Coefficient: 0.019436345966958212
20:20 Ratio: 1.0906344410876132
Max-min Ratio: 1.0906344410876132
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-22-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 662.49
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 101
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.697
    dispatch_time_ms: 6.611
    learner:
      cur_lr: 0.0013398202136158943
      grad_gnorm: 40.00000762939453
      policy_entropy: 9.894287109375
      policy_loss: -12.66134262084961
      var_gnorm: 28.117345809936523
      vf_explained_var: 0.4599958658218384
      vf_loss: 32.66360092163086
    num_steps_sampled: 306000
    num_steps_trained: 306000
    wait_time_ms: 73.457
  iterations_since_restore: 102
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 810.2336285114288
  time_this_iter_s: 7.921394109725952
  time_total_s: 810.2336285114288
  timestamp: 1594088566
  timesteps_since_restore: 306000
  timesteps_this_iter: 3000
  timesteps_total: 306000
  training_iteration: 102
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 810 s, 102 iter, 306000 ts, 662 rew

agent-1: 264.0
agent-2: 255.0
agent-3: 256.0
Sum Reward: 775.0
Avg Reward: 258.3333333333333
Min Reward: 255.0
Max Reward: 264.0
Gini Coefficient: 0.007741935483870968
20:20 Ratio: 1.035294117647059
Max-min Ratio: 1.035294117647059
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-22-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 666.97
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 102
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.472
    dispatch_time_ms: 7.359
    learner:
      cur_lr: 0.0013396204449236393
      grad_gnorm: 40.0000114440918
      policy_entropy: 16.405107498168945
      policy_loss: 5.916343688964844
      var_gnorm: 28.14453125
      vf_explained_var: 0.5988970994949341
      vf_loss: 33.16447830200195
    num_steps_sampled: 309000
    num_steps_trained: 309000
    wait_time_ms: 71.949
  iterations_since_restore: 103
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 818.127959728241
  time_this_iter_s: 7.894331216812134
  time_total_s: 818.127959728241
  timestamp: 1594088574
  timesteps_since_restore: 309000
  timesteps_this_iter: 3000
  timesteps_total: 309000
  training_iteration: 103
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 818 s, 103 iter, 309000 ts, 667 rew

agent-1: 243.0
agent-2: 224.0
agent-3: 235.0
Sum Reward: 702.0
Avg Reward: 234.0
Min Reward: 224.0
Max Reward: 243.0
Gini Coefficient: 0.018043684710351376
20:20 Ratio: 1.0848214285714286
Max-min Ratio: 1.0848214285714286
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-23-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 668.04
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 103
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.571
    dispatch_time_ms: 10.922
    learner:
      cur_lr: 0.0013394205598160625
      grad_gnorm: 40.0
      policy_entropy: 3.1337168216705322
      policy_loss: 3.9518423080444336
      var_gnorm: 28.117074966430664
      vf_explained_var: -0.1936168670654297
      vf_loss: 28.506200790405273
    num_steps_sampled: 312000
    num_steps_trained: 312000
    wait_time_ms: 72.511
  iterations_since_restore: 104
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 826.1310005187988
  time_this_iter_s: 8.003040790557861
  time_total_s: 826.1310005187988
  timestamp: 1594088582
  timesteps_since_restore: 312000
  timesteps_this_iter: 3000
  timesteps_total: 312000
  training_iteration: 104
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 826 s, 104 iter, 312000 ts, 668 rew

agent-1: 334.0
agent-2: 313.0
agent-3: 324.0
Sum Reward: 971.0
Avg Reward: 323.6666666666667
Min Reward: 313.0
Max Reward: 334.0
Gini Coefficient: 0.014418125643666324
20:20 Ratio: 1.0670926517571886
Max-min Ratio: 1.0670926517571886
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-23-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 672.32
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 104
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.285
    dispatch_time_ms: 10.073
    learner:
      cur_lr: 0.0013392207911238074
      grad_gnorm: 40.000003814697266
      policy_entropy: 6.797183990478516
      policy_loss: 4.989612102508545
      var_gnorm: 28.21648406982422
      vf_explained_var: -0.0559382438659668
      vf_loss: 33.07514953613281
    num_steps_sampled: 315000
    num_steps_trained: 315000
    wait_time_ms: 69.875
  iterations_since_restore: 105
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 834.3480362892151
  time_this_iter_s: 8.21703577041626
  time_total_s: 834.3480362892151
  timestamp: 1594088591
  timesteps_since_restore: 315000
  timesteps_this_iter: 3000
  timesteps_total: 315000
  training_iteration: 105
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 834 s, 105 iter, 315000 ts, 672 rew

agent-1: 368.0
agent-2: 337.0
agent-3: 318.0
Sum Reward: 1023.0
Avg Reward: 341.0
Min Reward: 318.0
Max Reward: 368.0
Gini Coefficient: 0.03258390355164549
20:20 Ratio: 1.1572327044025157
Max-min Ratio: 1.1572327044025157
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-23-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 676.08
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 105
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.117
    dispatch_time_ms: 7.384
    learner:
      cur_lr: 0.0013390210224315524
      grad_gnorm: 39.99999237060547
      policy_entropy: 5.638991832733154
      policy_loss: 5.837382793426514
      var_gnorm: 28.349143981933594
      vf_explained_var: 0.4002344012260437
      vf_loss: 11.537069320678711
    num_steps_sampled: 318000
    num_steps_trained: 318000
    wait_time_ms: 75.987
  iterations_since_restore: 106
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 842.6173098087311
  time_this_iter_s: 8.269273519515991
  time_total_s: 842.6173098087311
  timestamp: 1594088599
  timesteps_since_restore: 318000
  timesteps_this_iter: 3000
  timesteps_total: 318000
  training_iteration: 106
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 842 s, 106 iter, 318000 ts, 676 rew

agent-1: 335.0
agent-2: 356.0
agent-3: 358.0
Sum Reward: 1049.0
Avg Reward: 349.6666666666667
Min Reward: 335.0
Max Reward: 358.0
Gini Coefficient: 0.0146170956466476
20:20 Ratio: 1.0686567164179104
Max-min Ratio: 1.0686567164179104
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-23-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 679.45
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 106
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.392
    dispatch_time_ms: 6.092
    learner:
      cur_lr: 0.0013388212537392974
      grad_gnorm: 40.0
      policy_entropy: 4.949674606323242
      policy_loss: -10.916879653930664
      var_gnorm: 28.371936798095703
      vf_explained_var: 0.8694518804550171
      vf_loss: 26.444435119628906
    num_steps_sampled: 321000
    num_steps_trained: 321000
    wait_time_ms: 75.806
  iterations_since_restore: 107
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 850.9596738815308
  time_this_iter_s: 8.342364072799683
  time_total_s: 850.9596738815308
  timestamp: 1594088607
  timesteps_since_restore: 321000
  timesteps_this_iter: 3000
  timesteps_total: 321000
  training_iteration: 107
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 850 s, 107 iter, 321000 ts, 679 rew

agent-1: 357.0
agent-2: 305.0
agent-3: 240.0
Sum Reward: 902.0
Avg Reward: 300.6666666666667
Min Reward: 240.0
Max Reward: 357.0
Gini Coefficient: 0.08647450110864745
20:20 Ratio: 1.4875
Max-min Ratio: 1.4875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-23-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 682.38
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 107
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.678
    dispatch_time_ms: 8.201
    learner:
      cur_lr: 0.0013386213686317205
      grad_gnorm: 39.9999885559082
      policy_entropy: 9.816862106323242
      policy_loss: -10.057464599609375
      var_gnorm: 28.43556022644043
      vf_explained_var: 0.6970409154891968
      vf_loss: 47.03864288330078
    num_steps_sampled: 324000
    num_steps_trained: 324000
    wait_time_ms: 74.259
  iterations_since_restore: 108
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 858.9492998123169
  time_this_iter_s: 7.989625930786133
  time_total_s: 858.9492998123169
  timestamp: 1594088615
  timesteps_since_restore: 324000
  timesteps_this_iter: 3000
  timesteps_total: 324000
  training_iteration: 108
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 858 s, 108 iter, 324000 ts, 682 rew

agent-1: 364.0
agent-2: 246.0
agent-3: 294.0
Sum Reward: 904.0
Avg Reward: 301.3333333333333
Min Reward: 246.0
Max Reward: 364.0
Gini Coefficient: 0.08702064896755163
20:20 Ratio: 1.4796747967479675
Max-min Ratio: 1.4796747967479675
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-23-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 684.79
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 108
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.007
    dispatch_time_ms: 8.496
    learner:
      cur_lr: 0.0013384215999394655
      grad_gnorm: 39.99998474121094
      policy_entropy: 6.392978668212891
      policy_loss: 3.630736827850342
      var_gnorm: 28.57553482055664
      vf_explained_var: 0.7853662371635437
      vf_loss: 9.642478942871094
    num_steps_sampled: 327000
    num_steps_trained: 327000
    wait_time_ms: 69.698
  iterations_since_restore: 109
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 866.8861684799194
  time_this_iter_s: 7.936868667602539
  time_total_s: 866.8861684799194
  timestamp: 1594088623
  timesteps_since_restore: 327000
  timesteps_this_iter: 3000
  timesteps_total: 327000
  training_iteration: 109
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 866 s, 109 iter, 327000 ts, 685 rew

agent-1: 331.0
agent-2: 225.0
agent-3: 319.0
Sum Reward: 875.0
Avg Reward: 291.6666666666667
Min Reward: 225.0
Max Reward: 331.0
Gini Coefficient: 0.08076190476190476
20:20 Ratio: 1.471111111111111
Max-min Ratio: 1.471111111111111
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-23-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 686.27
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 109
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.543
    dispatch_time_ms: 11.423
    learner:
      cur_lr: 0.0013382218312472105
      grad_gnorm: 40.0
      policy_entropy: 10.594839096069336
      policy_loss: -34.11345672607422
      var_gnorm: 28.814287185668945
      vf_explained_var: 0.4723578095436096
      vf_loss: 113.36659240722656
    num_steps_sampled: 330000
    num_steps_trained: 330000
    wait_time_ms: 60.687
  iterations_since_restore: 110
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 876.9880330562592
  time_this_iter_s: 10.101864576339722
  time_total_s: 876.9880330562592
  timestamp: 1594088633
  timesteps_since_restore: 330000
  timesteps_this_iter: 3000
  timesteps_total: 330000
  training_iteration: 110
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 876 s, 110 iter, 330000 ts, 686 rew

agent-1: 353.0
agent-2: 243.0
agent-3: 359.0
Sum Reward: 955.0
Avg Reward: 318.3333333333333
Min Reward: 243.0
Max Reward: 359.0
Gini Coefficient: 0.08097731239092495
20:20 Ratio: 1.477366255144033
Max-min Ratio: 1.477366255144033
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-24-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 687.97
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 110
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.912
    dispatch_time_ms: 8.349
    learner:
      cur_lr: 0.0013380219461396337
      grad_gnorm: 31.184072494506836
      policy_entropy: 8.142314910888672
      policy_loss: 2.8233232498168945
      var_gnorm: 28.93815040588379
      vf_explained_var: 0.29479897022247314
      vf_loss: 7.597956657409668
    num_steps_sampled: 333000
    num_steps_trained: 333000
    wait_time_ms: 68.782
  iterations_since_restore: 111
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 884.7221496105194
  time_this_iter_s: 7.734116554260254
  time_total_s: 884.7221496105194
  timestamp: 1594088642
  timesteps_since_restore: 333000
  timesteps_this_iter: 3000
  timesteps_total: 333000
  training_iteration: 111
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 884 s, 111 iter, 333000 ts, 688 rew

agent-1: 340.0
agent-2: 340.0
agent-3: 331.0
Sum Reward: 1011.0
Avg Reward: 337.0
Min Reward: 331.0
Max Reward: 340.0
Gini Coefficient: 0.005934718100890208
20:20 Ratio: 1.027190332326284
Max-min Ratio: 1.027190332326284
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-24-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 692.61
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 111
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.791
    dispatch_time_ms: 10.505
    learner:
      cur_lr: 0.0013378221774473786
      grad_gnorm: 40.0
      policy_entropy: 11.069437026977539
      policy_loss: -0.9862878322601318
      var_gnorm: 29.01557159423828
      vf_explained_var: 0.38152843713760376
      vf_loss: 26.42148208618164
    num_steps_sampled: 336000
    num_steps_trained: 336000
    wait_time_ms: 75.808
  iterations_since_restore: 112
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 893.0028734207153
  time_this_iter_s: 8.280723810195923
  time_total_s: 893.0028734207153
  timestamp: 1594088651
  timesteps_since_restore: 336000
  timesteps_this_iter: 3000
  timesteps_total: 336000
  training_iteration: 112
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 893 s, 112 iter, 336000 ts, 693 rew

agent-1: 330.0
agent-2: 354.0
agent-3: 332.0
Sum Reward: 1016.0
Avg Reward: 338.6666666666667
Min Reward: 330.0
Max Reward: 354.0
Gini Coefficient: 0.015748031496062992
20:20 Ratio: 1.0727272727272728
Max-min Ratio: 1.0727272727272728
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-24-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 697.72
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 112
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.673
    dispatch_time_ms: 9.398
    learner:
      cur_lr: 0.0013376224087551236
      grad_gnorm: 40.000003814697266
      policy_entropy: 11.244112014770508
      policy_loss: 12.779603958129883
      var_gnorm: 29.098230361938477
      vf_explained_var: -1.0
      vf_loss: 29.024221420288086
    num_steps_sampled: 339000
    num_steps_trained: 339000
    wait_time_ms: 67.439
  iterations_since_restore: 113
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 901.3280565738678
  time_this_iter_s: 8.325183153152466
  time_total_s: 901.3280565738678
  timestamp: 1594088659
  timesteps_since_restore: 339000
  timesteps_this_iter: 3000
  timesteps_total: 339000
  training_iteration: 113
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 901 s, 113 iter, 339000 ts, 698 rew

agent-1: 349.0
agent-2: 348.0
agent-3: 310.0
Sum Reward: 1007.0
Avg Reward: 335.6666666666667
Min Reward: 310.0
Max Reward: 349.0
Gini Coefficient: 0.025819265143992055
20:20 Ratio: 1.1258064516129032
Max-min Ratio: 1.1258064516129032
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-24-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 700.23
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 113
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.436
    dispatch_time_ms: 7.069
    learner:
      cur_lr: 0.0013374226400628686
      grad_gnorm: 16.548240661621094
      policy_entropy: 16.994707107543945
      policy_loss: -0.4353523254394531
      var_gnorm: 29.15645980834961
      vf_explained_var: -0.22713494300842285
      vf_loss: 12.755376815795898
    num_steps_sampled: 342000
    num_steps_trained: 342000
    wait_time_ms: 65.794
  iterations_since_restore: 114
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 909.3577377796173
  time_this_iter_s: 8.029681205749512
  time_total_s: 909.3577377796173
  timestamp: 1594088667
  timesteps_since_restore: 342000
  timesteps_this_iter: 3000
  timesteps_total: 342000
  training_iteration: 114
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 909 s, 114 iter, 342000 ts, 700 rew

agent-1: 355.0
agent-2: 334.0
agent-3: 289.0
Sum Reward: 978.0
Avg Reward: 326.0
Min Reward: 289.0
Max Reward: 355.0
Gini Coefficient: 0.044989775051124746
20:20 Ratio: 1.2283737024221453
Max-min Ratio: 1.2283737024221453
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-24-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 701.84
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 114
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.249
    dispatch_time_ms: 8.316
    learner:
      cur_lr: 0.0013372227549552917
      grad_gnorm: 40.0
      policy_entropy: 6.362393379211426
      policy_loss: 3.8697290420532227
      var_gnorm: 29.143613815307617
      vf_explained_var: -0.467418909072876
      vf_loss: 104.04562377929688
    num_steps_sampled: 345000
    num_steps_trained: 345000
    wait_time_ms: 63.594
  iterations_since_restore: 115
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 917.5322685241699
  time_this_iter_s: 8.174530744552612
  time_total_s: 917.5322685241699
  timestamp: 1594088675
  timesteps_since_restore: 345000
  timesteps_this_iter: 3000
  timesteps_total: 345000
  training_iteration: 115
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 917 s, 115 iter, 345000 ts, 702 rew

agent-1: 333.0
agent-2: 259.0
agent-3: 316.0
Sum Reward: 908.0
Avg Reward: 302.6666666666667
Min Reward: 259.0
Max Reward: 333.0
Gini Coefficient: 0.05433186490455213
20:20 Ratio: 1.2857142857142858
Max-min Ratio: 1.2857142857142858
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-24-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 701.48
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 115
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.336
    dispatch_time_ms: 7.444
    learner:
      cur_lr: 0.0013370229862630367
      grad_gnorm: 39.999996185302734
      policy_entropy: 6.781604290008545
      policy_loss: -1.568985939025879
      var_gnorm: 29.210798263549805
      vf_explained_var: 0.848921537399292
      vf_loss: 36.59482192993164
    num_steps_sampled: 348000
    num_steps_trained: 348000
    wait_time_ms: 78.156
  iterations_since_restore: 116
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 925.7202835083008
  time_this_iter_s: 8.18801498413086
  time_total_s: 925.7202835083008
  timestamp: 1594088684
  timesteps_since_restore: 348000
  timesteps_this_iter: 3000
  timesteps_total: 348000
  training_iteration: 116
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 925 s, 116 iter, 348000 ts, 701 rew

agent-1: 299.0
agent-2: 253.0
agent-3: 76.0
Sum Reward: 628.0
Avg Reward: 209.33333333333334
Min Reward: 76.0
Max Reward: 299.0
Gini Coefficient: 0.2367303609341826
20:20 Ratio: 3.9342105263157894
Max-min Ratio: 3.9342105263157894
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-24-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 698.14
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 116
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.908
    dispatch_time_ms: 9.906
    learner:
      cur_lr: 0.0013368232175707817
      grad_gnorm: 40.0
      policy_entropy: 5.696651935577393
      policy_loss: -2.093926191329956
      var_gnorm: 29.54004669189453
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 13.527059555053711
    num_steps_sampled: 351000
    num_steps_trained: 351000
    wait_time_ms: 62.676
  iterations_since_restore: 117
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 933.2850060462952
  time_this_iter_s: 7.564722537994385
  time_total_s: 933.2850060462952
  timestamp: 1594088691
  timesteps_since_restore: 351000
  timesteps_this_iter: 3000
  timesteps_total: 351000
  training_iteration: 117
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 933 s, 117 iter, 351000 ts, 698 rew

agent-1: 211.0
agent-2: 177.0
agent-3: 164.0
Sum Reward: 552.0
Avg Reward: 184.0
Min Reward: 164.0
Max Reward: 211.0
Gini Coefficient: 0.05676328502415459
20:20 Ratio: 1.2865853658536586
Max-min Ratio: 1.2865853658536586
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-24-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 693.85
  episode_reward_min: 128.0
  episodes_this_iter: 1
  episodes_total: 117
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.837
    dispatch_time_ms: 9.487
    learner:
      cur_lr: 0.0013366234488785267
      grad_gnorm: 38.63842010498047
      policy_entropy: 19.25197410583496
      policy_loss: 3.7375881671905518
      var_gnorm: 29.565818786621094
      vf_explained_var: 0.0
      vf_loss: 14.826201438903809
    num_steps_sampled: 354000
    num_steps_trained: 354000
    wait_time_ms: 68.234
  iterations_since_restore: 118
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 940.3236334323883
  time_this_iter_s: 7.03862738609314
  time_total_s: 940.3236334323883
  timestamp: 1594088698
  timesteps_since_restore: 354000
  timesteps_this_iter: 3000
  timesteps_total: 354000
  training_iteration: 118
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 940 s, 118 iter, 354000 ts, 694 rew

agent-1: 22.0
agent-2: 18.0
agent-3: 84.0
Sum Reward: 124.0
Avg Reward: 41.333333333333336
Min Reward: 18.0
Max Reward: 84.0
Gini Coefficient: 0.3548387096774194
20:20 Ratio: 4.666666666666667
Max-min Ratio: 4.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-25-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 685.17
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 118
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.637
    dispatch_time_ms: 10.71
    learner:
      cur_lr: 0.0013364235637709498
      grad_gnorm: 37.54361343383789
      policy_entropy: 6.785358428955078
      policy_loss: 11.684295654296875
      var_gnorm: 29.600069046020508
      vf_explained_var: 0.0
      vf_loss: 31.983957290649414
    num_steps_sampled: 357000
    num_steps_trained: 357000
    wait_time_ms: 61.256
  iterations_since_restore: 119
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 947.9920291900635
  time_this_iter_s: 7.668395757675171
  time_total_s: 947.9920291900635
  timestamp: 1594088706
  timesteps_since_restore: 357000
  timesteps_this_iter: 3000
  timesteps_total: 357000
  training_iteration: 119
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 947 s, 119 iter, 357000 ts, 685 rew

agent-1: 146.0
agent-2: 90.0
agent-3: 125.0
Sum Reward: 361.0
Avg Reward: 120.33333333333333
Min Reward: 90.0
Max Reward: 146.0
Gini Coefficient: 0.10341643582640812
20:20 Ratio: 1.6222222222222222
Max-min Ratio: 1.6222222222222222
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-25-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 681.39
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 119
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.924
    dispatch_time_ms: 15.73
    learner:
      cur_lr: 0.0013362237950786948
      grad_gnorm: 16.886390686035156
      policy_entropy: 14.628755569458008
      policy_loss: 0.35227489471435547
      var_gnorm: 29.608091354370117
      vf_explained_var: 0.06639260053634644
      vf_loss: 3.6966447830200195
    num_steps_sampled: 360000
    num_steps_trained: 360000
    wait_time_ms: 55.724
  iterations_since_restore: 120
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 955.3685576915741
  time_this_iter_s: 7.37652850151062
  time_total_s: 955.3685576915741
  timestamp: 1594088713
  timesteps_since_restore: 360000
  timesteps_this_iter: 3000
  timesteps_total: 360000
  training_iteration: 120
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 955 s, 120 iter, 360000 ts, 681 rew

agent-1: 162.0
agent-2: 101.0
agent-3: 149.0
Sum Reward: 412.0
Avg Reward: 137.33333333333334
Min Reward: 101.0
Max Reward: 162.0
Gini Coefficient: 0.09870550161812297
20:20 Ratio: 1.603960396039604
Max-min Ratio: 1.603960396039604
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-25-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 677.51
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 120
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.694
    dispatch_time_ms: 27.858
    learner:
      cur_lr: 0.0013360240263864398
      grad_gnorm: 40.0
      policy_entropy: 8.026535987854004
      policy_loss: -3.9292073249816895
      var_gnorm: 29.67597770690918
      vf_explained_var: 0.12525594234466553
      vf_loss: 7.878557205200195
    num_steps_sampled: 363000
    num_steps_trained: 363000
    wait_time_ms: 37.777
  iterations_since_restore: 121
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 967.9775981903076
  time_this_iter_s: 12.60904049873352
  time_total_s: 967.9775981903076
  timestamp: 1594088727
  timesteps_since_restore: 363000
  timesteps_this_iter: 3000
  timesteps_total: 363000
  training_iteration: 121
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 967 s, 121 iter, 363000 ts, 678 rew

agent-1: 207.0
agent-2: 152.0
agent-3: 156.0
Sum Reward: 515.0
Avg Reward: 171.66666666666666
Min Reward: 152.0
Max Reward: 207.0
Gini Coefficient: 0.07119741100323625
20:20 Ratio: 1.361842105263158
Max-min Ratio: 1.361842105263158
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-25-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 681.38
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 121
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.229
    dispatch_time_ms: 28.001
    learner:
      cur_lr: 0.0013358242576941848
      grad_gnorm: 40.0
      policy_entropy: 8.365911483764648
      policy_loss: 9.933076858520508
      var_gnorm: 29.79071044921875
      vf_explained_var: 0.3949359655380249
      vf_loss: 20.883420944213867
    num_steps_sampled: 366000
    num_steps_trained: 366000
    wait_time_ms: 54.676
  iterations_since_restore: 122
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 975.8719158172607
  time_this_iter_s: 7.894317626953125
  time_total_s: 975.8719158172607
  timestamp: 1594088735
  timesteps_since_restore: 366000
  timesteps_this_iter: 3000
  timesteps_total: 366000
  training_iteration: 122
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 975 s, 122 iter, 366000 ts, 681 rew

agent-1: 281.0
agent-2: 271.0
agent-3: 251.0
Sum Reward: 803.0
Avg Reward: 267.6666666666667
Min Reward: 251.0
Max Reward: 281.0
Gini Coefficient: 0.024906600249066
20:20 Ratio: 1.1195219123505975
Max-min Ratio: 1.1195219123505975
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-25-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 688.01
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 122
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.585
    dispatch_time_ms: 27.878
    learner:
      cur_lr: 0.001335624372586608
      grad_gnorm: 40.0
      policy_entropy: 6.881904602050781
      policy_loss: 5.528651237487793
      var_gnorm: 29.96406364440918
      vf_explained_var: 0.10394680500030518
      vf_loss: 24.929580688476562
    num_steps_sampled: 369000
    num_steps_trained: 369000
    wait_time_ms: 31.749
  iterations_since_restore: 123
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 984.0699119567871
  time_this_iter_s: 8.197996139526367
  time_total_s: 984.0699119567871
  timestamp: 1594088743
  timesteps_since_restore: 369000
  timesteps_this_iter: 3000
  timesteps_total: 369000
  training_iteration: 123
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 984 s, 123 iter, 369000 ts, 688 rew

agent-1: 277.0
agent-2: 307.0
agent-3: 285.0
Sum Reward: 869.0
Avg Reward: 289.6666666666667
Min Reward: 277.0
Max Reward: 307.0
Gini Coefficient: 0.023014959723820484
20:20 Ratio: 1.108303249097473
Max-min Ratio: 1.108303249097473
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-25-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 694.08
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 123
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.111
    dispatch_time_ms: 35.953
    learner:
      cur_lr: 0.001335424603894353
      grad_gnorm: 40.0
      policy_entropy: 3.097153663635254
      policy_loss: 2.059516668319702
      var_gnorm: 30.112258911132812
      vf_explained_var: 0.44843775033950806
      vf_loss: 13.762579917907715
    num_steps_sampled: 372000
    num_steps_trained: 372000
    wait_time_ms: 47.818
  iterations_since_restore: 124
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 992.411740064621
  time_this_iter_s: 8.341828107833862
  time_total_s: 992.411740064621
  timestamp: 1594088751
  timesteps_since_restore: 372000
  timesteps_this_iter: 3000
  timesteps_total: 372000
  training_iteration: 124
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 992 s, 124 iter, 372000 ts, 694 rew

agent-1: 263.0
agent-2: 358.0
agent-3: 243.0
Sum Reward: 864.0
Avg Reward: 288.0
Min Reward: 243.0
Max Reward: 358.0
Gini Coefficient: 0.08873456790123457
20:20 Ratio: 1.4732510288065843
Max-min Ratio: 1.4732510288065843
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-26-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 699.65
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 124
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 38.808
    dispatch_time_ms: 22.345
    learner:
      cur_lr: 0.001335224835202098
      grad_gnorm: 40.000003814697266
      policy_entropy: 15.13709545135498
      policy_loss: 27.69319725036621
      var_gnorm: 30.277584075927734
      vf_explained_var: 0.13452792167663574
      vf_loss: 63.39901351928711
    num_steps_sampled: 375000
    num_steps_trained: 375000
    wait_time_ms: 34.602
  iterations_since_restore: 125
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1000.7837402820587
  time_this_iter_s: 8.372000217437744
  time_total_s: 1000.7837402820587
  timestamp: 1594088760
  timesteps_since_restore: 375000
  timesteps_this_iter: 3000
  timesteps_total: 375000
  training_iteration: 125
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1000 s, 125 iter, 375000 ts, 700 rew

agent-1: 167.0
agent-2: 301.0
agent-3: 298.0
Sum Reward: 766.0
Avg Reward: 255.33333333333334
Min Reward: 167.0
Max Reward: 301.0
Gini Coefficient: 0.11662315056570931
20:20 Ratio: 1.8023952095808384
Max-min Ratio: 1.8023952095808384
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-26-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 703.35
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 125
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.452
    dispatch_time_ms: 36.055
    learner:
      cur_lr: 0.001335024950094521
      grad_gnorm: 40.0
      policy_entropy: 5.712013244628906
      policy_loss: 10.401968002319336
      var_gnorm: 30.308509826660156
      vf_explained_var: -0.46005868911743164
      vf_loss: 27.738731384277344
    num_steps_sampled: 378000
    num_steps_trained: 378000
    wait_time_ms: 50.691
  iterations_since_restore: 126
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1008.4504110813141
  time_this_iter_s: 7.666670799255371
  time_total_s: 1008.4504110813141
  timestamp: 1594088767
  timesteps_since_restore: 378000
  timesteps_this_iter: 3000
  timesteps_total: 378000
  training_iteration: 126
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1008 s, 126 iter, 378000 ts, 703 rew

agent-1: 239.0
agent-2: 203.0
agent-3: 186.0
Sum Reward: 628.0
Avg Reward: 209.33333333333334
Min Reward: 186.0
Max Reward: 239.0
Gini Coefficient: 0.05626326963906582
20:20 Ratio: 1.2849462365591398
Max-min Ratio: 1.2849462365591398
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-26-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 706.02
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 126
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.73
    dispatch_time_ms: 24.058
    learner:
      cur_lr: 0.001334825181402266
      grad_gnorm: 40.000003814697266
      policy_entropy: 9.837389945983887
      policy_loss: 23.90545082092285
      var_gnorm: 30.396318435668945
      vf_explained_var: -0.44044530391693115
      vf_loss: 65.20317077636719
    num_steps_sampled: 381000
    num_steps_trained: 381000
    wait_time_ms: 61.542
  iterations_since_restore: 127
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1016.6688742637634
  time_this_iter_s: 8.21846318244934
  time_total_s: 1016.6688742637634
  timestamp: 1594088777
  timesteps_since_restore: 381000
  timesteps_this_iter: 3000
  timesteps_total: 381000
  training_iteration: 127
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1016 s, 127 iter, 381000 ts, 706 rew

agent-1: 318.0
agent-2: 301.0
agent-3: 316.0
Sum Reward: 935.0
Avg Reward: 311.6666666666667
Min Reward: 301.0
Max Reward: 318.0
Gini Coefficient: 0.012121212121212121
20:20 Ratio: 1.0564784053156147
Max-min Ratio: 1.0564784053156147
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-26-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 712.88
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 127
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.532
    dispatch_time_ms: 16.405
    learner:
      cur_lr: 0.001334625412710011
      grad_gnorm: 40.0
      policy_entropy: 8.301685333251953
      policy_loss: 7.484916687011719
      var_gnorm: 30.518735885620117
      vf_explained_var: 0.1501713991165161
      vf_loss: 24.364227294921875
    num_steps_sampled: 384000
    num_steps_trained: 384000
    wait_time_ms: 66.546
  iterations_since_restore: 128
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1025.3712952136993
  time_this_iter_s: 8.702420949935913
  time_total_s: 1025.3712952136993
  timestamp: 1594088785
  timesteps_since_restore: 384000
  timesteps_this_iter: 3000
  timesteps_total: 384000
  training_iteration: 128
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1025 s, 128 iter, 384000 ts, 713 rew

agent-1: 383.0
agent-2: 346.0
agent-3: 344.0
Sum Reward: 1073.0
Avg Reward: 357.6666666666667
Min Reward: 344.0
Max Reward: 383.0
Gini Coefficient: 0.024231127679403542
20:20 Ratio: 1.1133720930232558
Max-min Ratio: 1.1133720930232558
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-26-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 720.39
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 128
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.692
    dispatch_time_ms: 28.994
    learner:
      cur_lr: 0.001334425644017756
      grad_gnorm: 39.999996185302734
      policy_entropy: 9.632704734802246
      policy_loss: -6.522852420806885
      var_gnorm: 30.636554718017578
      vf_explained_var: 0.22966045141220093
      vf_loss: 50.703948974609375
    num_steps_sampled: 387000
    num_steps_trained: 387000
    wait_time_ms: 65.138
  iterations_since_restore: 129
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1034.110851764679
  time_this_iter_s: 8.739556550979614
  time_total_s: 1034.110851764679
  timestamp: 1594088794
  timesteps_since_restore: 387000
  timesteps_this_iter: 3000
  timesteps_total: 387000
  training_iteration: 129
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1034 s, 129 iter, 387000 ts, 720 rew

agent-1: 376.0
agent-2: 301.0
agent-3: 315.0
Sum Reward: 992.0
Avg Reward: 330.6666666666667
Min Reward: 301.0
Max Reward: 376.0
Gini Coefficient: 0.05040322580645161
20:20 Ratio: 1.2491694352159468
Max-min Ratio: 1.2491694352159468
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-26-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 725.81
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 129
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.277
    dispatch_time_ms: 34.649
    learner:
      cur_lr: 0.0013342257589101791
      grad_gnorm: 14.51280403137207
      policy_entropy: 5.320499420166016
      policy_loss: 1.280490756034851
      var_gnorm: 30.714956283569336
      vf_explained_var: 0.475368857383728
      vf_loss: 6.380323886871338
    num_steps_sampled: 390000
    num_steps_trained: 390000
    wait_time_ms: 56.804
  iterations_since_restore: 130
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1042.610191822052
  time_this_iter_s: 8.499340057373047
  time_total_s: 1042.610191822052
  timestamp: 1594088803
  timesteps_since_restore: 390000
  timesteps_this_iter: 3000
  timesteps_total: 390000
  training_iteration: 130
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1042 s, 130 iter, 390000 ts, 726 rew

agent-1: 348.0
agent-2: 291.0
agent-3: 300.0
Sum Reward: 939.0
Avg Reward: 313.0
Min Reward: 291.0
Max Reward: 348.0
Gini Coefficient: 0.04046858359957402
20:20 Ratio: 1.1958762886597938
Max-min Ratio: 1.1958762886597938
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-26-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 731.04
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 130
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.043
    dispatch_time_ms: 19.342
    learner:
      cur_lr: 0.0013340259902179241
      grad_gnorm: 40.0
      policy_entropy: 6.861574649810791
      policy_loss: 2.0756895542144775
      var_gnorm: 30.840787887573242
      vf_explained_var: 0.006340920925140381
      vf_loss: 24.05142593383789
    num_steps_sampled: 393000
    num_steps_trained: 393000
    wait_time_ms: 64.179
  iterations_since_restore: 131
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1051.2545998096466
  time_this_iter_s: 8.644407987594604
  time_total_s: 1051.2545998096466
  timestamp: 1594088811
  timesteps_since_restore: 393000
  timesteps_this_iter: 3000
  timesteps_total: 393000
  training_iteration: 131
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1051 s, 131 iter, 393000 ts, 731 rew

agent-1: 348.0
agent-2: 286.0
agent-3: 338.0
Sum Reward: 972.0
Avg Reward: 324.0
Min Reward: 286.0
Max Reward: 348.0
Gini Coefficient: 0.04252400548696845
20:20 Ratio: 1.2167832167832169
Max-min Ratio: 1.2167832167832169
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-27-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 735.75
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 131
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.551
    dispatch_time_ms: 20.955
    learner:
      cur_lr: 0.001333826221525669
      grad_gnorm: 36.41162109375
      policy_entropy: 12.7011079788208
      policy_loss: -8.593297958374023
      var_gnorm: 30.972946166992188
      vf_explained_var: -0.08054780960083008
      vf_loss: 28.185426712036133
    num_steps_sampled: 396000
    num_steps_trained: 396000
    wait_time_ms: 57.974
  iterations_since_restore: 132
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1059.506460905075
  time_this_iter_s: 8.251861095428467
  time_total_s: 1059.506460905075
  timestamp: 1594088820
  timesteps_since_restore: 396000
  timesteps_this_iter: 3000
  timesteps_total: 396000
  training_iteration: 132
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1059 s, 132 iter, 396000 ts, 736 rew

agent-1: 310.0
agent-2: 283.0
agent-3: 277.0
Sum Reward: 870.0
Avg Reward: 290.0
Min Reward: 277.0
Max Reward: 310.0
Gini Coefficient: 0.02528735632183908
20:20 Ratio: 1.1191335740072201
Max-min Ratio: 1.1191335740072201
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-27-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 739.2
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 132
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.365
    dispatch_time_ms: 17.442
    learner:
      cur_lr: 0.001333626452833414
      grad_gnorm: 40.0
      policy_entropy: 13.503679275512695
      policy_loss: -22.04045295715332
      var_gnorm: 31.03068733215332
      vf_explained_var: 0.7779035568237305
      vf_loss: 49.9449348449707
    num_steps_sampled: 399000
    num_steps_trained: 399000
    wait_time_ms: 44.899
  iterations_since_restore: 133
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1067.9415836334229
  time_this_iter_s: 8.435122728347778
  time_total_s: 1067.9415836334229
  timestamp: 1594088828
  timesteps_since_restore: 399000
  timesteps_this_iter: 3000
  timesteps_total: 399000
  training_iteration: 133
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1067 s, 133 iter, 399000 ts, 739 rew

agent-1: 297.0
agent-2: 306.0
agent-3: 325.0
Sum Reward: 928.0
Avg Reward: 309.3333333333333
Min Reward: 297.0
Max Reward: 325.0
Gini Coefficient: 0.020114942528735632
20:20 Ratio: 1.0942760942760943
Max-min Ratio: 1.0942760942760943
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-27-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 743.09
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 133
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.755
    dispatch_time_ms: 42.667
    learner:
      cur_lr: 0.0013334265677258372
      grad_gnorm: 37.14869689941406
      policy_entropy: 13.185857772827148
      policy_loss: -2.1787450313568115
      var_gnorm: 31.116666793823242
      vf_explained_var: 0.3776024580001831
      vf_loss: 21.917333602905273
    num_steps_sampled: 402000
    num_steps_trained: 402000
    wait_time_ms: 26.67
  iterations_since_restore: 134
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1076.472867012024
  time_this_iter_s: 8.531283378601074
  time_total_s: 1076.472867012024
  timestamp: 1594088837
  timesteps_since_restore: 402000
  timesteps_this_iter: 3000
  timesteps_total: 402000
  training_iteration: 134
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1076 s, 134 iter, 402000 ts, 743 rew

agent-1: 295.0
agent-2: 300.0
agent-3: 332.0
Sum Reward: 927.0
Avg Reward: 309.0
Min Reward: 295.0
Max Reward: 332.0
Gini Coefficient: 0.02660913340524991
20:20 Ratio: 1.1254237288135593
Max-min Ratio: 1.1254237288135593
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-27-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 747.62
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 134
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.271
    dispatch_time_ms: 14.372
    learner:
      cur_lr: 0.0013332267990335822
      grad_gnorm: 40.0
      policy_entropy: 10.302952766418457
      policy_loss: -8.238397598266602
      var_gnorm: 31.1242733001709
      vf_explained_var: 0.5474352836608887
      vf_loss: 4.8210625648498535
    num_steps_sampled: 405000
    num_steps_trained: 405000
    wait_time_ms: 59.507
  iterations_since_restore: 135
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1085.0460534095764
  time_this_iter_s: 8.57318639755249
  time_total_s: 1085.0460534095764
  timestamp: 1594088845
  timesteps_since_restore: 405000
  timesteps_this_iter: 3000
  timesteps_total: 405000
  training_iteration: 135
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1085 s, 135 iter, 405000 ts, 748 rew

agent-1: 336.0
agent-2: 351.0
agent-3: 334.0
Sum Reward: 1021.0
Avg Reward: 340.3333333333333
Min Reward: 334.0
Max Reward: 351.0
Gini Coefficient: 0.01110022853411688
20:20 Ratio: 1.0508982035928143
Max-min Ratio: 1.0508982035928143
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-27-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 753.67
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 135
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.667
    dispatch_time_ms: 46.312
    learner:
      cur_lr: 0.0013330270303413272
      grad_gnorm: 40.0
      policy_entropy: 10.403656005859375
      policy_loss: -5.418492317199707
      var_gnorm: 31.20663070678711
      vf_explained_var: 0.5660803318023682
      vf_loss: 35.447696685791016
    num_steps_sampled: 408000
    num_steps_trained: 408000
    wait_time_ms: 40.355
  iterations_since_restore: 136
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1093.4618635177612
  time_this_iter_s: 8.415810108184814
  time_total_s: 1093.4618635177612
  timestamp: 1594088854
  timesteps_since_restore: 408000
  timesteps_this_iter: 3000
  timesteps_total: 408000
  training_iteration: 136
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1093 s, 136 iter, 408000 ts, 754 rew

agent-1: 306.0
agent-2: 300.0
agent-3: 283.0
Sum Reward: 889.0
Avg Reward: 296.3333333333333
Min Reward: 283.0
Max Reward: 306.0
Gini Coefficient: 0.01724784401949756
20:20 Ratio: 1.0812720848056536
Max-min Ratio: 1.0812720848056536
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-27-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 758.7
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 136
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.678
    dispatch_time_ms: 42.966
    learner:
      cur_lr: 0.0013328271452337503
      grad_gnorm: 40.0
      policy_entropy: 14.302987098693848
      policy_loss: -13.883941650390625
      var_gnorm: 31.219398498535156
      vf_explained_var: 0.7740041613578796
      vf_loss: 36.25372314453125
    num_steps_sampled: 411000
    num_steps_trained: 411000
    wait_time_ms: 43.827
  iterations_since_restore: 137
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1102.45103764534
  time_this_iter_s: 8.989174127578735
  time_total_s: 1102.45103764534
  timestamp: 1594088863
  timesteps_since_restore: 411000
  timesteps_this_iter: 3000
  timesteps_total: 411000
  training_iteration: 137
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1102 s, 137 iter, 411000 ts, 759 rew

agent-1: 262.0
agent-2: 325.0
agent-3: 316.0
Sum Reward: 903.0
Avg Reward: 301.0
Min Reward: 262.0
Max Reward: 325.0
Gini Coefficient: 0.046511627906976744
20:20 Ratio: 1.2404580152671756
Max-min Ratio: 1.2404580152671756
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-27-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 763.16
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 137
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.43
    dispatch_time_ms: 27.443
    learner:
      cur_lr: 0.0013326273765414953
      grad_gnorm: 39.999996185302734
      policy_entropy: 11.032968521118164
      policy_loss: 16.43773651123047
      var_gnorm: 31.324665069580078
      vf_explained_var: 0.6727918982505798
      vf_loss: 13.687192916870117
    num_steps_sampled: 414000
    num_steps_trained: 414000
    wait_time_ms: 54.387
  iterations_since_restore: 138
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1110.9147033691406
  time_this_iter_s: 8.46366572380066
  time_total_s: 1110.9147033691406
  timestamp: 1594088871
  timesteps_since_restore: 414000
  timesteps_this_iter: 3000
  timesteps_total: 414000
  training_iteration: 138
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1110 s, 138 iter, 414000 ts, 763 rew

agent-1: 341.0
agent-2: 366.0
agent-3: 290.0
Sum Reward: 997.0
Avg Reward: 332.3333333333333
Min Reward: 290.0
Max Reward: 366.0
Gini Coefficient: 0.05081912403878302
20:20 Ratio: 1.2620689655172415
Max-min Ratio: 1.2620689655172415
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-28-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 768.38
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 138
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.055
    dispatch_time_ms: 33.363
    learner:
      cur_lr: 0.0013324276078492403
      grad_gnorm: 17.767135620117188
      policy_entropy: 11.370973587036133
      policy_loss: -4.312943935394287
      var_gnorm: 31.409284591674805
      vf_explained_var: 0.2666146159172058
      vf_loss: 34.903953552246094
    num_steps_sampled: 417000
    num_steps_trained: 417000
    wait_time_ms: 45.951
  iterations_since_restore: 139
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1119.3364474773407
  time_this_iter_s: 8.421744108200073
  time_total_s: 1119.3364474773407
  timestamp: 1594088880
  timesteps_since_restore: 417000
  timesteps_this_iter: 3000
  timesteps_total: 417000
  training_iteration: 139
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1119 s, 139 iter, 417000 ts, 768 rew

agent-1: 298.0
agent-2: 367.0
agent-3: 318.0
Sum Reward: 983.0
Avg Reward: 327.6666666666667
Min Reward: 298.0
Max Reward: 367.0
Gini Coefficient: 0.04679552390640895
20:20 Ratio: 1.2315436241610738
Max-min Ratio: 1.2315436241610738
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-28-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 773.69
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 139
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.59
    dispatch_time_ms: 27.306
    learner:
      cur_lr: 0.0013322278391569853
      grad_gnorm: 40.0
      policy_entropy: 14.242149353027344
      policy_loss: -13.63351058959961
      var_gnorm: 31.49871826171875
      vf_explained_var: 0.6104205250740051
      vf_loss: 33.635135650634766
    num_steps_sampled: 420000
    num_steps_trained: 420000
    wait_time_ms: 47.985
  iterations_since_restore: 140
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1128.0085248947144
  time_this_iter_s: 8.672077417373657
  time_total_s: 1128.0085248947144
  timestamp: 1594088888
  timesteps_since_restore: 420000
  timesteps_this_iter: 3000
  timesteps_total: 420000
  training_iteration: 140
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1128 s, 140 iter, 420000 ts, 774 rew

agent-1: 307.0
agent-2: 321.0
agent-3: 293.0
Sum Reward: 921.0
Avg Reward: 307.0
Min Reward: 293.0
Max Reward: 321.0
Gini Coefficient: 0.020267824828085413
20:20 Ratio: 1.0955631399317407
Max-min Ratio: 1.0955631399317407
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-28-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 779.46
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 140
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.673
    dispatch_time_ms: 29.721
    learner:
      cur_lr: 0.0013320279540494084
      grad_gnorm: 40.0
      policy_entropy: 10.26858901977539
      policy_loss: -5.945267200469971
      var_gnorm: 31.480995178222656
      vf_explained_var: 0.3752771019935608
      vf_loss: 9.593232154846191
    num_steps_sampled: 423000
    num_steps_trained: 423000
    wait_time_ms: 49.419
  iterations_since_restore: 141
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1136.3349137306213
  time_this_iter_s: 8.326388835906982
  time_total_s: 1136.3349137306213
  timestamp: 1594088897
  timesteps_since_restore: 423000
  timesteps_this_iter: 3000
  timesteps_total: 423000
  training_iteration: 141
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1136 s, 141 iter, 423000 ts, 779 rew

agent-1: 303.0
agent-2: 317.0
agent-3: 331.0
Sum Reward: 951.0
Avg Reward: 317.0
Min Reward: 303.0
Max Reward: 331.0
Gini Coefficient: 0.01962846126883982
20:20 Ratio: 1.0924092409240924
Max-min Ratio: 1.0924092409240924
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-28-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 784.62
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 141
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.676
    dispatch_time_ms: 43.683
    learner:
      cur_lr: 0.0013318281853571534
      grad_gnorm: 39.99999237060547
      policy_entropy: 6.649463653564453
      policy_loss: 2.9201881885528564
      var_gnorm: 31.563369750976562
      vf_explained_var: 0.07451075315475464
      vf_loss: 17.752988815307617
    num_steps_sampled: 426000
    num_steps_trained: 426000
    wait_time_ms: 38.105
  iterations_since_restore: 142
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1144.7096438407898
  time_this_iter_s: 8.374730110168457
  time_total_s: 1144.7096438407898
  timestamp: 1594088905
  timesteps_since_restore: 426000
  timesteps_this_iter: 3000
  timesteps_total: 426000
  training_iteration: 142
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1144 s, 142 iter, 426000 ts, 785 rew

agent-1: 346.0
agent-2: 359.0
agent-3: 325.0
Sum Reward: 1030.0
Avg Reward: 343.3333333333333
Min Reward: 325.0
Max Reward: 359.0
Gini Coefficient: 0.022006472491909384
20:20 Ratio: 1.1046153846153846
Max-min Ratio: 1.1046153846153846
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-28-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 790.88
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 142
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.794
    dispatch_time_ms: 30.728
    learner:
      cur_lr: 0.0013316284166648984
      grad_gnorm: 39.92292022705078
      policy_entropy: 10.090719223022461
      policy_loss: -1.3207011222839355
      var_gnorm: 31.601652145385742
      vf_explained_var: 0.42314785718917847
      vf_loss: 25.120899200439453
    num_steps_sampled: 429000
    num_steps_trained: 429000
    wait_time_ms: 55.343
  iterations_since_restore: 143
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1153.4317080974579
  time_this_iter_s: 8.72206425666809
  time_total_s: 1153.4317080974579
  timestamp: 1594088914
  timesteps_since_restore: 429000
  timesteps_this_iter: 3000
  timesteps_total: 429000
  training_iteration: 143
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1153 s, 143 iter, 429000 ts, 791 rew

agent-1: 305.0
agent-2: 327.0
agent-3: 369.0
Sum Reward: 1001.0
Avg Reward: 333.6666666666667
Min Reward: 305.0
Max Reward: 369.0
Gini Coefficient: 0.042624042624042624
20:20 Ratio: 1.2098360655737705
Max-min Ratio: 1.2098360655737705
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-28-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 795.71
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 143
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.891
    dispatch_time_ms: 52.569
    learner:
      cur_lr: 0.0013314286479726434
      grad_gnorm: 40.0
      policy_entropy: 6.614032745361328
      policy_loss: -2.4889297485351562
      var_gnorm: 31.63107681274414
      vf_explained_var: 0.29731637239456177
      vf_loss: 20.30016326904297
    num_steps_sampled: 432000
    num_steps_trained: 432000
    wait_time_ms: 41.936
  iterations_since_restore: 144
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1161.8914005756378
  time_this_iter_s: 8.459692478179932
  time_total_s: 1161.8914005756378
  timestamp: 1594088922
  timesteps_since_restore: 432000
  timesteps_this_iter: 3000
  timesteps_total: 432000
  training_iteration: 144
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1161 s, 144 iter, 432000 ts, 796 rew

agent-1: 363.0
agent-2: 373.0
agent-3: 341.0
Sum Reward: 1077.0
Avg Reward: 359.0
Min Reward: 341.0
Max Reward: 373.0
Gini Coefficient: 0.019808108944599195
20:20 Ratio: 1.093841642228739
Max-min Ratio: 1.093841642228739
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-28-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 801.63
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 144
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.599
    dispatch_time_ms: 24.155
    learner:
      cur_lr: 0.0013312287628650665
      grad_gnorm: 40.0
      policy_entropy: 8.806839942932129
      policy_loss: 2.9539794921875
      var_gnorm: 31.7167911529541
      vf_explained_var: -0.6446468830108643
      vf_loss: 20.923858642578125
    num_steps_sampled: 435000
    num_steps_trained: 435000
    wait_time_ms: 62.614
  iterations_since_restore: 145
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1170.684454202652
  time_this_iter_s: 8.79305362701416
  time_total_s: 1170.684454202652
  timestamp: 1594088931
  timesteps_since_restore: 435000
  timesteps_this_iter: 3000
  timesteps_total: 435000
  training_iteration: 145
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1170 s, 145 iter, 435000 ts, 802 rew

agent-1: 366.0
agent-2: 382.0
agent-3: 310.0
Sum Reward: 1058.0
Avg Reward: 352.6666666666667
Min Reward: 310.0
Max Reward: 382.0
Gini Coefficient: 0.045368620037807186
20:20 Ratio: 1.232258064516129
Max-min Ratio: 1.232258064516129
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-29-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 806.31
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 145
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.597
    dispatch_time_ms: 25.312
    learner:
      cur_lr: 0.0013310289941728115
      grad_gnorm: 40.000003814697266
      policy_entropy: 7.538228988647461
      policy_loss: 8.413361549377441
      var_gnorm: 31.803956985473633
      vf_explained_var: -0.13432073593139648
      vf_loss: 33.76988983154297
    num_steps_sampled: 438000
    num_steps_trained: 438000
    wait_time_ms: 67.293
  iterations_since_restore: 146
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1179.4081664085388
  time_this_iter_s: 8.72371220588684
  time_total_s: 1179.4081664085388
  timestamp: 1594088940
  timesteps_since_restore: 438000
  timesteps_this_iter: 3000
  timesteps_total: 438000
  training_iteration: 146
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1179 s, 146 iter, 438000 ts, 806 rew

agent-1: 359.0
agent-2: 354.0
agent-3: 329.0
Sum Reward: 1042.0
Avg Reward: 347.3333333333333
Min Reward: 329.0
Max Reward: 359.0
Gini Coefficient: 0.019193857965451054
20:20 Ratio: 1.0911854103343466
Max-min Ratio: 1.0911854103343466
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-29-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 811.5
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 146
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.752
    dispatch_time_ms: 40.329
    learner:
      cur_lr: 0.0013308292254805565
      grad_gnorm: 39.999996185302734
      policy_entropy: 9.923126220703125
      policy_loss: 8.60013484954834
      var_gnorm: 31.855255126953125
      vf_explained_var: -0.18444406986236572
      vf_loss: 27.667268753051758
    num_steps_sampled: 441000
    num_steps_trained: 441000
    wait_time_ms: 47.688
  iterations_since_restore: 147
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1188.1090483665466
  time_this_iter_s: 8.700881958007812
  time_total_s: 1188.1090483665466
  timestamp: 1594088949
  timesteps_since_restore: 441000
  timesteps_this_iter: 3000
  timesteps_total: 441000
  training_iteration: 147
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1188 s, 147 iter, 441000 ts, 812 rew

agent-1: 372.0
agent-2: 356.0
agent-3: 358.0
Sum Reward: 1086.0
Avg Reward: 362.0
Min Reward: 356.0
Max Reward: 372.0
Gini Coefficient: 0.009821976672805401
20:20 Ratio: 1.0449438202247192
Max-min Ratio: 1.0449438202247192
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-29-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 817.69
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 147
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.512
    dispatch_time_ms: 9.839
    learner:
      cur_lr: 0.0013306294567883015
      grad_gnorm: 2.861301898956299
      policy_entropy: 7.272453308105469
      policy_loss: -0.10143819451332092
      var_gnorm: 31.923952102661133
      vf_explained_var: 0.7896636724472046
      vf_loss: 2.6092123985290527
    num_steps_sampled: 444000
    num_steps_trained: 444000
    wait_time_ms: 82.109
  iterations_since_restore: 148
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1196.6561121940613
  time_this_iter_s: 8.547063827514648
  time_total_s: 1196.6561121940613
  timestamp: 1594088957
  timesteps_since_restore: 444000
  timesteps_this_iter: 3000
  timesteps_total: 444000
  training_iteration: 148
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1196 s, 148 iter, 444000 ts, 818 rew

agent-1: 365.0
agent-2: 353.0
agent-3: 349.0
Sum Reward: 1067.0
Avg Reward: 355.6666666666667
Min Reward: 349.0
Max Reward: 365.0
Gini Coefficient: 0.00999687597625742
20:20 Ratio: 1.0458452722063036
Max-min Ratio: 1.0458452722063036
agent-1: 314.0
agent-2: 374.0
agent-3: 370.0
Sum Reward: 1058.0
Avg Reward: 352.6666666666667
Min Reward: 314.0
Max Reward: 374.0
Gini Coefficient: 0.03780718336483932
20:20 Ratio: 1.1910828025477707
Max-min Ratio: 1.1910828025477707
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-29-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 829.38
  episode_reward_min: 124.0
  episodes_this_iter: 2
  episodes_total: 149
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.051
    dispatch_time_ms: 32.477
    learner:
      cur_lr: 0.0013304295716807246
      grad_gnorm: 40.0
      policy_entropy: 8.419775009155273
      policy_loss: 7.960944175720215
      var_gnorm: 32.03489303588867
      vf_explained_var: -0.19147813320159912
      vf_loss: 26.633424758911133
    num_steps_sampled: 447000
    num_steps_trained: 447000
    wait_time_ms: 54.043
  iterations_since_restore: 149
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1209.5410299301147
  time_this_iter_s: 12.884917736053467
  time_total_s: 1209.5410299301147
  timestamp: 1594088970
  timesteps_since_restore: 447000
  timesteps_this_iter: 3000
  timesteps_total: 447000
  training_iteration: 149
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1209 s, 149 iter, 447000 ts, 829 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-29-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 829.38
  episode_reward_min: 124.0
  episodes_this_iter: 0
  episodes_total: 149
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.023
    dispatch_time_ms: 26.132
    learner:
      cur_lr: 0.0013302298029884696
      grad_gnorm: 13.147494316101074
      policy_entropy: 7.606607437133789
      policy_loss: -8.206135749816895
      var_gnorm: 32.15450668334961
      vf_explained_var: 0.726982593536377
      vf_loss: 16.73686408996582
    num_steps_sampled: 450000
    num_steps_trained: 450000
    wait_time_ms: 64.331
  iterations_since_restore: 150
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1217.7018733024597
  time_this_iter_s: 8.16084337234497
  time_total_s: 1217.7018733024597
  timestamp: 1594088978
  timesteps_since_restore: 450000
  timesteps_this_iter: 3000
  timesteps_total: 450000
  training_iteration: 150
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1217 s, 150 iter, 450000 ts, 829 rew

agent-1: 290.0
agent-2: 369.0
agent-3: 358.0
Sum Reward: 1017.0
Avg Reward: 339.0
Min Reward: 290.0
Max Reward: 369.0
Gini Coefficient: 0.05178629957391019
20:20 Ratio: 1.2724137931034483
Max-min Ratio: 1.2724137931034483
agent-1: 341.0
agent-2: 367.0
agent-3: 175.0
Sum Reward: 883.0
Avg Reward: 294.3333333333333
Min Reward: 175.0
Max Reward: 367.0
Gini Coefficient: 0.144960362400906
20:20 Ratio: 2.097142857142857
Max-min Ratio: 2.097142857142857
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-29-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 835.59
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 150
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.632
    dispatch_time_ms: 29.077
    learner:
      cur_lr: 0.0013300300342962146
      grad_gnorm: 40.000003814697266
      policy_entropy: 7.815235137939453
      policy_loss: 11.81729793548584
      var_gnorm: 32.181663513183594
      vf_explained_var: -0.5109491348266602
      vf_loss: 170.32159423828125
    num_steps_sampled: 453000
    num_steps_trained: 453000
    wait_time_ms: 60.34
  iterations_since_restore: 151
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1226.5125532150269
  time_this_iter_s: 8.810679912567139
  time_total_s: 1226.5125532150269
  timestamp: 1594088987
  timesteps_since_restore: 453000
  timesteps_this_iter: 3000
  timesteps_total: 453000
  training_iteration: 151
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1226 s, 151 iter, 453000 ts, 836 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-29-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 839.58
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 151
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.227
    dispatch_time_ms: 15.545
    learner:
      cur_lr: 0.0013298301491886377
      grad_gnorm: 27.656856536865234
      policy_entropy: 11.273186683654785
      policy_loss: 2.2988052368164062
      var_gnorm: 32.22248077392578
      vf_explained_var: 0.3629603385925293
      vf_loss: 9.103872299194336
    num_steps_sampled: 456000
    num_steps_trained: 456000
    wait_time_ms: 67.052
  iterations_since_restore: 152
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1234.7649629116058
  time_this_iter_s: 8.25240969657898
  time_total_s: 1234.7649629116058
  timestamp: 1594088996
  timesteps_since_restore: 456000
  timesteps_this_iter: 3000
  timesteps_total: 456000
  training_iteration: 152
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1234 s, 152 iter, 456000 ts, 840 rew

agent-1: 343.0
agent-2: 329.0
agent-3: 371.0
Sum Reward: 1043.0
Avg Reward: 347.6666666666667
Min Reward: 329.0
Max Reward: 371.0
Gini Coefficient: 0.026845637583892617
20:20 Ratio: 1.127659574468085
Max-min Ratio: 1.127659574468085
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-30-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 843.74
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 152
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.334
    dispatch_time_ms: 34.763
    learner:
      cur_lr: 0.0013296303804963827
      grad_gnorm: 40.0
      policy_entropy: 4.055842876434326
      policy_loss: 5.18814754486084
      var_gnorm: 32.21349334716797
      vf_explained_var: 0.25517702102661133
      vf_loss: 12.17534351348877
    num_steps_sampled: 459000
    num_steps_trained: 459000
    wait_time_ms: 58.786
  iterations_since_restore: 153
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1243.6649196147919
  time_this_iter_s: 8.899956703186035
  time_total_s: 1243.6649196147919
  timestamp: 1594089005
  timesteps_since_restore: 459000
  timesteps_this_iter: 3000
  timesteps_total: 459000
  training_iteration: 153
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1243 s, 153 iter, 459000 ts, 844 rew

agent-1: 355.0
agent-2: 391.0
agent-3: 342.0
Sum Reward: 1088.0
Avg Reward: 362.6666666666667
Min Reward: 342.0
Max Reward: 391.0
Gini Coefficient: 0.03002450980392157
20:20 Ratio: 1.1432748538011697
Max-min Ratio: 1.1432748538011697
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-30-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 849.52
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 153
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.798
    dispatch_time_ms: 31.801
    learner:
      cur_lr: 0.0013294306118041277
      grad_gnorm: 11.599365234375
      policy_entropy: 3.387636423110962
      policy_loss: 3.743013620376587
      var_gnorm: 32.256736755371094
      vf_explained_var: -0.6351088285446167
      vf_loss: 12.119823455810547
    num_steps_sampled: 462000
    num_steps_trained: 462000
    wait_time_ms: 54.514
  iterations_since_restore: 154
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1252.1101489067078
  time_this_iter_s: 8.445229291915894
  time_total_s: 1252.1101489067078
  timestamp: 1594089013
  timesteps_since_restore: 462000
  timesteps_this_iter: 3000
  timesteps_total: 462000
  training_iteration: 154
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1252 s, 154 iter, 462000 ts, 850 rew

agent-1: 351.0
agent-2: 364.0
agent-3: 377.0
Sum Reward: 1092.0
Avg Reward: 364.0
Min Reward: 351.0
Max Reward: 377.0
Gini Coefficient: 0.015873015873015872
20:20 Ratio: 1.0740740740740742
Max-min Ratio: 1.0740740740740742
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-30-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 856.31
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 154
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.825
    dispatch_time_ms: 27.571
    learner:
      cur_lr: 0.0013292308431118727
      grad_gnorm: 40.0
      policy_entropy: 2.7904844284057617
      policy_loss: -0.4593554139137268
      var_gnorm: 32.319454193115234
      vf_explained_var: 0.3908156156539917
      vf_loss: 53.49290466308594
    num_steps_sampled: 465000
    num_steps_trained: 465000
    wait_time_ms: 54.777
  iterations_since_restore: 155
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1260.9899621009827
  time_this_iter_s: 8.879813194274902
  time_total_s: 1260.9899621009827
  timestamp: 1594089022
  timesteps_since_restore: 465000
  timesteps_this_iter: 3000
  timesteps_total: 465000
  training_iteration: 155
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1260 s, 155 iter, 465000 ts, 856 rew

agent-1: 378.0
agent-2: 356.0
agent-3: 363.0
Sum Reward: 1097.0
Avg Reward: 365.6666666666667
Min Reward: 356.0
Max Reward: 378.0
Gini Coefficient: 0.013369796414463689
20:20 Ratio: 1.0617977528089888
Max-min Ratio: 1.0617977528089888
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-30-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 861.92
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 155
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.545
    dispatch_time_ms: 23.463
    learner:
      cur_lr: 0.0013290309580042958
      grad_gnorm: 3.702380657196045
      policy_entropy: 5.6636457443237305
      policy_loss: -0.30841246247291565
      var_gnorm: 32.34069061279297
      vf_explained_var: 0.37937819957733154
      vf_loss: 11.565643310546875
    num_steps_sampled: 468000
    num_steps_trained: 468000
    wait_time_ms: 58.911
  iterations_since_restore: 156
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1269.5621554851532
  time_this_iter_s: 8.572193384170532
  time_total_s: 1269.5621554851532
  timestamp: 1594089031
  timesteps_since_restore: 468000
  timesteps_this_iter: 3000
  timesteps_total: 468000
  training_iteration: 156
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1269 s, 156 iter, 468000 ts, 862 rew

agent-1: 396.0
agent-2: 355.0
agent-3: 350.0
Sum Reward: 1101.0
Avg Reward: 367.0
Min Reward: 350.0
Max Reward: 396.0
Gini Coefficient: 0.02785346654556464
20:20 Ratio: 1.1314285714285715
Max-min Ratio: 1.1314285714285715
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-30-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1109.0
  episode_reward_mean: 867.9
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 156
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.936
    dispatch_time_ms: 20.717
    learner:
      cur_lr: 0.0013288311893120408
      grad_gnorm: 40.000003814697266
      policy_entropy: 8.898065567016602
      policy_loss: -3.5505685806274414
      var_gnorm: 32.41082000732422
      vf_explained_var: 0.4513784646987915
      vf_loss: 6.385238170623779
    num_steps_sampled: 471000
    num_steps_trained: 471000
    wait_time_ms: 59.388
  iterations_since_restore: 157
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1278.413740158081
  time_this_iter_s: 8.851584672927856
  time_total_s: 1278.413740158081
  timestamp: 1594089040
  timesteps_since_restore: 471000
  timesteps_this_iter: 3000
  timesteps_total: 471000
  training_iteration: 157
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1278 s, 157 iter, 471000 ts, 868 rew

agent-1: 329.0
agent-2: 410.0
agent-3: 377.0
Sum Reward: 1116.0
Avg Reward: 372.0
Min Reward: 329.0
Max Reward: 410.0
Gini Coefficient: 0.04838709677419355
20:20 Ratio: 1.2462006079027355
Max-min Ratio: 1.2462006079027355
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-30-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1116.0
  episode_reward_mean: 872.59
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 157
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.356
    dispatch_time_ms: 20.257
    learner:
      cur_lr: 0.0013286314206197858
      grad_gnorm: 40.00001907348633
      policy_entropy: 6.145148754119873
      policy_loss: 2.360727310180664
      var_gnorm: 32.42546844482422
      vf_explained_var: 0.644010603427887
      vf_loss: 7.648460388183594
    num_steps_sampled: 474000
    num_steps_trained: 474000
    wait_time_ms: 70.301
  iterations_since_restore: 158
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1286.9607548713684
  time_this_iter_s: 8.547014713287354
  time_total_s: 1286.9607548713684
  timestamp: 1594089048
  timesteps_since_restore: 474000
  timesteps_this_iter: 3000
  timesteps_total: 474000
  training_iteration: 158
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1286 s, 158 iter, 474000 ts, 873 rew

agent-1: 370.0
agent-2: 383.0
agent-3: 367.0
Sum Reward: 1120.0
Avg Reward: 373.3333333333333
Min Reward: 367.0
Max Reward: 383.0
Gini Coefficient: 0.009523809523809525
20:20 Ratio: 1.0435967302452316
Max-min Ratio: 1.0435967302452316
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-30-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1120.0
  episode_reward_mean: 876.72
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 158
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.737
    dispatch_time_ms: 29.238
    learner:
      cur_lr: 0.0013284316519275308
      grad_gnorm: 21.20384979248047
      policy_entropy: 4.157403469085693
      policy_loss: -0.31633156538009644
      var_gnorm: 32.41745376586914
      vf_explained_var: 0.2134913206100464
      vf_loss: 5.06373929977417
    num_steps_sampled: 477000
    num_steps_trained: 477000
    wait_time_ms: 55.249
  iterations_since_restore: 159
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1296.087072134018
  time_this_iter_s: 9.126317262649536
  time_total_s: 1296.087072134018
  timestamp: 1594089057
  timesteps_since_restore: 477000
  timesteps_this_iter: 3000
  timesteps_total: 477000
  training_iteration: 159
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1296 s, 159 iter, 477000 ts, 877 rew

agent-1: 388.0
agent-2: 343.0
agent-3: 360.0
Sum Reward: 1091.0
Avg Reward: 363.6666666666667
Min Reward: 343.0
Max Reward: 388.0
Gini Coefficient: 0.027497708524289642
20:20 Ratio: 1.131195335276968
Max-min Ratio: 1.131195335276968
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-31-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1120.0
  episode_reward_mean: 878.83
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 159
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.353
    dispatch_time_ms: 31.003
    learner:
      cur_lr: 0.001328231766819954
      grad_gnorm: 39.999996185302734
      policy_entropy: 3.413780450820923
      policy_loss: 1.35772705078125
      var_gnorm: 32.47981262207031
      vf_explained_var: 0.07929342985153198
      vf_loss: 14.499305725097656
    num_steps_sampled: 480000
    num_steps_trained: 480000
    wait_time_ms: 45.611
  iterations_since_restore: 160
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1304.5565054416656
  time_this_iter_s: 8.469433307647705
  time_total_s: 1304.5565054416656
  timestamp: 1594089066
  timesteps_since_restore: 480000
  timesteps_this_iter: 3000
  timesteps_total: 480000
  training_iteration: 160
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1304 s, 160 iter, 480000 ts, 879 rew

agent-1: 381.0
agent-2: 392.0
agent-3: 371.0
Sum Reward: 1144.0
Avg Reward: 381.3333333333333
Min Reward: 371.0
Max Reward: 392.0
Gini Coefficient: 0.012237762237762238
20:20 Ratio: 1.0566037735849056
Max-min Ratio: 1.0566037735849056
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-31-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 881.15
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 160
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.484
    dispatch_time_ms: 28.151
    learner:
      cur_lr: 0.001328031998127699
      grad_gnorm: 39.33401870727539
      policy_entropy: 14.285797119140625
      policy_loss: -5.388856887817383
      var_gnorm: 32.54844665527344
      vf_explained_var: 0.11757087707519531
      vf_loss: 17.790966033935547
    num_steps_sampled: 483000
    num_steps_trained: 483000
    wait_time_ms: 58.986
  iterations_since_restore: 161
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1313.5672886371613
  time_this_iter_s: 9.010783195495605
  time_total_s: 1313.5672886371613
  timestamp: 1594089075
  timesteps_since_restore: 483000
  timesteps_this_iter: 3000
  timesteps_total: 483000
  training_iteration: 161
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1313 s, 161 iter, 483000 ts, 881 rew

agent-1: 344.0
agent-2: 383.0
agent-3: 368.0
Sum Reward: 1095.0
Avg Reward: 365.0
Min Reward: 344.0
Max Reward: 383.0
Gini Coefficient: 0.023744292237442923
20:20 Ratio: 1.1133720930232558
Max-min Ratio: 1.1133720930232558
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-31-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 883.6
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 161
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.846
    dispatch_time_ms: 23.694
    learner:
      cur_lr: 0.0013278322294354439
      grad_gnorm: 40.0
      policy_entropy: 7.931180000305176
      policy_loss: -1.3332003355026245
      var_gnorm: 32.60702133178711
      vf_explained_var: 0.048577964305877686
      vf_loss: 17.79755973815918
    num_steps_sampled: 486000
    num_steps_trained: 486000
    wait_time_ms: 51.819
  iterations_since_restore: 162
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1321.9861590862274
  time_this_iter_s: 8.418870449066162
  time_total_s: 1321.9861590862274
  timestamp: 1594089083
  timesteps_since_restore: 486000
  timesteps_this_iter: 3000
  timesteps_total: 486000
  training_iteration: 162
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1321 s, 162 iter, 486000 ts, 884 rew

agent-1: 317.0
agent-2: 348.0
agent-3: 319.0
Sum Reward: 984.0
Avg Reward: 328.0
Min Reward: 317.0
Max Reward: 348.0
Gini Coefficient: 0.02100271002710027
20:20 Ratio: 1.0977917981072556
Max-min Ratio: 1.0977917981072556
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-31-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 884.97
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 162
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.177
    dispatch_time_ms: 29.78
    learner:
      cur_lr: 0.001327632344327867
      grad_gnorm: 34.0329704284668
      policy_entropy: 12.491273880004883
      policy_loss: -3.5399417877197266
      var_gnorm: 32.577999114990234
      vf_explained_var: 0.15082919597625732
      vf_loss: 5.842012405395508
    num_steps_sampled: 489000
    num_steps_trained: 489000
    wait_time_ms: 46.746
  iterations_since_restore: 163
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1330.5653760433197
  time_this_iter_s: 8.579216957092285
  time_total_s: 1330.5653760433197
  timestamp: 1594089092
  timesteps_since_restore: 489000
  timesteps_this_iter: 3000
  timesteps_total: 489000
  training_iteration: 163
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1330 s, 163 iter, 489000 ts, 885 rew

agent-1: 330.0
agent-2: 380.0
agent-3: 267.0
Sum Reward: 977.0
Avg Reward: 325.6666666666667
Min Reward: 267.0
Max Reward: 380.0
Gini Coefficient: 0.07710678949164108
20:20 Ratio: 1.4232209737827715
Max-min Ratio: 1.4232209737827715
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-31-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 885.79
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 163
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.436
    dispatch_time_ms: 28.021
    learner:
      cur_lr: 0.001327432575635612
      grad_gnorm: 22.38852882385254
      policy_entropy: 9.53370475769043
      policy_loss: -5.642006874084473
      var_gnorm: 32.633113861083984
      vf_explained_var: 0.5759496688842773
      vf_loss: 6.560704231262207
    num_steps_sampled: 492000
    num_steps_trained: 492000
    wait_time_ms: 55.417
  iterations_since_restore: 164
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1339.1108276844025
  time_this_iter_s: 8.545451641082764
  time_total_s: 1339.1108276844025
  timestamp: 1594089101
  timesteps_since_restore: 492000
  timesteps_this_iter: 3000
  timesteps_total: 492000
  training_iteration: 164
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1339 s, 164 iter, 492000 ts, 886 rew

agent-1: 370.0
agent-2: 387.0
agent-3: 355.0
Sum Reward: 1112.0
Avg Reward: 370.6666666666667
Min Reward: 355.0
Max Reward: 387.0
Gini Coefficient: 0.019184652278177457
20:20 Ratio: 1.0901408450704226
Max-min Ratio: 1.0901408450704226
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-31-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 888.04
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 164
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.585
    dispatch_time_ms: 22.485
    learner:
      cur_lr: 0.001327232806943357
      grad_gnorm: 40.0
      policy_entropy: 9.782176971435547
      policy_loss: -0.6980061531066895
      var_gnorm: 32.671566009521484
      vf_explained_var: 0.29962432384490967
      vf_loss: 29.608497619628906
    num_steps_sampled: 495000
    num_steps_trained: 495000
    wait_time_ms: 62.27
  iterations_since_restore: 165
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1347.9190809726715
  time_this_iter_s: 8.808253288269043
  time_total_s: 1347.9190809726715
  timestamp: 1594089110
  timesteps_since_restore: 495000
  timesteps_this_iter: 3000
  timesteps_total: 495000
  training_iteration: 165
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1347 s, 165 iter, 495000 ts, 888 rew

agent-1: 337.0
agent-2: 361.0
agent-3: 351.0
Sum Reward: 1049.0
Avg Reward: 349.6666666666667
Min Reward: 337.0
Max Reward: 361.0
Gini Coefficient: 0.015252621544327931
20:20 Ratio: 1.0712166172106825
Max-min Ratio: 1.0712166172106825
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-31-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 889.74
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 165
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 4.178
    dispatch_time_ms: 34.241
    learner:
      cur_lr: 0.001327033038251102
      grad_gnorm: 34.27185821533203
      policy_entropy: 8.271893501281738
      policy_loss: -1.2121437788009644
      var_gnorm: 32.744876861572266
      vf_explained_var: 0.6008268594741821
      vf_loss: 19.91788673400879
    num_steps_sampled: 498000
    num_steps_trained: 498000
    wait_time_ms: 42.875
  iterations_since_restore: 166
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1356.2877879142761
  time_this_iter_s: 8.368706941604614
  time_total_s: 1356.2877879142761
  timestamp: 1594089118
  timesteps_since_restore: 498000
  timesteps_this_iter: 3000
  timesteps_total: 498000
  training_iteration: 166
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1356 s, 166 iter, 498000 ts, 890 rew

agent-1: 322.0
agent-2: 332.0
agent-3: 312.0
Sum Reward: 966.0
Avg Reward: 322.0
Min Reward: 312.0
Max Reward: 332.0
Gini Coefficient: 0.013802622498274672
20:20 Ratio: 1.064102564102564
Max-min Ratio: 1.064102564102564
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-32-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 890.87
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 166
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.691
    dispatch_time_ms: 23.196
    learner:
      cur_lr: 0.0013268331531435251
      grad_gnorm: 38.16352462768555
      policy_entropy: 13.503517150878906
      policy_loss: -5.54512357711792
      var_gnorm: 32.781917572021484
      vf_explained_var: 0.7110973596572876
      vf_loss: 10.051182746887207
    num_steps_sampled: 501000
    num_steps_trained: 501000
    wait_time_ms: 43.878
  iterations_since_restore: 167
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1364.7514595985413
  time_this_iter_s: 8.463671684265137
  time_total_s: 1364.7514595985413
  timestamp: 1594089126
  timesteps_since_restore: 501000
  timesteps_this_iter: 3000
  timesteps_total: 501000
  training_iteration: 167
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1364 s, 167 iter, 501000 ts, 891 rew

agent-1: 321.0
agent-2: 329.0
agent-3: 300.0
Sum Reward: 950.0
Avg Reward: 316.6666666666667
Min Reward: 300.0
Max Reward: 329.0
Gini Coefficient: 0.020350877192982456
20:20 Ratio: 1.0966666666666667
Max-min Ratio: 1.0966666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-32-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 890.97
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 167
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.968
    dispatch_time_ms: 64.099
    learner:
      cur_lr: 0.00132663338445127
      grad_gnorm: 40.000003814697266
      policy_entropy: 12.096076011657715
      policy_loss: -6.906459808349609
      var_gnorm: 32.76911544799805
      vf_explained_var: -0.06754529476165771
      vf_loss: 30.312116622924805
    num_steps_sampled: 504000
    num_steps_trained: 504000
    wait_time_ms: 41.243
  iterations_since_restore: 168
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1373.2799789905548
  time_this_iter_s: 8.52851939201355
  time_total_s: 1373.2799789905548
  timestamp: 1594089135
  timesteps_since_restore: 504000
  timesteps_this_iter: 3000
  timesteps_total: 504000
  training_iteration: 168
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1373 s, 168 iter, 504000 ts, 891 rew

agent-1: 342.0
agent-2: 326.0
agent-3: 327.0
Sum Reward: 995.0
Avg Reward: 331.6666666666667
Min Reward: 326.0
Max Reward: 342.0
Gini Coefficient: 0.010720268006700168
20:20 Ratio: 1.049079754601227
Max-min Ratio: 1.049079754601227
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-32-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 891.07
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 168
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.952
    dispatch_time_ms: 23.705
    learner:
      cur_lr: 0.001326433615759015
      grad_gnorm: 39.999996185302734
      policy_entropy: 13.85784912109375
      policy_loss: 12.205233573913574
      var_gnorm: 32.83850860595703
      vf_explained_var: -0.4392951726913452
      vf_loss: 21.944650650024414
    num_steps_sampled: 507000
    num_steps_trained: 507000
    wait_time_ms: 52.791
  iterations_since_restore: 169
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1381.808583021164
  time_this_iter_s: 8.52860403060913
  time_total_s: 1381.808583021164
  timestamp: 1594089144
  timesteps_since_restore: 507000
  timesteps_this_iter: 3000
  timesteps_total: 507000
  training_iteration: 169
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1381 s, 169 iter, 507000 ts, 891 rew

agent-1: 342.0
agent-2: 357.0
agent-3: 304.0
Sum Reward: 1003.0
Avg Reward: 334.3333333333333
Min Reward: 304.0
Max Reward: 357.0
Gini Coefficient: 0.035227650382186775
20:20 Ratio: 1.174342105263158
Max-min Ratio: 1.174342105263158
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-32-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 891.57
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 169
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.564
    dispatch_time_ms: 16.986
    learner:
      cur_lr: 0.00132623384706676
      grad_gnorm: 39.999996185302734
      policy_entropy: 13.363260269165039
      policy_loss: -7.329022407531738
      var_gnorm: 32.84477996826172
      vf_explained_var: 0.6381294131278992
      vf_loss: 34.32459259033203
    num_steps_sampled: 510000
    num_steps_trained: 510000
    wait_time_ms: 69.526
  iterations_since_restore: 170
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1390.1975622177124
  time_this_iter_s: 8.388979196548462
  time_total_s: 1390.1975622177124
  timestamp: 1594089152
  timesteps_since_restore: 510000
  timesteps_this_iter: 3000
  timesteps_total: 510000
  training_iteration: 170
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1390 s, 170 iter, 510000 ts, 892 rew

agent-1: 332.0
agent-2: 327.0
agent-3: 246.0
Sum Reward: 905.0
Avg Reward: 301.6666666666667
Min Reward: 246.0
Max Reward: 332.0
Gini Coefficient: 0.06335174953959484
20:20 Ratio: 1.3495934959349594
Max-min Ratio: 1.3495934959349594
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-32-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 891.2
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 170
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.686
    dispatch_time_ms: 27.999
    learner:
      cur_lr: 0.0013260339619591832
      grad_gnorm: 37.76478958129883
      policy_entropy: 13.384015083312988
      policy_loss: -0.26264238357543945
      var_gnorm: 32.94327926635742
      vf_explained_var: 0.44766342639923096
      vf_loss: 33.834068298339844
    num_steps_sampled: 513000
    num_steps_trained: 513000
    wait_time_ms: 54.598
  iterations_since_restore: 171
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1399.231726884842
  time_this_iter_s: 9.034164667129517
  time_total_s: 1399.231726884842
  timestamp: 1594089161
  timesteps_since_restore: 513000
  timesteps_this_iter: 3000
  timesteps_total: 513000
  training_iteration: 171
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1399 s, 171 iter, 513000 ts, 891 rew

agent-1: 275.0
agent-2: 345.0
agent-3: 351.0
Sum Reward: 971.0
Avg Reward: 323.6666666666667
Min Reward: 275.0
Max Reward: 351.0
Gini Coefficient: 0.05217988328184003
20:20 Ratio: 1.2763636363636364
Max-min Ratio: 1.2763636363636364
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-32-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 891.88
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 171
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.943
    dispatch_time_ms: 25.055
    learner:
      cur_lr: 0.0013258341932669282
      grad_gnorm: 18.557178497314453
      policy_entropy: 22.342775344848633
      policy_loss: -4.875222206115723
      var_gnorm: 32.988250732421875
      vf_explained_var: -0.7040107250213623
      vf_loss: 17.011512756347656
    num_steps_sampled: 516000
    num_steps_trained: 516000
    wait_time_ms: 60.892
  iterations_since_restore: 172
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1407.6755363941193
  time_this_iter_s: 8.443809509277344
  time_total_s: 1407.6755363941193
  timestamp: 1594089170
  timesteps_since_restore: 516000
  timesteps_this_iter: 3000
  timesteps_total: 516000
  training_iteration: 172
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1407 s, 172 iter, 516000 ts, 892 rew

agent-1: 189.0
agent-2: 253.0
agent-3: 241.0
Sum Reward: 683.0
Avg Reward: 227.66666666666666
Min Reward: 189.0
Max Reward: 253.0
Gini Coefficient: 0.06246949731576379
20:20 Ratio: 1.3386243386243386
Max-min Ratio: 1.3386243386243386
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-32-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 889.22
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 172
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.368
    dispatch_time_ms: 23.855
    learner:
      cur_lr: 0.0013256344245746732
      grad_gnorm: 40.0
      policy_entropy: 17.218088150024414
      policy_loss: 6.241972923278809
      var_gnorm: 32.965171813964844
      vf_explained_var: 0.04118722677230835
      vf_loss: 168.07662963867188
    num_steps_sampled: 519000
    num_steps_trained: 519000
    wait_time_ms: 58.937
  iterations_since_restore: 173
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1416.6426327228546
  time_this_iter_s: 8.967096328735352
  time_total_s: 1416.6426327228546
  timestamp: 1594089179
  timesteps_since_restore: 519000
  timesteps_this_iter: 3000
  timesteps_total: 519000
  training_iteration: 173
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1416 s, 173 iter, 519000 ts, 889 rew

agent-1: 298.0
agent-2: 262.0
agent-3: 245.0
Sum Reward: 805.0
Avg Reward: 268.3333333333333
Min Reward: 245.0
Max Reward: 298.0
Gini Coefficient: 0.04389233954451346
20:20 Ratio: 1.2163265306122448
Max-min Ratio: 1.2163265306122448
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-33-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 886.57
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 173
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.324
    dispatch_time_ms: 38.801
    learner:
      cur_lr: 0.0013254346558824182
      grad_gnorm: 40.0
      policy_entropy: 19.712574005126953
      policy_loss: 1.157292366027832
      var_gnorm: 32.940338134765625
      vf_explained_var: -0.15955352783203125
      vf_loss: 19.94410514831543
    num_steps_sampled: 522000
    num_steps_trained: 522000
    wait_time_ms: 50.977
  iterations_since_restore: 174
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1425.0028860569
  time_this_iter_s: 8.36025333404541
  time_total_s: 1425.0028860569
  timestamp: 1594089187
  timesteps_since_restore: 522000
  timesteps_this_iter: 3000
  timesteps_total: 522000
  training_iteration: 174
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1425 s, 174 iter, 522000 ts, 887 rew

agent-1: 282.0
agent-2: 319.0
agent-3: 331.0
Sum Reward: 932.0
Avg Reward: 310.6666666666667
Min Reward: 282.0
Max Reward: 331.0
Gini Coefficient: 0.035050071530758224
20:20 Ratio: 1.173758865248227
Max-min Ratio: 1.173758865248227
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-33-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 884.85
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 174
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.968
    dispatch_time_ms: 20.127
    learner:
      cur_lr: 0.0013252347707748413
      grad_gnorm: 40.000003814697266
      policy_entropy: 20.060504913330078
      policy_loss: 6.807923316955566
      var_gnorm: 32.968955993652344
      vf_explained_var: 0.16529297828674316
      vf_loss: 36.459693908691406
    num_steps_sampled: 525000
    num_steps_trained: 525000
    wait_time_ms: 68.493
  iterations_since_restore: 175
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1434.0975427627563
  time_this_iter_s: 9.094656705856323
  time_total_s: 1434.0975427627563
  timestamp: 1594089196
  timesteps_since_restore: 525000
  timesteps_this_iter: 3000
  timesteps_total: 525000
  training_iteration: 175
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1434 s, 175 iter, 525000 ts, 885 rew

agent-1: 283.0
agent-2: 293.0
agent-3: 287.0
Sum Reward: 863.0
Avg Reward: 287.6666666666667
Min Reward: 283.0
Max Reward: 293.0
Gini Coefficient: 0.00772499034376207
20:20 Ratio: 1.0353356890459364
Max-min Ratio: 1.0353356890459364
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-33-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 882.39
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 175
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.552
    dispatch_time_ms: 44.996
    learner:
      cur_lr: 0.0013250350020825863
      grad_gnorm: 30.724130630493164
      policy_entropy: 15.675203323364258
      policy_loss: -3.155888319015503
      var_gnorm: 32.991798400878906
      vf_explained_var: 0.2285369634628296
      vf_loss: 11.658757209777832
    num_steps_sampled: 528000
    num_steps_trained: 528000
    wait_time_ms: 48.779
  iterations_since_restore: 176
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1463.4937798976898
  time_this_iter_s: 29.39623713493347
  time_total_s: 1463.4937798976898
  timestamp: 1594089226
  timesteps_since_restore: 528000
  timesteps_this_iter: 3000
  timesteps_total: 528000
  training_iteration: 176
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1463 s, 176 iter, 528000 ts, 882 rew

agent-1: 283.0
agent-2: 366.0
agent-3: 346.0
Sum Reward: 995.0
Avg Reward: 331.6666666666667
Min Reward: 283.0
Max Reward: 366.0
Gini Coefficient: 0.05561139028475712
20:20 Ratio: 1.2932862190812722
Max-min Ratio: 1.2932862190812722
agent-1: 326.0
agent-2: 369.0
agent-3: 371.0
Sum Reward: 1066.0
Avg Reward: 355.3333333333333
Min Reward: 326.0
Max Reward: 371.0
Gini Coefficient: 0.028142589118198873
20:20 Ratio: 1.138036809815951
Max-min Ratio: 1.138036809815951
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-34-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 892.43
  episode_reward_min: 124.0
  episodes_this_iter: 2
  episodes_total: 177
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.726
    dispatch_time_ms: 46.743
    learner:
      cur_lr: 0.0013248352333903313
      grad_gnorm: 40.0
      policy_entropy: 25.123260498046875
      policy_loss: 15.005171775817871
      var_gnorm: 33.082523345947266
      vf_explained_var: 0.07881247997283936
      vf_loss: 17.039836883544922
    num_steps_sampled: 531000
    num_steps_trained: 531000
    wait_time_ms: 26.467
  iterations_since_restore: 177
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1478.70787525177
  time_this_iter_s: 15.2140953540802
  time_total_s: 1478.70787525177
  timestamp: 1594089241
  timesteps_since_restore: 531000
  timesteps_this_iter: 3000
  timesteps_total: 531000
  training_iteration: 177
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1478 s, 177 iter, 531000 ts, 892 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-34-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 892.43
  episode_reward_min: 124.0
  episodes_this_iter: 0
  episodes_total: 177
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 4.403
    dispatch_time_ms: 19.815
    learner:
      cur_lr: 0.0013246353482827544
      grad_gnorm: 29.99639892578125
      policy_entropy: 20.448972702026367
      policy_loss: 3.6892151832580566
      var_gnorm: 33.11922836303711
      vf_explained_var: -0.32252538204193115
      vf_loss: 12.902152061462402
    num_steps_sampled: 534000
    num_steps_trained: 534000
    wait_time_ms: 69.124
  iterations_since_restore: 178
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1487.1133248806
  time_this_iter_s: 8.405449628829956
  time_total_s: 1487.1133248806
  timestamp: 1594089249
  timesteps_since_restore: 534000
  timesteps_this_iter: 3000
  timesteps_total: 534000
  training_iteration: 178
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1487 s, 178 iter, 534000 ts, 892 rew

agent-1: 273.0
agent-2: 326.0
agent-3: 289.0
Sum Reward: 888.0
Avg Reward: 296.0
Min Reward: 273.0
Max Reward: 326.0
Gini Coefficient: 0.03978978978978979
20:20 Ratio: 1.1941391941391941
Max-min Ratio: 1.1941391941391941
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-34-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 897.86
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 178
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.76
    dispatch_time_ms: 19.243
    learner:
      cur_lr: 0.0013244355795904994
      grad_gnorm: 40.00000762939453
      policy_entropy: 19.91227912902832
      policy_loss: -6.63765811920166
      var_gnorm: 33.13429260253906
      vf_explained_var: 0.5527034997940063
      vf_loss: 17.570180892944336
    num_steps_sampled: 537000
    num_steps_trained: 537000
    wait_time_ms: 62.851
  iterations_since_restore: 179
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1496.1757500171661
  time_this_iter_s: 9.062425136566162
  time_total_s: 1496.1757500171661
  timestamp: 1594089258
  timesteps_since_restore: 537000
  timesteps_this_iter: 3000
  timesteps_total: 537000
  training_iteration: 179
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1496 s, 179 iter, 537000 ts, 898 rew

agent-1: 282.0
agent-2: 314.0
agent-3: 355.0
Sum Reward: 951.0
Avg Reward: 317.0
Min Reward: 282.0
Max Reward: 355.0
Gini Coefficient: 0.05117420259376095
20:20 Ratio: 1.2588652482269505
Max-min Ratio: 1.2588652482269505
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-34-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 904.18
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 179
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.34
    dispatch_time_ms: 33.82
    learner:
      cur_lr: 0.0013242358108982444
      grad_gnorm: 40.0
      policy_entropy: 16.266382217407227
      policy_loss: 16.51974868774414
      var_gnorm: 33.15117263793945
      vf_explained_var: -0.3829929828643799
      vf_loss: 58.31718826293945
    num_steps_sampled: 540000
    num_steps_trained: 540000
    wait_time_ms: 48.38
  iterations_since_restore: 180
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1504.4828853607178
  time_this_iter_s: 8.307135343551636
  time_total_s: 1504.4828853607178
  timestamp: 1594089267
  timesteps_since_restore: 540000
  timesteps_this_iter: 3000
  timesteps_total: 540000
  training_iteration: 180
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1504 s, 180 iter, 540000 ts, 904 rew

agent-1: 276.0
agent-2: 319.0
agent-3: 314.0
Sum Reward: 909.0
Avg Reward: 303.0
Min Reward: 276.0
Max Reward: 319.0
Gini Coefficient: 0.031536486982031535
20:20 Ratio: 1.1557971014492754
Max-min Ratio: 1.1557971014492754
agent-1: 324.0
agent-2: 305.0
agent-3: 253.0
Sum Reward: 882.0
Avg Reward: 294.0
Min Reward: 253.0
Max Reward: 324.0
Gini Coefficient: 0.05366591080876795
20:20 Ratio: 1.2806324110671936
Max-min Ratio: 1.2806324110671936
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-34-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 913.76
  episode_reward_min: 124.0
  episodes_this_iter: 2
  episodes_total: 181
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.068
    dispatch_time_ms: 30.971
    learner:
      cur_lr: 0.0013240360422059894
      grad_gnorm: 40.0
      policy_entropy: 25.153188705444336
      policy_loss: 25.551067352294922
      var_gnorm: 33.20335388183594
      vf_explained_var: 0.2369503378868103
      vf_loss: 70.27203369140625
    num_steps_sampled: 543000
    num_steps_trained: 543000
    wait_time_ms: 63.822
  iterations_since_restore: 181
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1513.649870634079
  time_this_iter_s: 9.166985273361206
  time_total_s: 1513.649870634079
  timestamp: 1594089276
  timesteps_since_restore: 543000
  timesteps_this_iter: 3000
  timesteps_total: 543000
  training_iteration: 181
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1513 s, 181 iter, 543000 ts, 914 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-34-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 913.76
  episode_reward_min: 124.0
  episodes_this_iter: 0
  episodes_total: 181
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.926
    dispatch_time_ms: 34.216
    learner:
      cur_lr: 0.0013238361570984125
      grad_gnorm: 26.11159896850586
      policy_entropy: 23.48455810546875
      policy_loss: -3.8342936038970947
      var_gnorm: 33.2301025390625
      vf_explained_var: 0.5058218836784363
      vf_loss: 23.961545944213867
    num_steps_sampled: 546000
    num_steps_trained: 546000
    wait_time_ms: 43.193
  iterations_since_restore: 182
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1522.1854469776154
  time_this_iter_s: 8.535576343536377
  time_total_s: 1522.1854469776154
  timestamp: 1594089284
  timesteps_since_restore: 546000
  timesteps_this_iter: 3000
  timesteps_total: 546000
  training_iteration: 182
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1522 s, 182 iter, 546000 ts, 914 rew

agent-1: 306.0
agent-2: 313.0
agent-3: 246.0
Sum Reward: 865.0
Avg Reward: 288.3333333333333
Min Reward: 246.0
Max Reward: 313.0
Gini Coefficient: 0.05163776493256262
20:20 Ratio: 1.2723577235772359
Max-min Ratio: 1.2723577235772359
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-34-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 917.11
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 182
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.644
    dispatch_time_ms: 22.223
    learner:
      cur_lr: 0.0013236363884061575
      grad_gnorm: 29.817968368530273
      policy_entropy: 25.696605682373047
      policy_loss: -9.400498390197754
      var_gnorm: 33.28091812133789
      vf_explained_var: 0.13316994905471802
      vf_loss: 26.19146728515625
    num_steps_sampled: 549000
    num_steps_trained: 549000
    wait_time_ms: 64.119
  iterations_since_restore: 183
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1531.2473719120026
  time_this_iter_s: 9.061924934387207
  time_total_s: 1531.2473719120026
  timestamp: 1594089294
  timesteps_since_restore: 549000
  timesteps_this_iter: 3000
  timesteps_total: 549000
  training_iteration: 183
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1531 s, 183 iter, 549000 ts, 917 rew

agent-1: 161.0
agent-2: 308.0
agent-3: 305.0
Sum Reward: 774.0
Avg Reward: 258.0
Min Reward: 161.0
Max Reward: 308.0
Gini Coefficient: 0.12661498708010335
20:20 Ratio: 1.9130434782608696
Max-min Ratio: 1.9130434782608696
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-35-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 919.63
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 183
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.569
    dispatch_time_ms: 20.861
    learner:
      cur_lr: 0.0013234366197139025
      grad_gnorm: 40.0
      policy_entropy: 20.743526458740234
      policy_loss: -2.130803108215332
      var_gnorm: 33.37141036987305
      vf_explained_var: -0.1842101812362671
      vf_loss: 36.2470817565918
    num_steps_sampled: 552000
    num_steps_trained: 552000
    wait_time_ms: 60.997
  iterations_since_restore: 184
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1539.7521107196808
  time_this_iter_s: 8.504738807678223
  time_total_s: 1539.7521107196808
  timestamp: 1594089302
  timesteps_since_restore: 552000
  timesteps_this_iter: 3000
  timesteps_total: 552000
  training_iteration: 184
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1539 s, 184 iter, 552000 ts, 920 rew

agent-1: 209.0
agent-2: 306.0
agent-3: 266.0
Sum Reward: 781.0
Avg Reward: 260.3333333333333
Min Reward: 209.0
Max Reward: 306.0
Gini Coefficient: 0.08279982927870252
20:20 Ratio: 1.4641148325358853
Max-min Ratio: 1.4641148325358853
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-35-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 921.5
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 184
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.562
    dispatch_time_ms: 20.807
    learner:
      cur_lr: 0.0013232368510216475
      grad_gnorm: 40.000003814697266
      policy_entropy: 25.482152938842773
      policy_loss: 12.727120399475098
      var_gnorm: 33.36141586303711
      vf_explained_var: -0.06793010234832764
      vf_loss: 40.892860412597656
    num_steps_sampled: 555000
    num_steps_trained: 555000
    wait_time_ms: 68.694
  iterations_since_restore: 185
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1548.4760892391205
  time_this_iter_s: 8.723978519439697
  time_total_s: 1548.4760892391205
  timestamp: 1594089311
  timesteps_since_restore: 555000
  timesteps_this_iter: 3000
  timesteps_total: 555000
  training_iteration: 185
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1548 s, 185 iter, 555000 ts, 922 rew

agent-1: 289.0
agent-2: 334.0
agent-3: 287.0
Sum Reward: 910.0
Avg Reward: 303.3333333333333
Min Reward: 287.0
Max Reward: 334.0
Gini Coefficient: 0.034432234432234435
20:20 Ratio: 1.1637630662020906
Max-min Ratio: 1.1637630662020906
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-35-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 922.78
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 185
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.5
    dispatch_time_ms: 27.177
    learner:
      cur_lr: 0.0013230369659140706
      grad_gnorm: 40.0
      policy_entropy: 15.764986038208008
      policy_loss: 5.661160469055176
      var_gnorm: 33.36866760253906
      vf_explained_var: 0.674972414970398
      vf_loss: 83.58940887451172
    num_steps_sampled: 558000
    num_steps_trained: 558000
    wait_time_ms: 61.822
  iterations_since_restore: 186
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1556.8262107372284
  time_this_iter_s: 8.35012149810791
  time_total_s: 1556.8262107372284
  timestamp: 1594089319
  timesteps_since_restore: 558000
  timesteps_this_iter: 3000
  timesteps_total: 558000
  training_iteration: 186
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1556 s, 186 iter, 558000 ts, 923 rew

agent-1: 245.0
agent-2: 332.0
agent-3: 270.0
Sum Reward: 847.0
Avg Reward: 282.3333333333333
Min Reward: 245.0
Max Reward: 332.0
Gini Coefficient: 0.06847697756788666
20:20 Ratio: 1.3551020408163266
Max-min Ratio: 1.3551020408163266
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-35-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 922.09
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 186
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.631
    dispatch_time_ms: 27.294
    learner:
      cur_lr: 0.0013228371972218156
      grad_gnorm: 40.0
      policy_entropy: 18.27456283569336
      policy_loss: 14.906317710876465
      var_gnorm: 33.49885177612305
      vf_explained_var: 0.18653333187103271
      vf_loss: 27.09943962097168
    num_steps_sampled: 561000
    num_steps_trained: 561000
    wait_time_ms: 57.014
  iterations_since_restore: 187
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1565.6548056602478
  time_this_iter_s: 8.82859492301941
  time_total_s: 1565.6548056602478
  timestamp: 1594089328
  timesteps_since_restore: 561000
  timesteps_this_iter: 3000
  timesteps_total: 561000
  training_iteration: 187
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1565 s, 187 iter, 561000 ts, 922 rew

agent-1: 312.0
agent-2: 346.0
agent-3: 272.0
Sum Reward: 930.0
Avg Reward: 310.0
Min Reward: 272.0
Max Reward: 346.0
Gini Coefficient: 0.05304659498207885
20:20 Ratio: 1.2720588235294117
Max-min Ratio: 1.2720588235294117
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-35-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 922.42
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 187
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.086
    dispatch_time_ms: 20.012
    learner:
      cur_lr: 0.0013226374285295606
      grad_gnorm: 40.0
      policy_entropy: 24.75701904296875
      policy_loss: 19.24723243713379
      var_gnorm: 33.52503967285156
      vf_explained_var: 0.41773056983947754
      vf_loss: 17.416654586791992
    num_steps_sampled: 564000
    num_steps_trained: 564000
    wait_time_ms: 61.522
  iterations_since_restore: 188
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1573.8907296657562
  time_this_iter_s: 8.235924005508423
  time_total_s: 1573.8907296657562
  timestamp: 1594089336
  timesteps_since_restore: 564000
  timesteps_this_iter: 3000
  timesteps_total: 564000
  training_iteration: 188
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1573 s, 188 iter, 564000 ts, 922 rew

agent-1: 284.0
agent-2: 314.0
agent-3: 296.0
Sum Reward: 894.0
Avg Reward: 298.0
Min Reward: 284.0
Max Reward: 314.0
Gini Coefficient: 0.02237136465324385
20:20 Ratio: 1.1056338028169015
Max-min Ratio: 1.1056338028169015
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-35-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 920.68
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 188
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.256
    dispatch_time_ms: 22.876
    learner:
      cur_lr: 0.0013224375434219837
      grad_gnorm: 40.000003814697266
      policy_entropy: 24.61876678466797
      policy_loss: -12.936759948730469
      var_gnorm: 33.54460906982422
      vf_explained_var: 0.15341079235076904
      vf_loss: 41.012386322021484
    num_steps_sampled: 567000
    num_steps_trained: 567000
    wait_time_ms: 53.488
  iterations_since_restore: 189
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1582.6484262943268
  time_this_iter_s: 8.757696628570557
  time_total_s: 1582.6484262943268
  timestamp: 1594089345
  timesteps_since_restore: 567000
  timesteps_this_iter: 3000
  timesteps_total: 567000
  training_iteration: 189
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1582 s, 189 iter, 567000 ts, 921 rew

agent-1: 313.0
agent-2: 330.0
agent-3: 277.0
Sum Reward: 920.0
Avg Reward: 306.6666666666667
Min Reward: 277.0
Max Reward: 330.0
Gini Coefficient: 0.03840579710144928
20:20 Ratio: 1.1913357400722022
Max-min Ratio: 1.1913357400722022
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-35-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 919.04
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 189
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.633
    dispatch_time_ms: 19.622
    learner:
      cur_lr: 0.0013222377747297287
      grad_gnorm: 40.000003814697266
      policy_entropy: 20.094017028808594
      policy_loss: -10.105050086975098
      var_gnorm: 33.54655456542969
      vf_explained_var: -0.08892810344696045
      vf_loss: 10.46760368347168
    num_steps_sampled: 570000
    num_steps_trained: 570000
    wait_time_ms: 59.895
  iterations_since_restore: 190
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1596.2640264034271
  time_this_iter_s: 13.615600109100342
  time_total_s: 1596.2640264034271
  timestamp: 1594089359
  timesteps_since_restore: 570000
  timesteps_this_iter: 3000
  timesteps_total: 570000
  training_iteration: 190
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1596 s, 190 iter, 570000 ts, 919 rew

agent-1: 290.0
agent-2: 282.0
agent-3: 274.0
Sum Reward: 846.0
Avg Reward: 282.0
Min Reward: 274.0
Max Reward: 290.0
Gini Coefficient: 0.01260835303388495
20:20 Ratio: 1.0583941605839415
Max-min Ratio: 1.0583941605839415
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-36-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 917.16
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 190
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.955
    dispatch_time_ms: 30.292
    learner:
      cur_lr: 0.0013220380060374737
      grad_gnorm: 35.94636917114258
      policy_entropy: 20.916688919067383
      policy_loss: -1.8977794647216797
      var_gnorm: 33.597862243652344
      vf_explained_var: 0.6114978194236755
      vf_loss: 21.704145431518555
    num_steps_sampled: 573000
    num_steps_trained: 573000
    wait_time_ms: 51.586
  iterations_since_restore: 191
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1604.7585554122925
  time_this_iter_s: 8.494529008865356
  time_total_s: 1604.7585554122925
  timestamp: 1594089367
  timesteps_since_restore: 573000
  timesteps_this_iter: 3000
  timesteps_total: 573000
  training_iteration: 191
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1604 s, 191 iter, 573000 ts, 917 rew

agent-1: 205.0
agent-2: 348.0
agent-3: 245.0
Sum Reward: 798.0
Avg Reward: 266.0
Min Reward: 205.0
Max Reward: 348.0
Gini Coefficient: 0.11946532999164577
20:20 Ratio: 1.697560975609756
Max-min Ratio: 1.697560975609756
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-36-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 916.04
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 191
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.865
    dispatch_time_ms: 56.221
    learner:
      cur_lr: 0.0013218382373452187
      grad_gnorm: 40.0
      policy_entropy: 14.321418762207031
      policy_loss: -17.925216674804688
      var_gnorm: 33.66045379638672
      vf_explained_var: 0.28547942638397217
      vf_loss: 39.95956039428711
    num_steps_sampled: 576000
    num_steps_trained: 576000
    wait_time_ms: 36.982
  iterations_since_restore: 192
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1613.3618612289429
  time_this_iter_s: 8.60330581665039
  time_total_s: 1613.3618612289429
  timestamp: 1594089376
  timesteps_since_restore: 576000
  timesteps_this_iter: 3000
  timesteps_total: 576000
  training_iteration: 192
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1613 s, 192 iter, 576000 ts, 916 rew

agent-1: 393.0
agent-2: 337.0
agent-3: 302.0
Sum Reward: 1032.0
Avg Reward: 344.0
Min Reward: 302.0
Max Reward: 393.0
Gini Coefficient: 0.05878552971576227
20:20 Ratio: 1.3013245033112584
Max-min Ratio: 1.3013245033112584
agent-1: 310.0
agent-2: 339.0
agent-3: 325.0
Sum Reward: 974.0
Avg Reward: 324.6666666666667
Min Reward: 310.0
Max Reward: 339.0
Gini Coefficient: 0.019849418206707735
20:20 Ratio: 1.0935483870967742
Max-min Ratio: 1.0935483870967742
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-36-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 921.62
  episode_reward_min: 124.0
  episodes_this_iter: 2
  episodes_total: 193
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.551
    dispatch_time_ms: 42.342
    learner:
      cur_lr: 0.0013216383522376418
      grad_gnorm: 40.0
      policy_entropy: 13.329330444335938
      policy_loss: 41.48516082763672
      var_gnorm: 33.721927642822266
      vf_explained_var: -1.0
      vf_loss: 110.77690887451172
    num_steps_sampled: 579000
    num_steps_trained: 579000
    wait_time_ms: 52.316
  iterations_since_restore: 193
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1622.1986644268036
  time_this_iter_s: 8.836803197860718
  time_total_s: 1622.1986644268036
  timestamp: 1594089385
  timesteps_since_restore: 579000
  timesteps_this_iter: 3000
  timesteps_total: 579000
  training_iteration: 193
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1622 s, 193 iter, 579000 ts, 922 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-36-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 921.62
  episode_reward_min: 124.0
  episodes_this_iter: 0
  episodes_total: 193
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.771
    dispatch_time_ms: 24.604
    learner:
      cur_lr: 0.0013214385835453868
      grad_gnorm: 39.999996185302734
      policy_entropy: 13.84751033782959
      policy_loss: 15.85572624206543
      var_gnorm: 33.78520202636719
      vf_explained_var: 0.008789539337158203
      vf_loss: 28.956132888793945
    num_steps_sampled: 582000
    num_steps_trained: 582000
    wait_time_ms: 55.464
  iterations_since_restore: 194
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1630.6274588108063
  time_this_iter_s: 8.428794384002686
  time_total_s: 1630.6274588108063
  timestamp: 1594089393
  timesteps_since_restore: 582000
  timesteps_this_iter: 3000
  timesteps_total: 582000
  training_iteration: 194
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1630 s, 194 iter, 582000 ts, 922 rew

agent-1: 278.0
agent-2: 360.0
agent-3: 332.0
Sum Reward: 970.0
Avg Reward: 323.3333333333333
Min Reward: 278.0
Max Reward: 360.0
Gini Coefficient: 0.056357388316151204
20:20 Ratio: 1.2949640287769784
Max-min Ratio: 1.2949640287769784
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-36-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 924.12
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 194
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.526
    dispatch_time_ms: 19.061
    learner:
      cur_lr: 0.0013212388148531318
      grad_gnorm: 40.0
      policy_entropy: 15.530631065368652
      policy_loss: 18.576290130615234
      var_gnorm: 33.80636978149414
      vf_explained_var: -1.0
      vf_loss: 46.35526657104492
    num_steps_sampled: 585000
    num_steps_trained: 585000
    wait_time_ms: 64.441
  iterations_since_restore: 195
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1639.5587482452393
  time_this_iter_s: 8.931289434432983
  time_total_s: 1639.5587482452393
  timestamp: 1594089402
  timesteps_since_restore: 585000
  timesteps_this_iter: 3000
  timesteps_total: 585000
  training_iteration: 195
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1639 s, 195 iter, 585000 ts, 924 rew

agent-1: 336.0
agent-2: 343.0
agent-3: 229.0
Sum Reward: 908.0
Avg Reward: 302.6666666666667
Min Reward: 229.0
Max Reward: 343.0
Gini Coefficient: 0.08370044052863436
20:20 Ratio: 1.497816593886463
Max-min Ratio: 1.497816593886463
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-36-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 925.07
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 195
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.912
    dispatch_time_ms: 29.266
    learner:
      cur_lr: 0.0013210390461608768
      grad_gnorm: 40.0
      policy_entropy: 16.469547271728516
      policy_loss: 10.883888244628906
      var_gnorm: 33.87614822387695
      vf_explained_var: 0.20930933952331543
      vf_loss: 25.805252075195312
    num_steps_sampled: 588000
    num_steps_trained: 588000
    wait_time_ms: 44.224
  iterations_since_restore: 196
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1647.9012036323547
  time_this_iter_s: 8.342455387115479
  time_total_s: 1647.9012036323547
  timestamp: 1594089411
  timesteps_since_restore: 588000
  timesteps_this_iter: 3000
  timesteps_total: 588000
  training_iteration: 196
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1647 s, 196 iter, 588000 ts, 925 rew

agent-1: 354.0
agent-2: 346.0
agent-3: 323.0
Sum Reward: 1023.0
Avg Reward: 341.0
Min Reward: 323.0
Max Reward: 354.0
Gini Coefficient: 0.020202020202020204
20:20 Ratio: 1.0959752321981424
Max-min Ratio: 1.0959752321981424
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-36-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 925.66
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 196
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.539
    dispatch_time_ms: 26.82
    learner:
      cur_lr: 0.0013208391610533
      grad_gnorm: 31.00351333618164
      policy_entropy: 14.311148643493652
      policy_loss: -0.2946152091026306
      var_gnorm: 33.85460662841797
      vf_explained_var: 0.22475486993789673
      vf_loss: 18.850862503051758
    num_steps_sampled: 591000
    num_steps_trained: 591000
    wait_time_ms: 59.292
  iterations_since_restore: 197
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1656.536669254303
  time_this_iter_s: 8.635465621948242
  time_total_s: 1656.536669254303
  timestamp: 1594089419
  timesteps_since_restore: 591000
  timesteps_this_iter: 3000
  timesteps_total: 591000
  training_iteration: 197
  
agent-1: 338.0
agent-2: 350.0
agent-3: 293.0
Sum Reward: 981.0
Avg Reward: 327.0
Min Reward: 293.0
Max Reward: 350.0
Gini Coefficient: 0.03873598369011213
20:20 Ratio: 1.1945392491467577
Max-min Ratio: 1.1945392491467577
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1656 s, 197 iter, 591000 ts, 926 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-37-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 925.8
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 197
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.871
    dispatch_time_ms: 38.79
    learner:
      cur_lr: 0.0013206393923610449
      grad_gnorm: 24.591602325439453
      policy_entropy: 14.890563011169434
      policy_loss: 3.9232499599456787
      var_gnorm: 33.9070930480957
      vf_explained_var: 0.3029707670211792
      vf_loss: 7.853384971618652
    num_steps_sampled: 594000
    num_steps_trained: 594000
    wait_time_ms: 43.552
  iterations_since_restore: 198
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1665.0592362880707
  time_this_iter_s: 8.5225670337677
  time_total_s: 1665.0592362880707
  timestamp: 1594089428
  timesteps_since_restore: 594000
  timesteps_this_iter: 3000
  timesteps_total: 594000
  training_iteration: 198
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1665 s, 198 iter, 594000 ts, 926 rew

agent-1: 353.0
agent-2: 345.0
agent-3: 333.0
Sum Reward: 1031.0
Avg Reward: 343.6666666666667
Min Reward: 333.0
Max Reward: 353.0
Gini Coefficient: 0.012932428063368898
20:20 Ratio: 1.06006006006006
Max-min Ratio: 1.06006006006006
agent-1: 307.0
agent-2: 360.0
agent-3: 313.0
Sum Reward: 980.0
Avg Reward: 326.6666666666667
Min Reward: 307.0
Max Reward: 360.0
Gini Coefficient: 0.03605442176870748
20:20 Ratio: 1.1726384364820848
Max-min Ratio: 1.1726384364820848
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-37-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 926.05
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 198
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.025
    dispatch_time_ms: 20.052
    learner:
      cur_lr: 0.0013204396236687899
      grad_gnorm: 40.0
      policy_entropy: 10.89323902130127
      policy_loss: 30.569778442382812
      var_gnorm: 33.96878433227539
      vf_explained_var: -1.0
      vf_loss: 119.26606750488281
    num_steps_sampled: 597000
    num_steps_trained: 597000
    wait_time_ms: 54.659
  iterations_since_restore: 199
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1674.3848807811737
  time_this_iter_s: 9.325644493103027
  time_total_s: 1674.3848807811737
  timestamp: 1594089437
  timesteps_since_restore: 597000
  timesteps_this_iter: 3000
  timesteps_total: 597000
  training_iteration: 199
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1674 s, 199 iter, 597000 ts, 926 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-37-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 925.93
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 199
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.634
    dispatch_time_ms: 34.383
    learner:
      cur_lr: 0.0013202398549765348
      grad_gnorm: 27.072378158569336
      policy_entropy: 10.490838050842285
      policy_loss: 6.144814968109131
      var_gnorm: 33.95875930786133
      vf_explained_var: -1.0
      vf_loss: 12.308023452758789
    num_steps_sampled: 600000
    num_steps_trained: 600000
    wait_time_ms: 51.93
  iterations_since_restore: 200
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1682.7189071178436
  time_this_iter_s: 8.334026336669922
  time_total_s: 1682.7189071178436
  timestamp: 1594089446
  timesteps_since_restore: 600000
  timesteps_this_iter: 3000
  timesteps_total: 600000
  training_iteration: 200
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1682 s, 200 iter, 600000 ts, 926 rew

agent-1: 351.0
agent-2: 340.0
agent-3: 367.0
Sum Reward: 1058.0
Avg Reward: 352.6666666666667
Min Reward: 340.0
Max Reward: 367.0
Gini Coefficient: 0.017013232514177693
20:20 Ratio: 1.0794117647058823
Max-min Ratio: 1.0794117647058823
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-37-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 926.42
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 200
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.559
    dispatch_time_ms: 21.512
    learner:
      cur_lr: 0.001320039969868958
      grad_gnorm: 40.0
      policy_entropy: 15.839822769165039
      policy_loss: -6.69672155380249
      var_gnorm: 34.05112075805664
      vf_explained_var: -0.3624095916748047
      vf_loss: 14.76327896118164
    num_steps_sampled: 603000
    num_steps_trained: 603000
    wait_time_ms: 66.645
  iterations_since_restore: 201
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1691.4405937194824
  time_this_iter_s: 8.721686601638794
  time_total_s: 1691.4405937194824
  timestamp: 1594089454
  timesteps_since_restore: 603000
  timesteps_this_iter: 3000
  timesteps_total: 603000
  training_iteration: 201
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1691 s, 201 iter, 603000 ts, 926 rew

agent-1: 349.0
agent-2: 333.0
agent-3: 331.0
Sum Reward: 1013.0
Avg Reward: 337.6666666666667
Min Reward: 331.0
Max Reward: 349.0
Gini Coefficient: 0.011846001974333662
20:20 Ratio: 1.054380664652568
Max-min Ratio: 1.054380664652568
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-37-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 926.26
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 201
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.567
    dispatch_time_ms: 22.559
    learner:
      cur_lr: 0.001319840201176703
      grad_gnorm: 32.2313346862793
      policy_entropy: 7.693431854248047
      policy_loss: -0.7935658097267151
      var_gnorm: 34.105438232421875
      vf_explained_var: 0.43219369649887085
      vf_loss: 20.372276306152344
    num_steps_sampled: 606000
    num_steps_trained: 606000
    wait_time_ms: 60.685
  iterations_since_restore: 202
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1699.9990494251251
  time_this_iter_s: 8.5584557056427
  time_total_s: 1699.9990494251251
  timestamp: 1594089463
  timesteps_since_restore: 606000
  timesteps_this_iter: 3000
  timesteps_total: 606000
  training_iteration: 202
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1699 s, 202 iter, 606000 ts, 926 rew

agent-1: 324.0
agent-2: 332.0
agent-3: 337.0
Sum Reward: 993.0
Avg Reward: 331.0
Min Reward: 324.0
Max Reward: 337.0
Gini Coefficient: 0.00872776099362202
20:20 Ratio: 1.0401234567901234
Max-min Ratio: 1.0401234567901234
agent-1: 296.0
agent-2: 400.0
agent-3: 311.0
Sum Reward: 1007.0
Avg Reward: 335.6666666666667
Min Reward: 296.0
Max Reward: 400.0
Gini Coefficient: 0.06885137371731215
20:20 Ratio: 1.3513513513513513
Max-min Ratio: 1.3513513513513513
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-37-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 931.49
  episode_reward_min: 124.0
  episodes_this_iter: 2
  episodes_total: 203
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.239
    dispatch_time_ms: 26.069
    learner:
      cur_lr: 0.001319640432484448
      grad_gnorm: 40.0
      policy_entropy: 20.723915100097656
      policy_loss: -682.9219970703125
      var_gnorm: 34.14970397949219
      vf_explained_var: 0.20047199726104736
      vf_loss: 14241.27734375
    num_steps_sampled: 609000
    num_steps_trained: 609000
    wait_time_ms: 61.451
  iterations_since_restore: 203
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1709.2000091075897
  time_this_iter_s: 9.2009596824646
  time_total_s: 1709.2000091075897
  timestamp: 1594089472
  timesteps_since_restore: 609000
  timesteps_this_iter: 3000
  timesteps_total: 609000
  training_iteration: 203
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1709 s, 203 iter, 609000 ts, 931 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-38-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 931.49
  episode_reward_min: 124.0
  episodes_this_iter: 0
  episodes_total: 203
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.869
    dispatch_time_ms: 33.703
    learner:
      cur_lr: 0.0013194405473768711
      grad_gnorm: 40.0
      policy_entropy: 17.148752212524414
      policy_loss: 10.782750129699707
      var_gnorm: 34.20060729980469
      vf_explained_var: 0.37601274251937866
      vf_loss: 57.796478271484375
    num_steps_sampled: 612000
    num_steps_trained: 612000
    wait_time_ms: 59.904
  iterations_since_restore: 204
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1717.7565667629242
  time_this_iter_s: 8.556557655334473
  time_total_s: 1717.7565667629242
  timestamp: 1594089481
  timesteps_since_restore: 612000
  timesteps_this_iter: 3000
  timesteps_total: 612000
  training_iteration: 204
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1717 s, 204 iter, 612000 ts, 931 rew

agent-1: 300.0
agent-2: 313.0
agent-3: 325.0
Sum Reward: 938.0
Avg Reward: 312.6666666666667
Min Reward: 300.0
Max Reward: 325.0
Gini Coefficient: 0.017768301350390904
20:20 Ratio: 1.0833333333333333
Max-min Ratio: 1.0833333333333333
agent-1: 313.0
agent-2: 325.0
agent-3: 344.0
Sum Reward: 982.0
Avg Reward: 327.3333333333333
Min Reward: 313.0
Max Reward: 344.0
Gini Coefficient: 0.021045485403937542
20:20 Ratio: 1.099041533546326
Max-min Ratio: 1.099041533546326
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-38-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 930.75
  episode_reward_min: 124.0
  episodes_this_iter: 2
  episodes_total: 205
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.858
    dispatch_time_ms: 32.905
    learner:
      cur_lr: 0.001319240778684616
      grad_gnorm: 40.0
      policy_entropy: 23.56261444091797
      policy_loss: -1.5898151397705078
      var_gnorm: 34.28446960449219
      vf_explained_var: 0.28914111852645874
      vf_loss: 41.43307113647461
    num_steps_sampled: 615000
    num_steps_trained: 615000
    wait_time_ms: 774.113
  iterations_since_restore: 205
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1733.687828540802
  time_this_iter_s: 15.931261777877808
  time_total_s: 1733.687828540802
  timestamp: 1594089497
  timesteps_since_restore: 615000
  timesteps_this_iter: 3000
  timesteps_total: 615000
  training_iteration: 205
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1733 s, 205 iter, 615000 ts, 931 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-38-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 930.75
  episode_reward_min: 124.0
  episodes_this_iter: 0
  episodes_total: 205
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.557
    dispatch_time_ms: 30.362
    learner:
      cur_lr: 0.001319041009992361
      grad_gnorm: 14.590703964233398
      policy_entropy: 16.15057945251465
      policy_loss: 1.493011236190796
      var_gnorm: 34.32447052001953
      vf_explained_var: 0.09365350008010864
      vf_loss: 14.829717636108398
    num_steps_sampled: 618000
    num_steps_trained: 618000
    wait_time_ms: 53.363
  iterations_since_restore: 206
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1741.5919358730316
  time_this_iter_s: 7.904107332229614
  time_total_s: 1741.5919358730316
  timestamp: 1594089505
  timesteps_since_restore: 618000
  timesteps_this_iter: 3000
  timesteps_total: 618000
  training_iteration: 206
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1741 s, 206 iter, 618000 ts, 931 rew

agent-1: 270.0
agent-2: 282.0
agent-3: 346.0
Sum Reward: 898.0
Avg Reward: 299.3333333333333
Min Reward: 270.0
Max Reward: 346.0
Gini Coefficient: 0.05642167780252413
20:20 Ratio: 1.2814814814814814
Max-min Ratio: 1.2814814814814814
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-38-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 929.24
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 206
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.635
    dispatch_time_ms: 21.375
    learner:
      cur_lr: 0.001318841241300106
      grad_gnorm: 40.00000762939453
      policy_entropy: 22.33121681213379
      policy_loss: 1.3021488189697266
      var_gnorm: 34.4081916809082
      vf_explained_var: 0.580865204334259
      vf_loss: 53.79606628417969
    num_steps_sampled: 621000
    num_steps_trained: 621000
    wait_time_ms: 64.4
  iterations_since_restore: 207
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1750.671207666397
  time_this_iter_s: 9.079271793365479
  time_total_s: 1750.671207666397
  timestamp: 1594089514
  timesteps_since_restore: 621000
  timesteps_this_iter: 3000
  timesteps_total: 621000
  training_iteration: 207
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1750 s, 207 iter, 621000 ts, 929 rew

agent-1: 331.0
agent-2: 347.0
agent-3: 302.0
Sum Reward: 980.0
Avg Reward: 326.6666666666667
Min Reward: 302.0
Max Reward: 347.0
Gini Coefficient: 0.030612244897959183
20:20 Ratio: 1.1490066225165563
Max-min Ratio: 1.1490066225165563
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-38-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 930.02
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 207
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.614
    dispatch_time_ms: 22.028
    learner:
      cur_lr: 0.0013186413561925292
      grad_gnorm: 21.97639274597168
      policy_entropy: 30.132869720458984
      policy_loss: 0.9473268985748291
      var_gnorm: 34.46853256225586
      vf_explained_var: -0.4401414394378662
      vf_loss: 30.113037109375
    num_steps_sampled: 624000
    num_steps_trained: 624000
    wait_time_ms: 65.154
  iterations_since_restore: 208
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1759.5254888534546
  time_this_iter_s: 8.854281187057495
  time_total_s: 1759.5254888534546
  timestamp: 1594089523
  timesteps_since_restore: 624000
  timesteps_this_iter: 3000
  timesteps_total: 624000
  training_iteration: 208
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1759 s, 208 iter, 624000 ts, 930 rew

agent-1: 317.0
agent-2: 251.0
agent-3: 317.0
Sum Reward: 885.0
Avg Reward: 295.0
Min Reward: 251.0
Max Reward: 317.0
Gini Coefficient: 0.04971751412429379
20:20 Ratio: 1.2629482071713147
Max-min Ratio: 1.2629482071713147
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-38-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 929.83
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 208
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.671
    dispatch_time_ms: 20.341
    learner:
      cur_lr: 0.0013184415875002742
      grad_gnorm: 39.88574981689453
      policy_entropy: 16.005916595458984
      policy_loss: 8.119688034057617
      var_gnorm: 34.421443939208984
      vf_explained_var: 0.42642563581466675
      vf_loss: 17.645959854125977
    num_steps_sampled: 627000
    num_steps_trained: 627000
    wait_time_ms: 59.566
  iterations_since_restore: 209
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1768.4354815483093
  time_this_iter_s: 8.909992694854736
  time_total_s: 1768.4354815483093
  timestamp: 1594089532
  timesteps_since_restore: 627000
  timesteps_this_iter: 3000
  timesteps_total: 627000
  training_iteration: 209
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1768 s, 209 iter, 627000 ts, 930 rew

agent-1: 286.0
agent-2: 326.0
agent-3: 271.0
Sum Reward: 883.0
Avg Reward: 294.3333333333333
Min Reward: 271.0
Max Reward: 326.0
Gini Coefficient: 0.041525103812759534
20:20 Ratio: 1.2029520295202951
Max-min Ratio: 1.2029520295202951
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-39-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 929.91
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 209
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.633
    dispatch_time_ms: 13.362
    learner:
      cur_lr: 0.0013182418188080192
      grad_gnorm: 30.626976013183594
      policy_entropy: 8.029414176940918
      policy_loss: 9.326330184936523
      var_gnorm: 34.363826751708984
      vf_explained_var: -0.6795791387557983
      vf_loss: 16.503583908081055
    num_steps_sampled: 630000
    num_steps_trained: 630000
    wait_time_ms: 72.401
  iterations_since_restore: 210
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1777.1572606563568
  time_this_iter_s: 8.721779108047485
  time_total_s: 1777.1572606563568
  timestamp: 1594089540
  timesteps_since_restore: 630000
  timesteps_this_iter: 3000
  timesteps_total: 630000
  training_iteration: 210
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1777 s, 210 iter, 630000 ts, 930 rew

agent-1: 356.0
agent-2: 385.0
agent-3: 373.0
Sum Reward: 1114.0
Avg Reward: 371.3333333333333
Min Reward: 356.0
Max Reward: 385.0
Gini Coefficient: 0.017354877318970677
20:20 Ratio: 1.0814606741573034
Max-min Ratio: 1.0814606741573034
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-39-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 931.5
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 210
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.833
    dispatch_time_ms: 26.149
    learner:
      cur_lr: 0.0013180420501157641
      grad_gnorm: 40.0
      policy_entropy: 14.381669044494629
      policy_loss: 21.7850399017334
      var_gnorm: 34.47271728515625
      vf_explained_var: 0.22429746389389038
      vf_loss: 78.45674896240234
    num_steps_sampled: 633000
    num_steps_trained: 633000
    wait_time_ms: 58.849
  iterations_since_restore: 211
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1786.1305222511292
  time_this_iter_s: 8.973261594772339
  time_total_s: 1786.1305222511292
  timestamp: 1594089549
  timesteps_since_restore: 633000
  timesteps_this_iter: 3000
  timesteps_total: 633000
  training_iteration: 211
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1786 s, 211 iter, 633000 ts, 932 rew

agent-1: 342.0
agent-2: 381.0
agent-3: 339.0
Sum Reward: 1062.0
Avg Reward: 354.0
Min Reward: 339.0
Max Reward: 381.0
Gini Coefficient: 0.026365348399246705
20:20 Ratio: 1.1238938053097345
Max-min Ratio: 1.1238938053097345
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-39-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 932.01
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 211
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.453
    dispatch_time_ms: 25.691
    learner:
      cur_lr: 0.0013178421650081873
      grad_gnorm: 40.0
      policy_entropy: 13.440899848937988
      policy_loss: 20.234174728393555
      var_gnorm: 34.561241149902344
      vf_explained_var: 0.14032137393951416
      vf_loss: 50.68813705444336
    num_steps_sampled: 636000
    num_steps_trained: 636000
    wait_time_ms: 62.569
  iterations_since_restore: 212
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1794.9304213523865
  time_this_iter_s: 8.799899101257324
  time_total_s: 1794.9304213523865
  timestamp: 1594089558
  timesteps_since_restore: 636000
  timesteps_this_iter: 3000
  timesteps_total: 636000
  training_iteration: 212
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1794 s, 212 iter, 636000 ts, 932 rew

agent-1: 315.0
agent-2: 365.0
agent-3: 329.0
Sum Reward: 1009.0
Avg Reward: 336.3333333333333
Min Reward: 315.0
Max Reward: 365.0
Gini Coefficient: 0.03303600925008259
20:20 Ratio: 1.1587301587301588
Max-min Ratio: 1.1587301587301588
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-39-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 931.94
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 212
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.951
    dispatch_time_ms: 16.46
    learner:
      cur_lr: 0.0013176423963159323
      grad_gnorm: 40.0
      policy_entropy: 21.452808380126953
      policy_loss: 12.268088340759277
      var_gnorm: 34.66337585449219
      vf_explained_var: -0.2004082202911377
      vf_loss: 15.164892196655273
    num_steps_sampled: 639000
    num_steps_trained: 639000
    wait_time_ms: 67.175
  iterations_since_restore: 213
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1804.0366888046265
  time_this_iter_s: 9.10626745223999
  time_total_s: 1804.0366888046265
  timestamp: 1594089567
  timesteps_since_restore: 639000
  timesteps_this_iter: 3000
  timesteps_total: 639000
  training_iteration: 213
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1804 s, 213 iter, 639000 ts, 932 rew

agent-1: 351.0
agent-2: 313.0
agent-3: 367.0
Sum Reward: 1031.0
Avg Reward: 343.6666666666667
Min Reward: 313.0
Max Reward: 367.0
Gini Coefficient: 0.03491755577109602
20:20 Ratio: 1.1725239616613419
Max-min Ratio: 1.1725239616613419
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-39-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 932.18
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 213
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.466
    dispatch_time_ms: 17.699
    learner:
      cur_lr: 0.0013174426276236773
      grad_gnorm: 40.0
      policy_entropy: 24.815576553344727
      policy_loss: -21.9816951751709
      var_gnorm: 34.72547149658203
      vf_explained_var: 0.5600045919418335
      vf_loss: 24.92037582397461
    num_steps_sampled: 642000
    num_steps_trained: 642000
    wait_time_ms: 67.985
  iterations_since_restore: 214
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1812.6725492477417
  time_this_iter_s: 8.635860443115234
  time_total_s: 1812.6725492477417
  timestamp: 1594089576
  timesteps_since_restore: 642000
  timesteps_this_iter: 3000
  timesteps_total: 642000
  training_iteration: 214
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1812 s, 214 iter, 642000 ts, 932 rew

agent-1: 337.0
agent-2: 376.0
agent-3: 324.0
Sum Reward: 1037.0
Avg Reward: 345.6666666666667
Min Reward: 324.0
Max Reward: 376.0
Gini Coefficient: 0.03342976534876246
20:20 Ratio: 1.1604938271604939
Max-min Ratio: 1.1604938271604939
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-39-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 932.77
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 214
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.333
    dispatch_time_ms: 34.971
    learner:
      cur_lr: 0.0013172427425161004
      grad_gnorm: 38.22346115112305
      policy_entropy: 21.497066497802734
      policy_loss: -8.607270240783691
      var_gnorm: 34.74843215942383
      vf_explained_var: 0.6597331166267395
      vf_loss: 32.67906951904297
    num_steps_sampled: 645000
    num_steps_trained: 645000
    wait_time_ms: 59.745
  iterations_since_restore: 215
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1821.7562704086304
  time_this_iter_s: 9.083721160888672
  time_total_s: 1821.7562704086304
  timestamp: 1594089585
  timesteps_since_restore: 645000
  timesteps_this_iter: 3000
  timesteps_total: 645000
  training_iteration: 215
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1821 s, 215 iter, 645000 ts, 933 rew

agent-1: 366.0
agent-2: 355.0
agent-3: 302.0
Sum Reward: 1023.0
Avg Reward: 341.0
Min Reward: 302.0
Max Reward: 366.0
Gini Coefficient: 0.041707396546106223
20:20 Ratio: 1.2119205298013245
Max-min Ratio: 1.2119205298013245
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-39-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 933.92
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 215
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.829
    dispatch_time_ms: 14.158
    learner:
      cur_lr: 0.0013170429738238454
      grad_gnorm: 40.0
      policy_entropy: 12.227128028869629
      policy_loss: 3.705601692199707
      var_gnorm: 34.770084381103516
      vf_explained_var: -0.07472217082977295
      vf_loss: 23.401588439941406
    num_steps_sampled: 648000
    num_steps_trained: 648000
    wait_time_ms: 69.567
  iterations_since_restore: 216
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1830.6591968536377
  time_this_iter_s: 8.902926445007324
  time_total_s: 1830.6591968536377
  timestamp: 1594089594
  timesteps_since_restore: 648000
  timesteps_this_iter: 3000
  timesteps_total: 648000
  training_iteration: 216
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1830 s, 216 iter, 648000 ts, 934 rew

agent-1: 299.0
agent-2: 348.0
agent-3: 285.0
Sum Reward: 932.0
Avg Reward: 310.6666666666667
Min Reward: 285.0
Max Reward: 348.0
Gini Coefficient: 0.045064377682403435
20:20 Ratio: 1.2210526315789474
Max-min Ratio: 1.2210526315789474
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-40-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 936.96
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 216
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.488
    dispatch_time_ms: 29.408
    learner:
      cur_lr: 0.0013168432051315904
      grad_gnorm: 39.999996185302734
      policy_entropy: 17.644485473632812
      policy_loss: 32.38730239868164
      var_gnorm: 34.866641998291016
      vf_explained_var: -0.5352236032485962
      vf_loss: 144.1043701171875
    num_steps_sampled: 651000
    num_steps_trained: 651000
    wait_time_ms: 68.772
  iterations_since_restore: 217
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1840.5398395061493
  time_this_iter_s: 9.880642652511597
  time_total_s: 1840.5398395061493
  timestamp: 1594089604
  timesteps_since_restore: 651000
  timesteps_this_iter: 3000
  timesteps_total: 651000
  training_iteration: 217
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1840 s, 217 iter, 651000 ts, 937 rew

agent-1: 322.0
agent-2: 407.0
agent-3: 254.0
Sum Reward: 983.0
Avg Reward: 327.6666666666667
Min Reward: 254.0
Max Reward: 407.0
Gini Coefficient: 0.10376398779247202
20:20 Ratio: 1.6023622047244095
Max-min Ratio: 1.6023622047244095
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-40-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 941.27
  episode_reward_min: 124.0
  episodes_this_iter: 1
  episodes_total: 217
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.611
    dispatch_time_ms: 28.013
    learner:
      cur_lr: 0.0013166434364393353
      grad_gnorm: 40.000003814697266
      policy_entropy: 19.682540893554688
      policy_loss: -23.370792388916016
      var_gnorm: 34.96986770629883
      vf_explained_var: -0.5765697956085205
      vf_loss: 47.18608856201172
    num_steps_sampled: 654000
    num_steps_trained: 654000
    wait_time_ms: 49.583
  iterations_since_restore: 218
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1848.9115438461304
  time_this_iter_s: 8.371704339981079
  time_total_s: 1848.9115438461304
  timestamp: 1594089612
  timesteps_since_restore: 654000
  timesteps_this_iter: 3000
  timesteps_total: 654000
  training_iteration: 218
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1848 s, 218 iter, 654000 ts, 941 rew

agent-1: 233.0
agent-2: 234.0
agent-3: 238.0
Sum Reward: 705.0
Avg Reward: 235.0
Min Reward: 233.0
Max Reward: 238.0
Gini Coefficient: 0.004728132387706856
20:20 Ratio: 1.0214592274678111
Max-min Ratio: 1.0214592274678111
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-40-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 947.08
  episode_reward_min: 361.0
  episodes_this_iter: 1
  episodes_total: 218
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.791
    dispatch_time_ms: 12.442
    learner:
      cur_lr: 0.0013164435513317585
      grad_gnorm: 40.000003814697266
      policy_entropy: 21.539182662963867
      policy_loss: -11.464075088500977
      var_gnorm: 34.944488525390625
      vf_explained_var: 0.11669367551803589
      vf_loss: 38.31884002685547
    num_steps_sampled: 657000
    num_steps_trained: 657000
    wait_time_ms: 69.421
  iterations_since_restore: 219
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1857.4909799098969
  time_this_iter_s: 8.57943606376648
  time_total_s: 1857.4909799098969
  timestamp: 1594089621
  timesteps_since_restore: 657000
  timesteps_this_iter: 3000
  timesteps_total: 657000
  training_iteration: 219
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1857 s, 219 iter, 657000 ts, 947 rew

agent-1: 248.0
agent-2: 312.0
agent-3: 314.0
Sum Reward: 874.0
Avg Reward: 291.3333333333333
Min Reward: 248.0
Max Reward: 314.0
Gini Coefficient: 0.05034324942791762
20:20 Ratio: 1.2661290322580645
Max-min Ratio: 1.2661290322580645
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-40-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 952.21
  episode_reward_min: 412.0
  episodes_this_iter: 1
  episodes_total: 219
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.841
    dispatch_time_ms: 28.384
    learner:
      cur_lr: 0.0013162437826395035
      grad_gnorm: 40.0
      policy_entropy: 20.38873291015625
      policy_loss: 22.012046813964844
      var_gnorm: 34.98723602294922
      vf_explained_var: -0.07672393321990967
      vf_loss: 61.375850677490234
    num_steps_sampled: 660000
    num_steps_trained: 660000
    wait_time_ms: 55.172
  iterations_since_restore: 220
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1865.8156971931458
  time_this_iter_s: 8.324717283248901
  time_total_s: 1865.8156971931458
  timestamp: 1594089629
  timesteps_since_restore: 660000
  timesteps_this_iter: 3000
  timesteps_total: 660000
  training_iteration: 220
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1865 s, 220 iter, 660000 ts, 952 rew

agent-1: 272.0
agent-2: 259.0
agent-3: 276.0
Sum Reward: 807.0
Avg Reward: 269.0
Min Reward: 259.0
Max Reward: 276.0
Gini Coefficient: 0.014043783560512184
20:20 Ratio: 1.0656370656370657
Max-min Ratio: 1.0656370656370657
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-40-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 956.16
  episode_reward_min: 515.0
  episodes_this_iter: 1
  episodes_total: 220
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.576
    dispatch_time_ms: 25.464
    learner:
      cur_lr: 0.0013160440139472485
      grad_gnorm: 40.0
      policy_entropy: 22.556127548217773
      policy_loss: 18.28292465209961
      var_gnorm: 34.95286560058594
      vf_explained_var: 0.4601142406463623
      vf_loss: 77.02523040771484
    num_steps_sampled: 663000
    num_steps_trained: 663000
    wait_time_ms: 55.377
  iterations_since_restore: 221
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1874.3480656147003
  time_this_iter_s: 8.532368421554565
  time_total_s: 1874.3480656147003
  timestamp: 1594089638
  timesteps_since_restore: 663000
  timesteps_this_iter: 3000
  timesteps_total: 663000
  training_iteration: 221
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1874 s, 221 iter, 663000 ts, 956 rew

agent-1: 240.0
agent-2: 271.0
agent-3: 246.0
Sum Reward: 757.0
Avg Reward: 252.33333333333334
Min Reward: 240.0
Max Reward: 271.0
Gini Coefficient: 0.027300748568912372
20:20 Ratio: 1.1291666666666667
Max-min Ratio: 1.1291666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-40-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 958.58
  episode_reward_min: 628.0
  episodes_this_iter: 1
  episodes_total: 221
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.75
    dispatch_time_ms: 22.409
    learner:
      cur_lr: 0.0013158442452549934
      grad_gnorm: 40.0
      policy_entropy: 14.141271591186523
      policy_loss: 0.45513343811035156
      var_gnorm: 34.98230743408203
      vf_explained_var: 0.2816634178161621
      vf_loss: 40.31696319580078
    num_steps_sampled: 666000
    num_steps_trained: 666000
    wait_time_ms: 72.596
  iterations_since_restore: 222
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1882.99014878273
  time_this_iter_s: 8.642083168029785
  time_total_s: 1882.99014878273
  timestamp: 1594089647
  timesteps_since_restore: 666000
  timesteps_this_iter: 3000
  timesteps_total: 666000
  training_iteration: 222
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1882 s, 222 iter, 666000 ts, 959 rew

agent-1: 340.0
agent-2: 364.0
agent-3: 257.0
Sum Reward: 961.0
Avg Reward: 320.3333333333333
Min Reward: 257.0
Max Reward: 364.0
Gini Coefficient: 0.07422823447797433
20:20 Ratio: 1.416342412451362
Max-min Ratio: 1.416342412451362
agent-1: 303.0
agent-2: 324.0
agent-3: 343.0
Sum Reward: 970.0
Avg Reward: 323.3333333333333
Min Reward: 303.0
Max Reward: 343.0
Gini Coefficient: 0.027491408934707903
20:20 Ratio: 1.132013201320132
Max-min Ratio: 1.132013201320132
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-40-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 961.17
  episode_reward_min: 628.0
  episodes_this_iter: 2
  episodes_total: 223
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.668
    dispatch_time_ms: 15.935
    learner:
      cur_lr: 0.0013156443601474166
      grad_gnorm: 39.999996185302734
      policy_entropy: 12.331960678100586
      policy_loss: -415.9164733886719
      var_gnorm: 35.01921081542969
      vf_explained_var: 0.2718195915222168
      vf_loss: 11862.52734375
    num_steps_sampled: 669000
    num_steps_trained: 669000
    wait_time_ms: 79.996
  iterations_since_restore: 223
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1892.4024167060852
  time_this_iter_s: 9.412267923355103
  time_total_s: 1892.4024167060852
  timestamp: 1594089656
  timesteps_since_restore: 669000
  timesteps_this_iter: 3000
  timesteps_total: 669000
  training_iteration: 223
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1892 s, 223 iter, 669000 ts, 961 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-41-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 961.17
  episode_reward_min: 628.0
  episodes_this_iter: 0
  episodes_total: 223
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.411
    dispatch_time_ms: 16.872
    learner:
      cur_lr: 0.0013154445914551616
      grad_gnorm: 40.000003814697266
      policy_entropy: 21.050901412963867
      policy_loss: -13.615299224853516
      var_gnorm: 35.19163131713867
      vf_explained_var: 0.3279803991317749
      vf_loss: 16.285348892211914
    num_steps_sampled: 672000
    num_steps_trained: 672000
    wait_time_ms: 86.151
  iterations_since_restore: 224
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1901.4468700885773
  time_this_iter_s: 9.044453382492065
  time_total_s: 1901.4468700885773
  timestamp: 1594089665
  timesteps_since_restore: 672000
  timesteps_this_iter: 3000
  timesteps_total: 672000
  training_iteration: 224
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1901 s, 224 iter, 672000 ts, 961 rew

agent-1: 337.0
agent-2: 359.0
agent-3: 345.0
Sum Reward: 1041.0
Avg Reward: 347.0
Min Reward: 337.0
Max Reward: 359.0
Gini Coefficient: 0.01408901697086135
20:20 Ratio: 1.0652818991097923
Max-min Ratio: 1.0652818991097923
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-41-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 962.94
  episode_reward_min: 628.0
  episodes_this_iter: 1
  episodes_total: 224
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.33
    dispatch_time_ms: 16.167
    learner:
      cur_lr: 0.0013152448227629066
      grad_gnorm: 40.0
      policy_entropy: 22.60367774963379
      policy_loss: -27.524978637695312
      var_gnorm: 35.20024490356445
      vf_explained_var: 0.35501182079315186
      vf_loss: 22.391712188720703
    num_steps_sampled: 675000
    num_steps_trained: 675000
    wait_time_ms: 84.756
  iterations_since_restore: 225
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1911.0771613121033
  time_this_iter_s: 9.630291223526001
  time_total_s: 1911.0771613121033
  timestamp: 1594089675
  timesteps_since_restore: 675000
  timesteps_this_iter: 3000
  timesteps_total: 675000
  training_iteration: 225
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1911 s, 225 iter, 675000 ts, 963 rew

agent-1: 346.0
agent-2: 349.0
agent-3: 342.0
Sum Reward: 1037.0
Avg Reward: 345.6666666666667
Min Reward: 342.0
Max Reward: 349.0
Gini Coefficient: 0.004500160720025715
20:20 Ratio: 1.0204678362573099
Max-min Ratio: 1.0204678362573099
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-41-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 965.65
  episode_reward_min: 628.0
  episodes_this_iter: 1
  episodes_total: 225
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.994
    dispatch_time_ms: 33.785
    learner:
      cur_lr: 0.0013150450540706515
      grad_gnorm: 28.95345115661621
      policy_entropy: 14.674461364746094
      policy_loss: 2.225774049758911
      var_gnorm: 35.196929931640625
      vf_explained_var: 0.0910990834236145
      vf_loss: 17.333637237548828
    num_steps_sampled: 678000
    num_steps_trained: 678000
    wait_time_ms: 62.196
  iterations_since_restore: 226
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1920.1730771064758
  time_this_iter_s: 9.095915794372559
  time_total_s: 1920.1730771064758
  timestamp: 1594089684
  timesteps_since_restore: 678000
  timesteps_this_iter: 3000
  timesteps_total: 678000
  training_iteration: 226
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1920 s, 226 iter, 678000 ts, 966 rew

agent-1: 354.0
agent-2: 338.0
agent-3: 337.0
Sum Reward: 1029.0
Avg Reward: 343.0
Min Reward: 337.0
Max Reward: 354.0
Gini Coefficient: 0.01101392938127632
20:20 Ratio: 1.0504451038575668
Max-min Ratio: 1.0504451038575668
agent-1: 399.0
agent-2: 364.0
agent-3: 331.0
Sum Reward: 1094.0
Avg Reward: 364.6666666666667
Min Reward: 331.0
Max Reward: 399.0
Gini Coefficient: 0.04143814747105423
20:20 Ratio: 1.2054380664652569
Max-min Ratio: 1.2054380664652569
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-41-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 971.25
  episode_reward_min: 683.0
  episodes_this_iter: 2
  episodes_total: 227
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.492
    dispatch_time_ms: 30.186
    learner:
      cur_lr: 0.0013148451689630747
      grad_gnorm: 22.784128189086914
      policy_entropy: 13.34113883972168
      policy_loss: -7.226330757141113
      var_gnorm: 35.226470947265625
      vf_explained_var: 0.5350667238235474
      vf_loss: 14.389421463012695
    num_steps_sampled: 681000
    num_steps_trained: 681000
    wait_time_ms: 70.356
  iterations_since_restore: 227
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1929.5067772865295
  time_this_iter_s: 9.333700180053711
  time_total_s: 1929.5067772865295
  timestamp: 1594089693
  timesteps_since_restore: 681000
  timesteps_this_iter: 3000
  timesteps_total: 681000
  training_iteration: 227
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1929 s, 227 iter, 681000 ts, 971 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-41-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 971.25
  episode_reward_min: 683.0
  episodes_this_iter: 0
  episodes_total: 227
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.049
    dispatch_time_ms: 46.158
    learner:
      cur_lr: 0.0013146454002708197
      grad_gnorm: 40.0
      policy_entropy: 9.255514144897461
      policy_loss: 4.713191986083984
      var_gnorm: 35.30851745605469
      vf_explained_var: 0.312811017036438
      vf_loss: 15.659509658813477
    num_steps_sampled: 684000
    num_steps_trained: 684000
    wait_time_ms: 90.83
  iterations_since_restore: 228
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1938.5823578834534
  time_this_iter_s: 9.075580596923828
  time_total_s: 1938.5823578834534
  timestamp: 1594089703
  timesteps_since_restore: 684000
  timesteps_this_iter: 3000
  timesteps_total: 684000
  training_iteration: 228
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1938 s, 228 iter, 684000 ts, 971 rew

agent-1: 368.0
agent-2: 378.0
agent-3: 397.0
Sum Reward: 1143.0
Avg Reward: 381.0
Min Reward: 368.0
Max Reward: 397.0
Gini Coefficient: 0.016914552347623214
20:20 Ratio: 1.078804347826087
Max-min Ratio: 1.078804347826087
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-41-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 971.95
  episode_reward_min: 683.0
  episodes_this_iter: 1
  episodes_total: 228
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.559
    dispatch_time_ms: 21.904
    learner:
      cur_lr: 0.0013144456315785646
      grad_gnorm: 8.358624458312988
      policy_entropy: 13.273573875427246
      policy_loss: 3.8573520183563232
      var_gnorm: 35.376102447509766
      vf_explained_var: -0.12280714511871338
      vf_loss: 4.146456718444824
    num_steps_sampled: 687000
    num_steps_trained: 687000
    wait_time_ms: 59.981
  iterations_since_restore: 229
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1947.5443699359894
  time_this_iter_s: 8.96201205253601
  time_total_s: 1947.5443699359894
  timestamp: 1594089712
  timesteps_since_restore: 687000
  timesteps_this_iter: 3000
  timesteps_total: 687000
  training_iteration: 229
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1947 s, 229 iter, 687000 ts, 972 rew

agent-1: 397.0
agent-2: 344.0
agent-3: 403.0
Sum Reward: 1144.0
Avg Reward: 381.3333333333333
Min Reward: 344.0
Max Reward: 403.0
Gini Coefficient: 0.034382284382284384
20:20 Ratio: 1.1715116279069768
Max-min Ratio: 1.1715116279069768
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-42-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1144.0
  episode_reward_mean: 973.47
  episode_reward_min: 683.0
  episodes_this_iter: 1
  episodes_total: 229
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.616
    dispatch_time_ms: 32.94
    learner:
      cur_lr: 0.0013142457464709878
      grad_gnorm: 26.233964920043945
      policy_entropy: 5.284676551818848
      policy_loss: -2.662445068359375
      var_gnorm: 35.37751007080078
      vf_explained_var: 0.3311973810195923
      vf_loss: 14.599715232849121
    num_steps_sampled: 690000
    num_steps_trained: 690000
    wait_time_ms: 53.684
  iterations_since_restore: 230
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1956.24893283844
  time_this_iter_s: 8.704562902450562
  time_total_s: 1956.24893283844
  timestamp: 1594089720
  timesteps_since_restore: 690000
  timesteps_this_iter: 3000
  timesteps_total: 690000
  training_iteration: 230
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1956 s, 230 iter, 690000 ts, 973 rew

agent-1: 411.0
agent-2: 380.0
agent-3: 398.0
Sum Reward: 1189.0
Avg Reward: 396.3333333333333
Min Reward: 380.0
Max Reward: 411.0
Gini Coefficient: 0.017381553125876085
20:20 Ratio: 1.081578947368421
Max-min Ratio: 1.081578947368421
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-42-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1189.0
  episode_reward_mean: 975.97
  episode_reward_min: 683.0
  episodes_this_iter: 1
  episodes_total: 230
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.181
    dispatch_time_ms: 28.391
    learner:
      cur_lr: 0.0013140459777787328
      grad_gnorm: 28.169294357299805
      policy_entropy: 12.302550315856934
      policy_loss: -7.568180084228516
      var_gnorm: 35.47221374511719
      vf_explained_var: 0.37112605571746826
      vf_loss: 18.049861907958984
    num_steps_sampled: 693000
    num_steps_trained: 693000
    wait_time_ms: 48.432
  iterations_since_restore: 231
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1965.494684457779
  time_this_iter_s: 9.24575161933899
  time_total_s: 1965.494684457779
  timestamp: 1594089730
  timesteps_since_restore: 693000
  timesteps_this_iter: 3000
  timesteps_total: 693000
  training_iteration: 231
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1965 s, 231 iter, 693000 ts, 976 rew

agent-1: 415.0
agent-2: 391.0
agent-3: 389.0
Sum Reward: 1195.0
Avg Reward: 398.3333333333333
Min Reward: 389.0
Max Reward: 415.0
Gini Coefficient: 0.014504881450488146
20:20 Ratio: 1.0668380462724936
Max-min Ratio: 1.0668380462724936
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-42-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1195.0
  episode_reward_mean: 978.2
  episode_reward_min: 683.0
  episodes_this_iter: 1
  episodes_total: 231
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.523
    dispatch_time_ms: 22.431
    learner:
      cur_lr: 0.0013138462090864778
      grad_gnorm: 31.21907615661621
      policy_entropy: 13.215816497802734
      policy_loss: -6.195687294006348
      var_gnorm: 35.51210021972656
      vf_explained_var: -1.0
      vf_loss: 15.104129791259766
    num_steps_sampled: 696000
    num_steps_trained: 696000
    wait_time_ms: 60.42
  iterations_since_restore: 232
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1974.3671560287476
  time_this_iter_s: 8.872471570968628
  time_total_s: 1974.3671560287476
  timestamp: 1594089739
  timesteps_since_restore: 696000
  timesteps_this_iter: 3000
  timesteps_total: 696000
  training_iteration: 232
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1974 s, 232 iter, 696000 ts, 978 rew

agent-1: 414.0
agent-2: 406.0
agent-3: 388.0
Sum Reward: 1208.0
Avg Reward: 402.6666666666667
Min Reward: 388.0
Max Reward: 414.0
Gini Coefficient: 0.01434878587196468
20:20 Ratio: 1.0670103092783505
Max-min Ratio: 1.0670103092783505
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-42-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 981.58
  episode_reward_min: 683.0
  episodes_this_iter: 1
  episodes_total: 232
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.459
    dispatch_time_ms: 17.246
    learner:
      cur_lr: 0.0013136464403942227
      grad_gnorm: 20.99920654296875
      policy_entropy: 21.055599212646484
      policy_loss: -10.279870986938477
      var_gnorm: 35.59225082397461
      vf_explained_var: 0.11854475736618042
      vf_loss: 20.619871139526367
    num_steps_sampled: 699000
    num_steps_trained: 699000
    wait_time_ms: 56.505
  iterations_since_restore: 233
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1983.6689178943634
  time_this_iter_s: 9.301761865615845
  time_total_s: 1983.6689178943634
  timestamp: 1594089748
  timesteps_since_restore: 699000
  timesteps_this_iter: 3000
  timesteps_total: 699000
  training_iteration: 233
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1983 s, 233 iter, 699000 ts, 982 rew

agent-1: 374.0
agent-2: 380.0
agent-3: 405.0
Sum Reward: 1159.0
Avg Reward: 386.3333333333333
Min Reward: 374.0
Max Reward: 405.0
Gini Coefficient: 0.017831463905665805
20:20 Ratio: 1.0828877005347595
Max-min Ratio: 1.0828877005347595
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-42-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 983.89
  episode_reward_min: 683.0
  episodes_this_iter: 1
  episodes_total: 233
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.944
    dispatch_time_ms: 8.572
    learner:
      cur_lr: 0.0013134465552866459
      grad_gnorm: 24.148256301879883
      policy_entropy: 14.448395729064941
      policy_loss: -8.604713439941406
      var_gnorm: 35.59079360961914
      vf_explained_var: 0.4424816966056824
      vf_loss: 13.0543212890625
    num_steps_sampled: 702000
    num_steps_trained: 702000
    wait_time_ms: 77.814
  iterations_since_restore: 234
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 1998.2880039215088
  time_this_iter_s: 14.619086027145386
  time_total_s: 1998.2880039215088
  timestamp: 1594089763
  timesteps_since_restore: 702000
  timesteps_this_iter: 3000
  timesteps_total: 702000
  training_iteration: 234
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 1998 s, 234 iter, 702000 ts, 984 rew

agent-1: 269.0
agent-2: 361.0
agent-3: 382.0
Sum Reward: 1012.0
Avg Reward: 337.3333333333333
Min Reward: 269.0
Max Reward: 382.0
Gini Coefficient: 0.07444005270092227
20:20 Ratio: 1.420074349442379
Max-min Ratio: 1.420074349442379
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-42-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 984.74
  episode_reward_min: 683.0
  episodes_this_iter: 1
  episodes_total: 234
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.891
    dispatch_time_ms: 7.388
    learner:
      cur_lr: 0.0013132467865943909
      grad_gnorm: 21.118061065673828
      policy_entropy: 16.835052490234375
      policy_loss: 2.5419185161590576
      var_gnorm: 35.64509201049805
      vf_explained_var: 0.7074366211891174
      vf_loss: 3.009458541870117
    num_steps_sampled: 705000
    num_steps_trained: 705000
    wait_time_ms: 70.033
  iterations_since_restore: 235
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2007.5011961460114
  time_this_iter_s: 9.213192224502563
  time_total_s: 2007.5011961460114
  timestamp: 1594089772
  timesteps_since_restore: 705000
  timesteps_this_iter: 3000
  timesteps_total: 705000
  training_iteration: 235
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2007 s, 235 iter, 705000 ts, 985 rew

agent-1: 371.0
agent-2: 382.0
agent-3: 422.0
Sum Reward: 1175.0
Avg Reward: 391.6666666666667
Min Reward: 371.0
Max Reward: 422.0
Gini Coefficient: 0.02893617021276596
20:20 Ratio: 1.137466307277628
Max-min Ratio: 1.137466307277628
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-43-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 986.28
  episode_reward_min: 683.0
  episodes_this_iter: 1
  episodes_total: 235
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.61
    dispatch_time_ms: 7.341
    learner:
      cur_lr: 0.0013130470179021358
      grad_gnorm: 40.0
      policy_entropy: 18.282024383544922
      policy_loss: -24.681291580200195
      var_gnorm: 35.73092269897461
      vf_explained_var: 0.16958171129226685
      vf_loss: 43.51352310180664
    num_steps_sampled: 708000
    num_steps_trained: 708000
    wait_time_ms: 77.2
  iterations_since_restore: 236
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2016.0746674537659
  time_this_iter_s: 8.573471307754517
  time_total_s: 2016.0746674537659
  timestamp: 1594089780
  timesteps_since_restore: 708000
  timesteps_this_iter: 3000
  timesteps_total: 708000
  training_iteration: 236
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2016 s, 236 iter, 708000 ts, 986 rew

agent-1: 300.0
agent-2: 376.0
agent-3: 380.0
Sum Reward: 1056.0
Avg Reward: 352.0
Min Reward: 300.0
Max Reward: 380.0
Gini Coefficient: 0.050505050505050504
20:20 Ratio: 1.2666666666666666
Max-min Ratio: 1.2666666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-43-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 987.95
  episode_reward_min: 683.0
  episodes_this_iter: 1
  episodes_total: 236
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.703
    dispatch_time_ms: 7.349
    learner:
      cur_lr: 0.0013128472492098808
      grad_gnorm: 29.00908088684082
      policy_entropy: 17.11435890197754
      policy_loss: 6.46021842956543
      var_gnorm: 35.69102096557617
      vf_explained_var: 0.1966964602470398
      vf_loss: 8.110841751098633
    num_steps_sampled: 711000
    num_steps_trained: 711000
    wait_time_ms: 66.368
  iterations_since_restore: 237
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2024.793160200119
  time_this_iter_s: 8.71849274635315
  time_total_s: 2024.793160200119
  timestamp: 1594089789
  timesteps_since_restore: 711000
  timesteps_this_iter: 3000
  timesteps_total: 711000
  training_iteration: 237
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2024 s, 237 iter, 711000 ts, 988 rew

agent-1: 356.0
agent-2: 340.0
agent-3: 312.0
Sum Reward: 1008.0
Avg Reward: 336.0
Min Reward: 312.0
Max Reward: 356.0
Gini Coefficient: 0.0291005291005291
20:20 Ratio: 1.141025641025641
Max-min Ratio: 1.141025641025641
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-43-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 989.0
  episode_reward_min: 683.0
  episodes_this_iter: 1
  episodes_total: 237
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.385
    dispatch_time_ms: 4.743
    learner:
      cur_lr: 0.001312647364102304
      grad_gnorm: 40.0
      policy_entropy: 18.410171508789062
      policy_loss: -11.275238037109375
      var_gnorm: 35.65675354003906
      vf_explained_var: -0.24017930030822754
      vf_loss: 20.269899368286133
    num_steps_sampled: 714000
    num_steps_trained: 714000
    wait_time_ms: 84.279
  iterations_since_restore: 238
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2033.0341229438782
  time_this_iter_s: 8.240962743759155
  time_total_s: 2033.0341229438782
  timestamp: 1594089797
  timesteps_since_restore: 714000
  timesteps_this_iter: 3000
  timesteps_total: 714000
  training_iteration: 238
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2033 s, 238 iter, 714000 ts, 989 rew

agent-1: 349.0
agent-2: 350.0
agent-3: 391.0
Sum Reward: 1090.0
Avg Reward: 363.3333333333333
Min Reward: 349.0
Max Reward: 391.0
Gini Coefficient: 0.025688073394495414
20:20 Ratio: 1.1203438395415473
Max-min Ratio: 1.1203438395415473
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-43-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 989.93
  episode_reward_min: 683.0
  episodes_this_iter: 1
  episodes_total: 238
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.033
    dispatch_time_ms: 5.448
    learner:
      cur_lr: 0.001312447595410049
      grad_gnorm: 26.54271697998047
      policy_entropy: 1.7985996007919312
      policy_loss: 0.29772430658340454
      var_gnorm: 35.63329315185547
      vf_explained_var: 0.25939399003982544
      vf_loss: 14.663186073303223
    num_steps_sampled: 717000
    num_steps_trained: 717000
    wait_time_ms: 78.808
  iterations_since_restore: 239
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2042.1220653057098
  time_this_iter_s: 9.087942361831665
  time_total_s: 2042.1220653057098
  timestamp: 1594089807
  timesteps_since_restore: 717000
  timesteps_this_iter: 3000
  timesteps_total: 717000
  training_iteration: 239
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2042 s, 239 iter, 717000 ts, 990 rew

agent-1: 366.0
agent-2: 376.0
agent-3: 403.0
Sum Reward: 1145.0
Avg Reward: 381.6666666666667
Min Reward: 366.0
Max Reward: 403.0
Gini Coefficient: 0.021542940320232896
20:20 Ratio: 1.1010928961748634
Max-min Ratio: 1.1010928961748634
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-43-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 991.55
  episode_reward_min: 683.0
  episodes_this_iter: 1
  episodes_total: 239
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.683
    dispatch_time_ms: 7.045
    learner:
      cur_lr: 0.001312247826717794
      grad_gnorm: 23.8464298248291
      policy_entropy: 12.256509780883789
      policy_loss: -0.7287921905517578
      var_gnorm: 35.68193817138672
      vf_explained_var: 0.32354462146759033
      vf_loss: 7.374875068664551
    num_steps_sampled: 720000
    num_steps_trained: 720000
    wait_time_ms: 83.791
  iterations_since_restore: 240
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2050.705549478531
  time_this_iter_s: 8.583484172821045
  time_total_s: 2050.705549478531
  timestamp: 1594089815
  timesteps_since_restore: 720000
  timesteps_this_iter: 3000
  timesteps_total: 720000
  training_iteration: 240
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2050 s, 240 iter, 720000 ts, 992 rew

agent-1: 394.0
agent-2: 395.0
agent-3: 418.0
Sum Reward: 1207.0
Avg Reward: 402.3333333333333
Min Reward: 394.0
Max Reward: 418.0
Gini Coefficient: 0.013256006628003313
20:20 Ratio: 1.0609137055837563
Max-min Ratio: 1.0609137055837563
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-43-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 994.41
  episode_reward_min: 683.0
  episodes_this_iter: 1
  episodes_total: 240
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.601
    dispatch_time_ms: 6.904
    learner:
      cur_lr: 0.001312048058025539
      grad_gnorm: 40.0
      policy_entropy: 13.524698257446289
      policy_loss: 6.2628607749938965
      var_gnorm: 35.72539520263672
      vf_explained_var: -0.13363909721374512
      vf_loss: 15.796123504638672
    num_steps_sampled: 723000
    num_steps_trained: 723000
    wait_time_ms: 76.084
  iterations_since_restore: 241
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2059.688463449478
  time_this_iter_s: 8.982913970947266
  time_total_s: 2059.688463449478
  timestamp: 1594089824
  timesteps_since_restore: 723000
  timesteps_this_iter: 3000
  timesteps_total: 723000
  training_iteration: 241
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2059 s, 241 iter, 723000 ts, 994 rew

agent-1: 410.0
agent-2: 382.0
agent-3: 404.0
Sum Reward: 1196.0
Avg Reward: 398.6666666666667
Min Reward: 382.0
Max Reward: 410.0
Gini Coefficient: 0.01560758082497213
20:20 Ratio: 1.0732984293193717
Max-min Ratio: 1.0732984293193717
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-43-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 996.86
  episode_reward_min: 683.0
  episodes_this_iter: 1
  episodes_total: 241
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.355
    dispatch_time_ms: 9.184
    learner:
      cur_lr: 0.001311848172917962
      grad_gnorm: 24.092620849609375
      policy_entropy: 18.33340072631836
      policy_loss: -5.213122844696045
      var_gnorm: 35.78678894042969
      vf_explained_var: 0.2852299213409424
      vf_loss: 16.949661254882812
    num_steps_sampled: 726000
    num_steps_trained: 726000
    wait_time_ms: 75.782
  iterations_since_restore: 242
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2068.152971982956
  time_this_iter_s: 8.464508533477783
  time_total_s: 2068.152971982956
  timestamp: 1594089833
  timesteps_since_restore: 726000
  timesteps_this_iter: 3000
  timesteps_total: 726000
  training_iteration: 242
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2068 s, 242 iter, 726000 ts, 997 rew

agent-1: 343.0
agent-2: 333.0
agent-3: 370.0
Sum Reward: 1046.0
Avg Reward: 348.6666666666667
Min Reward: 333.0
Max Reward: 370.0
Gini Coefficient: 0.023581899298916506
20:20 Ratio: 1.1111111111111112
Max-min Ratio: 1.1111111111111112
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-44-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 997.02
  episode_reward_min: 683.0
  episodes_this_iter: 1
  episodes_total: 242
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.554
    dispatch_time_ms: 6.633
    learner:
      cur_lr: 0.001311648404225707
      grad_gnorm: 40.0
      policy_entropy: 17.59661102294922
      policy_loss: -32.421756744384766
      var_gnorm: 35.78855514526367
      vf_explained_var: 0.1885393261909485
      vf_loss: 29.49883270263672
    num_steps_sampled: 729000
    num_steps_trained: 729000
    wait_time_ms: 73.399
  iterations_since_restore: 243
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2077.2276310920715
  time_this_iter_s: 9.0746591091156
  time_total_s: 2077.2276310920715
  timestamp: 1594089842
  timesteps_since_restore: 729000
  timesteps_this_iter: 3000
  timesteps_total: 729000
  training_iteration: 243
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2077 s, 243 iter, 729000 ts, 997 rew

agent-1: 357.0
agent-2: 340.0
agent-3: 357.0
Sum Reward: 1054.0
Avg Reward: 351.3333333333333
Min Reward: 340.0
Max Reward: 357.0
Gini Coefficient: 0.010752688172043012
20:20 Ratio: 1.05
Max-min Ratio: 1.05
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-44-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 997.55
  episode_reward_min: 683.0
  episodes_this_iter: 1
  episodes_total: 243
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.292
    dispatch_time_ms: 5.609
    learner:
      cur_lr: 0.001311448635533452
      grad_gnorm: 40.0
      policy_entropy: 16.23497772216797
      policy_loss: 14.364204406738281
      var_gnorm: 35.79887008666992
      vf_explained_var: 0.26679497957229614
      vf_loss: 15.104665756225586
    num_steps_sampled: 732000
    num_steps_trained: 732000
    wait_time_ms: 83.548
  iterations_since_restore: 244
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2085.7511672973633
  time_this_iter_s: 8.523536205291748
  time_total_s: 2085.7511672973633
  timestamp: 1594089850
  timesteps_since_restore: 732000
  timesteps_this_iter: 3000
  timesteps_total: 732000
  training_iteration: 244
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2085 s, 244 iter, 732000 ts, 998 rew

agent-1: 362.0
agent-2: 366.0
agent-3: 368.0
Sum Reward: 1096.0
Avg Reward: 365.3333333333333
Min Reward: 362.0
Max Reward: 368.0
Gini Coefficient: 0.0036496350364963502
20:20 Ratio: 1.0165745856353592
Max-min Ratio: 1.0165745856353592
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-44-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 997.74
  episode_reward_min: 683.0
  episodes_this_iter: 1
  episodes_total: 244
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.273
    dispatch_time_ms: 5.628
    learner:
      cur_lr: 0.0013112487504258752
      grad_gnorm: 11.535555839538574
      policy_entropy: 19.078079223632812
      policy_loss: 0.30112266540527344
      var_gnorm: 35.85026931762695
      vf_explained_var: 0.23793792724609375
      vf_loss: 9.555032730102539
    num_steps_sampled: 735000
    num_steps_trained: 735000
    wait_time_ms: 83.009
  iterations_since_restore: 245
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2094.6704347133636
  time_this_iter_s: 8.919267416000366
  time_total_s: 2094.6704347133636
  timestamp: 1594089859
  timesteps_since_restore: 735000
  timesteps_this_iter: 3000
  timesteps_total: 735000
  training_iteration: 245
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2094 s, 245 iter, 735000 ts, 998 rew

agent-1: 395.0
agent-2: 370.0
agent-3: 398.0
Sum Reward: 1163.0
Avg Reward: 387.6666666666667
Min Reward: 370.0
Max Reward: 398.0
Gini Coefficient: 0.016050444253367727
20:20 Ratio: 1.0756756756756756
Max-min Ratio: 1.0756756756756756
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-44-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 998.79
  episode_reward_min: 683.0
  episodes_this_iter: 1
  episodes_total: 245
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.877
    dispatch_time_ms: 8.82
    learner:
      cur_lr: 0.0013110489817336202
      grad_gnorm: 26.183332443237305
      policy_entropy: 20.13709831237793
      policy_loss: -0.6554396152496338
      var_gnorm: 35.911502838134766
      vf_explained_var: 0.2764732837677002
      vf_loss: 27.768760681152344
    num_steps_sampled: 738000
    num_steps_trained: 738000
    wait_time_ms: 77.332
  iterations_since_restore: 246
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2103.323247909546
  time_this_iter_s: 8.652813196182251
  time_total_s: 2103.323247909546
  timestamp: 1594089868
  timesteps_since_restore: 738000
  timesteps_this_iter: 3000
  timesteps_total: 738000
  training_iteration: 246
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2103 s, 246 iter, 738000 ts, 999 rew

agent-1: 341.0
agent-2: 379.0
agent-3: 395.0
Sum Reward: 1115.0
Avg Reward: 371.6666666666667
Min Reward: 341.0
Max Reward: 395.0
Gini Coefficient: 0.03228699551569507
20:20 Ratio: 1.1583577712609971
Max-min Ratio: 1.1583577712609971
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-44-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 999.52
  episode_reward_min: 683.0
  episodes_this_iter: 1
  episodes_total: 246
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.688
    dispatch_time_ms: 6.894
    learner:
      cur_lr: 0.0013108492130413651
      grad_gnorm: 24.362817764282227
      policy_entropy: 15.083948135375977
      policy_loss: 4.084817409515381
      var_gnorm: 35.93400573730469
      vf_explained_var: 0.38054829835891724
      vf_loss: 8.56569766998291
    num_steps_sampled: 741000
    num_steps_trained: 741000
    wait_time_ms: 77.086
  iterations_since_restore: 247
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2112.258424758911
  time_this_iter_s: 8.935176849365234
  time_total_s: 2112.258424758911
  timestamp: 1594089877
  timesteps_since_restore: 741000
  timesteps_this_iter: 3000
  timesteps_total: 741000
  training_iteration: 247
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2112 s, 247 iter, 741000 ts, 1e+03 rew

agent-1: 375.0
agent-2: 359.0
agent-3: 380.0
Sum Reward: 1114.0
Avg Reward: 371.3333333333333
Min Reward: 359.0
Max Reward: 380.0
Gini Coefficient: 0.012567324955116697
20:20 Ratio: 1.0584958217270195
Max-min Ratio: 1.0584958217270195
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-44-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 999.8
  episode_reward_min: 683.0
  episodes_this_iter: 1
  episodes_total: 247
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.86
    dispatch_time_ms: 8.067
    learner:
      cur_lr: 0.0013106494443491101
      grad_gnorm: 40.0
      policy_entropy: 15.675917625427246
      policy_loss: 10.056235313415527
      var_gnorm: 36.03843688964844
      vf_explained_var: -0.09924447536468506
      vf_loss: 14.345996856689453
    num_steps_sampled: 744000
    num_steps_trained: 744000
    wait_time_ms: 81.658
  iterations_since_restore: 248
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2121.015385389328
  time_this_iter_s: 8.75696063041687
  time_total_s: 2121.015385389328
  timestamp: 1594089886
  timesteps_since_restore: 744000
  timesteps_this_iter: 3000
  timesteps_total: 744000
  training_iteration: 248
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2121 s, 248 iter, 744000 ts, 1e+03 rew

agent-1: 364.0
agent-2: 365.0
agent-3: 385.0
Sum Reward: 1114.0
Avg Reward: 371.3333333333333
Min Reward: 364.0
Max Reward: 385.0
Gini Coefficient: 0.012567324955116697
20:20 Ratio: 1.0576923076923077
Max-min Ratio: 1.0576923076923077
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-44-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 1000.36
  episode_reward_min: 683.0
  episodes_this_iter: 1
  episodes_total: 248
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.871
    dispatch_time_ms: 7.037
    learner:
      cur_lr: 0.0013104495592415333
      grad_gnorm: 24.67942237854004
      policy_entropy: 18.714996337890625
      policy_loss: 0.1639571189880371
      var_gnorm: 36.0916862487793
      vf_explained_var: 0.25982290506362915
      vf_loss: 25.930845260620117
    num_steps_sampled: 747000
    num_steps_trained: 747000
    wait_time_ms: 72.834
  iterations_since_restore: 249
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2130.333368062973
  time_this_iter_s: 9.31798267364502
  time_total_s: 2130.333368062973
  timestamp: 1594089895
  timesteps_since_restore: 747000
  timesteps_this_iter: 3000
  timesteps_total: 747000
  training_iteration: 249
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2130 s, 249 iter, 747000 ts, 1e+03 rew

agent-1: 390.0
agent-2: 381.0
agent-3: 364.0
Sum Reward: 1135.0
Avg Reward: 378.3333333333333
Min Reward: 364.0
Max Reward: 390.0
Gini Coefficient: 0.015271659324522761
20:20 Ratio: 1.0714285714285714
Max-min Ratio: 1.0714285714285714
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-45-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 1001.04
  episode_reward_min: 683.0
  episodes_this_iter: 1
  episodes_total: 249
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.525
    dispatch_time_ms: 5.532
    learner:
      cur_lr: 0.0013102497905492783
      grad_gnorm: 40.0
      policy_entropy: 15.132116317749023
      policy_loss: -1.6535770893096924
      var_gnorm: 36.12173080444336
      vf_explained_var: 0.19153445959091187
      vf_loss: 18.67035484313965
    num_steps_sampled: 750000
    num_steps_trained: 750000
    wait_time_ms: 80.756
  iterations_since_restore: 250
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2139.2408554553986
  time_this_iter_s: 8.907487392425537
  time_total_s: 2139.2408554553986
  timestamp: 1594089904
  timesteps_since_restore: 750000
  timesteps_this_iter: 3000
  timesteps_total: 750000
  training_iteration: 250
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2139 s, 250 iter, 750000 ts, 1e+03 rew

agent-1: 352.0
agent-2: 376.0
agent-3: 364.0
Sum Reward: 1092.0
Avg Reward: 364.0
Min Reward: 352.0
Max Reward: 376.0
Gini Coefficient: 0.014652014652014652
20:20 Ratio: 1.0681818181818181
Max-min Ratio: 1.0681818181818181
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-45-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 1001.79
  episode_reward_min: 683.0
  episodes_this_iter: 1
  episodes_total: 250
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.589
    dispatch_time_ms: 5.417
    learner:
      cur_lr: 0.0013100500218570232
      grad_gnorm: 40.000003814697266
      policy_entropy: 18.533430099487305
      policy_loss: 15.676544189453125
      var_gnorm: 36.17469024658203
      vf_explained_var: 0.027705609798431396
      vf_loss: 15.795435905456543
    num_steps_sampled: 753000
    num_steps_trained: 753000
    wait_time_ms: 82.004
  iterations_since_restore: 251
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2148.6580431461334
  time_this_iter_s: 9.417187690734863
  time_total_s: 2148.6580431461334
  timestamp: 1594089914
  timesteps_since_restore: 753000
  timesteps_this_iter: 3000
  timesteps_total: 753000
  training_iteration: 251
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2148 s, 251 iter, 753000 ts, 1e+03 rew

agent-1: 360.0
agent-2: 405.0
agent-3: 383.0
Sum Reward: 1148.0
Avg Reward: 382.6666666666667
Min Reward: 360.0
Max Reward: 405.0
Gini Coefficient: 0.02613240418118467
20:20 Ratio: 1.125
Max-min Ratio: 1.125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-45-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 1004.44
  episode_reward_min: 683.0
  episodes_this_iter: 1
  episodes_total: 251
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.249
    dispatch_time_ms: 8.908
    learner:
      cur_lr: 0.0013098502531647682
      grad_gnorm: 40.000003814697266
      policy_entropy: 19.555192947387695
      policy_loss: -8.11439037322998
      var_gnorm: 36.364952087402344
      vf_explained_var: -0.6814261674880981
      vf_loss: 26.643579483032227
    num_steps_sampled: 756000
    num_steps_trained: 756000
    wait_time_ms: 82.242
  iterations_since_restore: 252
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2157.497749567032
  time_this_iter_s: 8.839706420898438
  time_total_s: 2157.497749567032
  timestamp: 1594089922
  timesteps_since_restore: 756000
  timesteps_this_iter: 3000
  timesteps_total: 756000
  training_iteration: 252
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2157 s, 252 iter, 756000 ts, 1e+03 rew

agent-1: 377.0
agent-2: 362.0
agent-3: 334.0
Sum Reward: 1073.0
Avg Reward: 357.6666666666667
Min Reward: 334.0
Max Reward: 377.0
Gini Coefficient: 0.02671637154395775
20:20 Ratio: 1.1287425149700598
Max-min Ratio: 1.1287425149700598
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-45-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 1004.74
  episode_reward_min: 683.0
  episodes_this_iter: 1
  episodes_total: 252
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.459
    dispatch_time_ms: 29.127
    learner:
      cur_lr: 0.0013096503680571914
      grad_gnorm: 9.207062721252441
      policy_entropy: 15.18217945098877
      policy_loss: 1.9768052101135254
      var_gnorm: 36.3762092590332
      vf_explained_var: 0.3652114272117615
      vf_loss: 7.198678970336914
    num_steps_sampled: 759000
    num_steps_trained: 759000
    wait_time_ms: 56.596
  iterations_since_restore: 253
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2166.372884988785
  time_this_iter_s: 8.87513542175293
  time_total_s: 2166.372884988785
  timestamp: 1594089931
  timesteps_since_restore: 759000
  timesteps_this_iter: 3000
  timesteps_total: 759000
  training_iteration: 253
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2166 s, 253 iter, 759000 ts, 1e+03 rew

agent-1: 355.0
agent-2: 358.0
agent-3: 384.0
Sum Reward: 1097.0
Avg Reward: 365.6666666666667
Min Reward: 355.0
Max Reward: 384.0
Gini Coefficient: 0.0176238225463385
20:20 Ratio: 1.0816901408450703
Max-min Ratio: 1.0816901408450703
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-45-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 1004.83
  episode_reward_min: 683.0
  episodes_this_iter: 1
  episodes_total: 253
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.679
    dispatch_time_ms: 16.668
    learner:
      cur_lr: 0.0013094505993649364
      grad_gnorm: 39.999996185302734
      policy_entropy: 17.073320388793945
      policy_loss: -16.466697692871094
      var_gnorm: 36.47865295410156
      vf_explained_var: 0.45230674743652344
      vf_loss: 29.48133659362793
    num_steps_sampled: 762000
    num_steps_trained: 762000
    wait_time_ms: 81.202
  iterations_since_restore: 254
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2175.463887691498
  time_this_iter_s: 9.091002702713013
  time_total_s: 2175.463887691498
  timestamp: 1594089940
  timesteps_since_restore: 762000
  timesteps_this_iter: 3000
  timesteps_total: 762000
  training_iteration: 254
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2175 s, 254 iter, 762000 ts, 1e+03 rew

agent-1: 389.0
agent-2: 379.0
agent-3: 367.0
Sum Reward: 1135.0
Avg Reward: 378.3333333333333
Min Reward: 367.0
Max Reward: 389.0
Gini Coefficient: 0.012922173274596183
20:20 Ratio: 1.0599455040871935
Max-min Ratio: 1.0599455040871935
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-45-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 1005.26
  episode_reward_min: 683.0
  episodes_this_iter: 1
  episodes_total: 254
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.775
    dispatch_time_ms: 14.142
    learner:
      cur_lr: 0.0013092508306726813
      grad_gnorm: 35.658470153808594
      policy_entropy: 13.224197387695312
      policy_loss: 0.5477899312973022
      var_gnorm: 36.493408203125
      vf_explained_var: 0.5485082268714905
      vf_loss: 7.734267711639404
    num_steps_sampled: 765000
    num_steps_trained: 765000
    wait_time_ms: 74.606
  iterations_since_restore: 255
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2185.3840091228485
  time_this_iter_s: 9.920121431350708
  time_total_s: 2185.3840091228485
  timestamp: 1594089950
  timesteps_since_restore: 765000
  timesteps_this_iter: 3000
  timesteps_total: 765000
  training_iteration: 255
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2185 s, 255 iter, 765000 ts, 1.01e+03 rew

agent-1: 336.0
agent-2: 374.0
agent-3: 360.0
Sum Reward: 1070.0
Avg Reward: 356.6666666666667
Min Reward: 336.0
Max Reward: 374.0
Gini Coefficient: 0.02367601246105919
20:20 Ratio: 1.1130952380952381
Max-min Ratio: 1.1130952380952381
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-46-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 1004.99
  episode_reward_min: 683.0
  episodes_this_iter: 1
  episodes_total: 255
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.462
    dispatch_time_ms: 24.645
    learner:
      cur_lr: 0.0013090509455651045
      grad_gnorm: 39.999996185302734
      policy_entropy: 7.477757453918457
      policy_loss: 1.0897561311721802
      var_gnorm: 36.50692367553711
      vf_explained_var: 0.40007394552230835
      vf_loss: 9.297396659851074
    num_steps_sampled: 768000
    num_steps_trained: 768000
    wait_time_ms: 65.446
  iterations_since_restore: 256
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2194.4410014152527
  time_this_iter_s: 9.056992292404175
  time_total_s: 2194.4410014152527
  timestamp: 1594089960
  timesteps_since_restore: 768000
  timesteps_this_iter: 3000
  timesteps_total: 768000
  training_iteration: 256
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2194 s, 256 iter, 768000 ts, 1e+03 rew

agent-1: 351.0
agent-2: 364.0
agent-3: 401.0
Sum Reward: 1116.0
Avg Reward: 372.0
Min Reward: 351.0
Max Reward: 401.0
Gini Coefficient: 0.02986857825567503
20:20 Ratio: 1.1424501424501425
Max-min Ratio: 1.1424501424501425
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-46-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 1005.14
  episode_reward_min: 683.0
  episodes_this_iter: 1
  episodes_total: 256
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.699
    dispatch_time_ms: 20.624
    learner:
      cur_lr: 0.0013088511768728495
      grad_gnorm: 18.84708595275879
      policy_entropy: 15.47327709197998
      policy_loss: -2.070298671722412
      var_gnorm: 36.56289291381836
      vf_explained_var: -0.3522437810897827
      vf_loss: 13.403039932250977
    num_steps_sampled: 771000
    num_steps_trained: 771000
    wait_time_ms: 54.633
  iterations_since_restore: 257
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2203.777543067932
  time_this_iter_s: 9.336541652679443
  time_total_s: 2203.777543067932
  timestamp: 1594089969
  timesteps_since_restore: 771000
  timesteps_this_iter: 3000
  timesteps_total: 771000
  training_iteration: 257
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2203 s, 257 iter, 771000 ts, 1.01e+03 rew

agent-1: 406.0
agent-2: 378.0
agent-3: 387.0
Sum Reward: 1171.0
Avg Reward: 390.3333333333333
Min Reward: 378.0
Max Reward: 406.0
Gini Coefficient: 0.015940791346427556
20:20 Ratio: 1.0740740740740742
Max-min Ratio: 1.0740740740740742
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-46-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 1005.69
  episode_reward_min: 683.0
  episodes_this_iter: 1
  episodes_total: 257
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.971
    dispatch_time_ms: 35.161
    learner:
      cur_lr: 0.0013086514081805944
      grad_gnorm: 10.075882911682129
      policy_entropy: 15.917808532714844
      policy_loss: -7.366153240203857
      var_gnorm: 36.5930061340332
      vf_explained_var: -0.013825774192810059
      vf_loss: 20.570907592773438
    num_steps_sampled: 774000
    num_steps_trained: 774000
    wait_time_ms: 52.474
  iterations_since_restore: 258
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2212.638001203537
  time_this_iter_s: 8.860458135604858
  time_total_s: 2212.638001203537
  timestamp: 1594089978
  timesteps_since_restore: 774000
  timesteps_this_iter: 3000
  timesteps_total: 774000
  training_iteration: 258
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2212 s, 258 iter, 774000 ts, 1.01e+03 rew

agent-1: 370.0
agent-2: 361.0
agent-3: 372.0
Sum Reward: 1103.0
Avg Reward: 367.6666666666667
Min Reward: 361.0
Max Reward: 372.0
Gini Coefficient: 0.006648534300392868
20:20 Ratio: 1.0304709141274238
Max-min Ratio: 1.0304709141274238
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-46-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 1005.52
  episode_reward_min: 683.0
  episodes_this_iter: 1
  episodes_total: 258
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.565
    dispatch_time_ms: 21.572
    learner:
      cur_lr: 0.0013084516394883394
      grad_gnorm: 16.570606231689453
      policy_entropy: 14.12938404083252
      policy_loss: 0.4871041774749756
      var_gnorm: 36.606956481933594
      vf_explained_var: -1.0
      vf_loss: 9.616670608520508
    num_steps_sampled: 777000
    num_steps_trained: 777000
    wait_time_ms: 68.05
  iterations_since_restore: 259
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2222.0587618350983
  time_this_iter_s: 9.42076063156128
  time_total_s: 2222.0587618350983
  timestamp: 1594089987
  timesteps_since_restore: 777000
  timesteps_this_iter: 3000
  timesteps_total: 777000
  training_iteration: 259
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2222 s, 259 iter, 777000 ts, 1.01e+03 rew

agent-1: 381.0
agent-2: 345.0
agent-3: 378.0
Sum Reward: 1104.0
Avg Reward: 368.0
Min Reward: 345.0
Max Reward: 381.0
Gini Coefficient: 0.021739130434782608
20:20 Ratio: 1.1043478260869566
Max-min Ratio: 1.1043478260869566
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-46-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 1005.65
  episode_reward_min: 683.0
  episodes_this_iter: 1
  episodes_total: 259
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.976
    dispatch_time_ms: 29.863
    learner:
      cur_lr: 0.0013082517543807626
      grad_gnorm: 12.777822494506836
      policy_entropy: 14.018399238586426
      policy_loss: 1.206376314163208
      var_gnorm: 36.64500045776367
      vf_explained_var: 0.3431661128997803
      vf_loss: 9.45693588256836
    num_steps_sampled: 780000
    num_steps_trained: 780000
    wait_time_ms: 61.783
  iterations_since_restore: 260
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2231.1133546829224
  time_this_iter_s: 9.054592847824097
  time_total_s: 2231.1133546829224
  timestamp: 1594089996
  timesteps_since_restore: 780000
  timesteps_this_iter: 3000
  timesteps_total: 780000
  training_iteration: 260
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2231 s, 260 iter, 780000 ts, 1.01e+03 rew

agent-1: 336.0
agent-2: 370.0
agent-3: 381.0
Sum Reward: 1087.0
Avg Reward: 362.3333333333333
Min Reward: 336.0
Max Reward: 381.0
Gini Coefficient: 0.027598896044158234
20:20 Ratio: 1.1339285714285714
Max-min Ratio: 1.1339285714285714
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-46-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 1005.08
  episode_reward_min: 683.0
  episodes_this_iter: 1
  episodes_total: 260
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.573
    dispatch_time_ms: 20.201
    learner:
      cur_lr: 0.0013080519856885076
      grad_gnorm: 22.13728141784668
      policy_entropy: 15.143437385559082
      policy_loss: -1.9116950035095215
      var_gnorm: 36.68472671508789
      vf_explained_var: 0.03564697504043579
      vf_loss: 22.510379791259766
    num_steps_sampled: 783000
    num_steps_trained: 783000
    wait_time_ms: 71.636
  iterations_since_restore: 261
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2240.4868581295013
  time_this_iter_s: 9.37350344657898
  time_total_s: 2240.4868581295013
  timestamp: 1594090006
  timesteps_since_restore: 783000
  timesteps_this_iter: 3000
  timesteps_total: 783000
  training_iteration: 261
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2240 s, 261 iter, 783000 ts, 1.01e+03 rew

agent-1: 353.0
agent-2: 362.0
agent-3: 384.0
Sum Reward: 1099.0
Avg Reward: 366.3333333333333
Min Reward: 353.0
Max Reward: 384.0
Gini Coefficient: 0.01880497421898696
20:20 Ratio: 1.0878186968838528
Max-min Ratio: 1.0878186968838528
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-46-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 1005.12
  episode_reward_min: 683.0
  episodes_this_iter: 1
  episodes_total: 261
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.546
    dispatch_time_ms: 6.655
    learner:
      cur_lr: 0.0013078522169962525
      grad_gnorm: 40.0
      policy_entropy: 15.402010917663574
      policy_loss: 13.400375366210938
      var_gnorm: 36.79096603393555
      vf_explained_var: -0.42236387729644775
      vf_loss: 25.826152801513672
    num_steps_sampled: 786000
    num_steps_trained: 786000
    wait_time_ms: 80.551
  iterations_since_restore: 262
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2249.551283597946
  time_this_iter_s: 9.064425468444824
  time_total_s: 2249.551283597946
  timestamp: 1594090015
  timesteps_since_restore: 786000
  timesteps_this_iter: 3000
  timesteps_total: 786000
  training_iteration: 262
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2249 s, 262 iter, 786000 ts, 1.01e+03 rew

agent-1: 393.0
agent-2: 363.0
agent-3: 387.0
Sum Reward: 1143.0
Avg Reward: 381.0
Min Reward: 363.0
Max Reward: 393.0
Gini Coefficient: 0.017497812773403325
20:20 Ratio: 1.0826446280991735
Max-min Ratio: 1.0826446280991735
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-47-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 1006.71
  episode_reward_min: 683.0
  episodes_this_iter: 1
  episodes_total: 262
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.605
    dispatch_time_ms: 5.339
    learner:
      cur_lr: 0.0013076524483039975
      grad_gnorm: 40.0
      policy_entropy: 16.288694381713867
      policy_loss: 6.806690216064453
      var_gnorm: 36.802799224853516
      vf_explained_var: -0.15546858310699463
      vf_loss: 26.225910186767578
    num_steps_sampled: 789000
    num_steps_trained: 789000
    wait_time_ms: 81.323
  iterations_since_restore: 263
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2258.510243177414
  time_this_iter_s: 8.958959579467773
  time_total_s: 2258.510243177414
  timestamp: 1594090024
  timesteps_since_restore: 789000
  timesteps_this_iter: 3000
  timesteps_total: 789000
  training_iteration: 263
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2258 s, 263 iter, 789000 ts, 1.01e+03 rew

agent-1: 374.0
agent-2: 376.0
agent-3: 414.0
Sum Reward: 1164.0
Avg Reward: 388.0
Min Reward: 374.0
Max Reward: 414.0
Gini Coefficient: 0.022909507445589918
20:20 Ratio: 1.106951871657754
Max-min Ratio: 1.106951871657754
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-47-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 1008.58
  episode_reward_min: 683.0
  episodes_this_iter: 1
  episodes_total: 263
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.733
    dispatch_time_ms: 8.04
    learner:
      cur_lr: 0.0013074525631964207
      grad_gnorm: 40.0
      policy_entropy: 15.023295402526855
      policy_loss: -2.3688788414001465
      var_gnorm: 36.8138313293457
      vf_explained_var: -0.4698721170425415
      vf_loss: 25.732418060302734
    num_steps_sampled: 792000
    num_steps_trained: 792000
    wait_time_ms: 81.266
  iterations_since_restore: 264
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2267.187061548233
  time_this_iter_s: 8.676818370819092
  time_total_s: 2267.187061548233
  timestamp: 1594090033
  timesteps_since_restore: 792000
  timesteps_this_iter: 3000
  timesteps_total: 792000
  training_iteration: 264
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2267 s, 264 iter, 792000 ts, 1.01e+03 rew

agent-1: 385.0
agent-2: 365.0
agent-3: 366.0
Sum Reward: 1116.0
Avg Reward: 372.0
Min Reward: 365.0
Max Reward: 385.0
Gini Coefficient: 0.011947431302270013
20:20 Ratio: 1.0547945205479452
Max-min Ratio: 1.0547945205479452
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-47-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 1008.62
  episode_reward_min: 683.0
  episodes_this_iter: 1
  episodes_total: 264
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.519
    dispatch_time_ms: 6.745
    learner:
      cur_lr: 0.0013072527945041656
      grad_gnorm: 40.0
      policy_entropy: 15.876272201538086
      policy_loss: -13.112534523010254
      var_gnorm: 36.80018997192383
      vf_explained_var: 0.1598900556564331
      vf_loss: 36.34202194213867
    num_steps_sampled: 795000
    num_steps_trained: 795000
    wait_time_ms: 81.133
  iterations_since_restore: 265
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2276.4968781471252
  time_this_iter_s: 9.309816598892212
  time_total_s: 2276.4968781471252
  timestamp: 1594090042
  timesteps_since_restore: 795000
  timesteps_this_iter: 3000
  timesteps_total: 795000
  training_iteration: 265
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2276 s, 265 iter, 795000 ts, 1.01e+03 rew

agent-1: 376.0
agent-2: 351.0
agent-3: 409.0
Sum Reward: 1136.0
Avg Reward: 378.6666666666667
Min Reward: 351.0
Max Reward: 409.0
Gini Coefficient: 0.03403755868544601
20:20 Ratio: 1.1652421652421652
Max-min Ratio: 1.1652421652421652
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-47-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 1009.49
  episode_reward_min: 683.0
  episodes_this_iter: 1
  episodes_total: 265
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.879
    dispatch_time_ms: 6.679
    learner:
      cur_lr: 0.0013070530258119106
      grad_gnorm: 40.0
      policy_entropy: 12.55087661743164
      policy_loss: -5.216645240783691
      var_gnorm: 36.83086395263672
      vf_explained_var: 0.3382219076156616
      vf_loss: 13.233230590820312
    num_steps_sampled: 798000
    num_steps_trained: 798000
    wait_time_ms: 86.42
  iterations_since_restore: 266
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2285.193521261215
  time_this_iter_s: 8.696643114089966
  time_total_s: 2285.193521261215
  timestamp: 1594090051
  timesteps_since_restore: 798000
  timesteps_this_iter: 3000
  timesteps_total: 798000
  training_iteration: 266
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2285 s, 266 iter, 798000 ts, 1.01e+03 rew

agent-1: 375.0
agent-2: 319.0
agent-3: 370.0
Sum Reward: 1064.0
Avg Reward: 354.6666666666667
Min Reward: 319.0
Max Reward: 375.0
Gini Coefficient: 0.03508771929824561
20:20 Ratio: 1.1755485893416928
Max-min Ratio: 1.1755485893416928
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-47-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 1010.47
  episode_reward_min: 683.0
  episodes_this_iter: 1
  episodes_total: 266
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.351
    dispatch_time_ms: 5.032
    learner:
      cur_lr: 0.0013068532571196556
      grad_gnorm: 39.999996185302734
      policy_entropy: 13.20047378540039
      policy_loss: 11.296241760253906
      var_gnorm: 36.83232116699219
      vf_explained_var: 0.18120557069778442
      vf_loss: 42.31163024902344
    num_steps_sampled: 801000
    num_steps_trained: 801000
    wait_time_ms: 80.468
  iterations_since_restore: 267
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2294.313532114029
  time_this_iter_s: 9.12001085281372
  time_total_s: 2294.313532114029
  timestamp: 1594090060
  timesteps_since_restore: 801000
  timesteps_this_iter: 3000
  timesteps_total: 801000
  training_iteration: 267
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2294 s, 267 iter, 801000 ts, 1.01e+03 rew

agent-1: 360.0
agent-2: 355.0
agent-3: 364.0
Sum Reward: 1079.0
Avg Reward: 359.6666666666667
Min Reward: 355.0
Max Reward: 364.0
Gini Coefficient: 0.005560704355885079
20:20 Ratio: 1.0253521126760563
Max-min Ratio: 1.0253521126760563
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-47-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 1011.76
  episode_reward_min: 683.0
  episodes_this_iter: 1
  episodes_total: 267
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.651
    dispatch_time_ms: 5.681
    learner:
      cur_lr: 0.0013066533720120788
      grad_gnorm: 35.41673278808594
      policy_entropy: 13.78321647644043
      policy_loss: 6.092525959014893
      var_gnorm: 36.88855743408203
      vf_explained_var: 0.35369664430618286
      vf_loss: 6.423864364624023
    num_steps_sampled: 804000
    num_steps_trained: 804000
    wait_time_ms: 79.703
  iterations_since_restore: 268
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2302.9018399715424
  time_this_iter_s: 8.588307857513428
  time_total_s: 2302.9018399715424
  timestamp: 1594090069
  timesteps_since_restore: 804000
  timesteps_this_iter: 3000
  timesteps_total: 804000
  training_iteration: 268
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2302 s, 268 iter, 804000 ts, 1.01e+03 rew

agent-1: 357.0
agent-2: 357.0
agent-3: 411.0
Sum Reward: 1125.0
Avg Reward: 375.0
Min Reward: 357.0
Max Reward: 411.0
Gini Coefficient: 0.032
20:20 Ratio: 1.1512605042016806
Max-min Ratio: 1.1512605042016806
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-47-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 1013.06
  episode_reward_min: 683.0
  episodes_this_iter: 1
  episodes_total: 268
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.1
    dispatch_time_ms: 8.258
    learner:
      cur_lr: 0.0013064536033198237
      grad_gnorm: 39.999996185302734
      policy_entropy: 17.696044921875
      policy_loss: 13.388113975524902
      var_gnorm: 36.97422790527344
      vf_explained_var: 0.3153374195098877
      vf_loss: 13.69686508178711
    num_steps_sampled: 807000
    num_steps_trained: 807000
    wait_time_ms: 76.485
  iterations_since_restore: 269
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2311.6759889125824
  time_this_iter_s: 8.774148941040039
  time_total_s: 2311.6759889125824
  timestamp: 1594090077
  timesteps_since_restore: 807000
  timesteps_this_iter: 3000
  timesteps_total: 807000
  training_iteration: 269
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2311 s, 269 iter, 807000 ts, 1.01e+03 rew

agent-1: 370.0
agent-2: 374.0
agent-3: 365.0
Sum Reward: 1109.0
Avg Reward: 369.6666666666667
Min Reward: 365.0
Max Reward: 374.0
Gini Coefficient: 0.005410279531109108
20:20 Ratio: 1.0246575342465754
Max-min Ratio: 1.0246575342465754
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-48-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 1014.12
  episode_reward_min: 683.0
  episodes_this_iter: 1
  episodes_total: 269
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.58
    dispatch_time_ms: 5.622
    learner:
      cur_lr: 0.0013062538346275687
      grad_gnorm: 40.0
      policy_entropy: 17.623634338378906
      policy_loss: 8.212857246398926
      var_gnorm: 36.952693939208984
      vf_explained_var: -0.2134648561477661
      vf_loss: 23.421178817749023
    num_steps_sampled: 810000
    num_steps_trained: 810000
    wait_time_ms: 73.813
  iterations_since_restore: 270
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2319.851297855377
  time_this_iter_s: 8.1753089427948
  time_total_s: 2319.851297855377
  timestamp: 1594090086
  timesteps_since_restore: 810000
  timesteps_this_iter: 3000
  timesteps_total: 810000
  training_iteration: 270
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2319 s, 270 iter, 810000 ts, 1.01e+03 rew

agent-1: 373.0
agent-2: 333.0
agent-3: 342.0
Sum Reward: 1048.0
Avg Reward: 349.3333333333333
Min Reward: 333.0
Max Reward: 373.0
Gini Coefficient: 0.02544529262086514
20:20 Ratio: 1.12012012012012
Max-min Ratio: 1.12012012012012
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-48-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 1015.55
  episode_reward_min: 683.0
  episodes_this_iter: 1
  episodes_total: 270
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.865
    dispatch_time_ms: 6.383
    learner:
      cur_lr: 0.0013060539495199919
      grad_gnorm: 40.0
      policy_entropy: 20.41789436340332
      policy_loss: -11.473750114440918
      var_gnorm: 36.98313903808594
      vf_explained_var: 0.22954797744750977
      vf_loss: 10.298648834228516
    num_steps_sampled: 813000
    num_steps_trained: 813000
    wait_time_ms: 69.051
  iterations_since_restore: 271
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2328.4442319869995
  time_this_iter_s: 8.592934131622314
  time_total_s: 2328.4442319869995
  timestamp: 1594090094
  timesteps_since_restore: 813000
  timesteps_this_iter: 3000
  timesteps_total: 813000
  training_iteration: 271
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2328 s, 271 iter, 813000 ts, 1.02e+03 rew

agent-1: 367.0
agent-2: 370.0
agent-3: 330.0
Sum Reward: 1067.0
Avg Reward: 355.6666666666667
Min Reward: 330.0
Max Reward: 370.0
Gini Coefficient: 0.02499218994064355
20:20 Ratio: 1.121212121212121
Max-min Ratio: 1.121212121212121
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-48-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 1016.51
  episode_reward_min: 683.0
  episodes_this_iter: 1
  episodes_total: 271
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.005
    dispatch_time_ms: 6.535
    learner:
      cur_lr: 0.0013058541808277369
      grad_gnorm: 26.585037231445312
      policy_entropy: 20.860132217407227
      policy_loss: 3.781876564025879
      var_gnorm: 36.97520446777344
      vf_explained_var: -0.32924771308898926
      vf_loss: 10.064352035522461
    num_steps_sampled: 816000
    num_steps_trained: 816000
    wait_time_ms: 80.498
  iterations_since_restore: 272
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2337.063294649124
  time_this_iter_s: 8.619062662124634
  time_total_s: 2337.063294649124
  timestamp: 1594090103
  timesteps_since_restore: 816000
  timesteps_this_iter: 3000
  timesteps_total: 816000
  training_iteration: 272
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2337 s, 272 iter, 816000 ts, 1.02e+03 rew

agent-1: 391.0
agent-2: 379.0
agent-3: 363.0
Sum Reward: 1133.0
Avg Reward: 377.6666666666667
Min Reward: 363.0
Max Reward: 391.0
Gini Coefficient: 0.016475433951162105
20:20 Ratio: 1.0771349862258952
Max-min Ratio: 1.0771349862258952
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-48-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 1021.01
  episode_reward_min: 705.0
  episodes_this_iter: 1
  episodes_total: 272
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.98
    dispatch_time_ms: 6.009
    learner:
      cur_lr: 0.0013056544121354818
      grad_gnorm: 40.0
      policy_entropy: 22.294221878051758
      policy_loss: -20.99580192565918
      var_gnorm: 37.02206802368164
      vf_explained_var: 0.04969567060470581
      vf_loss: 37.16139602661133
    num_steps_sampled: 819000
    num_steps_trained: 819000
    wait_time_ms: 74.352
  iterations_since_restore: 273
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2345.7504971027374
  time_this_iter_s: 8.687202453613281
  time_total_s: 2345.7504971027374
  timestamp: 1594090112
  timesteps_since_restore: 819000
  timesteps_this_iter: 3000
  timesteps_total: 819000
  training_iteration: 273
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2345 s, 273 iter, 819000 ts, 1.02e+03 rew

agent-1: 387.0
agent-2: 398.0
agent-3: 353.0
Sum Reward: 1138.0
Avg Reward: 379.3333333333333
Min Reward: 353.0
Max Reward: 398.0
Gini Coefficient: 0.026362038664323375
20:20 Ratio: 1.1274787535410764
Max-min Ratio: 1.1274787535410764
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-48-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 1024.34
  episode_reward_min: 705.0
  episodes_this_iter: 1
  episodes_total: 273
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.68
    dispatch_time_ms: 6.547
    learner:
      cur_lr: 0.0013054546434432268
      grad_gnorm: 12.72833251953125
      policy_entropy: 15.225059509277344
      policy_loss: -4.262618541717529
      var_gnorm: 37.035160064697266
      vf_explained_var: 0.4873959422111511
      vf_loss: 13.713871002197266
    num_steps_sampled: 822000
    num_steps_trained: 822000
    wait_time_ms: 81.118
  iterations_since_restore: 274
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2354.4424889087677
  time_this_iter_s: 8.691991806030273
  time_total_s: 2354.4424889087677
  timestamp: 1594090120
  timesteps_since_restore: 822000
  timesteps_this_iter: 3000
  timesteps_total: 822000
  training_iteration: 274
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2354 s, 274 iter, 822000 ts, 1.02e+03 rew

agent-1: 341.0
agent-2: 395.0
agent-3: 363.0
Sum Reward: 1099.0
Avg Reward: 366.3333333333333
Min Reward: 341.0
Max Reward: 395.0
Gini Coefficient: 0.03275705186533212
20:20 Ratio: 1.1583577712609971
Max-min Ratio: 1.1583577712609971
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-48-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 1026.01
  episode_reward_min: 705.0
  episodes_this_iter: 1
  episodes_total: 274
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.832
    dispatch_time_ms: 6.435
    learner:
      cur_lr: 0.00130525475833565
      grad_gnorm: 33.679466247558594
      policy_entropy: 14.864089012145996
      policy_loss: 0.5144081115722656
      var_gnorm: 37.02296829223633
      vf_explained_var: 0.3329278230667114
      vf_loss: 39.74763488769531
    num_steps_sampled: 825000
    num_steps_trained: 825000
    wait_time_ms: 80.379
  iterations_since_restore: 275
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2363.6725311279297
  time_this_iter_s: 9.230042219161987
  time_total_s: 2363.6725311279297
  timestamp: 1594090130
  timesteps_since_restore: 825000
  timesteps_this_iter: 3000
  timesteps_total: 825000
  training_iteration: 275
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2363 s, 275 iter, 825000 ts, 1.03e+03 rew

agent-1: 344.0
agent-2: 392.0
agent-3: 312.0
Sum Reward: 1048.0
Avg Reward: 349.3333333333333
Min Reward: 312.0
Max Reward: 392.0
Gini Coefficient: 0.05089058524173028
20:20 Ratio: 1.2564102564102564
Max-min Ratio: 1.2564102564102564
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-48-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 1027.86
  episode_reward_min: 705.0
  episodes_this_iter: 1
  episodes_total: 275
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.61
    dispatch_time_ms: 6.611
    learner:
      cur_lr: 0.001305054989643395
      grad_gnorm: 21.342851638793945
      policy_entropy: 11.539002418518066
      policy_loss: -16.74632453918457
      var_gnorm: 37.09072494506836
      vf_explained_var: 0.2717044949531555
      vf_loss: 27.267396926879883
    num_steps_sampled: 828000
    num_steps_trained: 828000
    wait_time_ms: 75.851
  iterations_since_restore: 276
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2372.507065296173
  time_this_iter_s: 8.834534168243408
  time_total_s: 2372.507065296173
  timestamp: 1594090138
  timesteps_since_restore: 828000
  timesteps_this_iter: 3000
  timesteps_total: 828000
  training_iteration: 276
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2372 s, 276 iter, 828000 ts, 1.03e+03 rew

agent-1: 391.0
agent-2: 393.0
agent-3: 355.0
Sum Reward: 1139.0
Avg Reward: 379.6666666666667
Min Reward: 355.0
Max Reward: 393.0
Gini Coefficient: 0.02224173251390108
20:20 Ratio: 1.1070422535211268
Max-min Ratio: 1.1070422535211268
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-49-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 1029.3
  episode_reward_min: 705.0
  episodes_this_iter: 1
  episodes_total: 276
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.809
    dispatch_time_ms: 6.653
    learner:
      cur_lr: 0.00130485522095114
      grad_gnorm: 39.999996185302734
      policy_entropy: 14.383916854858398
      policy_loss: -8.231359481811523
      var_gnorm: 37.20077896118164
      vf_explained_var: -0.4886692762374878
      vf_loss: 15.186423301696777
    num_steps_sampled: 831000
    num_steps_trained: 831000
    wait_time_ms: 79.864
  iterations_since_restore: 277
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2381.436784505844
  time_this_iter_s: 8.92971920967102
  time_total_s: 2381.436784505844
  timestamp: 1594090147
  timesteps_since_restore: 831000
  timesteps_this_iter: 3000
  timesteps_total: 831000
  training_iteration: 277
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2381 s, 277 iter, 831000 ts, 1.03e+03 rew

agent-1: 378.0
agent-2: 312.0
agent-3: 403.0
Sum Reward: 1093.0
Avg Reward: 364.3333333333333
Min Reward: 312.0
Max Reward: 403.0
Gini Coefficient: 0.05550472705093016
20:20 Ratio: 1.2916666666666667
Max-min Ratio: 1.2916666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-49-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 1029.57
  episode_reward_min: 705.0
  episodes_this_iter: 1
  episodes_total: 277
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.812
    dispatch_time_ms: 10.478
    learner:
      cur_lr: 0.001304655452258885
      grad_gnorm: 25.960498809814453
      policy_entropy: 11.365483283996582
      policy_loss: 5.6546630859375
      var_gnorm: 37.25796127319336
      vf_explained_var: -0.3448120355606079
      vf_loss: 31.210012435913086
    num_steps_sampled: 834000
    num_steps_trained: 834000
    wait_time_ms: 78.706
  iterations_since_restore: 278
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2390.2185068130493
  time_this_iter_s: 8.7817223072052
  time_total_s: 2390.2185068130493
  timestamp: 1594090156
  timesteps_since_restore: 834000
  timesteps_this_iter: 3000
  timesteps_total: 834000
  training_iteration: 278
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2390 s, 278 iter, 834000 ts, 1.03e+03 rew

agent-1: 391.0
agent-2: 360.0
agent-3: 411.0
Sum Reward: 1162.0
Avg Reward: 387.3333333333333
Min Reward: 360.0
Max Reward: 411.0
Gini Coefficient: 0.029259896729776247
20:20 Ratio: 1.1416666666666666
Max-min Ratio: 1.1416666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-49-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 1032.31
  episode_reward_min: 705.0
  episodes_this_iter: 1
  episodes_total: 278
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.229
    dispatch_time_ms: 9.327
    learner:
      cur_lr: 0.001304455567151308
      grad_gnorm: 39.999996185302734
      policy_entropy: 21.19080352783203
      policy_loss: -10.447216987609863
      var_gnorm: 37.36720275878906
      vf_explained_var: 0.35882359743118286
      vf_loss: 14.073139190673828
    num_steps_sampled: 837000
    num_steps_trained: 837000
    wait_time_ms: 68.103
  iterations_since_restore: 279
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2399.237980365753
  time_this_iter_s: 9.019473552703857
  time_total_s: 2399.237980365753
  timestamp: 1594090165
  timesteps_since_restore: 837000
  timesteps_this_iter: 3000
  timesteps_total: 837000
  training_iteration: 279
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2399 s, 279 iter, 837000 ts, 1.03e+03 rew

agent-1: 374.0
agent-2: 376.0
agent-3: 418.0
Sum Reward: 1168.0
Avg Reward: 389.3333333333333
Min Reward: 374.0
Max Reward: 418.0
Gini Coefficient: 0.02511415525114155
20:20 Ratio: 1.1176470588235294
Max-min Ratio: 1.1176470588235294
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-49-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 1034.48
  episode_reward_min: 705.0
  episodes_this_iter: 1
  episodes_total: 279
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.245
    dispatch_time_ms: 8.631
    learner:
      cur_lr: 0.001304255798459053
      grad_gnorm: 40.0
      policy_entropy: 6.849296569824219
      policy_loss: -5.148146152496338
      var_gnorm: 37.3068962097168
      vf_explained_var: 0.5098621249198914
      vf_loss: 17.01495933532715
    num_steps_sampled: 840000
    num_steps_trained: 840000
    wait_time_ms: 77.391
  iterations_since_restore: 280
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2407.9716980457306
  time_this_iter_s: 8.733717679977417
  time_total_s: 2407.9716980457306
  timestamp: 1594090174
  timesteps_since_restore: 840000
  timesteps_this_iter: 3000
  timesteps_total: 840000
  training_iteration: 280
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2407 s, 280 iter, 840000 ts, 1.03e+03 rew

agent-1: 368.0
agent-2: 371.0
agent-3: 363.0
Sum Reward: 1102.0
Avg Reward: 367.3333333333333
Min Reward: 363.0
Max Reward: 371.0
Gini Coefficient: 0.004839685420447671
20:20 Ratio: 1.022038567493113
Max-min Ratio: 1.022038567493113
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-49-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 1036.41
  episode_reward_min: 705.0
  episodes_this_iter: 1
  episodes_total: 280
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.97
    dispatch_time_ms: 7.345
    learner:
      cur_lr: 0.001304056029766798
      grad_gnorm: 31.20726776123047
      policy_entropy: 11.396767616271973
      policy_loss: 9.162250518798828
      var_gnorm: 37.38541030883789
      vf_explained_var: -0.08613312244415283
      vf_loss: 18.276870727539062
    num_steps_sampled: 843000
    num_steps_trained: 843000
    wait_time_ms: 86.414
  iterations_since_restore: 281
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2416.9870805740356
  time_this_iter_s: 9.015382528305054
  time_total_s: 2416.9870805740356
  timestamp: 1594090183
  timesteps_since_restore: 843000
  timesteps_this_iter: 3000
  timesteps_total: 843000
  training_iteration: 281
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2416 s, 281 iter, 843000 ts, 1.04e+03 rew

agent-1: 342.0
agent-2: 359.0
agent-3: 359.0
Sum Reward: 1060.0
Avg Reward: 353.3333333333333
Min Reward: 342.0
Max Reward: 359.0
Gini Coefficient: 0.010691823899371069
20:20 Ratio: 1.0497076023391814
Max-min Ratio: 1.0497076023391814
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-49-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 1038.19
  episode_reward_min: 705.0
  episodes_this_iter: 1
  episodes_total: 281
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.293
    dispatch_time_ms: 7.081
    learner:
      cur_lr: 0.0013038561446592212
      grad_gnorm: 23.133302688598633
      policy_entropy: 14.579684257507324
      policy_loss: -5.634702205657959
      var_gnorm: 37.55400085449219
      vf_explained_var: 0.11341571807861328
      vf_loss: 21.13862419128418
    num_steps_sampled: 846000
    num_steps_trained: 846000
    wait_time_ms: 90.325
  iterations_since_restore: 282
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2426.255706548691
  time_this_iter_s: 9.268625974655151
  time_total_s: 2426.255706548691
  timestamp: 1594090192
  timesteps_since_restore: 846000
  timesteps_this_iter: 3000
  timesteps_total: 846000
  training_iteration: 282
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2426 s, 282 iter, 846000 ts, 1.04e+03 rew

agent-1: 382.0
agent-2: 337.0
agent-3: 349.0
Sum Reward: 1068.0
Avg Reward: 356.0
Min Reward: 337.0
Max Reward: 382.0
Gini Coefficient: 0.028089887640449437
20:20 Ratio: 1.1335311572700297
Max-min Ratio: 1.1335311572700297
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-50-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 1040.22
  episode_reward_min: 705.0
  episodes_this_iter: 1
  episodes_total: 282
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.663
    dispatch_time_ms: 8.363
    learner:
      cur_lr: 0.0013036563759669662
      grad_gnorm: 34.17821502685547
      policy_entropy: 12.58195686340332
      policy_loss: -5.05247688293457
      var_gnorm: 37.61477279663086
      vf_explained_var: -0.0010944604873657227
      vf_loss: 25.266353607177734
    num_steps_sampled: 849000
    num_steps_trained: 849000
    wait_time_ms: 83.337
  iterations_since_restore: 283
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2435.7322895526886
  time_this_iter_s: 9.476583003997803
  time_total_s: 2435.7322895526886
  timestamp: 1594090202
  timesteps_since_restore: 849000
  timesteps_this_iter: 3000
  timesteps_total: 849000
  training_iteration: 283
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2435 s, 283 iter, 849000 ts, 1.04e+03 rew

agent-1: 418.0
agent-2: 354.0
agent-3: 368.0
Sum Reward: 1140.0
Avg Reward: 380.0
Min Reward: 354.0
Max Reward: 418.0
Gini Coefficient: 0.03742690058479532
20:20 Ratio: 1.1807909604519775
Max-min Ratio: 1.1807909604519775
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-50-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 1043.88
  episode_reward_min: 705.0
  episodes_this_iter: 1
  episodes_total: 283
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.488
    dispatch_time_ms: 8.794
    learner:
      cur_lr: 0.0013034566072747111
      grad_gnorm: 39.999996185302734
      policy_entropy: 11.094648361206055
      policy_loss: 5.143144607543945
      var_gnorm: 37.72718811035156
      vf_explained_var: 0.4273277521133423
      vf_loss: 13.434690475463867
    num_steps_sampled: 852000
    num_steps_trained: 852000
    wait_time_ms: 72.16
  iterations_since_restore: 284
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2444.36354470253
  time_this_iter_s: 8.631255149841309
  time_total_s: 2444.36354470253
  timestamp: 1594090211
  timesteps_since_restore: 852000
  timesteps_this_iter: 3000
  timesteps_total: 852000
  training_iteration: 284
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2444 s, 284 iter, 852000 ts, 1.04e+03 rew

agent-1: 378.0
agent-2: 385.0
agent-3: 391.0
Sum Reward: 1154.0
Avg Reward: 384.6666666666667
Min Reward: 378.0
Max Reward: 391.0
Gini Coefficient: 0.007510109763142692
20:20 Ratio: 1.0343915343915344
Max-min Ratio: 1.0343915343915344
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-50-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 1047.61
  episode_reward_min: 705.0
  episodes_this_iter: 1
  episodes_total: 284
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.977
    dispatch_time_ms: 8.061
    learner:
      cur_lr: 0.0013032568385824561
      grad_gnorm: 40.0
      policy_entropy: 12.849618911743164
      policy_loss: 16.513296127319336
      var_gnorm: 37.77091979980469
      vf_explained_var: -0.28112995624542236
      vf_loss: 28.270973205566406
    num_steps_sampled: 855000
    num_steps_trained: 855000
    wait_time_ms: 74.552
  iterations_since_restore: 285
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2452.9650242328644
  time_this_iter_s: 8.601479530334473
  time_total_s: 2452.9650242328644
  timestamp: 1594090219
  timesteps_since_restore: 855000
  timesteps_this_iter: 3000
  timesteps_total: 855000
  training_iteration: 285
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2452 s, 285 iter, 855000 ts, 1.05e+03 rew

agent-1: 406.0
agent-2: 364.0
agent-3: 374.0
Sum Reward: 1144.0
Avg Reward: 381.3333333333333
Min Reward: 364.0
Max Reward: 406.0
Gini Coefficient: 0.024475524475524476
20:20 Ratio: 1.1153846153846154
Max-min Ratio: 1.1153846153846154
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-50-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 1049.95
  episode_reward_min: 705.0
  episodes_this_iter: 1
  episodes_total: 285
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.677
    dispatch_time_ms: 10.098
    learner:
      cur_lr: 0.0013030569534748793
      grad_gnorm: 40.000003814697266
      policy_entropy: 15.039111137390137
      policy_loss: -32.063446044921875
      var_gnorm: 37.82054138183594
      vf_explained_var: -1.0
      vf_loss: 46.90813064575195
    num_steps_sampled: 858000
    num_steps_trained: 858000
    wait_time_ms: 76.407
  iterations_since_restore: 286
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2461.8028259277344
  time_this_iter_s: 8.837801694869995
  time_total_s: 2461.8028259277344
  timestamp: 1594090228
  timesteps_since_restore: 858000
  timesteps_this_iter: 3000
  timesteps_total: 858000
  training_iteration: 286
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2461 s, 286 iter, 858000 ts, 1.05e+03 rew

agent-1: 372.0
agent-2: 416.0
agent-3: 407.0
Sum Reward: 1195.0
Avg Reward: 398.3333333333333
Min Reward: 372.0
Max Reward: 416.0
Gini Coefficient: 0.024546722454672244
20:20 Ratio: 1.118279569892473
Max-min Ratio: 1.118279569892473
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-50-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 1053.43
  episode_reward_min: 705.0
  episodes_this_iter: 1
  episodes_total: 286
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.587
    dispatch_time_ms: 5.245
    learner:
      cur_lr: 0.0013028571847826242
      grad_gnorm: 40.0
      policy_entropy: 13.886398315429688
      policy_loss: 6.463539123535156
      var_gnorm: 37.87129592895508
      vf_explained_var: 0.06502461433410645
      vf_loss: 14.828924179077148
    num_steps_sampled: 861000
    num_steps_trained: 861000
    wait_time_ms: 77.15
  iterations_since_restore: 287
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2470.9348361492157
  time_this_iter_s: 9.132010221481323
  time_total_s: 2470.9348361492157
  timestamp: 1594090237
  timesteps_since_restore: 861000
  timesteps_this_iter: 3000
  timesteps_total: 861000
  training_iteration: 287
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2470 s, 287 iter, 861000 ts, 1.05e+03 rew

agent-1: 398.0
agent-2: 399.0
agent-3: 355.0
Sum Reward: 1152.0
Avg Reward: 384.0
Min Reward: 355.0
Max Reward: 399.0
Gini Coefficient: 0.02546296296296296
20:20 Ratio: 1.123943661971831
Max-min Ratio: 1.123943661971831
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-50-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 1055.65
  episode_reward_min: 705.0
  episodes_this_iter: 1
  episodes_total: 287
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.71
    dispatch_time_ms: 6.35
    learner:
      cur_lr: 0.0013026574160903692
      grad_gnorm: 36.9481315612793
      policy_entropy: 11.551947593688965
      policy_loss: 0.3416292667388916
      var_gnorm: 37.933231353759766
      vf_explained_var: 0.27854305505752563
      vf_loss: 27.478355407714844
    num_steps_sampled: 864000
    num_steps_trained: 864000
    wait_time_ms: 83.583
  iterations_since_restore: 288
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2479.7354238033295
  time_this_iter_s: 8.80058765411377
  time_total_s: 2479.7354238033295
  timestamp: 1594090246
  timesteps_since_restore: 864000
  timesteps_this_iter: 3000
  timesteps_total: 864000
  training_iteration: 288
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2479 s, 288 iter, 864000 ts, 1.06e+03 rew

agent-1: 381.0
agent-2: 386.0
agent-3: 420.0
Sum Reward: 1187.0
Avg Reward: 395.6666666666667
Min Reward: 381.0
Max Reward: 420.0
Gini Coefficient: 0.02190395956192081
20:20 Ratio: 1.1023622047244095
Max-min Ratio: 1.1023622047244095
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-50-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 1058.58
  episode_reward_min: 705.0
  episodes_this_iter: 1
  episodes_total: 288
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.523
    dispatch_time_ms: 5.125
    learner:
      cur_lr: 0.0013024576473981142
      grad_gnorm: 40.0
      policy_entropy: 13.781047821044922
      policy_loss: -2.8272409439086914
      var_gnorm: 38.00057601928711
      vf_explained_var: 0.2583090662956238
      vf_loss: 8.794758796691895
    num_steps_sampled: 867000
    num_steps_trained: 867000
    wait_time_ms: 74.701
  iterations_since_restore: 289
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2488.413972377777
  time_this_iter_s: 8.678548574447632
  time_total_s: 2488.413972377777
  timestamp: 1594090255
  timesteps_since_restore: 867000
  timesteps_this_iter: 3000
  timesteps_total: 867000
  training_iteration: 289
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2488 s, 289 iter, 867000 ts, 1.06e+03 rew

agent-1: 379.0
agent-2: 374.0
agent-3: 390.0
Sum Reward: 1143.0
Avg Reward: 381.0
Min Reward: 374.0
Max Reward: 390.0
Gini Coefficient: 0.009332166812481774
20:20 Ratio: 1.0427807486631016
Max-min Ratio: 1.0427807486631016
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-51-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 1060.81
  episode_reward_min: 705.0
  episodes_this_iter: 1
  episodes_total: 289
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.057
    dispatch_time_ms: 7.955
    learner:
      cur_lr: 0.0013022577622905374
      grad_gnorm: 40.0
      policy_entropy: 12.24815559387207
      policy_loss: 4.601015090942383
      var_gnorm: 38.0112419128418
      vf_explained_var: -0.4278908967971802
      vf_loss: 14.793784141540527
    num_steps_sampled: 870000
    num_steps_trained: 870000
    wait_time_ms: 73.534
  iterations_since_restore: 290
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2497.1222021579742
  time_this_iter_s: 8.708229780197144
  time_total_s: 2497.1222021579742
  timestamp: 1594090263
  timesteps_since_restore: 870000
  timesteps_this_iter: 3000
  timesteps_total: 870000
  training_iteration: 290
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2497 s, 290 iter, 870000 ts, 1.06e+03 rew

agent-1: 393.0
agent-2: 420.0
agent-3: 345.0
Sum Reward: 1158.0
Avg Reward: 386.0
Min Reward: 345.0
Max Reward: 420.0
Gini Coefficient: 0.04317789291882556
20:20 Ratio: 1.2173913043478262
Max-min Ratio: 1.2173913043478262
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-51-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 1063.93
  episode_reward_min: 705.0
  episodes_this_iter: 1
  episodes_total: 290
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.367
    dispatch_time_ms: 5.235
    learner:
      cur_lr: 0.0013020579935982823
      grad_gnorm: 40.000003814697266
      policy_entropy: 13.461591720581055
      policy_loss: 22.706626892089844
      var_gnorm: 38.122928619384766
      vf_explained_var: -0.18682968616485596
      vf_loss: 43.548728942871094
    num_steps_sampled: 873000
    num_steps_trained: 873000
    wait_time_ms: 78.479
  iterations_since_restore: 291
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2505.942194700241
  time_this_iter_s: 8.819992542266846
  time_total_s: 2505.942194700241
  timestamp: 1594090272
  timesteps_since_restore: 873000
  timesteps_this_iter: 3000
  timesteps_total: 873000
  training_iteration: 291
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2505 s, 291 iter, 873000 ts, 1.06e+03 rew

agent-1: 339.0
agent-2: 373.0
agent-3: 381.0
Sum Reward: 1093.0
Avg Reward: 364.3333333333333
Min Reward: 339.0
Max Reward: 381.0
Gini Coefficient: 0.025617566331198535
20:20 Ratio: 1.1238938053097345
Max-min Ratio: 1.1238938053097345
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-51-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 1066.88
  episode_reward_min: 705.0
  episodes_this_iter: 1
  episodes_total: 291
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.61
    dispatch_time_ms: 8.614
    learner:
      cur_lr: 0.0013018582249060273
      grad_gnorm: 10.285293579101562
      policy_entropy: 14.102418899536133
      policy_loss: 2.2116081714630127
      var_gnorm: 38.126800537109375
      vf_explained_var: 0.46582889556884766
      vf_loss: 17.94894790649414
    num_steps_sampled: 876000
    num_steps_trained: 876000
    wait_time_ms: 73.233
  iterations_since_restore: 292
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2514.2904081344604
  time_this_iter_s: 8.34821343421936
  time_total_s: 2514.2904081344604
  timestamp: 1594090281
  timesteps_since_restore: 876000
  timesteps_this_iter: 3000
  timesteps_total: 876000
  training_iteration: 292
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2514 s, 292 iter, 876000 ts, 1.07e+03 rew

agent-1: 335.0
agent-2: 368.0
agent-3: 353.0
Sum Reward: 1056.0
Avg Reward: 352.0
Min Reward: 335.0
Max Reward: 368.0
Gini Coefficient: 0.020833333333333332
20:20 Ratio: 1.0985074626865672
Max-min Ratio: 1.0985074626865672
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-51-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 1067.12
  episode_reward_min: 705.0
  episodes_this_iter: 1
  episodes_total: 292
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.509
    dispatch_time_ms: 6.768
    learner:
      cur_lr: 0.0013016584562137723
      grad_gnorm: 40.0
      policy_entropy: 14.493108749389648
      policy_loss: 22.535018920898438
      var_gnorm: 38.12785339355469
      vf_explained_var: -0.24138569831848145
      vf_loss: 54.067604064941406
    num_steps_sampled: 879000
    num_steps_trained: 879000
    wait_time_ms: 66.318
  iterations_since_restore: 293
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2522.715929746628
  time_this_iter_s: 8.425521612167358
  time_total_s: 2522.715929746628
  timestamp: 1594090289
  timesteps_since_restore: 879000
  timesteps_this_iter: 3000
  timesteps_total: 879000
  training_iteration: 293
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2522 s, 293 iter, 879000 ts, 1.07e+03 rew

agent-1: 334.0
agent-2: 348.0
agent-3: 341.0
Sum Reward: 1023.0
Avg Reward: 341.0
Min Reward: 334.0
Max Reward: 348.0
Gini Coefficient: 0.009123492994460736
20:20 Ratio: 1.0419161676646707
Max-min Ratio: 1.0419161676646707
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-51-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 1067.61
  episode_reward_min: 705.0
  episodes_this_iter: 1
  episodes_total: 293
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.735
    dispatch_time_ms: 5.416
    learner:
      cur_lr: 0.0013014585711061954
      grad_gnorm: 40.0
      policy_entropy: 15.598333358764648
      policy_loss: -8.920440673828125
      var_gnorm: 38.16549301147461
      vf_explained_var: 0.5447565317153931
      vf_loss: 28.048154830932617
    num_steps_sampled: 882000
    num_steps_trained: 882000
    wait_time_ms: 82.146
  iterations_since_restore: 294
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2531.2117626667023
  time_this_iter_s: 8.495832920074463
  time_total_s: 2531.2117626667023
  timestamp: 1594090298
  timesteps_since_restore: 882000
  timesteps_this_iter: 3000
  timesteps_total: 882000
  training_iteration: 294
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2531 s, 294 iter, 882000 ts, 1.07e+03 rew

agent-1: 260.0
agent-2: 340.0
agent-3: 358.0
Sum Reward: 958.0
Avg Reward: 319.3333333333333
Min Reward: 260.0
Max Reward: 358.0
Gini Coefficient: 0.06819763395963814
20:20 Ratio: 1.376923076923077
Max-min Ratio: 1.376923076923077
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-51-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 1067.49
  episode_reward_min: 705.0
  episodes_this_iter: 1
  episodes_total: 294
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.509
    dispatch_time_ms: 6.664
    learner:
      cur_lr: 0.0013012588024139404
      grad_gnorm: 39.999996185302734
      policy_entropy: 13.095427513122559
      policy_loss: -16.262571334838867
      var_gnorm: 38.25229263305664
      vf_explained_var: 0.01376950740814209
      vf_loss: 45.4449462890625
    num_steps_sampled: 885000
    num_steps_trained: 885000
    wait_time_ms: 80.62
  iterations_since_restore: 295
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2539.951861858368
  time_this_iter_s: 8.74009919166565
  time_total_s: 2539.951861858368
  timestamp: 1594090306
  timesteps_since_restore: 885000
  timesteps_this_iter: 3000
  timesteps_total: 885000
  training_iteration: 295
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2539 s, 295 iter, 885000 ts, 1.07e+03 rew

agent-1: 335.0
agent-2: 319.0
agent-3: 338.0
Sum Reward: 992.0
Avg Reward: 330.6666666666667
Min Reward: 319.0
Max Reward: 338.0
Gini Coefficient: 0.012768817204301076
20:20 Ratio: 1.0595611285266457
Max-min Ratio: 1.0595611285266457
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-51-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 1068.33
  episode_reward_min: 705.0
  episodes_this_iter: 1
  episodes_total: 295
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.816
    dispatch_time_ms: 8.802
    learner:
      cur_lr: 0.0013010590337216854
      grad_gnorm: 40.0
      policy_entropy: 15.075296401977539
      policy_loss: -7.215392589569092
      var_gnorm: 38.23860168457031
      vf_explained_var: -0.01120758056640625
      vf_loss: 11.860953330993652
    num_steps_sampled: 888000
    num_steps_trained: 888000
    wait_time_ms: 67.972
  iterations_since_restore: 296
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2548.143593788147
  time_this_iter_s: 8.191731929779053
  time_total_s: 2548.143593788147
  timestamp: 1594090315
  timesteps_since_restore: 888000
  timesteps_this_iter: 3000
  timesteps_total: 888000
  training_iteration: 296
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2548 s, 296 iter, 888000 ts, 1.07e+03 rew

agent-1: 329.0
agent-2: 336.0
agent-3: 334.0
Sum Reward: 999.0
Avg Reward: 333.0
Min Reward: 329.0
Max Reward: 336.0
Gini Coefficient: 0.004671338004671338
20:20 Ratio: 1.0212765957446808
Max-min Ratio: 1.0212765957446808
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-52-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 1068.09
  episode_reward_min: 705.0
  episodes_this_iter: 1
  episodes_total: 296
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.449
    dispatch_time_ms: 6.295
    learner:
      cur_lr: 0.0013008591486141086
      grad_gnorm: 13.3086576461792
      policy_entropy: 15.136783599853516
      policy_loss: 2.640630006790161
      var_gnorm: 38.21229934692383
      vf_explained_var: 0.028738081455230713
      vf_loss: 40.522666931152344
    num_steps_sampled: 891000
    num_steps_trained: 891000
    wait_time_ms: 81.989
  iterations_since_restore: 297
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2556.68012714386
  time_this_iter_s: 8.53653335571289
  time_total_s: 2556.68012714386
  timestamp: 1594090323
  timesteps_since_restore: 891000
  timesteps_this_iter: 3000
  timesteps_total: 891000
  training_iteration: 297
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2556 s, 297 iter, 891000 ts, 1.07e+03 rew

agent-1: 376.0
agent-2: 368.0
agent-3: 330.0
Sum Reward: 1074.0
Avg Reward: 358.0
Min Reward: 330.0
Max Reward: 376.0
Gini Coefficient: 0.028553693358162633
20:20 Ratio: 1.1393939393939394
Max-min Ratio: 1.1393939393939394
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-52-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1208.0
  episode_reward_mean: 1069.02
  episode_reward_min: 705.0
  episodes_this_iter: 1
  episodes_total: 297
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.833
    dispatch_time_ms: 9.108
    learner:
      cur_lr: 0.0013006593799218535
      grad_gnorm: 29.13116455078125
      policy_entropy: 8.724481582641602
      policy_loss: -8.345664024353027
      var_gnorm: 38.256473541259766
      vf_explained_var: 0.3050990700721741
      vf_loss: 38.16665267944336
    num_steps_sampled: 894000
    num_steps_trained: 894000
    wait_time_ms: 74.647
  iterations_since_restore: 298
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2565.313836336136
  time_this_iter_s: 8.633709192276001
  time_total_s: 2565.313836336136
  timestamp: 1594090332
  timesteps_since_restore: 894000
  timesteps_this_iter: 3000
  timesteps_total: 894000
  training_iteration: 298
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2565 s, 298 iter, 894000 ts, 1.07e+03 rew

agent-1: 415.0
agent-2: 387.0
agent-3: 411.0
Sum Reward: 1213.0
Avg Reward: 404.3333333333333
Min Reward: 387.0
Max Reward: 415.0
Gini Coefficient: 0.01538884308876065
20:20 Ratio: 1.0723514211886305
Max-min Ratio: 1.0723514211886305
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-52-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.0
  episode_reward_mean: 1070.84
  episode_reward_min: 705.0
  episodes_this_iter: 1
  episodes_total: 298
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.207
    dispatch_time_ms: 9.278
    learner:
      cur_lr: 0.0013004596112295985
      grad_gnorm: 17.172950744628906
      policy_entropy: 9.491402626037598
      policy_loss: -12.796586990356445
      var_gnorm: 38.36716079711914
      vf_explained_var: 0.0951383113861084
      vf_loss: 25.968351364135742
    num_steps_sampled: 897000
    num_steps_trained: 897000
    wait_time_ms: 77.136
  iterations_since_restore: 299
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2574.2278978824615
  time_this_iter_s: 8.914061546325684
  time_total_s: 2574.2278978824615
  timestamp: 1594090341
  timesteps_since_restore: 897000
  timesteps_this_iter: 3000
  timesteps_total: 897000
  training_iteration: 299
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2574 s, 299 iter, 897000 ts, 1.07e+03 rew

agent-1: 403.0
agent-2: 383.0
agent-3: 412.0
Sum Reward: 1198.0
Avg Reward: 399.3333333333333
Min Reward: 383.0
Max Reward: 412.0
Gini Coefficient: 0.016138007790762382
20:20 Ratio: 1.0757180156657964
Max-min Ratio: 1.0757180156657964
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-52-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.0
  episode_reward_mean: 1073.02
  episode_reward_min: 705.0
  episodes_this_iter: 1
  episodes_total: 299
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.347
    dispatch_time_ms: 9.511
    learner:
      cur_lr: 0.0013002598425373435
      grad_gnorm: 26.53384780883789
      policy_entropy: 9.042316436767578
      policy_loss: -7.615815162658691
      var_gnorm: 38.40418243408203
      vf_explained_var: -0.3454490900039673
      vf_loss: 10.43636417388916
    num_steps_sampled: 900000
    num_steps_trained: 900000
    wait_time_ms: 78.654
  iterations_since_restore: 300
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2583.0166714191437
  time_this_iter_s: 8.788773536682129
  time_total_s: 2583.0166714191437
  timestamp: 1594090350
  timesteps_since_restore: 900000
  timesteps_this_iter: 3000
  timesteps_total: 900000
  training_iteration: 300
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2583 s, 300 iter, 900000 ts, 1.07e+03 rew

agent-1: 410.0
agent-2: 382.0
agent-3: 408.0
Sum Reward: 1200.0
Avg Reward: 400.0
Min Reward: 382.0
Max Reward: 410.0
Gini Coefficient: 0.015555555555555555
20:20 Ratio: 1.0732984293193717
Max-min Ratio: 1.0732984293193717
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-52-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.0
  episode_reward_mean: 1074.44
  episode_reward_min: 705.0
  episodes_this_iter: 1
  episodes_total: 300
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.546
    dispatch_time_ms: 7.431
    learner:
      cur_lr: 0.0013000599574297667
      grad_gnorm: 40.0
      policy_entropy: 9.455034255981445
      policy_loss: 16.596445083618164
      var_gnorm: 38.445556640625
      vf_explained_var: -0.39010417461395264
      vf_loss: 63.72574996948242
    num_steps_sampled: 903000
    num_steps_trained: 903000
    wait_time_ms: 79.608
  iterations_since_restore: 301
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2591.961575269699
  time_this_iter_s: 8.94490385055542
  time_total_s: 2591.961575269699
  timestamp: 1594090359
  timesteps_since_restore: 903000
  timesteps_this_iter: 3000
  timesteps_total: 903000
  training_iteration: 301
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2591 s, 301 iter, 903000 ts, 1.07e+03 rew

agent-1: 407.0
agent-2: 409.0
agent-3: 430.0
Sum Reward: 1246.0
Avg Reward: 415.3333333333333
Min Reward: 407.0
Max Reward: 430.0
Gini Coefficient: 0.012306046013911182
20:20 Ratio: 1.0565110565110565
Max-min Ratio: 1.0565110565110565
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-52-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1076.77
  episode_reward_min: 705.0
  episodes_this_iter: 1
  episodes_total: 301
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.951
    dispatch_time_ms: 9.341
    learner:
      cur_lr: 0.0012998601887375116
      grad_gnorm: 39.999996185302734
      policy_entropy: 9.777353286743164
      policy_loss: -12.488434791564941
      var_gnorm: 38.49921798706055
      vf_explained_var: -0.13056731224060059
      vf_loss: 33.29741668701172
    num_steps_sampled: 906000
    num_steps_trained: 906000
    wait_time_ms: 78.931
  iterations_since_restore: 302
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2601.0558462142944
  time_this_iter_s: 9.094270944595337
  time_total_s: 2601.0558462142944
  timestamp: 1594090368
  timesteps_since_restore: 906000
  timesteps_this_iter: 3000
  timesteps_total: 906000
  training_iteration: 302
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2601 s, 302 iter, 906000 ts, 1.08e+03 rew

agent-1: 382.0
agent-2: 397.0
agent-3: 456.0
Sum Reward: 1235.0
Avg Reward: 411.6666666666667
Min Reward: 382.0
Max Reward: 456.0
Gini Coefficient: 0.039946018893387315
20:20 Ratio: 1.193717277486911
Max-min Ratio: 1.193717277486911
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-52-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1079.19
  episode_reward_min: 705.0
  episodes_this_iter: 1
  episodes_total: 302
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 4.283
    dispatch_time_ms: 6.901
    learner:
      cur_lr: 0.0012996604200452566
      grad_gnorm: 39.999996185302734
      policy_entropy: 7.257382392883301
      policy_loss: -5.456976413726807
      var_gnorm: 38.562416076660156
      vf_explained_var: 0.15344542264938354
      vf_loss: 15.665216445922852
    num_steps_sampled: 909000
    num_steps_trained: 909000
    wait_time_ms: 77.347
  iterations_since_restore: 303
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2610.064112186432
  time_this_iter_s: 9.008265972137451
  time_total_s: 2610.064112186432
  timestamp: 1594090377
  timesteps_since_restore: 909000
  timesteps_this_iter: 3000
  timesteps_total: 909000
  training_iteration: 303
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2610 s, 303 iter, 909000 ts, 1.08e+03 rew

agent-1: 398.0
agent-2: 367.0
agent-3: 382.0
Sum Reward: 1147.0
Avg Reward: 382.3333333333333
Min Reward: 367.0
Max Reward: 398.0
Gini Coefficient: 0.018018018018018018
20:20 Ratio: 1.0844686648501363
Max-min Ratio: 1.0844686648501363
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-53-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1080.59
  episode_reward_min: 705.0
  episodes_this_iter: 1
  episodes_total: 303
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.111
    dispatch_time_ms: 9.685
    learner:
      cur_lr: 0.0012994606513530016
      grad_gnorm: 30.714340209960938
      policy_entropy: 8.995688438415527
      policy_loss: -6.668743133544922
      var_gnorm: 38.624752044677734
      vf_explained_var: -0.10609304904937744
      vf_loss: 16.89331817626953
    num_steps_sampled: 912000
    num_steps_trained: 912000
    wait_time_ms: 74.901
  iterations_since_restore: 304
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2618.759578704834
  time_this_iter_s: 8.6954665184021
  time_total_s: 2618.759578704834
  timestamp: 1594090386
  timesteps_since_restore: 912000
  timesteps_this_iter: 3000
  timesteps_total: 912000
  training_iteration: 304
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2618 s, 304 iter, 912000 ts, 1.08e+03 rew

agent-1: 352.0
agent-2: 357.0
agent-3: 370.0
Sum Reward: 1079.0
Avg Reward: 359.6666666666667
Min Reward: 352.0
Max Reward: 370.0
Gini Coefficient: 0.011121408711770158
20:20 Ratio: 1.0511363636363635
Max-min Ratio: 1.0511363636363635
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-53-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1081.56
  episode_reward_min: 705.0
  episodes_this_iter: 1
  episodes_total: 304
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.885
    dispatch_time_ms: 6.835
    learner:
      cur_lr: 0.0012992607662454247
      grad_gnorm: 35.03508758544922
      policy_entropy: 10.356722831726074
      policy_loss: -2.3783769607543945
      var_gnorm: 38.65055847167969
      vf_explained_var: 0.058498919010162354
      vf_loss: 16.157133102416992
    num_steps_sampled: 915000
    num_steps_trained: 915000
    wait_time_ms: 77.012
  iterations_since_restore: 305
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2627.232379436493
  time_this_iter_s: 8.472800731658936
  time_total_s: 2627.232379436493
  timestamp: 1594090394
  timesteps_since_restore: 915000
  timesteps_this_iter: 3000
  timesteps_total: 915000
  training_iteration: 305
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2627 s, 305 iter, 915000 ts, 1.08e+03 rew

agent-1: 337.0
agent-2: 372.0
agent-3: 347.0
Sum Reward: 1056.0
Avg Reward: 352.0
Min Reward: 337.0
Max Reward: 372.0
Gini Coefficient: 0.022095959595959596
20:20 Ratio: 1.1038575667655786
Max-min Ratio: 1.1038575667655786
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-53-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1082.74
  episode_reward_min: 705.0
  episodes_this_iter: 1
  episodes_total: 305
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.575
    dispatch_time_ms: 6.846
    learner:
      cur_lr: 0.0012990609975531697
      grad_gnorm: 27.18060874938965
      policy_entropy: 10.940485954284668
      policy_loss: 0.6163883209228516
      var_gnorm: 38.629371643066406
      vf_explained_var: 0.3010348677635193
      vf_loss: 17.18737030029297
    num_steps_sampled: 918000
    num_steps_trained: 918000
    wait_time_ms: 71.758
  iterations_since_restore: 306
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2635.7703557014465
  time_this_iter_s: 8.537976264953613
  time_total_s: 2635.7703557014465
  timestamp: 1594090403
  timesteps_since_restore: 918000
  timesteps_this_iter: 3000
  timesteps_total: 918000
  training_iteration: 306
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2635 s, 306 iter, 918000 ts, 1.08e+03 rew

agent-1: 353.0
agent-2: 353.0
agent-3: 339.0
Sum Reward: 1045.0
Avg Reward: 348.3333333333333
Min Reward: 339.0
Max Reward: 353.0
Gini Coefficient: 0.008931419457735247
20:20 Ratio: 1.0412979351032448
Max-min Ratio: 1.0412979351032448
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-53-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1084.21
  episode_reward_min: 705.0
  episodes_this_iter: 1
  episodes_total: 306
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.909
    dispatch_time_ms: 7.042
    learner:
      cur_lr: 0.0012988612288609147
      grad_gnorm: 40.0
      policy_entropy: 19.455970764160156
      policy_loss: -3.0702733993530273
      var_gnorm: 38.69432830810547
      vf_explained_var: 0.23499202728271484
      vf_loss: 20.077367782592773
    num_steps_sampled: 921000
    num_steps_trained: 921000
    wait_time_ms: 80.051
  iterations_since_restore: 307
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2644.400674343109
  time_this_iter_s: 8.630318641662598
  time_total_s: 2644.400674343109
  timestamp: 1594090411
  timesteps_since_restore: 921000
  timesteps_this_iter: 3000
  timesteps_total: 921000
  training_iteration: 307
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2644 s, 307 iter, 921000 ts, 1.08e+03 rew

agent-1: 341.0
agent-2: 364.0
agent-3: 329.0
Sum Reward: 1034.0
Avg Reward: 344.6666666666667
Min Reward: 329.0
Max Reward: 364.0
Gini Coefficient: 0.02256608639587363
20:20 Ratio: 1.1063829787234043
Max-min Ratio: 1.1063829787234043
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-53-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1084.75
  episode_reward_min: 705.0
  episodes_this_iter: 1
  episodes_total: 307
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.003
    dispatch_time_ms: 5.745
    learner:
      cur_lr: 0.0012986613437533379
      grad_gnorm: 40.0
      policy_entropy: 13.630131721496582
      policy_loss: -9.764504432678223
      var_gnorm: 38.725765228271484
      vf_explained_var: 0.33368200063705444
      vf_loss: 15.808749198913574
    num_steps_sampled: 924000
    num_steps_trained: 924000
    wait_time_ms: 72.113
  iterations_since_restore: 308
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2652.960521697998
  time_this_iter_s: 8.559847354888916
  time_total_s: 2652.960521697998
  timestamp: 1594090420
  timesteps_since_restore: 924000
  timesteps_this_iter: 3000
  timesteps_total: 924000
  training_iteration: 308
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2652 s, 308 iter, 924000 ts, 1.08e+03 rew

agent-1: 351.0
agent-2: 347.0
agent-3: 341.0
Sum Reward: 1039.0
Avg Reward: 346.3333333333333
Min Reward: 341.0
Max Reward: 351.0
Gini Coefficient: 0.006416426050689766
20:20 Ratio: 1.029325513196481
Max-min Ratio: 1.029325513196481
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-53-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1086.29
  episode_reward_min: 705.0
  episodes_this_iter: 1
  episodes_total: 308
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.546
    dispatch_time_ms: 6.204
    learner:
      cur_lr: 0.0012984615750610828
      grad_gnorm: 40.0
      policy_entropy: 17.299259185791016
      policy_loss: -25.079832077026367
      var_gnorm: 38.8072509765625
      vf_explained_var: -0.08431220054626465
      vf_loss: 35.01005172729492
    num_steps_sampled: 927000
    num_steps_trained: 927000
    wait_time_ms: 80.865
  iterations_since_restore: 309
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2661.4733765125275
  time_this_iter_s: 8.512854814529419
  time_total_s: 2661.4733765125275
  timestamp: 1594090428
  timesteps_since_restore: 927000
  timesteps_this_iter: 3000
  timesteps_total: 927000
  training_iteration: 309
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2661 s, 309 iter, 927000 ts, 1.09e+03 rew

agent-1: 328.0
agent-2: 360.0
agent-3: 366.0
Sum Reward: 1054.0
Avg Reward: 351.3333333333333
Min Reward: 328.0
Max Reward: 366.0
Gini Coefficient: 0.02403542061986085
20:20 Ratio: 1.1158536585365855
Max-min Ratio: 1.1158536585365855
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-53-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1088.0
  episode_reward_min: 705.0
  episodes_this_iter: 1
  episodes_total: 309
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.603
    dispatch_time_ms: 5.856
    learner:
      cur_lr: 0.0012982618063688278
      grad_gnorm: 12.768745422363281
      policy_entropy: 16.51044464111328
      policy_loss: -1.1480547189712524
      var_gnorm: 38.816627502441406
      vf_explained_var: -0.5150307416915894
      vf_loss: 8.350820541381836
    num_steps_sampled: 930000
    num_steps_trained: 930000
    wait_time_ms: 70.123
  iterations_since_restore: 310
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2669.907905101776
  time_this_iter_s: 8.434528589248657
  time_total_s: 2669.907905101776
  timestamp: 1594090437
  timesteps_since_restore: 930000
  timesteps_this_iter: 3000
  timesteps_total: 930000
  training_iteration: 310
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2669 s, 310 iter, 930000 ts, 1.09e+03 rew

agent-1: 330.0
agent-2: 377.0
agent-3: 363.0
Sum Reward: 1070.0
Avg Reward: 356.6666666666667
Min Reward: 330.0
Max Reward: 377.0
Gini Coefficient: 0.029283489096573207
20:20 Ratio: 1.1424242424242423
Max-min Ratio: 1.1424242424242423
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-54-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1087.56
  episode_reward_min: 705.0
  episodes_this_iter: 1
  episodes_total: 310
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.507
    dispatch_time_ms: 7.457
    learner:
      cur_lr: 0.0012980620376765728
      grad_gnorm: 40.0
      policy_entropy: 8.774754524230957
      policy_loss: -14.302894592285156
      var_gnorm: 38.91326141357422
      vf_explained_var: -0.5896158218383789
      vf_loss: 35.221046447753906
    num_steps_sampled: 933000
    num_steps_trained: 933000
    wait_time_ms: 82.347
  iterations_since_restore: 311
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2678.585818529129
  time_this_iter_s: 8.677913427352905
  time_total_s: 2678.585818529129
  timestamp: 1594090446
  timesteps_since_restore: 933000
  timesteps_this_iter: 3000
  timesteps_total: 933000
  training_iteration: 311
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2678 s, 311 iter, 933000 ts, 1.09e+03 rew

agent-1: 371.0
agent-2: 390.0
agent-3: 364.0
Sum Reward: 1125.0
Avg Reward: 375.0
Min Reward: 364.0
Max Reward: 390.0
Gini Coefficient: 0.015407407407407408
20:20 Ratio: 1.0714285714285714
Max-min Ratio: 1.0714285714285714
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-54-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1088.19
  episode_reward_min: 705.0
  episodes_this_iter: 1
  episodes_total: 311
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.017
    dispatch_time_ms: 6.586
    learner:
      cur_lr: 0.001297862152568996
      grad_gnorm: 39.999996185302734
      policy_entropy: 9.555898666381836
      policy_loss: -8.290708541870117
      var_gnorm: 38.964111328125
      vf_explained_var: 0.09219437837600708
      vf_loss: 13.838390350341797
    num_steps_sampled: 936000
    num_steps_trained: 936000
    wait_time_ms: 69.784
  iterations_since_restore: 312
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2687.1001830101013
  time_this_iter_s: 8.51436448097229
  time_total_s: 2687.1001830101013
  timestamp: 1594090454
  timesteps_since_restore: 936000
  timesteps_this_iter: 3000
  timesteps_total: 936000
  training_iteration: 312
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2687 s, 312 iter, 936000 ts, 1.09e+03 rew

agent-1: 360.0
agent-2: 367.0
agent-3: 341.0
Sum Reward: 1068.0
Avg Reward: 356.0
Min Reward: 341.0
Max Reward: 367.0
Gini Coefficient: 0.016229712858926344
20:20 Ratio: 1.0762463343108504
Max-min Ratio: 1.0762463343108504
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-54-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1088.78
  episode_reward_min: 705.0
  episodes_this_iter: 1
  episodes_total: 312
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.769
    dispatch_time_ms: 5.519
    learner:
      cur_lr: 0.001297662383876741
      grad_gnorm: 6.821534633636475
      policy_entropy: 10.917251586914062
      policy_loss: -2.667170524597168
      var_gnorm: 38.95542907714844
      vf_explained_var: -0.11228299140930176
      vf_loss: 4.4782209396362305
    num_steps_sampled: 939000
    num_steps_trained: 939000
    wait_time_ms: 75.237
  iterations_since_restore: 313
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2695.364107131958
  time_this_iter_s: 8.26392412185669
  time_total_s: 2695.364107131958
  timestamp: 1594090462
  timesteps_since_restore: 939000
  timesteps_this_iter: 3000
  timesteps_total: 939000
  training_iteration: 313
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2695 s, 313 iter, 939000 ts, 1.09e+03 rew

agent-1: 368.0
agent-2: 381.0
agent-3: 386.0
Sum Reward: 1135.0
Avg Reward: 378.3333333333333
Min Reward: 368.0
Max Reward: 386.0
Gini Coefficient: 0.010572687224669603
20:20 Ratio: 1.048913043478261
Max-min Ratio: 1.048913043478261
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-54-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1089.82
  episode_reward_min: 705.0
  episodes_this_iter: 1
  episodes_total: 313
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.345
    dispatch_time_ms: 5.304
    learner:
      cur_lr: 0.001297462615184486
      grad_gnorm: 40.0
      policy_entropy: 10.56548023223877
      policy_loss: -1.5483202934265137
      var_gnorm: 38.994590759277344
      vf_explained_var: 0.29847168922424316
      vf_loss: 41.3775520324707
    num_steps_sampled: 942000
    num_steps_trained: 942000
    wait_time_ms: 83.774
  iterations_since_restore: 314
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2704.361497402191
  time_this_iter_s: 8.997390270233154
  time_total_s: 2704.361497402191
  timestamp: 1594090471
  timesteps_since_restore: 942000
  timesteps_this_iter: 3000
  timesteps_total: 942000
  training_iteration: 314
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2704 s, 314 iter, 942000 ts, 1.09e+03 rew

agent-1: 392.0
agent-2: 375.0
agent-3: 371.0
Sum Reward: 1138.0
Avg Reward: 379.3333333333333
Min Reward: 371.0
Max Reward: 392.0
Gini Coefficient: 0.012302284710017574
20:20 Ratio: 1.0566037735849056
Max-min Ratio: 1.0566037735849056
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-54-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1090.83
  episode_reward_min: 705.0
  episodes_this_iter: 1
  episodes_total: 314
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.548
    dispatch_time_ms: 6.842
    learner:
      cur_lr: 0.001297262846492231
      grad_gnorm: 11.52423095703125
      policy_entropy: 9.296113967895508
      policy_loss: -0.38726747035980225
      var_gnorm: 39.04505157470703
      vf_explained_var: 0.19971072673797607
      vf_loss: 9.587875366210938
    num_steps_sampled: 945000
    num_steps_trained: 945000
    wait_time_ms: 93.728
  iterations_since_restore: 315
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2713.528988838196
  time_this_iter_s: 9.167491436004639
  time_total_s: 2713.528988838196
  timestamp: 1594090481
  timesteps_since_restore: 945000
  timesteps_this_iter: 3000
  timesteps_total: 945000
  training_iteration: 315
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2713 s, 315 iter, 945000 ts, 1.09e+03 rew

agent-1: 398.0
agent-2: 371.0
agent-3: 392.0
Sum Reward: 1161.0
Avg Reward: 387.0
Min Reward: 371.0
Max Reward: 398.0
Gini Coefficient: 0.015503875968992248
20:20 Ratio: 1.0727762803234502
Max-min Ratio: 1.0727762803234502
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-54-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1092.21
  episode_reward_min: 705.0
  episodes_this_iter: 1
  episodes_total: 315
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.571
    dispatch_time_ms: 7.279
    learner:
      cur_lr: 0.001297062961384654
      grad_gnorm: 40.000003814697266
      policy_entropy: 10.72443962097168
      policy_loss: -10.887797355651855
      var_gnorm: 39.12934494018555
      vf_explained_var: 0.16567111015319824
      vf_loss: 52.49760818481445
    num_steps_sampled: 948000
    num_steps_trained: 948000
    wait_time_ms: 80.765
  iterations_since_restore: 316
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2722.5367679595947
  time_this_iter_s: 9.007779121398926
  time_total_s: 2722.5367679595947
  timestamp: 1594090490
  timesteps_since_restore: 948000
  timesteps_this_iter: 3000
  timesteps_total: 948000
  training_iteration: 316
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2722 s, 316 iter, 948000 ts, 1.09e+03 rew

agent-1: 417.0
agent-2: 384.0
agent-3: 423.0
Sum Reward: 1224.0
Avg Reward: 408.0
Min Reward: 384.0
Max Reward: 423.0
Gini Coefficient: 0.021241830065359478
20:20 Ratio: 1.1015625
Max-min Ratio: 1.1015625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-54-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1095.13
  episode_reward_min: 705.0
  episodes_this_iter: 1
  episodes_total: 316
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.971
    dispatch_time_ms: 6.948
    learner:
      cur_lr: 0.001296863192692399
      grad_gnorm: 33.01276779174805
      policy_entropy: 10.579678535461426
      policy_loss: 0.29490533471107483
      var_gnorm: 39.156898498535156
      vf_explained_var: -0.000962376594543457
      vf_loss: 20.82375717163086
    num_steps_sampled: 951000
    num_steps_trained: 951000
    wait_time_ms: 80.054
  iterations_since_restore: 317
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2731.516783475876
  time_this_iter_s: 8.980015516281128
  time_total_s: 2731.516783475876
  timestamp: 1594090499
  timesteps_since_restore: 951000
  timesteps_this_iter: 3000
  timesteps_total: 951000
  training_iteration: 317
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2731 s, 317 iter, 951000 ts, 1.1e+03 rew

agent-1: 391.0
agent-2: 396.0
agent-3: 347.0
Sum Reward: 1134.0
Avg Reward: 378.0
Min Reward: 347.0
Max Reward: 396.0
Gini Coefficient: 0.02880658436213992
20:20 Ratio: 1.1412103746397695
Max-min Ratio: 1.1412103746397695
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-55-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1096.64
  episode_reward_min: 705.0
  episodes_this_iter: 1
  episodes_total: 317
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.383
    dispatch_time_ms: 5.393
    learner:
      cur_lr: 0.001296663424000144
      grad_gnorm: 40.0
      policy_entropy: 9.63330078125
      policy_loss: -9.630125999450684
      var_gnorm: 39.18611526489258
      vf_explained_var: 0.0
      vf_loss: 13.687084197998047
    num_steps_sampled: 954000
    num_steps_trained: 954000
    wait_time_ms: 72.778
  iterations_since_restore: 318
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2740.692693710327
  time_this_iter_s: 9.175910234451294
  time_total_s: 2740.692693710327
  timestamp: 1594090508
  timesteps_since_restore: 954000
  timesteps_this_iter: 3000
  timesteps_total: 954000
  training_iteration: 318
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2740 s, 318 iter, 954000 ts, 1.1e+03 rew

agent-1: 390.0
agent-2: 395.0
agent-3: 384.0
Sum Reward: 1169.0
Avg Reward: 389.6666666666667
Min Reward: 384.0
Max Reward: 395.0
Gini Coefficient: 0.006273167949814656
20:20 Ratio: 1.0286458333333333
Max-min Ratio: 1.0286458333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-55-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1101.28
  episode_reward_min: 757.0
  episodes_this_iter: 1
  episodes_total: 318
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.901
    dispatch_time_ms: 7.178
    learner:
      cur_lr: 0.001296463655307889
      grad_gnorm: 31.43699073791504
      policy_entropy: 10.25883674621582
      policy_loss: -7.128016471862793
      var_gnorm: 39.180458068847656
      vf_explained_var: -0.20357024669647217
      vf_loss: 42.57467269897461
    num_steps_sampled: 957000
    num_steps_trained: 957000
    wait_time_ms: 73.038
  iterations_since_restore: 319
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2749.0500581264496
  time_this_iter_s: 8.357364416122437
  time_total_s: 2749.0500581264496
  timestamp: 1594090516
  timesteps_since_restore: 957000
  timesteps_this_iter: 3000
  timesteps_total: 957000
  training_iteration: 319
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2749 s, 319 iter, 957000 ts, 1.1e+03 rew

agent-1: 386.0
agent-2: 362.0
agent-3: 369.0
Sum Reward: 1117.0
Avg Reward: 372.3333333333333
Min Reward: 362.0
Max Reward: 386.0
Gini Coefficient: 0.01432408236347359
20:20 Ratio: 1.0662983425414365
Max-min Ratio: 1.0662983425414365
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-55-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1103.71
  episode_reward_min: 757.0
  episodes_this_iter: 1
  episodes_total: 319
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.626
    dispatch_time_ms: 6.86
    learner:
      cur_lr: 0.0012962637702003121
      grad_gnorm: 40.0
      policy_entropy: 12.195638656616211
      policy_loss: -8.266746520996094
      var_gnorm: 39.19516372680664
      vf_explained_var: 0.10604614019393921
      vf_loss: 12.206510543823242
    num_steps_sampled: 960000
    num_steps_trained: 960000
    wait_time_ms: 74.945
  iterations_since_restore: 320
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2757.547340154648
  time_this_iter_s: 8.497282028198242
  time_total_s: 2757.547340154648
  timestamp: 1594090525
  timesteps_since_restore: 960000
  timesteps_this_iter: 3000
  timesteps_total: 960000
  training_iteration: 320
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2757 s, 320 iter, 960000 ts, 1.1e+03 rew

agent-1: 310.0
agent-2: 410.0
agent-3: 353.0
Sum Reward: 1073.0
Avg Reward: 357.6666666666667
Min Reward: 310.0
Max Reward: 410.0
Gini Coefficient: 0.062131096613855234
20:20 Ratio: 1.3225806451612903
Max-min Ratio: 1.3225806451612903
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-55-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1106.37
  episode_reward_min: 757.0
  episodes_this_iter: 1
  episodes_total: 320
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.983
    dispatch_time_ms: 8.511
    learner:
      cur_lr: 0.0012960640015080571
      grad_gnorm: 33.40436553955078
      policy_entropy: 21.600784301757812
      policy_loss: 10.782118797302246
      var_gnorm: 39.222442626953125
      vf_explained_var: -0.3287672996520996
      vf_loss: 15.367303848266602
    num_steps_sampled: 963000
    num_steps_trained: 963000
    wait_time_ms: 77.002
  iterations_since_restore: 321
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2765.843917608261
  time_this_iter_s: 8.296577453613281
  time_total_s: 2765.843917608261
  timestamp: 1594090533
  timesteps_since_restore: 963000
  timesteps_this_iter: 3000
  timesteps_total: 963000
  training_iteration: 321
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2765 s, 321 iter, 963000 ts, 1.11e+03 rew

agent-1: 348.0
agent-2: 340.0
agent-3: 374.0
Sum Reward: 1062.0
Avg Reward: 354.0
Min Reward: 340.0
Max Reward: 374.0
Gini Coefficient: 0.021343377275580666
20:20 Ratio: 1.1
Max-min Ratio: 1.1
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-55-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1109.42
  episode_reward_min: 958.0
  episodes_this_iter: 1
  episodes_total: 321
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.459
    dispatch_time_ms: 6.521
    learner:
      cur_lr: 0.001295864232815802
      grad_gnorm: 39.999996185302734
      policy_entropy: 10.823211669921875
      policy_loss: -0.7577366828918457
      var_gnorm: 39.2647819519043
      vf_explained_var: 0.06120032072067261
      vf_loss: 12.323280334472656
    num_steps_sampled: 966000
    num_steps_trained: 966000
    wait_time_ms: 77.383
  iterations_since_restore: 322
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2774.40287065506
  time_this_iter_s: 8.558953046798706
  time_total_s: 2774.40287065506
  timestamp: 1594090542
  timesteps_since_restore: 966000
  timesteps_this_iter: 3000
  timesteps_total: 966000
  training_iteration: 322
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2774 s, 322 iter, 966000 ts, 1.11e+03 rew

agent-1: 360.0
agent-2: 380.0
agent-3: 343.0
Sum Reward: 1083.0
Avg Reward: 361.0
Min Reward: 343.0
Max Reward: 380.0
Gini Coefficient: 0.02277623884272084
20:20 Ratio: 1.1078717201166182
Max-min Ratio: 1.1078717201166182
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-55-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1110.64
  episode_reward_min: 958.0
  episodes_this_iter: 1
  episodes_total: 322
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.793
    dispatch_time_ms: 7.643
    learner:
      cur_lr: 0.0012956643477082253
      grad_gnorm: 40.000003814697266
      policy_entropy: 9.743599891662598
      policy_loss: 4.854625701904297
      var_gnorm: 39.322872161865234
      vf_explained_var: -0.09114861488342285
      vf_loss: 17.531211853027344
    num_steps_sampled: 969000
    num_steps_trained: 969000
    wait_time_ms: 80.904
  iterations_since_restore: 323
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2782.800921201706
  time_this_iter_s: 8.398050546646118
  time_total_s: 2782.800921201706
  timestamp: 1594090550
  timesteps_since_restore: 969000
  timesteps_this_iter: 3000
  timesteps_total: 969000
  training_iteration: 323
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2782 s, 323 iter, 969000 ts, 1.11e+03 rew

agent-1: 382.0
agent-2: 346.0
agent-3: 411.0
Sum Reward: 1139.0
Avg Reward: 379.6666666666667
Min Reward: 346.0
Max Reward: 411.0
Gini Coefficient: 0.03804506877377817
20:20 Ratio: 1.1878612716763006
Max-min Ratio: 1.1878612716763006
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-55-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1112.33
  episode_reward_min: 958.0
  episodes_this_iter: 1
  episodes_total: 323
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.743
    dispatch_time_ms: 7.355
    learner:
      cur_lr: 0.0012954645790159702
      grad_gnorm: 40.0
      policy_entropy: 10.883955001831055
      policy_loss: -1.7454386949539185
      var_gnorm: 39.349483489990234
      vf_explained_var: 0.03231334686279297
      vf_loss: 17.85441780090332
    num_steps_sampled: 972000
    num_steps_trained: 972000
    wait_time_ms: 75.976
  iterations_since_restore: 324
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2791.493082046509
  time_this_iter_s: 8.692160844802856
  time_total_s: 2791.493082046509
  timestamp: 1594090559
  timesteps_since_restore: 972000
  timesteps_this_iter: 3000
  timesteps_total: 972000
  training_iteration: 324
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2791 s, 324 iter, 972000 ts, 1.11e+03 rew

agent-1: 397.0
agent-2: 385.0
agent-3: 404.0
Sum Reward: 1186.0
Avg Reward: 395.3333333333333
Min Reward: 385.0
Max Reward: 404.0
Gini Coefficient: 0.010680157391793142
20:20 Ratio: 1.0493506493506493
Max-min Ratio: 1.0493506493506493
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-56-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1113.78
  episode_reward_min: 958.0
  episodes_this_iter: 1
  episodes_total: 324
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.16
    dispatch_time_ms: 7.138
    learner:
      cur_lr: 0.0012952648103237152
      grad_gnorm: 40.000003814697266
      policy_entropy: 9.521356582641602
      policy_loss: -1.3302512168884277
      var_gnorm: 39.472564697265625
      vf_explained_var: 0.12627774477005005
      vf_loss: 48.33237075805664
    num_steps_sampled: 975000
    num_steps_trained: 975000
    wait_time_ms: 74.44
  iterations_since_restore: 325
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2800.1315944194794
  time_this_iter_s: 8.638512372970581
  time_total_s: 2800.1315944194794
  timestamp: 1594090568
  timesteps_since_restore: 975000
  timesteps_this_iter: 3000
  timesteps_total: 975000
  training_iteration: 325
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2800 s, 325 iter, 975000 ts, 1.11e+03 rew

agent-1: 370.0
agent-2: 362.0
agent-3: 413.0
Sum Reward: 1145.0
Avg Reward: 381.6666666666667
Min Reward: 362.0
Max Reward: 413.0
Gini Coefficient: 0.029694323144104803
20:20 Ratio: 1.1408839779005524
Max-min Ratio: 1.1408839779005524
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-56-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1114.86
  episode_reward_min: 958.0
  episodes_this_iter: 1
  episodes_total: 325
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.912
    dispatch_time_ms: 7.875
    learner:
      cur_lr: 0.0012950650416314602
      grad_gnorm: 40.000003814697266
      policy_entropy: 10.029829025268555
      policy_loss: 14.345366477966309
      var_gnorm: 39.4924430847168
      vf_explained_var: 0.06713885068893433
      vf_loss: 38.29370880126953
    num_steps_sampled: 978000
    num_steps_trained: 978000
    wait_time_ms: 73.599
  iterations_since_restore: 326
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2808.479108810425
  time_this_iter_s: 8.347514390945435
  time_total_s: 2808.479108810425
  timestamp: 1594090576
  timesteps_since_restore: 978000
  timesteps_this_iter: 3000
  timesteps_total: 978000
  training_iteration: 326
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2808 s, 326 iter, 978000 ts, 1.11e+03 rew

agent-1: 350.0
agent-2: 358.0
agent-3: 385.0
Sum Reward: 1093.0
Avg Reward: 364.3333333333333
Min Reward: 350.0
Max Reward: 385.0
Gini Coefficient: 0.021347971942665446
20:20 Ratio: 1.1
Max-min Ratio: 1.1
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-56-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1114.85
  episode_reward_min: 958.0
  episodes_this_iter: 1
  episodes_total: 326
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.439
    dispatch_time_ms: 5.285
    learner:
      cur_lr: 0.0012948651565238833
      grad_gnorm: 7.479005336761475
      policy_entropy: 11.205228805541992
      policy_loss: -0.8659672737121582
      var_gnorm: 39.52262878417969
      vf_explained_var: 0.18056225776672363
      vf_loss: 63.24287796020508
    num_steps_sampled: 981000
    num_steps_trained: 981000
    wait_time_ms: 82.397
  iterations_since_restore: 327
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2816.8190586566925
  time_this_iter_s: 8.3399498462677
  time_total_s: 2816.8190586566925
  timestamp: 1594090584
  timesteps_since_restore: 981000
  timesteps_this_iter: 3000
  timesteps_total: 981000
  training_iteration: 327
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2816 s, 327 iter, 981000 ts, 1.11e+03 rew

agent-1: 361.0
agent-2: 415.0
agent-3: 379.0
Sum Reward: 1155.0
Avg Reward: 385.0
Min Reward: 361.0
Max Reward: 415.0
Gini Coefficient: 0.03116883116883117
20:20 Ratio: 1.149584487534626
Max-min Ratio: 1.149584487534626
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-56-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1116.11
  episode_reward_min: 958.0
  episodes_this_iter: 1
  episodes_total: 327
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.46
    dispatch_time_ms: 5.942
    learner:
      cur_lr: 0.0012946653878316283
      grad_gnorm: 40.0
      policy_entropy: 9.178094863891602
      policy_loss: 7.463071346282959
      var_gnorm: 39.56290817260742
      vf_explained_var: -1.0
      vf_loss: 21.008289337158203
    num_steps_sampled: 984000
    num_steps_trained: 984000
    wait_time_ms: 84.733
  iterations_since_restore: 328
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2825.80055975914
  time_this_iter_s: 8.98150110244751
  time_total_s: 2825.80055975914
  timestamp: 1594090593
  timesteps_since_restore: 984000
  timesteps_this_iter: 3000
  timesteps_total: 984000
  training_iteration: 328
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2825 s, 328 iter, 984000 ts, 1.12e+03 rew

agent-1: 381.0
agent-2: 395.0
agent-3: 387.0
Sum Reward: 1163.0
Avg Reward: 387.6666666666667
Min Reward: 381.0
Max Reward: 395.0
Gini Coefficient: 0.008025222126683863
20:20 Ratio: 1.036745406824147
Max-min Ratio: 1.036745406824147
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-56-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1116.31
  episode_reward_min: 958.0
  episodes_this_iter: 1
  episodes_total: 328
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.769
    dispatch_time_ms: 6.642
    learner:
      cur_lr: 0.0012944656191393733
      grad_gnorm: 40.0
      policy_entropy: 11.69536018371582
      policy_loss: -6.315757751464844
      var_gnorm: 39.69327926635742
      vf_explained_var: 0.11315596103668213
      vf_loss: 12.099297523498535
    num_steps_sampled: 987000
    num_steps_trained: 987000
    wait_time_ms: 84.44
  iterations_since_restore: 329
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2834.750922679901
  time_this_iter_s: 8.950362920761108
  time_total_s: 2834.750922679901
  timestamp: 1594090602
  timesteps_since_restore: 987000
  timesteps_this_iter: 3000
  timesteps_total: 987000
  training_iteration: 329
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2834 s, 329 iter, 987000 ts, 1.12e+03 rew

agent-1: 382.0
agent-2: 349.0
agent-3: 371.0
Sum Reward: 1102.0
Avg Reward: 367.3333333333333
Min Reward: 349.0
Max Reward: 382.0
Gini Coefficient: 0.019963702359346643
20:20 Ratio: 1.0945558739255015
Max-min Ratio: 1.0945558739255015
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-56-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1115.89
  episode_reward_min: 958.0
  episodes_this_iter: 1
  episodes_total: 329
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.471
    dispatch_time_ms: 7.606
    learner:
      cur_lr: 0.0012942658504471183
      grad_gnorm: 40.0
      policy_entropy: 8.476116180419922
      policy_loss: 11.28963851928711
      var_gnorm: 39.66746520996094
      vf_explained_var: -0.09455907344818115
      vf_loss: 64.54655456542969
    num_steps_sampled: 990000
    num_steps_trained: 990000
    wait_time_ms: 75.495
  iterations_since_restore: 330
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2843.4403042793274
  time_this_iter_s: 8.68938159942627
  time_total_s: 2843.4403042793274
  timestamp: 1594090611
  timesteps_since_restore: 990000
  timesteps_this_iter: 3000
  timesteps_total: 990000
  training_iteration: 330
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2843 s, 330 iter, 990000 ts, 1.12e+03 rew

agent-1: 347.0
agent-2: 366.0
agent-3: 357.0
Sum Reward: 1070.0
Avg Reward: 356.6666666666667
Min Reward: 347.0
Max Reward: 366.0
Gini Coefficient: 0.011838006230529595
20:20 Ratio: 1.0547550432276658
Max-min Ratio: 1.0547550432276658
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-57-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1114.7
  episode_reward_min: 958.0
  episodes_this_iter: 1
  episodes_total: 330
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.507
    dispatch_time_ms: 5.872
    learner:
      cur_lr: 0.0012940659653395414
      grad_gnorm: 11.636983871459961
      policy_entropy: 8.299088478088379
      policy_loss: -1.772341012954712
      var_gnorm: 39.717063903808594
      vf_explained_var: 0.20646387338638306
      vf_loss: 8.200642585754395
    num_steps_sampled: 993000
    num_steps_trained: 993000
    wait_time_ms: 84.38
  iterations_since_restore: 331
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2852.190920352936
  time_this_iter_s: 8.750616073608398
  time_total_s: 2852.190920352936
  timestamp: 1594090620
  timesteps_since_restore: 993000
  timesteps_this_iter: 3000
  timesteps_total: 993000
  training_iteration: 331
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2852 s, 331 iter, 993000 ts, 1.11e+03 rew

agent-1: 433.0
agent-2: 332.0
agent-3: 380.0
Sum Reward: 1145.0
Avg Reward: 381.6666666666667
Min Reward: 332.0
Max Reward: 433.0
Gini Coefficient: 0.05880640465793304
20:20 Ratio: 1.3042168674698795
Max-min Ratio: 1.3042168674698795
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-57-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1114.2
  episode_reward_min: 958.0
  episodes_this_iter: 1
  episodes_total: 331
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.784
    dispatch_time_ms: 6.281
    learner:
      cur_lr: 0.0012938661966472864
      grad_gnorm: 40.0
      policy_entropy: 9.115342140197754
      policy_loss: -12.390754699707031
      var_gnorm: 39.743595123291016
      vf_explained_var: -0.012842059135437012
      vf_loss: 34.151004791259766
    num_steps_sampled: 996000
    num_steps_trained: 996000
    wait_time_ms: 76.1
  iterations_since_restore: 332
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2860.8638603687286
  time_this_iter_s: 8.672940015792847
  time_total_s: 2860.8638603687286
  timestamp: 1594090629
  timesteps_since_restore: 996000
  timesteps_this_iter: 3000
  timesteps_total: 996000
  training_iteration: 332
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2860 s, 332 iter, 996000 ts, 1.11e+03 rew

agent-1: 399.0
agent-2: 388.0
agent-3: 394.0
Sum Reward: 1181.0
Avg Reward: 393.6666666666667
Min Reward: 388.0
Max Reward: 399.0
Gini Coefficient: 0.006209427039232289
20:20 Ratio: 1.0283505154639174
Max-min Ratio: 1.0283505154639174
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-57-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1113.93
  episode_reward_min: 958.0
  episodes_this_iter: 1
  episodes_total: 332
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.804
    dispatch_time_ms: 8.0
    learner:
      cur_lr: 0.0012936664279550314
      grad_gnorm: 40.000003814697266
      policy_entropy: 7.756303787231445
      policy_loss: 5.3749895095825195
      var_gnorm: 39.77691650390625
      vf_explained_var: 0.04735070466995239
      vf_loss: 32.584571838378906
    num_steps_sampled: 999000
    num_steps_trained: 999000
    wait_time_ms: 76.164
  iterations_since_restore: 333
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2869.678965330124
  time_this_iter_s: 8.815104961395264
  time_total_s: 2869.678965330124
  timestamp: 1594090637
  timesteps_since_restore: 999000
  timesteps_this_iter: 3000
  timesteps_total: 999000
  training_iteration: 333
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2869 s, 333 iter, 999000 ts, 1.11e+03 rew

agent-1: 366.0
agent-2: 364.0
agent-3: 386.0
Sum Reward: 1116.0
Avg Reward: 372.0
Min Reward: 364.0
Max Reward: 386.0
Gini Coefficient: 0.013142174432497013
20:20 Ratio: 1.0604395604395604
Max-min Ratio: 1.0604395604395604
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-57-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1113.5
  episode_reward_min: 958.0
  episodes_this_iter: 1
  episodes_total: 333
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.66
    dispatch_time_ms: 7.86
    learner:
      cur_lr: 0.0012934665428474545
      grad_gnorm: 40.0
      policy_entropy: 9.136749267578125
      policy_loss: 7.186185359954834
      var_gnorm: 39.73760986328125
      vf_explained_var: -1.0
      vf_loss: 31.157489776611328
    num_steps_sampled: 1002000
    num_steps_trained: 1002000
    wait_time_ms: 83.737
  iterations_since_restore: 334
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2878.5016162395477
  time_this_iter_s: 8.822650909423828
  time_total_s: 2878.5016162395477
  timestamp: 1594090646
  timesteps_since_restore: 1002000
  timesteps_this_iter: 3000
  timesteps_total: 1002000
  training_iteration: 334
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2878 s, 334 iter, 1002000 ts, 1.11e+03 rew

agent-1: 419.0
agent-2: 362.0
agent-3: 389.0
Sum Reward: 1170.0
Avg Reward: 390.0
Min Reward: 362.0
Max Reward: 419.0
Gini Coefficient: 0.03247863247863248
20:20 Ratio: 1.1574585635359116
Max-min Ratio: 1.1574585635359116
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-57-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1115.08
  episode_reward_min: 958.0
  episodes_this_iter: 1
  episodes_total: 334
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.397
    dispatch_time_ms: 9.629
    learner:
      cur_lr: 0.0012932667741551995
      grad_gnorm: 40.0
      policy_entropy: 8.19489860534668
      policy_loss: 3.3741583824157715
      var_gnorm: 39.73979949951172
      vf_explained_var: 0.3524615168571472
      vf_loss: 17.4302921295166
    num_steps_sampled: 1005000
    num_steps_trained: 1005000
    wait_time_ms: 73.278
  iterations_since_restore: 335
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2887.2215900421143
  time_this_iter_s: 8.719973802566528
  time_total_s: 2887.2215900421143
  timestamp: 1594090655
  timesteps_since_restore: 1005000
  timesteps_this_iter: 3000
  timesteps_total: 1005000
  training_iteration: 335
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2887 s, 335 iter, 1005000 ts, 1.12e+03 rew

agent-1: 388.0
agent-2: 374.0
agent-3: 384.0
Sum Reward: 1146.0
Avg Reward: 382.0
Min Reward: 374.0
Max Reward: 388.0
Gini Coefficient: 0.008144269924374637
20:20 Ratio: 1.0374331550802138
Max-min Ratio: 1.0374331550802138
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-57-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1114.79
  episode_reward_min: 958.0
  episodes_this_iter: 1
  episodes_total: 335
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.63
    dispatch_time_ms: 7.782
    learner:
      cur_lr: 0.0012930670054629445
      grad_gnorm: 40.0
      policy_entropy: 11.58624267578125
      policy_loss: -42.11388397216797
      var_gnorm: 39.74675369262695
      vf_explained_var: 0.15580743551254272
      vf_loss: 38.19544219970703
    num_steps_sampled: 1008000
    num_steps_trained: 1008000
    wait_time_ms: 70.909
  iterations_since_restore: 336
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2895.8320071697235
  time_this_iter_s: 8.610417127609253
  time_total_s: 2895.8320071697235
  timestamp: 1594090664
  timesteps_since_restore: 1008000
  timesteps_this_iter: 3000
  timesteps_total: 1008000
  training_iteration: 336
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2895 s, 336 iter, 1008000 ts, 1.11e+03 rew

agent-1: 362.0
agent-2: 378.0
agent-3: 370.0
Sum Reward: 1110.0
Avg Reward: 370.0
Min Reward: 362.0
Max Reward: 378.0
Gini Coefficient: 0.00960960960960961
20:20 Ratio: 1.0441988950276244
Max-min Ratio: 1.0441988950276244
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-57-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1115.33
  episode_reward_min: 958.0
  episodes_this_iter: 1
  episodes_total: 336
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.82
    dispatch_time_ms: 7.807
    learner:
      cur_lr: 0.0012928672367706895
      grad_gnorm: 7.345180511474609
      policy_entropy: 9.81082534790039
      policy_loss: 1.9516993761062622
      var_gnorm: 39.76544189453125
      vf_explained_var: -0.3651435375213623
      vf_loss: 6.034107685089111
    num_steps_sampled: 1011000
    num_steps_trained: 1011000
    wait_time_ms: 77.068
  iterations_since_restore: 337
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2904.591104030609
  time_this_iter_s: 8.75909686088562
  time_total_s: 2904.591104030609
  timestamp: 1594090672
  timesteps_since_restore: 1011000
  timesteps_this_iter: 3000
  timesteps_total: 1011000
  training_iteration: 337
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2904 s, 337 iter, 1011000 ts, 1.12e+03 rew

agent-1: 352.0
agent-2: 352.0
agent-3: 370.0
Sum Reward: 1074.0
Avg Reward: 358.0
Min Reward: 352.0
Max Reward: 370.0
Gini Coefficient: 0.0111731843575419
20:20 Ratio: 1.0511363636363635
Max-min Ratio: 1.0511363636363635
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-58-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1115.99
  episode_reward_min: 958.0
  episodes_this_iter: 1
  episodes_total: 337
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.921
    dispatch_time_ms: 5.997
    learner:
      cur_lr: 0.0012926673516631126
      grad_gnorm: 40.000003814697266
      policy_entropy: 23.906734466552734
      policy_loss: -24.085411071777344
      var_gnorm: 39.83413314819336
      vf_explained_var: 0.158463716506958
      vf_loss: 32.24437713623047
    num_steps_sampled: 1014000
    num_steps_trained: 1014000
    wait_time_ms: 79.363
  iterations_since_restore: 338
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2913.3290576934814
  time_this_iter_s: 8.737953662872314
  time_total_s: 2913.3290576934814
  timestamp: 1594090681
  timesteps_since_restore: 1014000
  timesteps_this_iter: 3000
  timesteps_total: 1014000
  training_iteration: 338
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2913 s, 338 iter, 1014000 ts, 1.12e+03 rew

agent-1: 341.0
agent-2: 363.0
agent-3: 356.0
Sum Reward: 1060.0
Avg Reward: 353.3333333333333
Min Reward: 341.0
Max Reward: 363.0
Gini Coefficient: 0.013836477987421384
20:20 Ratio: 1.064516129032258
Max-min Ratio: 1.064516129032258
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-58-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1115.69
  episode_reward_min: 958.0
  episodes_this_iter: 1
  episodes_total: 338
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.176
    dispatch_time_ms: 7.4
    learner:
      cur_lr: 0.0012924675829708576
      grad_gnorm: 20.83213233947754
      policy_entropy: 10.11135482788086
      policy_loss: 0.6628259420394897
      var_gnorm: 39.82019805908203
      vf_explained_var: -0.0010706186294555664
      vf_loss: 12.182829856872559
    num_steps_sampled: 1017000
    num_steps_trained: 1017000
    wait_time_ms: 69.23
  iterations_since_restore: 339
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2921.4404861927032
  time_this_iter_s: 8.111428499221802
  time_total_s: 2921.4404861927032
  timestamp: 1594090689
  timesteps_since_restore: 1017000
  timesteps_this_iter: 3000
  timesteps_total: 1017000
  training_iteration: 339
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2921 s, 339 iter, 1017000 ts, 1.12e+03 rew

agent-1: 317.0
agent-2: 350.0
agent-3: 321.0
Sum Reward: 988.0
Avg Reward: 329.3333333333333
Min Reward: 317.0
Max Reward: 350.0
Gini Coefficient: 0.022267206477732792
20:20 Ratio: 1.1041009463722398
Max-min Ratio: 1.1041009463722398
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-58-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1114.12
  episode_reward_min: 958.0
  episodes_this_iter: 1
  episodes_total: 339
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.945
    dispatch_time_ms: 8.65
    learner:
      cur_lr: 0.0012922678142786026
      grad_gnorm: 40.0
      policy_entropy: 10.620218276977539
      policy_loss: 10.325523376464844
      var_gnorm: 39.83141326904297
      vf_explained_var: -0.02227497100830078
      vf_loss: 35.55414581298828
    num_steps_sampled: 1020000
    num_steps_trained: 1020000
    wait_time_ms: 72.572
  iterations_since_restore: 340
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2929.543210506439
  time_this_iter_s: 8.102724313735962
  time_total_s: 2929.543210506439
  timestamp: 1594090698
  timesteps_since_restore: 1020000
  timesteps_this_iter: 3000
  timesteps_total: 1020000
  training_iteration: 340
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2929 s, 340 iter, 1020000 ts, 1.11e+03 rew

agent-1: 346.0
agent-2: 303.0
agent-3: 329.0
Sum Reward: 978.0
Avg Reward: 326.0
Min Reward: 303.0
Max Reward: 346.0
Gini Coefficient: 0.02931152010906612
20:20 Ratio: 1.141914191419142
Max-min Ratio: 1.141914191419142
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-58-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1111.83
  episode_reward_min: 958.0
  episodes_this_iter: 1
  episodes_total: 340
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.131
    dispatch_time_ms: 5.523
    learner:
      cur_lr: 0.0012920680455863476
      grad_gnorm: 40.0
      policy_entropy: 12.058012008666992
      policy_loss: 18.065876007080078
      var_gnorm: 39.87635803222656
      vf_explained_var: 0.06400257349014282
      vf_loss: 22.60668182373047
    num_steps_sampled: 1023000
    num_steps_trained: 1023000
    wait_time_ms: 79.525
  iterations_since_restore: 341
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2937.8546674251556
  time_this_iter_s: 8.31145691871643
  time_total_s: 2937.8546674251556
  timestamp: 1594090706
  timesteps_since_restore: 1023000
  timesteps_this_iter: 3000
  timesteps_total: 1023000
  training_iteration: 341
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2937 s, 341 iter, 1023000 ts, 1.11e+03 rew

agent-1: 275.0
agent-2: 328.0
agent-3: 294.0
Sum Reward: 897.0
Avg Reward: 299.0
Min Reward: 275.0
Max Reward: 328.0
Gini Coefficient: 0.03939056112969157
20:20 Ratio: 1.1927272727272726
Max-min Ratio: 1.1927272727272726
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-58-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1108.84
  episode_reward_min: 897.0
  episodes_this_iter: 1
  episodes_total: 341
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.075
    dispatch_time_ms: 7.853
    learner:
      cur_lr: 0.0012918681604787707
      grad_gnorm: 40.000003814697266
      policy_entropy: 15.178311347961426
      policy_loss: 12.219770431518555
      var_gnorm: 39.8377799987793
      vf_explained_var: -0.21625399589538574
      vf_loss: 21.91927146911621
    num_steps_sampled: 1026000
    num_steps_trained: 1026000
    wait_time_ms: 67.582
  iterations_since_restore: 342
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2945.884909391403
  time_this_iter_s: 8.030241966247559
  time_total_s: 2945.884909391403
  timestamp: 1594090714
  timesteps_since_restore: 1026000
  timesteps_this_iter: 3000
  timesteps_total: 1026000
  training_iteration: 342
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2945 s, 342 iter, 1026000 ts, 1.11e+03 rew

agent-1: 274.0
agent-2: 328.0
agent-3: 312.0
Sum Reward: 914.0
Avg Reward: 304.6666666666667
Min Reward: 274.0
Max Reward: 328.0
Gini Coefficient: 0.03938730853391685
20:20 Ratio: 1.197080291970803
Max-min Ratio: 1.197080291970803
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-58-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1107.52
  episode_reward_min: 897.0
  episodes_this_iter: 1
  episodes_total: 342
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.799
    dispatch_time_ms: 8.573
    learner:
      cur_lr: 0.0012916683917865157
      grad_gnorm: 40.0
      policy_entropy: 23.803436279296875
      policy_loss: -14.14955997467041
      var_gnorm: 39.84336853027344
      vf_explained_var: 0.051251769065856934
      vf_loss: 9.391059875488281
    num_steps_sampled: 1029000
    num_steps_trained: 1029000
    wait_time_ms: 72.504
  iterations_since_restore: 343
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2954.060375928879
  time_this_iter_s: 8.175466537475586
  time_total_s: 2954.060375928879
  timestamp: 1594090722
  timesteps_since_restore: 1029000
  timesteps_this_iter: 3000
  timesteps_total: 1029000
  training_iteration: 343
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2954 s, 343 iter, 1029000 ts, 1.11e+03 rew

agent-1: 335.0
agent-2: 314.0
agent-3: 326.0
Sum Reward: 975.0
Avg Reward: 325.0
Min Reward: 314.0
Max Reward: 335.0
Gini Coefficient: 0.014358974358974359
20:20 Ratio: 1.0668789808917198
Max-min Ratio: 1.0668789808917198
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-58-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1106.73
  episode_reward_min: 897.0
  episodes_this_iter: 1
  episodes_total: 343
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.859
    dispatch_time_ms: 5.75
    learner:
      cur_lr: 0.0012914686230942607
      grad_gnorm: 40.0
      policy_entropy: 20.529239654541016
      policy_loss: 14.434725761413574
      var_gnorm: 39.84347915649414
      vf_explained_var: 0.34032559394836426
      vf_loss: 12.375292778015137
    num_steps_sampled: 1032000
    num_steps_trained: 1032000
    wait_time_ms: 75.859
  iterations_since_restore: 344
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2962.442055463791
  time_this_iter_s: 8.38167953491211
  time_total_s: 2962.442055463791
  timestamp: 1594090731
  timesteps_since_restore: 1032000
  timesteps_this_iter: 3000
  timesteps_total: 1032000
  training_iteration: 344
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2962 s, 344 iter, 1032000 ts, 1.11e+03 rew

agent-1: 297.0
agent-2: 346.0
agent-3: 349.0
Sum Reward: 992.0
Avg Reward: 330.6666666666667
Min Reward: 297.0
Max Reward: 349.0
Gini Coefficient: 0.03494623655913978
20:20 Ratio: 1.1750841750841752
Max-min Ratio: 1.1750841750841752
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-58-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1105.69
  episode_reward_min: 897.0
  episodes_this_iter: 1
  episodes_total: 344
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.046
    dispatch_time_ms: 7.749
    learner:
      cur_lr: 0.0012912688544020057
      grad_gnorm: 14.848258018493652
      policy_entropy: 20.85603904724121
      policy_loss: 2.109614849090576
      var_gnorm: 39.88218688964844
      vf_explained_var: 0.1261078119277954
      vf_loss: 8.793447494506836
    num_steps_sampled: 1035000
    num_steps_trained: 1035000
    wait_time_ms: 74.949
  iterations_since_restore: 345
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2970.9706835746765
  time_this_iter_s: 8.52862811088562
  time_total_s: 2970.9706835746765
  timestamp: 1594090739
  timesteps_since_restore: 1035000
  timesteps_this_iter: 3000
  timesteps_total: 1035000
  training_iteration: 345
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2970 s, 345 iter, 1035000 ts, 1.11e+03 rew

agent-1: 330.0
agent-2: 366.0
agent-3: 332.0
Sum Reward: 1028.0
Avg Reward: 342.6666666666667
Min Reward: 330.0
Max Reward: 366.0
Gini Coefficient: 0.023346303501945526
20:20 Ratio: 1.1090909090909091
Max-min Ratio: 1.1090909090909091
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-59-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1104.34
  episode_reward_min: 897.0
  episodes_this_iter: 1
  episodes_total: 345
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.539
    dispatch_time_ms: 28.205
    learner:
      cur_lr: 0.0012910689692944288
      grad_gnorm: 0.9403968453407288
      policy_entropy: 13.032018661499023
      policy_loss: -1.6019024848937988
      var_gnorm: 39.93113327026367
      vf_explained_var: 0.054630815982818604
      vf_loss: 19.604440689086914
    num_steps_sampled: 1038000
    num_steps_trained: 1038000
    wait_time_ms: 51.24
  iterations_since_restore: 346
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2985.521281480789
  time_this_iter_s: 14.550597906112671
  time_total_s: 2985.521281480789
  timestamp: 1594090754
  timesteps_since_restore: 1038000
  timesteps_this_iter: 3000
  timesteps_total: 1038000
  training_iteration: 346
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2985 s, 346 iter, 1038000 ts, 1.1e+03 rew

agent-1: 376.0
agent-2: 384.0
agent-3: 359.0
Sum Reward: 1119.0
Avg Reward: 373.0
Min Reward: 359.0
Max Reward: 384.0
Gini Coefficient: 0.014894250819183795
20:20 Ratio: 1.0696378830083566
Max-min Ratio: 1.0696378830083566
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-59-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1104.38
  episode_reward_min: 897.0
  episodes_this_iter: 1
  episodes_total: 346
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.311
    dispatch_time_ms: 24.197
    learner:
      cur_lr: 0.0012908692006021738
      grad_gnorm: 40.0
      policy_entropy: 9.57928466796875
      policy_loss: -4.836140155792236
      var_gnorm: 40.00615692138672
      vf_explained_var: 0.09363442659378052
      vf_loss: 47.11707305908203
    num_steps_sampled: 1041000
    num_steps_trained: 1041000
    wait_time_ms: 68.862
  iterations_since_restore: 347
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 2994.9270985126495
  time_this_iter_s: 9.405817031860352
  time_total_s: 2994.9270985126495
  timestamp: 1594090763
  timesteps_since_restore: 1041000
  timesteps_this_iter: 3000
  timesteps_total: 1041000
  training_iteration: 347
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 2994 s, 347 iter, 1041000 ts, 1.1e+03 rew

agent-1: 356.0
agent-2: 410.0
agent-3: 434.0
Sum Reward: 1200.0
Avg Reward: 400.0
Min Reward: 356.0
Max Reward: 434.0
Gini Coefficient: 0.043333333333333335
20:20 Ratio: 1.2191011235955056
Max-min Ratio: 1.2191011235955056
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-59-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1105.24
  episode_reward_min: 897.0
  episodes_this_iter: 1
  episodes_total: 347
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.975
    dispatch_time_ms: 20.038
    learner:
      cur_lr: 0.0012906694319099188
      grad_gnorm: 40.0
      policy_entropy: 10.978316307067871
      policy_loss: 7.456276893615723
      var_gnorm: 40.10106658935547
      vf_explained_var: 0.185502827167511
      vf_loss: 16.271785736083984
    num_steps_sampled: 1044000
    num_steps_trained: 1044000
    wait_time_ms: 74.741
  iterations_since_restore: 348
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3004.3535554409027
  time_this_iter_s: 9.426456928253174
  time_total_s: 3004.3535554409027
  timestamp: 1594090773
  timesteps_since_restore: 1044000
  timesteps_this_iter: 3000
  timesteps_total: 1044000
  training_iteration: 348
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3004 s, 348 iter, 1044000 ts, 1.11e+03 rew

agent-1: 385.0
agent-2: 360.0
agent-3: 386.0
Sum Reward: 1131.0
Avg Reward: 377.0
Min Reward: 360.0
Max Reward: 386.0
Gini Coefficient: 0.01532567049808429
20:20 Ratio: 1.0722222222222222
Max-min Ratio: 1.0722222222222222
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-59-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1105.41
  episode_reward_min: 897.0
  episodes_this_iter: 1
  episodes_total: 348
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.546
    dispatch_time_ms: 18.881
    learner:
      cur_lr: 0.001290469546802342
      grad_gnorm: 32.487770080566406
      policy_entropy: 8.957047462463379
      policy_loss: 0.5298441648483276
      var_gnorm: 40.13758850097656
      vf_explained_var: 0.019505977630615234
      vf_loss: 10.616561889648438
    num_steps_sampled: 1047000
    num_steps_trained: 1047000
    wait_time_ms: 63.606
  iterations_since_restore: 349
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3013.4217591285706
  time_this_iter_s: 9.068203687667847
  time_total_s: 3013.4217591285706
  timestamp: 1594090782
  timesteps_since_restore: 1047000
  timesteps_this_iter: 3000
  timesteps_total: 1047000
  training_iteration: 349
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3013 s, 349 iter, 1047000 ts, 1.11e+03 rew

agent-1: 412.0
agent-2: 377.0
agent-3: 380.0
Sum Reward: 1169.0
Avg Reward: 389.6666666666667
Min Reward: 377.0
Max Reward: 412.0
Gini Coefficient: 0.01996007984031936
20:20 Ratio: 1.0928381962864722
Max-min Ratio: 1.0928381962864722
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_22-59-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1105.75
  episode_reward_min: 897.0
  episodes_this_iter: 1
  episodes_total: 349
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.89
    dispatch_time_ms: 34.314
    learner:
      cur_lr: 0.001290269778110087
      grad_gnorm: 40.0
      policy_entropy: 12.825575828552246
      policy_loss: -25.863203048706055
      var_gnorm: 40.203269958496094
      vf_explained_var: 0.3432082533836365
      vf_loss: 22.412883758544922
    num_steps_sampled: 1050000
    num_steps_trained: 1050000
    wait_time_ms: 45.521
  iterations_since_restore: 350
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3022.4703986644745
  time_this_iter_s: 9.04863953590393
  time_total_s: 3022.4703986644745
  timestamp: 1594090791
  timesteps_since_restore: 1050000
  timesteps_this_iter: 3000
  timesteps_total: 1050000
  training_iteration: 350
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3022 s, 350 iter, 1050000 ts, 1.11e+03 rew

agent-1: 326.0
agent-2: 353.0
agent-3: 326.0
Sum Reward: 1005.0
Avg Reward: 335.0
Min Reward: 326.0
Max Reward: 353.0
Gini Coefficient: 0.01791044776119403
20:20 Ratio: 1.0828220858895705
Max-min Ratio: 1.0828220858895705
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-00-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1104.88
  episode_reward_min: 897.0
  episodes_this_iter: 1
  episodes_total: 350
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.262
    dispatch_time_ms: 18.895
    learner:
      cur_lr: 0.001290070009417832
      grad_gnorm: 40.0
      policy_entropy: 10.344367980957031
      policy_loss: 2.922744035720825
      var_gnorm: 40.23942184448242
      vf_explained_var: 0.43383651971817017
      vf_loss: 42.85025405883789
    num_steps_sampled: 1053000
    num_steps_trained: 1053000
    wait_time_ms: 65.328
  iterations_since_restore: 351
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3031.0963020324707
  time_this_iter_s: 8.625903367996216
  time_total_s: 3031.0963020324707
  timestamp: 1594090800
  timesteps_since_restore: 1053000
  timesteps_this_iter: 3000
  timesteps_total: 1053000
  training_iteration: 351
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3031 s, 351 iter, 1053000 ts, 1.1e+03 rew

agent-1: 263.0
agent-2: 380.0
agent-3: 259.0
Sum Reward: 902.0
Avg Reward: 300.6666666666667
Min Reward: 259.0
Max Reward: 380.0
Gini Coefficient: 0.08943089430894309
20:20 Ratio: 1.4671814671814671
Max-min Ratio: 1.4671814671814671
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-00-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1102.42
  episode_reward_min: 897.0
  episodes_this_iter: 1
  episodes_total: 351
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.868
    dispatch_time_ms: 25.076
    learner:
      cur_lr: 0.0012898702407255769
      grad_gnorm: 39.999996185302734
      policy_entropy: 12.723052978515625
      policy_loss: -21.444808959960938
      var_gnorm: 40.24321746826172
      vf_explained_var: -0.04899752140045166
      vf_loss: 45.80894088745117
    num_steps_sampled: 1056000
    num_steps_trained: 1056000
    wait_time_ms: 49.925
  iterations_since_restore: 352
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3039.389667034149
  time_this_iter_s: 8.293365001678467
  time_total_s: 3039.389667034149
  timestamp: 1594090808
  timesteps_since_restore: 1056000
  timesteps_this_iter: 3000
  timesteps_total: 1056000
  training_iteration: 352
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3039 s, 352 iter, 1056000 ts, 1.1e+03 rew

agent-1: 275.0
agent-2: 328.0
agent-3: 191.0
Sum Reward: 794.0
Avg Reward: 264.6666666666667
Min Reward: 191.0
Max Reward: 328.0
Gini Coefficient: 0.11502938706968933
20:20 Ratio: 1.7172774869109948
Max-min Ratio: 1.7172774869109948
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-00-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1099.63
  episode_reward_min: 794.0
  episodes_this_iter: 1
  episodes_total: 352
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.072
    dispatch_time_ms: 23.216
    learner:
      cur_lr: 0.001289670355618
      grad_gnorm: 40.0
      policy_entropy: 8.538694381713867
      policy_loss: -4.683464050292969
      var_gnorm: 40.16514205932617
      vf_explained_var: 4.172325134277344e-07
      vf_loss: 16.248332977294922
    num_steps_sampled: 1059000
    num_steps_trained: 1059000
    wait_time_ms: 40.525
  iterations_since_restore: 353
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3047.162326812744
  time_this_iter_s: 7.772659778594971
  time_total_s: 3047.162326812744
  timestamp: 1594090816
  timesteps_since_restore: 1059000
  timesteps_this_iter: 3000
  timesteps_total: 1059000
  training_iteration: 353
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3047 s, 353 iter, 1059000 ts, 1.1e+03 rew

agent-1: 149.0
agent-2: 228.0
agent-3: 161.0
Sum Reward: 538.0
Avg Reward: 179.33333333333334
Min Reward: 149.0
Max Reward: 228.0
Gini Coefficient: 0.09789343246592318
20:20 Ratio: 1.5302013422818792
Max-min Ratio: 1.5302013422818792
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-00-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1094.04
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 353
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.492
    dispatch_time_ms: 5.742
    learner:
      cur_lr: 0.001289470586925745
      grad_gnorm: 27.478988647460938
      policy_entropy: 9.566065788269043
      policy_loss: -8.154060363769531
      var_gnorm: 40.100215911865234
      vf_explained_var: 0.06332921981811523
      vf_loss: 29.01193618774414
    num_steps_sampled: 1062000
    num_steps_trained: 1062000
    wait_time_ms: 64.797
  iterations_since_restore: 354
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3054.614456176758
  time_this_iter_s: 7.452129364013672
  time_total_s: 3054.614456176758
  timestamp: 1594090823
  timesteps_since_restore: 1062000
  timesteps_this_iter: 3000
  timesteps_total: 1062000
  training_iteration: 354
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3054 s, 354 iter, 1062000 ts, 1.09e+03 rew

agent-1: 98.0
agent-2: 208.0
agent-3: 139.0
Sum Reward: 445.0
Avg Reward: 148.33333333333334
Min Reward: 98.0
Max Reward: 208.0
Gini Coefficient: 0.1647940074906367
20:20 Ratio: 2.122448979591837
Max-min Ratio: 2.122448979591837
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-00-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1087.14
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 354
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.466
    dispatch_time_ms: 5.563
    learner:
      cur_lr: 0.00128927081823349
      grad_gnorm: 23.19512367248535
      policy_entropy: 7.168720245361328
      policy_loss: 1.8256444931030273
      var_gnorm: 40.16114044189453
      vf_explained_var: 0.027131855487823486
      vf_loss: 15.441213607788086
    num_steps_sampled: 1065000
    num_steps_trained: 1065000
    wait_time_ms: 70.027
  iterations_since_restore: 355
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3062.298881292343
  time_this_iter_s: 7.684425115585327
  time_total_s: 3062.298881292343
  timestamp: 1594090831
  timesteps_since_restore: 1065000
  timesteps_this_iter: 3000
  timesteps_total: 1065000
  training_iteration: 355
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3062 s, 355 iter, 1065000 ts, 1.09e+03 rew

agent-1: 224.0
agent-2: 249.0
agent-3: 276.0
Sum Reward: 749.0
Avg Reward: 249.66666666666666
Min Reward: 224.0
Max Reward: 276.0
Gini Coefficient: 0.046283934134401426
20:20 Ratio: 1.2321428571428572
Max-min Ratio: 1.2321428571428572
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-00-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1083.93
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 355
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.909
    dispatch_time_ms: 7.74
    learner:
      cur_lr: 0.001289071049541235
      grad_gnorm: 9.488297462463379
      policy_entropy: 7.071598052978516
      policy_loss: 2.320053815841675
      var_gnorm: 40.19415283203125
      vf_explained_var: 0.053471386432647705
      vf_loss: 23.25428009033203
    num_steps_sampled: 1068000
    num_steps_trained: 1068000
    wait_time_ms: 70.111
  iterations_since_restore: 356
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3070.2554244995117
  time_this_iter_s: 7.956543207168579
  time_total_s: 3070.2554244995117
  timestamp: 1594090839
  timesteps_since_restore: 1068000
  timesteps_this_iter: 3000
  timesteps_total: 1068000
  training_iteration: 356
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3070 s, 356 iter, 1068000 ts, 1.08e+03 rew

agent-1: 286.0
agent-2: 295.0
agent-3: 305.0
Sum Reward: 886.0
Avg Reward: 295.3333333333333
Min Reward: 286.0
Max Reward: 305.0
Gini Coefficient: 0.014296463506395787
20:20 Ratio: 1.0664335664335665
Max-min Ratio: 1.0664335664335665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-00-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1081.63
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 356
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.124
    dispatch_time_ms: 6.965
    learner:
      cur_lr: 0.0012888711644336581
      grad_gnorm: 39.999996185302734
      policy_entropy: 9.588911056518555
      policy_loss: 12.563450813293457
      var_gnorm: 40.236846923828125
      vf_explained_var: 0.3408333659172058
      vf_loss: 46.51607894897461
    num_steps_sampled: 1071000
    num_steps_trained: 1071000
    wait_time_ms: 72.64
  iterations_since_restore: 357
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3078.248622894287
  time_this_iter_s: 7.993198394775391
  time_total_s: 3078.248622894287
  timestamp: 1594090847
  timesteps_since_restore: 1071000
  timesteps_this_iter: 3000
  timesteps_total: 1071000
  training_iteration: 357
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3078 s, 357 iter, 1071000 ts, 1.08e+03 rew

agent-1: 320.0
agent-2: 370.0
agent-3: 330.0
Sum Reward: 1020.0
Avg Reward: 340.0
Min Reward: 320.0
Max Reward: 370.0
Gini Coefficient: 0.032679738562091505
20:20 Ratio: 1.15625
Max-min Ratio: 1.15625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-00-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1080.12
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 357
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.91
    dispatch_time_ms: 17.51
    learner:
      cur_lr: 0.001288671395741403
      grad_gnorm: 40.0
      policy_entropy: 17.64073944091797
      policy_loss: -8.040990829467773
      var_gnorm: 40.28833770751953
      vf_explained_var: 0.23741626739501953
      vf_loss: 23.751754760742188
    num_steps_sampled: 1074000
    num_steps_trained: 1074000
    wait_time_ms: 73.952
  iterations_since_restore: 358
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3086.7714562416077
  time_this_iter_s: 8.522833347320557
  time_total_s: 3086.7714562416077
  timestamp: 1594090855
  timesteps_since_restore: 1074000
  timesteps_this_iter: 3000
  timesteps_total: 1074000
  training_iteration: 358
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3086 s, 358 iter, 1074000 ts, 1.08e+03 rew

agent-1: 278.0
agent-2: 248.0
agent-3: 302.0
Sum Reward: 828.0
Avg Reward: 276.0
Min Reward: 248.0
Max Reward: 302.0
Gini Coefficient: 0.043478260869565216
20:20 Ratio: 1.217741935483871
Max-min Ratio: 1.217741935483871
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-01-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1077.37
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 358
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.681
    dispatch_time_ms: 31.351
    learner:
      cur_lr: 0.001288471627049148
      grad_gnorm: 40.0
      policy_entropy: 16.2480411529541
      policy_loss: -24.74649429321289
      var_gnorm: 40.29226303100586
      vf_explained_var: -0.5041749477386475
      vf_loss: 34.18119812011719
    num_steps_sampled: 1077000
    num_steps_trained: 1077000
    wait_time_ms: 31.413
  iterations_since_restore: 359
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3095.277200937271
  time_this_iter_s: 8.505744695663452
  time_total_s: 3095.277200937271
  timestamp: 1594090864
  timesteps_since_restore: 1077000
  timesteps_this_iter: 3000
  timesteps_total: 1077000
  training_iteration: 359
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3095 s, 359 iter, 1077000 ts, 1.08e+03 rew

agent-1: 310.0
agent-2: 310.0
agent-3: 221.0
Sum Reward: 841.0
Avg Reward: 280.3333333333333
Min Reward: 221.0
Max Reward: 310.0
Gini Coefficient: 0.07055093143083631
20:20 Ratio: 1.4027149321266967
Max-min Ratio: 1.4027149321266967
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-01-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1074.74
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 359
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.673
    dispatch_time_ms: 30.024
    learner:
      cur_lr: 0.0012882717419415712
      grad_gnorm: 40.0
      policy_entropy: 13.325895309448242
      policy_loss: 9.14256763458252
      var_gnorm: 40.3435173034668
      vf_explained_var: -1.0
      vf_loss: 21.408405303955078
    num_steps_sampled: 1080000
    num_steps_trained: 1080000
    wait_time_ms: 41.176
  iterations_since_restore: 360
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3104.298409461975
  time_this_iter_s: 9.02120852470398
  time_total_s: 3104.298409461975
  timestamp: 1594090873
  timesteps_since_restore: 1080000
  timesteps_this_iter: 3000
  timesteps_total: 1080000
  training_iteration: 360
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3104 s, 360 iter, 1080000 ts, 1.07e+03 rew

agent-1: 253.0
agent-2: 301.0
agent-3: 198.0
Sum Reward: 752.0
Avg Reward: 250.66666666666666
Min Reward: 198.0
Max Reward: 301.0
Gini Coefficient: 0.09131205673758866
20:20 Ratio: 1.52020202020202
Max-min Ratio: 1.52020202020202
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-01-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1071.39
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 360
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.156
    dispatch_time_ms: 16.777
    learner:
      cur_lr: 0.0012880719732493162
      grad_gnorm: 40.000003814697266
      policy_entropy: 9.526327133178711
      policy_loss: -13.396259307861328
      var_gnorm: 40.330055236816406
      vf_explained_var: 0.028357267379760742
      vf_loss: 23.964513778686523
    num_steps_sampled: 1083000
    num_steps_trained: 1083000
    wait_time_ms: 62.402
  iterations_since_restore: 361
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3112.0023300647736
  time_this_iter_s: 7.703920602798462
  time_total_s: 3112.0023300647736
  timestamp: 1594090881
  timesteps_since_restore: 1083000
  timesteps_this_iter: 3000
  timesteps_total: 1083000
  training_iteration: 361
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3112 s, 361 iter, 1083000 ts, 1.07e+03 rew

agent-1: 218.0
agent-2: 233.0
agent-3: 234.0
Sum Reward: 685.0
Avg Reward: 228.33333333333334
Min Reward: 218.0
Max Reward: 234.0
Gini Coefficient: 0.015571776155717762
20:20 Ratio: 1.073394495412844
Max-min Ratio: 1.073394495412844
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-01-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1067.25
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 361
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.704
    dispatch_time_ms: 27.277
    learner:
      cur_lr: 0.0012878722045570612
      grad_gnorm: 38.522056579589844
      policy_entropy: 13.790361404418945
      policy_loss: -4.593565940856934
      var_gnorm: 40.34537887573242
      vf_explained_var: 0.044970035552978516
      vf_loss: 22.68254852294922
    num_steps_sampled: 1086000
    num_steps_trained: 1086000
    wait_time_ms: 53.76
  iterations_since_restore: 362
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3120.252444267273
  time_this_iter_s: 8.25011420249939
  time_total_s: 3120.252444267273
  timestamp: 1594090889
  timesteps_since_restore: 1086000
  timesteps_this_iter: 3000
  timesteps_total: 1086000
  training_iteration: 362
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3120 s, 362 iter, 1086000 ts, 1.07e+03 rew

agent-1: 141.0
agent-2: 281.0
agent-3: 195.0
Sum Reward: 617.0
Avg Reward: 205.66666666666666
Min Reward: 141.0
Max Reward: 281.0
Gini Coefficient: 0.151269584008644
20:20 Ratio: 1.9929078014184398
Max-min Ratio: 1.9929078014184398
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-01-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1061.99
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 362
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.349
    dispatch_time_ms: 19.908
    learner:
      cur_lr: 0.0012876724358648062
      grad_gnorm: 8.581399917602539
      policy_entropy: 7.587002277374268
      policy_loss: -1.9504096508026123
      var_gnorm: 40.3519287109375
      vf_explained_var: 0.3288572430610657
      vf_loss: 10.708914756774902
    num_steps_sampled: 1089000
    num_steps_trained: 1089000
    wait_time_ms: 58.589
  iterations_since_restore: 363
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3128.2171437740326
  time_this_iter_s: 7.9646995067596436
  time_total_s: 3128.2171437740326
  timestamp: 1594090897
  timesteps_since_restore: 1089000
  timesteps_this_iter: 3000
  timesteps_total: 1089000
  training_iteration: 363
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3128 s, 363 iter, 1089000 ts, 1.06e+03 rew

agent-1: 205.0
agent-2: 285.0
agent-3: 140.0
Sum Reward: 630.0
Avg Reward: 210.0
Min Reward: 140.0
Max Reward: 285.0
Gini Coefficient: 0.15343915343915343
20:20 Ratio: 2.0357142857142856
Max-min Ratio: 2.0357142857142856
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-01-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1056.65
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 363
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.065
    dispatch_time_ms: 17.039
    learner:
      cur_lr: 0.0012874725507572293
      grad_gnorm: 40.0
      policy_entropy: 10.085543632507324
      policy_loss: 12.2401123046875
      var_gnorm: 40.34056854248047
      vf_explained_var: 0.1664089560508728
      vf_loss: 29.9566593170166
    num_steps_sampled: 1092000
    num_steps_trained: 1092000
    wait_time_ms: 58.507
  iterations_since_restore: 364
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3136.4299619197845
  time_this_iter_s: 8.212818145751953
  time_total_s: 3136.4299619197845
  timestamp: 1594090905
  timesteps_since_restore: 1092000
  timesteps_this_iter: 3000
  timesteps_total: 1092000
  training_iteration: 364
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3136 s, 364 iter, 1092000 ts, 1.06e+03 rew

agent-1: 253.0
agent-2: 242.0
agent-3: 204.0
Sum Reward: 699.0
Avg Reward: 233.0
Min Reward: 204.0
Max Reward: 253.0
Gini Coefficient: 0.04673342870767763
20:20 Ratio: 1.2401960784313726
Max-min Ratio: 1.2401960784313726
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-01-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1052.48
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 364
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.687
    dispatch_time_ms: 28.08
    learner:
      cur_lr: 0.0012872727820649743
      grad_gnorm: 28.438867568969727
      policy_entropy: 9.916009902954102
      policy_loss: 3.475998878479004
      var_gnorm: 40.3924674987793
      vf_explained_var: -0.39101672172546387
      vf_loss: 21.732847213745117
    num_steps_sampled: 1095000
    num_steps_trained: 1095000
    wait_time_ms: 65.633
  iterations_since_restore: 365
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3144.847349882126
  time_this_iter_s: 8.417387962341309
  time_total_s: 3144.847349882126
  timestamp: 1594090914
  timesteps_since_restore: 1095000
  timesteps_this_iter: 3000
  timesteps_total: 1095000
  training_iteration: 365
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3144 s, 365 iter, 1095000 ts, 1.05e+03 rew

agent-1: 335.0
agent-2: 385.0
agent-3: 297.0
Sum Reward: 1017.0
Avg Reward: 339.0
Min Reward: 297.0
Max Reward: 385.0
Gini Coefficient: 0.057686004588659454
20:20 Ratio: 1.2962962962962963
Max-min Ratio: 1.2962962962962963
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-02-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1051.29
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 365
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.633
    dispatch_time_ms: 5.321
    learner:
      cur_lr: 0.0012870730133727193
      grad_gnorm: 40.0
      policy_entropy: 13.662029266357422
      policy_loss: -12.886451721191406
      var_gnorm: 40.47358703613281
      vf_explained_var: -0.0008842945098876953
      vf_loss: 23.444683074951172
    num_steps_sampled: 1098000
    num_steps_trained: 1098000
    wait_time_ms: 69.136
  iterations_since_restore: 366
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3153.0865194797516
  time_this_iter_s: 8.239169597625732
  time_total_s: 3153.0865194797516
  timestamp: 1594090922
  timesteps_since_restore: 1098000
  timesteps_this_iter: 3000
  timesteps_total: 1098000
  training_iteration: 366
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3153 s, 366 iter, 1098000 ts, 1.05e+03 rew

agent-1: 245.0
agent-2: 349.0
agent-3: 241.0
Sum Reward: 835.0
Avg Reward: 278.3333333333333
Min Reward: 241.0
Max Reward: 349.0
Gini Coefficient: 0.08622754491017964
20:20 Ratio: 1.4481327800829875
Max-min Ratio: 1.4481327800829875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-02-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1049.0
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 366
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.16
    dispatch_time_ms: 8.996
    learner:
      cur_lr: 0.0012868732446804643
      grad_gnorm: 23.064105987548828
      policy_entropy: 8.648563385009766
      policy_loss: 1.3282480239868164
      var_gnorm: 40.449153900146484
      vf_explained_var: 0.09175300598144531
      vf_loss: 23.36166000366211
    num_steps_sampled: 1101000
    num_steps_trained: 1101000
    wait_time_ms: 61.97
  iterations_since_restore: 367
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3160.4092421531677
  time_this_iter_s: 7.322722673416138
  time_total_s: 3160.4092421531677
  timestamp: 1594090929
  timesteps_since_restore: 1101000
  timesteps_this_iter: 3000
  timesteps_total: 1101000
  training_iteration: 367
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3160 s, 367 iter, 1101000 ts, 1.05e+03 rew

agent-1: 190.0
agent-2: 183.0
agent-3: 117.0
Sum Reward: 490.0
Avg Reward: 163.33333333333334
Min Reward: 117.0
Max Reward: 190.0
Gini Coefficient: 0.09931972789115646
20:20 Ratio: 1.623931623931624
Max-min Ratio: 1.623931623931624
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-02-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1043.11
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 367
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.005
    dispatch_time_ms: 7.412
    learner:
      cur_lr: 0.0012866733595728874
      grad_gnorm: 40.0
      policy_entropy: 22.607162475585938
      policy_loss: -12.502245903015137
      var_gnorm: 40.4359245300293
      vf_explained_var: 2.855062484741211e-05
      vf_loss: 15.395380973815918
    num_steps_sampled: 1104000
    num_steps_trained: 1104000
    wait_time_ms: 66.853
  iterations_since_restore: 368
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3168.0797855854034
  time_this_iter_s: 7.670543432235718
  time_total_s: 3168.0797855854034
  timestamp: 1594090937
  timesteps_since_restore: 1104000
  timesteps_this_iter: 3000
  timesteps_total: 1104000
  training_iteration: 368
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3168 s, 368 iter, 1104000 ts, 1.04e+03 rew

agent-1: 172.0
agent-2: 243.0
agent-3: 167.0
Sum Reward: 582.0
Avg Reward: 194.0
Min Reward: 167.0
Max Reward: 243.0
Gini Coefficient: 0.08705612829324169
20:20 Ratio: 1.4550898203592815
Max-min Ratio: 1.4550898203592815
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-02-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1037.68
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 368
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.545
    dispatch_time_ms: 6.099
    learner:
      cur_lr: 0.0012864735908806324
      grad_gnorm: 40.000003814697266
      policy_entropy: 21.488739013671875
      policy_loss: 33.01951217651367
      var_gnorm: 40.440589904785156
      vf_explained_var: 0.022054314613342285
      vf_loss: 39.3875846862793
    num_steps_sampled: 1107000
    num_steps_trained: 1107000
    wait_time_ms: 72.812
  iterations_since_restore: 369
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3176.071328639984
  time_this_iter_s: 7.9915430545806885
  time_total_s: 3176.071328639984
  timestamp: 1594090945
  timesteps_since_restore: 1107000
  timesteps_this_iter: 3000
  timesteps_total: 1107000
  training_iteration: 369
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3176 s, 369 iter, 1107000 ts, 1.04e+03 rew

agent-1: 296.0
agent-2: 253.0
agent-3: 268.0
Sum Reward: 817.0
Avg Reward: 272.3333333333333
Min Reward: 253.0
Max Reward: 296.0
Gini Coefficient: 0.03508771929824561
20:20 Ratio: 1.1699604743083003
Max-min Ratio: 1.1699604743083003
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-02-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1034.76
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 369
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.642
    dispatch_time_ms: 6.271
    learner:
      cur_lr: 0.0012862738221883774
      grad_gnorm: 40.0
      policy_entropy: 5.069525241851807
      policy_loss: 5.685342788696289
      var_gnorm: 40.43222427368164
      vf_explained_var: 0.39903610944747925
      vf_loss: 33.81266403198242
    num_steps_sampled: 1110000
    num_steps_trained: 1110000
    wait_time_ms: 77.437
  iterations_since_restore: 370
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3184.386862039566
  time_this_iter_s: 8.31553339958191
  time_total_s: 3184.386862039566
  timestamp: 1594090954
  timesteps_since_restore: 1110000
  timesteps_this_iter: 3000
  timesteps_total: 1110000
  training_iteration: 370
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3184 s, 370 iter, 1110000 ts, 1.03e+03 rew

agent-1: 270.0
agent-2: 281.0
agent-3: 324.0
Sum Reward: 875.0
Avg Reward: 291.6666666666667
Min Reward: 270.0
Max Reward: 324.0
Gini Coefficient: 0.04114285714285714
20:20 Ratio: 1.2
Max-min Ratio: 1.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-02-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1033.03
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 370
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.891
    dispatch_time_ms: 5.231
    learner:
      cur_lr: 0.0012860740534961224
      grad_gnorm: 27.94308853149414
      policy_entropy: 9.381784439086914
      policy_loss: 8.131117820739746
      var_gnorm: 40.467689514160156
      vf_explained_var: 0.212119460105896
      vf_loss: 42.23802947998047
    num_steps_sampled: 1113000
    num_steps_trained: 1113000
    wait_time_ms: 89.05
  iterations_since_restore: 371
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3193.1835355758667
  time_this_iter_s: 8.79667353630066
  time_total_s: 3193.1835355758667
  timestamp: 1594090962
  timesteps_since_restore: 1113000
  timesteps_this_iter: 3000
  timesteps_total: 1113000
  training_iteration: 371
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3193 s, 371 iter, 1113000 ts, 1.03e+03 rew

agent-1: 322.0
agent-2: 311.0
agent-3: 355.0
Sum Reward: 988.0
Avg Reward: 329.3333333333333
Min Reward: 311.0
Max Reward: 355.0
Gini Coefficient: 0.029689608636977057
20:20 Ratio: 1.1414790996784565
Max-min Ratio: 1.1414790996784565
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-02-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1032.24
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 371
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.53
    dispatch_time_ms: 6.358
    learner:
      cur_lr: 0.0012858741683885455
      grad_gnorm: 30.21152114868164
      policy_entropy: 7.663153171539307
      policy_loss: 6.420044898986816
      var_gnorm: 40.46863555908203
      vf_explained_var: -0.1968621015548706
      vf_loss: 21.283733367919922
    num_steps_sampled: 1116000
    num_steps_trained: 1116000
    wait_time_ms: 73.95
  iterations_since_restore: 372
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3202.233498573303
  time_this_iter_s: 9.049962997436523
  time_total_s: 3202.233498573303
  timestamp: 1594090971
  timesteps_since_restore: 1116000
  timesteps_this_iter: 3000
  timesteps_total: 1116000
  training_iteration: 372
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3202 s, 372 iter, 1116000 ts, 1.03e+03 rew

agent-1: 406.0
agent-2: 340.0
agent-3: 403.0
Sum Reward: 1149.0
Avg Reward: 383.0
Min Reward: 340.0
Max Reward: 406.0
Gini Coefficient: 0.038294168842471714
20:20 Ratio: 1.1941176470588235
Max-min Ratio: 1.1941176470588235
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-03-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1032.4
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 372
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.776
    dispatch_time_ms: 9.438
    learner:
      cur_lr: 0.0012856743996962905
      grad_gnorm: 21.046733856201172
      policy_entropy: 10.401501655578613
      policy_loss: -8.997016906738281
      var_gnorm: 40.55553436279297
      vf_explained_var: 0.3365008234977722
      vf_loss: 37.798057556152344
    num_steps_sampled: 1119000
    num_steps_trained: 1119000
    wait_time_ms: 80.181
  iterations_since_restore: 373
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3211.1450185775757
  time_this_iter_s: 8.911520004272461
  time_total_s: 3211.1450185775757
  timestamp: 1594090980
  timesteps_since_restore: 1119000
  timesteps_this_iter: 3000
  timesteps_total: 1119000
  training_iteration: 373
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3211 s, 373 iter, 1119000 ts, 1.03e+03 rew

agent-1: 411.0
agent-2: 361.0
agent-3: 415.0
Sum Reward: 1187.0
Avg Reward: 395.6666666666667
Min Reward: 361.0
Max Reward: 415.0
Gini Coefficient: 0.030328559393428812
20:20 Ratio: 1.149584487534626
Max-min Ratio: 1.149584487534626
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-03-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1032.89
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 373
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.076
    dispatch_time_ms: 5.871
    learner:
      cur_lr: 0.0012854746310040355
      grad_gnorm: 39.999996185302734
      policy_entropy: 8.82978630065918
      policy_loss: -6.523509502410889
      var_gnorm: 40.69610595703125
      vf_explained_var: 0.19590258598327637
      vf_loss: 18.788814544677734
    num_steps_sampled: 1122000
    num_steps_trained: 1122000
    wait_time_ms: 84.218
  iterations_since_restore: 374
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3222.771071910858
  time_this_iter_s: 11.62605333328247
  time_total_s: 3222.771071910858
  timestamp: 1594090992
  timesteps_since_restore: 1122000
  timesteps_this_iter: 3000
  timesteps_total: 1122000
  training_iteration: 374
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3222 s, 374 iter, 1122000 ts, 1.03e+03 rew

agent-1: 377.0
agent-2: 323.0
agent-3: 394.0
Sum Reward: 1094.0
Avg Reward: 364.6666666666667
Min Reward: 323.0
Max Reward: 394.0
Gini Coefficient: 0.043266301035953685
20:20 Ratio: 1.2198142414860682
Max-min Ratio: 1.2198142414860682
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-03-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: 1032.84
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 374
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.443
    dispatch_time_ms: 5.789
    learner:
      cur_lr: 0.0012852747458964586
      grad_gnorm: 40.0
      policy_entropy: 8.278950691223145
      policy_loss: 9.0785551071167
      var_gnorm: 40.74653244018555
      vf_explained_var: 0.1892833113670349
      vf_loss: 48.37763214111328
    num_steps_sampled: 1125000
    num_steps_trained: 1125000
    wait_time_ms: 85.403
  iterations_since_restore: 375
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3231.697306871414
  time_this_iter_s: 8.92623496055603
  time_total_s: 3231.697306871414
  timestamp: 1594091001
  timesteps_since_restore: 1125000
  timesteps_this_iter: 3000
  timesteps_total: 1125000
  training_iteration: 375
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3231 s, 375 iter, 1125000 ts, 1.03e+03 rew

agent-1: 424.0
agent-2: 393.0
agent-3: 447.0
Sum Reward: 1264.0
Avg Reward: 421.3333333333333
Min Reward: 393.0
Max Reward: 447.0
Gini Coefficient: 0.028481012658227847
20:20 Ratio: 1.1374045801526718
Max-min Ratio: 1.1374045801526718
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-03-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 1035.0
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 375
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.506
    dispatch_time_ms: 8.385
    learner:
      cur_lr: 0.0012850749772042036
      grad_gnorm: 39.999996185302734
      policy_entropy: 6.674005508422852
      policy_loss: 11.334157943725586
      var_gnorm: 40.773651123046875
      vf_explained_var: -0.6219640970230103
      vf_loss: 51.66781997680664
    num_steps_sampled: 1128000
    num_steps_trained: 1128000
    wait_time_ms: 75.537
  iterations_since_restore: 376
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3240.5478336811066
  time_this_iter_s: 8.850526809692383
  time_total_s: 3240.5478336811066
  timestamp: 1594091010
  timesteps_since_restore: 1128000
  timesteps_this_iter: 3000
  timesteps_total: 1128000
  training_iteration: 376
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3240 s, 376 iter, 1128000 ts, 1.04e+03 rew

agent-1: 432.0
agent-2: 346.0
agent-3: 401.0
Sum Reward: 1179.0
Avg Reward: 393.0
Min Reward: 346.0
Max Reward: 432.0
Gini Coefficient: 0.04862878145320893
20:20 Ratio: 1.2485549132947977
Max-min Ratio: 1.2485549132947977
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-03-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 1035.4
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 376
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.56
    dispatch_time_ms: 6.371
    learner:
      cur_lr: 0.0012848752085119486
      grad_gnorm: 33.56797409057617
      policy_entropy: 6.559378623962402
      policy_loss: 8.342809677124023
      var_gnorm: 40.852298736572266
      vf_explained_var: 0.014682948589324951
      vf_loss: 51.93233871459961
    num_steps_sampled: 1131000
    num_steps_trained: 1131000
    wait_time_ms: 81.855
  iterations_since_restore: 377
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3249.2447855472565
  time_this_iter_s: 8.696951866149902
  time_total_s: 3249.2447855472565
  timestamp: 1594091019
  timesteps_since_restore: 1131000
  timesteps_this_iter: 3000
  timesteps_total: 1131000
  training_iteration: 377
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3249 s, 377 iter, 1131000 ts, 1.04e+03 rew

agent-1: 419.0
agent-2: 355.0
agent-3: 431.0
Sum Reward: 1205.0
Avg Reward: 401.6666666666667
Min Reward: 355.0
Max Reward: 431.0
Gini Coefficient: 0.04204702627939143
20:20 Ratio: 1.2140845070422535
Max-min Ratio: 1.2140845070422535
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-03-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 1036.52
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 377
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.204
    dispatch_time_ms: 6.668
    learner:
      cur_lr: 0.0012846754398196936
      grad_gnorm: 13.009218215942383
      policy_entropy: 7.608211517333984
      policy_loss: 0.2756165564060211
      var_gnorm: 40.87609100341797
      vf_explained_var: 0.7869572639465332
      vf_loss: 19.768447875976562
    num_steps_sampled: 1134000
    num_steps_trained: 1134000
    wait_time_ms: 73.42
  iterations_since_restore: 378
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3258.3337008953094
  time_this_iter_s: 9.088915348052979
  time_total_s: 3258.3337008953094
  timestamp: 1594091028
  timesteps_since_restore: 1134000
  timesteps_this_iter: 3000
  timesteps_total: 1134000
  training_iteration: 378
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3258 s, 378 iter, 1134000 ts, 1.04e+03 rew

agent-1: 407.0
agent-2: 381.0
agent-3: 430.0
Sum Reward: 1218.0
Avg Reward: 406.0
Min Reward: 381.0
Max Reward: 430.0
Gini Coefficient: 0.02681992337164751
20:20 Ratio: 1.1286089238845145
Max-min Ratio: 1.1286089238845145
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-03-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 1037.08
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 378
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.963
    dispatch_time_ms: 5.783
    learner:
      cur_lr: 0.0012844755547121167
      grad_gnorm: 40.0
      policy_entropy: 6.257180690765381
      policy_loss: 7.902861595153809
      var_gnorm: 40.95452117919922
      vf_explained_var: 0.5651335716247559
      vf_loss: 10.592497825622559
    num_steps_sampled: 1137000
    num_steps_trained: 1137000
    wait_time_ms: 81.733
  iterations_since_restore: 379
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3266.87154340744
  time_this_iter_s: 8.537842512130737
  time_total_s: 3266.87154340744
  timestamp: 1594091036
  timesteps_since_restore: 1137000
  timesteps_this_iter: 3000
  timesteps_total: 1137000
  training_iteration: 379
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3266 s, 379 iter, 1137000 ts, 1.04e+03 rew

agent-1: 423.0
agent-2: 375.0
agent-3: 459.0
Sum Reward: 1257.0
Avg Reward: 419.0
Min Reward: 375.0
Max Reward: 459.0
Gini Coefficient: 0.04455051710421639
20:20 Ratio: 1.224
Max-min Ratio: 1.224
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-04-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 1037.97
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 379
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.733
    dispatch_time_ms: 5.126
    learner:
      cur_lr: 0.0012842757860198617
      grad_gnorm: 40.0
      policy_entropy: 5.670039653778076
      policy_loss: -6.228638648986816
      var_gnorm: 41.0520133972168
      vf_explained_var: -0.08565020561218262
      vf_loss: 37.04441833496094
    num_steps_sampled: 1140000
    num_steps_trained: 1140000
    wait_time_ms: 76.977
  iterations_since_restore: 380
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3275.719179391861
  time_this_iter_s: 8.847635984420776
  time_total_s: 3275.719179391861
  timestamp: 1594091045
  timesteps_since_restore: 1140000
  timesteps_this_iter: 3000
  timesteps_total: 1140000
  training_iteration: 380
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3275 s, 380 iter, 1140000 ts, 1.04e+03 rew

agent-1: 406.0
agent-2: 407.0
agent-3: 411.0
Sum Reward: 1224.0
Avg Reward: 408.0
Min Reward: 406.0
Max Reward: 411.0
Gini Coefficient: 0.0027233115468409588
20:20 Ratio: 1.0123152709359606
Max-min Ratio: 1.0123152709359606
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-04-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 1039.19
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 380
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.513
    dispatch_time_ms: 7.135
    learner:
      cur_lr: 0.0012840760173276067
      grad_gnorm: 15.750924110412598
      policy_entropy: 5.741873741149902
      policy_loss: 1.7102530002593994
      var_gnorm: 41.03483200073242
      vf_explained_var: -0.09038114547729492
      vf_loss: 49.415130615234375
    num_steps_sampled: 1143000
    num_steps_trained: 1143000
    wait_time_ms: 79.913
  iterations_since_restore: 381
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3284.41020154953
  time_this_iter_s: 8.691022157669067
  time_total_s: 3284.41020154953
  timestamp: 1594091054
  timesteps_since_restore: 1143000
  timesteps_this_iter: 3000
  timesteps_total: 1143000
  training_iteration: 381
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3284 s, 381 iter, 1143000 ts, 1.04e+03 rew

agent-1: 418.0
agent-2: 374.0
agent-3: 413.0
Sum Reward: 1205.0
Avg Reward: 401.6666666666667
Min Reward: 374.0
Max Reward: 418.0
Gini Coefficient: 0.02434301521438451
20:20 Ratio: 1.1176470588235294
Max-min Ratio: 1.1176470588235294
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-04-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 1040.64
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 381
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.47
    dispatch_time_ms: 5.929
    learner:
      cur_lr: 0.0012838762486353517
      grad_gnorm: 27.03142547607422
      policy_entropy: 7.3004631996154785
      policy_loss: -0.2987256944179535
      var_gnorm: 41.17115020751953
      vf_explained_var: -0.14350569248199463
      vf_loss: 24.115875244140625
    num_steps_sampled: 1146000
    num_steps_trained: 1146000
    wait_time_ms: 82.176
  iterations_since_restore: 382
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3293.7113695144653
  time_this_iter_s: 9.301167964935303
  time_total_s: 3293.7113695144653
  timestamp: 1594091063
  timesteps_since_restore: 1146000
  timesteps_this_iter: 3000
  timesteps_total: 1146000
  training_iteration: 382
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3293 s, 382 iter, 1146000 ts, 1.04e+03 rew

agent-1: 417.0
agent-2: 412.0
agent-3: 426.0
Sum Reward: 1255.0
Avg Reward: 418.3333333333333
Min Reward: 412.0
Max Reward: 426.0
Gini Coefficient: 0.007436918990703851
20:20 Ratio: 1.0339805825242718
Max-min Ratio: 1.0339805825242718
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-04-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 1042.51
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 382
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.521
    dispatch_time_ms: 5.558
    learner:
      cur_lr: 0.0012836763635277748
      grad_gnorm: 40.0
      policy_entropy: 11.579501152038574
      policy_loss: -8.903793334960938
      var_gnorm: 41.238460540771484
      vf_explained_var: -0.24548876285552979
      vf_loss: 34.479305267333984
    num_steps_sampled: 1149000
    num_steps_trained: 1149000
    wait_time_ms: 81.434
  iterations_since_restore: 383
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3302.38947725296
  time_this_iter_s: 8.678107738494873
  time_total_s: 3302.38947725296
  timestamp: 1594091072
  timesteps_since_restore: 1149000
  timesteps_this_iter: 3000
  timesteps_total: 1149000
  training_iteration: 383
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3302 s, 383 iter, 1149000 ts, 1.04e+03 rew

agent-1: 368.0
agent-2: 355.0
agent-3: 354.0
Sum Reward: 1077.0
Avg Reward: 359.0
Min Reward: 354.0
Max Reward: 368.0
Gini Coefficient: 0.008666047663262148
20:20 Ratio: 1.03954802259887
Max-min Ratio: 1.03954802259887
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-04-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 1041.88
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 383
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.474
    dispatch_time_ms: 21.042
    learner:
      cur_lr: 0.0012834765948355198
      grad_gnorm: 40.0
      policy_entropy: 21.75676155090332
      policy_loss: -26.099742889404297
      var_gnorm: 41.2059326171875
      vf_explained_var: -0.11398696899414062
      vf_loss: 42.93696594238281
    num_steps_sampled: 1152000
    num_steps_trained: 1152000
    wait_time_ms: 61.901
  iterations_since_restore: 384
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3311.289800643921
  time_this_iter_s: 8.900323390960693
  time_total_s: 3311.289800643921
  timestamp: 1594091081
  timesteps_since_restore: 1152000
  timesteps_this_iter: 3000
  timesteps_total: 1152000
  training_iteration: 384
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3311 s, 384 iter, 1152000 ts, 1.04e+03 rew

agent-1: 360.0
agent-2: 321.0
agent-3: 332.0
Sum Reward: 1013.0
Avg Reward: 337.6666666666667
Min Reward: 321.0
Max Reward: 360.0
Gini Coefficient: 0.02566633761105627
20:20 Ratio: 1.1214953271028036
Max-min Ratio: 1.1214953271028036
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-04-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 1040.47
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 384
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.638
    dispatch_time_ms: 34.988
    learner:
      cur_lr: 0.0012832768261432648
      grad_gnorm: 14.346795082092285
      policy_entropy: 12.710428237915039
      policy_loss: -3.989881992340088
      var_gnorm: 41.187904357910156
      vf_explained_var: 0.11538118124008179
      vf_loss: 11.446258544921875
    num_steps_sampled: 1155000
    num_steps_trained: 1155000
    wait_time_ms: 46.413
  iterations_since_restore: 385
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3319.6877806186676
  time_this_iter_s: 8.397979974746704
  time_total_s: 3319.6877806186676
  timestamp: 1594091089
  timesteps_since_restore: 1155000
  timesteps_this_iter: 3000
  timesteps_total: 1155000
  training_iteration: 385
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3319 s, 385 iter, 1155000 ts, 1.04e+03 rew

agent-1: 315.0
agent-2: 347.0
agent-3: 346.0
Sum Reward: 1008.0
Avg Reward: 336.0
Min Reward: 315.0
Max Reward: 347.0
Gini Coefficient: 0.021164021164021163
20:20 Ratio: 1.1015873015873017
Max-min Ratio: 1.1015873015873017
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-04-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 1039.11
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 385
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.535
    dispatch_time_ms: 27.98
    learner:
      cur_lr: 0.0012830770574510098
      grad_gnorm: 40.0
      policy_entropy: 7.9334821701049805
      policy_loss: 11.77955436706543
      var_gnorm: 41.23478698730469
      vf_explained_var: 0.009944260120391846
      vf_loss: 45.59834289550781
    num_steps_sampled: 1158000
    num_steps_trained: 1158000
    wait_time_ms: 55.281
  iterations_since_restore: 386
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3328.3885765075684
  time_this_iter_s: 8.700795888900757
  time_total_s: 3328.3885765075684
  timestamp: 1594091098
  timesteps_since_restore: 1158000
  timesteps_this_iter: 3000
  timesteps_total: 1158000
  training_iteration: 386
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3328 s, 386 iter, 1158000 ts, 1.04e+03 rew

agent-1: 331.0
agent-2: 348.0
agent-3: 340.0
Sum Reward: 1019.0
Avg Reward: 339.6666666666667
Min Reward: 331.0
Max Reward: 348.0
Gini Coefficient: 0.011122015047432123
20:20 Ratio: 1.051359516616314
Max-min Ratio: 1.051359516616314
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-05-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 1037.35
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 386
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.611
    dispatch_time_ms: 26.068
    learner:
      cur_lr: 0.001282877172343433
      grad_gnorm: 19.727380752563477
      policy_entropy: 9.480056762695312
      policy_loss: 4.410339832305908
      var_gnorm: 41.27461624145508
      vf_explained_var: -0.3412292003631592
      vf_loss: 8.77123737335205
    num_steps_sampled: 1161000
    num_steps_trained: 1161000
    wait_time_ms: 64.531
  iterations_since_restore: 387
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3337.0933990478516
  time_this_iter_s: 8.704822540283203
  time_total_s: 3337.0933990478516
  timestamp: 1594091107
  timesteps_since_restore: 1161000
  timesteps_this_iter: 3000
  timesteps_total: 1161000
  training_iteration: 387
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3337 s, 387 iter, 1161000 ts, 1.04e+03 rew

agent-1: 317.0
agent-2: 298.0
agent-3: 311.0
Sum Reward: 926.0
Avg Reward: 308.6666666666667
Min Reward: 298.0
Max Reward: 317.0
Gini Coefficient: 0.013678905687544997
20:20 Ratio: 1.063758389261745
Max-min Ratio: 1.063758389261745
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-05-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 1035.09
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 387
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.747
    dispatch_time_ms: 31.266
    learner:
      cur_lr: 0.0012826774036511779
      grad_gnorm: 40.0
      policy_entropy: 7.479066371917725
      policy_loss: 1.0277999639511108
      var_gnorm: 41.31820297241211
      vf_explained_var: 0.09295690059661865
      vf_loss: 39.90803146362305
    num_steps_sampled: 1164000
    num_steps_trained: 1164000
    wait_time_ms: 46.026
  iterations_since_restore: 388
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3345.616790533066
  time_this_iter_s: 8.523391485214233
  time_total_s: 3345.616790533066
  timestamp: 1594091115
  timesteps_since_restore: 1164000
  timesteps_this_iter: 3000
  timesteps_total: 1164000
  training_iteration: 388
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3345 s, 388 iter, 1164000 ts, 1.04e+03 rew

agent-1: 331.0
agent-2: 321.0
agent-3: 320.0
Sum Reward: 972.0
Avg Reward: 324.0
Min Reward: 320.0
Max Reward: 331.0
Gini Coefficient: 0.0075445816186556925
20:20 Ratio: 1.034375
Max-min Ratio: 1.034375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-05-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 1032.94
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 388
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.774
    dispatch_time_ms: 22.903
    learner:
      cur_lr: 0.0012824776349589229
      grad_gnorm: 39.999996185302734
      policy_entropy: 15.156110763549805
      policy_loss: -26.914777755737305
      var_gnorm: 41.29082107543945
      vf_explained_var: 0.0001494884490966797
      vf_loss: 59.7276725769043
    num_steps_sampled: 1167000
    num_steps_trained: 1167000
    wait_time_ms: 50.043
  iterations_since_restore: 389
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3353.8186650276184
  time_this_iter_s: 8.201874494552612
  time_total_s: 3353.8186650276184
  timestamp: 1594091124
  timesteps_since_restore: 1167000
  timesteps_this_iter: 3000
  timesteps_total: 1167000
  training_iteration: 389
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3353 s, 389 iter, 1167000 ts, 1.03e+03 rew

agent-1: 317.0
agent-2: 316.0
agent-3: 315.0
Sum Reward: 948.0
Avg Reward: 316.0
Min Reward: 315.0
Max Reward: 317.0
Gini Coefficient: 0.0014064697609001407
20:20 Ratio: 1.0063492063492063
Max-min Ratio: 1.0063492063492063
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-05-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 1030.99
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 389
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.47
    dispatch_time_ms: 16.535
    learner:
      cur_lr: 0.001282277749851346
      grad_gnorm: 30.931201934814453
      policy_entropy: 14.576078414916992
      policy_loss: 9.195296287536621
      var_gnorm: 41.28093719482422
      vf_explained_var: 0.0
      vf_loss: 6.198101043701172
    num_steps_sampled: 1170000
    num_steps_trained: 1170000
    wait_time_ms: 65.967
  iterations_since_restore: 390
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3362.4837386608124
  time_this_iter_s: 8.66507363319397
  time_total_s: 3362.4837386608124
  timestamp: 1594091132
  timesteps_since_restore: 1170000
  timesteps_this_iter: 3000
  timesteps_total: 1170000
  training_iteration: 390
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3362 s, 390 iter, 1170000 ts, 1.03e+03 rew

agent-1: 265.0
agent-2: 335.0
agent-3: 306.0
Sum Reward: 906.0
Avg Reward: 302.0
Min Reward: 265.0
Max Reward: 335.0
Gini Coefficient: 0.051508462104488596
20:20 Ratio: 1.2641509433962264
Max-min Ratio: 1.2641509433962264
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-05-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 1028.47
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 390
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.068
    dispatch_time_ms: 28.385
    learner:
      cur_lr: 0.001282077981159091
      grad_gnorm: 28.68074607849121
      policy_entropy: 17.84705352783203
      policy_loss: -3.1819257736206055
      var_gnorm: 41.29227828979492
      vf_explained_var: 0.018469929695129395
      vf_loss: 20.933992385864258
    num_steps_sampled: 1173000
    num_steps_trained: 1173000
    wait_time_ms: 58.825
  iterations_since_restore: 391
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3370.8229167461395
  time_this_iter_s: 8.339178085327148
  time_total_s: 3370.8229167461395
  timestamp: 1594091141
  timesteps_since_restore: 1173000
  timesteps_this_iter: 3000
  timesteps_total: 1173000
  training_iteration: 391
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3370 s, 391 iter, 1173000 ts, 1.03e+03 rew

agent-1: 320.0
agent-2: 348.0
agent-3: 283.0
Sum Reward: 951.0
Avg Reward: 317.0
Min Reward: 283.0
Max Reward: 348.0
Gini Coefficient: 0.04556607080266386
20:20 Ratio: 1.2296819787985867
Max-min Ratio: 1.2296819787985867
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-05-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 1027.05
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 391
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.803
    dispatch_time_ms: 28.963
    learner:
      cur_lr: 0.001281878212466836
      grad_gnorm: 19.1893310546875
      policy_entropy: 16.229389190673828
      policy_loss: 1.0543334484100342
      var_gnorm: 41.274139404296875
      vf_explained_var: -0.15092861652374268
      vf_loss: 10.215188980102539
    num_steps_sampled: 1176000
    num_steps_trained: 1176000
    wait_time_ms: 52.625
  iterations_since_restore: 392
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3379.622393131256
  time_this_iter_s: 8.799476385116577
  time_total_s: 3379.622393131256
  timestamp: 1594091150
  timesteps_since_restore: 1176000
  timesteps_this_iter: 3000
  timesteps_total: 1176000
  training_iteration: 392
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3379 s, 392 iter, 1176000 ts, 1.03e+03 rew

agent-1: 297.0
agent-2: 307.0
agent-3: 302.0
Sum Reward: 906.0
Avg Reward: 302.0
Min Reward: 297.0
Max Reward: 307.0
Gini Coefficient: 0.007358351729212656
20:20 Ratio: 1.0336700336700337
Max-min Ratio: 1.0336700336700337
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-05-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 1025.55
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 392
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.815
    dispatch_time_ms: 23.857
    learner:
      cur_lr: 0.001281678443774581
      grad_gnorm: 39.999996185302734
      policy_entropy: 19.873355865478516
      policy_loss: -18.649263381958008
      var_gnorm: 41.24044418334961
      vf_explained_var: -0.15882551670074463
      vf_loss: 69.97804260253906
    num_steps_sampled: 1179000
    num_steps_trained: 1179000
    wait_time_ms: 53.791
  iterations_since_restore: 393
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3387.6708006858826
  time_this_iter_s: 8.048407554626465
  time_total_s: 3387.6708006858826
  timestamp: 1594091158
  timesteps_since_restore: 1179000
  timesteps_this_iter: 3000
  timesteps_total: 1179000
  training_iteration: 393
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3387 s, 393 iter, 1179000 ts, 1.03e+03 rew

agent-1: 236.0
agent-2: 221.0
agent-3: 234.0
Sum Reward: 691.0
Avg Reward: 230.33333333333334
Min Reward: 221.0
Max Reward: 236.0
Gini Coefficient: 0.01447178002894356
20:20 Ratio: 1.0678733031674208
Max-min Ratio: 1.0678733031674208
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-06-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 1022.23
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 393
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.573
    dispatch_time_ms: 7.93
    learner:
      cur_lr: 0.0012814785586670041
      grad_gnorm: 40.0
      policy_entropy: 17.85243797302246
      policy_loss: -1.7771662473678589
      var_gnorm: 41.203609466552734
      vf_explained_var: -0.061147212982177734
      vf_loss: 42.480262756347656
    num_steps_sampled: 1182000
    num_steps_trained: 1182000
    wait_time_ms: 69.907
  iterations_since_restore: 394
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3395.5278091430664
  time_this_iter_s: 7.857008457183838
  time_total_s: 3395.5278091430664
  timestamp: 1594091166
  timesteps_since_restore: 1182000
  timesteps_this_iter: 3000
  timesteps_total: 1182000
  training_iteration: 394
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3395 s, 394 iter, 1182000 ts, 1.02e+03 rew

agent-1: 190.0
agent-2: 238.0
agent-3: 196.0
Sum Reward: 624.0
Avg Reward: 208.0
Min Reward: 190.0
Max Reward: 238.0
Gini Coefficient: 0.05128205128205128
20:20 Ratio: 1.2526315789473683
Max-min Ratio: 1.2526315789473683
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-06-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 1018.89
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 394
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.877
    dispatch_time_ms: 5.83
    learner:
      cur_lr: 0.001281278789974749
      grad_gnorm: 40.0
      policy_entropy: 15.029948234558105
      policy_loss: 8.595526695251465
      var_gnorm: 41.23139572143555
      vf_explained_var: -0.20439255237579346
      vf_loss: 20.852127075195312
    num_steps_sampled: 1185000
    num_steps_trained: 1185000
    wait_time_ms: 80.363
  iterations_since_restore: 395
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3403.5875318050385
  time_this_iter_s: 8.059722661972046
  time_total_s: 3403.5875318050385
  timestamp: 1594091174
  timesteps_since_restore: 1185000
  timesteps_this_iter: 3000
  timesteps_total: 1185000
  training_iteration: 395
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3403 s, 395 iter, 1185000 ts, 1.02e+03 rew

agent-1: 319.0
agent-2: 273.0
agent-3: 325.0
Sum Reward: 917.0
Avg Reward: 305.6666666666667
Min Reward: 273.0
Max Reward: 325.0
Gini Coefficient: 0.037804434750999635
20:20 Ratio: 1.1904761904761905
Max-min Ratio: 1.1904761904761905
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-06-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 1018.14
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 395
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.551
    dispatch_time_ms: 6.112
    learner:
      cur_lr: 0.001281079021282494
      grad_gnorm: 40.0
      policy_entropy: 13.925884246826172
      policy_loss: -5.4110493659973145
      var_gnorm: 41.24516296386719
      vf_explained_var: -0.08473682403564453
      vf_loss: 18.775827407836914
    num_steps_sampled: 1188000
    num_steps_trained: 1188000
    wait_time_ms: 67.546
  iterations_since_restore: 396
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3411.9099650382996
  time_this_iter_s: 8.322433233261108
  time_total_s: 3411.9099650382996
  timestamp: 1594091182
  timesteps_since_restore: 1188000
  timesteps_this_iter: 3000
  timesteps_total: 1188000
  training_iteration: 396
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3411 s, 396 iter, 1188000 ts, 1.02e+03 rew

agent-1: 319.0
agent-2: 298.0
agent-3: 281.0
Sum Reward: 898.0
Avg Reward: 299.3333333333333
Min Reward: 281.0
Max Reward: 319.0
Gini Coefficient: 0.028210838901262063
20:20 Ratio: 1.1352313167259787
Max-min Ratio: 1.1352313167259787
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-06-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 1017.13
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 396
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.387
    dispatch_time_ms: 9.547
    learner:
      cur_lr: 0.001280879252590239
      grad_gnorm: 40.0
      policy_entropy: 22.195154190063477
      policy_loss: 6.020204544067383
      var_gnorm: 41.27302932739258
      vf_explained_var: -0.05283164978027344
      vf_loss: 25.739261627197266
    num_steps_sampled: 1191000
    num_steps_trained: 1191000
    wait_time_ms: 70.195
  iterations_since_restore: 397
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3420.0939526557922
  time_this_iter_s: 8.183987617492676
  time_total_s: 3420.0939526557922
  timestamp: 1594091190
  timesteps_since_restore: 1191000
  timesteps_this_iter: 3000
  timesteps_total: 1191000
  training_iteration: 397
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3420 s, 397 iter, 1191000 ts, 1.02e+03 rew

agent-1: 286.0
agent-2: 294.0
agent-3: 299.0
Sum Reward: 879.0
Avg Reward: 293.0
Min Reward: 286.0
Max Reward: 299.0
Gini Coefficient: 0.009859689040576413
20:20 Ratio: 1.0454545454545454
Max-min Ratio: 1.0454545454545454
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-06-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 1015.18
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 397
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.985
    dispatch_time_ms: 6.58
    learner:
      cur_lr: 0.0012806793674826622
      grad_gnorm: 24.304153442382812
      policy_entropy: 22.18518829345703
      policy_loss: -4.742056369781494
      var_gnorm: 41.26576232910156
      vf_explained_var: -0.057219862937927246
      vf_loss: 9.17223834991455
    num_steps_sampled: 1194000
    num_steps_trained: 1194000
    wait_time_ms: 70.984
  iterations_since_restore: 398
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3428.2478053569794
  time_this_iter_s: 8.153852701187134
  time_total_s: 3428.2478053569794
  timestamp: 1594091198
  timesteps_since_restore: 1194000
  timesteps_this_iter: 3000
  timesteps_total: 1194000
  training_iteration: 398
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3428 s, 398 iter, 1194000 ts, 1.02e+03 rew

agent-1: 328.0
agent-2: 295.0
agent-3: 278.0
Sum Reward: 901.0
Avg Reward: 300.3333333333333
Min Reward: 278.0
Max Reward: 328.0
Gini Coefficient: 0.03699593044765076
20:20 Ratio: 1.1798561151079137
Max-min Ratio: 1.1798561151079137
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-06-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 1012.06
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 398
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.178
    dispatch_time_ms: 7.724
    learner:
      cur_lr: 0.0012804795987904072
      grad_gnorm: 24.03127670288086
      policy_entropy: 19.731155395507812
      policy_loss: 5.6767730712890625
      var_gnorm: 41.29441833496094
      vf_explained_var: 0.0
      vf_loss: 6.968023300170898
    num_steps_sampled: 1197000
    num_steps_trained: 1197000
    wait_time_ms: 72.406
  iterations_since_restore: 399
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3436.161938428879
  time_this_iter_s: 7.914133071899414
  time_total_s: 3436.161938428879
  timestamp: 1594091206
  timesteps_since_restore: 1197000
  timesteps_this_iter: 3000
  timesteps_total: 1197000
  training_iteration: 399
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3436 s, 399 iter, 1197000 ts, 1.01e+03 rew

agent-1: 263.0
agent-2: 254.0
agent-3: 275.0
Sum Reward: 792.0
Avg Reward: 264.0
Min Reward: 254.0
Max Reward: 275.0
Gini Coefficient: 0.017676767676767676
20:20 Ratio: 1.0826771653543308
Max-min Ratio: 1.0826771653543308
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-06-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 1008.0
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 399
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.876
    dispatch_time_ms: 7.887
    learner:
      cur_lr: 0.0012802798300981522
      grad_gnorm: 18.70650291442871
      policy_entropy: 15.390157699584961
      policy_loss: -4.283509731292725
      var_gnorm: 41.330291748046875
      vf_explained_var: -0.019963860511779785
      vf_loss: 14.464909553527832
    num_steps_sampled: 1200000
    num_steps_trained: 1200000
    wait_time_ms: 66.109
  iterations_since_restore: 400
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3444.279933691025
  time_this_iter_s: 8.117995262145996
  time_total_s: 3444.279933691025
  timestamp: 1594091215
  timesteps_since_restore: 1200000
  timesteps_this_iter: 3000
  timesteps_total: 1200000
  training_iteration: 400
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3444 s, 400 iter, 1200000 ts, 1.01e+03 rew

agent-1: 310.0
agent-2: 303.0
agent-3: 289.0
Sum Reward: 902.0
Avg Reward: 300.6666666666667
Min Reward: 289.0
Max Reward: 310.0
Gini Coefficient: 0.015521064301552107
20:20 Ratio: 1.0726643598615917
Max-min Ratio: 1.0726643598615917
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-07-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 1005.02
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 400
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.711
    dispatch_time_ms: 7.158
    learner:
      cur_lr: 0.0012800799449905753
      grad_gnorm: 8.696812629699707
      policy_entropy: 9.317399978637695
      policy_loss: 1.5138870477676392
      var_gnorm: 41.37579345703125
      vf_explained_var: 0.029238879680633545
      vf_loss: 13.24636459350586
    num_steps_sampled: 1203000
    num_steps_trained: 1203000
    wait_time_ms: 70.512
  iterations_since_restore: 401
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3452.363984107971
  time_this_iter_s: 8.084050416946411
  time_total_s: 3452.363984107971
  timestamp: 1594091223
  timesteps_since_restore: 1203000
  timesteps_this_iter: 3000
  timesteps_total: 1203000
  training_iteration: 401
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3452 s, 401 iter, 1203000 ts, 1.01e+03 rew

agent-1: 326.0
agent-2: 303.0
agent-3: 343.0
Sum Reward: 972.0
Avg Reward: 324.0
Min Reward: 303.0
Max Reward: 343.0
Gini Coefficient: 0.027434842249657063
20:20 Ratio: 1.132013201320132
Max-min Ratio: 1.132013201320132
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-07-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 1002.28
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 401
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.414
    dispatch_time_ms: 5.916
    learner:
      cur_lr: 0.0012798801762983203
      grad_gnorm: 40.0
      policy_entropy: 6.565732955932617
      policy_loss: 1.1196181774139404
      var_gnorm: 41.40613555908203
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 22.064678192138672
    num_steps_sampled: 1206000
    num_steps_trained: 1206000
    wait_time_ms: 67.511
  iterations_since_restore: 402
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3460.8289325237274
  time_this_iter_s: 8.464948415756226
  time_total_s: 3460.8289325237274
  timestamp: 1594091231
  timesteps_since_restore: 1206000
  timesteps_this_iter: 3000
  timesteps_total: 1206000
  training_iteration: 402
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3460 s, 402 iter, 1206000 ts, 1e+03 rew

agent-1: 304.0
agent-2: 303.0
agent-3: 336.0
Sum Reward: 943.0
Avg Reward: 314.3333333333333
Min Reward: 303.0
Max Reward: 336.0
Gini Coefficient: 0.02332979851537646
20:20 Ratio: 1.108910891089109
Max-min Ratio: 1.108910891089109
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-07-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 999.36
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 402
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.489
    dispatch_time_ms: 6.404
    learner:
      cur_lr: 0.0012796804076060653
      grad_gnorm: 40.0
      policy_entropy: 8.922746658325195
      policy_loss: -2.9614334106445312
      var_gnorm: 41.43344497680664
      vf_explained_var: -0.1090848445892334
      vf_loss: 27.358827590942383
    num_steps_sampled: 1209000
    num_steps_trained: 1209000
    wait_time_ms: 67.951
  iterations_since_restore: 403
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3468.733913421631
  time_this_iter_s: 7.904980897903442
  time_total_s: 3468.733913421631
  timestamp: 1594091239
  timesteps_since_restore: 1209000
  timesteps_this_iter: 3000
  timesteps_total: 1209000
  training_iteration: 403
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3468 s, 403 iter, 1209000 ts, 999 rew

agent-1: 260.0
agent-2: 340.0
agent-3: 295.0
Sum Reward: 895.0
Avg Reward: 298.3333333333333
Min Reward: 260.0
Max Reward: 340.0
Gini Coefficient: 0.0595903165735568
20:20 Ratio: 1.3076923076923077
Max-min Ratio: 1.3076923076923077
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-07-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 996.84
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 403
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.535
    dispatch_time_ms: 6.028
    learner:
      cur_lr: 0.0012794806389138103
      grad_gnorm: 12.73529052734375
      policy_entropy: 12.41972827911377
      policy_loss: -0.4796808958053589
      var_gnorm: 41.43553924560547
      vf_explained_var: -0.03030562400817871
      vf_loss: 9.812288284301758
    num_steps_sampled: 1212000
    num_steps_trained: 1212000
    wait_time_ms: 74.448
  iterations_since_restore: 404
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3476.854953289032
  time_this_iter_s: 8.121039867401123
  time_total_s: 3476.854953289032
  timestamp: 1594091247
  timesteps_since_restore: 1212000
  timesteps_this_iter: 3000
  timesteps_total: 1212000
  training_iteration: 404
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3476 s, 404 iter, 1212000 ts, 997 rew

agent-1: 306.0
agent-2: 324.0
agent-3: 321.0
Sum Reward: 951.0
Avg Reward: 317.0
Min Reward: 306.0
Max Reward: 324.0
Gini Coefficient: 0.012618296529968454
20:20 Ratio: 1.0588235294117647
Max-min Ratio: 1.0588235294117647
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-07-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 995.56
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 404
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.475
    dispatch_time_ms: 6.11
    learner:
      cur_lr: 0.0012792807538062334
      grad_gnorm: 33.27666091918945
      policy_entropy: 14.908710479736328
      policy_loss: 4.988742351531982
      var_gnorm: 41.51542663574219
      vf_explained_var: 0.48554742336273193
      vf_loss: 17.074363708496094
    num_steps_sampled: 1215000
    num_steps_trained: 1215000
    wait_time_ms: 72.142
  iterations_since_restore: 405
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3484.807824611664
  time_this_iter_s: 7.952871322631836
  time_total_s: 3484.807824611664
  timestamp: 1594091255
  timesteps_since_restore: 1215000
  timesteps_this_iter: 3000
  timesteps_total: 1215000
  training_iteration: 405
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3484 s, 405 iter, 1215000 ts, 996 rew

agent-1: 304.0
agent-2: 289.0
agent-3: 298.0
Sum Reward: 891.0
Avg Reward: 297.0
Min Reward: 289.0
Max Reward: 304.0
Gini Coefficient: 0.01122334455667789
20:20 Ratio: 1.0519031141868511
Max-min Ratio: 1.0519031141868511
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-07-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 993.91
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 405
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.472
    dispatch_time_ms: 6.702
    learner:
      cur_lr: 0.0012790809851139784
      grad_gnorm: 11.239745140075684
      policy_entropy: 23.92452621459961
      policy_loss: 4.177096366882324
      var_gnorm: 41.5940055847168
      vf_explained_var: -0.5846600532531738
      vf_loss: 4.5341267585754395
    num_steps_sampled: 1218000
    num_steps_trained: 1218000
    wait_time_ms: 70.388
  iterations_since_restore: 406
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3492.7880663871765
  time_this_iter_s: 7.980241775512695
  time_total_s: 3492.7880663871765
  timestamp: 1594091263
  timesteps_since_restore: 1218000
  timesteps_this_iter: 3000
  timesteps_total: 1218000
  training_iteration: 406
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3492 s, 406 iter, 1218000 ts, 994 rew

agent-1: 258.0
agent-2: 309.0
agent-3: 287.0
Sum Reward: 854.0
Avg Reward: 284.6666666666667
Min Reward: 258.0
Max Reward: 309.0
Gini Coefficient: 0.03981264637002342
20:20 Ratio: 1.197674418604651
Max-min Ratio: 1.197674418604651
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-07-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 992.0
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 406
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.059
    dispatch_time_ms: 7.989
    learner:
      cur_lr: 0.0012788812164217234
      grad_gnorm: 40.0
      policy_entropy: 19.965166091918945
      policy_loss: -30.980178833007812
      var_gnorm: 41.628509521484375
      vf_explained_var: 0.15721666812896729
      vf_loss: 34.364707946777344
    num_steps_sampled: 1221000
    num_steps_trained: 1221000
    wait_time_ms: 70.856
  iterations_since_restore: 407
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3500.847743034363
  time_this_iter_s: 8.05967664718628
  time_total_s: 3500.847743034363
  timestamp: 1594091271
  timesteps_since_restore: 1221000
  timesteps_this_iter: 3000
  timesteps_total: 1221000
  training_iteration: 407
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3500 s, 407 iter, 1221000 ts, 992 rew

agent-1: 233.0
agent-2: 253.0
agent-3: 240.0
Sum Reward: 726.0
Avg Reward: 242.0
Min Reward: 233.0
Max Reward: 253.0
Gini Coefficient: 0.018365472910927456
20:20 Ratio: 1.0858369098712446
Max-min Ratio: 1.0858369098712446
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-07-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 988.92
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 407
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.659
    dispatch_time_ms: 11.361
    learner:
      cur_lr: 0.0012786814477294683
      grad_gnorm: 39.999996185302734
      policy_entropy: 30.077716827392578
      policy_loss: -16.73641014099121
      var_gnorm: 41.61182403564453
      vf_explained_var: 0.003170788288116455
      vf_loss: 15.644563674926758
    num_steps_sampled: 1224000
    num_steps_trained: 1224000
    wait_time_ms: 67.428
  iterations_since_restore: 408
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3508.618064403534
  time_this_iter_s: 7.770321369171143
  time_total_s: 3508.618064403534
  timestamp: 1594091279
  timesteps_since_restore: 1224000
  timesteps_this_iter: 3000
  timesteps_total: 1224000
  training_iteration: 408
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3508 s, 408 iter, 1224000 ts, 989 rew

agent-1: 212.0
agent-2: 207.0
agent-3: 237.0
Sum Reward: 656.0
Avg Reward: 218.66666666666666
Min Reward: 207.0
Max Reward: 237.0
Gini Coefficient: 0.03048780487804878
20:20 Ratio: 1.144927536231884
Max-min Ratio: 1.144927536231884
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-08-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 985.09
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 408
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.797
    dispatch_time_ms: 6.899
    learner:
      cur_lr: 0.0012784815626218915
      grad_gnorm: 40.000003814697266
      policy_entropy: 23.25271224975586
      policy_loss: -17.27811050415039
      var_gnorm: 41.61763000488281
      vf_explained_var: -0.8825278282165527
      vf_loss: 30.800451278686523
    num_steps_sampled: 1227000
    num_steps_trained: 1227000
    wait_time_ms: 66.96
  iterations_since_restore: 409
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3516.3009734153748
  time_this_iter_s: 7.68290901184082
  time_total_s: 3516.3009734153748
  timestamp: 1594091287
  timesteps_since_restore: 1227000
  timesteps_this_iter: 3000
  timesteps_total: 1227000
  training_iteration: 409
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3516 s, 409 iter, 1227000 ts, 985 rew

agent-1: 127.0
agent-2: 94.0
agent-3: 255.0
Sum Reward: 476.0
Avg Reward: 158.66666666666666
Min Reward: 94.0
Max Reward: 255.0
Gini Coefficient: 0.22549019607843138
20:20 Ratio: 2.7127659574468086
Max-min Ratio: 2.7127659574468086
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-08-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 979.31
  episode_reward_min: 445.0
  episodes_this_iter: 1
  episodes_total: 409
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.056
    dispatch_time_ms: 7.048
    learner:
      cur_lr: 0.0012782817939296365
      grad_gnorm: 40.0
      policy_entropy: 24.338483810424805
      policy_loss: -23.690649032592773
      var_gnorm: 41.542579650878906
      vf_explained_var: 0.7559852004051208
      vf_loss: 22.61334991455078
    num_steps_sampled: 1230000
    num_steps_trained: 1230000
    wait_time_ms: 63.605
  iterations_since_restore: 410
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3523.6637423038483
  time_this_iter_s: 7.362768888473511
  time_total_s: 3523.6637423038483
  timestamp: 1594091294
  timesteps_since_restore: 1230000
  timesteps_this_iter: 3000
  timesteps_total: 1230000
  training_iteration: 410
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3523 s, 410 iter, 1230000 ts, 979 rew

agent-1: 72.0
agent-2: 206.0
agent-3: 105.0
Sum Reward: 383.0
Avg Reward: 127.66666666666667
Min Reward: 72.0
Max Reward: 206.0
Gini Coefficient: 0.23324630113141862
20:20 Ratio: 2.861111111111111
Max-min Ratio: 2.861111111111111
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-08-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 972.44
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 410
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.694
    dispatch_time_ms: 7.002
    learner:
      cur_lr: 0.0012780820252373815
      grad_gnorm: 17.968963623046875
      policy_entropy: 23.473827362060547
      policy_loss: 2.124267101287842
      var_gnorm: 41.57377624511719
      vf_explained_var: -0.839074969291687
      vf_loss: 12.402206420898438
    num_steps_sampled: 1233000
    num_steps_trained: 1233000
    wait_time_ms: 64.855
  iterations_since_restore: 411
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3531.018487215042
  time_this_iter_s: 7.354744911193848
  time_total_s: 3531.018487215042
  timestamp: 1594091302
  timesteps_since_restore: 1233000
  timesteps_this_iter: 3000
  timesteps_total: 1233000
  training_iteration: 411
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3531 s, 411 iter, 1233000 ts, 972 rew

agent-1: 164.0
agent-2: 131.0
agent-3: 130.0
Sum Reward: 425.0
Avg Reward: 141.66666666666666
Min Reward: 130.0
Max Reward: 164.0
Gini Coefficient: 0.05333333333333334
20:20 Ratio: 1.2615384615384615
Max-min Ratio: 1.2615384615384615
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-08-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 965.44
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 411
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.556
    dispatch_time_ms: 7.042
    learner:
      cur_lr: 0.0012778822565451264
      grad_gnorm: 40.000003814697266
      policy_entropy: 26.191633224487305
      policy_loss: 11.782840728759766
      var_gnorm: 41.56724166870117
      vf_explained_var: 0.02555549144744873
      vf_loss: 36.52964401245117
    num_steps_sampled: 1236000
    num_steps_trained: 1236000
    wait_time_ms: 65.85
  iterations_since_restore: 412
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3538.5000264644623
  time_this_iter_s: 7.481539249420166
  time_total_s: 3538.5000264644623
  timestamp: 1594091309
  timesteps_since_restore: 1236000
  timesteps_this_iter: 3000
  timesteps_total: 1236000
  training_iteration: 412
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3538 s, 412 iter, 1236000 ts, 965 rew

agent-1: 108.0
agent-2: 170.0
agent-3: 206.0
Sum Reward: 484.0
Avg Reward: 161.33333333333334
Min Reward: 108.0
Max Reward: 206.0
Gini Coefficient: 0.1349862258953168
20:20 Ratio: 1.9074074074074074
Max-min Ratio: 1.9074074074074074
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-08-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 959.6
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 412
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.493
    dispatch_time_ms: 7.287
    learner:
      cur_lr: 0.0012776823714375496
      grad_gnorm: 39.999996185302734
      policy_entropy: 26.046977996826172
      policy_loss: 8.478431701660156
      var_gnorm: 41.55419158935547
      vf_explained_var: 0.029259145259857178
      vf_loss: 29.19985008239746
    num_steps_sampled: 1239000
    num_steps_trained: 1239000
    wait_time_ms: 67.063
  iterations_since_restore: 413
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3546.1244025230408
  time_this_iter_s: 7.624376058578491
  time_total_s: 3546.1244025230408
  timestamp: 1594091317
  timesteps_since_restore: 1239000
  timesteps_this_iter: 3000
  timesteps_total: 1239000
  training_iteration: 413
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3546 s, 413 iter, 1239000 ts, 960 rew

agent-1: 161.0
agent-2: 175.0
agent-3: 145.0
Sum Reward: 481.0
Avg Reward: 160.33333333333334
Min Reward: 145.0
Max Reward: 175.0
Gini Coefficient: 0.04158004158004158
20:20 Ratio: 1.206896551724138
Max-min Ratio: 1.206896551724138
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-08-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 953.06
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 413
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.661
    dispatch_time_ms: 5.897
    learner:
      cur_lr: 0.0012774826027452946
      grad_gnorm: 40.0
      policy_entropy: 23.4005126953125
      policy_loss: 2.12992000579834
      var_gnorm: 41.51658248901367
      vf_explained_var: 0.07625424861907959
      vf_loss: 68.61973571777344
    num_steps_sampled: 1242000
    num_steps_trained: 1242000
    wait_time_ms: 63.694
  iterations_since_restore: 414
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3553.845868587494
  time_this_iter_s: 7.721466064453125
  time_total_s: 3553.845868587494
  timestamp: 1594091325
  timesteps_since_restore: 1242000
  timesteps_this_iter: 3000
  timesteps_total: 1242000
  training_iteration: 414
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3553 s, 414 iter, 1242000 ts, 953 rew

agent-1: 160.0
agent-2: 153.0
agent-3: 226.0
Sum Reward: 539.0
Avg Reward: 179.66666666666666
Min Reward: 153.0
Max Reward: 226.0
Gini Coefficient: 0.09029066171923315
20:20 Ratio: 1.477124183006536
Max-min Ratio: 1.477124183006536
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-08-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 947.07
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 414
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.505
    dispatch_time_ms: 5.424
    learner:
      cur_lr: 0.0012772828340530396
      grad_gnorm: 35.548465728759766
      policy_entropy: 30.421524047851562
      policy_loss: 8.968893051147461
      var_gnorm: 41.567535400390625
      vf_explained_var: -0.07319605350494385
      vf_loss: 33.76057815551758
    num_steps_sampled: 1245000
    num_steps_trained: 1245000
    wait_time_ms: 75.848
  iterations_since_restore: 415
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3561.838484287262
  time_this_iter_s: 7.992615699768066
  time_total_s: 3561.838484287262
  timestamp: 1594091333
  timesteps_since_restore: 1245000
  timesteps_this_iter: 3000
  timesteps_total: 1245000
  training_iteration: 415
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3561 s, 415 iter, 1245000 ts, 947 rew

agent-1: 270.0
agent-2: 231.0
agent-3: 231.0
Sum Reward: 732.0
Avg Reward: 244.0
Min Reward: 231.0
Max Reward: 270.0
Gini Coefficient: 0.03551912568306011
20:20 Ratio: 1.1688311688311688
Max-min Ratio: 1.1688311688311688
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-09-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 942.78
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 415
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.527
    dispatch_time_ms: 7.271
    learner:
      cur_lr: 0.0012770829489454627
      grad_gnorm: 8.295578002929688
      policy_entropy: 26.561302185058594
      policy_loss: -0.41230058670043945
      var_gnorm: 41.60078048706055
      vf_explained_var: 0.38831013441085815
      vf_loss: 14.979138374328613
    num_steps_sampled: 1248000
    num_steps_trained: 1248000
    wait_time_ms: 73.326
  iterations_since_restore: 416
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3569.932054042816
  time_this_iter_s: 8.0935697555542
  time_total_s: 3569.932054042816
  timestamp: 1594091341
  timesteps_since_restore: 1248000
  timesteps_this_iter: 3000
  timesteps_total: 1248000
  training_iteration: 416
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3569 s, 416 iter, 1248000 ts, 943 rew

agent-1: 209.0
agent-2: 288.0
agent-3: 266.0
Sum Reward: 763.0
Avg Reward: 254.33333333333334
Min Reward: 209.0
Max Reward: 288.0
Gini Coefficient: 0.0690257754477938
20:20 Ratio: 1.3779904306220097
Max-min Ratio: 1.3779904306220097
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-09-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 938.17
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 416
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.699
    dispatch_time_ms: 5.079
    learner:
      cur_lr: 0.0012768831802532077
      grad_gnorm: 39.999996185302734
      policy_entropy: 17.32637596130371
      policy_loss: -7.476194381713867
      var_gnorm: 41.59939956665039
      vf_explained_var: 0.24272578954696655
      vf_loss: 37.49811935424805
    num_steps_sampled: 1251000
    num_steps_trained: 1251000
    wait_time_ms: 68.625
  iterations_since_restore: 417
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3577.7418324947357
  time_this_iter_s: 7.809778451919556
  time_total_s: 3577.7418324947357
  timestamp: 1594091349
  timesteps_since_restore: 1251000
  timesteps_this_iter: 3000
  timesteps_total: 1251000
  training_iteration: 417
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3577 s, 417 iter, 1251000 ts, 938 rew

agent-1: 153.0
agent-2: 183.0
agent-3: 208.0
Sum Reward: 544.0
Avg Reward: 181.33333333333334
Min Reward: 153.0
Max Reward: 208.0
Gini Coefficient: 0.06740196078431372
20:20 Ratio: 1.3594771241830066
Max-min Ratio: 1.3594771241830066
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-09-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 932.27
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 417
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.705
    dispatch_time_ms: 5.99
    learner:
      cur_lr: 0.0012766834115609527
      grad_gnorm: 36.99179458618164
      policy_entropy: 25.483043670654297
      policy_loss: -4.586152076721191
      var_gnorm: 41.61180877685547
      vf_explained_var: -0.0173414945602417
      vf_loss: 12.200496673583984
    num_steps_sampled: 1254000
    num_steps_trained: 1254000
    wait_time_ms: 61.488
  iterations_since_restore: 418
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3585.4684596061707
  time_this_iter_s: 7.7266271114349365
  time_total_s: 3585.4684596061707
  timestamp: 1594091356
  timesteps_since_restore: 1254000
  timesteps_this_iter: 3000
  timesteps_total: 1254000
  training_iteration: 418
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3585 s, 418 iter, 1254000 ts, 932 rew

agent-1: 176.0
agent-2: 197.0
agent-3: 213.0
Sum Reward: 586.0
Avg Reward: 195.33333333333334
Min Reward: 176.0
Max Reward: 213.0
Gini Coefficient: 0.04209328782707622
20:20 Ratio: 1.2102272727272727
Max-min Ratio: 1.2102272727272727
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-09-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 926.44
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 418
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.69
    dispatch_time_ms: 5.975
    learner:
      cur_lr: 0.0012764836428686976
      grad_gnorm: 40.0
      policy_entropy: 24.696374893188477
      policy_loss: 11.233325958251953
      var_gnorm: 41.702083587646484
      vf_explained_var: 0.20731985569000244
      vf_loss: 41.069889068603516
    num_steps_sampled: 1257000
    num_steps_trained: 1257000
    wait_time_ms: 69.376
  iterations_since_restore: 419
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3593.157548189163
  time_this_iter_s: 7.689088582992554
  time_total_s: 3593.157548189163
  timestamp: 1594091364
  timesteps_since_restore: 1257000
  timesteps_this_iter: 3000
  timesteps_total: 1257000
  training_iteration: 419
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3593 s, 419 iter, 1257000 ts, 926 rew

agent-1: 187.0
agent-2: 184.0
agent-3: 217.0
Sum Reward: 588.0
Avg Reward: 196.0
Min Reward: 184.0
Max Reward: 217.0
Gini Coefficient: 0.03741496598639456
20:20 Ratio: 1.1793478260869565
Max-min Ratio: 1.1793478260869565
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-09-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 921.15
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 419
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.125
    dispatch_time_ms: 5.032
    learner:
      cur_lr: 0.0012762837577611208
      grad_gnorm: 34.52247619628906
      policy_entropy: 25.277870178222656
      policy_loss: -8.382427215576172
      var_gnorm: 41.68596649169922
      vf_explained_var: 0.030415773391723633
      vf_loss: 9.252866744995117
    num_steps_sampled: 1260000
    num_steps_trained: 1260000
    wait_time_ms: 71.918
  iterations_since_restore: 420
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3601.078516483307
  time_this_iter_s: 7.920968294143677
  time_total_s: 3601.078516483307
  timestamp: 1594091372
  timesteps_since_restore: 1260000
  timesteps_this_iter: 3000
  timesteps_total: 1260000
  training_iteration: 420
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3601 s, 420 iter, 1260000 ts, 921 rew

agent-1: 226.0
agent-2: 256.0
agent-3: 173.0
Sum Reward: 655.0
Avg Reward: 218.33333333333334
Min Reward: 173.0
Max Reward: 256.0
Gini Coefficient: 0.08447837150127227
20:20 Ratio: 1.4797687861271676
Max-min Ratio: 1.4797687861271676
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-09-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 916.97
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 420
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.456
    dispatch_time_ms: 8.149
    learner:
      cur_lr: 0.0012760839890688658
      grad_gnorm: 40.0
      policy_entropy: 22.578371047973633
      policy_loss: 4.462316513061523
      var_gnorm: 41.701419830322266
      vf_explained_var: 0.35269927978515625
      vf_loss: 41.61549377441406
    num_steps_sampled: 1263000
    num_steps_trained: 1263000
    wait_time_ms: 68.585
  iterations_since_restore: 421
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3608.891443490982
  time_this_iter_s: 7.812927007675171
  time_total_s: 3608.891443490982
  timestamp: 1594091380
  timesteps_since_restore: 1263000
  timesteps_this_iter: 3000
  timesteps_total: 1263000
  training_iteration: 421
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3608 s, 421 iter, 1263000 ts, 917 rew

agent-1: 203.0
agent-2: 213.0
agent-3: 206.0
Sum Reward: 622.0
Avg Reward: 207.33333333333334
Min Reward: 203.0
Max Reward: 213.0
Gini Coefficient: 0.010718113612004287
20:20 Ratio: 1.0492610837438423
Max-min Ratio: 1.0492610837438423
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-09-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 912.57
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 421
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.321
    dispatch_time_ms: 6.561
    learner:
      cur_lr: 0.0012758842203766108
      grad_gnorm: 40.0
      policy_entropy: 24.35911750793457
      policy_loss: 8.112969398498535
      var_gnorm: 41.70033645629883
      vf_explained_var: 0.27662622928619385
      vf_loss: 17.251527786254883
    num_steps_sampled: 1266000
    num_steps_trained: 1266000
    wait_time_ms: 69.384
  iterations_since_restore: 422
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3616.8021636009216
  time_this_iter_s: 7.910720109939575
  time_total_s: 3616.8021636009216
  timestamp: 1594091388
  timesteps_since_restore: 1266000
  timesteps_this_iter: 3000
  timesteps_total: 1266000
  training_iteration: 422
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3616 s, 422 iter, 1266000 ts, 913 rew

agent-1: 219.0
agent-2: 214.0
agent-3: 248.0
Sum Reward: 681.0
Avg Reward: 227.0
Min Reward: 214.0
Max Reward: 248.0
Gini Coefficient: 0.033284385707293196
20:20 Ratio: 1.158878504672897
Max-min Ratio: 1.158878504672897
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-09-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 908.55
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 422
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.057
    dispatch_time_ms: 8.354
    learner:
      cur_lr: 0.0012756844516843557
      grad_gnorm: 40.0
      policy_entropy: 21.504261016845703
      policy_loss: 0.0370410680770874
      var_gnorm: 41.799991607666016
      vf_explained_var: 0.43092644214630127
      vf_loss: 46.62928009033203
    num_steps_sampled: 1269000
    num_steps_trained: 1269000
    wait_time_ms: 69.287
  iterations_since_restore: 423
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3624.91769862175
  time_this_iter_s: 8.115535020828247
  time_total_s: 3624.91769862175
  timestamp: 1594091396
  timesteps_since_restore: 1269000
  timesteps_this_iter: 3000
  timesteps_total: 1269000
  training_iteration: 423
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3624 s, 423 iter, 1269000 ts, 909 rew

agent-1: 257.0
agent-2: 230.0
agent-3: 201.0
Sum Reward: 688.0
Avg Reward: 229.33333333333334
Min Reward: 201.0
Max Reward: 257.0
Gini Coefficient: 0.05426356589147287
20:20 Ratio: 1.2786069651741294
Max-min Ratio: 1.2786069651741294
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-10-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 904.04
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 423
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.612
    dispatch_time_ms: 5.5
    learner:
      cur_lr: 0.0012754845665767789
      grad_gnorm: 39.999996185302734
      policy_entropy: 18.747650146484375
      policy_loss: 33.14872360229492
      var_gnorm: 41.791385650634766
      vf_explained_var: 0.1327243447303772
      vf_loss: 66.2017593383789
    num_steps_sampled: 1272000
    num_steps_trained: 1272000
    wait_time_ms: 78.156
  iterations_since_restore: 424
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3633.0454137325287
  time_this_iter_s: 8.127715110778809
  time_total_s: 3633.0454137325287
  timestamp: 1594091404
  timesteps_since_restore: 1272000
  timesteps_this_iter: 3000
  timesteps_total: 1272000
  training_iteration: 424
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3633 s, 424 iter, 1272000 ts, 904 rew

agent-1: 212.0
agent-2: 229.0
agent-3: 214.0
Sum Reward: 655.0
Avg Reward: 218.33333333333334
Min Reward: 212.0
Max Reward: 229.0
Gini Coefficient: 0.017302798982188294
20:20 Ratio: 1.080188679245283
Max-min Ratio: 1.080188679245283
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-10-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 898.73
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 424
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 4.028
    dispatch_time_ms: 6.198
    learner:
      cur_lr: 0.0012752847978845239
      grad_gnorm: 40.000003814697266
      policy_entropy: 19.9820613861084
      policy_loss: 18.267024993896484
      var_gnorm: 41.800193786621094
      vf_explained_var: 0.4133150577545166
      vf_loss: 39.70003890991211
    num_steps_sampled: 1275000
    num_steps_trained: 1275000
    wait_time_ms: 77.374
  iterations_since_restore: 425
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3640.8064379692078
  time_this_iter_s: 7.761024236679077
  time_total_s: 3640.8064379692078
  timestamp: 1594091412
  timesteps_since_restore: 1275000
  timesteps_this_iter: 3000
  timesteps_total: 1275000
  training_iteration: 425
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3640 s, 425 iter, 1275000 ts, 899 rew

agent-1: 249.0
agent-2: 236.0
agent-3: 200.0
Sum Reward: 685.0
Avg Reward: 228.33333333333334
Min Reward: 200.0
Max Reward: 249.0
Gini Coefficient: 0.047688564476885645
20:20 Ratio: 1.245
Max-min Ratio: 1.245
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-10-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 894.13
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 425
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.369
    dispatch_time_ms: 6.81
    learner:
      cur_lr: 0.0012750850291922688
      grad_gnorm: 40.0
      policy_entropy: 19.00353240966797
      policy_loss: 10.985950469970703
      var_gnorm: 41.87541580200195
      vf_explained_var: 0.6191457509994507
      vf_loss: 23.765113830566406
    num_steps_sampled: 1278000
    num_steps_trained: 1278000
    wait_time_ms: 70.209
  iterations_since_restore: 426
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3648.9352173805237
  time_this_iter_s: 8.128779411315918
  time_total_s: 3648.9352173805237
  timestamp: 1594091420
  timesteps_since_restore: 1278000
  timesteps_this_iter: 3000
  timesteps_total: 1278000
  training_iteration: 426
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3648 s, 426 iter, 1278000 ts, 894 rew

agent-1: 285.0
agent-2: 255.0
agent-3: 246.0
Sum Reward: 786.0
Avg Reward: 262.0
Min Reward: 246.0
Max Reward: 285.0
Gini Coefficient: 0.03307888040712468
20:20 Ratio: 1.1585365853658536
Max-min Ratio: 1.1585365853658536
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-10-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 891.06
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 426
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.705
    dispatch_time_ms: 10.688
    learner:
      cur_lr: 0.001274885144084692
      grad_gnorm: 40.0
      policy_entropy: 24.39650535583496
      policy_loss: -28.345932006835938
      var_gnorm: 41.934326171875
      vf_explained_var: 0.5907484292984009
      vf_loss: 26.042861938476562
    num_steps_sampled: 1281000
    num_steps_trained: 1281000
    wait_time_ms: 70.369
  iterations_since_restore: 427
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3657.0290427207947
  time_this_iter_s: 8.093825340270996
  time_total_s: 3657.0290427207947
  timestamp: 1594091428
  timesteps_since_restore: 1281000
  timesteps_this_iter: 3000
  timesteps_total: 1281000
  training_iteration: 427
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3657 s, 427 iter, 1281000 ts, 891 rew

agent-1: 277.0
agent-2: 293.0
agent-3: 312.0
Sum Reward: 882.0
Avg Reward: 294.0
Min Reward: 277.0
Max Reward: 312.0
Gini Coefficient: 0.026455026455026454
20:20 Ratio: 1.1263537906137184
Max-min Ratio: 1.1263537906137184
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-10-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 888.33
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 427
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.458
    dispatch_time_ms: 5.473
    learner:
      cur_lr: 0.001274685375392437
      grad_gnorm: 40.000003814697266
      policy_entropy: 16.884431838989258
      policy_loss: 28.134244918823242
      var_gnorm: 41.952083587646484
      vf_explained_var: 0.016070544719696045
      vf_loss: 46.94102096557617
    num_steps_sampled: 1284000
    num_steps_trained: 1284000
    wait_time_ms: 73.727
  iterations_since_restore: 428
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3665.3541893959045
  time_this_iter_s: 8.325146675109863
  time_total_s: 3665.3541893959045
  timestamp: 1594091437
  timesteps_since_restore: 1284000
  timesteps_this_iter: 3000
  timesteps_total: 1284000
  training_iteration: 428
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3665 s, 428 iter, 1284000 ts, 888 rew

agent-1: 317.0
agent-2: 307.0
agent-3: 271.0
Sum Reward: 895.0
Avg Reward: 298.3333333333333
Min Reward: 271.0
Max Reward: 317.0
Gini Coefficient: 0.03426443202979516
20:20 Ratio: 1.169741697416974
Max-min Ratio: 1.169741697416974
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-10-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 885.65
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 428
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.131
    dispatch_time_ms: 7.983
    learner:
      cur_lr: 0.001274485606700182
      grad_gnorm: 37.637535095214844
      policy_entropy: 15.797393798828125
      policy_loss: 2.352149486541748
      var_gnorm: 41.938690185546875
      vf_explained_var: 0.3323777914047241
      vf_loss: 29.593551635742188
    num_steps_sampled: 1287000
    num_steps_trained: 1287000
    wait_time_ms: 75.994
  iterations_since_restore: 429
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3673.7536430358887
  time_this_iter_s: 8.39945363998413
  time_total_s: 3673.7536430358887
  timestamp: 1594091445
  timesteps_since_restore: 1287000
  timesteps_this_iter: 3000
  timesteps_total: 1287000
  training_iteration: 429
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3673 s, 429 iter, 1287000 ts, 886 rew

agent-1: 373.0
agent-2: 320.0
agent-3: 361.0
Sum Reward: 1054.0
Avg Reward: 351.3333333333333
Min Reward: 320.0
Max Reward: 373.0
Gini Coefficient: 0.033523086654016446
20:20 Ratio: 1.165625
Max-min Ratio: 1.165625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-10-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 885.17
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 429
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.535
    dispatch_time_ms: 6.63
    learner:
      cur_lr: 0.001274285838007927
      grad_gnorm: 36.98360824584961
      policy_entropy: 20.124530792236328
      policy_loss: 6.64301872253418
      var_gnorm: 42.04144287109375
      vf_explained_var: 0.1750282645225525
      vf_loss: 20.566360473632812
    num_steps_sampled: 1290000
    num_steps_trained: 1290000
    wait_time_ms: 69.762
  iterations_since_restore: 430
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3682.8197231292725
  time_this_iter_s: 9.066080093383789
  time_total_s: 3682.8197231292725
  timestamp: 1594091454
  timesteps_since_restore: 1290000
  timesteps_this_iter: 3000
  timesteps_total: 1290000
  training_iteration: 430
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3682 s, 430 iter, 1290000 ts, 885 rew

agent-1: 373.0
agent-2: 332.0
agent-3: 327.0
Sum Reward: 1032.0
Avg Reward: 344.0
Min Reward: 327.0
Max Reward: 373.0
Gini Coefficient: 0.029715762273901807
20:20 Ratio: 1.1406727828746177
Max-min Ratio: 1.1406727828746177
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-11-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 884.79
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 430
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.795
    dispatch_time_ms: 6.226
    learner:
      cur_lr: 0.00127408595290035
      grad_gnorm: 39.999996185302734
      policy_entropy: 13.170463562011719
      policy_loss: -16.248828887939453
      var_gnorm: 42.0914421081543
      vf_explained_var: 0.29050374031066895
      vf_loss: 63.73655700683594
    num_steps_sampled: 1293000
    num_steps_trained: 1293000
    wait_time_ms: 79.305
  iterations_since_restore: 431
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3691.330576658249
  time_this_iter_s: 8.51085352897644
  time_total_s: 3691.330576658249
  timestamp: 1594091463
  timesteps_since_restore: 1293000
  timesteps_this_iter: 3000
  timesteps_total: 1293000
  training_iteration: 431
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3691 s, 431 iter, 1293000 ts, 885 rew

agent-1: 376.0
agent-2: 411.0
agent-3: 394.0
Sum Reward: 1181.0
Avg Reward: 393.6666666666667
Min Reward: 376.0
Max Reward: 411.0
Gini Coefficient: 0.019757267852102738
20:20 Ratio: 1.0930851063829787
Max-min Ratio: 1.0930851063829787
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-11-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 885.15
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 431
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.083
    dispatch_time_ms: 6.213
    learner:
      cur_lr: 0.001273886184208095
      grad_gnorm: 40.0
      policy_entropy: 6.754735469818115
      policy_loss: 13.395371437072754
      var_gnorm: 42.176597595214844
      vf_explained_var: 0.20746010541915894
      vf_loss: 43.45695877075195
    num_steps_sampled: 1296000
    num_steps_trained: 1296000
    wait_time_ms: 80.008
  iterations_since_restore: 432
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3700.1260681152344
  time_this_iter_s: 8.795491456985474
  time_total_s: 3700.1260681152344
  timestamp: 1594091471
  timesteps_since_restore: 1296000
  timesteps_this_iter: 3000
  timesteps_total: 1296000
  training_iteration: 432
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3700 s, 432 iter, 1296000 ts, 885 rew

agent-1: 427.0
agent-2: 385.0
agent-3: 427.0
Sum Reward: 1239.0
Avg Reward: 413.0
Min Reward: 385.0
Max Reward: 427.0
Gini Coefficient: 0.022598870056497175
20:20 Ratio: 1.1090909090909091
Max-min Ratio: 1.1090909090909091
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-11-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 885.73
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 432
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.092
    dispatch_time_ms: 10.996
    learner:
      cur_lr: 0.00127368641551584
      grad_gnorm: 20.599817276000977
      policy_entropy: 6.445018768310547
      policy_loss: 1.8128141164779663
      var_gnorm: 42.2733154296875
      vf_explained_var: -0.9373414516448975
      vf_loss: 8.843092918395996
    num_steps_sampled: 1299000
    num_steps_trained: 1299000
    wait_time_ms: 74.521
  iterations_since_restore: 433
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3708.782054424286
  time_this_iter_s: 8.655986309051514
  time_total_s: 3708.782054424286
  timestamp: 1594091480
  timesteps_since_restore: 1299000
  timesteps_this_iter: 3000
  timesteps_total: 1299000
  training_iteration: 433
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3708 s, 433 iter, 1299000 ts, 886 rew

agent-1: 409.0
agent-2: 387.0
agent-3: 390.0
Sum Reward: 1186.0
Avg Reward: 395.3333333333333
Min Reward: 387.0
Max Reward: 409.0
Gini Coefficient: 0.012366498032602586
20:20 Ratio: 1.0568475452196382
Max-min Ratio: 1.0568475452196382
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-11-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 886.43
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 433
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.583
    dispatch_time_ms: 6.703
    learner:
      cur_lr: 0.001273486646823585
      grad_gnorm: 39.999996185302734
      policy_entropy: 8.581911087036133
      policy_loss: -4.200244426727295
      var_gnorm: 42.32080841064453
      vf_explained_var: 0.04069250822067261
      vf_loss: 35.198768615722656
    num_steps_sampled: 1302000
    num_steps_trained: 1302000
    wait_time_ms: 73.05
  iterations_since_restore: 434
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3717.792410135269
  time_this_iter_s: 9.010355710983276
  time_total_s: 3717.792410135269
  timestamp: 1594091489
  timesteps_since_restore: 1302000
  timesteps_this_iter: 3000
  timesteps_total: 1302000
  training_iteration: 434
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3717 s, 434 iter, 1302000 ts, 886 rew

agent-1: 363.0
agent-2: 428.0
agent-3: 402.0
Sum Reward: 1193.0
Avg Reward: 397.6666666666667
Min Reward: 363.0
Max Reward: 428.0
Gini Coefficient: 0.03632299525006985
20:20 Ratio: 1.1790633608815426
Max-min Ratio: 1.1790633608815426
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-11-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 886.66
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 434
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.67
    dispatch_time_ms: 8.482
    learner:
      cur_lr: 0.0012732867617160082
      grad_gnorm: 40.0
      policy_entropy: 4.7974371910095215
      policy_loss: 5.043299674987793
      var_gnorm: 42.3619384765625
      vf_explained_var: 0.320986807346344
      vf_loss: 43.528167724609375
    num_steps_sampled: 1305000
    num_steps_trained: 1305000
    wait_time_ms: 71.837
  iterations_since_restore: 435
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3726.2155113220215
  time_this_iter_s: 8.42310118675232
  time_total_s: 3726.2155113220215
  timestamp: 1594091498
  timesteps_since_restore: 1305000
  timesteps_this_iter: 3000
  timesteps_total: 1305000
  training_iteration: 435
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3726 s, 435 iter, 1305000 ts, 887 rew

agent-1: 400.0
agent-2: 384.0
agent-3: 394.0
Sum Reward: 1178.0
Avg Reward: 392.6666666666667
Min Reward: 384.0
Max Reward: 400.0
Gini Coefficient: 0.009054895302773062
20:20 Ratio: 1.0416666666666667
Max-min Ratio: 1.0416666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-11-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 886.98
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 435
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.714
    dispatch_time_ms: 5.086
    learner:
      cur_lr: 0.0012730869930237532
      grad_gnorm: 40.0
      policy_entropy: 7.064942836761475
      policy_loss: -16.425689697265625
      var_gnorm: 42.46184539794922
      vf_explained_var: -0.012688994407653809
      vf_loss: 40.794612884521484
    num_steps_sampled: 1308000
    num_steps_trained: 1308000
    wait_time_ms: 77.446
  iterations_since_restore: 436
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3734.6261823177338
  time_this_iter_s: 8.41067099571228
  time_total_s: 3734.6261823177338
  timestamp: 1594091506
  timesteps_since_restore: 1308000
  timesteps_this_iter: 3000
  timesteps_total: 1308000
  training_iteration: 436
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3734 s, 436 iter, 1308000 ts, 887 rew

agent-1: 415.0
agent-2: 335.0
agent-3: 406.0
Sum Reward: 1156.0
Avg Reward: 385.3333333333333
Min Reward: 335.0
Max Reward: 415.0
Gini Coefficient: 0.0461361014994233
20:20 Ratio: 1.2388059701492538
Max-min Ratio: 1.2388059701492538
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-11-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 887.44
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 436
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.589
    dispatch_time_ms: 6.175
    learner:
      cur_lr: 0.0012728872243314981
      grad_gnorm: 13.842779159545898
      policy_entropy: 7.37964391708374
      policy_loss: 1.4876267910003662
      var_gnorm: 42.533905029296875
      vf_explained_var: 0.29272449016571045
      vf_loss: 11.167619705200195
    num_steps_sampled: 1311000
    num_steps_trained: 1311000
    wait_time_ms: 75.268
  iterations_since_restore: 437
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3742.9007942676544
  time_this_iter_s: 8.274611949920654
  time_total_s: 3742.9007942676544
  timestamp: 1594091514
  timesteps_since_restore: 1311000
  timesteps_this_iter: 3000
  timesteps_total: 1311000
  training_iteration: 437
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3742 s, 437 iter, 1311000 ts, 887 rew

agent-1: 320.0
agent-2: 351.0
agent-3: 341.0
Sum Reward: 1012.0
Avg Reward: 337.3333333333333
Min Reward: 320.0
Max Reward: 351.0
Gini Coefficient: 0.020421607378129116
20:20 Ratio: 1.096875
Max-min Ratio: 1.096875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-12-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 886.82
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 437
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.472
    dispatch_time_ms: 7.148
    learner:
      cur_lr: 0.0012726874556392431
      grad_gnorm: 38.97393798828125
      policy_entropy: 14.12055778503418
      policy_loss: 3.0463624000549316
      var_gnorm: 42.58807373046875
      vf_explained_var: 0.20863527059555054
      vf_loss: 27.749977111816406
    num_steps_sampled: 1314000
    num_steps_trained: 1314000
    wait_time_ms: 66.213
  iterations_since_restore: 438
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3750.846224308014
  time_this_iter_s: 7.945430040359497
  time_total_s: 3750.846224308014
  timestamp: 1594091522
  timesteps_since_restore: 1314000
  timesteps_this_iter: 3000
  timesteps_total: 1314000
  training_iteration: 438
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3750 s, 438 iter, 1314000 ts, 887 rew

agent-1: 277.0
agent-2: 296.0
agent-3: 274.0
Sum Reward: 847.0
Avg Reward: 282.3333333333333
Min Reward: 274.0
Max Reward: 296.0
Gini Coefficient: 0.017316017316017316
20:20 Ratio: 1.0802919708029197
Max-min Ratio: 1.0802919708029197
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-12-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 884.69
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 438
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.538
    dispatch_time_ms: 5.578
    learner:
      cur_lr: 0.0012724875705316663
      grad_gnorm: 40.0
      policy_entropy: 13.00868034362793
      policy_loss: -10.296857833862305
      var_gnorm: 42.59500503540039
      vf_explained_var: 0.17812150716781616
      vf_loss: 25.0202579498291
    num_steps_sampled: 1317000
    num_steps_trained: 1317000
    wait_time_ms: 75.625
  iterations_since_restore: 439
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3758.546996831894
  time_this_iter_s: 7.700772523880005
  time_total_s: 3758.546996831894
  timestamp: 1594091530
  timesteps_since_restore: 1317000
  timesteps_this_iter: 3000
  timesteps_total: 1317000
  training_iteration: 439
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3758 s, 439 iter, 1317000 ts, 885 rew

agent-1: 222.0
agent-2: 263.0
agent-3: 247.0
Sum Reward: 732.0
Avg Reward: 244.0
Min Reward: 222.0
Max Reward: 263.0
Gini Coefficient: 0.037340619307832425
20:20 Ratio: 1.1846846846846846
Max-min Ratio: 1.1846846846846846
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-12-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 882.13
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 439
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.82
    dispatch_time_ms: 5.799
    learner:
      cur_lr: 0.0012722878018394113
      grad_gnorm: 40.0
      policy_entropy: 8.20177936553955
      policy_loss: -6.2634429931640625
      var_gnorm: 42.52215576171875
      vf_explained_var: -0.48478496074676514
      vf_loss: 51.143306732177734
    num_steps_sampled: 1320000
    num_steps_trained: 1320000
    wait_time_ms: 69.969
  iterations_since_restore: 440
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3766.3528180122375
  time_this_iter_s: 7.805821180343628
  time_total_s: 3766.3528180122375
  timestamp: 1594091538
  timesteps_since_restore: 1320000
  timesteps_this_iter: 3000
  timesteps_total: 1320000
  training_iteration: 440
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3766 s, 440 iter, 1320000 ts, 882 rew

agent-1: 235.0
agent-2: 221.0
agent-3: 217.0
Sum Reward: 673.0
Avg Reward: 224.33333333333334
Min Reward: 217.0
Max Reward: 235.0
Gini Coefficient: 0.017830609212481426
20:20 Ratio: 1.0829493087557605
Max-min Ratio: 1.0829493087557605
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-12-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 879.08
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 440
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.182
    dispatch_time_ms: 9.207
    learner:
      cur_lr: 0.0012720880331471562
      grad_gnorm: 40.000003814697266
      policy_entropy: 14.210159301757812
      policy_loss: -12.79721736907959
      var_gnorm: 42.53928756713867
      vf_explained_var: 0.07913845777511597
      vf_loss: 23.36785125732422
    num_steps_sampled: 1323000
    num_steps_trained: 1323000
    wait_time_ms: 63.575
  iterations_since_restore: 441
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3773.8409135341644
  time_this_iter_s: 7.48809552192688
  time_total_s: 3773.8409135341644
  timestamp: 1594091545
  timesteps_since_restore: 1323000
  timesteps_this_iter: 3000
  timesteps_total: 1323000
  training_iteration: 441
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3773 s, 441 iter, 1323000 ts, 879 rew

agent-1: 219.0
agent-2: 199.0
agent-3: 210.0
Sum Reward: 628.0
Avg Reward: 209.33333333333334
Min Reward: 199.0
Max Reward: 219.0
Gini Coefficient: 0.021231422505307854
20:20 Ratio: 1.100502512562814
Max-min Ratio: 1.100502512562814
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-12-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 876.39
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 441
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.346
    dispatch_time_ms: 7.577
    learner:
      cur_lr: 0.0012718881480395794
      grad_gnorm: 40.0
      policy_entropy: 7.370485305786133
      policy_loss: 9.137382507324219
      var_gnorm: 42.50120162963867
      vf_explained_var: 0.037328243255615234
      vf_loss: 34.081451416015625
    num_steps_sampled: 1326000
    num_steps_trained: 1326000
    wait_time_ms: 69.787
  iterations_since_restore: 442
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3781.599099636078
  time_this_iter_s: 7.758186101913452
  time_total_s: 3781.599099636078
  timestamp: 1594091553
  timesteps_since_restore: 1326000
  timesteps_this_iter: 3000
  timesteps_total: 1326000
  training_iteration: 442
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3781 s, 442 iter, 1326000 ts, 876 rew

agent-1: 223.0
agent-2: 255.0
agent-3: 158.0
Sum Reward: 636.0
Avg Reward: 212.0
Min Reward: 158.0
Max Reward: 255.0
Gini Coefficient: 0.10167714884696016
20:20 Ratio: 1.6139240506329113
Max-min Ratio: 1.6139240506329113
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-12-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 873.61
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 442
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.653
    dispatch_time_ms: 5.893
    learner:
      cur_lr: 0.0012716883793473244
      grad_gnorm: 17.756725311279297
      policy_entropy: 12.074626922607422
      policy_loss: 4.78010892868042
      var_gnorm: 42.466033935546875
      vf_explained_var: -0.022046685218811035
      vf_loss: 12.602605819702148
    num_steps_sampled: 1329000
    num_steps_trained: 1329000
    wait_time_ms: 68.339
  iterations_since_restore: 443
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3789.0304272174835
  time_this_iter_s: 7.43132758140564
  time_total_s: 3789.0304272174835
  timestamp: 1594091561
  timesteps_since_restore: 1329000
  timesteps_this_iter: 3000
  timesteps_total: 1329000
  training_iteration: 443
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3789 s, 443 iter, 1329000 ts, 874 rew

agent-1: 129.0
agent-2: 156.0
agent-3: 181.0
Sum Reward: 466.0
Avg Reward: 155.33333333333334
Min Reward: 129.0
Max Reward: 181.0
Gini Coefficient: 0.07439198855507868
20:20 Ratio: 1.4031007751937985
Max-min Ratio: 1.4031007751937985
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-12-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 868.52
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 443
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.145
    dispatch_time_ms: 6.405
    learner:
      cur_lr: 0.0012714886106550694
      grad_gnorm: 39.999996185302734
      policy_entropy: 6.016117095947266
      policy_loss: -1.3508665561676025
      var_gnorm: 42.46034622192383
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 18.237117767333984
    num_steps_sampled: 1332000
    num_steps_trained: 1332000
    wait_time_ms: 62.409
  iterations_since_restore: 444
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3796.4423480033875
  time_this_iter_s: 7.411920785903931
  time_total_s: 3796.4423480033875
  timestamp: 1594091568
  timesteps_since_restore: 1332000
  timesteps_this_iter: 3000
  timesteps_total: 1332000
  training_iteration: 444
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3796 s, 444 iter, 1332000 ts, 869 rew

agent-1: 144.0
agent-2: 234.0
agent-3: 185.0
Sum Reward: 563.0
Avg Reward: 187.66666666666666
Min Reward: 144.0
Max Reward: 234.0
Gini Coefficient: 0.10657193605683836
20:20 Ratio: 1.625
Max-min Ratio: 1.625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-12-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 864.23
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 444
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.748
    dispatch_time_ms: 6.999
    learner:
      cur_lr: 0.0012712888419628143
      grad_gnorm: 17.78007698059082
      policy_entropy: 10.357271194458008
      policy_loss: -1.17759370803833
      var_gnorm: 42.44334411621094
      vf_explained_var: 0.06419593095779419
      vf_loss: 19.235698699951172
    num_steps_sampled: 1335000
    num_steps_trained: 1335000
    wait_time_ms: 66.049
  iterations_since_restore: 445
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3803.862072467804
  time_this_iter_s: 7.419724464416504
  time_total_s: 3803.862072467804
  timestamp: 1594091576
  timesteps_since_restore: 1335000
  timesteps_this_iter: 3000
  timesteps_total: 1335000
  training_iteration: 445
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3803 s, 445 iter, 1335000 ts, 864 rew

agent-1: 136.0
agent-2: 178.0
agent-3: 199.0
Sum Reward: 513.0
Avg Reward: 171.0
Min Reward: 136.0
Max Reward: 199.0
Gini Coefficient: 0.08187134502923976
20:20 Ratio: 1.463235294117647
Max-min Ratio: 1.463235294117647
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-13-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 859.08
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 445
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.593
    dispatch_time_ms: 8.358
    learner:
      cur_lr: 0.0012710889568552375
      grad_gnorm: 40.0
      policy_entropy: 10.512744903564453
      policy_loss: -5.860879898071289
      var_gnorm: 42.441986083984375
      vf_explained_var: -0.04782402515411377
      vf_loss: 17.704538345336914
    num_steps_sampled: 1338000
    num_steps_trained: 1338000
    wait_time_ms: 65.382
  iterations_since_restore: 446
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3811.825097799301
  time_this_iter_s: 7.963025331497192
  time_total_s: 3811.825097799301
  timestamp: 1594091584
  timesteps_since_restore: 1338000
  timesteps_this_iter: 3000
  timesteps_total: 1338000
  training_iteration: 446
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3811 s, 446 iter, 1338000 ts, 859 rew

agent-1: 187.0
agent-2: 222.0
agent-3: 118.0
Sum Reward: 527.0
Avg Reward: 175.66666666666666
Min Reward: 118.0
Max Reward: 222.0
Gini Coefficient: 0.13156230234029095
20:20 Ratio: 1.88135593220339
Max-min Ratio: 1.88135593220339
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-13-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 853.16
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 446
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.452
    dispatch_time_ms: 7.406
    learner:
      cur_lr: 0.0012708891881629825
      grad_gnorm: 20.762645721435547
      policy_entropy: 11.577617645263672
      policy_loss: 0.046746909618377686
      var_gnorm: 42.43345260620117
      vf_explained_var: 0.0798957347869873
      vf_loss: 17.70378303527832
    num_steps_sampled: 1341000
    num_steps_trained: 1341000
    wait_time_ms: 66.844
  iterations_since_restore: 447
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3819.4306716918945
  time_this_iter_s: 7.605573892593384
  time_total_s: 3819.4306716918945
  timestamp: 1594091591
  timesteps_since_restore: 1341000
  timesteps_this_iter: 3000
  timesteps_total: 1341000
  training_iteration: 447
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3819 s, 447 iter, 1341000 ts, 853 rew

agent-1: 218.0
agent-2: 258.0
agent-3: 211.0
Sum Reward: 687.0
Avg Reward: 229.0
Min Reward: 211.0
Max Reward: 258.0
Gini Coefficient: 0.045608927704997575
20:20 Ratio: 1.2227488151658767
Max-min Ratio: 1.2227488151658767
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-13-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 848.03
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 447
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.274
    dispatch_time_ms: 9.163
    learner:
      cur_lr: 0.0012706894194707274
      grad_gnorm: 40.00000762939453
      policy_entropy: 10.650721549987793
      policy_loss: 24.228107452392578
      var_gnorm: 42.428157806396484
      vf_explained_var: -0.1821730136871338
      vf_loss: 44.922760009765625
    num_steps_sampled: 1344000
    num_steps_trained: 1344000
    wait_time_ms: 66.049
  iterations_since_restore: 448
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3827.144932985306
  time_this_iter_s: 7.714261293411255
  time_total_s: 3827.144932985306
  timestamp: 1594091599
  timesteps_since_restore: 1344000
  timesteps_this_iter: 3000
  timesteps_total: 1344000
  training_iteration: 448
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3827 s, 448 iter, 1344000 ts, 848 rew

agent-1: 274.0
agent-2: 238.0
agent-3: 186.0
Sum Reward: 698.0
Avg Reward: 232.66666666666666
Min Reward: 186.0
Max Reward: 274.0
Gini Coefficient: 0.08404966571155682
20:20 Ratio: 1.4731182795698925
Max-min Ratio: 1.4731182795698925
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-13-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 843.7
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 448
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.921
    dispatch_time_ms: 7.478
    learner:
      cur_lr: 0.0012704896507784724
      grad_gnorm: 40.0
      policy_entropy: 22.497182846069336
      policy_loss: 9.576797485351562
      var_gnorm: 42.46110534667969
      vf_explained_var: 0.2677740454673767
      vf_loss: 16.632680892944336
    num_steps_sampled: 1347000
    num_steps_trained: 1347000
    wait_time_ms: 74.802
  iterations_since_restore: 449
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3835.183305501938
  time_this_iter_s: 8.03837251663208
  time_total_s: 3835.183305501938
  timestamp: 1594091607
  timesteps_since_restore: 1347000
  timesteps_this_iter: 3000
  timesteps_total: 1347000
  training_iteration: 449
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3835 s, 449 iter, 1347000 ts, 844 rew

agent-1: 265.0
agent-2: 287.0
agent-3: 301.0
Sum Reward: 853.0
Avg Reward: 284.3333333333333
Min Reward: 265.0
Max Reward: 301.0
Gini Coefficient: 0.02813599062133646
20:20 Ratio: 1.1358490566037736
Max-min Ratio: 1.1358490566037736
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-13-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 840.54
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 449
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.298
    dispatch_time_ms: 5.943
    learner:
      cur_lr: 0.0012702897656708956
      grad_gnorm: 40.0
      policy_entropy: 21.554658889770508
      policy_loss: 14.82787799835205
      var_gnorm: 42.53432846069336
      vf_explained_var: -0.050148725509643555
      vf_loss: 29.81877899169922
    num_steps_sampled: 1350000
    num_steps_trained: 1350000
    wait_time_ms: 78.152
  iterations_since_restore: 450
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3843.5841727256775
  time_this_iter_s: 8.400867223739624
  time_total_s: 3843.5841727256775
  timestamp: 1594091615
  timesteps_since_restore: 1350000
  timesteps_this_iter: 3000
  timesteps_total: 1350000
  training_iteration: 450
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3843 s, 450 iter, 1350000 ts, 841 rew

agent-1: 298.0
agent-2: 325.0
agent-3: 283.0
Sum Reward: 906.0
Avg Reward: 302.0
Min Reward: 283.0
Max Reward: 325.0
Gini Coefficient: 0.03090507726269316
20:20 Ratio: 1.1484098939929328
Max-min Ratio: 1.1484098939929328
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-13-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 839.55
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 450
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.406
    dispatch_time_ms: 8.094
    learner:
      cur_lr: 0.0012700899969786406
      grad_gnorm: 40.0
      policy_entropy: 29.04537582397461
      policy_loss: -26.360591888427734
      var_gnorm: 42.68857955932617
      vf_explained_var: -0.018320322036743164
      vf_loss: 18.25630760192871
    num_steps_sampled: 1353000
    num_steps_trained: 1353000
    wait_time_ms: 69.726
  iterations_since_restore: 451
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3851.6784749031067
  time_this_iter_s: 8.0943021774292
  time_total_s: 3851.6784749031067
  timestamp: 1594091624
  timesteps_since_restore: 1353000
  timesteps_this_iter: 3000
  timesteps_total: 1353000
  training_iteration: 451
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3851 s, 451 iter, 1353000 ts, 840 rew

agent-1: 225.0
agent-2: 328.0
agent-3: 289.0
Sum Reward: 842.0
Avg Reward: 280.6666666666667
Min Reward: 225.0
Max Reward: 328.0
Gini Coefficient: 0.08155186064924783
20:20 Ratio: 1.4577777777777778
Max-min Ratio: 1.4577777777777778
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-13-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 838.95
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 451
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.507
    dispatch_time_ms: 6.016
    learner:
      cur_lr: 0.0012698902282863855
      grad_gnorm: 40.0
      policy_entropy: 26.37510871887207
      policy_loss: -15.333168983459473
      var_gnorm: 42.67665100097656
      vf_explained_var: -0.0016945600509643555
      vf_loss: 31.33601188659668
    num_steps_sampled: 1356000
    num_steps_trained: 1356000
    wait_time_ms: 74.71
  iterations_since_restore: 452
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3859.761160850525
  time_this_iter_s: 8.082685947418213
  time_total_s: 3859.761160850525
  timestamp: 1594091632
  timesteps_since_restore: 1356000
  timesteps_this_iter: 3000
  timesteps_total: 1356000
  training_iteration: 452
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3859 s, 452 iter, 1356000 ts, 839 rew

agent-1: 299.0
agent-2: 283.0
agent-3: 265.0
Sum Reward: 847.0
Avg Reward: 282.3333333333333
Min Reward: 265.0
Max Reward: 299.0
Gini Coefficient: 0.02676111767020858
20:20 Ratio: 1.1283018867924528
Max-min Ratio: 1.1283018867924528
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-14-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 839.48
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 452
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.536
    dispatch_time_ms: 5.482
    learner:
      cur_lr: 0.0012696903431788087
      grad_gnorm: 40.0
      policy_entropy: 18.892135620117188
      policy_loss: 12.102507591247559
      var_gnorm: 42.61949920654297
      vf_explained_var: -0.32288169860839844
      vf_loss: 46.454261779785156
    num_steps_sampled: 1359000
    num_steps_trained: 1359000
    wait_time_ms: 78.727
  iterations_since_restore: 453
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3867.9065506458282
  time_this_iter_s: 8.145389795303345
  time_total_s: 3867.9065506458282
  timestamp: 1594091640
  timesteps_since_restore: 1359000
  timesteps_this_iter: 3000
  timesteps_total: 1359000
  training_iteration: 453
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3867 s, 453 iter, 1359000 ts, 839 rew

agent-1: 291.0
agent-2: 327.0
agent-3: 308.0
Sum Reward: 926.0
Avg Reward: 308.6666666666667
Min Reward: 291.0
Max Reward: 327.0
Gini Coefficient: 0.02591792656587473
20:20 Ratio: 1.1237113402061856
Max-min Ratio: 1.1237113402061856
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-14-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 843.36
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 453
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.553
    dispatch_time_ms: 10.033
    learner:
      cur_lr: 0.0012694905744865537
      grad_gnorm: 18.748411178588867
      policy_entropy: 18.74427604675293
      policy_loss: 4.55381441116333
      var_gnorm: 42.795127868652344
      vf_explained_var: -0.9240360260009766
      vf_loss: 17.984222412109375
    num_steps_sampled: 1362000
    num_steps_trained: 1362000
    wait_time_ms: 67.737
  iterations_since_restore: 454
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3876.0972962379456
  time_this_iter_s: 8.19074559211731
  time_total_s: 3876.0972962379456
  timestamp: 1594091648
  timesteps_since_restore: 1362000
  timesteps_this_iter: 3000
  timesteps_total: 1362000
  training_iteration: 454
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3876 s, 454 iter, 1362000 ts, 843 rew

agent-1: 312.0
agent-2: 271.0
agent-3: 321.0
Sum Reward: 904.0
Avg Reward: 301.3333333333333
Min Reward: 271.0
Max Reward: 321.0
Gini Coefficient: 0.03687315634218289
20:20 Ratio: 1.1845018450184501
Max-min Ratio: 1.1845018450184501
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-14-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 847.95
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 454
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.925
    dispatch_time_ms: 6.657
    learner:
      cur_lr: 0.0012692908057942986
      grad_gnorm: 40.0
      policy_entropy: 21.346588134765625
      policy_loss: -11.495705604553223
      var_gnorm: 42.77600860595703
      vf_explained_var: 0.042875587940216064
      vf_loss: 45.49626541137695
    num_steps_sampled: 1365000
    num_steps_trained: 1365000
    wait_time_ms: 73.628
  iterations_since_restore: 455
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3883.980395555496
  time_this_iter_s: 7.883099317550659
  time_total_s: 3883.980395555496
  timestamp: 1594091656
  timesteps_since_restore: 1365000
  timesteps_this_iter: 3000
  timesteps_total: 1365000
  training_iteration: 455
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3883 s, 455 iter, 1365000 ts, 848 rew

agent-1: 290.0
agent-2: 337.0
agent-3: 266.0
Sum Reward: 893.0
Avg Reward: 297.6666666666667
Min Reward: 266.0
Max Reward: 337.0
Gini Coefficient: 0.05300485255692423
20:20 Ratio: 1.2669172932330828
Max-min Ratio: 1.2669172932330828
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-14-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 849.39
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 455
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.734
    dispatch_time_ms: 8.661
    learner:
      cur_lr: 0.0012690910371020436
      grad_gnorm: 40.0
      policy_entropy: 21.213722229003906
      policy_loss: -19.83310890197754
      var_gnorm: 42.84759521484375
      vf_explained_var: -0.04456162452697754
      vf_loss: 23.241641998291016
    num_steps_sampled: 1368000
    num_steps_trained: 1368000
    wait_time_ms: 69.323
  iterations_since_restore: 456
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3892.2235095500946
  time_this_iter_s: 8.243113994598389
  time_total_s: 3892.2235095500946
  timestamp: 1594091664
  timesteps_since_restore: 1368000
  timesteps_this_iter: 3000
  timesteps_total: 1368000
  training_iteration: 456
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3892 s, 456 iter, 1368000 ts, 849 rew

agent-1: 307.0
agent-2: 350.0
agent-3: 322.0
Sum Reward: 979.0
Avg Reward: 326.3333333333333
Min Reward: 307.0
Max Reward: 350.0
Gini Coefficient: 0.029281579843377595
20:20 Ratio: 1.1400651465798046
Max-min Ratio: 1.1400651465798046
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-14-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 850.32
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 456
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.907
    dispatch_time_ms: 7.356
    learner:
      cur_lr: 0.0012688911519944668
      grad_gnorm: 28.68870735168457
      policy_entropy: 12.581665992736816
      policy_loss: -6.334599494934082
      var_gnorm: 42.852664947509766
      vf_explained_var: 0.19385641813278198
      vf_loss: 8.29779052734375
    num_steps_sampled: 1371000
    num_steps_trained: 1371000
    wait_time_ms: 69.966
  iterations_since_restore: 457
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3900.186806678772
  time_this_iter_s: 7.963297128677368
  time_total_s: 3900.186806678772
  timestamp: 1594091672
  timesteps_since_restore: 1371000
  timesteps_this_iter: 3000
  timesteps_total: 1371000
  training_iteration: 457
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3900 s, 457 iter, 1371000 ts, 850 rew

agent-1: 316.0
agent-2: 296.0
agent-3: 293.0
Sum Reward: 905.0
Avg Reward: 301.6666666666667
Min Reward: 293.0
Max Reward: 316.0
Gini Coefficient: 0.01694290976058932
20:20 Ratio: 1.0784982935153584
Max-min Ratio: 1.0784982935153584
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-14-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 849.17
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 457
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.422
    dispatch_time_ms: 12.726
    learner:
      cur_lr: 0.0012686913833022118
      grad_gnorm: 16.5473690032959
      policy_entropy: 13.757942199707031
      policy_loss: 3.957491397857666
      var_gnorm: 42.90012741088867
      vf_explained_var: -0.041745662689208984
      vf_loss: 12.586061477661133
    num_steps_sampled: 1374000
    num_steps_trained: 1374000
    wait_time_ms: 35.699
  iterations_since_restore: 458
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3913.094282388687
  time_this_iter_s: 12.907475709915161
  time_total_s: 3913.094282388687
  timestamp: 1594091685
  timesteps_since_restore: 1374000
  timesteps_this_iter: 3000
  timesteps_total: 1374000
  training_iteration: 458
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3913 s, 458 iter, 1374000 ts, 849 rew

agent-1: 289.0
agent-2: 305.0
agent-3: 321.0
Sum Reward: 915.0
Avg Reward: 305.0
Min Reward: 289.0
Max Reward: 321.0
Gini Coefficient: 0.02331511839708561
20:20 Ratio: 1.1107266435986158
Max-min Ratio: 1.1107266435986158
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-14-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 850.04
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 458
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.713
    dispatch_time_ms: 5.821
    learner:
      cur_lr: 0.0012684916146099567
      grad_gnorm: 40.0
      policy_entropy: 16.304460525512695
      policy_loss: 23.036399841308594
      var_gnorm: 42.924468994140625
      vf_explained_var: -0.3409799337387085
      vf_loss: 35.64232635498047
    num_steps_sampled: 1377000
    num_steps_trained: 1377000
    wait_time_ms: 76.441
  iterations_since_restore: 459
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3921.0065338611603
  time_this_iter_s: 7.9122514724731445
  time_total_s: 3921.0065338611603
  timestamp: 1594091693
  timesteps_since_restore: 1377000
  timesteps_this_iter: 3000
  timesteps_total: 1377000
  training_iteration: 459
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3921 s, 459 iter, 1377000 ts, 850 rew

agent-1: 294.0
agent-2: 306.0
agent-3: 305.0
Sum Reward: 905.0
Avg Reward: 301.6666666666667
Min Reward: 294.0
Max Reward: 306.0
Gini Coefficient: 0.008839779005524863
20:20 Ratio: 1.0408163265306123
Max-min Ratio: 1.0408163265306123
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-15-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 850.68
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 459
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.848
    dispatch_time_ms: 6.735
    learner:
      cur_lr: 0.0012682918459177017
      grad_gnorm: 33.823543548583984
      policy_entropy: 30.211511611938477
      policy_loss: -4.034013748168945
      var_gnorm: 42.969425201416016
      vf_explained_var: -0.004202008247375488
      vf_loss: 7.769901752471924
    num_steps_sampled: 1380000
    num_steps_trained: 1380000
    wait_time_ms: 72.036
  iterations_since_restore: 460
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3929.1448237895966
  time_this_iter_s: 8.13828992843628
  time_total_s: 3929.1448237895966
  timestamp: 1594091701
  timesteps_since_restore: 1380000
  timesteps_this_iter: 3000
  timesteps_total: 1380000
  training_iteration: 460
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3929 s, 460 iter, 1380000 ts, 851 rew

agent-1: 219.0
agent-2: 259.0
agent-3: 283.0
Sum Reward: 761.0
Avg Reward: 253.66666666666666
Min Reward: 219.0
Max Reward: 283.0
Gini Coefficient: 0.05606657906263688
20:20 Ratio: 1.2922374429223744
Max-min Ratio: 1.2922374429223744
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-15-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 850.77
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 460
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.827
    dispatch_time_ms: 8.151
    learner:
      cur_lr: 0.0012680919608101249
      grad_gnorm: 30.849971771240234
      policy_entropy: 21.28927993774414
      policy_loss: 2.3344497680664062
      var_gnorm: 42.91757583618164
      vf_explained_var: 0.19104361534118652
      vf_loss: 33.080623626708984
    num_steps_sampled: 1383000
    num_steps_trained: 1383000
    wait_time_ms: 72.496
  iterations_since_restore: 461
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3937.099605321884
  time_this_iter_s: 7.954781532287598
  time_total_s: 3937.099605321884
  timestamp: 1594091709
  timesteps_since_restore: 1383000
  timesteps_this_iter: 3000
  timesteps_total: 1383000
  training_iteration: 461
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3937 s, 461 iter, 1383000 ts, 851 rew

agent-1: 289.0
agent-2: 300.0
agent-3: 299.0
Sum Reward: 888.0
Avg Reward: 296.0
Min Reward: 289.0
Max Reward: 300.0
Gini Coefficient: 0.008258258258258258
20:20 Ratio: 1.0380622837370241
Max-min Ratio: 1.0380622837370241
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-15-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 852.8
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 461
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.69
    dispatch_time_ms: 9.158
    learner:
      cur_lr: 0.0012678921921178699
      grad_gnorm: 40.0
      policy_entropy: 23.21127700805664
      policy_loss: -27.673133850097656
      var_gnorm: 42.96821594238281
      vf_explained_var: 0.6099843978881836
      vf_loss: 28.133474349975586
    num_steps_sampled: 1386000
    num_steps_trained: 1386000
    wait_time_ms: 73.134
  iterations_since_restore: 462
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3945.2266385555267
  time_this_iter_s: 8.127033233642578
  time_total_s: 3945.2266385555267
  timestamp: 1594091718
  timesteps_since_restore: 1386000
  timesteps_this_iter: 3000
  timesteps_total: 1386000
  training_iteration: 462
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3945 s, 462 iter, 1386000 ts, 853 rew

agent-1: 249.0
agent-2: 291.0
agent-3: 317.0
Sum Reward: 857.0
Avg Reward: 285.6666666666667
Min Reward: 249.0
Max Reward: 317.0
Gini Coefficient: 0.052897705173084404
20:20 Ratio: 1.2730923694779117
Max-min Ratio: 1.2730923694779117
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-15-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 855.2
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 462
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.538
    dispatch_time_ms: 8.204
    learner:
      cur_lr: 0.0012676924234256148
      grad_gnorm: 40.0
      policy_entropy: 14.82016658782959
      policy_loss: 10.151183128356934
      var_gnorm: 42.936031341552734
      vf_explained_var: 0.08981853723526001
      vf_loss: 58.36499786376953
    num_steps_sampled: 1389000
    num_steps_trained: 1389000
    wait_time_ms: 71.625
  iterations_since_restore: 463
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3953.3979897499084
  time_this_iter_s: 8.171351194381714
  time_total_s: 3953.3979897499084
  timestamp: 1594091726
  timesteps_since_restore: 1389000
  timesteps_this_iter: 3000
  timesteps_total: 1389000
  training_iteration: 463
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3953 s, 463 iter, 1389000 ts, 855 rew

agent-1: 316.0
agent-2: 318.0
agent-3: 334.0
Sum Reward: 968.0
Avg Reward: 322.6666666666667
Min Reward: 316.0
Max Reward: 334.0
Gini Coefficient: 0.012396694214876033
20:20 Ratio: 1.0569620253164558
Max-min Ratio: 1.0569620253164558
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-15-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 858.58
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 463
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.76
    dispatch_time_ms: 6.535
    learner:
      cur_lr: 0.0012674926547333598
      grad_gnorm: 40.000003814697266
      policy_entropy: 15.947718620300293
      policy_loss: 24.612415313720703
      var_gnorm: 42.970314025878906
      vf_explained_var: -0.09291303157806396
      vf_loss: 47.474761962890625
    num_steps_sampled: 1392000
    num_steps_trained: 1392000
    wait_time_ms: 75.474
  iterations_since_restore: 464
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3961.745742559433
  time_this_iter_s: 8.347752809524536
  time_total_s: 3961.745742559433
  timestamp: 1594091734
  timesteps_since_restore: 1392000
  timesteps_this_iter: 3000
  timesteps_total: 1392000
  training_iteration: 464
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3961 s, 464 iter, 1392000 ts, 859 rew

agent-1: 342.0
agent-2: 305.0
agent-3: 322.0
Sum Reward: 969.0
Avg Reward: 323.0
Min Reward: 305.0
Max Reward: 342.0
Gini Coefficient: 0.02545579635362917
20:20 Ratio: 1.1213114754098361
Max-min Ratio: 1.1213114754098361
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-15-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 861.28
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 464
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.555
    dispatch_time_ms: 6.673
    learner:
      cur_lr: 0.001267292769625783
      grad_gnorm: 40.0
      policy_entropy: 14.29194450378418
      policy_loss: 11.46059799194336
      var_gnorm: 42.99492645263672
      vf_explained_var: -0.10700380802154541
      vf_loss: 42.0084228515625
    num_steps_sampled: 1395000
    num_steps_trained: 1395000
    wait_time_ms: 72.202
  iterations_since_restore: 465
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3970.0333380699158
  time_this_iter_s: 8.287595510482788
  time_total_s: 3970.0333380699158
  timestamp: 1594091742
  timesteps_since_restore: 1395000
  timesteps_this_iter: 3000
  timesteps_total: 1395000
  training_iteration: 465
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3970 s, 465 iter, 1395000 ts, 861 rew

agent-1: 344.0
agent-2: 343.0
agent-3: 322.0
Sum Reward: 1009.0
Avg Reward: 336.3333333333333
Min Reward: 322.0
Max Reward: 344.0
Gini Coefficient: 0.01453584407003634
20:20 Ratio: 1.0683229813664596
Max-min Ratio: 1.0683229813664596
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-15-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 861.2
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 465
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.219
    dispatch_time_ms: 5.5
    learner:
      cur_lr: 0.001267093000933528
      grad_gnorm: 39.999996185302734
      policy_entropy: 20.024152755737305
      policy_loss: 18.885953903198242
      var_gnorm: 43.06808853149414
      vf_explained_var: -0.16236066818237305
      vf_loss: 25.37255096435547
    num_steps_sampled: 1398000
    num_steps_trained: 1398000
    wait_time_ms: 78.913
  iterations_since_restore: 466
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3978.4991958141327
  time_this_iter_s: 8.465857744216919
  time_total_s: 3978.4991958141327
  timestamp: 1594091751
  timesteps_since_restore: 1398000
  timesteps_this_iter: 3000
  timesteps_total: 1398000
  training_iteration: 466
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3978 s, 466 iter, 1398000 ts, 861 rew

agent-1: 344.0
agent-2: 310.0
agent-3: 348.0
Sum Reward: 1002.0
Avg Reward: 334.0
Min Reward: 310.0
Max Reward: 348.0
Gini Coefficient: 0.025282767797737856
20:20 Ratio: 1.1225806451612903
Max-min Ratio: 1.1225806451612903
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-15-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 862.87
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 466
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.71
    dispatch_time_ms: 35.456
    learner:
      cur_lr: 0.001266893232241273
      grad_gnorm: 39.999996185302734
      policy_entropy: 18.495813369750977
      policy_loss: -10.229684829711914
      var_gnorm: 43.120906829833984
      vf_explained_var: 0.38500291109085083
      vf_loss: 16.72815704345703
    num_steps_sampled: 1401000
    num_steps_trained: 1401000
    wait_time_ms: 48.241
  iterations_since_restore: 467
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3986.883815050125
  time_this_iter_s: 8.384619235992432
  time_total_s: 3986.883815050125
  timestamp: 1594091759
  timesteps_since_restore: 1401000
  timesteps_this_iter: 3000
  timesteps_total: 1401000
  training_iteration: 467
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3986 s, 467 iter, 1401000 ts, 863 rew

agent-1: 309.0
agent-2: 347.0
agent-3: 322.0
Sum Reward: 978.0
Avg Reward: 326.0
Min Reward: 309.0
Max Reward: 347.0
Gini Coefficient: 0.025903203817314247
20:20 Ratio: 1.1229773462783172
Max-min Ratio: 1.1229773462783172
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-16-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 867.75
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 467
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.003
    dispatch_time_ms: 27.919
    learner:
      cur_lr: 0.001266693347133696
      grad_gnorm: 40.0
      policy_entropy: 17.5
      policy_loss: -15.789237976074219
      var_gnorm: 43.11278533935547
      vf_explained_var: 0.5853976607322693
      vf_loss: 22.378314971923828
    num_steps_sampled: 1404000
    num_steps_trained: 1404000
    wait_time_ms: 38.05
  iterations_since_restore: 468
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 3995.6311688423157
  time_this_iter_s: 8.747353792190552
  time_total_s: 3995.6311688423157
  timestamp: 1594091768
  timesteps_since_restore: 1404000
  timesteps_this_iter: 3000
  timesteps_total: 1404000
  training_iteration: 468
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 3995 s, 468 iter, 1404000 ts, 868 rew

agent-1: 285.0
agent-2: 311.0
agent-3: 278.0
Sum Reward: 874.0
Avg Reward: 291.3333333333333
Min Reward: 278.0
Max Reward: 311.0
Gini Coefficient: 0.02517162471395881
20:20 Ratio: 1.118705035971223
Max-min Ratio: 1.118705035971223
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-16-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 870.67
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 468
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.591
    dispatch_time_ms: 29.684
    learner:
      cur_lr: 0.001266493578441441
      grad_gnorm: 15.820425987243652
      policy_entropy: 19.671794891357422
      policy_loss: -0.7075531482696533
      var_gnorm: 43.1303596496582
      vf_explained_var: 0.6135687828063965
      vf_loss: 5.037534236907959
    num_steps_sampled: 1407000
    num_steps_trained: 1407000
    wait_time_ms: 51.348
  iterations_since_restore: 469
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 4004.4361186027527
  time_this_iter_s: 8.804949760437012
  time_total_s: 4004.4361186027527
  timestamp: 1594091777
  timesteps_since_restore: 1407000
  timesteps_this_iter: 3000
  timesteps_total: 1407000
  training_iteration: 469
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 4004 s, 469 iter, 1407000 ts, 871 rew

agent-1: 291.0
agent-2: 329.0
agent-3: 287.0
Sum Reward: 907.0
Avg Reward: 302.3333333333333
Min Reward: 287.0
Max Reward: 329.0
Gini Coefficient: 0.030871003307607496
20:20 Ratio: 1.146341463414634
Max-min Ratio: 1.146341463414634
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-16-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 871.57
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 469
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.704
    dispatch_time_ms: 35.288
    learner:
      cur_lr: 0.001266293809749186
      grad_gnorm: 24.603410720825195
      policy_entropy: 18.83420181274414
      policy_loss: 2.307093381881714
      var_gnorm: 43.116641998291016
      vf_explained_var: -0.4490460157394409
      vf_loss: 20.422760009765625
    num_steps_sampled: 1410000
    num_steps_trained: 1410000
    wait_time_ms: 53.095
  iterations_since_restore: 470
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 4013.2268567085266
  time_this_iter_s: 8.790738105773926
  time_total_s: 4013.2268567085266
  timestamp: 1594091786
  timesteps_since_restore: 1410000
  timesteps_this_iter: 3000
  timesteps_total: 1410000
  training_iteration: 470
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 4013 s, 470 iter, 1410000 ts, 872 rew

agent-1: 307.0
agent-2: 303.0
agent-3: 308.0
Sum Reward: 918.0
Avg Reward: 306.0
Min Reward: 303.0
Max Reward: 308.0
Gini Coefficient: 0.0036310820624546117
20:20 Ratio: 1.0165016501650166
Max-min Ratio: 1.0165016501650166
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-16-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 872.0
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 470
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.006
    dispatch_time_ms: 5.447
    learner:
      cur_lr: 0.001266094041056931
      grad_gnorm: 28.994789123535156
      policy_entropy: 17.233070373535156
      policy_loss: -7.438051223754883
      var_gnorm: 43.16160583496094
      vf_explained_var: 0.13581466674804688
      vf_loss: 10.75687026977539
    num_steps_sampled: 1413000
    num_steps_trained: 1413000
    wait_time_ms: 72.204
  iterations_since_restore: 471
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 4021.662794828415
  time_this_iter_s: 8.435938119888306
  time_total_s: 4021.662794828415
  timestamp: 1594091794
  timesteps_since_restore: 1413000
  timesteps_this_iter: 3000
  timesteps_total: 1413000
  training_iteration: 471
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 4021 s, 471 iter, 1413000 ts, 872 rew

agent-1: 305.0
agent-2: 320.0
agent-3: 308.0
Sum Reward: 933.0
Avg Reward: 311.0
Min Reward: 305.0
Max Reward: 320.0
Gini Coefficient: 0.010718113612004287
20:20 Ratio: 1.0491803278688525
Max-min Ratio: 1.0491803278688525
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-16-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 871.45
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 471
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.867
    dispatch_time_ms: 7.716
    learner:
      cur_lr: 0.0012658941559493542
      grad_gnorm: 40.0
      policy_entropy: 11.6038236618042
      policy_loss: 25.169925689697266
      var_gnorm: 43.158905029296875
      vf_explained_var: -0.2445310354232788
      vf_loss: 52.98062515258789
    num_steps_sampled: 1416000
    num_steps_trained: 1416000
    wait_time_ms: 70.516
  iterations_since_restore: 472
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 4029.8812251091003
  time_this_iter_s: 8.218430280685425
  time_total_s: 4029.8812251091003
  timestamp: 1594091802
  timesteps_since_restore: 1416000
  timesteps_this_iter: 3000
  timesteps_total: 1416000
  training_iteration: 472
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 4029 s, 472 iter, 1416000 ts, 871 rew

agent-1: 334.0
agent-2: 324.0
agent-3: 313.0
Sum Reward: 971.0
Avg Reward: 323.6666666666667
Min Reward: 313.0
Max Reward: 334.0
Gini Coefficient: 0.014418125643666324
20:20 Ratio: 1.0670926517571886
Max-min Ratio: 1.0670926517571886
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-16-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 869.67
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 472
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.566
    dispatch_time_ms: 5.676
    learner:
      cur_lr: 0.0012656943872570992
      grad_gnorm: 39.674224853515625
      policy_entropy: 6.444752216339111
      policy_loss: 2.719327211380005
      var_gnorm: 43.23595428466797
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 31.722606658935547
    num_steps_sampled: 1419000
    num_steps_trained: 1419000
    wait_time_ms: 74.809
  iterations_since_restore: 473
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 4037.7868807315826
  time_this_iter_s: 7.9056556224823
  time_total_s: 4037.7868807315826
  timestamp: 1594091810
  timesteps_since_restore: 1419000
  timesteps_this_iter: 3000
  timesteps_total: 1419000
  training_iteration: 473
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 4037 s, 473 iter, 1419000 ts, 870 rew

agent-1: 329.0
agent-2: 325.0
agent-3: 335.0
Sum Reward: 989.0
Avg Reward: 329.6666666666667
Min Reward: 325.0
Max Reward: 335.0
Gini Coefficient: 0.006740815638692282
20:20 Ratio: 1.0307692307692307
Max-min Ratio: 1.0307692307692307
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-16-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 867.69
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 473
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.77
    dispatch_time_ms: 9.071
    learner:
      cur_lr: 0.0012654946185648441
      grad_gnorm: 15.48946762084961
      policy_entropy: 17.88908576965332
      policy_loss: -8.162841796875
      var_gnorm: 43.30093002319336
      vf_explained_var: 0.3956342935562134
      vf_loss: 39.50279235839844
    num_steps_sampled: 1422000
    num_steps_trained: 1422000
    wait_time_ms: 67.509
  iterations_since_restore: 474
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 4045.8874785900116
  time_this_iter_s: 8.100597858428955
  time_total_s: 4045.8874785900116
  timestamp: 1594091819
  timesteps_since_restore: 1422000
  timesteps_this_iter: 3000
  timesteps_total: 1422000
  training_iteration: 474
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 4045 s, 474 iter, 1422000 ts, 868 rew

agent-1: 328.0
agent-2: 309.0
agent-3: 279.0
Sum Reward: 916.0
Avg Reward: 305.3333333333333
Min Reward: 279.0
Max Reward: 328.0
Gini Coefficient: 0.03566229985443959
20:20 Ratio: 1.1756272401433692
Max-min Ratio: 1.1756272401433692
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-17-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1264.0
  episode_reward_mean: 865.91
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 474
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.824
    dispatch_time_ms: 6.526
    learner:
      cur_lr: 0.0012652948498725891
      grad_gnorm: 30.39032745361328
      policy_entropy: 22.18205451965332
      policy_loss: -6.80362606048584
      var_gnorm: 43.31517791748047
      vf_explained_var: 0.18773537874221802
      vf_loss: 13.196239471435547
    num_steps_sampled: 1425000
    num_steps_trained: 1425000
    wait_time_ms: 69.629
  iterations_since_restore: 475
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 4053.7917215824127
  time_this_iter_s: 7.904242992401123
  time_total_s: 4053.7917215824127
  timestamp: 1594091826
  timesteps_since_restore: 1425000
  timesteps_this_iter: 3000
  timesteps_total: 1425000
  training_iteration: 475
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 4053 s, 475 iter, 1425000 ts, 866 rew

agent-1: 265.0
agent-2: 304.0
agent-3: 277.0
Sum Reward: 846.0
Avg Reward: 282.0
Min Reward: 265.0
Max Reward: 304.0
Gini Coefficient: 0.030732860520094562
20:20 Ratio: 1.1471698113207547
Max-min Ratio: 1.1471698113207547
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-17-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1257.0
  episode_reward_mean: 861.73
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 475
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.61
    dispatch_time_ms: 7.311
    learner:
      cur_lr: 0.0012650949647650123
      grad_gnorm: 12.609029769897461
      policy_entropy: 25.144372940063477
      policy_loss: -3.1370811462402344
      var_gnorm: 43.30411148071289
      vf_explained_var: 0.16197580099105835
      vf_loss: 20.34322738647461
    num_steps_sampled: 1428000
    num_steps_trained: 1428000
    wait_time_ms: 67.43
  iterations_since_restore: 476
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 4061.8231830596924
  time_this_iter_s: 8.031461477279663
  time_total_s: 4061.8231830596924
  timestamp: 1594091835
  timesteps_since_restore: 1428000
  timesteps_this_iter: 3000
  timesteps_total: 1428000
  training_iteration: 476
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 4061 s, 476 iter, 1428000 ts, 862 rew

agent-1: 260.0
agent-2: 208.0
agent-3: 259.0
Sum Reward: 727.0
Avg Reward: 242.33333333333334
Min Reward: 208.0
Max Reward: 260.0
Gini Coefficient: 0.04768454837230628
20:20 Ratio: 1.25
Max-min Ratio: 1.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-17-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1257.0
  episode_reward_mean: 857.21
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 476
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.433
    dispatch_time_ms: 8.014
    learner:
      cur_lr: 0.0012648951960727572
      grad_gnorm: 19.65304946899414
      policy_entropy: 8.476984977722168
      policy_loss: 5.32958459854126
      var_gnorm: 43.22882080078125
      vf_explained_var: 0.282761812210083
      vf_loss: 7.039522647857666
    num_steps_sampled: 1431000
    num_steps_trained: 1431000
    wait_time_ms: 72.581
  iterations_since_restore: 477
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 4069.794466495514
  time_this_iter_s: 7.971283435821533
  time_total_s: 4069.794466495514
  timestamp: 1594091843
  timesteps_since_restore: 1431000
  timesteps_this_iter: 3000
  timesteps_total: 1431000
  training_iteration: 477
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 4069 s, 477 iter, 1431000 ts, 857 rew

agent-1: 281.0
agent-2: 279.0
agent-3: 299.0
Sum Reward: 859.0
Avg Reward: 286.3333333333333
Min Reward: 279.0
Max Reward: 299.0
Gini Coefficient: 0.015521924718665115
20:20 Ratio: 1.07168458781362
Max-min Ratio: 1.07168458781362
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-17-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1257.0
  episode_reward_mean: 853.75
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 477
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.656
    dispatch_time_ms: 4.927
    learner:
      cur_lr: 0.0012646954273805022
      grad_gnorm: 40.0
      policy_entropy: 17.149234771728516
      policy_loss: 14.196598052978516
      var_gnorm: 43.34510040283203
      vf_explained_var: 0.2108917236328125
      vf_loss: 70.99726104736328
    num_steps_sampled: 1434000
    num_steps_trained: 1434000
    wait_time_ms: 67.21
  iterations_since_restore: 478
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 4077.7726867198944
  time_this_iter_s: 7.978220224380493
  time_total_s: 4077.7726867198944
  timestamp: 1594091851
  timesteps_since_restore: 1434000
  timesteps_this_iter: 3000
  timesteps_total: 1434000
  training_iteration: 478
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 4077 s, 478 iter, 1434000 ts, 854 rew

agent-1: 275.0
agent-2: 260.0
agent-3: 263.0
Sum Reward: 798.0
Avg Reward: 266.0
Min Reward: 260.0
Max Reward: 275.0
Gini Coefficient: 0.012531328320802004
20:20 Ratio: 1.0576923076923077
Max-min Ratio: 1.0576923076923077
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-17-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1257.0
  episode_reward_mean: 849.55
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 478
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.704
    dispatch_time_ms: 9.079
    learner:
      cur_lr: 0.0012644955422729254
      grad_gnorm: 36.91215133666992
      policy_entropy: 28.237743377685547
      policy_loss: -17.588315963745117
      var_gnorm: 43.392784118652344
      vf_explained_var: 0.3010258674621582
      vf_loss: 18.761962890625
    num_steps_sampled: 1437000
    num_steps_trained: 1437000
    wait_time_ms: 68.246
  iterations_since_restore: 479
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 4085.717901945114
  time_this_iter_s: 7.945215225219727
  time_total_s: 4085.717901945114
  timestamp: 1594091859
  timesteps_since_restore: 1437000
  timesteps_this_iter: 3000
  timesteps_total: 1437000
  training_iteration: 479
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 4085 s, 479 iter, 1437000 ts, 850 rew

agent-1: 267.0
agent-2: 346.0
agent-3: 295.0
Sum Reward: 908.0
Avg Reward: 302.6666666666667
Min Reward: 267.0
Max Reward: 346.0
Gini Coefficient: 0.05800293685756241
20:20 Ratio: 1.2958801498127341
Max-min Ratio: 1.2958801498127341
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-17-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1255.0
  episode_reward_mean: 846.06
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 479
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.623
    dispatch_time_ms: 7.734
    learner:
      cur_lr: 0.0012642957735806704
      grad_gnorm: 13.250741958618164
      policy_entropy: 13.845330238342285
      policy_loss: 10.37708854675293
      var_gnorm: 43.38643264770508
      vf_explained_var: -0.24435198307037354
      vf_loss: 18.780433654785156
    num_steps_sampled: 1440000
    num_steps_trained: 1440000
    wait_time_ms: 70.662
  iterations_since_restore: 480
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 4093.692067861557
  time_this_iter_s: 7.974165916442871
  time_total_s: 4093.692067861557
  timestamp: 1594091867
  timesteps_since_restore: 1440000
  timesteps_this_iter: 3000
  timesteps_total: 1440000
  training_iteration: 480
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 4093 s, 480 iter, 1440000 ts, 846 rew

agent-1: 270.0
agent-2: 311.0
agent-3: 273.0
Sum Reward: 854.0
Avg Reward: 284.6666666666667
Min Reward: 270.0
Max Reward: 311.0
Gini Coefficient: 0.03200624512099922
20:20 Ratio: 1.151851851851852
Max-min Ratio: 1.151851851851852
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-17-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1255.0
  episode_reward_mean: 842.36
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 480
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.518
    dispatch_time_ms: 6.333
    learner:
      cur_lr: 0.0012640960048884153
      grad_gnorm: 39.999996185302734
      policy_entropy: 22.56468391418457
      policy_loss: -15.136743545532227
      var_gnorm: 43.45561218261719
      vf_explained_var: 0.41754186153411865
      vf_loss: 19.559232711791992
    num_steps_sampled: 1443000
    num_steps_trained: 1443000
    wait_time_ms: 72.7
  iterations_since_restore: 481
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 4101.699867486954
  time_this_iter_s: 8.007799625396729
  time_total_s: 4101.699867486954
  timestamp: 1594091875
  timesteps_since_restore: 1443000
  timesteps_this_iter: 3000
  timesteps_total: 1443000
  training_iteration: 481
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 4101 s, 481 iter, 1443000 ts, 842 rew

agent-1: 209.0
agent-2: 300.0
agent-3: 260.0
Sum Reward: 769.0
Avg Reward: 256.3333333333333
Min Reward: 209.0
Max Reward: 300.0
Gini Coefficient: 0.0788903337667967
20:20 Ratio: 1.4354066985645932
Max-min Ratio: 1.4354066985645932
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-18-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1255.0
  episode_reward_mean: 838.0
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 481
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.898
    dispatch_time_ms: 7.619
    learner:
      cur_lr: 0.0012638962361961603
      grad_gnorm: 28.170385360717773
      policy_entropy: 26.599987030029297
      policy_loss: -4.854072570800781
      var_gnorm: 43.541072845458984
      vf_explained_var: 0.05043220520019531
      vf_loss: 12.120223045349121
    num_steps_sampled: 1446000
    num_steps_trained: 1446000
    wait_time_ms: 67.389
  iterations_since_restore: 482
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 4109.571891784668
  time_this_iter_s: 7.872024297714233
  time_total_s: 4109.571891784668
  timestamp: 1594091883
  timesteps_since_restore: 1446000
  timesteps_this_iter: 3000
  timesteps_total: 1446000
  training_iteration: 482
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 4109 s, 482 iter, 1446000 ts, 838 rew

agent-1: 297.0
agent-2: 288.0
agent-3: 243.0
Sum Reward: 828.0
Avg Reward: 276.0
Min Reward: 243.0
Max Reward: 297.0
Gini Coefficient: 0.043478260869565216
20:20 Ratio: 1.2222222222222223
Max-min Ratio: 1.2222222222222223
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-18-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1239.0
  episode_reward_mean: 833.73
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 482
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.128
    dispatch_time_ms: 6.527
    learner:
      cur_lr: 0.0012636963510885835
      grad_gnorm: 40.0
      policy_entropy: 30.12552261352539
      policy_loss: -29.698009490966797
      var_gnorm: 43.53053665161133
      vf_explained_var: -0.18847191333770752
      vf_loss: 26.549182891845703
    num_steps_sampled: 1449000
    num_steps_trained: 1449000
    wait_time_ms: 65.385
  iterations_since_restore: 483
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 4117.273166894913
  time_this_iter_s: 7.701275110244751
  time_total_s: 4117.273166894913
  timestamp: 1594091890
  timesteps_since_restore: 1449000
  timesteps_this_iter: 3000
  timesteps_total: 1449000
  training_iteration: 483
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 4117 s, 483 iter, 1449000 ts, 834 rew

agent-1: 164.0
agent-2: 251.0
agent-3: 222.0
Sum Reward: 637.0
Avg Reward: 212.33333333333334
Min Reward: 164.0
Max Reward: 251.0
Gini Coefficient: 0.09105180533751962
20:20 Ratio: 1.5304878048780488
Max-min Ratio: 1.5304878048780488
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-18-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1239.0
  episode_reward_mean: 829.33
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 483
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.572
    dispatch_time_ms: 6.194
    learner:
      cur_lr: 0.0012634965823963284
      grad_gnorm: 40.0
      policy_entropy: 24.687664031982422
      policy_loss: -12.905941009521484
      var_gnorm: 43.51787185668945
      vf_explained_var: 0.3417072296142578
      vf_loss: 17.154253005981445
    num_steps_sampled: 1452000
    num_steps_trained: 1452000
    wait_time_ms: 72.212
  iterations_since_restore: 484
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 4125.20126914978
  time_this_iter_s: 7.928102254867554
  time_total_s: 4125.20126914978
  timestamp: 1594091898
  timesteps_since_restore: 1452000
  timesteps_this_iter: 3000
  timesteps_total: 1452000
  training_iteration: 484
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 4125 s, 484 iter, 1452000 ts, 829 rew

agent-1: 225.0
agent-2: 253.0
agent-3: 225.0
Sum Reward: 703.0
Avg Reward: 234.33333333333334
Min Reward: 225.0
Max Reward: 253.0
Gini Coefficient: 0.026552868658131817
20:20 Ratio: 1.1244444444444444
Max-min Ratio: 1.1244444444444444
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-18-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1239.0
  episode_reward_mean: 826.23
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 484
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.803
    dispatch_time_ms: 5.748
    learner:
      cur_lr: 0.0012632968137040734
      grad_gnorm: 13.929326057434082
      policy_entropy: 23.40390968322754
      policy_loss: 1.5284966230392456
      var_gnorm: 43.5499267578125
      vf_explained_var: 0.33713269233703613
      vf_loss: 8.822464942932129
    num_steps_sampled: 1455000
    num_steps_trained: 1455000
    wait_time_ms: 73.705
  iterations_since_restore: 485
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 4133.280631780624
  time_this_iter_s: 8.079362630844116
  time_total_s: 4133.280631780624
  timestamp: 1594091906
  timesteps_since_restore: 1455000
  timesteps_this_iter: 3000
  timesteps_total: 1455000
  training_iteration: 485
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 4133 s, 485 iter, 1455000 ts, 826 rew

agent-1: 255.0
agent-2: 235.0
agent-3: 230.0
Sum Reward: 720.0
Avg Reward: 240.0
Min Reward: 230.0
Max Reward: 255.0
Gini Coefficient: 0.023148148148148147
20:20 Ratio: 1.108695652173913
Max-min Ratio: 1.108695652173913
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-18-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1239.0
  episode_reward_mean: 823.35
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 485
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 6.309
    dispatch_time_ms: 9.897
    learner:
      cur_lr: 0.0012630970450118184
      grad_gnorm: 22.969148635864258
      policy_entropy: 20.8765869140625
      policy_loss: 2.535675525665283
      var_gnorm: 43.5651741027832
      vf_explained_var: 0.1644245982170105
      vf_loss: 35.25522232055664
    num_steps_sampled: 1458000
    num_steps_trained: 1458000
    wait_time_ms: 16.037
  iterations_since_restore: 486
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 4145.374322414398
  time_this_iter_s: 12.093690633773804
  time_total_s: 4145.374322414398
  timestamp: 1594091918
  timesteps_since_restore: 1458000
  timesteps_this_iter: 3000
  timesteps_total: 1458000
  training_iteration: 486
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 4145 s, 486 iter, 1458000 ts, 823 rew

agent-1: 277.0
agent-2: 242.0
agent-3: 275.0
Sum Reward: 794.0
Avg Reward: 264.6666666666667
Min Reward: 242.0
Max Reward: 277.0
Gini Coefficient: 0.02938706968933669
20:20 Ratio: 1.1446280991735538
Max-min Ratio: 1.1446280991735538
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-18-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1239.0
  episode_reward_mean: 821.1
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 486
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.461
    dispatch_time_ms: 6.241
    learner:
      cur_lr: 0.0012628971599042416
      grad_gnorm: 22.180177688598633
      policy_entropy: 17.277456283569336
      policy_loss: -3.09332275390625
      var_gnorm: 43.54308319091797
      vf_explained_var: 0.6556462049484253
      vf_loss: 13.277535438537598
    num_steps_sampled: 1461000
    num_steps_trained: 1461000
    wait_time_ms: 72.975
  iterations_since_restore: 487
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 4153.129112482071
  time_this_iter_s: 7.7547900676727295
  time_total_s: 4153.129112482071
  timestamp: 1594091926
  timesteps_since_restore: 1461000
  timesteps_this_iter: 3000
  timesteps_total: 1461000
  training_iteration: 487
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 4153 s, 487 iter, 1461000 ts, 821 rew

agent-1: 234.0
agent-2: 221.0
agent-3: 228.0
Sum Reward: 683.0
Avg Reward: 227.66666666666666
Min Reward: 221.0
Max Reward: 234.0
Gini Coefficient: 0.01268911664226452
20:20 Ratio: 1.0588235294117647
Max-min Ratio: 1.0588235294117647
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-18-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1239.0
  episode_reward_mean: 818.67
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 487
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.721
    dispatch_time_ms: 5.431
    learner:
      cur_lr: 0.0012626973912119865
      grad_gnorm: 23.90581512451172
      policy_entropy: 18.06553077697754
      policy_loss: 5.87617301940918
      var_gnorm: 43.558067321777344
      vf_explained_var: -0.1144716739654541
      vf_loss: 18.62169075012207
    num_steps_sampled: 1464000
    num_steps_trained: 1464000
    wait_time_ms: 69.342
  iterations_since_restore: 488
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 4161.223320245743
  time_this_iter_s: 8.094207763671875
  time_total_s: 4161.223320245743
  timestamp: 1594091934
  timesteps_since_restore: 1464000
  timesteps_this_iter: 3000
  timesteps_total: 1464000
  training_iteration: 488
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 4161 s, 488 iter, 1464000 ts, 819 rew

agent-1: 323.0
agent-2: 299.0
agent-3: 273.0
Sum Reward: 895.0
Avg Reward: 298.3333333333333
Min Reward: 273.0
Max Reward: 323.0
Gini Coefficient: 0.037243947858473
20:20 Ratio: 1.1831501831501832
Max-min Ratio: 1.1831501831501832
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-19-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1239.0
  episode_reward_mean: 817.9
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 488
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.932
    dispatch_time_ms: 8.299
    learner:
      cur_lr: 0.0012624976225197315
      grad_gnorm: 39.999996185302734
      policy_entropy: 24.078359603881836
      policy_loss: -5.915722370147705
      var_gnorm: 43.610111236572266
      vf_explained_var: 0.06347280740737915
      vf_loss: 29.441072463989258
    num_steps_sampled: 1467000
    num_steps_trained: 1467000
    wait_time_ms: 67.704
  iterations_since_restore: 489
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 4169.161019563675
  time_this_iter_s: 7.937699317932129
  time_total_s: 4169.161019563675
  timestamp: 1594091942
  timesteps_since_restore: 1467000
  timesteps_this_iter: 3000
  timesteps_total: 1467000
  training_iteration: 489
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 4169 s, 489 iter, 1467000 ts, 818 rew

agent-1: 276.0
agent-2: 297.0
agent-3: 271.0
Sum Reward: 844.0
Avg Reward: 281.3333333333333
Min Reward: 271.0
Max Reward: 297.0
Gini Coefficient: 0.020537124802527645
20:20 Ratio: 1.0959409594095941
Max-min Ratio: 1.0959409594095941
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-19-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1239.0
  episode_reward_mean: 816.86
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 489
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.738
    dispatch_time_ms: 7.471
    learner:
      cur_lr: 0.0012622978538274765
      grad_gnorm: 40.000003814697266
      policy_entropy: 22.891658782958984
      policy_loss: -0.6150091886520386
      var_gnorm: 43.61033248901367
      vf_explained_var: 0.1347852349281311
      vf_loss: 23.25033187866211
    num_steps_sampled: 1470000
    num_steps_trained: 1470000
    wait_time_ms: 65.986
  iterations_since_restore: 490
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 4177.385361194611
  time_this_iter_s: 8.224341630935669
  time_total_s: 4177.385361194611
  timestamp: 1594091951
  timesteps_since_restore: 1470000
  timesteps_this_iter: 3000
  timesteps_total: 1470000
  training_iteration: 490
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 4177 s, 490 iter, 1470000 ts, 817 rew

agent-1: 215.0
agent-2: 319.0
agent-3: 291.0
Sum Reward: 825.0
Avg Reward: 275.0
Min Reward: 215.0
Max Reward: 319.0
Gini Coefficient: 0.08404040404040404
20:20 Ratio: 1.4837209302325582
Max-min Ratio: 1.4837209302325582
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-19-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1239.0
  episode_reward_mean: 816.05
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 490
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.557
    dispatch_time_ms: 6.076
    learner:
      cur_lr: 0.0012620979687198997
      grad_gnorm: 40.0
      policy_entropy: 18.068403244018555
      policy_loss: 19.529396057128906
      var_gnorm: 43.66399383544922
      vf_explained_var: 0.5278971195220947
      vf_loss: 30.475500106811523
    num_steps_sampled: 1473000
    num_steps_trained: 1473000
    wait_time_ms: 74.063
  iterations_since_restore: 491
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 4185.815941095352
  time_this_iter_s: 8.430579900741577
  time_total_s: 4185.815941095352
  timestamp: 1594091959
  timesteps_since_restore: 1473000
  timesteps_this_iter: 3000
  timesteps_total: 1473000
  training_iteration: 491
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 4185 s, 491 iter, 1473000 ts, 816 rew

agent-1: 314.0
agent-2: 343.0
agent-3: 289.0
Sum Reward: 946.0
Avg Reward: 315.3333333333333
Min Reward: 289.0
Max Reward: 343.0
Gini Coefficient: 0.03805496828752643
20:20 Ratio: 1.1868512110726643
Max-min Ratio: 1.1868512110726643
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-19-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1239.0
  episode_reward_mean: 816.0
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 491
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 3.82
    dispatch_time_ms: 5.138
    learner:
      cur_lr: 0.0012618982000276446
      grad_gnorm: 40.0
      policy_entropy: 19.25520133972168
      policy_loss: 24.641529083251953
      var_gnorm: 43.69984436035156
      vf_explained_var: 0.15556573867797852
      vf_loss: 50.891082763671875
    num_steps_sampled: 1476000
    num_steps_trained: 1476000
    wait_time_ms: 75.692
  iterations_since_restore: 492
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 4194.182272195816
  time_this_iter_s: 8.366331100463867
  time_total_s: 4194.182272195816
  timestamp: 1594091967
  timesteps_since_restore: 1476000
  timesteps_this_iter: 3000
  timesteps_total: 1476000
  training_iteration: 492
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 4194 s, 492 iter, 1476000 ts, 816 rew

agent-1: 290.0
agent-2: 336.0
agent-3: 372.0
Sum Reward: 998.0
Avg Reward: 332.6666666666667
Min Reward: 290.0
Max Reward: 372.0
Gini Coefficient: 0.05477621910487642
20:20 Ratio: 1.282758620689655
Max-min Ratio: 1.282758620689655
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-19-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1239.0
  episode_reward_mean: 816.92
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 492
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.433
    dispatch_time_ms: 6.856
    learner:
      cur_lr: 0.0012616984313353896
      grad_gnorm: 40.0
      policy_entropy: 16.66554069519043
      policy_loss: -13.842025756835938
      var_gnorm: 43.72715377807617
      vf_explained_var: 0.6733856797218323
      vf_loss: 19.857105255126953
    num_steps_sampled: 1479000
    num_steps_trained: 1479000
    wait_time_ms: 77.566
  iterations_since_restore: 493
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 4202.678117513657
  time_this_iter_s: 8.495845317840576
  time_total_s: 4202.678117513657
  timestamp: 1594091976
  timesteps_since_restore: 1479000
  timesteps_this_iter: 3000
  timesteps_total: 1479000
  training_iteration: 493
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 4202 s, 493 iter, 1479000 ts, 817 rew

agent-1: 292.0
agent-2: 316.0
agent-3: 332.0
Sum Reward: 940.0
Avg Reward: 313.3333333333333
Min Reward: 292.0
Max Reward: 332.0
Gini Coefficient: 0.028368794326241134
20:20 Ratio: 1.1369863013698631
Max-min Ratio: 1.1369863013698631
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-19-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1239.0
  episode_reward_mean: 819.41
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 493
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.647
    dispatch_time_ms: 6.01
    learner:
      cur_lr: 0.0012614985462278128
      grad_gnorm: 40.0
      policy_entropy: 15.9976167678833
      policy_loss: 15.400116920471191
      var_gnorm: 43.70795440673828
      vf_explained_var: -0.2784538269042969
      vf_loss: 25.89969253540039
    num_steps_sampled: 1482000
    num_steps_trained: 1482000
    wait_time_ms: 73.892
  iterations_since_restore: 494
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 4211.044726610184
  time_this_iter_s: 8.3666090965271
  time_total_s: 4211.044726610184
  timestamp: 1594091984
  timesteps_since_restore: 1482000
  timesteps_this_iter: 3000
  timesteps_total: 1482000
  training_iteration: 494
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 4211 s, 494 iter, 1482000 ts, 819 rew

agent-1: 316.0
agent-2: 353.0
agent-3: 336.0
Sum Reward: 1005.0
Avg Reward: 335.0
Min Reward: 316.0
Max Reward: 353.0
Gini Coefficient: 0.024543946932006632
20:20 Ratio: 1.1170886075949367
Max-min Ratio: 1.1170886075949367
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-19-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1239.0
  episode_reward_mean: 823.22
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 494
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.758
    dispatch_time_ms: 20.277
    learner:
      cur_lr: 0.0012612987775355577
      grad_gnorm: 40.0
      policy_entropy: 19.75664520263672
      policy_loss: -16.703285217285156
      var_gnorm: 43.78160095214844
      vf_explained_var: -0.44359076023101807
      vf_loss: 19.920406341552734
    num_steps_sampled: 1485000
    num_steps_trained: 1485000
    wait_time_ms: 65.466
  iterations_since_restore: 495
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 4219.681871891022
  time_this_iter_s: 8.637145280838013
  time_total_s: 4219.681871891022
  timestamp: 1594091993
  timesteps_since_restore: 1485000
  timesteps_this_iter: 3000
  timesteps_total: 1485000
  training_iteration: 495
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 4219 s, 495 iter, 1485000 ts, 823 rew

agent-1: 354.0
agent-2: 299.0
agent-3: 322.0
Sum Reward: 975.0
Avg Reward: 325.0
Min Reward: 299.0
Max Reward: 354.0
Gini Coefficient: 0.037606837606837605
20:20 Ratio: 1.1839464882943145
Max-min Ratio: 1.1839464882943145
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-20-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1239.0
  episode_reward_mean: 823.8
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 495
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.901
    dispatch_time_ms: 27.787
    learner:
      cur_lr: 0.0012610990088433027
      grad_gnorm: 20.600738525390625
      policy_entropy: 18.53270149230957
      policy_loss: 4.459033966064453
      var_gnorm: 43.86357879638672
      vf_explained_var: -1.0
      vf_loss: 12.3206148147583
    num_steps_sampled: 1488000
    num_steps_trained: 1488000
    wait_time_ms: 55.079
  iterations_since_restore: 496
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 4228.493426322937
  time_this_iter_s: 8.811554431915283
  time_total_s: 4228.493426322937
  timestamp: 1594092002
  timesteps_since_restore: 1488000
  timesteps_this_iter: 3000
  timesteps_total: 1488000
  training_iteration: 496
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 4228 s, 496 iter, 1488000 ts, 824 rew

agent-1: 298.0
agent-2: 335.0
agent-3: 342.0
Sum Reward: 975.0
Avg Reward: 325.0
Min Reward: 298.0
Max Reward: 342.0
Gini Coefficient: 0.030085470085470085
20:20 Ratio: 1.1476510067114094
Max-min Ratio: 1.1476510067114094
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-20-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1239.0
  episode_reward_mean: 824.57
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 496
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.462
    dispatch_time_ms: 27.912
    learner:
      cur_lr: 0.0012608992401510477
      grad_gnorm: 40.0
      policy_entropy: 17.930419921875
      policy_loss: 21.052824020385742
      var_gnorm: 43.81916809082031
      vf_explained_var: -0.21017003059387207
      vf_loss: 20.145462036132812
    num_steps_sampled: 1491000
    num_steps_trained: 1491000
    wait_time_ms: 54.72
  iterations_since_restore: 497
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 4237.086755990982
  time_this_iter_s: 8.593329668045044
  time_total_s: 4237.086755990982
  timestamp: 1594092010
  timesteps_since_restore: 1491000
  timesteps_this_iter: 3000
  timesteps_total: 1491000
  training_iteration: 497
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 4237 s, 497 iter, 1491000 ts, 825 rew

agent-1: 289.0
agent-2: 330.0
agent-3: 294.0
Sum Reward: 913.0
Avg Reward: 304.3333333333333
Min Reward: 289.0
Max Reward: 330.0
Gini Coefficient: 0.029937933552391383
20:20 Ratio: 1.1418685121107266
Max-min Ratio: 1.1418685121107266
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-20-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1239.0
  episode_reward_mean: 824.91
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 497
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.795
    dispatch_time_ms: 22.502
    learner:
      cur_lr: 0.0012606993550434709
      grad_gnorm: 40.0
      policy_entropy: 19.388391494750977
      policy_loss: -20.011638641357422
      var_gnorm: 43.91312789916992
      vf_explained_var: -1.0
      vf_loss: 49.04214859008789
    num_steps_sampled: 1494000
    num_steps_trained: 1494000
    wait_time_ms: 63.305
  iterations_since_restore: 498
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 4245.918289422989
  time_this_iter_s: 8.831533432006836
  time_total_s: 4245.918289422989
  timestamp: 1594092019
  timesteps_since_restore: 1494000
  timesteps_this_iter: 3000
  timesteps_total: 1494000
  training_iteration: 498
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 4245 s, 498 iter, 1494000 ts, 825 rew

agent-1: 283.0
agent-2: 295.0
agent-3: 300.0
Sum Reward: 878.0
Avg Reward: 292.6666666666667
Min Reward: 283.0
Max Reward: 300.0
Gini Coefficient: 0.012908124525436599
20:20 Ratio: 1.0600706713780919
Max-min Ratio: 1.0600706713780919
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-20-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1239.0
  episode_reward_mean: 824.68
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 498
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.753
    dispatch_time_ms: 28.19
    learner:
      cur_lr: 0.0012604995863512158
      grad_gnorm: 40.00000762939453
      policy_entropy: 14.710647583007812
      policy_loss: -6.533681869506836
      var_gnorm: 43.91586685180664
      vf_explained_var: 0.24655288457870483
      vf_loss: 23.390180587768555
    num_steps_sampled: 1497000
    num_steps_trained: 1497000
    wait_time_ms: 52.66
  iterations_since_restore: 499
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 4254.4355709552765
  time_this_iter_s: 8.517281532287598
  time_total_s: 4254.4355709552765
  timestamp: 1594092028
  timesteps_since_restore: 1497000
  timesteps_this_iter: 3000
  timesteps_total: 1497000
  training_iteration: 499
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=23642], 4254 s, 499 iter, 1497000 ts, 825 rew

agent-1: 284.0
agent-2: 324.0
agent-3: 305.0
Sum Reward: 913.0
Avg Reward: 304.3333333333333
Min Reward: 284.0
Max Reward: 324.0
Gini Coefficient: 0.029207740051113547
20:20 Ratio: 1.1408450704225352
Max-min Ratio: 1.1408450704225352
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-06_23-20-37
  done: true
  episode_len_mean: 1000.0
  episode_reward_max: 1239.0
  episode_reward_mean: 825.89
  episode_reward_min: 383.0
  episodes_this_iter: 1
  episodes_total: 499
  experiment_id: af0e545ffdc143f199d33d76f66c8f69
  hostname: gpu019
  info:
    apply_time_ms: 2.487
    dispatch_time_ms: 24.51
    learner:
      cur_lr: 0.0012602998176589608
      grad_gnorm: 19.246240615844727
      policy_entropy: 14.305002212524414
      policy_loss: -4.427149295806885
      var_gnorm: 43.85215377807617
      vf_explained_var: 0.19717204570770264
      vf_loss: 47.378395080566406
    num_steps_sampled: 1500000
    num_steps_trained: 1500000
    wait_time_ms: 63.948
  iterations_since_restore: 500
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 23642
  policy_reward_mean: {}
  time_since_restore: 4263.140688419342
  time_this_iter_s: 8.705117464065552
  time_total_s: 4263.140688419342
  timestamp: 1594092037
  timesteps_since_restore: 1500000
  timesteps_this_iter: 3000
  timesteps_total: 1500000
  training_iteration: 500
  
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
TERMINATED trials:
 - A3C_harvest_env_0:	TERMINATED [pid=23642], 4263 s, 500 iter, 1500000 ts, 826 rew

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
TERMINATED trials:
 - A3C_harvest_env_0:	TERMINATED [pid=23642], 4263 s, 500 iter, 1500000 ts, 826 rew

WARNING: Logging before InitGoogleLogging() is written to STDERR
E0706 23:20:37.534786 23669 raylet_client.cc:345] IOError: [RayletClient] Connection closed unexpectedly. [RayletClient] Failed to push profile events.
Commencing experiment harvest_A3C
WARNING: Logging before InitGoogleLogging() is written to STDERR
E0706 23:20:38.113345 23667 raylet_client.cc:345] IOError: [RayletClient] Connection closed unexpectedly. [RayletClient] Failed to push profile events.
E0706 23:20:38.595302 23669 raylet_client.cc:345] IOError: [RayletClient] Connection closed unexpectedly. [RayletClient] Failed to push profile events.
