/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Process STDOUT and STDERR is being redirected to /tmp/ray/session_2020-07-07_00-05-42_349/logs.
Waiting for redis server at 127.0.0.1:62138 to respond...
Waiting for redis server at 127.0.0.1:49034 to respond...
Warning: Capping object memory store to 20.0GB. To increase this further, specify `object_store_memory` when calling ray.init() or ray start.
Starting the Plasma object store with 20.0 GB memory using /dev/shm.

======================================================================
View the web UI at http://localhost:8889/notebooks/ray_ui.ipynb?token=a7e717791c7f04052885ac83302a9b24fba79ad2b9c577f7
======================================================================

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.5/202.5 GB

Created LogSyncer for /h/zhaostep/ray_results/harvest_A3C/A3C_harvest_env_0_2020-07-07_00-05-42wzvpur0b -> 
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING

/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-07 00:05:54,613	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 0 on CPU (please ignore any CUDA init errors)
2020-07-07 00:05:54.613738: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-07 00:06:05,902	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 1 on CPU (please ignore any CUDA init errors)
2020-07-07 00:06:05.903046: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-07 00:06:06,073	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 2 on CPU (please ignore any CUDA init errors)
2020-07-07 00:06:06.074247: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-06-16
  done: false
  episode_len_mean: .nan
  episode_reward_max: .nan
  episode_reward_mean: .nan
  episode_reward_min: .nan
  episodes_this_iter: 0
  episodes_total: 0
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.608
    dispatch_time_ms: 8.212
    learner:
      cur_lr: 0.0013599999947473407
      grad_gnorm: 40.0
      policy_entropy: 49.45396423339844
      policy_loss: 30.539867401123047
      var_gnorm: 17.984403610229492
      vf_explained_var: -0.0243912935256958
      vf_loss: 10.11111831665039
    num_steps_sampled: 3000
    num_steps_trained: 3000
    wait_time_ms: 64.241
  iterations_since_restore: 1
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 20.187191247940063
  time_this_iter_s: 20.187191247940063
  time_total_s: 20.187191247940063
  timestamp: 1594094776
  timesteps_since_restore: 3000
  timesteps_this_iter: 3000
  timesteps_total: 3000
  training_iteration: 1
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 20 s, 1 iter, 3000 ts, nan rew

[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
agent-1: 133.0
agent-2: 79.0
agent-3: 23.0
Sum Reward: 235.0
Avg Reward: 78.33333333333333
Min Reward: 23.0
Max Reward: 133.0
Gini Coefficient: 0.3120567375886525
20:20 Ratio: 5.782608695652174
Max-min Ratio: 5.782608695652174
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-06-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 235.0
  episode_reward_mean: 235.0
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 1
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.69
    dispatch_time_ms: 11.391
    learner:
      cur_lr: 0.0013598002260550857
      grad_gnorm: 40.0
      policy_entropy: 45.54977798461914
      policy_loss: 24.50495147705078
      var_gnorm: 18.04441261291504
      vf_explained_var: -0.013260245323181152
      vf_loss: 13.159066200256348
    num_steps_sampled: 6000
    num_steps_trained: 6000
    wait_time_ms: 60.827
  iterations_since_restore: 2
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 27.959869861602783
  time_this_iter_s: 7.77267861366272
  time_total_s: 27.959869861602783
  timestamp: 1594094783
  timesteps_since_restore: 6000
  timesteps_this_iter: 3000
  timesteps_total: 6000
  training_iteration: 2
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 27 s, 2 iter, 6000 ts, 235 rew

[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
agent-1: 110.0
agent-2: 37.0
agent-3: 94.0
Sum Reward: 241.0
Avg Reward: 80.33333333333333
Min Reward: 37.0
Max Reward: 110.0
Gini Coefficient: 0.20193637621023514
20:20 Ratio: 2.972972972972973
Max-min Ratio: 2.972972972972973
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-06-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 241.0
  episode_reward_mean: 238.0
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 2
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.939
    dispatch_time_ms: 7.956
    learner:
      cur_lr: 0.0013596004573628306
      grad_gnorm: 40.0000114440918
      policy_entropy: 38.42237854003906
      policy_loss: 62.32594680786133
      var_gnorm: 18.140953063964844
      vf_explained_var: -0.023932814598083496
      vf_loss: 92.70352172851562
    num_steps_sampled: 9000
    num_steps_trained: 9000
    wait_time_ms: 68.222
  iterations_since_restore: 3
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 35.39007878303528
  time_this_iter_s: 7.430208921432495
  time_total_s: 35.39007878303528
  timestamp: 1594094791
  timesteps_since_restore: 9000
  timesteps_this_iter: 3000
  timesteps_total: 9000
  training_iteration: 3
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 35 s, 3 iter, 9000 ts, 238 rew

agent-1: 136.0
agent-2: 139.0
agent-3: 143.0
Sum Reward: 418.0
Avg Reward: 139.33333333333334
Min Reward: 136.0
Max Reward: 143.0
Gini Coefficient: 0.011164274322169059
20:20 Ratio: 1.0514705882352942
Max-min Ratio: 1.0514705882352942
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-06-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 418.0
  episode_reward_mean: 298.0
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 3
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.88
    dispatch_time_ms: 8.254
    learner:
      cur_lr: 0.0013594005722552538
      grad_gnorm: 40.00000762939453
      policy_entropy: 42.674827575683594
      policy_loss: 15.621749877929688
      var_gnorm: 18.344303131103516
      vf_explained_var: 0.0264093279838562
      vf_loss: 25.683631896972656
    num_steps_sampled: 12000
    num_steps_trained: 12000
    wait_time_ms: 61.954
  iterations_since_restore: 4
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 43.09149789810181
  time_this_iter_s: 7.701419115066528
  time_total_s: 43.09149789810181
  timestamp: 1594094799
  timesteps_since_restore: 12000
  timesteps_this_iter: 3000
  timesteps_total: 12000
  training_iteration: 4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 43 s, 4 iter, 12000 ts, 298 rew

agent-1: 153.0
agent-2: 94.0
agent-3: 39.0
Sum Reward: 286.0
Avg Reward: 95.33333333333333
Min Reward: 39.0
Max Reward: 153.0
Gini Coefficient: 0.26573426573426573
20:20 Ratio: 3.923076923076923
Max-min Ratio: 3.923076923076923
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-06-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 418.0
  episode_reward_mean: 295.0
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 4
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.611
    dispatch_time_ms: 7.804
    learner:
      cur_lr: 0.0013592008035629988
      grad_gnorm: 40.00000762939453
      policy_entropy: 40.42420196533203
      policy_loss: -16.17388343811035
      var_gnorm: 18.562028884887695
      vf_explained_var: 0.4393807053565979
      vf_loss: 6.128044605255127
    num_steps_sampled: 15000
    num_steps_trained: 15000
    wait_time_ms: 69.622
  iterations_since_restore: 5
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 50.67045736312866
  time_this_iter_s: 7.5789594650268555
  time_total_s: 50.67045736312866
  timestamp: 1594094806
  timesteps_since_restore: 15000
  timesteps_this_iter: 3000
  timesteps_total: 15000
  training_iteration: 5
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 50 s, 5 iter, 15000 ts, 295 rew

agent-1: 203.0
agent-2: 135.0
agent-3: 106.0
Sum Reward: 444.0
Avg Reward: 148.0
Min Reward: 106.0
Max Reward: 203.0
Gini Coefficient: 0.14564564564564564
20:20 Ratio: 1.9150943396226414
Max-min Ratio: 1.9150943396226414
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-06-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 444.0
  episode_reward_mean: 324.8
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 5
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.422
    dispatch_time_ms: 8.017
    learner:
      cur_lr: 0.0013590010348707438
      grad_gnorm: 40.00001907348633
      policy_entropy: 37.77439880371094
      policy_loss: 11.162527084350586
      var_gnorm: 18.737010955810547
      vf_explained_var: -0.17451918125152588
      vf_loss: 21.073867797851562
    num_steps_sampled: 18000
    num_steps_trained: 18000
    wait_time_ms: 67.92
  iterations_since_restore: 6
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 58.576430559158325
  time_this_iter_s: 7.905973196029663
  time_total_s: 58.576430559158325
  timestamp: 1594094814
  timesteps_since_restore: 18000
  timesteps_this_iter: 3000
  timesteps_total: 18000
  training_iteration: 6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 58 s, 6 iter, 18000 ts, 325 rew

agent-1: 219.0
agent-2: 240.0
agent-3: 218.0
Sum Reward: 677.0
Avg Reward: 225.66666666666666
Min Reward: 218.0
Max Reward: 240.0
Gini Coefficient: 0.021664204825209258
20:20 Ratio: 1.1009174311926606
Max-min Ratio: 1.1009174311926606
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-07-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 677.0
  episode_reward_mean: 383.5
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 6
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.614
    dispatch_time_ms: 9.245
    learner:
      cur_lr: 0.001358801149763167
      grad_gnorm: 22.866918563842773
      policy_entropy: 34.390079498291016
      policy_loss: 7.822026252746582
      var_gnorm: 18.942052841186523
      vf_explained_var: -0.0025603771209716797
      vf_loss: 7.761486053466797
    num_steps_sampled: 21000
    num_steps_trained: 21000
    wait_time_ms: 67.691
  iterations_since_restore: 7
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 66.37550187110901
  time_this_iter_s: 7.799071311950684
  time_total_s: 66.37550187110901
  timestamp: 1594094822
  timesteps_since_restore: 21000
  timesteps_this_iter: 3000
  timesteps_total: 21000
  training_iteration: 7
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 66 s, 7 iter, 21000 ts, 384 rew

agent-1: 262.0
agent-2: 245.0
agent-3: 211.0
Sum Reward: 718.0
Avg Reward: 239.33333333333334
Min Reward: 211.0
Max Reward: 262.0
Gini Coefficient: 0.04735376044568245
20:20 Ratio: 1.2417061611374407
Max-min Ratio: 1.2417061611374407
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-07-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 718.0
  episode_reward_mean: 431.2857142857143
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 7
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.433
    dispatch_time_ms: 7.98
    learner:
      cur_lr: 0.0013586013810709119
      grad_gnorm: 39.99999237060547
      policy_entropy: 32.29137420654297
      policy_loss: 35.832244873046875
      var_gnorm: 19.187305450439453
      vf_explained_var: -1.0
      vf_loss: 32.984596252441406
    num_steps_sampled: 24000
    num_steps_trained: 24000
    wait_time_ms: 73.681
  iterations_since_restore: 8
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 74.46927547454834
  time_this_iter_s: 8.093773603439331
  time_total_s: 74.46927547454834
  timestamp: 1594094830
  timesteps_since_restore: 24000
  timesteps_this_iter: 3000
  timesteps_total: 24000
  training_iteration: 8
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 74 s, 8 iter, 24000 ts, 431 rew

agent-1: 235.0
agent-2: 223.0
agent-3: 259.0
Sum Reward: 717.0
Avg Reward: 239.0
Min Reward: 223.0
Max Reward: 259.0
Gini Coefficient: 0.03347280334728033
20:20 Ratio: 1.1614349775784754
Max-min Ratio: 1.1614349775784754
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-07-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 718.0
  episode_reward_mean: 467.0
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 8
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 4.17
    dispatch_time_ms: 9.814
    learner:
      cur_lr: 0.0013584016123786569
      grad_gnorm: 40.000003814697266
      policy_entropy: 32.101810455322266
      policy_loss: 12.91145133972168
      var_gnorm: 19.410615921020508
      vf_explained_var: 0.03573340177536011
      vf_loss: 23.74106216430664
    num_steps_sampled: 27000
    num_steps_trained: 27000
    wait_time_ms: 68.824
  iterations_since_restore: 9
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 82.25746321678162
  time_this_iter_s: 7.788187742233276
  time_total_s: 82.25746321678162
  timestamp: 1594094838
  timesteps_since_restore: 27000
  timesteps_this_iter: 3000
  timesteps_total: 27000
  training_iteration: 9
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 82 s, 9 iter, 27000 ts, 467 rew

agent-1: 258.0
agent-2: 287.0
agent-3: 317.0
Sum Reward: 862.0
Avg Reward: 287.3333333333333
Min Reward: 258.0
Max Reward: 317.0
Gini Coefficient: 0.04563031709203403
20:20 Ratio: 1.2286821705426356
Max-min Ratio: 1.2286821705426356
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-07-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 862.0
  episode_reward_mean: 510.8888888888889
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 9
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.509
    dispatch_time_ms: 5.506
    learner:
      cur_lr: 0.0013582018436864018
      grad_gnorm: 40.000003814697266
      policy_entropy: 24.94277572631836
      policy_loss: 23.664451599121094
      var_gnorm: 19.68824005126953
      vf_explained_var: 0.023287594318389893
      vf_loss: 19.503711700439453
    num_steps_sampled: 30000
    num_steps_trained: 30000
    wait_time_ms: 75.535
  iterations_since_restore: 10
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 90.79172992706299
  time_this_iter_s: 8.534266710281372
  time_total_s: 90.79172992706299
  timestamp: 1594094846
  timesteps_since_restore: 30000
  timesteps_this_iter: 3000
  timesteps_total: 30000
  training_iteration: 10
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 90 s, 10 iter, 30000 ts, 511 rew

agent-1: 282.0
agent-2: 262.0
agent-3: 228.0
Sum Reward: 772.0
Avg Reward: 257.3333333333333
Min Reward: 228.0
Max Reward: 282.0
Gini Coefficient: 0.046632124352331605
20:20 Ratio: 1.236842105263158
Max-min Ratio: 1.236842105263158
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-07-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 862.0
  episode_reward_mean: 537.0
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 10
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.941
    dispatch_time_ms: 6.151
    learner:
      cur_lr: 0.001358001958578825
      grad_gnorm: 39.999977111816406
      policy_entropy: 25.188966751098633
      policy_loss: -3.4117488861083984
      var_gnorm: 19.95346450805664
      vf_explained_var: 0.3189714550971985
      vf_loss: 50.79766845703125
    num_steps_sampled: 33000
    num_steps_trained: 33000
    wait_time_ms: 76.191
  iterations_since_restore: 11
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 98.71877455711365
  time_this_iter_s: 7.927044630050659
  time_total_s: 98.71877455711365
  timestamp: 1594094854
  timesteps_since_restore: 33000
  timesteps_this_iter: 3000
  timesteps_total: 33000
  training_iteration: 11
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 98 s, 11 iter, 33000 ts, 537 rew

agent-1: 301.0
agent-2: 309.0
agent-3: 270.0
Sum Reward: 880.0
Avg Reward: 293.3333333333333
Min Reward: 270.0
Max Reward: 309.0
Gini Coefficient: 0.029545454545454545
20:20 Ratio: 1.1444444444444444
Max-min Ratio: 1.1444444444444444
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-07-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 880.0
  episode_reward_mean: 568.1818181818181
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 11
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.253
    dispatch_time_ms: 6.384
    learner:
      cur_lr: 0.00135780218988657
      grad_gnorm: 30.065549850463867
      policy_entropy: 25.34721565246582
      policy_loss: 3.7281107902526855
      var_gnorm: 20.20361328125
      vf_explained_var: 0.0329403281211853
      vf_loss: 18.736692428588867
    num_steps_sampled: 36000
    num_steps_trained: 36000
    wait_time_ms: 76.955
  iterations_since_restore: 12
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 106.87436962127686
  time_this_iter_s: 8.155595064163208
  time_total_s: 106.87436962127686
  timestamp: 1594094863
  timesteps_since_restore: 36000
  timesteps_this_iter: 3000
  timesteps_total: 36000
  training_iteration: 12
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 106 s, 12 iter, 36000 ts, 568 rew

agent-1: 241.0
agent-2: 286.0
agent-3: 269.0
Sum Reward: 796.0
Avg Reward: 265.3333333333333
Min Reward: 241.0
Max Reward: 286.0
Gini Coefficient: 0.03768844221105527
20:20 Ratio: 1.1867219917012448
Max-min Ratio: 1.1867219917012448
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-07-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 880.0
  episode_reward_mean: 587.1666666666666
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 12
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.958
    dispatch_time_ms: 9.542
    learner:
      cur_lr: 0.001357602421194315
      grad_gnorm: 39.99999237060547
      policy_entropy: 30.52785301208496
      policy_loss: 8.793756484985352
      var_gnorm: 20.27161979675293
      vf_explained_var: 0.2020174264907837
      vf_loss: 25.148456573486328
    num_steps_sampled: 39000
    num_steps_trained: 39000
    wait_time_ms: 63.988
  iterations_since_restore: 13
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 114.4722318649292
  time_this_iter_s: 7.597862243652344
  time_total_s: 114.4722318649292
  timestamp: 1594094870
  timesteps_since_restore: 39000
  timesteps_this_iter: 3000
  timesteps_total: 39000
  training_iteration: 13
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 114 s, 13 iter, 39000 ts, 587 rew

agent-1: 222.0
agent-2: 228.0
agent-3: 212.0
Sum Reward: 662.0
Avg Reward: 220.66666666666666
Min Reward: 212.0
Max Reward: 228.0
Gini Coefficient: 0.016112789526686808
20:20 Ratio: 1.0754716981132075
Max-min Ratio: 1.0754716981132075
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-07-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 880.0
  episode_reward_mean: 592.9230769230769
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 13
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.882
    dispatch_time_ms: 6.919
    learner:
      cur_lr: 0.00135740265250206
      grad_gnorm: 13.487390518188477
      policy_entropy: 31.139543533325195
      policy_loss: -0.21783065795898438
      var_gnorm: 20.458560943603516
      vf_explained_var: 0.3935644030570984
      vf_loss: 12.79448127746582
    num_steps_sampled: 42000
    num_steps_trained: 42000
    wait_time_ms: 62.62
  iterations_since_restore: 14
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 122.53744769096375
  time_this_iter_s: 8.065215826034546
  time_total_s: 122.53744769096375
  timestamp: 1594094878
  timesteps_since_restore: 42000
  timesteps_this_iter: 3000
  timesteps_total: 42000
  training_iteration: 14
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 122 s, 14 iter, 42000 ts, 593 rew

agent-1: 233.0
agent-2: 229.0
agent-3: 205.0
Sum Reward: 667.0
Avg Reward: 222.33333333333334
Min Reward: 205.0
Max Reward: 233.0
Gini Coefficient: 0.02798600699650175
20:20 Ratio: 1.1365853658536584
Max-min Ratio: 1.1365853658536584
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-08-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 880.0
  episode_reward_mean: 598.2142857142857
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 14
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.828
    dispatch_time_ms: 10.467
    learner:
      cur_lr: 0.001357202767394483
      grad_gnorm: 40.000003814697266
      policy_entropy: 23.277082443237305
      policy_loss: -17.173065185546875
      var_gnorm: 20.508447647094727
      vf_explained_var: 0.6988532543182373
      vf_loss: 12.120736122131348
    num_steps_sampled: 45000
    num_steps_trained: 45000
    wait_time_ms: 64.791
  iterations_since_restore: 15
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 130.03260922431946
  time_this_iter_s: 7.495161533355713
  time_total_s: 130.03260922431946
  timestamp: 1594094886
  timesteps_since_restore: 45000
  timesteps_this_iter: 3000
  timesteps_total: 45000
  training_iteration: 15
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 130 s, 15 iter, 45000 ts, 598 rew

agent-1: 222.0
agent-2: 187.0
agent-3: 201.0
Sum Reward: 610.0
Avg Reward: 203.33333333333334
Min Reward: 187.0
Max Reward: 222.0
Gini Coefficient: 0.03825136612021858
20:20 Ratio: 1.1871657754010696
Max-min Ratio: 1.1871657754010696
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-08-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 880.0
  episode_reward_mean: 599.0
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 15
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.561
    dispatch_time_ms: 7.869
    learner:
      cur_lr: 0.001357002998702228
      grad_gnorm: 40.000003814697266
      policy_entropy: 28.68619155883789
      policy_loss: 26.98931121826172
      var_gnorm: 20.66114616394043
      vf_explained_var: 0.2550489902496338
      vf_loss: 34.94967269897461
    num_steps_sampled: 48000
    num_steps_trained: 48000
    wait_time_ms: 61.974
  iterations_since_restore: 16
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 137.98201870918274
  time_this_iter_s: 7.949409484863281
  time_total_s: 137.98201870918274
  timestamp: 1594094894
  timesteps_since_restore: 48000
  timesteps_this_iter: 3000
  timesteps_total: 48000
  training_iteration: 16
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 137 s, 16 iter, 48000 ts, 599 rew

agent-1: 179.0
agent-2: 241.0
agent-3: 199.0
Sum Reward: 619.0
Avg Reward: 206.33333333333334
Min Reward: 179.0
Max Reward: 241.0
Gini Coefficient: 0.06677436725901992
20:20 Ratio: 1.3463687150837989
Max-min Ratio: 1.3463687150837989
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-08-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 880.0
  episode_reward_mean: 600.25
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 16
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.556
    dispatch_time_ms: 10.715
    learner:
      cur_lr: 0.001356803230009973
      grad_gnorm: 40.0
      policy_entropy: 25.202884674072266
      policy_loss: 2.933215379714966
      var_gnorm: 20.816896438598633
      vf_explained_var: 0.19702202081680298
      vf_loss: 25.78443145751953
    num_steps_sampled: 51000
    num_steps_trained: 51000
    wait_time_ms: 67.195
  iterations_since_restore: 17
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 145.93914318084717
  time_this_iter_s: 7.957124471664429
  time_total_s: 145.93914318084717
  timestamp: 1594094902
  timesteps_since_restore: 51000
  timesteps_this_iter: 3000
  timesteps_total: 51000
  training_iteration: 17
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 145 s, 17 iter, 51000 ts, 600 rew

agent-1: 283.0
agent-2: 260.0
agent-3: 305.0
Sum Reward: 848.0
Avg Reward: 282.6666666666667
Min Reward: 260.0
Max Reward: 305.0
Gini Coefficient: 0.03537735849056604
20:20 Ratio: 1.1730769230769231
Max-min Ratio: 1.1730769230769231
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-08-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 880.0
  episode_reward_mean: 614.8235294117648
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 17
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.65
    dispatch_time_ms: 8.253
    learner:
      cur_lr: 0.0013566033449023962
      grad_gnorm: 40.000003814697266
      policy_entropy: 26.249988555908203
      policy_loss: -20.854835510253906
      var_gnorm: 20.906457901000977
      vf_explained_var: -0.13719236850738525
      vf_loss: 49.96472930908203
    num_steps_sampled: 54000
    num_steps_trained: 54000
    wait_time_ms: 66.042
  iterations_since_restore: 18
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 154.16906356811523
  time_this_iter_s: 8.229920387268066
  time_total_s: 154.16906356811523
  timestamp: 1594094910
  timesteps_since_restore: 54000
  timesteps_this_iter: 3000
  timesteps_total: 54000
  training_iteration: 18
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 154 s, 18 iter, 54000 ts, 615 rew

agent-1: 244.0
agent-2: 295.0
agent-3: 291.0
Sum Reward: 830.0
Avg Reward: 276.6666666666667
Min Reward: 244.0
Max Reward: 295.0
Gini Coefficient: 0.04096385542168675
20:20 Ratio: 1.209016393442623
Max-min Ratio: 1.209016393442623
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-08-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 880.0
  episode_reward_mean: 626.7777777777778
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 18
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.023
    dispatch_time_ms: 7.487
    learner:
      cur_lr: 0.0013564035762101412
      grad_gnorm: 39.999996185302734
      policy_entropy: 28.033138275146484
      policy_loss: 11.3944091796875
      var_gnorm: 21.05541229248047
      vf_explained_var: 0.24740350246429443
      vf_loss: 26.84543228149414
    num_steps_sampled: 57000
    num_steps_trained: 57000
    wait_time_ms: 71.314
  iterations_since_restore: 19
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 162.0928349494934
  time_this_iter_s: 7.923771381378174
  time_total_s: 162.0928349494934
  timestamp: 1594094918
  timesteps_since_restore: 57000
  timesteps_this_iter: 3000
  timesteps_total: 57000
  training_iteration: 19
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 162 s, 19 iter, 57000 ts, 627 rew

agent-1: 255.0
agent-2: 265.0
agent-3: 291.0
Sum Reward: 811.0
Avg Reward: 270.3333333333333
Min Reward: 255.0
Max Reward: 291.0
Gini Coefficient: 0.029593094944512947
20:20 Ratio: 1.1411764705882352
Max-min Ratio: 1.1411764705882352
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-08-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 880.0
  episode_reward_mean: 636.4736842105264
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 19
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.794
    dispatch_time_ms: 7.657
    learner:
      cur_lr: 0.0013562038075178862
      grad_gnorm: 39.9999885559082
      policy_entropy: 26.64896011352539
      policy_loss: -18.47593116760254
      var_gnorm: 21.1578311920166
      vf_explained_var: -0.11925458908081055
      vf_loss: 16.789316177368164
    num_steps_sampled: 60000
    num_steps_trained: 60000
    wait_time_ms: 72.923
  iterations_since_restore: 20
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 170.49715209007263
  time_this_iter_s: 8.404317140579224
  time_total_s: 170.49715209007263
  timestamp: 1594094926
  timesteps_since_restore: 60000
  timesteps_this_iter: 3000
  timesteps_total: 60000
  training_iteration: 20
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 170 s, 20 iter, 60000 ts, 636 rew

agent-1: 250.0
agent-2: 260.0
agent-3: 255.0
Sum Reward: 765.0
Avg Reward: 255.0
Min Reward: 250.0
Max Reward: 260.0
Gini Coefficient: 0.008714596949891068
20:20 Ratio: 1.04
Max-min Ratio: 1.04
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-08-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 880.0
  episode_reward_mean: 642.9
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 20
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.615
    dispatch_time_ms: 7.116
    learner:
      cur_lr: 0.0013560040388256311
      grad_gnorm: 5.484810829162598
      policy_entropy: 28.676677703857422
      policy_loss: -1.1949208974838257
      var_gnorm: 21.331506729125977
      vf_explained_var: 0.4878900647163391
      vf_loss: 9.708372116088867
    num_steps_sampled: 63000
    num_steps_trained: 63000
    wait_time_ms: 72.38
  iterations_since_restore: 21
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 178.28707146644592
  time_this_iter_s: 7.789919376373291
  time_total_s: 178.28707146644592
  timestamp: 1594094934
  timesteps_since_restore: 63000
  timesteps_this_iter: 3000
  timesteps_total: 63000
  training_iteration: 21
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 178 s, 21 iter, 63000 ts, 643 rew

agent-1: 275.0
agent-2: 277.0
agent-3: 293.0
Sum Reward: 845.0
Avg Reward: 281.6666666666667
Min Reward: 275.0
Max Reward: 293.0
Gini Coefficient: 0.014201183431952662
20:20 Ratio: 1.0654545454545454
Max-min Ratio: 1.0654545454545454
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-09-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 880.0
  episode_reward_mean: 652.5238095238095
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 21
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.866
    dispatch_time_ms: 9.752
    learner:
      cur_lr: 0.0013558041537180543
      grad_gnorm: 39.999996185302734
      policy_entropy: 21.194133758544922
      policy_loss: 14.914740562438965
      var_gnorm: 21.46255874633789
      vf_explained_var: -0.8426699638366699
      vf_loss: 43.237789154052734
    num_steps_sampled: 66000
    num_steps_trained: 66000
    wait_time_ms: 66.852
  iterations_since_restore: 22
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 186.50869798660278
  time_this_iter_s: 8.22162652015686
  time_total_s: 186.50869798660278
  timestamp: 1594094943
  timesteps_since_restore: 66000
  timesteps_this_iter: 3000
  timesteps_total: 66000
  training_iteration: 22
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 186 s, 22 iter, 66000 ts, 653 rew

agent-1: 297.0
agent-2: 294.0
agent-3: 298.0
Sum Reward: 889.0
Avg Reward: 296.3333333333333
Min Reward: 294.0
Max Reward: 298.0
Gini Coefficient: 0.0029996250468691415
20:20 Ratio: 1.0136054421768708
Max-min Ratio: 1.0136054421768708
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-09-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 889.0
  episode_reward_mean: 663.2727272727273
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 22
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.35
    dispatch_time_ms: 5.45
    learner:
      cur_lr: 0.0013556043850257993
      grad_gnorm: 39.99999237060547
      policy_entropy: 28.37936019897461
      policy_loss: -10.369178771972656
      var_gnorm: 21.598909378051758
      vf_explained_var: -0.12776625156402588
      vf_loss: 38.35980224609375
    num_steps_sampled: 69000
    num_steps_trained: 69000
    wait_time_ms: 76.328
  iterations_since_restore: 23
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 194.4790050983429
  time_this_iter_s: 7.970307111740112
  time_total_s: 194.4790050983429
  timestamp: 1594094951
  timesteps_since_restore: 69000
  timesteps_this_iter: 3000
  timesteps_total: 69000
  training_iteration: 23
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 194 s, 23 iter, 69000 ts, 663 rew

agent-1: 290.0
agent-2: 310.0
agent-3: 325.0
Sum Reward: 925.0
Avg Reward: 308.3333333333333
Min Reward: 290.0
Max Reward: 325.0
Gini Coefficient: 0.025225225225225224
20:20 Ratio: 1.1206896551724137
Max-min Ratio: 1.1206896551724137
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-09-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 925.0
  episode_reward_mean: 674.6521739130435
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 23
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.349
    dispatch_time_ms: 7.751
    learner:
      cur_lr: 0.0013554046163335443
      grad_gnorm: 39.999996185302734
      policy_entropy: 23.498075485229492
      policy_loss: 30.174673080444336
      var_gnorm: 21.720977783203125
      vf_explained_var: -0.7723686695098877
      vf_loss: 46.506126403808594
    num_steps_sampled: 72000
    num_steps_trained: 72000
    wait_time_ms: 59.824
  iterations_since_restore: 24
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 202.76991415023804
  time_this_iter_s: 8.290909051895142
  time_total_s: 202.76991415023804
  timestamp: 1594094959
  timesteps_since_restore: 72000
  timesteps_this_iter: 3000
  timesteps_total: 72000
  training_iteration: 24
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 202 s, 24 iter, 72000 ts, 675 rew

agent-1: 305.0
agent-2: 328.0
agent-3: 287.0
Sum Reward: 920.0
Avg Reward: 306.6666666666667
Min Reward: 287.0
Max Reward: 328.0
Gini Coefficient: 0.029710144927536233
20:20 Ratio: 1.1428571428571428
Max-min Ratio: 1.1428571428571428
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-09-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 925.0
  episode_reward_mean: 684.875
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 24
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.904
    dispatch_time_ms: 8.744
    learner:
      cur_lr: 0.0013552048476412892
      grad_gnorm: 36.1868782043457
      policy_entropy: 26.98171615600586
      policy_loss: 9.393950462341309
      var_gnorm: 21.825464248657227
      vf_explained_var: -0.2773115634918213
      vf_loss: 12.849494934082031
    num_steps_sampled: 75000
    num_steps_trained: 75000
    wait_time_ms: 72.493
  iterations_since_restore: 25
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 210.97897338867188
  time_this_iter_s: 8.209059238433838
  time_total_s: 210.97897338867188
  timestamp: 1594094967
  timesteps_since_restore: 75000
  timesteps_this_iter: 3000
  timesteps_total: 75000
  training_iteration: 25
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 210 s, 25 iter, 75000 ts, 685 rew

agent-1: 320.0
agent-2: 292.0
agent-3: 288.0
Sum Reward: 900.0
Avg Reward: 300.0
Min Reward: 288.0
Max Reward: 320.0
Gini Coefficient: 0.023703703703703703
20:20 Ratio: 1.1111111111111112
Max-min Ratio: 1.1111111111111112
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-09-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 925.0
  episode_reward_mean: 693.48
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 25
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.547
    dispatch_time_ms: 7.917
    learner:
      cur_lr: 0.0013550049625337124
      grad_gnorm: 39.99997329711914
      policy_entropy: 31.53271484375
      policy_loss: -20.41732406616211
      var_gnorm: 21.899816513061523
      vf_explained_var: -0.21155810356140137
      vf_loss: 15.916571617126465
    num_steps_sampled: 78000
    num_steps_trained: 78000
    wait_time_ms: 64.237
  iterations_since_restore: 26
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 219.19899201393127
  time_this_iter_s: 8.2200186252594
  time_total_s: 219.19899201393127
  timestamp: 1594094975
  timesteps_since_restore: 78000
  timesteps_this_iter: 3000
  timesteps_total: 78000
  training_iteration: 26
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 219 s, 26 iter, 78000 ts, 693 rew

agent-1: 278.0
agent-2: 274.0
agent-3: 269.0
Sum Reward: 821.0
Avg Reward: 273.6666666666667
Min Reward: 269.0
Max Reward: 278.0
Gini Coefficient: 0.007308160779537149
20:20 Ratio: 1.033457249070632
Max-min Ratio: 1.033457249070632
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-09-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 925.0
  episode_reward_mean: 698.3846153846154
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 26
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.683
    dispatch_time_ms: 5.852
    learner:
      cur_lr: 0.0013548051938414574
      grad_gnorm: 40.0
      policy_entropy: 24.42579460144043
      policy_loss: 18.276630401611328
      var_gnorm: 21.932188034057617
      vf_explained_var: -1.0
      vf_loss: 42.59398651123047
    num_steps_sampled: 81000
    num_steps_trained: 81000
    wait_time_ms: 76.844
  iterations_since_restore: 27
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 227.01891255378723
  time_this_iter_s: 7.819920539855957
  time_total_s: 227.01891255378723
  timestamp: 1594094983
  timesteps_since_restore: 81000
  timesteps_this_iter: 3000
  timesteps_total: 81000
  training_iteration: 27
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 227 s, 27 iter, 81000 ts, 698 rew

agent-1: 290.0
agent-2: 265.0
agent-3: 315.0
Sum Reward: 870.0
Avg Reward: 290.0
Min Reward: 265.0
Max Reward: 315.0
Gini Coefficient: 0.038314176245210725
20:20 Ratio: 1.1886792452830188
Max-min Ratio: 1.1886792452830188
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-09-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 925.0
  episode_reward_mean: 704.7407407407408
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 27
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.77
    dispatch_time_ms: 9.279
    learner:
      cur_lr: 0.0013546054251492023
      grad_gnorm: 39.859588623046875
      policy_entropy: 18.97859764099121
      policy_loss: -6.471391677856445
      var_gnorm: 22.03234100341797
      vf_explained_var: 0.8797349333763123
      vf_loss: 6.2053022384643555
    num_steps_sampled: 84000
    num_steps_trained: 84000
    wait_time_ms: 73.594
  iterations_since_restore: 28
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 235.29693007469177
  time_this_iter_s: 8.278017520904541
  time_total_s: 235.29693007469177
  timestamp: 1594094991
  timesteps_since_restore: 84000
  timesteps_this_iter: 3000
  timesteps_total: 84000
  training_iteration: 28
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 235 s, 28 iter, 84000 ts, 705 rew

agent-1: 286.0
agent-2: 257.0
agent-3: 316.0
Sum Reward: 859.0
Avg Reward: 286.3333333333333
Min Reward: 257.0
Max Reward: 316.0
Gini Coefficient: 0.04578967792006209
20:20 Ratio: 1.2295719844357977
Max-min Ratio: 1.2295719844357977
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-09-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 925.0
  episode_reward_mean: 710.25
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 28
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.206
    dispatch_time_ms: 9.616
    learner:
      cur_lr: 0.0013544056564569473
      grad_gnorm: 40.000003814697266
      policy_entropy: 20.99791717529297
      policy_loss: 10.840152740478516
      var_gnorm: 22.107065200805664
      vf_explained_var: -0.06867969036102295
      vf_loss: 47.358734130859375
    num_steps_sampled: 87000
    num_steps_trained: 87000
    wait_time_ms: 71.939
  iterations_since_restore: 29
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 243.20293140411377
  time_this_iter_s: 7.906001329421997
  time_total_s: 243.20293140411377
  timestamp: 1594094999
  timesteps_since_restore: 87000
  timesteps_this_iter: 3000
  timesteps_total: 87000
  training_iteration: 29
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 243 s, 29 iter, 87000 ts, 710 rew

agent-1: 334.0
agent-2: 293.0
agent-3: 338.0
Sum Reward: 965.0
Avg Reward: 321.6666666666667
Min Reward: 293.0
Max Reward: 338.0
Gini Coefficient: 0.031088082901554404
20:20 Ratio: 1.1535836177474403
Max-min Ratio: 1.1535836177474403
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-10-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 965.0
  episode_reward_mean: 719.0344827586207
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 29
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.798
    dispatch_time_ms: 8.793
    learner:
      cur_lr: 0.0013542057713493705
      grad_gnorm: 40.0
      policy_entropy: 23.678300857543945
      policy_loss: 8.019948959350586
      var_gnorm: 22.23908233642578
      vf_explained_var: 0.21059536933898926
      vf_loss: 23.63497543334961
    num_steps_sampled: 90000
    num_steps_trained: 90000
    wait_time_ms: 71.273
  iterations_since_restore: 30
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 251.6254870891571
  time_this_iter_s: 8.422555685043335
  time_total_s: 251.6254870891571
  timestamp: 1594095008
  timesteps_since_restore: 90000
  timesteps_this_iter: 3000
  timesteps_total: 90000
  training_iteration: 30
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 251 s, 30 iter, 90000 ts, 719 rew

agent-1: 323.0
agent-2: 310.0
agent-3: 336.0
Sum Reward: 969.0
Avg Reward: 323.0
Min Reward: 310.0
Max Reward: 336.0
Gini Coefficient: 0.017887856897144824
20:20 Ratio: 1.0838709677419356
Max-min Ratio: 1.0838709677419356
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-10-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 969.0
  episode_reward_mean: 727.3666666666667
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 30
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.63
    dispatch_time_ms: 10.275
    learner:
      cur_lr: 0.0013540060026571155
      grad_gnorm: 40.000003814697266
      policy_entropy: 26.60951805114746
      policy_loss: -9.597698211669922
      var_gnorm: 22.328266143798828
      vf_explained_var: 0.18809479475021362
      vf_loss: 17.5271053314209
    num_steps_sampled: 93000
    num_steps_trained: 93000
    wait_time_ms: 71.966
  iterations_since_restore: 31
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 259.7564182281494
  time_this_iter_s: 8.13093113899231
  time_total_s: 259.7564182281494
  timestamp: 1594095016
  timesteps_since_restore: 93000
  timesteps_this_iter: 3000
  timesteps_total: 93000
  training_iteration: 31
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 259 s, 31 iter, 93000 ts, 727 rew

agent-1: 289.0
agent-2: 331.0
agent-3: 330.0
Sum Reward: 950.0
Avg Reward: 316.6666666666667
Min Reward: 289.0
Max Reward: 331.0
Gini Coefficient: 0.029473684210526315
20:20 Ratio: 1.1453287197231834
Max-min Ratio: 1.1453287197231834
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-10-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 969.0
  episode_reward_mean: 734.5483870967741
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 31
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.718
    dispatch_time_ms: 10.358
    learner:
      cur_lr: 0.0013538062339648604
      grad_gnorm: 40.0000114440918
      policy_entropy: 18.49551773071289
      policy_loss: 25.811851501464844
      var_gnorm: 22.41220474243164
      vf_explained_var: -0.35550689697265625
      vf_loss: 38.98371887207031
    num_steps_sampled: 96000
    num_steps_trained: 96000
    wait_time_ms: 69.035
  iterations_since_restore: 32
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 268.14811754226685
  time_this_iter_s: 8.391699314117432
  time_total_s: 268.14811754226685
  timestamp: 1594095024
  timesteps_since_restore: 96000
  timesteps_this_iter: 3000
  timesteps_total: 96000
  training_iteration: 32
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 268 s, 32 iter, 96000 ts, 735 rew

agent-1: 319.0
agent-2: 333.0
agent-3: 287.0
Sum Reward: 939.0
Avg Reward: 313.0
Min Reward: 287.0
Max Reward: 333.0
Gini Coefficient: 0.0326588569400071
20:20 Ratio: 1.1602787456445993
Max-min Ratio: 1.1602787456445993
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-10-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 969.0
  episode_reward_mean: 740.9375
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 32
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.671
    dispatch_time_ms: 10.776
    learner:
      cur_lr: 0.0013536063488572836
      grad_gnorm: 40.0000114440918
      policy_entropy: 16.32132339477539
      policy_loss: -1.254734754562378
      var_gnorm: 22.456707000732422
      vf_explained_var: 0.37583136558532715
      vf_loss: 26.84100914001465
    num_steps_sampled: 99000
    num_steps_trained: 99000
    wait_time_ms: 68.926
  iterations_since_restore: 33
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 276.09817481040955
  time_this_iter_s: 7.9500572681427
  time_total_s: 276.09817481040955
  timestamp: 1594095032
  timesteps_since_restore: 99000
  timesteps_this_iter: 3000
  timesteps_total: 99000
  training_iteration: 33
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 276 s, 33 iter, 99000 ts, 741 rew

agent-1: 315.0
agent-2: 298.0
agent-3: 339.0
Sum Reward: 952.0
Avg Reward: 317.3333333333333
Min Reward: 298.0
Max Reward: 339.0
Gini Coefficient: 0.028711484593837534
20:20 Ratio: 1.1375838926174497
Max-min Ratio: 1.1375838926174497
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-10-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 969.0
  episode_reward_mean: 747.3333333333334
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 33
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.753
    dispatch_time_ms: 8.994
    learner:
      cur_lr: 0.0013534065801650286
      grad_gnorm: 40.000003814697266
      policy_entropy: 20.468585968017578
      policy_loss: -15.312700271606445
      var_gnorm: 22.44515609741211
      vf_explained_var: 0.08993881940841675
      vf_loss: 23.336462020874023
    num_steps_sampled: 102000
    num_steps_trained: 102000
    wait_time_ms: 71.434
  iterations_since_restore: 34
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 284.52597069740295
  time_this_iter_s: 8.427795886993408
  time_total_s: 284.52597069740295
  timestamp: 1594095041
  timesteps_since_restore: 102000
  timesteps_this_iter: 3000
  timesteps_total: 102000
  training_iteration: 34
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 284 s, 34 iter, 102000 ts, 747 rew

agent-1: 328.0
agent-2: 311.0
agent-3: 323.0
Sum Reward: 962.0
Avg Reward: 320.6666666666667
Min Reward: 311.0
Max Reward: 328.0
Gini Coefficient: 0.01178101178101178
20:20 Ratio: 1.0546623794212218
Max-min Ratio: 1.0546623794212218
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-10-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 969.0
  episode_reward_mean: 753.6470588235294
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 34
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.673
    dispatch_time_ms: 7.501
    learner:
      cur_lr: 0.0013532068114727736
      grad_gnorm: 40.0
      policy_entropy: 18.971405029296875
      policy_loss: 39.79676055908203
      var_gnorm: 22.520116806030273
      vf_explained_var: -0.6101396083831787
      vf_loss: 24.493261337280273
    num_steps_sampled: 105000
    num_steps_trained: 105000
    wait_time_ms: 74.827
  iterations_since_restore: 35
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 292.5546772480011
  time_this_iter_s: 8.028706550598145
  time_total_s: 292.5546772480011
  timestamp: 1594095049
  timesteps_since_restore: 105000
  timesteps_this_iter: 3000
  timesteps_total: 105000
  training_iteration: 35
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 292 s, 35 iter, 105000 ts, 754 rew

agent-1: 351.0
agent-2: 307.0
agent-3: 330.0
Sum Reward: 988.0
Avg Reward: 329.3333333333333
Min Reward: 307.0
Max Reward: 351.0
Gini Coefficient: 0.029689608636977057
20:20 Ratio: 1.1433224755700326
Max-min Ratio: 1.1433224755700326
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-10-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 988.0
  episode_reward_mean: 760.3428571428572
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 35
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.41
    dispatch_time_ms: 6.233
    learner:
      cur_lr: 0.0013530070427805185
      grad_gnorm: 39.9999885559082
      policy_entropy: 16.543800354003906
      policy_loss: -1.0176560878753662
      var_gnorm: 22.569238662719727
      vf_explained_var: 0.02098989486694336
      vf_loss: 16.168500900268555
    num_steps_sampled: 108000
    num_steps_trained: 108000
    wait_time_ms: 66.383
  iterations_since_restore: 36
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 300.87215280532837
  time_this_iter_s: 8.31747555732727
  time_total_s: 300.87215280532837
  timestamp: 1594095057
  timesteps_since_restore: 108000
  timesteps_this_iter: 3000
  timesteps_total: 108000
  training_iteration: 36
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 300 s, 36 iter, 108000 ts, 760 rew

agent-1: 316.0
agent-2: 319.0
agent-3: 306.0
Sum Reward: 941.0
Avg Reward: 313.6666666666667
Min Reward: 306.0
Max Reward: 319.0
Gini Coefficient: 0.009210060219624512
20:20 Ratio: 1.042483660130719
Max-min Ratio: 1.042483660130719
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-11-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 988.0
  episode_reward_mean: 765.3611111111111
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 36
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.224
    dispatch_time_ms: 7.719
    learner:
      cur_lr: 0.0013528071576729417
      grad_gnorm: 39.999996185302734
      policy_entropy: 18.477569580078125
      policy_loss: -4.400225639343262
      var_gnorm: 22.683448791503906
      vf_explained_var: -0.04458117485046387
      vf_loss: 15.42927074432373
    num_steps_sampled: 111000
    num_steps_trained: 111000
    wait_time_ms: 74.216
  iterations_since_restore: 37
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 309.0272798538208
  time_this_iter_s: 8.155127048492432
  time_total_s: 309.0272798538208
  timestamp: 1594095065
  timesteps_since_restore: 111000
  timesteps_this_iter: 3000
  timesteps_total: 111000
  training_iteration: 37
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 309 s, 37 iter, 111000 ts, 765 rew

agent-1: 339.0
agent-2: 311.0
agent-3: 357.0
Sum Reward: 1007.0
Avg Reward: 335.6666666666667
Min Reward: 311.0
Max Reward: 357.0
Gini Coefficient: 0.030453492221118834
20:20 Ratio: 1.1479099678456592
Max-min Ratio: 1.1479099678456592
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-11-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.0
  episode_reward_mean: 771.8918918918919
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 37
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.705
    dispatch_time_ms: 6.163
    learner:
      cur_lr: 0.0013526073889806867
      grad_gnorm: 40.0
      policy_entropy: 25.79420280456543
      policy_loss: -0.7230014801025391
      var_gnorm: 22.699857711791992
      vf_explained_var: -0.33706581592559814
      vf_loss: 16.79443359375
    num_steps_sampled: 114000
    num_steps_trained: 114000
    wait_time_ms: 71.726
  iterations_since_restore: 38
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 317.63006353378296
  time_this_iter_s: 8.602783679962158
  time_total_s: 317.63006353378296
  timestamp: 1594095074
  timesteps_since_restore: 114000
  timesteps_this_iter: 3000
  timesteps_total: 114000
  training_iteration: 38
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 317 s, 38 iter, 114000 ts, 772 rew

agent-1: 351.0
agent-2: 331.0
agent-3: 340.0
Sum Reward: 1022.0
Avg Reward: 340.6666666666667
Min Reward: 331.0
Max Reward: 351.0
Gini Coefficient: 0.01304631441617743
20:20 Ratio: 1.0604229607250755
Max-min Ratio: 1.0604229607250755
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-11-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1022.0
  episode_reward_mean: 778.4736842105264
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 38
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.31
    dispatch_time_ms: 9.933
    learner:
      cur_lr: 0.0013524076202884316
      grad_gnorm: 39.999977111816406
      policy_entropy: 18.149951934814453
      policy_loss: 0.1323876976966858
      var_gnorm: 22.740283966064453
      vf_explained_var: -0.0186765193939209
      vf_loss: 7.210989952087402
    num_steps_sampled: 117000
    num_steps_trained: 117000
    wait_time_ms: 69.243
  iterations_since_restore: 39
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 325.6510396003723
  time_this_iter_s: 8.020976066589355
  time_total_s: 325.6510396003723
  timestamp: 1594095082
  timesteps_since_restore: 117000
  timesteps_this_iter: 3000
  timesteps_total: 117000
  training_iteration: 39
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 325 s, 39 iter, 117000 ts, 778 rew

agent-1: 306.0
agent-2: 307.0
agent-3: 316.0
Sum Reward: 929.0
Avg Reward: 309.6666666666667
Min Reward: 306.0
Max Reward: 316.0
Gini Coefficient: 0.007176175098672408
20:20 Ratio: 1.0326797385620916
Max-min Ratio: 1.0326797385620916
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-11-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1022.0
  episode_reward_mean: 782.3333333333334
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 39
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.89
    dispatch_time_ms: 7.488
    learner:
      cur_lr: 0.0013522078515961766
      grad_gnorm: 40.00000762939453
      policy_entropy: 24.194299697875977
      policy_loss: 3.0537326335906982
      var_gnorm: 22.747718811035156
      vf_explained_var: -0.09760904312133789
      vf_loss: 23.79595184326172
    num_steps_sampled: 120000
    num_steps_trained: 120000
    wait_time_ms: 69.695
  iterations_since_restore: 40
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 334.1035282611847
  time_this_iter_s: 8.452488660812378
  time_total_s: 334.1035282611847
  timestamp: 1594095091
  timesteps_since_restore: 120000
  timesteps_this_iter: 3000
  timesteps_total: 120000
  training_iteration: 40
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 334 s, 40 iter, 120000 ts, 782 rew

agent-1: 317.0
agent-2: 297.0
agent-3: 296.0
Sum Reward: 910.0
Avg Reward: 303.3333333333333
Min Reward: 296.0
Max Reward: 317.0
Gini Coefficient: 0.015384615384615385
20:20 Ratio: 1.070945945945946
Max-min Ratio: 1.070945945945946
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-11-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1022.0
  episode_reward_mean: 785.525
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 40
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.972
    dispatch_time_ms: 8.403
    learner:
      cur_lr: 0.0013520079664885998
      grad_gnorm: 39.9999885559082
      policy_entropy: 14.609562873840332
      policy_loss: 0.5898741483688354
      var_gnorm: 22.8819522857666
      vf_explained_var: -0.11647367477416992
      vf_loss: 15.281728744506836
    num_steps_sampled: 123000
    num_steps_trained: 123000
    wait_time_ms: 80.669
  iterations_since_restore: 41
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 342.5277531147003
  time_this_iter_s: 8.424224853515625
  time_total_s: 342.5277531147003
  timestamp: 1594095099
  timesteps_since_restore: 123000
  timesteps_this_iter: 3000
  timesteps_total: 123000
  training_iteration: 41
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 342 s, 41 iter, 123000 ts, 786 rew

agent-1: 350.0
agent-2: 360.0
agent-3: 355.0
Sum Reward: 1065.0
Avg Reward: 355.0
Min Reward: 350.0
Max Reward: 360.0
Gini Coefficient: 0.006259780907668232
20:20 Ratio: 1.0285714285714285
Max-min Ratio: 1.0285714285714285
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-11-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1065.0
  episode_reward_mean: 792.3414634146342
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 41
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.574
    dispatch_time_ms: 6.136
    learner:
      cur_lr: 0.0013518081977963448
      grad_gnorm: 39.99998092651367
      policy_entropy: 16.612529754638672
      policy_loss: 7.815954208374023
      var_gnorm: 23.120206832885742
      vf_explained_var: -0.6976001262664795
      vf_loss: 18.16963768005371
    num_steps_sampled: 126000
    num_steps_trained: 126000
    wait_time_ms: 75.978
  iterations_since_restore: 42
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 351.0351243019104
  time_this_iter_s: 8.507371187210083
  time_total_s: 351.0351243019104
  timestamp: 1594095108
  timesteps_since_restore: 126000
  timesteps_this_iter: 3000
  timesteps_total: 126000
  training_iteration: 42
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 351 s, 42 iter, 126000 ts, 792 rew

agent-1: 365.0
agent-2: 361.0
agent-3: 314.0
Sum Reward: 1040.0
Avg Reward: 346.6666666666667
Min Reward: 314.0
Max Reward: 365.0
Gini Coefficient: 0.032692307692307694
20:20 Ratio: 1.1624203821656052
Max-min Ratio: 1.1624203821656052
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-11-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1065.0
  episode_reward_mean: 798.2380952380952
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 42
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.867
    dispatch_time_ms: 8.553
    learner:
      cur_lr: 0.0013516084291040897
      grad_gnorm: 21.051414489746094
      policy_entropy: 23.07802963256836
      policy_loss: -7.615008354187012
      var_gnorm: 23.279939651489258
      vf_explained_var: 0.025011301040649414
      vf_loss: 22.859539031982422
    num_steps_sampled: 129000
    num_steps_trained: 129000
    wait_time_ms: 72.882
  iterations_since_restore: 43
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 359.1153132915497
  time_this_iter_s: 8.080188989639282
  time_total_s: 359.1153132915497
  timestamp: 1594095116
  timesteps_since_restore: 129000
  timesteps_this_iter: 3000
  timesteps_total: 129000
  training_iteration: 43
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 359 s, 43 iter, 129000 ts, 798 rew

agent-1: 382.0
agent-2: 377.0
agent-3: 316.0
Sum Reward: 1075.0
Avg Reward: 358.3333333333333
Min Reward: 316.0
Max Reward: 382.0
Gini Coefficient: 0.04093023255813953
20:20 Ratio: 1.2088607594936709
Max-min Ratio: 1.2088607594936709
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-12-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1075.0
  episode_reward_mean: 804.6744186046511
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 43
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.579
    dispatch_time_ms: 6.742
    learner:
      cur_lr: 0.0013514085439965129
      grad_gnorm: 40.0
      policy_entropy: 23.108074188232422
      policy_loss: -21.47842025756836
      var_gnorm: 23.364625930786133
      vf_explained_var: -0.08800351619720459
      vf_loss: 22.941987991333008
    num_steps_sampled: 132000
    num_steps_trained: 132000
    wait_time_ms: 77.765
  iterations_since_restore: 44
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 367.66294860839844
  time_this_iter_s: 8.547635316848755
  time_total_s: 367.66294860839844
  timestamp: 1594095124
  timesteps_since_restore: 132000
  timesteps_this_iter: 3000
  timesteps_total: 132000
  training_iteration: 44
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 367 s, 44 iter, 132000 ts, 805 rew

agent-1: 340.0
agent-2: 377.0
agent-3: 326.0
Sum Reward: 1043.0
Avg Reward: 347.6666666666667
Min Reward: 326.0
Max Reward: 377.0
Gini Coefficient: 0.032598274209012464
20:20 Ratio: 1.156441717791411
Max-min Ratio: 1.156441717791411
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-12-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1075.0
  episode_reward_mean: 810.0909090909091
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 44
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.199
    dispatch_time_ms: 8.884
    learner:
      cur_lr: 0.0013512087753042579
      grad_gnorm: 39.99999237060547
      policy_entropy: 21.491548538208008
      policy_loss: 12.575061798095703
      var_gnorm: 23.43526268005371
      vf_explained_var: -0.685644268989563
      vf_loss: 7.921143531799316
    num_steps_sampled: 135000
    num_steps_trained: 135000
    wait_time_ms: 73.744
  iterations_since_restore: 45
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 375.97729110717773
  time_this_iter_s: 8.314342498779297
  time_total_s: 375.97729110717773
  timestamp: 1594095133
  timesteps_since_restore: 135000
  timesteps_this_iter: 3000
  timesteps_total: 135000
  training_iteration: 45
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 375 s, 45 iter, 135000 ts, 810 rew

agent-1: 378.0
agent-2: 363.0
agent-3: 388.0
Sum Reward: 1129.0
Avg Reward: 376.3333333333333
Min Reward: 363.0
Max Reward: 388.0
Gini Coefficient: 0.014762326542663124
20:20 Ratio: 1.0688705234159779
Max-min Ratio: 1.0688705234159779
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-12-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1129.0
  episode_reward_mean: 817.1777777777778
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 45
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.779
    dispatch_time_ms: 6.86
    learner:
      cur_lr: 0.0013510090066120028
      grad_gnorm: 40.0
      policy_entropy: 24.180683135986328
      policy_loss: 14.639389038085938
      var_gnorm: 23.553916931152344
      vf_explained_var: -0.452677845954895
      vf_loss: 20.254362106323242
    num_steps_sampled: 138000
    num_steps_trained: 138000
    wait_time_ms: 68.305
  iterations_since_restore: 46
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 384.7182388305664
  time_this_iter_s: 8.740947723388672
  time_total_s: 384.7182388305664
  timestamp: 1594095141
  timesteps_since_restore: 138000
  timesteps_this_iter: 3000
  timesteps_total: 138000
  training_iteration: 46
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 384 s, 46 iter, 138000 ts, 817 rew

agent-1: 367.0
agent-2: 368.0
agent-3: 357.0
Sum Reward: 1092.0
Avg Reward: 364.0
Min Reward: 357.0
Max Reward: 368.0
Gini Coefficient: 0.006715506715506716
20:20 Ratio: 1.0308123249299719
Max-min Ratio: 1.0308123249299719
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-12-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1129.0
  episode_reward_mean: 823.1521739130435
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 46
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.097
    dispatch_time_ms: 7.976
    learner:
      cur_lr: 0.0013508092379197478
      grad_gnorm: 39.999996185302734
      policy_entropy: 21.954750061035156
      policy_loss: 20.52391242980957
      var_gnorm: 23.65515899658203
      vf_explained_var: 0.1894412636756897
      vf_loss: 35.893863677978516
    num_steps_sampled: 141000
    num_steps_trained: 141000
    wait_time_ms: 73.808
  iterations_since_restore: 47
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 393.2746727466583
  time_this_iter_s: 8.556433916091919
  time_total_s: 393.2746727466583
  timestamp: 1594095150
  timesteps_since_restore: 141000
  timesteps_this_iter: 3000
  timesteps_total: 141000
  training_iteration: 47
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 393 s, 47 iter, 141000 ts, 823 rew

agent-1: 370.0
agent-2: 374.0
agent-3: 314.0
Sum Reward: 1058.0
Avg Reward: 352.6666666666667
Min Reward: 314.0
Max Reward: 374.0
Gini Coefficient: 0.03780718336483932
20:20 Ratio: 1.1910828025477707
Max-min Ratio: 1.1910828025477707
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-12-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1129.0
  episode_reward_mean: 828.1489361702128
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 47
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.03
    dispatch_time_ms: 7.916
    learner:
      cur_lr: 0.001350609352812171
      grad_gnorm: 40.0
      policy_entropy: 19.054471969604492
      policy_loss: 27.042278289794922
      var_gnorm: 23.685514450073242
      vf_explained_var: -0.08584630489349365
      vf_loss: 44.02110290527344
    num_steps_sampled: 144000
    num_steps_trained: 144000
    wait_time_ms: 67.138
  iterations_since_restore: 48
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 401.8731617927551
  time_this_iter_s: 8.598489046096802
  time_total_s: 401.8731617927551
  timestamp: 1594095159
  timesteps_since_restore: 144000
  timesteps_this_iter: 3000
  timesteps_total: 144000
  training_iteration: 48
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 401 s, 48 iter, 144000 ts, 828 rew

agent-1: 347.0
agent-2: 314.0
agent-3: 357.0
Sum Reward: 1018.0
Avg Reward: 339.3333333333333
Min Reward: 314.0
Max Reward: 357.0
Gini Coefficient: 0.028159790438768827
20:20 Ratio: 1.1369426751592357
Max-min Ratio: 1.1369426751592357
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-12-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1129.0
  episode_reward_mean: 832.1041666666666
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 48
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.245
    dispatch_time_ms: 6.244
    learner:
      cur_lr: 0.001350409584119916
      grad_gnorm: 40.000030517578125
      policy_entropy: 18.354154586791992
      policy_loss: 0.004251956939697266
      var_gnorm: 23.781503677368164
      vf_explained_var: 0.270871102809906
      vf_loss: 23.176227569580078
    num_steps_sampled: 147000
    num_steps_trained: 147000
    wait_time_ms: 74.793
  iterations_since_restore: 49
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 410.1113715171814
  time_this_iter_s: 8.23820972442627
  time_total_s: 410.1113715171814
  timestamp: 1594095167
  timesteps_since_restore: 147000
  timesteps_this_iter: 3000
  timesteps_total: 147000
  training_iteration: 49
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 410 s, 49 iter, 147000 ts, 832 rew

agent-1: 370.0
agent-2: 393.0
agent-3: 323.0
Sum Reward: 1086.0
Avg Reward: 362.0
Min Reward: 323.0
Max Reward: 393.0
Gini Coefficient: 0.042971147943523635
20:20 Ratio: 1.21671826625387
Max-min Ratio: 1.21671826625387
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-12-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1129.0
  episode_reward_mean: 837.2857142857143
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 49
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.499
    dispatch_time_ms: 6.549
    learner:
      cur_lr: 0.001350209815427661
      grad_gnorm: 18.2445068359375
      policy_entropy: 20.065444946289062
      policy_loss: -4.478410720825195
      var_gnorm: 23.8735294342041
      vf_explained_var: 0.0011091232299804688
      vf_loss: 9.156865119934082
    num_steps_sampled: 150000
    num_steps_trained: 150000
    wait_time_ms: 75.978
  iterations_since_restore: 50
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 418.7631256580353
  time_this_iter_s: 8.651754140853882
  time_total_s: 418.7631256580353
  timestamp: 1594095176
  timesteps_since_restore: 150000
  timesteps_this_iter: 3000
  timesteps_total: 150000
  training_iteration: 50
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 418 s, 50 iter, 150000 ts, 837 rew

agent-1: 362.0
agent-2: 379.0
agent-3: 329.0
Sum Reward: 1070.0
Avg Reward: 356.6666666666667
Min Reward: 329.0
Max Reward: 379.0
Gini Coefficient: 0.03115264797507788
20:20 Ratio: 1.1519756838905775
Max-min Ratio: 1.1519756838905775
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-13-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1129.0
  episode_reward_mean: 841.94
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 50
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.708
    dispatch_time_ms: 7.432
    learner:
      cur_lr: 0.001350010046735406
      grad_gnorm: 40.000003814697266
      policy_entropy: 20.19419288635254
      policy_loss: -31.20461082458496
      var_gnorm: 23.974218368530273
      vf_explained_var: -1.0
      vf_loss: 55.13618850708008
    num_steps_sampled: 153000
    num_steps_trained: 153000
    wait_time_ms: 75.592
  iterations_since_restore: 51
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 427.2000563144684
  time_this_iter_s: 8.436930656433105
  time_total_s: 427.2000563144684
  timestamp: 1594095184
  timesteps_since_restore: 153000
  timesteps_this_iter: 3000
  timesteps_total: 153000
  training_iteration: 51
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 427 s, 51 iter, 153000 ts, 842 rew

agent-1: 410.0
agent-2: 387.0
agent-3: 423.0
Sum Reward: 1220.0
Avg Reward: 406.6666666666667
Min Reward: 387.0
Max Reward: 423.0
Gini Coefficient: 0.019672131147540985
20:20 Ratio: 1.0930232558139534
Max-min Ratio: 1.0930232558139534
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-13-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1220.0
  episode_reward_mean: 849.3529411764706
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 51
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.676
    dispatch_time_ms: 7.034
    learner:
      cur_lr: 0.001349810161627829
      grad_gnorm: 25.22783088684082
      policy_entropy: 15.036052703857422
      policy_loss: -6.045869827270508
      var_gnorm: 24.092805862426758
      vf_explained_var: 0.08545291423797607
      vf_loss: 30.251113891601562
    num_steps_sampled: 156000
    num_steps_trained: 156000
    wait_time_ms: 76.505
  iterations_since_restore: 52
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 436.16183853149414
  time_this_iter_s: 8.961782217025757
  time_total_s: 436.16183853149414
  timestamp: 1594095193
  timesteps_since_restore: 156000
  timesteps_this_iter: 3000
  timesteps_total: 156000
  training_iteration: 52
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 436 s, 52 iter, 156000 ts, 849 rew

agent-1: 390.0
agent-2: 376.0
agent-3: 360.0
Sum Reward: 1126.0
Avg Reward: 375.3333333333333
Min Reward: 360.0
Max Reward: 390.0
Gini Coefficient: 0.017761989342806393
20:20 Ratio: 1.0833333333333333
Max-min Ratio: 1.0833333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-13-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1220.0
  episode_reward_mean: 854.6730769230769
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 52
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.33
    dispatch_time_ms: 8.833
    learner:
      cur_lr: 0.001349610392935574
      grad_gnorm: 37.03218460083008
      policy_entropy: 18.67668914794922
      policy_loss: 3.3345959186553955
      var_gnorm: 24.251096725463867
      vf_explained_var: -0.021607041358947754
      vf_loss: 6.41148567199707
    num_steps_sampled: 159000
    num_steps_trained: 159000
    wait_time_ms: 79.7
  iterations_since_restore: 53
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 444.63515973091125
  time_this_iter_s: 8.473321199417114
  time_total_s: 444.63515973091125
  timestamp: 1594095202
  timesteps_since_restore: 159000
  timesteps_this_iter: 3000
  timesteps_total: 159000
  training_iteration: 53
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 444 s, 53 iter, 159000 ts, 855 rew

agent-1: 392.0
agent-2: 395.0
agent-3: 393.0
Sum Reward: 1180.0
Avg Reward: 393.3333333333333
Min Reward: 392.0
Max Reward: 395.0
Gini Coefficient: 0.001694915254237288
20:20 Ratio: 1.0076530612244898
Max-min Ratio: 1.0076530612244898
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-13-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1220.0
  episode_reward_mean: 860.811320754717
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 53
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.669
    dispatch_time_ms: 7.171
    learner:
      cur_lr: 0.001349410624243319
      grad_gnorm: 39.99998474121094
      policy_entropy: 20.267730712890625
      policy_loss: -1.8090429306030273
      var_gnorm: 24.326217651367188
      vf_explained_var: -0.020475149154663086
      vf_loss: 30.892654418945312
    num_steps_sampled: 162000
    num_steps_trained: 162000
    wait_time_ms: 79.501
  iterations_since_restore: 54
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 453.8918766975403
  time_this_iter_s: 9.256716966629028
  time_total_s: 453.8918766975403
  timestamp: 1594095211
  timesteps_since_restore: 162000
  timesteps_this_iter: 3000
  timesteps_total: 162000
  training_iteration: 54
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 453 s, 54 iter, 162000 ts, 861 rew

agent-1: 370.0
agent-2: 338.0
agent-3: 412.0
Sum Reward: 1120.0
Avg Reward: 373.3333333333333
Min Reward: 338.0
Max Reward: 412.0
Gini Coefficient: 0.04404761904761905
20:20 Ratio: 1.2189349112426036
Max-min Ratio: 1.2189349112426036
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-13-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1220.0
  episode_reward_mean: 865.6111111111111
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 54
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.934
    dispatch_time_ms: 7.959
    learner:
      cur_lr: 0.001349210855551064
      grad_gnorm: 39.99999237060547
      policy_entropy: 18.55402374267578
      policy_loss: 2.0657076835632324
      var_gnorm: 24.455337524414062
      vf_explained_var: 0.2126537561416626
      vf_loss: 44.38298797607422
    num_steps_sampled: 165000
    num_steps_trained: 165000
    wait_time_ms: 79.148
  iterations_since_restore: 55
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 462.6147677898407
  time_this_iter_s: 8.722891092300415
  time_total_s: 462.6147677898407
  timestamp: 1594095220
  timesteps_since_restore: 165000
  timesteps_this_iter: 3000
  timesteps_total: 165000
  training_iteration: 55
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 462 s, 55 iter, 165000 ts, 866 rew

agent-1: 411.0
agent-2: 328.0
agent-3: 399.0
Sum Reward: 1138.0
Avg Reward: 379.3333333333333
Min Reward: 328.0
Max Reward: 411.0
Gini Coefficient: 0.04862331575864089
20:20 Ratio: 1.2530487804878048
Max-min Ratio: 1.2530487804878048
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-13-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1220.0
  episode_reward_mean: 870.5636363636364
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 55
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.472
    dispatch_time_ms: 5.945
    learner:
      cur_lr: 0.0013490109704434872
      grad_gnorm: 39.999996185302734
      policy_entropy: 20.875022888183594
      policy_loss: -17.638578414916992
      var_gnorm: 24.44634246826172
      vf_explained_var: 0.1322726011276245
      vf_loss: 40.917572021484375
    num_steps_sampled: 168000
    num_steps_trained: 168000
    wait_time_ms: 73.938
  iterations_since_restore: 56
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 471.5739402770996
  time_this_iter_s: 8.959172487258911
  time_total_s: 471.5739402770996
  timestamp: 1594095229
  timesteps_since_restore: 168000
  timesteps_this_iter: 3000
  timesteps_total: 168000
  training_iteration: 56
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 471 s, 56 iter, 168000 ts, 871 rew

agent-1: 368.0
agent-2: 332.0
agent-3: 339.0
Sum Reward: 1039.0
Avg Reward: 346.3333333333333
Min Reward: 332.0
Max Reward: 368.0
Gini Coefficient: 0.023099133782483156
20:20 Ratio: 1.108433734939759
Max-min Ratio: 1.108433734939759
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-13-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1220.0
  episode_reward_mean: 873.5714285714286
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 56
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.663
    dispatch_time_ms: 5.873
    learner:
      cur_lr: 0.0013488112017512321
      grad_gnorm: 39.999996185302734
      policy_entropy: 20.61756134033203
      policy_loss: 25.73232078552246
      var_gnorm: 24.39887809753418
      vf_explained_var: 0.1567915678024292
      vf_loss: 35.3795280456543
    num_steps_sampled: 171000
    num_steps_trained: 171000
    wait_time_ms: 73.566
  iterations_since_restore: 57
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 479.73228335380554
  time_this_iter_s: 8.158343076705933
  time_total_s: 479.73228335380554
  timestamp: 1594095237
  timesteps_since_restore: 171000
  timesteps_this_iter: 3000
  timesteps_total: 171000
  training_iteration: 57
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 479 s, 57 iter, 171000 ts, 874 rew

agent-1: 284.0
agent-2: 273.0
agent-3: 295.0
Sum Reward: 852.0
Avg Reward: 284.0
Min Reward: 273.0
Max Reward: 295.0
Gini Coefficient: 0.017214397496087636
20:20 Ratio: 1.0805860805860805
Max-min Ratio: 1.0805860805860805
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-14-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1220.0
  episode_reward_mean: 873.1929824561404
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 57
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.92
    dispatch_time_ms: 6.915
    learner:
      cur_lr: 0.0013486114330589771
      grad_gnorm: 39.99999237060547
      policy_entropy: 22.588741302490234
      policy_loss: -10.883262634277344
      var_gnorm: 24.406709671020508
      vf_explained_var: 0.2923409342765808
      vf_loss: 11.262088775634766
    num_steps_sampled: 174000
    num_steps_trained: 174000
    wait_time_ms: 75.41
  iterations_since_restore: 58
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 488.43820452690125
  time_this_iter_s: 8.705921173095703
  time_total_s: 488.43820452690125
  timestamp: 1594095246
  timesteps_since_restore: 174000
  timesteps_this_iter: 3000
  timesteps_total: 174000
  training_iteration: 58
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 488 s, 58 iter, 174000 ts, 873 rew

agent-1: 326.0
agent-2: 254.0
agent-3: 284.0
Sum Reward: 864.0
Avg Reward: 288.0
Min Reward: 254.0
Max Reward: 326.0
Gini Coefficient: 0.05555555555555555
20:20 Ratio: 1.2834645669291338
Max-min Ratio: 1.2834645669291338
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-14-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1220.0
  episode_reward_mean: 873.0344827586207
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 58
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.66
    dispatch_time_ms: 5.487
    learner:
      cur_lr: 0.0013484115479514003
      grad_gnorm: 24.652175903320312
      policy_entropy: 20.97629165649414
      policy_loss: -4.176815986633301
      var_gnorm: 24.502899169921875
      vf_explained_var: -0.6832994222640991
      vf_loss: 23.297319412231445
    num_steps_sampled: 177000
    num_steps_trained: 177000
    wait_time_ms: 79.346
  iterations_since_restore: 59
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 496.943382024765
  time_this_iter_s: 8.50517749786377
  time_total_s: 496.943382024765
  timestamp: 1594095254
  timesteps_since_restore: 177000
  timesteps_this_iter: 3000
  timesteps_total: 177000
  training_iteration: 59
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 496 s, 59 iter, 177000 ts, 873 rew

agent-1: 385.0
agent-2: 332.0
agent-3: 351.0
Sum Reward: 1068.0
Avg Reward: 356.0
Min Reward: 332.0
Max Reward: 385.0
Gini Coefficient: 0.033083645443196
20:20 Ratio: 1.1596385542168675
Max-min Ratio: 1.1596385542168675
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-14-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1220.0
  episode_reward_mean: 876.3389830508474
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 59
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.0
    dispatch_time_ms: 8.081
    learner:
      cur_lr: 0.0013482117792591453
      grad_gnorm: 40.0
      policy_entropy: 13.482799530029297
      policy_loss: 12.182141304016113
      var_gnorm: 24.673625946044922
      vf_explained_var: -0.7446421384811401
      vf_loss: 26.23046112060547
    num_steps_sampled: 180000
    num_steps_trained: 180000
    wait_time_ms: 75.506
  iterations_since_restore: 60
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 505.86168575286865
  time_this_iter_s: 8.918303728103638
  time_total_s: 505.86168575286865
  timestamp: 1594095263
  timesteps_since_restore: 180000
  timesteps_this_iter: 3000
  timesteps_total: 180000
  training_iteration: 60
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 505 s, 60 iter, 180000 ts, 876 rew

agent-1: 397.0
agent-2: 371.0
agent-3: 431.0
Sum Reward: 1199.0
Avg Reward: 399.6666666666667
Min Reward: 371.0
Max Reward: 431.0
Gini Coefficient: 0.03336113427856547
20:20 Ratio: 1.1617250673854447
Max-min Ratio: 1.1617250673854447
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-14-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1220.0
  episode_reward_mean: 881.7166666666667
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 60
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.196
    dispatch_time_ms: 8.703
    learner:
      cur_lr: 0.0013480120105668902
      grad_gnorm: 40.000003814697266
      policy_entropy: 18.412744522094727
      policy_loss: -5.697274684906006
      var_gnorm: 24.80682945251465
      vf_explained_var: 0.24756866693496704
      vf_loss: 37.142112731933594
    num_steps_sampled: 183000
    num_steps_trained: 183000
    wait_time_ms: 76.311
  iterations_since_restore: 61
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 514.5906653404236
  time_this_iter_s: 8.728979587554932
  time_total_s: 514.5906653404236
  timestamp: 1594095272
  timesteps_since_restore: 183000
  timesteps_this_iter: 3000
  timesteps_total: 183000
  training_iteration: 61
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 514 s, 61 iter, 183000 ts, 882 rew

agent-1: 328.0
agent-2: 400.0
agent-3: 307.0
Sum Reward: 1035.0
Avg Reward: 345.0
Min Reward: 307.0
Max Reward: 400.0
Gini Coefficient: 0.05990338164251208
20:20 Ratio: 1.3029315960912051
Max-min Ratio: 1.3029315960912051
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-14-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1220.0
  episode_reward_mean: 884.2295081967213
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 61
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.086
    dispatch_time_ms: 5.376
    learner:
      cur_lr: 0.0013478122418746352
      grad_gnorm: 40.0
      policy_entropy: 14.801456451416016
      policy_loss: -18.739578247070312
      var_gnorm: 24.930368423461914
      vf_explained_var: 0.006688714027404785
      vf_loss: 56.57469940185547
    num_steps_sampled: 186000
    num_steps_trained: 186000
    wait_time_ms: 76.208
  iterations_since_restore: 62
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 523.7904784679413
  time_this_iter_s: 9.1998131275177
  time_total_s: 523.7904784679413
  timestamp: 1594095281
  timesteps_since_restore: 186000
  timesteps_this_iter: 3000
  timesteps_total: 186000
  training_iteration: 62
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 523 s, 62 iter, 186000 ts, 884 rew

agent-1: 370.0
agent-2: 389.0
agent-3: 381.0
Sum Reward: 1140.0
Avg Reward: 380.0
Min Reward: 370.0
Max Reward: 389.0
Gini Coefficient: 0.011111111111111112
20:20 Ratio: 1.0513513513513513
Max-min Ratio: 1.0513513513513513
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-14-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1220.0
  episode_reward_mean: 888.3548387096774
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 62
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.875
    dispatch_time_ms: 9.661
    learner:
      cur_lr: 0.0013476123567670584
      grad_gnorm: 29.50006675720215
      policy_entropy: 14.95324993133545
      policy_loss: -0.47525355219841003
      var_gnorm: 25.006925582885742
      vf_explained_var: 0.3645961880683899
      vf_loss: 46.746212005615234
    num_steps_sampled: 189000
    num_steps_trained: 189000
    wait_time_ms: 83.364
  iterations_since_restore: 63
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 532.3616540431976
  time_this_iter_s: 8.571175575256348
  time_total_s: 532.3616540431976
  timestamp: 1594095290
  timesteps_since_restore: 189000
  timesteps_this_iter: 3000
  timesteps_total: 189000
  training_iteration: 63
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 532 s, 63 iter, 189000 ts, 888 rew

agent-1: 218.0
agent-2: 363.0
agent-3: 375.0
Sum Reward: 956.0
Avg Reward: 318.6666666666667
Min Reward: 218.0
Max Reward: 375.0
Gini Coefficient: 0.10948396094839609
20:20 Ratio: 1.7201834862385321
Max-min Ratio: 1.7201834862385321
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-15-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1220.0
  episode_reward_mean: 889.4285714285714
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 63
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.771
    dispatch_time_ms: 7.895
    learner:
      cur_lr: 0.0013474125880748034
      grad_gnorm: 40.00000762939453
      policy_entropy: 11.45372486114502
      policy_loss: -5.765183925628662
      var_gnorm: 25.098350524902344
      vf_explained_var: -0.28461551666259766
      vf_loss: 17.937074661254883
    num_steps_sampled: 192000
    num_steps_trained: 192000
    wait_time_ms: 86.537
  iterations_since_restore: 64
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 542.2500348091125
  time_this_iter_s: 9.888380765914917
  time_total_s: 542.2500348091125
  timestamp: 1594095300
  timesteps_since_restore: 192000
  timesteps_this_iter: 3000
  timesteps_total: 192000
  training_iteration: 64
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 542 s, 64 iter, 192000 ts, 889 rew

agent-1: 291.0
agent-2: 345.0
agent-3: 404.0
Sum Reward: 1040.0
Avg Reward: 346.6666666666667
Min Reward: 291.0
Max Reward: 404.0
Gini Coefficient: 0.07243589743589744
20:20 Ratio: 1.388316151202749
Max-min Ratio: 1.388316151202749
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-15-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1220.0
  episode_reward_mean: 891.78125
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 64
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.374
    dispatch_time_ms: 6.742
    learner:
      cur_lr: 0.0013472128193825483
      grad_gnorm: 40.00000762939453
      policy_entropy: 18.94747543334961
      policy_loss: -7.904056549072266
      var_gnorm: 25.283296585083008
      vf_explained_var: 0.20410656929016113
      vf_loss: 29.107051849365234
    num_steps_sampled: 195000
    num_steps_trained: 195000
    wait_time_ms: 91.704
  iterations_since_restore: 65
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 551.8743598461151
  time_this_iter_s: 9.624325037002563
  time_total_s: 551.8743598461151
  timestamp: 1594095309
  timesteps_since_restore: 195000
  timesteps_this_iter: 3000
  timesteps_total: 195000
  training_iteration: 65
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 551 s, 65 iter, 195000 ts, 892 rew

agent-1: 443.0
agent-2: 351.0
agent-3: 334.0
Sum Reward: 1128.0
Avg Reward: 376.0
Min Reward: 334.0
Max Reward: 443.0
Gini Coefficient: 0.0644208037825059
20:20 Ratio: 1.3263473053892216
Max-min Ratio: 1.3263473053892216
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-15-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1220.0
  episode_reward_mean: 895.4153846153846
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 65
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.329
    dispatch_time_ms: 6.452
    learner:
      cur_lr: 0.0013470130506902933
      grad_gnorm: 40.000003814697266
      policy_entropy: 16.156984329223633
      policy_loss: 0.6131151914596558
      var_gnorm: 25.625654220581055
      vf_explained_var: 0.3642269968986511
      vf_loss: 6.776830673217773
    num_steps_sampled: 198000
    num_steps_trained: 198000
    wait_time_ms: 84.793
  iterations_since_restore: 66
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 561.8399431705475
  time_this_iter_s: 9.965583324432373
  time_total_s: 561.8399431705475
  timestamp: 1594095319
  timesteps_since_restore: 198000
  timesteps_this_iter: 3000
  timesteps_total: 198000
  training_iteration: 66
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 561 s, 66 iter, 198000 ts, 895 rew

agent-1: 369.0
agent-2: 394.0
agent-3: 359.0
Sum Reward: 1122.0
Avg Reward: 374.0
Min Reward: 359.0
Max Reward: 394.0
Gini Coefficient: 0.020796197266785502
20:20 Ratio: 1.0974930362116992
Max-min Ratio: 1.0974930362116992
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-15-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1220.0
  episode_reward_mean: 898.8484848484849
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 66
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.787
    dispatch_time_ms: 6.256
    learner:
      cur_lr: 0.0013468131655827165
      grad_gnorm: 40.000003814697266
      policy_entropy: 17.144742965698242
      policy_loss: 17.18037223815918
      var_gnorm: 25.838504791259766
      vf_explained_var: -0.5043538808822632
      vf_loss: 52.885643005371094
    num_steps_sampled: 201000
    num_steps_trained: 201000
    wait_time_ms: 77.35
  iterations_since_restore: 67
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 570.5957806110382
  time_this_iter_s: 8.755837440490723
  time_total_s: 570.5957806110382
  timestamp: 1594095328
  timesteps_since_restore: 201000
  timesteps_this_iter: 3000
  timesteps_total: 201000
  training_iteration: 67
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 570 s, 67 iter, 201000 ts, 899 rew

agent-1: 395.0
agent-2: 341.0
agent-3: 414.0
Sum Reward: 1150.0
Avg Reward: 383.3333333333333
Min Reward: 341.0
Max Reward: 414.0
Gini Coefficient: 0.042318840579710144
20:20 Ratio: 1.2140762463343109
Max-min Ratio: 1.2140762463343109
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-15-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1220.0
  episode_reward_mean: 902.5970149253732
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 67
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.542
    dispatch_time_ms: 5.865
    learner:
      cur_lr: 0.0013466133968904614
      grad_gnorm: 40.0
      policy_entropy: 15.500326156616211
      policy_loss: -14.533459663391113
      var_gnorm: 26.05868148803711
      vf_explained_var: -0.3019592761993408
      vf_loss: 16.872182846069336
    num_steps_sampled: 204000
    num_steps_trained: 204000
    wait_time_ms: 84.67
  iterations_since_restore: 68
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 579.5583045482635
  time_this_iter_s: 8.962523937225342
  time_total_s: 579.5583045482635
  timestamp: 1594095337
  timesteps_since_restore: 204000
  timesteps_this_iter: 3000
  timesteps_total: 204000
  training_iteration: 68
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 579 s, 68 iter, 204000 ts, 903 rew

agent-1: 409.0
agent-2: 369.0
agent-3: 397.0
Sum Reward: 1175.0
Avg Reward: 391.6666666666667
Min Reward: 369.0
Max Reward: 409.0
Gini Coefficient: 0.02269503546099291
20:20 Ratio: 1.10840108401084
Max-min Ratio: 1.10840108401084
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-15-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1220.0
  episode_reward_mean: 906.6029411764706
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 68
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.994
    dispatch_time_ms: 8.182
    learner:
      cur_lr: 0.0013464136281982064
      grad_gnorm: 40.00000762939453
      policy_entropy: 14.981532096862793
      policy_loss: -22.79892349243164
      var_gnorm: 26.222414016723633
      vf_explained_var: -1.0
      vf_loss: 20.773271560668945
    num_steps_sampled: 207000
    num_steps_trained: 207000
    wait_time_ms: 78.428
  iterations_since_restore: 69
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 588.2147028446198
  time_this_iter_s: 8.656398296356201
  time_total_s: 588.2147028446198
  timestamp: 1594095346
  timesteps_since_restore: 207000
  timesteps_this_iter: 3000
  timesteps_total: 207000
  training_iteration: 69
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 588 s, 69 iter, 207000 ts, 907 rew

agent-1: 412.0
agent-2: 344.0
agent-3: 391.0
Sum Reward: 1147.0
Avg Reward: 382.3333333333333
Min Reward: 344.0
Max Reward: 412.0
Gini Coefficient: 0.03952339436210404
20:20 Ratio: 1.197674418604651
Max-min Ratio: 1.197674418604651
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-15-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1220.0
  episode_reward_mean: 910.0869565217391
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 69
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.472
    dispatch_time_ms: 5.65
    learner:
      cur_lr: 0.0013462137430906296
      grad_gnorm: 40.00001907348633
      policy_entropy: 17.70681381225586
      policy_loss: 11.10106086730957
      var_gnorm: 26.394392013549805
      vf_explained_var: -0.2500936985015869
      vf_loss: 21.260740280151367
    num_steps_sampled: 210000
    num_steps_trained: 210000
    wait_time_ms: 83.179
  iterations_since_restore: 70
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 597.1493666172028
  time_this_iter_s: 8.934663772583008
  time_total_s: 597.1493666172028
  timestamp: 1594095355
  timesteps_since_restore: 210000
  timesteps_this_iter: 3000
  timesteps_total: 210000
  training_iteration: 70
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 597 s, 70 iter, 210000 ts, 910 rew

agent-1: 406.0
agent-2: 375.0
agent-3: 423.0
Sum Reward: 1204.0
Avg Reward: 401.3333333333333
Min Reward: 375.0
Max Reward: 423.0
Gini Coefficient: 0.026578073089700997
20:20 Ratio: 1.128
Max-min Ratio: 1.128
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-16-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1220.0
  episode_reward_mean: 914.2857142857143
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 70
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.968
    dispatch_time_ms: 8.038
    learner:
      cur_lr: 0.0013460139743983746
      grad_gnorm: 40.0
      policy_entropy: 19.69272232055664
      policy_loss: 9.802555084228516
      var_gnorm: 26.54050064086914
      vf_explained_var: -0.4268702268600464
      vf_loss: 17.466291427612305
    num_steps_sampled: 213000
    num_steps_trained: 213000
    wait_time_ms: 72.155
  iterations_since_restore: 71
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 605.6093807220459
  time_this_iter_s: 8.46001410484314
  time_total_s: 605.6093807220459
  timestamp: 1594095363
  timesteps_since_restore: 213000
  timesteps_this_iter: 3000
  timesteps_total: 213000
  training_iteration: 71
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 605 s, 71 iter, 213000 ts, 914 rew

agent-1: 403.0
agent-2: 397.0
agent-3: 421.0
Sum Reward: 1221.0
Avg Reward: 407.0
Min Reward: 397.0
Max Reward: 421.0
Gini Coefficient: 0.013104013104013105
20:20 Ratio: 1.0604534005037782
Max-min Ratio: 1.0604534005037782
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-16-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1221.0
  episode_reward_mean: 918.6056338028169
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 71
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.523
    dispatch_time_ms: 6.647
    learner:
      cur_lr: 0.0013458142057061195
      grad_gnorm: 40.0
      policy_entropy: 9.33901596069336
      policy_loss: 12.288860321044922
      var_gnorm: 26.658960342407227
      vf_explained_var: 0.17716580629348755
      vf_loss: 35.417659759521484
    num_steps_sampled: 216000
    num_steps_trained: 216000
    wait_time_ms: 75.441
  iterations_since_restore: 72
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 614.3365850448608
  time_this_iter_s: 8.727204322814941
  time_total_s: 614.3365850448608
  timestamp: 1594095372
  timesteps_since_restore: 216000
  timesteps_this_iter: 3000
  timesteps_total: 216000
  training_iteration: 72
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 614 s, 72 iter, 216000 ts, 919 rew

agent-1: 426.0
agent-2: 389.0
agent-3: 386.0
Sum Reward: 1201.0
Avg Reward: 400.3333333333333
Min Reward: 386.0
Max Reward: 426.0
Gini Coefficient: 0.022203719122953096
20:20 Ratio: 1.1036269430051813
Max-min Ratio: 1.1036269430051813
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-16-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1221.0
  episode_reward_mean: 922.5277777777778
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 72
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.403
    dispatch_time_ms: 10.584
    learner:
      cur_lr: 0.0013456144370138645
      grad_gnorm: 39.99999237060547
      policy_entropy: 15.233495712280273
      policy_loss: 2.6325035095214844
      var_gnorm: 26.879512786865234
      vf_explained_var: -0.10052680969238281
      vf_loss: 20.015600204467773
    num_steps_sampled: 219000
    num_steps_trained: 219000
    wait_time_ms: 77.953
  iterations_since_restore: 73
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 623.0858170986176
  time_this_iter_s: 8.749232053756714
  time_total_s: 623.0858170986176
  timestamp: 1594095381
  timesteps_since_restore: 219000
  timesteps_this_iter: 3000
  timesteps_total: 219000
  training_iteration: 73
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 623 s, 73 iter, 219000 ts, 923 rew

agent-1: 369.0
agent-2: 373.0
agent-3: 426.0
Sum Reward: 1168.0
Avg Reward: 389.3333333333333
Min Reward: 369.0
Max Reward: 426.0
Gini Coefficient: 0.032534246575342464
20:20 Ratio: 1.1544715447154472
Max-min Ratio: 1.1544715447154472
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-16-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1221.0
  episode_reward_mean: 925.8904109589041
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 73
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.637
    dispatch_time_ms: 6.786
    learner:
      cur_lr: 0.0013454145519062877
      grad_gnorm: 36.85806655883789
      policy_entropy: 16.8000545501709
      policy_loss: 8.062378883361816
      var_gnorm: 26.992252349853516
      vf_explained_var: -0.361314058303833
      vf_loss: 18.277231216430664
    num_steps_sampled: 222000
    num_steps_trained: 222000
    wait_time_ms: 81.082
  iterations_since_restore: 74
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 632.1649160385132
  time_this_iter_s: 9.07909893989563
  time_total_s: 632.1649160385132
  timestamp: 1594095390
  timesteps_since_restore: 222000
  timesteps_this_iter: 3000
  timesteps_total: 222000
  training_iteration: 74
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 632 s, 74 iter, 222000 ts, 926 rew

agent-1: 416.0
agent-2: 381.0
agent-3: 384.0
Sum Reward: 1181.0
Avg Reward: 393.6666666666667
Min Reward: 381.0
Max Reward: 416.0
Gini Coefficient: 0.019757267852102738
20:20 Ratio: 1.0918635170603674
Max-min Ratio: 1.0918635170603674
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-16-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1221.0
  episode_reward_mean: 929.3378378378378
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 74
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.578
    dispatch_time_ms: 6.452
    learner:
      cur_lr: 0.0013452147832140326
      grad_gnorm: 40.0
      policy_entropy: 13.588441848754883
      policy_loss: 16.948993682861328
      var_gnorm: 27.198457717895508
      vf_explained_var: -0.4797546863555908
      vf_loss: 23.514638900756836
    num_steps_sampled: 225000
    num_steps_trained: 225000
    wait_time_ms: 79.622
  iterations_since_restore: 75
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 640.9460210800171
  time_this_iter_s: 8.781105041503906
  time_total_s: 640.9460210800171
  timestamp: 1594095399
  timesteps_since_restore: 225000
  timesteps_this_iter: 3000
  timesteps_total: 225000
  training_iteration: 75
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 640 s, 75 iter, 225000 ts, 929 rew

agent-1: 435.0
agent-2: 399.0
agent-3: 401.0
Sum Reward: 1235.0
Avg Reward: 411.6666666666667
Min Reward: 399.0
Max Reward: 435.0
Gini Coefficient: 0.019433198380566803
20:20 Ratio: 1.0902255639097744
Max-min Ratio: 1.0902255639097744
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-16-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1235.0
  episode_reward_mean: 933.4133333333333
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 75
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.955
    dispatch_time_ms: 7.302
    learner:
      cur_lr: 0.0013450150145217776
      grad_gnorm: 39.999996185302734
      policy_entropy: 18.7406005859375
      policy_loss: -2.728336811065674
      var_gnorm: 27.546369552612305
      vf_explained_var: -0.25053250789642334
      vf_loss: 14.623495101928711
    num_steps_sampled: 228000
    num_steps_trained: 228000
    wait_time_ms: 78.788
  iterations_since_restore: 76
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 649.8744466304779
  time_this_iter_s: 8.928425550460815
  time_total_s: 649.8744466304779
  timestamp: 1594095408
  timesteps_since_restore: 228000
  timesteps_this_iter: 3000
  timesteps_total: 228000
  training_iteration: 76
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 649 s, 76 iter, 228000 ts, 933 rew

agent-1: 427.0
agent-2: 391.0
agent-3: 418.0
Sum Reward: 1236.0
Avg Reward: 412.0
Min Reward: 391.0
Max Reward: 427.0
Gini Coefficient: 0.019417475728155338
20:20 Ratio: 1.092071611253197
Max-min Ratio: 1.092071611253197
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-16-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1236.0
  episode_reward_mean: 937.3947368421053
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 76
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.437
    dispatch_time_ms: 7.557
    learner:
      cur_lr: 0.0013448152458295226
      grad_gnorm: 40.000003814697266
      policy_entropy: 16.445310592651367
      policy_loss: 11.744218826293945
      var_gnorm: 27.817665100097656
      vf_explained_var: 0.5102311372756958
      vf_loss: 44.718292236328125
    num_steps_sampled: 231000
    num_steps_trained: 231000
    wait_time_ms: 82.527
  iterations_since_restore: 77
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 658.7271015644073
  time_this_iter_s: 8.852654933929443
  time_total_s: 658.7271015644073
  timestamp: 1594095416
  timesteps_since_restore: 231000
  timesteps_this_iter: 3000
  timesteps_total: 231000
  training_iteration: 77
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 658 s, 77 iter, 231000 ts, 937 rew

agent-1: 397.0
agent-2: 416.0
agent-3: 409.0
Sum Reward: 1222.0
Avg Reward: 407.3333333333333
Min Reward: 397.0
Max Reward: 416.0
Gini Coefficient: 0.010365521003818877
20:20 Ratio: 1.0478589420654911
Max-min Ratio: 1.0478589420654911
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-17-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1236.0
  episode_reward_mean: 941.0909090909091
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 77
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.426
    dispatch_time_ms: 5.797
    learner:
      cur_lr: 0.0013446153607219458
      grad_gnorm: 40.00000762939453
      policy_entropy: 19.024641036987305
      policy_loss: -27.783857345581055
      var_gnorm: 27.989696502685547
      vf_explained_var: -0.02650773525238037
      vf_loss: 37.81319046020508
    num_steps_sampled: 234000
    num_steps_trained: 234000
    wait_time_ms: 83.032
  iterations_since_restore: 78
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 668.1775577068329
  time_this_iter_s: 9.450456142425537
  time_total_s: 668.1775577068329
  timestamp: 1594095426
  timesteps_since_restore: 234000
  timesteps_this_iter: 3000
  timesteps_total: 234000
  training_iteration: 78
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 668 s, 78 iter, 234000 ts, 941 rew

agent-1: 414.0
agent-2: 412.0
agent-3: 402.0
Sum Reward: 1228.0
Avg Reward: 409.3333333333333
Min Reward: 402.0
Max Reward: 414.0
Gini Coefficient: 0.006514657980456026
20:20 Ratio: 1.0298507462686568
Max-min Ratio: 1.0298507462686568
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-17-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1236.0
  episode_reward_mean: 944.7692307692307
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 78
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.547
    dispatch_time_ms: 8.511
    learner:
      cur_lr: 0.0013444155920296907
      grad_gnorm: 40.0
      policy_entropy: 16.559389114379883
      policy_loss: -24.946535110473633
      var_gnorm: 28.051673889160156
      vf_explained_var: -0.024462223052978516
      vf_loss: 46.73249435424805
    num_steps_sampled: 237000
    num_steps_trained: 237000
    wait_time_ms: 85.278
  iterations_since_restore: 79
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 677.5160531997681
  time_this_iter_s: 9.33849549293518
  time_total_s: 677.5160531997681
  timestamp: 1594095435
  timesteps_since_restore: 237000
  timesteps_this_iter: 3000
  timesteps_total: 237000
  training_iteration: 79
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 677 s, 79 iter, 237000 ts, 945 rew

agent-1: 284.0
agent-2: 435.0
agent-3: 342.0
Sum Reward: 1061.0
Avg Reward: 353.6666666666667
Min Reward: 284.0
Max Reward: 435.0
Gini Coefficient: 0.09487904492617028
20:20 Ratio: 1.5316901408450705
Max-min Ratio: 1.5316901408450705
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-17-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1236.0
  episode_reward_mean: 946.2405063291139
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 79
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.539
    dispatch_time_ms: 6.27
    learner:
      cur_lr: 0.0013442158233374357
      grad_gnorm: 40.000003814697266
      policy_entropy: 20.201274871826172
      policy_loss: -15.563631057739258
      var_gnorm: 28.169391632080078
      vf_explained_var: -0.004029631614685059
      vf_loss: 48.63823699951172
    num_steps_sampled: 240000
    num_steps_trained: 240000
    wait_time_ms: 88.179
  iterations_since_restore: 80
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 686.8853890895844
  time_this_iter_s: 9.369335889816284
  time_total_s: 686.8853890895844
  timestamp: 1594095445
  timesteps_since_restore: 240000
  timesteps_this_iter: 3000
  timesteps_total: 240000
  training_iteration: 80
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 686 s, 80 iter, 240000 ts, 946 rew

agent-1: 347.0
agent-2: 322.0
agent-3: 292.0
Sum Reward: 961.0
Avg Reward: 320.3333333333333
Min Reward: 292.0
Max Reward: 347.0
Gini Coefficient: 0.03815469996531391
20:20 Ratio: 1.1883561643835616
Max-min Ratio: 1.1883561643835616
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-17-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1236.0
  episode_reward_mean: 946.425
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 80
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.665
    dispatch_time_ms: 5.647
    learner:
      cur_lr: 0.0013440160546451807
      grad_gnorm: 40.0
      policy_entropy: 9.096052169799805
      policy_loss: 12.22712516784668
      var_gnorm: 28.295625686645508
      vf_explained_var: 0.25435739755630493
      vf_loss: 67.88140869140625
    num_steps_sampled: 243000
    num_steps_trained: 243000
    wait_time_ms: 79.294
  iterations_since_restore: 81
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 695.5500886440277
  time_this_iter_s: 8.66469955444336
  time_total_s: 695.5500886440277
  timestamp: 1594095453
  timesteps_since_restore: 243000
  timesteps_this_iter: 3000
  timesteps_total: 243000
  training_iteration: 81
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 695 s, 81 iter, 243000 ts, 946 rew

agent-1: 351.0
agent-2: 354.0
agent-3: 334.0
Sum Reward: 1039.0
Avg Reward: 346.3333333333333
Min Reward: 334.0
Max Reward: 354.0
Gini Coefficient: 0.012832852101379532
20:20 Ratio: 1.0598802395209581
Max-min Ratio: 1.0598802395209581
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-17-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1236.0
  episode_reward_mean: 947.5679012345679
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 81
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.903
    dispatch_time_ms: 6.451
    learner:
      cur_lr: 0.0013438161695376039
      grad_gnorm: 40.000003814697266
      policy_entropy: 13.361115455627441
      policy_loss: 6.649679660797119
      var_gnorm: 28.439300537109375
      vf_explained_var: 0.18691742420196533
      vf_loss: 16.717924118041992
    num_steps_sampled: 246000
    num_steps_trained: 246000
    wait_time_ms: 87.244
  iterations_since_restore: 82
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 704.4854638576508
  time_this_iter_s: 8.935375213623047
  time_total_s: 704.4854638576508
  timestamp: 1594095462
  timesteps_since_restore: 246000
  timesteps_this_iter: 3000
  timesteps_total: 246000
  training_iteration: 82
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 704 s, 82 iter, 246000 ts, 948 rew

agent-1: 393.0
agent-2: 387.0
agent-3: 333.0
Sum Reward: 1113.0
Avg Reward: 371.0
Min Reward: 333.0
Max Reward: 393.0
Gini Coefficient: 0.03593890386343217
20:20 Ratio: 1.1801801801801801
Max-min Ratio: 1.1801801801801801
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-17-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1236.0
  episode_reward_mean: 949.5853658536586
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 82
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.468
    dispatch_time_ms: 5.913
    learner:
      cur_lr: 0.0013436164008453488
      grad_gnorm: 40.0
      policy_entropy: 11.68575668334961
      policy_loss: -15.750799179077148
      var_gnorm: 28.588748931884766
      vf_explained_var: -0.45983731746673584
      vf_loss: 49.62931823730469
    num_steps_sampled: 249000
    num_steps_trained: 249000
    wait_time_ms: 88.485
  iterations_since_restore: 83
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 714.015566110611
  time_this_iter_s: 9.530102252960205
  time_total_s: 714.015566110611
  timestamp: 1594095472
  timesteps_since_restore: 249000
  timesteps_this_iter: 3000
  timesteps_total: 249000
  training_iteration: 83
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 714 s, 83 iter, 249000 ts, 950 rew

agent-1: 383.0
agent-2: 414.0
agent-3: 404.0
Sum Reward: 1201.0
Avg Reward: 400.3333333333333
Min Reward: 383.0
Max Reward: 414.0
Gini Coefficient: 0.017207882320288647
20:20 Ratio: 1.080939947780679
Max-min Ratio: 1.080939947780679
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-18-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1236.0
  episode_reward_mean: 952.6144578313254
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 83
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.141
    dispatch_time_ms: 6.079
    learner:
      cur_lr: 0.0013434166321530938
      grad_gnorm: 40.0
      policy_entropy: 16.981487274169922
      policy_loss: -18.419219970703125
      var_gnorm: 28.728849411010742
      vf_explained_var: -1.0
      vf_loss: 53.12008285522461
    num_steps_sampled: 252000
    num_steps_trained: 252000
    wait_time_ms: 91.918
  iterations_since_restore: 84
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 723.6104116439819
  time_this_iter_s: 9.594845533370972
  time_total_s: 723.6104116439819
  timestamp: 1594095482
  timesteps_since_restore: 252000
  timesteps_this_iter: 3000
  timesteps_total: 252000
  training_iteration: 84
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 723 s, 84 iter, 252000 ts, 953 rew

agent-1: 436.0
agent-2: 367.0
agent-3: 430.0
Sum Reward: 1233.0
Avg Reward: 411.0
Min Reward: 367.0
Max Reward: 436.0
Gini Coefficient: 0.0373073803730738
20:20 Ratio: 1.1880108991825613
Max-min Ratio: 1.1880108991825613
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-18-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1236.0
  episode_reward_mean: 955.952380952381
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 84
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.361
    dispatch_time_ms: 6.016
    learner:
      cur_lr: 0.001343216747045517
      grad_gnorm: 31.143587112426758
      policy_entropy: 17.796239852905273
      policy_loss: 0.5375183820724487
      var_gnorm: 28.838430404663086
      vf_explained_var: 0.48917335271835327
      vf_loss: 13.06761646270752
    num_steps_sampled: 255000
    num_steps_trained: 255000
    wait_time_ms: 83.309
  iterations_since_restore: 85
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 732.6967732906342
  time_this_iter_s: 9.086361646652222
  time_total_s: 732.6967732906342
  timestamp: 1594095491
  timesteps_since_restore: 255000
  timesteps_this_iter: 3000
  timesteps_total: 255000
  training_iteration: 85
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 732 s, 85 iter, 255000 ts, 956 rew

agent-1: 368.0
agent-2: 404.0
agent-3: 379.0
Sum Reward: 1151.0
Avg Reward: 383.6666666666667
Min Reward: 368.0
Max Reward: 404.0
Gini Coefficient: 0.020851433536055605
20:20 Ratio: 1.0978260869565217
Max-min Ratio: 1.0978260869565217
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-18-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1236.0
  episode_reward_mean: 958.2470588235294
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 85
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.574
    dispatch_time_ms: 7.074
    learner:
      cur_lr: 0.001343016978353262
      grad_gnorm: 40.0
      policy_entropy: 21.01618766784668
      policy_loss: 1.6769529581069946
      var_gnorm: 28.922311782836914
      vf_explained_var: 0.2780314087867737
      vf_loss: 13.389537811279297
    num_steps_sampled: 258000
    num_steps_trained: 258000
    wait_time_ms: 73.131
  iterations_since_restore: 86
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 741.7450788021088
  time_this_iter_s: 9.04830551147461
  time_total_s: 741.7450788021088
  timestamp: 1594095500
  timesteps_since_restore: 258000
  timesteps_this_iter: 3000
  timesteps_total: 258000
  training_iteration: 86
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 741 s, 86 iter, 258000 ts, 958 rew

agent-1: 379.0
agent-2: 364.0
agent-3: 390.0
Sum Reward: 1133.0
Avg Reward: 377.6666666666667
Min Reward: 364.0
Max Reward: 390.0
Gini Coefficient: 0.015298617240364814
20:20 Ratio: 1.0714285714285714
Max-min Ratio: 1.0714285714285714
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-18-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1236.0
  episode_reward_mean: 960.2790697674419
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 86
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.362
    dispatch_time_ms: 7.171
    learner:
      cur_lr: 0.001342817209661007
      grad_gnorm: 40.0
      policy_entropy: 27.146085739135742
      policy_loss: -21.42418670654297
      var_gnorm: 28.867015838623047
      vf_explained_var: -0.01818370819091797
      vf_loss: 26.708797454833984
    num_steps_sampled: 261000
    num_steps_trained: 261000
    wait_time_ms: 74.585
  iterations_since_restore: 87
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 750.3322501182556
  time_this_iter_s: 8.58717131614685
  time_total_s: 750.3322501182556
  timestamp: 1594095508
  timesteps_since_restore: 261000
  timesteps_this_iter: 3000
  timesteps_total: 261000
  training_iteration: 87
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 750 s, 87 iter, 261000 ts, 960 rew

agent-1: 318.0
agent-2: 298.0
agent-3: 320.0
Sum Reward: 936.0
Avg Reward: 312.0
Min Reward: 298.0
Max Reward: 320.0
Gini Coefficient: 0.01566951566951567
20:20 Ratio: 1.0738255033557047
Max-min Ratio: 1.0738255033557047
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-18-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1236.0
  episode_reward_mean: 960.0
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 87
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.449
    dispatch_time_ms: 7.738
    learner:
      cur_lr: 0.001342617440968752
      grad_gnorm: 40.0
      policy_entropy: 24.86847496032715
      policy_loss: -14.038429260253906
      var_gnorm: 28.83524513244629
      vf_explained_var: 0.06835001707077026
      vf_loss: 68.58197784423828
    num_steps_sampled: 264000
    num_steps_trained: 264000
    wait_time_ms: 69.365
  iterations_since_restore: 88
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 758.5164535045624
  time_this_iter_s: 8.184203386306763
  time_total_s: 758.5164535045624
  timestamp: 1594095517
  timesteps_since_restore: 264000
  timesteps_this_iter: 3000
  timesteps_total: 264000
  training_iteration: 88
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 758 s, 88 iter, 264000 ts, 960 rew

agent-1: 319.0
agent-2: 278.0
agent-3: 302.0
Sum Reward: 899.0
Avg Reward: 299.6666666666667
Min Reward: 278.0
Max Reward: 319.0
Gini Coefficient: 0.030404152762328513
20:20 Ratio: 1.1474820143884892
Max-min Ratio: 1.1474820143884892
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-18-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1236.0
  episode_reward_mean: 959.3068181818181
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 88
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.374
    dispatch_time_ms: 6.418
    learner:
      cur_lr: 0.001342417555861175
      grad_gnorm: 38.671199798583984
      policy_entropy: 22.78182601928711
      policy_loss: -13.846405029296875
      var_gnorm: 28.856403350830078
      vf_explained_var: 0.526697039604187
      vf_loss: 27.226375579833984
    num_steps_sampled: 267000
    num_steps_trained: 267000
    wait_time_ms: 78.782
  iterations_since_restore: 89
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 766.7142038345337
  time_this_iter_s: 8.197750329971313
  time_total_s: 766.7142038345337
  timestamp: 1594095525
  timesteps_since_restore: 267000
  timesteps_this_iter: 3000
  timesteps_total: 267000
  training_iteration: 89
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 766 s, 89 iter, 267000 ts, 959 rew

agent-1: 330.0
agent-2: 339.0
agent-3: 334.0
Sum Reward: 1003.0
Avg Reward: 334.3333333333333
Min Reward: 330.0
Max Reward: 339.0
Gini Coefficient: 0.005982053838484547
20:20 Ratio: 1.0272727272727273
Max-min Ratio: 1.0272727272727273
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-18-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1236.0
  episode_reward_mean: 959.7977528089888
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 89
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.762
    dispatch_time_ms: 7.625
    learner:
      cur_lr: 0.00134221778716892
      grad_gnorm: 33.4315185546875
      policy_entropy: 25.489503860473633
      policy_loss: 1.003114938735962
      var_gnorm: 28.944425582885742
      vf_explained_var: 0.37516796588897705
      vf_loss: 27.33660125732422
    num_steps_sampled: 270000
    num_steps_trained: 270000
    wait_time_ms: 72.636
  iterations_since_restore: 90
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 775.1369960308075
  time_this_iter_s: 8.422792196273804
  time_total_s: 775.1369960308075
  timestamp: 1594095533
  timesteps_since_restore: 270000
  timesteps_this_iter: 3000
  timesteps_total: 270000
  training_iteration: 90
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 775 s, 90 iter, 270000 ts, 960 rew

agent-1: 315.0
agent-2: 336.0
agent-3: 331.0
Sum Reward: 982.0
Avg Reward: 327.3333333333333
Min Reward: 315.0
Max Reward: 336.0
Gini Coefficient: 0.014256619144602852
20:20 Ratio: 1.0666666666666667
Max-min Ratio: 1.0666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-19-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1236.0
  episode_reward_mean: 960.0444444444445
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 90
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.729
    dispatch_time_ms: 10.253
    learner:
      cur_lr: 0.001342018018476665
      grad_gnorm: 38.05268859863281
      policy_entropy: 25.313385009765625
      policy_loss: -10.203330993652344
      var_gnorm: 28.946165084838867
      vf_explained_var: -0.233634352684021
      vf_loss: 27.30235481262207
    num_steps_sampled: 273000
    num_steps_trained: 273000
    wait_time_ms: 70.177
  iterations_since_restore: 91
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 783.4559056758881
  time_this_iter_s: 8.318909645080566
  time_total_s: 783.4559056758881
  timestamp: 1594095542
  timesteps_since_restore: 273000
  timesteps_this_iter: 3000
  timesteps_total: 273000
  training_iteration: 91
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 783 s, 91 iter, 273000 ts, 960 rew

agent-1: 323.0
agent-2: 332.0
agent-3: 378.0
Sum Reward: 1033.0
Avg Reward: 344.3333333333333
Min Reward: 323.0
Max Reward: 378.0
Gini Coefficient: 0.03549532107131333
20:20 Ratio: 1.1702786377708978
Max-min Ratio: 1.1702786377708978
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-19-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1236.0
  episode_reward_mean: 960.8461538461538
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 91
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.545
    dispatch_time_ms: 9.519
    learner:
      cur_lr: 0.00134181824978441
      grad_gnorm: 40.0
      policy_entropy: 18.30629539489746
      policy_loss: 9.202838897705078
      var_gnorm: 29.02073097229004
      vf_explained_var: -0.10369884967803955
      vf_loss: 31.217660903930664
    num_steps_sampled: 276000
    num_steps_trained: 276000
    wait_time_ms: 77.207
  iterations_since_restore: 92
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 792.4217386245728
  time_this_iter_s: 8.965832948684692
  time_total_s: 792.4217386245728
  timestamp: 1594095551
  timesteps_since_restore: 276000
  timesteps_this_iter: 3000
  timesteps_total: 276000
  training_iteration: 92
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 792 s, 92 iter, 276000 ts, 961 rew

agent-1: 338.0
agent-2: 384.0
agent-3: 392.0
Sum Reward: 1114.0
Avg Reward: 371.3333333333333
Min Reward: 338.0
Max Reward: 392.0
Gini Coefficient: 0.03231597845601436
20:20 Ratio: 1.1597633136094674
Max-min Ratio: 1.1597633136094674
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-19-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1236.0
  episode_reward_mean: 962.5108695652174
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 92
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.412
    dispatch_time_ms: 9.592
    learner:
      cur_lr: 0.0013416183646768332
      grad_gnorm: 40.0
      policy_entropy: 20.04541015625
      policy_loss: -0.5930653214454651
      var_gnorm: 29.1436767578125
      vf_explained_var: -0.26128315925598145
      vf_loss: 9.45874309539795
    num_steps_sampled: 279000
    num_steps_trained: 279000
    wait_time_ms: 79.512
  iterations_since_restore: 93
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 801.3797068595886
  time_this_iter_s: 8.95796823501587
  time_total_s: 801.3797068595886
  timestamp: 1594095560
  timesteps_since_restore: 279000
  timesteps_this_iter: 3000
  timesteps_total: 279000
  training_iteration: 93
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 801 s, 93 iter, 279000 ts, 963 rew

agent-1: 419.0
agent-2: 412.0
agent-3: 411.0
Sum Reward: 1242.0
Avg Reward: 414.0
Min Reward: 411.0
Max Reward: 419.0
Gini Coefficient: 0.0042941492216854536
20:20 Ratio: 1.0194647201946472
Max-min Ratio: 1.0194647201946472
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-19-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1242.0
  episode_reward_mean: 965.516129032258
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 93
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.044
    dispatch_time_ms: 8.133
    learner:
      cur_lr: 0.0013414185959845781
      grad_gnorm: 39.99999237060547
      policy_entropy: 18.142227172851562
      policy_loss: 16.82619285583496
      var_gnorm: 29.220109939575195
      vf_explained_var: -1.0
      vf_loss: 60.03330612182617
    num_steps_sampled: 282000
    num_steps_trained: 282000
    wait_time_ms: 75.885
  iterations_since_restore: 94
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 810.058849811554
  time_this_iter_s: 8.679142951965332
  time_total_s: 810.058849811554
  timestamp: 1594095568
  timesteps_since_restore: 282000
  timesteps_this_iter: 3000
  timesteps_total: 282000
  training_iteration: 94
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 810 s, 94 iter, 282000 ts, 966 rew

agent-1: 390.0
agent-2: 393.0
agent-3: 380.0
Sum Reward: 1163.0
Avg Reward: 387.6666666666667
Min Reward: 380.0
Max Reward: 393.0
Gini Coefficient: 0.007451991974777874
20:20 Ratio: 1.0342105263157895
Max-min Ratio: 1.0342105263157895
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-19-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1242.0
  episode_reward_mean: 967.6170212765958
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 94
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.425
    dispatch_time_ms: 5.661
    learner:
      cur_lr: 0.0013412188272923231
      grad_gnorm: 40.0
      policy_entropy: 18.27277374267578
      policy_loss: -12.210051536560059
      var_gnorm: 29.299135208129883
      vf_explained_var: 0.10153806209564209
      vf_loss: 10.013395309448242
    num_steps_sampled: 285000
    num_steps_trained: 285000
    wait_time_ms: 78.391
  iterations_since_restore: 95
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 818.7715854644775
  time_this_iter_s: 8.712735652923584
  time_total_s: 818.7715854644775
  timestamp: 1594095577
  timesteps_since_restore: 285000
  timesteps_this_iter: 3000
  timesteps_total: 285000
  training_iteration: 95
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 818 s, 95 iter, 285000 ts, 968 rew

agent-1: 405.0
agent-2: 379.0
agent-3: 414.0
Sum Reward: 1198.0
Avg Reward: 399.3333333333333
Min Reward: 379.0
Max Reward: 414.0
Gini Coefficient: 0.019476905954368393
20:20 Ratio: 1.0923482849604222
Max-min Ratio: 1.0923482849604222
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-19-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1242.0
  episode_reward_mean: 970.0421052631579
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 95
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.1
    dispatch_time_ms: 9.88
    learner:
      cur_lr: 0.0013410189421847463
      grad_gnorm: 36.552154541015625
      policy_entropy: 17.57648277282715
      policy_loss: -9.562787055969238
      var_gnorm: 29.44365119934082
      vf_explained_var: 0.04140448570251465
      vf_loss: 13.579803466796875
    num_steps_sampled: 288000
    num_steps_trained: 288000
    wait_time_ms: 77.88
  iterations_since_restore: 96
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 828.1277494430542
  time_this_iter_s: 9.35616397857666
  time_total_s: 828.1277494430542
  timestamp: 1594095587
  timesteps_since_restore: 288000
  timesteps_this_iter: 3000
  timesteps_total: 288000
  training_iteration: 96
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 828 s, 96 iter, 288000 ts, 970 rew

agent-1: 390.0
agent-2: 433.0
agent-3: 450.0
Sum Reward: 1273.0
Avg Reward: 424.3333333333333
Min Reward: 390.0
Max Reward: 450.0
Gini Coefficient: 0.031421838177533384
20:20 Ratio: 1.1538461538461537
Max-min Ratio: 1.1538461538461537
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-19-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1273.0
  episode_reward_mean: 973.1979166666666
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 96
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.775
    dispatch_time_ms: 7.307
    learner:
      cur_lr: 0.0013408191734924912
      grad_gnorm: 40.000003814697266
      policy_entropy: 21.1574764251709
      policy_loss: 22.083147048950195
      var_gnorm: 29.464078903198242
      vf_explained_var: 0.09822964668273926
      vf_loss: 38.90274429321289
    num_steps_sampled: 291000
    num_steps_trained: 291000
    wait_time_ms: 79.701
  iterations_since_restore: 97
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 837.2538344860077
  time_this_iter_s: 9.126085042953491
  time_total_s: 837.2538344860077
  timestamp: 1594095596
  timesteps_since_restore: 291000
  timesteps_this_iter: 3000
  timesteps_total: 291000
  training_iteration: 97
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 837 s, 97 iter, 291000 ts, 973 rew

agent-1: 387.0
agent-2: 414.0
agent-3: 366.0
Sum Reward: 1167.0
Avg Reward: 389.0
Min Reward: 366.0
Max Reward: 414.0
Gini Coefficient: 0.027420736932305057
20:20 Ratio: 1.1311475409836065
Max-min Ratio: 1.1311475409836065
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-20-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1273.0
  episode_reward_mean: 975.1958762886597
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 97
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.086
    dispatch_time_ms: 6.48
    learner:
      cur_lr: 0.0013406194048002362
      grad_gnorm: 28.832420349121094
      policy_entropy: 17.582469940185547
      policy_loss: 5.089815616607666
      var_gnorm: 29.49846839904785
      vf_explained_var: -0.7569859027862549
      vf_loss: 20.776941299438477
    num_steps_sampled: 294000
    num_steps_trained: 294000
    wait_time_ms: 94.516
  iterations_since_restore: 98
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 846.4904556274414
  time_this_iter_s: 9.236621141433716
  time_total_s: 846.4904556274414
  timestamp: 1594095605
  timesteps_since_restore: 294000
  timesteps_this_iter: 3000
  timesteps_total: 294000
  training_iteration: 98
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 846 s, 98 iter, 294000 ts, 975 rew

agent-1: 333.0
agent-2: 371.0
agent-3: 387.0
Sum Reward: 1091.0
Avg Reward: 363.6666666666667
Min Reward: 333.0
Max Reward: 387.0
Gini Coefficient: 0.03299725022914757
20:20 Ratio: 1.162162162162162
Max-min Ratio: 1.162162162162162
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-20-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1273.0
  episode_reward_mean: 976.3775510204082
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 98
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.503
    dispatch_time_ms: 7.433
    learner:
      cur_lr: 0.0013404196361079812
      grad_gnorm: 39.478538513183594
      policy_entropy: 9.732711791992188
      policy_loss: 2.049433469772339
      var_gnorm: 29.587005615234375
      vf_explained_var: -0.30602025985717773
      vf_loss: 12.384361267089844
    num_steps_sampled: 297000
    num_steps_trained: 297000
    wait_time_ms: 86.195
  iterations_since_restore: 99
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 855.8681988716125
  time_this_iter_s: 9.377743244171143
  time_total_s: 855.8681988716125
  timestamp: 1594095614
  timesteps_since_restore: 297000
  timesteps_this_iter: 3000
  timesteps_total: 297000
  training_iteration: 99
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 855 s, 99 iter, 297000 ts, 976 rew

agent-1: 435.0
agent-2: 448.0
agent-3: 437.0
Sum Reward: 1320.0
Avg Reward: 440.0
Min Reward: 435.0
Max Reward: 448.0
Gini Coefficient: 0.0065656565656565654
20:20 Ratio: 1.0298850574712644
Max-min Ratio: 1.0298850574712644
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-20-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1320.0
  episode_reward_mean: 979.8484848484849
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 99
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.604
    dispatch_time_ms: 7.023
    learner:
      cur_lr: 0.0013402197510004044
      grad_gnorm: 25.159473419189453
      policy_entropy: 13.575950622558594
      policy_loss: -16.981191635131836
      var_gnorm: 29.626190185546875
      vf_explained_var: 0.044155001640319824
      vf_loss: 42.68928146362305
    num_steps_sampled: 300000
    num_steps_trained: 300000
    wait_time_ms: 75.289
  iterations_since_restore: 100
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 865.1503744125366
  time_this_iter_s: 9.282175540924072
  time_total_s: 865.1503744125366
  timestamp: 1594095624
  timesteps_since_restore: 300000
  timesteps_this_iter: 3000
  timesteps_total: 300000
  training_iteration: 100
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 865 s, 100 iter, 300000 ts, 980 rew

agent-1: 426.0
agent-2: 425.0
agent-3: 412.0
Sum Reward: 1263.0
Avg Reward: 421.0
Min Reward: 412.0
Max Reward: 426.0
Gini Coefficient: 0.007389812615465822
20:20 Ratio: 1.0339805825242718
Max-min Ratio: 1.0339805825242718
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-20-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1320.0
  episode_reward_mean: 982.68
  episode_reward_min: 235.0
  episodes_this_iter: 1
  episodes_total: 100
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.373
    dispatch_time_ms: 6.858
    learner:
      cur_lr: 0.0013400199823081493
      grad_gnorm: 39.99999237060547
      policy_entropy: 19.877885818481445
      policy_loss: -11.815878868103027
      var_gnorm: 29.70410919189453
      vf_explained_var: 0.31918442249298096
      vf_loss: 19.262493133544922
    num_steps_sampled: 303000
    num_steps_trained: 303000
    wait_time_ms: 91.794
  iterations_since_restore: 101
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 874.6317627429962
  time_this_iter_s: 9.481388330459595
  time_total_s: 874.6317627429962
  timestamp: 1594095633
  timesteps_since_restore: 303000
  timesteps_this_iter: 3000
  timesteps_total: 303000
  training_iteration: 101
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 874 s, 101 iter, 303000 ts, 983 rew

agent-1: 388.0
agent-2: 406.0
agent-3: 359.0
Sum Reward: 1153.0
Avg Reward: 384.3333333333333
Min Reward: 359.0
Max Reward: 406.0
Gini Coefficient: 0.027175484244001156
20:20 Ratio: 1.1309192200557103
Max-min Ratio: 1.1309192200557103
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-20-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1320.0
  episode_reward_mean: 991.86
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 101
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.555
    dispatch_time_ms: 6.357
    learner:
      cur_lr: 0.0013398202136158943
      grad_gnorm: 40.0
      policy_entropy: 18.09465980529785
      policy_loss: -10.77677059173584
      var_gnorm: 29.783233642578125
      vf_explained_var: 0.03763169050216675
      vf_loss: 14.396707534790039
    num_steps_sampled: 306000
    num_steps_trained: 306000
    wait_time_ms: 74.311
  iterations_since_restore: 102
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 883.5430133342743
  time_this_iter_s: 8.911250591278076
  time_total_s: 883.5430133342743
  timestamp: 1594095642
  timesteps_since_restore: 306000
  timesteps_this_iter: 3000
  timesteps_total: 306000
  training_iteration: 102
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 883 s, 102 iter, 306000 ts, 992 rew

agent-1: 357.0
agent-2: 389.0
agent-3: 357.0
Sum Reward: 1103.0
Avg Reward: 367.6666666666667
Min Reward: 357.0
Max Reward: 389.0
Gini Coefficient: 0.01934119069205198
20:20 Ratio: 1.0896358543417366
Max-min Ratio: 1.0896358543417366
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-20-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1320.0
  episode_reward_mean: 1000.48
  episode_reward_min: 286.0
  episodes_this_iter: 1
  episodes_total: 102
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.46
    dispatch_time_ms: 6.645
    learner:
      cur_lr: 0.0013396204449236393
      grad_gnorm: 40.0
      policy_entropy: 19.67203140258789
      policy_loss: -11.224969863891602
      var_gnorm: 29.857009887695312
      vf_explained_var: 0.057325899600982666
      vf_loss: 22.992029190063477
    num_steps_sampled: 309000
    num_steps_trained: 309000
    wait_time_ms: 80.061
  iterations_since_restore: 103
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 892.3913125991821
  time_this_iter_s: 8.848299264907837
  time_total_s: 892.3913125991821
  timestamp: 1594095651
  timesteps_since_restore: 309000
  timesteps_this_iter: 3000
  timesteps_total: 309000
  training_iteration: 103
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 892 s, 103 iter, 309000 ts, 1e+03 rew

agent-1: 410.0
agent-2: 358.0
agent-3: 338.0
Sum Reward: 1106.0
Avg Reward: 368.6666666666667
Min Reward: 338.0
Max Reward: 410.0
Gini Coefficient: 0.0433996383363472
20:20 Ratio: 1.21301775147929
Max-min Ratio: 1.21301775147929
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-21-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1320.0
  episode_reward_mean: 1007.36
  episode_reward_min: 286.0
  episodes_this_iter: 1
  episodes_total: 103
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.968
    dispatch_time_ms: 8.199
    learner:
      cur_lr: 0.0013394205598160625
      grad_gnorm: 39.999977111816406
      policy_entropy: 17.503318786621094
      policy_loss: 0.8790603876113892
      var_gnorm: 29.938167572021484
      vf_explained_var: 0.44948869943618774
      vf_loss: 14.83841323852539
    num_steps_sampled: 312000
    num_steps_trained: 312000
    wait_time_ms: 77.641
  iterations_since_restore: 104
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 901.5894615650177
  time_this_iter_s: 9.198148965835571
  time_total_s: 901.5894615650177
  timestamp: 1594095660
  timesteps_since_restore: 312000
  timesteps_this_iter: 3000
  timesteps_total: 312000
  training_iteration: 104
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 901 s, 104 iter, 312000 ts, 1.01e+03 rew

agent-1: 370.0
agent-2: 431.0
agent-3: 348.0
Sum Reward: 1149.0
Avg Reward: 383.0
Min Reward: 348.0
Max Reward: 431.0
Gini Coefficient: 0.048157818392805335
20:20 Ratio: 1.2385057471264367
Max-min Ratio: 1.2385057471264367
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-21-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1320.0
  episode_reward_mean: 1015.99
  episode_reward_min: 444.0
  episodes_this_iter: 1
  episodes_total: 104
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.754
    dispatch_time_ms: 7.315
    learner:
      cur_lr: 0.0013392207911238074
      grad_gnorm: 40.0
      policy_entropy: 16.6656551361084
      policy_loss: 21.595062255859375
      var_gnorm: 30.057973861694336
      vf_explained_var: -0.28198301792144775
      vf_loss: 53.454444885253906
    num_steps_sampled: 315000
    num_steps_trained: 315000
    wait_time_ms: 85.365
  iterations_since_restore: 105
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 910.9473679065704
  time_this_iter_s: 9.357906341552734
  time_total_s: 910.9473679065704
  timestamp: 1594095670
  timesteps_since_restore: 315000
  timesteps_this_iter: 3000
  timesteps_total: 315000
  training_iteration: 105
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 910 s, 105 iter, 315000 ts, 1.02e+03 rew

agent-1: 395.0
agent-2: 399.0
agent-3: 354.0
Sum Reward: 1148.0
Avg Reward: 382.6666666666667
Min Reward: 354.0
Max Reward: 399.0
Gini Coefficient: 0.02613240418118467
20:20 Ratio: 1.1271186440677967
Max-min Ratio: 1.1271186440677967
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-21-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1320.0
  episode_reward_mean: 1023.03
  episode_reward_min: 610.0
  episodes_this_iter: 1
  episodes_total: 105
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.377
    dispatch_time_ms: 6.573
    learner:
      cur_lr: 0.0013390210224315524
      grad_gnorm: 40.0
      policy_entropy: 15.143465995788574
      policy_loss: -14.814777374267578
      var_gnorm: 30.217355728149414
      vf_explained_var: -0.852246880531311
      vf_loss: 31.606788635253906
    num_steps_sampled: 318000
    num_steps_trained: 318000
    wait_time_ms: 79.536
  iterations_since_restore: 106
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 920.5467269420624
  time_this_iter_s: 9.599359035491943
  time_total_s: 920.5467269420624
  timestamp: 1594095679
  timesteps_since_restore: 318000
  timesteps_this_iter: 3000
  timesteps_total: 318000
  training_iteration: 106
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 920 s, 106 iter, 318000 ts, 1.02e+03 rew

agent-1: 434.0
agent-2: 424.0
agent-3: 395.0
Sum Reward: 1253.0
Avg Reward: 417.6666666666667
Min Reward: 395.0
Max Reward: 434.0
Gini Coefficient: 0.020750199521149242
20:20 Ratio: 1.09873417721519
Max-min Ratio: 1.09873417721519
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-21-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1320.0
  episode_reward_mean: 1028.79
  episode_reward_min: 610.0
  episodes_this_iter: 1
  episodes_total: 106
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.516
    dispatch_time_ms: 7.437
    learner:
      cur_lr: 0.0013388212537392974
      grad_gnorm: 40.0
      policy_entropy: 14.808783531188965
      policy_loss: -1.4851388931274414
      var_gnorm: 30.288707733154297
      vf_explained_var: 0.1931251883506775
      vf_loss: 76.63646697998047
    num_steps_sampled: 321000
    num_steps_trained: 321000
    wait_time_ms: 75.204
  iterations_since_restore: 107
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 929.6254804134369
  time_this_iter_s: 9.078753471374512
  time_total_s: 929.6254804134369
  timestamp: 1594095688
  timesteps_since_restore: 321000
  timesteps_this_iter: 3000
  timesteps_total: 321000
  training_iteration: 107
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 929 s, 107 iter, 321000 ts, 1.03e+03 rew

agent-1: 372.0
agent-2: 339.0
agent-3: 337.0
Sum Reward: 1048.0
Avg Reward: 349.3333333333333
Min Reward: 337.0
Max Reward: 372.0
Gini Coefficient: 0.022264631043257
20:20 Ratio: 1.1038575667655786
Max-min Ratio: 1.1038575667655786
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-21-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1320.0
  episode_reward_mean: 1032.09
  episode_reward_min: 610.0
  episodes_this_iter: 1
  episodes_total: 107
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.466
    dispatch_time_ms: 5.997
    learner:
      cur_lr: 0.0013386213686317205
      grad_gnorm: 29.246976852416992
      policy_entropy: 14.929710388183594
      policy_loss: 6.332324981689453
      var_gnorm: 30.37791633605957
      vf_explained_var: 0.43861281871795654
      vf_loss: 31.540821075439453
    num_steps_sampled: 324000
    num_steps_trained: 324000
    wait_time_ms: 77.778
  iterations_since_restore: 108
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 938.7199079990387
  time_this_iter_s: 9.094427585601807
  time_total_s: 938.7199079990387
  timestamp: 1594095698
  timesteps_since_restore: 324000
  timesteps_this_iter: 3000
  timesteps_total: 324000
  training_iteration: 108
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 938 s, 108 iter, 324000 ts, 1.03e+03 rew

agent-1: 293.0
agent-2: 365.0
agent-3: 316.0
Sum Reward: 974.0
Avg Reward: 324.6666666666667
Min Reward: 293.0
Max Reward: 365.0
Gini Coefficient: 0.049281314168377825
20:20 Ratio: 1.2457337883959045
Max-min Ratio: 1.2457337883959045
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-21-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1320.0
  episode_reward_mean: 1034.66
  episode_reward_min: 610.0
  episodes_this_iter: 1
  episodes_total: 108
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.475
    dispatch_time_ms: 6.153
    learner:
      cur_lr: 0.0013384215999394655
      grad_gnorm: 40.0
      policy_entropy: 12.619745254516602
      policy_loss: -19.27029037475586
      var_gnorm: 30.428468704223633
      vf_explained_var: 0.3894492983818054
      vf_loss: 28.91791343688965
    num_steps_sampled: 327000
    num_steps_trained: 327000
    wait_time_ms: 79.476
  iterations_since_restore: 109
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 947.4304730892181
  time_this_iter_s: 8.710565090179443
  time_total_s: 947.4304730892181
  timestamp: 1594095706
  timesteps_since_restore: 327000
  timesteps_this_iter: 3000
  timesteps_total: 327000
  training_iteration: 109
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 947 s, 109 iter, 327000 ts, 1.03e+03 rew

agent-1: 300.0
agent-2: 396.0
agent-3: 357.0
Sum Reward: 1053.0
Avg Reward: 351.0
Min Reward: 300.0
Max Reward: 396.0
Gini Coefficient: 0.060778727445394115
20:20 Ratio: 1.32
Max-min Ratio: 1.32
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-21-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1320.0
  episode_reward_mean: 1036.57
  episode_reward_min: 610.0
  episodes_this_iter: 1
  episodes_total: 109
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.619
    dispatch_time_ms: 6.975
    learner:
      cur_lr: 0.0013382218312472105
      grad_gnorm: 40.0
      policy_entropy: 12.165754318237305
      policy_loss: 7.314922332763672
      var_gnorm: 30.488142013549805
      vf_explained_var: 0.1461816430091858
      vf_loss: 19.134923934936523
    num_steps_sampled: 330000
    num_steps_trained: 330000
    wait_time_ms: 76.993
  iterations_since_restore: 110
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 956.126359462738
  time_this_iter_s: 8.695886373519897
  time_total_s: 956.126359462738
  timestamp: 1594095715
  timesteps_since_restore: 330000
  timesteps_this_iter: 3000
  timesteps_total: 330000
  training_iteration: 110
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 956 s, 110 iter, 330000 ts, 1.04e+03 rew

agent-1: 299.0
agent-2: 364.0
agent-3: 318.0
Sum Reward: 981.0
Avg Reward: 327.0
Min Reward: 299.0
Max Reward: 364.0
Gini Coefficient: 0.04417261297995243
20:20 Ratio: 1.2173913043478262
Max-min Ratio: 1.2173913043478262
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-22-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1320.0
  episode_reward_mean: 1038.66
  episode_reward_min: 610.0
  episodes_this_iter: 1
  episodes_total: 110
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.567
    dispatch_time_ms: 9.597
    learner:
      cur_lr: 0.0013380219461396337
      grad_gnorm: 40.00000762939453
      policy_entropy: 17.453269958496094
      policy_loss: -6.648150444030762
      var_gnorm: 30.57862663269043
      vf_explained_var: -0.31958842277526855
      vf_loss: 16.579120635986328
    num_steps_sampled: 333000
    num_steps_trained: 333000
    wait_time_ms: 75.232
  iterations_since_restore: 111
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 964.7405965328217
  time_this_iter_s: 8.614237070083618
  time_total_s: 964.7405965328217
  timestamp: 1594095724
  timesteps_since_restore: 333000
  timesteps_this_iter: 3000
  timesteps_total: 333000
  training_iteration: 111
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 964 s, 111 iter, 333000 ts, 1.04e+03 rew

agent-1: 320.0
agent-2: 356.0
agent-3: 299.0
Sum Reward: 975.0
Avg Reward: 325.0
Min Reward: 299.0
Max Reward: 356.0
Gini Coefficient: 0.038974358974358976
20:20 Ratio: 1.1906354515050168
Max-min Ratio: 1.1906354515050168
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-22-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1320.0
  episode_reward_mean: 1039.61
  episode_reward_min: 610.0
  episodes_this_iter: 1
  episodes_total: 111
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.383
    dispatch_time_ms: 12.074
    learner:
      cur_lr: 0.0013378221774473786
      grad_gnorm: 17.816518783569336
      policy_entropy: 13.646164894104004
      policy_loss: -0.8146437406539917
      var_gnorm: 30.667057037353516
      vf_explained_var: -0.2593228816986084
      vf_loss: 24.30813217163086
    num_steps_sampled: 336000
    num_steps_trained: 336000
    wait_time_ms: 67.933
  iterations_since_restore: 112
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 975.1939198970795
  time_this_iter_s: 10.453323364257812
  time_total_s: 975.1939198970795
  timestamp: 1594095734
  timesteps_since_restore: 336000
  timesteps_this_iter: 3000
  timesteps_total: 336000
  training_iteration: 112
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 975 s, 112 iter, 336000 ts, 1.04e+03 rew

agent-1: 296.0
agent-2: 343.0
agent-3: 288.0
Sum Reward: 927.0
Avg Reward: 309.0
Min Reward: 288.0
Max Reward: 343.0
Gini Coefficient: 0.039554117224020136
20:20 Ratio: 1.1909722222222223
Max-min Ratio: 1.1909722222222223
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-22-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1320.0
  episode_reward_mean: 1040.92
  episode_reward_min: 610.0
  episodes_this_iter: 1
  episodes_total: 112
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.815
    dispatch_time_ms: 9.76
    learner:
      cur_lr: 0.0013376224087551236
      grad_gnorm: 40.00000762939453
      policy_entropy: 12.262802124023438
      policy_loss: -3.580009698867798
      var_gnorm: 30.724924087524414
      vf_explained_var: 0.2518458962440491
      vf_loss: 29.52145004272461
    num_steps_sampled: 339000
    num_steps_trained: 339000
    wait_time_ms: 70.73
  iterations_since_restore: 113
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 982.7362098693848
  time_this_iter_s: 7.542289972305298
  time_total_s: 982.7362098693848
  timestamp: 1594095743
  timesteps_since_restore: 339000
  timesteps_this_iter: 3000
  timesteps_total: 339000
  training_iteration: 113
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 982 s, 113 iter, 339000 ts, 1.04e+03 rew

agent-1: 178.0
agent-2: 227.0
agent-3: 225.0
Sum Reward: 630.0
Avg Reward: 210.0
Min Reward: 178.0
Max Reward: 227.0
Gini Coefficient: 0.05185185185185185
20:20 Ratio: 1.2752808988764044
Max-min Ratio: 1.2752808988764044
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-22-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1320.0
  episode_reward_mean: 1040.6
  episode_reward_min: 610.0
  episodes_this_iter: 1
  episodes_total: 113
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.774
    dispatch_time_ms: 6.785
    learner:
      cur_lr: 0.0013374226400628686
      grad_gnorm: 40.0
      policy_entropy: 10.950763702392578
      policy_loss: -5.5646071434021
      var_gnorm: 30.714942932128906
      vf_explained_var: 0.10927408933639526
      vf_loss: 19.215633392333984
    num_steps_sampled: 342000
    num_steps_trained: 342000
    wait_time_ms: 66.627
  iterations_since_restore: 114
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 990.5333924293518
  time_this_iter_s: 7.797182559967041
  time_total_s: 990.5333924293518
  timestamp: 1594095751
  timesteps_since_restore: 342000
  timesteps_this_iter: 3000
  timesteps_total: 342000
  training_iteration: 114
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 990 s, 114 iter, 342000 ts, 1.04e+03 rew

agent-1: 180.0
agent-2: 235.0
agent-3: 168.0
Sum Reward: 583.0
Avg Reward: 194.33333333333334
Min Reward: 168.0
Max Reward: 235.0
Gini Coefficient: 0.07661520869068039
20:20 Ratio: 1.3988095238095237
Max-min Ratio: 1.3988095238095237
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-22-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1320.0
  episode_reward_mean: 1039.76
  episode_reward_min: 583.0
  episodes_this_iter: 1
  episodes_total: 114
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.368
    dispatch_time_ms: 6.563
    learner:
      cur_lr: 0.0013372227549552917
      grad_gnorm: 40.0
      policy_entropy: 9.794732093811035
      policy_loss: 4.4471635818481445
      var_gnorm: 30.732046127319336
      vf_explained_var: -0.15276992321014404
      vf_loss: 16.697343826293945
    num_steps_sampled: 345000
    num_steps_trained: 345000
    wait_time_ms: 73.145
  iterations_since_restore: 115
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 998.2000958919525
  time_this_iter_s: 7.666703462600708
  time_total_s: 998.2000958919525
  timestamp: 1594095758
  timesteps_since_restore: 345000
  timesteps_this_iter: 3000
  timesteps_total: 345000
  training_iteration: 115
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 998 s, 115 iter, 345000 ts, 1.04e+03 rew

agent-1: 178.0
agent-2: 155.0
agent-3: 197.0
Sum Reward: 530.0
Avg Reward: 176.66666666666666
Min Reward: 155.0
Max Reward: 197.0
Gini Coefficient: 0.052830188679245285
20:20 Ratio: 1.270967741935484
Max-min Ratio: 1.270967741935484
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-22-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1320.0
  episode_reward_mean: 1038.96
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 115
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.491
    dispatch_time_ms: 6.4
    learner:
      cur_lr: 0.0013370229862630367
      grad_gnorm: 27.51932716369629
      policy_entropy: 13.75793170928955
      policy_loss: -5.021964073181152
      var_gnorm: 30.710697174072266
      vf_explained_var: 0.6681613326072693
      vf_loss: 30.44439697265625
    num_steps_sampled: 348000
    num_steps_trained: 348000
    wait_time_ms: 66.449
  iterations_since_restore: 116
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1005.815194606781
  time_this_iter_s: 7.615098714828491
  time_total_s: 1005.815194606781
  timestamp: 1594095766
  timesteps_since_restore: 348000
  timesteps_this_iter: 3000
  timesteps_total: 348000
  training_iteration: 116
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1005 s, 116 iter, 348000 ts, 1.04e+03 rew

agent-1: 199.0
agent-2: 188.0
agent-3: 230.0
Sum Reward: 617.0
Avg Reward: 205.66666666666666
Min Reward: 188.0
Max Reward: 230.0
Gini Coefficient: 0.04538087520259319
20:20 Ratio: 1.2234042553191489
Max-min Ratio: 1.2234042553191489
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-22-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1320.0
  episode_reward_mean: 1038.94
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 116
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.416
    dispatch_time_ms: 5.732
    learner:
      cur_lr: 0.0013368232175707817
      grad_gnorm: 40.0
      policy_entropy: 13.497732162475586
      policy_loss: 15.684587478637695
      var_gnorm: 30.781618118286133
      vf_explained_var: 0.05921578407287598
      vf_loss: 54.332847595214844
    num_steps_sampled: 351000
    num_steps_trained: 351000
    wait_time_ms: 77.942
  iterations_since_restore: 117
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1014.0048518180847
  time_this_iter_s: 8.189657211303711
  time_total_s: 1014.0048518180847
  timestamp: 1594095774
  timesteps_since_restore: 351000
  timesteps_this_iter: 3000
  timesteps_total: 351000
  training_iteration: 117
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1014 s, 117 iter, 351000 ts, 1.04e+03 rew

agent-1: 318.0
agent-2: 310.0
agent-3: 291.0
Sum Reward: 919.0
Avg Reward: 306.3333333333333
Min Reward: 291.0
Max Reward: 318.0
Gini Coefficient: 0.01958650707290533
20:20 Ratio: 1.092783505154639
Max-min Ratio: 1.092783505154639
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-23-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1320.0
  episode_reward_mean: 1039.65
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 117
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.673
    dispatch_time_ms: 7.505
    learner:
      cur_lr: 0.0013366234488785267
      grad_gnorm: 40.000022888183594
      policy_entropy: 15.47507095336914
      policy_loss: 11.929332733154297
      var_gnorm: 30.922399520874023
      vf_explained_var: 0.037136077880859375
      vf_loss: 28.62868309020996
    num_steps_sampled: 354000
    num_steps_trained: 354000
    wait_time_ms: 77.012
  iterations_since_restore: 118
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1022.9786298274994
  time_this_iter_s: 8.973778009414673
  time_total_s: 1022.9786298274994
  timestamp: 1594095783
  timesteps_since_restore: 354000
  timesteps_this_iter: 3000
  timesteps_total: 354000
  training_iteration: 118
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1022 s, 118 iter, 354000 ts, 1.04e+03 rew

agent-1: 377.0
agent-2: 373.0
agent-3: 356.0
Sum Reward: 1106.0
Avg Reward: 368.6666666666667
Min Reward: 356.0
Max Reward: 377.0
Gini Coefficient: 0.012658227848101266
20:20 Ratio: 1.0589887640449438
Max-min Ratio: 1.0589887640449438
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-23-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1320.0
  episode_reward_mean: 1042.41
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 118
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.705
    dispatch_time_ms: 7.611
    learner:
      cur_lr: 0.0013364235637709498
      grad_gnorm: 17.428808212280273
      policy_entropy: 21.252870559692383
      policy_loss: 0.6839656829833984
      var_gnorm: 31.069801330566406
      vf_explained_var: -0.054428935050964355
      vf_loss: 16.58925437927246
    num_steps_sampled: 357000
    num_steps_trained: 357000
    wait_time_ms: 79.781
  iterations_since_restore: 119
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1032.1462967395782
  time_this_iter_s: 9.167666912078857
  time_total_s: 1032.1462967395782
  timestamp: 1594095793
  timesteps_since_restore: 357000
  timesteps_this_iter: 3000
  timesteps_total: 357000
  training_iteration: 119
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1032 s, 119 iter, 357000 ts, 1.04e+03 rew

agent-1: 348.0
agent-2: 394.0
agent-3: 416.0
Sum Reward: 1158.0
Avg Reward: 386.0
Min Reward: 348.0
Max Reward: 416.0
Gini Coefficient: 0.03914795624640184
20:20 Ratio: 1.1954022988505748
Max-min Ratio: 1.1954022988505748
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-23-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1320.0
  episode_reward_mean: 1045.88
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 119
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.946
    dispatch_time_ms: 9.506
    learner:
      cur_lr: 0.0013362237950786948
      grad_gnorm: 29.528976440429688
      policy_entropy: 19.54757308959961
      policy_loss: 2.4396934509277344
      var_gnorm: 31.16546630859375
      vf_explained_var: -0.2356318235397339
      vf_loss: 14.740647315979004
    num_steps_sampled: 360000
    num_steps_trained: 360000
    wait_time_ms: 75.497
  iterations_since_restore: 120
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1041.213052034378
  time_this_iter_s: 9.066755294799805
  time_total_s: 1041.213052034378
  timestamp: 1594095802
  timesteps_since_restore: 360000
  timesteps_this_iter: 3000
  timesteps_total: 360000
  training_iteration: 120
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1041 s, 120 iter, 360000 ts, 1.05e+03 rew

agent-1: 392.0
agent-2: 375.0
agent-3: 354.0
Sum Reward: 1121.0
Avg Reward: 373.6666666666667
Min Reward: 354.0
Max Reward: 392.0
Gini Coefficient: 0.022598870056497175
20:20 Ratio: 1.1073446327683616
Max-min Ratio: 1.1073446327683616
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-23-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1320.0
  episode_reward_mean: 1049.44
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 120
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.745
    dispatch_time_ms: 18.953
    learner:
      cur_lr: 0.0013360240263864398
      grad_gnorm: 22.43143081665039
      policy_entropy: 18.812088012695312
      policy_loss: 2.587897777557373
      var_gnorm: 31.269786834716797
      vf_explained_var: 0.40386778116226196
      vf_loss: 29.32776641845703
    num_steps_sampled: 363000
    num_steps_trained: 363000
    wait_time_ms: 63.099
  iterations_since_restore: 121
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1054.4237079620361
  time_this_iter_s: 13.210655927658081
  time_total_s: 1054.4237079620361
  timestamp: 1594095816
  timesteps_since_restore: 363000
  timesteps_this_iter: 3000
  timesteps_total: 363000
  training_iteration: 121
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1054 s, 121 iter, 363000 ts, 1.05e+03 rew

agent-1: 382.0
agent-2: 379.0
agent-3: 346.0
Sum Reward: 1107.0
Avg Reward: 369.0
Min Reward: 346.0
Max Reward: 382.0
Gini Coefficient: 0.02168021680216802
20:20 Ratio: 1.1040462427745665
Max-min Ratio: 1.1040462427745665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-23-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1320.0
  episode_reward_mean: 1052.06
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 121
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.924
    dispatch_time_ms: 22.006
    learner:
      cur_lr: 0.0013358242576941848
      grad_gnorm: 40.0
      policy_entropy: 19.701631546020508
      policy_loss: -8.733527183532715
      var_gnorm: 31.356775283813477
      vf_explained_var: 0.43226534128189087
      vf_loss: 27.496135711669922
    num_steps_sampled: 366000
    num_steps_trained: 366000
    wait_time_ms: 77.796
  iterations_since_restore: 122
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1063.9373364448547
  time_this_iter_s: 9.513628482818604
  time_total_s: 1063.9373364448547
  timestamp: 1594095825
  timesteps_since_restore: 366000
  timesteps_this_iter: 3000
  timesteps_total: 366000
  training_iteration: 122
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1063 s, 122 iter, 366000 ts, 1.05e+03 rew

agent-1: 372.0
agent-2: 375.0
agent-3: 373.0
Sum Reward: 1120.0
Avg Reward: 373.3333333333333
Min Reward: 372.0
Max Reward: 375.0
Gini Coefficient: 0.0017857142857142857
20:20 Ratio: 1.0080645161290323
Max-min Ratio: 1.0080645161290323
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-23-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1320.0
  episode_reward_mean: 1054.37
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 122
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.493
    dispatch_time_ms: 29.814
    learner:
      cur_lr: 0.001335624372586608
      grad_gnorm: 39.999996185302734
      policy_entropy: 17.392864227294922
      policy_loss: -12.051226615905762
      var_gnorm: 31.416654586791992
      vf_explained_var: 0.181013822555542
      vf_loss: 53.85320281982422
    num_steps_sampled: 369000
    num_steps_trained: 369000
    wait_time_ms: 65.702
  iterations_since_restore: 123
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1073.2167029380798
  time_this_iter_s: 9.279366493225098
  time_total_s: 1073.2167029380798
  timestamp: 1594095834
  timesteps_since_restore: 369000
  timesteps_this_iter: 3000
  timesteps_total: 369000
  training_iteration: 123
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1073 s, 123 iter, 369000 ts, 1.05e+03 rew

agent-1: 395.0
agent-2: 399.0
agent-3: 408.0
Sum Reward: 1202.0
Avg Reward: 400.6666666666667
Min Reward: 395.0
Max Reward: 408.0
Gini Coefficient: 0.007210205213533
20:20 Ratio: 1.0329113924050632
Max-min Ratio: 1.0329113924050632
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-24-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1320.0
  episode_reward_mean: 1057.14
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 123
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.428
    dispatch_time_ms: 37.21
    learner:
      cur_lr: 0.001335424603894353
      grad_gnorm: 40.0
      policy_entropy: 12.4578275680542
      policy_loss: -24.555322647094727
      var_gnorm: 31.609508514404297
      vf_explained_var: 0.2753438949584961
      vf_loss: 64.89276123046875
    num_steps_sampled: 372000
    num_steps_trained: 372000
    wait_time_ms: 54.99
  iterations_since_restore: 124
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1083.1871445178986
  time_this_iter_s: 9.970441579818726
  time_total_s: 1083.1871445178986
  timestamp: 1594095844
  timesteps_since_restore: 372000
  timesteps_this_iter: 3000
  timesteps_total: 372000
  training_iteration: 124
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1083 s, 124 iter, 372000 ts, 1.06e+03 rew

agent-1: 408.0
agent-2: 400.0
agent-3: 442.0
Sum Reward: 1250.0
Avg Reward: 416.6666666666667
Min Reward: 400.0
Max Reward: 442.0
Gini Coefficient: 0.0224
20:20 Ratio: 1.105
Max-min Ratio: 1.105
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-24-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1320.0
  episode_reward_mean: 1060.44
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 124
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.385
    dispatch_time_ms: 14.216
    learner:
      cur_lr: 0.001335224835202098
      grad_gnorm: 40.000003814697266
      policy_entropy: 16.46230697631836
      policy_loss: -0.31627702713012695
      var_gnorm: 31.771427154541016
      vf_explained_var: -1.0
      vf_loss: 36.98225402832031
    num_steps_sampled: 375000
    num_steps_trained: 375000
    wait_time_ms: 78.338
  iterations_since_restore: 125
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1092.9370605945587
  time_this_iter_s: 9.749916076660156
  time_total_s: 1092.9370605945587
  timestamp: 1594095854
  timesteps_since_restore: 375000
  timesteps_this_iter: 3000
  timesteps_total: 375000
  training_iteration: 125
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1092 s, 125 iter, 375000 ts, 1.06e+03 rew

agent-1: 323.0
agent-2: 405.0
agent-3: 366.0
Sum Reward: 1094.0
Avg Reward: 364.6666666666667
Min Reward: 323.0
Max Reward: 405.0
Gini Coefficient: 0.049969530773918344
20:20 Ratio: 1.2538699690402477
Max-min Ratio: 1.2538699690402477
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-24-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1320.0
  episode_reward_mean: 1062.38
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 125
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.617
    dispatch_time_ms: 24.614
    learner:
      cur_lr: 0.001335024950094521
      grad_gnorm: 39.999996185302734
      policy_entropy: 11.398892402648926
      policy_loss: -19.446861267089844
      var_gnorm: 31.852771759033203
      vf_explained_var: 0.004517197608947754
      vf_loss: 45.274105072021484
    num_steps_sampled: 378000
    num_steps_trained: 378000
    wait_time_ms: 59.773
  iterations_since_restore: 126
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1102.6591935157776
  time_this_iter_s: 9.722132921218872
  time_total_s: 1102.6591935157776
  timestamp: 1594095864
  timesteps_since_restore: 378000
  timesteps_this_iter: 3000
  timesteps_total: 378000
  training_iteration: 126
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1102 s, 126 iter, 378000 ts, 1.06e+03 rew

agent-1: 384.0
agent-2: 431.0
agent-3: 397.0
Sum Reward: 1212.0
Avg Reward: 404.0
Min Reward: 384.0
Max Reward: 431.0
Gini Coefficient: 0.02585258525852585
20:20 Ratio: 1.1223958333333333
Max-min Ratio: 1.1223958333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-24-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1320.0
  episode_reward_mean: 1066.29
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 126
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.787
    dispatch_time_ms: 14.46
    learner:
      cur_lr: 0.001334825181402266
      grad_gnorm: 38.17710494995117
      policy_entropy: 10.629820823669434
      policy_loss: 8.634288787841797
      var_gnorm: 31.899965286254883
      vf_explained_var: -0.298663854598999
      vf_loss: 12.836738586425781
    num_steps_sampled: 381000
    num_steps_trained: 381000
    wait_time_ms: 86.039
  iterations_since_restore: 127
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1111.255119085312
  time_this_iter_s: 8.595925569534302
  time_total_s: 1111.255119085312
  timestamp: 1594095874
  timesteps_since_restore: 381000
  timesteps_this_iter: 3000
  timesteps_total: 381000
  training_iteration: 127
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1111 s, 127 iter, 381000 ts, 1.07e+03 rew

agent-1: 408.0
agent-2: 433.0
agent-3: 433.0
Sum Reward: 1274.0
Avg Reward: 424.6666666666667
Min Reward: 408.0
Max Reward: 433.0
Gini Coefficient: 0.013082155939298797
20:20 Ratio: 1.0612745098039216
Max-min Ratio: 1.0612745098039216
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-24-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1320.0
  episode_reward_mean: 1070.33
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 127
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.355
    dispatch_time_ms: 31.282
    learner:
      cur_lr: 0.001334625412710011
      grad_gnorm: 21.6423282623291
      policy_entropy: 11.66724967956543
      policy_loss: 1.247138261795044
      var_gnorm: 31.946725845336914
      vf_explained_var: -0.2585487365722656
      vf_loss: 18.396459579467773
    num_steps_sampled: 384000
    num_steps_trained: 384000
    wait_time_ms: 63.715
  iterations_since_restore: 128
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1121.186397075653
  time_this_iter_s: 9.931277990341187
  time_total_s: 1121.186397075653
  timestamp: 1594095884
  timesteps_since_restore: 384000
  timesteps_this_iter: 3000
  timesteps_total: 384000
  training_iteration: 128
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1121 s, 128 iter, 384000 ts, 1.07e+03 rew

agent-1: 412.0
agent-2: 383.0
agent-3: 435.0
Sum Reward: 1230.0
Avg Reward: 410.0
Min Reward: 383.0
Max Reward: 435.0
Gini Coefficient: 0.028184281842818428
20:20 Ratio: 1.1357702349869452
Max-min Ratio: 1.1357702349869452
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-24-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1320.0
  episode_reward_mean: 1074.04
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 128
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.697
    dispatch_time_ms: 20.089
    learner:
      cur_lr: 0.001334425644017756
      grad_gnorm: 40.00000762939453
      policy_entropy: 12.406518936157227
      policy_loss: -4.265361785888672
      var_gnorm: 32.033790588378906
      vf_explained_var: 0.162370502948761
      vf_loss: 18.13432502746582
    num_steps_sampled: 387000
    num_steps_trained: 387000
    wait_time_ms: 71.745
  iterations_since_restore: 129
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1130.7813444137573
  time_this_iter_s: 9.594947338104248
  time_total_s: 1130.7813444137573
  timestamp: 1594095893
  timesteps_since_restore: 387000
  timesteps_this_iter: 3000
  timesteps_total: 387000
  training_iteration: 129
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1130 s, 129 iter, 387000 ts, 1.07e+03 rew

agent-1: 391.0
agent-2: 458.0
agent-3: 412.0
Sum Reward: 1261.0
Avg Reward: 420.3333333333333
Min Reward: 391.0
Max Reward: 458.0
Gini Coefficient: 0.03542162305048903
20:20 Ratio: 1.1713554987212276
Max-min Ratio: 1.1713554987212276
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-25-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1320.0
  episode_reward_mean: 1077.0
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 129
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.173
    dispatch_time_ms: 24.194
    learner:
      cur_lr: 0.0013342257589101791
      grad_gnorm: 40.000003814697266
      policy_entropy: 8.469549179077148
      policy_loss: 2.7720723152160645
      var_gnorm: 32.144264221191406
      vf_explained_var: -0.2286090850830078
      vf_loss: 6.240627765655518
    num_steps_sampled: 390000
    num_steps_trained: 390000
    wait_time_ms: 76.566
  iterations_since_restore: 130
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1140.5740139484406
  time_this_iter_s: 9.792669534683228
  time_total_s: 1140.5740139484406
  timestamp: 1594095903
  timesteps_since_restore: 390000
  timesteps_this_iter: 3000
  timesteps_total: 390000
  training_iteration: 130
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1140 s, 130 iter, 390000 ts, 1.08e+03 rew

agent-1: 378.0
agent-2: 416.0
agent-3: 425.0
Sum Reward: 1219.0
Avg Reward: 406.3333333333333
Min Reward: 378.0
Max Reward: 425.0
Gini Coefficient: 0.0257041290675417
20:20 Ratio: 1.1243386243386244
Max-min Ratio: 1.1243386243386244
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-25-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1320.0
  episode_reward_mean: 1079.5
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 130
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.615
    dispatch_time_ms: 31.688
    learner:
      cur_lr: 0.0013340259902179241
      grad_gnorm: 29.166114807128906
      policy_entropy: 9.666038513183594
      policy_loss: -1.5900416374206543
      var_gnorm: 32.180721282958984
      vf_explained_var: 0.05194729566574097
      vf_loss: 33.26607131958008
    num_steps_sampled: 393000
    num_steps_trained: 393000
    wait_time_ms: 65.974
  iterations_since_restore: 131
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1150.2848892211914
  time_this_iter_s: 9.710875272750854
  time_total_s: 1150.2848892211914
  timestamp: 1594095913
  timesteps_since_restore: 393000
  timesteps_this_iter: 3000
  timesteps_total: 393000
  training_iteration: 131
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1150 s, 131 iter, 393000 ts, 1.08e+03 rew

agent-1: 394.0
agent-2: 435.0
agent-3: 428.0
Sum Reward: 1257.0
Avg Reward: 419.0
Min Reward: 394.0
Max Reward: 435.0
Gini Coefficient: 0.021744895253248474
20:20 Ratio: 1.1040609137055837
Max-min Ratio: 1.1040609137055837
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-25-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1320.0
  episode_reward_mean: 1082.57
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 131
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.709
    dispatch_time_ms: 15.436
    learner:
      cur_lr: 0.001333826221525669
      grad_gnorm: 39.999996185302734
      policy_entropy: 13.22842025756836
      policy_loss: 8.023075103759766
      var_gnorm: 32.245094299316406
      vf_explained_var: -1.0
      vf_loss: 12.663147926330566
    num_steps_sampled: 396000
    num_steps_trained: 396000
    wait_time_ms: 82.226
  iterations_since_restore: 132
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1160.3779227733612
  time_this_iter_s: 10.0930335521698
  time_total_s: 1160.3779227733612
  timestamp: 1594095923
  timesteps_since_restore: 396000
  timesteps_this_iter: 3000
  timesteps_total: 396000
  training_iteration: 132
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1160 s, 132 iter, 396000 ts, 1.08e+03 rew

agent-1: 401.0
agent-2: 406.0
agent-3: 382.0
Sum Reward: 1189.0
Avg Reward: 396.3333333333333
Min Reward: 382.0
Max Reward: 406.0
Gini Coefficient: 0.01345668629100084
20:20 Ratio: 1.0628272251308901
Max-min Ratio: 1.0628272251308901
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-25-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1320.0
  episode_reward_mean: 1085.07
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 132
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.659
    dispatch_time_ms: 30.482
    learner:
      cur_lr: 0.001333626452833414
      grad_gnorm: 40.000003814697266
      policy_entropy: 14.295391082763672
      policy_loss: 6.631374835968018
      var_gnorm: 32.31937026977539
      vf_explained_var: -1.0
      vf_loss: 17.519084930419922
    num_steps_sampled: 399000
    num_steps_trained: 399000
    wait_time_ms: 60.235
  iterations_since_restore: 133
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1169.6164491176605
  time_this_iter_s: 9.238526344299316
  time_total_s: 1169.6164491176605
  timestamp: 1594095932
  timesteps_since_restore: 399000
  timesteps_this_iter: 3000
  timesteps_total: 399000
  training_iteration: 133
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1169 s, 133 iter, 399000 ts, 1.09e+03 rew

agent-1: 315.0
agent-2: 352.0
agent-3: 290.0
Sum Reward: 957.0
Avg Reward: 319.0
Min Reward: 290.0
Max Reward: 352.0
Gini Coefficient: 0.04319052594914664
20:20 Ratio: 1.2137931034482758
Max-min Ratio: 1.2137931034482758
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-25-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1320.0
  episode_reward_mean: 1085.12
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 133
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.793
    dispatch_time_ms: 18.063
    learner:
      cur_lr: 0.0013334265677258372
      grad_gnorm: 40.0
      policy_entropy: 12.634689331054688
      policy_loss: -17.977420806884766
      var_gnorm: 32.28034591674805
      vf_explained_var: -0.12105941772460938
      vf_loss: 32.489479064941406
    num_steps_sampled: 402000
    num_steps_trained: 402000
    wait_time_ms: 65.715
  iterations_since_restore: 134
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1177.8927760124207
  time_this_iter_s: 8.276326894760132
  time_total_s: 1177.8927760124207
  timestamp: 1594095941
  timesteps_since_restore: 402000
  timesteps_this_iter: 3000
  timesteps_total: 402000
  training_iteration: 134
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1177 s, 134 iter, 402000 ts, 1.09e+03 rew

agent-1: 245.0
agent-2: 264.0
agent-3: 270.0
Sum Reward: 779.0
Avg Reward: 259.6666666666667
Min Reward: 245.0
Max Reward: 270.0
Gini Coefficient: 0.02139495079161318
20:20 Ratio: 1.1020408163265305
Max-min Ratio: 1.1020408163265305
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-25-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1320.0
  episode_reward_mean: 1083.29
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 134
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.831
    dispatch_time_ms: 38.126
    learner:
      cur_lr: 0.0013332267990335822
      grad_gnorm: 13.22502613067627
      policy_entropy: 16.31357765197754
      policy_loss: -6.254165172576904
      var_gnorm: 32.218631744384766
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 31.229352951049805
    num_steps_sampled: 405000
    num_steps_trained: 405000
    wait_time_ms: 40.777
  iterations_since_restore: 135
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1186.0121965408325
  time_this_iter_s: 8.119420528411865
  time_total_s: 1186.0121965408325
  timestamp: 1594095949
  timesteps_since_restore: 405000
  timesteps_this_iter: 3000
  timesteps_total: 405000
  training_iteration: 135
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1186 s, 135 iter, 405000 ts, 1.08e+03 rew

agent-1: 231.0
agent-2: 208.0
agent-3: 264.0
Sum Reward: 703.0
Avg Reward: 234.33333333333334
Min Reward: 208.0
Max Reward: 264.0
Gini Coefficient: 0.05310573731626363
20:20 Ratio: 1.2692307692307692
Max-min Ratio: 1.2692307692307692
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-25-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1320.0
  episode_reward_mean: 1080.44
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 135
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.575
    dispatch_time_ms: 26.646
    learner:
      cur_lr: 0.0013330270303413272
      grad_gnorm: 40.0
      policy_entropy: 16.723491668701172
      policy_loss: 4.7181925773620605
      var_gnorm: 32.17650604248047
      vf_explained_var: -0.004072904586791992
      vf_loss: 20.99028968811035
    num_steps_sampled: 408000
    num_steps_trained: 408000
    wait_time_ms: 43.709
  iterations_since_restore: 136
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1194.0043592453003
  time_this_iter_s: 7.992162704467773
  time_total_s: 1194.0043592453003
  timestamp: 1594095957
  timesteps_since_restore: 408000
  timesteps_this_iter: 3000
  timesteps_total: 408000
  training_iteration: 136
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1194 s, 136 iter, 408000 ts, 1.08e+03 rew

agent-1: 267.0
agent-2: 250.0
agent-3: 240.0
Sum Reward: 757.0
Avg Reward: 252.33333333333334
Min Reward: 240.0
Max Reward: 267.0
Gini Coefficient: 0.023778071334214
20:20 Ratio: 1.1125
Max-min Ratio: 1.1125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-26-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1320.0
  episode_reward_mean: 1078.6
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 136
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.155
    dispatch_time_ms: 19.862
    learner:
      cur_lr: 0.0013328271452337503
      grad_gnorm: 39.999996185302734
      policy_entropy: 21.982059478759766
      policy_loss: -19.079708099365234
      var_gnorm: 32.300811767578125
      vf_explained_var: 0.6370818614959717
      vf_loss: 15.694462776184082
    num_steps_sampled: 411000
    num_steps_trained: 411000
    wait_time_ms: 57.083
  iterations_since_restore: 137
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1202.5039563179016
  time_this_iter_s: 8.499597072601318
  time_total_s: 1202.5039563179016
  timestamp: 1594095965
  timesteps_since_restore: 411000
  timesteps_this_iter: 3000
  timesteps_total: 411000
  training_iteration: 137
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1202 s, 137 iter, 411000 ts, 1.08e+03 rew

agent-1: 258.0
agent-2: 333.0
agent-3: 328.0
Sum Reward: 919.0
Avg Reward: 306.3333333333333
Min Reward: 258.0
Max Reward: 333.0
Gini Coefficient: 0.0544069640914037
20:20 Ratio: 1.2906976744186047
Max-min Ratio: 1.2906976744186047
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-26-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1320.0
  episode_reward_mean: 1077.72
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 137
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.556
    dispatch_time_ms: 49.344
    learner:
      cur_lr: 0.0013326273765414953
      grad_gnorm: 39.999996185302734
      policy_entropy: 18.64933204650879
      policy_loss: 17.955787658691406
      var_gnorm: 32.38252639770508
      vf_explained_var: -0.023010730743408203
      vf_loss: 49.78955078125
    num_steps_sampled: 414000
    num_steps_trained: 414000
    wait_time_ms: 39.252
  iterations_since_restore: 138
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1211.5381150245667
  time_this_iter_s: 9.034158706665039
  time_total_s: 1211.5381150245667
  timestamp: 1594095974
  timesteps_since_restore: 414000
  timesteps_this_iter: 3000
  timesteps_total: 414000
  training_iteration: 138
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1211 s, 138 iter, 414000 ts, 1.08e+03 rew

agent-1: 324.0
agent-2: 330.0
agent-3: 308.0
Sum Reward: 962.0
Avg Reward: 320.6666666666667
Min Reward: 308.0
Max Reward: 330.0
Gini Coefficient: 0.015246015246015246
20:20 Ratio: 1.0714285714285714
Max-min Ratio: 1.0714285714285714
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-26-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1320.0
  episode_reward_mean: 1077.12
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 138
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.748
    dispatch_time_ms: 27.294
    learner:
      cur_lr: 0.0013324276078492403
      grad_gnorm: 25.731260299682617
      policy_entropy: 21.618234634399414
      policy_loss: -14.861099243164062
      var_gnorm: 32.490966796875
      vf_explained_var: 0.46566838026046753
      vf_loss: 42.19525909423828
    num_steps_sampled: 417000
    num_steps_trained: 417000
    wait_time_ms: 57.722
  iterations_since_restore: 139
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1220.4645278453827
  time_this_iter_s: 8.92641282081604
  time_total_s: 1220.4645278453827
  timestamp: 1594095983
  timesteps_since_restore: 417000
  timesteps_this_iter: 3000
  timesteps_total: 417000
  training_iteration: 139
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1220 s, 139 iter, 417000 ts, 1.08e+03 rew

agent-1: 222.0
agent-2: 337.0
agent-3: 277.0
Sum Reward: 836.0
Avg Reward: 278.6666666666667
Min Reward: 222.0
Max Reward: 337.0
Gini Coefficient: 0.09170653907496013
20:20 Ratio: 1.518018018018018
Max-min Ratio: 1.518018018018018
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-26-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1320.0
  episode_reward_mean: 1076.19
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 139
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.572
    dispatch_time_ms: 24.309
    learner:
      cur_lr: 0.0013322278391569853
      grad_gnorm: 28.961074829101562
      policy_entropy: 20.754467010498047
      policy_loss: -6.104098796844482
      var_gnorm: 32.443084716796875
      vf_explained_var: 0.3351956009864807
      vf_loss: 27.044326782226562
    num_steps_sampled: 420000
    num_steps_trained: 420000
    wait_time_ms: 49.753
  iterations_since_restore: 140
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1229.1610057353973
  time_this_iter_s: 8.696477890014648
  time_total_s: 1229.1610057353973
  timestamp: 1594095992
  timesteps_since_restore: 420000
  timesteps_this_iter: 3000
  timesteps_total: 420000
  training_iteration: 140
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1229 s, 140 iter, 420000 ts, 1.08e+03 rew

agent-1: 291.0
agent-2: 328.0
agent-3: 311.0
Sum Reward: 930.0
Avg Reward: 310.0
Min Reward: 291.0
Max Reward: 328.0
Gini Coefficient: 0.026523297491039426
20:20 Ratio: 1.127147766323024
Max-min Ratio: 1.127147766323024
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-26-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1320.0
  episode_reward_mean: 1076.39
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 140
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.95
    dispatch_time_ms: 24.19
    learner:
      cur_lr: 0.0013320279540494084
      grad_gnorm: 40.000003814697266
      policy_entropy: 17.38207244873047
      policy_loss: 21.153139114379883
      var_gnorm: 32.57054138183594
      vf_explained_var: 0.3343747854232788
      vf_loss: 30.709327697753906
    num_steps_sampled: 423000
    num_steps_trained: 423000
    wait_time_ms: 49.8
  iterations_since_restore: 141
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1238.1304335594177
  time_this_iter_s: 8.969427824020386
  time_total_s: 1238.1304335594177
  timestamp: 1594096001
  timesteps_since_restore: 423000
  timesteps_this_iter: 3000
  timesteps_total: 423000
  training_iteration: 141
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1238 s, 141 iter, 423000 ts, 1.08e+03 rew

agent-1: 366.0
agent-2: 427.0
agent-3: 332.0
Sum Reward: 1125.0
Avg Reward: 375.0
Min Reward: 332.0
Max Reward: 427.0
Gini Coefficient: 0.056296296296296296
20:20 Ratio: 1.286144578313253
Max-min Ratio: 1.286144578313253
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-26-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1320.0
  episode_reward_mean: 1076.99
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 141
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.443
    dispatch_time_ms: 30.937
    learner:
      cur_lr: 0.0013318281853571534
      grad_gnorm: 39.999977111816406
      policy_entropy: 20.436899185180664
      policy_loss: -16.260400772094727
      var_gnorm: 32.674617767333984
      vf_explained_var: 0.41348737478256226
      vf_loss: 28.353458404541016
    num_steps_sampled: 426000
    num_steps_trained: 426000
    wait_time_ms: 80.707
  iterations_since_restore: 142
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1247.950876712799
  time_this_iter_s: 9.820443153381348
  time_total_s: 1247.950876712799
  timestamp: 1594096011
  timesteps_since_restore: 426000
  timesteps_this_iter: 3000
  timesteps_total: 426000
  training_iteration: 142
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1247 s, 142 iter, 426000 ts, 1.08e+03 rew

agent-1: 398.0
agent-2: 363.0
agent-3: 372.0
Sum Reward: 1133.0
Avg Reward: 377.6666666666667
Min Reward: 363.0
Max Reward: 398.0
Gini Coefficient: 0.020594292438952635
20:20 Ratio: 1.0964187327823691
Max-min Ratio: 1.0964187327823691
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-27-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1320.0
  episode_reward_mean: 1077.92
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 142
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.113
    dispatch_time_ms: 24.166
    learner:
      cur_lr: 0.0013316284166648984
      grad_gnorm: 39.999996185302734
      policy_entropy: 22.221580505371094
      policy_loss: -9.545572280883789
      var_gnorm: 32.846195220947266
      vf_explained_var: 0.3215773105621338
      vf_loss: 19.378746032714844
    num_steps_sampled: 429000
    num_steps_trained: 429000
    wait_time_ms: 66.116
  iterations_since_restore: 143
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1257.2296886444092
  time_this_iter_s: 9.278811931610107
  time_total_s: 1257.2296886444092
  timestamp: 1594096020
  timesteps_since_restore: 429000
  timesteps_this_iter: 3000
  timesteps_total: 429000
  training_iteration: 143
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1257 s, 143 iter, 429000 ts, 1.08e+03 rew

agent-1: 373.0
agent-2: 455.0
agent-3: 415.0
Sum Reward: 1243.0
Avg Reward: 414.3333333333333
Min Reward: 373.0
Max Reward: 455.0
Gini Coefficient: 0.04397961920085814
20:20 Ratio: 1.2198391420911527
Max-min Ratio: 1.2198391420911527
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-27-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1320.0
  episode_reward_mean: 1079.6
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 143
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.741
    dispatch_time_ms: 23.026
    learner:
      cur_lr: 0.0013314286479726434
      grad_gnorm: 39.999996185302734
      policy_entropy: 12.643321990966797
      policy_loss: 21.204429626464844
      var_gnorm: 32.93391799926758
      vf_explained_var: -0.8434038162231445
      vf_loss: 37.41320037841797
    num_steps_sampled: 432000
    num_steps_trained: 432000
    wait_time_ms: 69.115
  iterations_since_restore: 144
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1266.4436693191528
  time_this_iter_s: 9.213980674743652
  time_total_s: 1266.4436693191528
  timestamp: 1594096030
  timesteps_since_restore: 432000
  timesteps_this_iter: 3000
  timesteps_total: 432000
  training_iteration: 144
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1266 s, 144 iter, 432000 ts, 1.08e+03 rew

agent-1: 406.0
agent-2: 435.0
agent-3: 453.0
Sum Reward: 1294.0
Avg Reward: 431.3333333333333
Min Reward: 406.0
Max Reward: 453.0
Gini Coefficient: 0.024214322514167955
20:20 Ratio: 1.1157635467980296
Max-min Ratio: 1.1157635467980296
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-27-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1320.0
  episode_reward_mean: 1082.11
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 144
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.611
    dispatch_time_ms: 17.195
    learner:
      cur_lr: 0.0013312287628650665
      grad_gnorm: 40.000003814697266
      policy_entropy: 12.829891204833984
      policy_loss: 8.171050071716309
      var_gnorm: 33.00892639160156
      vf_explained_var: 0.16187536716461182
      vf_loss: 12.682588577270508
    num_steps_sampled: 435000
    num_steps_trained: 435000
    wait_time_ms: 63.97
  iterations_since_restore: 145
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1276.1697533130646
  time_this_iter_s: 9.726083993911743
  time_total_s: 1276.1697533130646
  timestamp: 1594096039
  timesteps_since_restore: 435000
  timesteps_this_iter: 3000
  timesteps_total: 435000
  training_iteration: 145
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1276 s, 145 iter, 435000 ts, 1.08e+03 rew

agent-1: 458.0
agent-2: 455.0
agent-3: 437.0
Sum Reward: 1350.0
Avg Reward: 450.0
Min Reward: 437.0
Max Reward: 458.0
Gini Coefficient: 0.01037037037037037
20:20 Ratio: 1.0480549199084668
Max-min Ratio: 1.0480549199084668
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-27-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 1084.32
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 145
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.601
    dispatch_time_ms: 37.896
    learner:
      cur_lr: 0.0013310289941728115
      grad_gnorm: 27.933368682861328
      policy_entropy: 18.099231719970703
      policy_loss: 2.302661180496216
      var_gnorm: 32.99258804321289
      vf_explained_var: 0.29080623388290405
      vf_loss: 4.933714389801025
    num_steps_sampled: 438000
    num_steps_trained: 438000
    wait_time_ms: 47.148
  iterations_since_restore: 146
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1285.6408259868622
  time_this_iter_s: 9.471072673797607
  time_total_s: 1285.6408259868622
  timestamp: 1594096049
  timesteps_since_restore: 438000
  timesteps_this_iter: 3000
  timesteps_total: 438000
  training_iteration: 146
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1285 s, 146 iter, 438000 ts, 1.08e+03 rew

agent-1: 433.0
agent-2: 380.0
agent-3: 391.0
Sum Reward: 1204.0
Avg Reward: 401.3333333333333
Min Reward: 380.0
Max Reward: 433.0
Gini Coefficient: 0.029346622369878183
20:20 Ratio: 1.1394736842105264
Max-min Ratio: 1.1394736842105264
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-27-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 1085.44
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 146
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.754
    dispatch_time_ms: 42.512
    learner:
      cur_lr: 0.0013308292254805565
      grad_gnorm: 13.957639694213867
      policy_entropy: 17.895282745361328
      policy_loss: 1.0074572563171387
      var_gnorm: 33.039180755615234
      vf_explained_var: 0.3154674172401428
      vf_loss: 11.31403636932373
    num_steps_sampled: 441000
    num_steps_trained: 441000
    wait_time_ms: 60.135
  iterations_since_restore: 147
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1295.2079520225525
  time_this_iter_s: 9.567126035690308
  time_total_s: 1295.2079520225525
  timestamp: 1594096058
  timesteps_since_restore: 441000
  timesteps_this_iter: 3000
  timesteps_total: 441000
  training_iteration: 147
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1295 s, 147 iter, 441000 ts, 1.09e+03 rew

agent-1: 399.0
agent-2: 369.0
agent-3: 431.0
Sum Reward: 1199.0
Avg Reward: 399.6666666666667
Min Reward: 369.0
Max Reward: 431.0
Gini Coefficient: 0.03447317208785099
20:20 Ratio: 1.1680216802168022
Max-min Ratio: 1.1680216802168022
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-27-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 1086.85
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 147
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.464
    dispatch_time_ms: 23.458
    learner:
      cur_lr: 0.0013306294567883015
      grad_gnorm: 40.0000114440918
      policy_entropy: 19.75946044921875
      policy_loss: -2.264479160308838
      var_gnorm: 33.068603515625
      vf_explained_var: 0.03391373157501221
      vf_loss: 36.60680389404297
    num_steps_sampled: 444000
    num_steps_trained: 444000
    wait_time_ms: 64.163
  iterations_since_restore: 148
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1304.4489431381226
  time_this_iter_s: 9.240991115570068
  time_total_s: 1304.4489431381226
  timestamp: 1594096068
  timesteps_since_restore: 444000
  timesteps_this_iter: 3000
  timesteps_total: 444000
  training_iteration: 148
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1304 s, 148 iter, 444000 ts, 1.09e+03 rew

agent-1: 397.0
agent-2: 359.0
agent-3: 361.0
Sum Reward: 1117.0
Avg Reward: 372.3333333333333
Min Reward: 359.0
Max Reward: 397.0
Gini Coefficient: 0.02267979707549985
20:20 Ratio: 1.105849582172702
Max-min Ratio: 1.105849582172702
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-28-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 1087.84
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 148
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.847
    dispatch_time_ms: 58.106
    learner:
      cur_lr: 0.0013304295716807246
      grad_gnorm: 40.0
      policy_entropy: 26.395540237426758
      policy_loss: -22.67865753173828
      var_gnorm: 32.993717193603516
      vf_explained_var: -0.10555243492126465
      vf_loss: 11.449790954589844
    num_steps_sampled: 447000
    num_steps_trained: 447000
    wait_time_ms: 32.714
  iterations_since_restore: 149
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1318.0300636291504
  time_this_iter_s: 13.581120491027832
  time_total_s: 1318.0300636291504
  timestamp: 1594096081
  timesteps_since_restore: 447000
  timesteps_this_iter: 3000
  timesteps_total: 447000
  training_iteration: 149
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1318 s, 149 iter, 447000 ts, 1.09e+03 rew

agent-1: 298.0
agent-2: 301.0
agent-3: 310.0
Sum Reward: 909.0
Avg Reward: 303.0
Min Reward: 298.0
Max Reward: 310.0
Gini Coefficient: 0.0088008800880088
20:20 Ratio: 1.0402684563758389
Max-min Ratio: 1.0402684563758389
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-28-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 1086.07
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 149
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.69
    dispatch_time_ms: 26.101
    learner:
      cur_lr: 0.0013302298029884696
      grad_gnorm: 39.999977111816406
      policy_entropy: 25.13399314880371
      policy_loss: -4.254374027252197
      var_gnorm: 32.95689392089844
      vf_explained_var: -0.9371085166931152
      vf_loss: 9.871744155883789
    num_steps_sampled: 450000
    num_steps_trained: 450000
    wait_time_ms: 59.779
  iterations_since_restore: 150
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1326.0474183559418
  time_this_iter_s: 8.017354726791382
  time_total_s: 1326.0474183559418
  timestamp: 1594096089
  timesteps_since_restore: 450000
  timesteps_this_iter: 3000
  timesteps_total: 450000
  training_iteration: 150
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1326 s, 150 iter, 450000 ts, 1.09e+03 rew

agent-1: 265.0
agent-2: 287.0
agent-3: 250.0
Sum Reward: 802.0
Avg Reward: 267.3333333333333
Min Reward: 250.0
Max Reward: 287.0
Gini Coefficient: 0.030756442227763924
20:20 Ratio: 1.148
Max-min Ratio: 1.148
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-28-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 1083.39
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 150
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.579
    dispatch_time_ms: 37.466
    learner:
      cur_lr: 0.0013300300342962146
      grad_gnorm: 40.0
      policy_entropy: 21.5123348236084
      policy_loss: -12.776518821716309
      var_gnorm: 32.93708801269531
      vf_explained_var: 0.07348048686981201
      vf_loss: 34.90862274169922
    num_steps_sampled: 453000
    num_steps_trained: 453000
    wait_time_ms: 44.72
  iterations_since_restore: 151
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1334.3783009052277
  time_this_iter_s: 8.330882549285889
  time_total_s: 1334.3783009052277
  timestamp: 1594096098
  timesteps_since_restore: 453000
  timesteps_this_iter: 3000
  timesteps_total: 453000
  training_iteration: 151
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1334 s, 151 iter, 453000 ts, 1.08e+03 rew

agent-1: 272.0
agent-2: 297.0
agent-3: 304.0
Sum Reward: 873.0
Avg Reward: 291.0
Min Reward: 272.0
Max Reward: 304.0
Gini Coefficient: 0.024436807941962582
20:20 Ratio: 1.1176470588235294
Max-min Ratio: 1.1176470588235294
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-28-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 1079.92
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 151
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.001
    dispatch_time_ms: 27.795
    learner:
      cur_lr: 0.0013298301491886377
      grad_gnorm: 39.91987991333008
      policy_entropy: 19.211570739746094
      policy_loss: -11.886154174804688
      var_gnorm: 32.935943603515625
      vf_explained_var: -0.2874901294708252
      vf_loss: 9.090694427490234
    num_steps_sampled: 456000
    num_steps_trained: 456000
    wait_time_ms: 68.707
  iterations_since_restore: 152
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1342.6862123012543
  time_this_iter_s: 8.307911396026611
  time_total_s: 1342.6862123012543
  timestamp: 1594096106
  timesteps_since_restore: 456000
  timesteps_this_iter: 3000
  timesteps_total: 456000
  training_iteration: 152
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1342 s, 152 iter, 456000 ts, 1.08e+03 rew

agent-1: 308.0
agent-2: 274.0
agent-3: 282.0
Sum Reward: 864.0
Avg Reward: 288.0
Min Reward: 274.0
Max Reward: 308.0
Gini Coefficient: 0.026234567901234566
20:20 Ratio: 1.1240875912408759
Max-min Ratio: 1.1240875912408759
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-28-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 1077.3
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 152
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.689
    dispatch_time_ms: 38.045
    learner:
      cur_lr: 0.0013296303804963827
      grad_gnorm: 40.0
      policy_entropy: 22.572391510009766
      policy_loss: -19.873144149780273
      var_gnorm: 32.93300247192383
      vf_explained_var: -0.2684842348098755
      vf_loss: 39.97199249267578
    num_steps_sampled: 459000
    num_steps_trained: 459000
    wait_time_ms: 45.045
  iterations_since_restore: 153
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1350.9897141456604
  time_this_iter_s: 8.303501844406128
  time_total_s: 1350.9897141456604
  timestamp: 1594096114
  timesteps_since_restore: 459000
  timesteps_this_iter: 3000
  timesteps_total: 459000
  training_iteration: 153
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1350 s, 153 iter, 459000 ts, 1.08e+03 rew

agent-1: 274.0
agent-2: 275.0
agent-3: 307.0
Sum Reward: 856.0
Avg Reward: 285.3333333333333
Min Reward: 274.0
Max Reward: 307.0
Gini Coefficient: 0.02570093457943925
20:20 Ratio: 1.1204379562043796
Max-min Ratio: 1.1204379562043796
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-28-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 1074.06
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 153
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.994
    dispatch_time_ms: 44.346
    learner:
      cur_lr: 0.0013294306118041277
      grad_gnorm: 39.99998092651367
      policy_entropy: 21.581029891967773
      policy_loss: 2.3347201347351074
      var_gnorm: 32.92547607421875
      vf_explained_var: 0.33152252435684204
      vf_loss: 24.667888641357422
    num_steps_sampled: 462000
    num_steps_trained: 462000
    wait_time_ms: 35.914
  iterations_since_restore: 154
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1359.2542624473572
  time_this_iter_s: 8.264548301696777
  time_total_s: 1359.2542624473572
  timestamp: 1594096123
  timesteps_since_restore: 462000
  timesteps_this_iter: 3000
  timesteps_total: 462000
  training_iteration: 154
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1359 s, 154 iter, 462000 ts, 1.07e+03 rew

agent-1: 308.0
agent-2: 289.0
agent-3: 272.0
Sum Reward: 869.0
Avg Reward: 289.6666666666667
Min Reward: 272.0
Max Reward: 308.0
Gini Coefficient: 0.02761795166858458
20:20 Ratio: 1.1323529411764706
Max-min Ratio: 1.1323529411764706
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-28-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 1071.55
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 154
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.643
    dispatch_time_ms: 35.789
    learner:
      cur_lr: 0.0013292308431118727
      grad_gnorm: 40.0
      policy_entropy: 11.138660430908203
      policy_loss: 18.7135009765625
      var_gnorm: 32.9491081237793
      vf_explained_var: -0.16708838939666748
      vf_loss: 34.561500549316406
    num_steps_sampled: 465000
    num_steps_trained: 465000
    wait_time_ms: 55.581
  iterations_since_restore: 155
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1367.6318037509918
  time_this_iter_s: 8.377541303634644
  time_total_s: 1367.6318037509918
  timestamp: 1594096131
  timesteps_since_restore: 465000
  timesteps_this_iter: 3000
  timesteps_total: 465000
  training_iteration: 155
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1367 s, 155 iter, 465000 ts, 1.07e+03 rew

agent-1: 313.0
agent-2: 254.0
agent-3: 333.0
Sum Reward: 900.0
Avg Reward: 300.0
Min Reward: 254.0
Max Reward: 333.0
Gini Coefficient: 0.05851851851851852
20:20 Ratio: 1.311023622047244
Max-min Ratio: 1.311023622047244
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-29-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 1069.17
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 155
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.29
    dispatch_time_ms: 33.193
    learner:
      cur_lr: 0.0013290309580042958
      grad_gnorm: 8.715007781982422
      policy_entropy: 11.789376258850098
      policy_loss: 5.397226810455322
      var_gnorm: 32.96310806274414
      vf_explained_var: 0.12407046556472778
      vf_loss: 5.158551216125488
    num_steps_sampled: 468000
    num_steps_trained: 468000
    wait_time_ms: 51.426
  iterations_since_restore: 156
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1376.1164951324463
  time_this_iter_s: 8.484691381454468
  time_total_s: 1376.1164951324463
  timestamp: 1594096140
  timesteps_since_restore: 468000
  timesteps_this_iter: 3000
  timesteps_total: 468000
  training_iteration: 156
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1376 s, 156 iter, 468000 ts, 1.07e+03 rew

agent-1: 323.0
agent-2: 328.0
agent-3: 327.0
Sum Reward: 978.0
Avg Reward: 326.0
Min Reward: 323.0
Max Reward: 328.0
Gini Coefficient: 0.0034083162917518746
20:20 Ratio: 1.0154798761609907
Max-min Ratio: 1.0154798761609907
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-29-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 1068.56
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 156
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.534
    dispatch_time_ms: 27.533
    learner:
      cur_lr: 0.0013288311893120408
      grad_gnorm: 40.000003814697266
      policy_entropy: 20.15115737915039
      policy_loss: -18.583539962768555
      var_gnorm: 32.98820114135742
      vf_explained_var: -0.04889369010925293
      vf_loss: 31.87496566772461
    num_steps_sampled: 471000
    num_steps_trained: 471000
    wait_time_ms: 54.478
  iterations_since_restore: 157
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1384.6331791877747
  time_this_iter_s: 8.51668405532837
  time_total_s: 1384.6331791877747
  timestamp: 1594096148
  timesteps_since_restore: 471000
  timesteps_this_iter: 3000
  timesteps_total: 471000
  training_iteration: 157
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1384 s, 157 iter, 471000 ts, 1.07e+03 rew

agent-1: 324.0
agent-2: 328.0
agent-3: 334.0
Sum Reward: 986.0
Avg Reward: 328.6666666666667
Min Reward: 324.0
Max Reward: 334.0
Gini Coefficient: 0.0067613252197430695
20:20 Ratio: 1.0308641975308641
Max-min Ratio: 1.0308641975308641
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-29-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 1069.9
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 157
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.872
    dispatch_time_ms: 18.897
    learner:
      cur_lr: 0.0013286314206197858
      grad_gnorm: 30.321727752685547
      policy_entropy: 12.696725845336914
      policy_loss: 1.205942153930664
      var_gnorm: 33.03976058959961
      vf_explained_var: -0.3124704360961914
      vf_loss: 55.0235595703125
    num_steps_sampled: 474000
    num_steps_trained: 474000
    wait_time_ms: 68.405
  iterations_since_restore: 158
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1393.2522354125977
  time_this_iter_s: 8.619056224822998
  time_total_s: 1393.2522354125977
  timestamp: 1594096157
  timesteps_since_restore: 474000
  timesteps_this_iter: 3000
  timesteps_total: 474000
  training_iteration: 158
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1393 s, 158 iter, 474000 ts, 1.07e+03 rew

agent-1: 350.0
agent-2: 344.0
agent-3: 322.0
Sum Reward: 1016.0
Avg Reward: 338.6666666666667
Min Reward: 322.0
Max Reward: 350.0
Gini Coefficient: 0.01837270341207349
20:20 Ratio: 1.0869565217391304
Max-min Ratio: 1.0869565217391304
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-29-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 1071.42
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 158
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.018
    dispatch_time_ms: 28.665
    learner:
      cur_lr: 0.0013284316519275308
      grad_gnorm: 40.0
      policy_entropy: 16.519624710083008
      policy_loss: -21.142000198364258
      var_gnorm: 33.05653762817383
      vf_explained_var: 0.18599683046340942
      vf_loss: 22.122486114501953
    num_steps_sampled: 477000
    num_steps_trained: 477000
    wait_time_ms: 55.265
  iterations_since_restore: 159
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1401.4005765914917
  time_this_iter_s: 8.148341178894043
  time_total_s: 1401.4005765914917
  timestamp: 1594096165
  timesteps_since_restore: 477000
  timesteps_this_iter: 3000
  timesteps_total: 477000
  training_iteration: 159
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1401 s, 159 iter, 477000 ts, 1.07e+03 rew

agent-1: 326.0
agent-2: 350.0
agent-3: 312.0
Sum Reward: 988.0
Avg Reward: 329.3333333333333
Min Reward: 312.0
Max Reward: 350.0
Gini Coefficient: 0.02564102564102564
20:20 Ratio: 1.1217948717948718
Max-min Ratio: 1.1217948717948718
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-29-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 1070.62
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 159
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.442
    dispatch_time_ms: 23.3
    learner:
      cur_lr: 0.001328231766819954
      grad_gnorm: 40.00000762939453
      policy_entropy: 26.934497833251953
      policy_loss: -15.186355590820312
      var_gnorm: 33.06050109863281
      vf_explained_var: 0.10528069734573364
      vf_loss: 24.99874496459961
    num_steps_sampled: 480000
    num_steps_trained: 480000
    wait_time_ms: 61.406
  iterations_since_restore: 160
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1409.862498998642
  time_this_iter_s: 8.461922407150269
  time_total_s: 1409.862498998642
  timestamp: 1594096174
  timesteps_since_restore: 480000
  timesteps_this_iter: 3000
  timesteps_total: 480000
  training_iteration: 160
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1409 s, 160 iter, 480000 ts, 1.07e+03 rew

agent-1: 303.0
agent-2: 285.0
agent-3: 284.0
Sum Reward: 872.0
Avg Reward: 290.6666666666667
Min Reward: 284.0
Max Reward: 303.0
Gini Coefficient: 0.01452599388379205
20:20 Ratio: 1.0669014084507042
Max-min Ratio: 1.0669014084507042
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-29-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 1067.35
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 160
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.728
    dispatch_time_ms: 23.262
    learner:
      cur_lr: 0.001328031998127699
      grad_gnorm: 21.759065628051758
      policy_entropy: 26.134960174560547
      policy_loss: -5.342628002166748
      var_gnorm: 33.05231857299805
      vf_explained_var: -0.1670973300933838
      vf_loss: 18.429515838623047
    num_steps_sampled: 483000
    num_steps_trained: 483000
    wait_time_ms: 70.389
  iterations_since_restore: 161
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1418.4904561042786
  time_this_iter_s: 8.627957105636597
  time_total_s: 1418.4904561042786
  timestamp: 1594096182
  timesteps_since_restore: 483000
  timesteps_this_iter: 3000
  timesteps_total: 483000
  training_iteration: 161
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1418 s, 161 iter, 483000 ts, 1.07e+03 rew

agent-1: 288.0
agent-2: 323.0
agent-3: 296.0
Sum Reward: 907.0
Avg Reward: 302.3333333333333
Min Reward: 288.0
Max Reward: 323.0
Gini Coefficient: 0.025725836089672913
20:20 Ratio: 1.1215277777777777
Max-min Ratio: 1.1215277777777777
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-29-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 1066.07
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 161
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.976
    dispatch_time_ms: 29.892
    learner:
      cur_lr: 0.0013278322294354439
      grad_gnorm: 40.000003814697266
      policy_entropy: 28.277000427246094
      policy_loss: -40.637245178222656
      var_gnorm: 33.07990264892578
      vf_explained_var: 0.6843317747116089
      vf_loss: 27.635910034179688
    num_steps_sampled: 486000
    num_steps_trained: 486000
    wait_time_ms: 44.727
  iterations_since_restore: 162
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1426.9131200313568
  time_this_iter_s: 8.422663927078247
  time_total_s: 1426.9131200313568
  timestamp: 1594096191
  timesteps_since_restore: 486000
  timesteps_this_iter: 3000
  timesteps_total: 486000
  training_iteration: 162
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1426 s, 162 iter, 486000 ts, 1.07e+03 rew

agent-1: 277.0
agent-2: 270.0
agent-3: 287.0
Sum Reward: 834.0
Avg Reward: 278.0
Min Reward: 270.0
Max Reward: 287.0
Gini Coefficient: 0.013589128697042365
20:20 Ratio: 1.0629629629629629
Max-min Ratio: 1.0629629629629629
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-29-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 1063.01
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 162
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.913
    dispatch_time_ms: 40.568
    learner:
      cur_lr: 0.001327632344327867
      grad_gnorm: 40.000003814697266
      policy_entropy: 21.740049362182617
      policy_loss: -21.45257568359375
      var_gnorm: 33.0052490234375
      vf_explained_var: -0.14960885047912598
      vf_loss: 19.76490592956543
    num_steps_sampled: 489000
    num_steps_trained: 489000
    wait_time_ms: 36.683
  iterations_since_restore: 163
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1435.0350596904755
  time_this_iter_s: 8.121939659118652
  time_total_s: 1435.0350596904755
  timestamp: 1594096199
  timesteps_since_restore: 489000
  timesteps_this_iter: 3000
  timesteps_total: 489000
  training_iteration: 163
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1435 s, 163 iter, 489000 ts, 1.06e+03 rew

agent-1: 244.0
agent-2: 168.0
agent-3: 170.0
Sum Reward: 582.0
Avg Reward: 194.0
Min Reward: 168.0
Max Reward: 244.0
Gini Coefficient: 0.08705612829324169
20:20 Ratio: 1.4523809523809523
Max-min Ratio: 1.4523809523809523
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-30-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 1059.27
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 163
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.406
    dispatch_time_ms: 36.852
    learner:
      cur_lr: 0.001327432575635612
      grad_gnorm: 38.75262451171875
      policy_entropy: 23.406036376953125
      policy_loss: 7.581193447113037
      var_gnorm: 33.024925231933594
      vf_explained_var: 0.3871268630027771
      vf_loss: 11.581138610839844
    num_steps_sampled: 492000
    num_steps_trained: 492000
    wait_time_ms: 61.202
  iterations_since_restore: 164
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1443.4247257709503
  time_this_iter_s: 8.389666080474854
  time_total_s: 1443.4247257709503
  timestamp: 1594096207
  timesteps_since_restore: 492000
  timesteps_this_iter: 3000
  timesteps_total: 492000
  training_iteration: 164
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1443 s, 164 iter, 492000 ts, 1.06e+03 rew

agent-1: 278.0
agent-2: 266.0
agent-3: 264.0
Sum Reward: 808.0
Avg Reward: 269.3333333333333
Min Reward: 264.0
Max Reward: 278.0
Gini Coefficient: 0.01155115511551155
20:20 Ratio: 1.053030303030303
Max-min Ratio: 1.053030303030303
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-30-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 1056.95
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 164
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.748
    dispatch_time_ms: 43.781
    learner:
      cur_lr: 0.001327232806943357
      grad_gnorm: 40.000003814697266
      policy_entropy: 18.401580810546875
      policy_loss: 12.797723770141602
      var_gnorm: 33.03760528564453
      vf_explained_var: -0.04205667972564697
      vf_loss: 19.116268157958984
    num_steps_sampled: 495000
    num_steps_trained: 495000
    wait_time_ms: 34.395
  iterations_since_restore: 165
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1451.878092288971
  time_this_iter_s: 8.45336651802063
  time_total_s: 1451.878092288971
  timestamp: 1594096216
  timesteps_since_restore: 495000
  timesteps_this_iter: 3000
  timesteps_total: 495000
  training_iteration: 165
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1451 s, 165 iter, 495000 ts, 1.06e+03 rew

agent-1: 298.0
agent-2: 318.0
agent-3: 264.0
Sum Reward: 880.0
Avg Reward: 293.3333333333333
Min Reward: 264.0
Max Reward: 318.0
Gini Coefficient: 0.04090909090909091
20:20 Ratio: 1.2045454545454546
Max-min Ratio: 1.2045454545454546
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-30-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 1054.47
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 165
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.865
    dispatch_time_ms: 27.728
    learner:
      cur_lr: 0.001327033038251102
      grad_gnorm: 39.999996185302734
      policy_entropy: 15.874210357666016
      policy_loss: 12.787866592407227
      var_gnorm: 33.06859588623047
      vf_explained_var: -0.01999223232269287
      vf_loss: 36.77861785888672
    num_steps_sampled: 498000
    num_steps_trained: 498000
    wait_time_ms: 50.135
  iterations_since_restore: 166
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1459.9955942630768
  time_this_iter_s: 8.117501974105835
  time_total_s: 1459.9955942630768
  timestamp: 1594096224
  timesteps_since_restore: 498000
  timesteps_this_iter: 3000
  timesteps_total: 498000
  training_iteration: 166
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1459 s, 166 iter, 498000 ts, 1.05e+03 rew

agent-1: 314.0
agent-2: 290.0
agent-3: 273.0
Sum Reward: 877.0
Avg Reward: 292.3333333333333
Min Reward: 273.0
Max Reward: 314.0
Gini Coefficient: 0.031166856708475865
20:20 Ratio: 1.15018315018315
Max-min Ratio: 1.15018315018315
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-30-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 1052.02
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 166
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.2
    dispatch_time_ms: 36.878
    learner:
      cur_lr: 0.0013268331531435251
      grad_gnorm: 7.474058628082275
      policy_entropy: 21.223134994506836
      policy_loss: -0.5853328704833984
      var_gnorm: 33.0982666015625
      vf_explained_var: 0.15886807441711426
      vf_loss: 42.15449523925781
    num_steps_sampled: 501000
    num_steps_trained: 501000
    wait_time_ms: 38.567
  iterations_since_restore: 167
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1468.1451201438904
  time_this_iter_s: 8.149525880813599
  time_total_s: 1468.1451201438904
  timestamp: 1594096232
  timesteps_since_restore: 501000
  timesteps_this_iter: 3000
  timesteps_total: 501000
  training_iteration: 167
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1468 s, 167 iter, 501000 ts, 1.05e+03 rew

agent-1: 288.0
agent-2: 223.0
agent-3: 242.0
Sum Reward: 753.0
Avg Reward: 251.0
Min Reward: 223.0
Max Reward: 288.0
Gini Coefficient: 0.05754758742806552
20:20 Ratio: 1.2914798206278026
Max-min Ratio: 1.2914798206278026
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-30-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 1048.05
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 167
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.679
    dispatch_time_ms: 34.807
    learner:
      cur_lr: 0.00132663338445127
      grad_gnorm: 28.188352584838867
      policy_entropy: 28.140201568603516
      policy_loss: 6.172843933105469
      var_gnorm: 33.06869888305664
      vf_explained_var: 0.06320440769195557
      vf_loss: 9.489250183105469
    num_steps_sampled: 504000
    num_steps_trained: 504000
    wait_time_ms: 41.859
  iterations_since_restore: 168
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1476.4268202781677
  time_this_iter_s: 8.281700134277344
  time_total_s: 1476.4268202781677
  timestamp: 1594096240
  timesteps_since_restore: 504000
  timesteps_this_iter: 3000
  timesteps_total: 504000
  training_iteration: 168
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1476 s, 168 iter, 504000 ts, 1.05e+03 rew

agent-1: 288.0
agent-2: 281.0
agent-3: 275.0
Sum Reward: 844.0
Avg Reward: 281.3333333333333
Min Reward: 275.0
Max Reward: 288.0
Gini Coefficient: 0.010268562401263823
20:20 Ratio: 1.0472727272727274
Max-min Ratio: 1.0472727272727274
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-30-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 1044.74
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 168
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.983
    dispatch_time_ms: 27.85
    learner:
      cur_lr: 0.001326433615759015
      grad_gnorm: 40.000003814697266
      policy_entropy: 30.919517517089844
      policy_loss: -26.271175384521484
      var_gnorm: 33.1400146484375
      vf_explained_var: 0.3812497854232788
      vf_loss: 24.234676361083984
    num_steps_sampled: 507000
    num_steps_trained: 507000
    wait_time_ms: 50.319
  iterations_since_restore: 169
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1484.612429857254
  time_this_iter_s: 8.185609579086304
  time_total_s: 1484.612429857254
  timestamp: 1594096249
  timesteps_since_restore: 507000
  timesteps_this_iter: 3000
  timesteps_total: 507000
  training_iteration: 169
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1484 s, 169 iter, 507000 ts, 1.04e+03 rew

agent-1: 248.0
agent-2: 291.0
agent-3: 242.0
Sum Reward: 781.0
Avg Reward: 260.3333333333333
Min Reward: 242.0
Max Reward: 291.0
Gini Coefficient: 0.04182671788305591
20:20 Ratio: 1.2024793388429753
Max-min Ratio: 1.2024793388429753
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-30-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 1041.08
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 169
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.409
    dispatch_time_ms: 22.441
    learner:
      cur_lr: 0.00132623384706676
      grad_gnorm: 40.0
      policy_entropy: 19.054750442504883
      policy_loss: -3.919902801513672
      var_gnorm: 33.114871978759766
      vf_explained_var: 0.14460664987564087
      vf_loss: 35.724185943603516
    num_steps_sampled: 510000
    num_steps_trained: 510000
    wait_time_ms: 53.893
  iterations_since_restore: 170
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1492.7165231704712
  time_this_iter_s: 8.104093313217163
  time_total_s: 1492.7165231704712
  timestamp: 1594096257
  timesteps_since_restore: 510000
  timesteps_this_iter: 3000
  timesteps_total: 510000
  training_iteration: 170
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1492 s, 170 iter, 510000 ts, 1.04e+03 rew

agent-1: 278.0
agent-2: 240.0
agent-3: 222.0
Sum Reward: 740.0
Avg Reward: 246.66666666666666
Min Reward: 222.0
Max Reward: 278.0
Gini Coefficient: 0.05045045045045045
20:20 Ratio: 1.2522522522522523
Max-min Ratio: 1.2522522522522523
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-31-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 1036.44
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 170
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.439
    dispatch_time_ms: 26.912
    learner:
      cur_lr: 0.0013260339619591832
      grad_gnorm: 40.0
      policy_entropy: 25.785167694091797
      policy_loss: 9.834493637084961
      var_gnorm: 33.08799362182617
      vf_explained_var: 0.10090911388397217
      vf_loss: 12.730203628540039
    num_steps_sampled: 513000
    num_steps_trained: 513000
    wait_time_ms: 60.417
  iterations_since_restore: 171
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1500.747067451477
  time_this_iter_s: 8.03054428100586
  time_total_s: 1500.747067451477
  timestamp: 1594096265
  timesteps_since_restore: 513000
  timesteps_this_iter: 3000
  timesteps_total: 513000
  training_iteration: 171
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1500 s, 171 iter, 513000 ts, 1.04e+03 rew

agent-1: 194.0
agent-2: 239.0
agent-3: 248.0
Sum Reward: 681.0
Avg Reward: 227.0
Min Reward: 194.0
Max Reward: 248.0
Gini Coefficient: 0.05286343612334802
20:20 Ratio: 1.2783505154639174
Max-min Ratio: 1.2783505154639174
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-31-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 1031.04
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 171
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.795
    dispatch_time_ms: 24.715
    learner:
      cur_lr: 0.0013258341932669282
      grad_gnorm: 40.0
      policy_entropy: 23.26215934753418
      policy_loss: 16.41896629333496
      var_gnorm: 33.086849212646484
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 19.141963958740234
    num_steps_sampled: 516000
    num_steps_trained: 516000
    wait_time_ms: 57.119
  iterations_since_restore: 172
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1508.9042451381683
  time_this_iter_s: 8.157177686691284
  time_total_s: 1508.9042451381683
  timestamp: 1594096273
  timesteps_since_restore: 516000
  timesteps_this_iter: 3000
  timesteps_total: 516000
  training_iteration: 172
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1508 s, 172 iter, 516000 ts, 1.03e+03 rew

agent-1: 234.0
agent-2: 202.0
agent-3: 241.0
Sum Reward: 677.0
Avg Reward: 225.66666666666666
Min Reward: 202.0
Max Reward: 241.0
Gini Coefficient: 0.03840472673559823
20:20 Ratio: 1.193069306930693
Max-min Ratio: 1.193069306930693
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-31-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 1025.8
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 172
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.613
    dispatch_time_ms: 22.395
    learner:
      cur_lr: 0.0013256344245746732
      grad_gnorm: 24.98758888244629
      policy_entropy: 28.4578914642334
      policy_loss: 5.955966949462891
      var_gnorm: 33.07914733886719
      vf_explained_var: 0.0
      vf_loss: 21.866167068481445
    num_steps_sampled: 519000
    num_steps_trained: 519000
    wait_time_ms: 49.436
  iterations_since_restore: 173
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1516.9389445781708
  time_this_iter_s: 8.034699440002441
  time_total_s: 1516.9389445781708
  timestamp: 1594096281
  timesteps_since_restore: 519000
  timesteps_this_iter: 3000
  timesteps_total: 519000
  training_iteration: 173
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1516 s, 173 iter, 519000 ts, 1.03e+03 rew

agent-1: 195.0
agent-2: 266.0
agent-3: 226.0
Sum Reward: 687.0
Avg Reward: 229.0
Min Reward: 195.0
Max Reward: 266.0
Gini Coefficient: 0.06889859291606017
20:20 Ratio: 1.3641025641025641
Max-min Ratio: 1.3641025641025641
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-31-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 1020.99
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 173
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.48
    dispatch_time_ms: 33.536
    learner:
      cur_lr: 0.0013254346558824182
      grad_gnorm: 39.999996185302734
      policy_entropy: 21.68715476989746
      policy_loss: -9.404650688171387
      var_gnorm: 33.076595306396484
      vf_explained_var: 0.0
      vf_loss: 16.51651382446289
    num_steps_sampled: 522000
    num_steps_trained: 522000
    wait_time_ms: 55.054
  iterations_since_restore: 174
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1525.1296741962433
  time_this_iter_s: 8.19072961807251
  time_total_s: 1525.1296741962433
  timestamp: 1594096289
  timesteps_since_restore: 522000
  timesteps_this_iter: 3000
  timesteps_total: 522000
  training_iteration: 174
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1525 s, 174 iter, 522000 ts, 1.02e+03 rew

agent-1: 209.0
agent-2: 277.0
agent-3: 168.0
Sum Reward: 654.0
Avg Reward: 218.0
Min Reward: 168.0
Max Reward: 277.0
Gini Coefficient: 0.1111111111111111
20:20 Ratio: 1.6488095238095237
Max-min Ratio: 1.6488095238095237
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-31-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 1015.72
  episode_reward_min: 530.0
  episodes_this_iter: 1
  episodes_total: 174
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.963
    dispatch_time_ms: 24.432
    learner:
      cur_lr: 0.0013252347707748413
      grad_gnorm: 40.000003814697266
      policy_entropy: 16.134836196899414
      policy_loss: -8.710284233093262
      var_gnorm: 33.05634689331055
      vf_explained_var: 0.0
      vf_loss: 24.816484451293945
    num_steps_sampled: 525000
    num_steps_trained: 525000
    wait_time_ms: 60.341
  iterations_since_restore: 175
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1533.3532090187073
  time_this_iter_s: 8.22353482246399
  time_total_s: 1533.3532090187073
  timestamp: 1594096298
  timesteps_since_restore: 525000
  timesteps_this_iter: 3000
  timesteps_total: 525000
  training_iteration: 175
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1533 s, 175 iter, 525000 ts, 1.02e+03 rew

agent-1: 180.0
agent-2: 175.0
agent-3: 151.0
Sum Reward: 506.0
Avg Reward: 168.66666666666666
Min Reward: 151.0
Max Reward: 180.0
Gini Coefficient: 0.03820816864295125
20:20 Ratio: 1.1920529801324504
Max-min Ratio: 1.1920529801324504
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-31-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 1008.43
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 175
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.669
    dispatch_time_ms: 26.389
    learner:
      cur_lr: 0.0013250350020825863
      grad_gnorm: 22.355676651000977
      policy_entropy: 18.32436752319336
      policy_loss: 5.884795188903809
      var_gnorm: 33.01997375488281
      vf_explained_var: 0.09003150463104248
      vf_loss: 13.734241485595703
    num_steps_sampled: 528000
    num_steps_trained: 528000
    wait_time_ms: 46.513
  iterations_since_restore: 176
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1541.2366983890533
  time_this_iter_s: 7.883489370346069
  time_total_s: 1541.2366983890533
  timestamp: 1594096306
  timesteps_since_restore: 528000
  timesteps_this_iter: 3000
  timesteps_total: 528000
  training_iteration: 176
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1541 s, 176 iter, 528000 ts, 1.01e+03 rew

agent-1: 172.0
agent-2: 200.0
agent-3: 222.0
Sum Reward: 594.0
Avg Reward: 198.0
Min Reward: 172.0
Max Reward: 222.0
Gini Coefficient: 0.05611672278338945
20:20 Ratio: 1.2906976744186047
Max-min Ratio: 1.2906976744186047
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-31-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 1002.01
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 176
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.069
    dispatch_time_ms: 55.476
    learner:
      cur_lr: 0.0013248352333903313
      grad_gnorm: 27.801311492919922
      policy_entropy: 21.949499130249023
      policy_loss: 1.216329574584961
      var_gnorm: 33.019840240478516
      vf_explained_var: 0.1334516406059265
      vf_loss: 19.211091995239258
    num_steps_sampled: 531000
    num_steps_trained: 531000
    wait_time_ms: 27.83
  iterations_since_restore: 177
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1554.3175597190857
  time_this_iter_s: 13.080861330032349
  time_total_s: 1554.3175597190857
  timestamp: 1594096319
  timesteps_since_restore: 531000
  timesteps_this_iter: 3000
  timesteps_total: 531000
  training_iteration: 177
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1554 s, 177 iter, 531000 ts, 1e+03 rew

agent-1: 264.0
agent-2: 184.0
agent-3: 204.0
Sum Reward: 652.0
Avg Reward: 217.33333333333334
Min Reward: 184.0
Max Reward: 264.0
Gini Coefficient: 0.081799591002045
20:20 Ratio: 1.434782608695652
Max-min Ratio: 1.434782608695652
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-32-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 996.31
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 177
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.027
    dispatch_time_ms: 31.099
    learner:
      cur_lr: 0.0013246353482827544
      grad_gnorm: 21.071640014648438
      policy_entropy: 16.063566207885742
      policy_loss: -1.0525654554367065
      var_gnorm: 33.091773986816406
      vf_explained_var: 0.08559763431549072
      vf_loss: 6.697695732116699
    num_steps_sampled: 534000
    num_steps_trained: 534000
    wait_time_ms: 61.96
  iterations_since_restore: 178
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1582.6511933803558
  time_this_iter_s: 28.33363366127014
  time_total_s: 1582.6511933803558
  timestamp: 1594096347
  timesteps_since_restore: 534000
  timesteps_this_iter: 3000
  timesteps_total: 534000
  training_iteration: 178
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1582 s, 178 iter, 534000 ts, 996 rew

agent-1: 289.0
agent-2: 255.0
agent-3: 276.0
Sum Reward: 820.0
Avg Reward: 273.3333333333333
Min Reward: 255.0
Max Reward: 289.0
Gini Coefficient: 0.027642276422764227
20:20 Ratio: 1.1333333333333333
Max-min Ratio: 1.1333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-32-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 992.23
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 178
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.375
    dispatch_time_ms: 25.241
    learner:
      cur_lr: 0.0013244355795904994
      grad_gnorm: 30.839101791381836
      policy_entropy: 12.808025360107422
      policy_loss: 1.3667614459991455
      var_gnorm: 33.1644401550293
      vf_explained_var: 0.0894574522972107
      vf_loss: 22.461294174194336
    num_steps_sampled: 537000
    num_steps_trained: 537000
    wait_time_ms: 56.088
  iterations_since_restore: 179
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1590.7012898921967
  time_this_iter_s: 8.05009651184082
  time_total_s: 1590.7012898921967
  timestamp: 1594096355
  timesteps_since_restore: 537000
  timesteps_this_iter: 3000
  timesteps_total: 537000
  training_iteration: 179
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1590 s, 179 iter, 537000 ts, 992 rew

agent-1: 329.0
agent-2: 315.0
agent-3: 323.0
Sum Reward: 967.0
Avg Reward: 322.3333333333333
Min Reward: 315.0
Max Reward: 329.0
Gini Coefficient: 0.009651844191658049
20:20 Ratio: 1.0444444444444445
Max-min Ratio: 1.0444444444444445
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-32-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 991.29
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 179
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.594
    dispatch_time_ms: 22.81
    learner:
      cur_lr: 0.0013242358108982444
      grad_gnorm: 40.000003814697266
      policy_entropy: 18.725433349609375
      policy_loss: 18.521163940429688
      var_gnorm: 33.26195526123047
      vf_explained_var: -1.0
      vf_loss: 20.92685890197754
    num_steps_sampled: 540000
    num_steps_trained: 540000
    wait_time_ms: 56.893
  iterations_since_restore: 180
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1599.0057590007782
  time_this_iter_s: 8.304469108581543
  time_total_s: 1599.0057590007782
  timestamp: 1594096363
  timesteps_since_restore: 540000
  timesteps_this_iter: 3000
  timesteps_total: 540000
  training_iteration: 180
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1599 s, 180 iter, 540000 ts, 991 rew

agent-1: 360.0
agent-2: 307.0
agent-3: 283.0
Sum Reward: 950.0
Avg Reward: 316.6666666666667
Min Reward: 283.0
Max Reward: 360.0
Gini Coefficient: 0.05403508771929825
20:20 Ratio: 1.2720848056537102
Max-min Ratio: 1.2720848056537102
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-32-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 991.18
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 180
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.638
    dispatch_time_ms: 18.751
    learner:
      cur_lr: 0.0013240360422059894
      grad_gnorm: 9.447877883911133
      policy_entropy: 25.765220642089844
      policy_loss: 1.3495442867279053
      var_gnorm: 33.32292175292969
      vf_explained_var: 0.29839104413986206
      vf_loss: 5.83234167098999
    num_steps_sampled: 543000
    num_steps_trained: 543000
    wait_time_ms: 60.44
  iterations_since_restore: 181
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1607.127442598343
  time_this_iter_s: 8.121683597564697
  time_total_s: 1607.127442598343
  timestamp: 1594096372
  timesteps_since_restore: 543000
  timesteps_this_iter: 3000
  timesteps_total: 543000
  training_iteration: 181
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1607 s, 181 iter, 543000 ts, 991 rew

agent-1: 252.0
agent-2: 283.0
agent-3: 259.0
Sum Reward: 794.0
Avg Reward: 264.6666666666667
Min Reward: 252.0
Max Reward: 283.0
Gini Coefficient: 0.026028547439126783
20:20 Ratio: 1.123015873015873
Max-min Ratio: 1.123015873015873
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-33-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 988.73
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 181
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.956
    dispatch_time_ms: 31.991
    learner:
      cur_lr: 0.0013238361570984125
      grad_gnorm: 40.000003814697266
      policy_entropy: 22.872028350830078
      policy_loss: -22.664827346801758
      var_gnorm: 33.30900955200195
      vf_explained_var: 0.0
      vf_loss: 15.091392517089844
    num_steps_sampled: 546000
    num_steps_trained: 546000
    wait_time_ms: 52.471
  iterations_since_restore: 182
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1615.388290643692
  time_this_iter_s: 8.260848045349121
  time_total_s: 1615.388290643692
  timestamp: 1594096380
  timesteps_since_restore: 546000
  timesteps_this_iter: 3000
  timesteps_total: 546000
  training_iteration: 182
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1615 s, 182 iter, 546000 ts, 989 rew

agent-1: 266.0
agent-2: 248.0
agent-3: 198.0
Sum Reward: 712.0
Avg Reward: 237.33333333333334
Min Reward: 198.0
Max Reward: 266.0
Gini Coefficient: 0.06367041198501873
20:20 Ratio: 1.3434343434343434
Max-min Ratio: 1.3434343434343434
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-33-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 984.72
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 182
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.784
    dispatch_time_ms: 29.298
    learner:
      cur_lr: 0.0013236363884061575
      grad_gnorm: 15.865026473999023
      policy_entropy: 16.83000373840332
      policy_loss: -6.341744422912598
      var_gnorm: 33.260826110839844
      vf_explained_var: -0.32655882835388184
      vf_loss: 3.2818307876586914
    num_steps_sampled: 549000
    num_steps_trained: 549000
    wait_time_ms: 55.941
  iterations_since_restore: 183
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1623.3983407020569
  time_this_iter_s: 8.010050058364868
  time_total_s: 1623.3983407020569
  timestamp: 1594096388
  timesteps_since_restore: 549000
  timesteps_this_iter: 3000
  timesteps_total: 549000
  training_iteration: 183
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1623 s, 183 iter, 549000 ts, 985 rew

agent-1: 171.0
agent-2: 220.0
agent-3: 210.0
Sum Reward: 601.0
Avg Reward: 200.33333333333334
Min Reward: 171.0
Max Reward: 220.0
Gini Coefficient: 0.05435385468663339
20:20 Ratio: 1.286549707602339
Max-min Ratio: 1.286549707602339
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-33-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 978.72
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 183
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.604
    dispatch_time_ms: 29.359
    learner:
      cur_lr: 0.0013234366197139025
      grad_gnorm: 40.0
      policy_entropy: 21.22612953186035
      policy_loss: -16.794742584228516
      var_gnorm: 33.2458610534668
      vf_explained_var: 0.24941527843475342
      vf_loss: 16.58873176574707
    num_steps_sampled: 552000
    num_steps_trained: 552000
    wait_time_ms: 48.189
  iterations_since_restore: 184
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1631.5413038730621
  time_this_iter_s: 8.142963171005249
  time_total_s: 1631.5413038730621
  timestamp: 1594096396
  timesteps_since_restore: 552000
  timesteps_this_iter: 3000
  timesteps_total: 552000
  training_iteration: 184
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1631 s, 184 iter, 552000 ts, 979 rew

agent-1: 240.0
agent-2: 176.0
agent-3: 227.0
Sum Reward: 643.0
Avg Reward: 214.33333333333334
Min Reward: 176.0
Max Reward: 240.0
Gini Coefficient: 0.06635562467599793
20:20 Ratio: 1.3636363636363635
Max-min Ratio: 1.3636363636363635
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-33-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 972.82
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 184
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.44
    dispatch_time_ms: 25.893
    learner:
      cur_lr: 0.0013232368510216475
      grad_gnorm: 40.0
      policy_entropy: 27.29900360107422
      policy_loss: -1.998223066329956
      var_gnorm: 33.331329345703125
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 29.22262191772461
    num_steps_sampled: 555000
    num_steps_trained: 555000
    wait_time_ms: 61.103
  iterations_since_restore: 185
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1639.794422864914
  time_this_iter_s: 8.253118991851807
  time_total_s: 1639.794422864914
  timestamp: 1594096404
  timesteps_since_restore: 555000
  timesteps_this_iter: 3000
  timesteps_total: 555000
  training_iteration: 185
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1639 s, 185 iter, 555000 ts, 973 rew

agent-1: 209.0
agent-2: 207.0
agent-3: 168.0
Sum Reward: 584.0
Avg Reward: 194.66666666666666
Min Reward: 168.0
Max Reward: 209.0
Gini Coefficient: 0.04680365296803653
20:20 Ratio: 1.244047619047619
Max-min Ratio: 1.244047619047619
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-33-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 967.15
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 185
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.077
    dispatch_time_ms: 29.02
    learner:
      cur_lr: 0.0013230369659140706
      grad_gnorm: 40.0
      policy_entropy: 24.773189544677734
      policy_loss: -15.35862922668457
      var_gnorm: 33.3043098449707
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 16.101232528686523
    num_steps_sampled: 558000
    num_steps_trained: 558000
    wait_time_ms: 56.5
  iterations_since_restore: 186
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1647.8840174674988
  time_this_iter_s: 8.089594602584839
  time_total_s: 1647.8840174674988
  timestamp: 1594096413
  timesteps_since_restore: 558000
  timesteps_this_iter: 3000
  timesteps_total: 558000
  training_iteration: 186
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1647 s, 186 iter, 558000 ts, 967 rew

agent-1: 180.0
agent-2: 186.0
agent-3: 212.0
Sum Reward: 578.0
Avg Reward: 192.66666666666666
Min Reward: 180.0
Max Reward: 212.0
Gini Coefficient: 0.03690888119953864
20:20 Ratio: 1.1777777777777778
Max-min Ratio: 1.1777777777777778
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-33-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 961.6
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 186
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.839
    dispatch_time_ms: 25.001
    learner:
      cur_lr: 0.0013228371972218156
      grad_gnorm: 39.999996185302734
      policy_entropy: 25.318904876708984
      policy_loss: 32.08675765991211
      var_gnorm: 33.26261520385742
      vf_explained_var: 0.19494038820266724
      vf_loss: 35.629920959472656
    num_steps_sampled: 561000
    num_steps_trained: 561000
    wait_time_ms: 54.805
  iterations_since_restore: 187
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1655.7547821998596
  time_this_iter_s: 7.87076473236084
  time_total_s: 1655.7547821998596
  timestamp: 1594096420
  timesteps_since_restore: 561000
  timesteps_this_iter: 3000
  timesteps_total: 561000
  training_iteration: 187
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1655 s, 187 iter, 561000 ts, 962 rew

agent-1: 193.0
agent-2: 206.0
agent-3: 160.0
Sum Reward: 559.0
Avg Reward: 186.33333333333334
Min Reward: 160.0
Max Reward: 206.0
Gini Coefficient: 0.054859868813357186
20:20 Ratio: 1.2875
Max-min Ratio: 1.2875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-33-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 957.83
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 187
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.362
    dispatch_time_ms: 28.198
    learner:
      cur_lr: 0.0013226374285295606
      grad_gnorm: 40.0
      policy_entropy: 27.031038284301758
      policy_loss: -11.710012435913086
      var_gnorm: 33.281707763671875
      vf_explained_var: -0.19549131393432617
      vf_loss: 18.266273498535156
    num_steps_sampled: 564000
    num_steps_trained: 564000
    wait_time_ms: 54.702
  iterations_since_restore: 188
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1663.7912800312042
  time_this_iter_s: 8.036497831344604
  time_total_s: 1663.7912800312042
  timestamp: 1594096429
  timesteps_since_restore: 564000
  timesteps_this_iter: 3000
  timesteps_total: 564000
  training_iteration: 188
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1663 s, 188 iter, 564000 ts, 958 rew

agent-1: 197.0
agent-2: 230.0
agent-3: 239.0
Sum Reward: 666.0
Avg Reward: 222.0
Min Reward: 197.0
Max Reward: 239.0
Gini Coefficient: 0.042042042042042045
20:20 Ratio: 1.2131979695431472
Max-min Ratio: 1.2131979695431472
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-33-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 955.5
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 188
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.598
    dispatch_time_ms: 22.134
    learner:
      cur_lr: 0.0013224375434219837
      grad_gnorm: 40.0
      policy_entropy: 27.171606063842773
      policy_loss: 13.014717102050781
      var_gnorm: 33.348411560058594
      vf_explained_var: 0.24323821067810059
      vf_loss: 44.04207229614258
    num_steps_sampled: 567000
    num_steps_trained: 567000
    wait_time_ms: 65.291
  iterations_since_restore: 189
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1672.1350572109222
  time_this_iter_s: 8.343777179718018
  time_total_s: 1672.1350572109222
  timestamp: 1594096437
  timesteps_since_restore: 567000
  timesteps_this_iter: 3000
  timesteps_total: 567000
  training_iteration: 189
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1672 s, 189 iter, 567000 ts, 956 rew

agent-1: 235.0
agent-2: 242.0
agent-3: 202.0
Sum Reward: 679.0
Avg Reward: 226.33333333333334
Min Reward: 202.0
Max Reward: 242.0
Gini Coefficient: 0.039273441335297005
20:20 Ratio: 1.198019801980198
Max-min Ratio: 1.198019801980198
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-34-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 952.26
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 189
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.791
    dispatch_time_ms: 20.17
    learner:
      cur_lr: 0.0013222377747297287
      grad_gnorm: 31.81474494934082
      policy_entropy: 25.038393020629883
      policy_loss: -0.5294146537780762
      var_gnorm: 33.41489028930664
      vf_explained_var: 0.19413262605667114
      vf_loss: 27.50888442993164
    num_steps_sampled: 570000
    num_steps_trained: 570000
    wait_time_ms: 51.756
  iterations_since_restore: 190
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1680.4965584278107
  time_this_iter_s: 8.361501216888428
  time_total_s: 1680.4965584278107
  timestamp: 1594096445
  timesteps_since_restore: 570000
  timesteps_this_iter: 3000
  timesteps_total: 570000
  training_iteration: 190
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1680 s, 190 iter, 570000 ts, 952 rew

agent-1: 204.0
agent-2: 274.0
agent-3: 299.0
Sum Reward: 777.0
Avg Reward: 259.0
Min Reward: 204.0
Max Reward: 299.0
Gini Coefficient: 0.08151008151008152
20:20 Ratio: 1.4656862745098038
Max-min Ratio: 1.4656862745098038
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-34-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 950.21
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 190
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.372
    dispatch_time_ms: 28.578
    learner:
      cur_lr: 0.0013220380060374737
      grad_gnorm: 36.062294006347656
      policy_entropy: 19.776525497436523
      policy_loss: 20.24881362915039
      var_gnorm: 33.5139045715332
      vf_explained_var: -0.479877233505249
      vf_loss: 15.622986793518066
    num_steps_sampled: 573000
    num_steps_trained: 573000
    wait_time_ms: 62.744
  iterations_since_restore: 191
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1689.153071641922
  time_this_iter_s: 8.656513214111328
  time_total_s: 1689.153071641922
  timestamp: 1594096454
  timesteps_since_restore: 573000
  timesteps_this_iter: 3000
  timesteps_total: 573000
  training_iteration: 191
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1689 s, 191 iter, 573000 ts, 950 rew

agent-1: 292.0
agent-2: 283.0
agent-3: 287.0
Sum Reward: 862.0
Avg Reward: 287.3333333333333
Min Reward: 283.0
Max Reward: 292.0
Gini Coefficient: 0.0069605568445475635
20:20 Ratio: 1.0318021201413428
Max-min Ratio: 1.0318021201413428
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-34-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 948.5
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 191
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.549
    dispatch_time_ms: 27.835
    learner:
      cur_lr: 0.0013218382373452187
      grad_gnorm: 2.742732524871826
      policy_entropy: 14.340935707092285
      policy_loss: 2.943533420562744
      var_gnorm: 33.63528060913086
      vf_explained_var: -0.21675074100494385
      vf_loss: 15.140848159790039
    num_steps_sampled: 576000
    num_steps_trained: 576000
    wait_time_ms: 61.971
  iterations_since_restore: 192
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1698.023518562317
  time_this_iter_s: 8.870446920394897
  time_total_s: 1698.023518562317
  timestamp: 1594096463
  timesteps_since_restore: 576000
  timesteps_this_iter: 3000
  timesteps_total: 576000
  training_iteration: 192
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1698 s, 192 iter, 576000 ts, 948 rew

agent-1: 340.0
agent-2: 303.0
agent-3: 353.0
Sum Reward: 996.0
Avg Reward: 332.0
Min Reward: 303.0
Max Reward: 353.0
Gini Coefficient: 0.03346720214190094
20:20 Ratio: 1.165016501650165
Max-min Ratio: 1.165016501650165
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-34-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 947.32
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 192
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.862
    dispatch_time_ms: 29.998
    learner:
      cur_lr: 0.0013216383522376418
      grad_gnorm: 40.0
      policy_entropy: 23.200519561767578
      policy_loss: 11.801057815551758
      var_gnorm: 33.76945495605469
      vf_explained_var: 0.1981518268585205
      vf_loss: 48.42267608642578
    num_steps_sampled: 579000
    num_steps_trained: 579000
    wait_time_ms: 49.342
  iterations_since_restore: 193
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1706.3338553905487
  time_this_iter_s: 8.310336828231812
  time_total_s: 1706.3338553905487
  timestamp: 1594096471
  timesteps_since_restore: 579000
  timesteps_this_iter: 3000
  timesteps_total: 579000
  training_iteration: 193
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1706 s, 193 iter, 579000 ts, 947 rew

agent-1: 297.0
agent-2: 313.0
agent-3: 272.0
Sum Reward: 882.0
Avg Reward: 294.0
Min Reward: 272.0
Max Reward: 313.0
Gini Coefficient: 0.030990173847316706
20:20 Ratio: 1.150735294117647
Max-min Ratio: 1.150735294117647
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-34-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 943.72
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 193
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.499
    dispatch_time_ms: 28.203
    learner:
      cur_lr: 0.0013214385835453868
      grad_gnorm: 39.999996185302734
      policy_entropy: 22.649599075317383
      policy_loss: -17.463029861450195
      var_gnorm: 33.77958679199219
      vf_explained_var: 0.0810537338256836
      vf_loss: 27.532695770263672
    num_steps_sampled: 582000
    num_steps_trained: 582000
    wait_time_ms: 54.033
  iterations_since_restore: 194
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1714.5576615333557
  time_this_iter_s: 8.223806142807007
  time_total_s: 1714.5576615333557
  timestamp: 1594096479
  timesteps_since_restore: 582000
  timesteps_this_iter: 3000
  timesteps_total: 582000
  training_iteration: 194
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1714 s, 194 iter, 582000 ts, 944 rew

agent-1: 214.0
agent-2: 238.0
agent-3: 214.0
Sum Reward: 666.0
Avg Reward: 222.0
Min Reward: 214.0
Max Reward: 238.0
Gini Coefficient: 0.024024024024024024
20:20 Ratio: 1.1121495327102804
Max-min Ratio: 1.1121495327102804
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-34-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 938.75
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 194
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.553
    dispatch_time_ms: 22.389
    learner:
      cur_lr: 0.0013212388148531318
      grad_gnorm: 16.09613037109375
      policy_entropy: 26.025598526000977
      policy_loss: -5.014073371887207
      var_gnorm: 33.732521057128906
      vf_explained_var: 0.610843300819397
      vf_loss: 5.3952789306640625
    num_steps_sampled: 585000
    num_steps_trained: 585000
    wait_time_ms: 52.378
  iterations_since_restore: 195
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1722.568333864212
  time_this_iter_s: 8.010672330856323
  time_total_s: 1722.568333864212
  timestamp: 1594096488
  timesteps_since_restore: 585000
  timesteps_this_iter: 3000
  timesteps_total: 585000
  training_iteration: 195
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1722 s, 195 iter, 585000 ts, 939 rew

agent-1: 192.0
agent-2: 227.0
agent-3: 156.0
Sum Reward: 575.0
Avg Reward: 191.66666666666666
Min Reward: 156.0
Max Reward: 227.0
Gini Coefficient: 0.08231884057971015
20:20 Ratio: 1.455128205128205
Max-min Ratio: 1.455128205128205
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-34-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 932.52
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 195
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.011
    dispatch_time_ms: 33.621
    learner:
      cur_lr: 0.0013210390461608768
      grad_gnorm: 14.051131248474121
      policy_entropy: 28.53736686706543
      policy_loss: 2.8790388107299805
      var_gnorm: 33.78399658203125
      vf_explained_var: 0.21232491731643677
      vf_loss: 26.404428482055664
    num_steps_sampled: 588000
    num_steps_trained: 588000
    wait_time_ms: 31.109
  iterations_since_restore: 196
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1730.5836389064789
  time_this_iter_s: 8.015305042266846
  time_total_s: 1730.5836389064789
  timestamp: 1594096496
  timesteps_since_restore: 588000
  timesteps_this_iter: 3000
  timesteps_total: 588000
  training_iteration: 196
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1730 s, 196 iter, 588000 ts, 933 rew

agent-1: 191.0
agent-2: 232.0
agent-3: 246.0
Sum Reward: 669.0
Avg Reward: 223.0
Min Reward: 191.0
Max Reward: 246.0
Gini Coefficient: 0.05480817140009965
20:20 Ratio: 1.287958115183246
Max-min Ratio: 1.287958115183246
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-35-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 926.48
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 196
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.187
    dispatch_time_ms: 27.706
    learner:
      cur_lr: 0.0013208391610533
      grad_gnorm: 40.0
      policy_entropy: 23.61566925048828
      policy_loss: -8.868577003479004
      var_gnorm: 33.796485900878906
      vf_explained_var: 0.1385243535041809
      vf_loss: 22.128894805908203
    num_steps_sampled: 591000
    num_steps_trained: 591000
    wait_time_ms: 44.124
  iterations_since_restore: 197
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1738.7649500370026
  time_this_iter_s: 8.181311130523682
  time_total_s: 1738.7649500370026
  timestamp: 1594096504
  timesteps_since_restore: 591000
  timesteps_this_iter: 3000
  timesteps_total: 591000
  training_iteration: 197
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1738 s, 197 iter, 591000 ts, 926 rew

agent-1: 174.0
agent-2: 240.0
agent-3: 197.0
Sum Reward: 611.0
Avg Reward: 203.66666666666666
Min Reward: 174.0
Max Reward: 240.0
Gini Coefficient: 0.07201309328968904
20:20 Ratio: 1.3793103448275863
Max-min Ratio: 1.3793103448275863
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-35-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 920.92
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 197
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.154
    dispatch_time_ms: 37.726
    learner:
      cur_lr: 0.0013206393923610449
      grad_gnorm: 38.05146408081055
      policy_entropy: 25.822708129882812
      policy_loss: 16.26422691345215
      var_gnorm: 33.8003044128418
      vf_explained_var: -0.24694406986236572
      vf_loss: 10.683460235595703
    num_steps_sampled: 594000
    num_steps_trained: 594000
    wait_time_ms: 39.762
  iterations_since_restore: 198
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1747.1344978809357
  time_this_iter_s: 8.369547843933105
  time_total_s: 1747.1344978809357
  timestamp: 1594096512
  timesteps_since_restore: 594000
  timesteps_this_iter: 3000
  timesteps_total: 594000
  training_iteration: 198
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1747 s, 198 iter, 594000 ts, 921 rew

agent-1: 246.0
agent-2: 223.0
agent-3: 237.0
Sum Reward: 706.0
Avg Reward: 235.33333333333334
Min Reward: 223.0
Max Reward: 246.0
Gini Coefficient: 0.021718602455146365
20:20 Ratio: 1.1031390134529149
Max-min Ratio: 1.1031390134529149
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-35-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 917.07
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 198
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.415
    dispatch_time_ms: 22.867
    learner:
      cur_lr: 0.0013204396236687899
      grad_gnorm: 40.0
      policy_entropy: 24.43062973022461
      policy_loss: 23.268028259277344
      var_gnorm: 33.885738372802734
      vf_explained_var: 0.17393279075622559
      vf_loss: 44.45070266723633
    num_steps_sampled: 597000
    num_steps_trained: 597000
    wait_time_ms: 60.782
  iterations_since_restore: 199
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1755.4858067035675
  time_this_iter_s: 8.351308822631836
  time_total_s: 1755.4858067035675
  timestamp: 1594096521
  timesteps_since_restore: 597000
  timesteps_this_iter: 3000
  timesteps_total: 597000
  training_iteration: 199
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1755 s, 199 iter, 597000 ts, 917 rew

agent-1: 259.0
agent-2: 289.0
agent-3: 315.0
Sum Reward: 863.0
Avg Reward: 287.6666666666667
Min Reward: 259.0
Max Reward: 315.0
Gini Coefficient: 0.04325994592506759
20:20 Ratio: 1.2162162162162162
Max-min Ratio: 1.2162162162162162
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-35-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 912.5
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 199
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.543
    dispatch_time_ms: 20.164
    learner:
      cur_lr: 0.0013202398549765348
      grad_gnorm: 40.0
      policy_entropy: 24.03556251525879
      policy_loss: 23.085214614868164
      var_gnorm: 34.04861068725586
      vf_explained_var: -0.4946795701980591
      vf_loss: 26.63475799560547
    num_steps_sampled: 600000
    num_steps_trained: 600000
    wait_time_ms: 75.298
  iterations_since_restore: 200
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1764.2490725517273
  time_this_iter_s: 8.76326584815979
  time_total_s: 1764.2490725517273
  timestamp: 1594096529
  timesteps_since_restore: 600000
  timesteps_this_iter: 3000
  timesteps_total: 600000
  training_iteration: 200
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1764 s, 200 iter, 600000 ts, 912 rew

agent-1: 313.0
agent-2: 308.0
agent-3: 320.0
Sum Reward: 941.0
Avg Reward: 313.6666666666667
Min Reward: 308.0
Max Reward: 320.0
Gini Coefficient: 0.008501594048884165
20:20 Ratio: 1.0389610389610389
Max-min Ratio: 1.0389610389610389
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-35-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 909.28
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 200
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.748
    dispatch_time_ms: 29.496
    learner:
      cur_lr: 0.001320039969868958
      grad_gnorm: 29.053909301757812
      policy_entropy: 19.767478942871094
      policy_loss: -15.685546875
      var_gnorm: 34.220245361328125
      vf_explained_var: 0.3258902430534363
      vf_loss: 12.700989723205566
    num_steps_sampled: 603000
    num_steps_trained: 603000
    wait_time_ms: 57.273
  iterations_since_restore: 201
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1773.0237307548523
  time_this_iter_s: 8.774658203125
  time_total_s: 1773.0237307548523
  timestamp: 1594096538
  timesteps_since_restore: 603000
  timesteps_this_iter: 3000
  timesteps_total: 603000
  training_iteration: 201
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1773 s, 201 iter, 603000 ts, 909 rew

agent-1: 335.0
agent-2: 290.0
agent-3: 273.0
Sum Reward: 898.0
Avg Reward: 299.3333333333333
Min Reward: 273.0
Max Reward: 335.0
Gini Coefficient: 0.04602821083890126
20:20 Ratio: 1.2271062271062272
Max-min Ratio: 1.2271062271062272
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-35-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 906.73
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 201
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.331
    dispatch_time_ms: 29.284
    learner:
      cur_lr: 0.001319840201176703
      grad_gnorm: 40.0
      policy_entropy: 27.345468521118164
      policy_loss: -14.857112884521484
      var_gnorm: 34.23875427246094
      vf_explained_var: 0.4024588465690613
      vf_loss: 16.864356994628906
    num_steps_sampled: 606000
    num_steps_trained: 606000
    wait_time_ms: 59.448
  iterations_since_restore: 202
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1781.4180083274841
  time_this_iter_s: 8.394277572631836
  time_total_s: 1781.4180083274841
  timestamp: 1594096547
  timesteps_since_restore: 606000
  timesteps_this_iter: 3000
  timesteps_total: 606000
  training_iteration: 202
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1781 s, 202 iter, 606000 ts, 907 rew

agent-1: 266.0
agent-2: 269.0
agent-3: 222.0
Sum Reward: 757.0
Avg Reward: 252.33333333333334
Min Reward: 222.0
Max Reward: 269.0
Gini Coefficient: 0.041391457507705856
20:20 Ratio: 1.2117117117117118
Max-min Ratio: 1.2117117117117118
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-35-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 903.27
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 202
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.046
    dispatch_time_ms: 36.415
    learner:
      cur_lr: 0.001319640432484448
      grad_gnorm: 40.0
      policy_entropy: 22.96693992614746
      policy_loss: 6.106086730957031
      var_gnorm: 34.281497955322266
      vf_explained_var: 0.5286070108413696
      vf_loss: 25.568214416503906
    num_steps_sampled: 609000
    num_steps_trained: 609000
    wait_time_ms: 49.118
  iterations_since_restore: 203
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1789.9623010158539
  time_this_iter_s: 8.544292688369751
  time_total_s: 1789.9623010158539
  timestamp: 1594096555
  timesteps_since_restore: 609000
  timesteps_this_iter: 3000
  timesteps_total: 609000
  training_iteration: 203
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1789 s, 203 iter, 609000 ts, 903 rew

agent-1: 221.0
agent-2: 261.0
agent-3: 266.0
Sum Reward: 748.0
Avg Reward: 249.33333333333334
Min Reward: 221.0
Max Reward: 266.0
Gini Coefficient: 0.040106951871657755
20:20 Ratio: 1.2036199095022624
Max-min Ratio: 1.2036199095022624
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-36-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 899.69
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 203
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.514
    dispatch_time_ms: 21.069
    learner:
      cur_lr: 0.0013194405473768711
      grad_gnorm: 10.634763717651367
      policy_entropy: 24.616310119628906
      policy_loss: 4.588953018188477
      var_gnorm: 34.388816833496094
      vf_explained_var: -0.06879079341888428
      vf_loss: 29.568883895874023
    num_steps_sampled: 612000
    num_steps_trained: 612000
    wait_time_ms: 74.385
  iterations_since_restore: 204
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1798.425476551056
  time_this_iter_s: 8.463175535202026
  time_total_s: 1798.425476551056
  timestamp: 1594096564
  timesteps_since_restore: 612000
  timesteps_this_iter: 3000
  timesteps_total: 612000
  training_iteration: 204
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1798 s, 204 iter, 612000 ts, 900 rew

agent-1: 276.0
agent-2: 243.0
agent-3: 300.0
Sum Reward: 819.0
Avg Reward: 273.0
Min Reward: 243.0
Max Reward: 300.0
Gini Coefficient: 0.0463980463980464
20:20 Ratio: 1.2345679012345678
Max-min Ratio: 1.2345679012345678
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-36-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 896.39
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 204
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 4.802
    dispatch_time_ms: 30.58
    learner:
      cur_lr: 0.001319240778684616
      grad_gnorm: 25.964828491210938
      policy_entropy: 19.67256736755371
      policy_loss: -8.713739395141602
      var_gnorm: 34.453712463378906
      vf_explained_var: 0.5672119855880737
      vf_loss: 29.876943588256836
    num_steps_sampled: 615000
    num_steps_trained: 615000
    wait_time_ms: 731.543
  iterations_since_restore: 205
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1814.0912327766418
  time_this_iter_s: 15.665756225585938
  time_total_s: 1814.0912327766418
  timestamp: 1594096579
  timesteps_since_restore: 615000
  timesteps_this_iter: 3000
  timesteps_total: 615000
  training_iteration: 205
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1814 s, 205 iter, 615000 ts, 896 rew

agent-1: 255.0
agent-2: 262.0
agent-3: 233.0
Sum Reward: 750.0
Avg Reward: 250.0
Min Reward: 233.0
Max Reward: 262.0
Gini Coefficient: 0.025777777777777778
20:20 Ratio: 1.1244635193133048
Max-min Ratio: 1.1244635193133048
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-36-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 892.41
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 205
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.709
    dispatch_time_ms: 31.569
    learner:
      cur_lr: 0.001319041009992361
      grad_gnorm: 39.999996185302734
      policy_entropy: 13.818020820617676
      policy_loss: 21.84166145324707
      var_gnorm: 34.68437194824219
      vf_explained_var: 0.08004242181777954
      vf_loss: 55.0045166015625
    num_steps_sampled: 618000
    num_steps_trained: 618000
    wait_time_ms: 66.254
  iterations_since_restore: 206
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1822.552541255951
  time_this_iter_s: 8.461308479309082
  time_total_s: 1822.552541255951
  timestamp: 1594096588
  timesteps_since_restore: 618000
  timesteps_this_iter: 3000
  timesteps_total: 618000
  training_iteration: 206
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1822 s, 206 iter, 618000 ts, 892 rew

agent-1: 335.0
agent-2: 413.0
agent-3: 331.0
Sum Reward: 1079.0
Avg Reward: 359.6666666666667
Min Reward: 331.0
Max Reward: 413.0
Gini Coefficient: 0.050664195242508495
20:20 Ratio: 1.2477341389728096
Max-min Ratio: 1.2477341389728096
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-36-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 890.67
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 206
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.362
    dispatch_time_ms: 29.258
    learner:
      cur_lr: 0.001318841241300106
      grad_gnorm: 40.0
      policy_entropy: 8.494974136352539
      policy_loss: -2.9626903533935547
      var_gnorm: 34.96449279785156
      vf_explained_var: -0.2797778844833374
      vf_loss: 29.9478759765625
    num_steps_sampled: 621000
    num_steps_trained: 621000
    wait_time_ms: 68.986
  iterations_since_restore: 207
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1832.6423904895782
  time_this_iter_s: 10.08984923362732
  time_total_s: 1832.6423904895782
  timestamp: 1594096598
  timesteps_since_restore: 621000
  timesteps_this_iter: 3000
  timesteps_total: 621000
  training_iteration: 207
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1832 s, 207 iter, 621000 ts, 891 rew

agent-1: 410.0
agent-2: 397.0
agent-3: 426.0
Sum Reward: 1233.0
Avg Reward: 411.0
Min Reward: 397.0
Max Reward: 426.0
Gini Coefficient: 0.01567991349013247
20:20 Ratio: 1.0730478589420656
Max-min Ratio: 1.0730478589420656
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-36-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 892.52
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 207
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.604
    dispatch_time_ms: 20.484
    learner:
      cur_lr: 0.0013186413561925292
      grad_gnorm: 39.999996185302734
      policy_entropy: 16.400653839111328
      policy_loss: 12.960881233215332
      var_gnorm: 35.177833557128906
      vf_explained_var: 0.07700586318969727
      vf_loss: 64.23127746582031
    num_steps_sampled: 624000
    num_steps_trained: 624000
    wait_time_ms: 74.099
  iterations_since_restore: 208
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1842.1510829925537
  time_this_iter_s: 9.508692502975464
  time_total_s: 1842.1510829925537
  timestamp: 1594096608
  timesteps_since_restore: 624000
  timesteps_this_iter: 3000
  timesteps_total: 624000
  training_iteration: 208
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1842 s, 208 iter, 624000 ts, 893 rew

agent-1: 480.0
agent-2: 357.0
agent-3: 435.0
Sum Reward: 1272.0
Avg Reward: 424.0
Min Reward: 357.0
Max Reward: 480.0
Gini Coefficient: 0.06446540880503145
20:20 Ratio: 1.3445378151260505
Max-min Ratio: 1.3445378151260505
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-36-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 895.5
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 208
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.707
    dispatch_time_ms: 27.381
    learner:
      cur_lr: 0.0013184415875002742
      grad_gnorm: 40.0
      policy_entropy: 15.693986892700195
      policy_loss: 11.996286392211914
      var_gnorm: 35.39091110229492
      vf_explained_var: -0.6542189121246338
      vf_loss: 21.04378890991211
    num_steps_sampled: 627000
    num_steps_trained: 627000
    wait_time_ms: 77.265
  iterations_since_restore: 209
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1852.2040259838104
  time_this_iter_s: 10.052942991256714
  time_total_s: 1852.2040259838104
  timestamp: 1594096618
  timesteps_since_restore: 627000
  timesteps_this_iter: 3000
  timesteps_total: 627000
  training_iteration: 209
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1852 s, 209 iter, 627000 ts, 896 rew

agent-1: 422.0
agent-2: 412.0
agent-3: 435.0
Sum Reward: 1269.0
Avg Reward: 423.0
Min Reward: 412.0
Max Reward: 435.0
Gini Coefficient: 0.012083004990806409
20:20 Ratio: 1.0558252427184467
Max-min Ratio: 1.0558252427184467
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-37-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 897.66
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 209
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.488
    dispatch_time_ms: 21.553
    learner:
      cur_lr: 0.0013182418188080192
      grad_gnorm: 8.921745300292969
      policy_entropy: 12.04880142211914
      policy_loss: -4.297849655151367
      var_gnorm: 35.51078414916992
      vf_explained_var: 0.25997668504714966
      vf_loss: 16.770111083984375
    num_steps_sampled: 630000
    num_steps_trained: 630000
    wait_time_ms: 78.876
  iterations_since_restore: 210
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1861.531436920166
  time_this_iter_s: 9.32741093635559
  time_total_s: 1861.531436920166
  timestamp: 1594096627
  timesteps_since_restore: 630000
  timesteps_this_iter: 3000
  timesteps_total: 630000
  training_iteration: 210
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1861 s, 210 iter, 630000 ts, 898 rew

agent-1: 358.0
agent-2: 374.0
agent-3: 399.0
Sum Reward: 1131.0
Avg Reward: 377.0
Min Reward: 358.0
Max Reward: 399.0
Gini Coefficient: 0.024167403477748307
20:20 Ratio: 1.1145251396648044
Max-min Ratio: 1.1145251396648044
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-37-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 899.16
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 210
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.628
    dispatch_time_ms: 27.299
    learner:
      cur_lr: 0.0013180420501157641
      grad_gnorm: 40.00000762939453
      policy_entropy: 13.3327054977417
      policy_loss: 6.900539875030518
      var_gnorm: 35.61133575439453
      vf_explained_var: 0.23244768381118774
      vf_loss: 14.467428207397461
    num_steps_sampled: 633000
    num_steps_trained: 633000
    wait_time_ms: 69.274
  iterations_since_restore: 211
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1870.9553544521332
  time_this_iter_s: 9.423917531967163
  time_total_s: 1870.9553544521332
  timestamp: 1594096636
  timesteps_since_restore: 633000
  timesteps_this_iter: 3000
  timesteps_total: 633000
  training_iteration: 211
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1870 s, 211 iter, 633000 ts, 899 rew

agent-1: 411.0
agent-2: 414.0
agent-3: 353.0
Sum Reward: 1178.0
Avg Reward: 392.6666666666667
Min Reward: 353.0
Max Reward: 414.0
Gini Coefficient: 0.0345217883418223
20:20 Ratio: 1.1728045325779037
Max-min Ratio: 1.1728045325779037
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-37-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 901.19
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 211
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.575
    dispatch_time_ms: 30.143
    learner:
      cur_lr: 0.0013178421650081873
      grad_gnorm: 40.0
      policy_entropy: 10.915409088134766
      policy_loss: 8.286323547363281
      var_gnorm: 35.67181396484375
      vf_explained_var: 0.401394248008728
      vf_loss: 43.760276794433594
    num_steps_sampled: 636000
    num_steps_trained: 636000
    wait_time_ms: 67.478
  iterations_since_restore: 212
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1880.2931213378906
  time_this_iter_s: 9.337766885757446
  time_total_s: 1880.2931213378906
  timestamp: 1594096646
  timesteps_since_restore: 636000
  timesteps_this_iter: 3000
  timesteps_total: 636000
  training_iteration: 212
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1880 s, 212 iter, 636000 ts, 901 rew

agent-1: 413.0
agent-2: 404.0
agent-3: 365.0
Sum Reward: 1182.0
Avg Reward: 394.0
Min Reward: 365.0
Max Reward: 413.0
Gini Coefficient: 0.02707275803722504
20:20 Ratio: 1.1315068493150684
Max-min Ratio: 1.1315068493150684
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-37-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 903.74
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 212
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.223
    dispatch_time_ms: 11.966
    learner:
      cur_lr: 0.0013176423963159323
      grad_gnorm: 35.65667724609375
      policy_entropy: 9.321653366088867
      policy_loss: 9.989194869995117
      var_gnorm: 35.75468444824219
      vf_explained_var: 0.14840686321258545
      vf_loss: 20.424907684326172
    num_steps_sampled: 639000
    num_steps_trained: 639000
    wait_time_ms: 84.311
  iterations_since_restore: 213
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1890.497810125351
  time_this_iter_s: 10.204688787460327
  time_total_s: 1890.497810125351
  timestamp: 1594096656
  timesteps_since_restore: 639000
  timesteps_this_iter: 3000
  timesteps_total: 639000
  training_iteration: 213
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1890 s, 213 iter, 639000 ts, 904 rew

agent-1: 348.0
agent-2: 467.0
agent-3: 421.0
Sum Reward: 1236.0
Avg Reward: 412.0
Min Reward: 348.0
Max Reward: 467.0
Gini Coefficient: 0.06418554476806904
20:20 Ratio: 1.3419540229885059
Max-min Ratio: 1.3419540229885059
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-37-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 909.8
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 213
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.788
    dispatch_time_ms: 25.891
    learner:
      cur_lr: 0.0013174426276236773
      grad_gnorm: 40.000003814697266
      policy_entropy: 9.876517295837402
      policy_loss: 5.266439437866211
      var_gnorm: 35.84370422363281
      vf_explained_var: 0.3455703854560852
      vf_loss: 36.70775604248047
    num_steps_sampled: 642000
    num_steps_trained: 642000
    wait_time_ms: 72.813
  iterations_since_restore: 214
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1900.2690613269806
  time_this_iter_s: 9.771251201629639
  time_total_s: 1900.2690613269806
  timestamp: 1594096666
  timesteps_since_restore: 642000
  timesteps_this_iter: 3000
  timesteps_total: 642000
  training_iteration: 214
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1900 s, 214 iter, 642000 ts, 910 rew

agent-1: 443.0
agent-2: 431.0
agent-3: 412.0
Sum Reward: 1286.0
Avg Reward: 428.6666666666667
Min Reward: 412.0
Max Reward: 443.0
Gini Coefficient: 0.01607050285121825
20:20 Ratio: 1.075242718446602
Max-min Ratio: 1.075242718446602
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-37-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 916.83
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 214
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.57
    dispatch_time_ms: 27.954
    learner:
      cur_lr: 0.0013172427425161004
      grad_gnorm: 40.000003814697266
      policy_entropy: 12.634124755859375
      policy_loss: 5.967189788818359
      var_gnorm: 35.89706802368164
      vf_explained_var: 0.08646667003631592
      vf_loss: 21.590007781982422
    num_steps_sampled: 645000
    num_steps_trained: 645000
    wait_time_ms: 68.789
  iterations_since_restore: 215
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1910.4817292690277
  time_this_iter_s: 10.21266794204712
  time_total_s: 1910.4817292690277
  timestamp: 1594096676
  timesteps_since_restore: 645000
  timesteps_this_iter: 3000
  timesteps_total: 645000
  training_iteration: 215
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1910 s, 215 iter, 645000 ts, 917 rew

agent-1: 428.0
agent-2: 415.0
agent-3: 427.0
Sum Reward: 1270.0
Avg Reward: 423.3333333333333
Min Reward: 415.0
Max Reward: 428.0
Gini Coefficient: 0.0068241469816272965
20:20 Ratio: 1.0313253012048194
Max-min Ratio: 1.0313253012048194
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-38-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 924.23
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 215
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.22
    dispatch_time_ms: 32.156
    learner:
      cur_lr: 0.0013170429738238454
      grad_gnorm: 39.999996185302734
      policy_entropy: 13.482131958007812
      policy_loss: -13.63116455078125
      var_gnorm: 35.9520149230957
      vf_explained_var: 0.3389905095100403
      vf_loss: 49.2402229309082
    num_steps_sampled: 648000
    num_steps_trained: 648000
    wait_time_ms: 78.477
  iterations_since_restore: 216
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1920.1392197608948
  time_this_iter_s: 9.657490491867065
  time_total_s: 1920.1392197608948
  timestamp: 1594096686
  timesteps_since_restore: 648000
  timesteps_this_iter: 3000
  timesteps_total: 648000
  training_iteration: 216
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1920 s, 216 iter, 648000 ts, 924 rew

agent-1: 469.0
agent-2: 367.0
agent-3: 402.0
Sum Reward: 1238.0
Avg Reward: 412.6666666666667
Min Reward: 367.0
Max Reward: 469.0
Gini Coefficient: 0.05492730210016155
20:20 Ratio: 1.2779291553133516
Max-min Ratio: 1.2779291553133516
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-38-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 930.44
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 216
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.672
    dispatch_time_ms: 20.867
    learner:
      cur_lr: 0.0013168432051315904
      grad_gnorm: 39.524574279785156
      policy_entropy: 17.653099060058594
      policy_loss: -3.7177693843841553
      var_gnorm: 36.0262451171875
      vf_explained_var: 0.48720449209213257
      vf_loss: 14.374375343322754
    num_steps_sampled: 651000
    num_steps_trained: 651000
    wait_time_ms: 72.692
  iterations_since_restore: 217
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1930.7380073070526
  time_this_iter_s: 10.598787546157837
  time_total_s: 1930.7380073070526
  timestamp: 1594096696
  timesteps_since_restore: 651000
  timesteps_this_iter: 3000
  timesteps_total: 651000
  training_iteration: 217
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1930 s, 217 iter, 651000 ts, 930 rew

agent-1: 394.0
agent-2: 414.0
agent-3: 428.0
Sum Reward: 1236.0
Avg Reward: 412.0
Min Reward: 394.0
Max Reward: 428.0
Gini Coefficient: 0.018338727076591153
20:20 Ratio: 1.0862944162436547
Max-min Ratio: 1.0862944162436547
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-38-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 933.61
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 217
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.04
    dispatch_time_ms: 21.043
    learner:
      cur_lr: 0.0013166434364393353
      grad_gnorm: 29.489566802978516
      policy_entropy: 10.811101913452148
      policy_loss: -8.81904411315918
      var_gnorm: 36.1096076965332
      vf_explained_var: 0.11666673421859741
      vf_loss: 34.86494445800781
    num_steps_sampled: 654000
    num_steps_trained: 654000
    wait_time_ms: 83.159
  iterations_since_restore: 218
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1941.3694219589233
  time_this_iter_s: 10.631414651870728
  time_total_s: 1941.3694219589233
  timestamp: 1594096707
  timesteps_since_restore: 654000
  timesteps_this_iter: 3000
  timesteps_total: 654000
  training_iteration: 218
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1941 s, 218 iter, 654000 ts, 934 rew

agent-1: 401.0
agent-2: 450.0
agent-3: 403.0
Sum Reward: 1254.0
Avg Reward: 418.0
Min Reward: 401.0
Max Reward: 450.0
Gini Coefficient: 0.026049973418394472
20:20 Ratio: 1.1221945137157108
Max-min Ratio: 1.1221945137157108
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-38-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 935.09
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 218
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.622
    dispatch_time_ms: 36.261
    learner:
      cur_lr: 0.0013164435513317585
      grad_gnorm: 11.377561569213867
      policy_entropy: 10.911836624145508
      policy_loss: 2.6721529960632324
      var_gnorm: 36.08416748046875
      vf_explained_var: 0.0520632266998291
      vf_loss: 11.338032722473145
    num_steps_sampled: 657000
    num_steps_trained: 657000
    wait_time_ms: 52.669
  iterations_since_restore: 219
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1951.4291470050812
  time_this_iter_s: 10.059725046157837
  time_total_s: 1951.4291470050812
  timestamp: 1594096717
  timesteps_since_restore: 657000
  timesteps_this_iter: 3000
  timesteps_total: 657000
  training_iteration: 219
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1951 s, 219 iter, 657000 ts, 935 rew

agent-1: 387.0
agent-2: 403.0
agent-3: 392.0
Sum Reward: 1182.0
Avg Reward: 394.0
Min Reward: 387.0
Max Reward: 403.0
Gini Coefficient: 0.009024252679075015
20:20 Ratio: 1.041343669250646
Max-min Ratio: 1.041343669250646
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-38-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 935.33
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 219
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.358
    dispatch_time_ms: 38.227
    learner:
      cur_lr: 0.0013162437826395035
      grad_gnorm: 40.000003814697266
      policy_entropy: 11.242650985717773
      policy_loss: 6.493385314941406
      var_gnorm: 36.1159553527832
      vf_explained_var: -0.07014012336730957
      vf_loss: 8.064213752746582
    num_steps_sampled: 660000
    num_steps_trained: 660000
    wait_time_ms: 57.194
  iterations_since_restore: 220
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1960.6095128059387
  time_this_iter_s: 9.180365800857544
  time_total_s: 1960.6095128059387
  timestamp: 1594096726
  timesteps_since_restore: 660000
  timesteps_this_iter: 3000
  timesteps_total: 660000
  training_iteration: 220
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1960 s, 220 iter, 660000 ts, 935 rew

agent-1: 412.0
agent-2: 390.0
agent-3: 428.0
Sum Reward: 1230.0
Avg Reward: 410.0
Min Reward: 390.0
Max Reward: 428.0
Gini Coefficient: 0.020596205962059622
20:20 Ratio: 1.0974358974358975
Max-min Ratio: 1.0974358974358975
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-38-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 936.42
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 220
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.706
    dispatch_time_ms: 30.573
    learner:
      cur_lr: 0.0013160440139472485
      grad_gnorm: 26.793466567993164
      policy_entropy: 9.471341133117676
      policy_loss: -4.378568649291992
      var_gnorm: 36.17538070678711
      vf_explained_var: -0.0447617769241333
      vf_loss: 22.14210319519043
    num_steps_sampled: 663000
    num_steps_trained: 663000
    wait_time_ms: 66.101
  iterations_since_restore: 221
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1969.9026701450348
  time_this_iter_s: 9.29315733909607
  time_total_s: 1969.9026701450348
  timestamp: 1594096736
  timesteps_since_restore: 663000
  timesteps_this_iter: 3000
  timesteps_total: 663000
  training_iteration: 221
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1969 s, 221 iter, 663000 ts, 936 rew

agent-1: 453.0
agent-2: 434.0
agent-3: 425.0
Sum Reward: 1312.0
Avg Reward: 437.3333333333333
Min Reward: 425.0
Max Reward: 453.0
Gini Coefficient: 0.014227642276422764
20:20 Ratio: 1.0658823529411765
Max-min Ratio: 1.0658823529411765
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-39-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 938.47
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 221
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.476
    dispatch_time_ms: 27.663
    learner:
      cur_lr: 0.0013158442452549934
      grad_gnorm: 40.000003814697266
      policy_entropy: 9.45440673828125
      policy_loss: 1.7322742938995361
      var_gnorm: 36.20668029785156
      vf_explained_var: -0.6051275730133057
      vf_loss: 10.644025802612305
    num_steps_sampled: 666000
    num_steps_trained: 666000
    wait_time_ms: 63.901
  iterations_since_restore: 222
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1979.055204153061
  time_this_iter_s: 9.152534008026123
  time_total_s: 1979.055204153061
  timestamp: 1594096745
  timesteps_since_restore: 666000
  timesteps_this_iter: 3000
  timesteps_total: 666000
  training_iteration: 222
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1979 s, 222 iter, 666000 ts, 938 rew

agent-1: 442.0
agent-2: 414.0
agent-3: 459.0
Sum Reward: 1315.0
Avg Reward: 438.3333333333333
Min Reward: 414.0
Max Reward: 459.0
Gini Coefficient: 0.022813688212927757
20:20 Ratio: 1.108695652173913
Max-min Ratio: 1.108695652173913
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-39-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 940.42
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 222
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.681
    dispatch_time_ms: 16.327
    learner:
      cur_lr: 0.0013156443601474166
      grad_gnorm: 20.07269859313965
      policy_entropy: 6.440011501312256
      policy_loss: 5.192517280578613
      var_gnorm: 36.268775939941406
      vf_explained_var: 0.048987507820129395
      vf_loss: 10.078357696533203
    num_steps_sampled: 669000
    num_steps_trained: 669000
    wait_time_ms: 79.767
  iterations_since_restore: 223
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1988.3037893772125
  time_this_iter_s: 9.248585224151611
  time_total_s: 1988.3037893772125
  timestamp: 1594096754
  timesteps_since_restore: 669000
  timesteps_this_iter: 3000
  timesteps_total: 669000
  training_iteration: 223
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1988 s, 223 iter, 669000 ts, 940 rew

agent-1: 450.0
agent-2: 414.0
agent-3: 448.0
Sum Reward: 1312.0
Avg Reward: 437.3333333333333
Min Reward: 414.0
Max Reward: 450.0
Gini Coefficient: 0.018292682926829267
20:20 Ratio: 1.0869565217391304
Max-min Ratio: 1.0869565217391304
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-39-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 941.52
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 223
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.925
    dispatch_time_ms: 27.965
    learner:
      cur_lr: 0.0013154445914551616
      grad_gnorm: 40.0
      policy_entropy: 8.144707679748535
      policy_loss: -3.5425631999969482
      var_gnorm: 36.32356262207031
      vf_explained_var: 0.23683714866638184
      vf_loss: 27.492958068847656
    num_steps_sampled: 672000
    num_steps_trained: 672000
    wait_time_ms: 65.409
  iterations_since_restore: 224
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 1997.5368523597717
  time_this_iter_s: 9.233062982559204
  time_total_s: 1997.5368523597717
  timestamp: 1594096763
  timesteps_since_restore: 672000
  timesteps_this_iter: 3000
  timesteps_total: 672000
  training_iteration: 224
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 1997 s, 224 iter, 672000 ts, 942 rew

agent-1: 467.0
agent-2: 410.0
agent-3: 431.0
Sum Reward: 1308.0
Avg Reward: 436.0
Min Reward: 410.0
Max Reward: 467.0
Gini Coefficient: 0.0290519877675841
20:20 Ratio: 1.1390243902439023
Max-min Ratio: 1.1390243902439023
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-39-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 942.1
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 224
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.534
    dispatch_time_ms: 31.32
    learner:
      cur_lr: 0.0013152448227629066
      grad_gnorm: 40.0
      policy_entropy: 8.669095993041992
      policy_loss: -9.001336097717285
      var_gnorm: 36.346981048583984
      vf_explained_var: 0.4357530474662781
      vf_loss: 44.957305908203125
    num_steps_sampled: 675000
    num_steps_trained: 675000
    wait_time_ms: 81.855
  iterations_since_restore: 225
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2007.6134412288666
  time_this_iter_s: 10.076588869094849
  time_total_s: 2007.6134412288666
  timestamp: 1594096774
  timesteps_since_restore: 675000
  timesteps_this_iter: 3000
  timesteps_total: 675000
  training_iteration: 225
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2007 s, 225 iter, 675000 ts, 942 rew

agent-1: 467.0
agent-2: 374.0
agent-3: 419.0
Sum Reward: 1260.0
Avg Reward: 420.0
Min Reward: 374.0
Max Reward: 467.0
Gini Coefficient: 0.049206349206349205
20:20 Ratio: 1.2486631016042782
Max-min Ratio: 1.2486631016042782
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-39-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 943.76
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 225
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.347
    dispatch_time_ms: 29.81
    learner:
      cur_lr: 0.0013150450540706515
      grad_gnorm: 40.0
      policy_entropy: 10.296854019165039
      policy_loss: -6.541101455688477
      var_gnorm: 36.38491439819336
      vf_explained_var: 0.3349488377571106
      vf_loss: 57.02772903442383
    num_steps_sampled: 678000
    num_steps_trained: 678000
    wait_time_ms: 61.257
  iterations_since_restore: 226
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2017.9227380752563
  time_this_iter_s: 10.30929684638977
  time_total_s: 2017.9227380752563
  timestamp: 1594096784
  timesteps_since_restore: 678000
  timesteps_this_iter: 3000
  timesteps_total: 678000
  training_iteration: 226
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2017 s, 226 iter, 678000 ts, 944 rew

agent-1: 346.0
agent-2: 429.0
agent-3: 410.0
Sum Reward: 1185.0
Avg Reward: 395.0
Min Reward: 346.0
Max Reward: 429.0
Gini Coefficient: 0.04669479606188467
20:20 Ratio: 1.239884393063584
Max-min Ratio: 1.239884393063584
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-39-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 943.49
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 226
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.448
    dispatch_time_ms: 23.195
    learner:
      cur_lr: 0.0013148451689630747
      grad_gnorm: 24.58041000366211
      policy_entropy: 12.565470695495605
      policy_loss: 0.6179707050323486
      var_gnorm: 36.42535400390625
      vf_explained_var: -0.46476829051971436
      vf_loss: 8.234257698059082
    num_steps_sampled: 681000
    num_steps_trained: 681000
    wait_time_ms: 75.52
  iterations_since_restore: 227
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2027.818606853485
  time_this_iter_s: 9.89586877822876
  time_total_s: 2027.818606853485
  timestamp: 1594096794
  timesteps_since_restore: 681000
  timesteps_this_iter: 3000
  timesteps_total: 681000
  training_iteration: 227
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2027 s, 227 iter, 681000 ts, 943 rew

agent-1: 373.0
agent-2: 449.0
agent-3: 472.0
Sum Reward: 1294.0
Avg Reward: 431.3333333333333
Min Reward: 373.0
Max Reward: 472.0
Gini Coefficient: 0.05100463678516229
20:20 Ratio: 1.2654155495978552
Max-min Ratio: 1.2654155495978552
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-40-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 943.69
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 227
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.401
    dispatch_time_ms: 41.383
    learner:
      cur_lr: 0.0013146454002708197
      grad_gnorm: 30.506092071533203
      policy_entropy: 12.770809173583984
      policy_loss: -3.3984146118164062
      var_gnorm: 36.50306701660156
      vf_explained_var: 0.23956286907196045
      vf_loss: 50.57144546508789
    num_steps_sampled: 684000
    num_steps_trained: 684000
    wait_time_ms: 64.67
  iterations_since_restore: 228
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2037.9970588684082
  time_this_iter_s: 10.178452014923096
  time_total_s: 2037.9970588684082
  timestamp: 1594096804
  timesteps_since_restore: 684000
  timesteps_this_iter: 3000
  timesteps_total: 684000
  training_iteration: 228
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2037 s, 228 iter, 684000 ts, 944 rew

agent-1: 373.0
agent-2: 415.0
agent-3: 366.0
Sum Reward: 1154.0
Avg Reward: 384.6666666666667
Min Reward: 366.0
Max Reward: 415.0
Gini Coefficient: 0.02830733679953784
20:20 Ratio: 1.133879781420765
Max-min Ratio: 1.133879781420765
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-40-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 942.93
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 228
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.896
    dispatch_time_ms: 51.626
    learner:
      cur_lr: 0.0013144456315785646
      grad_gnorm: 11.128029823303223
      policy_entropy: 8.500575065612793
      policy_loss: -4.62899112701416
      var_gnorm: 36.580902099609375
      vf_explained_var: -0.20184385776519775
      vf_loss: 16.13412094116211
    num_steps_sampled: 687000
    num_steps_trained: 687000
    wait_time_ms: 50.776
  iterations_since_restore: 229
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2048.2955634593964
  time_this_iter_s: 10.29850459098816
  time_total_s: 2048.2955634593964
  timestamp: 1594096814
  timesteps_since_restore: 687000
  timesteps_this_iter: 3000
  timesteps_total: 687000
  training_iteration: 229
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2048 s, 229 iter, 687000 ts, 943 rew

agent-1: 413.0
agent-2: 501.0
agent-3: 312.0
Sum Reward: 1226.0
Avg Reward: 408.6666666666667
Min Reward: 312.0
Max Reward: 501.0
Gini Coefficient: 0.10277324632952692
20:20 Ratio: 1.6057692307692308
Max-min Ratio: 1.6057692307692308
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-40-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 942.58
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 229
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.759
    dispatch_time_ms: 21.88
    learner:
      cur_lr: 0.0013142457464709878
      grad_gnorm: 40.00000762939453
      policy_entropy: 16.174421310424805
      policy_loss: -33.255950927734375
      var_gnorm: 36.69739532470703
      vf_explained_var: 0.34962427616119385
      vf_loss: 70.74111938476562
    num_steps_sampled: 690000
    num_steps_trained: 690000
    wait_time_ms: 84.945
  iterations_since_restore: 230
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2058.6824667453766
  time_this_iter_s: 10.386903285980225
  time_total_s: 2058.6824667453766
  timestamp: 1594096825
  timesteps_since_restore: 690000
  timesteps_this_iter: 3000
  timesteps_total: 690000
  training_iteration: 230
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2058 s, 230 iter, 690000 ts, 943 rew

agent-1: 426.0
agent-2: 427.0
agent-3: 449.0
Sum Reward: 1302.0
Avg Reward: 434.0
Min Reward: 426.0
Max Reward: 449.0
Gini Coefficient: 0.011776753712237584
20:20 Ratio: 1.0539906103286385
Max-min Ratio: 1.0539906103286385
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-40-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1350.0
  episode_reward_mean: 943.41
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 230
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.546
    dispatch_time_ms: 40.136
    learner:
      cur_lr: 0.0013140459777787328
      grad_gnorm: 40.0
      policy_entropy: 10.64286994934082
      policy_loss: 12.40086555480957
      var_gnorm: 36.80506896972656
      vf_explained_var: -0.2729792594909668
      vf_loss: 16.701642990112305
    num_steps_sampled: 693000
    num_steps_trained: 693000
    wait_time_ms: 52.555
  iterations_since_restore: 231
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2069.250487089157
  time_this_iter_s: 10.568020343780518
  time_total_s: 2069.250487089157
  timestamp: 1594096835
  timesteps_since_restore: 693000
  timesteps_this_iter: 3000
  timesteps_total: 693000
  training_iteration: 231
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2069 s, 231 iter, 693000 ts, 943 rew

agent-1: 494.0
agent-2: 473.0
agent-3: 487.0
Sum Reward: 1454.0
Avg Reward: 484.6666666666667
Min Reward: 473.0
Max Reward: 494.0
Gini Coefficient: 0.009628610729023384
20:20 Ratio: 1.0443974630021142
Max-min Ratio: 1.0443974630021142
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-40-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1454.0
  episode_reward_mean: 945.38
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 231
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.498
    dispatch_time_ms: 26.609
    learner:
      cur_lr: 0.0013138462090864778
      grad_gnorm: 39.999996185302734
      policy_entropy: 9.884688377380371
      policy_loss: -24.53433609008789
      var_gnorm: 36.8975715637207
      vf_explained_var: -0.048184990882873535
      vf_loss: 78.48469543457031
    num_steps_sampled: 696000
    num_steps_trained: 696000
    wait_time_ms: 80.231
  iterations_since_restore: 232
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2079.1160364151
  time_this_iter_s: 9.865549325942993
  time_total_s: 2079.1160364151
  timestamp: 1594096845
  timesteps_since_restore: 696000
  timesteps_this_iter: 3000
  timesteps_total: 696000
  training_iteration: 232
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2079 s, 232 iter, 696000 ts, 945 rew

agent-1: 398.0
agent-2: 484.0
agent-3: 451.0
Sum Reward: 1333.0
Avg Reward: 444.3333333333333
Min Reward: 398.0
Max Reward: 484.0
Gini Coefficient: 0.043010752688172046
20:20 Ratio: 1.2160804020100502
Max-min Ratio: 1.2160804020100502
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-40-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1454.0
  episode_reward_mean: 946.82
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 232
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.508
    dispatch_time_ms: 17.621
    learner:
      cur_lr: 0.0013136464403942227
      grad_gnorm: 40.0
      policy_entropy: 5.333115100860596
      policy_loss: 1.0570791959762573
      var_gnorm: 36.88084411621094
      vf_explained_var: 0.3760499358177185
      vf_loss: 27.151994705200195
    num_steps_sampled: 699000
    num_steps_trained: 699000
    wait_time_ms: 75.309
  iterations_since_restore: 233
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2090.47452712059
  time_this_iter_s: 11.358490705490112
  time_total_s: 2090.47452712059
  timestamp: 1594096857
  timesteps_since_restore: 699000
  timesteps_this_iter: 3000
  timesteps_total: 699000
  training_iteration: 233
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2090 s, 233 iter, 699000 ts, 947 rew

agent-1: 387.0
agent-2: 381.0
agent-3: 378.0
Sum Reward: 1146.0
Avg Reward: 382.0
Min Reward: 378.0
Max Reward: 387.0
Gini Coefficient: 0.005235602094240838
20:20 Ratio: 1.0238095238095237
Max-min Ratio: 1.0238095238095237
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-41-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1454.0
  episode_reward_mean: 948.71
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 233
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.436
    dispatch_time_ms: 5.577
    learner:
      cur_lr: 0.0013134465552866459
      grad_gnorm: 39.999996185302734
      policy_entropy: 8.341899871826172
      policy_loss: -8.929779052734375
      var_gnorm: 37.009796142578125
      vf_explained_var: 0.5907923579216003
      vf_loss: 13.891753196716309
    num_steps_sampled: 702000
    num_steps_trained: 702000
    wait_time_ms: 92.068
  iterations_since_restore: 234
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2106.8010873794556
  time_this_iter_s: 16.326560258865356
  time_total_s: 2106.8010873794556
  timestamp: 1594096873
  timesteps_since_restore: 702000
  timesteps_this_iter: 3000
  timesteps_total: 702000
  training_iteration: 234
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2106 s, 234 iter, 702000 ts, 949 rew

agent-1: 464.0
agent-2: 438.0
agent-3: 452.0
Sum Reward: 1354.0
Avg Reward: 451.3333333333333
Min Reward: 438.0
Max Reward: 464.0
Gini Coefficient: 0.012801575578532743
20:20 Ratio: 1.0593607305936072
Max-min Ratio: 1.0593607305936072
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-41-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1454.0
  episode_reward_mean: 954.46
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 234
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.303
    dispatch_time_ms: 6.09
    learner:
      cur_lr: 0.0013132467865943909
      grad_gnorm: 39.99999237060547
      policy_entropy: 7.305179595947266
      policy_loss: 1.314300775527954
      var_gnorm: 37.100826263427734
      vf_explained_var: 0.12244534492492676
      vf_loss: 19.843643188476562
    num_steps_sampled: 705000
    num_steps_trained: 705000
    wait_time_ms: 74.583
  iterations_since_restore: 235
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2116.70787525177
  time_this_iter_s: 9.906787872314453
  time_total_s: 2116.70787525177
  timestamp: 1594096883
  timesteps_since_restore: 705000
  timesteps_this_iter: 3000
  timesteps_total: 705000
  training_iteration: 235
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2116 s, 235 iter, 705000 ts, 954 rew

agent-1: 514.0
agent-2: 487.0
agent-3: 458.0
Sum Reward: 1459.0
Avg Reward: 486.3333333333333
Min Reward: 458.0
Max Reward: 514.0
Gini Coefficient: 0.025588302490290152
20:20 Ratio: 1.1222707423580787
Max-min Ratio: 1.1222707423580787
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-41-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 962.02
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 235
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.547
    dispatch_time_ms: 5.559
    learner:
      cur_lr: 0.0013130470179021358
      grad_gnorm: 32.28959274291992
      policy_entropy: 8.449540138244629
      policy_loss: -7.881321907043457
      var_gnorm: 37.204166412353516
      vf_explained_var: 0.41045045852661133
      vf_loss: 12.359060287475586
    num_steps_sampled: 708000
    num_steps_trained: 708000
    wait_time_ms: 86.454
  iterations_since_restore: 236
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2125.7119541168213
  time_this_iter_s: 9.00407886505127
  time_total_s: 2125.7119541168213
  timestamp: 1594096892
  timesteps_since_restore: 708000
  timesteps_this_iter: 3000
  timesteps_total: 708000
  training_iteration: 236
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2125 s, 236 iter, 708000 ts, 962 rew

agent-1: 419.0
agent-2: 465.0
agent-3: 472.0
Sum Reward: 1356.0
Avg Reward: 452.0
Min Reward: 419.0
Max Reward: 472.0
Gini Coefficient: 0.026057030481809244
20:20 Ratio: 1.126491646778043
Max-min Ratio: 1.126491646778043
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-41-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 968.01
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 236
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.481
    dispatch_time_ms: 6.952
    learner:
      cur_lr: 0.0013128472492098808
      grad_gnorm: 5.293374538421631
      policy_entropy: 8.463264465332031
      policy_loss: 1.6269068717956543
      var_gnorm: 37.21657943725586
      vf_explained_var: 0.36431074142456055
      vf_loss: 4.97074556350708
    num_steps_sampled: 711000
    num_steps_trained: 711000
    wait_time_ms: 85.096
  iterations_since_restore: 237
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2135.5266726017
  time_this_iter_s: 9.81471848487854
  time_total_s: 2135.5266726017
  timestamp: 1594096902
  timesteps_since_restore: 711000
  timesteps_this_iter: 3000
  timesteps_total: 711000
  training_iteration: 237
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2135 s, 237 iter, 711000 ts, 968 rew

agent-1: 403.0
agent-2: 412.0
agent-3: 457.0
Sum Reward: 1272.0
Avg Reward: 424.0
Min Reward: 403.0
Max Reward: 457.0
Gini Coefficient: 0.02830188679245283
20:20 Ratio: 1.1339950372208436
Max-min Ratio: 1.1339950372208436
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-41-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 971.54
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 237
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.802
    dispatch_time_ms: 7.882
    learner:
      cur_lr: 0.001312647364102304
      grad_gnorm: 40.000003814697266
      policy_entropy: 14.681819915771484
      policy_loss: -17.8499813079834
      var_gnorm: 37.24588394165039
      vf_explained_var: 0.39323145151138306
      vf_loss: 40.21310043334961
    num_steps_sampled: 714000
    num_steps_trained: 714000
    wait_time_ms: 79.923
  iterations_since_restore: 238
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2144.7791035175323
  time_this_iter_s: 9.25243091583252
  time_total_s: 2144.7791035175323
  timestamp: 1594096911
  timesteps_since_restore: 714000
  timesteps_this_iter: 3000
  timesteps_total: 714000
  training_iteration: 238
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2144 s, 238 iter, 714000 ts, 972 rew

agent-1: 408.0
agent-2: 401.0
agent-3: 411.0
Sum Reward: 1220.0
Avg Reward: 406.6666666666667
Min Reward: 401.0
Max Reward: 411.0
Gini Coefficient: 0.00546448087431694
20:20 Ratio: 1.0249376558603491
Max-min Ratio: 1.0249376558603491
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-42-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 974.12
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 238
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.504
    dispatch_time_ms: 8.969
    learner:
      cur_lr: 0.001312447595410049
      grad_gnorm: 40.0
      policy_entropy: 13.152647018432617
      policy_loss: 16.59649658203125
      var_gnorm: 37.279136657714844
      vf_explained_var: 0.23396658897399902
      vf_loss: 25.83475112915039
    num_steps_sampled: 717000
    num_steps_trained: 717000
    wait_time_ms: 76.356
  iterations_since_restore: 239
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2153.6798877716064
  time_this_iter_s: 8.900784254074097
  time_total_s: 2153.6798877716064
  timestamp: 1594096920
  timesteps_since_restore: 717000
  timesteps_this_iter: 3000
  timesteps_total: 717000
  training_iteration: 239
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2153 s, 239 iter, 717000 ts, 974 rew

agent-1: 371.0
agent-2: 353.0
agent-3: 357.0
Sum Reward: 1081.0
Avg Reward: 360.3333333333333
Min Reward: 353.0
Max Reward: 371.0
Gini Coefficient: 0.011100832562442183
20:20 Ratio: 1.0509915014164306
Max-min Ratio: 1.0509915014164306
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-42-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 976.57
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 239
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.536
    dispatch_time_ms: 6.884
    learner:
      cur_lr: 0.001312247826717794
      grad_gnorm: 40.0
      policy_entropy: 17.96700096130371
      policy_loss: -8.937602043151855
      var_gnorm: 37.271541595458984
      vf_explained_var: 0.5369213819503784
      vf_loss: 52.99055099487305
    num_steps_sampled: 720000
    num_steps_trained: 720000
    wait_time_ms: 79.805
  iterations_since_restore: 240
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2162.352684020996
  time_this_iter_s: 8.672796249389648
  time_total_s: 2162.352684020996
  timestamp: 1594096929
  timesteps_since_restore: 720000
  timesteps_this_iter: 3000
  timesteps_total: 720000
  training_iteration: 240
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2162 s, 240 iter, 720000 ts, 977 rew

agent-1: 316.0
agent-2: 375.0
agent-3: 369.0
Sum Reward: 1060.0
Avg Reward: 353.3333333333333
Min Reward: 316.0
Max Reward: 375.0
Gini Coefficient: 0.03710691823899371
20:20 Ratio: 1.1867088607594938
Max-min Ratio: 1.1867088607594938
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-42-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 977.87
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 240
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.884
    dispatch_time_ms: 8.579
    learner:
      cur_lr: 0.001312048058025539
      grad_gnorm: 7.533715724945068
      policy_entropy: 21.156681060791016
      policy_loss: 0.9412975311279297
      var_gnorm: 37.34217834472656
      vf_explained_var: -0.21237587928771973
      vf_loss: 7.012978553771973
    num_steps_sampled: 723000
    num_steps_trained: 723000
    wait_time_ms: 70.868
  iterations_since_restore: 241
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2171.3804585933685
  time_this_iter_s: 9.027774572372437
  time_total_s: 2171.3804585933685
  timestamp: 1594096938
  timesteps_since_restore: 723000
  timesteps_this_iter: 3000
  timesteps_total: 723000
  training_iteration: 241
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2171 s, 241 iter, 723000 ts, 978 rew

agent-1: 397.0
agent-2: 374.0
agent-3: 326.0
Sum Reward: 1097.0
Avg Reward: 365.6666666666667
Min Reward: 326.0
Max Reward: 397.0
Gini Coefficient: 0.04314797933758736
20:20 Ratio: 1.2177914110429449
Max-min Ratio: 1.2177914110429449
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-42-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 977.59
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 241
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.794
    dispatch_time_ms: 7.327
    learner:
      cur_lr: 0.001311848172917962
      grad_gnorm: 40.0
      policy_entropy: 23.816307067871094
      policy_loss: 17.40150260925293
      var_gnorm: 37.35309982299805
      vf_explained_var: 0.10617202520370483
      vf_loss: 16.48061752319336
    num_steps_sampled: 726000
    num_steps_trained: 726000
    wait_time_ms: 77.282
  iterations_since_restore: 242
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2179.8398003578186
  time_this_iter_s: 8.459341764450073
  time_total_s: 2179.8398003578186
  timestamp: 1594096946
  timesteps_since_restore: 726000
  timesteps_this_iter: 3000
  timesteps_total: 726000
  training_iteration: 242
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2179 s, 242 iter, 726000 ts, 978 rew

agent-1: 359.0
agent-2: 359.0
agent-3: 349.0
Sum Reward: 1067.0
Avg Reward: 355.6666666666667
Min Reward: 349.0
Max Reward: 359.0
Gini Coefficient: 0.006248047485160888
20:20 Ratio: 1.0286532951289398
Max-min Ratio: 1.0286532951289398
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-42-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 976.93
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 242
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.239
    dispatch_time_ms: 5.546
    learner:
      cur_lr: 0.001311648404225707
      grad_gnorm: 40.0
      policy_entropy: 13.314739227294922
      policy_loss: 4.43508243560791
      var_gnorm: 37.3646240234375
      vf_explained_var: -0.08294880390167236
      vf_loss: 88.65483093261719
    num_steps_sampled: 729000
    num_steps_trained: 729000
    wait_time_ms: 73.176
  iterations_since_restore: 243
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2188.722692012787
  time_this_iter_s: 8.882891654968262
  time_total_s: 2188.722692012787
  timestamp: 1594096955
  timesteps_since_restore: 729000
  timesteps_this_iter: 3000
  timesteps_total: 729000
  training_iteration: 243
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2188 s, 243 iter, 729000 ts, 977 rew

agent-1: 318.0
agent-2: 329.0
agent-3: 373.0
Sum Reward: 1020.0
Avg Reward: 340.0
Min Reward: 318.0
Max Reward: 373.0
Gini Coefficient: 0.03594771241830065
20:20 Ratio: 1.1729559748427674
Max-min Ratio: 1.1729559748427674
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-42-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 974.7
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 243
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.032
    dispatch_time_ms: 5.177
    learner:
      cur_lr: 0.001311448635533452
      grad_gnorm: 40.000003814697266
      policy_entropy: 16.301895141601562
      policy_loss: -14.043290138244629
      var_gnorm: 37.441734313964844
      vf_explained_var: 0.571697473526001
      vf_loss: 20.87957763671875
    num_steps_sampled: 732000
    num_steps_trained: 732000
    wait_time_ms: 88.091
  iterations_since_restore: 244
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2197.7722551822662
  time_this_iter_s: 9.04956316947937
  time_total_s: 2197.7722551822662
  timestamp: 1594096964
  timesteps_since_restore: 732000
  timesteps_this_iter: 3000
  timesteps_total: 732000
  training_iteration: 244
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2197 s, 244 iter, 732000 ts, 975 rew

agent-1: 409.0
agent-2: 407.0
agent-3: 418.0
Sum Reward: 1234.0
Avg Reward: 411.3333333333333
Min Reward: 407.0
Max Reward: 418.0
Gini Coefficient: 0.005942733657482442
20:20 Ratio: 1.027027027027027
Max-min Ratio: 1.027027027027027
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-42-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 974.1
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 244
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.706
    dispatch_time_ms: 6.038
    learner:
      cur_lr: 0.0013112487504258752
      grad_gnorm: 40.0
      policy_entropy: 10.056083679199219
      policy_loss: 3.927165985107422
      var_gnorm: 37.560829162597656
      vf_explained_var: -1.0
      vf_loss: 33.83637237548828
    num_steps_sampled: 735000
    num_steps_trained: 735000
    wait_time_ms: 88.779
  iterations_since_restore: 245
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2207.94055891037
  time_this_iter_s: 10.168303728103638
  time_total_s: 2207.94055891037
  timestamp: 1594096975
  timesteps_since_restore: 735000
  timesteps_this_iter: 3000
  timesteps_total: 735000
  training_iteration: 245
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2207 s, 245 iter, 735000 ts, 974 rew

agent-1: 462.0
agent-2: 379.0
agent-3: 407.0
Sum Reward: 1248.0
Avg Reward: 416.0
Min Reward: 379.0
Max Reward: 462.0
Gini Coefficient: 0.04433760683760684
20:20 Ratio: 1.2189973614775726
Max-min Ratio: 1.2189973614775726
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-43-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 973.08
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 245
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.9
    dispatch_time_ms: 5.012
    learner:
      cur_lr: 0.0013110489817336202
      grad_gnorm: 19.27566146850586
      policy_entropy: 13.108461380004883
      policy_loss: 3.0430409908294678
      var_gnorm: 37.6209716796875
      vf_explained_var: -0.1628788709640503
      vf_loss: 15.907764434814453
    num_steps_sampled: 738000
    num_steps_trained: 738000
    wait_time_ms: 91.777
  iterations_since_restore: 246
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2217.229768514633
  time_this_iter_s: 9.289209604263306
  time_total_s: 2217.229768514633
  timestamp: 1594096984
  timesteps_since_restore: 738000
  timesteps_this_iter: 3000
  timesteps_total: 738000
  training_iteration: 246
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2217 s, 246 iter, 738000 ts, 973 rew

agent-1: 365.0
agent-2: 370.0
agent-3: 438.0
Sum Reward: 1173.0
Avg Reward: 391.0
Min Reward: 365.0
Max Reward: 438.0
Gini Coefficient: 0.04148905939187269
20:20 Ratio: 1.2
Max-min Ratio: 1.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-43-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 972.77
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 246
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.606
    dispatch_time_ms: 6.257
    learner:
      cur_lr: 0.0013108492130413651
      grad_gnorm: 39.999996185302734
      policy_entropy: 17.75835418701172
      policy_loss: -17.29185676574707
      var_gnorm: 37.71809005737305
      vf_explained_var: 0.036984801292419434
      vf_loss: 28.941001892089844
    num_steps_sampled: 741000
    num_steps_trained: 741000
    wait_time_ms: 73.944
  iterations_since_restore: 247
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2226.770259141922
  time_this_iter_s: 9.540490627288818
  time_total_s: 2226.770259141922
  timestamp: 1594096994
  timesteps_since_restore: 741000
  timesteps_this_iter: 3000
  timesteps_total: 741000
  training_iteration: 247
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2226 s, 247 iter, 741000 ts, 973 rew

agent-1: 417.0
agent-2: 410.0
agent-3: 432.0
Sum Reward: 1259.0
Avg Reward: 419.6666666666667
Min Reward: 410.0
Max Reward: 432.0
Gini Coefficient: 0.011649457241196717
20:20 Ratio: 1.053658536585366
Max-min Ratio: 1.053658536585366
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-43-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 973.37
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 247
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.697
    dispatch_time_ms: 6.72
    learner:
      cur_lr: 0.0013106494443491101
      grad_gnorm: 15.207144737243652
      policy_entropy: 17.663549423217773
      policy_loss: -3.7036378383636475
      var_gnorm: 37.72573471069336
      vf_explained_var: 0.013483703136444092
      vf_loss: 10.252399444580078
    num_steps_sampled: 744000
    num_steps_trained: 744000
    wait_time_ms: 72.925
  iterations_since_restore: 248
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2234.885915517807
  time_this_iter_s: 8.11565637588501
  time_total_s: 2234.885915517807
  timestamp: 1594097002
  timesteps_since_restore: 744000
  timesteps_this_iter: 3000
  timesteps_total: 744000
  training_iteration: 248
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2234 s, 248 iter, 744000 ts, 973 rew

agent-1: 316.0
agent-2: 308.0
agent-3: 353.0
Sum Reward: 977.0
Avg Reward: 325.6666666666667
Min Reward: 308.0
Max Reward: 353.0
Gini Coefficient: 0.030706243602865915
20:20 Ratio: 1.146103896103896
Max-min Ratio: 1.146103896103896
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-43-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 971.97
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 248
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.525
    dispatch_time_ms: 8.605
    learner:
      cur_lr: 0.0013104495592415333
      grad_gnorm: 40.00000762939453
      policy_entropy: 21.8786678314209
      policy_loss: -21.936080932617188
      var_gnorm: 37.7453727722168
      vf_explained_var: 0.015956521034240723
      vf_loss: 32.8722038269043
    num_steps_sampled: 747000
    num_steps_trained: 747000
    wait_time_ms: 66.934
  iterations_since_restore: 249
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2243.2883808612823
  time_this_iter_s: 8.402465343475342
  time_total_s: 2243.2883808612823
  timestamp: 1594097010
  timesteps_since_restore: 747000
  timesteps_this_iter: 3000
  timesteps_total: 747000
  training_iteration: 249
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2243 s, 249 iter, 747000 ts, 972 rew

agent-1: 346.0
agent-2: 316.0
agent-3: 349.0
Sum Reward: 1011.0
Avg Reward: 337.0
Min Reward: 316.0
Max Reward: 349.0
Gini Coefficient: 0.021760633036597428
20:20 Ratio: 1.1044303797468353
Max-min Ratio: 1.1044303797468353
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-43-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 972.99
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 249
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.442
    dispatch_time_ms: 6.186
    learner:
      cur_lr: 0.0013102497905492783
      grad_gnorm: 40.0
      policy_entropy: 15.208730697631836
      policy_loss: -6.18821382522583
      var_gnorm: 37.777923583984375
      vf_explained_var: 0.48687493801116943
      vf_loss: 19.109041213989258
    num_steps_sampled: 750000
    num_steps_trained: 750000
    wait_time_ms: 83.651
  iterations_since_restore: 250
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2251.9025735855103
  time_this_iter_s: 8.614192724227905
  time_total_s: 2251.9025735855103
  timestamp: 1594097019
  timesteps_since_restore: 750000
  timesteps_this_iter: 3000
  timesteps_total: 750000
  training_iteration: 250
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2251 s, 250 iter, 750000 ts, 973 rew

agent-1: 373.0
agent-2: 375.0
agent-3: 377.0
Sum Reward: 1125.0
Avg Reward: 375.0
Min Reward: 373.0
Max Reward: 377.0
Gini Coefficient: 0.0023703703703703703
20:20 Ratio: 1.0107238605898123
Max-min Ratio: 1.0107238605898123
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-43-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 976.22
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 250
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.737
    dispatch_time_ms: 6.506
    learner:
      cur_lr: 0.0013100500218570232
      grad_gnorm: 40.000003814697266
      policy_entropy: 11.643962860107422
      policy_loss: 7.660261154174805
      var_gnorm: 37.797767639160156
      vf_explained_var: -0.36618292331695557
      vf_loss: 47.98816680908203
    num_steps_sampled: 753000
    num_steps_trained: 753000
    wait_time_ms: 76.109
  iterations_since_restore: 251
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2260.9895820617676
  time_this_iter_s: 9.087008476257324
  time_total_s: 2260.9895820617676
  timestamp: 1594097028
  timesteps_since_restore: 753000
  timesteps_this_iter: 3000
  timesteps_total: 753000
  training_iteration: 251
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2260 s, 251 iter, 753000 ts, 976 rew

agent-1: 353.0
agent-2: 383.0
agent-3: 426.0
Sum Reward: 1162.0
Avg Reward: 387.3333333333333
Min Reward: 353.0
Max Reward: 426.0
Gini Coefficient: 0.04188181296615032
20:20 Ratio: 1.206798866855524
Max-min Ratio: 1.206798866855524
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-43-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 979.11
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 251
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.637
    dispatch_time_ms: 5.445
    learner:
      cur_lr: 0.0013098502531647682
      grad_gnorm: 12.386833190917969
      policy_entropy: 7.613353729248047
      policy_loss: 4.518960952758789
      var_gnorm: 37.89607238769531
      vf_explained_var: 0.38386380672454834
      vf_loss: 10.477132797241211
    num_steps_sampled: 756000
    num_steps_trained: 756000
    wait_time_ms: 88.756
  iterations_since_restore: 252
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2270.1392261981964
  time_this_iter_s: 9.149644136428833
  time_total_s: 2270.1392261981964
  timestamp: 1594097037
  timesteps_since_restore: 756000
  timesteps_this_iter: 3000
  timesteps_total: 756000
  training_iteration: 252
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2270 s, 252 iter, 756000 ts, 979 rew

agent-1: 484.0
agent-2: 446.0
agent-3: 430.0
Sum Reward: 1360.0
Avg Reward: 453.3333333333333
Min Reward: 430.0
Max Reward: 484.0
Gini Coefficient: 0.026470588235294117
20:20 Ratio: 1.1255813953488372
Max-min Ratio: 1.1255813953488372
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-44-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 984.07
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 252
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.32
    dispatch_time_ms: 25.463
    learner:
      cur_lr: 0.0013096503680571914
      grad_gnorm: 40.0
      policy_entropy: 12.173535346984863
      policy_loss: 13.756082534790039
      var_gnorm: 37.97931671142578
      vf_explained_var: -0.6879078149795532
      vf_loss: 23.855560302734375
    num_steps_sampled: 759000
    num_steps_trained: 759000
    wait_time_ms: 73.982
  iterations_since_restore: 253
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2280.5825786590576
  time_this_iter_s: 10.443352460861206
  time_total_s: 2280.5825786590576
  timestamp: 1594097048
  timesteps_since_restore: 759000
  timesteps_this_iter: 3000
  timesteps_total: 759000
  training_iteration: 253
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2280 s, 253 iter, 759000 ts, 984 rew

agent-1: 430.0
agent-2: 487.0
agent-3: 465.0
Sum Reward: 1382.0
Avg Reward: 460.6666666666667
Min Reward: 430.0
Max Reward: 487.0
Gini Coefficient: 0.027496382054992764
20:20 Ratio: 1.1325581395348838
Max-min Ratio: 1.1325581395348838
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-44-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 989.33
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 253
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.626
    dispatch_time_ms: 23.239
    learner:
      cur_lr: 0.0013094505993649364
      grad_gnorm: 40.0
      policy_entropy: 9.210356712341309
      policy_loss: 7.035735607147217
      var_gnorm: 38.07926559448242
      vf_explained_var: 0.5845407247543335
      vf_loss: 10.615348815917969
    num_steps_sampled: 762000
    num_steps_trained: 762000
    wait_time_ms: 79.57
  iterations_since_restore: 254
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2290.213365316391
  time_this_iter_s: 9.630786657333374
  time_total_s: 2290.213365316391
  timestamp: 1594097057
  timesteps_since_restore: 762000
  timesteps_this_iter: 3000
  timesteps_total: 762000
  training_iteration: 254
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2290 s, 254 iter, 762000 ts, 989 rew

agent-1: 473.0
agent-2: 479.0
agent-3: 482.0
Sum Reward: 1434.0
Avg Reward: 478.0
Min Reward: 473.0
Max Reward: 482.0
Gini Coefficient: 0.0041841004184100415
20:20 Ratio: 1.0190274841437632
Max-min Ratio: 1.0190274841437632
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-44-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 994.98
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 254
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.515
    dispatch_time_ms: 20.172
    learner:
      cur_lr: 0.0013092508306726813
      grad_gnorm: 40.0
      policy_entropy: 11.855672836303711
      policy_loss: -2.741835594177246
      var_gnorm: 38.14271545410156
      vf_explained_var: 0.3053845167160034
      vf_loss: 14.876301765441895
    num_steps_sampled: 765000
    num_steps_trained: 765000
    wait_time_ms: 79.748
  iterations_since_restore: 255
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2301.236161470413
  time_this_iter_s: 11.022796154022217
  time_total_s: 2301.236161470413
  timestamp: 1594097068
  timesteps_since_restore: 765000
  timesteps_this_iter: 3000
  timesteps_total: 765000
  training_iteration: 255
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2301 s, 255 iter, 765000 ts, 995 rew

agent-1: 408.0
agent-2: 473.0
agent-3: 467.0
Sum Reward: 1348.0
Avg Reward: 449.3333333333333
Min Reward: 408.0
Max Reward: 473.0
Gini Coefficient: 0.03214638971315529
20:20 Ratio: 1.1593137254901962
Max-min Ratio: 1.1593137254901962
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-44-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 999.46
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 255
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.563
    dispatch_time_ms: 24.393
    learner:
      cur_lr: 0.0013090509455651045
      grad_gnorm: 40.0
      policy_entropy: 7.348602294921875
      policy_loss: 3.8434464931488037
      var_gnorm: 38.210086822509766
      vf_explained_var: -0.42375755310058594
      vf_loss: 8.324660301208496
    num_steps_sampled: 768000
    num_steps_trained: 768000
    wait_time_ms: 74.625
  iterations_since_restore: 256
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2311.4176087379456
  time_this_iter_s: 10.181447267532349
  time_total_s: 2311.4176087379456
  timestamp: 1594097078
  timesteps_since_restore: 768000
  timesteps_this_iter: 3000
  timesteps_total: 768000
  training_iteration: 256
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2311 s, 256 iter, 768000 ts, 999 rew

agent-1: 444.0
agent-2: 462.0
agent-3: 365.0
Sum Reward: 1271.0
Avg Reward: 423.6666666666667
Min Reward: 365.0
Max Reward: 462.0
Gini Coefficient: 0.05087857330186205
20:20 Ratio: 1.2657534246575342
Max-min Ratio: 1.2657534246575342
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-44-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1002.39
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 256
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.564
    dispatch_time_ms: 27.738
    learner:
      cur_lr: 0.0013088511768728495
      grad_gnorm: 39.999996185302734
      policy_entropy: 9.161355018615723
      policy_loss: -16.38118553161621
      var_gnorm: 38.21359634399414
      vf_explained_var: 0.45305073261260986
      vf_loss: 41.35946273803711
    num_steps_sampled: 771000
    num_steps_trained: 771000
    wait_time_ms: 62.053
  iterations_since_restore: 257
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2322.066099882126
  time_this_iter_s: 10.648491144180298
  time_total_s: 2322.066099882126
  timestamp: 1594097089
  timesteps_since_restore: 771000
  timesteps_this_iter: 3000
  timesteps_total: 771000
  training_iteration: 257
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2322 s, 257 iter, 771000 ts, 1e+03 rew

agent-1: 392.0
agent-2: 448.0
agent-3: 459.0
Sum Reward: 1299.0
Avg Reward: 433.0
Min Reward: 392.0
Max Reward: 459.0
Gini Coefficient: 0.034385424685655634
20:20 Ratio: 1.1709183673469388
Max-min Ratio: 1.1709183673469388
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-44-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1005.52
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 257
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.586
    dispatch_time_ms: 33.46
    learner:
      cur_lr: 0.0013086514081805944
      grad_gnorm: 37.954734802246094
      policy_entropy: 5.757393836975098
      policy_loss: -0.8494256734848022
      var_gnorm: 38.26488494873047
      vf_explained_var: 0.3242154121398926
      vf_loss: 23.00896644592285
    num_steps_sampled: 774000
    num_steps_trained: 774000
    wait_time_ms: 70.291
  iterations_since_restore: 258
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2332.0176661014557
  time_this_iter_s: 9.951566219329834
  time_total_s: 2332.0176661014557
  timestamp: 1594097099
  timesteps_since_restore: 774000
  timesteps_this_iter: 3000
  timesteps_total: 774000
  training_iteration: 258
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2332 s, 258 iter, 774000 ts, 1.01e+03 rew

agent-1: 448.0
agent-2: 416.0
agent-3: 396.0
Sum Reward: 1260.0
Avg Reward: 420.0
Min Reward: 396.0
Max Reward: 448.0
Gini Coefficient: 0.027513227513227514
20:20 Ratio: 1.1313131313131313
Max-min Ratio: 1.1313131313131313
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-45-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1007.96
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 258
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.728
    dispatch_time_ms: 19.055
    learner:
      cur_lr: 0.0013084516394883394
      grad_gnorm: 40.000003814697266
      policy_entropy: 11.263031005859375
      policy_loss: -45.77385711669922
      var_gnorm: 38.30568313598633
      vf_explained_var: 0.3783300518989563
      vf_loss: 68.06122589111328
    num_steps_sampled: 777000
    num_steps_trained: 777000
    wait_time_ms: 79.495
  iterations_since_restore: 259
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2343.080709218979
  time_this_iter_s: 11.063043117523193
  time_total_s: 2343.080709218979
  timestamp: 1594097110
  timesteps_since_restore: 777000
  timesteps_this_iter: 3000
  timesteps_total: 777000
  training_iteration: 259
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2343 s, 259 iter, 777000 ts, 1.01e+03 rew

agent-1: 477.0
agent-2: 400.0
agent-3: 438.0
Sum Reward: 1315.0
Avg Reward: 438.3333333333333
Min Reward: 400.0
Max Reward: 477.0
Gini Coefficient: 0.03903675538656527
20:20 Ratio: 1.1925
Max-min Ratio: 1.1925
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-45-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1011.23
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 259
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.733
    dispatch_time_ms: 28.984
    learner:
      cur_lr: 0.0013082517543807626
      grad_gnorm: 40.000003814697266
      policy_entropy: 11.98267936706543
      policy_loss: 6.040411472320557
      var_gnorm: 38.36271286010742
      vf_explained_var: 0.19668203592300415
      vf_loss: 27.472248077392578
    num_steps_sampled: 780000
    num_steps_trained: 780000
    wait_time_ms: 72.211
  iterations_since_restore: 260
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2353.4037024974823
  time_this_iter_s: 10.322993278503418
  time_total_s: 2353.4037024974823
  timestamp: 1594097121
  timesteps_since_restore: 780000
  timesteps_this_iter: 3000
  timesteps_total: 780000
  training_iteration: 260
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2353 s, 260 iter, 780000 ts, 1.01e+03 rew

agent-1: 430.0
agent-2: 397.0
agent-3: 438.0
Sum Reward: 1265.0
Avg Reward: 421.6666666666667
Min Reward: 397.0
Max Reward: 438.0
Gini Coefficient: 0.02160737812911726
20:20 Ratio: 1.1032745591939546
Max-min Ratio: 1.1032745591939546
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-45-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1015.16
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 260
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.139
    dispatch_time_ms: 23.1
    learner:
      cur_lr: 0.0013080519856885076
      grad_gnorm: 40.0
      policy_entropy: 4.761284828186035
      policy_loss: 0.6215547919273376
      var_gnorm: 38.3677978515625
      vf_explained_var: 0.34345507621765137
      vf_loss: 85.34251403808594
    num_steps_sampled: 783000
    num_steps_trained: 783000
    wait_time_ms: 71.943
  iterations_since_restore: 261
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2364.5441880226135
  time_this_iter_s: 11.140485525131226
  time_total_s: 2364.5441880226135
  timestamp: 1594097139
  timesteps_since_restore: 783000
  timesteps_this_iter: 3000
  timesteps_total: 783000
  training_iteration: 261
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2364 s, 261 iter, 783000 ts, 1.02e+03 rew

agent-1: 437.0
agent-2: 461.0
agent-3: 434.0
Sum Reward: 1332.0
Avg Reward: 444.0
Min Reward: 434.0
Max Reward: 461.0
Gini Coefficient: 0.013513513513513514
20:20 Ratio: 1.0622119815668203
Max-min Ratio: 1.0622119815668203
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-45-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1019.41
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 261
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.527
    dispatch_time_ms: 5.356
    learner:
      cur_lr: 0.0013078522169962525
      grad_gnorm: 40.0
      policy_entropy: 7.804015159606934
      policy_loss: 7.514509201049805
      var_gnorm: 38.41119384765625
      vf_explained_var: -0.4072662591934204
      vf_loss: 25.841825485229492
    num_steps_sampled: 786000
    num_steps_trained: 786000
    wait_time_ms: 95.927
  iterations_since_restore: 262
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2374.2519414424896
  time_this_iter_s: 9.707753419876099
  time_total_s: 2374.2519414424896
  timestamp: 1594097149
  timesteps_since_restore: 786000
  timesteps_this_iter: 3000
  timesteps_total: 786000
  training_iteration: 262
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2374 s, 262 iter, 786000 ts, 1.02e+03 rew

agent-1: 451.0
agent-2: 500.0
agent-3: 427.0
Sum Reward: 1378.0
Avg Reward: 459.3333333333333
Min Reward: 427.0
Max Reward: 500.0
Gini Coefficient: 0.03531688437348815
20:20 Ratio: 1.17096018735363
Max-min Ratio: 1.17096018735363
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-45-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1024.85
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 262
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.623
    dispatch_time_ms: 7.617
    learner:
      cur_lr: 0.0013076524483039975
      grad_gnorm: 39.99998474121094
      policy_entropy: 5.668562412261963
      policy_loss: -0.4258970320224762
      var_gnorm: 38.4481315612793
      vf_explained_var: 0.08627945184707642
      vf_loss: 21.072755813598633
    num_steps_sampled: 789000
    num_steps_trained: 789000
    wait_time_ms: 75.612
  iterations_since_restore: 263
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2385.0046632289886
  time_this_iter_s: 10.752721786499023
  time_total_s: 2385.0046632289886
  timestamp: 1594097159
  timesteps_since_restore: 789000
  timesteps_this_iter: 3000
  timesteps_total: 789000
  training_iteration: 263
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2385 s, 263 iter, 789000 ts, 1.02e+03 rew

agent-1: 401.0
agent-2: 442.0
agent-3: 424.0
Sum Reward: 1267.0
Avg Reward: 422.3333333333333
Min Reward: 401.0
Max Reward: 442.0
Gini Coefficient: 0.02157327019205472
20:20 Ratio: 1.1022443890274314
Max-min Ratio: 1.1022443890274314
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-46-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1031.7
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 263
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.855
    dispatch_time_ms: 7.126
    learner:
      cur_lr: 0.0013074525631964207
      grad_gnorm: 40.0
      policy_entropy: 6.22175407409668
      policy_loss: 2.3631680011749268
      var_gnorm: 38.50623321533203
      vf_explained_var: 0.40174436569213867
      vf_loss: 34.01791000366211
    num_steps_sampled: 792000
    num_steps_trained: 792000
    wait_time_ms: 89.942
  iterations_since_restore: 264
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2394.5965003967285
  time_this_iter_s: 9.591837167739868
  time_total_s: 2394.5965003967285
  timestamp: 1594097169
  timesteps_since_restore: 792000
  timesteps_this_iter: 3000
  timesteps_total: 792000
  training_iteration: 264
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2394 s, 264 iter, 792000 ts, 1.03e+03 rew

agent-1: 355.0
agent-2: 453.0
agent-3: 382.0
Sum Reward: 1190.0
Avg Reward: 396.6666666666667
Min Reward: 355.0
Max Reward: 453.0
Gini Coefficient: 0.054901960784313725
20:20 Ratio: 1.276056338028169
Max-min Ratio: 1.276056338028169
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-46-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1035.52
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 264
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.557
    dispatch_time_ms: 7.356
    learner:
      cur_lr: 0.0013072527945041656
      grad_gnorm: 40.0
      policy_entropy: 12.373916625976562
      policy_loss: 11.348745346069336
      var_gnorm: 38.54357147216797
      vf_explained_var: 0.7334112524986267
      vf_loss: 28.315874099731445
    num_steps_sampled: 795000
    num_steps_trained: 795000
    wait_time_ms: 72.331
  iterations_since_restore: 265
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2405.270878314972
  time_this_iter_s: 10.674377918243408
  time_total_s: 2405.270878314972
  timestamp: 1594097180
  timesteps_since_restore: 795000
  timesteps_this_iter: 3000
  timesteps_total: 795000
  training_iteration: 265
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2405 s, 265 iter, 795000 ts, 1.04e+03 rew

agent-1: 356.0
agent-2: 365.0
agent-3: 497.0
Sum Reward: 1218.0
Avg Reward: 406.0
Min Reward: 356.0
Max Reward: 497.0
Gini Coefficient: 0.07717569786535304
20:20 Ratio: 1.396067415730337
Max-min Ratio: 1.396067415730337
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-46-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1038.9
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 265
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.396
    dispatch_time_ms: 9.534
    learner:
      cur_lr: 0.0013070530258119106
      grad_gnorm: 40.000003814697266
      policy_entropy: 16.950057983398438
      policy_loss: -25.674772262573242
      var_gnorm: 38.58063888549805
      vf_explained_var: 0.4768912196159363
      vf_loss: 46.955711364746094
    num_steps_sampled: 798000
    num_steps_trained: 798000
    wait_time_ms: 88.168
  iterations_since_restore: 266
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2414.6739161014557
  time_this_iter_s: 9.403037786483765
  time_total_s: 2414.6739161014557
  timestamp: 1594097189
  timesteps_since_restore: 798000
  timesteps_this_iter: 3000
  timesteps_total: 798000
  training_iteration: 266
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2414 s, 266 iter, 798000 ts, 1.04e+03 rew

agent-1: 418.0
agent-2: 499.0
agent-3: 319.0
Sum Reward: 1236.0
Avg Reward: 412.0
Min Reward: 319.0
Max Reward: 499.0
Gini Coefficient: 0.0970873786407767
20:20 Ratio: 1.5642633228840126
Max-min Ratio: 1.5642633228840126
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-46-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1042.49
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 266
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.704
    dispatch_time_ms: 6.747
    learner:
      cur_lr: 0.0013068532571196556
      grad_gnorm: 40.0
      policy_entropy: 13.134624481201172
      policy_loss: 7.116940975189209
      var_gnorm: 38.596832275390625
      vf_explained_var: 0.28935617208480835
      vf_loss: 52.86064910888672
    num_steps_sampled: 801000
    num_steps_trained: 801000
    wait_time_ms: 87.776
  iterations_since_restore: 267
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2425.2402353286743
  time_this_iter_s: 10.566319227218628
  time_total_s: 2425.2402353286743
  timestamp: 1594097200
  timesteps_since_restore: 801000
  timesteps_this_iter: 3000
  timesteps_total: 801000
  training_iteration: 267
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2425 s, 267 iter, 801000 ts, 1.04e+03 rew

agent-1: 427.0
agent-2: 424.0
agent-3: 307.0
Sum Reward: 1158.0
Avg Reward: 386.0
Min Reward: 307.0
Max Reward: 427.0
Gini Coefficient: 0.0690846286701209
20:20 Ratio: 1.3908794788273615
Max-min Ratio: 1.3908794788273615
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-46-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1046.54
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 267
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.892
    dispatch_time_ms: 8.191
    learner:
      cur_lr: 0.0013066533720120788
      grad_gnorm: 40.000003814697266
      policy_entropy: 16.934494018554688
      policy_loss: -12.443815231323242
      var_gnorm: 38.67025375366211
      vf_explained_var: 0.269209086894989
      vf_loss: 72.11300659179688
    num_steps_sampled: 804000
    num_steps_trained: 804000
    wait_time_ms: 85.071
  iterations_since_restore: 268
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2434.737449645996
  time_this_iter_s: 9.497214317321777
  time_total_s: 2434.737449645996
  timestamp: 1594097209
  timesteps_since_restore: 804000
  timesteps_this_iter: 3000
  timesteps_total: 804000
  training_iteration: 268
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2434 s, 268 iter, 804000 ts, 1.05e+03 rew

agent-1: 347.0
agent-2: 450.0
agent-3: 391.0
Sum Reward: 1188.0
Avg Reward: 396.0
Min Reward: 347.0
Max Reward: 450.0
Gini Coefficient: 0.057800224466891134
20:20 Ratio: 1.2968299711815563
Max-min Ratio: 1.2968299711815563
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-46-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1049.98
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 268
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.394
    dispatch_time_ms: 5.681
    learner:
      cur_lr: 0.0013064536033198237
      grad_gnorm: 40.0
      policy_entropy: 14.209917068481445
      policy_loss: -9.988639831542969
      var_gnorm: 38.65443420410156
      vf_explained_var: 0.25621986389160156
      vf_loss: 63.04045486450195
    num_steps_sampled: 807000
    num_steps_trained: 807000
    wait_time_ms: 76.277
  iterations_since_restore: 269
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2443.810797929764
  time_this_iter_s: 9.0733482837677
  time_total_s: 2443.810797929764
  timestamp: 1594097218
  timesteps_since_restore: 807000
  timesteps_this_iter: 3000
  timesteps_total: 807000
  training_iteration: 269
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2443 s, 269 iter, 807000 ts, 1.05e+03 rew

agent-1: 353.0
agent-2: 453.0
agent-3: 404.0
Sum Reward: 1210.0
Avg Reward: 403.3333333333333
Min Reward: 353.0
Max Reward: 453.0
Gini Coefficient: 0.05509641873278237
20:20 Ratio: 1.2832861189801699
Max-min Ratio: 1.2832861189801699
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-47-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1054.27
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 269
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.641
    dispatch_time_ms: 6.873
    learner:
      cur_lr: 0.0013062538346275687
      grad_gnorm: 40.00000762939453
      policy_entropy: 15.99190902709961
      policy_loss: -4.531523704528809
      var_gnorm: 38.75935363769531
      vf_explained_var: -0.231192946434021
      vf_loss: 31.535385131835938
    num_steps_sampled: 810000
    num_steps_trained: 810000
    wait_time_ms: 76.915
  iterations_since_restore: 270
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2452.472635746002
  time_this_iter_s: 8.661837816238403
  time_total_s: 2452.472635746002
  timestamp: 1594097227
  timesteps_since_restore: 810000
  timesteps_this_iter: 3000
  timesteps_total: 810000
  training_iteration: 270
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2452 s, 270 iter, 810000 ts, 1.05e+03 rew

agent-1: 379.0
agent-2: 384.0
agent-3: 398.0
Sum Reward: 1161.0
Avg Reward: 387.0
Min Reward: 379.0
Max Reward: 398.0
Gini Coefficient: 0.010910134941142693
20:20 Ratio: 1.050131926121372
Max-min Ratio: 1.050131926121372
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-47-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1058.48
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 270
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.675
    dispatch_time_ms: 6.895
    learner:
      cur_lr: 0.0013060539495199919
      grad_gnorm: 40.0
      policy_entropy: 12.230688095092773
      policy_loss: 6.527189254760742
      var_gnorm: 38.79262161254883
      vf_explained_var: -0.05822646617889404
      vf_loss: 14.09081745147705
    num_steps_sampled: 813000
    num_steps_trained: 813000
    wait_time_ms: 71.977
  iterations_since_restore: 271
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2461.3795392513275
  time_this_iter_s: 8.906903505325317
  time_total_s: 2461.3795392513275
  timestamp: 1594097236
  timesteps_since_restore: 813000
  timesteps_this_iter: 3000
  timesteps_total: 813000
  training_iteration: 271
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2461 s, 271 iter, 813000 ts, 1.06e+03 rew

agent-1: 385.0
agent-2: 410.0
agent-3: 360.0
Sum Reward: 1155.0
Avg Reward: 385.0
Min Reward: 360.0
Max Reward: 410.0
Gini Coefficient: 0.02886002886002886
20:20 Ratio: 1.1388888888888888
Max-min Ratio: 1.1388888888888888
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-47-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1063.22
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 271
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.818
    dispatch_time_ms: 6.877
    learner:
      cur_lr: 0.0013058541808277369
      grad_gnorm: 23.666711807250977
      policy_entropy: 16.056793212890625
      policy_loss: -0.5230939388275146
      var_gnorm: 38.872032165527344
      vf_explained_var: 0.23062115907669067
      vf_loss: 36.34363555908203
    num_steps_sampled: 816000
    num_steps_trained: 816000
    wait_time_ms: 84.393
  iterations_since_restore: 272
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2470.332073688507
  time_this_iter_s: 8.952534437179565
  time_total_s: 2470.332073688507
  timestamp: 1594097245
  timesteps_since_restore: 816000
  timesteps_this_iter: 3000
  timesteps_total: 816000
  training_iteration: 272
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2470 s, 272 iter, 816000 ts, 1.06e+03 rew

agent-1: 345.0
agent-2: 389.0
agent-3: 349.0
Sum Reward: 1083.0
Avg Reward: 361.0
Min Reward: 345.0
Max Reward: 389.0
Gini Coefficient: 0.02708525700215451
20:20 Ratio: 1.127536231884058
Max-min Ratio: 1.127536231884058
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-47-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1067.28
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 272
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.575
    dispatch_time_ms: 7.168
    learner:
      cur_lr: 0.0013056544121354818
      grad_gnorm: 20.338653564453125
      policy_entropy: 17.852336883544922
      policy_loss: 2.78935170173645
      var_gnorm: 38.85272216796875
      vf_explained_var: 0.20689153671264648
      vf_loss: 18.300918579101562
    num_steps_sampled: 819000
    num_steps_trained: 819000
    wait_time_ms: 70.092
  iterations_since_restore: 273
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2479.663102865219
  time_this_iter_s: 9.331029176712036
  time_total_s: 2479.663102865219
  timestamp: 1594097254
  timesteps_since_restore: 819000
  timesteps_this_iter: 3000
  timesteps_total: 819000
  training_iteration: 273
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2479 s, 273 iter, 819000 ts, 1.07e+03 rew

agent-1: 413.0
agent-2: 408.0
agent-3: 367.0
Sum Reward: 1188.0
Avg Reward: 396.0
Min Reward: 367.0
Max Reward: 413.0
Gini Coefficient: 0.025813692480359147
20:20 Ratio: 1.125340599455041
Max-min Ratio: 1.125340599455041
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-47-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1072.29
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 273
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.414
    dispatch_time_ms: 7.463
    learner:
      cur_lr: 0.0013054546434432268
      grad_gnorm: 39.999996185302734
      policy_entropy: 20.635766983032227
      policy_loss: -14.80573844909668
      var_gnorm: 38.82707977294922
      vf_explained_var: 0.35231953859329224
      vf_loss: 71.44595336914062
    num_steps_sampled: 822000
    num_steps_trained: 822000
    wait_time_ms: 75.548
  iterations_since_restore: 274
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2488.1442465782166
  time_this_iter_s: 8.481143712997437
  time_total_s: 2488.1442465782166
  timestamp: 1594097263
  timesteps_since_restore: 822000
  timesteps_this_iter: 3000
  timesteps_total: 822000
  training_iteration: 274
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2488 s, 274 iter, 822000 ts, 1.07e+03 rew

agent-1: 427.0
agent-2: 383.0
agent-3: 266.0
Sum Reward: 1076.0
Avg Reward: 358.6666666666667
Min Reward: 266.0
Max Reward: 427.0
Gini Coefficient: 0.09975216852540272
20:20 Ratio: 1.605263157894737
Max-min Ratio: 1.605263157894737
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-47-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1076.51
  episode_reward_min: 506.0
  episodes_this_iter: 1
  episodes_total: 274
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.541
    dispatch_time_ms: 5.916
    learner:
      cur_lr: 0.00130525475833565
      grad_gnorm: 40.000003814697266
      policy_entropy: 11.125398635864258
      policy_loss: -4.993602752685547
      var_gnorm: 38.88381576538086
      vf_explained_var: 0.6489112377166748
      vf_loss: 43.14808654785156
    num_steps_sampled: 825000
    num_steps_trained: 825000
    wait_time_ms: 80.871
  iterations_since_restore: 275
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2497.7251420021057
  time_this_iter_s: 9.58089542388916
  time_total_s: 2497.7251420021057
  timestamp: 1594097272
  timesteps_since_restore: 825000
  timesteps_this_iter: 3000
  timesteps_total: 825000
  training_iteration: 275
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2497 s, 275 iter, 825000 ts, 1.08e+03 rew

agent-1: 344.0
agent-2: 379.0
agent-3: 420.0
Sum Reward: 1143.0
Avg Reward: 381.0
Min Reward: 344.0
Max Reward: 420.0
Gini Coefficient: 0.04432779235928842
20:20 Ratio: 1.2209302325581395
Max-min Ratio: 1.2209302325581395
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-48-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1082.88
  episode_reward_min: 559.0
  episodes_this_iter: 1
  episodes_total: 275
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.321
    dispatch_time_ms: 5.177
    learner:
      cur_lr: 0.001305054989643395
      grad_gnorm: 40.0
      policy_entropy: 7.043020725250244
      policy_loss: 9.742118835449219
      var_gnorm: 38.97043228149414
      vf_explained_var: 0.34547436237335205
      vf_loss: 24.391550064086914
    num_steps_sampled: 828000
    num_steps_trained: 828000
    wait_time_ms: 89.823
  iterations_since_restore: 276
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2507.111228942871
  time_this_iter_s: 9.38608694076538
  time_total_s: 2507.111228942871
  timestamp: 1594097282
  timesteps_since_restore: 828000
  timesteps_this_iter: 3000
  timesteps_total: 828000
  training_iteration: 276
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2507 s, 276 iter, 828000 ts, 1.08e+03 rew

agent-1: 444.0
agent-2: 493.0
agent-3: 455.0
Sum Reward: 1392.0
Avg Reward: 464.0
Min Reward: 444.0
Max Reward: 493.0
Gini Coefficient: 0.02346743295019157
20:20 Ratio: 1.1103603603603605
Max-min Ratio: 1.1103603603603605
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-48-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1090.86
  episode_reward_min: 559.0
  episodes_this_iter: 1
  episodes_total: 276
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.064
    dispatch_time_ms: 7.333
    learner:
      cur_lr: 0.00130485522095114
      grad_gnorm: 40.0
      policy_entropy: 10.258636474609375
      policy_loss: -15.51485538482666
      var_gnorm: 39.01064682006836
      vf_explained_var: 0.6255089044570923
      vf_loss: 39.54267883300781
    num_steps_sampled: 831000
    num_steps_trained: 831000
    wait_time_ms: 87.515
  iterations_since_restore: 277
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2517.38973236084
  time_this_iter_s: 10.27850341796875
  time_total_s: 2517.38973236084
  timestamp: 1594097292
  timesteps_since_restore: 831000
  timesteps_this_iter: 3000
  timesteps_total: 831000
  training_iteration: 277
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2517 s, 277 iter, 831000 ts, 1.09e+03 rew

agent-1: 394.0
agent-2: 396.0
agent-3: 503.0
Sum Reward: 1293.0
Avg Reward: 431.0
Min Reward: 394.0
Max Reward: 503.0
Gini Coefficient: 0.05620005155968033
20:20 Ratio: 1.2766497461928934
Max-min Ratio: 1.2766497461928934
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-48-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1097.27
  episode_reward_min: 559.0
  episodes_this_iter: 1
  episodes_total: 277
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.729
    dispatch_time_ms: 5.843
    learner:
      cur_lr: 0.001304655452258885
      grad_gnorm: 40.0
      policy_entropy: 10.487801551818848
      policy_loss: -2.5176515579223633
      var_gnorm: 39.066593170166016
      vf_explained_var: -1.0
      vf_loss: 38.107757568359375
    num_steps_sampled: 834000
    num_steps_trained: 834000
    wait_time_ms: 92.107
  iterations_since_restore: 278
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2526.411700963974
  time_this_iter_s: 9.021968603134155
  time_total_s: 2526.411700963974
  timestamp: 1594097301
  timesteps_since_restore: 834000
  timesteps_this_iter: 3000
  timesteps_total: 834000
  training_iteration: 278
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2526 s, 278 iter, 834000 ts, 1.1e+03 rew

agent-1: 496.0
agent-2: 415.0
agent-3: 355.0
Sum Reward: 1266.0
Avg Reward: 422.0
Min Reward: 355.0
Max Reward: 496.0
Gini Coefficient: 0.07424960505529225
20:20 Ratio: 1.3971830985915492
Max-min Ratio: 1.3971830985915492
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-48-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1101.73
  episode_reward_min: 559.0
  episodes_this_iter: 1
  episodes_total: 278
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.805
    dispatch_time_ms: 6.266
    learner:
      cur_lr: 0.001304455567151308
      grad_gnorm: 40.0
      policy_entropy: 5.985241889953613
      policy_loss: 4.441677093505859
      var_gnorm: 39.1037712097168
      vf_explained_var: -0.003069639205932617
      vf_loss: 42.90089797973633
    num_steps_sampled: 837000
    num_steps_trained: 837000
    wait_time_ms: 82.353
  iterations_since_restore: 279
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2536.446063041687
  time_this_iter_s: 10.034362077713013
  time_total_s: 2536.446063041687
  timestamp: 1594097311
  timesteps_since_restore: 837000
  timesteps_this_iter: 3000
  timesteps_total: 837000
  training_iteration: 279
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2536 s, 279 iter, 837000 ts, 1.1e+03 rew

agent-1: 412.0
agent-2: 451.0
agent-3: 423.0
Sum Reward: 1286.0
Avg Reward: 428.6666666666667
Min Reward: 412.0
Max Reward: 451.0
Gini Coefficient: 0.02021772939346812
20:20 Ratio: 1.0946601941747574
Max-min Ratio: 1.0946601941747574
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-48-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1104.92
  episode_reward_min: 559.0
  episodes_this_iter: 1
  episodes_total: 279
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.898
    dispatch_time_ms: 5.794
    learner:
      cur_lr: 0.001304255798459053
      grad_gnorm: 37.430328369140625
      policy_entropy: 9.742904663085938
      policy_loss: 1.3541755676269531
      var_gnorm: 39.195735931396484
      vf_explained_var: 0.41188472509384155
      vf_loss: 47.38988494873047
    num_steps_sampled: 840000
    num_steps_trained: 840000
    wait_time_ms: 88.241
  iterations_since_restore: 280
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2545.781048297882
  time_this_iter_s: 9.334985256195068
  time_total_s: 2545.781048297882
  timestamp: 1594097321
  timesteps_since_restore: 840000
  timesteps_this_iter: 3000
  timesteps_total: 840000
  training_iteration: 280
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2545 s, 280 iter, 840000 ts, 1.1e+03 rew

agent-1: 440.0
agent-2: 396.0
agent-3: 417.0
Sum Reward: 1253.0
Avg Reward: 417.6666666666667
Min Reward: 396.0
Max Reward: 440.0
Gini Coefficient: 0.02341048151104017
20:20 Ratio: 1.1111111111111112
Max-min Ratio: 1.1111111111111112
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-48-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1107.95
  episode_reward_min: 559.0
  episodes_this_iter: 1
  episodes_total: 280
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.55
    dispatch_time_ms: 7.656
    learner:
      cur_lr: 0.001304056029766798
      grad_gnorm: 23.632566452026367
      policy_entropy: 17.02724266052246
      policy_loss: -2.2208313941955566
      var_gnorm: 39.23565673828125
      vf_explained_var: 0.6432859897613525
      vf_loss: 13.36245346069336
    num_steps_sampled: 843000
    num_steps_trained: 843000
    wait_time_ms: 90.37
  iterations_since_restore: 281
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2555.5831542015076
  time_this_iter_s: 9.802105903625488
  time_total_s: 2555.5831542015076
  timestamp: 1594097330
  timesteps_since_restore: 843000
  timesteps_this_iter: 3000
  timesteps_total: 843000
  training_iteration: 281
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2555 s, 281 iter, 843000 ts, 1.11e+03 rew

agent-1: 356.0
agent-2: 440.0
agent-3: 373.0
Sum Reward: 1169.0
Avg Reward: 389.6666666666667
Min Reward: 356.0
Max Reward: 440.0
Gini Coefficient: 0.04790419161676647
20:20 Ratio: 1.2359550561797752
Max-min Ratio: 1.2359550561797752
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-49-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1111.7
  episode_reward_min: 559.0
  episodes_this_iter: 1
  episodes_total: 281
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.166
    dispatch_time_ms: 5.11
    learner:
      cur_lr: 0.0013038561446592212
      grad_gnorm: 39.999996185302734
      policy_entropy: 9.596232414245605
      policy_loss: -3.9582908153533936
      var_gnorm: 39.190250396728516
      vf_explained_var: 0.6676130294799805
      vf_loss: 47.15983581542969
    num_steps_sampled: 846000
    num_steps_trained: 846000
    wait_time_ms: 105.693
  iterations_since_restore: 282
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2565.336006164551
  time_this_iter_s: 9.752851963043213
  time_total_s: 2565.336006164551
  timestamp: 1594097340
  timesteps_since_restore: 846000
  timesteps_this_iter: 3000
  timesteps_total: 846000
  training_iteration: 282
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2565 s, 282 iter, 846000 ts, 1.11e+03 rew

agent-1: 469.0
agent-2: 390.0
agent-3: 288.0
Sum Reward: 1147.0
Avg Reward: 382.3333333333333
Min Reward: 288.0
Max Reward: 469.0
Gini Coefficient: 0.1052019761697181
20:20 Ratio: 1.6284722222222223
Max-min Ratio: 1.6284722222222223
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-49-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1116.05
  episode_reward_min: 559.0
  episodes_this_iter: 1
  episodes_total: 282
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.935
    dispatch_time_ms: 6.153
    learner:
      cur_lr: 0.0013036563759669662
      grad_gnorm: 27.24357795715332
      policy_entropy: 9.04211711883545
      policy_loss: -0.7600536346435547
      var_gnorm: 39.210235595703125
      vf_explained_var: 0.2395802140235901
      vf_loss: 54.936283111572266
    num_steps_sampled: 849000
    num_steps_trained: 849000
    wait_time_ms: 71.672
  iterations_since_restore: 283
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2575.9344506263733
  time_this_iter_s: 10.59844446182251
  time_total_s: 2575.9344506263733
  timestamp: 1594097351
  timesteps_since_restore: 849000
  timesteps_this_iter: 3000
  timesteps_total: 849000
  training_iteration: 283
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2575 s, 283 iter, 849000 ts, 1.12e+03 rew

agent-1: 396.0
agent-2: 459.0
agent-3: 470.0
Sum Reward: 1325.0
Avg Reward: 441.6666666666667
Min Reward: 396.0
Max Reward: 470.0
Gini Coefficient: 0.03723270440251572
20:20 Ratio: 1.1868686868686869
Max-min Ratio: 1.1868686868686869
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-49-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1123.29
  episode_reward_min: 559.0
  episodes_this_iter: 1
  episodes_total: 283
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.203
    dispatch_time_ms: 8.449
    learner:
      cur_lr: 0.0013034566072747111
      grad_gnorm: 9.558975219726562
      policy_entropy: 10.17518424987793
      policy_loss: 3.1044557094573975
      var_gnorm: 39.299503326416016
      vf_explained_var: -0.13437509536743164
      vf_loss: 6.334336280822754
    num_steps_sampled: 852000
    num_steps_trained: 852000
    wait_time_ms: 86.762
  iterations_since_restore: 284
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2585.1571776866913
  time_this_iter_s: 9.222727060317993
  time_total_s: 2585.1571776866913
  timestamp: 1594097360
  timesteps_since_restore: 852000
  timesteps_this_iter: 3000
  timesteps_total: 852000
  training_iteration: 284
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2585 s, 284 iter, 852000 ts, 1.12e+03 rew

agent-1: 432.0
agent-2: 409.0
agent-3: 386.0
Sum Reward: 1227.0
Avg Reward: 409.0
Min Reward: 386.0
Max Reward: 432.0
Gini Coefficient: 0.024993208367291495
20:20 Ratio: 1.1191709844559585
Max-min Ratio: 1.1191709844559585
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-49-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1129.13
  episode_reward_min: 559.0
  episodes_this_iter: 1
  episodes_total: 284
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.396
    dispatch_time_ms: 6.376
    learner:
      cur_lr: 0.0013032568385824561
      grad_gnorm: 40.0
      policy_entropy: 5.0942230224609375
      policy_loss: 4.834624767303467
      var_gnorm: 39.32474136352539
      vf_explained_var: -0.155511736869812
      vf_loss: 51.52986526489258
    num_steps_sampled: 855000
    num_steps_trained: 855000
    wait_time_ms: 71.5
  iterations_since_restore: 285
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2594.6113843917847
  time_this_iter_s: 9.454206705093384
  time_total_s: 2594.6113843917847
  timestamp: 1594097370
  timesteps_since_restore: 855000
  timesteps_this_iter: 3000
  timesteps_total: 855000
  training_iteration: 285
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2594 s, 285 iter, 855000 ts, 1.13e+03 rew

agent-1: 458.0
agent-2: 453.0
agent-3: 402.0
Sum Reward: 1313.0
Avg Reward: 437.6666666666667
Min Reward: 402.0
Max Reward: 458.0
Gini Coefficient: 0.028433612592028434
20:20 Ratio: 1.1393034825870647
Max-min Ratio: 1.1393034825870647
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-49-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1136.42
  episode_reward_min: 559.0
  episodes_this_iter: 1
  episodes_total: 285
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.991
    dispatch_time_ms: 7.725
    learner:
      cur_lr: 0.0013030569534748793
      grad_gnorm: 40.0
      policy_entropy: 18.535797119140625
      policy_loss: -9.370299339294434
      var_gnorm: 39.398075103759766
      vf_explained_var: 0.6681113243103027
      vf_loss: 20.52525520324707
    num_steps_sampled: 858000
    num_steps_trained: 858000
    wait_time_ms: 87.765
  iterations_since_restore: 286
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2603.4959819316864
  time_this_iter_s: 8.884597539901733
  time_total_s: 2603.4959819316864
  timestamp: 1594097379
  timesteps_since_restore: 858000
  timesteps_this_iter: 3000
  timesteps_total: 858000
  training_iteration: 286
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2603 s, 286 iter, 858000 ts, 1.14e+03 rew

agent-1: 381.0
agent-2: 435.0
agent-3: 379.0
Sum Reward: 1195.0
Avg Reward: 398.3333333333333
Min Reward: 379.0
Max Reward: 435.0
Gini Coefficient: 0.031241283124128313
20:20 Ratio: 1.1477572559366755
Max-min Ratio: 1.1477572559366755
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-49-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1142.59
  episode_reward_min: 559.0
  episodes_this_iter: 1
  episodes_total: 286
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.628
    dispatch_time_ms: 6.253
    learner:
      cur_lr: 0.0013028571847826242
      grad_gnorm: 40.0
      policy_entropy: 10.435678482055664
      policy_loss: 4.182623863220215
      var_gnorm: 39.355560302734375
      vf_explained_var: 0.09246271848678589
      vf_loss: 16.912559509277344
    num_steps_sampled: 861000
    num_steps_trained: 861000
    wait_time_ms: 81.006
  iterations_since_restore: 287
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2613.0183959007263
  time_this_iter_s: 9.522413969039917
  time_total_s: 2613.0183959007263
  timestamp: 1594097388
  timesteps_since_restore: 861000
  timesteps_this_iter: 3000
  timesteps_total: 861000
  training_iteration: 287
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2613 s, 287 iter, 861000 ts, 1.14e+03 rew

agent-1: 410.0
agent-2: 459.0
agent-3: 280.0
Sum Reward: 1149.0
Avg Reward: 383.0
Min Reward: 280.0
Max Reward: 459.0
Gini Coefficient: 0.10385842761821874
20:20 Ratio: 1.6392857142857142
Max-min Ratio: 1.6392857142857142
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-49-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1148.49
  episode_reward_min: 575.0
  episodes_this_iter: 1
  episodes_total: 287
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.796
    dispatch_time_ms: 7.836
    learner:
      cur_lr: 0.0013026574160903692
      grad_gnorm: 15.119518280029297
      policy_entropy: 7.132785797119141
      policy_loss: 9.43865966796875
      var_gnorm: 39.38920974731445
      vf_explained_var: -1.0
      vf_loss: 10.77861213684082
    num_steps_sampled: 864000
    num_steps_trained: 864000
    wait_time_ms: 81.319
  iterations_since_restore: 288
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2621.66397190094
  time_this_iter_s: 8.645576000213623
  time_total_s: 2621.66397190094
  timestamp: 1594097397
  timesteps_since_restore: 864000
  timesteps_this_iter: 3000
  timesteps_total: 864000
  training_iteration: 288
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2621 s, 288 iter, 864000 ts, 1.15e+03 rew

agent-1: 357.0
agent-2: 401.0
agent-3: 410.0
Sum Reward: 1168.0
Avg Reward: 389.3333333333333
Min Reward: 357.0
Max Reward: 410.0
Gini Coefficient: 0.030251141552511414
20:20 Ratio: 1.1484593837535013
Max-min Ratio: 1.1484593837535013
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-50-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1153.51
  episode_reward_min: 575.0
  episodes_this_iter: 1
  episodes_total: 288
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.822
    dispatch_time_ms: 7.312
    learner:
      cur_lr: 0.0013024576473981142
      grad_gnorm: 40.0
      policy_entropy: 13.052929878234863
      policy_loss: -0.7302498817443848
      var_gnorm: 39.464664459228516
      vf_explained_var: 0.6041305065155029
      vf_loss: 36.03700637817383
    num_steps_sampled: 867000
    num_steps_trained: 867000
    wait_time_ms: 80.22
  iterations_since_restore: 289
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2631.702078104019
  time_this_iter_s: 10.038106203079224
  time_total_s: 2631.702078104019
  timestamp: 1594097407
  timesteps_since_restore: 867000
  timesteps_this_iter: 3000
  timesteps_total: 867000
  training_iteration: 289
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2631 s, 289 iter, 867000 ts, 1.15e+03 rew

agent-1: 387.0
agent-2: 411.0
agent-3: 432.0
Sum Reward: 1230.0
Avg Reward: 410.0
Min Reward: 387.0
Max Reward: 432.0
Gini Coefficient: 0.024390243902439025
20:20 Ratio: 1.1162790697674418
Max-min Ratio: 1.1162790697674418
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-50-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1159.02
  episode_reward_min: 575.0
  episodes_this_iter: 1
  episodes_total: 289
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.719
    dispatch_time_ms: 5.541
    learner:
      cur_lr: 0.0013022577622905374
      grad_gnorm: 10.441675186157227
      policy_entropy: 11.70930004119873
      policy_loss: 4.382089614868164
      var_gnorm: 39.548458099365234
      vf_explained_var: -0.24166977405548096
      vf_loss: 8.517218589782715
    num_steps_sampled: 870000
    num_steps_trained: 870000
    wait_time_ms: 87.7
  iterations_since_restore: 290
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2641.1278746128082
  time_this_iter_s: 9.425796508789062
  time_total_s: 2641.1278746128082
  timestamp: 1594097416
  timesteps_since_restore: 870000
  timesteps_this_iter: 3000
  timesteps_total: 870000
  training_iteration: 290
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2641 s, 290 iter, 870000 ts, 1.16e+03 rew

agent-1: 463.0
agent-2: 439.0
agent-3: 434.0
Sum Reward: 1336.0
Avg Reward: 445.3333333333333
Min Reward: 434.0
Max Reward: 463.0
Gini Coefficient: 0.014471057884231538
20:20 Ratio: 1.066820276497696
Max-min Ratio: 1.066820276497696
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-50-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1164.61
  episode_reward_min: 575.0
  episodes_this_iter: 1
  episodes_total: 290
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.502
    dispatch_time_ms: 7.045
    learner:
      cur_lr: 0.0013020579935982823
      grad_gnorm: 40.000003814697266
      policy_entropy: 16.572154998779297
      policy_loss: -17.85703468322754
      var_gnorm: 39.6375617980957
      vf_explained_var: 0.6149967908859253
      vf_loss: 52.76590347290039
    num_steps_sampled: 873000
    num_steps_trained: 873000
    wait_time_ms: 72.988
  iterations_since_restore: 291
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2650.75203537941
  time_this_iter_s: 9.624160766601562
  time_total_s: 2650.75203537941
  timestamp: 1594097426
  timesteps_since_restore: 873000
  timesteps_this_iter: 3000
  timesteps_total: 873000
  training_iteration: 291
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2650 s, 291 iter, 873000 ts, 1.16e+03 rew

agent-1: 457.0
agent-2: 396.0
agent-3: 383.0
Sum Reward: 1236.0
Avg Reward: 412.0
Min Reward: 383.0
Max Reward: 457.0
Gini Coefficient: 0.039913700107874865
20:20 Ratio: 1.1932114882506528
Max-min Ratio: 1.1932114882506528
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-50-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1168.35
  episode_reward_min: 575.0
  episodes_this_iter: 1
  episodes_total: 291
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.779
    dispatch_time_ms: 7.392
    learner:
      cur_lr: 0.0013018582249060273
      grad_gnorm: 40.0
      policy_entropy: 8.782829284667969
      policy_loss: -23.374162673950195
      var_gnorm: 39.63645553588867
      vf_explained_var: 0.7209855318069458
      vf_loss: 52.989830017089844
    num_steps_sampled: 876000
    num_steps_trained: 876000
    wait_time_ms: 92.893
  iterations_since_restore: 292
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2660.1596710681915
  time_this_iter_s: 9.407635688781738
  time_total_s: 2660.1596710681915
  timestamp: 1594097435
  timesteps_since_restore: 876000
  timesteps_this_iter: 3000
  timesteps_total: 876000
  training_iteration: 292
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2660 s, 292 iter, 876000 ts, 1.17e+03 rew

agent-1: 434.0
agent-2: 442.0
agent-3: 367.0
Sum Reward: 1243.0
Avg Reward: 414.3333333333333
Min Reward: 367.0
Max Reward: 442.0
Gini Coefficient: 0.04022526146419952
20:20 Ratio: 1.2043596730245232
Max-min Ratio: 1.2043596730245232
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-50-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1170.82
  episode_reward_min: 575.0
  episodes_this_iter: 1
  episodes_total: 292
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.614
    dispatch_time_ms: 5.686
    learner:
      cur_lr: 0.0013016584562137723
      grad_gnorm: 9.852364540100098
      policy_entropy: 7.532567977905273
      policy_loss: -5.778079032897949
      var_gnorm: 39.645774841308594
      vf_explained_var: -0.21068131923675537
      vf_loss: 22.435699462890625
    num_steps_sampled: 879000
    num_steps_trained: 879000
    wait_time_ms: 83.512
  iterations_since_restore: 293
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2670.836048603058
  time_this_iter_s: 10.676377534866333
  time_total_s: 2670.836048603058
  timestamp: 1594097446
  timesteps_since_restore: 879000
  timesteps_this_iter: 3000
  timesteps_total: 879000
  training_iteration: 293
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2670 s, 293 iter, 879000 ts, 1.17e+03 rew

agent-1: 359.0
agent-2: 438.0
agent-3: 394.0
Sum Reward: 1191.0
Avg Reward: 397.0
Min Reward: 359.0
Max Reward: 438.0
Gini Coefficient: 0.04422054296109712
20:20 Ratio: 1.2200557103064067
Max-min Ratio: 1.2200557103064067
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-50-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1173.91
  episode_reward_min: 575.0
  episodes_this_iter: 1
  episodes_total: 293
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.951
    dispatch_time_ms: 6.36
    learner:
      cur_lr: 0.0013014585711061954
      grad_gnorm: 40.0
      policy_entropy: 6.2454400062561035
      policy_loss: -5.660944938659668
      var_gnorm: 39.65813446044922
      vf_explained_var: 0.6689524054527283
      vf_loss: 53.702449798583984
    num_steps_sampled: 882000
    num_steps_trained: 882000
    wait_time_ms: 97.534
  iterations_since_restore: 294
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2680.486255645752
  time_this_iter_s: 9.650207042694092
  time_total_s: 2680.486255645752
  timestamp: 1594097456
  timesteps_since_restore: 882000
  timesteps_this_iter: 3000
  timesteps_total: 882000
  training_iteration: 294
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2680 s, 294 iter, 882000 ts, 1.17e+03 rew

agent-1: 502.0
agent-2: 450.0
agent-3: 292.0
Sum Reward: 1244.0
Avg Reward: 414.6666666666667
Min Reward: 292.0
Max Reward: 502.0
Gini Coefficient: 0.11254019292604502
20:20 Ratio: 1.7191780821917808
Max-min Ratio: 1.7191780821917808
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-51-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1179.69
  episode_reward_min: 575.0
  episodes_this_iter: 1
  episodes_total: 294
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.453
    dispatch_time_ms: 8.063
    learner:
      cur_lr: 0.0013012588024139404
      grad_gnorm: 26.946481704711914
      policy_entropy: 8.124144554138184
      policy_loss: 0.1386364996433258
      var_gnorm: 39.71287536621094
      vf_explained_var: 0.7057300806045532
      vf_loss: 23.854049682617188
    num_steps_sampled: 885000
    num_steps_trained: 885000
    wait_time_ms: 88.26
  iterations_since_restore: 295
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2691.012478351593
  time_this_iter_s: 10.526222705841064
  time_total_s: 2691.012478351593
  timestamp: 1594097466
  timesteps_since_restore: 885000
  timesteps_this_iter: 3000
  timesteps_total: 885000
  training_iteration: 295
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2691 s, 295 iter, 885000 ts, 1.18e+03 rew

agent-1: 405.0
agent-2: 428.0
agent-3: 419.0
Sum Reward: 1252.0
Avg Reward: 417.3333333333333
Min Reward: 405.0
Max Reward: 428.0
Gini Coefficient: 0.012247071352502662
20:20 Ratio: 1.05679012345679
Max-min Ratio: 1.05679012345679
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-51-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1186.46
  episode_reward_min: 611.0
  episodes_this_iter: 1
  episodes_total: 295
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.93
    dispatch_time_ms: 6.797
    learner:
      cur_lr: 0.0013010590337216854
      grad_gnorm: 40.0
      policy_entropy: 10.584577560424805
      policy_loss: 0.10967123508453369
      var_gnorm: 39.75648498535156
      vf_explained_var: 0.6559020280838013
      vf_loss: 55.11174774169922
    num_steps_sampled: 888000
    num_steps_trained: 888000
    wait_time_ms: 87.934
  iterations_since_restore: 296
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2700.32923412323
  time_this_iter_s: 9.316755771636963
  time_total_s: 2700.32923412323
  timestamp: 1594097476
  timesteps_since_restore: 888000
  timesteps_this_iter: 3000
  timesteps_total: 888000
  training_iteration: 296
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2700 s, 296 iter, 888000 ts, 1.19e+03 rew

agent-1: 414.0
agent-2: 427.0
agent-3: 394.0
Sum Reward: 1235.0
Avg Reward: 411.6666666666667
Min Reward: 394.0
Max Reward: 427.0
Gini Coefficient: 0.017813765182186234
20:20 Ratio: 1.083756345177665
Max-min Ratio: 1.083756345177665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-51-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1192.12
  episode_reward_min: 611.0
  episodes_this_iter: 1
  episodes_total: 296
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.426
    dispatch_time_ms: 7.942
    learner:
      cur_lr: 0.0013008591486141086
      grad_gnorm: 33.2987174987793
      policy_entropy: 11.373497009277344
      policy_loss: -6.201329708099365
      var_gnorm: 39.808860778808594
      vf_explained_var: 0.6787925958633423
      vf_loss: 71.79013061523438
    num_steps_sampled: 891000
    num_steps_trained: 891000
    wait_time_ms: 84.062
  iterations_since_restore: 297
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2710.190747976303
  time_this_iter_s: 9.86151385307312
  time_total_s: 2710.190747976303
  timestamp: 1594097486
  timesteps_since_restore: 891000
  timesteps_this_iter: 3000
  timesteps_total: 891000
  training_iteration: 297
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2710 s, 297 iter, 891000 ts, 1.19e+03 rew

agent-1: 341.0
agent-2: 466.0
agent-3: 406.0
Sum Reward: 1213.0
Avg Reward: 404.3333333333333
Min Reward: 341.0
Max Reward: 466.0
Gini Coefficient: 0.0687001923605386
20:20 Ratio: 1.3665689149560116
Max-min Ratio: 1.3665689149560116
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-51-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1198.14
  episode_reward_min: 706.0
  episodes_this_iter: 1
  episodes_total: 297
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.643
    dispatch_time_ms: 7.17
    learner:
      cur_lr: 0.0013006593799218535
      grad_gnorm: 27.312217712402344
      policy_entropy: 12.74123764038086
      policy_loss: 2.812994956970215
      var_gnorm: 39.8624153137207
      vf_explained_var: -0.2155996561050415
      vf_loss: 23.373292922973633
    num_steps_sampled: 894000
    num_steps_trained: 894000
    wait_time_ms: 82.63
  iterations_since_restore: 298
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2719.4804039001465
  time_this_iter_s: 9.289655923843384
  time_total_s: 2719.4804039001465
  timestamp: 1594097495
  timesteps_since_restore: 894000
  timesteps_this_iter: 3000
  timesteps_total: 894000
  training_iteration: 298
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2719 s, 298 iter, 894000 ts, 1.2e+03 rew

agent-1: 295.0
agent-2: 481.0
agent-3: 473.0
Sum Reward: 1249.0
Avg Reward: 416.3333333333333
Min Reward: 295.0
Max Reward: 481.0
Gini Coefficient: 0.09927942353883107
20:20 Ratio: 1.6305084745762712
Max-min Ratio: 1.6305084745762712
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-51-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1203.57
  episode_reward_min: 748.0
  episodes_this_iter: 1
  episodes_total: 298
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.483
    dispatch_time_ms: 7.916
    learner:
      cur_lr: 0.0013004596112295985
      grad_gnorm: 40.000003814697266
      policy_entropy: 11.989297866821289
      policy_loss: 11.653548240661621
      var_gnorm: 39.82814025878906
      vf_explained_var: 0.2582894563674927
      vf_loss: 71.31016540527344
    num_steps_sampled: 897000
    num_steps_trained: 897000
    wait_time_ms: 78.292
  iterations_since_restore: 299
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2728.839353322983
  time_this_iter_s: 9.358949422836304
  time_total_s: 2728.839353322983
  timestamp: 1594097504
  timesteps_since_restore: 897000
  timesteps_this_iter: 3000
  timesteps_total: 897000
  training_iteration: 299
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2728 s, 299 iter, 897000 ts, 1.2e+03 rew

agent-1: 495.0
agent-2: 384.0
agent-3: 227.0
Sum Reward: 1106.0
Avg Reward: 368.6666666666667
Min Reward: 227.0
Max Reward: 495.0
Gini Coefficient: 0.161543098251959
20:20 Ratio: 2.1806167400881056
Max-min Ratio: 2.1806167400881056
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-51-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1206.0
  episode_reward_min: 748.0
  episodes_this_iter: 1
  episodes_total: 299
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.655
    dispatch_time_ms: 5.778
    learner:
      cur_lr: 0.0013002598425373435
      grad_gnorm: 40.000003814697266
      policy_entropy: 10.329083442687988
      policy_loss: 8.758491516113281
      var_gnorm: 39.90277099609375
      vf_explained_var: -0.4142758846282959
      vf_loss: 24.20267677307129
    num_steps_sampled: 900000
    num_steps_trained: 900000
    wait_time_ms: 94.015
  iterations_since_restore: 300
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2738.3166377544403
  time_this_iter_s: 9.47728443145752
  time_total_s: 2738.3166377544403
  timestamp: 1594097514
  timesteps_since_restore: 900000
  timesteps_this_iter: 3000
  timesteps_total: 900000
  training_iteration: 300
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2738 s, 300 iter, 900000 ts, 1.21e+03 rew

agent-1: 405.0
agent-2: 437.0
agent-3: 444.0
Sum Reward: 1286.0
Avg Reward: 428.6666666666667
Min Reward: 405.0
Max Reward: 444.0
Gini Coefficient: 0.02021772939346812
20:20 Ratio: 1.0962962962962963
Max-min Ratio: 1.0962962962962963
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-52-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1209.45
  episode_reward_min: 748.0
  episodes_this_iter: 1
  episodes_total: 300
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.732
    dispatch_time_ms: 6.937
    learner:
      cur_lr: 0.0013000599574297667
      grad_gnorm: 40.0
      policy_entropy: 8.324483871459961
      policy_loss: 4.712164402008057
      var_gnorm: 39.939212799072266
      vf_explained_var: -0.34589827060699463
      vf_loss: 20.46312141418457
    num_steps_sampled: 903000
    num_steps_trained: 903000
    wait_time_ms: 82.793
  iterations_since_restore: 301
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2748.2965717315674
  time_this_iter_s: 9.979933977127075
  time_total_s: 2748.2965717315674
  timestamp: 1594097524
  timesteps_since_restore: 903000
  timesteps_this_iter: 3000
  timesteps_total: 903000
  training_iteration: 301
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2748 s, 301 iter, 903000 ts, 1.21e+03 rew

agent-1: 443.0
agent-2: 454.0
agent-3: 444.0
Sum Reward: 1341.0
Avg Reward: 447.0
Min Reward: 443.0
Max Reward: 454.0
Gini Coefficient: 0.005468555804126274
20:20 Ratio: 1.0248306997742664
Max-min Ratio: 1.0248306997742664
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-52-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1213.88
  episode_reward_min: 748.0
  episodes_this_iter: 1
  episodes_total: 301
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.376
    dispatch_time_ms: 5.099
    learner:
      cur_lr: 0.0012998601887375116
      grad_gnorm: 39.99999237060547
      policy_entropy: 12.896472930908203
      policy_loss: -12.81364631652832
      var_gnorm: 39.94636917114258
      vf_explained_var: 0.5374928712844849
      vf_loss: 47.25360870361328
    num_steps_sampled: 906000
    num_steps_trained: 906000
    wait_time_ms: 95.159
  iterations_since_restore: 302
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2757.971659898758
  time_this_iter_s: 9.675088167190552
  time_total_s: 2757.971659898758
  timestamp: 1594097534
  timesteps_since_restore: 906000
  timesteps_this_iter: 3000
  timesteps_total: 906000
  training_iteration: 302
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2757 s, 302 iter, 906000 ts, 1.21e+03 rew

agent-1: 328.0
agent-2: 422.0
agent-3: 415.0
Sum Reward: 1165.0
Avg Reward: 388.3333333333333
Min Reward: 328.0
Max Reward: 422.0
Gini Coefficient: 0.053791130185979974
20:20 Ratio: 1.2865853658536586
Max-min Ratio: 1.2865853658536586
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-52-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1217.96
  episode_reward_min: 748.0
  episodes_this_iter: 1
  episodes_total: 302
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.457
    dispatch_time_ms: 6.928
    learner:
      cur_lr: 0.0012996604200452566
      grad_gnorm: 39.999996185302734
      policy_entropy: 15.137062072753906
      policy_loss: -13.826552391052246
      var_gnorm: 39.98025131225586
      vf_explained_var: 0.5662916302680969
      vf_loss: 69.17282104492188
    num_steps_sampled: 909000
    num_steps_trained: 909000
    wait_time_ms: 79.617
  iterations_since_restore: 303
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2768.0233895778656
  time_this_iter_s: 10.051729679107666
  time_total_s: 2768.0233895778656
  timestamp: 1594097544
  timesteps_since_restore: 909000
  timesteps_this_iter: 3000
  timesteps_total: 909000
  training_iteration: 303
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2768 s, 303 iter, 909000 ts, 1.22e+03 rew

agent-1: 475.0
agent-2: 350.0
agent-3: 331.0
Sum Reward: 1156.0
Avg Reward: 385.3333333333333
Min Reward: 331.0
Max Reward: 475.0
Gini Coefficient: 0.08304498269896193
20:20 Ratio: 1.4350453172205437
Max-min Ratio: 1.4350453172205437
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-52-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1222.04
  episode_reward_min: 750.0
  episodes_this_iter: 1
  episodes_total: 303
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.58
    dispatch_time_ms: 6.8
    learner:
      cur_lr: 0.0012994606513530016
      grad_gnorm: 40.0
      policy_entropy: 14.766142845153809
      policy_loss: -9.215828895568848
      var_gnorm: 40.06708526611328
      vf_explained_var: 0.694365382194519
      vf_loss: 50.30569839477539
    num_steps_sampled: 912000
    num_steps_trained: 912000
    wait_time_ms: 88.03
  iterations_since_restore: 304
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2777.199585914612
  time_this_iter_s: 9.176196336746216
  time_total_s: 2777.199585914612
  timestamp: 1594097553
  timesteps_since_restore: 912000
  timesteps_this_iter: 3000
  timesteps_total: 912000
  training_iteration: 304
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2777 s, 304 iter, 912000 ts, 1.22e+03 rew

agent-1: 437.0
agent-2: 421.0
agent-3: 420.0
Sum Reward: 1278.0
Avg Reward: 426.0
Min Reward: 420.0
Max Reward: 437.0
Gini Coefficient: 0.008868022952529996
20:20 Ratio: 1.0404761904761906
Max-min Ratio: 1.0404761904761906
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-52-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1226.63
  episode_reward_min: 750.0
  episodes_this_iter: 1
  episodes_total: 304
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.43
    dispatch_time_ms: 6.135
    learner:
      cur_lr: 0.0012992607662454247
      grad_gnorm: 40.00000762939453
      policy_entropy: 6.7348175048828125
      policy_loss: -10.012996673583984
      var_gnorm: 40.13474655151367
      vf_explained_var: -0.0295945405960083
      vf_loss: 34.497501373291016
    num_steps_sampled: 915000
    num_steps_trained: 915000
    wait_time_ms: 76.044
  iterations_since_restore: 305
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2786.992970943451
  time_this_iter_s: 9.793385028839111
  time_total_s: 2786.992970943451
  timestamp: 1594097563
  timesteps_since_restore: 915000
  timesteps_this_iter: 3000
  timesteps_total: 915000
  training_iteration: 305
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2786 s, 305 iter, 915000 ts, 1.23e+03 rew

agent-1: 464.0
agent-2: 471.0
agent-3: 460.0
Sum Reward: 1395.0
Avg Reward: 465.0
Min Reward: 460.0
Max Reward: 471.0
Gini Coefficient: 0.0052568697729988055
20:20 Ratio: 1.0239130434782608
Max-min Ratio: 1.0239130434782608
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-52-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1233.08
  episode_reward_min: 977.0
  episodes_this_iter: 1
  episodes_total: 305
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.756
    dispatch_time_ms: 8.717
    learner:
      cur_lr: 0.0012990609975531697
      grad_gnorm: 40.0
      policy_entropy: 14.396430969238281
      policy_loss: -31.30057144165039
      var_gnorm: 40.22365188598633
      vf_explained_var: 0.7449753284454346
      vf_loss: 66.49847412109375
    num_steps_sampled: 918000
    num_steps_trained: 918000
    wait_time_ms: 91.589
  iterations_since_restore: 306
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2796.2944581508636
  time_this_iter_s: 9.30148720741272
  time_total_s: 2796.2944581508636
  timestamp: 1594097572
  timesteps_since_restore: 918000
  timesteps_this_iter: 3000
  timesteps_total: 918000
  training_iteration: 306
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2796 s, 306 iter, 918000 ts, 1.23e+03 rew

agent-1: 444.0
agent-2: 437.0
agent-3: 426.0
Sum Reward: 1307.0
Avg Reward: 435.6666666666667
Min Reward: 426.0
Max Reward: 444.0
Gini Coefficient: 0.009181331293037491
20:20 Ratio: 1.0422535211267605
Max-min Ratio: 1.0422535211267605
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-53-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1235.36
  episode_reward_min: 977.0
  episodes_this_iter: 1
  episodes_total: 306
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.467
    dispatch_time_ms: 6.873
    learner:
      cur_lr: 0.0012988612288609147
      grad_gnorm: 33.35710144042969
      policy_entropy: 7.358058929443359
      policy_loss: 1.4927760362625122
      var_gnorm: 40.19077682495117
      vf_explained_var: -1.0
      vf_loss: 20.87325668334961
    num_steps_sampled: 921000
    num_steps_trained: 921000
    wait_time_ms: 78.25
  iterations_since_restore: 307
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2806.323932647705
  time_this_iter_s: 10.02947449684143
  time_total_s: 2806.323932647705
  timestamp: 1594097582
  timesteps_since_restore: 921000
  timesteps_this_iter: 3000
  timesteps_total: 921000
  training_iteration: 307
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2806 s, 307 iter, 921000 ts, 1.24e+03 rew

agent-1: 443.0
agent-2: 428.0
agent-3: 425.0
Sum Reward: 1296.0
Avg Reward: 432.0
Min Reward: 425.0
Max Reward: 443.0
Gini Coefficient: 0.009259259259259259
20:20 Ratio: 1.0423529411764705
Max-min Ratio: 1.0423529411764705
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-53-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1235.99
  episode_reward_min: 977.0
  episodes_this_iter: 1
  episodes_total: 307
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.582
    dispatch_time_ms: 6.137
    learner:
      cur_lr: 0.0012986613437533379
      grad_gnorm: 11.874459266662598
      policy_entropy: 11.480358123779297
      policy_loss: 1.2957191467285156
      var_gnorm: 40.138206481933594
      vf_explained_var: 0.3485402464866638
      vf_loss: 26.010478973388672
    num_steps_sampled: 924000
    num_steps_trained: 924000
    wait_time_ms: 83.445
  iterations_since_restore: 308
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2815.256880044937
  time_this_iter_s: 8.932947397232056
  time_total_s: 2815.256880044937
  timestamp: 1594097591
  timesteps_since_restore: 924000
  timesteps_this_iter: 3000
  timesteps_total: 924000
  training_iteration: 308
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2815 s, 308 iter, 924000 ts, 1.24e+03 rew

agent-1: 392.0
agent-2: 309.0
agent-3: 343.0
Sum Reward: 1044.0
Avg Reward: 348.0
Min Reward: 309.0
Max Reward: 392.0
Gini Coefficient: 0.05300127713920817
20:20 Ratio: 1.2686084142394822
Max-min Ratio: 1.2686084142394822
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-53-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1233.71
  episode_reward_min: 977.0
  episodes_this_iter: 1
  episodes_total: 308
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.544
    dispatch_time_ms: 6.568
    learner:
      cur_lr: 0.0012984615750610828
      grad_gnorm: 40.0
      policy_entropy: 8.832959175109863
      policy_loss: 14.62666130065918
      var_gnorm: 40.03052520751953
      vf_explained_var: 0.010431230068206787
      vf_loss: 32.46894836425781
    num_steps_sampled: 927000
    num_steps_trained: 927000
    wait_time_ms: 80.858
  iterations_since_restore: 309
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2824.562008857727
  time_this_iter_s: 9.305128812789917
  time_total_s: 2824.562008857727
  timestamp: 1594097600
  timesteps_since_restore: 927000
  timesteps_this_iter: 3000
  timesteps_total: 927000
  training_iteration: 309
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2824 s, 309 iter, 927000 ts, 1.23e+03 rew

agent-1: 321.0
agent-2: 323.0
agent-3: 368.0
Sum Reward: 1012.0
Avg Reward: 337.3333333333333
Min Reward: 321.0
Max Reward: 368.0
Gini Coefficient: 0.030961791831357048
20:20 Ratio: 1.146417445482866
Max-min Ratio: 1.146417445482866
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-53-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1231.14
  episode_reward_min: 977.0
  episodes_this_iter: 1
  episodes_total: 309
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.989
    dispatch_time_ms: 9.668
    learner:
      cur_lr: 0.0012982618063688278
      grad_gnorm: 40.0
      policy_entropy: 11.283924102783203
      policy_loss: 7.561282157897949
      var_gnorm: 40.059181213378906
      vf_explained_var: 0.12454050779342651
      vf_loss: 32.99301528930664
    num_steps_sampled: 930000
    num_steps_trained: 930000
    wait_time_ms: 80.687
  iterations_since_restore: 310
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2833.079512119293
  time_this_iter_s: 8.517503261566162
  time_total_s: 2833.079512119293
  timestamp: 1594097609
  timesteps_since_restore: 930000
  timesteps_this_iter: 3000
  timesteps_total: 930000
  training_iteration: 310
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2833 s, 310 iter, 930000 ts, 1.23e+03 rew

agent-1: 390.0
agent-2: 351.0
agent-3: 384.0
Sum Reward: 1125.0
Avg Reward: 375.0
Min Reward: 351.0
Max Reward: 390.0
Gini Coefficient: 0.02311111111111111
20:20 Ratio: 1.1111111111111112
Max-min Ratio: 1.1111111111111112
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-53-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1231.08
  episode_reward_min: 977.0
  episodes_this_iter: 1
  episodes_total: 310
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.705
    dispatch_time_ms: 6.964
    learner:
      cur_lr: 0.0012980620376765728
      grad_gnorm: 15.409366607666016
      policy_entropy: 7.17893648147583
      policy_loss: 1.5941267013549805
      var_gnorm: 40.12611770629883
      vf_explained_var: -0.2335505485534668
      vf_loss: 10.386377334594727
    num_steps_sampled: 933000
    num_steps_trained: 933000
    wait_time_ms: 80.168
  iterations_since_restore: 311
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2843.052056789398
  time_this_iter_s: 9.97254467010498
  time_total_s: 2843.052056789398
  timestamp: 1594097619
  timesteps_since_restore: 933000
  timesteps_this_iter: 3000
  timesteps_total: 933000
  training_iteration: 311
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2843 s, 311 iter, 933000 ts, 1.23e+03 rew

agent-1: 420.0
agent-2: 395.0
agent-3: 429.0
Sum Reward: 1244.0
Avg Reward: 414.6666666666667
Min Reward: 395.0
Max Reward: 429.0
Gini Coefficient: 0.01822079314040729
20:20 Ratio: 1.0860759493670886
Max-min Ratio: 1.0860759493670886
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-53-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1231.74
  episode_reward_min: 977.0
  episodes_this_iter: 1
  episodes_total: 311
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.502
    dispatch_time_ms: 5.816
    learner:
      cur_lr: 0.001297862152568996
      grad_gnorm: 22.367523193359375
      policy_entropy: 11.393621444702148
      policy_loss: -6.095118522644043
      var_gnorm: 40.167869567871094
      vf_explained_var: 0.19330060482025146
      vf_loss: 34.535823822021484
    num_steps_sampled: 936000
    num_steps_trained: 936000
    wait_time_ms: 86.823
  iterations_since_restore: 312
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2852.3471989631653
  time_this_iter_s: 9.29514217376709
  time_total_s: 2852.3471989631653
  timestamp: 1594097628
  timesteps_since_restore: 936000
  timesteps_this_iter: 3000
  timesteps_total: 936000
  training_iteration: 312
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2852 s, 312 iter, 936000 ts, 1.23e+03 rew

agent-1: 366.0
agent-2: 414.0
agent-3: 385.0
Sum Reward: 1165.0
Avg Reward: 388.3333333333333
Min Reward: 366.0
Max Reward: 414.0
Gini Coefficient: 0.027467811158798282
20:20 Ratio: 1.1311475409836065
Max-min Ratio: 1.1311475409836065
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-53-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1231.57
  episode_reward_min: 977.0
  episodes_this_iter: 1
  episodes_total: 312
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.904
    dispatch_time_ms: 6.816
    learner:
      cur_lr: 0.001297662383876741
      grad_gnorm: 40.0
      policy_entropy: 15.585213661193848
      policy_loss: -18.381519317626953
      var_gnorm: 40.134613037109375
      vf_explained_var: 0.5692411065101624
      vf_loss: 81.7220458984375
    num_steps_sampled: 939000
    num_steps_trained: 939000
    wait_time_ms: 71.965
  iterations_since_restore: 313
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2862.0394744873047
  time_this_iter_s: 9.692275524139404
  time_total_s: 2862.0394744873047
  timestamp: 1594097638
  timesteps_since_restore: 939000
  timesteps_this_iter: 3000
  timesteps_total: 939000
  training_iteration: 313
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2862 s, 313 iter, 939000 ts, 1.23e+03 rew

agent-1: 205.0
agent-2: 265.0
agent-3: 408.0
Sum Reward: 878.0
Avg Reward: 292.6666666666667
Min Reward: 205.0
Max Reward: 408.0
Gini Coefficient: 0.15413819286256644
20:20 Ratio: 1.9902439024390244
Max-min Ratio: 1.9902439024390244
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-54-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1227.99
  episode_reward_min: 878.0
  episodes_this_iter: 1
  episodes_total: 313
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.592
    dispatch_time_ms: 7.045
    learner:
      cur_lr: 0.001297462615184486
      grad_gnorm: 40.0
      policy_entropy: 14.195258140563965
      policy_loss: -32.84345626831055
      var_gnorm: 40.12917709350586
      vf_explained_var: 0.028708219528198242
      vf_loss: 63.39307403564453
    num_steps_sampled: 942000
    num_steps_trained: 942000
    wait_time_ms: 76.831
  iterations_since_restore: 314
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2870.293573141098
  time_this_iter_s: 8.254098653793335
  time_total_s: 2870.293573141098
  timestamp: 1594097646
  timesteps_since_restore: 942000
  timesteps_this_iter: 3000
  timesteps_total: 942000
  training_iteration: 314
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2870 s, 314 iter, 942000 ts, 1.23e+03 rew

agent-1: 372.0
agent-2: 219.0
agent-3: 358.0
Sum Reward: 949.0
Avg Reward: 316.3333333333333
Min Reward: 219.0
Max Reward: 372.0
Gini Coefficient: 0.10748155953635406
20:20 Ratio: 1.6986301369863013
Max-min Ratio: 1.6986301369863013
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-54-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1224.62
  episode_reward_min: 878.0
  episodes_this_iter: 1
  episodes_total: 314
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.056
    dispatch_time_ms: 6.462
    learner:
      cur_lr: 0.001297262846492231
      grad_gnorm: 8.612730026245117
      policy_entropy: 18.353797912597656
      policy_loss: -0.11050884425640106
      var_gnorm: 40.09523391723633
      vf_explained_var: 0.306121289730072
      vf_loss: 4.4019999504089355
    num_steps_sampled: 945000
    num_steps_trained: 945000
    wait_time_ms: 78.872
  iterations_since_restore: 315
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2879.3414812088013
  time_this_iter_s: 9.047908067703247
  time_total_s: 2879.3414812088013
  timestamp: 1594097655
  timesteps_since_restore: 945000
  timesteps_this_iter: 3000
  timesteps_total: 945000
  training_iteration: 315
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2879 s, 315 iter, 945000 ts, 1.22e+03 rew

agent-1: 383.0
agent-2: 319.0
agent-3: 365.0
Sum Reward: 1067.0
Avg Reward: 355.6666666666667
Min Reward: 319.0
Max Reward: 383.0
Gini Coefficient: 0.03998750390502968
20:20 Ratio: 1.2006269592476488
Max-min Ratio: 1.2006269592476488
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-54-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1222.59
  episode_reward_min: 878.0
  episodes_this_iter: 1
  episodes_total: 315
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.39
    dispatch_time_ms: 8.261
    learner:
      cur_lr: 0.001297062961384654
      grad_gnorm: 15.035223007202148
      policy_entropy: 9.897741317749023
      policy_loss: -0.5151503086090088
      var_gnorm: 40.08905029296875
      vf_explained_var: 0.42313194274902344
      vf_loss: 14.010302543640137
    num_steps_sampled: 948000
    num_steps_trained: 948000
    wait_time_ms: 80.284
  iterations_since_restore: 316
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2887.7992327213287
  time_this_iter_s: 8.457751512527466
  time_total_s: 2887.7992327213287
  timestamp: 1594097664
  timesteps_since_restore: 948000
  timesteps_this_iter: 3000
  timesteps_total: 948000
  training_iteration: 316
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2887 s, 316 iter, 948000 ts, 1.22e+03 rew

agent-1: 350.0
agent-2: 362.0
agent-3: 389.0
Sum Reward: 1101.0
Avg Reward: 367.0
Min Reward: 350.0
Max Reward: 389.0
Gini Coefficient: 0.023614895549500452
20:20 Ratio: 1.1114285714285714
Max-min Ratio: 1.1114285714285714
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-54-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1221.22
  episode_reward_min: 878.0
  episodes_this_iter: 1
  episodes_total: 316
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.426
    dispatch_time_ms: 6.653
    learner:
      cur_lr: 0.001296863192692399
      grad_gnorm: 25.740243911743164
      policy_entropy: 16.300785064697266
      policy_loss: -0.40734219551086426
      var_gnorm: 40.129154205322266
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 25.896121978759766
    num_steps_sampled: 951000
    num_steps_trained: 951000
    wait_time_ms: 80.38
  iterations_since_restore: 317
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2896.8897273540497
  time_this_iter_s: 9.090494632720947
  time_total_s: 2896.8897273540497
  timestamp: 1594097673
  timesteps_since_restore: 951000
  timesteps_this_iter: 3000
  timesteps_total: 951000
  training_iteration: 317
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2896 s, 317 iter, 951000 ts, 1.22e+03 rew

agent-1: 355.0
agent-2: 335.0
agent-3: 345.0
Sum Reward: 1035.0
Avg Reward: 345.0
Min Reward: 335.0
Max Reward: 355.0
Gini Coefficient: 0.01288244766505636
20:20 Ratio: 1.0597014925373134
Max-min Ratio: 1.0597014925373134
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-54-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1219.21
  episode_reward_min: 878.0
  episodes_this_iter: 1
  episodes_total: 317
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.754
    dispatch_time_ms: 5.889
    learner:
      cur_lr: 0.001296663424000144
      grad_gnorm: 40.000003814697266
      policy_entropy: 10.164400100708008
      policy_loss: -16.02528190612793
      var_gnorm: 40.160919189453125
      vf_explained_var: 0.05018794536590576
      vf_loss: 35.60247802734375
    num_steps_sampled: 954000
    num_steps_trained: 954000
    wait_time_ms: 73.287
  iterations_since_restore: 318
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2905.6256999969482
  time_this_iter_s: 8.73597264289856
  time_total_s: 2905.6256999969482
  timestamp: 1594097682
  timesteps_since_restore: 954000
  timesteps_this_iter: 3000
  timesteps_total: 954000
  training_iteration: 318
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2905 s, 318 iter, 954000 ts, 1.22e+03 rew

agent-1: 375.0
agent-2: 316.0
agent-3: 379.0
Sum Reward: 1070.0
Avg Reward: 356.6666666666667
Min Reward: 316.0
Max Reward: 379.0
Gini Coefficient: 0.03925233644859813
20:20 Ratio: 1.1993670886075949
Max-min Ratio: 1.1993670886075949
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-54-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1217.37
  episode_reward_min: 878.0
  episodes_this_iter: 1
  episodes_total: 318
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.759
    dispatch_time_ms: 7.675
    learner:
      cur_lr: 0.001296463655307889
      grad_gnorm: 40.0
      policy_entropy: 13.390800476074219
      policy_loss: -10.783820152282715
      var_gnorm: 40.16584777832031
      vf_explained_var: 0.04621076583862305
      vf_loss: 23.438331604003906
    num_steps_sampled: 957000
    num_steps_trained: 957000
    wait_time_ms: 75.801
  iterations_since_restore: 319
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2914.4308552742004
  time_this_iter_s: 8.805155277252197
  time_total_s: 2914.4308552742004
  timestamp: 1594097691
  timesteps_since_restore: 957000
  timesteps_this_iter: 3000
  timesteps_total: 957000
  training_iteration: 319
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2914 s, 319 iter, 957000 ts, 1.22e+03 rew

agent-1: 364.0
agent-2: 325.0
agent-3: 348.0
Sum Reward: 1037.0
Avg Reward: 345.6666666666667
Min Reward: 325.0
Max Reward: 364.0
Gini Coefficient: 0.02507232401157184
20:20 Ratio: 1.12
Max-min Ratio: 1.12
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-54-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1215.92
  episode_reward_min: 878.0
  episodes_this_iter: 1
  episodes_total: 319
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.841
    dispatch_time_ms: 7.979
    learner:
      cur_lr: 0.0012962637702003121
      grad_gnorm: 40.0
      policy_entropy: 16.903799057006836
      policy_loss: -11.432417869567871
      var_gnorm: 40.21305847167969
      vf_explained_var: -0.046932339668273926
      vf_loss: 9.054117202758789
    num_steps_sampled: 960000
    num_steps_trained: 960000
    wait_time_ms: 80.315
  iterations_since_restore: 320
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2922.9466500282288
  time_this_iter_s: 8.51579475402832
  time_total_s: 2922.9466500282288
  timestamp: 1594097699
  timesteps_since_restore: 960000
  timesteps_this_iter: 3000
  timesteps_total: 960000
  training_iteration: 320
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2922 s, 320 iter, 960000 ts, 1.22e+03 rew

agent-1: 387.0
agent-2: 355.0
agent-3: 393.0
Sum Reward: 1135.0
Avg Reward: 378.3333333333333
Min Reward: 355.0
Max Reward: 393.0
Gini Coefficient: 0.022320117474302497
20:20 Ratio: 1.1070422535211268
Max-min Ratio: 1.1070422535211268
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-55-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1214.97
  episode_reward_min: 878.0
  episodes_this_iter: 1
  episodes_total: 320
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.733
    dispatch_time_ms: 7.44
    learner:
      cur_lr: 0.0012960640015080571
      grad_gnorm: 40.0
      policy_entropy: 16.793102264404297
      policy_loss: 15.416399002075195
      var_gnorm: 40.22403335571289
      vf_explained_var: 0.0514829158782959
      vf_loss: 17.56785774230957
    num_steps_sampled: 963000
    num_steps_trained: 963000
    wait_time_ms: 72.514
  iterations_since_restore: 321
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2932.2017834186554
  time_this_iter_s: 9.255133390426636
  time_total_s: 2932.2017834186554
  timestamp: 1594097708
  timesteps_since_restore: 963000
  timesteps_this_iter: 3000
  timesteps_total: 963000
  training_iteration: 321
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2932 s, 321 iter, 963000 ts, 1.21e+03 rew

agent-1: 395.0
agent-2: 335.0
agent-3: 372.0
Sum Reward: 1102.0
Avg Reward: 367.3333333333333
Min Reward: 335.0
Max Reward: 395.0
Gini Coefficient: 0.036297640653357534
20:20 Ratio: 1.1791044776119404
Max-min Ratio: 1.1791044776119404
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-55-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1212.87
  episode_reward_min: 878.0
  episodes_this_iter: 1
  episodes_total: 321
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.449
    dispatch_time_ms: 6.681
    learner:
      cur_lr: 0.001295864232815802
      grad_gnorm: 32.38740539550781
      policy_entropy: 14.407636642456055
      policy_loss: -3.0090813636779785
      var_gnorm: 40.267242431640625
      vf_explained_var: 0.19459831714630127
      vf_loss: 16.461132049560547
    num_steps_sampled: 966000
    num_steps_trained: 966000
    wait_time_ms: 81.546
  iterations_since_restore: 322
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2940.6547825336456
  time_this_iter_s: 8.452999114990234
  time_total_s: 2940.6547825336456
  timestamp: 1594097717
  timesteps_since_restore: 966000
  timesteps_this_iter: 3000
  timesteps_total: 966000
  training_iteration: 322
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2940 s, 322 iter, 966000 ts, 1.21e+03 rew

agent-1: 382.0
agent-2: 339.0
agent-3: 368.0
Sum Reward: 1089.0
Avg Reward: 363.0
Min Reward: 339.0
Max Reward: 382.0
Gini Coefficient: 0.026323844505662688
20:20 Ratio: 1.126843657817109
Max-min Ratio: 1.126843657817109
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-55-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1210.61
  episode_reward_min: 878.0
  episodes_this_iter: 1
  episodes_total: 322
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.93
    dispatch_time_ms: 8.504
    learner:
      cur_lr: 0.0012956643477082253
      grad_gnorm: 35.11286544799805
      policy_entropy: 15.126996040344238
      policy_loss: -6.865670204162598
      var_gnorm: 40.27456283569336
      vf_explained_var: 0.5253242254257202
      vf_loss: 7.949380874633789
    num_steps_sampled: 969000
    num_steps_trained: 969000
    wait_time_ms: 69.242
  iterations_since_restore: 323
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2949.7418508529663
  time_this_iter_s: 9.087068319320679
  time_total_s: 2949.7418508529663
  timestamp: 1594097726
  timesteps_since_restore: 969000
  timesteps_this_iter: 3000
  timesteps_total: 969000
  training_iteration: 323
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2949 s, 323 iter, 969000 ts, 1.21e+03 rew

agent-1: 249.0
agent-2: 329.0
agent-3: 366.0
Sum Reward: 944.0
Avg Reward: 314.6666666666667
Min Reward: 249.0
Max Reward: 366.0
Gini Coefficient: 0.0826271186440678
20:20 Ratio: 1.4698795180722892
Max-min Ratio: 1.4698795180722892
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-55-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1206.93
  episode_reward_min: 878.0
  episodes_this_iter: 1
  episodes_total: 323
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.766
    dispatch_time_ms: 8.549
    learner:
      cur_lr: 0.0012954645790159702
      grad_gnorm: 21.985857009887695
      policy_entropy: 17.129844665527344
      policy_loss: 5.512507438659668
      var_gnorm: 40.35790252685547
      vf_explained_var: 0.027475297451019287
      vf_loss: 10.08737850189209
    num_steps_sampled: 972000
    num_steps_trained: 972000
    wait_time_ms: 78.512
  iterations_since_restore: 324
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2958.2085893154144
  time_this_iter_s: 8.46673846244812
  time_total_s: 2958.2085893154144
  timestamp: 1594097735
  timesteps_since_restore: 972000
  timesteps_this_iter: 3000
  timesteps_total: 972000
  training_iteration: 324
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2958 s, 324 iter, 972000 ts, 1.21e+03 rew

agent-1: 396.0
agent-2: 407.0
agent-3: 380.0
Sum Reward: 1183.0
Avg Reward: 394.3333333333333
Min Reward: 380.0
Max Reward: 407.0
Gini Coefficient: 0.015215553677092139
20:20 Ratio: 1.0710526315789475
Max-min Ratio: 1.0710526315789475
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-55-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1205.68
  episode_reward_min: 878.0
  episodes_this_iter: 1
  episodes_total: 324
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.813
    dispatch_time_ms: 7.216
    learner:
      cur_lr: 0.0012952648103237152
      grad_gnorm: 17.945655822753906
      policy_entropy: 20.205095291137695
      policy_loss: 0.1834176778793335
      var_gnorm: 40.36883544921875
      vf_explained_var: 0.026814281940460205
      vf_loss: 14.440893173217773
    num_steps_sampled: 975000
    num_steps_trained: 975000
    wait_time_ms: 73.871
  iterations_since_restore: 325
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2967.2219223976135
  time_this_iter_s: 9.013333082199097
  time_total_s: 2967.2219223976135
  timestamp: 1594097744
  timesteps_since_restore: 975000
  timesteps_this_iter: 3000
  timesteps_total: 975000
  training_iteration: 325
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2967 s, 325 iter, 975000 ts, 1.21e+03 rew

agent-1: 329.0
agent-2: 405.0
agent-3: 378.0
Sum Reward: 1112.0
Avg Reward: 370.6666666666667
Min Reward: 329.0
Max Reward: 405.0
Gini Coefficient: 0.045563549160671464
20:20 Ratio: 1.2310030395136777
Max-min Ratio: 1.2310030395136777
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-55-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1204.2
  episode_reward_min: 878.0
  episodes_this_iter: 1
  episodes_total: 325
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.446
    dispatch_time_ms: 7.794
    learner:
      cur_lr: 0.0012950650416314602
      grad_gnorm: 21.65853500366211
      policy_entropy: 19.713932037353516
      policy_loss: -4.701676845550537
      var_gnorm: 40.36823272705078
      vf_explained_var: -0.14732110500335693
      vf_loss: 28.576919555664062
    num_steps_sampled: 978000
    num_steps_trained: 978000
    wait_time_ms: 76.609
  iterations_since_restore: 326
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2975.676892518997
  time_this_iter_s: 8.454970121383667
  time_total_s: 2975.676892518997
  timestamp: 1594097752
  timesteps_since_restore: 978000
  timesteps_this_iter: 3000
  timesteps_total: 978000
  training_iteration: 326
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2975 s, 326 iter, 978000 ts, 1.2e+03 rew

agent-1: 382.0
agent-2: 338.0
agent-3: 380.0
Sum Reward: 1100.0
Avg Reward: 366.6666666666667
Min Reward: 338.0
Max Reward: 382.0
Gini Coefficient: 0.02666666666666667
20:20 Ratio: 1.1301775147928994
Max-min Ratio: 1.1301775147928994
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-56-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1203.35
  episode_reward_min: 878.0
  episodes_this_iter: 1
  episodes_total: 326
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.594
    dispatch_time_ms: 7.808
    learner:
      cur_lr: 0.0012948651565238833
      grad_gnorm: 12.340962409973145
      policy_entropy: 22.84884262084961
      policy_loss: -5.758127212524414
      var_gnorm: 40.402408599853516
      vf_explained_var: -0.007515668869018555
      vf_loss: 8.152494430541992
    num_steps_sampled: 981000
    num_steps_trained: 981000
    wait_time_ms: 65.551
  iterations_since_restore: 327
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2984.410795688629
  time_this_iter_s: 8.733903169631958
  time_total_s: 2984.410795688629
  timestamp: 1594097761
  timesteps_since_restore: 981000
  timesteps_this_iter: 3000
  timesteps_total: 981000
  training_iteration: 327
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2984 s, 327 iter, 981000 ts, 1.2e+03 rew

agent-1: 380.0
agent-2: 335.0
agent-3: 355.0
Sum Reward: 1070.0
Avg Reward: 356.6666666666667
Min Reward: 335.0
Max Reward: 380.0
Gini Coefficient: 0.028037383177570093
20:20 Ratio: 1.1343283582089552
Max-min Ratio: 1.1343283582089552
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-56-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1201.11
  episode_reward_min: 878.0
  episodes_this_iter: 1
  episodes_total: 327
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.606
    dispatch_time_ms: 7.777
    learner:
      cur_lr: 0.0012946653878316283
      grad_gnorm: 14.924138069152832
      policy_entropy: 20.37206268310547
      policy_loss: -3.8803868293762207
      var_gnorm: 40.47069549560547
      vf_explained_var: 0.24482643604278564
      vf_loss: 19.316307067871094
    num_steps_sampled: 984000
    num_steps_trained: 984000
    wait_time_ms: 76.816
  iterations_since_restore: 328
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 2992.8237011432648
  time_this_iter_s: 8.41290545463562
  time_total_s: 2992.8237011432648
  timestamp: 1594097769
  timesteps_since_restore: 984000
  timesteps_this_iter: 3000
  timesteps_total: 984000
  training_iteration: 328
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 2992 s, 328 iter, 984000 ts, 1.2e+03 rew

agent-1: 393.0
agent-2: 376.0
agent-3: 357.0
Sum Reward: 1126.0
Avg Reward: 375.3333333333333
Min Reward: 357.0
Max Reward: 393.0
Gini Coefficient: 0.021314387211367674
20:20 Ratio: 1.1008403361344539
Max-min Ratio: 1.1008403361344539
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-56-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1200.83
  episode_reward_min: 878.0
  episodes_this_iter: 1
  episodes_total: 328
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.624
    dispatch_time_ms: 6.485
    learner:
      cur_lr: 0.0012944656191393733
      grad_gnorm: 20.99031639099121
      policy_entropy: 19.19196319580078
      policy_loss: 4.003715515136719
      var_gnorm: 40.50734329223633
      vf_explained_var: -0.11659085750579834
      vf_loss: 10.354923248291016
    num_steps_sampled: 987000
    num_steps_trained: 987000
    wait_time_ms: 73.205
  iterations_since_restore: 329
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3001.5608203411102
  time_this_iter_s: 8.737119197845459
  time_total_s: 3001.5608203411102
  timestamp: 1594097778
  timesteps_since_restore: 987000
  timesteps_this_iter: 3000
  timesteps_total: 987000
  training_iteration: 329
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3001 s, 329 iter, 987000 ts, 1.2e+03 rew

agent-1: 373.0
agent-2: 393.0
agent-3: 352.0
Sum Reward: 1118.0
Avg Reward: 372.6666666666667
Min Reward: 352.0
Max Reward: 393.0
Gini Coefficient: 0.024448419797257006
20:20 Ratio: 1.1164772727272727
Max-min Ratio: 1.1164772727272727
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-56-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1199.75
  episode_reward_min: 878.0
  episodes_this_iter: 1
  episodes_total: 329
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.488
    dispatch_time_ms: 7.463
    learner:
      cur_lr: 0.0012942658504471183
      grad_gnorm: 40.0
      policy_entropy: 18.13541030883789
      policy_loss: -12.913517951965332
      var_gnorm: 40.516807556152344
      vf_explained_var: -0.16786956787109375
      vf_loss: 32.965538024902344
    num_steps_sampled: 990000
    num_steps_trained: 990000
    wait_time_ms: 76.862
  iterations_since_restore: 330
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3009.9834084510803
  time_this_iter_s: 8.422588109970093
  time_total_s: 3009.9834084510803
  timestamp: 1594097787
  timesteps_since_restore: 990000
  timesteps_this_iter: 3000
  timesteps_total: 990000
  training_iteration: 330
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3009 s, 330 iter, 990000 ts, 1.2e+03 rew

agent-1: 356.0
agent-2: 344.0
agent-3: 326.0
Sum Reward: 1026.0
Avg Reward: 342.0
Min Reward: 326.0
Max Reward: 356.0
Gini Coefficient: 0.01949317738791423
20:20 Ratio: 1.0920245398773005
Max-min Ratio: 1.0920245398773005
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-56-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1196.99
  episode_reward_min: 878.0
  episodes_this_iter: 1
  episodes_total: 330
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.822
    dispatch_time_ms: 7.954
    learner:
      cur_lr: 0.0012940659653395414
      grad_gnorm: 20.579551696777344
      policy_entropy: 16.602807998657227
      policy_loss: -4.61944580078125
      var_gnorm: 40.42876052856445
      vf_explained_var: 0.0
      vf_loss: 22.58437156677246
    num_steps_sampled: 993000
    num_steps_trained: 993000
    wait_time_ms: 66.842
  iterations_since_restore: 331
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3018.663736820221
  time_this_iter_s: 8.680328369140625
  time_total_s: 3018.663736820221
  timestamp: 1594097795
  timesteps_since_restore: 993000
  timesteps_this_iter: 3000
  timesteps_total: 993000
  training_iteration: 331
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3018 s, 331 iter, 993000 ts, 1.2e+03 rew

agent-1: 331.0
agent-2: 284.0
agent-3: 311.0
Sum Reward: 926.0
Avg Reward: 308.6666666666667
Min Reward: 284.0
Max Reward: 331.0
Gini Coefficient: 0.033837293016558675
20:20 Ratio: 1.1654929577464788
Max-min Ratio: 1.1654929577464788
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-56-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1191.71
  episode_reward_min: 878.0
  episodes_this_iter: 1
  episodes_total: 331
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.489
    dispatch_time_ms: 7.762
    learner:
      cur_lr: 0.0012938661966472864
      grad_gnorm: 40.000003814697266
      policy_entropy: 17.991838455200195
      policy_loss: -19.886394500732422
      var_gnorm: 40.33330154418945
      vf_explained_var: 0.07523936033248901
      vf_loss: 21.764644622802734
    num_steps_sampled: 996000
    num_steps_trained: 996000
    wait_time_ms: 68.272
  iterations_since_restore: 332
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3026.4647727012634
  time_this_iter_s: 7.8010358810424805
  time_total_s: 3026.4647727012634
  timestamp: 1594097803
  timesteps_since_restore: 996000
  timesteps_this_iter: 3000
  timesteps_total: 996000
  training_iteration: 332
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3026 s, 332 iter, 996000 ts, 1.19e+03 rew

agent-1: 228.0
agent-2: 256.0
agent-3: 247.0
Sum Reward: 731.0
Avg Reward: 243.66666666666666
Min Reward: 228.0
Max Reward: 256.0
Gini Coefficient: 0.02553579571363429
20:20 Ratio: 1.1228070175438596
Max-min Ratio: 1.1228070175438596
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-56-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1185.69
  episode_reward_min: 731.0
  episodes_this_iter: 1
  episodes_total: 332
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.694
    dispatch_time_ms: 6.945
    learner:
      cur_lr: 0.0012936664279550314
      grad_gnorm: 11.295098304748535
      policy_entropy: 14.312057495117188
      policy_loss: -4.505627632141113
      var_gnorm: 40.31224060058594
      vf_explained_var: 0.15607917308807373
      vf_loss: 10.557586669921875
    num_steps_sampled: 999000
    num_steps_trained: 999000
    wait_time_ms: 70.831
  iterations_since_restore: 333
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3034.4705073833466
  time_this_iter_s: 8.00573468208313
  time_total_s: 3034.4705073833466
  timestamp: 1594097811
  timesteps_since_restore: 999000
  timesteps_this_iter: 3000
  timesteps_total: 999000
  training_iteration: 333
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3034 s, 333 iter, 999000 ts, 1.19e+03 rew

agent-1: 265.0
agent-2: 194.0
agent-3: 279.0
Sum Reward: 738.0
Avg Reward: 246.0
Min Reward: 194.0
Max Reward: 279.0
Gini Coefficient: 0.07678410117434507
20:20 Ratio: 1.4381443298969072
Max-min Ratio: 1.4381443298969072
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-56-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1181.61
  episode_reward_min: 731.0
  episodes_this_iter: 1
  episodes_total: 333
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.25
    dispatch_time_ms: 7.927
    learner:
      cur_lr: 0.0012934665428474545
      grad_gnorm: 40.000003814697266
      policy_entropy: 22.935943603515625
      policy_loss: 16.85831069946289
      var_gnorm: 40.324466705322266
      vf_explained_var: 0.17956525087356567
      vf_loss: 26.069229125976562
    num_steps_sampled: 1002000
    num_steps_trained: 1002000
    wait_time_ms: 75.669
  iterations_since_restore: 334
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3042.3441364765167
  time_this_iter_s: 7.873629093170166
  time_total_s: 3042.3441364765167
  timestamp: 1594097819
  timesteps_since_restore: 1002000
  timesteps_this_iter: 3000
  timesteps_total: 1002000
  training_iteration: 334
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3042 s, 334 iter, 1002000 ts, 1.18e+03 rew

agent-1: 292.0
agent-2: 290.0
agent-3: 303.0
Sum Reward: 885.0
Avg Reward: 295.0
Min Reward: 290.0
Max Reward: 303.0
Gini Coefficient: 0.009792843691148776
20:20 Ratio: 1.0448275862068965
Max-min Ratio: 1.0448275862068965
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-57-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1459.0
  episode_reward_mean: 1176.92
  episode_reward_min: 731.0
  episodes_this_iter: 1
  episodes_total: 334
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.72
    dispatch_time_ms: 6.429
    learner:
      cur_lr: 0.0012932667741551995
      grad_gnorm: 8.256793975830078
      policy_entropy: 22.562400817871094
      policy_loss: 1.9745144844055176
      var_gnorm: 40.34699630737305
      vf_explained_var: -0.0004228353500366211
      vf_loss: 10.032078742980957
    num_steps_sampled: 1005000
    num_steps_trained: 1005000
    wait_time_ms: 70.199
  iterations_since_restore: 335
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3050.8226130008698
  time_this_iter_s: 8.478476524353027
  time_total_s: 3050.8226130008698
  timestamp: 1594097828
  timesteps_since_restore: 1005000
  timesteps_this_iter: 3000
  timesteps_total: 1005000
  training_iteration: 335
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3050 s, 335 iter, 1005000 ts, 1.18e+03 rew

agent-1: 304.0
agent-2: 302.0
agent-3: 297.0
Sum Reward: 903.0
Avg Reward: 301.0
Min Reward: 297.0
Max Reward: 304.0
Gini Coefficient: 0.00516795865633075
20:20 Ratio: 1.0235690235690236
Max-min Ratio: 1.0235690235690236
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-57-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1434.0
  episode_reward_mean: 1171.36
  episode_reward_min: 731.0
  episodes_this_iter: 1
  episodes_total: 335
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.664
    dispatch_time_ms: 8.67
    learner:
      cur_lr: 0.0012930670054629445
      grad_gnorm: 28.64610481262207
      policy_entropy: 23.722999572753906
      policy_loss: -7.535262584686279
      var_gnorm: 40.3295783996582
      vf_explained_var: 0.04689431190490723
      vf_loss: 19.663822174072266
    num_steps_sampled: 1008000
    num_steps_trained: 1008000
    wait_time_ms: 73.85
  iterations_since_restore: 336
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3058.976279258728
  time_this_iter_s: 8.153666257858276
  time_total_s: 3058.976279258728
  timestamp: 1594097836
  timesteps_since_restore: 1008000
  timesteps_this_iter: 3000
  timesteps_total: 1008000
  training_iteration: 336
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3058 s, 336 iter, 1008000 ts, 1.17e+03 rew

agent-1: 299.0
agent-2: 254.0
agent-3: 288.0
Sum Reward: 841.0
Avg Reward: 280.3333333333333
Min Reward: 254.0
Max Reward: 299.0
Gini Coefficient: 0.0356718192627824
20:20 Ratio: 1.1771653543307086
Max-min Ratio: 1.1771653543307086
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-57-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1434.0
  episode_reward_mean: 1166.21
  episode_reward_min: 731.0
  episodes_this_iter: 1
  episodes_total: 336
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.887
    dispatch_time_ms: 6.118
    learner:
      cur_lr: 0.0012928672367706895
      grad_gnorm: 40.0
      policy_entropy: 23.02334213256836
      policy_loss: 10.846803665161133
      var_gnorm: 40.32802200317383
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 32.28420639038086
    num_steps_sampled: 1011000
    num_steps_trained: 1011000
    wait_time_ms: 72.797
  iterations_since_restore: 337
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3067.368947505951
  time_this_iter_s: 8.3926682472229
  time_total_s: 3067.368947505951
  timestamp: 1594097844
  timesteps_since_restore: 1011000
  timesteps_this_iter: 3000
  timesteps_total: 1011000
  training_iteration: 337
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3067 s, 337 iter, 1011000 ts, 1.17e+03 rew

agent-1: 304.0
agent-2: 262.0
agent-3: 293.0
Sum Reward: 859.0
Avg Reward: 286.3333333333333
Min Reward: 262.0
Max Reward: 304.0
Gini Coefficient: 0.03259604190919674
20:20 Ratio: 1.1603053435114503
Max-min Ratio: 1.1603053435114503
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-57-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1434.0
  episode_reward_mean: 1162.08
  episode_reward_min: 731.0
  episodes_this_iter: 1
  episodes_total: 337
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.152
    dispatch_time_ms: 8.406
    learner:
      cur_lr: 0.0012926673516631126
      grad_gnorm: 40.0
      policy_entropy: 22.850845336914062
      policy_loss: 28.853261947631836
      var_gnorm: 40.38219451904297
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 51.23051071166992
    num_steps_sampled: 1014000
    num_steps_trained: 1014000
    wait_time_ms: 75.605
  iterations_since_restore: 338
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3075.4122836589813
  time_this_iter_s: 8.043336153030396
  time_total_s: 3075.4122836589813
  timestamp: 1594097852
  timesteps_since_restore: 1014000
  timesteps_this_iter: 3000
  timesteps_total: 1014000
  training_iteration: 338
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3075 s, 338 iter, 1014000 ts, 1.16e+03 rew

agent-1: 260.0
agent-2: 310.0
agent-3: 312.0
Sum Reward: 882.0
Avg Reward: 294.0
Min Reward: 260.0
Max Reward: 312.0
Gini Coefficient: 0.039304610733182165
20:20 Ratio: 1.2
Max-min Ratio: 1.2
agent-1: 299.0
agent-2: 299.0
agent-3: 285.0
Sum Reward: 883.0
Avg Reward: 294.3333333333333
Min Reward: 285.0
Max Reward: 299.0
Gini Coefficient: 0.010570026425066062
20:20 Ratio: 1.0491228070175438
Max-min Ratio: 1.0491228070175438
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-57-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1434.0
  episode_reward_mean: 1156.72
  episode_reward_min: 731.0
  episodes_this_iter: 2
  episodes_total: 339
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.953
    dispatch_time_ms: 8.218
    learner:
      cur_lr: 0.0012924675829708576
      grad_gnorm: 39.999996185302734
      policy_entropy: 23.871681213378906
      policy_loss: -583.8153076171875
      var_gnorm: 40.38153076171875
      vf_explained_var: 0.00020307302474975586
      vf_loss: 11115.4716796875
    num_steps_sampled: 1017000
    num_steps_trained: 1017000
    wait_time_ms: 74.785
  iterations_since_restore: 339
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3084.269634246826
  time_this_iter_s: 8.857350587844849
  time_total_s: 3084.269634246826
  timestamp: 1594097861
  timesteps_since_restore: 1017000
  timesteps_this_iter: 3000
  timesteps_total: 1017000
  training_iteration: 339
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3084 s, 339 iter, 1017000 ts, 1.16e+03 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-57-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1434.0
  episode_reward_mean: 1156.72
  episode_reward_min: 731.0
  episodes_this_iter: 0
  episodes_total: 339
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.389
    dispatch_time_ms: 9.002
    learner:
      cur_lr: 0.0012922678142786026
      grad_gnorm: 40.0
      policy_entropy: 23.437480926513672
      policy_loss: -27.18627166748047
      var_gnorm: 40.43722152709961
      vf_explained_var: 0.026380479335784912
      vf_loss: 34.57345962524414
    num_steps_sampled: 1020000
    num_steps_trained: 1020000
    wait_time_ms: 75.542
  iterations_since_restore: 340
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3092.2664279937744
  time_this_iter_s: 7.996793746948242
  time_total_s: 3092.2664279937744
  timestamp: 1594097869
  timesteps_since_restore: 1020000
  timesteps_this_iter: 3000
  timesteps_total: 1020000
  training_iteration: 340
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3092 s, 340 iter, 1020000 ts, 1.16e+03 rew

agent-1: 332.0
agent-2: 306.0
agent-3: 340.0
Sum Reward: 978.0
Avg Reward: 326.0
Min Reward: 306.0
Max Reward: 340.0
Gini Coefficient: 0.023176550783912748
20:20 Ratio: 1.1111111111111112
Max-min Ratio: 1.1111111111111112
agent-1: 305.0
agent-2: 305.0
agent-3: 333.0
Sum Reward: 943.0
Avg Reward: 314.3333333333333
Min Reward: 305.0
Max Reward: 333.0
Gini Coefficient: 0.01979498055850124
20:20 Ratio: 1.0918032786885246
Max-min Ratio: 1.0918032786885246
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-57-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1434.0
  episode_reward_mean: 1154.36
  episode_reward_min: 731.0
  episodes_this_iter: 2
  episodes_total: 341
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.755
    dispatch_time_ms: 7.445
    learner:
      cur_lr: 0.0012920680455863476
      grad_gnorm: 39.999996185302734
      policy_entropy: 22.434391021728516
      policy_loss: -602.446533203125
      var_gnorm: 40.49013137817383
      vf_explained_var: 0.0119706392288208
      vf_loss: 12577.681640625
    num_steps_sampled: 1023000
    num_steps_trained: 1023000
    wait_time_ms: 80.66
  iterations_since_restore: 341
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3101.059539794922
  time_this_iter_s: 8.793111801147461
  time_total_s: 3101.059539794922
  timestamp: 1594097878
  timesteps_since_restore: 1023000
  timesteps_this_iter: 3000
  timesteps_total: 1023000
  training_iteration: 341
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3101 s, 341 iter, 1023000 ts, 1.15e+03 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-58-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1434.0
  episode_reward_mean: 1154.36
  episode_reward_min: 731.0
  episodes_this_iter: 0
  episodes_total: 341
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.473
    dispatch_time_ms: 6.103
    learner:
      cur_lr: 0.0012918681604787707
      grad_gnorm: 30.05095863342285
      policy_entropy: 24.26459312438965
      policy_loss: -12.78758716583252
      var_gnorm: 40.51224136352539
      vf_explained_var: 0.10328656435012817
      vf_loss: 35.68926239013672
    num_steps_sampled: 1026000
    num_steps_trained: 1026000
    wait_time_ms: 71.029
  iterations_since_restore: 342
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3108.991372823715
  time_this_iter_s: 7.931833028793335
  time_total_s: 3108.991372823715
  timestamp: 1594097886
  timesteps_since_restore: 1026000
  timesteps_this_iter: 3000
  timesteps_total: 1026000
  training_iteration: 342
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3108 s, 342 iter, 1026000 ts, 1.15e+03 rew

agent-1: 325.0
agent-2: 342.0
agent-3: 327.0
Sum Reward: 994.0
Avg Reward: 331.3333333333333
Min Reward: 325.0
Max Reward: 342.0
Gini Coefficient: 0.011401743796109993
20:20 Ratio: 1.0523076923076924
Max-min Ratio: 1.0523076923076924
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-58-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1434.0
  episode_reward_mean: 1153.63
  episode_reward_min: 731.0
  episodes_this_iter: 1
  episodes_total: 342
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.693
    dispatch_time_ms: 7.074
    learner:
      cur_lr: 0.0012916683917865157
      grad_gnorm: 14.494034767150879
      policy_entropy: 24.632312774658203
      policy_loss: -3.5652658939361572
      var_gnorm: 40.577789306640625
      vf_explained_var: -0.16632401943206787
      vf_loss: 20.047649383544922
    num_steps_sampled: 1029000
    num_steps_trained: 1029000
    wait_time_ms: 73.694
  iterations_since_restore: 343
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3117.4122626781464
  time_this_iter_s: 8.420889854431152
  time_total_s: 3117.4122626781464
  timestamp: 1594097894
  timesteps_since_restore: 1029000
  timesteps_this_iter: 3000
  timesteps_total: 1029000
  training_iteration: 343
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3117 s, 343 iter, 1029000 ts, 1.15e+03 rew

agent-1: 334.0
agent-2: 323.0
agent-3: 333.0
Sum Reward: 990.0
Avg Reward: 330.0
Min Reward: 323.0
Max Reward: 334.0
Gini Coefficient: 0.007407407407407408
20:20 Ratio: 1.0340557275541795
Max-min Ratio: 1.0340557275541795
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-58-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1434.0
  episode_reward_mean: 1153.33
  episode_reward_min: 731.0
  episodes_this_iter: 1
  episodes_total: 343
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.519
    dispatch_time_ms: 6.152
    learner:
      cur_lr: 0.0012914686230942607
      grad_gnorm: 23.17080307006836
      policy_entropy: 24.674922943115234
      policy_loss: 3.4919562339782715
      var_gnorm: 40.613975524902344
      vf_explained_var: 0.13821232318878174
      vf_loss: 15.124590873718262
    num_steps_sampled: 1032000
    num_steps_trained: 1032000
    wait_time_ms: 74.37
  iterations_since_restore: 344
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3125.486017227173
  time_this_iter_s: 8.07375454902649
  time_total_s: 3125.486017227173
  timestamp: 1594097903
  timesteps_since_restore: 1032000
  timesteps_this_iter: 3000
  timesteps_total: 1032000
  training_iteration: 344
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3125 s, 344 iter, 1032000 ts, 1.15e+03 rew

agent-1: 359.0
agent-2: 316.0
agent-3: 332.0
Sum Reward: 1007.0
Avg Reward: 335.6666666666667
Min Reward: 316.0
Max Reward: 359.0
Gini Coefficient: 0.028467394902350215
20:20 Ratio: 1.1360759493670887
Max-min Ratio: 1.1360759493670887
agent-1: 344.0
agent-2: 313.0
agent-3: 335.0
Sum Reward: 992.0
Avg Reward: 330.6666666666667
Min Reward: 313.0
Max Reward: 344.0
Gini Coefficient: 0.020833333333333332
20:20 Ratio: 1.099041533546326
Max-min Ratio: 1.099041533546326
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-58-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1434.0
  episode_reward_mean: 1148.5
  episode_reward_min: 731.0
  episodes_this_iter: 2
  episodes_total: 345
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.592
    dispatch_time_ms: 6.074
    learner:
      cur_lr: 0.0012912688544020057
      grad_gnorm: 40.0
      policy_entropy: 24.271936416625977
      policy_loss: -762.8291015625
      var_gnorm: 40.65843963623047
      vf_explained_var: -0.020186662673950195
      vf_loss: 14551.9423828125
    num_steps_sampled: 1035000
    num_steps_trained: 1035000
    wait_time_ms: 77.923
  iterations_since_restore: 345
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3134.0950541496277
  time_this_iter_s: 8.609036922454834
  time_total_s: 3134.0950541496277
  timestamp: 1594097911
  timesteps_since_restore: 1035000
  timesteps_this_iter: 3000
  timesteps_total: 1035000
  training_iteration: 345
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3134 s, 345 iter, 1035000 ts, 1.15e+03 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-58-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1434.0
  episode_reward_mean: 1148.5
  episode_reward_min: 731.0
  episodes_this_iter: 0
  episodes_total: 345
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.059
    dispatch_time_ms: 8.696
    learner:
      cur_lr: 0.0012910689692944288
      grad_gnorm: 34.381736755371094
      policy_entropy: 21.956296920776367
      policy_loss: -5.9534807205200195
      var_gnorm: 40.73796463012695
      vf_explained_var: -0.02650439739227295
      vf_loss: 19.11216163635254
    num_steps_sampled: 1038000
    num_steps_trained: 1038000
    wait_time_ms: 69.608
  iterations_since_restore: 346
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3148.3399465084076
  time_this_iter_s: 14.244892358779907
  time_total_s: 3148.3399465084076
  timestamp: 1594097925
  timesteps_since_restore: 1038000
  timesteps_this_iter: 3000
  timesteps_total: 1038000
  training_iteration: 346
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3148 s, 346 iter, 1038000 ts, 1.15e+03 rew

agent-1: 335.0
agent-2: 357.0
agent-3: 364.0
Sum Reward: 1056.0
Avg Reward: 352.0
Min Reward: 335.0
Max Reward: 364.0
Gini Coefficient: 0.018308080808080808
20:20 Ratio: 1.0865671641791044
Max-min Ratio: 1.0865671641791044
agent-1: 332.0
agent-2: 336.0
agent-3: 383.0
Sum Reward: 1051.0
Avg Reward: 350.3333333333333
Min Reward: 332.0
Max Reward: 383.0
Gini Coefficient: 0.03235014272121789
20:20 Ratio: 1.1536144578313252
Max-min Ratio: 1.1536144578313252
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-58-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1434.0
  episode_reward_mean: 1145.25
  episode_reward_min: 731.0
  episodes_this_iter: 2
  episodes_total: 347
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.399
    dispatch_time_ms: 13.212
    learner:
      cur_lr: 0.0012908692006021738
      grad_gnorm: 39.999996185302734
      policy_entropy: 19.43150520324707
      policy_loss: -572.2247924804688
      var_gnorm: 40.809486389160156
      vf_explained_var: 0.3733728528022766
      vf_loss: 15154.61328125
    num_steps_sampled: 1041000
    num_steps_trained: 1041000
    wait_time_ms: 78.346
  iterations_since_restore: 347
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3157.438279390335
  time_this_iter_s: 9.09833288192749
  time_total_s: 3157.438279390335
  timestamp: 1594097935
  timesteps_since_restore: 1041000
  timesteps_this_iter: 3000
  timesteps_total: 1041000
  training_iteration: 347
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3157 s, 347 iter, 1041000 ts, 1.15e+03 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-59-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1434.0
  episode_reward_mean: 1145.25
  episode_reward_min: 731.0
  episodes_this_iter: 0
  episodes_total: 347
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.551
    dispatch_time_ms: 21.488
    learner:
      cur_lr: 0.0012906694319099188
      grad_gnorm: 39.999996185302734
      policy_entropy: 14.142593383789062
      policy_loss: 9.744366645812988
      var_gnorm: 40.929054260253906
      vf_explained_var: -0.10419201850891113
      vf_loss: 30.076725006103516
    num_steps_sampled: 1044000
    num_steps_trained: 1044000
    wait_time_ms: 68.775
  iterations_since_restore: 348
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3166.217351436615
  time_this_iter_s: 8.779072046279907
  time_total_s: 3166.217351436615
  timestamp: 1594097943
  timesteps_since_restore: 1044000
  timesteps_this_iter: 3000
  timesteps_total: 1044000
  training_iteration: 348
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3166 s, 348 iter, 1044000 ts, 1.15e+03 rew

agent-1: 289.0
agent-2: 421.0
agent-3: 294.0
Sum Reward: 1004.0
Avg Reward: 334.6666666666667
Min Reward: 289.0
Max Reward: 421.0
Gini Coefficient: 0.08764940239043825
20:20 Ratio: 1.4567474048442905
Max-min Ratio: 1.4567474048442905
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-59-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1434.0
  episode_reward_mean: 1145.52
  episode_reward_min: 731.0
  episodes_this_iter: 1
  episodes_total: 348
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.781
    dispatch_time_ms: 21.614
    learner:
      cur_lr: 0.001290469546802342
      grad_gnorm: 40.000003814697266
      policy_entropy: 12.091541290283203
      policy_loss: 10.103245735168457
      var_gnorm: 41.0988655090332
      vf_explained_var: 0.09473413228988647
      vf_loss: 19.753660202026367
    num_steps_sampled: 1047000
    num_steps_trained: 1047000
    wait_time_ms: 63.195
  iterations_since_restore: 349
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3175.200436592102
  time_this_iter_s: 8.98308515548706
  time_total_s: 3175.200436592102
  timestamp: 1594097952
  timesteps_since_restore: 1047000
  timesteps_this_iter: 3000
  timesteps_total: 1047000
  training_iteration: 349
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3175 s, 349 iter, 1047000 ts, 1.15e+03 rew

agent-1: 361.0
agent-2: 330.0
agent-3: 377.0
Sum Reward: 1068.0
Avg Reward: 356.0
Min Reward: 330.0
Max Reward: 377.0
Gini Coefficient: 0.02933832709113608
20:20 Ratio: 1.1424242424242423
Max-min Ratio: 1.1424242424242423
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-59-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1434.0
  episode_reward_mean: 1146.09
  episode_reward_min: 731.0
  episodes_this_iter: 1
  episodes_total: 349
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.742
    dispatch_time_ms: 23.937
    learner:
      cur_lr: 0.001290269778110087
      grad_gnorm: 40.000003814697266
      policy_entropy: 11.669410705566406
      policy_loss: 10.969162940979004
      var_gnorm: 41.177242279052734
      vf_explained_var: -0.6420023441314697
      vf_loss: 69.31476593017578
    num_steps_sampled: 1050000
    num_steps_trained: 1050000
    wait_time_ms: 62.084
  iterations_since_restore: 350
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3183.8012919425964
  time_this_iter_s: 8.600855350494385
  time_total_s: 3183.8012919425964
  timestamp: 1594097961
  timesteps_since_restore: 1050000
  timesteps_this_iter: 3000
  timesteps_total: 1050000
  training_iteration: 350
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3183 s, 350 iter, 1050000 ts, 1.15e+03 rew

agent-1: 302.0
agent-2: 395.0
agent-3: 374.0
Sum Reward: 1071.0
Avg Reward: 357.0
Min Reward: 302.0
Max Reward: 395.0
Gini Coefficient: 0.05788982259570495
20:20 Ratio: 1.3079470198675496
Max-min Ratio: 1.3079470198675496
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-59-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1434.0
  episode_reward_mean: 1145.55
  episode_reward_min: 731.0
  episodes_this_iter: 1
  episodes_total: 350
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.724
    dispatch_time_ms: 22.976
    learner:
      cur_lr: 0.001290070009417832
      grad_gnorm: 40.0
      policy_entropy: 8.566446304321289
      policy_loss: -0.5727024078369141
      var_gnorm: 41.31605911254883
      vf_explained_var: 0.18454480171203613
      vf_loss: 62.592254638671875
    num_steps_sampled: 1053000
    num_steps_trained: 1053000
    wait_time_ms: 54.064
  iterations_since_restore: 351
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3192.9700832366943
  time_this_iter_s: 9.1687912940979
  time_total_s: 3192.9700832366943
  timestamp: 1594097970
  timesteps_since_restore: 1053000
  timesteps_this_iter: 3000
  timesteps_total: 1053000
  training_iteration: 351
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3192 s, 351 iter, 1053000 ts, 1.15e+03 rew

agent-1: 315.0
agent-2: 410.0
agent-3: 308.0
Sum Reward: 1033.0
Avg Reward: 344.3333333333333
Min Reward: 308.0
Max Reward: 410.0
Gini Coefficient: 0.06582768635043562
20:20 Ratio: 1.3311688311688312
Max-min Ratio: 1.3311688311688312
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-59-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1434.0
  episode_reward_mean: 1144.26
  episode_reward_min: 731.0
  episodes_this_iter: 1
  episodes_total: 351
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.547
    dispatch_time_ms: 17.649
    learner:
      cur_lr: 0.0012898702407255769
      grad_gnorm: 40.000003814697266
      policy_entropy: 12.741462707519531
      policy_loss: -1.192760944366455
      var_gnorm: 41.40559387207031
      vf_explained_var: 0.3800241947174072
      vf_loss: 36.636383056640625
    num_steps_sampled: 1056000
    num_steps_trained: 1056000
    wait_time_ms: 72.534
  iterations_since_restore: 352
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3201.8230681419373
  time_this_iter_s: 8.85298490524292
  time_total_s: 3201.8230681419373
  timestamp: 1594097979
  timesteps_since_restore: 1056000
  timesteps_this_iter: 3000
  timesteps_total: 1056000
  training_iteration: 352
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3201 s, 352 iter, 1056000 ts, 1.14e+03 rew

agent-1: 349.0
agent-2: 463.0
agent-3: 329.0
Sum Reward: 1141.0
Avg Reward: 380.3333333333333
Min Reward: 329.0
Max Reward: 463.0
Gini Coefficient: 0.07829389424481449
20:20 Ratio: 1.4072948328267476
Max-min Ratio: 1.4072948328267476
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-59-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1434.0
  episode_reward_mean: 1142.07
  episode_reward_min: 731.0
  episodes_this_iter: 1
  episodes_total: 352
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.982
    dispatch_time_ms: 14.563
    learner:
      cur_lr: 0.001289670355618
      grad_gnorm: 40.000003814697266
      policy_entropy: 6.136152267456055
      policy_loss: 2.457233428955078
      var_gnorm: 41.49140930175781
      vf_explained_var: -0.01291358470916748
      vf_loss: 28.948026657104492
    num_steps_sampled: 1059000
    num_steps_trained: 1059000
    wait_time_ms: 63.425
  iterations_since_restore: 353
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3211.3585827350616
  time_this_iter_s: 9.53551459312439
  time_total_s: 3211.3585827350616
  timestamp: 1594097989
  timesteps_since_restore: 1059000
  timesteps_this_iter: 3000
  timesteps_total: 1059000
  training_iteration: 353
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3211 s, 353 iter, 1059000 ts, 1.14e+03 rew

agent-1: 380.0
agent-2: 420.0
agent-3: 434.0
Sum Reward: 1234.0
Avg Reward: 411.3333333333333
Min Reward: 380.0
Max Reward: 434.0
Gini Coefficient: 0.029173419773095625
20:20 Ratio: 1.1421052631578947
Max-min Ratio: 1.1421052631578947
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-59-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1434.0
  episode_reward_mean: 1140.59
  episode_reward_min: 731.0
  episodes_this_iter: 1
  episodes_total: 353
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.406
    dispatch_time_ms: 6.6
    learner:
      cur_lr: 0.001289470586925745
      grad_gnorm: 40.0
      policy_entropy: 9.045994758605957
      policy_loss: -6.6340203285217285
      var_gnorm: 41.542301177978516
      vf_explained_var: 0.6852547526359558
      vf_loss: 60.70265197753906
    num_steps_sampled: 1062000
    num_steps_trained: 1062000
    wait_time_ms: 80.134
  iterations_since_restore: 354
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3220.1324439048767
  time_this_iter_s: 8.773861169815063
  time_total_s: 3220.1324439048767
  timestamp: 1594097998
  timesteps_since_restore: 1062000
  timesteps_this_iter: 3000
  timesteps_total: 1062000
  training_iteration: 354
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3220 s, 354 iter, 1062000 ts, 1.14e+03 rew

agent-1: 262.0
agent-2: 416.0
agent-3: 428.0
Sum Reward: 1106.0
Avg Reward: 368.6666666666667
Min Reward: 262.0
Max Reward: 428.0
Gini Coefficient: 0.10006027727546715
20:20 Ratio: 1.633587786259542
Max-min Ratio: 1.633587786259542
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-00-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1395.0
  episode_reward_mean: 1137.31
  episode_reward_min: 731.0
  episodes_this_iter: 1
  episodes_total: 354
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.513
    dispatch_time_ms: 5.88
    learner:
      cur_lr: 0.00128927081823349
      grad_gnorm: 40.0
      policy_entropy: 10.98189926147461
      policy_loss: -10.8680419921875
      var_gnorm: 41.67416763305664
      vf_explained_var: 0.6611583232879639
      vf_loss: 60.39137649536133
    num_steps_sampled: 1065000
    num_steps_trained: 1065000
    wait_time_ms: 78.742
  iterations_since_restore: 355
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3229.4800894260406
  time_this_iter_s: 9.34764552116394
  time_total_s: 3229.4800894260406
  timestamp: 1594098007
  timesteps_since_restore: 1065000
  timesteps_this_iter: 3000
  timesteps_total: 1065000
  training_iteration: 355
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3229 s, 355 iter, 1065000 ts, 1.14e+03 rew

agent-1: 222.0
agent-2: 449.0
agent-3: 417.0
Sum Reward: 1088.0
Avg Reward: 362.6666666666667
Min Reward: 222.0
Max Reward: 449.0
Gini Coefficient: 0.13909313725490197
20:20 Ratio: 2.0225225225225225
Max-min Ratio: 2.0225225225225225
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-00-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1395.0
  episode_reward_mean: 1134.71
  episode_reward_min: 731.0
  episodes_this_iter: 1
  episodes_total: 355
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.627
    dispatch_time_ms: 5.887
    learner:
      cur_lr: 0.001289071049541235
      grad_gnorm: 40.0
      policy_entropy: 11.72904109954834
      policy_loss: 22.049516677856445
      var_gnorm: 41.77171325683594
      vf_explained_var: 0.7099231481552124
      vf_loss: 77.56645202636719
    num_steps_sampled: 1068000
    num_steps_trained: 1068000
    wait_time_ms: 75.348
  iterations_since_restore: 356
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3237.840663909912
  time_this_iter_s: 8.36057448387146
  time_total_s: 3237.840663909912
  timestamp: 1594098015
  timesteps_since_restore: 1068000
  timesteps_this_iter: 3000
  timesteps_total: 1068000
  training_iteration: 356
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3237 s, 356 iter, 1068000 ts, 1.13e+03 rew

agent-1: 258.0
agent-2: 399.0
agent-3: 334.0
Sum Reward: 991.0
Avg Reward: 330.3333333333333
Min Reward: 258.0
Max Reward: 399.0
Gini Coefficient: 0.09485368314833502
20:20 Ratio: 1.5465116279069768
Max-min Ratio: 1.5465116279069768
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-00-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1395.0
  episode_reward_mean: 1131.91
  episode_reward_min: 731.0
  episodes_this_iter: 1
  episodes_total: 356
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.91
    dispatch_time_ms: 7.607
    learner:
      cur_lr: 0.0012888711644336581
      grad_gnorm: 40.0
      policy_entropy: 15.174354553222656
      policy_loss: -9.54682445526123
      var_gnorm: 41.80512619018555
      vf_explained_var: 0.7912473082542419
      vf_loss: 39.9062385559082
    num_steps_sampled: 1071000
    num_steps_trained: 1071000
    wait_time_ms: 70.764
  iterations_since_restore: 357
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3246.4091033935547
  time_this_iter_s: 8.568439483642578
  time_total_s: 3246.4091033935547
  timestamp: 1594098024
  timesteps_since_restore: 1071000
  timesteps_this_iter: 3000
  timesteps_total: 1071000
  training_iteration: 357
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3246 s, 357 iter, 1071000 ts, 1.13e+03 rew

agent-1: 293.0
agent-2: 281.0
agent-3: 299.0
Sum Reward: 873.0
Avg Reward: 291.0
Min Reward: 281.0
Max Reward: 299.0
Gini Coefficient: 0.013745704467353952
20:20 Ratio: 1.0640569395017794
Max-min Ratio: 1.0640569395017794
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-00-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1395.0
  episode_reward_mean: 1127.65
  episode_reward_min: 731.0
  episodes_this_iter: 1
  episodes_total: 357
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.792
    dispatch_time_ms: 27.134
    learner:
      cur_lr: 0.001288671395741403
      grad_gnorm: 36.39714431762695
      policy_entropy: 14.933002471923828
      policy_loss: 20.912235260009766
      var_gnorm: 41.80517578125
      vf_explained_var: -0.9457384347915649
      vf_loss: 83.65258026123047
    num_steps_sampled: 1074000
    num_steps_trained: 1074000
    wait_time_ms: 67.289
  iterations_since_restore: 358
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3254.533229827881
  time_this_iter_s: 8.124126434326172
  time_total_s: 3254.533229827881
  timestamp: 1594098032
  timesteps_since_restore: 1074000
  timesteps_this_iter: 3000
  timesteps_total: 1074000
  training_iteration: 358
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3254 s, 358 iter, 1074000 ts, 1.13e+03 rew

agent-1: 305.0
agent-2: 325.0
agent-3: 331.0
Sum Reward: 961.0
Avg Reward: 320.3333333333333
Min Reward: 305.0
Max Reward: 331.0
Gini Coefficient: 0.018036767256330213
20:20 Ratio: 1.0852459016393443
Max-min Ratio: 1.0852459016393443
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-00-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1395.0
  episode_reward_mean: 1124.66
  episode_reward_min: 731.0
  episodes_this_iter: 1
  episodes_total: 358
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.619
    dispatch_time_ms: 25.893
    learner:
      cur_lr: 0.001288471627049148
      grad_gnorm: 40.0
      policy_entropy: 15.90565299987793
      policy_loss: -2.9150381088256836
      var_gnorm: 41.86502456665039
      vf_explained_var: -0.03613877296447754
      vf_loss: 52.32106399536133
    num_steps_sampled: 1077000
    num_steps_trained: 1077000
    wait_time_ms: 56.968
  iterations_since_restore: 359
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3263.289966106415
  time_this_iter_s: 8.756736278533936
  time_total_s: 3263.289966106415
  timestamp: 1594098041
  timesteps_since_restore: 1077000
  timesteps_this_iter: 3000
  timesteps_total: 1077000
  training_iteration: 359
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3263 s, 359 iter, 1077000 ts, 1.12e+03 rew

agent-1: 333.0
agent-2: 252.0
agent-3: 286.0
Sum Reward: 871.0
Avg Reward: 290.3333333333333
Min Reward: 252.0
Max Reward: 333.0
Gini Coefficient: 0.06199770378874857
20:20 Ratio: 1.3214285714285714
Max-min Ratio: 1.3214285714285714
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-00-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1395.0
  episode_reward_mean: 1120.22
  episode_reward_min: 731.0
  episodes_this_iter: 1
  episodes_total: 359
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.69
    dispatch_time_ms: 26.852
    learner:
      cur_lr: 0.0012882717419415712
      grad_gnorm: 40.0
      policy_entropy: 24.54629135131836
      policy_loss: -1.209067940711975
      var_gnorm: 41.86103439331055
      vf_explained_var: 0.01632213592529297
      vf_loss: 135.0260009765625
    num_steps_sampled: 1080000
    num_steps_trained: 1080000
    wait_time_ms: 62.84
  iterations_since_restore: 360
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3271.844762325287
  time_this_iter_s: 8.55479621887207
  time_total_s: 3271.844762325287
  timestamp: 1594098049
  timesteps_since_restore: 1080000
  timesteps_this_iter: 3000
  timesteps_total: 1080000
  training_iteration: 360
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3271 s, 360 iter, 1080000 ts, 1.12e+03 rew

agent-1: 350.0
agent-2: 188.0
agent-3: 265.0
Sum Reward: 803.0
Avg Reward: 267.6666666666667
Min Reward: 188.0
Max Reward: 350.0
Gini Coefficient: 0.13449564134495642
20:20 Ratio: 1.8617021276595744
Max-min Ratio: 1.8617021276595744
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-00-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1395.0
  episode_reward_mean: 1115.6
  episode_reward_min: 731.0
  episodes_this_iter: 1
  episodes_total: 360
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.56
    dispatch_time_ms: 30.772
    learner:
      cur_lr: 0.0012880719732493162
      grad_gnorm: 40.0
      policy_entropy: 21.847497940063477
      policy_loss: -21.031572341918945
      var_gnorm: 41.86262512207031
      vf_explained_var: -1.0
      vf_loss: 36.608551025390625
    num_steps_sampled: 1083000
    num_steps_trained: 1083000
    wait_time_ms: 52.84
  iterations_since_restore: 361
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3280.8056037425995
  time_this_iter_s: 8.960841417312622
  time_total_s: 3280.8056037425995
  timestamp: 1594098058
  timesteps_since_restore: 1083000
  timesteps_this_iter: 3000
  timesteps_total: 1083000
  training_iteration: 361
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3280 s, 361 iter, 1083000 ts, 1.12e+03 rew

agent-1: 361.0
agent-2: 329.0
agent-3: 285.0
Sum Reward: 975.0
Avg Reward: 325.0
Min Reward: 285.0
Max Reward: 361.0
Gini Coefficient: 0.051965811965811966
20:20 Ratio: 1.2666666666666666
Max-min Ratio: 1.2666666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-01-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1395.0
  episode_reward_mean: 1112.03
  episode_reward_min: 731.0
  episodes_this_iter: 1
  episodes_total: 361
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.516
    dispatch_time_ms: 39.809
    learner:
      cur_lr: 0.0012878722045570612
      grad_gnorm: 27.280057907104492
      policy_entropy: 16.581335067749023
      policy_loss: -8.587909698486328
      var_gnorm: 41.95209503173828
      vf_explained_var: -0.3674604892730713
      vf_loss: 19.813249588012695
    num_steps_sampled: 1086000
    num_steps_trained: 1086000
    wait_time_ms: 55.154
  iterations_since_restore: 362
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3289.9630060195923
  time_this_iter_s: 9.157402276992798
  time_total_s: 3289.9630060195923
  timestamp: 1594098068
  timesteps_since_restore: 1086000
  timesteps_this_iter: 3000
  timesteps_total: 1086000
  training_iteration: 362
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3289 s, 362 iter, 1086000 ts, 1.11e+03 rew

agent-1: 339.0
agent-2: 296.0
agent-3: 329.0
Sum Reward: 964.0
Avg Reward: 321.3333333333333
Min Reward: 296.0
Max Reward: 339.0
Gini Coefficient: 0.029737206085753802
20:20 Ratio: 1.1452702702702702
Max-min Ratio: 1.1452702702702702
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-01-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1395.0
  episode_reward_mean: 1107.89
  episode_reward_min: 731.0
  episodes_this_iter: 1
  episodes_total: 362
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.476
    dispatch_time_ms: 26.802
    learner:
      cur_lr: 0.0012876724358648062
      grad_gnorm: 40.000003814697266
      policy_entropy: 20.16437339782715
      policy_loss: -19.953258514404297
      var_gnorm: 41.977294921875
      vf_explained_var: -0.25898706912994385
      vf_loss: 13.279218673706055
    num_steps_sampled: 1089000
    num_steps_trained: 1089000
    wait_time_ms: 49.914
  iterations_since_restore: 363
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3299.0086505413055
  time_this_iter_s: 9.045644521713257
  time_total_s: 3299.0086505413055
  timestamp: 1594098077
  timesteps_since_restore: 1089000
  timesteps_this_iter: 3000
  timesteps_total: 1089000
  training_iteration: 363
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3299 s, 363 iter, 1089000 ts, 1.11e+03 rew

agent-1: 312.0
agent-2: 347.0
agent-3: 333.0
Sum Reward: 992.0
Avg Reward: 330.6666666666667
Min Reward: 312.0
Max Reward: 347.0
Gini Coefficient: 0.023521505376344086
20:20 Ratio: 1.1121794871794872
Max-min Ratio: 1.1121794871794872
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-01-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1395.0
  episode_reward_mean: 1105.14
  episode_reward_min: 731.0
  episodes_this_iter: 1
  episodes_total: 363
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.994
    dispatch_time_ms: 31.949
    learner:
      cur_lr: 0.0012874725507572293
      grad_gnorm: 33.669883728027344
      policy_entropy: 20.350692749023438
      policy_loss: 5.646678924560547
      var_gnorm: 41.905906677246094
      vf_explained_var: 0.006452381610870361
      vf_loss: 13.460932731628418
    num_steps_sampled: 1092000
    num_steps_trained: 1092000
    wait_time_ms: 60.514
  iterations_since_restore: 364
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3307.282487630844
  time_this_iter_s: 8.273837089538574
  time_total_s: 3307.282487630844
  timestamp: 1594098085
  timesteps_since_restore: 1092000
  timesteps_this_iter: 3000
  timesteps_total: 1092000
  training_iteration: 364
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3307 s, 364 iter, 1092000 ts, 1.11e+03 rew

agent-1: 249.0
agent-2: 191.0
agent-3: 191.0
Sum Reward: 631.0
Avg Reward: 210.33333333333334
Min Reward: 191.0
Max Reward: 249.0
Gini Coefficient: 0.0612783940834654
20:20 Ratio: 1.3036649214659686
Max-min Ratio: 1.3036649214659686
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-01-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1395.0
  episode_reward_mean: 1099.55
  episode_reward_min: 631.0
  episodes_this_iter: 1
  episodes_total: 364
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.913
    dispatch_time_ms: 36.833
    learner:
      cur_lr: 0.0012872727820649743
      grad_gnorm: 9.955565452575684
      policy_entropy: 21.23898696899414
      policy_loss: 3.120321750640869
      var_gnorm: 41.848880767822266
      vf_explained_var: 0.12469339370727539
      vf_loss: 44.15916442871094
    num_steps_sampled: 1095000
    num_steps_trained: 1095000
    wait_time_ms: 45.998
  iterations_since_restore: 365
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3315.556173801422
  time_this_iter_s: 8.273686170578003
  time_total_s: 3315.556173801422
  timestamp: 1594098093
  timesteps_since_restore: 1095000
  timesteps_this_iter: 3000
  timesteps_total: 1095000
  training_iteration: 365
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3315 s, 365 iter, 1095000 ts, 1.1e+03 rew

agent-1: 229.0
agent-2: 190.0
agent-3: 291.0
Sum Reward: 710.0
Avg Reward: 236.66666666666666
Min Reward: 190.0
Max Reward: 291.0
Gini Coefficient: 0.09483568075117371
20:20 Ratio: 1.5315789473684212
Max-min Ratio: 1.5315789473684212
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-01-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1395.0
  episode_reward_mean: 1094.47
  episode_reward_min: 631.0
  episodes_this_iter: 1
  episodes_total: 365
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.6
    dispatch_time_ms: 6.951
    learner:
      cur_lr: 0.0012870730133727193
      grad_gnorm: 25.425432205200195
      policy_entropy: 18.978620529174805
      policy_loss: -3.093783378601074
      var_gnorm: 41.88057327270508
      vf_explained_var: 0.672165036201477
      vf_loss: 23.4404239654541
    num_steps_sampled: 1098000
    num_steps_trained: 1098000
    wait_time_ms: 61.281
  iterations_since_restore: 366
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3323.5359058380127
  time_this_iter_s: 7.979732036590576
  time_total_s: 3323.5359058380127
  timestamp: 1594098101
  timesteps_since_restore: 1098000
  timesteps_this_iter: 3000
  timesteps_total: 1098000
  training_iteration: 366
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3323 s, 366 iter, 1098000 ts, 1.09e+03 rew

agent-1: 357.0
agent-2: 331.0
agent-3: 286.0
Sum Reward: 974.0
Avg Reward: 324.6666666666667
Min Reward: 286.0
Max Reward: 357.0
Gini Coefficient: 0.0485968514715948
20:20 Ratio: 1.2482517482517483
Max-min Ratio: 1.2482517482517483
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-01-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1395.0
  episode_reward_mean: 1091.85
  episode_reward_min: 631.0
  episodes_this_iter: 1
  episodes_total: 366
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.561
    dispatch_time_ms: 7.521
    learner:
      cur_lr: 0.0012868732446804643
      grad_gnorm: 38.055458068847656
      policy_entropy: 16.33873748779297
      policy_loss: -3.2695093154907227
      var_gnorm: 41.93744659423828
      vf_explained_var: 0.048556625843048096
      vf_loss: 49.1339225769043
    num_steps_sampled: 1101000
    num_steps_trained: 1101000
    wait_time_ms: 65.869
  iterations_since_restore: 367
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3332.2681119441986
  time_this_iter_s: 8.732206106185913
  time_total_s: 3332.2681119441986
  timestamp: 1594098110
  timesteps_since_restore: 1101000
  timesteps_this_iter: 3000
  timesteps_total: 1101000
  training_iteration: 367
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3332 s, 367 iter, 1101000 ts, 1.09e+03 rew

agent-1: 288.0
agent-2: 427.0
agent-3: 261.0
Sum Reward: 976.0
Avg Reward: 325.3333333333333
Min Reward: 261.0
Max Reward: 427.0
Gini Coefficient: 0.1133879781420765
20:20 Ratio: 1.6360153256704981
Max-min Ratio: 1.6360153256704981
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-01-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1395.0
  episode_reward_mean: 1090.03
  episode_reward_min: 631.0
  episodes_this_iter: 1
  episodes_total: 367
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.57
    dispatch_time_ms: 5.921
    learner:
      cur_lr: 0.0012866733595728874
      grad_gnorm: 40.0
      policy_entropy: 16.499385833740234
      policy_loss: 15.193853378295898
      var_gnorm: 42.01912307739258
      vf_explained_var: 0.5284709334373474
      vf_loss: 37.716373443603516
    num_steps_sampled: 1104000
    num_steps_trained: 1104000
    wait_time_ms: 79.939
  iterations_since_restore: 368
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3340.730833530426
  time_this_iter_s: 8.462721586227417
  time_total_s: 3340.730833530426
  timestamp: 1594098119
  timesteps_since_restore: 1104000
  timesteps_this_iter: 3000
  timesteps_total: 1104000
  training_iteration: 368
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3340 s, 368 iter, 1104000 ts, 1.09e+03 rew

agent-1: 377.0
agent-2: 394.0
agent-3: 356.0
Sum Reward: 1127.0
Avg Reward: 375.6666666666667
Min Reward: 356.0
Max Reward: 394.0
Gini Coefficient: 0.022478556640047324
20:20 Ratio: 1.1067415730337078
Max-min Ratio: 1.1067415730337078
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-02-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1395.0
  episode_reward_mean: 1089.42
  episode_reward_min: 631.0
  episodes_this_iter: 1
  episodes_total: 368
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.531
    dispatch_time_ms: 7.333
    learner:
      cur_lr: 0.0012864735908806324
      grad_gnorm: 39.99999237060547
      policy_entropy: 12.336368560791016
      policy_loss: 9.071017265319824
      var_gnorm: 42.05230712890625
      vf_explained_var: 0.15983933210372925
      vf_loss: 63.60890579223633
    num_steps_sampled: 1107000
    num_steps_trained: 1107000
    wait_time_ms: 69.91
  iterations_since_restore: 369
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3349.8689754009247
  time_this_iter_s: 9.138141870498657
  time_total_s: 3349.8689754009247
  timestamp: 1594098128
  timesteps_since_restore: 1107000
  timesteps_this_iter: 3000
  timesteps_total: 1107000
  training_iteration: 369
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3349 s, 369 iter, 1107000 ts, 1.09e+03 rew

agent-1: 317.0
agent-2: 367.0
agent-3: 408.0
Sum Reward: 1092.0
Avg Reward: 364.0
Min Reward: 317.0
Max Reward: 408.0
Gini Coefficient: 0.05555555555555555
20:20 Ratio: 1.2870662460567823
Max-min Ratio: 1.2870662460567823
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-02-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1395.0
  episode_reward_mean: 1088.24
  episode_reward_min: 631.0
  episodes_this_iter: 1
  episodes_total: 369
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.97
    dispatch_time_ms: 10.361
    learner:
      cur_lr: 0.0012862738221883774
      grad_gnorm: 40.0
      policy_entropy: 11.334696769714355
      policy_loss: 24.356658935546875
      var_gnorm: 42.124427795410156
      vf_explained_var: -0.028941631317138672
      vf_loss: 59.788753509521484
    num_steps_sampled: 1110000
    num_steps_trained: 1110000
    wait_time_ms: 70.101
  iterations_since_restore: 370
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3358.137897491455
  time_this_iter_s: 8.268922090530396
  time_total_s: 3358.137897491455
  timestamp: 1594098136
  timesteps_since_restore: 1110000
  timesteps_this_iter: 3000
  timesteps_total: 1110000
  training_iteration: 370
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3358 s, 370 iter, 1110000 ts, 1.09e+03 rew

agent-1: 362.0
agent-2: 357.0
agent-3: 384.0
Sum Reward: 1103.0
Avg Reward: 367.6666666666667
Min Reward: 357.0
Max Reward: 384.0
Gini Coefficient: 0.016319129646418858
20:20 Ratio: 1.0756302521008403
Max-min Ratio: 1.0756302521008403
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-02-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1395.0
  episode_reward_mean: 1087.66
  episode_reward_min: 631.0
  episodes_this_iter: 1
  episodes_total: 370
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.877
    dispatch_time_ms: 7.014
    learner:
      cur_lr: 0.0012860740534961224
      grad_gnorm: 39.999996185302734
      policy_entropy: 8.97372055053711
      policy_loss: -17.23084831237793
      var_gnorm: 42.12026596069336
      vf_explained_var: 0.5265910625457764
      vf_loss: 33.756980895996094
    num_steps_sampled: 1113000
    num_steps_trained: 1113000
    wait_time_ms: 69.188
  iterations_since_restore: 371
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3366.6859097480774
  time_this_iter_s: 8.548012256622314
  time_total_s: 3366.6859097480774
  timestamp: 1594098145
  timesteps_since_restore: 1113000
  timesteps_this_iter: 3000
  timesteps_total: 1113000
  training_iteration: 371
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3366 s, 371 iter, 1113000 ts, 1.09e+03 rew

agent-1: 363.0
agent-2: 385.0
agent-3: 331.0
Sum Reward: 1079.0
Avg Reward: 359.6666666666667
Min Reward: 331.0
Max Reward: 385.0
Gini Coefficient: 0.033364226135310475
20:20 Ratio: 1.163141993957704
Max-min Ratio: 1.163141993957704
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-02-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1395.0
  episode_reward_mean: 1086.9
  episode_reward_min: 631.0
  episodes_this_iter: 1
  episodes_total: 371
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.623
    dispatch_time_ms: 8.298
    learner:
      cur_lr: 0.0012858741683885455
      grad_gnorm: 40.0
      policy_entropy: 12.383976936340332
      policy_loss: 11.180727005004883
      var_gnorm: 42.21377182006836
      vf_explained_var: 0.4521659016609192
      vf_loss: 92.19403839111328
    num_steps_sampled: 1116000
    num_steps_trained: 1116000
    wait_time_ms: 90.41
  iterations_since_restore: 372
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3375.674256324768
  time_this_iter_s: 8.988346576690674
  time_total_s: 3375.674256324768
  timestamp: 1594098154
  timesteps_since_restore: 1116000
  timesteps_this_iter: 3000
  timesteps_total: 1116000
  training_iteration: 372
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3375 s, 372 iter, 1116000 ts, 1.09e+03 rew

agent-1: 310.0
agent-2: 443.0
agent-3: 416.0
Sum Reward: 1169.0
Avg Reward: 389.6666666666667
Min Reward: 310.0
Max Reward: 443.0
Gini Coefficient: 0.07584830339321358
20:20 Ratio: 1.429032258064516
Max-min Ratio: 1.429032258064516
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-02-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1395.0
  episode_reward_mean: 1087.76
  episode_reward_min: 631.0
  episodes_this_iter: 1
  episodes_total: 372
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.629
    dispatch_time_ms: 6.955
    learner:
      cur_lr: 0.0012856743996962905
      grad_gnorm: 40.0
      policy_entropy: 6.254464626312256
      policy_loss: 9.769853591918945
      var_gnorm: 42.24456787109375
      vf_explained_var: 0.3295131325721741
      vf_loss: 39.0760498046875
    num_steps_sampled: 1119000
    num_steps_trained: 1119000
    wait_time_ms: 85.336
  iterations_since_restore: 373
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3385.711820602417
  time_this_iter_s: 10.037564277648926
  time_total_s: 3385.711820602417
  timestamp: 1594098164
  timesteps_since_restore: 1119000
  timesteps_this_iter: 3000
  timesteps_total: 1119000
  training_iteration: 373
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3385 s, 373 iter, 1119000 ts, 1.09e+03 rew

agent-1: 402.0
agent-2: 438.0
agent-3: 432.0
Sum Reward: 1272.0
Avg Reward: 424.0
Min Reward: 402.0
Max Reward: 438.0
Gini Coefficient: 0.018867924528301886
20:20 Ratio: 1.0895522388059702
Max-min Ratio: 1.0895522388059702
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-02-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1395.0
  episode_reward_mean: 1088.6
  episode_reward_min: 631.0
  episodes_this_iter: 1
  episodes_total: 373
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.614
    dispatch_time_ms: 8.472
    learner:
      cur_lr: 0.0012854746310040355
      grad_gnorm: 27.537214279174805
      policy_entropy: 12.689140319824219
      policy_loss: -4.997817039489746
      var_gnorm: 42.32685852050781
      vf_explained_var: 0.5530438423156738
      vf_loss: 91.00210571289062
    num_steps_sampled: 1122000
    num_steps_trained: 1122000
    wait_time_ms: 90.017
  iterations_since_restore: 374
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3400.1632039546967
  time_this_iter_s: 14.451383352279663
  time_total_s: 3400.1632039546967
  timestamp: 1594098178
  timesteps_since_restore: 1122000
  timesteps_this_iter: 3000
  timesteps_total: 1122000
  training_iteration: 374
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3400 s, 374 iter, 1122000 ts, 1.09e+03 rew

agent-1: 352.0
agent-2: 463.0
agent-3: 422.0
Sum Reward: 1237.0
Avg Reward: 412.3333333333333
Min Reward: 352.0
Max Reward: 463.0
Gini Coefficient: 0.05982215036378335
20:20 Ratio: 1.3153409090909092
Max-min Ratio: 1.3153409090909092
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-03-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1395.0
  episode_reward_mean: 1090.21
  episode_reward_min: 631.0
  episodes_this_iter: 1
  episodes_total: 374
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.346
    dispatch_time_ms: 5.745
    learner:
      cur_lr: 0.0012852747458964586
      grad_gnorm: 40.0
      policy_entropy: 3.2672715187072754
      policy_loss: 2.0954718589782715
      var_gnorm: 42.350284576416016
      vf_explained_var: 0.2009977102279663
      vf_loss: 49.82326126098633
    num_steps_sampled: 1125000
    num_steps_trained: 1125000
    wait_time_ms: 78.351
  iterations_since_restore: 375
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3410.0820112228394
  time_this_iter_s: 9.9188072681427
  time_total_s: 3410.0820112228394
  timestamp: 1594098188
  timesteps_since_restore: 1125000
  timesteps_this_iter: 3000
  timesteps_total: 1125000
  training_iteration: 375
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3410 s, 375 iter, 1125000 ts, 1.09e+03 rew

agent-1: 431.0
agent-2: 449.0
agent-3: 445.0
Sum Reward: 1325.0
Avg Reward: 441.6666666666667
Min Reward: 431.0
Max Reward: 449.0
Gini Coefficient: 0.009056603773584906
20:20 Ratio: 1.0417633410672853
Max-min Ratio: 1.0417633410672853
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-03-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1395.0
  episode_reward_mean: 1092.03
  episode_reward_min: 631.0
  episodes_this_iter: 1
  episodes_total: 375
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 4.256
    dispatch_time_ms: 5.733
    learner:
      cur_lr: 0.0012850749772042036
      grad_gnorm: 36.99248123168945
      policy_entropy: 7.470012187957764
      policy_loss: -6.30766487121582
      var_gnorm: 42.492855072021484
      vf_explained_var: 0.7739859223365784
      vf_loss: 35.52055358886719
    num_steps_sampled: 1128000
    num_steps_trained: 1128000
    wait_time_ms: 90.59
  iterations_since_restore: 376
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3422.4672141075134
  time_this_iter_s: 12.385202884674072
  time_total_s: 3422.4672141075134
  timestamp: 1594098201
  timesteps_since_restore: 1128000
  timesteps_this_iter: 3000
  timesteps_total: 1128000
  training_iteration: 376
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3422 s, 376 iter, 1128000 ts, 1.09e+03 rew

agent-1: 452.0
agent-2: 439.0
agent-3: 417.0
Sum Reward: 1308.0
Avg Reward: 436.0
Min Reward: 417.0
Max Reward: 452.0
Gini Coefficient: 0.01783893985728848
20:20 Ratio: 1.0839328537170263
Max-min Ratio: 1.0839328537170263
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-03-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1395.0
  episode_reward_mean: 1091.19
  episode_reward_min: 631.0
  episodes_this_iter: 1
  episodes_total: 376
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.406
    dispatch_time_ms: 5.323
    learner:
      cur_lr: 0.0012848752085119486
      grad_gnorm: 40.0
      policy_entropy: 4.853786468505859
      policy_loss: 2.1277947425842285
      var_gnorm: 42.599525451660156
      vf_explained_var: -0.2382984161376953
      vf_loss: 45.62302780151367
    num_steps_sampled: 1131000
    num_steps_trained: 1131000
    wait_time_ms: 80.903
  iterations_since_restore: 377
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3432.614545106888
  time_this_iter_s: 10.14733099937439
  time_total_s: 3432.614545106888
  timestamp: 1594098211
  timesteps_since_restore: 1131000
  timesteps_this_iter: 3000
  timesteps_total: 1131000
  training_iteration: 377
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3432 s, 377 iter, 1131000 ts, 1.09e+03 rew

agent-1: 498.0
agent-2: 509.0
agent-3: 389.0
Sum Reward: 1396.0
Avg Reward: 465.3333333333333
Min Reward: 389.0
Max Reward: 509.0
Gini Coefficient: 0.05730659025787966
20:20 Ratio: 1.3084832904884318
Max-min Ratio: 1.3084832904884318
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-03-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1396.0
  episode_reward_mean: 1092.22
  episode_reward_min: 631.0
  episodes_this_iter: 1
  episodes_total: 377
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.487
    dispatch_time_ms: 5.496
    learner:
      cur_lr: 0.0012846754398196936
      grad_gnorm: 39.999996185302734
      policy_entropy: 20.610958099365234
      policy_loss: -25.606958389282227
      var_gnorm: 42.67320251464844
      vf_explained_var: -0.12490928173065186
      vf_loss: 44.28253173828125
    num_steps_sampled: 1134000
    num_steps_trained: 1134000
    wait_time_ms: 87.727
  iterations_since_restore: 378
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3441.9252700805664
  time_this_iter_s: 9.310724973678589
  time_total_s: 3441.9252700805664
  timestamp: 1594098220
  timesteps_since_restore: 1134000
  timesteps_this_iter: 3000
  timesteps_total: 1134000
  training_iteration: 378
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3441 s, 378 iter, 1134000 ts, 1.09e+03 rew

agent-1: 356.0
agent-2: 339.0
agent-3: 424.0
Sum Reward: 1119.0
Avg Reward: 373.0
Min Reward: 339.0
Max Reward: 424.0
Gini Coefficient: 0.0506404527852249
20:20 Ratio: 1.2507374631268438
Max-min Ratio: 1.2507374631268438
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-03-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1396.0
  episode_reward_mean: 1090.75
  episode_reward_min: 631.0
  episodes_this_iter: 1
  episodes_total: 378
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.367
    dispatch_time_ms: 6.061
    learner:
      cur_lr: 0.0012844755547121167
      grad_gnorm: 40.000003814697266
      policy_entropy: 13.81907844543457
      policy_loss: -17.303829193115234
      var_gnorm: 42.69736099243164
      vf_explained_var: 0.5389177799224854
      vf_loss: 46.98826599121094
    num_steps_sampled: 1137000
    num_steps_trained: 1137000
    wait_time_ms: 71.354
  iterations_since_restore: 379
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3451.3640389442444
  time_this_iter_s: 9.438768863677979
  time_total_s: 3451.3640389442444
  timestamp: 1594098230
  timesteps_since_restore: 1137000
  timesteps_this_iter: 3000
  timesteps_total: 1137000
  training_iteration: 379
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3451 s, 379 iter, 1137000 ts, 1.09e+03 rew

agent-1: 264.0
agent-2: 363.0
agent-3: 386.0
Sum Reward: 1013.0
Avg Reward: 337.6666666666667
Min Reward: 264.0
Max Reward: 386.0
Gini Coefficient: 0.08028956893715038
20:20 Ratio: 1.4621212121212122
Max-min Ratio: 1.4621212121212122
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-03-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1396.0
  episode_reward_mean: 1088.02
  episode_reward_min: 631.0
  episodes_this_iter: 1
  episodes_total: 379
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.697
    dispatch_time_ms: 7.469
    learner:
      cur_lr: 0.0012842757860198617
      grad_gnorm: 40.0
      policy_entropy: 9.285858154296875
      policy_loss: -3.7553062438964844
      var_gnorm: 42.685829162597656
      vf_explained_var: 0.4305703639984131
      vf_loss: 93.40863037109375
    num_steps_sampled: 1140000
    num_steps_trained: 1140000
    wait_time_ms: 80.746
  iterations_since_restore: 380
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3459.8848102092743
  time_this_iter_s: 8.520771265029907
  time_total_s: 3459.8848102092743
  timestamp: 1594098238
  timesteps_since_restore: 1140000
  timesteps_this_iter: 3000
  timesteps_total: 1140000
  training_iteration: 380
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3459 s, 380 iter, 1140000 ts, 1.09e+03 rew

agent-1: 307.0
agent-2: 431.0
agent-3: 372.0
Sum Reward: 1110.0
Avg Reward: 370.0
Min Reward: 307.0
Max Reward: 431.0
Gini Coefficient: 0.07447447447447447
20:20 Ratio: 1.4039087947882736
Max-min Ratio: 1.4039087947882736
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-04-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1396.0
  episode_reward_mean: 1086.59
  episode_reward_min: 631.0
  episodes_this_iter: 1
  episodes_total: 380
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.85
    dispatch_time_ms: 6.075
    learner:
      cur_lr: 0.0012840760173276067
      grad_gnorm: 40.000003814697266
      policy_entropy: 7.63298225402832
      policy_loss: -0.4109412431716919
      var_gnorm: 42.754661560058594
      vf_explained_var: 0.347179651260376
      vf_loss: 97.24230194091797
    num_steps_sampled: 1143000
    num_steps_trained: 1143000
    wait_time_ms: 74.602
  iterations_since_restore: 381
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3469.180608510971
  time_this_iter_s: 9.295798301696777
  time_total_s: 3469.180608510971
  timestamp: 1594098248
  timesteps_since_restore: 1143000
  timesteps_this_iter: 3000
  timesteps_total: 1143000
  training_iteration: 381
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3469 s, 381 iter, 1143000 ts, 1.09e+03 rew

agent-1: 382.0
agent-2: 423.0
agent-3: 302.0
Sum Reward: 1107.0
Avg Reward: 369.0
Min Reward: 302.0
Max Reward: 423.0
Gini Coefficient: 0.07286961758506474
20:20 Ratio: 1.400662251655629
Max-min Ratio: 1.400662251655629
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-04-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1396.0
  episode_reward_mean: 1085.97
  episode_reward_min: 631.0
  episodes_this_iter: 1
  episodes_total: 381
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.84
    dispatch_time_ms: 8.325
    learner:
      cur_lr: 0.0012838762486353517
      grad_gnorm: 40.0
      policy_entropy: 12.32814884185791
      policy_loss: 0.8061479330062866
      var_gnorm: 42.77521514892578
      vf_explained_var: 0.7490023374557495
      vf_loss: 27.10259246826172
    num_steps_sampled: 1146000
    num_steps_trained: 1146000
    wait_time_ms: 83.462
  iterations_since_restore: 382
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3478.142019033432
  time_this_iter_s: 8.961410522460938
  time_total_s: 3478.142019033432
  timestamp: 1594098257
  timesteps_since_restore: 1146000
  timesteps_this_iter: 3000
  timesteps_total: 1146000
  training_iteration: 382
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3478 s, 382 iter, 1146000 ts, 1.09e+03 rew

agent-1: 381.0
agent-2: 392.0
agent-3: 478.0
Sum Reward: 1251.0
Avg Reward: 417.0
Min Reward: 381.0
Max Reward: 478.0
Gini Coefficient: 0.051691979749533705
20:20 Ratio: 1.2545931758530184
Max-min Ratio: 1.2545931758530184
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-04-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1396.0
  episode_reward_mean: 1087.01
  episode_reward_min: 631.0
  episodes_this_iter: 1
  episodes_total: 382
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.225
    dispatch_time_ms: 6.999
    learner:
      cur_lr: 0.0012836763635277748
      grad_gnorm: 39.99999237060547
      policy_entropy: 8.123126029968262
      policy_loss: 6.793260097503662
      var_gnorm: 42.7484245300293
      vf_explained_var: 0.7603623867034912
      vf_loss: 31.664884567260742
    num_steps_sampled: 1149000
    num_steps_trained: 1149000
    wait_time_ms: 77.175
  iterations_since_restore: 383
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3488.049107313156
  time_this_iter_s: 9.907088279724121
  time_total_s: 3488.049107313156
  timestamp: 1594098267
  timesteps_since_restore: 1149000
  timesteps_this_iter: 3000
  timesteps_total: 1149000
  training_iteration: 383
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3488 s, 383 iter, 1149000 ts, 1.09e+03 rew

agent-1: 525.0
agent-2: 412.0
agent-3: 226.0
Sum Reward: 1163.0
Avg Reward: 387.6666666666667
Min Reward: 226.0
Max Reward: 525.0
Gini Coefficient: 0.17139581541989107
20:20 Ratio: 2.3230088495575223
Max-min Ratio: 2.3230088495575223
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-04-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1396.0
  episode_reward_mean: 1085.39
  episode_reward_min: 631.0
  episodes_this_iter: 1
  episodes_total: 383
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.425
    dispatch_time_ms: 16.529
    learner:
      cur_lr: 0.0012834765948355198
      grad_gnorm: 40.000003814697266
      policy_entropy: 14.634841918945312
      policy_loss: -30.15237808227539
      var_gnorm: 42.846771240234375
      vf_explained_var: -1.0
      vf_loss: 112.57434844970703
    num_steps_sampled: 1152000
    num_steps_trained: 1152000
    wait_time_ms: 80.242
  iterations_since_restore: 384
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3497.297326564789
  time_this_iter_s: 9.24821925163269
  time_total_s: 3497.297326564789
  timestamp: 1594098276
  timesteps_since_restore: 1152000
  timesteps_this_iter: 3000
  timesteps_total: 1152000
  training_iteration: 384
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3497 s, 384 iter, 1152000 ts, 1.09e+03 rew

agent-1: 291.0
agent-2: 502.0
agent-3: 336.0
Sum Reward: 1129.0
Avg Reward: 376.3333333333333
Min Reward: 291.0
Max Reward: 502.0
Gini Coefficient: 0.12459403602007676
20:20 Ratio: 1.725085910652921
Max-min Ratio: 1.725085910652921
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-04-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1396.0
  episode_reward_mean: 1084.41
  episode_reward_min: 631.0
  episodes_this_iter: 1
  episodes_total: 384
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.849
    dispatch_time_ms: 16.834
    learner:
      cur_lr: 0.0012832768261432648
      grad_gnorm: 39.999996185302734
      policy_entropy: 4.003554821014404
      policy_loss: 10.923054695129395
      var_gnorm: 42.77385711669922
      vf_explained_var: -0.8291717767715454
      vf_loss: 65.29647827148438
    num_steps_sampled: 1155000
    num_steps_trained: 1155000
    wait_time_ms: 61.85
  iterations_since_restore: 385
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3506.7535383701324
  time_this_iter_s: 9.456211805343628
  time_total_s: 3506.7535383701324
  timestamp: 1594098285
  timesteps_since_restore: 1155000
  timesteps_this_iter: 3000
  timesteps_total: 1155000
  training_iteration: 385
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3506 s, 385 iter, 1155000 ts, 1.08e+03 rew

agent-1: 312.0
agent-2: 421.0
agent-3: 414.0
Sum Reward: 1147.0
Avg Reward: 382.3333333333333
Min Reward: 312.0
Max Reward: 421.0
Gini Coefficient: 0.06335367625690207
20:20 Ratio: 1.3493589743589745
Max-min Ratio: 1.3493589743589745
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-04-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1396.0
  episode_reward_mean: 1082.75
  episode_reward_min: 631.0
  episodes_this_iter: 1
  episodes_total: 385
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.665
    dispatch_time_ms: 23.806
    learner:
      cur_lr: 0.0012830770574510098
      grad_gnorm: 24.429298400878906
      policy_entropy: 4.422015190124512
      policy_loss: 1.6410393714904785
      var_gnorm: 42.79582214355469
      vf_explained_var: 0.1319449543952942
      vf_loss: 17.292255401611328
    num_steps_sampled: 1158000
    num_steps_trained: 1158000
    wait_time_ms: 79.357
  iterations_since_restore: 386
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3516.3481106758118
  time_this_iter_s: 9.594572305679321
  time_total_s: 3516.3481106758118
  timestamp: 1594098295
  timesteps_since_restore: 1158000
  timesteps_this_iter: 3000
  timesteps_total: 1158000
  training_iteration: 386
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3516 s, 386 iter, 1158000 ts, 1.08e+03 rew

agent-1: 429.0
agent-2: 427.0
agent-3: 383.0
Sum Reward: 1239.0
Avg Reward: 413.0
Min Reward: 383.0
Max Reward: 429.0
Gini Coefficient: 0.024751143395211193
20:20 Ratio: 1.1201044386422976
Max-min Ratio: 1.1201044386422976
agent-1: 378.0
agent-2: 440.0
agent-3: 457.0
Sum Reward: 1275.0
Avg Reward: 425.0
Min Reward: 378.0
Max Reward: 457.0
Gini Coefficient: 0.04130718954248366
20:20 Ratio: 1.208994708994709
Max-min Ratio: 1.208994708994709
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-05-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1396.0
  episode_reward_mean: 1084.45
  episode_reward_min: 631.0
  episodes_this_iter: 2
  episodes_total: 387
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.887
    dispatch_time_ms: 36.331
    learner:
      cur_lr: 0.001282877172343433
      grad_gnorm: 39.999996185302734
      policy_entropy: 6.325722694396973
      policy_loss: -173.9110565185547
      var_gnorm: 42.81432342529297
      vf_explained_var: -1.0
      vf_loss: 23549.8515625
    num_steps_sampled: 1161000
    num_steps_trained: 1161000
    wait_time_ms: 78.716
  iterations_since_restore: 387
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3527.407647371292
  time_this_iter_s: 11.059536695480347
  time_total_s: 3527.407647371292
  timestamp: 1594098306
  timesteps_since_restore: 1161000
  timesteps_this_iter: 3000
  timesteps_total: 1161000
  training_iteration: 387
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3527 s, 387 iter, 1161000 ts, 1.08e+03 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-05-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1396.0
  episode_reward_mean: 1084.45
  episode_reward_min: 631.0
  episodes_this_iter: 0
  episodes_total: 387
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.939
    dispatch_time_ms: 22.109
    learner:
      cur_lr: 0.0012826774036511779
      grad_gnorm: 30.931583404541016
      policy_entropy: 7.3473920822143555
      policy_loss: 7.279693603515625
      var_gnorm: 42.89262390136719
      vf_explained_var: -1.0
      vf_loss: 10.948502540588379
    num_steps_sampled: 1164000
    num_steps_trained: 1164000
    wait_time_ms: 77.27
  iterations_since_restore: 388
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3536.6729757785797
  time_this_iter_s: 9.265328407287598
  time_total_s: 3536.6729757785797
  timestamp: 1594098315
  timesteps_since_restore: 1164000
  timesteps_this_iter: 3000
  timesteps_total: 1164000
  training_iteration: 388
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3536 s, 388 iter, 1164000 ts, 1.08e+03 rew

agent-1: 413.0
agent-2: 394.0
agent-3: 424.0
Sum Reward: 1231.0
Avg Reward: 410.3333333333333
Min Reward: 394.0
Max Reward: 424.0
Gini Coefficient: 0.016246953696181964
20:20 Ratio: 1.0761421319796953
Max-min Ratio: 1.0761421319796953
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-05-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1396.0
  episode_reward_mean: 1085.08
  episode_reward_min: 631.0
  episodes_this_iter: 1
  episodes_total: 388
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.5
    dispatch_time_ms: 11.306
    learner:
      cur_lr: 0.0012824776349589229
      grad_gnorm: 12.770195007324219
      policy_entropy: 6.2810211181640625
      policy_loss: -4.812098026275635
      var_gnorm: 42.90938186645508
      vf_explained_var: 0.04802614450454712
      vf_loss: 73.1014404296875
    num_steps_sampled: 1167000
    num_steps_trained: 1167000
    wait_time_ms: 99.372
  iterations_since_restore: 389
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3547.4313640594482
  time_this_iter_s: 10.75838828086853
  time_total_s: 3547.4313640594482
  timestamp: 1594098326
  timesteps_since_restore: 1167000
  timesteps_this_iter: 3000
  timesteps_total: 1167000
  training_iteration: 389
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3547 s, 389 iter, 1167000 ts, 1.09e+03 rew

agent-1: 448.0
agent-2: 407.0
agent-3: 480.0
Sum Reward: 1335.0
Avg Reward: 445.0
Min Reward: 407.0
Max Reward: 480.0
Gini Coefficient: 0.03645443196004994
20:20 Ratio: 1.1793611793611793
Max-min Ratio: 1.1793611793611793
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-05-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1396.0
  episode_reward_mean: 1086.13
  episode_reward_min: 631.0
  episodes_this_iter: 1
  episodes_total: 389
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.436
    dispatch_time_ms: 24.663
    learner:
      cur_lr: 0.001282277749851346
      grad_gnorm: 40.0
      policy_entropy: 8.170098304748535
      policy_loss: -11.430526733398438
      var_gnorm: 43.07693099975586
      vf_explained_var: 0.808617353439331
      vf_loss: 56.876155853271484
    num_steps_sampled: 1170000
    num_steps_trained: 1170000
    wait_time_ms: 71.474
  iterations_since_restore: 390
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3556.8504781723022
  time_this_iter_s: 9.419114112854004
  time_total_s: 3556.8504781723022
  timestamp: 1594098336
  timesteps_since_restore: 1170000
  timesteps_this_iter: 3000
  timesteps_total: 1170000
  training_iteration: 390
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3556 s, 390 iter, 1170000 ts, 1.09e+03 rew

agent-1: 402.0
agent-2: 447.0
agent-3: 253.0
Sum Reward: 1102.0
Avg Reward: 367.3333333333333
Min Reward: 253.0
Max Reward: 447.0
Gini Coefficient: 0.11736237144585603
20:20 Ratio: 1.766798418972332
Max-min Ratio: 1.766798418972332
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-05-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1396.0
  episode_reward_mean: 1083.79
  episode_reward_min: 631.0
  episodes_this_iter: 1
  episodes_total: 390
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.648
    dispatch_time_ms: 19.846
    learner:
      cur_lr: 0.001282077981159091
      grad_gnorm: 40.0
      policy_entropy: 6.795768737792969
      policy_loss: 2.4610509872436523
      var_gnorm: 43.09112548828125
      vf_explained_var: -1.0
      vf_loss: 31.133638381958008
    num_steps_sampled: 1173000
    num_steps_trained: 1173000
    wait_time_ms: 62.696
  iterations_since_restore: 391
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3566.8253622055054
  time_this_iter_s: 9.974884033203125
  time_total_s: 3566.8253622055054
  timestamp: 1594098346
  timesteps_since_restore: 1173000
  timesteps_this_iter: 3000
  timesteps_total: 1173000
  training_iteration: 391
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3566 s, 391 iter, 1173000 ts, 1.08e+03 rew

agent-1: 456.0
agent-2: 461.0
agent-3: 430.0
Sum Reward: 1347.0
Avg Reward: 449.0
Min Reward: 430.0
Max Reward: 461.0
Gini Coefficient: 0.015342736946300421
20:20 Ratio: 1.072093023255814
Max-min Ratio: 1.072093023255814
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-05-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1396.0
  episode_reward_mean: 1084.9
  episode_reward_min: 631.0
  episodes_this_iter: 1
  episodes_total: 391
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.825
    dispatch_time_ms: 33.749
    learner:
      cur_lr: 0.001281878212466836
      grad_gnorm: 40.000003814697266
      policy_entropy: 12.646638870239258
      policy_loss: -14.7063627243042
      var_gnorm: 43.18707275390625
      vf_explained_var: 0.5979354381561279
      vf_loss: 57.42236328125
    num_steps_sampled: 1176000
    num_steps_trained: 1176000
    wait_time_ms: 62.85
  iterations_since_restore: 392
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3576.4477713108063
  time_this_iter_s: 9.622409105300903
  time_total_s: 3576.4477713108063
  timestamp: 1594098355
  timesteps_since_restore: 1176000
  timesteps_this_iter: 3000
  timesteps_total: 1176000
  training_iteration: 392
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3576 s, 392 iter, 1176000 ts, 1.08e+03 rew

agent-1: 479.0
agent-2: 407.0
agent-3: 440.0
Sum Reward: 1326.0
Avg Reward: 442.0
Min Reward: 407.0
Max Reward: 479.0
Gini Coefficient: 0.03619909502262444
20:20 Ratio: 1.1769041769041768
Max-min Ratio: 1.1769041769041768
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-06-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1396.0
  episode_reward_mean: 1085.73
  episode_reward_min: 631.0
  episodes_this_iter: 1
  episodes_total: 392
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.502
    dispatch_time_ms: 19.323
    learner:
      cur_lr: 0.001281678443774581
      grad_gnorm: 40.0
      policy_entropy: 10.182832717895508
      policy_loss: 0.1670072078704834
      var_gnorm: 43.198081970214844
      vf_explained_var: 0.23448282480239868
      vf_loss: 38.230255126953125
    num_steps_sampled: 1179000
    num_steps_trained: 1179000
    wait_time_ms: 70.937
  iterations_since_restore: 393
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3586.7663264274597
  time_this_iter_s: 10.318555116653442
  time_total_s: 3586.7663264274597
  timestamp: 1594098366
  timesteps_since_restore: 1179000
  timesteps_this_iter: 3000
  timesteps_total: 1179000
  training_iteration: 393
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3586 s, 393 iter, 1179000 ts, 1.09e+03 rew

agent-1: 388.0
agent-2: 425.0
agent-3: 487.0
Sum Reward: 1300.0
Avg Reward: 433.3333333333333
Min Reward: 388.0
Max Reward: 487.0
Gini Coefficient: 0.05076923076923077
20:20 Ratio: 1.2551546391752577
Max-min Ratio: 1.2551546391752577
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-06-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1396.0
  episode_reward_mean: 1086.82
  episode_reward_min: 631.0
  episodes_this_iter: 1
  episodes_total: 393
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.424
    dispatch_time_ms: 6.179
    learner:
      cur_lr: 0.0012814785586670041
      grad_gnorm: 40.0
      policy_entropy: 11.924561500549316
      policy_loss: -7.371718883514404
      var_gnorm: 43.25151824951172
      vf_explained_var: 0.44195878505706787
      vf_loss: 106.17906951904297
    num_steps_sampled: 1182000
    num_steps_trained: 1182000
    wait_time_ms: 90.92
  iterations_since_restore: 394
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3595.819706916809
  time_this_iter_s: 9.053380489349365
  time_total_s: 3595.819706916809
  timestamp: 1594098375
  timesteps_since_restore: 1182000
  timesteps_this_iter: 3000
  timesteps_total: 1182000
  training_iteration: 394
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3595 s, 394 iter, 1182000 ts, 1.09e+03 rew

agent-1: 464.0
agent-2: 448.0
agent-3: 378.0
Sum Reward: 1290.0
Avg Reward: 430.0
Min Reward: 378.0
Max Reward: 464.0
Gini Coefficient: 0.044444444444444446
20:20 Ratio: 1.2275132275132274
Max-min Ratio: 1.2275132275132274
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-06-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1396.0
  episode_reward_mean: 1087.28
  episode_reward_min: 631.0
  episodes_this_iter: 1
  episodes_total: 394
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.642
    dispatch_time_ms: 6.159
    learner:
      cur_lr: 0.001281278789974749
      grad_gnorm: 33.436988830566406
      policy_entropy: 8.404194831848145
      policy_loss: 1.9330503940582275
      var_gnorm: 43.28528594970703
      vf_explained_var: -0.8119158744812012
      vf_loss: 14.519572257995605
    num_steps_sampled: 1185000
    num_steps_trained: 1185000
    wait_time_ms: 74.291
  iterations_since_restore: 395
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3605.249615907669
  time_this_iter_s: 9.429908990859985
  time_total_s: 3605.249615907669
  timestamp: 1594098384
  timesteps_since_restore: 1185000
  timesteps_this_iter: 3000
  timesteps_total: 1185000
  training_iteration: 395
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3605 s, 395 iter, 1185000 ts, 1.09e+03 rew

agent-1: 495.0
agent-2: 471.0
agent-3: 465.0
Sum Reward: 1431.0
Avg Reward: 477.0
Min Reward: 465.0
Max Reward: 495.0
Gini Coefficient: 0.013976240391334731
20:20 Ratio: 1.064516129032258
Max-min Ratio: 1.064516129032258
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-06-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1089.07
  episode_reward_min: 631.0
  episodes_this_iter: 1
  episodes_total: 395
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.604
    dispatch_time_ms: 5.67
    learner:
      cur_lr: 0.001281079021282494
      grad_gnorm: 40.000003814697266
      policy_entropy: 11.26585578918457
      policy_loss: -7.524937629699707
      var_gnorm: 43.432350158691406
      vf_explained_var: 0.8182367086410522
      vf_loss: 42.254058837890625
    num_steps_sampled: 1188000
    num_steps_trained: 1188000
    wait_time_ms: 74.382
  iterations_since_restore: 396
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3614.1136705875397
  time_this_iter_s: 8.864054679870605
  time_total_s: 3614.1136705875397
  timestamp: 1594098393
  timesteps_since_restore: 1188000
  timesteps_this_iter: 3000
  timesteps_total: 1188000
  training_iteration: 396
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3614 s, 396 iter, 1188000 ts, 1.09e+03 rew

agent-1: 390.0
agent-2: 425.0
agent-3: 399.0
Sum Reward: 1214.0
Avg Reward: 404.6666666666667
Min Reward: 390.0
Max Reward: 425.0
Gini Coefficient: 0.019220208676551345
20:20 Ratio: 1.0897435897435896
Max-min Ratio: 1.0897435897435896
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-06-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1088.86
  episode_reward_min: 631.0
  episodes_this_iter: 1
  episodes_total: 396
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.001
    dispatch_time_ms: 7.487
    learner:
      cur_lr: 0.001280879252590239
      grad_gnorm: 40.000003814697266
      policy_entropy: 11.366265296936035
      policy_loss: 5.306427001953125
      var_gnorm: 43.55828094482422
      vf_explained_var: 0.24156689643859863
      vf_loss: 55.46782302856445
    num_steps_sampled: 1191000
    num_steps_trained: 1191000
    wait_time_ms: 70.329
  iterations_since_restore: 397
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3623.231953382492
  time_this_iter_s: 9.118282794952393
  time_total_s: 3623.231953382492
  timestamp: 1594098402
  timesteps_since_restore: 1191000
  timesteps_this_iter: 3000
  timesteps_total: 1191000
  training_iteration: 397
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3623 s, 397 iter, 1191000 ts, 1.09e+03 rew

agent-1: 404.0
agent-2: 421.0
agent-3: 334.0
Sum Reward: 1159.0
Avg Reward: 386.3333333333333
Min Reward: 334.0
Max Reward: 421.0
Gini Coefficient: 0.05004314063848145
20:20 Ratio: 1.2604790419161678
Max-min Ratio: 1.2604790419161678
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-06-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1088.32
  episode_reward_min: 631.0
  episodes_this_iter: 1
  episodes_total: 397
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.414
    dispatch_time_ms: 7.201
    learner:
      cur_lr: 0.0012806793674826622
      grad_gnorm: 36.720787048339844
      policy_entropy: 5.441860198974609
      policy_loss: -5.782521724700928
      var_gnorm: 43.50457763671875
      vf_explained_var: -1.0
      vf_loss: 41.887569427490234
    num_steps_sampled: 1194000
    num_steps_trained: 1194000
    wait_time_ms: 70.694
  iterations_since_restore: 398
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3631.237829208374
  time_this_iter_s: 8.005875825881958
  time_total_s: 3631.237829208374
  timestamp: 1594098410
  timesteps_since_restore: 1194000
  timesteps_this_iter: 3000
  timesteps_total: 1194000
  training_iteration: 398
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3631 s, 398 iter, 1194000 ts, 1.09e+03 rew

agent-1: 218.0
agent-2: 329.0
agent-3: 318.0
Sum Reward: 865.0
Avg Reward: 288.3333333333333
Min Reward: 218.0
Max Reward: 329.0
Gini Coefficient: 0.08554913294797688
20:20 Ratio: 1.5091743119266054
Max-min Ratio: 1.5091743119266054
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-06-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1084.48
  episode_reward_min: 631.0
  episodes_this_iter: 1
  episodes_total: 398
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.556
    dispatch_time_ms: 6.002
    learner:
      cur_lr: 0.0012804795987904072
      grad_gnorm: 40.0
      policy_entropy: 8.339728355407715
      policy_loss: -19.931673049926758
      var_gnorm: 43.558223724365234
      vf_explained_var: 0.358032763004303
      vf_loss: 40.93288040161133
    num_steps_sampled: 1197000
    num_steps_trained: 1197000
    wait_time_ms: 74.228
  iterations_since_restore: 399
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3640.1631231307983
  time_this_iter_s: 8.925293922424316
  time_total_s: 3640.1631231307983
  timestamp: 1594098419
  timesteps_since_restore: 1197000
  timesteps_this_iter: 3000
  timesteps_total: 1197000
  training_iteration: 399
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3640 s, 399 iter, 1197000 ts, 1.08e+03 rew

agent-1: 297.0
agent-2: 325.0
agent-3: 268.0
Sum Reward: 890.0
Avg Reward: 296.6666666666667
Min Reward: 268.0
Max Reward: 325.0
Gini Coefficient: 0.04269662921348315
20:20 Ratio: 1.212686567164179
Max-min Ratio: 1.212686567164179
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-07-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1082.32
  episode_reward_min: 631.0
  episodes_this_iter: 1
  episodes_total: 399
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.458
    dispatch_time_ms: 5.61
    learner:
      cur_lr: 0.0012802798300981522
      grad_gnorm: 39.999996185302734
      policy_entropy: 8.159835815429688
      policy_loss: -13.76954460144043
      var_gnorm: 43.52694320678711
      vf_explained_var: -0.3118727207183838
      vf_loss: 58.77853012084961
    num_steps_sampled: 1200000
    num_steps_trained: 1200000
    wait_time_ms: 78.423
  iterations_since_restore: 400
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3648.175808429718
  time_this_iter_s: 8.012685298919678
  time_total_s: 3648.175808429718
  timestamp: 1594098427
  timesteps_since_restore: 1200000
  timesteps_this_iter: 3000
  timesteps_total: 1200000
  training_iteration: 400
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3648 s, 400 iter, 1200000 ts, 1.08e+03 rew

agent-1: 268.0
agent-2: 329.0
agent-3: 298.0
Sum Reward: 895.0
Avg Reward: 298.3333333333333
Min Reward: 268.0
Max Reward: 329.0
Gini Coefficient: 0.04543761638733706
20:20 Ratio: 1.2276119402985075
Max-min Ratio: 1.2276119402985075
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-07-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1078.41
  episode_reward_min: 631.0
  episodes_this_iter: 1
  episodes_total: 400
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.428
    dispatch_time_ms: 7.59
    learner:
      cur_lr: 0.0012800799449905753
      grad_gnorm: 40.000003814697266
      policy_entropy: 11.78643798828125
      policy_loss: 11.732364654541016
      var_gnorm: 43.37909698486328
      vf_explained_var: -0.4250384569168091
      vf_loss: 39.558509826660156
    num_steps_sampled: 1203000
    num_steps_trained: 1203000
    wait_time_ms: 66.02
  iterations_since_restore: 401
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3656.349380970001
  time_this_iter_s: 8.173572540283203
  time_total_s: 3656.349380970001
  timestamp: 1594098436
  timesteps_since_restore: 1203000
  timesteps_this_iter: 3000
  timesteps_total: 1203000
  training_iteration: 401
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3656 s, 401 iter, 1203000 ts, 1.08e+03 rew

agent-1: 310.0
agent-2: 235.0
agent-3: 243.0
Sum Reward: 788.0
Avg Reward: 262.6666666666667
Min Reward: 235.0
Max Reward: 310.0
Gini Coefficient: 0.06345177664974619
20:20 Ratio: 1.3191489361702127
Max-min Ratio: 1.3191489361702127
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-07-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1072.88
  episode_reward_min: 631.0
  episodes_this_iter: 1
  episodes_total: 401
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.605
    dispatch_time_ms: 6.378
    learner:
      cur_lr: 0.0012798801762983203
      grad_gnorm: 27.32916831970215
      policy_entropy: 15.676881790161133
      policy_loss: 1.6163289546966553
      var_gnorm: 43.425235748291016
      vf_explained_var: -0.06419539451599121
      vf_loss: 37.869529724121094
    num_steps_sampled: 1206000
    num_steps_trained: 1206000
    wait_time_ms: 72.552
  iterations_since_restore: 402
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3664.6607596874237
  time_this_iter_s: 8.311378717422485
  time_total_s: 3664.6607596874237
  timestamp: 1594098444
  timesteps_since_restore: 1206000
  timesteps_this_iter: 3000
  timesteps_total: 1206000
  training_iteration: 402
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3664 s, 402 iter, 1206000 ts, 1.07e+03 rew

agent-1: 294.0
agent-2: 333.0
agent-3: 357.0
Sum Reward: 984.0
Avg Reward: 328.0
Min Reward: 294.0
Max Reward: 357.0
Gini Coefficient: 0.042682926829268296
20:20 Ratio: 1.2142857142857142
Max-min Ratio: 1.2142857142857142
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-07-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1071.07
  episode_reward_min: 631.0
  episodes_this_iter: 1
  episodes_total: 402
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.735
    dispatch_time_ms: 6.61
    learner:
      cur_lr: 0.0012796804076060653
      grad_gnorm: 16.141096115112305
      policy_entropy: 10.735392570495605
      policy_loss: 15.05205249786377
      var_gnorm: 43.451717376708984
      vf_explained_var: -1.0
      vf_loss: 24.598217010498047
    num_steps_sampled: 1209000
    num_steps_trained: 1209000
    wait_time_ms: 70.45
  iterations_since_restore: 403
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3672.7564470767975
  time_this_iter_s: 8.09568738937378
  time_total_s: 3672.7564470767975
  timestamp: 1594098452
  timesteps_since_restore: 1209000
  timesteps_this_iter: 3000
  timesteps_total: 1209000
  training_iteration: 403
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3672 s, 403 iter, 1209000 ts, 1.07e+03 rew

agent-1: 343.0
agent-2: 348.0
agent-3: 279.0
Sum Reward: 970.0
Avg Reward: 323.3333333333333
Min Reward: 279.0
Max Reward: 348.0
Gini Coefficient: 0.04742268041237113
20:20 Ratio: 1.2473118279569892
Max-min Ratio: 1.2473118279569892
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-07-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1069.21
  episode_reward_min: 631.0
  episodes_this_iter: 1
  episodes_total: 403
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.975
    dispatch_time_ms: 7.935
    learner:
      cur_lr: 0.0012794806389138103
      grad_gnorm: 40.0
      policy_entropy: 13.75093936920166
      policy_loss: -15.273845672607422
      var_gnorm: 43.488502502441406
      vf_explained_var: 0.374347448348999
      vf_loss: 34.218788146972656
    num_steps_sampled: 1212000
    num_steps_trained: 1212000
    wait_time_ms: 81.465
  iterations_since_restore: 404
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3681.279429912567
  time_this_iter_s: 8.522982835769653
  time_total_s: 3681.279429912567
  timestamp: 1594098461
  timesteps_since_restore: 1212000
  timesteps_this_iter: 3000
  timesteps_total: 1212000
  training_iteration: 404
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3681 s, 404 iter, 1212000 ts, 1.07e+03 rew

agent-1: 357.0
agent-2: 366.0
agent-3: 369.0
Sum Reward: 1092.0
Avg Reward: 364.0
Min Reward: 357.0
Max Reward: 369.0
Gini Coefficient: 0.007326007326007326
20:20 Ratio: 1.0336134453781514
Max-min Ratio: 1.0336134453781514
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-07-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1067.35
  episode_reward_min: 631.0
  episodes_this_iter: 1
  episodes_total: 404
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.668
    dispatch_time_ms: 7.213
    learner:
      cur_lr: 0.0012792807538062334
      grad_gnorm: 22.88593292236328
      policy_entropy: 8.508914947509766
      policy_loss: 10.310468673706055
      var_gnorm: 43.59210205078125
      vf_explained_var: 0.7345341444015503
      vf_loss: 38.06407928466797
    num_steps_sampled: 1215000
    num_steps_trained: 1215000
    wait_time_ms: 69.624
  iterations_since_restore: 405
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3690.043603181839
  time_this_iter_s: 8.76417326927185
  time_total_s: 3690.043603181839
  timestamp: 1594098469
  timesteps_since_restore: 1215000
  timesteps_this_iter: 3000
  timesteps_total: 1215000
  training_iteration: 405
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3690 s, 405 iter, 1215000 ts, 1.07e+03 rew

agent-1: 370.0
agent-2: 353.0
agent-3: 369.0
Sum Reward: 1092.0
Avg Reward: 364.0
Min Reward: 353.0
Max Reward: 370.0
Gini Coefficient: 0.010378510378510378
20:20 Ratio: 1.048158640226629
Max-min Ratio: 1.048158640226629
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-07-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1064.32
  episode_reward_min: 631.0
  episodes_this_iter: 1
  episodes_total: 405
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.651
    dispatch_time_ms: 9.341
    learner:
      cur_lr: 0.0012790809851139784
      grad_gnorm: 40.0
      policy_entropy: 6.6732988357543945
      policy_loss: 16.05436897277832
      var_gnorm: 43.5935173034668
      vf_explained_var: 0.6733988523483276
      vf_loss: 50.612220764160156
    num_steps_sampled: 1218000
    num_steps_trained: 1218000
    wait_time_ms: 69.849
  iterations_since_restore: 406
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3698.073081970215
  time_this_iter_s: 8.029478788375854
  time_total_s: 3698.073081970215
  timestamp: 1594098477
  timesteps_since_restore: 1218000
  timesteps_this_iter: 3000
  timesteps_total: 1218000
  training_iteration: 406
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3698 s, 406 iter, 1218000 ts, 1.06e+03 rew

agent-1: 186.0
agent-2: 99.0
agent-3: 294.0
Sum Reward: 579.0
Avg Reward: 193.0
Min Reward: 99.0
Max Reward: 294.0
Gini Coefficient: 0.22452504317789293
20:20 Ratio: 2.9696969696969697
Max-min Ratio: 2.9696969696969697
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-08-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1057.04
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 406
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.814
    dispatch_time_ms: 7.096
    learner:
      cur_lr: 0.0012788812164217234
      grad_gnorm: 40.0
      policy_entropy: 13.908781051635742
      policy_loss: -11.110855102539062
      var_gnorm: 43.545372009277344
      vf_explained_var: 0.6263375282287598
      vf_loss: 29.05086898803711
    num_steps_sampled: 1221000
    num_steps_trained: 1221000
    wait_time_ms: 77.255
  iterations_since_restore: 407
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3706.0411100387573
  time_this_iter_s: 7.9680280685424805
  time_total_s: 3706.0411100387573
  timestamp: 1594098485
  timesteps_since_restore: 1221000
  timesteps_this_iter: 3000
  timesteps_total: 1221000
  training_iteration: 407
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3706 s, 407 iter, 1221000 ts, 1.06e+03 rew

agent-1: 194.0
agent-2: 339.0
agent-3: 419.0
Sum Reward: 952.0
Avg Reward: 317.3333333333333
Min Reward: 194.0
Max Reward: 419.0
Gini Coefficient: 0.15756302521008403
20:20 Ratio: 2.1597938144329896
Max-min Ratio: 2.1597938144329896
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-08-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1053.6
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 407
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.737
    dispatch_time_ms: 8.504
    learner:
      cur_lr: 0.0012786814477294683
      grad_gnorm: 40.0
      policy_entropy: 9.677115440368652
      policy_loss: -6.147634029388428
      var_gnorm: 43.536964416503906
      vf_explained_var: 0.7548707127571106
      vf_loss: 35.751564025878906
    num_steps_sampled: 1224000
    num_steps_trained: 1224000
    wait_time_ms: 74.052
  iterations_since_restore: 408
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3714.127674818039
  time_this_iter_s: 8.086564779281616
  time_total_s: 3714.127674818039
  timestamp: 1594098494
  timesteps_since_restore: 1224000
  timesteps_this_iter: 3000
  timesteps_total: 1224000
  training_iteration: 408
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3714 s, 408 iter, 1224000 ts, 1.05e+03 rew

agent-1: 255.0
agent-2: 450.0
agent-3: 307.0
Sum Reward: 1012.0
Avg Reward: 337.3333333333333
Min Reward: 255.0
Max Reward: 450.0
Gini Coefficient: 0.12845849802371542
20:20 Ratio: 1.7647058823529411
Max-min Ratio: 1.7647058823529411
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-08-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1053.28
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 408
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.457
    dispatch_time_ms: 6.808
    learner:
      cur_lr: 0.0012784815626218915
      grad_gnorm: 40.0
      policy_entropy: 11.497787475585938
      policy_loss: -2.983452558517456
      var_gnorm: 43.57966232299805
      vf_explained_var: 0.7302792072296143
      vf_loss: 31.803871154785156
    num_steps_sampled: 1227000
    num_steps_trained: 1227000
    wait_time_ms: 79.61
  iterations_since_restore: 409
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3723.015681743622
  time_this_iter_s: 8.888006925582886
  time_total_s: 3723.015681743622
  timestamp: 1594098502
  timesteps_since_restore: 1227000
  timesteps_this_iter: 3000
  timesteps_total: 1227000
  training_iteration: 409
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3723 s, 409 iter, 1227000 ts, 1.05e+03 rew

agent-1: 340.0
agent-2: 367.0
agent-3: 314.0
Sum Reward: 1021.0
Avg Reward: 340.3333333333333
Min Reward: 314.0
Max Reward: 367.0
Gini Coefficient: 0.034606594841658504
20:20 Ratio: 1.1687898089171975
Max-min Ratio: 1.1687898089171975
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-08-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1053.37
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 409
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.636
    dispatch_time_ms: 9.272
    learner:
      cur_lr: 0.0012782817939296365
      grad_gnorm: 40.0
      policy_entropy: 14.595446586608887
      policy_loss: 15.430612564086914
      var_gnorm: 43.645626068115234
      vf_explained_var: -1.0
      vf_loss: 32.432979583740234
    num_steps_sampled: 1230000
    num_steps_trained: 1230000
    wait_time_ms: 81.691
  iterations_since_restore: 410
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3731.7638976573944
  time_this_iter_s: 8.748215913772583
  time_total_s: 3731.7638976573944
  timestamp: 1594098511
  timesteps_since_restore: 1230000
  timesteps_this_iter: 3000
  timesteps_total: 1230000
  training_iteration: 410
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3731 s, 410 iter, 1230000 ts, 1.05e+03 rew

agent-1: 445.0
agent-2: 403.0
agent-3: 436.0
Sum Reward: 1284.0
Avg Reward: 428.0
Min Reward: 403.0
Max Reward: 445.0
Gini Coefficient: 0.021806853582554516
20:20 Ratio: 1.1042183622828785
Max-min Ratio: 1.1042183622828785
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-08-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1054.96
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 410
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.399
    dispatch_time_ms: 6.762
    learner:
      cur_lr: 0.0012780820252373815
      grad_gnorm: 40.0
      policy_entropy: 18.129064559936523
      policy_loss: 6.291592597961426
      var_gnorm: 43.72001647949219
      vf_explained_var: -0.38855648040771484
      vf_loss: 18.55756950378418
    num_steps_sampled: 1233000
    num_steps_trained: 1233000
    wait_time_ms: 73.709
  iterations_since_restore: 411
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3740.7537970542908
  time_this_iter_s: 8.989899396896362
  time_total_s: 3740.7537970542908
  timestamp: 1594098520
  timesteps_since_restore: 1233000
  timesteps_this_iter: 3000
  timesteps_total: 1233000
  training_iteration: 411
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3740 s, 411 iter, 1233000 ts, 1.05e+03 rew

agent-1: 388.0
agent-2: 445.0
agent-3: 429.0
Sum Reward: 1262.0
Avg Reward: 420.6666666666667
Min Reward: 388.0
Max Reward: 445.0
Gini Coefficient: 0.030110935023771792
20:20 Ratio: 1.1469072164948453
Max-min Ratio: 1.1469072164948453
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-08-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1055.14
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 411
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.616
    dispatch_time_ms: 9.043
    learner:
      cur_lr: 0.0012778822565451264
      grad_gnorm: 40.0
      policy_entropy: 15.809576034545898
      policy_loss: -2.2519850730895996
      var_gnorm: 43.75657272338867
      vf_explained_var: 0.44002193212509155
      vf_loss: 23.902572631835938
    num_steps_sampled: 1236000
    num_steps_trained: 1236000
    wait_time_ms: 76.08
  iterations_since_restore: 412
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3749.0966250896454
  time_this_iter_s: 8.342828035354614
  time_total_s: 3749.0966250896454
  timestamp: 1594098529
  timesteps_since_restore: 1236000
  timesteps_this_iter: 3000
  timesteps_total: 1236000
  training_iteration: 412
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3749 s, 412 iter, 1236000 ts, 1.06e+03 rew

agent-1: 386.0
agent-2: 435.0
agent-3: 432.0
Sum Reward: 1253.0
Avg Reward: 417.6666666666667
Min Reward: 386.0
Max Reward: 435.0
Gini Coefficient: 0.0260707635009311
20:20 Ratio: 1.1269430051813472
Max-min Ratio: 1.1269430051813472
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-08-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1056.02
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 412
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.305
    dispatch_time_ms: 7.173
    learner:
      cur_lr: 0.0012776823714375496
      grad_gnorm: 36.69020462036133
      policy_entropy: 17.54741859436035
      policy_loss: -1.2703688144683838
      var_gnorm: 43.807376861572266
      vf_explained_var: -0.304445743560791
      vf_loss: 20.28667449951172
    num_steps_sampled: 1239000
    num_steps_trained: 1239000
    wait_time_ms: 72.034
  iterations_since_restore: 413
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3757.8252096176147
  time_this_iter_s: 8.72858452796936
  time_total_s: 3757.8252096176147
  timestamp: 1594098537
  timesteps_since_restore: 1239000
  timesteps_this_iter: 3000
  timesteps_total: 1239000
  training_iteration: 413
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3757 s, 413 iter, 1239000 ts, 1.06e+03 rew

agent-1: 424.0
agent-2: 418.0
agent-3: 389.0
Sum Reward: 1231.0
Avg Reward: 410.3333333333333
Min Reward: 389.0
Max Reward: 424.0
Gini Coefficient: 0.018954779312212292
20:20 Ratio: 1.0899742930591259
Max-min Ratio: 1.0899742930591259
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-09-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1059.55
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 413
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.523
    dispatch_time_ms: 5.585
    learner:
      cur_lr: 0.0012774826027452946
      grad_gnorm: 39.999996185302734
      policy_entropy: 20.697959899902344
      policy_loss: 0.19829273223876953
      var_gnorm: 43.8509521484375
      vf_explained_var: 0.07447797060012817
      vf_loss: 27.207008361816406
    num_steps_sampled: 1242000
    num_steps_trained: 1242000
    wait_time_ms: 72.476
  iterations_since_restore: 414
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3766.1220276355743
  time_this_iter_s: 8.296818017959595
  time_total_s: 3766.1220276355743
  timestamp: 1594098546
  timesteps_since_restore: 1242000
  timesteps_this_iter: 3000
  timesteps_total: 1242000
  training_iteration: 414
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3766 s, 414 iter, 1242000 ts, 1.06e+03 rew

agent-1: 362.0
agent-2: 408.0
agent-3: 409.0
Sum Reward: 1179.0
Avg Reward: 393.0
Min Reward: 362.0
Max Reward: 409.0
Gini Coefficient: 0.026576194515125814
20:20 Ratio: 1.1298342541436464
Max-min Ratio: 1.1298342541436464
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-09-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1061.85
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 414
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.422
    dispatch_time_ms: 5.412
    learner:
      cur_lr: 0.0012772828340530396
      grad_gnorm: 39.999996185302734
      policy_entropy: 15.138738632202148
      policy_loss: -14.316547393798828
      var_gnorm: 43.81986618041992
      vf_explained_var: -0.326511025428772
      vf_loss: 19.090606689453125
    num_steps_sampled: 1245000
    num_steps_trained: 1245000
    wait_time_ms: 71.355
  iterations_since_restore: 415
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3774.879492998123
  time_this_iter_s: 8.757465362548828
  time_total_s: 3774.879492998123
  timestamp: 1594098555
  timesteps_since_restore: 1245000
  timesteps_this_iter: 3000
  timesteps_total: 1245000
  training_iteration: 415
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3774 s, 415 iter, 1245000 ts, 1.06e+03 rew

agent-1: 394.0
agent-2: 402.0
agent-3: 387.0
Sum Reward: 1183.0
Avg Reward: 394.3333333333333
Min Reward: 387.0
Max Reward: 402.0
Gini Coefficient: 0.0084530853761623
20:20 Ratio: 1.0387596899224807
Max-min Ratio: 1.0387596899224807
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-09-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1063.01
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 415
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.914
    dispatch_time_ms: 13.331
    learner:
      cur_lr: 0.0012770829489454627
      grad_gnorm: 23.85869789123535
      policy_entropy: 15.049543380737305
      policy_loss: -1.6995258331298828
      var_gnorm: 43.8763427734375
      vf_explained_var: 0.44697368144989014
      vf_loss: 15.723075866699219
    num_steps_sampled: 1248000
    num_steps_trained: 1248000
    wait_time_ms: 76.17
  iterations_since_restore: 416
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3783.494742155075
  time_this_iter_s: 8.615249156951904
  time_total_s: 3783.494742155075
  timestamp: 1594098563
  timesteps_since_restore: 1248000
  timesteps_this_iter: 3000
  timesteps_total: 1248000
  training_iteration: 416
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3783 s, 416 iter, 1248000 ts, 1.06e+03 rew

agent-1: 440.0
agent-2: 442.0
agent-3: 417.0
Sum Reward: 1299.0
Avg Reward: 433.0
Min Reward: 417.0
Max Reward: 442.0
Gini Coefficient: 0.012830382345393894
20:20 Ratio: 1.0599520383693046
Max-min Ratio: 1.0599520383693046
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-09-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1064.99
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 416
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.666
    dispatch_time_ms: 8.493
    learner:
      cur_lr: 0.0012768831802532077
      grad_gnorm: 34.040504455566406
      policy_entropy: 14.604097366333008
      policy_loss: -20.83612632751465
      var_gnorm: 43.86332702636719
      vf_explained_var: 0.12635815143585205
      vf_loss: 55.11933898925781
    num_steps_sampled: 1251000
    num_steps_trained: 1251000
    wait_time_ms: 73.07
  iterations_since_restore: 417
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3792.224420070648
  time_this_iter_s: 8.72967791557312
  time_total_s: 3792.224420070648
  timestamp: 1594098572
  timesteps_since_restore: 1251000
  timesteps_this_iter: 3000
  timesteps_total: 1251000
  training_iteration: 417
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3792 s, 417 iter, 1251000 ts, 1.06e+03 rew

agent-1: 410.0
agent-2: 442.0
agent-3: 426.0
Sum Reward: 1278.0
Avg Reward: 426.0
Min Reward: 410.0
Max Reward: 442.0
Gini Coefficient: 0.016692749087115284
20:20 Ratio: 1.078048780487805
Max-min Ratio: 1.078048780487805
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-09-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1067.42
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 417
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.747
    dispatch_time_ms: 7.075
    learner:
      cur_lr: 0.0012766834115609527
      grad_gnorm: 6.436671733856201
      policy_entropy: 15.18596363067627
      policy_loss: 1.4264880418777466
      var_gnorm: 43.89303207397461
      vf_explained_var: -0.010426640510559082
      vf_loss: 5.958451747894287
    num_steps_sampled: 1254000
    num_steps_trained: 1254000
    wait_time_ms: 81.678
  iterations_since_restore: 418
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3800.99107503891
  time_this_iter_s: 8.766654968261719
  time_total_s: 3800.99107503891
  timestamp: 1594098581
  timesteps_since_restore: 1254000
  timesteps_this_iter: 3000
  timesteps_total: 1254000
  training_iteration: 418
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3800 s, 418 iter, 1254000 ts, 1.07e+03 rew

agent-1: 461.0
agent-2: 425.0
agent-3: 453.0
Sum Reward: 1339.0
Avg Reward: 446.3333333333333
Min Reward: 425.0
Max Reward: 461.0
Gini Coefficient: 0.017923823749066467
20:20 Ratio: 1.0847058823529412
Max-min Ratio: 1.0847058823529412
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-09-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1070.11
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 418
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.794
    dispatch_time_ms: 5.573
    learner:
      cur_lr: 0.0012764836428686976
      grad_gnorm: 40.000003814697266
      policy_entropy: 11.592179298400879
      policy_loss: -7.766239166259766
      var_gnorm: 43.976593017578125
      vf_explained_var: -0.3482024669647217
      vf_loss: 77.81614685058594
    num_steps_sampled: 1257000
    num_steps_trained: 1257000
    wait_time_ms: 76.694
  iterations_since_restore: 419
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3809.967397928238
  time_this_iter_s: 8.976322889328003
  time_total_s: 3809.967397928238
  timestamp: 1594098590
  timesteps_since_restore: 1257000
  timesteps_this_iter: 3000
  timesteps_total: 1257000
  training_iteration: 419
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3809 s, 419 iter, 1257000 ts, 1.07e+03 rew

agent-1: 431.0
agent-2: 409.0
agent-3: 451.0
Sum Reward: 1291.0
Avg Reward: 430.3333333333333
Min Reward: 409.0
Max Reward: 451.0
Gini Coefficient: 0.021688613477924088
20:20 Ratio: 1.1026894865525672
Max-min Ratio: 1.1026894865525672
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-09-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1072.65
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 419
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.338
    dispatch_time_ms: 5.749
    learner:
      cur_lr: 0.0012762837577611208
      grad_gnorm: 40.000003814697266
      policy_entropy: 10.986505508422852
      policy_loss: -28.66394805908203
      var_gnorm: 44.073368072509766
      vf_explained_var: -0.020796775817871094
      vf_loss: 23.108251571655273
    num_steps_sampled: 1260000
    num_steps_trained: 1260000
    wait_time_ms: 92.844
  iterations_since_restore: 420
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3819.0782227516174
  time_this_iter_s: 9.110824823379517
  time_total_s: 3819.0782227516174
  timestamp: 1594098599
  timesteps_since_restore: 1260000
  timesteps_this_iter: 3000
  timesteps_total: 1260000
  training_iteration: 420
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3819 s, 420 iter, 1260000 ts, 1.07e+03 rew

agent-1: 419.0
agent-2: 442.0
agent-3: 428.0
Sum Reward: 1289.0
Avg Reward: 429.6666666666667
Min Reward: 419.0
Max Reward: 442.0
Gini Coefficient: 0.011895526247737265
20:20 Ratio: 1.0548926014319808
Max-min Ratio: 1.0548926014319808
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-10-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1074.19
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 420
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.791
    dispatch_time_ms: 7.273
    learner:
      cur_lr: 0.0012760839890688658
      grad_gnorm: 40.0
      policy_entropy: 11.160821914672852
      policy_loss: 5.700389862060547
      var_gnorm: 44.0450325012207
      vf_explained_var: -0.3842965364456177
      vf_loss: 11.790923118591309
    num_steps_sampled: 1263000
    num_steps_trained: 1263000
    wait_time_ms: 84.76
  iterations_since_restore: 421
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3828.2703177928925
  time_this_iter_s: 9.192095041275024
  time_total_s: 3828.2703177928925
  timestamp: 1594098608
  timesteps_since_restore: 1263000
  timesteps_this_iter: 3000
  timesteps_total: 1263000
  training_iteration: 421
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3828 s, 421 iter, 1263000 ts, 1.07e+03 rew

agent-1: 444.0
agent-2: 393.0
agent-3: 398.0
Sum Reward: 1235.0
Avg Reward: 411.6666666666667
Min Reward: 393.0
Max Reward: 444.0
Gini Coefficient: 0.027530364372469637
20:20 Ratio: 1.1297709923664123
Max-min Ratio: 1.1297709923664123
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-10-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1075.52
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 421
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.421
    dispatch_time_ms: 5.646
    learner:
      cur_lr: 0.0012758842203766108
      grad_gnorm: 39.99999237060547
      policy_entropy: 11.898104667663574
      policy_loss: 7.638146877288818
      var_gnorm: 44.141231536865234
      vf_explained_var: 0.15587306022644043
      vf_loss: 19.57190704345703
    num_steps_sampled: 1266000
    num_steps_trained: 1266000
    wait_time_ms: 83.396
  iterations_since_restore: 422
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3837.1643493175507
  time_this_iter_s: 8.894031524658203
  time_total_s: 3837.1643493175507
  timestamp: 1594098617
  timesteps_since_restore: 1266000
  timesteps_this_iter: 3000
  timesteps_total: 1266000
  training_iteration: 422
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3837 s, 422 iter, 1266000 ts, 1.08e+03 rew

agent-1: 390.0
agent-2: 442.0
agent-3: 426.0
Sum Reward: 1258.0
Avg Reward: 419.3333333333333
Min Reward: 390.0
Max Reward: 442.0
Gini Coefficient: 0.02755696873343932
20:20 Ratio: 1.1333333333333333
Max-min Ratio: 1.1333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-10-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1077.21
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 422
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.501
    dispatch_time_ms: 5.497
    learner:
      cur_lr: 0.0012756844516843557
      grad_gnorm: 40.0
      policy_entropy: 12.550537109375
      policy_loss: -8.581167221069336
      var_gnorm: 44.20608139038086
      vf_explained_var: 0.8516033291816711
      vf_loss: 31.192333221435547
    num_steps_sampled: 1269000
    num_steps_trained: 1269000
    wait_time_ms: 88.247
  iterations_since_restore: 423
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3846.5291209220886
  time_this_iter_s: 9.364771604537964
  time_total_s: 3846.5291209220886
  timestamp: 1594098627
  timesteps_since_restore: 1269000
  timesteps_this_iter: 3000
  timesteps_total: 1269000
  training_iteration: 423
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3846 s, 423 iter, 1269000 ts, 1.08e+03 rew

agent-1: 462.0
agent-2: 371.0
agent-3: 328.0
Sum Reward: 1161.0
Avg Reward: 387.0
Min Reward: 328.0
Max Reward: 462.0
Gini Coefficient: 0.07694516221648004
20:20 Ratio: 1.4085365853658536
Max-min Ratio: 1.4085365853658536
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-10-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1079.38
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 423
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.705
    dispatch_time_ms: 6.345
    learner:
      cur_lr: 0.0012754845665767789
      grad_gnorm: 31.397186279296875
      policy_entropy: 11.124116897583008
      policy_loss: 10.947088241577148
      var_gnorm: 44.26607131958008
      vf_explained_var: 0.646752119064331
      vf_loss: 17.90068244934082
    num_steps_sampled: 1272000
    num_steps_trained: 1272000
    wait_time_ms: 81.55
  iterations_since_restore: 424
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3855.759712934494
  time_this_iter_s: 9.230592012405396
  time_total_s: 3855.759712934494
  timestamp: 1594098636
  timesteps_since_restore: 1272000
  timesteps_this_iter: 3000
  timesteps_total: 1272000
  training_iteration: 424
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3855 s, 424 iter, 1272000 ts, 1.08e+03 rew

agent-1: 357.0
agent-2: 420.0
agent-3: 402.0
Sum Reward: 1179.0
Avg Reward: 393.0
Min Reward: 357.0
Max Reward: 420.0
Gini Coefficient: 0.035623409669211195
20:20 Ratio: 1.1764705882352942
Max-min Ratio: 1.1764705882352942
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-10-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1079.34
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 424
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.984
    dispatch_time_ms: 6.175
    learner:
      cur_lr: 0.0012752847978845239
      grad_gnorm: 38.8966178894043
      policy_entropy: 10.138872146606445
      policy_loss: -8.885350227355957
      var_gnorm: 44.24509811401367
      vf_explained_var: -0.05422866344451904
      vf_loss: 22.007734298706055
    num_steps_sampled: 1275000
    num_steps_trained: 1275000
    wait_time_ms: 75.946
  iterations_since_restore: 425
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3864.823970556259
  time_this_iter_s: 9.064257621765137
  time_total_s: 3864.823970556259
  timestamp: 1594098645
  timesteps_since_restore: 1275000
  timesteps_this_iter: 3000
  timesteps_total: 1275000
  training_iteration: 425
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3864 s, 425 iter, 1275000 ts, 1.08e+03 rew

agent-1: 347.0
agent-2: 445.0
agent-3: 364.0
Sum Reward: 1156.0
Avg Reward: 385.3333333333333
Min Reward: 347.0
Max Reward: 445.0
Gini Coefficient: 0.05651672433679354
20:20 Ratio: 1.282420749279539
Max-min Ratio: 1.282420749279539
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-10-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1079.78
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 425
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.469
    dispatch_time_ms: 6.438
    learner:
      cur_lr: 0.0012750850291922688
      grad_gnorm: 40.000003814697266
      policy_entropy: 10.11762523651123
      policy_loss: 5.764625072479248
      var_gnorm: 44.244388580322266
      vf_explained_var: 0.11694514751434326
      vf_loss: 93.56292724609375
    num_steps_sampled: 1278000
    num_steps_trained: 1278000
    wait_time_ms: 83.626
  iterations_since_restore: 426
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3873.4079875946045
  time_this_iter_s: 8.584017038345337
  time_total_s: 3873.4079875946045
  timestamp: 1594098654
  timesteps_since_restore: 1278000
  timesteps_this_iter: 3000
  timesteps_total: 1278000
  training_iteration: 426
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3873 s, 426 iter, 1278000 ts, 1.08e+03 rew

agent-1: 395.0
agent-2: 377.0
agent-3: 434.0
Sum Reward: 1206.0
Avg Reward: 402.0
Min Reward: 377.0
Max Reward: 434.0
Gini Coefficient: 0.03150912106135987
20:20 Ratio: 1.1511936339522546
Max-min Ratio: 1.1511936339522546
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-11-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1080.84
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 426
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.532
    dispatch_time_ms: 6.096
    learner:
      cur_lr: 0.001274885144084692
      grad_gnorm: 39.999996185302734
      policy_entropy: 9.053244590759277
      policy_loss: -2.252122640609741
      var_gnorm: 44.270233154296875
      vf_explained_var: 0.02861398458480835
      vf_loss: 25.07858657836914
    num_steps_sampled: 1281000
    num_steps_trained: 1281000
    wait_time_ms: 70.21
  iterations_since_restore: 427
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3882.2881710529327
  time_this_iter_s: 8.880183458328247
  time_total_s: 3882.2881710529327
  timestamp: 1594098662
  timesteps_since_restore: 1281000
  timesteps_this_iter: 3000
  timesteps_total: 1281000
  training_iteration: 427
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3882 s, 427 iter, 1281000 ts, 1.08e+03 rew

agent-1: 379.0
agent-2: 374.0
agent-3: 412.0
Sum Reward: 1165.0
Avg Reward: 388.3333333333333
Min Reward: 374.0
Max Reward: 412.0
Gini Coefficient: 0.021745350500715306
20:20 Ratio: 1.1016042780748663
Max-min Ratio: 1.1016042780748663
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-11-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1081.79
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 427
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.459
    dispatch_time_ms: 7.602
    learner:
      cur_lr: 0.001274685375392437
      grad_gnorm: 34.135345458984375
      policy_entropy: 10.583187103271484
      policy_loss: 7.183557987213135
      var_gnorm: 44.26552200317383
      vf_explained_var: 0.36543363332748413
      vf_loss: 19.916582107543945
    num_steps_sampled: 1284000
    num_steps_trained: 1284000
    wait_time_ms: 84.081
  iterations_since_restore: 428
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3891.06724858284
  time_this_iter_s: 8.779077529907227
  time_total_s: 3891.06724858284
  timestamp: 1594098671
  timesteps_since_restore: 1284000
  timesteps_this_iter: 3000
  timesteps_total: 1284000
  training_iteration: 428
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3891 s, 428 iter, 1284000 ts, 1.08e+03 rew

agent-1: 412.0
agent-2: 361.0
agent-3: 403.0
Sum Reward: 1176.0
Avg Reward: 392.0
Min Reward: 361.0
Max Reward: 412.0
Gini Coefficient: 0.02891156462585034
20:20 Ratio: 1.1412742382271468
Max-min Ratio: 1.1412742382271468
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-11-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1082.29
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 428
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.921
    dispatch_time_ms: 6.314
    learner:
      cur_lr: 0.001274485606700182
      grad_gnorm: 12.868820190429688
      policy_entropy: 10.399789810180664
      policy_loss: -1.286189317703247
      var_gnorm: 44.32427215576172
      vf_explained_var: -0.5996599197387695
      vf_loss: 23.460329055786133
    num_steps_sampled: 1287000
    num_steps_trained: 1287000
    wait_time_ms: 78.792
  iterations_since_restore: 429
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3900.531494617462
  time_this_iter_s: 9.464246034622192
  time_total_s: 3900.531494617462
  timestamp: 1594098681
  timesteps_since_restore: 1287000
  timesteps_this_iter: 3000
  timesteps_total: 1287000
  training_iteration: 429
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3900 s, 429 iter, 1287000 ts, 1.08e+03 rew

agent-1: 430.0
agent-2: 405.0
agent-3: 362.0
Sum Reward: 1197.0
Avg Reward: 399.0
Min Reward: 362.0
Max Reward: 430.0
Gini Coefficient: 0.0378724589250905
20:20 Ratio: 1.1878453038674033
Max-min Ratio: 1.1878453038674033
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-11-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1083.08
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 429
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.691
    dispatch_time_ms: 7.694
    learner:
      cur_lr: 0.001274285838007927
      grad_gnorm: 6.914847373962402
      policy_entropy: 9.811208724975586
      policy_loss: -2.7712066173553467
      var_gnorm: 44.341121673583984
      vf_explained_var: 0.14815741777420044
      vf_loss: 6.2061662673950195
    num_steps_sampled: 1290000
    num_steps_trained: 1290000
    wait_time_ms: 82.766
  iterations_since_restore: 430
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3909.605540752411
  time_this_iter_s: 9.07404613494873
  time_total_s: 3909.605540752411
  timestamp: 1594098690
  timesteps_since_restore: 1290000
  timesteps_this_iter: 3000
  timesteps_total: 1290000
  training_iteration: 430
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3909 s, 430 iter, 1290000 ts, 1.08e+03 rew

agent-1: 381.0
agent-2: 436.0
agent-3: 493.0
Sum Reward: 1310.0
Avg Reward: 436.6666666666667
Min Reward: 381.0
Max Reward: 493.0
Gini Coefficient: 0.056997455470737916
20:20 Ratio: 1.2939632545931758
Max-min Ratio: 1.2939632545931758
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-11-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1085.92
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 430
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.551
    dispatch_time_ms: 7.624
    learner:
      cur_lr: 0.00127408595290035
      grad_gnorm: 40.0
      policy_entropy: 9.257577896118164
      policy_loss: 6.400448322296143
      var_gnorm: 44.33356475830078
      vf_explained_var: 0.28471308946609497
      vf_loss: 21.61034393310547
    num_steps_sampled: 1293000
    num_steps_trained: 1293000
    wait_time_ms: 75.408
  iterations_since_restore: 431
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3919.1013634204865
  time_this_iter_s: 9.495822668075562
  time_total_s: 3919.1013634204865
  timestamp: 1594098699
  timesteps_since_restore: 1293000
  timesteps_this_iter: 3000
  timesteps_total: 1293000
  training_iteration: 431
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3919 s, 431 iter, 1293000 ts, 1.09e+03 rew

agent-1: 432.0
agent-2: 434.0
agent-3: 476.0
Sum Reward: 1342.0
Avg Reward: 447.3333333333333
Min Reward: 432.0
Max Reward: 476.0
Gini Coefficient: 0.02185792349726776
20:20 Ratio: 1.1018518518518519
Max-min Ratio: 1.1018518518518519
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-11-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1090.08
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 431
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.059
    dispatch_time_ms: 5.619
    learner:
      cur_lr: 0.001273886184208095
      grad_gnorm: 40.0
      policy_entropy: 9.018693923950195
      policy_loss: -2.5567784309387207
      var_gnorm: 44.36314392089844
      vf_explained_var: -0.1511976718902588
      vf_loss: 33.19537353515625
    num_steps_sampled: 1296000
    num_steps_trained: 1296000
    wait_time_ms: 90.506
  iterations_since_restore: 432
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3928.056348800659
  time_this_iter_s: 8.95498538017273
  time_total_s: 3928.056348800659
  timestamp: 1594098708
  timesteps_since_restore: 1296000
  timesteps_this_iter: 3000
  timesteps_total: 1296000
  training_iteration: 432
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3928 s, 432 iter, 1296000 ts, 1.09e+03 rew

agent-1: 417.0
agent-2: 401.0
agent-3: 461.0
Sum Reward: 1279.0
Avg Reward: 426.3333333333333
Min Reward: 401.0
Max Reward: 461.0
Gini Coefficient: 0.03127443315089914
20:20 Ratio: 1.1496259351620948
Max-min Ratio: 1.1496259351620948
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-11-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1095.56
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 432
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.672
    dispatch_time_ms: 5.935
    learner:
      cur_lr: 0.00127368641551584
      grad_gnorm: 27.158803939819336
      policy_entropy: 10.453073501586914
      policy_loss: -2.325005531311035
      var_gnorm: 44.35542678833008
      vf_explained_var: 0.3999846577644348
      vf_loss: 11.818708419799805
    num_steps_sampled: 1299000
    num_steps_trained: 1299000
    wait_time_ms: 78.939
  iterations_since_restore: 433
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3937.420961856842
  time_this_iter_s: 9.364613056182861
  time_total_s: 3937.420961856842
  timestamp: 1594098718
  timesteps_since_restore: 1299000
  timesteps_this_iter: 3000
  timesteps_total: 1299000
  training_iteration: 433
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3937 s, 433 iter, 1299000 ts, 1.1e+03 rew

agent-1: 449.0
agent-2: 411.0
agent-3: 458.0
Sum Reward: 1318.0
Avg Reward: 439.3333333333333
Min Reward: 411.0
Max Reward: 458.0
Gini Coefficient: 0.023773394031360646
20:20 Ratio: 1.1143552311435523
Max-min Ratio: 1.1143552311435523
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-12-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1101.36
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 433
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.462
    dispatch_time_ms: 6.494
    learner:
      cur_lr: 0.001273486646823585
      grad_gnorm: 16.788352966308594
      policy_entropy: 12.22732925415039
      policy_loss: -1.1835517883300781
      var_gnorm: 44.36037063598633
      vf_explained_var: 0.5390615463256836
      vf_loss: 9.619729995727539
    num_steps_sampled: 1302000
    num_steps_trained: 1302000
    wait_time_ms: 82.656
  iterations_since_restore: 434
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3946.1362121105194
  time_this_iter_s: 8.715250253677368
  time_total_s: 3946.1362121105194
  timestamp: 1594098727
  timesteps_since_restore: 1302000
  timesteps_this_iter: 3000
  timesteps_total: 1302000
  training_iteration: 434
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3946 s, 434 iter, 1302000 ts, 1.1e+03 rew

agent-1: 462.0
agent-2: 432.0
agent-3: 471.0
Sum Reward: 1365.0
Avg Reward: 455.0
Min Reward: 432.0
Max Reward: 471.0
Gini Coefficient: 0.01904761904761905
20:20 Ratio: 1.0902777777777777
Max-min Ratio: 1.0902777777777777
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-12-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1106.16
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 434
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.443
    dispatch_time_ms: 5.409
    learner:
      cur_lr: 0.0012732867617160082
      grad_gnorm: 19.047996520996094
      policy_entropy: 10.04766845703125
      policy_loss: 3.9297804832458496
      var_gnorm: 44.467227935791016
      vf_explained_var: 0.10543781518936157
      vf_loss: 20.756914138793945
    num_steps_sampled: 1305000
    num_steps_trained: 1305000
    wait_time_ms: 79.256
  iterations_since_restore: 435
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3955.571932077408
  time_this_iter_s: 9.435719966888428
  time_total_s: 3955.571932077408
  timestamp: 1594098736
  timesteps_since_restore: 1305000
  timesteps_this_iter: 3000
  timesteps_total: 1305000
  training_iteration: 435
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3955 s, 435 iter, 1305000 ts, 1.11e+03 rew

agent-1: 450.0
agent-2: 416.0
agent-3: 429.0
Sum Reward: 1295.0
Avg Reward: 431.6666666666667
Min Reward: 416.0
Max Reward: 450.0
Gini Coefficient: 0.017503217503217504
20:20 Ratio: 1.0817307692307692
Max-min Ratio: 1.0817307692307692
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-12-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1110.08
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 435
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.657
    dispatch_time_ms: 7.306
    learner:
      cur_lr: 0.0012730869930237532
      grad_gnorm: 18.353567123413086
      policy_entropy: 16.103290557861328
      policy_loss: -3.6878225803375244
      var_gnorm: 44.51387405395508
      vf_explained_var: 0.08925896883010864
      vf_loss: 6.731522560119629
    num_steps_sampled: 1308000
    num_steps_trained: 1308000
    wait_time_ms: 84.853
  iterations_since_restore: 436
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3964.5211441516876
  time_this_iter_s: 8.949212074279785
  time_total_s: 3964.5211441516876
  timestamp: 1594098745
  timesteps_since_restore: 1308000
  timesteps_this_iter: 3000
  timesteps_total: 1308000
  training_iteration: 436
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3964 s, 436 iter, 1308000 ts, 1.11e+03 rew

agent-1: 413.0
agent-2: 430.0
agent-3: 468.0
Sum Reward: 1311.0
Avg Reward: 437.0
Min Reward: 413.0
Max Reward: 468.0
Gini Coefficient: 0.02796847190439868
20:20 Ratio: 1.1331719128329298
Max-min Ratio: 1.1331719128329298
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-12-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1114.78
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 436
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.774
    dispatch_time_ms: 5.778
    learner:
      cur_lr: 0.0012728872243314981
      grad_gnorm: 40.0
      policy_entropy: 12.930656433105469
      policy_loss: 9.182758331298828
      var_gnorm: 44.50979232788086
      vf_explained_var: -0.5742974281311035
      vf_loss: 38.41847610473633
    num_steps_sampled: 1311000
    num_steps_trained: 1311000
    wait_time_ms: 73.143
  iterations_since_restore: 437
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3973.611163854599
  time_this_iter_s: 9.090019702911377
  time_total_s: 3973.611163854599
  timestamp: 1594098754
  timesteps_since_restore: 1311000
  timesteps_this_iter: 3000
  timesteps_total: 1311000
  training_iteration: 437
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3973 s, 437 iter, 1311000 ts, 1.11e+03 rew

agent-1: 431.0
agent-2: 405.0
agent-3: 445.0
Sum Reward: 1281.0
Avg Reward: 427.0
Min Reward: 405.0
Max Reward: 445.0
Gini Coefficient: 0.020817069997397866
20:20 Ratio: 1.0987654320987654
Max-min Ratio: 1.0987654320987654
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-12-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1119.0
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 437
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.773
    dispatch_time_ms: 7.675
    learner:
      cur_lr: 0.0012726874556392431
      grad_gnorm: 40.000003814697266
      policy_entropy: 16.967912673950195
      policy_loss: -14.317418098449707
      var_gnorm: 44.55439758300781
      vf_explained_var: -0.8471200466156006
      vf_loss: 21.639955520629883
    num_steps_sampled: 1314000
    num_steps_trained: 1314000
    wait_time_ms: 80.55
  iterations_since_restore: 438
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3982.5196137428284
  time_this_iter_s: 8.90844988822937
  time_total_s: 3982.5196137428284
  timestamp: 1594098763
  timesteps_since_restore: 1314000
  timesteps_this_iter: 3000
  timesteps_total: 1314000
  training_iteration: 438
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3982 s, 438 iter, 1314000 ts, 1.12e+03 rew

agent-1: 459.0
agent-2: 438.0
agent-3: 433.0
Sum Reward: 1330.0
Avg Reward: 443.3333333333333
Min Reward: 433.0
Max Reward: 459.0
Gini Coefficient: 0.013032581453634085
20:20 Ratio: 1.0600461893764435
Max-min Ratio: 1.0600461893764435
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-12-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1123.47
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 438
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.334
    dispatch_time_ms: 8.882
    learner:
      cur_lr: 0.0012724875705316663
      grad_gnorm: 40.000003814697266
      policy_entropy: 9.50974178314209
      policy_loss: 12.744355201721191
      var_gnorm: 44.635963439941406
      vf_explained_var: 0.13026833534240723
      vf_loss: 46.342891693115234
    num_steps_sampled: 1317000
    num_steps_trained: 1317000
    wait_time_ms: 75.539
  iterations_since_restore: 439
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 3991.6518094539642
  time_this_iter_s: 9.132195711135864
  time_total_s: 3991.6518094539642
  timestamp: 1594098772
  timesteps_since_restore: 1317000
  timesteps_this_iter: 3000
  timesteps_total: 1317000
  training_iteration: 439
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 3991 s, 439 iter, 1317000 ts, 1.12e+03 rew

agent-1: 483.0
agent-2: 436.0
agent-3: 443.0
Sum Reward: 1362.0
Avg Reward: 454.0
Min Reward: 436.0
Max Reward: 483.0
Gini Coefficient: 0.023005384238864415
20:20 Ratio: 1.1077981651376148
Max-min Ratio: 1.1077981651376148
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-13-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1128.27
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 439
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.493
    dispatch_time_ms: 9.23
    learner:
      cur_lr: 0.0012722878018394113
      grad_gnorm: 39.999996185302734
      policy_entropy: 11.564842224121094
      policy_loss: -7.469510078430176
      var_gnorm: 44.678009033203125
      vf_explained_var: 0.28223592042922974
      vf_loss: 28.97545623779297
    num_steps_sampled: 1320000
    num_steps_trained: 1320000
    wait_time_ms: 77.603
  iterations_since_restore: 440
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4000.396471977234
  time_this_iter_s: 8.744662523269653
  time_total_s: 4000.396471977234
  timestamp: 1594098781
  timesteps_since_restore: 1320000
  timesteps_this_iter: 3000
  timesteps_total: 1320000
  training_iteration: 440
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4000 s, 440 iter, 1320000 ts, 1.13e+03 rew

agent-1: 449.0
agent-2: 358.0
agent-3: 377.0
Sum Reward: 1184.0
Avg Reward: 394.6666666666667
Min Reward: 358.0
Max Reward: 449.0
Gini Coefficient: 0.051238738738738736
20:20 Ratio: 1.2541899441340782
Max-min Ratio: 1.2541899441340782
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-13-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1130.33
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 440
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.615
    dispatch_time_ms: 7.194
    learner:
      cur_lr: 0.0012720880331471562
      grad_gnorm: 40.0
      policy_entropy: 17.41363525390625
      policy_loss: -8.79203987121582
      var_gnorm: 44.642147064208984
      vf_explained_var: 0.17994022369384766
      vf_loss: 21.906591415405273
    num_steps_sampled: 1323000
    num_steps_trained: 1323000
    wait_time_ms: 81.369
  iterations_since_restore: 441
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4009.4234426021576
  time_this_iter_s: 9.026970624923706
  time_total_s: 4009.4234426021576
  timestamp: 1594098790
  timesteps_since_restore: 1323000
  timesteps_this_iter: 3000
  timesteps_total: 1323000
  training_iteration: 441
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4009 s, 441 iter, 1323000 ts, 1.13e+03 rew

agent-1: 396.0
agent-2: 426.0
agent-3: 411.0
Sum Reward: 1233.0
Avg Reward: 411.0
Min Reward: 396.0
Max Reward: 426.0
Gini Coefficient: 0.016220600162206
20:20 Ratio: 1.0757575757575757
Max-min Ratio: 1.0757575757575757
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-13-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1133.23
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 441
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.597
    dispatch_time_ms: 7.3
    learner:
      cur_lr: 0.0012718881480395794
      grad_gnorm: 39.999996185302734
      policy_entropy: 12.68293571472168
      policy_loss: -19.504440307617188
      var_gnorm: 44.769718170166016
      vf_explained_var: 0.4361141324043274
      vf_loss: 12.034481048583984
    num_steps_sampled: 1326000
    num_steps_trained: 1326000
    wait_time_ms: 77.127
  iterations_since_restore: 442
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4017.8617763519287
  time_this_iter_s: 8.438333749771118
  time_total_s: 4017.8617763519287
  timestamp: 1594098799
  timesteps_since_restore: 1326000
  timesteps_this_iter: 3000
  timesteps_total: 1326000
  training_iteration: 442
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4017 s, 442 iter, 1326000 ts, 1.13e+03 rew

agent-1: 409.0
agent-2: 406.0
agent-3: 411.0
Sum Reward: 1226.0
Avg Reward: 408.6666666666667
Min Reward: 406.0
Max Reward: 411.0
Gini Coefficient: 0.0027188689505165853
20:20 Ratio: 1.0123152709359606
Max-min Ratio: 1.0123152709359606
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-13-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1135.55
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 442
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.553
    dispatch_time_ms: 8.662
    learner:
      cur_lr: 0.0012716883793473244
      grad_gnorm: 40.0
      policy_entropy: 7.508053302764893
      policy_loss: -13.065195083618164
      var_gnorm: 44.781105041503906
      vf_explained_var: 0.19420069456100464
      vf_loss: 6.193181991577148
    num_steps_sampled: 1329000
    num_steps_trained: 1329000
    wait_time_ms: 84.585
  iterations_since_restore: 443
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4027.0022296905518
  time_this_iter_s: 9.140453338623047
  time_total_s: 4027.0022296905518
  timestamp: 1594098808
  timesteps_since_restore: 1329000
  timesteps_this_iter: 3000
  timesteps_total: 1329000
  training_iteration: 443
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4027 s, 443 iter, 1329000 ts, 1.14e+03 rew

agent-1: 403.0
agent-2: 409.0
agent-3: 397.0
Sum Reward: 1209.0
Avg Reward: 403.0
Min Reward: 397.0
Max Reward: 409.0
Gini Coefficient: 0.006617038875103391
20:20 Ratio: 1.0302267002518892
Max-min Ratio: 1.0302267002518892
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-13-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1137.74
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 443
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.611
    dispatch_time_ms: 5.755
    learner:
      cur_lr: 0.0012714886106550694
      grad_gnorm: 26.133081436157227
      policy_entropy: 7.384477615356445
      policy_loss: 9.868718147277832
      var_gnorm: 44.85291290283203
      vf_explained_var: 0.015231013298034668
      vf_loss: 55.19113540649414
    num_steps_sampled: 1332000
    num_steps_trained: 1332000
    wait_time_ms: 76.436
  iterations_since_restore: 444
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4035.219778060913
  time_this_iter_s: 8.217548370361328
  time_total_s: 4035.219778060913
  timestamp: 1594098816
  timesteps_since_restore: 1332000
  timesteps_this_iter: 3000
  timesteps_total: 1332000
  training_iteration: 444
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4035 s, 444 iter, 1332000 ts, 1.14e+03 rew

agent-1: 383.0
agent-2: 418.0
agent-3: 382.0
Sum Reward: 1183.0
Avg Reward: 394.3333333333333
Min Reward: 382.0
Max Reward: 418.0
Gini Coefficient: 0.02028740490278952
20:20 Ratio: 1.094240837696335
Max-min Ratio: 1.094240837696335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-13-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1139.65
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 444
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.155
    dispatch_time_ms: 8.88
    learner:
      cur_lr: 0.0012712888419628143
      grad_gnorm: 39.94134521484375
      policy_entropy: 6.139585494995117
      policy_loss: -7.399073600769043
      var_gnorm: 44.83067321777344
      vf_explained_var: -0.0865778923034668
      vf_loss: 48.60376739501953
    num_steps_sampled: 1335000
    num_steps_trained: 1335000
    wait_time_ms: 66.839
  iterations_since_restore: 445
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4043.906991004944
  time_this_iter_s: 8.687212944030762
  time_total_s: 4043.906991004944
  timestamp: 1594098825
  timesteps_since_restore: 1335000
  timesteps_this_iter: 3000
  timesteps_total: 1335000
  training_iteration: 445
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4043 s, 445 iter, 1335000 ts, 1.14e+03 rew

agent-1: 393.0
agent-2: 376.0
agent-3: 313.0
Sum Reward: 1082.0
Avg Reward: 360.6666666666667
Min Reward: 313.0
Max Reward: 393.0
Gini Coefficient: 0.04929143561306223
20:20 Ratio: 1.255591054313099
Max-min Ratio: 1.255591054313099
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-13-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1140.4
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 445
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.756
    dispatch_time_ms: 6.867
    learner:
      cur_lr: 0.0012710889568552375
      grad_gnorm: 40.00000762939453
      policy_entropy: 6.829533576965332
      policy_loss: 0.8157827854156494
      var_gnorm: 44.86204528808594
      vf_explained_var: -0.5462980270385742
      vf_loss: 46.50094985961914
    num_steps_sampled: 1338000
    num_steps_trained: 1338000
    wait_time_ms: 71.459
  iterations_since_restore: 446
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4051.901328086853
  time_this_iter_s: 7.99433708190918
  time_total_s: 4051.901328086853
  timestamp: 1594098833
  timesteps_since_restore: 1338000
  timesteps_this_iter: 3000
  timesteps_total: 1338000
  training_iteration: 446
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4051 s, 446 iter, 1338000 ts, 1.14e+03 rew

agent-1: 363.0
agent-2: 362.0
agent-3: 392.0
Sum Reward: 1117.0
Avg Reward: 372.3333333333333
Min Reward: 362.0
Max Reward: 392.0
Gini Coefficient: 0.017905102954341987
20:20 Ratio: 1.0828729281767955
Max-min Ratio: 1.0828729281767955
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-14-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1141.01
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 446
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.88
    dispatch_time_ms: 8.86
    learner:
      cur_lr: 0.0012708891881629825
      grad_gnorm: 40.000003814697266
      policy_entropy: 9.747867584228516
      policy_loss: -1.2038865089416504
      var_gnorm: 44.85987854003906
      vf_explained_var: -0.049472808837890625
      vf_loss: 13.455794334411621
    num_steps_sampled: 1341000
    num_steps_trained: 1341000
    wait_time_ms: 73.753
  iterations_since_restore: 447
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4060.323356628418
  time_this_iter_s: 8.422028541564941
  time_total_s: 4060.323356628418
  timestamp: 1594098841
  timesteps_since_restore: 1341000
  timesteps_this_iter: 3000
  timesteps_total: 1341000
  training_iteration: 447
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4060 s, 447 iter, 1341000 ts, 1.14e+03 rew

agent-1: 315.0
agent-2: 404.0
agent-3: 361.0
Sum Reward: 1080.0
Avg Reward: 360.0
Min Reward: 315.0
Max Reward: 404.0
Gini Coefficient: 0.05493827160493827
20:20 Ratio: 1.2825396825396826
Max-min Ratio: 1.2825396825396826
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-14-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1141.3
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 447
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 113.12
    dispatch_time_ms: 7.803
    learner:
      cur_lr: 0.0012706894194707274
      grad_gnorm: 28.615602493286133
      policy_entropy: 6.539797782897949
      policy_loss: -3.8392627239227295
      var_gnorm: 44.81817626953125
      vf_explained_var: 0.10538029670715332
      vf_loss: 53.2552490234375
    num_steps_sampled: 1344000
    num_steps_trained: 1344000
    wait_time_ms: 66.082
  iterations_since_restore: 448
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4069.5065817832947
  time_this_iter_s: 9.183225154876709
  time_total_s: 4069.5065817832947
  timestamp: 1594098850
  timesteps_since_restore: 1344000
  timesteps_this_iter: 3000
  timesteps_total: 1344000
  training_iteration: 448
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4069 s, 448 iter, 1344000 ts, 1.14e+03 rew

agent-1: 381.0
agent-2: 389.0
agent-3: 364.0
Sum Reward: 1134.0
Avg Reward: 378.0
Min Reward: 364.0
Max Reward: 389.0
Gini Coefficient: 0.014697236919459141
20:20 Ratio: 1.0686813186813187
Max-min Ratio: 1.0686813186813187
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-14-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1142.6
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 448
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.508
    dispatch_time_ms: 6.587
    learner:
      cur_lr: 0.0012704896507784724
      grad_gnorm: 21.165454864501953
      policy_entropy: 8.890090942382812
      policy_loss: 3.1344518661499023
      var_gnorm: 44.82818603515625
      vf_explained_var: -0.061055660247802734
      vf_loss: 30.795024871826172
    num_steps_sampled: 1347000
    num_steps_trained: 1347000
    wait_time_ms: 71.886
  iterations_since_restore: 449
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4077.7256371974945
  time_this_iter_s: 8.219055414199829
  time_total_s: 4077.7256371974945
  timestamp: 1594098859
  timesteps_since_restore: 1347000
  timesteps_this_iter: 3000
  timesteps_total: 1347000
  training_iteration: 449
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4077 s, 449 iter, 1347000 ts, 1.14e+03 rew

agent-1: 353.0
agent-2: 377.0
agent-3: 395.0
Sum Reward: 1125.0
Avg Reward: 375.0
Min Reward: 353.0
Max Reward: 395.0
Gini Coefficient: 0.024888888888888887
20:20 Ratio: 1.1189801699716715
Max-min Ratio: 1.1189801699716715
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-14-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1143.17
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 449
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.363
    dispatch_time_ms: 5.749
    learner:
      cur_lr: 0.0012702897656708956
      grad_gnorm: 14.732022285461426
      policy_entropy: 11.407329559326172
      policy_loss: 0.40043413639068604
      var_gnorm: 44.82876968383789
      vf_explained_var: 0.21167242527008057
      vf_loss: 53.213829040527344
    num_steps_sampled: 1350000
    num_steps_trained: 1350000
    wait_time_ms: 82.784
  iterations_since_restore: 450
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4085.9991188049316
  time_this_iter_s: 8.273481607437134
  time_total_s: 4085.9991188049316
  timestamp: 1594098867
  timesteps_since_restore: 1350000
  timesteps_this_iter: 3000
  timesteps_total: 1350000
  training_iteration: 450
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4085 s, 450 iter, 1350000 ts, 1.14e+03 rew

agent-1: 335.0
agent-2: 309.0
agent-3: 322.0
Sum Reward: 966.0
Avg Reward: 322.0
Min Reward: 309.0
Max Reward: 335.0
Gini Coefficient: 0.017943409247757072
20:20 Ratio: 1.0841423948220066
Max-min Ratio: 1.0841423948220066
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-14-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1142.12
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 450
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.981
    dispatch_time_ms: 6.269
    learner:
      cur_lr: 0.0012700899969786406
      grad_gnorm: 15.499048233032227
      policy_entropy: 20.738235473632812
      policy_loss: -9.332463264465332
      var_gnorm: 44.93407440185547
      vf_explained_var: 0.4877092242240906
      vf_loss: 41.58827209472656
    num_steps_sampled: 1353000
    num_steps_trained: 1353000
    wait_time_ms: 67.025
  iterations_since_restore: 451
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4094.363851547241
  time_this_iter_s: 8.36473274230957
  time_total_s: 4094.363851547241
  timestamp: 1594098875
  timesteps_since_restore: 1353000
  timesteps_this_iter: 3000
  timesteps_total: 1353000
  training_iteration: 451
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4094 s, 451 iter, 1353000 ts, 1.14e+03 rew

agent-1: 316.0
agent-2: 371.0
agent-3: 325.0
Sum Reward: 1012.0
Avg Reward: 337.3333333333333
Min Reward: 316.0
Max Reward: 371.0
Gini Coefficient: 0.036231884057971016
20:20 Ratio: 1.1740506329113924
Max-min Ratio: 1.1740506329113924
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-14-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1141.91
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 451
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.911
    dispatch_time_ms: 6.827
    learner:
      cur_lr: 0.0012698902282863855
      grad_gnorm: 40.0
      policy_entropy: 26.797115325927734
      policy_loss: -35.95146560668945
      var_gnorm: 44.9514045715332
      vf_explained_var: -0.5929319858551025
      vf_loss: 33.940185546875
    num_steps_sampled: 1356000
    num_steps_trained: 1356000
    wait_time_ms: 73.147
  iterations_since_restore: 452
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4102.412179946899
  time_this_iter_s: 8.048328399658203
  time_total_s: 4102.412179946899
  timestamp: 1594098883
  timesteps_since_restore: 1356000
  timesteps_this_iter: 3000
  timesteps_total: 1356000
  training_iteration: 452
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4102 s, 452 iter, 1356000 ts, 1.14e+03 rew

agent-1: 286.0
agent-2: 339.0
agent-3: 304.0
Sum Reward: 929.0
Avg Reward: 309.6666666666667
Min Reward: 286.0
Max Reward: 339.0
Gini Coefficient: 0.03803372802296376
20:20 Ratio: 1.1853146853146854
Max-min Ratio: 1.1853146853146854
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-14-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1139.79
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 452
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.608
    dispatch_time_ms: 8.455
    learner:
      cur_lr: 0.0012696903431788087
      grad_gnorm: 25.487815856933594
      policy_entropy: 23.931243896484375
      policy_loss: 14.004169464111328
      var_gnorm: 44.91761016845703
      vf_explained_var: 0.5435959100723267
      vf_loss: 7.431652545928955
    num_steps_sampled: 1359000
    num_steps_trained: 1359000
    wait_time_ms: 66.529
  iterations_since_restore: 453
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4110.709873199463
  time_this_iter_s: 8.297693252563477
  time_total_s: 4110.709873199463
  timestamp: 1594098892
  timesteps_since_restore: 1359000
  timesteps_this_iter: 3000
  timesteps_total: 1359000
  training_iteration: 453
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4110 s, 453 iter, 1359000 ts, 1.14e+03 rew

agent-1: 297.0
agent-2: 316.0
agent-3: 304.0
Sum Reward: 917.0
Avg Reward: 305.6666666666667
Min Reward: 297.0
Max Reward: 316.0
Gini Coefficient: 0.013813158851326791
20:20 Ratio: 1.063973063973064
Max-min Ratio: 1.063973063973064
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-15-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1136.62
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 453
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.869
    dispatch_time_ms: 7.754
    learner:
      cur_lr: 0.0012694905744865537
      grad_gnorm: 40.0
      policy_entropy: 18.565471649169922
      policy_loss: 19.497526168823242
      var_gnorm: 44.92041015625
      vf_explained_var: 0.13128012418746948
      vf_loss: 66.3504638671875
    num_steps_sampled: 1362000
    num_steps_trained: 1362000
    wait_time_ms: 73.478
  iterations_since_restore: 454
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4118.732158660889
  time_this_iter_s: 8.022285461425781
  time_total_s: 4118.732158660889
  timestamp: 1594098900
  timesteps_since_restore: 1362000
  timesteps_this_iter: 3000
  timesteps_total: 1362000
  training_iteration: 454
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4118 s, 454 iter, 1362000 ts, 1.14e+03 rew

agent-1: 325.0
agent-2: 358.0
agent-3: 328.0
Sum Reward: 1011.0
Avg Reward: 337.0
Min Reward: 325.0
Max Reward: 358.0
Gini Coefficient: 0.021760633036597428
20:20 Ratio: 1.1015384615384616
Max-min Ratio: 1.1015384615384616
agent-1: 298.0
agent-2: 353.0
agent-3: 329.0
Sum Reward: 980.0
Avg Reward: 326.6666666666667
Min Reward: 298.0
Max Reward: 353.0
Gini Coefficient: 0.03741496598639456
20:20 Ratio: 1.1845637583892616
Max-min Ratio: 1.1845637583892616
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-15-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1134.59
  episode_reward_min: 579.0
  episodes_this_iter: 2
  episodes_total: 455
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.507
    dispatch_time_ms: 5.304
    learner:
      cur_lr: 0.0012692908057942986
      grad_gnorm: 39.999996185302734
      policy_entropy: 26.443344116210938
      policy_loss: -894.39453125
      var_gnorm: 44.959564208984375
      vf_explained_var: 0.4596982002258301
      vf_loss: 14191.513671875
    num_steps_sampled: 1365000
    num_steps_trained: 1365000
    wait_time_ms: 80.342
  iterations_since_restore: 455
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4127.548373699188
  time_this_iter_s: 8.81621503829956
  time_total_s: 4127.548373699188
  timestamp: 1594098909
  timesteps_since_restore: 1365000
  timesteps_this_iter: 3000
  timesteps_total: 1365000
  training_iteration: 455
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4127 s, 455 iter, 1365000 ts, 1.13e+03 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-15-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1134.59
  episode_reward_min: 579.0
  episodes_this_iter: 0
  episodes_total: 455
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.798
    dispatch_time_ms: 5.58
    learner:
      cur_lr: 0.0012690910371020436
      grad_gnorm: 40.00000762939453
      policy_entropy: 29.321517944335938
      policy_loss: 15.190652847290039
      var_gnorm: 45.02827453613281
      vf_explained_var: 0.20955181121826172
      vf_loss: 32.033103942871094
    num_steps_sampled: 1368000
    num_steps_trained: 1368000
    wait_time_ms: 80.522
  iterations_since_restore: 456
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4135.672934055328
  time_this_iter_s: 8.124560356140137
  time_total_s: 4135.672934055328
  timestamp: 1594098917
  timesteps_since_restore: 1368000
  timesteps_this_iter: 3000
  timesteps_total: 1368000
  training_iteration: 456
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4135 s, 456 iter, 1368000 ts, 1.13e+03 rew

agent-1: 294.0
agent-2: 366.0
agent-3: 260.0
Sum Reward: 920.0
Avg Reward: 306.6666666666667
Min Reward: 260.0
Max Reward: 366.0
Gini Coefficient: 0.07681159420289856
20:20 Ratio: 1.4076923076923078
Max-min Ratio: 1.4076923076923078
agent-1: 304.0
agent-2: 344.0
agent-3: 301.0
Sum Reward: 949.0
Avg Reward: 316.3333333333333
Min Reward: 301.0
Max Reward: 344.0
Gini Coefficient: 0.03020723568668774
20:20 Ratio: 1.1428571428571428
Max-min Ratio: 1.1428571428571428
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-15-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1134.64
  episode_reward_min: 579.0
  episodes_this_iter: 2
  episodes_total: 457
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.023
    dispatch_time_ms: 8.435
    learner:
      cur_lr: 0.0012688911519944668
      grad_gnorm: 40.0
      policy_entropy: 25.04250717163086
      policy_loss: -647.3900146484375
      var_gnorm: 45.05540466308594
      vf_explained_var: -0.15539932250976562
      vf_loss: 12232.80859375
    num_steps_sampled: 1371000
    num_steps_trained: 1371000
    wait_time_ms: 71.583
  iterations_since_restore: 457
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4144.028409004211
  time_this_iter_s: 8.355474948883057
  time_total_s: 4144.028409004211
  timestamp: 1594098925
  timesteps_since_restore: 1371000
  timesteps_this_iter: 3000
  timesteps_total: 1371000
  training_iteration: 457
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4144 s, 457 iter, 1371000 ts, 1.13e+03 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-15-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1134.64
  episode_reward_min: 579.0
  episodes_this_iter: 0
  episodes_total: 457
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 5.248
    dispatch_time_ms: 8.67
    learner:
      cur_lr: 0.0012686913833022118
      grad_gnorm: 40.0
      policy_entropy: 23.221826553344727
      policy_loss: 14.445743560791016
      var_gnorm: 45.009098052978516
      vf_explained_var: 0.36236560344696045
      vf_loss: 35.12097930908203
    num_steps_sampled: 1374000
    num_steps_trained: 1374000
    wait_time_ms: 44.156
  iterations_since_restore: 458
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4152.805019617081
  time_this_iter_s: 8.776610612869263
  time_total_s: 4152.805019617081
  timestamp: 1594098934
  timesteps_since_restore: 1374000
  timesteps_this_iter: 3000
  timesteps_total: 1374000
  training_iteration: 458
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4152 s, 458 iter, 1374000 ts, 1.13e+03 rew

agent-1: 167.0
agent-2: 274.0
agent-3: 249.0
Sum Reward: 690.0
Avg Reward: 230.0
Min Reward: 167.0
Max Reward: 274.0
Gini Coefficient: 0.10338164251207729
20:20 Ratio: 1.6407185628742516
Max-min Ratio: 1.6407185628742516
agent-1: 207.0
agent-2: 245.0
agent-3: 225.0
Sum Reward: 677.0
Avg Reward: 225.66666666666666
Min Reward: 207.0
Max Reward: 245.0
Gini Coefficient: 0.03741999015263417
20:20 Ratio: 1.183574879227053
Max-min Ratio: 1.183574879227053
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-15-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1129.99
  episode_reward_min: 579.0
  episodes_this_iter: 2
  episodes_total: 459
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.957
    dispatch_time_ms: 7.98
    learner:
      cur_lr: 0.0012684916146099567
      grad_gnorm: 40.0
      policy_entropy: 27.75052833557129
      policy_loss: -772.1070556640625
      var_gnorm: 44.978736877441406
      vf_explained_var: -1.0
      vf_loss: 9987.2978515625
    num_steps_sampled: 1377000
    num_steps_trained: 1377000
    wait_time_ms: 72.317
  iterations_since_restore: 459
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4160.971160888672
  time_this_iter_s: 8.166141271591187
  time_total_s: 4160.971160888672
  timestamp: 1594098942
  timesteps_since_restore: 1377000
  timesteps_this_iter: 3000
  timesteps_total: 1377000
  training_iteration: 459
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4160 s, 459 iter, 1377000 ts, 1.13e+03 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-15-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1129.99
  episode_reward_min: 579.0
  episodes_this_iter: 0
  episodes_total: 459
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.383
    dispatch_time_ms: 8.844
    learner:
      cur_lr: 0.0012682918459177017
      grad_gnorm: 23.3521785736084
      policy_entropy: 27.414382934570312
      policy_loss: -4.119384765625
      var_gnorm: 44.94892501831055
      vf_explained_var: 0.43326228857040405
      vf_loss: 14.102534294128418
    num_steps_sampled: 1380000
    num_steps_trained: 1380000
    wait_time_ms: 61.668
  iterations_since_restore: 460
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4168.523309230804
  time_this_iter_s: 7.552148342132568
  time_total_s: 4168.523309230804
  timestamp: 1594098950
  timesteps_since_restore: 1380000
  timesteps_this_iter: 3000
  timesteps_total: 1380000
  training_iteration: 460
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4168 s, 460 iter, 1380000 ts, 1.13e+03 rew

agent-1: 301.0
agent-2: 359.0
agent-3: 273.0
Sum Reward: 933.0
Avg Reward: 311.0
Min Reward: 273.0
Max Reward: 359.0
Gini Coefficient: 0.06145051804215791
20:20 Ratio: 1.315018315018315
Max-min Ratio: 1.315018315018315
agent-1: 331.0
agent-2: 316.0
agent-3: 265.0
Sum Reward: 912.0
Avg Reward: 304.0
Min Reward: 265.0
Max Reward: 331.0
Gini Coefficient: 0.04824561403508772
20:20 Ratio: 1.2490566037735849
Max-min Ratio: 1.2490566037735849
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-15-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1130.66
  episode_reward_min: 579.0
  episodes_this_iter: 2
  episodes_total: 461
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.615
    dispatch_time_ms: 5.523
    learner:
      cur_lr: 0.0012680919608101249
      grad_gnorm: 40.0
      policy_entropy: 18.969457626342773
      policy_loss: -427.49493408203125
      var_gnorm: 44.95413589477539
      vf_explained_var: -1.0
      vf_loss: 10757.595703125
    num_steps_sampled: 1383000
    num_steps_trained: 1383000
    wait_time_ms: 85.679
  iterations_since_restore: 461
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4176.941974639893
  time_this_iter_s: 8.418665409088135
  time_total_s: 4176.941974639893
  timestamp: 1594098958
  timesteps_since_restore: 1383000
  timesteps_this_iter: 3000
  timesteps_total: 1383000
  training_iteration: 461
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4176 s, 461 iter, 1383000 ts, 1.13e+03 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-16-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1130.66
  episode_reward_min: 579.0
  episodes_this_iter: 0
  episodes_total: 461
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.955
    dispatch_time_ms: 7.14
    learner:
      cur_lr: 0.0012678921921178699
      grad_gnorm: 40.0
      policy_entropy: 9.515968322753906
      policy_loss: 6.43035888671875
      var_gnorm: 45.01592254638672
      vf_explained_var: 0.18048036098480225
      vf_loss: 25.286781311035156
    num_steps_sampled: 1386000
    num_steps_trained: 1386000
    wait_time_ms: 82.96
  iterations_since_restore: 462
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4185.549826383591
  time_this_iter_s: 8.60785174369812
  time_total_s: 4185.549826383591
  timestamp: 1594098967
  timesteps_since_restore: 1386000
  timesteps_this_iter: 3000
  timesteps_total: 1386000
  training_iteration: 462
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4185 s, 462 iter, 1386000 ts, 1.13e+03 rew

agent-1: 341.0
agent-2: 396.0
agent-3: 399.0
Sum Reward: 1136.0
Avg Reward: 378.6666666666667
Min Reward: 341.0
Max Reward: 399.0
Gini Coefficient: 0.03403755868544601
20:20 Ratio: 1.1700879765395895
Max-min Ratio: 1.1700879765395895
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-16-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1132.38
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 462
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.907
    dispatch_time_ms: 7.177
    learner:
      cur_lr: 0.0012676924234256148
      grad_gnorm: 39.999996185302734
      policy_entropy: 12.034908294677734
      policy_loss: 3.7967782020568848
      var_gnorm: 45.124168395996094
      vf_explained_var: 0.6142129898071289
      vf_loss: 46.779903411865234
    num_steps_sampled: 1389000
    num_steps_trained: 1389000
    wait_time_ms: 81.733
  iterations_since_restore: 463
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4194.946207284927
  time_this_iter_s: 9.39638090133667
  time_total_s: 4194.946207284927
  timestamp: 1594098976
  timesteps_since_restore: 1389000
  timesteps_this_iter: 3000
  timesteps_total: 1389000
  training_iteration: 463
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4194 s, 463 iter, 1389000 ts, 1.13e+03 rew

agent-1: 348.0
agent-2: 433.0
agent-3: 435.0
Sum Reward: 1216.0
Avg Reward: 405.3333333333333
Min Reward: 348.0
Max Reward: 435.0
Gini Coefficient: 0.047697368421052634
20:20 Ratio: 1.25
Max-min Ratio: 1.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-16-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1134.62
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 463
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.522
    dispatch_time_ms: 7.774
    learner:
      cur_lr: 0.0012674926547333598
      grad_gnorm: 18.493738174438477
      policy_entropy: 21.074626922607422
      policy_loss: -3.959743022918701
      var_gnorm: 45.244937896728516
      vf_explained_var: 0.16582167148590088
      vf_loss: 26.135738372802734
    num_steps_sampled: 1392000
    num_steps_trained: 1392000
    wait_time_ms: 77.32
  iterations_since_restore: 464
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4203.217222213745
  time_this_iter_s: 8.271014928817749
  time_total_s: 4203.217222213745
  timestamp: 1594098985
  timesteps_since_restore: 1392000
  timesteps_this_iter: 3000
  timesteps_total: 1392000
  training_iteration: 464
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4203 s, 464 iter, 1392000 ts, 1.13e+03 rew

agent-1: 276.0
agent-2: 407.0
agent-3: 355.0
Sum Reward: 1038.0
Avg Reward: 346.0
Min Reward: 276.0
Max Reward: 407.0
Gini Coefficient: 0.08413615928066795
20:20 Ratio: 1.4746376811594204
Max-min Ratio: 1.4746376811594204
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-16-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1138.69
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 464
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.315
    dispatch_time_ms: 5.74
    learner:
      cur_lr: 0.001267292769625783
      grad_gnorm: 40.0
      policy_entropy: 8.996127128601074
      policy_loss: 24.89339256286621
      var_gnorm: 45.24814224243164
      vf_explained_var: -0.07277703285217285
      vf_loss: 79.31393432617188
    num_steps_sampled: 1395000
    num_steps_trained: 1395000
    wait_time_ms: 74.9
  iterations_since_restore: 465
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4211.74538397789
  time_this_iter_s: 8.528161764144897
  time_total_s: 4211.74538397789
  timestamp: 1594098993
  timesteps_since_restore: 1395000
  timesteps_this_iter: 3000
  timesteps_total: 1395000
  training_iteration: 465
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4211 s, 465 iter, 1395000 ts, 1.14e+03 rew

agent-1: 396.0
agent-2: 298.0
agent-3: 281.0
Sum Reward: 975.0
Avg Reward: 325.0
Min Reward: 281.0
Max Reward: 396.0
Gini Coefficient: 0.07863247863247863
20:20 Ratio: 1.4092526690391458
Max-min Ratio: 1.4092526690391458
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-16-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1141.34
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 465
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.943
    dispatch_time_ms: 7.408
    learner:
      cur_lr: 0.001267093000933528
      grad_gnorm: 40.0
      policy_entropy: 14.33177661895752
      policy_loss: 12.880401611328125
      var_gnorm: 45.278961181640625
      vf_explained_var: -0.08935821056365967
      vf_loss: 30.010717391967773
    num_steps_sampled: 1398000
    num_steps_trained: 1398000
    wait_time_ms: 75.559
  iterations_since_restore: 466
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4220.119425773621
  time_this_iter_s: 8.37404179573059
  time_total_s: 4220.119425773621
  timestamp: 1594099002
  timesteps_since_restore: 1398000
  timesteps_this_iter: 3000
  timesteps_total: 1398000
  training_iteration: 466
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4220 s, 466 iter, 1398000 ts, 1.14e+03 rew

agent-1: 399.0
agent-2: 394.0
agent-3: 347.0
Sum Reward: 1140.0
Avg Reward: 380.0
Min Reward: 347.0
Max Reward: 399.0
Gini Coefficient: 0.0304093567251462
20:20 Ratio: 1.1498559077809798
Max-min Ratio: 1.1498559077809798
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-16-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1143.0
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 466
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.975
    dispatch_time_ms: 6.762
    learner:
      cur_lr: 0.001266893232241273
      grad_gnorm: 40.0
      policy_entropy: 17.721792221069336
      policy_loss: 14.246136665344238
      var_gnorm: 45.370704650878906
      vf_explained_var: -1.0
      vf_loss: 72.52129364013672
    num_steps_sampled: 1401000
    num_steps_trained: 1401000
    wait_time_ms: 69.764
  iterations_since_restore: 467
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4228.857838392258
  time_this_iter_s: 8.738412618637085
  time_total_s: 4228.857838392258
  timestamp: 1594099010
  timesteps_since_restore: 1401000
  timesteps_this_iter: 3000
  timesteps_total: 1401000
  training_iteration: 467
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4228 s, 467 iter, 1401000 ts, 1.14e+03 rew

agent-1: 370.0
agent-2: 396.0
agent-3: 329.0
Sum Reward: 1095.0
Avg Reward: 365.0
Min Reward: 329.0
Max Reward: 396.0
Gini Coefficient: 0.040791476407914765
20:20 Ratio: 1.203647416413374
Max-min Ratio: 1.203647416413374
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-16-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1144.19
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 467
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.517
    dispatch_time_ms: 5.815
    learner:
      cur_lr: 0.001266693347133696
      grad_gnorm: 33.1104621887207
      policy_entropy: 29.41364288330078
      policy_loss: -6.396060943603516
      var_gnorm: 45.4676513671875
      vf_explained_var: 0.5209138989448547
      vf_loss: 19.16739273071289
    num_steps_sampled: 1404000
    num_steps_trained: 1404000
    wait_time_ms: 69.148
  iterations_since_restore: 468
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4236.25771856308
  time_this_iter_s: 7.3998801708221436
  time_total_s: 4236.25771856308
  timestamp: 1594099018
  timesteps_since_restore: 1404000
  timesteps_this_iter: 3000
  timesteps_total: 1404000
  training_iteration: 468
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4236 s, 468 iter, 1404000 ts, 1.14e+03 rew

agent-1: 151.0
agent-2: 264.0
agent-3: 191.0
Sum Reward: 606.0
Avg Reward: 202.0
Min Reward: 151.0
Max Reward: 264.0
Gini Coefficient: 0.12431243124312431
20:20 Ratio: 1.7483443708609272
Max-min Ratio: 1.7483443708609272
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-17-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1138.98
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 468
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.254
    dispatch_time_ms: 8.354
    learner:
      cur_lr: 0.001266493578441441
      grad_gnorm: 40.0
      policy_entropy: 22.690853118896484
      policy_loss: -20.312103271484375
      var_gnorm: 45.36467742919922
      vf_explained_var: 0.5618767738342285
      vf_loss: 34.972251892089844
    num_steps_sampled: 1407000
    num_steps_trained: 1407000
    wait_time_ms: 67.428
  iterations_since_restore: 469
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4244.219959020615
  time_this_iter_s: 7.96224045753479
  time_total_s: 4244.219959020615
  timestamp: 1594099026
  timesteps_since_restore: 1407000
  timesteps_this_iter: 3000
  timesteps_total: 1407000
  training_iteration: 469
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4244 s, 469 iter, 1407000 ts, 1.14e+03 rew

agent-1: 224.0
agent-2: 279.0
agent-3: 195.0
Sum Reward: 698.0
Avg Reward: 232.66666666666666
Min Reward: 195.0
Max Reward: 279.0
Gini Coefficient: 0.08022922636103152
20:20 Ratio: 1.4307692307692308
Max-min Ratio: 1.4307692307692308
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-17-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1135.04
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 469
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.729
    dispatch_time_ms: 22.791
    learner:
      cur_lr: 0.001266293809749186
      grad_gnorm: 40.0
      policy_entropy: 24.762685775756836
      policy_loss: -13.431154251098633
      var_gnorm: 45.462371826171875
      vf_explained_var: 0.1851627230644226
      vf_loss: 21.019012451171875
    num_steps_sampled: 1410000
    num_steps_trained: 1410000
    wait_time_ms: 63.139
  iterations_since_restore: 470
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4252.561880350113
  time_this_iter_s: 8.341921329498291
  time_total_s: 4252.561880350113
  timestamp: 1594099034
  timesteps_since_restore: 1410000
  timesteps_this_iter: 3000
  timesteps_total: 1410000
  training_iteration: 470
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4252 s, 470 iter, 1410000 ts, 1.14e+03 rew

agent-1: 237.0
agent-2: 252.0
agent-3: 216.0
Sum Reward: 705.0
Avg Reward: 235.0
Min Reward: 216.0
Max Reward: 252.0
Gini Coefficient: 0.03404255319148936
20:20 Ratio: 1.1666666666666667
Max-min Ratio: 1.1666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-17-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1131.06
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 470
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.506
    dispatch_time_ms: 7.611
    learner:
      cur_lr: 0.001266094041056931
      grad_gnorm: 40.000003814697266
      policy_entropy: 23.223947525024414
      policy_loss: -19.98760223388672
      var_gnorm: 45.412841796875
      vf_explained_var: 0.5330063104629517
      vf_loss: 28.619327545166016
    num_steps_sampled: 1413000
    num_steps_trained: 1413000
    wait_time_ms: 71.185
  iterations_since_restore: 471
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4260.491899013519
  time_this_iter_s: 7.930018663406372
  time_total_s: 4260.491899013519
  timestamp: 1594099042
  timesteps_since_restore: 1413000
  timesteps_this_iter: 3000
  timesteps_total: 1413000
  training_iteration: 471
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4260 s, 471 iter, 1413000 ts, 1.13e+03 rew

agent-1: 231.0
agent-2: 309.0
agent-3: 207.0
Sum Reward: 747.0
Avg Reward: 249.0
Min Reward: 207.0
Max Reward: 309.0
Gini Coefficient: 0.09103078982597054
20:20 Ratio: 1.4927536231884058
Max-min Ratio: 1.4927536231884058
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-17-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1127.74
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 471
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.226
    dispatch_time_ms: 8.488
    learner:
      cur_lr: 0.0012658941559493542
      grad_gnorm: 29.553329467773438
      policy_entropy: 20.486562728881836
      policy_loss: -0.4536893367767334
      var_gnorm: 45.389408111572266
      vf_explained_var: -0.4289501905441284
      vf_loss: 26.151630401611328
    num_steps_sampled: 1416000
    num_steps_trained: 1416000
    wait_time_ms: 73.387
  iterations_since_restore: 472
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4268.510146856308
  time_this_iter_s: 8.018247842788696
  time_total_s: 4268.510146856308
  timestamp: 1594099050
  timesteps_since_restore: 1416000
  timesteps_this_iter: 3000
  timesteps_total: 1416000
  training_iteration: 472
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4268 s, 472 iter, 1416000 ts, 1.13e+03 rew

agent-1: 249.0
agent-2: 333.0
agent-3: 329.0
Sum Reward: 911.0
Avg Reward: 303.6666666666667
Min Reward: 249.0
Max Reward: 333.0
Gini Coefficient: 0.06147091108671789
20:20 Ratio: 1.3373493975903614
Max-min Ratio: 1.3373493975903614
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-17-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1125.16
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 472
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.776
    dispatch_time_ms: 11.208
    learner:
      cur_lr: 0.0012656943872570992
      grad_gnorm: 40.000003814697266
      policy_entropy: 25.247066497802734
      policy_loss: 32.175880432128906
      var_gnorm: 45.40843963623047
      vf_explained_var: 0.21368741989135742
      vf_loss: 36.333412170410156
    num_steps_sampled: 1419000
    num_steps_trained: 1419000
    wait_time_ms: 71.637
  iterations_since_restore: 473
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4276.962865352631
  time_this_iter_s: 8.452718496322632
  time_total_s: 4276.962865352631
  timestamp: 1594099059
  timesteps_since_restore: 1419000
  timesteps_this_iter: 3000
  timesteps_total: 1419000
  training_iteration: 473
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4276 s, 473 iter, 1419000 ts, 1.13e+03 rew

agent-1: 285.0
agent-2: 331.0
agent-3: 337.0
Sum Reward: 953.0
Avg Reward: 317.6666666666667
Min Reward: 285.0
Max Reward: 337.0
Gini Coefficient: 0.03637635536901014
20:20 Ratio: 1.182456140350877
Max-min Ratio: 1.182456140350877
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-17-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1121.97
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 473
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.287
    dispatch_time_ms: 6.224
    learner:
      cur_lr: 0.0012654946185648441
      grad_gnorm: 40.0
      policy_entropy: 21.707090377807617
      policy_loss: -17.47728157043457
      var_gnorm: 45.44577407836914
      vf_explained_var: -0.021697998046875
      vf_loss: 27.517005920410156
    num_steps_sampled: 1422000
    num_steps_trained: 1422000
    wait_time_ms: 76.495
  iterations_since_restore: 474
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4285.301319599152
  time_this_iter_s: 8.338454246520996
  time_total_s: 4285.301319599152
  timestamp: 1594099067
  timesteps_since_restore: 1422000
  timesteps_this_iter: 3000
  timesteps_total: 1422000
  training_iteration: 474
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4285 s, 474 iter, 1422000 ts, 1.12e+03 rew

agent-1: 394.0
agent-2: 423.0
agent-3: 381.0
Sum Reward: 1198.0
Avg Reward: 399.3333333333333
Min Reward: 381.0
Max Reward: 423.0
Gini Coefficient: 0.02337228714524207
20:20 Ratio: 1.110236220472441
Max-min Ratio: 1.110236220472441
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-17-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1121.58
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 474
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.498
    dispatch_time_ms: 5.677
    learner:
      cur_lr: 0.0012652948498725891
      grad_gnorm: 19.264080047607422
      policy_entropy: 7.375898838043213
      policy_loss: 1.3432304859161377
      var_gnorm: 45.42576599121094
      vf_explained_var: 0.02229773998260498
      vf_loss: 12.581501007080078
    num_steps_sampled: 1425000
    num_steps_trained: 1425000
    wait_time_ms: 83.514
  iterations_since_restore: 475
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4293.902362585068
  time_this_iter_s: 8.601042985916138
  time_total_s: 4293.902362585068
  timestamp: 1594099076
  timesteps_since_restore: 1425000
  timesteps_this_iter: 3000
  timesteps_total: 1425000
  training_iteration: 475
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4293 s, 475 iter, 1425000 ts, 1.12e+03 rew

agent-1: 371.0
agent-2: 412.0
agent-3: 393.0
Sum Reward: 1176.0
Avg Reward: 392.0
Min Reward: 371.0
Max Reward: 412.0
Gini Coefficient: 0.023242630385487528
20:20 Ratio: 1.110512129380054
Max-min Ratio: 1.110512129380054
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-18-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1120.09
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 475
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.593
    dispatch_time_ms: 7.931
    learner:
      cur_lr: 0.0012650949647650123
      grad_gnorm: 25.041879653930664
      policy_entropy: 10.530911445617676
      policy_loss: 4.035334587097168
      var_gnorm: 45.47674560546875
      vf_explained_var: 0.08873206377029419
      vf_loss: 24.434078216552734
    num_steps_sampled: 1428000
    num_steps_trained: 1428000
    wait_time_ms: 87.588
  iterations_since_restore: 476
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4302.710422754288
  time_this_iter_s: 8.80806016921997
  time_total_s: 4302.710422754288
  timestamp: 1594099085
  timesteps_since_restore: 1428000
  timesteps_this_iter: 3000
  timesteps_total: 1428000
  training_iteration: 476
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4302 s, 476 iter, 1428000 ts, 1.12e+03 rew

agent-1: 411.0
agent-2: 465.0
agent-3: 338.0
Sum Reward: 1214.0
Avg Reward: 404.6666666666667
Min Reward: 338.0
Max Reward: 465.0
Gini Coefficient: 0.06974190005491489
20:20 Ratio: 1.3757396449704142
Max-min Ratio: 1.3757396449704142
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-18-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1119.15
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 476
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.86
    dispatch_time_ms: 9.056
    learner:
      cur_lr: 0.0012648951960727572
      grad_gnorm: 29.436199188232422
      policy_entropy: 14.050708770751953
      policy_loss: 1.740803837776184
      var_gnorm: 45.53308868408203
      vf_explained_var: 0.32872945070266724
      vf_loss: 15.452102661132812
    num_steps_sampled: 1431000
    num_steps_trained: 1431000
    wait_time_ms: 75.181
  iterations_since_restore: 477
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4312.149485826492
  time_this_iter_s: 9.43906307220459
  time_total_s: 4312.149485826492
  timestamp: 1594099094
  timesteps_since_restore: 1431000
  timesteps_this_iter: 3000
  timesteps_total: 1431000
  training_iteration: 477
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4312 s, 477 iter, 1431000 ts, 1.12e+03 rew

agent-1: 468.0
agent-2: 440.0
agent-3: 458.0
Sum Reward: 1366.0
Avg Reward: 455.3333333333333
Min Reward: 440.0
Max Reward: 468.0
Gini Coefficient: 0.013665202537823329
20:20 Ratio: 1.0636363636363637
Max-min Ratio: 1.0636363636363637
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-18-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1118.85
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 477
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.767
    dispatch_time_ms: 5.827
    learner:
      cur_lr: 0.0012646954273805022
      grad_gnorm: 4.139105319976807
      policy_entropy: 18.054187774658203
      policy_loss: -1.398838758468628
      var_gnorm: 45.56007385253906
      vf_explained_var: -0.07876169681549072
      vf_loss: 8.159151077270508
    num_steps_sampled: 1434000
    num_steps_trained: 1434000
    wait_time_ms: 77.578
  iterations_since_restore: 478
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4320.29837012291
  time_this_iter_s: 8.148884296417236
  time_total_s: 4320.29837012291
  timestamp: 1594099102
  timesteps_since_restore: 1434000
  timesteps_this_iter: 3000
  timesteps_total: 1434000
  training_iteration: 478
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4320 s, 478 iter, 1434000 ts, 1.12e+03 rew

agent-1: 362.0
agent-2: 377.0
agent-3: 414.0
Sum Reward: 1153.0
Avg Reward: 384.3333333333333
Min Reward: 362.0
Max Reward: 414.0
Gini Coefficient: 0.03006649320612894
20:20 Ratio: 1.143646408839779
Max-min Ratio: 1.143646408839779
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-18-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1119.19
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 478
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.693
    dispatch_time_ms: 6.471
    learner:
      cur_lr: 0.0012644955422729254
      grad_gnorm: 40.0
      policy_entropy: 18.849956512451172
      policy_loss: -3.1002612113952637
      var_gnorm: 45.58744430541992
      vf_explained_var: 0.21971464157104492
      vf_loss: 29.4937744140625
    num_steps_sampled: 1437000
    num_steps_trained: 1437000
    wait_time_ms: 75.67
  iterations_since_restore: 479
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4328.925164461136
  time_this_iter_s: 8.626794338226318
  time_total_s: 4328.925164461136
  timestamp: 1594099111
  timesteps_since_restore: 1437000
  timesteps_this_iter: 3000
  timesteps_total: 1437000
  training_iteration: 479
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4328 s, 479 iter, 1437000 ts, 1.12e+03 rew

agent-1: 389.0
agent-2: 370.0
agent-3: 408.0
Sum Reward: 1167.0
Avg Reward: 389.0
Min Reward: 370.0
Max Reward: 408.0
Gini Coefficient: 0.021708083404741504
20:20 Ratio: 1.1027027027027028
Max-min Ratio: 1.1027027027027028
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-18-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1120.73
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 479
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.555
    dispatch_time_ms: 6.136
    learner:
      cur_lr: 0.0012642957735806704
      grad_gnorm: 28.464008331298828
      policy_entropy: 17.493789672851562
      policy_loss: 5.89735746383667
      var_gnorm: 45.572914123535156
      vf_explained_var: 0.14555150270462036
      vf_loss: 8.205432891845703
    num_steps_sampled: 1440000
    num_steps_trained: 1440000
    wait_time_ms: 81.941
  iterations_since_restore: 480
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4337.233232498169
  time_this_iter_s: 8.308068037033081
  time_total_s: 4337.233232498169
  timestamp: 1594099119
  timesteps_since_restore: 1440000
  timesteps_this_iter: 3000
  timesteps_total: 1440000
  training_iteration: 480
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4337 s, 480 iter, 1440000 ts, 1.12e+03 rew

agent-1: 368.0
agent-2: 345.0
agent-3: 393.0
Sum Reward: 1106.0
Avg Reward: 368.6666666666667
Min Reward: 345.0
Max Reward: 393.0
Gini Coefficient: 0.028933092224231464
20:20 Ratio: 1.1391304347826088
Max-min Ratio: 1.1391304347826088
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-18-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1120.69
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 480
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.455
    dispatch_time_ms: 5.55
    learner:
      cur_lr: 0.0012640960048884153
      grad_gnorm: 40.0
      policy_entropy: 12.274229049682617
      policy_loss: -6.846579074859619
      var_gnorm: 45.55160903930664
      vf_explained_var: 0.014206886291503906
      vf_loss: 19.309608459472656
    num_steps_sampled: 1443000
    num_steps_trained: 1443000
    wait_time_ms: 83.242
  iterations_since_restore: 481
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4346.002977132797
  time_this_iter_s: 8.769744634628296
  time_total_s: 4346.002977132797
  timestamp: 1594099128
  timesteps_since_restore: 1443000
  timesteps_this_iter: 3000
  timesteps_total: 1443000
  training_iteration: 481
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4346 s, 481 iter, 1443000 ts, 1.12e+03 rew

agent-1: 402.0
agent-2: 332.0
agent-3: 383.0
Sum Reward: 1117.0
Avg Reward: 372.3333333333333
Min Reward: 332.0
Max Reward: 402.0
Gini Coefficient: 0.0417785735601313
20:20 Ratio: 1.2108433734939759
Max-min Ratio: 1.2108433734939759
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-18-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1120.79
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 481
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.75
    dispatch_time_ms: 10.104
    learner:
      cur_lr: 0.0012638962361961603
      grad_gnorm: 40.0
      policy_entropy: 20.47685432434082
      policy_loss: -7.727197647094727
      var_gnorm: 45.526126861572266
      vf_explained_var: -0.200522780418396
      vf_loss: 16.074548721313477
    num_steps_sampled: 1446000
    num_steps_trained: 1446000
    wait_time_ms: 70.889
  iterations_since_restore: 482
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4354.109399318695
  time_this_iter_s: 8.106422185897827
  time_total_s: 4354.109399318695
  timestamp: 1594099136
  timesteps_since_restore: 1446000
  timesteps_this_iter: 3000
  timesteps_total: 1446000
  training_iteration: 482
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4354 s, 482 iter, 1446000 ts, 1.12e+03 rew

agent-1: 347.0
agent-2: 342.0
agent-3: 364.0
Sum Reward: 1053.0
Avg Reward: 351.0
Min Reward: 342.0
Max Reward: 364.0
Gini Coefficient: 0.013928458372902817
20:20 Ratio: 1.064327485380117
Max-min Ratio: 1.064327485380117
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-19-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1118.81
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 482
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.449
    dispatch_time_ms: 5.686
    learner:
      cur_lr: 0.0012636963510885835
      grad_gnorm: 39.999996185302734
      policy_entropy: 15.59959888458252
      policy_loss: -9.636343002319336
      var_gnorm: 45.541465759277344
      vf_explained_var: 0.06265681982040405
      vf_loss: 21.805524826049805
    num_steps_sampled: 1449000
    num_steps_trained: 1449000
    wait_time_ms: 75.562
  iterations_since_restore: 483
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4362.625396728516
  time_this_iter_s: 8.515997409820557
  time_total_s: 4362.625396728516
  timestamp: 1594099145
  timesteps_since_restore: 1449000
  timesteps_this_iter: 3000
  timesteps_total: 1449000
  training_iteration: 483
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4362 s, 483 iter, 1449000 ts, 1.12e+03 rew

agent-1: 357.0
agent-2: 354.0
agent-3: 323.0
Sum Reward: 1034.0
Avg Reward: 344.6666666666667
Min Reward: 323.0
Max Reward: 357.0
Gini Coefficient: 0.02192134107027724
20:20 Ratio: 1.105263157894737
Max-min Ratio: 1.105263157894737
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-19-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1117.52
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 483
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.938
    dispatch_time_ms: 9.487
    learner:
      cur_lr: 0.0012634965823963284
      grad_gnorm: 39.999996185302734
      policy_entropy: 10.564056396484375
      policy_loss: 4.214466094970703
      var_gnorm: 45.57640838623047
      vf_explained_var: -0.7559453248977661
      vf_loss: 14.16120433807373
    num_steps_sampled: 1452000
    num_steps_trained: 1452000
    wait_time_ms: 72.179
  iterations_since_restore: 484
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4370.593004465103
  time_this_iter_s: 7.967607736587524
  time_total_s: 4370.593004465103
  timestamp: 1594099153
  timesteps_since_restore: 1452000
  timesteps_this_iter: 3000
  timesteps_total: 1452000
  training_iteration: 484
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4370 s, 484 iter, 1452000 ts, 1.12e+03 rew

agent-1: 338.0
agent-2: 340.0
agent-3: 327.0
Sum Reward: 1005.0
Avg Reward: 335.0
Min Reward: 327.0
Max Reward: 340.0
Gini Coefficient: 0.008623548922056384
20:20 Ratio: 1.039755351681957
Max-min Ratio: 1.039755351681957
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-19-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1116.28
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 484
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.327
    dispatch_time_ms: 5.953
    learner:
      cur_lr: 0.0012632968137040734
      grad_gnorm: 40.000003814697266
      policy_entropy: 9.270673751831055
      policy_loss: 7.499781131744385
      var_gnorm: 45.547550201416016
      vf_explained_var: 0.18151992559432983
      vf_loss: 23.824493408203125
    num_steps_sampled: 1455000
    num_steps_trained: 1455000
    wait_time_ms: 69.799
  iterations_since_restore: 485
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4378.748591423035
  time_this_iter_s: 8.155586957931519
  time_total_s: 4378.748591423035
  timestamp: 1594099161
  timesteps_since_restore: 1455000
  timesteps_this_iter: 3000
  timesteps_total: 1455000
  training_iteration: 485
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4378 s, 485 iter, 1455000 ts, 1.12e+03 rew

agent-1: 303.0
agent-2: 313.0
agent-3: 310.0
Sum Reward: 926.0
Avg Reward: 308.6666666666667
Min Reward: 303.0
Max Reward: 313.0
Gini Coefficient: 0.007199424046076314
20:20 Ratio: 1.033003300330033
Max-min Ratio: 1.033003300330033
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-19-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1114.07
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 485
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.608
    dispatch_time_ms: 21.036
    learner:
      cur_lr: 0.0012630970450118184
      grad_gnorm: 40.0
      policy_entropy: 17.74159812927246
      policy_loss: -23.65006446838379
      var_gnorm: 45.560306549072266
      vf_explained_var: -0.012214899063110352
      vf_loss: 38.018306732177734
    num_steps_sampled: 1458000
    num_steps_trained: 1458000
    wait_time_ms: 16.828
  iterations_since_restore: 486
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4395.509662866592
  time_this_iter_s: 16.76107144355774
  time_total_s: 4395.509662866592
  timestamp: 1594099178
  timesteps_since_restore: 1458000
  timesteps_this_iter: 3000
  timesteps_total: 1458000
  training_iteration: 486
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4395 s, 486 iter, 1458000 ts, 1.11e+03 rew

agent-1: 317.0
agent-2: 329.0
agent-3: 313.0
Sum Reward: 959.0
Avg Reward: 319.6666666666667
Min Reward: 313.0
Max Reward: 329.0
Gini Coefficient: 0.011122697254084116
20:20 Ratio: 1.0511182108626198
Max-min Ratio: 1.0511182108626198
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-19-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1110.91
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 486
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.872
    dispatch_time_ms: 6.447
    learner:
      cur_lr: 0.0012628971599042416
      grad_gnorm: 33.594173431396484
      policy_entropy: 22.809968948364258
      policy_loss: 7.255298614501953
      var_gnorm: 45.531005859375
      vf_explained_var: 0.019487380981445312
      vf_loss: 11.040218353271484
    num_steps_sampled: 1461000
    num_steps_trained: 1461000
    wait_time_ms: 70.371
  iterations_since_restore: 487
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4403.730083703995
  time_this_iter_s: 8.220420837402344
  time_total_s: 4403.730083703995
  timestamp: 1594099186
  timesteps_since_restore: 1461000
  timesteps_this_iter: 3000
  timesteps_total: 1461000
  training_iteration: 487
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4403 s, 487 iter, 1461000 ts, 1.11e+03 rew

agent-1: 313.0
agent-2: 315.0
agent-3: 358.0
Sum Reward: 986.0
Avg Reward: 328.6666666666667
Min Reward: 313.0
Max Reward: 358.0
Gini Coefficient: 0.030425963488843813
20:20 Ratio: 1.1437699680511182
Max-min Ratio: 1.1437699680511182
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-19-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1108.38
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 487
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.968
    dispatch_time_ms: 8.529
    learner:
      cur_lr: 0.0012626973912119865
      grad_gnorm: 40.0
      policy_entropy: 21.82313346862793
      policy_loss: 12.457891464233398
      var_gnorm: 45.62582015991211
      vf_explained_var: 0.39883267879486084
      vf_loss: 58.57649230957031
    num_steps_sampled: 1464000
    num_steps_trained: 1464000
    wait_time_ms: 66.396
  iterations_since_restore: 488
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4411.663036823273
  time_this_iter_s: 7.932953119277954
  time_total_s: 4411.663036823273
  timestamp: 1594099194
  timesteps_since_restore: 1464000
  timesteps_this_iter: 3000
  timesteps_total: 1464000
  training_iteration: 488
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4411 s, 488 iter, 1464000 ts, 1.11e+03 rew

agent-1: 269.0
agent-2: 276.0
agent-3: 285.0
Sum Reward: 830.0
Avg Reward: 276.6666666666667
Min Reward: 269.0
Max Reward: 285.0
Gini Coefficient: 0.01285140562248996
20:20 Ratio: 1.0594795539033457
Max-min Ratio: 1.0594795539033457
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-20-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1104.37
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 488
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.371
    dispatch_time_ms: 5.35
    learner:
      cur_lr: 0.0012624976225197315
      grad_gnorm: 40.0
      policy_entropy: 19.979450225830078
      policy_loss: -5.892548561096191
      var_gnorm: 45.61137008666992
      vf_explained_var: 0.212909996509552
      vf_loss: 20.378570556640625
    num_steps_sampled: 1467000
    num_steps_trained: 1467000
    wait_time_ms: 73.563
  iterations_since_restore: 489
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4419.7304446697235
  time_this_iter_s: 8.067407846450806
  time_total_s: 4419.7304446697235
  timestamp: 1594099202
  timesteps_since_restore: 1467000
  timesteps_this_iter: 3000
  timesteps_total: 1467000
  training_iteration: 489
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4419 s, 489 iter, 1467000 ts, 1.1e+03 rew

agent-1: 278.0
agent-2: 304.0
agent-3: 254.0
Sum Reward: 836.0
Avg Reward: 278.6666666666667
Min Reward: 254.0
Max Reward: 304.0
Gini Coefficient: 0.03987240829346093
20:20 Ratio: 1.1968503937007875
Max-min Ratio: 1.1968503937007875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-20-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1099.38
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 489
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.386
    dispatch_time_ms: 7.463
    learner:
      cur_lr: 0.0012622978538274765
      grad_gnorm: 17.9927921295166
      policy_entropy: 22.59966278076172
      policy_loss: -9.671852111816406
      var_gnorm: 45.582313537597656
      vf_explained_var: 0.3005884885787964
      vf_loss: 24.68288230895996
    num_steps_sampled: 1470000
    num_steps_trained: 1470000
    wait_time_ms: 72.113
  iterations_since_restore: 490
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4427.650885105133
  time_this_iter_s: 7.920440435409546
  time_total_s: 4427.650885105133
  timestamp: 1594099210
  timesteps_since_restore: 1470000
  timesteps_this_iter: 3000
  timesteps_total: 1470000
  training_iteration: 490
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4427 s, 490 iter, 1470000 ts, 1.1e+03 rew

agent-1: 316.0
agent-2: 330.0
agent-3: 274.0
Sum Reward: 920.0
Avg Reward: 306.6666666666667
Min Reward: 274.0
Max Reward: 330.0
Gini Coefficient: 0.04057971014492753
20:20 Ratio: 1.2043795620437956
Max-min Ratio: 1.2043795620437956
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-20-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1097.56
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 490
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.514
    dispatch_time_ms: 6.293
    learner:
      cur_lr: 0.0012620979687198997
      grad_gnorm: 40.0
      policy_entropy: 20.418020248413086
      policy_loss: 25.118587493896484
      var_gnorm: 45.591400146484375
      vf_explained_var: 0.006563246250152588
      vf_loss: 50.55765914916992
    num_steps_sampled: 1473000
    num_steps_trained: 1473000
    wait_time_ms: 74.423
  iterations_since_restore: 491
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4436.150321960449
  time_this_iter_s: 8.499436855316162
  time_total_s: 4436.150321960449
  timestamp: 1594099219
  timesteps_since_restore: 1473000
  timesteps_this_iter: 3000
  timesteps_total: 1473000
  training_iteration: 491
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4436 s, 491 iter, 1473000 ts, 1.1e+03 rew

agent-1: 362.0
agent-2: 325.0
agent-3: 313.0
Sum Reward: 1000.0
Avg Reward: 333.3333333333333
Min Reward: 313.0
Max Reward: 362.0
Gini Coefficient: 0.03266666666666666
20:20 Ratio: 1.156549520766773
Max-min Ratio: 1.156549520766773
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-20-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1094.09
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 491
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.819
    dispatch_time_ms: 8.433
    learner:
      cur_lr: 0.0012618982000276446
      grad_gnorm: 33.31036376953125
      policy_entropy: 21.792343139648438
      policy_loss: -7.348248481750488
      var_gnorm: 45.63444900512695
      vf_explained_var: -0.03163266181945801
      vf_loss: 9.941388130187988
    num_steps_sampled: 1476000
    num_steps_trained: 1476000
    wait_time_ms: 70.561
  iterations_since_restore: 492
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4444.230336666107
  time_this_iter_s: 8.080014705657959
  time_total_s: 4444.230336666107
  timestamp: 1594099227
  timesteps_since_restore: 1476000
  timesteps_this_iter: 3000
  timesteps_total: 1476000
  training_iteration: 492
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4444 s, 492 iter, 1476000 ts, 1.09e+03 rew

agent-1: 325.0
agent-2: 352.0
agent-3: 289.0
Sum Reward: 966.0
Avg Reward: 322.0
Min Reward: 289.0
Max Reward: 352.0
Gini Coefficient: 0.043478260869565216
20:20 Ratio: 1.217993079584775
Max-min Ratio: 1.217993079584775
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-20-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1090.49
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 492
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.736
    dispatch_time_ms: 7.585
    learner:
      cur_lr: 0.0012616984313353896
      grad_gnorm: 12.884675979614258
      policy_entropy: 19.205007553100586
      policy_loss: 0.21312236785888672
      var_gnorm: 45.648414611816406
      vf_explained_var: 0.08560651540756226
      vf_loss: 4.6005401611328125
    num_steps_sampled: 1479000
    num_steps_trained: 1479000
    wait_time_ms: 72.589
  iterations_since_restore: 493
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4452.491569042206
  time_this_iter_s: 8.261232376098633
  time_total_s: 4452.491569042206
  timestamp: 1594099235
  timesteps_since_restore: 1479000
  timesteps_this_iter: 3000
  timesteps_total: 1479000
  training_iteration: 493
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4452 s, 493 iter, 1479000 ts, 1.09e+03 rew

agent-1: 336.0
agent-2: 336.0
agent-3: 338.0
Sum Reward: 1010.0
Avg Reward: 336.6666666666667
Min Reward: 336.0
Max Reward: 338.0
Gini Coefficient: 0.0013201320132013201
20:20 Ratio: 1.005952380952381
Max-min Ratio: 1.005952380952381
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-20-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1087.59
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 493
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.438
    dispatch_time_ms: 6.106
    learner:
      cur_lr: 0.0012614985462278128
      grad_gnorm: 40.0
      policy_entropy: 25.089458465576172
      policy_loss: -28.393354415893555
      var_gnorm: 45.694496154785156
      vf_explained_var: 0.05307585000991821
      vf_loss: 30.001148223876953
    num_steps_sampled: 1482000
    num_steps_trained: 1482000
    wait_time_ms: 75.971
  iterations_since_restore: 494
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4460.46964097023
  time_this_iter_s: 7.978071928024292
  time_total_s: 4460.46964097023
  timestamp: 1594099243
  timesteps_since_restore: 1482000
  timesteps_this_iter: 3000
  timesteps_total: 1482000
  training_iteration: 494
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4460 s, 494 iter, 1482000 ts, 1.09e+03 rew

agent-1: 329.0
agent-2: 362.0
agent-3: 347.0
Sum Reward: 1038.0
Avg Reward: 346.0
Min Reward: 329.0
Max Reward: 362.0
Gini Coefficient: 0.02119460500963391
20:20 Ratio: 1.1003039513677813
Max-min Ratio: 1.1003039513677813
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-20-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1431.0
  episode_reward_mean: 1085.07
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 494
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.699
    dispatch_time_ms: 35.883
    learner:
      cur_lr: 0.0012612987775355577
      grad_gnorm: 28.077716827392578
      policy_entropy: 21.021303176879883
      policy_loss: -5.78910493850708
      var_gnorm: 45.68450927734375
      vf_explained_var: -0.09687721729278564
      vf_loss: 7.8228936195373535
    num_steps_sampled: 1485000
    num_steps_trained: 1485000
    wait_time_ms: 68.316
  iterations_since_restore: 495
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4469.405706644058
  time_this_iter_s: 8.936065673828125
  time_total_s: 4469.405706644058
  timestamp: 1594099252
  timesteps_since_restore: 1485000
  timesteps_this_iter: 3000
  timesteps_total: 1485000
  training_iteration: 495
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4469 s, 495 iter, 1485000 ts, 1.09e+03 rew

agent-1: 341.0
agent-2: 361.0
agent-3: 325.0
Sum Reward: 1027.0
Avg Reward: 342.3333333333333
Min Reward: 325.0
Max Reward: 361.0
Gini Coefficient: 0.023369036027263874
20:20 Ratio: 1.1107692307692307
Max-min Ratio: 1.1107692307692307
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-21-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1366.0
  episode_reward_mean: 1081.03
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 495
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.86
    dispatch_time_ms: 34.61
    learner:
      cur_lr: 0.0012610990088433027
      grad_gnorm: 17.03879737854004
      policy_entropy: 21.296276092529297
      policy_loss: 5.067078590393066
      var_gnorm: 45.71944808959961
      vf_explained_var: 0.2153337597846985
      vf_loss: 4.4038896560668945
    num_steps_sampled: 1488000
    num_steps_trained: 1488000
    wait_time_ms: 47.152
  iterations_since_restore: 496
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4477.690301418304
  time_this_iter_s: 8.284594774246216
  time_total_s: 4477.690301418304
  timestamp: 1594099260
  timesteps_since_restore: 1488000
  timesteps_this_iter: 3000
  timesteps_total: 1488000
  training_iteration: 496
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4477 s, 496 iter, 1488000 ts, 1.08e+03 rew

agent-1: 298.0
agent-2: 364.0
agent-3: 286.0
Sum Reward: 948.0
Avg Reward: 316.0
Min Reward: 286.0
Max Reward: 364.0
Gini Coefficient: 0.05485232067510549
20:20 Ratio: 1.2727272727272727
Max-min Ratio: 1.2727272727272727
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-21-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1366.0
  episode_reward_mean: 1078.37
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 496
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.463
    dispatch_time_ms: 66.006
    learner:
      cur_lr: 0.0012608992401510477
      grad_gnorm: 40.0
      policy_entropy: 21.16316032409668
      policy_loss: -10.089630126953125
      var_gnorm: 45.71428298950195
      vf_explained_var: 0.15960949659347534
      vf_loss: 10.890807151794434
    num_steps_sampled: 1491000
    num_steps_trained: 1491000
    wait_time_ms: 26.184
  iterations_since_restore: 497
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4486.480809688568
  time_this_iter_s: 8.790508270263672
  time_total_s: 4486.480809688568
  timestamp: 1594099269
  timesteps_since_restore: 1491000
  timesteps_this_iter: 3000
  timesteps_total: 1491000
  training_iteration: 497
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4486 s, 497 iter, 1491000 ts, 1.08e+03 rew

agent-1: 259.0
agent-2: 346.0
agent-3: 331.0
Sum Reward: 936.0
Avg Reward: 312.0
Min Reward: 259.0
Max Reward: 346.0
Gini Coefficient: 0.06196581196581197
20:20 Ratio: 1.335907335907336
Max-min Ratio: 1.335907335907336
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-21-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1366.0
  episode_reward_mean: 1076.14
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 497
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 2.82
    dispatch_time_ms: 23.2
    learner:
      cur_lr: 0.0012606993550434709
      grad_gnorm: 39.999996185302734
      policy_entropy: 23.14539909362793
      policy_loss: 13.538703918457031
      var_gnorm: 45.71398162841797
      vf_explained_var: 0.3573998808860779
      vf_loss: 23.805246353149414
    num_steps_sampled: 1494000
    num_steps_trained: 1494000
    wait_time_ms: 59.391
  iterations_since_restore: 498
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4494.680819034576
  time_this_iter_s: 8.2000093460083
  time_total_s: 4494.680819034576
  timestamp: 1594099277
  timesteps_since_restore: 1494000
  timesteps_this_iter: 3000
  timesteps_total: 1494000
  training_iteration: 498
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4494 s, 498 iter, 1494000 ts, 1.08e+03 rew

agent-1: 278.0
agent-2: 312.0
agent-3: 301.0
Sum Reward: 891.0
Avg Reward: 297.0
Min Reward: 278.0
Max Reward: 312.0
Gini Coefficient: 0.02543958099513655
20:20 Ratio: 1.1223021582733812
Max-min Ratio: 1.1223021582733812
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-21-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1366.0
  episode_reward_mean: 1076.4
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 498
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.265
    dispatch_time_ms: 23.735
    learner:
      cur_lr: 0.0012604995863512158
      grad_gnorm: 40.000003814697266
      policy_entropy: 28.185945510864258
      policy_loss: -10.649415969848633
      var_gnorm: 45.74378204345703
      vf_explained_var: -0.15596413612365723
      vf_loss: 43.55653381347656
    num_steps_sampled: 1497000
    num_steps_trained: 1497000
    wait_time_ms: 51.878
  iterations_since_restore: 499
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4503.211736679077
  time_this_iter_s: 8.530917644500732
  time_total_s: 4503.211736679077
  timestamp: 1594099286
  timesteps_since_restore: 1497000
  timesteps_this_iter: 3000
  timesteps_total: 1497000
  training_iteration: 499
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=470], 4503 s, 499 iter, 1497000 ts, 1.08e+03 rew

agent-1: 320.0
agent-2: 336.0
agent-3: 329.0
Sum Reward: 985.0
Avg Reward: 328.3333333333333
Min Reward: 320.0
Max Reward: 336.0
Gini Coefficient: 0.010829103214890017
20:20 Ratio: 1.05
Max-min Ratio: 1.05
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-21-34
  done: true
  episode_len_mean: 1000.0
  episode_reward_max: 1366.0
  episode_reward_mean: 1077.35
  episode_reward_min: 579.0
  episodes_this_iter: 1
  episodes_total: 499
  experiment_id: c1aa491745614ad2b8154d8081374a19
  hostname: gpu019
  info:
    apply_time_ms: 3.152
    dispatch_time_ms: 30.244
    learner:
      cur_lr: 0.0012602998176589608
      grad_gnorm: 39.999996185302734
      policy_entropy: 20.216598510742188
      policy_loss: 16.329898834228516
      var_gnorm: 45.683349609375
      vf_explained_var: 0.02375507354736328
      vf_loss: 19.333717346191406
    num_steps_sampled: 1500000
    num_steps_trained: 1500000
    wait_time_ms: 50.922
  iterations_since_restore: 500
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 470
  policy_reward_mean: {}
  time_since_restore: 4511.5260310173035
  time_this_iter_s: 8.314294338226318
  time_total_s: 4511.5260310173035
  timestamp: 1594099294
  timesteps_since_restore: 1500000
  timesteps_this_iter: 3000
  timesteps_total: 1500000
  training_iteration: 500
  
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
TERMINATED trials:
 - A3C_harvest_env_0:	TERMINATED [pid=470], 4511 s, 500 iter, 1500000 ts, 1.08e+03 rew

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
TERMINATED trials:
 - A3C_harvest_env_0:	TERMINATED [pid=470], 4511 s, 500 iter, 1500000 ts, 1.08e+03 rew

WARNING: Logging before InitGoogleLogging() is written to STDERR
E0707 01:21:35.542537   490 raylet_client.cc:345] IOError: [RayletClient] Connection closed unexpectedly. [RayletClient] Failed to push profile events.
WARNING: Logging before InitGoogleLogging() is written to STDERR
E0707 01:21:35.512586   498 raylet_client.cc:345] IOError: [RayletClient] Connection closed unexpectedly. [RayletClient] Failed to push profile events.
Commencing experiment harvest_A3C
E0707 01:21:36.573089   490 raylet_client.cc:345] IOError: [RayletClient] Connection closed unexpectedly. [RayletClient] Failed to push profile events.
E0707 01:21:36.651029   498 raylet_client.cc:345] IOError: [RayletClient] Connection closed unexpectedly. [RayletClient] Failed to push profile events.
