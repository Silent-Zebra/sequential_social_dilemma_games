/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Process STDOUT and STDERR is being redirected to /tmp/ray/session_2020-07-07_16-02-29_10901/logs.
Waiting for redis server at 127.0.0.1:30405 to respond...
Waiting for redis server at 127.0.0.1:28606 to respond...
Warning: Capping object memory store to 20.0GB. To increase this further, specify `object_store_memory` when calling ray.init() or ray start.
Starting the Plasma object store with 20.0 GB memory using /dev/shm.

======================================================================
View the web UI at http://localhost:8888/notebooks/ray_ui.ipynb?token=03a578ef2e8a4cdf0cf500ce5f3cb820e371773eda13b484
======================================================================

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0/2 CPUs, 0/1 GPUs
Memory usage on this node: 36.0/202.5 GB

Created LogSyncer for /h/zhaostep/ray_results/harvest_A3C/A3C_harvest_env_0_2020-07-07_16-02-30g_54mljr -> 
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 36.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING

/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-07 16:02:42,449	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 0 on CPU (please ignore any CUDA init errors)
2020-07-07 16:02:42.449880: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-07 16:02:53,731	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 1 on CPU (please ignore any CUDA init errors)
2020-07-07 16:02:53.733077: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-07 16:02:53,797	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 2 on CPU (please ignore any CUDA init errors)
2020-07-07 16:02:53.798654: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-03-40
  done: false
  episode_len_mean: .nan
  episode_reward_max: .nan
  episode_reward_mean: .nan
  episode_reward_min: .nan
  episodes_this_iter: 0
  episodes_total: 0
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.614
    dispatch_time_ms: 14.968
    learner:
      cur_lr: 0.0013599999947473407
      grad_gnorm: 40.0
      policy_entropy: 504.04052734375
      policy_loss: -20873.619140625
      var_gnorm: 18.36275863647461
      vf_explained_var: 0.0005638599395751953
      vf_loss: 813539.75
    num_steps_sampled: 30000
    num_steps_trained: 30000
    wait_time_ms: 454.359
  iterations_since_restore: 1
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 56.414127349853516
  time_this_iter_s: 56.414127349853516
  time_total_s: 56.414127349853516
  timestamp: 1594152220
  timesteps_since_restore: 30000
  timesteps_this_iter: 30000
  timesteps_total: 30000
  training_iteration: 1
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 56 s, 1 iter, 30000 ts, nan rew

[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
agent-1: -10775.0
agent-2: -10438.0
agent-3: -4794.0
agent-4: -11867.0
agent-5: -5997.0
agent-6: -10503.0
agent-7: -11597.0
agent-8: -3159.0
agent-9: -9737.0
agent-10: -4695.0
agent-11: -7910.0
agent-12: -6712.0
agent-13: -9332.0
agent-14: -11082.0
agent-15: -9655.0
agent-16: -5761.0
agent-17: -4636.0
agent-18: -8470.0
agent-19: -3889.0
agent-20: -7541.0
agent-21: -6856.0
agent-22: -14337.0
agent-23: -8516.0
agent-24: -6644.0
agent-25: -8537.0
agent-26: -8491.0
agent-27: -5175.0
agent-28: -9787.0
agent-29: -2547.0
agent-30: -12714.0
Sum Reward: -242154.0
Avg Reward: -8071.8
Min Reward: -14337.0
Max Reward: -2547.0
Gini Coefficient: -0.20673841164438056
20:20 Ratio: 0.32775106394738296
Max-min Ratio: 0.17765222849968612
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-04-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -242154.0
  episode_reward_mean: -242154.0
  episode_reward_min: -242154.0
  episodes_this_iter: 1
  episodes_total: 1
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 5.579
    dispatch_time_ms: 24.669
    learner:
      cur_lr: 0.001358001958578825
      grad_gnorm: 40.0
      policy_entropy: 195.13230895996094
      policy_loss: -14758.3759765625
      var_gnorm: 18.551603317260742
      vf_explained_var: 0.0007879734039306641
      vf_loss: 2067153.875
    num_steps_sampled: 60000
    num_steps_trained: 60000
    wait_time_ms: 492.238
  iterations_since_restore: 2
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 105.5341260433197
  time_this_iter_s: 49.11999869346619
  time_total_s: 105.5341260433197
  timestamp: 1594152269
  timesteps_since_restore: 60000
  timesteps_this_iter: 30000
  timesteps_total: 60000
  training_iteration: 2
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 105 s, 2 iter, 60000 ts, -2.42e+05 rew

[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
agent-1: -11411.0
agent-2: -20443.0
agent-3: -5747.0
agent-4: -1259.0
agent-5: -9993.0
agent-6: -8096.0
agent-7: -2783.0
agent-8: -5269.0
agent-9: -5598.0
agent-10: -2159.0
agent-11: -13511.0
agent-12: -4289.0
agent-13: -8009.0
agent-14: -3581.0
agent-15: -13020.0
agent-16: -6365.0
agent-17: -14240.0
agent-18: -7639.0
agent-19: -4148.0
agent-20: -9758.0
agent-21: -9341.0
agent-22: -5880.0
agent-23: -2201.0
agent-24: -8640.0
agent-25: -10069.0
agent-26: -7948.0
agent-27: -8823.0
agent-28: -11971.0
agent-29: -7910.0
agent-30: -8844.0
Sum Reward: -238945.0
Avg Reward: -7964.833333333333
Min Reward: -20443.0
Max Reward: -1259.0
Gini Coefficient: -0.28279185586641276
20:20 Ratio: 0.19068277459927183
Max-min Ratio: 0.061585872914934205
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-05-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -238945.0
  episode_reward_mean: -240549.5
  episode_reward_min: -242154.0
  episodes_this_iter: 1
  episodes_total: 2
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.772
    dispatch_time_ms: 10.69
    learner:
      cur_lr: 0.0013560040388256311
      grad_gnorm: 39.999996185302734
      policy_entropy: 77.6151123046875
      policy_loss: -6090.69189453125
      var_gnorm: 18.86928367614746
      vf_explained_var: 0.0
      vf_loss: 8996770.0
    num_steps_sampled: 90000
    num_steps_trained: 90000
    wait_time_ms: 482.69
  iterations_since_restore: 3
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 152.47799491882324
  time_this_iter_s: 46.94386887550354
  time_total_s: 152.47799491882324
  timestamp: 1594152316
  timesteps_since_restore: 90000
  timesteps_this_iter: 30000
  timesteps_total: 90000
  training_iteration: 3
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 152 s, 3 iter, 90000 ts, -2.41e+05 rew

agent-1: -14990.0
agent-2: -19545.0
agent-3: -25952.0
agent-4: -6643.0
agent-5: -4942.0
agent-6: -29985.0
agent-7: -6078.0
agent-8: -16878.0
agent-9: -20185.0
agent-10: -7429.0
agent-11: -19440.0
agent-12: -32880.0
agent-13: -22760.0
agent-14: -16003.0
agent-15: -24746.0
agent-16: -8552.0
agent-17: -10036.0
agent-18: -29042.0
agent-19: -8494.0
agent-20: -44150.0
agent-21: -30995.0
agent-22: -17934.0
agent-23: -19408.0
agent-24: -18022.0
agent-25: -15415.0
agent-26: -9077.0
agent-27: -36736.0
agent-28: -20777.0
agent-29: -7737.0
agent-30: -24015.0
Sum Reward: -568846.0
Avg Reward: -18961.533333333333
Min Reward: -44150.0
Max Reward: -4942.0
Gini Coefficient: -0.2880196046030033
20:20 Ratio: 0.20277445188136692
Max-min Ratio: 0.1119365798414496
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-06-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -238945.0
  episode_reward_mean: -349981.6666666667
  episode_reward_min: -568846.0
  episodes_this_iter: 1
  episodes_total: 3
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.787
    dispatch_time_ms: 7.0
    learner:
      cur_lr: 0.0013540060026571155
      grad_gnorm: 40.0
      policy_entropy: 34.0001106262207
      policy_loss: -9448.1259765625
      var_gnorm: 19.213672637939453
      vf_explained_var: -0.00010418891906738281
      vf_loss: 8709070.0
    num_steps_sampled: 120000
    num_steps_trained: 120000
    wait_time_ms: 462.954
  iterations_since_restore: 4
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 200.65813064575195
  time_this_iter_s: 48.18013572692871
  time_total_s: 200.65813064575195
  timestamp: 1594152364
  timesteps_since_restore: 120000
  timesteps_this_iter: 30000
  timesteps_total: 120000
  training_iteration: 4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 39.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 200 s, 4 iter, 120000 ts, -3.5e+05 rew

agent-1: -16950.0
agent-2: -11545.0
agent-3: -19358.0
agent-4: -10494.0
agent-5: -20596.0
agent-6: -4177.0
agent-7: -11344.0
agent-8: -22910.0
agent-9: -19609.0
agent-10: -30895.0
agent-11: -32703.0
agent-12: -17496.0
agent-13: -34858.0
agent-14: -10774.0
agent-15: -10558.0
agent-16: -7574.0
agent-17: -50536.0
agent-18: -26944.0
agent-19: -36266.0
agent-20: -24327.0
agent-21: -25158.0
agent-22: -4888.0
agent-23: -10302.0
agent-24: -13645.0
agent-25: -23547.0
agent-26: -19714.0
agent-27: -886.0
agent-28: -25002.0
agent-29: -39536.0
agent-30: -39195.0
Sum Reward: -621787.0
Avg Reward: -20726.233333333334
Min Reward: -50536.0
Max Reward: -886.0
Gini Coefficient: -0.31837671099588766
20:20 Ratio: 0.1644014860957382
Max-min Ratio: 0.017532056355865126
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-06-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -238945.0
  episode_reward_mean: -417933.0
  episode_reward_min: -621787.0
  episodes_this_iter: 1
  episodes_total: 4
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.332
    dispatch_time_ms: 8.022
    learner:
      cur_lr: 0.0013520079664885998
      grad_gnorm: 39.999996185302734
      policy_entropy: 33.60201644897461
      policy_loss: -891.82861328125
      var_gnorm: 19.649309158325195
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 10806848.0
    num_steps_sampled: 150000
    num_steps_trained: 150000
    wait_time_ms: 456.031
  iterations_since_restore: 5
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 245.85190892219543
  time_this_iter_s: 45.19377827644348
  time_total_s: 245.85190892219543
  timestamp: 1594152409
  timesteps_since_restore: 150000
  timesteps_this_iter: 30000
  timesteps_total: 150000
  training_iteration: 5
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 39.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 245 s, 5 iter, 150000 ts, -4.18e+05 rew

agent-1: -42972.0
agent-2: -35666.0
agent-3: -32575.0
agent-4: -38976.0
agent-5: -1971.0
agent-6: -41076.0
agent-7: -14778.0
agent-8: -31673.0
agent-9: -23320.0
agent-10: -31327.0
agent-11: -35159.0
agent-12: -22973.0
agent-13: -18526.0
agent-14: -11727.0
agent-15: -45675.0
agent-16: -38269.0
agent-17: -29978.0
agent-18: -2773.0
agent-19: -25975.0
agent-20: -46523.0
agent-21: -19561.0
agent-22: -7318.0
agent-23: -33181.0
agent-24: -32225.0
agent-25: -2221.0
agent-26: -9125.0
agent-27: -34678.0
agent-28: -2026.0
agent-29: -19629.0
agent-30: -57577.0
Sum Reward: -789453.0
Avg Reward: -26315.1
Min Reward: -57577.0
Max Reward: -1971.0
Gini Coefficient: -0.31668370377970567
20:20 Ratio: 0.09323347959486655
Max-min Ratio: 0.03423241919516474
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-07-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -238945.0
  episode_reward_mean: -492237.0
  episode_reward_min: -789453.0
  episodes_this_iter: 1
  episodes_total: 5
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.887
    dispatch_time_ms: 7.126
    learner:
      cur_lr: 0.001350010046735406
      grad_gnorm: 40.0
      policy_entropy: 100.24481964111328
      policy_loss: -16042.97265625
      var_gnorm: 20.128976821899414
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 4429744.0
    num_steps_sampled: 180000
    num_steps_trained: 180000
    wait_time_ms: 454.764
  iterations_since_restore: 6
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 292.05449318885803
  time_this_iter_s: 46.2025842666626
  time_total_s: 292.05449318885803
  timestamp: 1594152456
  timesteps_since_restore: 180000
  timesteps_this_iter: 30000
  timesteps_total: 180000
  training_iteration: 6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 39.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 292 s, 6 iter, 180000 ts, -4.92e+05 rew

agent-1: -2316.0
agent-2: -26226.0
agent-3: -39626.0
agent-4: -44625.0
agent-5: -53874.0
agent-6: -37014.0
agent-7: -38322.0
agent-8: -18127.0
agent-9: -49820.0
agent-10: -48519.0
agent-11: -7174.0
agent-12: -17867.0
agent-13: -4073.0
agent-14: -44634.0
agent-15: -17634.0
agent-16: -64931.0
agent-17: -17181.0
agent-18: -1279.0
agent-19: -976.0
agent-20: -20926.0
agent-21: -4881.0
agent-22: -3969.0
agent-23: -5277.0
agent-24: -34377.0
agent-25: -26426.0
agent-26: -18124.0
agent-27: -47421.0
agent-28: -34771.0
agent-29: -963.0
agent-30: -11817.0
Sum Reward: -743170.0
Avg Reward: -24772.333333333332
Min Reward: -64931.0
Max Reward: -963.0
Gini Coefficient: -0.4243554861830626
20:20 Ratio: 0.04390699840555758
Max-min Ratio: 0.014831128428639633
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-08-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -238945.0
  episode_reward_mean: -534059.1666666666
  episode_reward_min: -789453.0
  episodes_this_iter: 1
  episodes_total: 6
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.348
    dispatch_time_ms: 5.557
    learner:
      cur_lr: 0.0013480120105668902
      grad_gnorm: 39.999996185302734
      policy_entropy: 57.47881317138672
      policy_loss: -6979.96337890625
      var_gnorm: 20.667888641357422
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 13674284.0
    num_steps_sampled: 210000
    num_steps_trained: 210000
    wait_time_ms: 444.702
  iterations_since_restore: 7
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 336.6669750213623
  time_this_iter_s: 44.61248183250427
  time_total_s: 336.6669750213623
  timestamp: 1594152500
  timesteps_since_restore: 210000
  timesteps_this_iter: 30000
  timesteps_total: 210000
  training_iteration: 7
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 336 s, 7 iter, 210000 ts, -5.34e+05 rew

agent-1: -10109.0
agent-2: -15655.0
agent-3: -39021.0
agent-4: -18566.0
agent-5: -14715.0
agent-6: -51407.0
agent-7: -25845.0
agent-8: -38150.0
agent-9: -37404.0
agent-10: -21344.0
agent-11: -74669.0
agent-12: -55210.0
agent-13: -6171.0
agent-14: -12299.0
agent-15: -3640.0
agent-16: -20461.0
agent-17: -6758.0
agent-18: -34508.0
agent-19: -6363.0
agent-20: -3868.0
agent-21: -14401.0
agent-22: -30212.0
agent-23: -7859.0
agent-24: -13468.0
agent-25: -43479.0
agent-26: -905.0
agent-27: -32049.0
agent-28: -22560.0
agent-29: -27299.0
agent-30: -13260.0
Sum Reward: -701655.0
Avg Reward: -23388.5
Min Reward: -74669.0
Max Reward: -905.0
Gini Coefficient: -0.4007010567871675
20:20 Ratio: 0.09175785596947697
Max-min Ratio: 0.012120156959380733
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-09-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -238945.0
  episode_reward_mean: -558001.4285714285
  episode_reward_min: -789453.0
  episodes_this_iter: 1
  episodes_total: 7
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 4.06
    dispatch_time_ms: 6.63
    learner:
      cur_lr: 0.0013460139743983746
      grad_gnorm: 40.000003814697266
      policy_entropy: 20.278099060058594
      policy_loss: -6514.1650390625
      var_gnorm: 21.277706146240234
      vf_explained_var: 0.0
      vf_loss: 10667394.0
    num_steps_sampled: 240000
    num_steps_trained: 240000
    wait_time_ms: 453.651
  iterations_since_restore: 8
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 383.37147283554077
  time_this_iter_s: 46.70449781417847
  time_total_s: 383.37147283554077
  timestamp: 1594152547
  timesteps_since_restore: 240000
  timesteps_this_iter: 30000
  timesteps_total: 240000
  training_iteration: 8
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 383 s, 8 iter, 240000 ts, -5.58e+05 rew

agent-1: -21460.0
agent-2: -11763.0
agent-3: -8408.0
agent-4: -24108.0
agent-5: -9558.0
agent-6: -3605.0
agent-7: -59765.0
agent-8: -8797.0
agent-9: -28201.0
agent-10: -13817.0
agent-11: -3672.0
agent-12: -19655.0
agent-13: -38768.0
agent-14: -6960.0
agent-15: -72510.0
agent-16: -35221.0
agent-17: -2010.0
agent-18: -9464.0
agent-19: -28824.0
agent-20: -20763.0
agent-21: -20008.0
agent-22: -911.0
agent-23: -61707.0
agent-24: -30712.0
agent-25: -49159.0
agent-26: -13863.0
agent-27: -12320.0
agent-28: -30815.0
agent-29: -23059.0
agent-30: -11750.0
Sum Reward: -681633.0
Avg Reward: -22721.1
Min Reward: -72510.0
Max Reward: -911.0
Gini Coefficient: -0.42475432771985316
20:20 Ratio: 0.08061678176142276
Max-min Ratio: 0.012563784305613019
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-09-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -238945.0
  episode_reward_mean: -573455.375
  episode_reward_min: -789453.0
  episodes_this_iter: 1
  episodes_total: 8
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.132
    dispatch_time_ms: 5.899
    learner:
      cur_lr: 0.0013440160546451807
      grad_gnorm: 39.999996185302734
      policy_entropy: 21.24981689453125
      policy_loss: -505.38201904296875
      var_gnorm: 21.931486129760742
      vf_explained_var: 0.0
      vf_loss: 15268236.0
    num_steps_sampled: 270000
    num_steps_trained: 270000
    wait_time_ms: 457.564
  iterations_since_restore: 9
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 429.130167722702
  time_this_iter_s: 45.758694887161255
  time_total_s: 429.130167722702
  timestamp: 1594152593
  timesteps_since_restore: 270000
  timesteps_this_iter: 30000
  timesteps_total: 270000
  training_iteration: 9
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 429 s, 9 iter, 270000 ts, -5.73e+05 rew

agent-1: -39635.0
agent-2: -8838.0
agent-3: -49339.0
agent-4: -19584.0
agent-5: -14887.0
agent-6: -31687.0
agent-7: -21635.0
agent-8: -29638.0
agent-9: -12690.0
agent-10: -12085.0
agent-11: -46939.0
agent-12: -20037.0
agent-13: -77890.0
agent-14: -979.0
agent-15: -62136.0
agent-16: -44239.0
agent-17: -13441.0
agent-18: -14633.0
agent-19: -7739.0
agent-20: -22144.0
agent-21: -71692.0
agent-22: -3683.0
agent-23: -26185.0
agent-24: -1031.0
agent-25: -22686.0
agent-26: -5185.0
agent-27: -30823.0
agent-28: -13534.0
agent-29: -990.0
agent-30: -7477.0
Sum Reward: -733481.0
Avg Reward: -24449.366666666665
Min Reward: -77890.0
Max Reward: -979.0
Gini Coefficient: -0.4473825952319601
20:20 Ratio: 0.05492072054168382
Max-min Ratio: 0.012569007574784952
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-10-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -238945.0
  episode_reward_mean: -591236.0
  episode_reward_min: -789453.0
  episodes_this_iter: 1
  episodes_total: 9
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.527
    dispatch_time_ms: 7.984
    learner:
      cur_lr: 0.001342018018476665
      grad_gnorm: 40.0
      policy_entropy: 77.67965698242188
      policy_loss: -8338.626953125
      var_gnorm: 22.61907386779785
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 9460110.0
    num_steps_sampled: 300000
    num_steps_trained: 300000
    wait_time_ms: 443.757
  iterations_since_restore: 10
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 474.9010293483734
  time_this_iter_s: 45.77086162567139
  time_total_s: 474.9010293483734
  timestamp: 1594152639
  timesteps_since_restore: 300000
  timesteps_this_iter: 30000
  timesteps_total: 300000
  training_iteration: 10
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 474 s, 10 iter, 300000 ts, -5.91e+05 rew

agent-1: -37236.0
agent-2: -74285.0
agent-3: -47334.0
agent-4: -10083.0
agent-5: -24441.0
agent-6: -27829.0
agent-7: -83132.0
agent-8: -28037.0
agent-9: -7127.0
agent-10: -36327.0
agent-11: -34985.0
agent-12: -7136.0
agent-13: -27388.0
agent-14: -15534.0
agent-15: -982.0
agent-16: -35781.0
agent-17: -6479.0
agent-18: -73385.0
agent-19: -18325.0
agent-20: -20874.0
agent-21: -4290.0
agent-22: -1682.0
agent-23: -974.0
agent-24: -26928.0
agent-25: -31484.0
agent-26: -18724.0
agent-27: -85419.0
agent-28: -8079.0
agent-29: -18135.0
agent-30: -3578.0
Sum Reward: -815993.0
Avg Reward: -27199.766666666666
Min Reward: -85419.0
Max Reward: -974.0
Gini Coefficient: -0.46328179285851717
20:20 Ratio: 0.04487376213537729
Max-min Ratio: 0.011402615343190625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-11-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -238945.0
  episode_reward_mean: -613711.7
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 10
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.673
    dispatch_time_ms: 6.041
    learner:
      cur_lr: 0.0013400199823081493
      grad_gnorm: 40.0
      policy_entropy: 32.799381256103516
      policy_loss: 180.04515075683594
      var_gnorm: 22.921375274658203
      vf_explained_var: 0.0006435513496398926
      vf_loss: 7773.47119140625
    num_steps_sampled: 330000
    num_steps_trained: 330000
    wait_time_ms: 408.213
  iterations_since_restore: 11
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 518.0479917526245
  time_this_iter_s: 43.1469624042511
  time_total_s: 518.0479917526245
  timestamp: 1594152682
  timesteps_since_restore: 330000
  timesteps_this_iter: 30000
  timesteps_total: 330000
  training_iteration: 11
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 42.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 518 s, 11 iter, 330000 ts, -6.14e+05 rew

agent-1: -947.0
agent-2: -434.0
agent-3: -12201.0
agent-4: -14062.0
agent-5: -23134.0
agent-6: -5492.0
agent-7: -5486.0
agent-8: -18001.0
agent-9: -9483.0
agent-10: -18412.0
agent-11: -5628.0
agent-12: -13215.0
agent-13: -8683.0
agent-14: -7193.0
agent-15: -9333.0
agent-16: -14740.0
agent-17: -3657.0
agent-18: -9935.0
agent-19: -913.0
agent-20: -10114.0
agent-21: -3391.0
agent-22: -186.0
agent-23: -18891.0
agent-24: -6714.0
agent-25: -10437.0
agent-26: -2636.0
agent-27: -3746.0
agent-28: -6248.0
agent-29: -854.0
agent-30: -10942.0
Sum Reward: -255108.0
Avg Reward: -8503.6
Min Reward: -23134.0
Max Reward: -186.0
Gini Coefficient: -0.39760911718435593
20:20 Ratio: 0.05566952629615815
Max-min Ratio: 0.008040114117748768
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-12-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -238945.0
  episode_reward_mean: -581111.3636363636
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 11
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 4.149
    dispatch_time_ms: 8.394
    learner:
      cur_lr: 0.0013380219461396337
      grad_gnorm: 40.0
      policy_entropy: 62.391910552978516
      policy_loss: 395.7676086425781
      var_gnorm: 22.208600997924805
      vf_explained_var: 0.0
      vf_loss: 7330.21240234375
    num_steps_sampled: 360000
    num_steps_trained: 360000
    wait_time_ms: 379.772
  iterations_since_restore: 12
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 558.1759893894196
  time_this_iter_s: 40.127997636795044
  time_total_s: 558.1759893894196
  timestamp: 1594152722
  timesteps_since_restore: 360000
  timesteps_this_iter: 30000
  timesteps_total: 360000
  training_iteration: 12
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 42.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 558 s, 12 iter, 360000 ts, -5.81e+05 rew

agent-1: -4282.0
agent-2: -3872.0
agent-3: -5281.0
agent-4: -4227.0
agent-5: -1358.0
agent-6: -4297.0
agent-7: -942.0
agent-8: -5198.0
agent-9: -4635.0
agent-10: -4539.0
agent-11: -2896.0
agent-12: -8531.0
agent-13: -4397.0
agent-14: -4219.0
agent-15: -808.0
agent-16: -2662.0
agent-17: -3909.0
agent-18: -4713.0
agent-19: -3159.0
agent-20: -4003.0
agent-21: -3385.0
agent-22: -1442.0
agent-23: -318.0
agent-24: -2977.0
agent-25: -2631.0
agent-26: -2285.0
agent-27: -1617.0
agent-28: -4400.0
agent-29: -702.0
agent-30: -8584.0
Sum Reward: -106269.0
Avg Reward: -3542.3
Min Reward: -8584.0
Max Reward: -318.0
Gini Coefficient: -0.29569269181667907
20:20 Ratio: 0.15077689350874343
Max-min Ratio: 0.037045666356011184
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-12-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -106269.0
  episode_reward_mean: -541541.1666666666
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 12
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.377
    dispatch_time_ms: 6.449
    learner:
      cur_lr: 0.0013360240263864398
      grad_gnorm: 40.000003814697266
      policy_entropy: 30.201955795288086
      policy_loss: 194.82974243164062
      var_gnorm: 21.547515869140625
      vf_explained_var: 0.0
      vf_loss: 5409.466796875
    num_steps_sampled: 390000
    num_steps_trained: 390000
    wait_time_ms: 420.576
  iterations_since_restore: 13
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 599.4449450969696
  time_this_iter_s: 41.26895570755005
  time_total_s: 599.4449450969696
  timestamp: 1594152763
  timesteps_since_restore: 390000
  timesteps_this_iter: 30000
  timesteps_total: 390000
  training_iteration: 13
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 43.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 599 s, 13 iter, 390000 ts, -5.42e+05 rew

agent-1: 45.0
agent-2: 7.0
agent-3: 61.0
agent-4: 35.0
agent-5: -12.0
agent-6: 27.0
agent-7: 45.0
agent-8: 35.0
agent-9: 64.0
agent-10: -26.0
agent-11: 45.0
agent-12: 26.0
agent-13: 33.0
agent-14: 39.0
agent-15: 25.0
agent-16: 28.0
agent-17: 51.0
agent-18: 46.0
agent-19: 26.0
agent-20: 5.0
agent-21: -69.0
agent-22: 19.0
agent-23: 31.0
agent-24: 66.0
agent-25: -13.0
agent-26: 72.0
agent-27: 14.0
agent-28: -55.0
agent-29: -16.0
agent-30: 66.0
Sum Reward: 720.0
Avg Reward: 24.0
Min Reward: -69.0
Max Reward: 72.0
Gini Coefficient: 0.7619444444444444
20:20 Ratio: -1.9895287958115184
Max-min Ratio: -1.0434782608695652
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-13-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 720.0
  episode_reward_mean: -499828.76923076925
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 13
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.155
    dispatch_time_ms: 7.43
    learner:
      cur_lr: 0.0013340259902179241
      grad_gnorm: 40.0
      policy_entropy: 20.475557327270508
      policy_loss: 74.6602783203125
      var_gnorm: 20.938068389892578
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 4384.35302734375
    num_steps_sampled: 420000
    num_steps_trained: 420000
    wait_time_ms: 377.442
  iterations_since_restore: 14
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 639.5384519100189
  time_this_iter_s: 40.093506813049316
  time_total_s: 639.5384519100189
  timestamp: 1594152803
  timesteps_since_restore: 420000
  timesteps_this_iter: 30000
  timesteps_total: 420000
  training_iteration: 14
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 44.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 639 s, 14 iter, 420000 ts, -5e+05 rew

agent-1: 28.0
agent-2: 28.0
agent-3: 70.0
agent-4: -25.0
agent-5: 41.0
agent-6: 38.0
agent-7: 18.0
agent-8: 51.0
agent-9: -34.0
agent-10: 38.0
agent-11: 9.0
agent-12: 18.0
agent-13: 12.0
agent-14: 30.0
agent-15: -31.0
agent-16: 50.0
agent-17: 29.0
agent-18: 66.0
agent-19: 58.0
agent-20: -7.0
agent-21: -1.0
agent-22: 25.0
agent-23: -13.0
agent-24: -14.0
agent-25: 63.0
agent-26: 21.0
agent-27: 53.0
agent-28: 42.0
agent-29: 64.0
agent-30: -9.0
Sum Reward: 718.0
Avg Reward: 23.933333333333334
Min Reward: -34.0
Max Reward: 70.0
Gini Coefficient: 0.7045496750232126
20:20 Ratio: -2.9682539682539684
Max-min Ratio: -2.0588235294117645
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-14-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 720.0
  episode_reward_mean: -464075.4285714286
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 14
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.391
    dispatch_time_ms: 6.299
    learner:
      cur_lr: 0.0013320279540494084
      grad_gnorm: 40.000003814697266
      policy_entropy: 17.456457138061523
      policy_loss: 79.9747543334961
      var_gnorm: 20.386707305908203
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 3406.33251953125
    num_steps_sampled: 450000
    num_steps_trained: 450000
    wait_time_ms: 370.286
  iterations_since_restore: 15
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 677.9346797466278
  time_this_iter_s: 38.39622783660889
  time_total_s: 677.9346797466278
  timestamp: 1594152842
  timesteps_since_restore: 450000
  timesteps_this_iter: 30000
  timesteps_total: 450000
  training_iteration: 15
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 44.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 677 s, 15 iter, 450000 ts, -4.64e+05 rew

agent-1: -35.0
agent-2: 22.0
agent-3: 10.0
agent-4: -13.0
agent-5: 13.0
agent-6: 14.0
agent-7: 19.0
agent-8: 20.0
agent-9: -51.0
agent-10: 39.0
agent-11: 37.0
agent-12: 27.0
agent-13: 54.0
agent-14: 21.0
agent-15: -31.0
agent-16: 23.0
agent-17: 53.0
agent-18: -20.0
agent-19: 48.0
agent-20: 32.0
agent-21: -76.0
agent-22: -25.0
agent-23: 35.0
agent-24: 14.0
agent-25: -35.0
agent-26: 26.0
agent-27: 51.0
agent-28: -70.0
agent-29: 20.0
agent-30: 11.0
Sum Reward: 233.0
Avg Reward: 7.766666666666667
Min Reward: -76.0
Max Reward: 54.0
Gini Coefficient: 2.4487839771101574
20:20 Ratio: -0.9463087248322147
Max-min Ratio: -0.7105263157894737
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-14-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 720.0
  episode_reward_mean: -433121.5333333333
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 15
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.478
    dispatch_time_ms: 9.524
    learner:
      cur_lr: 0.0013300300342962146
      grad_gnorm: 40.0
      policy_entropy: 129.18467712402344
      policy_loss: 541.1853637695312
      var_gnorm: 19.8922061920166
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 3107.03515625
    num_steps_sampled: 480000
    num_steps_trained: 480000
    wait_time_ms: 386.547
  iterations_since_restore: 16
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 717.2350826263428
  time_this_iter_s: 39.300402879714966
  time_total_s: 717.2350826263428
  timestamp: 1594152881
  timesteps_since_restore: 480000
  timesteps_this_iter: 30000
  timesteps_total: 480000
  training_iteration: 16
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 45.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 717 s, 16 iter, 480000 ts, -4.33e+05 rew

agent-1: 3.0
agent-2: 45.0
agent-3: 13.0
agent-4: 22.0
agent-5: 28.0
agent-6: 1.0
agent-7: -7.0
agent-8: -44.0
agent-9: 65.0
agent-10: 37.0
agent-11: 43.0
agent-12: -38.0
agent-13: 0.0
agent-14: 36.0
agent-15: 26.0
agent-16: 35.0
agent-17: 37.0
agent-18: 35.0
agent-19: 74.0
agent-20: 35.0
agent-21: -18.0
agent-22: -30.0
agent-23: 37.0
agent-24: 45.0
agent-25: 14.0
agent-26: 37.0
agent-27: 38.0
agent-28: -17.0
agent-29: 24.0
agent-30: -8.0
Sum Reward: 568.0
Avg Reward: 18.933333333333334
Min Reward: -44.0
Max Reward: 74.0
Gini Coefficient: 0.8368544600938967
20:20 Ratio: -2.0
Max-min Ratio: -1.6818181818181819
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-15-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 720.0
  episode_reward_mean: -406015.9375
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 16
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.253
    dispatch_time_ms: 6.524
    learner:
      cur_lr: 0.001328031998127699
      grad_gnorm: 40.00004196166992
      policy_entropy: 313.22991943359375
      policy_loss: 143.08154296875
      var_gnorm: 20.189069747924805
      vf_explained_var: -0.0023949146270751953
      vf_loss: 10754.166015625
    num_steps_sampled: 510000
    num_steps_trained: 510000
    wait_time_ms: 442.213
  iterations_since_restore: 17
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 759.8756093978882
  time_this_iter_s: 42.64052677154541
  time_total_s: 759.8756093978882
  timestamp: 1594152924
  timesteps_since_restore: 510000
  timesteps_this_iter: 30000
  timesteps_total: 510000
  training_iteration: 17
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 45.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 759 s, 17 iter, 510000 ts, -4.06e+05 rew

agent-1: 41.0
agent-2: 57.0
agent-3: -200.0
agent-4: -94.0
agent-5: 32.0
agent-6: 14.0
agent-7: 18.0
agent-8: -51.0
agent-9: 27.0
agent-10: -118.0
agent-11: -23.0
agent-12: -250.0
agent-13: -27.0
agent-14: -133.0
agent-15: -242.0
agent-16: -232.0
agent-17: 20.0
agent-18: 58.0
agent-19: 33.0
agent-20: 42.0
agent-21: -80.0
agent-22: -57.0
agent-23: -70.0
agent-24: -121.0
agent-25: 34.0
agent-26: -186.0
agent-27: -74.0
agent-28: -18.0
agent-29: -4.0
agent-30: -133.0
Sum Reward: -1737.0
Avg Reward: -57.9
Min Reward: -250.0
Max Reward: 58.0
Gini Coefficient: -0.900882748033007
20:20 Ratio: -0.21319388576025744
Max-min Ratio: -0.232
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-16-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 720.0
  episode_reward_mean: -382234.82352941175
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 17
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.718
    dispatch_time_ms: 6.22
    learner:
      cur_lr: 0.0013260339619591832
      grad_gnorm: 39.99999237060547
      policy_entropy: 330.8548889160156
      policy_loss: 166.02027893066406
      var_gnorm: 20.93586540222168
      vf_explained_var: 0.1967998743057251
      vf_loss: 83.52558898925781
    num_steps_sampled: 540000
    num_steps_trained: 540000
    wait_time_ms: 442.243
  iterations_since_restore: 18
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 804.4529805183411
  time_this_iter_s: 44.57737112045288
  time_total_s: 804.4529805183411
  timestamp: 1594152969
  timesteps_since_restore: 540000
  timesteps_this_iter: 30000
  timesteps_total: 540000
  training_iteration: 18
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 46.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 804 s, 18 iter, 540000 ts, -3.82e+05 rew

agent-1: -112.0
agent-2: -274.0
agent-3: -73.0
agent-4: -359.0
agent-5: -88.0
agent-6: -107.0
agent-7: -89.0
agent-8: 3.0
agent-9: -325.0
agent-10: -161.0
agent-11: -250.0
agent-12: -205.0
agent-13: -271.0
agent-14: -17.0
agent-15: -161.0
agent-16: -163.0
agent-17: -107.0
agent-18: -97.0
agent-19: -179.0
agent-20: -122.0
agent-21: -448.0
agent-22: -123.0
agent-23: -136.0
agent-24: -251.0
agent-25: 47.0
agent-26: -281.0
agent-27: -35.0
agent-28: -208.0
agent-29: -139.0
agent-30: -122.0
Sum Reward: -4853.0
Avg Reward: -161.76666666666668
Min Reward: -448.0
Max Reward: 47.0
Gini Coefficient: -0.36971632667078785
20:20 Ratio: 0.08324821246169561
Max-min Ratio: -0.10491071428571429
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-16-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 720.0
  episode_reward_mean: -361269.1666666667
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 18
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.263
    dispatch_time_ms: 6.305
    learner:
      cur_lr: 0.0013240360422059894
      grad_gnorm: 40.000003814697266
      policy_entropy: 252.3913116455078
      policy_loss: -755.2760009765625
      var_gnorm: 21.100866317749023
      vf_explained_var: -0.0025246143341064453
      vf_loss: 17685.716796875
    num_steps_sampled: 570000
    num_steps_trained: 570000
    wait_time_ms: 429.335
  iterations_since_restore: 19
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 847.39604139328
  time_this_iter_s: 42.943060874938965
  time_total_s: 847.39604139328
  timestamp: 1594153012
  timesteps_since_restore: 570000
  timesteps_this_iter: 30000
  timesteps_total: 570000
  training_iteration: 19
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 46.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 847 s, 19 iter, 570000 ts, -3.61e+05 rew

agent-1: -666.0
agent-2: -165.0
agent-3: -159.0
agent-4: -257.0
agent-5: -234.0
agent-6: -222.0
agent-7: -413.0
agent-8: -135.0
agent-9: -380.0
agent-10: -243.0
agent-11: -183.0
agent-12: -349.0
agent-13: -703.0
agent-14: -42.0
agent-15: -259.0
agent-16: -32.0
agent-17: -52.0
agent-18: -319.0
agent-19: -241.0
agent-20: -371.0
agent-21: 15.0
agent-22: -298.0
agent-23: -318.0
agent-24: -302.0
agent-25: -282.0
agent-26: -291.0
agent-27: -287.0
agent-28: -677.0
agent-29: -282.0
agent-30: -497.0
Sum Reward: -8644.0
Avg Reward: -288.1333333333333
Min Reward: -703.0
Max Reward: 15.0
Gini Coefficient: -0.32189572728675
20:20 Ratio: 0.12140287769784172
Max-min Ratio: -0.021337126600284494
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-17-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 720.0
  episode_reward_mean: -342709.94736842107
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 19
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.684
    dispatch_time_ms: 7.414
    learner:
      cur_lr: 0.0013220380060374737
      grad_gnorm: 40.0
      policy_entropy: 234.85247802734375
      policy_loss: 31.804737091064453
      var_gnorm: 21.126781463623047
      vf_explained_var: 0.28115493059158325
      vf_loss: 41.97653579711914
    num_steps_sampled: 600000
    num_steps_trained: 600000
    wait_time_ms: 434.616
  iterations_since_restore: 20
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 891.6561744213104
  time_this_iter_s: 44.260133028030396
  time_total_s: 891.6561744213104
  timestamp: 1594153056
  timesteps_since_restore: 600000
  timesteps_this_iter: 30000
  timesteps_total: 600000
  training_iteration: 20
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 46.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 891 s, 20 iter, 600000 ts, -3.43e+05 rew

agent-1: 40.0
agent-2: -119.0
agent-3: -25.0
agent-4: -49.0
agent-5: -4.0
agent-6: 51.0
agent-7: -14.0
agent-8: -11.0
agent-9: -292.0
agent-10: -57.0
agent-11: -18.0
agent-12: -113.0
agent-13: -42.0
agent-14: -314.0
agent-15: -74.0
agent-16: -45.0
agent-17: -120.0
agent-18: 49.0
agent-19: -50.0
agent-20: 46.0
agent-21: -104.0
agent-22: -24.0
agent-23: 1.0
agent-24: -42.0
agent-25: 8.0
agent-26: -329.0
agent-27: -13.0
agent-28: -77.0
agent-29: -169.0
agent-30: -69.0
Sum Reward: -1979.0
Avg Reward: -65.96666666666667
Min Reward: -329.0
Max Reward: 51.0
Gini Coefficient: -0.7516422435573522
20:20 Ratio: -0.14519731943410275
Max-min Ratio: -0.15501519756838905
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-18-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 720.0
  episode_reward_mean: -325673.4
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 20
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.185
    dispatch_time_ms: 6.84
    learner:
      cur_lr: 0.001320039969868958
      grad_gnorm: 39.999996185302734
      policy_entropy: 226.64907836914062
      policy_loss: 17.53447151184082
      var_gnorm: 21.17661476135254
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 85.32865142822266
    num_steps_sampled: 630000
    num_steps_trained: 630000
    wait_time_ms: 438.177
  iterations_since_restore: 21
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 935.1514298915863
  time_this_iter_s: 43.49525547027588
  time_total_s: 935.1514298915863
  timestamp: 1594153099
  timesteps_since_restore: 630000
  timesteps_this_iter: 30000
  timesteps_total: 630000
  training_iteration: 21
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 47.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 935 s, 21 iter, 630000 ts, -3.26e+05 rew

agent-1: 52.0
agent-2: 39.0
agent-3: 50.0
agent-4: 47.0
agent-5: 27.0
agent-6: 47.0
agent-7: 51.0
agent-8: 13.0
agent-9: 49.0
agent-10: 50.0
agent-11: 38.0
agent-12: 30.0
agent-13: 21.0
agent-14: 40.0
agent-15: -4.0
agent-16: 64.0
agent-17: -60.0
agent-18: 29.0
agent-19: 23.0
agent-20: 80.0
agent-21: -25.0
agent-22: 58.0
agent-23: -9.0
agent-24: -3.0
agent-25: 16.0
agent-26: 42.0
agent-27: 46.0
agent-28: 60.0
agent-29: 26.0
agent-30: 37.0
Sum Reward: 934.0
Avg Reward: 31.133333333333333
Min Reward: -60.0
Max Reward: 80.0
Gini Coefficient: 0.4797287651677373
20:20 Ratio: -4.1477272727272725
Max-min Ratio: -1.3333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-19-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 934.0
  episode_reward_mean: -310120.6666666667
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 21
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.786
    dispatch_time_ms: 7.586
    learner:
      cur_lr: 0.0013180420501157641
      grad_gnorm: 39.999996185302734
      policy_entropy: 261.8023681640625
      policy_loss: 20.831239700317383
      var_gnorm: 21.188796997070312
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 56.71970748901367
    num_steps_sampled: 660000
    num_steps_trained: 660000
    wait_time_ms: 426.117
  iterations_since_restore: 22
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 979.1138389110565
  time_this_iter_s: 43.962409019470215
  time_total_s: 979.1138389110565
  timestamp: 1594153144
  timesteps_since_restore: 660000
  timesteps_this_iter: 30000
  timesteps_total: 660000
  training_iteration: 22
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 47.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 979 s, 22 iter, 660000 ts, -3.1e+05 rew

agent-1: 62.0
agent-2: 35.0
agent-3: 41.0
agent-4: 43.0
agent-5: 13.0
agent-6: 33.0
agent-7: 22.0
agent-8: 53.0
agent-9: 75.0
agent-10: -15.0
agent-11: 39.0
agent-12: 63.0
agent-13: 38.0
agent-14: 40.0
agent-15: 35.0
agent-16: 48.0
agent-17: 32.0
agent-18: 17.0
agent-19: 63.0
agent-20: 40.0
agent-21: 38.0
agent-22: 67.0
agent-23: 43.0
agent-24: 43.0
agent-25: 43.0
agent-26: 18.0
agent-27: 31.0
agent-28: 50.0
agent-29: 59.0
agent-30: 44.0
Sum Reward: 1213.0
Avg Reward: 40.43333333333333
Min Reward: -15.0
Max Reward: 75.0
Gini Coefficient: 0.23674086287441604
20:20 Ratio: 4.523255813953488
Max-min Ratio: -5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-19-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.0
  episode_reward_mean: -295969.13636363635
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 22
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.856
    dispatch_time_ms: 7.139
    learner:
      cur_lr: 0.0013160440139472485
      grad_gnorm: 39.999996185302734
      policy_entropy: 267.4066162109375
      policy_loss: 24.141014099121094
      var_gnorm: 21.19684410095215
      vf_explained_var: 0.0
      vf_loss: 79.09144592285156
    num_steps_sampled: 690000
    num_steps_trained: 690000
    wait_time_ms: 433.752
  iterations_since_restore: 23
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 1022.6024556159973
  time_this_iter_s: 43.488616704940796
  time_total_s: 1022.6024556159973
  timestamp: 1594153187
  timesteps_since_restore: 690000
  timesteps_this_iter: 30000
  timesteps_total: 690000
  training_iteration: 23
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 48.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 1022 s, 23 iter, 690000 ts, -2.96e+05 rew

agent-1: 45.0
agent-2: 39.0
agent-3: 21.0
agent-4: 47.0
agent-5: 35.0
agent-6: 65.0
agent-7: 42.0
agent-8: 49.0
agent-9: 34.0
agent-10: 20.0
agent-11: 51.0
agent-12: 36.0
agent-13: 34.0
agent-14: 24.0
agent-15: 23.0
agent-16: 45.0
agent-17: 62.0
agent-18: 32.0
agent-19: 58.0
agent-20: 39.0
agent-21: 73.0
agent-22: 27.0
agent-23: 23.0
agent-24: 32.0
agent-25: 53.0
agent-26: 28.0
agent-27: 73.0
agent-28: 38.0
agent-29: 2.0
agent-30: 65.0
Sum Reward: 1215.0
Avg Reward: 40.5
Min Reward: 2.0
Max Reward: 73.0
Gini Coefficient: 0.2308641975308642
20:20 Ratio: 3.504424778761062
Max-min Ratio: 36.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-20-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1215.0
  episode_reward_mean: -283048.0869565217
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 23
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.906
    dispatch_time_ms: 6.349
    learner:
      cur_lr: 0.0013140459777787328
      grad_gnorm: 40.0
      policy_entropy: 251.729248046875
      policy_loss: -19.67519187927246
      var_gnorm: 21.201269149780273
      vf_explained_var: -7.152557373046875e-07
      vf_loss: 6.655977725982666
    num_steps_sampled: 720000
    num_steps_trained: 720000
    wait_time_ms: 431.491
  iterations_since_restore: 24
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 1067.356193780899
  time_this_iter_s: 44.75373816490173
  time_total_s: 1067.356193780899
  timestamp: 1594153232
  timesteps_since_restore: 720000
  timesteps_this_iter: 30000
  timesteps_total: 720000
  training_iteration: 24
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 48.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 1067 s, 24 iter, 720000 ts, -2.83e+05 rew

agent-1: 60.0
agent-2: 10.0
agent-3: 20.0
agent-4: 29.0
agent-5: 28.0
agent-6: 37.0
agent-7: 34.0
agent-8: 37.0
agent-9: 14.0
agent-10: 24.0
agent-11: 1.0
agent-12: 46.0
agent-13: 37.0
agent-14: 22.0
agent-15: 25.0
agent-16: 61.0
agent-17: 36.0
agent-18: 23.0
agent-19: 47.0
agent-20: 62.0
agent-21: 16.0
agent-22: 45.0
agent-23: 76.0
agent-24: 43.0
agent-25: 39.0
agent-26: 11.0
agent-27: 59.0
agent-28: 18.0
agent-29: 48.0
agent-30: 38.0
Sum Reward: 1046.0
Avg Reward: 34.86666666666667
Min Reward: 1.0
Max Reward: 76.0
Gini Coefficient: 0.28425748884639895
20:20 Ratio: 5.228571428571429
Max-min Ratio: 76.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-21-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1215.0
  episode_reward_mean: -271210.8333333333
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 24
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.696
    dispatch_time_ms: 7.956
    learner:
      cur_lr: 0.001312048058025539
      grad_gnorm: 40.0
      policy_entropy: 151.5701141357422
      policy_loss: -18.014129638671875
      var_gnorm: 21.23719596862793
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 40.59492492675781
    num_steps_sampled: 750000
    num_steps_trained: 750000
    wait_time_ms: 436.447
  iterations_since_restore: 25
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 1111.2993297576904
  time_this_iter_s: 43.94313597679138
  time_total_s: 1111.2993297576904
  timestamp: 1594153276
  timesteps_since_restore: 750000
  timesteps_this_iter: 30000
  timesteps_total: 750000
  training_iteration: 25
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 49.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 1111 s, 25 iter, 750000 ts, -2.71e+05 rew

agent-1: 60.0
agent-2: 31.0
agent-3: 20.0
agent-4: 61.0
agent-5: 47.0
agent-6: 23.0
agent-7: 58.0
agent-8: 59.0
agent-9: 68.0
agent-10: 51.0
agent-11: 38.0
agent-12: 47.0
agent-13: 64.0
agent-14: 36.0
agent-15: 17.0
agent-16: 31.0
agent-17: 39.0
agent-18: 65.0
agent-19: 2.0
agent-20: 28.0
agent-21: 34.0
agent-22: 46.0
agent-23: 28.0
agent-24: 35.0
agent-25: 33.0
agent-26: 66.0
agent-27: 27.0
agent-28: 47.0
agent-29: 56.0
agent-30: 29.0
Sum Reward: 1246.0
Avg Reward: 41.53333333333333
Min Reward: 2.0
Max Reward: 68.0
Gini Coefficient: 0.2258426966292135
20:20 Ratio: 3.282051282051282
Max-min Ratio: 34.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-22-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: -260312.56
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 25
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.757
    dispatch_time_ms: 5.797
    learner:
      cur_lr: 0.0013100500218570232
      grad_gnorm: 40.0
      policy_entropy: 145.56312561035156
      policy_loss: -17.937889099121094
      var_gnorm: 21.235671997070312
      vf_explained_var: 2.980232238769531e-07
      vf_loss: 7.660608768463135
    num_steps_sampled: 780000
    num_steps_trained: 780000
    wait_time_ms: 442.108
  iterations_since_restore: 26
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 1155.2048461437225
  time_this_iter_s: 43.905516386032104
  time_total_s: 1155.2048461437225
  timestamp: 1594153320
  timesteps_since_restore: 780000
  timesteps_this_iter: 30000
  timesteps_total: 780000
  training_iteration: 26
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 49.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 1155 s, 26 iter, 780000 ts, -2.6e+05 rew

agent-1: 34.0
agent-2: 53.0
agent-3: 43.0
agent-4: 13.0
agent-5: 43.0
agent-6: 10.0
agent-7: 34.0
agent-8: 52.0
agent-9: 43.0
agent-10: 57.0
agent-11: 50.0
agent-12: 45.0
agent-13: 70.0
agent-14: 56.0
agent-15: 47.0
agent-16: 38.0
agent-17: 43.0
agent-18: 50.0
agent-19: 36.0
agent-20: 36.0
agent-21: 31.0
agent-22: 25.0
agent-23: 52.0
agent-24: 42.0
agent-25: 45.0
agent-26: 35.0
agent-27: 47.0
agent-28: 35.0
agent-29: 29.0
agent-30: 37.0
Sum Reward: 1231.0
Avg Reward: 41.03333333333333
Min Reward: 10.0
Max Reward: 70.0
Gini Coefficient: 0.1618467370701327
20:20 Ratio: 2.3943661971830985
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-22-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: -250253.1923076923
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 26
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.713
    dispatch_time_ms: 6.59
    learner:
      cur_lr: 0.0013080519856885076
      grad_gnorm: 40.000003814697266
      policy_entropy: 111.12555694580078
      policy_loss: -9.472078323364258
      var_gnorm: 21.241214752197266
      vf_explained_var: 0.0
      vf_loss: 15.73751449584961
    num_steps_sampled: 810000
    num_steps_trained: 810000
    wait_time_ms: 446.684
  iterations_since_restore: 27
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 1198.9371259212494
  time_this_iter_s: 43.732279777526855
  time_total_s: 1198.9371259212494
  timestamp: 1594153364
  timesteps_since_restore: 810000
  timesteps_this_iter: 30000
  timesteps_total: 810000
  training_iteration: 27
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 50.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 1198 s, 27 iter, 810000 ts, -2.5e+05 rew

agent-1: 34.0
agent-2: 45.0
agent-3: -10.0
agent-4: 45.0
agent-5: 23.0
agent-6: 35.0
agent-7: 25.0
agent-8: 32.0
agent-9: 41.0
agent-10: 65.0
agent-11: 47.0
agent-12: 41.0
agent-13: 24.0
agent-14: 64.0
agent-15: 40.0
agent-16: 34.0
agent-17: 66.0
agent-18: 48.0
agent-19: 65.0
agent-20: 42.0
agent-21: 18.0
agent-22: 65.0
agent-23: 56.0
agent-24: 29.0
agent-25: 42.0
agent-26: 39.0
agent-27: 35.0
agent-28: 25.0
agent-29: 73.0
agent-30: 44.0
Sum Reward: 1232.0
Avg Reward: 41.06666666666667
Min Reward: -10.0
Max Reward: 73.0
Gini Coefficient: 0.22835497835497837
20:20 Ratio: 3.7904761904761903
Max-min Ratio: -7.3
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-23-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1246.0
  episode_reward_mean: -240938.92592592593
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 27
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.735
    dispatch_time_ms: 7.324
    learner:
      cur_lr: 0.0013060539495199919
      grad_gnorm: 40.0
      policy_entropy: 126.69204711914062
      policy_loss: 54.203712463378906
      var_gnorm: 21.242534637451172
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 109.33557891845703
    num_steps_sampled: 840000
    num_steps_trained: 840000
    wait_time_ms: 419.425
  iterations_since_restore: 28
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 1242.79687166214
  time_this_iter_s: 43.8597457408905
  time_total_s: 1242.79687166214
  timestamp: 1594153408
  timesteps_since_restore: 840000
  timesteps_this_iter: 30000
  timesteps_total: 840000
  training_iteration: 28
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 51.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 1242 s, 28 iter, 840000 ts, -2.41e+05 rew

agent-1: 63.0
agent-2: 25.0
agent-3: 33.0
agent-4: 50.0
agent-5: 71.0
agent-6: 37.0
agent-7: 59.0
agent-8: 48.0
agent-9: 58.0
agent-10: 24.0
agent-11: 62.0
agent-12: 18.0
agent-13: 61.0
agent-14: 53.0
agent-15: 45.0
agent-16: 48.0
agent-17: 46.0
agent-18: 36.0
agent-19: 85.0
agent-20: 50.0
agent-21: 64.0
agent-22: 41.0
agent-23: 48.0
agent-24: 29.0
agent-25: 39.0
agent-26: 56.0
agent-27: 53.0
agent-28: 26.0
agent-29: 51.0
agent-30: 55.0
Sum Reward: 1434.0
Avg Reward: 47.8
Min Reward: 18.0
Max Reward: 85.0
Gini Coefficient: 0.17405857740585773
20:20 Ratio: 2.6193548387096772
Max-min Ratio: 4.722222222222222
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-24-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1434.0
  episode_reward_mean: -232282.75
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 28
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.764
    dispatch_time_ms: 6.542
    learner:
      cur_lr: 0.001304056029766798
      grad_gnorm: 39.99999237060547
      policy_entropy: 172.694580078125
      policy_loss: -33.79121017456055
      var_gnorm: 21.246686935424805
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 19.151792526245117
    num_steps_sampled: 870000
    num_steps_trained: 870000
    wait_time_ms: 439.328
  iterations_since_restore: 29
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 1286.8798658847809
  time_this_iter_s: 44.08299422264099
  time_total_s: 1286.8798658847809
  timestamp: 1594153452
  timesteps_since_restore: 870000
  timesteps_this_iter: 30000
  timesteps_total: 870000
  training_iteration: 29
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 51.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 1286 s, 29 iter, 870000 ts, -2.32e+05 rew

agent-1: 58.0
agent-2: 23.0
agent-3: 43.0
agent-4: 17.0
agent-5: 35.0
agent-6: 33.0
agent-7: 18.0
agent-8: 52.0
agent-9: 38.0
agent-10: 45.0
agent-11: 33.0
agent-12: 53.0
agent-13: 25.0
agent-14: 48.0
agent-15: 44.0
agent-16: 61.0
agent-17: 50.0
agent-18: 33.0
agent-19: 13.0
agent-20: 14.0
agent-21: 54.0
agent-22: 19.0
agent-23: 57.0
agent-24: 46.0
agent-25: 35.0
agent-26: 24.0
agent-27: 57.0
agent-28: 47.0
agent-29: 25.0
agent-30: 27.0
Sum Reward: 1127.0
Avg Reward: 37.56666666666667
Min Reward: 13.0
Max Reward: 61.0
Gini Coefficient: 0.21990535344572612
20:20 Ratio: 3.269230769230769
Max-min Ratio: 4.6923076923076925
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-24-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1434.0
  episode_reward_mean: -224234.1379310345
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 29
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.769
    dispatch_time_ms: 6.073
    learner:
      cur_lr: 0.0013020579935982823
      grad_gnorm: 40.0
      policy_entropy: 268.62139892578125
      policy_loss: 64.69328308105469
      var_gnorm: 21.26607322692871
      vf_explained_var: 0.0
      vf_loss: 73.52601623535156
    num_steps_sampled: 900000
    num_steps_trained: 900000
    wait_time_ms: 429.304
  iterations_since_restore: 30
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 1331.3231265544891
  time_this_iter_s: 44.44326066970825
  time_total_s: 1331.3231265544891
  timestamp: 1594153496
  timesteps_since_restore: 900000
  timesteps_this_iter: 30000
  timesteps_total: 900000
  training_iteration: 30
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 52.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 1331 s, 30 iter, 900000 ts, -2.24e+05 rew

agent-1: 46.0
agent-2: 39.0
agent-3: 34.0
agent-4: 39.0
agent-5: 52.0
agent-6: 37.0
agent-7: 27.0
agent-8: 33.0
agent-9: 43.0
agent-10: 53.0
agent-11: 33.0
agent-12: 40.0
agent-13: 42.0
agent-14: -27.0
agent-15: 21.0
agent-16: 23.0
agent-17: 25.0
agent-18: 38.0
agent-19: 44.0
agent-20: 19.0
agent-21: 13.0
agent-22: 39.0
agent-23: 34.0
agent-24: 18.0
agent-25: 54.0
agent-26: 35.0
agent-27: 34.0
agent-28: 32.0
agent-29: 43.0
agent-30: 57.0
Sum Reward: 1020.0
Avg Reward: 34.0
Min Reward: -27.0
Max Reward: 57.0
Gini Coefficient: 0.22816993464052288
20:20 Ratio: 4.567164179104478
Max-min Ratio: -2.111111111111111
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-25-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1434.0
  episode_reward_mean: -216725.66666666666
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 30
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.334
    dispatch_time_ms: 6.616
    learner:
      cur_lr: 0.0013000599574297667
      grad_gnorm: 40.0
      policy_entropy: 174.8445281982422
      policy_loss: 18.740564346313477
      var_gnorm: 21.359827041625977
      vf_explained_var: 0.0
      vf_loss: 42.67161560058594
    num_steps_sampled: 930000
    num_steps_trained: 930000
    wait_time_ms: 433.478
  iterations_since_restore: 31
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 1375.6048765182495
  time_this_iter_s: 44.281749963760376
  time_total_s: 1375.6048765182495
  timestamp: 1594153541
  timesteps_since_restore: 930000
  timesteps_this_iter: 30000
  timesteps_total: 930000
  training_iteration: 31
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 52.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 1375 s, 31 iter, 930000 ts, -2.17e+05 rew

agent-1: 32.0
agent-2: 37.0
agent-3: 31.0
agent-4: 56.0
agent-5: 32.0
agent-6: 30.0
agent-7: 39.0
agent-8: 20.0
agent-9: 31.0
agent-10: 25.0
agent-11: 30.0
agent-12: 56.0
agent-13: 32.0
agent-14: 33.0
agent-15: 25.0
agent-16: 42.0
agent-17: 36.0
agent-18: 36.0
agent-19: 42.0
agent-20: 47.0
agent-21: 29.0
agent-22: 30.0
agent-23: 47.0
agent-24: 31.0
agent-25: 36.0
agent-26: 27.0
agent-27: 35.0
agent-28: 51.0
agent-29: 48.0
agent-30: 50.0
Sum Reward: 1096.0
Avg Reward: 36.53333333333333
Min Reward: 20.0
Max Reward: 56.0
Gini Coefficient: 0.1398418491484185
20:20 Ratio: 1.9743589743589745
Max-min Ratio: 2.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-26-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1434.0
  episode_reward_mean: -209699.16129032258
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 31
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.604
    dispatch_time_ms: 6.344
    learner:
      cur_lr: 0.0012980620376765728
      grad_gnorm: 40.000003814697266
      policy_entropy: 264.4101867675781
      policy_loss: -35.869544982910156
      var_gnorm: 21.37550163269043
      vf_explained_var: 0.0
      vf_loss: 13.269124031066895
    num_steps_sampled: 960000
    num_steps_trained: 960000
    wait_time_ms: 420.662
  iterations_since_restore: 32
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 1418.4116048812866
  time_this_iter_s: 42.80672836303711
  time_total_s: 1418.4116048812866
  timestamp: 1594153583
  timesteps_since_restore: 960000
  timesteps_this_iter: 30000
  timesteps_total: 960000
  training_iteration: 32
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 52.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 1418 s, 32 iter, 960000 ts, -2.1e+05 rew

agent-1: 61.0
agent-2: 38.0
agent-3: 42.0
agent-4: 69.0
agent-5: 44.0
agent-6: 38.0
agent-7: 41.0
agent-8: 63.0
agent-9: 56.0
agent-10: 61.0
agent-11: 54.0
agent-12: 37.0
agent-13: 80.0
agent-14: 12.0
agent-15: 32.0
agent-16: 32.0
agent-17: 41.0
agent-18: 42.0
agent-19: 66.0
agent-20: 63.0
agent-21: 58.0
agent-22: 42.0
agent-23: 59.0
agent-24: 35.0
agent-25: 62.0
agent-26: 49.0
agent-27: 76.0
agent-28: 54.0
agent-29: 40.0
agent-30: 29.0
Sum Reward: 1476.0
Avg Reward: 49.2
Min Reward: 12.0
Max Reward: 80.0
Gini Coefficient: 0.17177055103884373
20:20 Ratio: 2.3559322033898304
Max-min Ratio: 6.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-27-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1476.0
  episode_reward_mean: -203099.9375
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 32
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.515
    dispatch_time_ms: 9.272
    learner:
      cur_lr: 0.0012960640015080571
      grad_gnorm: 35.92607116699219
      policy_entropy: 217.4333038330078
      policy_loss: 8.416812896728516
      var_gnorm: 21.383541107177734
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 73.87027740478516
    num_steps_sampled: 990000
    num_steps_trained: 990000
    wait_time_ms: 430.646
  iterations_since_restore: 33
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 1464.1775786876678
  time_this_iter_s: 45.765973806381226
  time_total_s: 1464.1775786876678
  timestamp: 1594153629
  timesteps_since_restore: 990000
  timesteps_this_iter: 30000
  timesteps_total: 990000
  training_iteration: 33
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 52.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 1464 s, 33 iter, 990000 ts, -2.03e+05 rew

agent-1: 50.0
agent-2: 76.0
agent-3: 76.0
agent-4: 75.0
agent-5: 34.0
agent-6: 20.0
agent-7: 59.0
agent-8: 46.0
agent-9: 33.0
agent-10: 63.0
agent-11: 33.0
agent-12: 52.0
agent-13: 57.0
agent-14: 47.0
agent-15: 50.0
agent-16: 36.0
agent-17: 60.0
agent-18: 63.0
agent-19: 58.0
agent-20: 31.0
agent-21: 49.0
agent-22: 44.0
agent-23: 26.0
agent-24: 42.0
agent-25: 42.0
agent-26: 53.0
agent-27: 26.0
agent-28: 39.0
agent-29: 53.0
agent-30: 31.0
Sum Reward: 1424.0
Avg Reward: 47.46666666666667
Min Reward: 20.0
Max Reward: 76.0
Gini Coefficient: 0.17701310861423222
20:20 Ratio: 2.4730538922155687
Max-min Ratio: 3.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-27-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1476.0
  episode_reward_mean: -196902.24242424243
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 33
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 5.295
    dispatch_time_ms: 8.331
    learner:
      cur_lr: 0.0012940659653395414
      grad_gnorm: 30.41450309753418
      policy_entropy: 254.06727600097656
      policy_loss: 17.75347137451172
      var_gnorm: 21.376848220825195
      vf_explained_var: 0.0
      vf_loss: 48.95912170410156
    num_steps_sampled: 1020000
    num_steps_trained: 1020000
    wait_time_ms: 405.591
  iterations_since_restore: 34
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 1504.633249282837
  time_this_iter_s: 40.45567059516907
  time_total_s: 1504.633249282837
  timestamp: 1594153674
  timesteps_since_restore: 1020000
  timesteps_this_iter: 30000
  timesteps_total: 1020000
  training_iteration: 34
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 52.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 1504 s, 34 iter, 1020000 ts, -1.97e+05 rew

agent-1: 29.0
agent-2: 22.0
agent-3: 40.0
agent-4: 51.0
agent-5: 52.0
agent-6: 22.0
agent-7: 58.0
agent-8: 20.0
agent-9: 53.0
agent-10: 39.0
agent-11: 33.0
agent-12: 65.0
agent-13: 18.0
agent-14: 41.0
agent-15: 26.0
agent-16: 37.0
agent-17: 67.0
agent-18: 27.0
agent-19: 44.0
agent-20: 30.0
agent-21: 47.0
agent-22: 60.0
agent-23: 33.0
agent-24: 55.0
agent-25: 38.0
agent-26: 53.0
agent-27: 31.0
agent-28: 36.0
agent-29: 44.0
agent-30: 37.0
Sum Reward: 1208.0
Avg Reward: 40.266666666666666
Min Reward: 18.0
Max Reward: 67.0
Gini Coefficient: 0.1891280353200883
20:20 Ratio: 2.651851851851852
Max-min Ratio: 3.7222222222222223
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-28-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1476.0
  episode_reward_mean: -191075.4705882353
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 34
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.699
    dispatch_time_ms: 19.494
    learner:
      cur_lr: 0.0012920680455863476
      grad_gnorm: 40.0
      policy_entropy: 291.1767578125
      policy_loss: -28.753007888793945
      var_gnorm: 21.560495376586914
      vf_explained_var: -0.0005991458892822266
      vf_loss: 15.451869010925293
    num_steps_sampled: 1050000
    num_steps_trained: 1050000
    wait_time_ms: 602.022
  iterations_since_restore: 35
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 1551.0885343551636
  time_this_iter_s: 46.45528507232666
  time_total_s: 1551.0885343551636
  timestamp: 1594153720
  timesteps_since_restore: 1050000
  timesteps_this_iter: 30000
  timesteps_total: 1050000
  training_iteration: 35
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 52.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 1551 s, 35 iter, 1050000 ts, -1.91e+05 rew

agent-1: 74.0
agent-2: 29.0
agent-3: 24.0
agent-4: 55.0
agent-5: 15.0
agent-6: 23.0
agent-7: 47.0
agent-8: 44.0
agent-9: 20.0
agent-10: 51.0
agent-11: 43.0
agent-12: 60.0
agent-13: 63.0
agent-14: 33.0
agent-15: 43.0
agent-16: 50.0
agent-17: 56.0
agent-18: 45.0
agent-19: 38.0
agent-20: 42.0
agent-21: 24.0
agent-22: 44.0
agent-23: 37.0
agent-24: 40.0
agent-25: 66.0
agent-26: 46.0
agent-27: 68.0
agent-28: 51.0
agent-29: 45.0
agent-30: 36.0
Sum Reward: 1312.0
Avg Reward: 43.733333333333334
Min Reward: 15.0
Max Reward: 74.0
Gini Coefficient: 0.18465447154471545
20:20 Ratio: 2.8666666666666667
Max-min Ratio: 4.933333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-29-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1476.0
  episode_reward_mean: -185578.6857142857
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 35
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.576
    dispatch_time_ms: 21.796
    learner:
      cur_lr: 0.001290070009417832
      grad_gnorm: 40.0
      policy_entropy: 234.06434631347656
      policy_loss: 20.069398880004883
      var_gnorm: 21.597726821899414
      vf_explained_var: 0.0
      vf_loss: 66.60926818847656
    num_steps_sampled: 1080000
    num_steps_trained: 1080000
    wait_time_ms: 410.263
  iterations_since_restore: 36
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 1595.091578245163
  time_this_iter_s: 44.00304388999939
  time_total_s: 1595.091578245163
  timestamp: 1594153765
  timesteps_since_restore: 1080000
  timesteps_this_iter: 30000
  timesteps_total: 1080000
  training_iteration: 36
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 52.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 1595 s, 36 iter, 1080000 ts, -1.86e+05 rew

agent-1: 38.0
agent-2: 29.0
agent-3: 42.0
agent-4: 40.0
agent-5: 23.0
agent-6: -14.0
agent-7: 17.0
agent-8: 46.0
agent-9: 54.0
agent-10: 38.0
agent-11: 67.0
agent-12: 49.0
agent-13: 20.0
agent-14: 35.0
agent-15: 61.0
agent-16: 41.0
agent-17: 46.0
agent-18: 12.0
agent-19: 52.0
agent-20: 56.0
agent-21: 29.0
agent-22: 26.0
agent-23: 42.0
agent-24: 44.0
agent-25: 36.0
agent-26: 59.0
agent-27: 35.0
agent-28: 27.0
agent-29: 62.0
agent-30: 37.0
Sum Reward: 1149.0
Avg Reward: 38.3
Min Reward: -14.0
Max Reward: 67.0
Gini Coefficient: 0.23635044966637656
20:20 Ratio: 4.273809523809524
Max-min Ratio: -4.785714285714286
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-30-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1476.0
  episode_reward_mean: -180391.80555555556
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 36
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.632
    dispatch_time_ms: 29.773
    learner:
      cur_lr: 0.0012880719732493162
      grad_gnorm: 40.0
      policy_entropy: 252.3089141845703
      policy_loss: 52.32830810546875
      var_gnorm: 21.6162166595459
      vf_explained_var: 0.0
      vf_loss: 141.7406768798828
    num_steps_sampled: 1110000
    num_steps_trained: 1110000
    wait_time_ms: 412.596
  iterations_since_restore: 37
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 1639.6873772144318
  time_this_iter_s: 44.5957989692688
  time_total_s: 1639.6873772144318
  timestamp: 1594153809
  timesteps_since_restore: 1110000
  timesteps_this_iter: 30000
  timesteps_total: 1110000
  training_iteration: 37
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 52.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 1639 s, 37 iter, 1110000 ts, -1.8e+05 rew

agent-1: 23.0
agent-2: 45.0
agent-3: 47.0
agent-4: 67.0
agent-5: 32.0
agent-6: 38.0
agent-7: 61.0
agent-8: 48.0
agent-9: 68.0
agent-10: 51.0
agent-11: 38.0
agent-12: 36.0
agent-13: 66.0
agent-14: 50.0
agent-15: 50.0
agent-16: 41.0
agent-17: 77.0
agent-18: 28.0
agent-19: 28.0
agent-20: 68.0
agent-21: 59.0
agent-22: 34.0
agent-23: 39.0
agent-24: 31.0
agent-25: 58.0
agent-26: 28.0
agent-27: 43.0
agent-28: 27.0
agent-29: 49.0
agent-30: 50.0
Sum Reward: 1380.0
Avg Reward: 46.0
Min Reward: 23.0
Max Reward: 77.0
Gini Coefficient: 0.17695652173913043
20:20 Ratio: 2.466666666666667
Max-min Ratio: 3.347826086956522
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-30-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1476.0
  episode_reward_mean: -175479.05405405405
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 37
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.82
    dispatch_time_ms: 31.658
    learner:
      cur_lr: 0.0012860740534961224
      grad_gnorm: 40.0
      policy_entropy: 203.7845458984375
      policy_loss: -28.754182815551758
      var_gnorm: 21.621395111083984
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 32.197208404541016
    num_steps_sampled: 1140000
    num_steps_trained: 1140000
    wait_time_ms: 439.877
  iterations_since_restore: 38
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 1684.7277088165283
  time_this_iter_s: 45.04033160209656
  time_total_s: 1684.7277088165283
  timestamp: 1594153854
  timesteps_since_restore: 1140000
  timesteps_this_iter: 30000
  timesteps_total: 1140000
  training_iteration: 38
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 1684 s, 38 iter, 1140000 ts, -1.75e+05 rew

agent-1: 54.0
agent-2: 50.0
agent-3: 23.0
agent-4: 38.0
agent-5: 51.0
agent-6: 59.0
agent-7: 43.0
agent-8: 37.0
agent-9: 74.0
agent-10: 27.0
agent-11: 34.0
agent-12: 35.0
agent-13: 66.0
agent-14: 47.0
agent-15: 27.0
agent-16: 60.0
agent-17: 80.0
agent-18: 36.0
agent-19: 39.0
agent-20: 48.0
agent-21: 69.0
agent-22: 39.0
agent-23: 42.0
agent-24: 40.0
agent-25: 30.0
agent-26: 55.0
agent-27: 51.0
agent-28: 54.0
agent-29: 75.0
agent-30: 14.0
Sum Reward: 1397.0
Avg Reward: 46.56666666666667
Min Reward: 14.0
Max Reward: 80.0
Gini Coefficient: 0.19238845144356956
20:20 Ratio: 2.735483870967742
Max-min Ratio: 5.714285714285714
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-31-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1476.0
  episode_reward_mean: -170824.42105263157
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 38
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.16
    dispatch_time_ms: 17.638
    learner:
      cur_lr: 0.0012840760173276067
      grad_gnorm: 20.24519920349121
      policy_entropy: 173.77088928222656
      policy_loss: 1.325171947479248
      var_gnorm: 21.62071990966797
      vf_explained_var: 0.0
      vf_loss: 31.211013793945312
    num_steps_sampled: 1170000
    num_steps_trained: 1170000
    wait_time_ms: 426.744
  iterations_since_restore: 39
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 1729.9238171577454
  time_this_iter_s: 45.19610834121704
  time_total_s: 1729.9238171577454
  timestamp: 1594153900
  timesteps_since_restore: 1170000
  timesteps_this_iter: 30000
  timesteps_total: 1170000
  training_iteration: 39
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 1729 s, 39 iter, 1170000 ts, -1.71e+05 rew

agent-1: 56.0
agent-2: 37.0
agent-3: 51.0
agent-4: 23.0
agent-5: 29.0
agent-6: 28.0
agent-7: 38.0
agent-8: 44.0
agent-9: 42.0
agent-10: 31.0
agent-11: 49.0
agent-12: 28.0
agent-13: 41.0
agent-14: 33.0
agent-15: 26.0
agent-16: 28.0
agent-17: 48.0
agent-18: 45.0
agent-19: 55.0
agent-20: 50.0
agent-21: 22.0
agent-22: 23.0
agent-23: 53.0
agent-24: 14.0
agent-25: 66.0
agent-26: 58.0
agent-27: 42.0
agent-28: 60.0
agent-29: 35.0
agent-30: 45.0
Sum Reward: 1200.0
Avg Reward: 40.0
Min Reward: 14.0
Max Reward: 66.0
Gini Coefficient: 0.18461111111111111
20:20 Ratio: 2.5588235294117645
Max-min Ratio: 4.714285714285714
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-32-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1476.0
  episode_reward_mean: -166413.53846153847
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 39
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.917
    dispatch_time_ms: 30.696
    learner:
      cur_lr: 0.001282077981159091
      grad_gnorm: 39.999996185302734
      policy_entropy: 135.603759765625
      policy_loss: -50.93696594238281
      var_gnorm: 21.631595611572266
      vf_explained_var: -0.22735798358917236
      vf_loss: 35.62513732910156
    num_steps_sampled: 1200000
    num_steps_trained: 1200000
    wait_time_ms: 436.444
  iterations_since_restore: 40
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 1775.2150268554688
  time_this_iter_s: 45.29120969772339
  time_total_s: 1775.2150268554688
  timestamp: 1594153945
  timesteps_since_restore: 1200000
  timesteps_this_iter: 30000
  timesteps_total: 1200000
  training_iteration: 40
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 1775 s, 40 iter, 1200000 ts, -1.66e+05 rew

agent-1: 24.0
agent-2: 68.0
agent-3: 70.0
agent-4: 34.0
agent-5: 19.0
agent-6: 57.0
agent-7: 45.0
agent-8: 36.0
agent-9: 45.0
agent-10: 53.0
agent-11: 45.0
agent-12: 24.0
agent-13: 51.0
agent-14: 17.0
agent-15: 24.0
agent-16: 31.0
agent-17: 45.0
agent-18: 80.0
agent-19: 39.0
agent-20: 32.0
agent-21: 42.0
agent-22: 64.0
agent-23: 46.0
agent-24: 33.0
agent-25: 52.0
agent-26: 78.0
agent-27: 41.0
agent-28: 45.0
agent-29: 61.0
agent-30: 54.0
Sum Reward: 1355.0
Avg Reward: 45.166666666666664
Min Reward: 17.0
Max Reward: 80.0
Gini Coefficient: 0.20450184501845017
20:20 Ratio: 3.028776978417266
Max-min Ratio: 4.705882352941177
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-33-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1476.0
  episode_reward_mean: -162219.325
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 40
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.483
    dispatch_time_ms: 18.111
    learner:
      cur_lr: 0.0012800799449905753
      grad_gnorm: 40.0
      policy_entropy: 169.59951782226562
      policy_loss: 13.002190589904785
      var_gnorm: 21.660247802734375
      vf_explained_var: 0.0
      vf_loss: 95.07504272460938
    num_steps_sampled: 1230000
    num_steps_trained: 1230000
    wait_time_ms: 416.966
  iterations_since_restore: 41
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 1820.1517248153687
  time_this_iter_s: 44.9366979598999
  time_total_s: 1820.1517248153687
  timestamp: 1594153990
  timesteps_since_restore: 1230000
  timesteps_this_iter: 30000
  timesteps_total: 1230000
  training_iteration: 41
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 1820 s, 41 iter, 1230000 ts, -1.62e+05 rew

agent-1: 46.0
agent-2: 34.0
agent-3: 37.0
agent-4: 20.0
agent-5: 26.0
agent-6: 33.0
agent-7: 32.0
agent-8: 41.0
agent-9: 46.0
agent-10: 58.0
agent-11: 41.0
agent-12: 58.0
agent-13: 42.0
agent-14: 37.0
agent-15: 68.0
agent-16: 27.0
agent-17: 44.0
agent-18: 25.0
agent-19: 24.0
agent-20: 34.0
agent-21: 31.0
agent-22: 35.0
agent-23: 39.0
agent-24: 48.0
agent-25: 20.0
agent-26: 22.0
agent-27: 34.0
agent-28: 37.0
agent-29: 27.0
agent-30: 57.0
Sum Reward: 1123.0
Avg Reward: 37.43333333333333
Min Reward: 20.0
Max Reward: 68.0
Gini Coefficient: 0.1749183734045711
20:20 Ratio: 2.4452554744525545
Max-min Ratio: 3.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-33-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1476.0
  episode_reward_mean: -158235.36585365853
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 41
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.97
    dispatch_time_ms: 15.627
    learner:
      cur_lr: 0.0012780820252373815
      grad_gnorm: 40.0
      policy_entropy: 110.06019592285156
      policy_loss: 6.7686004638671875
      var_gnorm: 21.66897201538086
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 89.10929870605469
    num_steps_sampled: 1260000
    num_steps_trained: 1260000
    wait_time_ms: 416.433
  iterations_since_restore: 42
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 1865.8236634731293
  time_this_iter_s: 45.67193865776062
  time_total_s: 1865.8236634731293
  timestamp: 1594154036
  timesteps_since_restore: 1260000
  timesteps_this_iter: 30000
  timesteps_total: 1260000
  training_iteration: 42
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 1865 s, 42 iter, 1260000 ts, -1.58e+05 rew

agent-1: 30.0
agent-2: 40.0
agent-3: 54.0
agent-4: 33.0
agent-5: 8.0
agent-6: 44.0
agent-7: 29.0
agent-8: 63.0
agent-9: 30.0
agent-10: 50.0
agent-11: 48.0
agent-12: 46.0
agent-13: 41.0
agent-14: 38.0
agent-15: 37.0
agent-16: 22.0
agent-17: 60.0
agent-18: 46.0
agent-19: 15.0
agent-20: 21.0
agent-21: 31.0
agent-22: 43.0
agent-23: 36.0
agent-24: 30.0
agent-25: 46.0
agent-26: 29.0
agent-27: 47.0
agent-28: 49.0
agent-29: 37.0
agent-30: 56.0
Sum Reward: 1159.0
Avg Reward: 38.63333333333333
Min Reward: 8.0
Max Reward: 63.0
Gini Coefficient: 0.18386540120793787
20:20 Ratio: 2.6774193548387095
Max-min Ratio: 7.875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-34-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1476.0
  episode_reward_mean: -154440.2619047619
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 42
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.402
    dispatch_time_ms: 31.577
    learner:
      cur_lr: 0.0012760839890688658
      grad_gnorm: 40.0
      policy_entropy: 131.30101013183594
      policy_loss: 23.07115364074707
      var_gnorm: 21.678380966186523
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 56.47206115722656
    num_steps_sampled: 1290000
    num_steps_trained: 1290000
    wait_time_ms: 390.97
  iterations_since_restore: 43
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 1910.845585823059
  time_this_iter_s: 45.02192234992981
  time_total_s: 1910.845585823059
  timestamp: 1594154081
  timesteps_since_restore: 1290000
  timesteps_this_iter: 30000
  timesteps_total: 1290000
  training_iteration: 43
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 1910 s, 43 iter, 1290000 ts, -1.54e+05 rew

agent-1: 63.0
agent-2: 54.0
agent-3: 61.0
agent-4: 57.0
agent-5: 26.0
agent-6: 70.0
agent-7: 30.0
agent-8: 55.0
agent-9: 71.0
agent-10: 73.0
agent-11: 43.0
agent-12: 35.0
agent-13: 29.0
agent-14: 74.0
agent-15: 62.0
agent-16: 74.0
agent-17: 48.0
agent-18: 31.0
agent-19: 32.0
agent-20: 82.0
agent-21: 43.0
agent-22: 67.0
agent-23: 61.0
agent-24: 55.0
agent-25: 71.0
agent-26: 24.0
agent-27: 35.0
agent-28: 38.0
agent-29: 61.0
agent-30: 47.0
Sum Reward: 1572.0
Avg Reward: 52.4
Min Reward: 24.0
Max Reward: 82.0
Gini Coefficient: 0.1826972010178117
20:20 Ratio: 2.5872093023255816
Max-min Ratio: 3.4166666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-35-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -150812.06976744186
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 43
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.716
    dispatch_time_ms: 20.197
    learner:
      cur_lr: 0.00127408595290035
      grad_gnorm: 33.250606536865234
      policy_entropy: 130.1390380859375
      policy_loss: 9.137856483459473
      var_gnorm: 21.687902450561523
      vf_explained_var: 0.0
      vf_loss: 49.192481994628906
    num_steps_sampled: 1320000
    num_steps_trained: 1320000
    wait_time_ms: 437.08
  iterations_since_restore: 44
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 1956.172173500061
  time_this_iter_s: 45.32658767700195
  time_total_s: 1956.172173500061
  timestamp: 1594154127
  timesteps_since_restore: 1320000
  timesteps_this_iter: 30000
  timesteps_total: 1320000
  training_iteration: 44
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 1956 s, 44 iter, 1320000 ts, -1.51e+05 rew

agent-1: 59.0
agent-2: 18.0
agent-3: 28.0
agent-4: 9.0
agent-5: 32.0
agent-6: 27.0
agent-7: 20.0
agent-8: 39.0
agent-9: 34.0
agent-10: 41.0
agent-11: 33.0
agent-12: 43.0
agent-13: 32.0
agent-14: 20.0
agent-15: 30.0
agent-16: 50.0
agent-17: 24.0
agent-18: 34.0
agent-19: 27.0
agent-20: 45.0
agent-21: 53.0
agent-22: 29.0
agent-23: 36.0
agent-24: 34.0
agent-25: 57.0
agent-26: 49.0
agent-27: 36.0
agent-28: 13.0
agent-29: 54.0
agent-30: 51.0
Sum Reward: 1057.0
Avg Reward: 35.233333333333334
Min Reward: 9.0
Max Reward: 59.0
Gini Coefficient: 0.206401766004415
20:20 Ratio: 3.1153846153846154
Max-min Ratio: 6.555555555555555
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-36-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -147360.5
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 44
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.496
    dispatch_time_ms: 22.849
    learner:
      cur_lr: 0.0012720880331471562
      grad_gnorm: 40.0
      policy_entropy: 126.90044403076172
      policy_loss: -21.713275909423828
      var_gnorm: 21.686359405517578
      vf_explained_var: 0.0
      vf_loss: 20.19232177734375
    num_steps_sampled: 1350000
    num_steps_trained: 1350000
    wait_time_ms: 442.976
  iterations_since_restore: 45
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 2001.125205039978
  time_this_iter_s: 44.95303153991699
  time_total_s: 2001.125205039978
  timestamp: 1594154172
  timesteps_since_restore: 1350000
  timesteps_this_iter: 30000
  timesteps_total: 1350000
  training_iteration: 45
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 2001 s, 45 iter, 1350000 ts, -1.47e+05 rew

agent-1: 61.0
agent-2: 46.0
agent-3: 49.0
agent-4: 55.0
agent-5: 45.0
agent-6: 26.0
agent-7: 78.0
agent-8: 52.0
agent-9: 51.0
agent-10: 51.0
agent-11: 59.0
agent-12: 54.0
agent-13: 64.0
agent-14: 39.0
agent-15: 53.0
agent-16: 45.0
agent-17: 58.0
agent-18: 31.0
agent-19: 34.0
agent-20: 25.0
agent-21: 37.0
agent-22: 88.0
agent-23: 21.0
agent-24: 64.0
agent-25: 31.0
agent-26: 45.0
agent-27: 65.0
agent-28: 21.0
agent-29: 56.0
agent-30: 29.0
Sum Reward: 1433.0
Avg Reward: 47.766666666666666
Min Reward: 21.0
Max Reward: 88.0
Gini Coefficient: 0.18862526168876484
20:20 Ratio: 2.7450980392156863
Max-min Ratio: 4.190476190476191
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-36-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -144053.97777777776
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 45
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.27
    dispatch_time_ms: 21.827
    learner:
      cur_lr: 0.0012700899969786406
      grad_gnorm: 40.0
      policy_entropy: 113.42951965332031
      policy_loss: 21.691699981689453
      var_gnorm: 21.697887420654297
      vf_explained_var: 0.0
      vf_loss: 67.13014221191406
    num_steps_sampled: 1380000
    num_steps_trained: 1380000
    wait_time_ms: 424.667
  iterations_since_restore: 46
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 2045.8613913059235
  time_this_iter_s: 44.736186265945435
  time_total_s: 2045.8613913059235
  timestamp: 1594154216
  timesteps_since_restore: 1380000
  timesteps_this_iter: 30000
  timesteps_total: 1380000
  training_iteration: 46
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 2045 s, 46 iter, 1380000 ts, -1.44e+05 rew

agent-1: 50.0
agent-2: 53.0
agent-3: 18.0
agent-4: 47.0
agent-5: 38.0
agent-6: 47.0
agent-7: 31.0
agent-8: 44.0
agent-9: 52.0
agent-10: 51.0
agent-11: 27.0
agent-12: 40.0
agent-13: 48.0
agent-14: 46.0
agent-15: 47.0
agent-16: 33.0
agent-17: 41.0
agent-18: 68.0
agent-19: 58.0
agent-20: 62.0
agent-21: 54.0
agent-22: 49.0
agent-23: 39.0
agent-24: 45.0
agent-25: 54.0
agent-26: 36.0
agent-27: 51.0
agent-28: 33.0
agent-29: 43.0
agent-30: 24.0
Sum Reward: 1329.0
Avg Reward: 44.3
Min Reward: 18.0
Max Reward: 68.0
Gini Coefficient: 0.13702031602708803
20:20 Ratio: 2.102409638554217
Max-min Ratio: 3.7777777777777777
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-37-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -140893.47826086957
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 46
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.518
    dispatch_time_ms: 39.718
    learner:
      cur_lr: 0.0012680919608101249
      grad_gnorm: 39.999996185302734
      policy_entropy: 78.93708801269531
      policy_loss: 29.300132751464844
      var_gnorm: 21.699447631835938
      vf_explained_var: 0.0
      vf_loss: 75.78022003173828
    num_steps_sampled: 1410000
    num_steps_trained: 1410000
    wait_time_ms: 1609.225
  iterations_since_restore: 47
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 2105.76220870018
  time_this_iter_s: 59.90081739425659
  time_total_s: 2105.76220870018
  timestamp: 1594154276
  timesteps_since_restore: 1410000
  timesteps_this_iter: 30000
  timesteps_total: 1410000
  training_iteration: 47
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 2105 s, 47 iter, 1410000 ts, -1.41e+05 rew

agent-1: 44.0
agent-2: 12.0
agent-3: 64.0
agent-4: 42.0
agent-5: 47.0
agent-6: 25.0
agent-7: 37.0
agent-8: 63.0
agent-9: 51.0
agent-10: 51.0
agent-11: 44.0
agent-12: 66.0
agent-13: 54.0
agent-14: 32.0
agent-15: 59.0
agent-16: 54.0
agent-17: 63.0
agent-18: 28.0
agent-19: 50.0
agent-20: 77.0
agent-21: 37.0
agent-22: 35.0
agent-23: 65.0
agent-24: 15.0
agent-25: 57.0
agent-26: 59.0
agent-27: 73.0
agent-28: 30.0
agent-29: 75.0
agent-30: 37.0
Sum Reward: 1446.0
Avg Reward: 48.2
Min Reward: 12.0
Max Reward: 77.0
Gini Coefficient: 0.1978792070078377
20:20 Ratio: 2.9577464788732395
Max-min Ratio: 6.416666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-38-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -137864.97872340426
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 47
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.036
    dispatch_time_ms: 29.323
    learner:
      cur_lr: 0.001266094041056931
      grad_gnorm: 40.0
      policy_entropy: 98.61630249023438
      policy_loss: -11.389527320861816
      var_gnorm: 21.69680404663086
      vf_explained_var: 0.0
      vf_loss: 23.940183639526367
    num_steps_sampled: 1440000
    num_steps_trained: 1440000
    wait_time_ms: 395.159
  iterations_since_restore: 48
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 2156.2920956611633
  time_this_iter_s: 50.529886960983276
  time_total_s: 2156.2920956611633
  timestamp: 1594154327
  timesteps_since_restore: 1440000
  timesteps_this_iter: 30000
  timesteps_total: 1440000
  training_iteration: 48
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 2156 s, 48 iter, 1440000 ts, -1.38e+05 rew

agent-1: 38.0
agent-2: 52.0
agent-3: 54.0
agent-4: 46.0
agent-5: 30.0
agent-6: 44.0
agent-7: 43.0
agent-8: 61.0
agent-9: 61.0
agent-10: 37.0
agent-11: 29.0
agent-12: 39.0
agent-13: 79.0
agent-14: 51.0
agent-15: 32.0
agent-16: 41.0
agent-17: 56.0
agent-18: 44.0
agent-19: 46.0
agent-20: 22.0
agent-21: 45.0
agent-22: 35.0
agent-23: 45.0
agent-24: 23.0
agent-25: 24.0
agent-26: 52.0
agent-27: 43.0
agent-28: 49.0
agent-29: 64.0
agent-30: 32.0
Sum Reward: 1317.0
Avg Reward: 43.9
Min Reward: 22.0
Max Reward: 79.0
Gini Coefficient: 0.16190837762591748
20:20 Ratio: 2.34375
Max-min Ratio: 3.590909090909091
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-39-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -134965.35416666666
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 48
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.735
    dispatch_time_ms: 45.13
    learner:
      cur_lr: 0.0012640960048884153
      grad_gnorm: 40.0
      policy_entropy: 97.11398315429688
      policy_loss: 23.83560562133789
      var_gnorm: 21.701066970825195
      vf_explained_var: 0.0
      vf_loss: 144.06988525390625
    num_steps_sampled: 1470000
    num_steps_trained: 1470000
    wait_time_ms: 389.481
  iterations_since_restore: 49
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 2200.409698486328
  time_this_iter_s: 44.117602825164795
  time_total_s: 2200.409698486328
  timestamp: 1594154371
  timesteps_since_restore: 1470000
  timesteps_this_iter: 30000
  timesteps_total: 1470000
  training_iteration: 49
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 2200 s, 49 iter, 1470000 ts, -1.35e+05 rew

agent-1: 20.0
agent-2: 45.0
agent-3: 55.0
agent-4: 38.0
agent-5: 48.0
agent-6: 61.0
agent-7: 45.0
agent-8: 30.0
agent-9: 57.0
agent-10: 58.0
agent-11: 19.0
agent-12: 51.0
agent-13: 29.0
agent-14: 33.0
agent-15: 15.0
agent-16: 34.0
agent-17: 23.0
agent-18: 32.0
agent-19: 56.0
agent-20: 41.0
agent-21: 43.0
agent-22: 44.0
agent-23: 37.0
agent-24: 35.0
agent-25: 62.0
agent-26: 31.0
agent-27: 55.0
agent-28: 48.0
agent-29: 44.0
agent-30: 35.0
Sum Reward: 1224.0
Avg Reward: 40.8
Min Reward: 15.0
Max Reward: 62.0
Gini Coefficient: 0.17777777777777778
20:20 Ratio: 2.5661764705882355
Max-min Ratio: 4.133333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-40-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -132185.97959183675
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 49
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.495
    dispatch_time_ms: 14.753
    learner:
      cur_lr: 0.0012620979687198997
      grad_gnorm: 40.000003814697266
      policy_entropy: 103.8133544921875
      policy_loss: 11.448935508728027
      var_gnorm: 21.700395584106445
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 87.94960021972656
    num_steps_sampled: 1500000
    num_steps_trained: 1500000
    wait_time_ms: 424.674
  iterations_since_restore: 50
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 2245.6632561683655
  time_this_iter_s: 45.25355768203735
  time_total_s: 2245.6632561683655
  timestamp: 1594154416
  timesteps_since_restore: 1500000
  timesteps_this_iter: 30000
  timesteps_total: 1500000
  training_iteration: 50
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 2245 s, 50 iter, 1500000 ts, -1.32e+05 rew

agent-1: 53.0
agent-2: 57.0
agent-3: 38.0
agent-4: 56.0
agent-5: 40.0
agent-6: 43.0
agent-7: 55.0
agent-8: 46.0
agent-9: 48.0
agent-10: 72.0
agent-11: 75.0
agent-12: 54.0
agent-13: 48.0
agent-14: 57.0
agent-15: 46.0
agent-16: 32.0
agent-17: 43.0
agent-18: 53.0
agent-19: 40.0
agent-20: 34.0
agent-21: 74.0
agent-22: 33.0
agent-23: 51.0
agent-24: 72.0
agent-25: 68.0
agent-26: 65.0
agent-27: 33.0
agent-28: 54.0
agent-29: 39.0
agent-30: 84.0
Sum Reward: 1563.0
Avg Reward: 52.1
Min Reward: 32.0
Max Reward: 84.0
Gini Coefficient: 0.1491789294092557
20:20 Ratio: 2.1291866028708135
Max-min Ratio: 2.625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-41-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -129511.0
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 50
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.756
    dispatch_time_ms: 19.491
    learner:
      cur_lr: 0.0012601000489667058
      grad_gnorm: 40.0
      policy_entropy: 114.22340393066406
      policy_loss: 6.324615955352783
      var_gnorm: 21.704021453857422
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 143.51174926757812
    num_steps_sampled: 1530000
    num_steps_trained: 1530000
    wait_time_ms: 438.876
  iterations_since_restore: 51
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 2289.939587831497
  time_this_iter_s: 44.276331663131714
  time_total_s: 2289.939587831497
  timestamp: 1594154461
  timesteps_since_restore: 1530000
  timesteps_this_iter: 30000
  timesteps_total: 1530000
  training_iteration: 51
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 2289 s, 51 iter, 1530000 ts, -1.3e+05 rew

agent-1: 35.0
agent-2: 41.0
agent-3: 40.0
agent-4: 29.0
agent-5: 44.0
agent-6: 42.0
agent-7: 52.0
agent-8: 51.0
agent-9: 14.0
agent-10: 62.0
agent-11: 39.0
agent-12: 24.0
agent-13: 66.0
agent-14: 60.0
agent-15: 61.0
agent-16: 40.0
agent-17: 36.0
agent-18: 55.0
agent-19: 38.0
agent-20: 60.0
agent-21: 92.0
agent-22: 33.0
agent-23: 72.0
agent-24: 64.0
agent-25: 52.0
agent-26: 80.0
agent-27: 75.0
agent-28: 62.0
agent-29: 33.0
agent-30: 58.0
Sum Reward: 1510.0
Avg Reward: 50.333333333333336
Min Reward: 14.0
Max Reward: 92.0
Gini Coefficient: 0.19342163355408387
20:20 Ratio: 2.6726190476190474
Max-min Ratio: 6.571428571428571
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-41-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -126941.96078431372
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 51
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 4.148
    dispatch_time_ms: 58.691
    learner:
      cur_lr: 0.0012581020127981901
      grad_gnorm: 40.000003814697266
      policy_entropy: 133.05499267578125
      policy_loss: 56.90058898925781
      var_gnorm: 21.70244026184082
      vf_explained_var: 0.0
      vf_loss: 184.81837463378906
    num_steps_sampled: 1560000
    num_steps_trained: 1560000
    wait_time_ms: 369.989
  iterations_since_restore: 52
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 2335.051894903183
  time_this_iter_s: 45.11230707168579
  time_total_s: 2335.051894903183
  timestamp: 1594154506
  timesteps_since_restore: 1560000
  timesteps_this_iter: 30000
  timesteps_total: 1560000
  training_iteration: 52
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 2335 s, 52 iter, 1560000 ts, -1.27e+05 rew

agent-1: 53.0
agent-2: 67.0
agent-3: 53.0
agent-4: 70.0
agent-5: 53.0
agent-6: 34.0
agent-7: 77.0
agent-8: 39.0
agent-9: 36.0
agent-10: 48.0
agent-11: 46.0
agent-12: 19.0
agent-13: 44.0
agent-14: 47.0
agent-15: 52.0
agent-16: 59.0
agent-17: 61.0
agent-18: 38.0
agent-19: 45.0
agent-20: 59.0
agent-21: 33.0
agent-22: 45.0
agent-23: 35.0
agent-24: 56.0
agent-25: 38.0
agent-26: 58.0
agent-27: 69.0
agent-28: 53.0
agent-29: 47.0
agent-30: 43.0
Sum Reward: 1477.0
Avg Reward: 49.233333333333334
Min Reward: 19.0
Max Reward: 77.0
Gini Coefficient: 0.1422929361317987
20:20 Ratio: 2.066666666666667
Max-min Ratio: 4.052631578947368
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-42-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -124472.36538461539
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 52
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.759
    dispatch_time_ms: 31.987
    learner:
      cur_lr: 0.0012561039766296744
      grad_gnorm: 40.000003814697266
      policy_entropy: 119.90554809570312
      policy_loss: 0.032965287566185
      var_gnorm: 21.696788787841797
      vf_explained_var: 3.5762786865234375e-07
      vf_loss: 54.37898254394531
    num_steps_sampled: 1590000
    num_steps_trained: 1590000
    wait_time_ms: 457.172
  iterations_since_restore: 53
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 2380.489372730255
  time_this_iter_s: 45.437477827072144
  time_total_s: 2380.489372730255
  timestamp: 1594154551
  timesteps_since_restore: 1590000
  timesteps_this_iter: 30000
  timesteps_total: 1590000
  training_iteration: 53
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 2380 s, 53 iter, 1590000 ts, -1.24e+05 rew

agent-1: 47.0
agent-2: 70.0
agent-3: 41.0
agent-4: 33.0
agent-5: 30.0
agent-6: 18.0
agent-7: 28.0
agent-8: 28.0
agent-9: 40.0
agent-10: 22.0
agent-11: 12.0
agent-12: 9.0
agent-13: 20.0
agent-14: 28.0
agent-15: 51.0
agent-16: 60.0
agent-17: 40.0
agent-18: 32.0
agent-19: 38.0
agent-20: 40.0
agent-21: 58.0
agent-22: 56.0
agent-23: 47.0
agent-24: 40.0
agent-25: 40.0
agent-26: 54.0
agent-27: 34.0
agent-28: 43.0
agent-29: 34.0
agent-30: 33.0
Sum Reward: 1126.0
Avg Reward: 37.53333333333333
Min Reward: 9.0
Max Reward: 70.0
Gini Coefficient: 0.20840734162226168
20:20 Ratio: 3.2018348623853212
Max-min Ratio: 7.777777777777778
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-43-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -122102.58490566038
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 53
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.589
    dispatch_time_ms: 33.418
    learner:
      cur_lr: 0.0012541060568764806
      grad_gnorm: 40.0
      policy_entropy: 112.57199096679688
      policy_loss: -10.683639526367188
      var_gnorm: 21.690101623535156
      vf_explained_var: 0.0
      vf_loss: 2.214264154434204
    num_steps_sampled: 1620000
    num_steps_trained: 1620000
    wait_time_ms: 408.755
  iterations_since_restore: 54
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 2426.1051077842712
  time_this_iter_s: 45.61573505401611
  time_total_s: 2426.1051077842712
  timestamp: 1594154597
  timesteps_since_restore: 1620000
  timesteps_this_iter: 30000
  timesteps_total: 1620000
  training_iteration: 54
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 2426 s, 54 iter, 1620000 ts, -1.22e+05 rew

agent-1: 22.0
agent-2: 28.0
agent-3: 19.0
agent-4: 58.0
agent-5: 29.0
agent-6: 15.0
agent-7: 40.0
agent-8: 31.0
agent-9: 28.0
agent-10: 37.0
agent-11: 16.0
agent-12: 38.0
agent-13: 44.0
agent-14: 33.0
agent-15: 40.0
agent-16: 27.0
agent-17: 25.0
agent-18: 40.0
agent-19: 48.0
agent-20: 15.0
agent-21: 34.0
agent-22: 27.0
agent-23: 34.0
agent-24: 37.0
agent-25: 35.0
agent-26: 30.0
agent-27: 38.0
agent-28: 31.0
agent-29: 46.0
agent-30: 20.0
Sum Reward: 965.0
Avg Reward: 32.166666666666664
Min Reward: 15.0
Max Reward: 58.0
Gini Coefficient: 0.17412780656303972
20:20 Ratio: 2.5794392523364484
Max-min Ratio: 3.8666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-44-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -119823.55555555556
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 54
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.761
    dispatch_time_ms: 13.655
    learner:
      cur_lr: 0.001252108020707965
      grad_gnorm: 40.0
      policy_entropy: 99.78427124023438
      policy_loss: 16.712800979614258
      var_gnorm: 21.696733474731445
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 116.26021575927734
    num_steps_sampled: 1650000
    num_steps_trained: 1650000
    wait_time_ms: 446.288
  iterations_since_restore: 55
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 2471.2635724544525
  time_this_iter_s: 45.158464670181274
  time_total_s: 2471.2635724544525
  timestamp: 1594154642
  timesteps_since_restore: 1650000
  timesteps_this_iter: 30000
  timesteps_total: 1650000
  training_iteration: 55
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 2471 s, 55 iter, 1650000 ts, -1.2e+05 rew

agent-1: 51.0
agent-2: 70.0
agent-3: 25.0
agent-4: 67.0
agent-5: 61.0
agent-6: 55.0
agent-7: 40.0
agent-8: 35.0
agent-9: 44.0
agent-10: 31.0
agent-11: 49.0
agent-12: 36.0
agent-13: 35.0
agent-14: 31.0
agent-15: 35.0
agent-16: 33.0
agent-17: 41.0
agent-18: 37.0
agent-19: 54.0
agent-20: 53.0
agent-21: 51.0
agent-22: 85.0
agent-23: 76.0
agent-24: 43.0
agent-25: 56.0
agent-26: 32.0
agent-27: 42.0
agent-28: 77.0
agent-29: 36.0
agent-30: 31.0
Sum Reward: 1412.0
Avg Reward: 47.06666666666667
Min Reward: 25.0
Max Reward: 85.0
Gini Coefficient: 0.18059490084985835
20:20 Ratio: 2.3825136612021858
Max-min Ratio: 3.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-44-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -117619.27272727272
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 55
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.401
    dispatch_time_ms: 24.614
    learner:
      cur_lr: 0.0012501099845394492
      grad_gnorm: 40.0
      policy_entropy: 75.40229034423828
      policy_loss: -17.414995193481445
      var_gnorm: 21.701013565063477
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 16.991849899291992
    num_steps_sampled: 1680000
    num_steps_trained: 1680000
    wait_time_ms: 422.43
  iterations_since_restore: 56
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 2516.3311579227448
  time_this_iter_s: 45.067585468292236
  time_total_s: 2516.3311579227448
  timestamp: 1594154688
  timesteps_since_restore: 1680000
  timesteps_this_iter: 30000
  timesteps_total: 1680000
  training_iteration: 56
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 2516 s, 56 iter, 1680000 ts, -1.18e+05 rew

agent-1: 40.0
agent-2: 38.0
agent-3: 31.0
agent-4: 61.0
agent-5: 44.0
agent-6: 50.0
agent-7: 39.0
agent-8: 53.0
agent-9: 37.0
agent-10: 59.0
agent-11: 41.0
agent-12: 22.0
agent-13: 43.0
agent-14: 36.0
agent-15: 53.0
agent-16: 44.0
agent-17: 51.0
agent-18: 51.0
agent-19: 51.0
agent-20: 45.0
agent-21: 54.0
agent-22: 39.0
agent-23: 86.0
agent-24: 46.0
agent-25: 51.0
agent-26: 40.0
agent-27: 27.0
agent-28: 34.0
agent-29: 33.0
agent-30: 60.0
Sum Reward: 1359.0
Avg Reward: 45.3
Min Reward: 22.0
Max Reward: 86.0
Gini Coefficient: 0.14213882756929114
20:20 Ratio: 2.0382513661202184
Max-min Ratio: 3.909090909090909
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-45-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -115494.66071428571
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 56
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.552
    dispatch_time_ms: 33.958
    learner:
      cur_lr: 0.0012481119483709335
      grad_gnorm: 40.0
      policy_entropy: 105.31998443603516
      policy_loss: -20.78915786743164
      var_gnorm: 21.704708099365234
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 13.122897148132324
    num_steps_sampled: 1710000
    num_steps_trained: 1710000
    wait_time_ms: 395.299
  iterations_since_restore: 57
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 2560.903960466385
  time_this_iter_s: 44.57280254364014
  time_total_s: 2560.903960466385
  timestamp: 1594154732
  timesteps_since_restore: 1710000
  timesteps_this_iter: 30000
  timesteps_total: 1710000
  training_iteration: 57
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 2560 s, 57 iter, 1710000 ts, -1.15e+05 rew

agent-1: 31.0
agent-2: 29.0
agent-3: 42.0
agent-4: 45.0
agent-5: 20.0
agent-6: 40.0
agent-7: 46.0
agent-8: 51.0
agent-9: 40.0
agent-10: 38.0
agent-11: 60.0
agent-12: 21.0
agent-13: 41.0
agent-14: 57.0
agent-15: 53.0
agent-16: 41.0
agent-17: 39.0
agent-18: 57.0
agent-19: 60.0
agent-20: 71.0
agent-21: 52.0
agent-22: 43.0
agent-23: 48.0
agent-24: 51.0
agent-25: 39.0
agent-26: 41.0
agent-27: 48.0
agent-28: 17.0
agent-29: 51.0
agent-30: 51.0
Sum Reward: 1323.0
Avg Reward: 44.1
Min Reward: 17.0
Max Reward: 71.0
Gini Coefficient: 0.14988662131519273
20:20 Ratio: 2.2948717948717947
Max-min Ratio: 4.176470588235294
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-46-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -113445.22807017544
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 57
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.649
    dispatch_time_ms: 30.623
    learner:
      cur_lr: 0.0012461140286177397
      grad_gnorm: 31.86956024169922
      policy_entropy: 84.02650451660156
      policy_loss: 1.1634364128112793
      var_gnorm: 21.702428817749023
      vf_explained_var: 0.0
      vf_loss: 76.56121063232422
    num_steps_sampled: 1740000
    num_steps_trained: 1740000
    wait_time_ms: 400.731
  iterations_since_restore: 58
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 2606.2650756835938
  time_this_iter_s: 45.36111521720886
  time_total_s: 2606.2650756835938
  timestamp: 1594154778
  timesteps_since_restore: 1740000
  timesteps_this_iter: 30000
  timesteps_total: 1740000
  training_iteration: 58
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 2606 s, 58 iter, 1740000 ts, -1.13e+05 rew

agent-1: 65.0
agent-2: 44.0
agent-3: 35.0
agent-4: 61.0
agent-5: 57.0
agent-6: 45.0
agent-7: 34.0
agent-8: 65.0
agent-9: 40.0
agent-10: 15.0
agent-11: 64.0
agent-12: 40.0
agent-13: 43.0
agent-14: 49.0
agent-15: 19.0
agent-16: 66.0
agent-17: 37.0
agent-18: 50.0
agent-19: 23.0
agent-20: 74.0
agent-21: 25.0
agent-22: 53.0
agent-23: 35.0
agent-24: 49.0
agent-25: 40.0
agent-26: 36.0
agent-27: 61.0
agent-28: 54.0
agent-29: 57.0
agent-30: 43.0
Sum Reward: 1379.0
Avg Reward: 45.96666666666667
Min Reward: 15.0
Max Reward: 74.0
Gini Coefficient: 0.18083152042542905
20:20 Ratio: 2.615894039735099
Max-min Ratio: 4.933333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-47-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -111465.5
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 58
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.972
    dispatch_time_ms: 26.662
    learner:
      cur_lr: 0.001244115992449224
      grad_gnorm: 15.407013893127441
      policy_entropy: 113.92366790771484
      policy_loss: 3.6210312843322754
      var_gnorm: 21.70802116394043
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 60.74056625366211
    num_steps_sampled: 1770000
    num_steps_trained: 1770000
    wait_time_ms: 425.23
  iterations_since_restore: 59
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 2651.0780239105225
  time_this_iter_s: 44.81294822692871
  time_total_s: 2651.0780239105225
  timestamp: 1594154822
  timesteps_since_restore: 1770000
  timesteps_this_iter: 30000
  timesteps_total: 1770000
  training_iteration: 59
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 2651 s, 59 iter, 1770000 ts, -1.11e+05 rew

agent-1: 59.0
agent-2: 64.0
agent-3: 29.0
agent-4: 29.0
agent-5: 50.0
agent-6: 36.0
agent-7: 70.0
agent-8: 47.0
agent-9: 50.0
agent-10: 79.0
agent-11: 34.0
agent-12: 74.0
agent-13: 57.0
agent-14: 28.0
agent-15: 96.0
agent-16: 40.0
agent-17: 64.0
agent-18: 55.0
agent-19: 65.0
agent-20: 34.0
agent-21: 53.0
agent-22: 66.0
agent-23: 49.0
agent-24: 47.0
agent-25: 70.0
agent-26: 23.0
agent-27: 43.0
agent-28: 38.0
agent-29: 36.0
agent-30: 71.0
Sum Reward: 1556.0
Avg Reward: 51.86666666666667
Min Reward: 23.0
Max Reward: 96.0
Gini Coefficient: 0.18933161953727506
20:20 Ratio: 2.598870056497175
Max-min Ratio: 4.173913043478261
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-47-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -109549.8813559322
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 59
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.821
    dispatch_time_ms: 42.529
    learner:
      cur_lr: 0.0012421179562807083
      grad_gnorm: 40.0
      policy_entropy: 118.83175659179688
      policy_loss: 5.235572814941406
      var_gnorm: 21.707748413085938
      vf_explained_var: 0.0
      vf_loss: 85.72483825683594
    num_steps_sampled: 1800000
    num_steps_trained: 1800000
    wait_time_ms: 402.087
  iterations_since_restore: 60
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 2696.3047711849213
  time_this_iter_s: 45.226747274398804
  time_total_s: 2696.3047711849213
  timestamp: 1594154868
  timesteps_since_restore: 1800000
  timesteps_this_iter: 30000
  timesteps_total: 1800000
  training_iteration: 60
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 2696 s, 60 iter, 1800000 ts, -1.1e+05 rew

agent-1: 48.0
agent-2: 33.0
agent-3: 13.0
agent-4: 26.0
agent-5: 15.0
agent-6: 47.0
agent-7: 43.0
agent-8: 44.0
agent-9: 45.0
agent-10: 26.0
agent-11: 50.0
agent-12: 33.0
agent-13: 36.0
agent-14: 41.0
agent-15: 39.0
agent-16: 26.0
agent-17: 53.0
agent-18: 29.0
agent-19: 36.0
agent-20: 34.0
agent-21: 60.0
agent-22: 43.0
agent-23: 53.0
agent-24: 45.0
agent-25: 59.0
agent-26: 33.0
agent-27: 21.0
agent-28: 28.0
agent-29: 52.0
agent-30: 20.0
Sum Reward: 1131.0
Avg Reward: 37.7
Min Reward: 13.0
Max Reward: 60.0
Gini Coefficient: 0.1870026525198939
20:20 Ratio: 2.7024793388429753
Max-min Ratio: 4.615384615384615
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-48-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -107705.2
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 60
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.657
    dispatch_time_ms: 34.143
    learner:
      cur_lr: 0.0012401200365275145
      grad_gnorm: 40.0
      policy_entropy: 117.693603515625
      policy_loss: -14.416234970092773
      var_gnorm: 21.70168685913086
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 18.828380584716797
    num_steps_sampled: 1830000
    num_steps_trained: 1830000
    wait_time_ms: 415.951
  iterations_since_restore: 61
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 2741.6859323978424
  time_this_iter_s: 45.38116121292114
  time_total_s: 2741.6859323978424
  timestamp: 1594154913
  timesteps_since_restore: 1830000
  timesteps_this_iter: 30000
  timesteps_total: 1830000
  training_iteration: 61
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 2741 s, 61 iter, 1830000 ts, -1.08e+05 rew

agent-1: 72.0
agent-2: 51.0
agent-3: 39.0
agent-4: 17.0
agent-5: 38.0
agent-6: 27.0
agent-7: 54.0
agent-8: 24.0
agent-9: 50.0
agent-10: 36.0
agent-11: 34.0
agent-12: 46.0
agent-13: 59.0
agent-14: 51.0
agent-15: 18.0
agent-16: 46.0
agent-17: 44.0
agent-18: 42.0
agent-19: 37.0
agent-20: 43.0
agent-21: 63.0
agent-22: 38.0
agent-23: 57.0
agent-24: 46.0
agent-25: 25.0
agent-26: 42.0
agent-27: 41.0
agent-28: 33.0
agent-29: 37.0
agent-30: 57.0
Sum Reward: 1267.0
Avg Reward: 42.233333333333334
Min Reward: 17.0
Max Reward: 72.0
Gini Coefficient: 0.16813996316758748
20:20 Ratio: 2.513888888888889
Max-min Ratio: 4.235294117647059
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-49-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -105918.77049180328
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 61
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.757
    dispatch_time_ms: 22.018
    learner:
      cur_lr: 0.0012381220003589988
      grad_gnorm: 40.000003814697266
      policy_entropy: 146.33673095703125
      policy_loss: -18.378772735595703
      var_gnorm: 21.70150375366211
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 25.8543701171875
    num_steps_sampled: 1860000
    num_steps_trained: 1860000
    wait_time_ms: 412.911
  iterations_since_restore: 62
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 2786.9786908626556
  time_this_iter_s: 45.29275846481323
  time_total_s: 2786.9786908626556
  timestamp: 1594154958
  timesteps_since_restore: 1860000
  timesteps_this_iter: 30000
  timesteps_total: 1860000
  training_iteration: 62
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 2786 s, 62 iter, 1860000 ts, -1.06e+05 rew

agent-1: 31.0
agent-2: 25.0
agent-3: 54.0
agent-4: 49.0
agent-5: 44.0
agent-6: 12.0
agent-7: 39.0
agent-8: 18.0
agent-9: 49.0
agent-10: 42.0
agent-11: 39.0
agent-12: 35.0
agent-13: 47.0
agent-14: 50.0
agent-15: 47.0
agent-16: 77.0
agent-17: 48.0
agent-18: 49.0
agent-19: 36.0
agent-20: 50.0
agent-21: 44.0
agent-22: 56.0
agent-23: 16.0
agent-24: 46.0
agent-25: 19.0
agent-26: 32.0
agent-27: 26.0
agent-28: 63.0
agent-29: 43.0
agent-30: 31.0
Sum Reward: 1217.0
Avg Reward: 40.56666666666667
Min Reward: 12.0
Max Reward: 77.0
Gini Coefficient: 0.19246781703642837
20:20 Ratio: 3.0172413793103448
Max-min Ratio: 6.416666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-50-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -104190.7741935484
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 62
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.752
    dispatch_time_ms: 23.557
    learner:
      cur_lr: 0.001236123964190483
      grad_gnorm: 40.0
      policy_entropy: 159.2876434326172
      policy_loss: 43.657508850097656
      var_gnorm: 21.70543670654297
      vf_explained_var: 0.0
      vf_loss: 173.3536376953125
    num_steps_sampled: 1890000
    num_steps_trained: 1890000
    wait_time_ms: 417.513
  iterations_since_restore: 63
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 2832.160633087158
  time_this_iter_s: 45.18194222450256
  time_total_s: 2832.160633087158
  timestamp: 1594155004
  timesteps_since_restore: 1890000
  timesteps_this_iter: 30000
  timesteps_total: 1890000
  training_iteration: 63
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 2832 s, 63 iter, 1890000 ts, -1.04e+05 rew

agent-1: 70.0
agent-2: 25.0
agent-3: 42.0
agent-4: 47.0
agent-5: 76.0
agent-6: 71.0
agent-7: 46.0
agent-8: 39.0
agent-9: 51.0
agent-10: 36.0
agent-11: 59.0
agent-12: 23.0
agent-13: 65.0
agent-14: 59.0
agent-15: 52.0
agent-16: 20.0
agent-17: 18.0
agent-18: 46.0
agent-19: 48.0
agent-20: 72.0
agent-21: 26.0
agent-22: 32.0
agent-23: 62.0
agent-24: 56.0
agent-25: 47.0
agent-26: 48.0
agent-27: 70.0
agent-28: 38.0
agent-29: 32.0
agent-30: 59.0
Sum Reward: 1435.0
Avg Reward: 47.833333333333336
Min Reward: 18.0
Max Reward: 76.0
Gini Coefficient: 0.19551684088269455
20:20 Ratio: 2.9444444444444446
Max-min Ratio: 4.222222222222222
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-50-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -102514.1746031746
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 63
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.878
    dispatch_time_ms: 30.786
    learner:
      cur_lr: 0.0012341260444372892
      grad_gnorm: 40.0
      policy_entropy: 257.6717529296875
      policy_loss: -9.242944717407227
      var_gnorm: 21.710933685302734
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 40.74296951293945
    num_steps_sampled: 1920000
    num_steps_trained: 1920000
    wait_time_ms: 442.7
  iterations_since_restore: 64
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 2877.4699878692627
  time_this_iter_s: 45.30935478210449
  time_total_s: 2877.4699878692627
  timestamp: 1594155049
  timesteps_since_restore: 1920000
  timesteps_this_iter: 30000
  timesteps_total: 1920000
  training_iteration: 64
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 2877 s, 64 iter, 1920000 ts, -1.03e+05 rew

agent-1: 47.0
agent-2: 84.0
agent-3: 15.0
agent-4: 47.0
agent-5: 48.0
agent-6: 59.0
agent-7: 41.0
agent-8: 17.0
agent-9: 58.0
agent-10: 42.0
agent-11: 26.0
agent-12: 29.0
agent-13: 40.0
agent-14: 41.0
agent-15: 50.0
agent-16: 35.0
agent-17: 24.0
agent-18: 54.0
agent-19: 24.0
agent-20: 33.0
agent-21: 42.0
agent-22: 63.0
agent-23: 58.0
agent-24: 47.0
agent-25: 28.0
agent-26: 16.0
agent-27: 69.0
agent-28: 56.0
agent-29: 35.0
agent-30: 52.0
Sum Reward: 1280.0
Avg Reward: 42.666666666666664
Min Reward: 15.0
Max Reward: 84.0
Gini Coefficient: 0.21317708333333332
20:20 Ratio: 3.2049180327868854
Max-min Ratio: 5.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-51-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -100892.390625
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 64
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.626
    dispatch_time_ms: 17.412
    learner:
      cur_lr: 0.0012321280082687736
      grad_gnorm: 40.0
      policy_entropy: 140.2996826171875
      policy_loss: -12.477560043334961
      var_gnorm: 21.71080207824707
      vf_explained_var: 0.0002447962760925293
      vf_loss: 1.5467159748077393
    num_steps_sampled: 1950000
    num_steps_trained: 1950000
    wait_time_ms: 427.51
  iterations_since_restore: 65
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 2923.0961921215057
  time_this_iter_s: 45.62620425224304
  time_total_s: 2923.0961921215057
  timestamp: 1594155095
  timesteps_since_restore: 1950000
  timesteps_this_iter: 30000
  timesteps_total: 1950000
  training_iteration: 65
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 2923 s, 65 iter, 1950000 ts, -1.01e+05 rew

agent-1: 29.0
agent-2: 31.0
agent-3: 25.0
agent-4: 32.0
agent-5: 39.0
agent-6: 41.0
agent-7: 28.0
agent-8: 38.0
agent-9: 20.0
agent-10: 5.0
agent-11: 28.0
agent-12: 42.0
agent-13: 37.0
agent-14: 26.0
agent-15: 27.0
agent-16: 34.0
agent-17: 21.0
agent-18: 30.0
agent-19: 42.0
agent-20: 21.0
agent-21: 29.0
agent-22: 45.0
agent-23: 27.0
agent-24: 5.0
agent-25: 31.0
agent-26: 14.0
agent-27: 28.0
agent-28: 53.0
agent-29: 27.0
agent-30: 28.0
Sum Reward: 883.0
Avg Reward: 29.433333333333334
Min Reward: 5.0
Max Reward: 53.0
Gini Coefficient: 0.19037372593431484
20:20 Ratio: 3.046511627906977
Max-min Ratio: 10.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-52-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -99326.61538461539
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 65
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 5.137
    dispatch_time_ms: 39.515
    learner:
      cur_lr: 0.0012301299721002579
      grad_gnorm: 40.0
      policy_entropy: 205.8052215576172
      policy_loss: 35.545387268066406
      var_gnorm: 21.728151321411133
      vf_explained_var: 0.0
      vf_loss: 125.10060119628906
    num_steps_sampled: 1980000
    num_steps_trained: 1980000
    wait_time_ms: 396.619
  iterations_since_restore: 66
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 2968.325424194336
  time_this_iter_s: 45.2292320728302
  time_total_s: 2968.325424194336
  timestamp: 1594155140
  timesteps_since_restore: 1980000
  timesteps_this_iter: 30000
  timesteps_total: 1980000
  training_iteration: 66
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 2968 s, 66 iter, 1980000 ts, -9.93e+04 rew

agent-1: 42.0
agent-2: 54.0
agent-3: 47.0
agent-4: 23.0
agent-5: 24.0
agent-6: 37.0
agent-7: 81.0
agent-8: 50.0
agent-9: 42.0
agent-10: 32.0
agent-11: 33.0
agent-12: 25.0
agent-13: 65.0
agent-14: 49.0
agent-15: 90.0
agent-16: 35.0
agent-17: 54.0
agent-18: 51.0
agent-19: 64.0
agent-20: 56.0
agent-21: 64.0
agent-22: 67.0
agent-23: 37.0
agent-24: 36.0
agent-25: 36.0
agent-26: 54.0
agent-27: 40.0
agent-28: 62.0
agent-29: 27.0
agent-30: 35.0
Sum Reward: 1412.0
Avg Reward: 47.06666666666667
Min Reward: 23.0
Max Reward: 90.0
Gini Coefficient: 0.1935788479697828
20:20 Ratio: 2.6280487804878048
Max-min Ratio: 3.9130434782608696
W0707 16:52:49.881227 10987 client_connection.cc:255] [worker]ProcessMessage with type 1 took 104 ms.
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-53-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -97800.27272727272
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 66
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.822
    dispatch_time_ms: 20.458
    learner:
      cur_lr: 0.001228132052347064
      grad_gnorm: 10.691431999206543
      policy_entropy: 172.86050415039062
      policy_loss: -2.99648380279541
      var_gnorm: 21.733318328857422
      vf_explained_var: 0.0
      vf_loss: 48.61565017700195
    num_steps_sampled: 2010000
    num_steps_trained: 2010000
    wait_time_ms: 425.437
  iterations_since_restore: 67
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 3012.9376657009125
  time_this_iter_s: 44.61224150657654
  time_total_s: 3012.9376657009125
  timestamp: 1594155185
  timesteps_since_restore: 2010000
  timesteps_this_iter: 30000
  timesteps_total: 2010000
  training_iteration: 67
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 3012 s, 67 iter, 2010000 ts, -9.78e+04 rew

agent-1: 40.0
agent-2: 65.0
agent-3: 49.0
agent-4: 31.0
agent-5: 42.0
agent-6: 36.0
agent-7: 26.0
agent-8: 60.0
agent-9: 33.0
agent-10: 57.0
agent-11: 39.0
agent-12: 38.0
agent-13: 35.0
agent-14: 62.0
agent-15: 51.0
agent-16: 32.0
agent-17: 52.0
agent-18: 43.0
agent-19: 52.0
agent-20: 52.0
agent-21: 31.0
agent-22: 69.0
agent-23: 82.0
agent-24: 40.0
agent-25: 29.0
agent-26: 27.0
agent-27: 29.0
agent-28: 45.0
agent-29: 59.0
agent-30: 29.0
Sum Reward: 1335.0
Avg Reward: 44.5
Min Reward: 26.0
Max Reward: 82.0
Gini Coefficient: 0.1755056179775281
20:20 Ratio: 2.3216374269005846
Max-min Ratio: 3.1538461538461537
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-53-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -96320.64179104478
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 67
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.36
    dispatch_time_ms: 6.228
    learner:
      cur_lr: 0.0012261340161785483
      grad_gnorm: 40.0
      policy_entropy: 115.42708587646484
      policy_loss: -23.06963539123535
      var_gnorm: 21.73830795288086
      vf_explained_var: 0.0
      vf_loss: 20.08899688720703
    num_steps_sampled: 2040000
    num_steps_trained: 2040000
    wait_time_ms: 444.056
  iterations_since_restore: 68
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 3057.315445661545
  time_this_iter_s: 44.377779960632324
  time_total_s: 3057.315445661545
  timestamp: 1594155229
  timesteps_since_restore: 2040000
  timesteps_this_iter: 30000
  timesteps_total: 2040000
  training_iteration: 68
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 3057 s, 68 iter, 2040000 ts, -9.63e+04 rew

agent-1: 9.0
agent-2: 51.0
agent-3: 28.0
agent-4: 26.0
agent-5: 49.0
agent-6: 37.0
agent-7: 65.0
agent-8: 55.0
agent-9: 35.0
agent-10: 48.0
agent-11: 29.0
agent-12: 33.0
agent-13: 42.0
agent-14: 61.0
agent-15: 53.0
agent-16: 71.0
agent-17: 54.0
agent-18: 32.0
agent-19: 51.0
agent-20: 44.0
agent-21: 60.0
agent-22: 57.0
agent-23: 49.0
agent-24: 62.0
agent-25: 51.0
agent-26: 45.0
agent-27: 50.0
agent-28: 25.0
agent-29: 19.0
agent-30: 43.0
Sum Reward: 1334.0
Avg Reward: 44.46666666666667
Min Reward: 9.0
Max Reward: 71.0
Gini Coefficient: 0.1811094452773613
20:20 Ratio: 2.764705882352941
Max-min Ratio: 7.888888888888889
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-54-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -94884.54411764706
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 68
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.423
    dispatch_time_ms: 5.652
    learner:
      cur_lr: 0.0012241359800100327
      grad_gnorm: 40.00000762939453
      policy_entropy: 130.2605743408203
      policy_loss: 35.17387008666992
      var_gnorm: 21.975671768188477
      vf_explained_var: 0.0016178488731384277
      vf_loss: 67.02265930175781
    num_steps_sampled: 2070000
    num_steps_trained: 2070000
    wait_time_ms: 429.17
  iterations_since_restore: 69
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 3101.4471006393433
  time_this_iter_s: 44.13165497779846
  time_total_s: 3101.4471006393433
  timestamp: 1594155273
  timesteps_since_restore: 2070000
  timesteps_this_iter: 30000
  timesteps_total: 2070000
  training_iteration: 69
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 3101 s, 69 iter, 2070000 ts, -9.49e+04 rew

agent-1: 22.0
agent-2: 29.0
agent-3: 63.0
agent-4: 46.0
agent-5: 38.0
agent-6: 34.0
agent-7: 54.0
agent-8: 55.0
agent-9: 54.0
agent-10: 34.0
agent-11: 36.0
agent-12: 21.0
agent-13: 39.0
agent-14: 24.0
agent-15: 16.0
agent-16: 44.0
agent-17: 66.0
agent-18: 49.0
agent-19: 42.0
agent-20: 42.0
agent-21: 64.0
agent-22: 31.0
agent-23: 53.0
agent-24: 47.0
agent-25: 52.0
agent-26: 55.0
agent-27: 16.0
agent-28: 33.0
agent-29: 42.0
agent-30: 46.0
Sum Reward: 1247.0
Avg Reward: 41.56666666666667
Min Reward: 16.0
Max Reward: 66.0
Gini Coefficient: 0.18623362737236032
20:20 Ratio: 2.7890625
Max-min Ratio: 4.125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-55-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -93491.33333333333
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 69
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.864
    dispatch_time_ms: 5.723
    learner:
      cur_lr: 0.001222137943841517
      grad_gnorm: 40.0
      policy_entropy: 132.5486297607422
      policy_loss: 7.120826244354248
      var_gnorm: 22.12565803527832
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 105.34870910644531
    num_steps_sampled: 2100000
    num_steps_trained: 2100000
    wait_time_ms: 418.263
  iterations_since_restore: 70
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 3145.2718002796173
  time_this_iter_s: 43.82469964027405
  time_total_s: 3145.2718002796173
  timestamp: 1594155317
  timesteps_since_restore: 2100000
  timesteps_this_iter: 30000
  timesteps_total: 2100000
  training_iteration: 70
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 3145 s, 70 iter, 2100000 ts, -9.35e+04 rew

agent-1: 31.0
agent-2: 63.0
agent-3: 44.0
agent-4: 38.0
agent-5: 32.0
agent-6: 33.0
agent-7: 21.0
agent-8: 65.0
agent-9: 69.0
agent-10: 55.0
agent-11: 65.0
agent-12: 63.0
agent-13: 69.0
agent-14: 39.0
agent-15: 55.0
agent-16: 22.0
agent-17: 42.0
agent-18: 28.0
agent-19: 41.0
agent-20: 28.0
agent-21: 42.0
agent-22: 13.0
agent-23: 26.0
agent-24: 53.0
agent-25: 18.0
agent-26: 52.0
agent-27: 30.0
agent-28: 37.0
agent-29: 44.0
agent-30: 47.0
Sum Reward: 1265.0
Avg Reward: 42.166666666666664
Min Reward: 13.0
Max Reward: 69.0
Gini Coefficient: 0.2130961791831357
20:20 Ratio: 3.078125
Max-min Ratio: 5.3076923076923075
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-56-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -92137.67142857143
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 70
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.901
    dispatch_time_ms: 7.2
    learner:
      cur_lr: 0.0012201400240883231
      grad_gnorm: 40.0
      policy_entropy: 90.81802368164062
      policy_loss: 12.46961498260498
      var_gnorm: 22.172039031982422
      vf_explained_var: -2.8967857360839844e-05
      vf_loss: 26.852216720581055
    num_steps_sampled: 2130000
    num_steps_trained: 2130000
    wait_time_ms: 435.284
  iterations_since_restore: 71
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 3189.1696348190308
  time_this_iter_s: 43.89783453941345
  time_total_s: 3189.1696348190308
  timestamp: 1594155361
  timesteps_since_restore: 2130000
  timesteps_this_iter: 30000
  timesteps_total: 2130000
  training_iteration: 71
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 3189 s, 71 iter, 2130000 ts, -9.21e+04 rew

agent-1: 31.0
agent-2: 24.0
agent-3: 50.0
agent-4: 26.0
agent-5: 47.0
agent-6: 39.0
agent-7: 58.0
agent-8: 39.0
agent-9: 49.0
agent-10: 32.0
agent-11: 22.0
agent-12: 36.0
agent-13: 37.0
agent-14: 66.0
agent-15: 37.0
agent-16: 69.0
agent-17: 20.0
agent-18: 67.0
agent-19: 45.0
agent-20: 32.0
agent-21: 49.0
agent-22: 45.0
agent-23: 45.0
agent-24: 39.0
agent-25: 15.0
agent-26: 17.0
agent-27: 37.0
agent-28: 58.0
agent-29: 51.0
agent-30: 27.0
Sum Reward: 1209.0
Avg Reward: 40.3
Min Reward: 15.0
Max Reward: 69.0
Gini Coefficient: 0.20162668872346293
20:20 Ratio: 2.975806451612903
Max-min Ratio: 4.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-56-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -90822.92957746479
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 71
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.696
    dispatch_time_ms: 7.349
    learner:
      cur_lr: 0.0012181419879198074
      grad_gnorm: 39.999996185302734
      policy_entropy: 106.66407775878906
      policy_loss: 3.7852795124053955
      var_gnorm: 22.24648666381836
      vf_explained_var: 0.0
      vf_loss: 67.46060943603516
    num_steps_sampled: 2160000
    num_steps_trained: 2160000
    wait_time_ms: 434.714
  iterations_since_restore: 72
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 3231.868115901947
  time_this_iter_s: 42.69848108291626
  time_total_s: 3231.868115901947
  timestamp: 1594155404
  timesteps_since_restore: 2160000
  timesteps_this_iter: 30000
  timesteps_total: 2160000
  training_iteration: 72
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 3231 s, 72 iter, 2160000 ts, -9.08e+04 rew

agent-1: 73.0
agent-2: 52.0
agent-3: 45.0
agent-4: 61.0
agent-5: 48.0
agent-6: 49.0
agent-7: 53.0
agent-8: 41.0
agent-9: 53.0
agent-10: 69.0
agent-11: 37.0
agent-12: 48.0
agent-13: 56.0
agent-14: 31.0
agent-15: 97.0
agent-16: 42.0
agent-17: 65.0
agent-18: 70.0
agent-19: 38.0
agent-20: 39.0
agent-21: 63.0
agent-22: 39.0
agent-23: 36.0
agent-24: 42.0
agent-25: 50.0
agent-26: 48.0
agent-27: 55.0
agent-28: 45.0
agent-29: 53.0
agent-30: 68.0
Sum Reward: 1566.0
Avg Reward: 52.2
Min Reward: 31.0
Max Reward: 97.0
Gini Coefficient: 0.1415495955725841
20:20 Ratio: 2.0090909090909093
Max-min Ratio: 3.129032258064516
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-57-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -89539.75
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 72
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.943
    dispatch_time_ms: 7.076
    learner:
      cur_lr: 0.0012161439517512918
      grad_gnorm: 40.0
      policy_entropy: 145.14230346679688
      policy_loss: -17.755414962768555
      var_gnorm: 22.234525680541992
      vf_explained_var: 0.0
      vf_loss: 16.22119140625
    num_steps_sampled: 2190000
    num_steps_trained: 2190000
    wait_time_ms: 417.49
  iterations_since_restore: 73
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 3275.2308661937714
  time_this_iter_s: 43.36275029182434
  time_total_s: 3275.2308661937714
  timestamp: 1594155447
  timesteps_since_restore: 2190000
  timesteps_this_iter: 30000
  timesteps_total: 2190000
  training_iteration: 73
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 3275 s, 73 iter, 2190000 ts, -8.95e+04 rew

agent-1: 42.0
agent-2: 55.0
agent-3: 43.0
agent-4: 50.0
agent-5: 29.0
agent-6: 53.0
agent-7: 77.0
agent-8: 47.0
agent-9: 48.0
agent-10: 45.0
agent-11: 13.0
agent-12: 46.0
agent-13: 66.0
agent-14: 64.0
agent-15: 56.0
agent-16: 38.0
agent-17: 62.0
agent-18: 18.0
agent-19: 11.0
agent-20: 38.0
agent-21: 61.0
agent-22: 45.0
agent-23: 22.0
agent-24: 98.0
agent-25: 51.0
agent-26: 53.0
agent-27: 69.0
agent-28: 34.0
agent-29: 59.0
agent-30: 67.0
Sum Reward: 1460.0
Avg Reward: 48.666666666666664
Min Reward: 11.0
Max Reward: 98.0
Gini Coefficient: 0.21050228310502284
20:20 Ratio: 3.47244094488189
Max-min Ratio: 8.909090909090908
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-58-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -88293.17808219178
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 73
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.933
    dispatch_time_ms: 23.19
    learner:
      cur_lr: 0.001214146031998098
      grad_gnorm: 40.0
      policy_entropy: 196.40463256835938
      policy_loss: 32.66791915893555
      var_gnorm: 22.23519515991211
      vf_explained_var: 0.0
      vf_loss: 80.81420135498047
    num_steps_sampled: 2220000
    num_steps_trained: 2220000
    wait_time_ms: 381.191
  iterations_since_restore: 74
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 3319.623613357544
  time_this_iter_s: 44.39274716377258
  time_total_s: 3319.623613357544
  timestamp: 1594155492
  timesteps_since_restore: 2220000
  timesteps_this_iter: 30000
  timesteps_total: 2220000
  training_iteration: 74
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 3319 s, 74 iter, 2220000 ts, -8.83e+04 rew

agent-1: 27.0
agent-2: 36.0
agent-3: 33.0
agent-4: 34.0
agent-5: 54.0
agent-6: 39.0
agent-7: 56.0
agent-8: 51.0
agent-9: 25.0
agent-10: 30.0
agent-11: 46.0
agent-12: 58.0
agent-13: 35.0
agent-14: 46.0
agent-15: 51.0
agent-16: 34.0
agent-17: 64.0
agent-18: 24.0
agent-19: 43.0
agent-20: 36.0
agent-21: 47.0
agent-22: 62.0
agent-23: 50.0
agent-24: 25.0
agent-25: 25.0
agent-26: 76.0
agent-27: 55.0
agent-28: 28.0
agent-29: 40.0
agent-30: 17.0
Sum Reward: 1247.0
Avg Reward: 41.56666666666667
Min Reward: 17.0
Max Reward: 76.0
Gini Coefficient: 0.18954824913124832
20:20 Ratio: 2.5944055944055946
Max-min Ratio: 4.470588235294118
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-58-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -87083.17567567568
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 74
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.233
    dispatch_time_ms: 27.203
    learner:
      cur_lr: 0.0012121479958295822
      grad_gnorm: 39.999996185302734
      policy_entropy: 148.37013244628906
      policy_loss: -10.664315223693848
      var_gnorm: 22.2407283782959
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 10.969280242919922
    num_steps_sampled: 2250000
    num_steps_trained: 2250000
    wait_time_ms: 407.001
  iterations_since_restore: 75
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 3365.0710232257843
  time_this_iter_s: 45.447409868240356
  time_total_s: 3365.0710232257843
  timestamp: 1594155537
  timesteps_since_restore: 2250000
  timesteps_this_iter: 30000
  timesteps_total: 2250000
  training_iteration: 75
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 3365 s, 75 iter, 2250000 ts, -8.71e+04 rew

agent-1: 52.0
agent-2: 33.0
agent-3: 40.0
agent-4: 52.0
agent-5: 40.0
agent-6: 32.0
agent-7: 36.0
agent-8: 27.0
agent-9: 49.0
agent-10: 65.0
agent-11: 67.0
agent-12: 61.0
agent-13: 34.0
agent-14: 60.0
agent-15: 51.0
agent-16: 58.0
agent-17: 73.0
agent-18: 14.0
agent-19: 36.0
agent-20: 51.0
agent-21: 67.0
agent-22: 40.0
agent-23: 20.0
agent-24: 41.0
agent-25: 54.0
agent-26: 57.0
agent-27: 37.0
agent-28: 56.0
agent-29: 40.0
agent-30: 80.0
Sum Reward: 1423.0
Avg Reward: 47.43333333333333
Min Reward: 14.0
Max Reward: 80.0
Gini Coefficient: 0.18297025064417896
20:20 Ratio: 2.58125
Max-min Ratio: 5.714285714285714
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_16-59-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -85903.09333333334
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 75
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.907
    dispatch_time_ms: 8.155
    learner:
      cur_lr: 0.0012101499596610665
      grad_gnorm: 39.999996185302734
      policy_entropy: 238.9188232421875
      policy_loss: -44.79519271850586
      var_gnorm: 22.248464584350586
      vf_explained_var: 0.0
      vf_loss: 6.671509742736816
    num_steps_sampled: 2280000
    num_steps_trained: 2280000
    wait_time_ms: 440.288
  iterations_since_restore: 76
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 3409.6463680267334
  time_this_iter_s: 44.5753448009491
  time_total_s: 3409.6463680267334
  timestamp: 1594155582
  timesteps_since_restore: 2280000
  timesteps_this_iter: 30000
  timesteps_total: 2280000
  training_iteration: 76
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 3409 s, 76 iter, 2280000 ts, -8.59e+04 rew

agent-1: 19.0
agent-2: 24.0
agent-3: 24.0
agent-4: 53.0
agent-5: 48.0
agent-6: 41.0
agent-7: 47.0
agent-8: 35.0
agent-9: 44.0
agent-10: 57.0
agent-11: 51.0
agent-12: 16.0
agent-13: 22.0
agent-14: 43.0
agent-15: 24.0
agent-16: 17.0
agent-17: 41.0
agent-18: 27.0
agent-19: 63.0
agent-20: 45.0
agent-21: 20.0
agent-22: 20.0
agent-23: 50.0
agent-24: 65.0
agent-25: 25.0
agent-26: 53.0
agent-27: 36.0
agent-28: 21.0
agent-29: 53.0
agent-30: 50.0
Sum Reward: 1134.0
Avg Reward: 37.8
Min Reward: 16.0
Max Reward: 65.0
Gini Coefficient: 0.2218694885361552
20:20 Ratio: 3.0442477876106193
Max-min Ratio: 4.0625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-00-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -84757.86842105263
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 76
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.226
    dispatch_time_ms: 6.386
    learner:
      cur_lr: 0.0012081520399078727
      grad_gnorm: 40.0
      policy_entropy: 216.70022583007812
      policy_loss: 28.83098793029785
      var_gnorm: 22.280122756958008
      vf_explained_var: 0.0
      vf_loss: 56.815574645996094
    num_steps_sampled: 2310000
    num_steps_trained: 2310000
    wait_time_ms: 424.277
  iterations_since_restore: 77
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 3453.7995145320892
  time_this_iter_s: 44.153146505355835
  time_total_s: 3453.7995145320892
  timestamp: 1594155626
  timesteps_since_restore: 2310000
  timesteps_this_iter: 30000
  timesteps_total: 2310000
  training_iteration: 77
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 3453 s, 77 iter, 2310000 ts, -8.48e+04 rew

agent-1: 43.0
agent-2: 49.0
agent-3: 47.0
agent-4: 44.0
agent-5: 21.0
agent-6: 45.0
agent-7: 22.0
agent-8: 34.0
agent-9: 37.0
agent-10: 49.0
agent-11: 29.0
agent-12: 38.0
agent-13: 36.0
agent-14: 25.0
agent-15: 41.0
agent-16: 36.0
agent-17: 31.0
agent-18: 28.0
agent-19: 39.0
agent-20: 43.0
agent-21: 37.0
agent-22: 24.0
agent-23: 38.0
agent-24: 50.0
agent-25: 41.0
agent-26: 39.0
agent-27: 43.0
agent-28: 50.0
agent-29: 16.0
agent-30: 43.0
Sum Reward: 1118.0
Avg Reward: 37.266666666666666
Min Reward: 16.0
Max Reward: 50.0
Gini Coefficient: 0.13559928443649374
20:20 Ratio: 2.1323529411764706
Max-min Ratio: 3.125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-01-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -83642.5974025974
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 77
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.784
    dispatch_time_ms: 5.314
    learner:
      cur_lr: 0.001206154003739357
      grad_gnorm: 25.801559448242188
      policy_entropy: 247.11172485351562
      policy_loss: 3.0356483459472656
      var_gnorm: 22.286945343017578
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 35.22370910644531
    num_steps_sampled: 2340000
    num_steps_trained: 2340000
    wait_time_ms: 403.552
  iterations_since_restore: 78
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 3497.0097219944
  time_this_iter_s: 43.21020746231079
  time_total_s: 3497.0097219944
  timestamp: 1594155669
  timesteps_since_restore: 2340000
  timesteps_this_iter: 30000
  timesteps_total: 2340000
  training_iteration: 78
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 3497 s, 78 iter, 2340000 ts, -8.36e+04 rew

agent-1: 39.0
agent-2: 45.0
agent-3: 26.0
agent-4: 42.0
agent-5: 68.0
agent-6: 42.0
agent-7: 29.0
agent-8: 44.0
agent-9: 33.0
agent-10: 30.0
agent-11: 58.0
agent-12: 50.0
agent-13: 52.0
agent-14: 43.0
agent-15: 28.0
agent-16: 54.0
agent-17: 45.0
agent-18: 43.0
agent-19: 38.0
agent-20: 41.0
agent-21: 17.0
agent-22: 63.0
agent-23: 35.0
agent-24: 43.0
agent-25: 44.0
agent-26: 50.0
agent-27: 51.0
agent-28: 83.0
agent-29: 34.0
agent-30: 20.0
Sum Reward: 1290.0
Avg Reward: 43.0
Min Reward: 17.0
Max Reward: 83.0
Gini Coefficient: 0.1724547803617571
20:20 Ratio: 2.52
Max-min Ratio: 4.882352941176471
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-01-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -82553.71794871795
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 78
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.36
    dispatch_time_ms: 7.093
    learner:
      cur_lr: 0.0012041559675708413
      grad_gnorm: 39.99999237060547
      policy_entropy: 270.0061340332031
      policy_loss: 19.454540252685547
      var_gnorm: 22.294809341430664
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 63.710872650146484
    num_steps_sampled: 2370000
    num_steps_trained: 2370000
    wait_time_ms: 423.782
  iterations_since_restore: 79
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 3540.3680515289307
  time_this_iter_s: 43.35832953453064
  time_total_s: 3540.3680515289307
  timestamp: 1594155713
  timesteps_since_restore: 2370000
  timesteps_this_iter: 30000
  timesteps_total: 2370000
  training_iteration: 79
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 3540 s, 79 iter, 2370000 ts, -8.26e+04 rew

agent-1: 46.0
agent-2: 53.0
agent-3: 25.0
agent-4: 25.0
agent-5: 66.0
agent-6: 64.0
agent-7: 54.0
agent-8: 60.0
agent-9: 33.0
agent-10: 46.0
agent-11: 60.0
agent-12: 20.0
agent-13: 62.0
agent-14: 43.0
agent-15: 43.0
agent-16: 64.0
agent-17: 49.0
agent-18: 45.0
agent-19: 46.0
agent-20: 60.0
agent-21: 75.0
agent-22: 40.0
agent-23: 58.0
agent-24: 54.0
agent-25: 50.0
agent-26: 46.0
agent-27: 55.0
agent-28: 49.0
agent-29: 52.0
agent-30: 32.0
Sum Reward: 1475.0
Avg Reward: 49.166666666666664
Min Reward: 20.0
Max Reward: 75.0
Gini Coefficient: 0.14433898305084747
20:20 Ratio: 2.2342857142857144
Max-min Ratio: 3.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-02-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -81490.06329113925
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 79
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.48
    dispatch_time_ms: 6.816
    learner:
      cur_lr: 0.0012021580478176475
      grad_gnorm: 40.0
      policy_entropy: 259.4432373046875
      policy_loss: -14.246044158935547
      var_gnorm: 22.296470642089844
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 31.747535705566406
    num_steps_sampled: 2400000
    num_steps_trained: 2400000
    wait_time_ms: 448.698
  iterations_since_restore: 80
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 3584.47647690773
  time_this_iter_s: 44.10842537879944
  time_total_s: 3584.47647690773
  timestamp: 1594155757
  timesteps_since_restore: 2400000
  timesteps_this_iter: 30000
  timesteps_total: 2400000
  training_iteration: 80
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 3584 s, 80 iter, 2400000 ts, -8.15e+04 rew

agent-1: 44.0
agent-2: 24.0
agent-3: 45.0
agent-4: 24.0
agent-5: 34.0
agent-6: 22.0
agent-7: 29.0
agent-8: 41.0
agent-9: 27.0
agent-10: 27.0
agent-11: 26.0
agent-12: 18.0
agent-13: 23.0
agent-14: 37.0
agent-15: 39.0
agent-16: 50.0
agent-17: 48.0
agent-18: 16.0
agent-19: 52.0
agent-20: 44.0
agent-21: 55.0
agent-22: 26.0
agent-23: 52.0
agent-24: 46.0
agent-25: 61.0
agent-26: 42.0
agent-27: 37.0
agent-28: 24.0
agent-29: 46.0
agent-30: 41.0
Sum Reward: 1100.0
Avg Reward: 36.666666666666664
Min Reward: 16.0
Max Reward: 61.0
Gini Coefficient: 0.1855757575757576
20:20 Ratio: 2.5039370078740157
Max-min Ratio: 3.8125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-03-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -80457.6875
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 80
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.731
    dispatch_time_ms: 6.699
    learner:
      cur_lr: 0.0012001600116491318
      grad_gnorm: 40.000003814697266
      policy_entropy: 189.1462860107422
      policy_loss: 88.42117309570312
      var_gnorm: 22.294878005981445
      vf_explained_var: 0.0
      vf_loss: 192.7110137939453
    num_steps_sampled: 2430000
    num_steps_trained: 2430000
    wait_time_ms: 394.098
  iterations_since_restore: 81
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 3628.478682756424
  time_this_iter_s: 44.00220584869385
  time_total_s: 3628.478682756424
  timestamp: 1594155801
  timesteps_since_restore: 2430000
  timesteps_this_iter: 30000
  timesteps_total: 2430000
  training_iteration: 81
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 3628 s, 81 iter, 2430000 ts, -8.05e+04 rew

agent-1: 26.0
agent-2: 30.0
agent-3: 24.0
agent-4: 21.0
agent-5: 79.0
agent-6: 40.0
agent-7: 27.0
agent-8: 41.0
agent-9: 42.0
agent-10: 43.0
agent-11: 32.0
agent-12: 25.0
agent-13: 37.0
agent-14: 36.0
agent-15: 20.0
agent-16: 39.0
agent-17: 35.0
agent-18: 29.0
agent-19: 46.0
agent-20: 67.0
agent-21: 28.0
agent-22: 63.0
agent-23: 28.0
agent-24: 52.0
agent-25: 26.0
agent-26: 27.0
agent-27: 69.0
agent-28: 13.0
agent-29: 62.0
agent-30: 41.0
Sum Reward: 1148.0
Avg Reward: 38.266666666666666
Min Reward: 13.0
Max Reward: 79.0
Gini Coefficient: 0.22439024390243903
20:20 Ratio: 3.0387596899224807
Max-min Ratio: 6.076923076923077
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-04-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -79450.20987654322
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 81
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.752
    dispatch_time_ms: 5.628
    learner:
      cur_lr: 0.001198161975480616
      grad_gnorm: 40.0
      policy_entropy: 286.43878173828125
      policy_loss: -46.32123947143555
      var_gnorm: 22.296531677246094
      vf_explained_var: 0.0
      vf_loss: 10.405518531799316
    num_steps_sampled: 2460000
    num_steps_trained: 2460000
    wait_time_ms: 453.676
  iterations_since_restore: 82
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 3672.333370447159
  time_this_iter_s: 43.85468769073486
  time_total_s: 3672.333370447159
  timestamp: 1594155845
  timesteps_since_restore: 2460000
  timesteps_this_iter: 30000
  timesteps_total: 2460000
  training_iteration: 82
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 3672 s, 82 iter, 2460000 ts, -7.95e+04 rew

agent-1: 66.0
agent-2: 28.0
agent-3: 28.0
agent-4: 65.0
agent-5: 23.0
agent-6: 28.0
agent-7: 16.0
agent-8: 35.0
agent-9: 29.0
agent-10: 20.0
agent-11: 37.0
agent-12: 15.0
agent-13: 49.0
agent-14: 52.0
agent-15: 41.0
agent-16: 37.0
agent-17: 49.0
agent-18: 39.0
agent-19: 39.0
agent-20: 35.0
agent-21: 22.0
agent-22: 75.0
agent-23: 31.0
agent-24: 32.0
agent-25: 23.0
agent-26: 31.0
agent-27: 45.0
agent-28: 45.0
agent-29: 7.0
agent-30: 38.0
Sum Reward: 1080.0
Avg Reward: 36.0
Min Reward: 7.0
Max Reward: 75.0
Gini Coefficient: 0.230679012345679
20:20 Ratio: 3.4563106796116503
Max-min Ratio: 10.714285714285714
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-04-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -78468.13414634146
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 82
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.573
    dispatch_time_ms: 6.419
    learner:
      cur_lr: 0.0011961640557274222
      grad_gnorm: 40.00000762939453
      policy_entropy: 261.8381042480469
      policy_loss: -6.307279109954834
      var_gnorm: 22.289880752563477
      vf_explained_var: 0.0
      vf_loss: 13.636005401611328
    num_steps_sampled: 2490000
    num_steps_trained: 2490000
    wait_time_ms: 445.666
  iterations_since_restore: 83
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 3717.288028717041
  time_this_iter_s: 44.9546582698822
  time_total_s: 3717.288028717041
  timestamp: 1594155890
  timesteps_since_restore: 2490000
  timesteps_this_iter: 30000
  timesteps_total: 2490000
  training_iteration: 83
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 3717 s, 83 iter, 2490000 ts, -7.85e+04 rew

agent-1: 31.0
agent-2: 26.0
agent-3: 49.0
agent-4: 42.0
agent-5: 28.0
agent-6: 24.0
agent-7: 10.0
agent-8: 48.0
agent-9: 36.0
agent-10: 36.0
agent-11: 23.0
agent-12: 34.0
agent-13: 22.0
agent-14: 16.0
agent-15: 24.0
agent-16: 37.0
agent-17: 20.0
agent-18: 72.0
agent-19: 43.0
agent-20: 25.0
agent-21: 47.0
agent-22: 34.0
agent-23: 47.0
agent-24: 42.0
agent-25: 49.0
agent-26: 50.0
agent-27: 47.0
agent-28: 82.0
agent-29: 36.0
agent-30: 56.0
Sum Reward: 1136.0
Avg Reward: 37.86666666666667
Min Reward: 10.0
Max Reward: 82.0
Gini Coefficient: 0.22276995305164318
20:20 Ratio: 3.1130434782608694
Max-min Ratio: 8.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-05-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -77509.04819277108
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 83
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.692
    dispatch_time_ms: 6.488
    learner:
      cur_lr: 0.0011941660195589066
      grad_gnorm: 40.0
      policy_entropy: 299.1199951171875
      policy_loss: 47.12370681762695
      var_gnorm: 22.29667091369629
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 93.90926361083984
    num_steps_sampled: 2520000
    num_steps_trained: 2520000
    wait_time_ms: 434.388
  iterations_since_restore: 84
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 3761.077407360077
  time_this_iter_s: 43.78937864303589
  time_total_s: 3761.077407360077
  timestamp: 1594155934
  timesteps_since_restore: 2520000
  timesteps_this_iter: 30000
  timesteps_total: 2520000
  training_iteration: 84
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 3761 s, 84 iter, 2520000 ts, -7.75e+04 rew

agent-1: 34.0
agent-2: 55.0
agent-3: 30.0
agent-4: 52.0
agent-5: 20.0
agent-6: 21.0
agent-7: 23.0
agent-8: 20.0
agent-9: 35.0
agent-10: 40.0
agent-11: 32.0
agent-12: 17.0
agent-13: 38.0
agent-14: 26.0
agent-15: 47.0
agent-16: 13.0
agent-17: 23.0
agent-18: 41.0
agent-19: 43.0
agent-20: 26.0
agent-21: 60.0
agent-22: 23.0
agent-23: 31.0
agent-24: 31.0
agent-25: 40.0
agent-26: 25.0
agent-27: 54.0
agent-28: 22.0
agent-29: 30.0
agent-30: 14.0
Sum Reward: 966.0
Avg Reward: 32.2
Min Reward: 13.0
Max Reward: 60.0
Gini Coefficient: 0.21601104209799862
20:20 Ratio: 2.961904761904762
Max-min Ratio: 4.615384615384615
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-06-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -76574.82142857143
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 84
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.739
    dispatch_time_ms: 7.765
    learner:
      cur_lr: 0.0011921679833903909
      grad_gnorm: 40.00003433227539
      policy_entropy: 273.6221923828125
      policy_loss: 2.375136375427246
      var_gnorm: 22.289417266845703
      vf_explained_var: -0.6973191499710083
      vf_loss: 6.109109878540039
    num_steps_sampled: 2550000
    num_steps_trained: 2550000
    wait_time_ms: 435.907
  iterations_since_restore: 85
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 3806.458877325058
  time_this_iter_s: 45.38146996498108
  time_total_s: 3806.458877325058
  timestamp: 1594155979
  timesteps_since_restore: 2550000
  timesteps_this_iter: 30000
  timesteps_total: 2550000
  training_iteration: 85
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 3806 s, 85 iter, 2550000 ts, -7.66e+04 rew

agent-1: 21.0
agent-2: 52.0
agent-3: 43.0
agent-4: 35.0
agent-5: 25.0
agent-6: 20.0
agent-7: 34.0
agent-8: 15.0
agent-9: 25.0
agent-10: 37.0
agent-11: 47.0
agent-12: 10.0
agent-13: 32.0
agent-14: 28.0
agent-15: 39.0
agent-16: 32.0
agent-17: 42.0
agent-18: 59.0
agent-19: 30.0
agent-20: 65.0
agent-21: 26.0
agent-22: 38.0
agent-23: 8.0
agent-24: 30.0
agent-25: 31.0
agent-26: 22.0
agent-27: 19.0
agent-28: 28.0
agent-29: 24.0
agent-30: 36.0
Sum Reward: 953.0
Avg Reward: 31.766666666666666
Min Reward: 8.0
Max Reward: 65.0
Gini Coefficient: 0.22221056313396292
20:20 Ratio: 3.3118279569892475
Max-min Ratio: 8.125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-07-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -75662.72941176471
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 85
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.45
    dispatch_time_ms: 6.122
    learner:
      cur_lr: 0.0011901699472218752
      grad_gnorm: 29.800979614257812
      policy_entropy: 263.09283447265625
      policy_loss: 8.265811920166016
      var_gnorm: 22.301069259643555
      vf_explained_var: 0.0
      vf_loss: 32.45562744140625
    num_steps_sampled: 2580000
    num_steps_trained: 2580000
    wait_time_ms: 442.682
  iterations_since_restore: 86
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 3851.1455039978027
  time_this_iter_s: 44.68662667274475
  time_total_s: 3851.1455039978027
  timestamp: 1594156024
  timesteps_since_restore: 2580000
  timesteps_this_iter: 30000
  timesteps_total: 2580000
  training_iteration: 86
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 3851 s, 86 iter, 2580000 ts, -7.57e+04 rew

agent-1: 35.0
agent-2: 17.0
agent-3: 15.0
agent-4: 31.0
agent-5: 27.0
agent-6: 7.0
agent-7: 9.0
agent-8: 10.0
agent-9: 25.0
agent-10: 27.0
agent-11: 18.0
agent-12: 41.0
agent-13: 30.0
agent-14: 60.0
agent-15: 38.0
agent-16: 22.0
agent-17: 24.0
agent-18: 30.0
agent-19: 47.0
agent-20: 27.0
agent-21: 15.0
agent-22: 21.0
agent-23: 16.0
agent-24: 11.0
agent-25: 30.0
agent-26: 7.0
agent-27: 36.0
agent-28: 42.0
agent-29: 28.0
agent-30: 56.0
Sum Reward: 802.0
Avg Reward: 26.733333333333334
Min Reward: 7.0
Max Reward: 60.0
Gini Coefficient: 0.2798004987531172
20:20 Ratio: 4.813559322033898
Max-min Ratio: 8.571428571428571
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-07-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -74773.6046511628
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 86
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.545
    dispatch_time_ms: 7.553
    learner:
      cur_lr: 0.0011881720274686813
      grad_gnorm: 16.643417358398438
      policy_entropy: 285.0272521972656
      policy_loss: -3.4146018028259277
      var_gnorm: 22.307147979736328
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 0.06434149295091629
    num_steps_sampled: 2610000
    num_steps_trained: 2610000
    wait_time_ms: 435.786
  iterations_since_restore: 87
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 3896.389703273773
  time_this_iter_s: 45.24419927597046
  time_total_s: 3896.389703273773
  timestamp: 1594156069
  timesteps_since_restore: 2610000
  timesteps_this_iter: 30000
  timesteps_total: 2610000
  training_iteration: 87
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 3896 s, 87 iter, 2610000 ts, -7.48e+04 rew

agent-1: 40.0
agent-2: 36.0
agent-3: 30.0
agent-4: 36.0
agent-5: 38.0
agent-6: 28.0
agent-7: 36.0
agent-8: 30.0
agent-9: 48.0
agent-10: 10.0
agent-11: 28.0
agent-12: 19.0
agent-13: 34.0
agent-14: 38.0
agent-15: 11.0
agent-16: 40.0
agent-17: 38.0
agent-18: 25.0
agent-19: 23.0
agent-20: 31.0
agent-21: 50.0
agent-22: 40.0
agent-23: 27.0
agent-24: 4.0
agent-25: 23.0
agent-26: 40.0
agent-27: 35.0
agent-28: 14.0
agent-29: 26.0
agent-30: 35.0
Sum Reward: 913.0
Avg Reward: 30.433333333333334
Min Reward: 4.0
Max Reward: 50.0
Gini Coefficient: 0.19434100036509674
20:20 Ratio: 3.185185185185185
Max-min Ratio: 12.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-08-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -73903.64367816092
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 87
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.658
    dispatch_time_ms: 6.016
    learner:
      cur_lr: 0.0011861739913001657
      grad_gnorm: 23.065275192260742
      policy_entropy: 262.17315673828125
      policy_loss: -10.092101097106934
      var_gnorm: 22.35959815979004
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 28.151180267333984
    num_steps_sampled: 2640000
    num_steps_trained: 2640000
    wait_time_ms: 439.66
  iterations_since_restore: 88
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 3940.3069994449615
  time_this_iter_s: 43.917296171188354
  time_total_s: 3940.3069994449615
  timestamp: 1594156113
  timesteps_since_restore: 2640000
  timesteps_this_iter: 30000
  timesteps_total: 2640000
  training_iteration: 88
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 3940 s, 88 iter, 2640000 ts, -7.39e+04 rew

agent-1: 39.0
agent-2: 41.0
agent-3: 37.0
agent-4: 47.0
agent-5: 28.0
agent-6: 36.0
agent-7: 26.0
agent-8: 60.0
agent-9: 56.0
agent-10: 30.0
agent-11: 42.0
agent-12: 32.0
agent-13: 42.0
agent-14: 31.0
agent-15: 25.0
agent-16: 51.0
agent-17: 47.0
agent-18: 43.0
agent-19: 35.0
agent-20: 25.0
agent-21: 38.0
agent-22: 60.0
agent-23: 37.0
agent-24: 21.0
agent-25: 24.0
agent-26: 45.0
agent-27: 34.0
agent-28: 38.0
agent-29: 39.0
agent-30: 45.0
Sum Reward: 1154.0
Avg Reward: 38.46666666666667
Min Reward: 21.0
Max Reward: 60.0
Gini Coefficient: 0.14696707105719237
20:20 Ratio: 2.1543624161073827
Max-min Ratio: 2.857142857142857
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-09-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -73050.71590909091
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 88
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.438
    dispatch_time_ms: 6.742
    learner:
      cur_lr: 0.00118417595513165
      grad_gnorm: 39.999996185302734
      policy_entropy: 214.71920776367188
      policy_loss: -17.96289825439453
      var_gnorm: 22.359384536743164
      vf_explained_var: 0.0
      vf_loss: 4.165787696838379
    num_steps_sampled: 2670000
    num_steps_trained: 2670000
    wait_time_ms: 425.182
  iterations_since_restore: 89
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 3984.537659406662
  time_this_iter_s: 44.23065996170044
  time_total_s: 3984.537659406662
  timestamp: 1594156157
  timesteps_since_restore: 2670000
  timesteps_this_iter: 30000
  timesteps_total: 2670000
  training_iteration: 89
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 3984 s, 89 iter, 2670000 ts, -7.31e+04 rew

agent-1: 34.0
agent-2: 35.0
agent-3: 37.0
agent-4: 29.0
agent-5: 30.0
agent-6: 35.0
agent-7: 41.0
agent-8: 54.0
agent-9: 34.0
agent-10: -20.0
agent-11: 24.0
agent-12: 14.0
agent-13: 54.0
agent-14: 31.0
agent-15: 56.0
agent-16: 42.0
agent-17: 24.0
agent-18: 37.0
agent-19: 59.0
agent-20: 54.0
agent-21: 27.0
agent-22: 63.0
agent-23: 45.0
agent-24: 41.0
agent-25: 32.0
agent-26: 59.0
agent-27: 57.0
agent-28: 51.0
agent-29: 44.0
agent-30: 56.0
Sum Reward: 1179.0
Avg Reward: 39.3
Min Reward: -20.0
Max Reward: 63.0
Gini Coefficient: 0.221006502685892
20:20 Ratio: 3.5714285714285716
Max-min Ratio: -3.15
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-10-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -72216.67415730337
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 89
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.76
    dispatch_time_ms: 6.183
    learner:
      cur_lr: 0.0011821780353784561
      grad_gnorm: 40.000003814697266
      policy_entropy: 263.5472717285156
      policy_loss: 52.296852111816406
      var_gnorm: 22.367050170898438
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 141.85694885253906
    num_steps_sampled: 2700000
    num_steps_trained: 2700000
    wait_time_ms: 432.044
  iterations_since_restore: 90
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 4027.9409992694855
  time_this_iter_s: 43.403339862823486
  time_total_s: 4027.9409992694855
  timestamp: 1594156201
  timesteps_since_restore: 2700000
  timesteps_this_iter: 30000
  timesteps_total: 2700000
  training_iteration: 90
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 4027 s, 90 iter, 2700000 ts, -7.22e+04 rew

agent-1: 45.0
agent-2: 36.0
agent-3: 24.0
agent-4: 38.0
agent-5: 30.0
agent-6: 27.0
agent-7: 42.0
agent-8: 53.0
agent-9: 33.0
agent-10: 62.0
agent-11: 31.0
agent-12: 30.0
agent-13: 41.0
agent-14: 74.0
agent-15: 33.0
agent-16: 40.0
agent-17: 48.0
agent-18: 31.0
agent-19: 51.0
agent-20: 42.0
agent-21: 25.0
agent-22: 47.0
agent-23: 57.0
agent-24: 48.0
agent-25: 25.0
agent-26: 29.0
agent-27: 34.0
agent-28: 42.0
agent-29: 38.0
agent-30: 61.0
Sum Reward: 1217.0
Avg Reward: 40.56666666666667
Min Reward: 24.0
Max Reward: 74.0
Gini Coefficient: 0.16491372226787182
20:20 Ratio: 2.2375
Max-min Ratio: 3.0833333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-10-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -71400.74444444444
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 90
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.621
    dispatch_time_ms: 7.534
    learner:
      cur_lr: 0.0011801799992099404
      grad_gnorm: 40.000003814697266
      policy_entropy: 278.938720703125
      policy_loss: 143.6521759033203
      var_gnorm: 22.60181999206543
      vf_explained_var: 0.0
      vf_loss: 202.69622802734375
    num_steps_sampled: 2730000
    num_steps_trained: 2730000
    wait_time_ms: 391.163
  iterations_since_restore: 91
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 4072.864731311798
  time_this_iter_s: 44.92373204231262
  time_total_s: 4072.864731311798
  timestamp: 1594156246
  timesteps_since_restore: 2730000
  timesteps_this_iter: 30000
  timesteps_total: 2730000
  training_iteration: 91
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 4072 s, 91 iter, 2730000 ts, -7.14e+04 rew

agent-1: 32.0
agent-2: 47.0
agent-3: 55.0
agent-4: 35.0
agent-5: 23.0
agent-6: 38.0
agent-7: 46.0
agent-8: 44.0
agent-9: 17.0
agent-10: 42.0
agent-11: 45.0
agent-12: 45.0
agent-13: 41.0
agent-14: 26.0
agent-15: 23.0
agent-16: 56.0
agent-17: 21.0
agent-18: 35.0
agent-19: 55.0
agent-20: 18.0
agent-21: 28.0
agent-22: 31.0
agent-23: 23.0
agent-24: 47.0
agent-25: 39.0
agent-26: 54.0
agent-27: 51.0
agent-28: 45.0
agent-29: 43.0
agent-30: 43.0
Sum Reward: 1148.0
Avg Reward: 38.266666666666666
Min Reward: 17.0
Max Reward: 56.0
Gini Coefficient: 0.17073170731707318
20:20 Ratio: 2.544
Max-min Ratio: 3.2941176470588234
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-11-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -70603.5054945055
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 91
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.053
    dispatch_time_ms: 11.656
    learner:
      cur_lr: 0.0011781819630414248
      grad_gnorm: 40.0
      policy_entropy: 124.6398696899414
      policy_loss: -20.92597198486328
      var_gnorm: 22.629343032836914
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 27.144235610961914
    num_steps_sampled: 2760000
    num_steps_trained: 2760000
    wait_time_ms: 431.957
  iterations_since_restore: 92
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 4116.300084590912
  time_this_iter_s: 43.43535327911377
  time_total_s: 4116.300084590912
  timestamp: 1594156289
  timesteps_since_restore: 2760000
  timesteps_this_iter: 30000
  timesteps_total: 2760000
  training_iteration: 92
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 4116 s, 92 iter, 2760000 ts, -7.06e+04 rew

agent-1: 38.0
agent-2: 36.0
agent-3: 52.0
agent-4: 11.0
agent-5: 40.0
agent-6: 53.0
agent-7: 49.0
agent-8: 41.0
agent-9: 50.0
agent-10: 48.0
agent-11: 29.0
agent-12: 32.0
agent-13: 40.0
agent-14: 47.0
agent-15: 35.0
agent-16: 58.0
agent-17: 20.0
agent-18: 54.0
agent-19: 47.0
agent-20: 60.0
agent-21: 60.0
agent-22: 22.0
agent-23: 40.0
agent-24: 47.0
agent-25: 39.0
agent-26: 34.0
agent-27: 33.0
agent-28: 67.0
agent-29: 43.0
agent-30: 50.0
Sum Reward: 1275.0
Avg Reward: 42.5
Min Reward: 11.0
Max Reward: 67.0
Gini Coefficient: 0.16169934640522876
20:20 Ratio: 2.3945578231292517
Max-min Ratio: 6.090909090909091
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-12-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -69822.21739130435
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 92
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.532
    dispatch_time_ms: 7.072
    learner:
      cur_lr: 0.001176184043288231
      grad_gnorm: 40.0
      policy_entropy: 138.20248413085938
      policy_loss: 79.50533294677734
      var_gnorm: 22.61865234375
      vf_explained_var: 0.0
      vf_loss: 161.79251098632812
    num_steps_sampled: 2790000
    num_steps_trained: 2790000
    wait_time_ms: 391.624
  iterations_since_restore: 93
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 4160.640953779221
  time_this_iter_s: 44.340869188308716
  time_total_s: 4160.640953779221
  timestamp: 1594156333
  timesteps_since_restore: 2790000
  timesteps_this_iter: 30000
  timesteps_total: 2790000
  training_iteration: 93
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 4160 s, 93 iter, 2790000 ts, -6.98e+04 rew

agent-1: 62.0
agent-2: 26.0
agent-3: 61.0
agent-4: 53.0
agent-5: 72.0
agent-6: 29.0
agent-7: 43.0
agent-8: 52.0
agent-9: 31.0
agent-10: 39.0
agent-11: 57.0
agent-12: 50.0
agent-13: 33.0
agent-14: 28.0
agent-15: 49.0
agent-16: 40.0
agent-17: 32.0
agent-18: 45.0
agent-19: 48.0
agent-20: 59.0
agent-21: 68.0
agent-22: 65.0
agent-23: 22.0
agent-24: 50.0
agent-25: 61.0
agent-26: 64.0
agent-27: 43.0
agent-28: 35.0
agent-29: 32.0
agent-30: 34.0
Sum Reward: 1383.0
Avg Reward: 46.1
Min Reward: 22.0
Max Reward: 72.0
Gini Coefficient: 0.17206555796577488
20:20 Ratio: 2.3333333333333335
Max-min Ratio: 3.272727272727273
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-12-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -69056.56989247311
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 93
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.253
    dispatch_time_ms: 6.798
    learner:
      cur_lr: 0.0011741860071197152
      grad_gnorm: 15.85241985321045
      policy_entropy: 169.59307861328125
      policy_loss: 2.0520548820495605
      var_gnorm: 22.629777908325195
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 55.773353576660156
    num_steps_sampled: 2820000
    num_steps_trained: 2820000
    wait_time_ms: 421.811
  iterations_since_restore: 94
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 4203.322034835815
  time_this_iter_s: 42.68108105659485
  time_total_s: 4203.322034835815
  timestamp: 1594156376
  timesteps_since_restore: 2820000
  timesteps_this_iter: 30000
  timesteps_total: 2820000
  training_iteration: 94
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 4203 s, 94 iter, 2820000 ts, -6.91e+04 rew

agent-1: 15.0
agent-2: 38.0
agent-3: 59.0
agent-4: 63.0
agent-5: 29.0
agent-6: 49.0
agent-7: 53.0
agent-8: 27.0
agent-9: 49.0
agent-10: 47.0
agent-11: 34.0
agent-12: 45.0
agent-13: 35.0
agent-14: 55.0
agent-15: 20.0
agent-16: 97.0
agent-17: 59.0
agent-18: 41.0
agent-19: 64.0
agent-20: 21.0
agent-21: 53.0
agent-22: 15.0
agent-23: 81.0
agent-24: 55.0
agent-25: 28.0
agent-26: 60.0
agent-27: 49.0
agent-28: 38.0
agent-29: 48.0
agent-30: 26.0
Sum Reward: 1353.0
Avg Reward: 45.1
Min Reward: 15.0
Max Reward: 97.0
Gini Coefficient: 0.22668144863266815
20:20 Ratio: 3.4193548387096775
Max-min Ratio: 6.466666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-13-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -68307.53191489361
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 94
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.964
    dispatch_time_ms: 7.963
    learner:
      cur_lr: 0.0011721879709511995
      grad_gnorm: 9.473827362060547
      policy_entropy: 211.72711181640625
      policy_loss: -2.4622201919555664
      var_gnorm: 22.614782333374023
      vf_explained_var: 2.384185791015625e-05
      vf_loss: 0.02134399488568306
    num_steps_sampled: 2850000
    num_steps_trained: 2850000
    wait_time_ms: 443.419
  iterations_since_restore: 95
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 4248.702313661575
  time_this_iter_s: 45.38027882575989
  time_total_s: 4248.702313661575
  timestamp: 1594156422
  timesteps_since_restore: 2850000
  timesteps_this_iter: 30000
  timesteps_total: 2850000
  training_iteration: 95
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 4248 s, 95 iter, 2850000 ts, -6.83e+04 rew

agent-1: 52.0
agent-2: 39.0
agent-3: 25.0
agent-4: 35.0
agent-5: 46.0
agent-6: 33.0
agent-7: 57.0
agent-8: 34.0
agent-9: 30.0
agent-10: 22.0
agent-11: 54.0
agent-12: 18.0
agent-13: 55.0
agent-14: 36.0
agent-15: 48.0
agent-16: 52.0
agent-17: 59.0
agent-18: 44.0
agent-19: 28.0
agent-20: 52.0
agent-21: 23.0
agent-22: 53.0
agent-23: 44.0
agent-24: 33.0
agent-25: 41.0
agent-26: 58.0
agent-27: 31.0
agent-28: 57.0
agent-29: 38.0
agent-30: 30.0
Sum Reward: 1227.0
Avg Reward: 40.9
Min Reward: 18.0
Max Reward: 59.0
Gini Coefficient: 0.16829665851670741
20:20 Ratio: 2.328767123287671
Max-min Ratio: 3.2777777777777777
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-14-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -67575.58947368422
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 95
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.62
    dispatch_time_ms: 6.848
    learner:
      cur_lr: 0.0011701900511980057
      grad_gnorm: 40.0
      policy_entropy: 226.07919311523438
      policy_loss: -48.10310363769531
      var_gnorm: 22.621782302856445
      vf_explained_var: 0.0
      vf_loss: 11.9443941116333
    num_steps_sampled: 2880000
    num_steps_trained: 2880000
    wait_time_ms: 439.557
  iterations_since_restore: 96
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 4291.068283557892
  time_this_iter_s: 42.36596989631653
  time_total_s: 4291.068283557892
  timestamp: 1594156464
  timesteps_since_restore: 2880000
  timesteps_this_iter: 30000
  timesteps_total: 2880000
  training_iteration: 96
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 4291 s, 96 iter, 2880000 ts, -6.76e+04 rew

agent-1: 38.0
agent-2: 39.0
agent-3: 39.0
agent-4: 54.0
agent-5: 34.0
agent-6: 71.0
agent-7: 77.0
agent-8: 66.0
agent-9: 91.0
agent-10: 41.0
agent-11: 32.0
agent-12: 46.0
agent-13: 61.0
agent-14: 20.0
agent-15: 34.0
agent-16: 78.0
agent-17: 17.0
agent-18: 46.0
agent-19: 63.0
agent-20: 68.0
agent-21: 35.0
agent-22: 40.0
agent-23: 51.0
agent-24: 49.0
agent-25: 46.0
agent-26: 51.0
agent-27: 51.0
agent-28: 52.0
agent-29: 62.0
agent-30: 41.0
Sum Reward: 1493.0
Avg Reward: 49.766666666666666
Min Reward: 17.0
Max Reward: 91.0
Gini Coefficient: 0.18783210538066533
20:20 Ratio: 2.622093023255814
Max-min Ratio: 5.352941176470588
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-15-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -66856.125
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 96
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.308
    dispatch_time_ms: 6.221
    learner:
      cur_lr: 0.00116819201502949
      grad_gnorm: 40.0
      policy_entropy: 225.53688049316406
      policy_loss: -18.262346267700195
      var_gnorm: 22.629323959350586
      vf_explained_var: -3.5762786865234375e-07
      vf_loss: 19.10930061340332
    num_steps_sampled: 2910000
    num_steps_trained: 2910000
    wait_time_ms: 397.686
  iterations_since_restore: 97
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 4335.521798372269
  time_this_iter_s: 44.45351481437683
  time_total_s: 4335.521798372269
  timestamp: 1594156508
  timesteps_since_restore: 2910000
  timesteps_this_iter: 30000
  timesteps_total: 2910000
  training_iteration: 97
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 4335 s, 97 iter, 2910000 ts, -6.69e+04 rew

agent-1: 40.0
agent-2: 75.0
agent-3: 67.0
agent-4: 26.0
agent-5: 36.0
agent-6: 70.0
agent-7: 36.0
agent-8: 53.0
agent-9: 13.0
agent-10: 67.0
agent-11: 32.0
agent-12: 41.0
agent-13: 28.0
agent-14: 47.0
agent-15: 64.0
agent-16: 42.0
agent-17: 53.0
agent-18: 15.0
agent-19: 42.0
agent-20: 65.0
agent-21: 42.0
agent-22: 68.0
agent-23: 36.0
agent-24: 24.0
agent-25: 43.0
agent-26: 56.0
agent-27: 13.0
agent-28: 51.0
agent-29: 56.0
agent-30: 60.0
Sum Reward: 1361.0
Avg Reward: 45.36666666666667
Min Reward: 13.0
Max Reward: 75.0
Gini Coefficient: 0.21702179769777125
20:20 Ratio: 3.46218487394958
Max-min Ratio: 5.769230769230769
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-15-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -66152.85567010309
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 97
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.953
    dispatch_time_ms: 7.114
    learner:
      cur_lr: 0.0011661939788609743
      grad_gnorm: 40.0
      policy_entropy: 175.31622314453125
      policy_loss: -29.201509475708008
      var_gnorm: 22.645418167114258
      vf_explained_var: 0.0
      vf_loss: 8.354070663452148
    num_steps_sampled: 2940000
    num_steps_trained: 2940000
    wait_time_ms: 423.416
  iterations_since_restore: 98
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 4378.995737075806
  time_this_iter_s: 43.47393870353699
  time_total_s: 4378.995737075806
  timestamp: 1594156552
  timesteps_since_restore: 2940000
  timesteps_this_iter: 30000
  timesteps_total: 2940000
  training_iteration: 98
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 4378 s, 98 iter, 2940000 ts, -6.62e+04 rew

agent-1: 35.0
agent-2: 29.0
agent-3: 26.0
agent-4: 43.0
agent-5: 41.0
agent-6: 23.0
agent-7: 48.0
agent-8: 50.0
agent-9: 37.0
agent-10: 52.0
agent-11: 28.0
agent-12: 48.0
agent-13: 67.0
agent-14: 56.0
agent-15: 58.0
agent-16: 47.0
agent-17: 32.0
agent-18: 44.0
agent-19: 29.0
agent-20: 37.0
agent-21: 55.0
agent-22: 51.0
agent-23: 28.0
agent-24: 52.0
agent-25: 44.0
agent-26: 35.0
agent-27: 47.0
agent-28: 35.0
agent-29: 15.0
agent-30: 56.0
Sum Reward: 1248.0
Avg Reward: 41.6
Min Reward: 15.0
Max Reward: 67.0
Gini Coefficient: 0.16324786324786325
20:20 Ratio: 2.3087248322147653
Max-min Ratio: 4.466666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-16-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -65465.0918367347
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 98
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 4.257
    dispatch_time_ms: 6.565
    learner:
      cur_lr: 0.0011641959426924586
      grad_gnorm: 39.999996185302734
      policy_entropy: 186.80670166015625
      policy_loss: 81.78009796142578
      var_gnorm: 22.64436912536621
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 305.1358947753906
    num_steps_sampled: 2970000
    num_steps_trained: 2970000
    wait_time_ms: 412.161
  iterations_since_restore: 99
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 4423.13188958168
  time_this_iter_s: 44.136152505874634
  time_total_s: 4423.13188958168
  timestamp: 1594156596
  timesteps_since_restore: 2970000
  timesteps_this_iter: 30000
  timesteps_total: 2970000
  training_iteration: 99
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 4423 s, 99 iter, 2970000 ts, -6.55e+04 rew

agent-1: 24.0
agent-2: 37.0
agent-3: 55.0
agent-4: 53.0
agent-5: 66.0
agent-6: 39.0
agent-7: 34.0
agent-8: 75.0
agent-9: 23.0
agent-10: 26.0
agent-11: 27.0
agent-12: 54.0
agent-13: 18.0
agent-14: 52.0
agent-15: 40.0
agent-16: 30.0
agent-17: 59.0
agent-18: 27.0
agent-19: 31.0
agent-20: 60.0
agent-21: 35.0
agent-22: 52.0
agent-23: 43.0
agent-24: 56.0
agent-25: 44.0
agent-26: 18.0
agent-27: 58.0
agent-28: 47.0
agent-29: 36.0
agent-30: 23.0
Sum Reward: 1242.0
Avg Reward: 41.4
Min Reward: 18.0
Max Reward: 75.0
Gini Coefficient: 0.20670960815888353
20:20 Ratio: 2.8333333333333335
Max-min Ratio: 4.166666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-17-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -64791.28282828283
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 99
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.817
    dispatch_time_ms: 7.305
    learner:
      cur_lr: 0.0011621980229392648
      grad_gnorm: 36.55324935913086
      policy_entropy: 255.333251953125
      policy_loss: 1.7361304759979248
      var_gnorm: 22.65339469909668
      vf_explained_var: 0.0
      vf_loss: 47.48202896118164
    num_steps_sampled: 3000000
    num_steps_trained: 3000000
    wait_time_ms: 436.539
  iterations_since_restore: 100
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 4465.392471790314
  time_this_iter_s: 42.26058220863342
  time_total_s: 4465.392471790314
  timestamp: 1594156638
  timesteps_since_restore: 3000000
  timesteps_this_iter: 30000
  timesteps_total: 3000000
  training_iteration: 100
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 4465 s, 100 iter, 3000000 ts, -6.48e+04 rew

agent-1: 56.0
agent-2: 52.0
agent-3: 47.0
agent-4: 25.0
agent-5: 42.0
agent-6: 21.0
agent-7: 42.0
agent-8: 66.0
agent-9: 86.0
agent-10: 24.0
agent-11: 53.0
agent-12: 52.0
agent-13: 36.0
agent-14: 50.0
agent-15: 48.0
agent-16: 27.0
agent-17: 73.0
agent-18: 52.0
agent-19: 48.0
agent-20: 41.0
agent-21: 47.0
agent-22: 42.0
agent-23: 52.0
agent-24: 49.0
agent-25: 33.0
agent-26: 39.0
agent-27: 46.0
agent-28: 104.0
agent-29: 30.0
agent-30: 31.0
Sum Reward: 1414.0
Avg Reward: 47.13333333333333
Min Reward: 21.0
Max Reward: 104.0
Gini Coefficient: 0.19217350306459216
20:20 Ratio: 2.7721518987341773
Max-min Ratio: 4.9523809523809526
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-18-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -64129.23
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 100
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.001
    dispatch_time_ms: 35.24
    learner:
      cur_lr: 0.001160199986770749
      grad_gnorm: 40.000003814697266
      policy_entropy: 131.611328125
      policy_loss: 102.81349182128906
      var_gnorm: 22.64992332458496
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 278.697509765625
    num_steps_sampled: 3030000
    num_steps_trained: 3030000
    wait_time_ms: 393.875
  iterations_since_restore: 101
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 4511.683146476746
  time_this_iter_s: 46.290674686431885
  time_total_s: 4511.683146476746
  timestamp: 1594156685
  timesteps_since_restore: 3030000
  timesteps_this_iter: 30000
  timesteps_total: 3030000
  training_iteration: 101
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 4511 s, 101 iter, 3030000 ts, -6.41e+04 rew

agent-1: 80.0
agent-2: 38.0
agent-3: 51.0
agent-4: 50.0
agent-5: 62.0
agent-6: 39.0
agent-7: 44.0
agent-8: 26.0
agent-9: 35.0
agent-10: 53.0
agent-11: 23.0
agent-12: 47.0
agent-13: 52.0
agent-14: 64.0
agent-15: 38.0
agent-16: 39.0
agent-17: 69.0
agent-18: 46.0
agent-19: 36.0
agent-20: 56.0
agent-21: 63.0
agent-22: 34.0
agent-23: 29.0
agent-24: 79.0
agent-25: 36.0
agent-26: 28.0
agent-27: 49.0
agent-28: 50.0
agent-29: 46.0
agent-30: 49.0
Sum Reward: 1411.0
Avg Reward: 47.03333333333333
Min Reward: 23.0
Max Reward: 80.0
Gini Coefficient: 0.16931254429482637
20:20 Ratio: 2.382857142857143
Max-min Ratio: 3.4782608695652173
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-18-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -61693.58
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 101
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.826
    dispatch_time_ms: 21.868
    learner:
      cur_lr: 0.0011582019506022334
      grad_gnorm: 40.0
      policy_entropy: 227.23785400390625
      policy_loss: -25.807815551757812
      var_gnorm: 22.66425323486328
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 39.06464767456055
    num_steps_sampled: 3060000
    num_steps_trained: 3060000
    wait_time_ms: 449.789
  iterations_since_restore: 102
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 4555.359441757202
  time_this_iter_s: 43.67629528045654
  time_total_s: 4555.359441757202
  timestamp: 1594156729
  timesteps_since_restore: 3060000
  timesteps_this_iter: 30000
  timesteps_total: 3060000
  training_iteration: 102
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 4555 s, 102 iter, 3060000 ts, -6.17e+04 rew

agent-1: 74.0
agent-2: 40.0
agent-3: 31.0
agent-4: 40.0
agent-5: 39.0
agent-6: 52.0
agent-7: 78.0
agent-8: 38.0
agent-9: 52.0
agent-10: 58.0
agent-11: 47.0
agent-12: 42.0
agent-13: 33.0
agent-14: 74.0
agent-15: 55.0
agent-16: 37.0
agent-17: 35.0
agent-18: 59.0
agent-19: 46.0
agent-20: 57.0
agent-21: -11.0
agent-22: 45.0
agent-23: 45.0
agent-24: 57.0
agent-25: 59.0
agent-26: 23.0
agent-27: 66.0
agent-28: 80.0
agent-29: 31.0
agent-30: 40.0
Sum Reward: 1422.0
Avg Reward: 47.4
Min Reward: -11.0
Max Reward: 80.0
Gini Coefficient: 0.20412564463197375
20:20 Ratio: 3.035211267605634
Max-min Ratio: -7.2727272727272725
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-19-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -59289.91
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 102
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.652
    dispatch_time_ms: 5.809
    learner:
      cur_lr: 0.0011562040308490396
      grad_gnorm: 40.0
      policy_entropy: 181.22479248046875
      policy_loss: -13.867416381835938
      var_gnorm: 22.654674530029297
      vf_explained_var: 7.152557373046875e-07
      vf_loss: 9.188075065612793
    num_steps_sampled: 3090000
    num_steps_trained: 3090000
    wait_time_ms: 450.592
  iterations_since_restore: 103
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 4600.365755081177
  time_this_iter_s: 45.00631332397461
  time_total_s: 4600.365755081177
  timestamp: 1594156774
  timesteps_since_restore: 3090000
  timesteps_this_iter: 30000
  timesteps_total: 3090000
  training_iteration: 103
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 4600 s, 103 iter, 3090000 ts, -5.93e+04 rew

agent-1: 60.0
agent-2: 49.0
agent-3: 64.0
agent-4: 61.0
agent-5: 42.0
agent-6: 27.0
agent-7: 50.0
agent-8: 51.0
agent-9: 23.0
agent-10: 51.0
agent-11: 22.0
agent-12: 14.0
agent-13: 43.0
agent-14: 49.0
agent-15: 49.0
agent-16: 46.0
agent-17: 36.0
agent-18: 37.0
agent-19: 35.0
agent-20: 61.0
agent-21: 54.0
agent-22: 49.0
agent-23: 40.0
agent-24: 41.0
agent-25: 29.0
agent-26: 46.0
agent-27: 16.0
agent-28: 37.0
agent-29: 63.0
agent-30: 22.0
Sum Reward: 1267.0
Avg Reward: 42.233333333333334
Min Reward: 14.0
Max Reward: 64.0
Gini Coefficient: 0.1850828729281768
20:20 Ratio: 2.9274193548387095
Max-min Ratio: 4.571428571428571
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-20-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -53588.78
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 103
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.591
    dispatch_time_ms: 26.12
    learner:
      cur_lr: 0.0011542059946805239
      grad_gnorm: 40.0
      policy_entropy: 125.51995086669922
      policy_loss: 55.58270263671875
      var_gnorm: 22.663963317871094
      vf_explained_var: 0.0
      vf_loss: 149.5525665283203
    num_steps_sampled: 3120000
    num_steps_trained: 3120000
    wait_time_ms: 401.045
  iterations_since_restore: 104
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 4643.896464109421
  time_this_iter_s: 43.53070902824402
  time_total_s: 4643.896464109421
  timestamp: 1594156817
  timesteps_since_restore: 3120000
  timesteps_this_iter: 30000
  timesteps_total: 3120000
  training_iteration: 104
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 4643 s, 104 iter, 3120000 ts, -5.36e+04 rew

agent-1: 79.0
agent-2: 63.0
agent-3: 27.0
agent-4: 57.0
agent-5: 38.0
agent-6: 54.0
agent-7: 53.0
agent-8: 55.0
agent-9: 62.0
agent-10: 51.0
agent-11: 50.0
agent-12: 77.0
agent-13: 39.0
agent-14: 64.0
agent-15: 50.0
agent-16: 55.0
agent-17: 58.0
agent-18: 23.0
agent-19: 31.0
agent-20: 44.0
agent-21: 21.0
agent-22: 41.0
agent-23: 71.0
agent-24: 25.0
agent-25: 70.0
agent-26: 75.0
agent-27: 36.0
agent-28: 45.0
agent-29: 67.0
agent-30: 62.0
Sum Reward: 1543.0
Avg Reward: 51.43333333333333
Min Reward: 21.0
Max Reward: 79.0
Gini Coefficient: 0.17902354720241953
20:20 Ratio: 2.6932515337423313
Max-min Ratio: 3.761904761904762
agent-1: 44.0
agent-2: 35.0
agent-3: 30.0
agent-4: 61.0
agent-5: 20.0
agent-6: 60.0
agent-7: 52.0
agent-8: 46.0
agent-9: 39.0
agent-10: 66.0
agent-11: 62.0
agent-12: 53.0
agent-13: 33.0
agent-14: 40.0
agent-15: 63.0
agent-16: 33.0
agent-17: 62.0
agent-18: 42.0
agent-19: 43.0
agent-20: 54.0
agent-21: 78.0
agent-22: 40.0
agent-23: 48.0
agent-24: 32.0
agent-25: 57.0
agent-26: 58.0
agent-27: 18.0
agent-28: 30.0
agent-29: 23.0
agent-30: 46.0
Sum Reward: 1368.0
Avg Reward: 45.6
Min Reward: 18.0
Max Reward: 78.0
Gini Coefficient: 0.18196881091617934
20:20 Ratio: 2.5620915032679736
Max-min Ratio: 4.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-21-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -39447.27
  episode_reward_min: -815993.0
  episodes_this_iter: 2
  episodes_total: 105
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.005
    dispatch_time_ms: 54.786
    learner:
      cur_lr: 0.0011522079585120082
      grad_gnorm: 39.999996185302734
      policy_entropy: 208.92007446289062
      policy_loss: 114.0383529663086
      var_gnorm: 22.66022300720215
      vf_explained_var: -0.027686357498168945
      vf_loss: 290.4529724121094
    num_steps_sampled: 3150000
    num_steps_trained: 3150000
    wait_time_ms: 403.776
  iterations_since_restore: 105
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 4689.828105926514
  time_this_iter_s: 45.931641817092896
  time_total_s: 4689.828105926514
  timestamp: 1594156863
  timesteps_since_restore: 3150000
  timesteps_this_iter: 30000
  timesteps_total: 3150000
  training_iteration: 105
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 4689 s, 105 iter, 3150000 ts, -3.94e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-21-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -39447.27
  episode_reward_min: -815993.0
  episodes_this_iter: 0
  episodes_total: 105
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.027
    dispatch_time_ms: 5.288
    learner:
      cur_lr: 0.0011502100387588143
      grad_gnorm: 40.0
      policy_entropy: 228.73941040039062
      policy_loss: -37.45197296142578
      var_gnorm: 22.665788650512695
      vf_explained_var: 0.0
      vf_loss: 17.31538200378418
    num_steps_sampled: 3180000
    num_steps_trained: 3180000
    wait_time_ms: 455.707
  iterations_since_restore: 106
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 4734.191765069962
  time_this_iter_s: 44.363659143447876
  time_total_s: 4734.191765069962
  timestamp: 1594156908
  timesteps_since_restore: 3180000
  timesteps_this_iter: 30000
  timesteps_total: 3180000
  training_iteration: 106
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 4734 s, 106 iter, 3180000 ts, -3.94e+04 rew

agent-1: 50.0
agent-2: 27.0
agent-3: 26.0
agent-4: 33.0
agent-5: 14.0
agent-6: 31.0
agent-7: 49.0
agent-8: 30.0
agent-9: 46.0
agent-10: 25.0
agent-11: 29.0
agent-12: 51.0
agent-13: 36.0
agent-14: 44.0
agent-15: 10.0
agent-16: 24.0
agent-17: 42.0
agent-18: 16.0
agent-19: 55.0
agent-20: 25.0
agent-21: 40.0
agent-22: 52.0
agent-23: 32.0
agent-24: 29.0
agent-25: 35.0
agent-26: 46.0
agent-27: 35.0
agent-28: 58.0
agent-29: 41.0
agent-30: 28.0
Sum Reward: 1059.0
Avg Reward: 35.3
Min Reward: 10.0
Max Reward: 58.0
Gini Coefficient: 0.1948693736229147
20:20 Ratio: 2.763157894736842
Max-min Ratio: 5.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-22-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -32004.98
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 106
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.29
    dispatch_time_ms: 7.11
    learner:
      cur_lr: 0.0011482120025902987
      grad_gnorm: 39.999996185302734
      policy_entropy: 291.3757019042969
      policy_loss: 152.23741149902344
      var_gnorm: 22.65620231628418
      vf_explained_var: 0.0006012916564941406
      vf_loss: 193.7620391845703
    num_steps_sampled: 3210000
    num_steps_trained: 3210000
    wait_time_ms: 429.082
  iterations_since_restore: 107
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 4779.622468709946
  time_this_iter_s: 45.43070363998413
  time_total_s: 4779.622468709946
  timestamp: 1594156953
  timesteps_since_restore: 3210000
  timesteps_this_iter: 30000
  timesteps_total: 3210000
  training_iteration: 107
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 4779 s, 107 iter, 3210000 ts, -3.2e+04 rew

agent-1: 33.0
agent-2: 35.0
agent-3: 34.0
agent-4: 21.0
agent-5: 48.0
agent-6: 51.0
agent-7: 19.0
agent-8: 50.0
agent-9: 43.0
agent-10: 36.0
agent-11: 24.0
agent-12: 30.0
agent-13: 26.0
agent-14: 41.0
agent-15: 17.0
agent-16: 48.0
agent-17: 40.0
agent-18: 57.0
agent-19: 28.0
agent-20: 24.0
agent-21: 36.0
agent-22: 48.0
agent-23: 36.0
agent-24: 32.0
agent-25: 32.0
agent-26: 32.0
agent-27: 57.0
agent-28: 39.0
agent-29: 12.0
agent-30: 29.0
Sum Reward: 1058.0
Avg Reward: 35.266666666666666
Min Reward: 12.0
Max Reward: 57.0
Gini Coefficient: 0.18267170762444865
20:20 Ratio: 2.658119658119658
Max-min Ratio: 4.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-23-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -24977.85
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 107
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.408
    dispatch_time_ms: 6.579
    learner:
      cur_lr: 0.001146213966421783
      grad_gnorm: 39.999996185302734
      policy_entropy: 263.7560119628906
      policy_loss: -18.4421443939209
      var_gnorm: 22.66349220275879
      vf_explained_var: 0.0
      vf_loss: 59.51918411254883
    num_steps_sampled: 3240000
    num_steps_trained: 3240000
    wait_time_ms: 453.033
  iterations_since_restore: 108
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 4822.744044542313
  time_this_iter_s: 43.12157583236694
  time_total_s: 4822.744044542313
  timestamp: 1594156996
  timesteps_since_restore: 3240000
  timesteps_this_iter: 30000
  timesteps_total: 3240000
  training_iteration: 108
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 4822 s, 108 iter, 3240000 ts, -2.5e+04 rew

agent-1: 63.0
agent-2: 22.0
agent-3: 33.0
agent-4: 51.0
agent-5: 27.0
agent-6: 34.0
agent-7: 47.0
agent-8: 27.0
agent-9: 26.0
agent-10: 46.0
agent-11: 36.0
agent-12: 41.0
agent-13: 47.0
agent-14: 34.0
agent-15: 49.0
agent-16: 29.0
agent-17: 28.0
agent-18: 53.0
agent-19: 23.0
agent-20: 30.0
agent-21: 49.0
agent-22: 38.0
agent-23: 29.0
agent-24: 52.0
agent-25: 48.0
agent-26: 54.0
agent-27: 37.0
agent-28: 47.0
agent-29: 27.0
agent-30: 25.0
Sum Reward: 1152.0
Avg Reward: 38.4
Min Reward: 22.0
Max Reward: 63.0
Gini Coefficient: 0.1633101851851852
20:20 Ratio: 2.1466666666666665
Max-min Ratio: 2.8636363636363638
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-24-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -18150.0
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 108
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.14
    dispatch_time_ms: 6.43
    learner:
      cur_lr: 0.0011442160466685891
      grad_gnorm: 39.999996185302734
      policy_entropy: 117.37545776367188
      policy_loss: 22.95516014099121
      var_gnorm: 22.666767120361328
      vf_explained_var: -9.5367431640625e-07
      vf_loss: 29.262331008911133
    num_steps_sampled: 3270000
    num_steps_trained: 3270000
    wait_time_ms: 455.661
  iterations_since_restore: 109
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 4868.3911216259
  time_this_iter_s: 45.64707708358765
  time_total_s: 4868.3911216259
  timestamp: 1594157042
  timesteps_since_restore: 3270000
  timesteps_this_iter: 30000
  timesteps_total: 3270000
  training_iteration: 109
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 4868 s, 109 iter, 3270000 ts, -1.82e+04 rew

agent-1: 34.0
agent-2: 16.0
agent-3: 44.0
agent-4: 19.0
agent-5: 54.0
agent-6: 10.0
agent-7: 40.0
agent-8: 32.0
agent-9: 18.0
agent-10: 47.0
agent-11: 35.0
agent-12: 44.0
agent-13: 27.0
agent-14: 27.0
agent-15: 40.0
agent-16: 38.0
agent-17: 38.0
agent-18: 41.0
agent-19: 37.0
agent-20: 26.0
agent-21: 24.0
agent-22: 21.0
agent-23: 28.0
agent-24: 46.0
agent-25: 20.0
agent-26: 43.0
agent-27: 10.0
agent-28: 14.0
agent-29: 35.0
agent-30: 44.0
Sum Reward: 952.0
Avg Reward: 31.733333333333334
Min Reward: 10.0
Max Reward: 54.0
Gini Coefficient: 0.21092436974789916
20:20 Ratio: 3.206896551724138
Max-min Ratio: 5.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-24-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -10805.67
  episode_reward_min: -815993.0
  episodes_this_iter: 1
  episodes_total: 109
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.849
    dispatch_time_ms: 5.744
    learner:
      cur_lr: 0.0011422180105000734
      grad_gnorm: 40.0
      policy_entropy: 141.53970336914062
      policy_loss: 19.388874053955078
      var_gnorm: 22.675180435180664
      vf_explained_var: 0.0
      vf_loss: 50.64899444580078
    num_steps_sampled: 3300000
    num_steps_trained: 3300000
    wait_time_ms: 428.999
  iterations_since_restore: 110
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 4910.901326656342
  time_this_iter_s: 42.510205030441284
  time_total_s: 4910.901326656342
  timestamp: 1594157084
  timesteps_since_restore: 3300000
  timesteps_this_iter: 30000
  timesteps_total: 3300000
  training_iteration: 110
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 4910 s, 110 iter, 3300000 ts, -1.08e+04 rew

agent-1: 28.0
agent-2: 49.0
agent-3: 66.0
agent-4: 48.0
agent-5: 37.0
agent-6: 21.0
agent-7: 25.0
agent-8: 64.0
agent-9: 27.0
agent-10: 39.0
agent-11: 38.0
agent-12: 49.0
agent-13: 64.0
agent-14: 77.0
agent-15: 23.0
agent-16: 23.0
agent-17: 42.0
agent-18: 44.0
agent-19: 52.0
agent-20: 66.0
agent-21: 36.0
agent-22: 42.0
agent-23: 34.0
agent-24: 60.0
agent-25: 47.0
agent-26: 38.0
agent-27: 20.0
agent-28: 61.0
agent-29: 33.0
agent-30: 67.0
Sum Reward: 1320.0
Avg Reward: 44.0
Min Reward: 20.0
Max Reward: 77.0
Gini Coefficient: 0.2035858585858586
20:20 Ratio: 2.906474820143885
Max-min Ratio: 3.85
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-25-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -2632.54
  episode_reward_min: -255108.0
  episodes_this_iter: 1
  episodes_total: 110
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.866
    dispatch_time_ms: 6.136
    learner:
      cur_lr: 0.0011402199743315578
      grad_gnorm: 40.0
      policy_entropy: 172.19369506835938
      policy_loss: 89.6310806274414
      var_gnorm: 22.672508239746094
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 170.40467834472656
    num_steps_sampled: 3330000
    num_steps_trained: 3330000
    wait_time_ms: 410.921
  iterations_since_restore: 111
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 4955.046236515045
  time_this_iter_s: 44.14490985870361
  time_total_s: 4955.046236515045
  timestamp: 1594157129
  timesteps_since_restore: 3330000
  timesteps_this_iter: 30000
  timesteps_total: 3330000
  training_iteration: 111
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 4955 s, 111 iter, 3330000 ts, -2.63e+03 rew

agent-1: 52.0
agent-2: 60.0
agent-3: 38.0
agent-4: 41.0
agent-5: 68.0
agent-6: 33.0
agent-7: 49.0
agent-8: 60.0
agent-9: 34.0
agent-10: 44.0
agent-11: 40.0
agent-12: 45.0
agent-13: 62.0
agent-14: 51.0
agent-15: 30.0
agent-16: 49.0
agent-17: 45.0
agent-18: 57.0
agent-19: 31.0
agent-20: 55.0
agent-21: 48.0
agent-22: 38.0
agent-23: 24.0
agent-24: 62.0
agent-25: 59.0
agent-26: 50.0
agent-27: 72.0
agent-28: 36.0
agent-29: 23.0
agent-30: 25.0
Sum Reward: 1381.0
Avg Reward: 46.03333333333333
Min Reward: 23.0
Max Reward: 72.0
Gini Coefficient: 0.16193579531740285
20:20 Ratio: 2.3132530120481927
Max-min Ratio: 3.130434782608696
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-26-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: -67.65
  episode_reward_min: -106269.0
  episodes_this_iter: 1
  episodes_total: 111
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.681
    dispatch_time_ms: 5.575
    learner:
      cur_lr: 0.001138222054578364
      grad_gnorm: 36.5575065612793
      policy_entropy: 147.78189086914062
      policy_loss: 10.927801132202148
      var_gnorm: 22.681018829345703
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 73.91246795654297
    num_steps_sampled: 3360000
    num_steps_trained: 3360000
    wait_time_ms: 430.814
  iterations_since_restore: 112
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 4997.626905202866
  time_this_iter_s: 42.580668687820435
  time_total_s: 4997.626905202866
  timestamp: 1594157171
  timesteps_since_restore: 3360000
  timesteps_this_iter: 30000
  timesteps_total: 3360000
  training_iteration: 112
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 4997 s, 112 iter, 3360000 ts, -67.7 rew

agent-1: 35.0
agent-2: 37.0
agent-3: 18.0
agent-4: 33.0
agent-5: 47.0
agent-6: 16.0
agent-7: 31.0
agent-8: 34.0
agent-9: 26.0
agent-10: 47.0
agent-11: 51.0
agent-12: 34.0
agent-13: 62.0
agent-14: 57.0
agent-15: 20.0
agent-16: 20.0
agent-17: 51.0
agent-18: 51.0
agent-19: 38.0
agent-20: 17.0
agent-21: 61.0
agent-22: 60.0
agent-23: 21.0
agent-24: 44.0
agent-25: 40.0
agent-26: 32.0
agent-27: 56.0
agent-28: 57.0
agent-29: 27.0
agent-30: 32.0
Sum Reward: 1155.0
Avg Reward: 38.5
Min Reward: 16.0
Max Reward: 62.0
Gini Coefficient: 0.21157287157287158
20:20 Ratio: 3.1517857142857144
Max-min Ratio: 3.875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-26-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: 1006.59
  episode_reward_min: -8644.0
  episodes_this_iter: 1
  episodes_total: 112
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.567
    dispatch_time_ms: 6.393
    learner:
      cur_lr: 0.0011362240184098482
      grad_gnorm: 28.116979598999023
      policy_entropy: 146.18994140625
      policy_loss: -4.977617263793945
      var_gnorm: 22.727508544921875
      vf_explained_var: 0.0
      vf_loss: 12.004952430725098
    num_steps_sampled: 3390000
    num_steps_trained: 3390000
    wait_time_ms: 432.172
  iterations_since_restore: 113
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 5042.667559862137
  time_this_iter_s: 45.04065465927124
  time_total_s: 5042.667559862137
  timestamp: 1594157216
  timesteps_since_restore: 3390000
  timesteps_this_iter: 30000
  timesteps_total: 3390000
  training_iteration: 113
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 5042 s, 113 iter, 3390000 ts, 1.01e+03 rew

agent-1: 67.0
agent-2: 67.0
agent-3: 56.0
agent-4: 49.0
agent-5: 15.0
agent-6: 50.0
agent-7: 28.0
agent-8: 64.0
agent-9: 61.0
agent-10: 49.0
agent-11: 46.0
agent-12: 36.0
agent-13: 46.0
agent-14: 42.0
agent-15: 63.0
agent-16: 53.0
agent-17: 30.0
agent-18: 50.0
agent-19: 44.0
agent-20: 52.0
agent-21: 50.0
agent-22: 40.0
agent-23: 25.0
agent-24: 48.0
agent-25: 47.0
agent-26: 37.0
agent-27: 41.0
agent-28: 55.0
agent-29: 37.0
agent-30: 29.0
Sum Reward: 1377.0
Avg Reward: 45.9
Min Reward: 15.0
Max Reward: 67.0
Gini Coefficient: 0.1523844105543452
20:20 Ratio: 2.3190184049079754
Max-min Ratio: 4.466666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-27-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: 1013.16
  episode_reward_min: -8644.0
  episodes_this_iter: 1
  episodes_total: 113
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.536
    dispatch_time_ms: 21.734
    learner:
      cur_lr: 0.0011342259822413325
      grad_gnorm: 31.2479305267334
      policy_entropy: 155.83761596679688
      policy_loss: -12.837814331054688
      var_gnorm: 22.740840911865234
      vf_explained_var: 0.0
      vf_loss: 47.57378387451172
    num_steps_sampled: 3420000
    num_steps_trained: 3420000
    wait_time_ms: 440.721
  iterations_since_restore: 114
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 5086.1152946949005
  time_this_iter_s: 43.44773483276367
  time_total_s: 5086.1152946949005
  timestamp: 1594157260
  timesteps_since_restore: 3420000
  timesteps_this_iter: 30000
  timesteps_total: 3420000
  training_iteration: 114
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 5086 s, 114 iter, 3420000 ts, 1.01e+03 rew

agent-1: 15.0
agent-2: 40.0
agent-3: 42.0
agent-4: 42.0
agent-5: 78.0
agent-6: 36.0
agent-7: 54.0
agent-8: 25.0
agent-9: 32.0
agent-10: 67.0
agent-11: 31.0
agent-12: 37.0
agent-13: 47.0
agent-14: 69.0
agent-15: 58.0
agent-16: 42.0
agent-17: 59.0
agent-18: 77.0
agent-19: 42.0
agent-20: 16.0
agent-21: 26.0
agent-22: 54.0
agent-23: 45.0
agent-24: 42.0
agent-25: 30.0
agent-26: 40.0
agent-27: 53.0
agent-28: 31.0
agent-29: 46.0
agent-30: 44.0
Sum Reward: 1320.0
Avg Reward: 44.0
Min Reward: 15.0
Max Reward: 78.0
Gini Coefficient: 0.1967171717171717
20:20 Ratio: 2.8531468531468533
Max-min Ratio: 5.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-28-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: 1019.18
  episode_reward_min: -8644.0
  episodes_this_iter: 1
  episodes_total: 114
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.69
    dispatch_time_ms: 36.51
    learner:
      cur_lr: 0.0011322279460728168
      grad_gnorm: 40.0
      policy_entropy: 114.54818725585938
      policy_loss: 63.237648010253906
      var_gnorm: 22.73164176940918
      vf_explained_var: 0.0
      vf_loss: 216.51541137695312
    num_steps_sampled: 3450000
    num_steps_trained: 3450000
    wait_time_ms: 399.787
  iterations_since_restore: 115
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 5132.3719828128815
  time_this_iter_s: 46.25668811798096
  time_total_s: 5132.3719828128815
  timestamp: 1594157306
  timesteps_since_restore: 3450000
  timesteps_this_iter: 30000
  timesteps_total: 3450000
  training_iteration: 115
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 5132 s, 115 iter, 3450000 ts, 1.02e+03 rew

agent-1: 30.0
agent-2: 45.0
agent-3: 70.0
agent-4: 49.0
agent-5: 39.0
agent-6: 50.0
agent-7: 55.0
agent-8: 48.0
agent-9: 60.0
agent-10: 31.0
agent-11: 46.0
agent-12: 58.0
agent-13: 30.0
agent-14: 35.0
agent-15: 20.0
agent-16: 39.0
agent-17: 31.0
agent-18: 34.0
agent-19: 54.0
agent-20: 42.0
agent-21: 66.0
agent-22: 25.0
agent-23: 39.0
agent-24: 32.0
agent-25: 44.0
agent-26: 38.0
agent-27: 33.0
agent-28: 50.0
agent-29: 32.0
agent-30: 22.0
Sum Reward: 1247.0
Avg Reward: 41.56666666666667
Min Reward: 20.0
Max Reward: 70.0
Gini Coefficient: 0.16880513231756214
20:20 Ratio: 2.2974683544303796
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-29-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: 1029.32
  episode_reward_min: -8644.0
  episodes_this_iter: 1
  episodes_total: 115
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.641
    dispatch_time_ms: 40.265
    learner:
      cur_lr: 0.001130230026319623
      grad_gnorm: 40.0
      policy_entropy: 232.3081817626953
      policy_loss: -5.966184616088867
      var_gnorm: 22.74070930480957
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 32.37960433959961
    num_steps_sampled: 3480000
    num_steps_trained: 3480000
    wait_time_ms: 433.842
  iterations_since_restore: 116
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 5176.246487617493
  time_this_iter_s: 43.874504804611206
  time_total_s: 5176.246487617493
  timestamp: 1594157350
  timesteps_since_restore: 3480000
  timesteps_this_iter: 30000
  timesteps_total: 3480000
  training_iteration: 116
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 5176 s, 116 iter, 3480000 ts, 1.03e+03 rew

agent-1: 32.0
agent-2: 34.0
agent-3: 37.0
agent-4: 45.0
agent-5: 45.0
agent-6: 34.0
agent-7: 44.0
agent-8: 58.0
agent-9: 60.0
agent-10: 30.0
agent-11: 78.0
agent-12: 56.0
agent-13: 35.0
agent-14: 61.0
agent-15: 32.0
agent-16: 48.0
agent-17: 76.0
agent-18: 39.0
agent-19: 37.0
agent-20: 27.0
agent-21: 42.0
agent-22: 48.0
agent-23: 49.0
agent-24: 43.0
agent-25: 39.0
agent-26: 30.0
agent-27: 64.0
agent-28: 64.0
agent-29: 64.0
agent-30: 44.0
Sum Reward: 1395.0
Avg Reward: 46.5
Min Reward: 27.0
Max Reward: 78.0
Gini Coefficient: 0.1630346475507766
20:20 Ratio: 2.2
Max-min Ratio: 2.888888888888889
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-29-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: 1037.59
  episode_reward_min: -8644.0
  episodes_this_iter: 1
  episodes_total: 116
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.129
    dispatch_time_ms: 7.68
    learner:
      cur_lr: 0.0011282319901511073
      grad_gnorm: 40.0
      policy_entropy: 239.8411407470703
      policy_loss: 110.83602142333984
      var_gnorm: 22.73267364501953
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 144.74176025390625
    num_steps_sampled: 3510000
    num_steps_trained: 3510000
    wait_time_ms: 423.451
  iterations_since_restore: 117
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 5221.447899580002
  time_this_iter_s: 45.201411962509155
  time_total_s: 5221.447899580002
  timestamp: 1594157395
  timesteps_since_restore: 3510000
  timesteps_this_iter: 30000
  timesteps_total: 3510000
  training_iteration: 117
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 5221 s, 117 iter, 3510000 ts, 1.04e+03 rew

agent-1: 33.0
agent-2: 26.0
agent-3: 52.0
agent-4: 54.0
agent-5: 26.0
agent-6: 42.0
agent-7: 34.0
agent-8: 29.0
agent-9: 42.0
agent-10: 39.0
agent-11: 39.0
agent-12: 46.0
agent-13: 37.0
agent-14: 36.0
agent-15: 39.0
agent-16: 57.0
agent-17: 28.0
agent-18: 44.0
agent-19: 24.0
agent-20: 46.0
agent-21: 43.0
agent-22: 41.0
agent-23: 24.0
agent-24: 24.0
agent-25: 46.0
agent-26: 68.0
agent-27: 18.0
agent-28: 39.0
agent-29: 54.0
agent-30: 42.0
Sum Reward: 1172.0
Avg Reward: 39.06666666666667
Min Reward: 18.0
Max Reward: 68.0
Gini Coefficient: 0.15984072810011377
20:20 Ratio: 2.3309859154929575
Max-min Ratio: 3.7777777777777777
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-30-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: 1066.68
  episode_reward_min: -8644.0
  episodes_this_iter: 1
  episodes_total: 117
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.612
    dispatch_time_ms: 6.256
    learner:
      cur_lr: 0.0011262339539825916
      grad_gnorm: 39.999996185302734
      policy_entropy: 269.3946228027344
      policy_loss: -43.82513427734375
      var_gnorm: 22.748594284057617
      vf_explained_var: 0.0
      vf_loss: 4.561750888824463
    num_steps_sampled: 3540000
    num_steps_trained: 3540000
    wait_time_ms: 438.078
  iterations_since_restore: 118
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 5265.612508058548
  time_this_iter_s: 44.16460847854614
  time_total_s: 5265.612508058548
  timestamp: 1594157439
  timesteps_since_restore: 3540000
  timesteps_this_iter: 30000
  timesteps_total: 3540000
  training_iteration: 118
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 5265 s, 118 iter, 3540000 ts, 1.07e+03 rew

agent-1: 39.0
agent-2: 57.0
agent-3: 34.0
agent-4: 19.0
agent-5: 67.0
agent-6: 16.0
agent-7: 42.0
agent-8: 19.0
agent-9: 8.0
agent-10: 48.0
agent-11: 32.0
agent-12: 21.0
agent-13: 25.0
agent-14: 32.0
agent-15: 26.0
agent-16: 49.0
agent-17: 22.0
agent-18: 35.0
agent-19: 47.0
agent-20: 35.0
agent-21: 23.0
agent-22: 51.0
agent-23: 35.0
agent-24: 57.0
agent-25: 30.0
agent-26: 35.0
agent-27: 37.0
agent-28: 25.0
agent-29: 31.0
agent-30: 23.0
Sum Reward: 1020.0
Avg Reward: 34.0
Min Reward: 8.0
Max Reward: 67.0
Gini Coefficient: 0.22026143790849673
20:20 Ratio: 3.1333333333333333
Max-min Ratio: 8.375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-31-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: 1125.41
  episode_reward_min: -8644.0
  episodes_this_iter: 1
  episodes_total: 118
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 4.047
    dispatch_time_ms: 7.06
    learner:
      cur_lr: 0.0011242360342293978
      grad_gnorm: 40.0
      policy_entropy: 248.6605224609375
      policy_loss: 82.91121673583984
      var_gnorm: 22.746675491333008
      vf_explained_var: 0.0
      vf_loss: 79.52079010009766
    num_steps_sampled: 3570000
    num_steps_trained: 3570000
    wait_time_ms: 404.093
  iterations_since_restore: 119
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 5310.286236047745
  time_this_iter_s: 44.67372798919678
  time_total_s: 5310.286236047745
  timestamp: 1594157484
  timesteps_since_restore: 3570000
  timesteps_this_iter: 30000
  timesteps_total: 3570000
  training_iteration: 119
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 5310 s, 119 iter, 3570000 ts, 1.13e+03 rew

agent-1: 16.0
agent-2: 34.0
agent-3: 37.0
agent-4: 33.0
agent-5: 23.0
agent-6: 43.0
agent-7: 57.0
agent-8: 35.0
agent-9: 39.0
agent-10: 15.0
agent-11: 41.0
agent-12: 41.0
agent-13: 53.0
agent-14: 56.0
agent-15: 24.0
agent-16: 48.0
agent-17: 39.0
agent-18: 34.0
agent-19: 24.0
agent-20: 24.0
agent-21: 9.0
agent-22: 31.0
agent-23: 41.0
agent-24: 45.0
agent-25: 44.0
agent-26: 37.0
agent-27: 46.0
agent-28: 18.0
agent-29: 34.0
agent-30: 27.0
Sum Reward: 1048.0
Avg Reward: 34.93333333333333
Min Reward: 9.0
Max Reward: 57.0
Gini Coefficient: 0.1926208651399491
20:20 Ratio: 2.9047619047619047
Max-min Ratio: 6.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-32-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: 1222.33
  episode_reward_min: -1979.0
  episodes_this_iter: 1
  episodes_total: 119
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.968
    dispatch_time_ms: 10.587
    learner:
      cur_lr: 0.001122237998060882
      grad_gnorm: 40.0
      policy_entropy: 204.49449157714844
      policy_loss: -29.89902114868164
      var_gnorm: 22.754138946533203
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 13.272736549377441
    num_steps_sampled: 3600000
    num_steps_trained: 3600000
    wait_time_ms: 424.332
  iterations_since_restore: 120
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 5353.96622467041
  time_this_iter_s: 43.679988622665405
  time_total_s: 5353.96622467041
  timestamp: 1594157528
  timesteps_since_restore: 3600000
  timesteps_this_iter: 30000
  timesteps_total: 3600000
  training_iteration: 120
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 5353 s, 120 iter, 3600000 ts, 1.22e+03 rew

agent-1: 35.0
agent-2: 33.0
agent-3: 25.0
agent-4: 33.0
agent-5: 48.0
agent-6: 40.0
agent-7: 25.0
agent-8: 38.0
agent-9: 51.0
agent-10: 31.0
agent-11: 43.0
agent-12: 38.0
agent-13: 36.0
agent-14: 53.0
agent-15: 49.0
agent-16: 37.0
agent-17: 71.0
agent-18: 27.0
agent-19: 45.0
agent-20: 38.0
agent-21: 54.0
agent-22: 33.0
agent-23: 41.0
agent-24: 33.0
agent-25: 56.0
agent-26: 14.0
agent-27: 50.0
agent-28: 39.0
agent-29: 46.0
agent-30: 50.0
Sum Reward: 1212.0
Avg Reward: 40.4
Min Reward: 14.0
Max Reward: 71.0
Gini Coefficient: 0.15253025302530254
20:20 Ratio: 2.161290322580645
Max-min Ratio: 5.071428571428571
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-32-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: 1254.24
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 120
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.999
    dispatch_time_ms: 5.816
    learner:
      cur_lr: 0.0011202399618923664
      grad_gnorm: 34.2805290222168
      policy_entropy: 226.46031188964844
      policy_loss: 7.909284591674805
      var_gnorm: 22.752113342285156
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 37.490516662597656
    num_steps_sampled: 3630000
    num_steps_trained: 3630000
    wait_time_ms: 412.327
  iterations_since_restore: 121
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 5397.809896230698
  time_this_iter_s: 43.843671560287476
  time_total_s: 5397.809896230698
  timestamp: 1594157572
  timesteps_since_restore: 3630000
  timesteps_this_iter: 30000
  timesteps_total: 3630000
  training_iteration: 121
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 5397 s, 121 iter, 3630000 ts, 1.25e+03 rew

agent-1: 36.0
agent-2: 60.0
agent-3: 49.0
agent-4: 37.0
agent-5: 52.0
agent-6: 22.0
agent-7: 60.0
agent-8: 27.0
agent-9: 50.0
agent-10: 38.0
agent-11: 43.0
agent-12: 45.0
agent-13: 18.0
agent-14: 52.0
agent-15: 53.0
agent-16: 31.0
agent-17: 45.0
agent-18: 26.0
agent-19: 29.0
agent-20: 61.0
agent-21: 25.0
agent-22: 41.0
agent-23: 45.0
agent-24: 15.0
agent-25: 38.0
agent-26: 28.0
agent-27: 59.0
agent-28: 44.0
agent-29: 32.0
agent-30: 27.0
Sum Reward: 1188.0
Avg Reward: 39.6
Min Reward: 15.0
Max Reward: 61.0
Gini Coefficient: 0.18641975308641975
20:20 Ratio: 2.593984962406015
Max-min Ratio: 4.066666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-33-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: 1256.78
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 121
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.494
    dispatch_time_ms: 6.821
    learner:
      cur_lr: 0.0011182420421391726
      grad_gnorm: 40.0
      policy_entropy: 245.79005432128906
      policy_loss: -36.53685760498047
      var_gnorm: 22.752687454223633
      vf_explained_var: 0.0
      vf_loss: 5.763613700866699
    num_steps_sampled: 3660000
    num_steps_trained: 3660000
    wait_time_ms: 438.877
  iterations_since_restore: 122
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 5442.134408950806
  time_this_iter_s: 44.32451272010803
  time_total_s: 5442.134408950806
  timestamp: 1594157617
  timesteps_since_restore: 3660000
  timesteps_this_iter: 30000
  timesteps_total: 3660000
  training_iteration: 122
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 5442 s, 122 iter, 3660000 ts, 1.26e+03 rew

agent-1: 42.0
agent-2: 10.0
agent-3: 45.0
agent-4: 47.0
agent-5: 23.0
agent-6: 20.0
agent-7: 24.0
agent-8: 27.0
agent-9: 28.0
agent-10: 29.0
agent-11: 42.0
agent-12: 42.0
agent-13: 41.0
agent-14: 47.0
agent-15: 38.0
agent-16: 19.0
agent-17: 49.0
agent-18: 17.0
agent-19: 21.0
agent-20: 25.0
agent-21: 56.0
agent-22: 17.0
agent-23: 15.0
agent-24: 25.0
agent-25: 11.0
agent-26: 17.0
agent-27: 22.0
agent-28: 69.0
agent-29: 25.0
agent-30: 33.0
Sum Reward: 926.0
Avg Reward: 30.866666666666667
Min Reward: 10.0
Max Reward: 69.0
Gini Coefficient: 0.25413966882649386
20:20 Ratio: 3.5977011494252875
Max-min Ratio: 6.9
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-34-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: 1253.91
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 122
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.667
    dispatch_time_ms: 6.108
    learner:
      cur_lr: 0.0011162440059706569
      grad_gnorm: 40.0
      policy_entropy: 161.44290161132812
      policy_loss: 53.95976638793945
      var_gnorm: 22.747312545776367
      vf_explained_var: 0.0
      vf_loss: 104.27378845214844
    num_steps_sampled: 3690000
    num_steps_trained: 3690000
    wait_time_ms: 396.417
  iterations_since_restore: 123
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 5486.464663982391
  time_this_iter_s: 44.33025503158569
  time_total_s: 5486.464663982391
  timestamp: 1594157661
  timesteps_since_restore: 3690000
  timesteps_this_iter: 30000
  timesteps_total: 3690000
  training_iteration: 123
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 5486 s, 123 iter, 3690000 ts, 1.25e+03 rew

agent-1: 47.0
agent-2: 40.0
agent-3: 31.0
agent-4: 27.0
agent-5: 37.0
agent-6: 56.0
agent-7: 43.0
agent-8: 28.0
agent-9: 39.0
agent-10: 37.0
agent-11: 31.0
agent-12: 60.0
agent-13: 47.0
agent-14: 52.0
agent-15: 36.0
agent-16: 24.0
agent-17: 38.0
agent-18: 34.0
agent-19: 39.0
agent-20: 45.0
agent-21: 47.0
agent-22: 33.0
agent-23: 49.0
agent-24: 28.0
agent-25: 33.0
agent-26: 43.0
agent-27: 27.0
agent-28: 31.0
agent-29: 27.0
agent-30: 23.0
Sum Reward: 1132.0
Avg Reward: 37.733333333333334
Min Reward: 23.0
Max Reward: 60.0
Gini Coefficient: 0.14151943462897526
20:20 Ratio: 1.9935897435897436
Max-min Ratio: 2.608695652173913
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-35-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: 1253.08
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 123
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.433
    dispatch_time_ms: 6.008
    learner:
      cur_lr: 0.0011142459698021412
      grad_gnorm: 40.0
      policy_entropy: 149.73654174804688
      policy_loss: -14.49834156036377
      var_gnorm: 22.755048751831055
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 18.666698455810547
    num_steps_sampled: 3720000
    num_steps_trained: 3720000
    wait_time_ms: 437.687
  iterations_since_restore: 124
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 5530.287102222443
  time_this_iter_s: 43.82243824005127
  time_total_s: 5530.287102222443
  timestamp: 1594157705
  timesteps_since_restore: 3720000
  timesteps_this_iter: 30000
  timesteps_total: 3720000
  training_iteration: 124
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 5530 s, 124 iter, 3720000 ts, 1.25e+03 rew

agent-1: 48.0
agent-2: 29.0
agent-3: 52.0
agent-4: 49.0
agent-5: 41.0
agent-6: 41.0
agent-7: 50.0
agent-8: 41.0
agent-9: 28.0
agent-10: 43.0
agent-11: 64.0
agent-12: 36.0
agent-13: 34.0
agent-14: 46.0
agent-15: 50.0
agent-16: 27.0
agent-17: 53.0
agent-18: 47.0
agent-19: 72.0
agent-20: 40.0
agent-21: 32.0
agent-22: 57.0
agent-23: 45.0
agent-24: 41.0
agent-25: 23.0
agent-26: 32.0
agent-27: 32.0
agent-28: 46.0
agent-29: 59.0
agent-30: 46.0
Sum Reward: 1304.0
Avg Reward: 43.46666666666667
Min Reward: 23.0
Max Reward: 72.0
Gini Coefficient: 0.1429959100204499
20:20 Ratio: 2.087719298245614
Max-min Ratio: 3.130434782608696
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-35-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: 1255.66
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 124
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 4.33
    dispatch_time_ms: 7.807
    learner:
      cur_lr: 0.0011122480500489473
      grad_gnorm: 40.000003814697266
      policy_entropy: 180.6617431640625
      policy_loss: 11.985722541809082
      var_gnorm: 22.751300811767578
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 49.38285827636719
    num_steps_sampled: 3750000
    num_steps_trained: 3750000
    wait_time_ms: 417.85
  iterations_since_restore: 125
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 5574.299423217773
  time_this_iter_s: 44.01232099533081
  time_total_s: 5574.299423217773
  timestamp: 1594157749
  timesteps_since_restore: 3750000
  timesteps_this_iter: 30000
  timesteps_total: 3750000
  training_iteration: 125
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 5574 s, 125 iter, 3750000 ts, 1.26e+03 rew

agent-1: 39.0
agent-2: 48.0
agent-3: 47.0
agent-4: 54.0
agent-5: 41.0
agent-6: 20.0
agent-7: 46.0
agent-8: 31.0
agent-9: 39.0
agent-10: 28.0
agent-11: 51.0
agent-12: 24.0
agent-13: 37.0
agent-14: 56.0
agent-15: 38.0
agent-16: 52.0
agent-17: 13.0
agent-18: 54.0
agent-19: 31.0
agent-20: 39.0
agent-21: 34.0
agent-22: 39.0
agent-23: 41.0
agent-24: 43.0
agent-25: 43.0
agent-26: 23.0
agent-27: 34.0
agent-28: 51.0
agent-29: 36.0
agent-30: 64.0
Sum Reward: 1196.0
Avg Reward: 39.86666666666667
Min Reward: 13.0
Max Reward: 64.0
Gini Coefficient: 0.15981047937569676
20:20 Ratio: 2.381294964028777
Max-min Ratio: 4.923076923076923
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-36-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: 1255.16
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 125
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.609
    dispatch_time_ms: 6.018
    learner:
      cur_lr: 0.0011102500138804317
      grad_gnorm: 4.432521343231201
      policy_entropy: 156.78787231445312
      policy_loss: -1.0868099927902222
      var_gnorm: 22.76312255859375
      vf_explained_var: 0.0
      vf_loss: 79.0130615234375
    num_steps_sampled: 3780000
    num_steps_trained: 3780000
    wait_time_ms: 432.801
  iterations_since_restore: 126
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 5617.1711003780365
  time_this_iter_s: 42.87167716026306
  time_total_s: 5617.1711003780365
  timestamp: 1594157792
  timesteps_since_restore: 3780000
  timesteps_this_iter: 30000
  timesteps_total: 3780000
  training_iteration: 126
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 5617 s, 126 iter, 3780000 ts, 1.26e+03 rew

agent-1: 48.0
agent-2: 38.0
agent-3: 56.0
agent-4: 39.0
agent-5: 58.0
agent-6: 35.0
agent-7: 33.0
agent-8: 78.0
agent-9: 72.0
agent-10: 46.0
agent-11: 28.0
agent-12: 36.0
agent-13: 71.0
agent-14: 28.0
agent-15: 51.0
agent-16: 42.0
agent-17: 48.0
agent-18: 42.0
agent-19: 41.0
agent-20: 31.0
agent-21: 41.0
agent-22: 54.0
agent-23: 71.0
agent-24: 56.0
agent-25: 51.0
agent-26: 70.0
agent-27: 49.0
agent-28: 30.0
agent-29: 21.0
agent-30: 69.0
Sum Reward: 1433.0
Avg Reward: 47.766666666666666
Min Reward: 21.0
Max Reward: 78.0
Gini Coefficient: 0.17834380088392648
20:20 Ratio: 2.52046783625731
Max-min Ratio: 3.7142857142857144
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-37-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: 1257.18
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 126
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.018
    dispatch_time_ms: 5.964
    learner:
      cur_lr: 0.001108251977711916
      grad_gnorm: 40.0
      policy_entropy: 137.9637451171875
      policy_loss: -22.966352462768555
      var_gnorm: 22.75896453857422
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.853934288024902
    num_steps_sampled: 3810000
    num_steps_trained: 3810000
    wait_time_ms: 420.041
  iterations_since_restore: 127
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 5659.893138408661
  time_this_iter_s: 42.72203803062439
  time_total_s: 5659.893138408661
  timestamp: 1594157836
  timesteps_since_restore: 3810000
  timesteps_this_iter: 30000
  timesteps_total: 3810000
  training_iteration: 127
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 5659 s, 127 iter, 3810000 ts, 1.26e+03 rew

agent-1: 72.0
agent-2: 36.0
agent-3: 37.0
agent-4: 66.0
agent-5: 40.0
agent-6: 31.0
agent-7: 61.0
agent-8: 50.0
agent-9: 69.0
agent-10: 54.0
agent-11: 48.0
agent-12: 32.0
agent-13: 33.0
agent-14: 50.0
agent-15: 28.0
agent-16: 59.0
agent-17: 42.0
agent-18: 38.0
agent-19: 24.0
agent-20: 38.0
agent-21: 60.0
agent-22: 42.0
agent-23: 41.0
agent-24: 15.0
agent-25: 32.0
agent-26: 34.0
agent-27: 54.0
agent-28: 39.0
agent-29: 54.0
agent-30: 45.0
Sum Reward: 1324.0
Avg Reward: 44.13333333333333
Min Reward: 15.0
Max Reward: 72.0
Gini Coefficient: 0.17265861027190332
20:20 Ratio: 2.388888888888889
Max-min Ratio: 4.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-37-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: 1258.1
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 127
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.914
    dispatch_time_ms: 8.389
    learner:
      cur_lr: 0.0011062540579587221
      grad_gnorm: 40.0
      policy_entropy: 158.81671142578125
      policy_loss: -3.681877613067627
      var_gnorm: 22.763399124145508
      vf_explained_var: 0.0
      vf_loss: 70.60276794433594
    num_steps_sampled: 3840000
    num_steps_trained: 3840000
    wait_time_ms: 427.365
  iterations_since_restore: 128
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 5703.259669542313
  time_this_iter_s: 43.36653113365173
  time_total_s: 5703.259669542313
  timestamp: 1594157879
  timesteps_since_restore: 3840000
  timesteps_this_iter: 30000
  timesteps_total: 3840000
  training_iteration: 128
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 5703 s, 128 iter, 3840000 ts, 1.26e+03 rew

agent-1: 46.0
agent-2: 33.0
agent-3: 40.0
agent-4: 49.0
agent-5: 59.0
agent-6: 72.0
agent-7: 44.0
agent-8: 48.0
agent-9: 47.0
agent-10: 57.0
agent-11: 22.0
agent-12: 39.0
agent-13: 43.0
agent-14: 25.0
agent-15: 82.0
agent-16: 51.0
agent-17: 39.0
agent-18: 43.0
agent-19: 43.0
agent-20: 21.0
agent-21: 36.0
agent-22: 68.0
agent-23: 26.0
agent-24: 13.0
agent-25: 44.0
agent-26: 47.0
agent-27: 63.0
agent-28: 44.0
agent-29: 14.0
agent-30: 43.0
Sum Reward: 1301.0
Avg Reward: 43.36666666666667
Min Reward: 13.0
Max Reward: 82.0
Gini Coefficient: 0.19951319497822187
20:20 Ratio: 3.3140495867768593
Max-min Ratio: 6.3076923076923075
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-38-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: 1256.77
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 128
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.582
    dispatch_time_ms: 6.724
    learner:
      cur_lr: 0.0011042560217902064
      grad_gnorm: 40.0
      policy_entropy: 161.0644989013672
      policy_loss: 48.66448974609375
      var_gnorm: 22.759782791137695
      vf_explained_var: 0.0
      vf_loss: 108.03831481933594
    num_steps_sampled: 3870000
    num_steps_trained: 3870000
    wait_time_ms: 401.117
  iterations_since_restore: 129
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 5746.956230401993
  time_this_iter_s: 43.696560859680176
  time_total_s: 5746.956230401993
  timestamp: 1594157923
  timesteps_since_restore: 3870000
  timesteps_this_iter: 30000
  timesteps_total: 3870000
  training_iteration: 129
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 5746 s, 129 iter, 3870000 ts, 1.26e+03 rew

agent-1: 40.0
agent-2: 52.0
agent-3: 45.0
agent-4: 51.0
agent-5: 45.0
agent-6: 66.0
agent-7: 70.0
agent-8: 61.0
agent-9: 72.0
agent-10: 64.0
agent-11: 44.0
agent-12: 57.0
agent-13: 39.0
agent-14: 44.0
agent-15: 65.0
agent-16: 33.0
agent-17: 9.0
agent-18: 47.0
agent-19: 29.0
agent-20: 27.0
agent-21: 26.0
agent-22: 27.0
agent-23: 53.0
agent-24: 34.0
agent-25: 38.0
agent-26: 31.0
agent-27: 27.0
agent-28: 58.0
agent-29: 67.0
agent-30: 49.0
Sum Reward: 1370.0
Avg Reward: 45.666666666666664
Min Reward: 9.0
Max Reward: 72.0
Gini Coefficient: 0.19347931873479318
20:20 Ratio: 2.786206896551724
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-39-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: 1259.2
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 129
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.783
    dispatch_time_ms: 5.609
    learner:
      cur_lr: 0.0011022579856216908
      grad_gnorm: 40.0
      policy_entropy: 103.13101959228516
      policy_loss: -2.425323963165283
      var_gnorm: 22.76414680480957
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 47.833431243896484
    num_steps_sampled: 3900000
    num_steps_trained: 3900000
    wait_time_ms: 449.45
  iterations_since_restore: 130
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 5790.43376493454
  time_this_iter_s: 43.477534532547
  time_total_s: 5790.43376493454
  timestamp: 1594157967
  timesteps_since_restore: 3900000
  timesteps_this_iter: 30000
  timesteps_total: 3900000
  training_iteration: 130
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 5790 s, 130 iter, 3900000 ts, 1.26e+03 rew

agent-1: 60.0
agent-2: 46.0
agent-3: 58.0
agent-4: 46.0
agent-5: 28.0
agent-6: 54.0
agent-7: 46.0
agent-8: 49.0
agent-9: 32.0
agent-10: 62.0
agent-11: 30.0
agent-12: 60.0
agent-13: 47.0
agent-14: 80.0
agent-15: 29.0
agent-16: 40.0
agent-17: 43.0
agent-18: 28.0
agent-19: 57.0
agent-20: 69.0
agent-21: 51.0
agent-22: 32.0
agent-23: 37.0
agent-24: 10.0
agent-25: 57.0
agent-26: 56.0
agent-27: 65.0
agent-28: 64.0
agent-29: 38.0
agent-30: 66.0
Sum Reward: 1440.0
Avg Reward: 48.0
Min Reward: 10.0
Max Reward: 80.0
Gini Coefficient: 0.1787037037037037
20:20 Ratio: 2.5859872611464967
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-40-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: 1263.4
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 130
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.218
    dispatch_time_ms: 10.46
    learner:
      cur_lr: 0.001100259949453175
      grad_gnorm: 23.96200942993164
      policy_entropy: 134.10122680664062
      policy_loss: -0.03447036072611809
      var_gnorm: 22.759822845458984
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 36.02751541137695
    num_steps_sampled: 3930000
    num_steps_trained: 3930000
    wait_time_ms: 429.407
  iterations_since_restore: 131
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 5834.2205901145935
  time_this_iter_s: 43.78682518005371
  time_total_s: 5834.2205901145935
  timestamp: 1594158010
  timesteps_since_restore: 3930000
  timesteps_this_iter: 30000
  timesteps_total: 3930000
  training_iteration: 131
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 5834 s, 131 iter, 3930000 ts, 1.26e+03 rew

agent-1: 17.0
agent-2: 55.0
agent-3: 51.0
agent-4: 52.0
agent-5: 46.0
agent-6: 32.0
agent-7: 58.0
agent-8: 50.0
agent-9: 54.0
agent-10: 43.0
agent-11: 37.0
agent-12: 47.0
agent-13: 42.0
agent-14: 35.0
agent-15: 24.0
agent-16: 35.0
agent-17: 57.0
agent-18: 42.0
agent-19: 41.0
agent-20: 58.0
agent-21: 42.0
agent-22: 46.0
agent-23: 46.0
agent-24: 69.0
agent-25: 15.0
agent-26: 24.0
agent-27: 19.0
agent-28: 46.0
agent-29: 43.0
agent-30: 35.0
Sum Reward: 1261.0
Avg Reward: 42.03333333333333
Min Reward: 15.0
Max Reward: 69.0
Gini Coefficient: 0.1695744118424531
20:20 Ratio: 2.6793893129770994
Max-min Ratio: 4.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-40-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: 1265.05
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 131
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.07
    dispatch_time_ms: 6.868
    learner:
      cur_lr: 0.0010982620296999812
      grad_gnorm: 40.0
      policy_entropy: 145.2776641845703
      policy_loss: -19.698631286621094
      var_gnorm: 22.76294708251953
      vf_explained_var: 0.0
      vf_loss: 30.58701515197754
    num_steps_sampled: 3960000
    num_steps_trained: 3960000
    wait_time_ms: 426.748
  iterations_since_restore: 132
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 5877.729393482208
  time_this_iter_s: 43.508803367614746
  time_total_s: 5877.729393482208
  timestamp: 1594158054
  timesteps_since_restore: 3960000
  timesteps_this_iter: 30000
  timesteps_total: 3960000
  training_iteration: 132
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 5877 s, 132 iter, 3960000 ts, 1.27e+03 rew

agent-1: 53.0
agent-2: 48.0
agent-3: 54.0
agent-4: 32.0
agent-5: 59.0
agent-6: 25.0
agent-7: 49.0
agent-8: 47.0
agent-9: 58.0
agent-10: 34.0
agent-11: 34.0
agent-12: 42.0
agent-13: 47.0
agent-14: 47.0
agent-15: 71.0
agent-16: 30.0
agent-17: 40.0
agent-18: 60.0
agent-19: 52.0
agent-20: 52.0
agent-21: 53.0
agent-22: 34.0
agent-23: 41.0
agent-24: 50.0
agent-25: 56.0
agent-26: 60.0
agent-27: 47.0
agent-28: 24.0
agent-29: 40.0
agent-30: 42.0
Sum Reward: 1381.0
Avg Reward: 46.03333333333333
Min Reward: 24.0
Max Reward: 71.0
Gini Coefficient: 0.1348056963552981
20:20 Ratio: 2.0335195530726256
Max-min Ratio: 2.9583333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-41-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: 1264.1
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 132
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.553
    dispatch_time_ms: 5.48
    learner:
      cur_lr: 0.0010962639935314655
      grad_gnorm: 40.0
      policy_entropy: 139.1563720703125
      policy_loss: -21.60822868347168
      var_gnorm: 22.76654624938965
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 28.695798873901367
    num_steps_sampled: 3990000
    num_steps_trained: 3990000
    wait_time_ms: 441.87
  iterations_since_restore: 133
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 5921.297726869583
  time_this_iter_s: 43.56833338737488
  time_total_s: 5921.297726869583
  timestamp: 1594158098
  timesteps_since_restore: 3990000
  timesteps_this_iter: 30000
  timesteps_total: 3990000
  training_iteration: 133
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 5921 s, 133 iter, 3990000 ts, 1.26e+03 rew

agent-1: 43.0
agent-2: 85.0
agent-3: 37.0
agent-4: 56.0
agent-5: 39.0
agent-6: 70.0
agent-7: 49.0
agent-8: 32.0
agent-9: 66.0
agent-10: 54.0
agent-11: 41.0
agent-12: 68.0
agent-13: 49.0
agent-14: 31.0
agent-15: 55.0
agent-16: 53.0
agent-17: 48.0
agent-18: 62.0
agent-19: 64.0
agent-20: 28.0
agent-21: 45.0
agent-22: 51.0
agent-23: 46.0
agent-24: 57.0
agent-25: 22.0
agent-26: 53.0
agent-27: 73.0
agent-28: 58.0
agent-29: 73.0
agent-30: 50.0
Sum Reward: 1558.0
Avg Reward: 51.93333333333333
Min Reward: 22.0
Max Reward: 85.0
Gini Coefficient: 0.1550278134360291
20:20 Ratio: 2.3015873015873014
Max-min Ratio: 3.8636363636363638
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-42-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: 1265.44
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 133
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.185
    dispatch_time_ms: 6.162
    learner:
      cur_lr: 0.0010942659573629498
      grad_gnorm: 40.0
      policy_entropy: 105.78317260742188
      policy_loss: 1.207708477973938
      var_gnorm: 22.765295028686523
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 64.02538299560547
    num_steps_sampled: 4020000
    num_steps_trained: 4020000
    wait_time_ms: 426.611
  iterations_since_restore: 134
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 5964.949867725372
  time_this_iter_s: 43.652140855789185
  time_total_s: 5964.949867725372
  timestamp: 1594158141
  timesteps_since_restore: 4020000
  timesteps_this_iter: 30000
  timesteps_total: 4020000
  training_iteration: 134
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 5964 s, 134 iter, 4020000 ts, 1.27e+03 rew

agent-1: 25.0
agent-2: 19.0
agent-3: 38.0
agent-4: 50.0
agent-5: 41.0
agent-6: 35.0
agent-7: 43.0
agent-8: 49.0
agent-9: 41.0
agent-10: 36.0
agent-11: 58.0
agent-12: 50.0
agent-13: 35.0
agent-14: 40.0
agent-15: 29.0
agent-16: 25.0
agent-17: 18.0
agent-18: 32.0
agent-19: 72.0
agent-20: 39.0
agent-21: 20.0
agent-22: 36.0
agent-23: 45.0
agent-24: 50.0
agent-25: 56.0
agent-26: 29.0
agent-27: 64.0
agent-28: 52.0
agent-29: 52.0
agent-30: 50.0
Sum Reward: 1229.0
Avg Reward: 40.96666666666667
Min Reward: 18.0
Max Reward: 72.0
Gini Coefficient: 0.18028207214537564
20:20 Ratio: 2.6029411764705883
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-43-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: 1265.65
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 134
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.434
    dispatch_time_ms: 7.603
    learner:
      cur_lr: 0.001092268037609756
      grad_gnorm: 40.000003814697266
      policy_entropy: 110.17263793945312
      policy_loss: -11.286401748657227
      var_gnorm: 22.767173767089844
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 14.441645622253418
    num_steps_sampled: 4050000
    num_steps_trained: 4050000
    wait_time_ms: 444.488
  iterations_since_restore: 135
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 6008.840468883514
  time_this_iter_s: 43.89060115814209
  time_total_s: 6008.840468883514
  timestamp: 1594158185
  timesteps_since_restore: 4050000
  timesteps_this_iter: 30000
  timesteps_total: 4050000
  training_iteration: 135
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 6008 s, 135 iter, 4050000 ts, 1.27e+03 rew

agent-1: 32.0
agent-2: 48.0
agent-3: 36.0
agent-4: 46.0
agent-5: 30.0
agent-6: 79.0
agent-7: 36.0
agent-8: 45.0
agent-9: 51.0
agent-10: 48.0
agent-11: 33.0
agent-12: 55.0
agent-13: 54.0
agent-14: 36.0
agent-15: 47.0
agent-16: 26.0
agent-17: 69.0
agent-18: 47.0
agent-19: 45.0
agent-20: 37.0
agent-21: 72.0
agent-22: 45.0
agent-23: 77.0
agent-24: 34.0
agent-25: 39.0
agent-26: 60.0
agent-27: 51.0
agent-28: 44.0
agent-29: 38.0
agent-30: 50.0
Sum Reward: 1410.0
Avg Reward: 47.0
Min Reward: 26.0
Max Reward: 79.0
Gini Coefficient: 0.15394799054373523
20:20 Ratio: 2.157068062827225
Max-min Ratio: 3.0384615384615383
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-43-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: 1266.63
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 135
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.015
    dispatch_time_ms: 21.527
    learner:
      cur_lr: 0.0010902700014412403
      grad_gnorm: 18.475732803344727
      policy_entropy: 153.01861572265625
      policy_loss: 2.557366371154785
      var_gnorm: 22.766708374023438
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 49.182777404785156
    num_steps_sampled: 4080000
    num_steps_trained: 4080000
    wait_time_ms: 446.454
  iterations_since_restore: 136
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 6053.095455646515
  time_this_iter_s: 44.25498676300049
  time_total_s: 6053.095455646515
  timestamp: 1594158229
  timesteps_since_restore: 4080000
  timesteps_this_iter: 30000
  timesteps_total: 4080000
  training_iteration: 136
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 6053 s, 136 iter, 4080000 ts, 1.27e+03 rew

agent-1: 53.0
agent-2: 43.0
agent-3: 24.0
agent-4: 51.0
agent-5: 37.0
agent-6: 43.0
agent-7: 49.0
agent-8: 46.0
agent-9: 44.0
agent-10: 54.0
agent-11: 57.0
agent-12: 61.0
agent-13: 19.0
agent-14: 34.0
agent-15: 10.0
agent-16: 61.0
agent-17: 27.0
agent-18: 55.0
agent-19: 57.0
agent-20: 41.0
agent-21: 40.0
agent-22: 33.0
agent-23: 59.0
agent-24: 28.0
agent-25: 38.0
agent-26: 39.0
agent-27: 35.0
agent-28: 41.0
agent-29: 42.0
agent-30: 26.0
Sum Reward: 1247.0
Avg Reward: 41.56666666666667
Min Reward: 10.0
Max Reward: 61.0
Gini Coefficient: 0.17254744720662923
20:20 Ratio: 2.611940298507463
Max-min Ratio: 6.1
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-44-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: 1267.61
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 136
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.455
    dispatch_time_ms: 5.784
    learner:
      cur_lr: 0.0010882719652727246
      grad_gnorm: 33.563392639160156
      policy_entropy: 104.5228042602539
      policy_loss: -9.406133651733398
      var_gnorm: 22.763444900512695
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 27.951465606689453
    num_steps_sampled: 4110000
    num_steps_trained: 4110000
    wait_time_ms: 451.278
  iterations_since_restore: 137
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 6097.897710800171
  time_this_iter_s: 44.802255153656006
  time_total_s: 6097.897710800171
  timestamp: 1594158274
  timesteps_since_restore: 4110000
  timesteps_this_iter: 30000
  timesteps_total: 4110000
  training_iteration: 137
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 6097 s, 137 iter, 4110000 ts, 1.27e+03 rew

agent-1: 18.0
agent-2: 20.0
agent-3: 31.0
agent-4: 44.0
agent-5: 43.0
agent-6: 36.0
agent-7: 43.0
agent-8: 26.0
agent-9: 45.0
agent-10: 20.0
agent-11: 46.0
agent-12: 41.0
agent-13: 22.0
agent-14: 32.0
agent-15: 28.0
agent-16: 40.0
agent-17: 32.0
agent-18: 25.0
agent-19: 70.0
agent-20: 46.0
agent-21: 59.0
agent-22: 32.0
agent-23: 39.0
agent-24: 22.0
agent-25: 39.0
agent-26: 43.0
agent-27: 37.0
agent-28: 50.0
agent-29: 20.0
agent-30: 58.0
Sum Reward: 1107.0
Avg Reward: 36.9
Min Reward: 18.0
Max Reward: 70.0
Gini Coefficient: 0.19003312255344776
20:20 Ratio: 2.69672131147541
Max-min Ratio: 3.888888888888889
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-45-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: 1264.88
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 137
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.586
    dispatch_time_ms: 5.718
    learner:
      cur_lr: 0.0010862740455195308
      grad_gnorm: 28.713918685913086
      policy_entropy: 130.7147216796875
      policy_loss: -10.869710922241211
      var_gnorm: 22.76874542236328
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 31.66524887084961
    num_steps_sampled: 4140000
    num_steps_trained: 4140000
    wait_time_ms: 414.895
  iterations_since_restore: 138
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 6140.826350688934
  time_this_iter_s: 42.92863988876343
  time_total_s: 6140.826350688934
  timestamp: 1594158317
  timesteps_since_restore: 4140000
  timesteps_this_iter: 30000
  timesteps_total: 4140000
  training_iteration: 138
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 6140 s, 138 iter, 4140000 ts, 1.26e+03 rew

agent-1: 62.0
agent-2: 48.0
agent-3: 94.0
agent-4: 32.0
agent-5: 42.0
agent-6: 47.0
agent-7: 53.0
agent-8: 20.0
agent-9: 56.0
agent-10: 32.0
agent-11: 75.0
agent-12: 64.0
agent-13: 56.0
agent-14: 30.0
agent-15: 58.0
agent-16: 47.0
agent-17: 45.0
agent-18: 57.0
agent-19: 39.0
agent-20: 54.0
agent-21: 61.0
agent-22: 67.0
agent-23: 39.0
agent-24: 16.0
agent-25: 55.0
agent-26: 38.0
agent-27: 52.0
agent-28: 64.0
agent-29: 53.0
agent-30: 39.0
Sum Reward: 1495.0
Avg Reward: 49.833333333333336
Min Reward: 16.0
Max Reward: 94.0
Gini Coefficient: 0.17366778149386844
20:20 Ratio: 2.5357142857142856
Max-min Ratio: 5.875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-46-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: 1265.86
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 138
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.056
    dispatch_time_ms: 5.751
    learner:
      cur_lr: 0.001084276009351015
      grad_gnorm: 8.183087348937988
      policy_entropy: 150.2916259765625
      policy_loss: -0.5445839762687683
      var_gnorm: 22.770971298217773
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 44.61488342285156
    num_steps_sampled: 4170000
    num_steps_trained: 4170000
    wait_time_ms: 423.087
  iterations_since_restore: 139
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 6184.290327072144
  time_this_iter_s: 43.46397638320923
  time_total_s: 6184.290327072144
  timestamp: 1594158361
  timesteps_since_restore: 4170000
  timesteps_this_iter: 30000
  timesteps_total: 4170000
  training_iteration: 139
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 6184 s, 139 iter, 4170000 ts, 1.27e+03 rew

agent-1: 36.0
agent-2: 68.0
agent-3: 53.0
agent-4: 63.0
agent-5: 46.0
agent-6: 60.0
agent-7: 28.0
agent-8: 32.0
agent-9: 51.0
agent-10: 60.0
agent-11: 30.0
agent-12: 39.0
agent-13: 50.0
agent-14: 46.0
agent-15: 45.0
agent-16: 51.0
agent-17: 44.0
agent-18: 29.0
agent-19: 51.0
agent-20: 70.0
agent-21: 41.0
agent-22: 29.0
agent-23: 56.0
agent-24: 13.0
agent-25: 59.0
agent-26: 46.0
agent-27: 41.0
agent-28: 64.0
agent-29: 14.0
agent-30: 82.0
Sum Reward: 1397.0
Avg Reward: 46.56666666666667
Min Reward: 13.0
Max Reward: 82.0
Gini Coefficient: 0.18985922214268672
20:20 Ratio: 2.8461538461538463
Max-min Ratio: 6.3076923076923075
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-46-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: 1267.83
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 139
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.598
    dispatch_time_ms: 6.697
    learner:
      cur_lr: 0.0010822779731824994
      grad_gnorm: 40.0
      policy_entropy: 166.79515075683594
      policy_loss: -13.068806648254395
      var_gnorm: 22.76839828491211
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 27.357664108276367
    num_steps_sampled: 4200000
    num_steps_trained: 4200000
    wait_time_ms: 430.724
  iterations_since_restore: 140
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 6228.125633716583
  time_this_iter_s: 43.8353066444397
  time_total_s: 6228.125633716583
  timestamp: 1594158405
  timesteps_since_restore: 4200000
  timesteps_this_iter: 30000
  timesteps_total: 4200000
  training_iteration: 140
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 6228 s, 140 iter, 4200000 ts, 1.27e+03 rew

agent-1: 71.0
agent-2: 51.0
agent-3: 55.0
agent-4: 62.0
agent-5: 25.0
agent-6: 78.0
agent-7: 31.0
agent-8: 25.0
agent-9: 49.0
agent-10: 18.0
agent-11: 29.0
agent-12: 59.0
agent-13: 49.0
agent-14: 45.0
agent-15: 45.0
agent-16: 52.0
agent-17: 36.0
agent-18: 7.0
agent-19: 25.0
agent-20: 42.0
agent-21: 32.0
agent-22: 57.0
agent-23: 23.0
agent-24: 20.0
agent-25: 38.0
agent-26: 41.0
agent-27: 20.0
agent-28: 48.0
agent-29: 50.0
agent-30: 63.0
Sum Reward: 1246.0
Avg Reward: 41.53333333333333
Min Reward: 7.0
Max Reward: 78.0
Gini Coefficient: 0.23044408774745853
20:20 Ratio: 3.4513274336283186
Max-min Ratio: 11.142857142857142
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-47-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: 1266.74
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 140
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.773
    dispatch_time_ms: 6.533
    learner:
      cur_lr: 0.0010802800534293056
      grad_gnorm: 40.000003814697266
      policy_entropy: 179.1280517578125
      policy_loss: -22.133190155029297
      var_gnorm: 22.766029357910156
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 21.312755584716797
    num_steps_sampled: 4230000
    num_steps_trained: 4230000
    wait_time_ms: 426.556
  iterations_since_restore: 141
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 6271.9240465164185
  time_this_iter_s: 43.798412799835205
  time_total_s: 6271.9240465164185
  timestamp: 1594158448
  timesteps_since_restore: 4230000
  timesteps_this_iter: 30000
  timesteps_total: 4230000
  training_iteration: 141
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 6271 s, 141 iter, 4230000 ts, 1.27e+03 rew

agent-1: 38.0
agent-2: 20.0
agent-3: 56.0
agent-4: 53.0
agent-5: 47.0
agent-6: 37.0
agent-7: 49.0
agent-8: 20.0
agent-9: 37.0
agent-10: 42.0
agent-11: 55.0
agent-12: 17.0
agent-13: 27.0
agent-14: 26.0
agent-15: 48.0
agent-16: 38.0
agent-17: 39.0
agent-18: 64.0
agent-19: 32.0
agent-20: 43.0
agent-21: 55.0
agent-22: 42.0
agent-23: 36.0
agent-24: 40.0
agent-25: 54.0
agent-26: 43.0
agent-27: 34.0
agent-28: 59.0
agent-29: 20.0
agent-30: 56.0
Sum Reward: 1227.0
Avg Reward: 40.9
Min Reward: 17.0
Max Reward: 64.0
Gini Coefficient: 0.1737299646835099
20:20 Ratio: 2.6538461538461537
Max-min Ratio: 3.764705882352941
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-48-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: 1267.78
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 141
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.987
    dispatch_time_ms: 10.002
    learner:
      cur_lr: 0.0010782820172607899
      grad_gnorm: 40.000003814697266
      policy_entropy: 196.08425903320312
      policy_loss: -32.3254280090332
      var_gnorm: 22.76467514038086
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 5.281689643859863
    num_steps_sampled: 4260000
    num_steps_trained: 4260000
    wait_time_ms: 429.71
  iterations_since_restore: 142
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 6315.8418798446655
  time_this_iter_s: 43.91783332824707
  time_total_s: 6315.8418798446655
  timestamp: 1594158492
  timesteps_since_restore: 4260000
  timesteps_this_iter: 30000
  timesteps_total: 4260000
  training_iteration: 142
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 6315 s, 142 iter, 4260000 ts, 1.27e+03 rew

agent-1: 40.0
agent-2: 60.0
agent-3: 45.0
agent-4: 36.0
agent-5: 45.0
agent-6: 49.0
agent-7: 53.0
agent-8: 48.0
agent-9: 48.0
agent-10: 32.0
agent-11: 36.0
agent-12: 41.0
agent-13: 34.0
agent-14: 51.0
agent-15: 55.0
agent-16: 35.0
agent-17: 48.0
agent-18: 39.0
agent-19: 30.0
agent-20: 53.0
agent-21: 50.0
agent-22: 49.0
agent-23: 28.0
agent-24: 20.0
agent-25: 59.0
agent-26: 21.0
agent-27: 24.0
agent-28: 47.0
agent-29: 39.0
agent-30: 42.0
Sum Reward: 1257.0
Avg Reward: 41.9
Min Reward: 20.0
Max Reward: 60.0
Gini Coefficient: 0.1420578095995757
20:20 Ratio: 2.1354838709677417
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-48-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1572.0
  episode_reward_mean: 1268.76
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 142
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.945
    dispatch_time_ms: 7.851
    learner:
      cur_lr: 0.0010762839810922742
      grad_gnorm: 40.0
      policy_entropy: 234.73648071289062
      policy_loss: -41.29212951660156
      var_gnorm: 22.771547317504883
      vf_explained_var: 0.0
      vf_loss: 6.157962799072266
    num_steps_sampled: 4290000
    num_steps_trained: 4290000
    wait_time_ms: 422.988
  iterations_since_restore: 143
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 6359.57611823082
  time_this_iter_s: 43.734238386154175
  time_total_s: 6359.57611823082
  timestamp: 1594158536
  timesteps_since_restore: 4290000
  timesteps_this_iter: 30000
  timesteps_total: 4290000
  training_iteration: 143
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 6359 s, 143 iter, 4290000 ts, 1.27e+03 rew

agent-1: 50.0
agent-2: 35.0
agent-3: 40.0
agent-4: 60.0
agent-5: 68.0
agent-6: 19.0
agent-7: 21.0
agent-8: 42.0
agent-9: 35.0
agent-10: 33.0
agent-11: 62.0
agent-12: 29.0
agent-13: 22.0
agent-14: 36.0
agent-15: 28.0
agent-16: 30.0
agent-17: 37.0
agent-18: 37.0
agent-19: 50.0
agent-20: 45.0
agent-21: 56.0
agent-22: 53.0
agent-23: 38.0
agent-24: 24.0
agent-25: 62.0
agent-26: 33.0
agent-27: 41.0
agent-28: 38.0
agent-29: 28.0
agent-30: 8.0
Sum Reward: 1160.0
Avg Reward: 38.666666666666664
Min Reward: 8.0
Max Reward: 68.0
Gini Coefficient: 0.20281609195402298
20:20 Ratio: 2.959016393442623
Max-min Ratio: 8.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-49-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1566.0
  episode_reward_mean: 1264.64
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 143
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 4.227
    dispatch_time_ms: 6.592
    learner:
      cur_lr: 0.0010742859449237585
      grad_gnorm: 40.000003814697266
      policy_entropy: 263.3582763671875
      policy_loss: 26.212608337402344
      var_gnorm: 22.77558708190918
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 143.00331115722656
    num_steps_sampled: 4320000
    num_steps_trained: 4320000
    wait_time_ms: 431.775
  iterations_since_restore: 144
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 6403.367390871048
  time_this_iter_s: 43.79127264022827
  time_total_s: 6403.367390871048
  timestamp: 1594158580
  timesteps_since_restore: 4320000
  timesteps_this_iter: 30000
  timesteps_total: 4320000
  training_iteration: 144
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 6403 s, 144 iter, 4320000 ts, 1.26e+03 rew

agent-1: 54.0
agent-2: 48.0
agent-3: 30.0
agent-4: 79.0
agent-5: 61.0
agent-6: 44.0
agent-7: 33.0
agent-8: 62.0
agent-9: 35.0
agent-10: 40.0
agent-11: 18.0
agent-12: 69.0
agent-13: 56.0
agent-14: 63.0
agent-15: 51.0
agent-16: 66.0
agent-17: 33.0
agent-18: 30.0
agent-19: 47.0
agent-20: 40.0
agent-21: 57.0
agent-22: 43.0
agent-23: 55.0
agent-24: 49.0
agent-25: 28.0
agent-26: 43.0
agent-27: 51.0
agent-28: 48.0
agent-29: 39.0
agent-30: 58.0
Sum Reward: 1430.0
Avg Reward: 47.666666666666664
Min Reward: 18.0
Max Reward: 79.0
Gini Coefficient: 0.16097902097902098
20:20 Ratio: 2.3255813953488373
Max-min Ratio: 4.388888888888889
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-50-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1566.0
  episode_reward_mean: 1268.37
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 144
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.105
    dispatch_time_ms: 7.738
    learner:
      cur_lr: 0.0010722880251705647
      grad_gnorm: 40.000003814697266
      policy_entropy: 264.4244384765625
      policy_loss: 25.850582122802734
      var_gnorm: 22.774309158325195
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 67.60359191894531
    num_steps_sampled: 4350000
    num_steps_trained: 4350000
    wait_time_ms: 423.2
  iterations_since_restore: 145
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 6447.575597047806
  time_this_iter_s: 44.20820617675781
  time_total_s: 6447.575597047806
  timestamp: 1594158624
  timesteps_since_restore: 4350000
  timesteps_this_iter: 30000
  timesteps_total: 4350000
  training_iteration: 145
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 6447 s, 145 iter, 4350000 ts, 1.27e+03 rew

agent-1: 26.0
agent-2: 42.0
agent-3: 28.0
agent-4: 47.0
agent-5: 28.0
agent-6: 36.0
agent-7: 19.0
agent-8: 37.0
agent-9: 9.0
agent-10: 49.0
agent-11: 37.0
agent-12: 32.0
agent-13: 64.0
agent-14: 26.0
agent-15: 44.0
agent-16: 42.0
agent-17: 57.0
agent-18: 31.0
agent-19: 12.0
agent-20: 60.0
agent-21: 66.0
agent-22: 21.0
agent-23: 49.0
agent-24: 33.0
agent-25: 18.0
agent-26: 14.0
agent-27: 26.0
agent-28: 32.0
agent-29: 31.0
agent-30: 34.0
Sum Reward: 1050.0
Avg Reward: 35.0
Min Reward: 9.0
Max Reward: 66.0
Gini Coefficient: 0.23523809523809525
20:20 Ratio: 3.7096774193548385
Max-min Ratio: 7.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-51-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1566.0
  episode_reward_mean: 1264.54
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 145
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.569
    dispatch_time_ms: 6.576
    learner:
      cur_lr: 0.001070289989002049
      grad_gnorm: 40.0
      policy_entropy: 204.56773376464844
      policy_loss: -19.517240524291992
      var_gnorm: 22.774803161621094
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 4.558493137359619
    num_steps_sampled: 4380000
    num_steps_trained: 4380000
    wait_time_ms: 433.426
  iterations_since_restore: 146
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 6491.977182388306
  time_this_iter_s: 44.40158534049988
  time_total_s: 6491.977182388306
  timestamp: 1594158669
  timesteps_since_restore: 4380000
  timesteps_this_iter: 30000
  timesteps_total: 4380000
  training_iteration: 146
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 6491 s, 146 iter, 4380000 ts, 1.26e+03 rew

agent-1: 27.0
agent-2: 59.0
agent-3: 50.0
agent-4: 37.0
agent-5: 40.0
agent-6: 55.0
agent-7: 39.0
agent-8: 45.0
agent-9: 40.0
agent-10: 37.0
agent-11: 20.0
agent-12: 38.0
agent-13: 44.0
agent-14: 42.0
agent-15: 41.0
agent-16: 40.0
agent-17: 19.0
agent-18: 31.0
agent-19: 47.0
agent-20: 27.0
agent-21: 44.0
agent-22: 33.0
agent-23: 25.0
agent-24: 40.0
agent-25: 59.0
agent-26: 26.0
agent-27: 12.0
agent-28: 53.0
agent-29: 29.0
agent-30: 20.0
Sum Reward: 1119.0
Avg Reward: 37.3
Min Reward: 12.0
Max Reward: 59.0
Gini Coefficient: 0.17852249031873696
20:20 Ratio: 2.6475409836065573
Max-min Ratio: 4.916666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-51-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1566.0
  episode_reward_mean: 1262.44
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 146
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.45
    dispatch_time_ms: 18.753
    learner:
      cur_lr: 0.0010682919528335333
      grad_gnorm: 40.0
      policy_entropy: 211.4410858154297
      policy_loss: -27.41201400756836
      var_gnorm: 22.77847671508789
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 4.437921047210693
    num_steps_sampled: 4410000
    num_steps_trained: 4410000
    wait_time_ms: 469.108
  iterations_since_restore: 147
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 6537.344784736633
  time_this_iter_s: 45.36760234832764
  time_total_s: 6537.344784736633
  timestamp: 1594158714
  timesteps_since_restore: 4410000
  timesteps_this_iter: 30000
  timesteps_total: 4410000
  training_iteration: 147
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 6537 s, 147 iter, 4410000 ts, 1.26e+03 rew

agent-1: 41.0
agent-2: 35.0
agent-3: 32.0
agent-4: 26.0
agent-5: 55.0
agent-6: 39.0
agent-7: 38.0
agent-8: 36.0
agent-9: 23.0
agent-10: 48.0
agent-11: 15.0
agent-12: 25.0
agent-13: 14.0
agent-14: 39.0
agent-15: 64.0
agent-16: 48.0
agent-17: 27.0
agent-18: 36.0
agent-19: 46.0
agent-20: 20.0
agent-21: 49.0
agent-22: 29.0
agent-23: 15.0
agent-24: 34.0
agent-25: 39.0
agent-26: 50.0
agent-27: 32.0
agent-28: 33.0
agent-29: 55.0
agent-30: 50.0
Sum Reward: 1093.0
Avg Reward: 36.43333333333333
Min Reward: 14.0
Max Reward: 64.0
Gini Coefficient: 0.19490698383653554
20:20 Ratio: 2.8839285714285716
Max-min Ratio: 4.571428571428571
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-52-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1566.0
  episode_reward_mean: 1258.91
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 147
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.697
    dispatch_time_ms: 18.516
    learner:
      cur_lr: 0.0010662940330803394
      grad_gnorm: 39.999996185302734
      policy_entropy: 216.3509521484375
      policy_loss: 93.12403106689453
      var_gnorm: 22.777278900146484
      vf_explained_var: 0.0
      vf_loss: 213.95408630371094
    num_steps_sampled: 4440000
    num_steps_trained: 4440000
    wait_time_ms: 418.535
  iterations_since_restore: 148
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 6582.811223268509
  time_this_iter_s: 45.46643853187561
  time_total_s: 6582.811223268509
  timestamp: 1594158760
  timesteps_since_restore: 4440000
  timesteps_this_iter: 30000
  timesteps_total: 4440000
  training_iteration: 148
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 6582 s, 148 iter, 4440000 ts, 1.26e+03 rew

agent-1: 40.0
agent-2: 22.0
agent-3: 29.0
agent-4: 27.0
agent-5: 53.0
agent-6: 60.0
agent-7: 46.0
agent-8: 50.0
agent-9: 49.0
agent-10: 57.0
agent-11: 29.0
agent-12: 60.0
agent-13: 48.0
agent-14: 37.0
agent-15: 51.0
agent-16: 55.0
agent-17: 26.0
agent-18: 22.0
agent-19: 30.0
agent-20: 65.0
agent-21: 36.0
agent-22: 28.0
agent-23: 21.0
agent-24: 46.0
agent-25: 42.0
agent-26: 59.0
agent-27: 38.0
agent-28: 83.0
agent-29: 57.0
agent-30: 31.0
Sum Reward: 1297.0
Avg Reward: 43.233333333333334
Min Reward: 21.0
Max Reward: 83.0
Gini Coefficient: 0.194834232845027
20:20 Ratio: 2.6301369863013697
Max-min Ratio: 3.9523809523809526
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-53-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1566.0
  episode_reward_mean: 1258.71
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 148
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.944
    dispatch_time_ms: 22.151
    learner:
      cur_lr: 0.0010642959969118237
      grad_gnorm: 39.999996185302734
      policy_entropy: 162.8408966064453
      policy_loss: 3.793208360671997
      var_gnorm: 22.78455352783203
      vf_explained_var: -1.5497207641601562e-06
      vf_loss: 43.97098922729492
    num_steps_sampled: 4470000
    num_steps_trained: 4470000
    wait_time_ms: 597.309
  iterations_since_restore: 149
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 6629.890201330185
  time_this_iter_s: 47.078978061676025
  time_total_s: 6629.890201330185
  timestamp: 1594158807
  timesteps_since_restore: 4470000
  timesteps_this_iter: 30000
  timesteps_total: 4470000
  training_iteration: 149
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 6629 s, 149 iter, 4470000 ts, 1.26e+03 rew

agent-1: 41.0
agent-2: 21.0
agent-3: 51.0
agent-4: 43.0
agent-5: 37.0
agent-6: 56.0
agent-7: 41.0
agent-8: 62.0
agent-9: 20.0
agent-10: 23.0
agent-11: 46.0
agent-12: 39.0
agent-13: 67.0
agent-14: 72.0
agent-15: 36.0
agent-16: 35.0
agent-17: 48.0
agent-18: 47.0
agent-19: 46.0
agent-20: 71.0
agent-21: 30.0
agent-22: 44.0
agent-23: 49.0
agent-24: 64.0
agent-25: 20.0
agent-26: 38.0
agent-27: 61.0
agent-28: 58.0
agent-29: 44.0
agent-30: 12.0
Sum Reward: 1322.0
Avg Reward: 44.06666666666667
Min Reward: 12.0
Max Reward: 72.0
Gini Coefficient: 0.19768028240040342
20:20 Ratio: 3.1507936507936507
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-54-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1566.0
  episode_reward_mean: 1259.69
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 149
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.718
    dispatch_time_ms: 5.726
    learner:
      cur_lr: 0.001062297960743308
      grad_gnorm: 40.0
      policy_entropy: 165.72018432617188
      policy_loss: 27.000261306762695
      var_gnorm: 22.782541275024414
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 100.25145721435547
    num_steps_sampled: 4500000
    num_steps_trained: 4500000
    wait_time_ms: 429.23
  iterations_since_restore: 150
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 6672.407377719879
  time_this_iter_s: 42.517176389694214
  time_total_s: 6672.407377719879
  timestamp: 1594158849
  timesteps_since_restore: 4500000
  timesteps_this_iter: 30000
  timesteps_total: 4500000
  training_iteration: 150
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 6672 s, 150 iter, 4500000 ts, 1.26e+03 rew

agent-1: 27.0
agent-2: 29.0
agent-3: 24.0
agent-4: 29.0
agent-5: 28.0
agent-6: 54.0
agent-7: 31.0
agent-8: 67.0
agent-9: 60.0
agent-10: 22.0
agent-11: 37.0
agent-12: 51.0
agent-13: 25.0
agent-14: 43.0
agent-15: 10.0
agent-16: 39.0
agent-17: 31.0
agent-18: 36.0
agent-19: 55.0
agent-20: 48.0
agent-21: 45.0
agent-22: 61.0
agent-23: 41.0
agent-24: 53.0
agent-25: 65.0
agent-26: 34.0
agent-27: 29.0
agent-28: 41.0
agent-29: 16.0
agent-30: 39.0
Sum Reward: 1170.0
Avg Reward: 39.0
Min Reward: 10.0
Max Reward: 67.0
Gini Coefficient: 0.20866096866096867
20:20 Ratio: 2.9193548387096775
Max-min Ratio: 6.7
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-54-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1566.0
  episode_reward_mean: 1255.76
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 150
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.759
    dispatch_time_ms: 6.118
    learner:
      cur_lr: 0.0010603000409901142
      grad_gnorm: 39.999996185302734
      policy_entropy: 140.29833984375
      policy_loss: 19.162181854248047
      var_gnorm: 22.786823272705078
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 103.9452896118164
    num_steps_sampled: 4530000
    num_steps_trained: 4530000
    wait_time_ms: 411.439
  iterations_since_restore: 151
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 6715.757980823517
  time_this_iter_s: 43.350603103637695
  time_total_s: 6715.757980823517
  timestamp: 1594158893
  timesteps_since_restore: 4530000
  timesteps_this_iter: 30000
  timesteps_total: 4530000
  training_iteration: 151
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 6715 s, 151 iter, 4530000 ts, 1.26e+03 rew

agent-1: 28.0
agent-2: 58.0
agent-3: 47.0
agent-4: 42.0
agent-5: 26.0
agent-6: 28.0
agent-7: 45.0
agent-8: 18.0
agent-9: 13.0
agent-10: 41.0
agent-11: 32.0
agent-12: 36.0
agent-13: 43.0
agent-14: 23.0
agent-15: 31.0
agent-16: 29.0
agent-17: 26.0
agent-18: 46.0
agent-19: 47.0
agent-20: 40.0
agent-21: 48.0
agent-22: 39.0
agent-23: 34.0
agent-24: 55.0
agent-25: 45.0
agent-26: 41.0
agent-27: 49.0
agent-28: 42.0
agent-29: 35.0
agent-30: 55.0
Sum Reward: 1142.0
Avg Reward: 38.06666666666667
Min Reward: 13.0
Max Reward: 58.0
Gini Coefficient: 0.16129597197898424
20:20 Ratio: 2.328358208955224
Max-min Ratio: 4.461538461538462
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-55-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1566.0
  episode_reward_mean: 1252.08
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 151
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.576
    dispatch_time_ms: 8.352
    learner:
      cur_lr: 0.0010583020048215985
      grad_gnorm: 40.0
      policy_entropy: 161.23236083984375
      policy_loss: -10.190447807312012
      var_gnorm: 22.791439056396484
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 19.430831909179688
    num_steps_sampled: 4560000
    num_steps_trained: 4560000
    wait_time_ms: 444.635
  iterations_since_restore: 152
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 6759.862457036972
  time_this_iter_s: 44.1044762134552
  time_total_s: 6759.862457036972
  timestamp: 1594158937
  timesteps_since_restore: 4560000
  timesteps_this_iter: 30000
  timesteps_total: 4560000
  training_iteration: 152
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 6759 s, 152 iter, 4560000 ts, 1.25e+03 rew

agent-1: 38.0
agent-2: 47.0
agent-3: 24.0
agent-4: 41.0
agent-5: 80.0
agent-6: 51.0
agent-7: 74.0
agent-8: 60.0
agent-9: 56.0
agent-10: 53.0
agent-11: 52.0
agent-12: 57.0
agent-13: 49.0
agent-14: 39.0
agent-15: 44.0
agent-16: 43.0
agent-17: 33.0
agent-18: 37.0
agent-19: 34.0
agent-20: 17.0
agent-21: 54.0
agent-22: 40.0
agent-23: 41.0
agent-24: 63.0
agent-25: 47.0
agent-26: 32.0
agent-27: 63.0
agent-28: 75.0
agent-29: 55.0
agent-30: 21.0
Sum Reward: 1420.0
Avg Reward: 47.333333333333336
Min Reward: 17.0
Max Reward: 80.0
Gini Coefficient: 0.1780281690140845
20:20 Ratio: 2.577639751552795
Max-min Ratio: 4.705882352941177
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-56-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1566.0
  episode_reward_mean: 1251.51
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 152
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.77
    dispatch_time_ms: 5.707
    learner:
      cur_lr: 0.0010563039686530828
      grad_gnorm: 40.00000762939453
      policy_entropy: 155.39913940429688
      policy_loss: -6.876423358917236
      var_gnorm: 22.79844093322754
      vf_explained_var: 0.0
      vf_loss: 121.80986022949219
    num_steps_sampled: 4590000
    num_steps_trained: 4590000
    wait_time_ms: 426.241
  iterations_since_restore: 153
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 6802.921319484711
  time_this_iter_s: 43.05886244773865
  time_total_s: 6802.921319484711
  timestamp: 1594158980
  timesteps_since_restore: 4590000
  timesteps_this_iter: 30000
  timesteps_total: 4590000
  training_iteration: 153
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 6802 s, 153 iter, 4590000 ts, 1.25e+03 rew

agent-1: 16.0
agent-2: 61.0
agent-3: 48.0
agent-4: 33.0
agent-5: 28.0
agent-6: 42.0
agent-7: 59.0
agent-8: 63.0
agent-9: 43.0
agent-10: 32.0
agent-11: 59.0
agent-12: 31.0
agent-13: 55.0
agent-14: 21.0
agent-15: 42.0
agent-16: 18.0
agent-17: 47.0
agent-18: 85.0
agent-19: 36.0
agent-20: 23.0
agent-21: 41.0
agent-22: 78.0
agent-23: 12.0
agent-24: 50.0
agent-25: 27.0
agent-26: 57.0
agent-27: 68.0
agent-28: 54.0
agent-29: 51.0
agent-30: 59.0
Sum Reward: 1339.0
Avg Reward: 44.63333333333333
Min Reward: 12.0
Max Reward: 85.0
Gini Coefficient: 0.22954941498630818
20:20 Ratio: 3.5384615384615383
Max-min Ratio: 7.083333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-57-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1566.0
  episode_reward_mean: 1253.64
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 153
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.917
    dispatch_time_ms: 6.166
    learner:
      cur_lr: 0.001054306048899889
      grad_gnorm: 40.0
      policy_entropy: 170.15211486816406
      policy_loss: 39.74757385253906
      var_gnorm: 22.792530059814453
      vf_explained_var: 0.0
      vf_loss: 102.97722625732422
    num_steps_sampled: 4620000
    num_steps_trained: 4620000
    wait_time_ms: 442.259
  iterations_since_restore: 154
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 6847.331513166428
  time_this_iter_s: 44.41019368171692
  time_total_s: 6847.331513166428
  timestamp: 1594159024
  timesteps_since_restore: 4620000
  timesteps_this_iter: 30000
  timesteps_total: 4620000
  training_iteration: 154
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 6847 s, 154 iter, 4620000 ts, 1.25e+03 rew

agent-1: 34.0
agent-2: 57.0
agent-3: 36.0
agent-4: 45.0
agent-5: 24.0
agent-6: 42.0
agent-7: 24.0
agent-8: 44.0
agent-9: 42.0
agent-10: 17.0
agent-11: 32.0
agent-12: 54.0
agent-13: 26.0
agent-14: 63.0
agent-15: 37.0
agent-16: 47.0
agent-17: 43.0
agent-18: 44.0
agent-19: 61.0
agent-20: 19.0
agent-21: 32.0
agent-22: 32.0
agent-23: 24.0
agent-24: 32.0
agent-25: 33.0
agent-26: 41.0
agent-27: 33.0
agent-28: 37.0
agent-29: 27.0
agent-30: 86.0
Sum Reward: 1168.0
Avg Reward: 38.93333333333333
Min Reward: 17.0
Max Reward: 86.0
Gini Coefficient: 0.19600456621004567
20:20 Ratio: 2.746268656716418
Max-min Ratio: 5.0588235294117645
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-57-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1566.0
  episode_reward_mean: 1255.67
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 154
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.71
    dispatch_time_ms: 19.359
    learner:
      cur_lr: 0.0010523080127313733
      grad_gnorm: 40.0
      policy_entropy: 169.15701293945312
      policy_loss: 16.196069717407227
      var_gnorm: 22.79801368713379
      vf_explained_var: 0.0
      vf_loss: 79.75594329833984
    num_steps_sampled: 4650000
    num_steps_trained: 4650000
    wait_time_ms: 423.7
  iterations_since_restore: 155
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 6891.00257229805
  time_this_iter_s: 43.671059131622314
  time_total_s: 6891.00257229805
  timestamp: 1594159068
  timesteps_since_restore: 4650000
  timesteps_this_iter: 30000
  timesteps_total: 4650000
  training_iteration: 155
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 6891 s, 155 iter, 4650000 ts, 1.26e+03 rew

agent-1: 17.0
agent-2: 58.0
agent-3: 49.0
agent-4: 14.0
agent-5: 62.0
agent-6: 32.0
agent-7: 57.0
agent-8: 52.0
agent-9: 56.0
agent-10: 65.0
agent-11: 59.0
agent-12: 31.0
agent-13: 60.0
agent-14: 27.0
agent-15: 44.0
agent-16: 30.0
agent-17: 32.0
agent-18: 4.0
agent-19: 54.0
agent-20: 49.0
agent-21: 43.0
agent-22: 47.0
agent-23: 36.0
agent-24: 50.0
agent-25: 26.0
agent-26: 31.0
agent-27: 39.0
agent-28: 43.0
agent-29: 37.0
agent-30: 30.0
Sum Reward: 1234.0
Avg Reward: 41.13333333333333
Min Reward: 4.0
Max Reward: 65.0
Gini Coefficient: 0.20610480821177743
20:20 Ratio: 3.059322033898305
Max-min Ratio: 16.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-58-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1566.0
  episode_reward_mean: 1253.89
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 155
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.374
    dispatch_time_ms: 33.399
    learner:
      cur_lr: 0.0010503099765628576
      grad_gnorm: 40.0
      policy_entropy: 170.3086395263672
      policy_loss: 74.9178466796875
      var_gnorm: 22.79677391052246
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 120.18238067626953
    num_steps_sampled: 4680000
    num_steps_trained: 4680000
    wait_time_ms: 368.004
  iterations_since_restore: 156
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 6936.327920675278
  time_this_iter_s: 45.32534837722778
  time_total_s: 6936.327920675278
  timestamp: 1594159114
  timesteps_since_restore: 4680000
  timesteps_this_iter: 30000
  timesteps_total: 4680000
  training_iteration: 156
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 6936 s, 156 iter, 4680000 ts, 1.25e+03 rew

agent-1: 39.0
agent-2: 38.0
agent-3: 63.0
agent-4: 54.0
agent-5: 72.0
agent-6: 55.0
agent-7: 43.0
agent-8: 43.0
agent-9: 22.0
agent-10: 45.0
agent-11: 35.0
agent-12: 30.0
agent-13: 51.0
agent-14: 59.0
agent-15: 41.0
agent-16: 49.0
agent-17: 78.0
agent-18: 44.0
agent-19: 72.0
agent-20: 67.0
agent-21: 88.0
agent-22: 58.0
agent-23: 51.0
agent-24: 60.0
agent-25: 47.0
agent-26: 47.0
agent-27: 56.0
agent-28: 44.0
agent-29: 55.0
agent-30: 77.0
Sum Reward: 1583.0
Avg Reward: 52.766666666666666
Min Reward: 22.0
Max Reward: 88.0
Gini Coefficient: 0.1554643082754264
20:20 Ratio: 2.2146341463414636
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_17-59-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1583.0
  episode_reward_mean: 1256.13
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 156
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.547
    dispatch_time_ms: 28.113
    learner:
      cur_lr: 0.0010483120568096638
      grad_gnorm: 39.999996185302734
      policy_entropy: 195.9297637939453
      policy_loss: -36.55591583251953
      var_gnorm: 22.803176879882812
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 19.53035545349121
    num_steps_sampled: 4710000
    num_steps_trained: 4710000
    wait_time_ms: 431.275
  iterations_since_restore: 157
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 6981.284863233566
  time_this_iter_s: 44.956942558288574
  time_total_s: 6981.284863233566
  timestamp: 1594159159
  timesteps_since_restore: 4710000
  timesteps_this_iter: 30000
  timesteps_total: 4710000
  training_iteration: 157
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 6981 s, 157 iter, 4710000 ts, 1.26e+03 rew

agent-1: 32.0
agent-2: 26.0
agent-3: 17.0
agent-4: 32.0
agent-5: 60.0
agent-6: 35.0
agent-7: 27.0
agent-8: 18.0
agent-9: 80.0
agent-10: 43.0
agent-11: 57.0
agent-12: 42.0
agent-13: 37.0
agent-14: 46.0
agent-15: 45.0
agent-16: 53.0
agent-17: 60.0
agent-18: 58.0
agent-19: 50.0
agent-20: 35.0
agent-21: 46.0
agent-22: 21.0
agent-23: 75.0
agent-24: 41.0
agent-25: 60.0
agent-26: 40.0
agent-27: 32.0
agent-28: 30.0
agent-29: 32.0
agent-30: 39.0
Sum Reward: 1269.0
Avg Reward: 42.3
Min Reward: 17.0
Max Reward: 80.0
Gini Coefficient: 0.2018649855529288
20:20 Ratio: 2.827338129496403
Max-min Ratio: 4.705882352941177
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-00-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1583.0
  episode_reward_mean: 1255.59
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 157
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.389
    dispatch_time_ms: 32.333
    learner:
      cur_lr: 0.001046314020641148
      grad_gnorm: 40.000003814697266
      policy_entropy: 167.35617065429688
      policy_loss: -12.719045639038086
      var_gnorm: 22.795642852783203
      vf_explained_var: 0.0
      vf_loss: 7.385422706604004
    num_steps_sampled: 4740000
    num_steps_trained: 4740000
    wait_time_ms: 436.94
  iterations_since_restore: 158
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 7028.114890098572
  time_this_iter_s: 46.83002686500549
  time_total_s: 7028.114890098572
  timestamp: 1594159205
  timesteps_since_restore: 4740000
  timesteps_this_iter: 30000
  timesteps_total: 4740000
  training_iteration: 158
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 7028 s, 158 iter, 4740000 ts, 1.26e+03 rew

agent-1: 36.0
agent-2: 24.0
agent-3: 31.0
agent-4: 26.0
agent-5: 39.0
agent-6: 34.0
agent-7: 56.0
agent-8: 39.0
agent-9: 52.0
agent-10: 34.0
agent-11: 38.0
agent-12: 45.0
agent-13: 30.0
agent-14: 40.0
agent-15: 36.0
agent-16: 53.0
agent-17: 29.0
agent-18: 35.0
agent-19: 32.0
agent-20: 45.0
agent-21: 49.0
agent-22: 47.0
agent-23: 28.0
agent-24: 32.0
agent-25: 40.0
agent-26: 66.0
agent-27: 40.0
agent-28: 30.0
agent-29: 73.0
agent-30: 54.0
Sum Reward: 1213.0
Avg Reward: 40.43333333333333
Min Reward: 24.0
Max Reward: 73.0
Gini Coefficient: 0.15435559219565814
20:20 Ratio: 2.1197604790419162
Max-min Ratio: 3.0416666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-00-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1583.0
  episode_reward_mean: 1253.93
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 158
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.769
    dispatch_time_ms: 43.087
    learner:
      cur_lr: 0.0010443159844726324
      grad_gnorm: 29.990947723388672
      policy_entropy: 202.9495086669922
      policy_loss: 9.908614158630371
      var_gnorm: 22.807924270629883
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 53.11099624633789
    num_steps_sampled: 4770000
    num_steps_trained: 4770000
    wait_time_ms: 421.005
  iterations_since_restore: 159
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 7072.211535453796
  time_this_iter_s: 44.09664535522461
  time_total_s: 7072.211535453796
  timestamp: 1594159250
  timesteps_since_restore: 4770000
  timesteps_this_iter: 30000
  timesteps_total: 4770000
  training_iteration: 159
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 7072 s, 159 iter, 4770000 ts, 1.25e+03 rew

agent-1: 59.0
agent-2: 63.0
agent-3: 72.0
agent-4: 35.0
agent-5: 64.0
agent-6: 35.0
agent-7: 40.0
agent-8: 73.0
agent-9: 64.0
agent-10: 63.0
agent-11: 52.0
agent-12: 63.0
agent-13: 29.0
agent-14: 47.0
agent-15: 67.0
agent-16: 52.0
agent-17: 51.0
agent-18: 48.0
agent-19: 44.0
agent-20: 33.0
agent-21: 75.0
agent-22: 36.0
agent-23: 67.0
agent-24: 40.0
agent-25: 33.0
agent-26: 40.0
agent-27: 48.0
agent-28: 45.0
agent-29: 79.0
agent-30: 60.0
Sum Reward: 1577.0
Avg Reward: 52.56666666666667
Min Reward: 29.0
Max Reward: 79.0
Gini Coefficient: 0.15415345592897908
20:20 Ratio: 2.154228855721393
Max-min Ratio: 2.7241379310344827
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-01-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1583.0
  episode_reward_mean: 1254.14
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 159
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.134
    dispatch_time_ms: 6.749
    learner:
      cur_lr: 0.0010423179483041167
      grad_gnorm: 40.0
      policy_entropy: 163.6002197265625
      policy_loss: 76.1294174194336
      var_gnorm: 22.803388595581055
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 131.84718322753906
    num_steps_sampled: 4800000
    num_steps_trained: 4800000
    wait_time_ms: 393.1
  iterations_since_restore: 160
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 7116.419609308243
  time_this_iter_s: 44.20807385444641
  time_total_s: 7116.419609308243
  timestamp: 1594159294
  timesteps_since_restore: 4800000
  timesteps_this_iter: 30000
  timesteps_total: 4800000
  training_iteration: 160
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 7116 s, 160 iter, 4800000 ts, 1.25e+03 rew

agent-1: 38.0
agent-2: 57.0
agent-3: 29.0
agent-4: 40.0
agent-5: 28.0
agent-6: 26.0
agent-7: 45.0
agent-8: 29.0
agent-9: 58.0
agent-10: 31.0
agent-11: 30.0
agent-12: 40.0
agent-13: 41.0
agent-14: 47.0
agent-15: 49.0
agent-16: 32.0
agent-17: 40.0
agent-18: 19.0
agent-19: 25.0
agent-20: 23.0
agent-21: 40.0
agent-22: 59.0
agent-23: 71.0
agent-24: 28.0
agent-25: 36.0
agent-26: 50.0
agent-27: 57.0
agent-28: 39.0
agent-29: 34.0
agent-30: 28.0
Sum Reward: 1169.0
Avg Reward: 38.96666666666667
Min Reward: 19.0
Max Reward: 71.0
Gini Coefficient: 0.17624750499001995
20:20 Ratio: 2.3624161073825505
Max-min Ratio: 3.736842105263158
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-02-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1583.0
  episode_reward_mean: 1254.52
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 160
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.472
    dispatch_time_ms: 4.799
    learner:
      cur_lr: 0.0010403200285509229
      grad_gnorm: 17.997419357299805
      policy_entropy: 151.4903564453125
      policy_loss: 6.841259956359863
      var_gnorm: 22.81456184387207
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 51.123477935791016
    num_steps_sampled: 4830000
    num_steps_trained: 4830000
    wait_time_ms: 431.286
  iterations_since_restore: 161
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 7159.28333234787
  time_this_iter_s: 42.863723039627075
  time_total_s: 7159.28333234787
  timestamp: 1594159337
  timesteps_since_restore: 4830000
  timesteps_this_iter: 30000
  timesteps_total: 4830000
  training_iteration: 161
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 7159 s, 161 iter, 4830000 ts, 1.25e+03 rew

agent-1: 48.0
agent-2: 37.0
agent-3: 36.0
agent-4: 40.0
agent-5: 64.0
agent-6: 59.0
agent-7: 61.0
agent-8: 82.0
agent-9: 76.0
agent-10: 58.0
agent-11: 73.0
agent-12: 46.0
agent-13: 39.0
agent-14: 37.0
agent-15: 49.0
agent-16: 47.0
agent-17: 39.0
agent-18: 52.0
agent-19: 107.0
agent-20: 21.0
agent-21: 64.0
agent-22: 53.0
agent-23: 75.0
agent-24: 62.0
agent-25: 55.0
agent-26: 88.0
agent-27: 34.0
agent-28: 64.0
agent-29: 43.0
agent-30: 41.0
Sum Reward: 1650.0
Avg Reward: 55.0
Min Reward: 21.0
Max Reward: 107.0
Gini Coefficient: 0.1823030303030303
20:20 Ratio: 2.4558823529411766
Max-min Ratio: 5.095238095238095
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-03-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1258.35
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 161
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.553
    dispatch_time_ms: 5.479
    learner:
      cur_lr: 0.0010383219923824072
      grad_gnorm: 35.116119384765625
      policy_entropy: 224.72781372070312
      policy_loss: -10.44348430633545
      var_gnorm: 22.804790496826172
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 58.249454498291016
    num_steps_sampled: 4860000
    num_steps_trained: 4860000
    wait_time_ms: 416.04
  iterations_since_restore: 162
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 7202.984460353851
  time_this_iter_s: 43.701128005981445
  time_total_s: 7202.984460353851
  timestamp: 1594159381
  timesteps_since_restore: 4860000
  timesteps_this_iter: 30000
  timesteps_total: 4860000
  training_iteration: 162
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 7202 s, 162 iter, 4860000 ts, 1.26e+03 rew

agent-1: 29.0
agent-2: 23.0
agent-3: 51.0
agent-4: 23.0
agent-5: 34.0
agent-6: 54.0
agent-7: 32.0
agent-8: 21.0
agent-9: 67.0
agent-10: 21.0
agent-11: 49.0
agent-12: 38.0
agent-13: 39.0
agent-14: 67.0
agent-15: 50.0
agent-16: 54.0
agent-17: 46.0
agent-18: 30.0
agent-19: 47.0
agent-20: 53.0
agent-21: 44.0
agent-22: 43.0
agent-23: 58.0
agent-24: 44.0
agent-25: 29.0
agent-26: 39.0
agent-27: 65.0
agent-28: 31.0
agent-29: 28.0
agent-30: 25.0
Sum Reward: 1234.0
Avg Reward: 41.13333333333333
Min Reward: 21.0
Max Reward: 67.0
Gini Coefficient: 0.18903295515937332
20:20 Ratio: 2.5886524822695036
Max-min Ratio: 3.1904761904761907
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-03-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1258.52
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 162
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.032
    dispatch_time_ms: 6.982
    learner:
      cur_lr: 0.0010363239562138915
      grad_gnorm: 8.58436107635498
      policy_entropy: 146.60545349121094
      policy_loss: 0.8717851638793945
      var_gnorm: 22.8125057220459
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 64.76508331298828
    num_steps_sampled: 4890000
    num_steps_trained: 4890000
    wait_time_ms: 422.462
  iterations_since_restore: 163
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 7245.605942964554
  time_this_iter_s: 42.621482610702515
  time_total_s: 7245.605942964554
  timestamp: 1594159423
  timesteps_since_restore: 4890000
  timesteps_this_iter: 30000
  timesteps_total: 4890000
  training_iteration: 163
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 7245 s, 163 iter, 4890000 ts, 1.26e+03 rew

agent-1: 30.0
agent-2: 36.0
agent-3: 57.0
agent-4: 48.0
agent-5: 31.0
agent-6: 44.0
agent-7: 28.0
agent-8: 63.0
agent-9: 33.0
agent-10: 22.0
agent-11: 34.0
agent-12: 50.0
agent-13: 61.0
agent-14: 79.0
agent-15: 50.0
agent-16: 66.0
agent-17: 63.0
agent-18: 67.0
agent-19: 71.0
agent-20: 32.0
agent-21: 64.0
agent-22: 53.0
agent-23: 54.0
agent-24: 61.0
agent-25: 33.0
agent-26: 51.0
agent-27: 27.0
agent-28: 25.0
agent-29: 45.0
agent-30: 53.0
Sum Reward: 1431.0
Avg Reward: 47.7
Min Reward: 22.0
Max Reward: 79.0
Gini Coefficient: 0.18469601677148847
20:20 Ratio: 2.5153374233128836
Max-min Ratio: 3.590909090909091
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-04-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1258.48
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 163
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.385
    dispatch_time_ms: 5.788
    learner:
      cur_lr: 0.0010343260364606977
      grad_gnorm: 40.0
      policy_entropy: 158.54132080078125
      policy_loss: 61.59227752685547
      var_gnorm: 22.804777145385742
      vf_explained_var: 0.0
      vf_loss: 224.02053833007812
    num_steps_sampled: 4920000
    num_steps_trained: 4920000
    wait_time_ms: 409.169
  iterations_since_restore: 164
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 7289.694722890854
  time_this_iter_s: 44.08877992630005
  time_total_s: 7289.694722890854
  timestamp: 1594159468
  timesteps_since_restore: 4920000
  timesteps_this_iter: 30000
  timesteps_total: 4920000
  training_iteration: 164
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 7289 s, 164 iter, 4920000 ts, 1.26e+03 rew

agent-1: 31.0
agent-2: 39.0
agent-3: 53.0
agent-4: 35.0
agent-5: 30.0
agent-6: 60.0
agent-7: 39.0
agent-8: 30.0
agent-9: 16.0
agent-10: 38.0
agent-11: 46.0
agent-12: 80.0
agent-13: 60.0
agent-14: 56.0
agent-15: 68.0
agent-16: 77.0
agent-17: 36.0
agent-18: 22.0
agent-19: 24.0
agent-20: 56.0
agent-21: 41.0
agent-22: 36.0
agent-23: 71.0
agent-24: 60.0
agent-25: 30.0
agent-26: 43.0
agent-27: 55.0
agent-28: 28.0
agent-29: 32.0
agent-30: 31.0
Sum Reward: 1323.0
Avg Reward: 44.1
Min Reward: 16.0
Max Reward: 80.0
Gini Coefficient: 0.2110103300579491
20:20 Ratio: 2.7733333333333334
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-05-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1258.91
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 164
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.77
    dispatch_time_ms: 7.472
    learner:
      cur_lr: 0.001032328000292182
      grad_gnorm: 40.0
      policy_entropy: 280.65142822265625
      policy_loss: -27.101369857788086
      var_gnorm: 22.808536529541016
      vf_explained_var: 0.0
      vf_loss: 43.74635314941406
    num_steps_sampled: 4950000
    num_steps_trained: 4950000
    wait_time_ms: 435.986
  iterations_since_restore: 165
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 7332.6206130981445
  time_this_iter_s: 42.92589020729065
  time_total_s: 7332.6206130981445
  timestamp: 1594159511
  timesteps_since_restore: 4950000
  timesteps_this_iter: 30000
  timesteps_total: 4950000
  training_iteration: 165
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 7332 s, 165 iter, 4950000 ts, 1.26e+03 rew

agent-1: 43.0
agent-2: 52.0
agent-3: 58.0
agent-4: 61.0
agent-5: 35.0
agent-6: 23.0
agent-7: 32.0
agent-8: 36.0
agent-9: 29.0
agent-10: 43.0
agent-11: 36.0
agent-12: 37.0
agent-13: 54.0
agent-14: 42.0
agent-15: 66.0
agent-16: 48.0
agent-17: 36.0
agent-18: 32.0
agent-19: 40.0
agent-20: 36.0
agent-21: 34.0
agent-22: 54.0
agent-23: 52.0
agent-24: 56.0
agent-25: 47.0
agent-26: 47.0
agent-27: 59.0
agent-28: 31.0
agent-29: 27.0
agent-30: 59.0
Sum Reward: 1305.0
Avg Reward: 43.5
Min Reward: 23.0
Max Reward: 66.0
Gini Coefficient: 0.14853128991060024
20:20 Ratio: 2.0632183908045976
Max-min Ratio: 2.869565217391304
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-05-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1263.13
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 165
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.839
    dispatch_time_ms: 6.247
    learner:
      cur_lr: 0.0010303299641236663
      grad_gnorm: 40.0
      policy_entropy: 276.8910827636719
      policy_loss: 82.04716491699219
      var_gnorm: 22.799909591674805
      vf_explained_var: 0.0
      vf_loss: 100.61800384521484
    num_steps_sampled: 4980000
    num_steps_trained: 4980000
    wait_time_ms: 390.692
  iterations_since_restore: 166
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 7377.062162160873
  time_this_iter_s: 44.44154906272888
  time_total_s: 7377.062162160873
  timestamp: 1594159555
  timesteps_since_restore: 4980000
  timesteps_this_iter: 30000
  timesteps_total: 4980000
  training_iteration: 166
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 7377 s, 166 iter, 4980000 ts, 1.26e+03 rew

agent-1: 25.0
agent-2: 36.0
agent-3: 40.0
agent-4: 19.0
agent-5: 45.0
agent-6: 23.0
agent-7: 58.0
agent-8: 15.0
agent-9: 55.0
agent-10: 62.0
agent-11: 23.0
agent-12: 43.0
agent-13: 69.0
agent-14: 43.0
agent-15: 1.0
agent-16: 78.0
agent-17: 17.0
agent-18: 18.0
agent-19: 23.0
agent-20: 61.0
agent-21: 61.0
agent-22: 64.0
agent-23: 9.0
agent-24: 29.0
agent-25: 40.0
agent-26: 79.0
agent-27: 50.0
agent-28: 51.0
agent-29: 42.0
agent-30: 54.0
Sum Reward: 1233.0
Avg Reward: 41.1
Min Reward: 1.0
Max Reward: 79.0
Gini Coefficient: 0.2842660178426602
20:20 Ratio: 5.227848101265823
Max-min Ratio: 79.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-06-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1261.34
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 166
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.804
    dispatch_time_ms: 6.507
    learner:
      cur_lr: 0.0010283320443704724
      grad_gnorm: 40.0
      policy_entropy: 242.866943359375
      policy_loss: 3.4854583740234375
      var_gnorm: 22.801822662353516
      vf_explained_var: 0.0
      vf_loss: 49.84672164916992
    num_steps_sampled: 5010000
    num_steps_trained: 5010000
    wait_time_ms: 439.822
  iterations_since_restore: 167
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 7421.133138895035
  time_this_iter_s: 44.07097673416138
  time_total_s: 7421.133138895035
  timestamp: 1594159599
  timesteps_since_restore: 5010000
  timesteps_this_iter: 30000
  timesteps_total: 5010000
  training_iteration: 167
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 7421 s, 167 iter, 5010000 ts, 1.26e+03 rew

agent-1: 49.0
agent-2: 46.0
agent-3: 19.0
agent-4: 41.0
agent-5: 56.0
agent-6: 19.0
agent-7: 35.0
agent-8: 37.0
agent-9: 44.0
agent-10: 20.0
agent-11: 34.0
agent-12: 44.0
agent-13: 25.0
agent-14: 51.0
agent-15: 45.0
agent-16: 26.0
agent-17: 18.0
agent-18: 16.0
agent-19: 41.0
agent-20: 25.0
agent-21: 54.0
agent-22: 31.0
agent-23: 56.0
agent-24: 25.0
agent-25: 22.0
agent-26: 17.0
agent-27: 26.0
agent-28: 44.0
agent-29: 38.0
agent-30: 21.0
Sum Reward: 1025.0
Avg Reward: 34.166666666666664
Min Reward: 16.0
Max Reward: 56.0
Gini Coefficient: 0.21121951219512194
20:20 Ratio: 2.8623853211009176
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-07-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1258.24
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 167
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.417
    dispatch_time_ms: 5.515
    learner:
      cur_lr: 0.0010263340082019567
      grad_gnorm: 23.9648380279541
      policy_entropy: 186.8437042236328
      policy_loss: -3.5951156616210938
      var_gnorm: 22.799625396728516
      vf_explained_var: 2.1457672119140625e-06
      vf_loss: 4.326839447021484
    num_steps_sampled: 5040000
    num_steps_trained: 5040000
    wait_time_ms: 439.616
  iterations_since_restore: 168
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 7466.348668575287
  time_this_iter_s: 45.215529680252075
  time_total_s: 7466.348668575287
  timestamp: 1594159644
  timesteps_since_restore: 5040000
  timesteps_this_iter: 30000
  timesteps_total: 5040000
  training_iteration: 168
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 7466 s, 168 iter, 5040000 ts, 1.26e+03 rew

agent-1: 12.0
agent-2: 24.0
agent-3: 22.0
agent-4: 19.0
agent-5: 21.0
agent-6: 16.0
agent-7: 16.0
agent-8: 24.0
agent-9: 28.0
agent-10: 36.0
agent-11: 51.0
agent-12: 41.0
agent-13: 31.0
agent-14: 32.0
agent-15: 39.0
agent-16: 36.0
agent-17: 14.0
agent-18: 50.0
agent-19: 40.0
agent-20: 35.0
agent-21: 34.0
agent-22: 49.0
agent-23: 29.0
agent-24: 12.0
agent-25: 27.0
agent-26: 30.0
agent-27: 29.0
agent-28: 35.0
agent-29: 21.0
agent-30: 27.0
Sum Reward: 880.0
Avg Reward: 29.333333333333332
Min Reward: 12.0
Max Reward: 51.0
Gini Coefficient: 0.205
20:20 Ratio: 3.033707865168539
Max-min Ratio: 4.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-08-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1253.7
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 168
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.859
    dispatch_time_ms: 5.756
    learner:
      cur_lr: 0.001024335972033441
      grad_gnorm: 40.0
      policy_entropy: 166.77468872070312
      policy_loss: 16.636247634887695
      var_gnorm: 22.806316375732422
      vf_explained_var: 0.0
      vf_loss: 68.21467590332031
    num_steps_sampled: 5070000
    num_steps_trained: 5070000
    wait_time_ms: 392.074
  iterations_since_restore: 169
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 7535.771336555481
  time_this_iter_s: 69.42266798019409
  time_total_s: 7535.771336555481
  timestamp: 1594159714
  timesteps_since_restore: 5070000
  timesteps_this_iter: 30000
  timesteps_total: 5070000
  training_iteration: 169
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 7535 s, 169 iter, 5070000 ts, 1.25e+03 rew

agent-1: 53.0
agent-2: 49.0
agent-3: 44.0
agent-4: 47.0
agent-5: 30.0
agent-6: 44.0
agent-7: 47.0
agent-8: 28.0
agent-9: 43.0
agent-10: 60.0
agent-11: 47.0
agent-12: 34.0
agent-13: 32.0
agent-14: 50.0
agent-15: 34.0
agent-16: 49.0
agent-17: 45.0
agent-18: 31.0
agent-19: 21.0
agent-20: 46.0
agent-21: 66.0
agent-22: 70.0
agent-23: 54.0
agent-24: 73.0
agent-25: 63.0
agent-26: 38.0
agent-27: 27.0
agent-28: 52.0
agent-29: 51.0
agent-30: 23.0
Sum Reward: 1351.0
Avg Reward: 45.03333333333333
Min Reward: 21.0
Max Reward: 73.0
Gini Coefficient: 0.16567974339995065
20:20 Ratio: 2.4125
Max-min Ratio: 3.4761904761904763
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-09-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1254.74
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 169
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.628
    dispatch_time_ms: 6.115
    learner:
      cur_lr: 0.0010223380522802472
      grad_gnorm: 40.000003814697266
      policy_entropy: 128.6742401123047
      policy_loss: 40.861793518066406
      var_gnorm: 22.80585479736328
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 110.16472625732422
    num_steps_sampled: 5100000
    num_steps_trained: 5100000
    wait_time_ms: 404.673
  iterations_since_restore: 170
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 7579.762903213501
  time_this_iter_s: 43.99156665802002
  time_total_s: 7579.762903213501
  timestamp: 1594159758
  timesteps_since_restore: 5100000
  timesteps_this_iter: 30000
  timesteps_total: 5100000
  training_iteration: 170
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 7579 s, 170 iter, 5100000 ts, 1.25e+03 rew

agent-1: 37.0
agent-2: 39.0
agent-3: 73.0
agent-4: 25.0
agent-5: 70.0
agent-6: 45.0
agent-7: 50.0
agent-8: 33.0
agent-9: 48.0
agent-10: 54.0
agent-11: 40.0
agent-12: 30.0
agent-13: 52.0
agent-14: 44.0
agent-15: 70.0
agent-16: 71.0
agent-17: 61.0
agent-18: 42.0
agent-19: 44.0
agent-20: 31.0
agent-21: 57.0
agent-22: 62.0
agent-23: 32.0
agent-24: 57.0
agent-25: 39.0
agent-26: 23.0
agent-27: 58.0
agent-28: 36.0
agent-29: 35.0
agent-30: 51.0
Sum Reward: 1409.0
Avg Reward: 46.96666666666667
Min Reward: 23.0
Max Reward: 73.0
Gini Coefficient: 0.16865389164892358
20:20 Ratio: 2.339080459770115
Max-min Ratio: 3.1739130434782608
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-10-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1256.18
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 170
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.119
    dispatch_time_ms: 7.972
    learner:
      cur_lr: 0.0010203400161117315
      grad_gnorm: 40.0
      policy_entropy: 140.0797119140625
      policy_loss: -21.56934928894043
      var_gnorm: 22.813447952270508
      vf_explained_var: 0.0
      vf_loss: 37.757164001464844
    num_steps_sampled: 5130000
    num_steps_trained: 5130000
    wait_time_ms: 421.359
  iterations_since_restore: 171
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 7623.091972589493
  time_this_iter_s: 43.32906937599182
  time_total_s: 7623.091972589493
  timestamp: 1594159801
  timesteps_since_restore: 5130000
  timesteps_this_iter: 30000
  timesteps_total: 5130000
  training_iteration: 171
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 7623 s, 171 iter, 5130000 ts, 1.26e+03 rew

agent-1: 32.0
agent-2: 55.0
agent-3: 42.0
agent-4: 42.0
agent-5: 60.0
agent-6: 52.0
agent-7: 22.0
agent-8: 50.0
agent-9: 54.0
agent-10: 45.0
agent-11: 49.0
agent-12: 30.0
agent-13: 60.0
agent-14: 46.0
agent-15: 50.0
agent-16: 41.0
agent-17: 25.0
agent-18: 51.0
agent-19: 35.0
agent-20: 45.0
agent-21: 22.0
agent-22: 76.0
agent-23: 48.0
agent-24: 22.0
agent-25: 44.0
agent-26: 22.0
agent-27: 51.0
agent-28: 44.0
agent-29: 37.0
agent-30: 64.0
Sum Reward: 1316.0
Avg Reward: 43.86666666666667
Min Reward: 22.0
Max Reward: 76.0
Gini Coefficient: 0.167629179331307
20:20 Ratio: 2.5804195804195804
Max-min Ratio: 3.4545454545454546
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-10-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1257.25
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 171
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.225
    dispatch_time_ms: 5.825
    learner:
      cur_lr: 0.0010183419799432158
      grad_gnorm: 40.0
      policy_entropy: 168.523193359375
      policy_loss: -20.341535568237305
      var_gnorm: 22.804485321044922
      vf_explained_var: 0.0
      vf_loss: 2.814209222793579
    num_steps_sampled: 5160000
    num_steps_trained: 5160000
    wait_time_ms: 449.544
  iterations_since_restore: 172
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 7667.783365011215
  time_this_iter_s: 44.69139242172241
  time_total_s: 7667.783365011215
  timestamp: 1594159846
  timesteps_since_restore: 5160000
  timesteps_this_iter: 30000
  timesteps_total: 5160000
  training_iteration: 172
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 7667 s, 172 iter, 5160000 ts, 1.26e+03 rew

agent-1: 36.0
agent-2: 76.0
agent-3: 30.0
agent-4: 81.0
agent-5: 16.0
agent-6: 57.0
agent-7: 39.0
agent-8: 55.0
agent-9: 44.0
agent-10: 25.0
agent-11: 72.0
agent-12: 30.0
agent-13: 39.0
agent-14: 30.0
agent-15: 16.0
agent-16: 18.0
agent-17: 34.0
agent-18: 43.0
agent-19: 59.0
agent-20: 48.0
agent-21: 36.0
agent-22: 44.0
agent-23: 38.0
agent-24: 39.0
agent-25: 48.0
agent-26: 54.0
agent-27: 49.0
agent-28: 38.0
agent-29: 52.0
agent-30: 38.0
Sum Reward: 1284.0
Avg Reward: 42.8
Min Reward: 16.0
Max Reward: 81.0
Gini Coefficient: 0.20332294911734164
20:20 Ratio: 2.962962962962963
Max-min Ratio: 5.0625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-11-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1254.43
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 172
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.691
    dispatch_time_ms: 5.62
    learner:
      cur_lr: 0.0010163439437747002
      grad_gnorm: 40.0
      policy_entropy: 104.33541107177734
      policy_loss: -10.549403190612793
      var_gnorm: 22.809890747070312
      vf_explained_var: 0.0
      vf_loss: 31.021730422973633
    num_steps_sampled: 5190000
    num_steps_trained: 5190000
    wait_time_ms: 424.625
  iterations_since_restore: 173
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 7710.6801817417145
  time_this_iter_s: 42.89681673049927
  time_total_s: 7710.6801817417145
  timestamp: 1594159889
  timesteps_since_restore: 5190000
  timesteps_this_iter: 30000
  timesteps_total: 5190000
  training_iteration: 173
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 7710 s, 173 iter, 5190000 ts, 1.25e+03 rew

agent-1: 35.0
agent-2: 15.0
agent-3: 34.0
agent-4: 29.0
agent-5: 32.0
agent-6: 27.0
agent-7: 29.0
agent-8: 16.0
agent-9: 43.0
agent-10: 38.0
agent-11: 37.0
agent-12: 35.0
agent-13: 34.0
agent-14: 37.0
agent-15: 58.0
agent-16: 47.0
agent-17: 68.0
agent-18: 45.0
agent-19: 36.0
agent-20: 39.0
agent-21: 22.0
agent-22: 24.0
agent-23: 53.0
agent-24: 59.0
agent-25: 36.0
agent-26: 31.0
agent-27: 28.0
agent-28: 50.0
agent-29: 38.0
agent-30: 51.0
Sum Reward: 1126.0
Avg Reward: 37.53333333333333
Min Reward: 15.0
Max Reward: 68.0
Gini Coefficient: 0.17898164594434576
20:20 Ratio: 2.5681818181818183
Max-min Ratio: 4.533333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-12-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1251.09
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 173
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.104
    dispatch_time_ms: 6.216
    learner:
      cur_lr: 0.0010143460240215063
      grad_gnorm: 40.0
      policy_entropy: 157.29554748535156
      policy_loss: 79.27473449707031
      var_gnorm: 22.806657791137695
      vf_explained_var: 0.0
      vf_loss: 200.98980712890625
    num_steps_sampled: 5220000
    num_steps_trained: 5220000
    wait_time_ms: 382.132
  iterations_since_restore: 174
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 7755.195157051086
  time_this_iter_s: 44.51497530937195
  time_total_s: 7755.195157051086
  timestamp: 1594159934
  timesteps_since_restore: 5220000
  timesteps_this_iter: 30000
  timesteps_total: 5220000
  training_iteration: 174
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 7755 s, 174 iter, 5220000 ts, 1.25e+03 rew

agent-1: 37.0
agent-2: 21.0
agent-3: 31.0
agent-4: 26.0
agent-5: 28.0
agent-6: 66.0
agent-7: 49.0
agent-8: 32.0
agent-9: 43.0
agent-10: 30.0
agent-11: 19.0
agent-12: 28.0
agent-13: 33.0
agent-14: 23.0
agent-15: 46.0
agent-16: 61.0
agent-17: 23.0
agent-18: 52.0
agent-19: 65.0
agent-20: 31.0
agent-21: 52.0
agent-22: 21.0
agent-23: 72.0
agent-24: 44.0
agent-25: 26.0
agent-26: 40.0
agent-27: 43.0
agent-28: 37.0
agent-29: 49.0
agent-30: 58.0
Sum Reward: 1186.0
Avg Reward: 39.53333333333333
Min Reward: 19.0
Max Reward: 72.0
Gini Coefficient: 0.20905002810567735
20:20 Ratio: 2.81203007518797
Max-min Ratio: 3.789473684210526
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-12-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1250.48
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 174
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.997
    dispatch_time_ms: 5.437
    learner:
      cur_lr: 0.0010123479878529906
      grad_gnorm: 40.0
      policy_entropy: 114.08525085449219
      policy_loss: -2.7243518829345703
      var_gnorm: 22.814199447631836
      vf_explained_var: 4.76837158203125e-07
      vf_loss: 109.70337677001953
    num_steps_sampled: 5250000
    num_steps_trained: 5250000
    wait_time_ms: 453.938
  iterations_since_restore: 175
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 7798.64600276947
  time_this_iter_s: 43.45084571838379
  time_total_s: 7798.64600276947
  timestamp: 1594159977
  timesteps_since_restore: 5250000
  timesteps_this_iter: 30000
  timesteps_total: 5250000
  training_iteration: 175
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 7798 s, 175 iter, 5250000 ts, 1.25e+03 rew

agent-1: 65.0
agent-2: 34.0
agent-3: 20.0
agent-4: 47.0
agent-5: 49.0
agent-6: 19.0
agent-7: 21.0
agent-8: 40.0
agent-9: 23.0
agent-10: 36.0
agent-11: 33.0
agent-12: 16.0
agent-13: 38.0
agent-14: 41.0
agent-15: 27.0
agent-16: 83.0
agent-17: 37.0
agent-18: 44.0
agent-19: 61.0
agent-20: 49.0
agent-21: 44.0
agent-22: 58.0
agent-23: 40.0
agent-24: 40.0
agent-25: 32.0
agent-26: 52.0
agent-27: 20.0
agent-28: 50.0
agent-29: 54.0
agent-30: 6.0
Sum Reward: 1179.0
Avg Reward: 39.3
Min Reward: 6.0
Max Reward: 83.0
Gini Coefficient: 0.22954481198756008
20:20 Ratio: 3.656862745098039
Max-min Ratio: 13.833333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-13-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1248.04
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 175
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.83
    dispatch_time_ms: 5.248
    learner:
      cur_lr: 0.001010349951684475
      grad_gnorm: 39.999996185302734
      policy_entropy: 133.39488220214844
      policy_loss: 59.90232849121094
      var_gnorm: 23.27643585205078
      vf_explained_var: 0.0
      vf_loss: 159.11134338378906
    num_steps_sampled: 5280000
    num_steps_trained: 5280000
    wait_time_ms: 388.497
  iterations_since_restore: 176
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 7843.315685510635
  time_this_iter_s: 44.66968274116516
  time_total_s: 7843.315685510635
  timestamp: 1594160022
  timesteps_since_restore: 5280000
  timesteps_this_iter: 30000
  timesteps_total: 5280000
  training_iteration: 176
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 7843 s, 176 iter, 5280000 ts, 1.25e+03 rew

agent-1: 44.0
agent-2: 47.0
agent-3: 54.0
agent-4: 25.0
agent-5: 34.0
agent-6: 47.0
agent-7: 50.0
agent-8: 25.0
agent-9: 40.0
agent-10: 51.0
agent-11: 31.0
agent-12: 44.0
agent-13: 25.0
agent-14: 66.0
agent-15: 53.0
agent-16: 21.0
agent-17: 57.0
agent-18: 52.0
agent-19: 27.0
agent-20: 33.0
agent-21: 35.0
agent-22: 43.0
agent-23: 23.0
agent-24: 19.0
agent-25: 28.0
agent-26: 42.0
agent-27: 26.0
agent-28: 50.0
agent-29: 40.0
agent-30: 40.0
Sum Reward: 1172.0
Avg Reward: 39.06666666666667
Min Reward: 19.0
Max Reward: 66.0
Gini Coefficient: 0.17650739476678043
20:20 Ratio: 2.4130434782608696
Max-min Ratio: 3.473684210526316
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-14-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1248.42
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 176
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.387
    dispatch_time_ms: 6.734
    learner:
      cur_lr: 0.001008352031931281
      grad_gnorm: 39.999996185302734
      policy_entropy: 141.37371826171875
      policy_loss: -24.133764266967773
      var_gnorm: 23.29660987854004
      vf_explained_var: 0.0
      vf_loss: 27.670183181762695
    num_steps_sampled: 5310000
    num_steps_trained: 5310000
    wait_time_ms: 441.028
  iterations_since_restore: 177
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 7886.366649866104
  time_this_iter_s: 43.05096435546875
  time_total_s: 7886.366649866104
  timestamp: 1594160065
  timesteps_since_restore: 5310000
  timesteps_this_iter: 30000
  timesteps_total: 5310000
  training_iteration: 177
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 7886 s, 177 iter, 5310000 ts, 1.25e+03 rew

agent-1: 44.0
agent-2: 33.0
agent-3: 25.0
agent-4: 32.0
agent-5: 26.0
agent-6: 36.0
agent-7: 23.0
agent-8: 42.0
agent-9: 42.0
agent-10: 44.0
agent-11: 19.0
agent-12: 39.0
agent-13: 35.0
agent-14: 23.0
agent-15: 27.0
agent-16: 29.0
agent-17: 42.0
agent-18: 34.0
agent-19: 41.0
agent-20: 41.0
agent-21: 48.0
agent-22: 58.0
agent-23: 37.0
agent-24: 42.0
agent-25: 32.0
agent-26: 48.0
agent-27: 37.0
agent-28: 51.0
agent-29: 40.0
agent-30: 51.0
Sum Reward: 1121.0
Avg Reward: 37.36666666666667
Min Reward: 19.0
Max Reward: 58.0
Gini Coefficient: 0.1393101397561701
20:20 Ratio: 2.097902097902098
Max-min Ratio: 3.0526315789473686
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-15-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1248.45
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 177
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.446
    dispatch_time_ms: 5.402
    learner:
      cur_lr: 0.0010063539957627654
      grad_gnorm: 13.224721908569336
      policy_entropy: 128.76234436035156
      policy_loss: -5.006492614746094
      var_gnorm: 23.291015625
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 19.29877471923828
    num_steps_sampled: 5340000
    num_steps_trained: 5340000
    wait_time_ms: 436.044
  iterations_since_restore: 178
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 7931.424431562424
  time_this_iter_s: 45.05778169631958
  time_total_s: 7931.424431562424
  timestamp: 1594160110
  timesteps_since_restore: 5340000
  timesteps_this_iter: 30000
  timesteps_total: 5340000
  training_iteration: 178
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 7931 s, 178 iter, 5340000 ts, 1.25e+03 rew

agent-1: 39.0
agent-2: 37.0
agent-3: 61.0
agent-4: 30.0
agent-5: 38.0
agent-6: 38.0
agent-7: 40.0
agent-8: 43.0
agent-9: 45.0
agent-10: 50.0
agent-11: 25.0
agent-12: 38.0
agent-13: 48.0
agent-14: 53.0
agent-15: 62.0
agent-16: 57.0
agent-17: 43.0
agent-18: 58.0
agent-19: 69.0
agent-20: 43.0
agent-21: 78.0
agent-22: 46.0
agent-23: 42.0
agent-24: 26.0
agent-25: 45.0
agent-26: 46.0
agent-27: 42.0
agent-28: 35.0
agent-29: 27.0
agent-30: 49.0
Sum Reward: 1353.0
Avg Reward: 45.1
Min Reward: 25.0
Max Reward: 78.0
Gini Coefficient: 0.14607046070460705
20:20 Ratio: 2.138888888888889
Max-min Ratio: 3.12
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-15-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1249.08
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 178
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.632
    dispatch_time_ms: 6.908
    learner:
      cur_lr: 0.0010043559595942497
      grad_gnorm: 40.0
      policy_entropy: 145.54920959472656
      policy_loss: 23.966758728027344
      var_gnorm: 23.29759979248047
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 120.37237548828125
    num_steps_sampled: 5370000
    num_steps_trained: 5370000
    wait_time_ms: 425.128
  iterations_since_restore: 179
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 7974.153389930725
  time_this_iter_s: 42.72895836830139
  time_total_s: 7974.153389930725
  timestamp: 1594160153
  timesteps_since_restore: 5370000
  timesteps_this_iter: 30000
  timesteps_total: 5370000
  training_iteration: 179
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 7974 s, 179 iter, 5370000 ts, 1.25e+03 rew

agent-1: 65.0
agent-2: 30.0
agent-3: 23.0
agent-4: 41.0
agent-5: 41.0
agent-6: 28.0
agent-7: 86.0
agent-8: 26.0
agent-9: 39.0
agent-10: 41.0
agent-11: 43.0
agent-12: 25.0
agent-13: 43.0
agent-14: 29.0
agent-15: 52.0
agent-16: 38.0
agent-17: 54.0
agent-18: 49.0
agent-19: 47.0
agent-20: 15.0
agent-21: 20.0
agent-22: 34.0
agent-23: 29.0
agent-24: 44.0
agent-25: 32.0
agent-26: 40.0
agent-27: 32.0
agent-28: 31.0
agent-29: 54.0
agent-30: 62.0
Sum Reward: 1193.0
Avg Reward: 39.766666666666666
Min Reward: 15.0
Max Reward: 86.0
Gini Coefficient: 0.19812796870634256
20:20 Ratio: 2.7226277372262775
Max-min Ratio: 5.733333333333333
agent-1: 25.0
agent-2: 51.0
agent-3: 73.0
agent-4: 43.0
agent-5: 64.0
agent-6: 72.0
agent-7: 24.0
agent-8: 49.0
agent-9: 45.0
agent-10: 64.0
agent-11: 85.0
agent-12: 38.0
agent-13: 50.0
agent-14: 42.0
agent-15: 22.0
agent-16: 67.0
agent-17: 47.0
agent-18: 73.0
agent-19: 56.0
agent-20: 47.0
agent-21: 51.0
agent-22: 40.0
agent-23: 45.0
agent-24: 29.0
agent-25: 46.0
agent-26: 44.0
agent-27: 50.0
agent-28: 12.0
agent-29: 48.0
agent-30: 51.0
Sum Reward: 1453.0
Avg Reward: 48.43333333333333
Min Reward: 12.0
Max Reward: 85.0
Gini Coefficient: 0.18368891947694424
20:20 Ratio: 2.8933333333333335
Max-min Ratio: 7.083333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-16-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1249.79
  episode_reward_min: 802.0
  episodes_this_iter: 2
  episodes_total: 180
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.868
    dispatch_time_ms: 7.323
    learner:
      cur_lr: 0.0010023580398410559
      grad_gnorm: 40.0
      policy_entropy: 111.78215789794922
      policy_loss: -281.1877746582031
      var_gnorm: 23.293535232543945
      vf_explained_var: 0.0
      vf_loss: 787.3074340820312
    num_steps_sampled: 5400000
    num_steps_trained: 5400000
    wait_time_ms: 431.225
  iterations_since_restore: 180
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 8018.7671275138855
  time_this_iter_s: 44.6137375831604
  time_total_s: 8018.7671275138855
  timestamp: 1594160197
  timesteps_since_restore: 5400000
  timesteps_this_iter: 30000
  timesteps_total: 5400000
  training_iteration: 180
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 8018 s, 180 iter, 5400000 ts, 1.25e+03 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-17-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1249.79
  episode_reward_min: 802.0
  episodes_this_iter: 0
  episodes_total: 180
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.861
    dispatch_time_ms: 7.184
    learner:
      cur_lr: 0.0010003600036725402
      grad_gnorm: 28.231578826904297
      policy_entropy: 145.5421905517578
      policy_loss: 9.407402992248535
      var_gnorm: 23.298234939575195
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 75.53927612304688
    num_steps_sampled: 5430000
    num_steps_trained: 5430000
    wait_time_ms: 440.398
  iterations_since_restore: 181
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 8061.021219968796
  time_this_iter_s: 42.25409245491028
  time_total_s: 8061.021219968796
  timestamp: 1594160240
  timesteps_since_restore: 5430000
  timesteps_this_iter: 30000
  timesteps_total: 5430000
  training_iteration: 181
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 8061 s, 181 iter, 5430000 ts, 1.25e+03 rew

agent-1: 33.0
agent-2: 63.0
agent-3: 75.0
agent-4: 54.0
agent-5: 53.0
agent-6: 75.0
agent-7: 38.0
agent-8: 41.0
agent-9: 32.0
agent-10: 48.0
agent-11: 33.0
agent-12: 66.0
agent-13: 54.0
agent-14: 59.0
agent-15: 26.0
agent-16: 41.0
agent-17: 39.0
agent-18: 18.0
agent-19: 65.0
agent-20: 12.0
agent-21: 54.0
agent-22: 44.0
agent-23: 73.0
agent-24: 82.0
agent-25: 49.0
agent-26: 70.0
agent-27: 50.0
agent-28: 67.0
agent-29: 50.0
agent-30: 51.0
Sum Reward: 1515.0
Avg Reward: 50.5
Min Reward: 12.0
Max Reward: 82.0
Gini Coefficient: 0.19091309130913092
20:20 Ratio: 2.8701298701298703
Max-min Ratio: 6.833333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-18-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1253.46
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 181
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.54
    dispatch_time_ms: 23.625
    learner:
      cur_lr: 0.0009983619675040245
      grad_gnorm: 40.0
      policy_entropy: 168.95938110351562
      policy_loss: -23.80643081665039
      var_gnorm: 23.29119110107422
      vf_explained_var: 0.0
      vf_loss: 16.370332717895508
    num_steps_sampled: 5460000
    num_steps_trained: 5460000
    wait_time_ms: 437.998
  iterations_since_restore: 182
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 8106.315364122391
  time_this_iter_s: 45.29414415359497
  time_total_s: 8106.315364122391
  timestamp: 1594160285
  timesteps_since_restore: 5460000
  timesteps_this_iter: 30000
  timesteps_total: 5460000
  training_iteration: 182
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 8106 s, 182 iter, 5460000 ts, 1.25e+03 rew

agent-1: 44.0
agent-2: 60.0
agent-3: 39.0
agent-4: 39.0
agent-5: 50.0
agent-6: 35.0
agent-7: 32.0
agent-8: 36.0
agent-9: 33.0
agent-10: 59.0
agent-11: 38.0
agent-12: 30.0
agent-13: 45.0
agent-14: 56.0
agent-15: 40.0
agent-16: 36.0
agent-17: 28.0
agent-18: 37.0
agent-19: 37.0
agent-20: 29.0
agent-21: 43.0
agent-22: 51.0
agent-23: 25.0
agent-24: 58.0
agent-25: 49.0
agent-26: 33.0
agent-27: 32.0
agent-28: 51.0
agent-29: 44.0
agent-30: 33.0
Sum Reward: 1222.0
Avg Reward: 40.733333333333334
Min Reward: 25.0
Max Reward: 60.0
Gini Coefficient: 0.1326241134751773
20:20 Ratio: 1.9034090909090908
Max-min Ratio: 2.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-18-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1254.88
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 182
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.096
    dispatch_time_ms: 28.896
    learner:
      cur_lr: 0.0009963640477508307
      grad_gnorm: 39.999996185302734
      policy_entropy: 205.07302856445312
      policy_loss: -19.831554412841797
      var_gnorm: 23.297399520874023
      vf_explained_var: 0.0
      vf_loss: 29.13545036315918
    num_steps_sampled: 5490000
    num_steps_trained: 5490000
    wait_time_ms: 455.312
  iterations_since_restore: 183
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 8150.197601079941
  time_this_iter_s: 43.88223695755005
  time_total_s: 8150.197601079941
  timestamp: 1594160329
  timesteps_since_restore: 5490000
  timesteps_this_iter: 30000
  timesteps_total: 5490000
  training_iteration: 183
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 8150 s, 183 iter, 5490000 ts, 1.25e+03 rew

agent-1: 28.0
agent-2: 53.0
agent-3: 58.0
agent-4: 63.0
agent-5: 43.0
agent-6: 55.0
agent-7: 43.0
agent-8: 48.0
agent-9: 33.0
agent-10: 22.0
agent-11: 37.0
agent-12: 52.0
agent-13: 31.0
agent-14: 35.0
agent-15: 31.0
agent-16: 56.0
agent-17: 53.0
agent-18: 28.0
agent-19: 43.0
agent-20: 65.0
agent-21: 36.0
agent-22: 52.0
agent-23: 31.0
agent-24: 55.0
agent-25: 64.0
agent-26: 29.0
agent-27: 38.0
agent-28: 30.0
agent-29: 40.0
agent-30: 21.0
Sum Reward: 1273.0
Avg Reward: 42.43333333333333
Min Reward: 21.0
Max Reward: 65.0
Gini Coefficient: 0.17111809374181722
20:20 Ratio: 2.2848101265822787
Max-min Ratio: 3.0952380952380953
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-19-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1256.25
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 183
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.632
    dispatch_time_ms: 23.241
    learner:
      cur_lr: 0.000994366011582315
      grad_gnorm: 39.999996185302734
      policy_entropy: 256.78887939453125
      policy_loss: 13.474976539611816
      var_gnorm: 23.290002822875977
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 64.30525970458984
    num_steps_sampled: 5520000
    num_steps_trained: 5520000
    wait_time_ms: 435.098
  iterations_since_restore: 184
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 8196.89530992508
  time_this_iter_s: 46.69770884513855
  time_total_s: 8196.89530992508
  timestamp: 1594160376
  timesteps_since_restore: 5520000
  timesteps_this_iter: 30000
  timesteps_total: 5520000
  training_iteration: 184
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 8196 s, 184 iter, 5520000 ts, 1.26e+03 rew

agent-1: 49.0
agent-2: 27.0
agent-3: 31.0
agent-4: 57.0
agent-5: 17.0
agent-6: 28.0
agent-7: 16.0
agent-8: 27.0
agent-9: 29.0
agent-10: 48.0
agent-11: 36.0
agent-12: 37.0
agent-13: 19.0
agent-14: 18.0
agent-15: 19.0
agent-16: 26.0
agent-17: 25.0
agent-18: 58.0
agent-19: 49.0
agent-20: 25.0
agent-21: 54.0
agent-22: 53.0
agent-23: 40.0
agent-24: 31.0
agent-25: 18.0
agent-26: 50.0
agent-27: 50.0
agent-28: 28.0
agent-29: 45.0
agent-30: 32.0
Sum Reward: 1042.0
Avg Reward: 34.733333333333334
Min Reward: 16.0
Max Reward: 58.0
Gini Coefficient: 0.21509916826615483
20:20 Ratio: 3.0093457943925235
Max-min Ratio: 3.625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-20-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1257.01
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 184
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.818
    dispatch_time_ms: 14.805
    learner:
      cur_lr: 0.0009923679754137993
      grad_gnorm: 40.0
      policy_entropy: 213.17498779296875
      policy_loss: 25.697660446166992
      var_gnorm: 23.295568466186523
      vf_explained_var: 0.0
      vf_loss: 59.639835357666016
    num_steps_sampled: 5550000
    num_steps_trained: 5550000
    wait_time_ms: 414.01
  iterations_since_restore: 185
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 8242.061775445938
  time_this_iter_s: 45.166465520858765
  time_total_s: 8242.061775445938
  timestamp: 1594160421
  timesteps_since_restore: 5550000
  timesteps_this_iter: 30000
  timesteps_total: 5550000
  training_iteration: 185
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 8242 s, 185 iter, 5550000 ts, 1.26e+03 rew

agent-1: 32.0
agent-2: 46.0
agent-3: 64.0
agent-4: 65.0
agent-5: 33.0
agent-6: 30.0
agent-7: 65.0
agent-8: 23.0
agent-9: 50.0
agent-10: 43.0
agent-11: 31.0
agent-12: 21.0
agent-13: 46.0
agent-14: 16.0
agent-15: 17.0
agent-16: 45.0
agent-17: 35.0
agent-18: 31.0
agent-19: 38.0
agent-20: 19.0
agent-21: 44.0
agent-22: 22.0
agent-23: 25.0
agent-24: 39.0
agent-25: 46.0
agent-26: 29.0
agent-27: 42.0
agent-28: 27.0
agent-29: 49.0
agent-30: 55.0
Sum Reward: 1128.0
Avg Reward: 37.6
Min Reward: 16.0
Max Reward: 65.0
Gini Coefficient: 0.20703309692671396
20:20 Ratio: 2.9491525423728815
Max-min Ratio: 4.0625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-21-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1258.76
  episode_reward_min: 802.0
  episodes_this_iter: 1
  episodes_total: 185
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.482
    dispatch_time_ms: 4.901
    learner:
      cur_lr: 0.0009903700556606054
      grad_gnorm: 40.000003814697266
      policy_entropy: 173.10369873046875
      policy_loss: -13.023225784301758
      var_gnorm: 23.290294647216797
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1.1611595153808594
    num_steps_sampled: 5580000
    num_steps_trained: 5580000
    wait_time_ms: 412.804
  iterations_since_restore: 186
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 8286.903552055359
  time_this_iter_s: 44.841776609420776
  time_total_s: 8286.903552055359
  timestamp: 1594160466
  timesteps_since_restore: 5580000
  timesteps_this_iter: 30000
  timesteps_total: 5580000
  training_iteration: 186
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 8286 s, 186 iter, 5580000 ts, 1.26e+03 rew

agent-1: 18.0
agent-2: 52.0
agent-3: 38.0
agent-4: 22.0
agent-5: 41.0
agent-6: 61.0
agent-7: 40.0
agent-8: 32.0
agent-9: 17.0
agent-10: 29.0
agent-11: 48.0
agent-12: 28.0
agent-13: 31.0
agent-14: 43.0
agent-15: 37.0
agent-16: 37.0
agent-17: 29.0
agent-18: 30.0
agent-19: 28.0
agent-20: 33.0
agent-21: 58.0
agent-22: 23.0
agent-23: 50.0
agent-24: 34.0
agent-25: 75.0
agent-26: 21.0
agent-27: 46.0
agent-28: 33.0
agent-29: 24.0
agent-30: 48.0
Sum Reward: 1106.0
Avg Reward: 36.86666666666667
Min Reward: 17.0
Max Reward: 75.0
Gini Coefficient: 0.19837251356238697
20:20 Ratio: 2.752
Max-min Ratio: 4.411764705882353
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-21-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1261.8
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 186
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.955
    dispatch_time_ms: 6.309
    learner:
      cur_lr: 0.0009883720194920897
      grad_gnorm: 40.0
      policy_entropy: 122.76414489746094
      policy_loss: -10.963732719421387
      var_gnorm: 23.298967361450195
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 46.803863525390625
    num_steps_sampled: 5610000
    num_steps_trained: 5610000
    wait_time_ms: 424.721
  iterations_since_restore: 187
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 8329.899254322052
  time_this_iter_s: 42.995702266693115
  time_total_s: 8329.899254322052
  timestamp: 1594160509
  timesteps_since_restore: 5610000
  timesteps_this_iter: 30000
  timesteps_total: 5610000
  training_iteration: 187
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 8329 s, 187 iter, 5610000 ts, 1.26e+03 rew

agent-1: 66.0
agent-2: 48.0
agent-3: 37.0
agent-4: 39.0
agent-5: 45.0
agent-6: 52.0
agent-7: 40.0
agent-8: 61.0
agent-9: 52.0
agent-10: 29.0
agent-11: 20.0
agent-12: 40.0
agent-13: 47.0
agent-14: 49.0
agent-15: 42.0
agent-16: 34.0
agent-17: 46.0
agent-18: 40.0
agent-19: 53.0
agent-20: 37.0
agent-21: 50.0
agent-22: 51.0
agent-23: 34.0
agent-24: 62.0
agent-25: 34.0
agent-26: 20.0
agent-27: 48.0
agent-28: 47.0
agent-29: 25.0
agent-30: 35.0
Sum Reward: 1283.0
Avg Reward: 42.766666666666666
Min Reward: 20.0
Max Reward: 66.0
Gini Coefficient: 0.14593400883346325
20:20 Ratio: 2.1358024691358026
Max-min Ratio: 3.3
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-22-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1265.5
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 187
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.956
    dispatch_time_ms: 5.551
    learner:
      cur_lr: 0.000986373983323574
      grad_gnorm: 40.0
      policy_entropy: 209.7151336669922
      policy_loss: -23.317516326904297
      var_gnorm: 23.29584312438965
      vf_explained_var: 0.0
      vf_loss: 7.007293701171875
    num_steps_sampled: 5640000
    num_steps_trained: 5640000
    wait_time_ms: 425.042
  iterations_since_restore: 188
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 8374.245554208755
  time_this_iter_s: 44.34629988670349
  time_total_s: 8374.245554208755
  timestamp: 1594160553
  timesteps_since_restore: 5640000
  timesteps_this_iter: 30000
  timesteps_total: 5640000
  training_iteration: 188
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 8374 s, 188 iter, 5640000 ts, 1.27e+03 rew

agent-1: 48.0
agent-2: 61.0
agent-3: 51.0
agent-4: 26.0
agent-5: 39.0
agent-6: 69.0
agent-7: 47.0
agent-8: 48.0
agent-9: 66.0
agent-10: 31.0
agent-11: 43.0
agent-12: 28.0
agent-13: 32.0
agent-14: 44.0
agent-15: 20.0
agent-16: 49.0
agent-17: 37.0
agent-18: 58.0
agent-19: 43.0
agent-20: 64.0
agent-21: 52.0
agent-22: 46.0
agent-23: 39.0
agent-24: 42.0
agent-25: 79.0
agent-26: 30.0
agent-27: 36.0
agent-28: 52.0
agent-29: 31.0
agent-30: 42.0
Sum Reward: 1353.0
Avg Reward: 45.1
Min Reward: 20.0
Max Reward: 79.0
Gini Coefficient: 0.16696230598669623
20:20 Ratio: 2.391566265060241
Max-min Ratio: 3.95
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-23-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1267.49
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 188
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.567
    dispatch_time_ms: 6.072
    learner:
      cur_lr: 0.0009843759471550584
      grad_gnorm: 40.0
      policy_entropy: 140.35719299316406
      policy_loss: -22.973180770874023
      var_gnorm: 23.307165145874023
      vf_explained_var: 0.0
      vf_loss: 10.038118362426758
    num_steps_sampled: 5670000
    num_steps_trained: 5670000
    wait_time_ms: 439.939
  iterations_since_restore: 189
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 8417.318732261658
  time_this_iter_s: 43.07317805290222
  time_total_s: 8417.318732261658
  timestamp: 1594160596
  timesteps_since_restore: 5670000
  timesteps_this_iter: 30000
  timesteps_total: 5670000
  training_iteration: 189
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 8417 s, 189 iter, 5670000 ts, 1.27e+03 rew

agent-1: 20.0
agent-2: 63.0
agent-3: 51.0
agent-4: 33.0
agent-5: 39.0
agent-6: 49.0
agent-7: 39.0
agent-8: 51.0
agent-9: 51.0
agent-10: 33.0
agent-11: 26.0
agent-12: 51.0
agent-13: 16.0
agent-14: 55.0
agent-15: 36.0
agent-16: 54.0
agent-17: 20.0
agent-18: 14.0
agent-19: 24.0
agent-20: 93.0
agent-21: 31.0
agent-22: 40.0
agent-23: 50.0
agent-24: 41.0
agent-25: 52.0
agent-26: 51.0
agent-27: 43.0
agent-28: 29.0
agent-29: 65.0
agent-30: 50.0
Sum Reward: 1270.0
Avg Reward: 42.333333333333336
Min Reward: 14.0
Max Reward: 93.0
Gini Coefficient: 0.210498687664042
20:20 Ratio: 3.183333333333333
Max-min Ratio: 6.642857142857143
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-24-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1268.4
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 189
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.131
    dispatch_time_ms: 7.576
    learner:
      cur_lr: 0.0009823780274018645
      grad_gnorm: 40.0
      policy_entropy: 217.8750762939453
      policy_loss: 101.9359359741211
      var_gnorm: 23.30302619934082
      vf_explained_var: 0.0
      vf_loss: 189.0657196044922
    num_steps_sampled: 5700000
    num_steps_trained: 5700000
    wait_time_ms: 412.464
  iterations_since_restore: 190
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 8461.227514743805
  time_this_iter_s: 43.90878248214722
  time_total_s: 8461.227514743805
  timestamp: 1594160640
  timesteps_since_restore: 5700000
  timesteps_this_iter: 30000
  timesteps_total: 5700000
  training_iteration: 190
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 8461 s, 190 iter, 5700000 ts, 1.27e+03 rew

agent-1: 22.0
agent-2: 19.0
agent-3: 64.0
agent-4: 46.0
agent-5: 46.0
agent-6: 40.0
agent-7: 41.0
agent-8: 62.0
agent-9: 47.0
agent-10: 71.0
agent-11: 54.0
agent-12: 66.0
agent-13: 47.0
agent-14: 58.0
agent-15: 57.0
agent-16: 70.0
agent-17: 59.0
agent-18: 29.0
agent-19: 50.0
agent-20: 65.0
agent-21: 52.0
agent-22: 64.0
agent-23: 50.0
agent-24: 69.0
agent-25: 43.0
agent-26: 31.0
agent-27: 32.0
agent-28: 44.0
agent-29: 38.0
agent-30: 47.0
Sum Reward: 1483.0
Avg Reward: 49.43333333333333
Min Reward: 19.0
Max Reward: 71.0
Gini Coefficient: 0.1589795459653855
20:20 Ratio: 2.3684210526315788
Max-min Ratio: 3.736842105263158
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-24-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1271.06
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 190
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.757
    dispatch_time_ms: 7.281
    learner:
      cur_lr: 0.0009803799912333488
      grad_gnorm: 39.999996185302734
      policy_entropy: 238.34951782226562
      policy_loss: 13.516676902770996
      var_gnorm: 23.306034088134766
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 88.03053283691406
    num_steps_sampled: 5730000
    num_steps_trained: 5730000
    wait_time_ms: 455.554
  iterations_since_restore: 191
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 8504.830262184143
  time_this_iter_s: 43.602747440338135
  time_total_s: 8504.830262184143
  timestamp: 1594160684
  timesteps_since_restore: 5730000
  timesteps_this_iter: 30000
  timesteps_total: 5730000
  training_iteration: 191
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 8504 s, 191 iter, 5730000 ts, 1.27e+03 rew

agent-1: 48.0
agent-2: 63.0
agent-3: 30.0
agent-4: 25.0
agent-5: 24.0
agent-6: 39.0
agent-7: 11.0
agent-8: 35.0
agent-9: 40.0
agent-10: 39.0
agent-11: 33.0
agent-12: 48.0
agent-13: 14.0
agent-14: 23.0
agent-15: 40.0
agent-16: 38.0
agent-17: 55.0
agent-18: 61.0
agent-19: 16.0
agent-20: 35.0
agent-21: 30.0
agent-22: 81.0
agent-23: 50.0
agent-24: 23.0
agent-25: 43.0
agent-26: 26.0
agent-27: 17.0
agent-28: 39.0
agent-29: 36.0
agent-30: 19.0
Sum Reward: 1081.0
Avg Reward: 36.03333333333333
Min Reward: 11.0
Max Reward: 81.0
Gini Coefficient: 0.23808202281837804
20:20 Ratio: 3.58
Max-min Ratio: 7.363636363636363
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-25-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1270.39
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 191
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.002
    dispatch_time_ms: 8.634
    learner:
      cur_lr: 0.0009783819550648332
      grad_gnorm: 36.96010971069336
      policy_entropy: 239.09910583496094
      policy_loss: -10.89903450012207
      var_gnorm: 23.297760009765625
      vf_explained_var: 0.0
      vf_loss: 2.622385025024414
    num_steps_sampled: 5760000
    num_steps_trained: 5760000
    wait_time_ms: 427.834
  iterations_since_restore: 192
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 8549.911805868149
  time_this_iter_s: 45.08154368400574
  time_total_s: 8549.911805868149
  timestamp: 1594160729
  timesteps_since_restore: 5760000
  timesteps_this_iter: 30000
  timesteps_total: 5760000
  training_iteration: 192
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 8549 s, 192 iter, 5760000 ts, 1.27e+03 rew

agent-1: 34.0
agent-2: 23.0
agent-3: 33.0
agent-4: 36.0
agent-5: 32.0
agent-6: 12.0
agent-7: 30.0
agent-8: 30.0
agent-9: 46.0
agent-10: 37.0
agent-11: 30.0
agent-12: 46.0
agent-13: 23.0
agent-14: 8.0
agent-15: 29.0
agent-16: 24.0
agent-17: 17.0
agent-18: 55.0
agent-19: 49.0
agent-20: 33.0
agent-21: 43.0
agent-22: 24.0
agent-23: 21.0
agent-24: 25.0
agent-25: 36.0
agent-26: 27.0
agent-27: 23.0
agent-28: 35.0
agent-29: 13.0
agent-30: 37.0
Sum Reward: 911.0
Avg Reward: 30.366666666666667
Min Reward: 8.0
Max Reward: 55.0
Gini Coefficient: 0.1990852542993048
20:20 Ratio: 2.9361702127659575
Max-min Ratio: 6.875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-26-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1266.75
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 192
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.93
    dispatch_time_ms: 8.219
    learner:
      cur_lr: 0.0009763839771039784
      grad_gnorm: 39.999996185302734
      policy_entropy: 195.3260955810547
      policy_loss: 12.475638389587402
      var_gnorm: 23.304777145385742
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 61.451210021972656
    num_steps_sampled: 5790000
    num_steps_trained: 5790000
    wait_time_ms: 430.809
  iterations_since_restore: 193
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 8593.639509439468
  time_this_iter_s: 43.72770357131958
  time_total_s: 8593.639509439468
  timestamp: 1594160773
  timesteps_since_restore: 5790000
  timesteps_this_iter: 30000
  timesteps_total: 5790000
  training_iteration: 193
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 8593 s, 193 iter, 5790000 ts, 1.27e+03 rew

agent-1: 43.0
agent-2: 48.0
agent-3: 35.0
agent-4: 60.0
agent-5: 20.0
agent-6: 31.0
agent-7: 44.0
agent-8: 43.0
agent-9: 50.0
agent-10: 64.0
agent-11: 13.0
agent-12: 50.0
agent-13: 31.0
agent-14: 25.0
agent-15: 52.0
agent-16: 33.0
agent-17: 32.0
agent-18: 25.0
agent-19: 36.0
agent-20: 37.0
agent-21: 47.0
agent-22: 52.0
agent-23: 40.0
agent-24: 59.0
agent-25: 37.0
agent-26: 23.0
agent-27: 58.0
agent-28: 40.0
agent-29: 32.0
agent-30: 46.0
Sum Reward: 1206.0
Avg Reward: 40.2
Min Reward: 13.0
Max Reward: 64.0
Gini Coefficient: 0.17529021558872304
20:20 Ratio: 2.5182481751824817
Max-min Ratio: 4.923076923076923
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-26-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1264.98
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 193
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.638
    dispatch_time_ms: 5.498
    learner:
      cur_lr: 0.0009743859991431236
      grad_gnorm: 15.282254219055176
      policy_entropy: 172.8389892578125
      policy_loss: -1.4972529411315918
      var_gnorm: 23.30084991455078
      vf_explained_var: 0.0
      vf_loss: 12.118000984191895
    num_steps_sampled: 5820000
    num_steps_trained: 5820000
    wait_time_ms: 435.346
  iterations_since_restore: 194
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 8638.304271697998
  time_this_iter_s: 44.66476225852966
  time_total_s: 8638.304271697998
  timestamp: 1594160818
  timesteps_since_restore: 5820000
  timesteps_this_iter: 30000
  timesteps_total: 5820000
  training_iteration: 194
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 8638 s, 194 iter, 5820000 ts, 1.26e+03 rew

agent-1: 40.0
agent-2: 57.0
agent-3: 38.0
agent-4: 24.0
agent-5: 31.0
agent-6: 43.0
agent-7: 30.0
agent-8: 33.0
agent-9: 20.0
agent-10: 35.0
agent-11: 36.0
agent-12: 21.0
agent-13: 49.0
agent-14: 19.0
agent-15: 31.0
agent-16: 55.0
agent-17: 48.0
agent-18: 31.0
agent-19: 60.0
agent-20: 46.0
agent-21: 37.0
agent-22: 54.0
agent-23: 50.0
agent-24: 62.0
agent-25: 65.0
agent-26: 49.0
agent-27: 42.0
agent-28: 27.0
agent-29: 45.0
agent-30: 47.0
Sum Reward: 1225.0
Avg Reward: 40.833333333333336
Min Reward: 19.0
Max Reward: 65.0
Gini Coefficient: 0.17613605442176872
20:20 Ratio: 2.50354609929078
Max-min Ratio: 3.4210526315789473
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-27-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1263.7
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 194
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.157
    dispatch_time_ms: 28.276
    learner:
      cur_lr: 0.0009723880211822689
      grad_gnorm: 40.000003814697266
      policy_entropy: 187.39752197265625
      policy_loss: 28.775955200195312
      var_gnorm: 23.312580108642578
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 136.75572204589844
    num_steps_sampled: 5850000
    num_steps_trained: 5850000
    wait_time_ms: 413.833
  iterations_since_restore: 195
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 8681.80218744278
  time_this_iter_s: 43.497915744781494
  time_total_s: 8681.80218744278
  timestamp: 1594160861
  timesteps_since_restore: 5850000
  timesteps_this_iter: 30000
  timesteps_total: 5850000
  training_iteration: 195
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 8681 s, 195 iter, 5850000 ts, 1.26e+03 rew

agent-1: 50.0
agent-2: 50.0
agent-3: 64.0
agent-4: 48.0
agent-5: 38.0
agent-6: 42.0
agent-7: 49.0
agent-8: 76.0
agent-9: 44.0
agent-10: 66.0
agent-11: 87.0
agent-12: 49.0
agent-13: 45.0
agent-14: 68.0
agent-15: 53.0
agent-16: 57.0
agent-17: 49.0
agent-18: 37.0
agent-19: 45.0
agent-20: 59.0
agent-21: 39.0
agent-22: 34.0
agent-23: 49.0
agent-24: 41.0
agent-25: 73.0
agent-26: 47.0
agent-27: 42.0
agent-28: 31.0
agent-29: 46.0
agent-30: 57.0
Sum Reward: 1535.0
Avg Reward: 51.166666666666664
Min Reward: 31.0
Max Reward: 87.0
Gini Coefficient: 0.13483170466883823
20:20 Ratio: 1.9727272727272727
Max-min Ratio: 2.806451612903226
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-28-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1266.78
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 195
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.977
    dispatch_time_ms: 33.335
    learner:
      cur_lr: 0.0009703899850137532
      grad_gnorm: 40.0
      policy_entropy: 217.82339477539062
      policy_loss: 104.96173858642578
      var_gnorm: 23.302759170532227
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 212.2826690673828
    num_steps_sampled: 5880000
    num_steps_trained: 5880000
    wait_time_ms: 423.444
  iterations_since_restore: 196
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 8727.704189538956
  time_this_iter_s: 45.90200209617615
  time_total_s: 8727.704189538956
  timestamp: 1594160907
  timesteps_since_restore: 5880000
  timesteps_this_iter: 30000
  timesteps_total: 5880000
  training_iteration: 196
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 8727 s, 196 iter, 5880000 ts, 1.27e+03 rew

agent-1: 63.0
agent-2: 38.0
agent-3: 46.0
agent-4: 63.0
agent-5: 39.0
agent-6: 38.0
agent-7: 49.0
agent-8: 33.0
agent-9: 46.0
agent-10: 64.0
agent-11: 38.0
agent-12: 46.0
agent-13: 31.0
agent-14: 42.0
agent-15: 24.0
agent-16: 34.0
agent-17: 56.0
agent-18: 14.0
agent-19: 40.0
agent-20: 34.0
agent-21: 30.0
agent-22: 31.0
agent-23: 22.0
agent-24: 50.0
agent-25: 51.0
agent-26: 32.0
agent-27: 41.0
agent-28: 6.0
agent-29: 50.0
agent-30: 85.0
Sum Reward: 1236.0
Avg Reward: 41.2
Min Reward: 6.0
Max Reward: 85.0
Gini Coefficient: 0.20539374325782092
20:20 Ratio: 3.0078740157480315
Max-min Ratio: 14.166666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-29-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1264.21
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 196
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.083
    dispatch_time_ms: 20.737
    learner:
      cur_lr: 0.0009683920070528984
      grad_gnorm: 40.000003814697266
      policy_entropy: 134.69607543945312
      policy_loss: -27.835485458374023
      var_gnorm: 23.307857513427734
      vf_explained_var: 0.0
      vf_loss: 12.106443405151367
    num_steps_sampled: 5910000
    num_steps_trained: 5910000
    wait_time_ms: 443.928
  iterations_since_restore: 197
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 8772.956600666046
  time_this_iter_s: 45.252411127090454
  time_total_s: 8772.956600666046
  timestamp: 1594160952
  timesteps_since_restore: 5910000
  timesteps_this_iter: 30000
  timesteps_total: 5910000
  training_iteration: 197
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 8772 s, 197 iter, 5910000 ts, 1.26e+03 rew

agent-1: 32.0
agent-2: 30.0
agent-3: 39.0
agent-4: 31.0
agent-5: 18.0
agent-6: 28.0
agent-7: 55.0
agent-8: 37.0
agent-9: 35.0
agent-10: 45.0
agent-11: 54.0
agent-12: 28.0
agent-13: 22.0
agent-14: 38.0
agent-15: 38.0
agent-16: 79.0
agent-17: 51.0
agent-18: 67.0
agent-19: 54.0
agent-20: 68.0
agent-21: 37.0
agent-22: 37.0
agent-23: 55.0
agent-24: 10.0
agent-25: 48.0
agent-26: 27.0
agent-27: 37.0
agent-28: 61.0
agent-29: 55.0
agent-30: 13.0
Sum Reward: 1229.0
Avg Reward: 40.96666666666667
Min Reward: 10.0
Max Reward: 79.0
Gini Coefficient: 0.22302685109845402
20:20 Ratio: 3.26271186440678
Max-min Ratio: 7.9
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-29-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1262.89
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 197
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.376
    dispatch_time_ms: 6.97
    learner:
      cur_lr: 0.0009663940290920436
      grad_gnorm: 40.0
      policy_entropy: 184.88690185546875
      policy_loss: -8.809366226196289
      var_gnorm: 23.30039405822754
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 4.779390811920166
    num_steps_sampled: 5940000
    num_steps_trained: 5940000
    wait_time_ms: 401.664
  iterations_since_restore: 198
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 8818.886942148209
  time_this_iter_s: 45.930341482162476
  time_total_s: 8818.886942148209
  timestamp: 1594160998
  timesteps_since_restore: 5940000
  timesteps_this_iter: 30000
  timesteps_total: 5940000
  training_iteration: 198
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 8818 s, 198 iter, 5940000 ts, 1.26e+03 rew

agent-1: 42.0
agent-2: 46.0
agent-3: 26.0
agent-4: 26.0
agent-5: 49.0
agent-6: 29.0
agent-7: 50.0
agent-8: 23.0
agent-9: 26.0
agent-10: 20.0
agent-11: 23.0
agent-12: 28.0
agent-13: 35.0
agent-14: 44.0
agent-15: 27.0
agent-16: 27.0
agent-17: 36.0
agent-18: 48.0
agent-19: 42.0
agent-20: 41.0
agent-21: 61.0
agent-22: 29.0
agent-23: 43.0
agent-24: 11.0
agent-25: 32.0
agent-26: 26.0
agent-27: 41.0
agent-28: 54.0
agent-29: 47.0
agent-30: 17.0
Sum Reward: 1049.0
Avg Reward: 34.96666666666667
Min Reward: 11.0
Max Reward: 61.0
Gini Coefficient: 0.19151572926596758
20:20 Ratio: 2.575
Max-min Ratio: 5.545454545454546
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-30-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1260.9
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 198
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.752
    dispatch_time_ms: 5.524
    learner:
      cur_lr: 0.000964395992923528
      grad_gnorm: 40.0
      policy_entropy: 132.76292419433594
      policy_loss: -17.835153579711914
      var_gnorm: 23.308780670166016
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 8.702210426330566
    num_steps_sampled: 5970000
    num_steps_trained: 5970000
    wait_time_ms: 435.142
  iterations_since_restore: 199
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 8862.44788479805
  time_this_iter_s: 43.56094264984131
  time_total_s: 8862.44788479805
  timestamp: 1594161042
  timesteps_since_restore: 5970000
  timesteps_this_iter: 30000
  timesteps_total: 5970000
  training_iteration: 199
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 8862 s, 199 iter, 5970000 ts, 1.26e+03 rew

agent-1: 51.0
agent-2: 58.0
agent-3: 47.0
agent-4: 26.0
agent-5: 50.0
agent-6: 38.0
agent-7: 49.0
agent-8: 20.0
agent-9: 32.0
agent-10: 84.0
agent-11: 39.0
agent-12: 58.0
agent-13: 65.0
agent-14: 29.0
agent-15: 38.0
agent-16: 59.0
agent-17: 50.0
agent-18: 53.0
agent-19: 61.0
agent-20: 46.0
agent-21: 51.0
agent-22: 37.0
agent-23: 49.0
agent-24: 57.0
agent-25: 47.0
agent-26: 19.0
agent-27: 37.0
agent-28: 58.0
agent-29: 31.0
agent-30: 51.0
Sum Reward: 1390.0
Avg Reward: 46.333333333333336
Min Reward: 19.0
Max Reward: 84.0
Gini Coefficient: 0.1651798561151079
20:20 Ratio: 2.4522292993630574
Max-min Ratio: 4.421052631578948
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-31-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1262.38
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 199
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.649
    dispatch_time_ms: 5.386
    learner:
      cur_lr: 0.0009623980149626732
      grad_gnorm: 40.0
      policy_entropy: 155.0489044189453
      policy_loss: -26.45060157775879
      var_gnorm: 23.307443618774414
      vf_explained_var: 0.0
      vf_loss: 11.25039005279541
    num_steps_sampled: 6000000
    num_steps_trained: 6000000
    wait_time_ms: 413.13
  iterations_since_restore: 200
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 8906.277047395706
  time_this_iter_s: 43.82916259765625
  time_total_s: 8906.277047395706
  timestamp: 1594161086
  timesteps_since_restore: 6000000
  timesteps_this_iter: 30000
  timesteps_total: 6000000
  training_iteration: 200
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 8906 s, 200 iter, 6000000 ts, 1.26e+03 rew

agent-1: 59.0
agent-2: 40.0
agent-3: 32.0
agent-4: 41.0
agent-5: 50.0
agent-6: 59.0
agent-7: 42.0
agent-8: 29.0
agent-9: 42.0
agent-10: 35.0
agent-11: 48.0
agent-12: 49.0
agent-13: 13.0
agent-14: 35.0
agent-15: 46.0
agent-16: 68.0
agent-17: 44.0
agent-18: 71.0
agent-19: 22.0
agent-20: 47.0
agent-21: 51.0
agent-22: 32.0
agent-23: 45.0
agent-24: 28.0
agent-25: 31.0
agent-26: 49.0
agent-27: 60.0
agent-28: 52.0
agent-29: 35.0
agent-30: 53.0
Sum Reward: 1308.0
Avg Reward: 43.6
Min Reward: 13.0
Max Reward: 71.0
Gini Coefficient: 0.16559633027522935
20:20 Ratio: 2.3870967741935485
Max-min Ratio: 5.461538461538462
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-32-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1261.32
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 200
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.879
    dispatch_time_ms: 9.189
    learner:
      cur_lr: 0.0009603999787941575
      grad_gnorm: 40.0
      policy_entropy: 158.0078125
      policy_loss: 31.705217361450195
      var_gnorm: 23.308958053588867
      vf_explained_var: 0.0
      vf_loss: 94.2646484375
    num_steps_sampled: 6030000
    num_steps_trained: 6030000
    wait_time_ms: 429.788
  iterations_since_restore: 201
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 8950.26276230812
  time_this_iter_s: 43.98571491241455
  time_total_s: 8950.26276230812
  timestamp: 1594161130
  timesteps_since_restore: 6030000
  timesteps_this_iter: 30000
  timesteps_total: 6030000
  training_iteration: 201
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 8950 s, 201 iter, 6030000 ts, 1.26e+03 rew

agent-1: 57.0
agent-2: 34.0
agent-3: 37.0
agent-4: 36.0
agent-5: 47.0
agent-6: 47.0
agent-7: 28.0
agent-8: 35.0
agent-9: 45.0
agent-10: 35.0
agent-11: 19.0
agent-12: 40.0
agent-13: 23.0
agent-14: 22.0
agent-15: 33.0
agent-16: 26.0
agent-17: 46.0
agent-18: 21.0
agent-19: 36.0
agent-20: 42.0
agent-21: 46.0
agent-22: 36.0
agent-23: 20.0
agent-24: 26.0
agent-25: 48.0
agent-26: 32.0
agent-27: 32.0
agent-28: 43.0
agent-29: 23.0
agent-30: 55.0
Sum Reward: 1070.0
Avg Reward: 35.666666666666664
Min Reward: 19.0
Max Reward: 57.0
Gini Coefficient: 0.16454828660436138
20:20 Ratio: 2.34375
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-32-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1257.91
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 201
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.878
    dispatch_time_ms: 6.36
    learner:
      cur_lr: 0.0009584020008333027
      grad_gnorm: 39.999996185302734
      policy_entropy: 157.20542907714844
      policy_loss: 86.82261657714844
      var_gnorm: 23.309619903564453
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 251.85812377929688
    num_steps_sampled: 6060000
    num_steps_trained: 6060000
    wait_time_ms: 405.07
  iterations_since_restore: 202
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 8994.060857534409
  time_this_iter_s: 43.79809522628784
  time_total_s: 8994.060857534409
  timestamp: 1594161174
  timesteps_since_restore: 6060000
  timesteps_this_iter: 30000
  timesteps_total: 6060000
  training_iteration: 202
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 8994 s, 202 iter, 6060000 ts, 1.26e+03 rew

agent-1: 48.0
agent-2: 52.0
agent-3: 48.0
agent-4: 53.0
agent-5: 55.0
agent-6: 50.0
agent-7: 57.0
agent-8: 28.0
agent-9: 41.0
agent-10: 40.0
agent-11: 36.0
agent-12: 51.0
agent-13: 44.0
agent-14: 55.0
agent-15: 51.0
agent-16: 47.0
agent-17: 55.0
agent-18: 55.0
agent-19: 48.0
agent-20: 23.0
agent-21: 44.0
agent-22: 45.0
agent-23: 45.0
agent-24: 23.0
agent-25: 49.0
agent-26: 76.0
agent-27: 50.0
agent-28: 31.0
agent-29: 40.0
agent-30: 34.0
Sum Reward: 1374.0
Avg Reward: 45.8
Min Reward: 23.0
Max Reward: 76.0
Gini Coefficient: 0.1262493934983018
20:20 Ratio: 2.0171428571428573
Max-min Ratio: 3.3043478260869565
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-33-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1257.43
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 202
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.624
    dispatch_time_ms: 7.48
    learner:
      cur_lr: 0.000956404022872448
      grad_gnorm: 40.0
      policy_entropy: 118.57968139648438
      policy_loss: -0.9710046052932739
      var_gnorm: 23.31749153137207
      vf_explained_var: 0.0
      vf_loss: 66.76026153564453
    num_steps_sampled: 6090000
    num_steps_trained: 6090000
    wait_time_ms: 426.994
  iterations_since_restore: 203
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 9037.124464511871
  time_this_iter_s: 43.06360697746277
  time_total_s: 9037.124464511871
  timestamp: 1594161217
  timesteps_since_restore: 6090000
  timesteps_this_iter: 30000
  timesteps_total: 6090000
  training_iteration: 203
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 9037 s, 203 iter, 6090000 ts, 1.26e+03 rew

agent-1: 47.0
agent-2: 26.0
agent-3: 30.0
agent-4: 47.0
agent-5: 59.0
agent-6: 60.0
agent-7: 100.0
agent-8: 64.0
agent-9: 34.0
agent-10: 51.0
agent-11: 43.0
agent-12: 43.0
agent-13: 31.0
agent-14: 54.0
agent-15: 37.0
agent-16: 23.0
agent-17: 33.0
agent-18: 18.0
agent-19: 50.0
agent-20: 64.0
agent-21: 16.0
agent-22: 40.0
agent-23: 34.0
agent-24: 64.0
agent-25: 26.0
agent-26: 41.0
agent-27: 34.0
agent-28: 30.0
agent-29: 63.0
agent-30: 17.0
Sum Reward: 1279.0
Avg Reward: 42.63333333333333
Min Reward: 16.0
Max Reward: 100.0
Gini Coefficient: 0.22916340891321343
20:20 Ratio: 3.2936507936507935
Max-min Ratio: 6.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-34-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1257.55
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 203
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.623
    dispatch_time_ms: 17.247
    learner:
      cur_lr: 0.0009544059867039323
      grad_gnorm: 39.999996185302734
      policy_entropy: 100.4373550415039
      policy_loss: 28.614112854003906
      var_gnorm: 23.314029693603516
      vf_explained_var: 0.0
      vf_loss: 130.9022979736328
    num_steps_sampled: 6120000
    num_steps_trained: 6120000
    wait_time_ms: 396.92
  iterations_since_restore: 204
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 9082.195994615555
  time_this_iter_s: 45.07153010368347
  time_total_s: 9082.195994615555
  timestamp: 1594161262
  timesteps_since_restore: 6120000
  timesteps_this_iter: 30000
  timesteps_total: 6120000
  training_iteration: 204
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 9082 s, 204 iter, 6120000 ts, 1.26e+03 rew

agent-1: 45.0
agent-2: 38.0
agent-3: 26.0
agent-4: 61.0
agent-5: 57.0
agent-6: 81.0
agent-7: 26.0
agent-8: 39.0
agent-9: 39.0
agent-10: 51.0
agent-11: 62.0
agent-12: 31.0
agent-13: 40.0
agent-14: 36.0
agent-15: 58.0
agent-16: 62.0
agent-17: 54.0
agent-18: 51.0
agent-19: 43.0
agent-20: 74.0
agent-21: 55.0
agent-22: 44.0
agent-23: 66.0
agent-24: 48.0
agent-25: 33.0
agent-26: 45.0
agent-27: 34.0
agent-28: 39.0
agent-29: 32.0
agent-30: 55.0
Sum Reward: 1425.0
Avg Reward: 47.5
Min Reward: 26.0
Max Reward: 81.0
Gini Coefficient: 0.16105263157894736
20:20 Ratio: 2.230769230769231
Max-min Ratio: 3.1153846153846154
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-35-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1258.12
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 204
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.415
    dispatch_time_ms: 26.983
    learner:
      cur_lr: 0.0009524080087430775
      grad_gnorm: 30.23749542236328
      policy_entropy: 140.23362731933594
      policy_loss: -4.204307556152344
      var_gnorm: 23.319063186645508
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 33.7630615234375
    num_steps_sampled: 6150000
    num_steps_trained: 6150000
    wait_time_ms: 443.733
  iterations_since_restore: 205
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 9127.764954090118
  time_this_iter_s: 45.5689594745636
  time_total_s: 9127.764954090118
  timestamp: 1594161308
  timesteps_since_restore: 6150000
  timesteps_this_iter: 30000
  timesteps_total: 6150000
  training_iteration: 205
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 9127 s, 205 iter, 6150000 ts, 1.26e+03 rew

agent-1: 23.0
agent-2: 41.0
agent-3: 14.0
agent-4: 62.0
agent-5: 61.0
agent-6: 14.0
agent-7: 26.0
agent-8: 37.0
agent-9: 34.0
agent-10: 36.0
agent-11: 52.0
agent-12: 31.0
agent-13: 41.0
agent-14: 50.0
agent-15: 55.0
agent-16: 52.0
agent-17: 50.0
agent-18: 45.0
agent-19: 43.0
agent-20: 32.0
agent-21: 23.0
agent-22: 22.0
agent-23: 31.0
agent-24: 40.0
agent-25: 64.0
agent-26: 51.0
agent-27: 41.0
agent-28: 43.0
agent-29: 22.0
agent-30: 43.0
Sum Reward: 1179.0
Avg Reward: 39.3
Min Reward: 14.0
Max Reward: 64.0
Gini Coefficient: 0.19516539440203562
20:20 Ratio: 2.9322033898305087
Max-min Ratio: 4.571428571428571
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-35-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1254.48
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 205
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.721
    dispatch_time_ms: 34.282
    learner:
      cur_lr: 0.0009504099725745618
      grad_gnorm: 40.0
      policy_entropy: 108.87614440917969
      policy_loss: 3.6204304695129395
      var_gnorm: 23.312442779541016
      vf_explained_var: 0.0
      vf_loss: 43.263545989990234
    num_steps_sampled: 6180000
    num_steps_trained: 6180000
    wait_time_ms: 627.761
  iterations_since_restore: 206
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 9175.841489315033
  time_this_iter_s: 48.07653522491455
  time_total_s: 9175.841489315033
  timestamp: 1594161356
  timesteps_since_restore: 6180000
  timesteps_this_iter: 30000
  timesteps_total: 6180000
  training_iteration: 206
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 9175 s, 206 iter, 6180000 ts, 1.25e+03 rew

agent-1: 49.0
agent-2: 22.0
agent-3: 57.0
agent-4: 29.0
agent-5: 43.0
agent-6: 26.0
agent-7: 35.0
agent-8: 56.0
agent-9: 36.0
agent-10: 34.0
agent-11: 63.0
agent-12: 37.0
agent-13: 39.0
agent-14: 31.0
agent-15: 33.0
agent-16: 35.0
agent-17: 55.0
agent-18: 43.0
agent-19: 48.0
agent-20: 36.0
agent-21: 61.0
agent-22: 35.0
agent-23: 31.0
agent-24: 58.0
agent-25: 34.0
agent-26: 54.0
agent-27: 39.0
agent-28: 60.0
agent-29: 55.0
agent-30: 21.0
Sum Reward: 1255.0
Avg Reward: 41.833333333333336
Min Reward: 21.0
Max Reward: 63.0
Gini Coefficient: 0.16284196547144755
20:20 Ratio: 2.21875
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-36-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1256.44
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 206
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.591
    dispatch_time_ms: 6.961
    learner:
      cur_lr: 0.0009484119946137071
      grad_gnorm: 40.000003814697266
      policy_entropy: 124.39820861816406
      policy_loss: 9.709845542907715
      var_gnorm: 23.318769454956055
      vf_explained_var: 0.0
      vf_loss: 86.53189086914062
    num_steps_sampled: 6210000
    num_steps_trained: 6210000
    wait_time_ms: 423.351
  iterations_since_restore: 207
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 9216.35877585411
  time_this_iter_s: 40.51728653907776
  time_total_s: 9216.35877585411
  timestamp: 1594161396
  timesteps_since_restore: 6210000
  timesteps_this_iter: 30000
  timesteps_total: 6210000
  training_iteration: 207
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 9216 s, 207 iter, 6210000 ts, 1.26e+03 rew

agent-1: 59.0
agent-2: 18.0
agent-3: 54.0
agent-4: 60.0
agent-5: 46.0
agent-6: 68.0
agent-7: 22.0
agent-8: 50.0
agent-9: 34.0
agent-10: 9.0
agent-11: 49.0
agent-12: 39.0
agent-13: 33.0
agent-14: 63.0
agent-15: 43.0
agent-16: 41.0
agent-17: 36.0
agent-18: 69.0
agent-19: 46.0
agent-20: 66.0
agent-21: 71.0
agent-22: 67.0
agent-23: 15.0
agent-24: 68.0
agent-25: 88.0
agent-26: 65.0
agent-27: 57.0
agent-28: 40.0
agent-29: 33.0
agent-30: 39.0
Sum Reward: 1448.0
Avg Reward: 48.266666666666666
Min Reward: 9.0
Max Reward: 88.0
Gini Coefficient: 0.21620626151012892
20:20 Ratio: 3.3153846153846156
Max-min Ratio: 9.777777777777779
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-37-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1260.34
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 207
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.593
    dispatch_time_ms: 5.856
    learner:
      cur_lr: 0.0009464140166528523
      grad_gnorm: 40.0
      policy_entropy: 88.09288787841797
      policy_loss: 34.70398712158203
      var_gnorm: 23.3179931640625
      vf_explained_var: 0.0
      vf_loss: 137.59788513183594
    num_steps_sampled: 6240000
    num_steps_trained: 6240000
    wait_time_ms: 423.009
  iterations_since_restore: 208
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 9260.1318089962
  time_this_iter_s: 43.773033142089844
  time_total_s: 9260.1318089962
  timestamp: 1594161440
  timesteps_since_restore: 6240000
  timesteps_this_iter: 30000
  timesteps_total: 6240000
  training_iteration: 208
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 9260 s, 208 iter, 6240000 ts, 1.26e+03 rew

agent-1: 38.0
agent-2: 35.0
agent-3: 39.0
agent-4: 47.0
agent-5: 71.0
agent-6: 37.0
agent-7: 33.0
agent-8: 15.0
agent-9: 54.0
agent-10: 73.0
agent-11: 48.0
agent-12: 36.0
agent-13: 28.0
agent-14: 49.0
agent-15: 42.0
agent-16: 65.0
agent-17: 74.0
agent-18: 40.0
agent-19: 69.0
agent-20: 37.0
agent-21: 57.0
agent-22: 24.0
agent-23: 44.0
agent-24: 55.0
agent-25: 16.0
agent-26: 52.0
agent-27: 52.0
agent-28: 68.0
agent-29: 71.0
agent-30: 51.0
Sum Reward: 1420.0
Avg Reward: 47.333333333333336
Min Reward: 15.0
Max Reward: 74.0
Gini Coefficient: 0.193943661971831
20:20 Ratio: 2.8211920529801326
Max-min Ratio: 4.933333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-38-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1263.02
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 208
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.441
    dispatch_time_ms: 5.43
    learner:
      cur_lr: 0.0009444159804843366
      grad_gnorm: 40.0
      policy_entropy: 117.09854125976562
      policy_loss: -19.882400512695312
      var_gnorm: 23.322673797607422
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 25.792522430419922
    num_steps_sampled: 6270000
    num_steps_trained: 6270000
    wait_time_ms: 440.787
  iterations_since_restore: 209
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 9303.50076341629
  time_this_iter_s: 43.36895442008972
  time_total_s: 9303.50076341629
  timestamp: 1594161483
  timesteps_since_restore: 6270000
  timesteps_this_iter: 30000
  timesteps_total: 6270000
  training_iteration: 209
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 9303 s, 209 iter, 6270000 ts, 1.26e+03 rew

agent-1: 57.0
agent-2: 24.0
agent-3: 24.0
agent-4: 40.0
agent-5: 58.0
agent-6: 58.0
agent-7: 61.0
agent-8: 25.0
agent-9: 34.0
agent-10: 42.0
agent-11: 52.0
agent-12: 29.0
agent-13: 69.0
agent-14: 75.0
agent-15: 35.0
agent-16: 73.0
agent-17: 20.0
agent-18: 38.0
agent-19: 23.0
agent-20: 67.0
agent-21: 19.0
agent-22: 51.0
agent-23: 33.0
agent-24: 74.0
agent-25: 45.0
agent-26: 38.0
agent-27: 53.0
agent-28: 54.0
agent-29: 31.0
agent-30: 64.0
Sum Reward: 1366.0
Avg Reward: 45.53333333333333
Min Reward: 19.0
Max Reward: 75.0
Gini Coefficient: 0.21766715470961445
20:20 Ratio: 3.1259259259259258
Max-min Ratio: 3.9473684210526314
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-38-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1267.16
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 209
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.921
    dispatch_time_ms: 28.189
    learner:
      cur_lr: 0.0009424180025234818
      grad_gnorm: 40.0
      policy_entropy: 119.801025390625
      policy_loss: 29.997215270996094
      var_gnorm: 23.313812255859375
      vf_explained_var: 0.0
      vf_loss: 157.92379760742188
    num_steps_sampled: 6300000
    num_steps_trained: 6300000
    wait_time_ms: 399.621
  iterations_since_restore: 210
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 9348.630074501038
  time_this_iter_s: 45.129311084747314
  time_total_s: 9348.630074501038
  timestamp: 1594161529
  timesteps_since_restore: 6300000
  timesteps_this_iter: 30000
  timesteps_total: 6300000
  training_iteration: 210
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 9348 s, 210 iter, 6300000 ts, 1.27e+03 rew

agent-1: 43.0
agent-2: 35.0
agent-3: 42.0
agent-4: 64.0
agent-5: 42.0
agent-6: 34.0
agent-7: 77.0
agent-8: 35.0
agent-9: 48.0
agent-10: 22.0
agent-11: 58.0
agent-12: 33.0
agent-13: 46.0
agent-14: 24.0
agent-15: 29.0
agent-16: 22.0
agent-17: 60.0
agent-18: 31.0
agent-19: 46.0
agent-20: 43.0
agent-21: 34.0
agent-22: 17.0
agent-23: 59.0
agent-24: 37.0
agent-25: 35.0
agent-26: 30.0
agent-27: 42.0
agent-28: 13.0
agent-29: 35.0
agent-30: 42.0
Sum Reward: 1178.0
Avg Reward: 39.266666666666666
Min Reward: 13.0
Max Reward: 77.0
Gini Coefficient: 0.19541595925297114
20:20 Ratio: 2.8818897637795278
Max-min Ratio: 5.923076923076923
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-39-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1265.74
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 210
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.81
    dispatch_time_ms: 31.346
    learner:
      cur_lr: 0.0009404200245626271
      grad_gnorm: 40.0
      policy_entropy: 93.6549072265625
      policy_loss: -17.097959518432617
      var_gnorm: 23.319242477416992
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 15.568194389343262
    num_steps_sampled: 6330000
    num_steps_trained: 6330000
    wait_time_ms: 418.712
  iterations_since_restore: 211
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 9394.191904783249
  time_this_iter_s: 45.561830282211304
  time_total_s: 9394.191904783249
  timestamp: 1594161574
  timesteps_since_restore: 6330000
  timesteps_this_iter: 30000
  timesteps_total: 6330000
  training_iteration: 211
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 9394 s, 211 iter, 6330000 ts, 1.27e+03 rew

agent-1: 41.0
agent-2: 46.0
agent-3: 18.0
agent-4: 58.0
agent-5: 53.0
agent-6: 37.0
agent-7: 27.0
agent-8: 60.0
agent-9: 28.0
agent-10: 39.0
agent-11: 56.0
agent-12: 29.0
agent-13: 58.0
agent-14: 16.0
agent-15: 45.0
agent-16: 64.0
agent-17: 15.0
agent-18: 73.0
agent-19: 26.0
agent-20: 27.0
agent-21: 80.0
agent-22: 27.0
agent-23: 30.0
agent-24: 36.0
agent-25: 68.0
agent-26: 62.0
agent-27: 49.0
agent-28: 58.0
agent-29: 79.0
agent-30: 31.0
Sum Reward: 1336.0
Avg Reward: 44.53333333333333
Min Reward: 15.0
Max Reward: 80.0
Gini Coefficient: 0.23687624750499
20:20 Ratio: 3.302325581395349
Max-min Ratio: 5.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-40-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1265.29
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 211
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.627
    dispatch_time_ms: 36.89
    learner:
      cur_lr: 0.0009384219883941114
      grad_gnorm: 40.0
      policy_entropy: 122.5399169921875
      policy_loss: 51.9345817565918
      var_gnorm: 23.318767547607422
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 160.01046752929688
    num_steps_sampled: 6360000
    num_steps_trained: 6360000
    wait_time_ms: 380.131
  iterations_since_restore: 212
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 9439.186813354492
  time_this_iter_s: 44.994908571243286
  time_total_s: 9439.186813354492
  timestamp: 1594161619
  timesteps_since_restore: 6360000
  timesteps_this_iter: 30000
  timesteps_total: 6360000
  training_iteration: 212
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 9439 s, 212 iter, 6360000 ts, 1.27e+03 rew

agent-1: 59.0
agent-2: 54.0
agent-3: 56.0
agent-4: 47.0
agent-5: 30.0
agent-6: 48.0
agent-7: 36.0
agent-8: 31.0
agent-9: 56.0
agent-10: 43.0
agent-11: 66.0
agent-12: 35.0
agent-13: 37.0
agent-14: 60.0
agent-15: 49.0
agent-16: 55.0
agent-17: 64.0
agent-18: 62.0
agent-19: 46.0
agent-20: 28.0
agent-21: 59.0
agent-22: 30.0
agent-23: 73.0
agent-24: 48.0
agent-25: 49.0
agent-26: 37.0
agent-27: 44.0
agent-28: 57.0
agent-29: 42.0
agent-30: 41.0
Sum Reward: 1442.0
Avg Reward: 48.06666666666667
Min Reward: 28.0
Max Reward: 73.0
Gini Coefficient: 0.139251040221914
20:20 Ratio: 2.0210526315789474
Max-min Ratio: 2.607142857142857
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-41-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1268.16
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 212
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.978
    dispatch_time_ms: 46.721
    learner:
      cur_lr: 0.0009364240104332566
      grad_gnorm: 40.0
      policy_entropy: 144.3266143798828
      policy_loss: 14.700151443481445
      var_gnorm: 23.322019577026367
      vf_explained_var: 0.0
      vf_loss: 113.04473876953125
    num_steps_sampled: 6390000
    num_steps_trained: 6390000
    wait_time_ms: 412.397
  iterations_since_restore: 213
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 9484.743351221085
  time_this_iter_s: 45.55653786659241
  time_total_s: 9484.743351221085
  timestamp: 1594161665
  timesteps_since_restore: 6390000
  timesteps_this_iter: 30000
  timesteps_total: 6390000
  training_iteration: 213
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 9484 s, 213 iter, 6390000 ts, 1.27e+03 rew

agent-1: 47.0
agent-2: 20.0
agent-3: 56.0
agent-4: 36.0
agent-5: 50.0
agent-6: 52.0
agent-7: 38.0
agent-8: 20.0
agent-9: 44.0
agent-10: 49.0
agent-11: 31.0
agent-12: 63.0
agent-13: 47.0
agent-14: 80.0
agent-15: 47.0
agent-16: 52.0
agent-17: 42.0
agent-18: 45.0
agent-19: 52.0
agent-20: 32.0
agent-21: 60.0
agent-22: 42.0
agent-23: 35.0
agent-24: 53.0
agent-25: 36.0
agent-26: 50.0
agent-27: 39.0
agent-28: 58.0
agent-29: 47.0
agent-30: 47.0
Sum Reward: 1370.0
Avg Reward: 45.666666666666664
Min Reward: 20.0
Max Reward: 80.0
Gini Coefficient: 0.1421897810218978
20:20 Ratio: 2.1264367816091956
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-41-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1268.09
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 213
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.546
    dispatch_time_ms: 26.939
    learner:
      cur_lr: 0.0009344259742647409
      grad_gnorm: 40.000003814697266
      policy_entropy: 115.64160919189453
      policy_loss: 29.136959075927734
      var_gnorm: 23.3138370513916
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 65.74486541748047
    num_steps_sampled: 6420000
    num_steps_trained: 6420000
    wait_time_ms: 474.21
  iterations_since_restore: 214
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 9530.802007436752
  time_this_iter_s: 46.058656215667725
  time_total_s: 9530.802007436752
  timestamp: 1594161711
  timesteps_since_restore: 6420000
  timesteps_this_iter: 30000
  timesteps_total: 6420000
  training_iteration: 214
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 9530 s, 214 iter, 6420000 ts, 1.27e+03 rew

agent-1: 43.0
agent-2: 38.0
agent-3: 30.0
agent-4: 48.0
agent-5: 21.0
agent-6: 22.0
agent-7: 26.0
agent-8: 29.0
agent-9: 18.0
agent-10: 29.0
agent-11: 22.0
agent-12: 50.0
agent-13: 44.0
agent-14: 20.0
agent-15: 35.0
agent-16: 40.0
agent-17: 47.0
agent-18: 54.0
agent-19: 46.0
agent-20: 34.0
agent-21: 44.0
agent-22: 15.0
agent-23: 10.0
agent-24: 22.0
agent-25: 44.0
agent-26: 38.0
agent-27: 42.0
agent-28: 21.0
agent-29: 52.0
agent-30: 61.0
Sum Reward: 1045.0
Avg Reward: 34.833333333333336
Min Reward: 10.0
Max Reward: 61.0
Gini Coefficient: 0.21170653907496012
20:20 Ratio: 2.9714285714285715
Max-min Ratio: 6.1
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-42-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1265.34
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 214
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.924
    dispatch_time_ms: 6.216
    learner:
      cur_lr: 0.0009324279963038862
      grad_gnorm: 40.0
      policy_entropy: 109.22267150878906
      policy_loss: 8.175358772277832
      var_gnorm: 23.319889068603516
      vf_explained_var: 0.0
      vf_loss: 94.2451400756836
    num_steps_sampled: 6450000
    num_steps_trained: 6450000
    wait_time_ms: 447.755
  iterations_since_restore: 215
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 9573.888496875763
  time_this_iter_s: 43.08648943901062
  time_total_s: 9573.888496875763
  timestamp: 1594161754
  timesteps_since_restore: 6450000
  timesteps_this_iter: 30000
  timesteps_total: 6450000
  training_iteration: 215
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 9573 s, 215 iter, 6450000 ts, 1.27e+03 rew

agent-1: 44.0
agent-2: 65.0
agent-3: 55.0
agent-4: 30.0
agent-5: 44.0
agent-6: 53.0
agent-7: 53.0
agent-8: 48.0
agent-9: 48.0
agent-10: 43.0
agent-11: 46.0
agent-12: 27.0
agent-13: 51.0
agent-14: 43.0
agent-15: 42.0
agent-16: 59.0
agent-17: 46.0
agent-18: 68.0
agent-19: 49.0
agent-20: 30.0
agent-21: 51.0
agent-22: 63.0
agent-23: 53.0
agent-24: 44.0
agent-25: 47.0
agent-26: 38.0
agent-27: 54.0
agent-28: 38.0
agent-29: 52.0
agent-30: 58.0
Sum Reward: 1442.0
Avg Reward: 48.06666666666667
Min Reward: 27.0
Max Reward: 68.0
Gini Coefficient: 0.11095700416088766
20:20 Ratio: 1.7951219512195122
Max-min Ratio: 2.5185185185185186
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-43-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1267.29
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 215
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.879
    dispatch_time_ms: 6.192
    learner:
      cur_lr: 0.0009304300183430314
      grad_gnorm: 40.0
      policy_entropy: 123.40824890136719
      policy_loss: 18.224586486816406
      var_gnorm: 23.322324752807617
      vf_explained_var: 0.0
      vf_loss: 103.09520721435547
    num_steps_sampled: 6480000
    num_steps_trained: 6480000
    wait_time_ms: 437.352
  iterations_since_restore: 216
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 9617.377551555634
  time_this_iter_s: 43.489054679870605
  time_total_s: 9617.377551555634
  timestamp: 1594161798
  timesteps_since_restore: 6480000
  timesteps_this_iter: 30000
  timesteps_total: 6480000
  training_iteration: 216
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 9617 s, 216 iter, 6480000 ts, 1.27e+03 rew

agent-1: 50.0
agent-2: 56.0
agent-3: 52.0
agent-4: 48.0
agent-5: 61.0
agent-6: 26.0
agent-7: 48.0
agent-8: 59.0
agent-9: 66.0
agent-10: 43.0
agent-11: 39.0
agent-12: 63.0
agent-13: 77.0
agent-14: 63.0
agent-15: 16.0
agent-16: 46.0
agent-17: 47.0
agent-18: 54.0
agent-19: 52.0
agent-20: 47.0
agent-21: 41.0
agent-22: 44.0
agent-23: 44.0
agent-24: 64.0
agent-25: 64.0
agent-26: 35.0
agent-27: 17.0
agent-28: 41.0
agent-29: 38.0
agent-30: 61.0
Sum Reward: 1462.0
Avg Reward: 48.733333333333334
Min Reward: 16.0
Max Reward: 77.0
Gini Coefficient: 0.15585955312357502
20:20 Ratio: 2.3216374269005846
Max-min Ratio: 4.8125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-44-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1267.96
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 216
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.434
    dispatch_time_ms: 6.831
    learner:
      cur_lr: 0.0009284319821745157
      grad_gnorm: 40.0
      policy_entropy: 153.2271728515625
      policy_loss: 19.371440887451172
      var_gnorm: 23.32119369506836
      vf_explained_var: 0.0
      vf_loss: 57.53398895263672
    num_steps_sampled: 6510000
    num_steps_trained: 6510000
    wait_time_ms: 411.526
  iterations_since_restore: 217
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 9660.257325172424
  time_this_iter_s: 42.87977361679077
  time_total_s: 9660.257325172424
  timestamp: 1594161841
  timesteps_since_restore: 6510000
  timesteps_this_iter: 30000
  timesteps_total: 6510000
  training_iteration: 217
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 9660 s, 217 iter, 6510000 ts, 1.27e+03 rew

agent-1: 47.0
agent-2: 70.0
agent-3: 64.0
agent-4: 28.0
agent-5: 43.0
agent-6: 34.0
agent-7: 66.0
agent-8: 59.0
agent-9: 65.0
agent-10: 58.0
agent-11: 36.0
agent-12: 69.0
agent-13: 41.0
agent-14: 33.0
agent-15: 62.0
agent-16: 56.0
agent-17: 54.0
agent-18: 44.0
agent-19: 48.0
agent-20: 70.0
agent-21: 45.0
agent-22: 56.0
agent-23: 56.0
agent-24: 63.0
agent-25: 47.0
agent-26: 59.0
agent-27: 88.0
agent-28: 18.0
agent-29: 37.0
agent-30: 66.0
Sum Reward: 1582.0
Avg Reward: 52.733333333333334
Min Reward: 18.0
Max Reward: 88.0
Gini Coefficient: 0.15760640539401602
20:20 Ratio: 2.306451612903226
Max-min Ratio: 4.888888888888889
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-44-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1272.06
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 217
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.957
    dispatch_time_ms: 5.772
    learner:
      cur_lr: 0.000926434004213661
      grad_gnorm: 40.0
      policy_entropy: 159.22984313964844
      policy_loss: -25.01282501220703
      var_gnorm: 23.318387985229492
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 10.336243629455566
    num_steps_sampled: 6540000
    num_steps_trained: 6540000
    wait_time_ms: 456.916
  iterations_since_restore: 218
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 9704.167518615723
  time_this_iter_s: 43.91019344329834
  time_total_s: 9704.167518615723
  timestamp: 1594161885
  timesteps_since_restore: 6540000
  timesteps_this_iter: 30000
  timesteps_total: 6540000
  training_iteration: 218
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 9704 s, 218 iter, 6540000 ts, 1.27e+03 rew

agent-1: 46.0
agent-2: 46.0
agent-3: 59.0
agent-4: 39.0
agent-5: 43.0
agent-6: 38.0
agent-7: 42.0
agent-8: 48.0
agent-9: 32.0
agent-10: 50.0
agent-11: 41.0
agent-12: 20.0
agent-13: 54.0
agent-14: 41.0
agent-15: 66.0
agent-16: 30.0
agent-17: 22.0
agent-18: 18.0
agent-19: 44.0
agent-20: 44.0
agent-21: 60.0
agent-22: 17.0
agent-23: 57.0
agent-24: 32.0
agent-25: 41.0
agent-26: 22.0
agent-27: 70.0
agent-28: 27.0
agent-29: 35.0
agent-30: 35.0
Sum Reward: 1219.0
Avg Reward: 40.63333333333333
Min Reward: 17.0
Max Reward: 70.0
Gini Coefficient: 0.19034727919059338
20:20 Ratio: 2.9047619047619047
Max-min Ratio: 4.117647058823529
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-45-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1274.05
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 218
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.624
    dispatch_time_ms: 7.21
    learner:
      cur_lr: 0.0009244360262528062
      grad_gnorm: 40.000003814697266
      policy_entropy: 215.48155212402344
      policy_loss: -6.378818988800049
      var_gnorm: 23.312053680419922
      vf_explained_var: 0.0
      vf_loss: 113.0141372680664
    num_steps_sampled: 6570000
    num_steps_trained: 6570000
    wait_time_ms: 426.156
  iterations_since_restore: 219
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 9748.068106651306
  time_this_iter_s: 43.900588035583496
  time_total_s: 9748.068106651306
  timestamp: 1594161929
  timesteps_since_restore: 6570000
  timesteps_this_iter: 30000
  timesteps_total: 6570000
  training_iteration: 219
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 9748 s, 219 iter, 6570000 ts, 1.27e+03 rew

agent-1: 11.0
agent-2: 46.0
agent-3: 40.0
agent-4: 38.0
agent-5: 33.0
agent-6: 49.0
agent-7: 30.0
agent-8: 16.0
agent-9: 25.0
agent-10: 29.0
agent-11: 47.0
agent-12: 35.0
agent-13: 57.0
agent-14: 61.0
agent-15: 60.0
agent-16: 15.0
agent-17: 45.0
agent-18: 54.0
agent-19: 29.0
agent-20: 18.0
agent-21: 56.0
agent-22: 17.0
agent-23: 39.0
agent-24: 40.0
agent-25: 32.0
agent-26: 48.0
agent-27: 45.0
agent-28: 25.0
agent-29: 28.0
agent-30: 44.0
Sum Reward: 1112.0
Avg Reward: 37.06666666666667
Min Reward: 11.0
Max Reward: 61.0
Gini Coefficient: 0.21408872901678658
20:20 Ratio: 3.303921568627451
Max-min Ratio: 5.545454545454546
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-46-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1274.69
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 219
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.505
    dispatch_time_ms: 5.993
    learner:
      cur_lr: 0.0009224379900842905
      grad_gnorm: 39.999996185302734
      policy_entropy: 175.68734741210938
      policy_loss: 7.70352840423584
      var_gnorm: 23.313640594482422
      vf_explained_var: 0.0
      vf_loss: 126.6009521484375
    num_steps_sampled: 6600000
    num_steps_trained: 6600000
    wait_time_ms: 401.196
  iterations_since_restore: 220
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 9791.403046131134
  time_this_iter_s: 43.33493947982788
  time_total_s: 9791.403046131134
  timestamp: 1594161972
  timesteps_since_restore: 6600000
  timesteps_this_iter: 30000
  timesteps_total: 6600000
  training_iteration: 220
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 9791 s, 220 iter, 6600000 ts, 1.27e+03 rew

agent-1: 61.0
agent-2: 9.0
agent-3: 31.0
agent-4: 33.0
agent-5: 41.0
agent-6: 37.0
agent-7: 43.0
agent-8: 78.0
agent-9: 52.0
agent-10: 35.0
agent-11: 53.0
agent-12: 43.0
agent-13: 54.0
agent-14: 44.0
agent-15: 67.0
agent-16: 26.0
agent-17: 67.0
agent-18: 40.0
agent-19: 38.0
agent-20: 32.0
agent-21: 55.0
agent-22: 35.0
agent-23: 51.0
agent-24: 82.0
agent-25: 63.0
agent-26: 44.0
agent-27: 48.0
agent-28: 45.0
agent-29: 74.0
agent-30: 38.0
Sum Reward: 1419.0
Avg Reward: 47.3
Min Reward: 9.0
Max Reward: 82.0
Gini Coefficient: 0.1865398167723749
20:20 Ratio: 2.5963855421686746
Max-min Ratio: 9.11111111111111
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-46-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1276.76
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 220
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.657
    dispatch_time_ms: 5.418
    learner:
      cur_lr: 0.0009204400121234357
      grad_gnorm: 40.0
      policy_entropy: 189.70350646972656
      policy_loss: -28.177461624145508
      var_gnorm: 23.31533432006836
      vf_explained_var: 0.0
      vf_loss: 11.483428955078125
    num_steps_sampled: 6630000
    num_steps_trained: 6630000
    wait_time_ms: 442.063
  iterations_since_restore: 221
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 9835.23623919487
  time_this_iter_s: 43.83319306373596
  time_total_s: 9835.23623919487
  timestamp: 1594162016
  timesteps_since_restore: 6630000
  timesteps_this_iter: 30000
  timesteps_total: 6630000
  training_iteration: 221
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 9835 s, 221 iter, 6630000 ts, 1.28e+03 rew

agent-1: 14.0
agent-2: 42.0
agent-3: 67.0
agent-4: 31.0
agent-5: 40.0
agent-6: 54.0
agent-7: 54.0
agent-8: 75.0
agent-9: 45.0
agent-10: 34.0
agent-11: 45.0
agent-12: 60.0
agent-13: 59.0
agent-14: 23.0
agent-15: 36.0
agent-16: 36.0
agent-17: 26.0
agent-18: 63.0
agent-19: 51.0
agent-20: 36.0
agent-21: 53.0
agent-22: 21.0
agent-23: 51.0
agent-24: 74.0
agent-25: 50.0
agent-26: 18.0
agent-27: 17.0
agent-28: 42.0
agent-29: 49.0
agent-30: 47.0
Sum Reward: 1313.0
Avg Reward: 43.766666666666666
Min Reward: 14.0
Max Reward: 75.0
Gini Coefficient: 0.20906321401370906
20:20 Ratio: 3.3445378151260505
Max-min Ratio: 5.357142857142857
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-47-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1278.01
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 221
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.876
    dispatch_time_ms: 6.287
    learner:
      cur_lr: 0.00091844197595492
      grad_gnorm: 40.0
      policy_entropy: 138.94898986816406
      policy_loss: -28.315044403076172
      var_gnorm: 23.313873291015625
      vf_explained_var: 0.0
      vf_loss: 12.176182746887207
    num_steps_sampled: 6660000
    num_steps_trained: 6660000
    wait_time_ms: 437.115
  iterations_since_restore: 222
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 9879.005759239197
  time_this_iter_s: 43.76952004432678
  time_total_s: 9879.005759239197
  timestamp: 1594162060
  timesteps_since_restore: 6660000
  timesteps_this_iter: 30000
  timesteps_total: 6660000
  training_iteration: 222
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 9879 s, 222 iter, 6660000 ts, 1.28e+03 rew

agent-1: 41.0
agent-2: 18.0
agent-3: 44.0
agent-4: 37.0
agent-5: 52.0
agent-6: 41.0
agent-7: 37.0
agent-8: 43.0
agent-9: 18.0
agent-10: 33.0
agent-11: 36.0
agent-12: 23.0
agent-13: 30.0
agent-14: 40.0
agent-15: 47.0
agent-16: 29.0
agent-17: 63.0
agent-18: 87.0
agent-19: 49.0
agent-20: 29.0
agent-21: 62.0
agent-22: 46.0
agent-23: 29.0
agent-24: 30.0
agent-25: 39.0
agent-26: 86.0
agent-27: 33.0
agent-28: 39.0
agent-29: 57.0
agent-30: 16.0
Sum Reward: 1234.0
Avg Reward: 41.13333333333333
Min Reward: 16.0
Max Reward: 87.0
Gini Coefficient: 0.21663965424095083
20:20 Ratio: 3.0601503759398496
Max-min Ratio: 5.4375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-48-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1281.09
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 222
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.86
    dispatch_time_ms: 6.848
    learner:
      cur_lr: 0.0009164439979940653
      grad_gnorm: 40.0
      policy_entropy: 165.593505859375
      policy_loss: -11.201028823852539
      var_gnorm: 23.3115291595459
      vf_explained_var: 0.0
      vf_loss: 18.240236282348633
    num_steps_sampled: 6690000
    num_steps_trained: 6690000
    wait_time_ms: 441.844
  iterations_since_restore: 223
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 9923.953160762787
  time_this_iter_s: 44.94740152359009
  time_total_s: 9923.953160762787
  timestamp: 1594162105
  timesteps_since_restore: 6690000
  timesteps_this_iter: 30000
  timesteps_total: 6690000
  training_iteration: 223
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 48.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 9923 s, 223 iter, 6690000 ts, 1.28e+03 rew

agent-1: 35.0
agent-2: 55.0
agent-3: 23.0
agent-4: 70.0
agent-5: 51.0
agent-6: 29.0
agent-7: 55.0
agent-8: 55.0
agent-9: 24.0
agent-10: 21.0
agent-11: 69.0
agent-12: 35.0
agent-13: 35.0
agent-14: 30.0
agent-15: 54.0
agent-16: 33.0
agent-17: 59.0
agent-18: 42.0
agent-19: 36.0
agent-20: 57.0
agent-21: 37.0
agent-22: 11.0
agent-23: 38.0
agent-24: 42.0
agent-25: 41.0
agent-26: 20.0
agent-27: 25.0
agent-28: 44.0
agent-29: 49.0
agent-30: 75.0
Sum Reward: 1250.0
Avg Reward: 41.666666666666664
Min Reward: 11.0
Max Reward: 75.0
Gini Coefficient: 0.21333333333333335
20:20 Ratio: 3.1048387096774195
Max-min Ratio: 6.818181818181818
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-49-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1282.27
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 223
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.759
    dispatch_time_ms: 6.545
    learner:
      cur_lr: 0.0009144460200332105
      grad_gnorm: 39.999996185302734
      policy_entropy: 120.7606430053711
      policy_loss: 5.231056213378906
      var_gnorm: 23.332002639770508
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 180.09066772460938
    num_steps_sampled: 6720000
    num_steps_trained: 6720000
    wait_time_ms: 417.597
  iterations_since_restore: 224
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 9967.146509885788
  time_this_iter_s: 43.1933491230011
  time_total_s: 9967.146509885788
  timestamp: 1594162148
  timesteps_since_restore: 6720000
  timesteps_this_iter: 30000
  timesteps_total: 6720000
  training_iteration: 224
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 56.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 9967 s, 224 iter, 6720000 ts, 1.28e+03 rew

agent-1: 58.0
agent-2: 72.0
agent-3: 56.0
agent-4: 60.0
agent-5: 5.0
agent-6: 26.0
agent-7: 42.0
agent-8: 20.0
agent-9: 37.0
agent-10: 21.0
agent-11: 19.0
agent-12: 45.0
agent-13: 24.0
agent-14: 35.0
agent-15: 43.0
agent-16: 31.0
agent-17: 42.0
agent-18: 50.0
agent-19: 30.0
agent-20: 42.0
agent-21: 41.0
agent-22: 34.0
agent-23: 24.0
agent-24: 26.0
agent-25: 34.0
agent-26: 21.0
agent-27: 44.0
agent-28: 48.0
agent-29: 64.0
agent-30: 31.0
Sum Reward: 1125.0
Avg Reward: 37.5
Min Reward: 5.0
Max Reward: 72.0
Gini Coefficient: 0.22361481481481482
20:20 Ratio: 3.272727272727273
Max-min Ratio: 14.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-49-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1280.48
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 224
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.781
    dispatch_time_ms: 6.538
    learner:
      cur_lr: 0.0009124479838646948
      grad_gnorm: 40.000003814697266
      policy_entropy: 172.41705322265625
      policy_loss: 7.013283729553223
      var_gnorm: 23.332630157470703
      vf_explained_var: 0.0
      vf_loss: 50.844879150390625
    num_steps_sampled: 6750000
    num_steps_trained: 6750000
    wait_time_ms: 417.852
  iterations_since_restore: 225
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 10010.816996574402
  time_this_iter_s: 43.67048668861389
  time_total_s: 10010.816996574402
  timestamp: 1594162192
  timesteps_since_restore: 6750000
  timesteps_this_iter: 30000
  timesteps_total: 6750000
  training_iteration: 225
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 56.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 10010 s, 225 iter, 6750000 ts, 1.28e+03 rew

agent-1: 23.0
agent-2: 110.0
agent-3: 50.0
agent-4: 36.0
agent-5: 112.0
agent-6: 54.0
agent-7: 28.0
agent-8: 61.0
agent-9: 57.0
agent-10: 44.0
agent-11: 30.0
agent-12: 18.0
agent-13: 59.0
agent-14: 22.0
agent-15: 82.0
agent-16: 37.0
agent-17: 42.0
agent-18: 17.0
agent-19: 66.0
agent-20: 41.0
agent-21: 20.0
agent-22: 58.0
agent-23: 30.0
agent-24: 51.0
agent-25: 49.0
agent-26: 87.0
agent-27: 59.0
agent-28: 52.0
agent-29: 19.0
agent-30: 62.0
Sum Reward: 1476.0
Avg Reward: 49.2
Min Reward: 17.0
Max Reward: 112.0
Gini Coefficient: 0.2707317073170732
20:20 Ratio: 4.361344537815126
Max-min Ratio: 6.588235294117647
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-50-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1283.28
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 225
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 4.297
    dispatch_time_ms: 6.474
    learner:
      cur_lr: 0.0009104500059038401
      grad_gnorm: 40.000003814697266
      policy_entropy: 178.206298828125
      policy_loss: -24.86182975769043
      var_gnorm: 23.332075119018555
      vf_explained_var: 0.0
      vf_loss: 59.23542785644531
    num_steps_sampled: 6780000
    num_steps_trained: 6780000
    wait_time_ms: 456.027
  iterations_since_restore: 226
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 10054.873171329498
  time_this_iter_s: 44.056174755096436
  time_total_s: 10054.873171329498
  timestamp: 1594162236
  timesteps_since_restore: 6780000
  timesteps_this_iter: 30000
  timesteps_total: 6780000
  training_iteration: 226
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 53.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 10054 s, 226 iter, 6780000 ts, 1.28e+03 rew

agent-1: 29.0
agent-2: 58.0
agent-3: 40.0
agent-4: 41.0
agent-5: 55.0
agent-6: 26.0
agent-7: 26.0
agent-8: 62.0
agent-9: 49.0
agent-10: 19.0
agent-11: 30.0
agent-12: 36.0
agent-13: 26.0
agent-14: 49.0
agent-15: 38.0
agent-16: 46.0
agent-17: 33.0
agent-18: 41.0
agent-19: 4.0
agent-20: 29.0
agent-21: 37.0
agent-22: 43.0
agent-23: 32.0
agent-24: 39.0
agent-25: 40.0
agent-26: 29.0
agent-27: 56.0
agent-28: 33.0
agent-29: 33.0
agent-30: 48.0
Sum Reward: 1127.0
Avg Reward: 37.56666666666667
Min Reward: 4.0
Max Reward: 62.0
Gini Coefficient: 0.1782608695652174
20:20 Ratio: 2.5307692307692307
Max-min Ratio: 15.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-51-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1280.22
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 226
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.296
    dispatch_time_ms: 6.915
    learner:
      cur_lr: 0.0009084520279429853
      grad_gnorm: 40.0
      policy_entropy: 139.37307739257812
      policy_loss: 28.466562271118164
      var_gnorm: 23.327457427978516
      vf_explained_var: 0.0
      vf_loss: 138.7567138671875
    num_steps_sampled: 6810000
    num_steps_trained: 6810000
    wait_time_ms: 408.116
  iterations_since_restore: 227
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 10098.951185464859
  time_this_iter_s: 44.07801413536072
  time_total_s: 10098.951185464859
  timestamp: 1594162280
  timesteps_since_restore: 6810000
  timesteps_this_iter: 30000
  timesteps_total: 6810000
  training_iteration: 227
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 53.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 10098 s, 227 iter, 6810000 ts, 1.28e+03 rew

agent-1: 54.0
agent-2: 44.0
agent-3: 43.0
agent-4: 50.0
agent-5: 68.0
agent-6: 27.0
agent-7: 28.0
agent-8: 42.0
agent-9: 40.0
agent-10: 37.0
agent-11: 27.0
agent-12: 46.0
agent-13: 22.0
agent-14: 20.0
agent-15: 36.0
agent-16: 36.0
agent-17: 25.0
agent-18: 40.0
agent-19: 58.0
agent-20: 59.0
agent-21: 33.0
agent-22: 34.0
agent-23: 43.0
agent-24: 41.0
agent-25: 21.0
agent-26: 16.0
agent-27: 31.0
agent-28: 15.0
agent-29: 51.0
agent-30: 47.0
Sum Reward: 1134.0
Avg Reward: 37.8
Min Reward: 15.0
Max Reward: 68.0
Gini Coefficient: 0.19523809523809524
20:20 Ratio: 2.857142857142857
Max-min Ratio: 4.533333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-52-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1278.32
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 227
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.234
    dispatch_time_ms: 5.135
    learner:
      cur_lr: 0.0009064539917744696
      grad_gnorm: 40.000003814697266
      policy_entropy: 132.79689025878906
      policy_loss: -13.596904754638672
      var_gnorm: 23.332956314086914
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 21.74297523498535
    num_steps_sampled: 6840000
    num_steps_trained: 6840000
    wait_time_ms: 443.685
  iterations_since_restore: 228
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 10142.91004729271
  time_this_iter_s: 43.95886182785034
  time_total_s: 10142.91004729271
  timestamp: 1594162324
  timesteps_since_restore: 6840000
  timesteps_this_iter: 30000
  timesteps_total: 6840000
  training_iteration: 228
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 53.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 10142 s, 228 iter, 6840000 ts, 1.28e+03 rew

agent-1: 47.0
agent-2: 48.0
agent-3: 26.0
agent-4: 43.0
agent-5: 36.0
agent-6: 34.0
agent-7: 42.0
agent-8: 58.0
agent-9: 35.0
agent-10: 38.0
agent-11: 17.0
agent-12: 42.0
agent-13: 52.0
agent-14: 51.0
agent-15: 18.0
agent-16: 53.0
agent-17: 43.0
agent-18: 61.0
agent-19: 73.0
agent-20: 19.0
agent-21: 50.0
agent-22: 47.0
agent-23: 57.0
agent-24: 63.0
agent-25: 21.0
agent-26: 28.0
agent-27: 33.0
agent-28: 47.0
agent-29: 51.0
agent-30: 55.0
Sum Reward: 1288.0
Avg Reward: 42.93333333333333
Min Reward: 17.0
Max Reward: 73.0
Gini Coefficient: 0.18317805383022776
20:20 Ratio: 2.8449612403100777
Max-min Ratio: 4.294117647058823
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-52-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1278.19
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 228
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.608
    dispatch_time_ms: 6.701
    learner:
      cur_lr: 0.0009044560138136148
      grad_gnorm: 40.0
      policy_entropy: 123.7681655883789
      policy_loss: -15.18472957611084
      var_gnorm: 23.330360412597656
      vf_explained_var: 0.0
      vf_loss: 20.55933380126953
    num_steps_sampled: 6870000
    num_steps_trained: 6870000
    wait_time_ms: 439.979
  iterations_since_restore: 229
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 10187.287202835083
  time_this_iter_s: 44.37715554237366
  time_total_s: 10187.287202835083
  timestamp: 1594162368
  timesteps_since_restore: 6870000
  timesteps_this_iter: 30000
  timesteps_total: 6870000
  training_iteration: 229
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 53.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 10187 s, 229 iter, 6870000 ts, 1.28e+03 rew

agent-1: 50.0
agent-2: 36.0
agent-3: 30.0
agent-4: 37.0
agent-5: 33.0
agent-6: 46.0
agent-7: 31.0
agent-8: 32.0
agent-9: 46.0
agent-10: 37.0
agent-11: 26.0
agent-12: 38.0
agent-13: 31.0
agent-14: 60.0
agent-15: 38.0
agent-16: 38.0
agent-17: 37.0
agent-18: 29.0
agent-19: 60.0
agent-20: 41.0
agent-21: 22.0
agent-22: 61.0
agent-23: 39.0
agent-24: 64.0
agent-25: 52.0
agent-26: 49.0
agent-27: 39.0
agent-28: 31.0
agent-29: 13.0
agent-30: 54.0
Sum Reward: 1200.0
Avg Reward: 40.0
Min Reward: 13.0
Max Reward: 64.0
Gini Coefficient: 0.16633333333333333
20:20 Ratio: 2.3245033112582782
Max-min Ratio: 4.923076923076923
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-53-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1276.49
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 229
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.285
    dispatch_time_ms: 7.593
    learner:
      cur_lr: 0.0009024579776450992
      grad_gnorm: 21.857816696166992
      policy_entropy: 131.1343536376953
      policy_loss: -0.17757540941238403
      var_gnorm: 23.335044860839844
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 57.49252700805664
    num_steps_sampled: 6900000
    num_steps_trained: 6900000
    wait_time_ms: 455.66
  iterations_since_restore: 230
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 10230.856402397156
  time_this_iter_s: 43.569199562072754
  time_total_s: 10230.856402397156
  timestamp: 1594162412
  timesteps_since_restore: 6900000
  timesteps_this_iter: 30000
  timesteps_total: 6900000
  training_iteration: 230
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 53.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 10230 s, 230 iter, 6900000 ts, 1.28e+03 rew

agent-1: 15.0
agent-2: 30.0
agent-3: 51.0
agent-4: 44.0
agent-5: 62.0
agent-6: 36.0
agent-7: 29.0
agent-8: 61.0
agent-9: 38.0
agent-10: 37.0
agent-11: 27.0
agent-12: 55.0
agent-13: 55.0
agent-14: 74.0
agent-15: 32.0
agent-16: 66.0
agent-17: 38.0
agent-18: 23.0
agent-19: 25.0
agent-20: 45.0
agent-21: 57.0
agent-22: 17.0
agent-23: 54.0
agent-24: 44.0
agent-25: 44.0
agent-26: 44.0
agent-27: 43.0
agent-28: 30.0
agent-29: 27.0
agent-30: 33.0
Sum Reward: 1236.0
Avg Reward: 41.2
Min Reward: 15.0
Max Reward: 74.0
Gini Coefficient: 0.20037756202804746
20:20 Ratio: 2.798507462686567
Max-min Ratio: 4.933333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-54-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1274.45
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 230
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.605
    dispatch_time_ms: 5.855
    learner:
      cur_lr: 0.0009004599996842444
      grad_gnorm: 39.999996185302734
      policy_entropy: 111.06025695800781
      policy_loss: 20.349105834960938
      var_gnorm: 23.332319259643555
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 73.0799331665039
    num_steps_sampled: 6930000
    num_steps_trained: 6930000
    wait_time_ms: 404.209
  iterations_since_restore: 231
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 10274.648920059204
  time_this_iter_s: 43.79251766204834
  time_total_s: 10274.648920059204
  timestamp: 1594162456
  timesteps_since_restore: 6930000
  timesteps_this_iter: 30000
  timesteps_total: 6930000
  training_iteration: 231
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 53.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 10274 s, 231 iter, 6930000 ts, 1.27e+03 rew

agent-1: 41.0
agent-2: 32.0
agent-3: 67.0
agent-4: 60.0
agent-5: 55.0
agent-6: 67.0
agent-7: 31.0
agent-8: 25.0
agent-9: 33.0
agent-10: 55.0
agent-11: 54.0
agent-12: 54.0
agent-13: 43.0
agent-14: 38.0
agent-15: 46.0
agent-16: 32.0
agent-17: 71.0
agent-18: 83.0
agent-19: 42.0
agent-20: 68.0
agent-21: 32.0
agent-22: 51.0
agent-23: 52.0
agent-24: 43.0
agent-25: 40.0
agent-26: 65.0
agent-27: 28.0
agent-28: 48.0
agent-29: 56.0
agent-30: 68.0
Sum Reward: 1480.0
Avg Reward: 49.333333333333336
Min Reward: 25.0
Max Reward: 83.0
Gini Coefficient: 0.16896396396396396
20:20 Ratio: 2.3555555555555556
Max-min Ratio: 3.32
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-54-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1276.64
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 231
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.749
    dispatch_time_ms: 6.503
    learner:
      cur_lr: 0.0008984620217233896
      grad_gnorm: 22.956239700317383
      policy_entropy: 150.53553771972656
      policy_loss: -8.317865371704102
      var_gnorm: 23.33907699584961
      vf_explained_var: 0.0
      vf_loss: 77.01679992675781
    num_steps_sampled: 6960000
    num_steps_trained: 6960000
    wait_time_ms: 421.642
  iterations_since_restore: 232
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 10318.288358926773
  time_this_iter_s: 43.63943886756897
  time_total_s: 10318.288358926773
  timestamp: 1594162499
  timesteps_since_restore: 6960000
  timesteps_this_iter: 30000
  timesteps_total: 6960000
  training_iteration: 232
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 53.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 10318 s, 232 iter, 6960000 ts, 1.28e+03 rew

agent-1: 37.0
agent-2: 33.0
agent-3: 81.0
agent-4: 28.0
agent-5: 46.0
agent-6: 27.0
agent-7: 42.0
agent-8: 28.0
agent-9: 56.0
agent-10: 56.0
agent-11: 14.0
agent-12: 35.0
agent-13: 53.0
agent-14: 42.0
agent-15: 26.0
agent-16: 27.0
agent-17: 34.0
agent-18: 23.0
agent-19: 28.0
agent-20: 65.0
agent-21: 44.0
agent-22: 66.0
agent-23: 41.0
agent-24: 29.0
agent-25: 24.0
agent-26: 34.0
agent-27: 38.0
agent-28: 36.0
agent-29: 44.0
agent-30: 37.0
Sum Reward: 1174.0
Avg Reward: 39.13333333333333
Min Reward: 14.0
Max Reward: 81.0
Gini Coefficient: 0.19806927881885292
20:20 Ratio: 2.673758865248227
Max-min Ratio: 5.785714285714286
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-55-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1274.57
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 232
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.555
    dispatch_time_ms: 6.48
    learner:
      cur_lr: 0.0008964639855548739
      grad_gnorm: 39.999996185302734
      policy_entropy: 147.61216735839844
      policy_loss: 6.024539947509766
      var_gnorm: 23.33135414123535
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 57.55232620239258
    num_steps_sampled: 6990000
    num_steps_trained: 6990000
    wait_time_ms: 402.042
  iterations_since_restore: 233
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 10362.36808013916
  time_this_iter_s: 44.079721212387085
  time_total_s: 10362.36808013916
  timestamp: 1594162543
  timesteps_since_restore: 6990000
  timesteps_this_iter: 30000
  timesteps_total: 6990000
  training_iteration: 233
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 53.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 10362 s, 233 iter, 6990000 ts, 1.27e+03 rew

agent-1: 54.0
agent-2: 17.0
agent-3: 52.0
agent-4: 36.0
agent-5: 42.0
agent-6: 48.0
agent-7: 62.0
agent-8: 48.0
agent-9: 38.0
agent-10: 30.0
agent-11: 34.0
agent-12: 36.0
agent-13: 37.0
agent-14: 39.0
agent-15: 27.0
agent-16: 33.0
agent-17: 39.0
agent-18: 63.0
agent-19: 32.0
agent-20: 57.0
agent-21: 44.0
agent-22: 56.0
agent-23: 42.0
agent-24: 35.0
agent-25: 20.0
agent-26: 62.0
agent-27: 46.0
agent-28: 65.0
agent-29: 59.0
agent-30: 57.0
Sum Reward: 1310.0
Avg Reward: 43.666666666666664
Min Reward: 17.0
Max Reward: 65.0
Gini Coefficient: 0.16595419847328244
20:20 Ratio: 2.3144654088050314
Max-min Ratio: 3.823529411764706
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-56-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1272.09
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 233
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.826
    dispatch_time_ms: 6.193
    learner:
      cur_lr: 0.0008944660075940192
      grad_gnorm: 39.999996185302734
      policy_entropy: 206.56924438476562
      policy_loss: 11.259354591369629
      var_gnorm: 23.3393497467041
      vf_explained_var: 0.0
      vf_loss: 42.367958068847656
    num_steps_sampled: 7020000
    num_steps_trained: 7020000
    wait_time_ms: 426.107
  iterations_since_restore: 234
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 10405.584754228592
  time_this_iter_s: 43.21667408943176
  time_total_s: 10405.584754228592
  timestamp: 1594162587
  timesteps_since_restore: 7020000
  timesteps_this_iter: 30000
  timesteps_total: 7020000
  training_iteration: 234
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 10405 s, 234 iter, 7020000 ts, 1.27e+03 rew

agent-1: 60.0
agent-2: 46.0
agent-3: 50.0
agent-4: 65.0
agent-5: 48.0
agent-6: 61.0
agent-7: 51.0
agent-8: 46.0
agent-9: 32.0
agent-10: 44.0
agent-11: 31.0
agent-12: 57.0
agent-13: 13.0
agent-14: 70.0
agent-15: 37.0
agent-16: 42.0
agent-17: 51.0
agent-18: 47.0
agent-19: 31.0
agent-20: 33.0
agent-21: 38.0
agent-22: 52.0
agent-23: 37.0
agent-24: 50.0
agent-25: 52.0
agent-26: 25.0
agent-27: 68.0
agent-28: 61.0
agent-29: 60.0
agent-30: 56.0
Sum Reward: 1414.0
Avg Reward: 47.13333333333333
Min Reward: 13.0
Max Reward: 70.0
Gini Coefficient: 0.15685997171145685
20:20 Ratio: 2.3333333333333335
Max-min Ratio: 5.384615384615385
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-57-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1273.94
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 234
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.751
    dispatch_time_ms: 7.562
    learner:
      cur_lr: 0.0008924679714255035
      grad_gnorm: 39.999996185302734
      policy_entropy: 250.68869018554688
      policy_loss: -11.296453475952148
      var_gnorm: 23.331504821777344
      vf_explained_var: 0.0
      vf_loss: 16.533967971801758
    num_steps_sampled: 7050000
    num_steps_trained: 7050000
    wait_time_ms: 417.091
  iterations_since_restore: 235
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 10450.140484809875
  time_this_iter_s: 44.55573058128357
  time_total_s: 10450.140484809875
  timestamp: 1594162631
  timesteps_since_restore: 7050000
  timesteps_this_iter: 30000
  timesteps_total: 7050000
  training_iteration: 235
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 10450 s, 235 iter, 7050000 ts, 1.27e+03 rew

agent-1: 53.0
agent-2: 21.0
agent-3: 34.0
agent-4: 22.0
agent-5: 40.0
agent-6: 23.0
agent-7: 48.0
agent-8: 29.0
agent-9: 36.0
agent-10: 54.0
agent-11: 38.0
agent-12: 41.0
agent-13: 36.0
agent-14: 29.0
agent-15: 36.0
agent-16: 31.0
agent-17: 51.0
agent-18: 41.0
agent-19: 40.0
agent-20: 54.0
agent-21: 48.0
agent-22: 23.0
agent-23: 56.0
agent-24: 45.0
agent-25: 49.0
agent-26: 48.0
agent-27: 50.0
agent-28: 40.0
agent-29: 35.0
agent-30: 40.0
Sum Reward: 1191.0
Avg Reward: 39.7
Min Reward: 21.0
Max Reward: 56.0
Gini Coefficient: 0.14422054296109713
20:20 Ratio: 2.163265306122449
Max-min Ratio: 2.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-57-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1271.75
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 235
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.738
    dispatch_time_ms: 5.976
    learner:
      cur_lr: 0.0008904699934646487
      grad_gnorm: 19.93771743774414
      policy_entropy: 252.4132080078125
      policy_loss: -6.930291175842285
      var_gnorm: 23.334989547729492
      vf_explained_var: 0.0
      vf_loss: 26.94309425354004
    num_steps_sampled: 7080000
    num_steps_trained: 7080000
    wait_time_ms: 428.281
  iterations_since_restore: 236
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 10494.134266138077
  time_this_iter_s: 43.993781328201294
  time_total_s: 10494.134266138077
  timestamp: 1594162675
  timesteps_since_restore: 7080000
  timesteps_this_iter: 30000
  timesteps_total: 7080000
  training_iteration: 236
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 10494 s, 236 iter, 7080000 ts, 1.27e+03 rew

agent-1: 18.0
agent-2: 18.0
agent-3: 37.0
agent-4: 34.0
agent-5: 33.0
agent-6: 32.0
agent-7: 21.0
agent-8: 11.0
agent-9: 13.0
agent-10: 39.0
agent-11: 51.0
agent-12: 33.0
agent-13: 36.0
agent-14: 33.0
agent-15: 37.0
agent-16: 42.0
agent-17: 29.0
agent-18: 29.0
agent-19: 9.0
agent-20: 35.0
agent-21: 39.0
agent-22: 38.0
agent-23: 38.0
agent-24: 33.0
agent-25: 42.0
agent-26: 34.0
agent-27: 50.0
agent-28: 37.0
agent-29: 12.0
agent-30: 52.0
Sum Reward: 965.0
Avg Reward: 32.166666666666664
Min Reward: 9.0
Max Reward: 52.0
Gini Coefficient: 0.1915371329879102
20:20 Ratio: 3.4074074074074074
Max-min Ratio: 5.777777777777778
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-58-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1268.93
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 236
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.055
    dispatch_time_ms: 5.349
    learner:
      cur_lr: 0.000888472015503794
      grad_gnorm: 40.000003814697266
      policy_entropy: 247.63856506347656
      policy_loss: 131.8020477294922
      var_gnorm: 23.329879760742188
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 207.5730743408203
    num_steps_sampled: 7110000
    num_steps_trained: 7110000
    wait_time_ms: 403.675
  iterations_since_restore: 237
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 10538.914190769196
  time_this_iter_s: 44.779924631118774
  time_total_s: 10538.914190769196
  timestamp: 1594162720
  timesteps_since_restore: 7110000
  timesteps_this_iter: 30000
  timesteps_total: 7110000
  training_iteration: 237
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 10538 s, 237 iter, 7110000 ts, 1.27e+03 rew

agent-1: 10.0
agent-2: 27.0
agent-3: 24.0
agent-4: 17.0
agent-5: 20.0
agent-6: 36.0
agent-7: 35.0
agent-8: 62.0
agent-9: 51.0
agent-10: 32.0
agent-11: 26.0
agent-12: 60.0
agent-13: 35.0
agent-14: 30.0
agent-15: 52.0
agent-16: 40.0
agent-17: 23.0
agent-18: 66.0
agent-19: 52.0
agent-20: 57.0
agent-21: 75.0
agent-22: 39.0
agent-23: 17.0
agent-24: 19.0
agent-25: 56.0
agent-26: 41.0
agent-27: 33.0
agent-28: 56.0
agent-29: 26.0
agent-30: 27.0
Sum Reward: 1144.0
Avg Reward: 38.13333333333333
Min Reward: 10.0
Max Reward: 75.0
Gini Coefficient: 0.2463869463869464
20:20 Ratio: 3.547169811320755
Max-min Ratio: 7.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_18-59-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1269.3
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 237
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.885
    dispatch_time_ms: 5.69
    learner:
      cur_lr: 0.0008864739793352783
      grad_gnorm: 40.0
      policy_entropy: 259.14056396484375
      policy_loss: -26.7418155670166
      var_gnorm: 23.333335876464844
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 13.7765531539917
    num_steps_sampled: 7140000
    num_steps_trained: 7140000
    wait_time_ms: 451.483
  iterations_since_restore: 238
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 10583.065036296844
  time_this_iter_s: 44.150845527648926
  time_total_s: 10583.065036296844
  timestamp: 1594162764
  timesteps_since_restore: 7140000
  timesteps_this_iter: 30000
  timesteps_total: 7140000
  training_iteration: 238
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 10583 s, 238 iter, 7140000 ts, 1.27e+03 rew

agent-1: 36.0
agent-2: 42.0
agent-3: 11.0
agent-4: 23.0
agent-5: 55.0
agent-6: 27.0
agent-7: 50.0
agent-8: 45.0
agent-9: 25.0
agent-10: 36.0
agent-11: 14.0
agent-12: 46.0
agent-13: 23.0
agent-14: 19.0
agent-15: 42.0
agent-16: 49.0
agent-17: 23.0
agent-18: 51.0
agent-19: 34.0
agent-20: 41.0
agent-21: 19.0
agent-22: 30.0
agent-23: 33.0
agent-24: 38.0
agent-25: 24.0
agent-26: 23.0
agent-27: 28.0
agent-28: 43.0
agent-29: 18.0
agent-30: 35.0
Sum Reward: 983.0
Avg Reward: 32.766666666666666
Min Reward: 11.0
Max Reward: 55.0
Gini Coefficient: 0.20498474059003052
20:20 Ratio: 2.8461538461538463
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-00-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1264.18
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 238
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.427
    dispatch_time_ms: 7.027
    learner:
      cur_lr: 0.0008844760013744235
      grad_gnorm: 24.941682815551758
      policy_entropy: 230.16648864746094
      policy_loss: -6.799559116363525
      var_gnorm: 23.335350036621094
      vf_explained_var: -3.5762786865234375e-07
      vf_loss: 1.561668872833252
    num_steps_sampled: 7170000
    num_steps_trained: 7170000
    wait_time_ms: 414.484
  iterations_since_restore: 239
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 10628.412693738937
  time_this_iter_s: 45.347657442092896
  time_total_s: 10628.412693738937
  timestamp: 1594162810
  timesteps_since_restore: 7170000
  timesteps_this_iter: 30000
  timesteps_total: 7170000
  training_iteration: 239
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 10628 s, 239 iter, 7170000 ts, 1.26e+03 rew

agent-1: 23.0
agent-2: 27.0
agent-3: 26.0
agent-4: 41.0
agent-5: 22.0
agent-6: 31.0
agent-7: 19.0
agent-8: 43.0
agent-9: 27.0
agent-10: 9.0
agent-11: 34.0
agent-12: 27.0
agent-13: 40.0
agent-14: 21.0
agent-15: 20.0
agent-16: 12.0
agent-17: 31.0
agent-18: 50.0
agent-19: 47.0
agent-20: 33.0
agent-21: 24.0
agent-22: 17.0
agent-23: 28.0
agent-24: 29.0
agent-25: 11.0
agent-26: 50.0
agent-27: 49.0
agent-28: 46.0
agent-29: 28.0
agent-30: 19.0
Sum Reward: 884.0
Avg Reward: 29.466666666666665
Min Reward: 9.0
Max Reward: 50.0
Gini Coefficient: 0.222473604826546
20:20 Ratio: 3.2758620689655173
Max-min Ratio: 5.555555555555555
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-00-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1259.05
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 239
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.467
    dispatch_time_ms: 5.648
    learner:
      cur_lr: 0.0008824780234135687
      grad_gnorm: 37.47129440307617
      policy_entropy: 150.1038055419922
      policy_loss: 13.483845710754395
      var_gnorm: 23.342979431152344
      vf_explained_var: 0.0
      vf_loss: 42.55898666381836
    num_steps_sampled: 7200000
    num_steps_trained: 7200000
    wait_time_ms: 443.307
  iterations_since_restore: 240
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 10671.56846690178
  time_this_iter_s: 43.1557731628418
  time_total_s: 10671.56846690178
  timestamp: 1594162853
  timesteps_since_restore: 7200000
  timesteps_this_iter: 30000
  timesteps_total: 7200000
  training_iteration: 240
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 10671 s, 240 iter, 7200000 ts, 1.26e+03 rew

agent-1: 40.0
agent-2: 39.0
agent-3: 44.0
agent-4: 63.0
agent-5: 10.0
agent-6: 49.0
agent-7: 47.0
agent-8: 55.0
agent-9: 46.0
agent-10: 63.0
agent-11: 80.0
agent-12: 41.0
agent-13: 60.0
agent-14: 46.0
agent-15: 20.0
agent-16: 46.0
agent-17: 61.0
agent-18: 59.0
agent-19: 54.0
agent-20: 28.0
agent-21: 53.0
agent-22: 43.0
agent-23: 35.0
agent-24: 48.0
agent-25: 38.0
agent-26: 47.0
agent-27: 60.0
agent-28: 70.0
agent-29: 39.0
agent-30: 53.0
Sum Reward: 1437.0
Avg Reward: 47.9
Min Reward: 10.0
Max Reward: 80.0
Gini Coefficient: 0.1595221526327998
20:20 Ratio: 2.335294117647059
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-01-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1260.96
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 240
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 4.246
    dispatch_time_ms: 6.735
    learner:
      cur_lr: 0.000880479987245053
      grad_gnorm: 40.000003814697266
      policy_entropy: 197.47140502929688
      policy_loss: -27.004596710205078
      var_gnorm: 23.341358184814453
      vf_explained_var: 0.0
      vf_loss: 5.286404609680176
    num_steps_sampled: 7230000
    num_steps_trained: 7230000
    wait_time_ms: 433.349
  iterations_since_restore: 241
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 10715.650792360306
  time_this_iter_s: 44.08232545852661
  time_total_s: 10715.650792360306
  timestamp: 1594162897
  timesteps_since_restore: 7230000
  timesteps_this_iter: 30000
  timesteps_total: 7230000
  training_iteration: 241
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 10715 s, 241 iter, 7230000 ts, 1.26e+03 rew

agent-1: 20.0
agent-2: 36.0
agent-3: 30.0
agent-4: 40.0
agent-5: 28.0
agent-6: 18.0
agent-7: 62.0
agent-8: 17.0
agent-9: 30.0
agent-10: 49.0
agent-11: 34.0
agent-12: 59.0
agent-13: 70.0
agent-14: 30.0
agent-15: 38.0
agent-16: 57.0
agent-17: 68.0
agent-18: 37.0
agent-19: 29.0
agent-20: 51.0
agent-21: 59.0
agent-22: 41.0
agent-23: 47.0
agent-24: 56.0
agent-25: 68.0
agent-26: 42.0
agent-27: 24.0
agent-28: 46.0
agent-29: 55.0
agent-30: 36.0
Sum Reward: 1277.0
Avg Reward: 42.56666666666667
Min Reward: 17.0
Max Reward: 70.0
Gini Coefficient: 0.203471678412947
20:20 Ratio: 2.838235294117647
Max-min Ratio: 4.117647058823529
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-02-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1261.46
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 241
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.637
    dispatch_time_ms: 24.627
    learner:
      cur_lr: 0.0008784820092841983
      grad_gnorm: 40.0
      policy_entropy: 211.6166534423828
      policy_loss: -19.226947784423828
      var_gnorm: 23.345232009887695
      vf_explained_var: 0.0
      vf_loss: 24.619014739990234
    num_steps_sampled: 7260000
    num_steps_trained: 7260000
    wait_time_ms: 435.577
  iterations_since_restore: 242
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 10759.005784273148
  time_this_iter_s: 43.3549919128418
  time_total_s: 10759.005784273148
  timestamp: 1594162940
  timesteps_since_restore: 7260000
  timesteps_this_iter: 30000
  timesteps_total: 7260000
  training_iteration: 242
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 10759 s, 242 iter, 7260000 ts, 1.26e+03 rew

agent-1: 58.0
agent-2: 35.0
agent-3: 23.0
agent-4: 26.0
agent-5: 52.0
agent-6: 19.0
agent-7: 42.0
agent-8: 35.0
agent-9: 45.0
agent-10: 42.0
agent-11: 27.0
agent-12: 38.0
agent-13: 13.0
agent-14: 35.0
agent-15: 36.0
agent-16: 43.0
agent-17: 66.0
agent-18: 37.0
agent-19: 38.0
agent-20: 27.0
agent-21: 38.0
agent-22: 42.0
agent-23: 27.0
agent-24: 31.0
agent-25: 56.0
agent-26: 28.0
agent-27: 68.0
agent-28: 38.0
agent-29: 42.0
agent-30: 33.0
Sum Reward: 1140.0
Avg Reward: 38.0
Min Reward: 13.0
Max Reward: 68.0
Gini Coefficient: 0.17912280701754385
20:20 Ratio: 2.5555555555555554
Max-min Ratio: 5.230769230769231
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-03-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1260.29
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 242
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.569
    dispatch_time_ms: 16.705
    learner:
      cur_lr: 0.0008764839731156826
      grad_gnorm: 40.00000762939453
      policy_entropy: 129.5679931640625
      policy_loss: 68.13776397705078
      var_gnorm: 23.337890625
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 121.20552825927734
    num_steps_sampled: 7290000
    num_steps_trained: 7290000
    wait_time_ms: 376.541
  iterations_since_restore: 243
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 10805.951121807098
  time_this_iter_s: 46.945337533950806
  time_total_s: 10805.951121807098
  timestamp: 1594162987
  timesteps_since_restore: 7290000
  timesteps_this_iter: 30000
  timesteps_total: 7290000
  training_iteration: 243
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 10805 s, 243 iter, 7290000 ts, 1.26e+03 rew

agent-1: 28.0
agent-2: 46.0
agent-3: 34.0
agent-4: 63.0
agent-5: 14.0
agent-6: 50.0
agent-7: 52.0
agent-8: 45.0
agent-9: 52.0
agent-10: 24.0
agent-11: 26.0
agent-12: 28.0
agent-13: 33.0
agent-14: 34.0
agent-15: 39.0
agent-16: 39.0
agent-17: 48.0
agent-18: 61.0
agent-19: 56.0
agent-20: 33.0
agent-21: 28.0
agent-22: 35.0
agent-23: 44.0
agent-24: 30.0
agent-25: 27.0
agent-26: 27.0
agent-27: 53.0
agent-28: 30.0
agent-29: 47.0
agent-30: 32.0
Sum Reward: 1158.0
Avg Reward: 38.6
Min Reward: 14.0
Max Reward: 63.0
Gini Coefficient: 0.17443868739205526
20:20 Ratio: 2.308219178082192
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-03-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1260.27
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 243
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.288
    dispatch_time_ms: 34.737
    learner:
      cur_lr: 0.0008744859951548278
      grad_gnorm: 40.0
      policy_entropy: 110.61407470703125
      policy_loss: 8.249939918518066
      var_gnorm: 23.34722900390625
      vf_explained_var: 0.0
      vf_loss: 55.940940856933594
    num_steps_sampled: 7320000
    num_steps_trained: 7320000
    wait_time_ms: 414.502
  iterations_since_restore: 244
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 10850.450284957886
  time_this_iter_s: 44.49916315078735
  time_total_s: 10850.450284957886
  timestamp: 1594163032
  timesteps_since_restore: 7320000
  timesteps_this_iter: 30000
  timesteps_total: 7320000
  training_iteration: 244
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 10850 s, 244 iter, 7320000 ts, 1.26e+03 rew

agent-1: 42.0
agent-2: 54.0
agent-3: 71.0
agent-4: 63.0
agent-5: 46.0
agent-6: 31.0
agent-7: 41.0
agent-8: 56.0
agent-9: 30.0
agent-10: 54.0
agent-11: 50.0
agent-12: 39.0
agent-13: 59.0
agent-14: 20.0
agent-15: 35.0
agent-16: 46.0
agent-17: 39.0
agent-18: 59.0
agent-19: 84.0
agent-20: 65.0
agent-21: 45.0
agent-22: 34.0
agent-23: 45.0
agent-24: 51.0
agent-25: 39.0
agent-26: 20.0
agent-27: 26.0
agent-28: 29.0
agent-29: 17.0
agent-30: 34.0
Sum Reward: 1324.0
Avg Reward: 44.13333333333333
Min Reward: 17.0
Max Reward: 84.0
Gini Coefficient: 0.1972809667673716
20:20 Ratio: 2.823943661971831
Max-min Ratio: 4.9411764705882355
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-04-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1259.21
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 244
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.794
    dispatch_time_ms: 6.914
    learner:
      cur_lr: 0.0008724880171939731
      grad_gnorm: 40.0
      policy_entropy: 150.8800506591797
      policy_loss: 11.324087142944336
      var_gnorm: 23.34110450744629
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 75.24932098388672
    num_steps_sampled: 7350000
    num_steps_trained: 7350000
    wait_time_ms: 436.686
  iterations_since_restore: 245
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 10895.376286506653
  time_this_iter_s: 44.92600154876709
  time_total_s: 10895.376286506653
  timestamp: 1594163077
  timesteps_since_restore: 7350000
  timesteps_this_iter: 30000
  timesteps_total: 7350000
  training_iteration: 245
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 10895 s, 245 iter, 7350000 ts, 1.26e+03 rew

agent-1: 32.0
agent-2: 66.0
agent-3: 42.0
agent-4: 36.0
agent-5: 69.0
agent-6: 53.0
agent-7: 38.0
agent-8: 68.0
agent-9: 39.0
agent-10: 60.0
agent-11: 35.0
agent-12: 53.0
agent-13: 54.0
agent-14: 40.0
agent-15: 54.0
agent-16: 32.0
agent-17: 69.0
agent-18: 15.0
agent-19: 58.0
agent-20: 50.0
agent-21: 52.0
agent-22: 51.0
agent-23: 70.0
agent-24: 67.0
agent-25: 48.0
agent-26: 62.0
agent-27: 68.0
agent-28: 42.0
agent-29: 57.0
agent-30: 31.0
Sum Reward: 1511.0
Avg Reward: 50.36666666666667
Min Reward: 15.0
Max Reward: 70.0
Gini Coefficient: 0.157004191484668
20:20 Ratio: 2.270718232044199
Max-min Ratio: 4.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-05-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1263.82
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 245
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 4.026
    dispatch_time_ms: 5.817
    learner:
      cur_lr: 0.0008704899810254574
      grad_gnorm: 40.0
      policy_entropy: 232.8781280517578
      policy_loss: -9.724746704101562
      var_gnorm: 23.343765258789062
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 73.43069458007812
    num_steps_sampled: 7380000
    num_steps_trained: 7380000
    wait_time_ms: 439.729
  iterations_since_restore: 246
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 10938.432929754257
  time_this_iter_s: 43.05664324760437
  time_total_s: 10938.432929754257
  timestamp: 1594163120
  timesteps_since_restore: 7380000
  timesteps_this_iter: 30000
  timesteps_total: 7380000
  training_iteration: 246
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 10938 s, 246 iter, 7380000 ts, 1.26e+03 rew

agent-1: 36.0
agent-2: 23.0
agent-3: 38.0
agent-4: 26.0
agent-5: 25.0
agent-6: 42.0
agent-7: 28.0
agent-8: 34.0
agent-9: 37.0
agent-10: 37.0
agent-11: 12.0
agent-12: 48.0
agent-13: 48.0
agent-14: 40.0
agent-15: 42.0
agent-16: 61.0
agent-17: 36.0
agent-18: 44.0
agent-19: 53.0
agent-20: 43.0
agent-21: 60.0
agent-22: 30.0
agent-23: 45.0
agent-24: 44.0
agent-25: 49.0
agent-26: 31.0
agent-27: 67.0
agent-28: 34.0
agent-29: 45.0
agent-30: 31.0
Sum Reward: 1189.0
Avg Reward: 39.63333333333333
Min Reward: 12.0
Max Reward: 67.0
Gini Coefficient: 0.16302214746285393
20:20 Ratio: 2.3472222222222223
Max-min Ratio: 5.583333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-06-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1264.52
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 246
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.63
    dispatch_time_ms: 5.615
    learner:
      cur_lr: 0.0008684920030646026
      grad_gnorm: 40.0
      policy_entropy: 209.98062133789062
      policy_loss: -16.686779022216797
      var_gnorm: 23.333833694458008
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 1.075412392616272
    num_steps_sampled: 7410000
    num_steps_trained: 7410000
    wait_time_ms: 426.608
  iterations_since_restore: 247
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 10983.665024995804
  time_this_iter_s: 45.23209524154663
  time_total_s: 10983.665024995804
  timestamp: 1594163165
  timesteps_since_restore: 7410000
  timesteps_this_iter: 30000
  timesteps_total: 7410000
  training_iteration: 247
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 10983 s, 247 iter, 7410000 ts, 1.26e+03 rew

agent-1: 53.0
agent-2: 40.0
agent-3: 39.0
agent-4: 39.0
agent-5: 39.0
agent-6: 36.0
agent-7: 17.0
agent-8: 73.0
agent-9: 35.0
agent-10: 24.0
agent-11: 59.0
agent-12: 34.0
agent-13: 34.0
agent-14: 36.0
agent-15: 34.0
agent-16: 19.0
agent-17: 32.0
agent-18: 48.0
agent-19: 54.0
agent-20: 36.0
agent-21: 45.0
agent-22: 44.0
agent-23: 47.0
agent-24: 26.0
agent-25: 31.0
agent-26: 13.0
agent-27: 18.0
agent-28: 36.0
agent-29: 27.0
agent-30: 51.0
Sum Reward: 1119.0
Avg Reward: 37.3
Min Reward: 13.0
Max Reward: 73.0
Gini Coefficient: 0.19103366100685135
20:20 Ratio: 2.888888888888889
Max-min Ratio: 5.615384615384615
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-06-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1264.78
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 247
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.691
    dispatch_time_ms: 11.446
    learner:
      cur_lr: 0.0008664940251037478
      grad_gnorm: 40.0
      policy_entropy: 209.0610809326172
      policy_loss: -13.947701454162598
      var_gnorm: 23.223228454589844
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 19.84650230407715
    num_steps_sampled: 7440000
    num_steps_trained: 7440000
    wait_time_ms: 431.212
  iterations_since_restore: 248
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 11026.709913492203
  time_this_iter_s: 43.044888496398926
  time_total_s: 11026.709913492203
  timestamp: 1594163208
  timesteps_since_restore: 7440000
  timesteps_this_iter: 30000
  timesteps_total: 7440000
  training_iteration: 248
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 11026 s, 248 iter, 7440000 ts, 1.26e+03 rew

agent-1: 59.0
agent-2: 37.0
agent-3: 21.0
agent-4: 20.0
agent-5: 66.0
agent-6: 32.0
agent-7: 27.0
agent-8: 24.0
agent-9: 44.0
agent-10: 44.0
agent-11: 29.0
agent-12: 25.0
agent-13: 28.0
agent-14: 42.0
agent-15: 24.0
agent-16: 41.0
agent-17: 39.0
agent-18: 49.0
agent-19: 47.0
agent-20: 50.0
agent-21: 39.0
agent-22: 25.0
agent-23: 52.0
agent-24: 53.0
agent-25: 35.0
agent-26: 47.0
agent-27: 42.0
agent-28: 50.0
agent-29: 29.0
agent-30: 36.0
Sum Reward: 1156.0
Avg Reward: 38.53333333333333
Min Reward: 20.0
Max Reward: 66.0
Gini Coefficient: 0.1726066897347174
20:20 Ratio: 2.3741007194244603
Max-min Ratio: 3.3
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-07-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1263.37
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 248
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 4.048
    dispatch_time_ms: 6.743
    learner:
      cur_lr: 0.0008644959889352322
      grad_gnorm: 40.0
      policy_entropy: 251.24461364746094
      policy_loss: -20.738662719726562
      var_gnorm: 23.215652465820312
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 1.361364722251892
    num_steps_sampled: 7470000
    num_steps_trained: 7470000
    wait_time_ms: 451.393
  iterations_since_restore: 249
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 11072.329675674438
  time_this_iter_s: 45.61976218223572
  time_total_s: 11072.329675674438
  timestamp: 1594163254
  timesteps_since_restore: 7470000
  timesteps_this_iter: 30000
  timesteps_total: 7470000
  training_iteration: 249
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 11072 s, 249 iter, 7470000 ts, 1.26e+03 rew

agent-1: 23.0
agent-2: 35.0
agent-3: 42.0
agent-4: 25.0
agent-5: 60.0
agent-6: 50.0
agent-7: 41.0
agent-8: 33.0
agent-9: 67.0
agent-10: 37.0
agent-11: 42.0
agent-12: 34.0
agent-13: 56.0
agent-14: 44.0
agent-15: 44.0
agent-16: 30.0
agent-17: 34.0
agent-18: 35.0
agent-19: 24.0
agent-20: 31.0
agent-21: 35.0
agent-22: 43.0
agent-23: 30.0
agent-24: 49.0
agent-25: 50.0
agent-26: 42.0
agent-27: 33.0
agent-28: 41.0
agent-29: 40.0
agent-30: 38.0
Sum Reward: 1188.0
Avg Reward: 39.6
Min Reward: 23.0
Max Reward: 67.0
Gini Coefficient: 0.13911335578002246
20:20 Ratio: 2.03680981595092
Max-min Ratio: 2.9130434782608696
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-08-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1262.03
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 249
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.99
    dispatch_time_ms: 6.209
    learner:
      cur_lr: 0.0008624980109743774
      grad_gnorm: 40.0
      policy_entropy: 264.315185546875
      policy_loss: -42.229679107666016
      var_gnorm: 23.220293045043945
      vf_explained_var: 0.0
      vf_loss: 5.435309886932373
    num_steps_sampled: 7500000
    num_steps_trained: 7500000
    wait_time_ms: 443.954
  iterations_since_restore: 250
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 11115.468314647675
  time_this_iter_s: 43.138638973236084
  time_total_s: 11115.468314647675
  timestamp: 1594163297
  timesteps_since_restore: 7500000
  timesteps_this_iter: 30000
  timesteps_total: 7500000
  training_iteration: 250
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 11115 s, 250 iter, 7500000 ts, 1.26e+03 rew

agent-1: 40.0
agent-2: 20.0
agent-3: 51.0
agent-4: 49.0
agent-5: 32.0
agent-6: 38.0
agent-7: 17.0
agent-8: 34.0
agent-9: 45.0
agent-10: 27.0
agent-11: 29.0
agent-12: 34.0
agent-13: 35.0
agent-14: 46.0
agent-15: 43.0
agent-16: 26.0
agent-17: 41.0
agent-18: 19.0
agent-19: 29.0
agent-20: 35.0
agent-21: 17.0
agent-22: 36.0
agent-23: 53.0
agent-24: 50.0
agent-25: 50.0
agent-26: 46.0
agent-27: 27.0
agent-28: 47.0
agent-29: 19.0
agent-30: 38.0
Sum Reward: 1073.0
Avg Reward: 35.766666666666666
Min Reward: 17.0
Max Reward: 53.0
Gini Coefficient: 0.17337682510096303
20:20 Ratio: 2.542372881355932
Max-min Ratio: 3.1176470588235294
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-09-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1261.06
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 250
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.17
    dispatch_time_ms: 7.435
    learner:
      cur_lr: 0.0008604999748058617
      grad_gnorm: 21.712308883666992
      policy_entropy: 269.74652099609375
      policy_loss: -7.876237392425537
      var_gnorm: 23.209680557250977
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 0.11481986939907074
    num_steps_sampled: 7530000
    num_steps_trained: 7530000
    wait_time_ms: 440.03
  iterations_since_restore: 251
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 11161.035375118256
  time_this_iter_s: 45.567060470581055
  time_total_s: 11161.035375118256
  timestamp: 1594163343
  timesteps_since_restore: 7530000
  timesteps_this_iter: 30000
  timesteps_total: 7530000
  training_iteration: 251
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 11161 s, 251 iter, 7530000 ts, 1.26e+03 rew

agent-1: 54.0
agent-2: 31.0
agent-3: 31.0
agent-4: 43.0
agent-5: 35.0
agent-6: 32.0
agent-7: 25.0
agent-8: 38.0
agent-9: 24.0
agent-10: 18.0
agent-11: 45.0
agent-12: 23.0
agent-13: 25.0
agent-14: 36.0
agent-15: 20.0
agent-16: 36.0
agent-17: 38.0
agent-18: 19.0
agent-19: 27.0
agent-20: 27.0
agent-21: 14.0
agent-22: 49.0
agent-23: 35.0
agent-24: 54.0
agent-25: 11.0
agent-26: 40.0
agent-27: 41.0
agent-28: 30.0
agent-29: 43.0
agent-30: 14.0
Sum Reward: 958.0
Avg Reward: 31.933333333333334
Min Reward: 11.0
Max Reward: 54.0
Gini Coefficient: 0.20194850382741822
20:20 Ratio: 3.0
Max-min Ratio: 4.909090909090909
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-09-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1259.22
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 251
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.692
    dispatch_time_ms: 6.022
    learner:
      cur_lr: 0.0008585019968450069
      grad_gnorm: 25.75640869140625
      policy_entropy: 265.8186340332031
      policy_loss: 0.5453836917877197
      var_gnorm: 23.217552185058594
      vf_explained_var: 0.0
      vf_loss: 24.84431266784668
    num_steps_sampled: 7560000
    num_steps_trained: 7560000
    wait_time_ms: 430.489
  iterations_since_restore: 252
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 11204.010507106781
  time_this_iter_s: 42.97513198852539
  time_total_s: 11204.010507106781
  timestamp: 1594163386
  timesteps_since_restore: 7560000
  timesteps_this_iter: 30000
  timesteps_total: 7560000
  training_iteration: 252
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 11204 s, 252 iter, 7560000 ts, 1.26e+03 rew

agent-1: 18.0
agent-2: 43.0
agent-3: 62.0
agent-4: 46.0
agent-5: 32.0
agent-6: 40.0
agent-7: 37.0
agent-8: 38.0
agent-9: 29.0
agent-10: 54.0
agent-11: 46.0
agent-12: 31.0
agent-13: 13.0
agent-14: 46.0
agent-15: 30.0
agent-16: 53.0
agent-17: 31.0
agent-18: 20.0
agent-19: 38.0
agent-20: 19.0
agent-21: 41.0
agent-22: 28.0
agent-23: 29.0
agent-24: 36.0
agent-25: 45.0
agent-26: 51.0
agent-27: 44.0
agent-28: 60.0
agent-29: 33.0
agent-30: 43.0
Sum Reward: 1136.0
Avg Reward: 37.86666666666667
Min Reward: 13.0
Max Reward: 62.0
Gini Coefficient: 0.17758215962441315
20:20 Ratio: 2.5669291338582676
Max-min Ratio: 4.769230769230769
agent-1: 51.0
agent-2: 51.0
agent-3: 59.0
agent-4: 56.0
agent-5: 73.0
agent-6: 18.0
agent-7: 43.0
agent-8: 26.0
agent-9: 67.0
agent-10: 33.0
agent-11: 54.0
agent-12: 47.0
agent-13: 43.0
agent-14: 55.0
agent-15: 19.0
agent-16: 58.0
agent-17: 28.0
agent-18: 41.0
agent-19: 33.0
agent-20: 7.0
agent-21: 29.0
agent-22: 23.0
agent-23: 32.0
agent-24: 67.0
agent-25: 27.0
agent-26: 46.0
agent-27: 40.0
agent-28: 53.0
agent-29: 93.0
agent-30: 44.0
Sum Reward: 1316.0
Avg Reward: 43.86666666666667
Min Reward: 7.0
Max Reward: 93.0
Gini Coefficient: 0.23110435663627152
20:20 Ratio: 3.475
Max-min Ratio: 13.285714285714286
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-10-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1256.15
  episode_reward_min: 880.0
  episodes_this_iter: 2
  episodes_total: 253
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.823
    dispatch_time_ms: 6.974
    learner:
      cur_lr: 0.0008565040188841522
      grad_gnorm: 40.0
      policy_entropy: 236.0219268798828
      policy_loss: -419.5592346191406
      var_gnorm: 23.213634490966797
      vf_explained_var: -1.0
      vf_loss: 471.0139465332031
    num_steps_sampled: 7590000
    num_steps_trained: 7590000
    wait_time_ms: 451.335
  iterations_since_restore: 253
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 11249.509760856628
  time_this_iter_s: 45.49925374984741
  time_total_s: 11249.509760856628
  timestamp: 1594163431
  timesteps_since_restore: 7590000
  timesteps_this_iter: 30000
  timesteps_total: 7590000
  training_iteration: 253
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 11249 s, 253 iter, 7590000 ts, 1.26e+03 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-11-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1256.15
  episode_reward_min: 880.0
  episodes_this_iter: 0
  episodes_total: 253
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.286
    dispatch_time_ms: 5.449
    learner:
      cur_lr: 0.0008545059827156365
      grad_gnorm: 40.0
      policy_entropy: 238.56581115722656
      policy_loss: -36.52058792114258
      var_gnorm: 23.217605590820312
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 8.842710494995117
    num_steps_sampled: 7620000
    num_steps_trained: 7620000
    wait_time_ms: 435.734
  iterations_since_restore: 254
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 11292.322588205338
  time_this_iter_s: 42.812827348709106
  time_total_s: 11292.322588205338
  timestamp: 1594163474
  timesteps_since_restore: 7620000
  timesteps_this_iter: 30000
  timesteps_total: 7620000
  training_iteration: 254
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 11292 s, 254 iter, 7620000 ts, 1.26e+03 rew

agent-1: 15.0
agent-2: 71.0
agent-3: 40.0
agent-4: 34.0
agent-5: 30.0
agent-6: 37.0
agent-7: 24.0
agent-8: 60.0
agent-9: 30.0
agent-10: 51.0
agent-11: 19.0
agent-12: 26.0
agent-13: 21.0
agent-14: 35.0
agent-15: 24.0
agent-16: 40.0
agent-17: 61.0
agent-18: 26.0
agent-19: 27.0
agent-20: 49.0
agent-21: 39.0
agent-22: 53.0
agent-23: 24.0
agent-24: 25.0
agent-25: 30.0
agent-26: 32.0
agent-27: 25.0
agent-28: 16.0
agent-29: 52.0
agent-30: 13.0
Sum Reward: 1029.0
Avg Reward: 34.3
Min Reward: 13.0
Max Reward: 71.0
Gini Coefficient: 0.23281503077421445
20:20 Ratio: 3.2222222222222223
Max-min Ratio: 5.461538461538462
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-12-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1254.76
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 254
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.633
    dispatch_time_ms: 7.987
    learner:
      cur_lr: 0.0008525080047547817
      grad_gnorm: 38.507755279541016
      policy_entropy: 254.43536376953125
      policy_loss: -12.201313972473145
      var_gnorm: 23.207317352294922
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.3618606925010681
    num_steps_sampled: 7650000
    num_steps_trained: 7650000
    wait_time_ms: 450.509
  iterations_since_restore: 255
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 11338.437180995941
  time_this_iter_s: 46.11459279060364
  time_total_s: 11338.437180995941
  timestamp: 1594163520
  timesteps_since_restore: 7650000
  timesteps_this_iter: 30000
  timesteps_total: 7650000
  training_iteration: 255
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 11338 s, 255 iter, 7650000 ts, 1.25e+03 rew

agent-1: 27.0
agent-2: 51.0
agent-3: 35.0
agent-4: 34.0
agent-5: 45.0
agent-6: 38.0
agent-7: 28.0
agent-8: 28.0
agent-9: 48.0
agent-10: 22.0
agent-11: 23.0
agent-12: 24.0
agent-13: 22.0
agent-14: 17.0
agent-15: 40.0
agent-16: 33.0
agent-17: 39.0
agent-18: 47.0
agent-19: 27.0
agent-20: 28.0
agent-21: 46.0
agent-22: 39.0
agent-23: 24.0
agent-24: 9.0
agent-25: 25.0
agent-26: 74.0
agent-27: 37.0
agent-28: 34.0
agent-29: 31.0
agent-30: 54.0
Sum Reward: 1029.0
Avg Reward: 34.3
Min Reward: 9.0
Max Reward: 74.0
Gini Coefficient: 0.2007450599287334
20:20 Ratio: 2.735042735042735
Max-min Ratio: 8.222222222222221
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-12-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1252.71
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 255
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.861
    dispatch_time_ms: 5.371
    learner:
      cur_lr: 0.000850510026793927
      grad_gnorm: 40.0
      policy_entropy: 263.3830261230469
      policy_loss: -25.804014205932617
      var_gnorm: 23.214792251586914
      vf_explained_var: 0.0
      vf_loss: 8.163359642028809
    num_steps_sampled: 7680000
    num_steps_trained: 7680000
    wait_time_ms: 459.57
  iterations_since_restore: 256
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 11381.794661283493
  time_this_iter_s: 43.35748028755188
  time_total_s: 11381.794661283493
  timestamp: 1594163564
  timesteps_since_restore: 7680000
  timesteps_this_iter: 30000
  timesteps_total: 7680000
  training_iteration: 256
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 11381 s, 256 iter, 7680000 ts, 1.25e+03 rew

agent-1: 58.0
agent-2: 36.0
agent-3: 37.0
agent-4: 29.0
agent-5: 47.0
agent-6: 11.0
agent-7: 57.0
agent-8: 43.0
agent-9: 32.0
agent-10: 50.0
agent-11: 60.0
agent-12: 27.0
agent-13: 25.0
agent-14: 47.0
agent-15: 39.0
agent-16: 49.0
agent-17: 35.0
agent-18: 27.0
agent-19: 27.0
agent-20: 25.0
agent-21: 39.0
agent-22: 57.0
agent-23: 13.0
agent-24: 21.0
agent-25: 28.0
agent-26: 48.0
agent-27: 49.0
agent-28: 20.0
agent-29: 54.0
agent-30: 35.0
Sum Reward: 1125.0
Avg Reward: 37.5
Min Reward: 11.0
Max Reward: 60.0
Gini Coefficient: 0.20536296296296297
20:20 Ratio: 2.9217391304347826
Max-min Ratio: 5.454545454545454
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-13-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1248.13
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 256
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.656
    dispatch_time_ms: 5.862
    learner:
      cur_lr: 0.0008485119906254113
      grad_gnorm: 22.92458724975586
      policy_entropy: 282.943603515625
      policy_loss: -8.636152267456055
      var_gnorm: 23.214475631713867
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.12669704854488373
    num_steps_sampled: 7710000
    num_steps_trained: 7710000
    wait_time_ms: 451.443
  iterations_since_restore: 257
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 11427.317152261734
  time_this_iter_s: 45.52249097824097
  time_total_s: 11427.317152261734
  timestamp: 1594163609
  timesteps_since_restore: 7710000
  timesteps_this_iter: 30000
  timesteps_total: 7710000
  training_iteration: 257
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 11427 s, 257 iter, 7710000 ts, 1.25e+03 rew

agent-1: 41.0
agent-2: 42.0
agent-3: 34.0
agent-4: 19.0
agent-5: 28.0
agent-6: 27.0
agent-7: 33.0
agent-8: 41.0
agent-9: 41.0
agent-10: 26.0
agent-11: 44.0
agent-12: 36.0
agent-13: 30.0
agent-14: 29.0
agent-15: 38.0
agent-16: 27.0
agent-17: 42.0
agent-18: 18.0
agent-19: 34.0
agent-20: 37.0
agent-21: 33.0
agent-22: 27.0
agent-23: 53.0
agent-24: 30.0
agent-25: 28.0
agent-26: 13.0
agent-27: 38.0
agent-28: 39.0
agent-29: 32.0
agent-30: 51.0
Sum Reward: 1011.0
Avg Reward: 33.7
Min Reward: 13.0
Max Reward: 53.0
Gini Coefficient: 0.14655456643587209
20:20 Ratio: 2.1
Max-min Ratio: 4.076923076923077
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-14-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1245.55
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 257
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.482
    dispatch_time_ms: 6.085
    learner:
      cur_lr: 0.0008465140126645565
      grad_gnorm: 40.0
      policy_entropy: 237.21270751953125
      policy_loss: -15.71042537689209
      var_gnorm: 23.22270393371582
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 11.161018371582031
    num_steps_sampled: 7740000
    num_steps_trained: 7740000
    wait_time_ms: 449.827
  iterations_since_restore: 258
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 11470.83827495575
  time_this_iter_s: 43.5211226940155
  time_total_s: 11470.83827495575
  timestamp: 1594163653
  timesteps_since_restore: 7740000
  timesteps_this_iter: 30000
  timesteps_total: 7740000
  training_iteration: 258
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 11470 s, 258 iter, 7740000 ts, 1.25e+03 rew

agent-1: 13.0
agent-2: 9.0
agent-3: 26.0
agent-4: 41.0
agent-5: 47.0
agent-6: 21.0
agent-7: 20.0
agent-8: 27.0
agent-9: 43.0
agent-10: 43.0
agent-11: 36.0
agent-12: 68.0
agent-13: 20.0
agent-14: 32.0
agent-15: 18.0
agent-16: 26.0
agent-17: 59.0
agent-18: 55.0
agent-19: 32.0
agent-20: 78.0
agent-21: 28.0
agent-22: 20.0
agent-23: 30.0
agent-24: 56.0
agent-25: 46.0
agent-26: 17.0
agent-27: 32.0
agent-28: 35.0
agent-29: 12.0
agent-30: 32.0
Sum Reward: 1022.0
Avg Reward: 34.06666666666667
Min Reward: 9.0
Max Reward: 78.0
Gini Coefficient: 0.2694063926940639
20:20 Ratio: 4.078651685393258
Max-min Ratio: 8.666666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-14-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1243.64
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 258
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.014
    dispatch_time_ms: 6.318
    learner:
      cur_lr: 0.0008445159764960408
      grad_gnorm: 39.999996185302734
      policy_entropy: 231.969970703125
      policy_loss: 97.16690826416016
      var_gnorm: 23.217653274536133
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 209.98281860351562
    num_steps_sampled: 7770000
    num_steps_trained: 7770000
    wait_time_ms: 432.364
  iterations_since_restore: 259
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 11516.033759593964
  time_this_iter_s: 45.19548463821411
  time_total_s: 11516.033759593964
  timestamp: 1594163698
  timesteps_since_restore: 7770000
  timesteps_this_iter: 30000
  timesteps_total: 7770000
  training_iteration: 259
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 11516 s, 259 iter, 7770000 ts, 1.24e+03 rew

agent-1: 40.0
agent-2: 20.0
agent-3: 30.0
agent-4: 28.0
agent-5: 25.0
agent-6: 35.0
agent-7: 36.0
agent-8: 43.0
agent-9: 25.0
agent-10: 23.0
agent-11: 35.0
agent-12: 14.0
agent-13: 29.0
agent-14: 18.0
agent-15: 35.0
agent-16: 35.0
agent-17: 36.0
agent-18: 47.0
agent-19: 24.0
agent-20: 25.0
agent-21: 10.0
agent-22: 37.0
agent-23: 43.0
agent-24: 20.0
agent-25: 10.0
agent-26: 21.0
agent-27: 44.0
agent-28: 22.0
agent-29: 31.0
agent-30: 47.0
Sum Reward: 888.0
Avg Reward: 29.6
Min Reward: 10.0
Max Reward: 47.0
Gini Coefficient: 0.19714714714714715
20:20 Ratio: 2.869565217391304
Max-min Ratio: 4.7
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-15-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1236.75
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 259
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.52
    dispatch_time_ms: 7.942
    learner:
      cur_lr: 0.000842517998535186
      grad_gnorm: 40.0
      policy_entropy: 239.1118621826172
      policy_loss: -19.71630096435547
      var_gnorm: 23.2265682220459
      vf_explained_var: 0.0
      vf_loss: 10.103167533874512
    num_steps_sampled: 7800000
    num_steps_trained: 7800000
    wait_time_ms: 435.091
  iterations_since_restore: 260
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 11558.92902803421
  time_this_iter_s: 42.89526844024658
  time_total_s: 11558.92902803421
  timestamp: 1594163741
  timesteps_since_restore: 7800000
  timesteps_this_iter: 30000
  timesteps_total: 7800000
  training_iteration: 260
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 11558 s, 260 iter, 7800000 ts, 1.24e+03 rew

agent-1: 15.0
agent-2: 51.0
agent-3: 48.0
agent-4: 22.0
agent-5: 23.0
agent-6: 70.0
agent-7: 37.0
agent-8: 54.0
agent-9: 53.0
agent-10: 48.0
agent-11: 29.0
agent-12: 46.0
agent-13: 36.0
agent-14: 41.0
agent-15: 53.0
agent-16: 55.0
agent-17: 55.0
agent-18: 36.0
agent-19: 33.0
agent-20: 52.0
agent-21: 35.0
agent-22: 42.0
agent-23: 60.0
agent-24: 36.0
agent-25: 22.0
agent-26: 47.0
agent-27: 90.0
agent-28: 33.0
agent-29: 29.0
agent-30: 45.0
Sum Reward: 1296.0
Avg Reward: 43.2
Min Reward: 15.0
Max Reward: 90.0
Gini Coefficient: 0.19197530864197532
20:20 Ratio: 2.742857142857143
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-16-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1650.0
  episode_reward_mean: 1238.02
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 260
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.093
    dispatch_time_ms: 5.561
    learner:
      cur_lr: 0.0008405200205743313
      grad_gnorm: 40.0
      policy_entropy: 257.5205383300781
      policy_loss: -14.03471851348877
      var_gnorm: 23.222553253173828
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 34.29750061035156
    num_steps_sampled: 7830000
    num_steps_trained: 7830000
    wait_time_ms: 430.72
  iterations_since_restore: 261
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 11603.496804237366
  time_this_iter_s: 44.56777620315552
  time_total_s: 11603.496804237366
  timestamp: 1594163786
  timesteps_since_restore: 7830000
  timesteps_this_iter: 30000
  timesteps_total: 7830000
  training_iteration: 261
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 11603 s, 261 iter, 7830000 ts, 1.24e+03 rew

agent-1: 35.0
agent-2: 40.0
agent-3: 44.0
agent-4: 12.0
agent-5: 37.0
agent-6: 50.0
agent-7: 45.0
agent-8: 30.0
agent-9: 18.0
agent-10: 48.0
agent-11: 67.0
agent-12: 49.0
agent-13: 60.0
agent-14: 54.0
agent-15: 30.0
agent-16: 18.0
agent-17: 43.0
agent-18: 55.0
agent-19: 29.0
agent-20: 48.0
agent-21: 60.0
agent-22: 17.0
agent-23: 34.0
agent-24: 42.0
agent-25: 41.0
agent-26: 57.0
agent-27: 33.0
agent-28: 51.0
agent-29: 54.0
agent-30: 45.0
Sum Reward: 1246.0
Avg Reward: 41.53333333333333
Min Reward: 12.0
Max Reward: 67.0
Gini Coefficient: 0.1853932584269663
20:20 Ratio: 2.846774193548387
Max-min Ratio: 5.583333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-17-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1233.98
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 261
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 4.842
    dispatch_time_ms: 25.731
    learner:
      cur_lr: 0.0008385219844058156
      grad_gnorm: 40.0
      policy_entropy: 217.9503936767578
      policy_loss: -34.913368225097656
      var_gnorm: 23.227907180786133
      vf_explained_var: 0.0
      vf_loss: 13.56226921081543
    num_steps_sampled: 7860000
    num_steps_trained: 7860000
    wait_time_ms: 447.811
  iterations_since_restore: 262
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 11647.626197338104
  time_this_iter_s: 44.129393100738525
  time_total_s: 11647.626197338104
  timestamp: 1594163830
  timesteps_since_restore: 7860000
  timesteps_this_iter: 30000
  timesteps_total: 7860000
  training_iteration: 262
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 11647 s, 262 iter, 7860000 ts, 1.23e+03 rew

agent-1: 58.0
agent-2: 37.0
agent-3: 56.0
agent-4: 46.0
agent-5: 58.0
agent-6: 51.0
agent-7: 36.0
agent-8: 32.0
agent-9: 45.0
agent-10: 31.0
agent-11: 36.0
agent-12: 42.0
agent-13: 36.0
agent-14: 55.0
agent-15: 19.0
agent-16: 14.0
agent-17: 30.0
agent-18: 49.0
agent-19: 50.0
agent-20: 14.0
agent-21: 20.0
agent-22: 24.0
agent-23: 40.0
agent-24: 54.0
agent-25: 35.0
agent-26: 56.0
agent-27: 38.0
agent-28: 47.0
agent-29: 31.0
agent-30: 31.0
Sum Reward: 1171.0
Avg Reward: 39.03333333333333
Min Reward: 14.0
Max Reward: 58.0
Gini Coefficient: 0.18653572445203528
20:20 Ratio: 2.7851239669421486
Max-min Ratio: 4.142857142857143
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-17-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1233.35
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 262
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.753
    dispatch_time_ms: 33.086
    learner:
      cur_lr: 0.0008365240064449608
      grad_gnorm: 40.0
      policy_entropy: 217.60716247558594
      policy_loss: 87.68131256103516
      var_gnorm: 23.215930938720703
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 157.6331329345703
    num_steps_sampled: 7890000
    num_steps_trained: 7890000
    wait_time_ms: 662.255
  iterations_since_restore: 263
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 11696.87481713295
  time_this_iter_s: 49.24861979484558
  time_total_s: 11696.87481713295
  timestamp: 1594163879
  timesteps_since_restore: 7890000
  timesteps_this_iter: 30000
  timesteps_total: 7890000
  training_iteration: 263
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 11696 s, 263 iter, 7890000 ts, 1.23e+03 rew

agent-1: 27.0
agent-2: 30.0
agent-3: 19.0
agent-4: 28.0
agent-5: 34.0
agent-6: 31.0
agent-7: 43.0
agent-8: 35.0
agent-9: 23.0
agent-10: 33.0
agent-11: 32.0
agent-12: 27.0
agent-13: 22.0
agent-14: 7.0
agent-15: 21.0
agent-16: 50.0
agent-17: 29.0
agent-18: 38.0
agent-19: 47.0
agent-20: 54.0
agent-21: 45.0
agent-22: 40.0
agent-23: 31.0
agent-24: 47.0
agent-25: 19.0
agent-26: 47.0
agent-27: 45.0
agent-28: 33.0
agent-29: 39.0
agent-30: 40.0
Sum Reward: 1016.0
Avg Reward: 33.86666666666667
Min Reward: 7.0
Max Reward: 54.0
Gini Coefficient: 0.1778215223097113
20:20 Ratio: 2.6126126126126126
Max-min Ratio: 7.714285714285714
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-18-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1229.2
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 263
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.493
    dispatch_time_ms: 28.792
    learner:
      cur_lr: 0.0008345260284841061
      grad_gnorm: 40.0
      policy_entropy: 219.04464721679688
      policy_loss: -12.3790283203125
      var_gnorm: 23.227365493774414
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 46.437889099121094
    num_steps_sampled: 7920000
    num_steps_trained: 7920000
    wait_time_ms: 437.604
  iterations_since_restore: 264
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 11739.356549024582
  time_this_iter_s: 42.48173189163208
  time_total_s: 11739.356549024582
  timestamp: 1594163921
  timesteps_since_restore: 7920000
  timesteps_this_iter: 30000
  timesteps_total: 7920000
  training_iteration: 264
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 11739 s, 264 iter, 7920000 ts, 1.23e+03 rew

agent-1: 38.0
agent-2: 14.0
agent-3: 81.0
agent-4: 33.0
agent-5: 38.0
agent-6: 25.0
agent-7: 44.0
agent-8: 28.0
agent-9: 11.0
agent-10: 30.0
agent-11: 52.0
agent-12: 25.0
agent-13: 34.0
agent-14: 36.0
agent-15: 38.0
agent-16: 39.0
agent-17: 36.0
agent-18: 31.0
agent-19: 31.0
agent-20: 35.0
agent-21: 46.0
agent-22: 21.0
agent-23: 56.0
agent-24: 47.0
agent-25: 37.0
agent-26: 37.0
agent-27: 35.0
agent-28: 30.0
agent-29: 53.0
agent-30: 37.0
Sum Reward: 1098.0
Avg Reward: 36.6
Min Reward: 11.0
Max Reward: 81.0
Gini Coefficient: 0.1825136612021858
20:20 Ratio: 2.7016129032258065
Max-min Ratio: 7.363636363636363
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-19-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1226.95
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 264
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.617
    dispatch_time_ms: 25.285
    learner:
      cur_lr: 0.0008325279923155904
      grad_gnorm: 40.0
      policy_entropy: 182.96054077148438
      policy_loss: 13.178645133972168
      var_gnorm: 23.217697143554688
      vf_explained_var: 0.0
      vf_loss: 98.55049133300781
    num_steps_sampled: 7950000
    num_steps_trained: 7950000
    wait_time_ms: 447.212
  iterations_since_restore: 265
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 11785.712387084961
  time_this_iter_s: 46.35583806037903
  time_total_s: 11785.712387084961
  timestamp: 1594163968
  timesteps_since_restore: 7950000
  timesteps_this_iter: 30000
  timesteps_total: 7950000
  training_iteration: 265
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 11785 s, 265 iter, 7950000 ts, 1.23e+03 rew

agent-1: 36.0
agent-2: 37.0
agent-3: 65.0
agent-4: 32.0
agent-5: 35.0
agent-6: 47.0
agent-7: 22.0
agent-8: 17.0
agent-9: 35.0
agent-10: 22.0
agent-11: 33.0
agent-12: 72.0
agent-13: 43.0
agent-14: 43.0
agent-15: 44.0
agent-16: 45.0
agent-17: 65.0
agent-18: 27.0
agent-19: 56.0
agent-20: 40.0
agent-21: 33.0
agent-22: 36.0
agent-23: 30.0
agent-24: 36.0
agent-25: 41.0
agent-26: 28.0
agent-27: 32.0
agent-28: 46.0
agent-29: 51.0
agent-30: 41.0
Sum Reward: 1190.0
Avg Reward: 39.666666666666664
Min Reward: 17.0
Max Reward: 72.0
Gini Coefficient: 0.17204481792717086
20:20 Ratio: 2.4383561643835616
Max-min Ratio: 4.235294117647059
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-20-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1225.8
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 265
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.496
    dispatch_time_ms: 32.821
    learner:
      cur_lr: 0.0008305300143547356
      grad_gnorm: 40.0
      policy_entropy: 184.39198303222656
      policy_loss: 20.888874053955078
      var_gnorm: 23.22827911376953
      vf_explained_var: 0.0
      vf_loss: 53.14387512207031
    num_steps_sampled: 7980000
    num_steps_trained: 7980000
    wait_time_ms: 412.276
  iterations_since_restore: 266
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 11830.210715055466
  time_this_iter_s: 44.49832797050476
  time_total_s: 11830.210715055466
  timestamp: 1594164012
  timesteps_since_restore: 7980000
  timesteps_this_iter: 30000
  timesteps_total: 7980000
  training_iteration: 266
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 11830 s, 266 iter, 7980000 ts, 1.23e+03 rew

agent-1: 37.0
agent-2: 37.0
agent-3: 38.0
agent-4: 34.0
agent-5: 58.0
agent-6: 47.0
agent-7: 72.0
agent-8: 52.0
agent-9: 33.0
agent-10: 30.0
agent-11: 31.0
agent-12: 37.0
agent-13: 50.0
agent-14: 25.0
agent-15: 6.0
agent-16: 92.0
agent-17: 34.0
agent-18: 39.0
agent-19: 31.0
agent-20: 25.0
agent-21: 20.0
agent-22: 33.0
agent-23: 32.0
agent-24: 34.0
agent-25: 28.0
agent-26: 41.0
agent-27: 79.0
agent-28: 35.0
agent-29: 38.0
agent-30: 33.0
Sum Reward: 1181.0
Avg Reward: 39.36666666666667
Min Reward: 6.0
Max Reward: 92.0
Gini Coefficient: 0.21368896415467117
20:20 Ratio: 3.0074626865671643
Max-min Ratio: 15.333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-20-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1225.28
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 266
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.786
    dispatch_time_ms: 20.914
    learner:
      cur_lr: 0.0008285319781862199
      grad_gnorm: 39.999996185302734
      policy_entropy: 173.68145751953125
      policy_loss: -20.062118530273438
      var_gnorm: 23.22037124633789
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 2.97369384765625
    num_steps_sampled: 8010000
    num_steps_trained: 8010000
    wait_time_ms: 442.702
  iterations_since_restore: 267
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 11875.35162639618
  time_this_iter_s: 45.1409113407135
  time_total_s: 11875.35162639618
  timestamp: 1594164058
  timesteps_since_restore: 8010000
  timesteps_this_iter: 30000
  timesteps_total: 8010000
  training_iteration: 267
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 11875 s, 267 iter, 8010000 ts, 1.23e+03 rew

agent-1: 33.0
agent-2: 53.0
agent-3: 49.0
agent-4: 27.0
agent-5: 56.0
agent-6: 34.0
agent-7: 46.0
agent-8: 23.0
agent-9: 52.0
agent-10: 42.0
agent-11: 55.0
agent-12: 54.0
agent-13: 36.0
agent-14: 39.0
agent-15: 40.0
agent-16: 29.0
agent-17: 17.0
agent-18: 59.0
agent-19: 45.0
agent-20: 53.0
agent-21: 66.0
agent-22: 51.0
agent-23: 50.0
agent-24: 26.0
agent-25: 35.0
agent-26: 28.0
agent-27: 26.0
agent-28: 45.0
agent-29: 40.0
agent-30: 45.0
Sum Reward: 1254.0
Avg Reward: 41.8
Min Reward: 17.0
Max Reward: 66.0
Gini Coefficient: 0.16321105794790006
20:20 Ratio: 2.3333333333333335
Max-min Ratio: 3.8823529411764706
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-21-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1227.57
  episode_reward_min: 880.0
  episodes_this_iter: 1
  episodes_total: 267
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 4.425
    dispatch_time_ms: 26.869
    learner:
      cur_lr: 0.0008265340002253652
      grad_gnorm: 40.0
      policy_entropy: 201.200439453125
      policy_loss: -25.576955795288086
      var_gnorm: 23.226903915405273
      vf_explained_var: 0.0
      vf_loss: 21.122310638427734
    num_steps_sampled: 8040000
    num_steps_trained: 8040000
    wait_time_ms: 429.685
  iterations_since_restore: 268
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 11920.76347565651
  time_this_iter_s: 45.4118492603302
  time_total_s: 11920.76347565651
  timestamp: 1594164103
  timesteps_since_restore: 8040000
  timesteps_this_iter: 30000
  timesteps_total: 8040000
  training_iteration: 268
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 11920 s, 268 iter, 8040000 ts, 1.23e+03 rew

agent-1: 19.0
agent-2: 39.0
agent-3: 63.0
agent-4: 58.0
agent-5: 25.0
agent-6: 30.0
agent-7: 62.0
agent-8: 43.0
agent-9: 49.0
agent-10: 16.0
agent-11: 48.0
agent-12: 62.0
agent-13: 32.0
agent-14: 27.0
agent-15: 27.0
agent-16: 66.0
agent-17: 51.0
agent-18: 34.0
agent-19: 51.0
agent-20: 44.0
agent-21: 50.0
agent-22: 30.0
agent-23: 40.0
agent-24: 56.0
agent-25: 31.0
agent-26: 40.0
agent-27: 48.0
agent-28: 28.0
agent-29: 39.0
agent-30: 45.0
Sum Reward: 1253.0
Avg Reward: 41.766666666666666
Min Reward: 16.0
Max Reward: 66.0
Gini Coefficient: 0.1833200319233839
20:20 Ratio: 2.584507042253521
Max-min Ratio: 4.125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-22-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1231.3
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 268
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.885
    dispatch_time_ms: 6.787
    learner:
      cur_lr: 0.0008245360222645104
      grad_gnorm: 40.000003814697266
      policy_entropy: 155.6989288330078
      policy_loss: 107.5716552734375
      var_gnorm: 23.217578887939453
      vf_explained_var: 0.0
      vf_loss: 157.81243896484375
    num_steps_sampled: 8070000
    num_steps_trained: 8070000
    wait_time_ms: 1217.938
  iterations_since_restore: 269
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 11974.894136428833
  time_this_iter_s: 54.13066077232361
  time_total_s: 11974.894136428833
  timestamp: 1594164157
  timesteps_since_restore: 8070000
  timesteps_this_iter: 30000
  timesteps_total: 8070000
  training_iteration: 269
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 53.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 11974 s, 269 iter, 8070000 ts, 1.23e+03 rew

agent-1: 47.0
agent-2: 63.0
agent-3: 46.0
agent-4: 37.0
agent-5: 41.0
agent-6: 24.0
agent-7: 38.0
agent-8: 52.0
agent-9: 29.0
agent-10: 32.0
agent-11: 27.0
agent-12: 27.0
agent-13: 32.0
agent-14: 18.0
agent-15: 30.0
agent-16: 47.0
agent-17: 9.0
agent-18: 41.0
agent-19: 29.0
agent-20: 42.0
agent-21: 51.0
agent-22: 62.0
agent-23: 25.0
agent-24: 53.0
agent-25: 45.0
agent-26: 45.0
agent-27: 42.0
agent-28: 32.0
agent-29: 44.0
agent-30: 36.0
Sum Reward: 1146.0
Avg Reward: 38.2
Min Reward: 9.0
Max Reward: 63.0
Gini Coefficient: 0.17760325770796975
20:20 Ratio: 2.523076923076923
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-23-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1229.25
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 269
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.576
    dispatch_time_ms: 6.002
    learner:
      cur_lr: 0.0008225379860959947
      grad_gnorm: 40.0
      policy_entropy: 185.52194213867188
      policy_loss: -7.592745780944824
      var_gnorm: 23.23019790649414
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 40.787567138671875
    num_steps_sampled: 8100000
    num_steps_trained: 8100000
    wait_time_ms: 444.716
  iterations_since_restore: 270
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 12015.901422977448
  time_this_iter_s: 41.0072865486145
  time_total_s: 12015.901422977448
  timestamp: 1594164198
  timesteps_since_restore: 8100000
  timesteps_this_iter: 30000
  timesteps_total: 8100000
  training_iteration: 270
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 56.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 12015 s, 270 iter, 8100000 ts, 1.23e+03 rew

agent-1: 45.0
agent-2: 47.0
agent-3: 60.0
agent-4: 45.0
agent-5: 44.0
agent-6: 70.0
agent-7: 73.0
agent-8: 32.0
agent-9: 9.0
agent-10: 38.0
agent-11: 55.0
agent-12: 35.0
agent-13: 48.0
agent-14: 48.0
agent-15: 17.0
agent-16: 73.0
agent-17: 26.0
agent-18: 33.0
agent-19: 57.0
agent-20: 42.0
agent-21: 70.0
agent-22: 38.0
agent-23: 43.0
agent-24: 61.0
agent-25: 44.0
agent-26: 26.0
agent-27: 91.0
agent-28: 56.0
agent-29: 41.0
agent-30: 42.0
Sum Reward: 1409.0
Avg Reward: 46.96666666666667
Min Reward: 9.0
Max Reward: 91.0
Gini Coefficient: 0.20404542228530873
20:20 Ratio: 3.062937062937063
Max-min Ratio: 10.11111111111111
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-24-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1229.25
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 270
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.632
    dispatch_time_ms: 6.639
    learner:
      cur_lr: 0.0008205400081351399
      grad_gnorm: 40.0
      policy_entropy: 204.37197875976562
      policy_loss: -21.556312561035156
      var_gnorm: 23.217256546020508
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 20.97072982788086
    num_steps_sampled: 8130000
    num_steps_trained: 8130000
    wait_time_ms: 444.449
  iterations_since_restore: 271
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 12060.031803131104
  time_this_iter_s: 44.130380153656006
  time_total_s: 12060.031803131104
  timestamp: 1594164243
  timesteps_since_restore: 8130000
  timesteps_this_iter: 30000
  timesteps_total: 8130000
  training_iteration: 271
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 52.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 12060 s, 271 iter, 8130000 ts, 1.23e+03 rew

agent-1: 46.0
agent-2: 37.0
agent-3: 44.0
agent-4: 21.0
agent-5: 49.0
agent-6: 74.0
agent-7: 51.0
agent-8: 36.0
agent-9: 47.0
agent-10: 37.0
agent-11: 19.0
agent-12: 22.0
agent-13: 52.0
agent-14: 29.0
agent-15: 42.0
agent-16: 59.0
agent-17: 35.0
agent-18: 49.0
agent-19: 34.0
agent-20: 59.0
agent-21: 45.0
agent-22: 34.0
agent-23: 32.0
agent-24: 75.0
agent-25: 32.0
agent-26: 55.0
agent-27: 28.0
agent-28: 30.0
agent-29: 25.0
agent-30: 28.0
Sum Reward: 1226.0
Avg Reward: 40.86666666666667
Min Reward: 19.0
Max Reward: 75.0
Gini Coefficient: 0.19244154431756388
20:20 Ratio: 2.6153846153846154
Max-min Ratio: 3.9473684210526314
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-24-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1228.35
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 271
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 4.088
    dispatch_time_ms: 38.201
    learner:
      cur_lr: 0.0008185419719666243
      grad_gnorm: 40.0
      policy_entropy: 216.0736541748047
      policy_loss: -19.093198776245117
      var_gnorm: 23.223520278930664
      vf_explained_var: 0.0
      vf_loss: 18.840927124023438
    num_steps_sampled: 8160000
    num_steps_trained: 8160000
    wait_time_ms: 429.407
  iterations_since_restore: 272
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 12104.329874753952
  time_this_iter_s: 44.29807162284851
  time_total_s: 12104.329874753952
  timestamp: 1594164287
  timesteps_since_restore: 8160000
  timesteps_this_iter: 30000
  timesteps_total: 8160000
  training_iteration: 272
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 53.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 12104 s, 272 iter, 8160000 ts, 1.23e+03 rew

agent-1: 14.0
agent-2: 38.0
agent-3: 60.0
agent-4: 35.0
agent-5: 36.0
agent-6: 30.0
agent-7: 57.0
agent-8: 26.0
agent-9: 27.0
agent-10: 27.0
agent-11: 30.0
agent-12: 23.0
agent-13: 58.0
agent-14: 69.0
agent-15: 34.0
agent-16: 54.0
agent-17: 40.0
agent-18: 21.0
agent-19: 21.0
agent-20: 41.0
agent-21: 19.0
agent-22: 29.0
agent-23: 51.0
agent-24: 64.0
agent-25: 68.0
agent-26: 30.0
agent-27: 64.0
agent-28: 43.0
agent-29: 39.0
agent-30: 38.0
Sum Reward: 1186.0
Avg Reward: 39.53333333333333
Min Reward: 14.0
Max Reward: 69.0
Gini Coefficient: 0.22248454187745925
20:20 Ratio: 3.088709677419355
Max-min Ratio: 4.928571428571429
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-25-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1227.37
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 272
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.895
    dispatch_time_ms: 6.036
    learner:
      cur_lr: 0.0008165439940057695
      grad_gnorm: 40.0
      policy_entropy: 195.09791564941406
      policy_loss: 76.35478210449219
      var_gnorm: 23.199440002441406
      vf_explained_var: 0.0
      vf_loss: 179.645751953125
    num_steps_sampled: 8190000
    num_steps_trained: 8190000
    wait_time_ms: 435.81
  iterations_since_restore: 273
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 12149.650072813034
  time_this_iter_s: 45.32019805908203
  time_total_s: 12149.650072813034
  timestamp: 1594164332
  timesteps_since_restore: 8190000
  timesteps_this_iter: 30000
  timesteps_total: 8190000
  training_iteration: 273
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 53.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 12149 s, 273 iter, 8190000 ts, 1.23e+03 rew

agent-1: 20.0
agent-2: 15.0
agent-3: 44.0
agent-4: 34.0
agent-5: 30.0
agent-6: 29.0
agent-7: 25.0
agent-8: 12.0
agent-9: 27.0
agent-10: 40.0
agent-11: 24.0
agent-12: 22.0
agent-13: 32.0
agent-14: 46.0
agent-15: 30.0
agent-16: 35.0
agent-17: 26.0
agent-18: 59.0
agent-19: 28.0
agent-20: 39.0
agent-21: 19.0
agent-22: 18.0
agent-23: 34.0
agent-24: 44.0
agent-25: 48.0
agent-26: 47.0
agent-27: 32.0
agent-28: 40.0
agent-29: 20.0
agent-30: 44.0
Sum Reward: 963.0
Avg Reward: 32.1
Min Reward: 12.0
Max Reward: 59.0
Gini Coefficient: 0.1958809276566286
20:20 Ratio: 2.769230769230769
Max-min Ratio: 4.916666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-26-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1225.74
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 273
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.179
    dispatch_time_ms: 6.788
    learner:
      cur_lr: 0.0008145460160449147
      grad_gnorm: 17.408029556274414
      policy_entropy: 156.2507781982422
      policy_loss: -4.879768371582031
      var_gnorm: 23.372854232788086
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 26.35871696472168
    num_steps_sampled: 8220000
    num_steps_trained: 8220000
    wait_time_ms: 434.421
  iterations_since_restore: 274
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 12193.29517364502
  time_this_iter_s: 43.645100831985474
  time_total_s: 12193.29517364502
  timestamp: 1594164376
  timesteps_since_restore: 8220000
  timesteps_this_iter: 30000
  timesteps_total: 8220000
  training_iteration: 274
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 53.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 12193 s, 274 iter, 8220000 ts, 1.23e+03 rew

agent-1: 59.0
agent-2: 24.0
agent-3: 31.0
agent-4: 31.0
agent-5: 43.0
agent-6: 48.0
agent-7: 37.0
agent-8: 63.0
agent-9: 32.0
agent-10: 29.0
agent-11: 44.0
agent-12: 39.0
agent-13: 21.0
agent-14: 24.0
agent-15: 23.0
agent-16: 54.0
agent-17: 39.0
agent-18: 37.0
agent-19: 42.0
agent-20: 38.0
agent-21: 29.0
agent-22: 31.0
agent-23: 28.0
agent-24: 37.0
agent-25: 39.0
agent-26: 43.0
agent-27: 34.0
agent-28: 51.0
agent-29: 68.0
agent-30: 73.0
Sum Reward: 1191.0
Avg Reward: 39.7
Min Reward: 21.0
Max Reward: 73.0
Gini Coefficient: 0.17954100195913797
20:20 Ratio: 2.469798657718121
Max-min Ratio: 3.4761904761904763
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-27-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1225.79
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 274
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.274
    dispatch_time_ms: 6.09
    learner:
      cur_lr: 0.000812547979876399
      grad_gnorm: 40.0
      policy_entropy: 138.61572265625
      policy_loss: 77.99042510986328
      var_gnorm: 23.371150970458984
      vf_explained_var: 0.0
      vf_loss: 186.88414001464844
    num_steps_sampled: 8250000
    num_steps_trained: 8250000
    wait_time_ms: 426.843
  iterations_since_restore: 275
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 12237.747112512589
  time_this_iter_s: 44.45193886756897
  time_total_s: 12237.747112512589
  timestamp: 1594164420
  timesteps_since_restore: 8250000
  timesteps_this_iter: 30000
  timesteps_total: 8250000
  training_iteration: 275
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 53.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 12237 s, 275 iter, 8250000 ts, 1.23e+03 rew

agent-1: 55.0
agent-2: 15.0
agent-3: 50.0
agent-4: 43.0
agent-5: 31.0
agent-6: 28.0
agent-7: 36.0
agent-8: 64.0
agent-9: 35.0
agent-10: 41.0
agent-11: 30.0
agent-12: 31.0
agent-13: 41.0
agent-14: 38.0
agent-15: 47.0
agent-16: 25.0
agent-17: 35.0
agent-18: 84.0
agent-19: 26.0
agent-20: 51.0
agent-21: 45.0
agent-22: 57.0
agent-23: 30.0
agent-24: 31.0
agent-25: 51.0
agent-26: 29.0
agent-27: 32.0
agent-28: 40.0
agent-29: 50.0
agent-30: 28.0
Sum Reward: 1199.0
Avg Reward: 39.96666666666667
Min Reward: 15.0
Max Reward: 84.0
Gini Coefficient: 0.1826800111203781
20:20 Ratio: 2.3973509933774833
Max-min Ratio: 5.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-27-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1225.99
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 275
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.0
    dispatch_time_ms: 7.494
    learner:
      cur_lr: 0.0008105500019155443
      grad_gnorm: 40.0
      policy_entropy: 154.8828125
      policy_loss: -8.427778244018555
      var_gnorm: 23.379514694213867
      vf_explained_var: 0.0
      vf_loss: 43.26171875
    num_steps_sampled: 8280000
    num_steps_trained: 8280000
    wait_time_ms: 427.577
  iterations_since_restore: 276
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 12280.738854646683
  time_this_iter_s: 42.99174213409424
  time_total_s: 12280.738854646683
  timestamp: 1594164463
  timesteps_since_restore: 8280000
  timesteps_this_iter: 30000
  timesteps_total: 8280000
  training_iteration: 276
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 53.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 12280 s, 276 iter, 8280000 ts, 1.23e+03 rew

agent-1: 53.0
agent-2: 30.0
agent-3: 49.0
agent-4: 45.0
agent-5: 41.0
agent-6: 53.0
agent-7: 26.0
agent-8: 41.0
agent-9: 35.0
agent-10: 47.0
agent-11: 61.0
agent-12: 11.0
agent-13: 55.0
agent-14: 34.0
agent-15: 32.0
agent-16: 69.0
agent-17: 39.0
agent-18: 33.0
agent-19: 32.0
agent-20: 32.0
agent-21: 32.0
agent-22: 24.0
agent-23: 55.0
agent-24: 61.0
agent-25: 44.0
agent-26: 62.0
agent-27: 50.0
agent-28: 21.0
agent-29: 41.0
agent-30: 44.0
Sum Reward: 1252.0
Avg Reward: 41.733333333333334
Min Reward: 11.0
Max Reward: 69.0
Gini Coefficient: 0.18061767838125667
20:20 Ratio: 2.5208333333333335
Max-min Ratio: 6.2727272727272725
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-28-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1226.79
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 276
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.282
    dispatch_time_ms: 8.36
    learner:
      cur_lr: 0.0008085520239546895
      grad_gnorm: 40.0
      policy_entropy: 140.6936798095703
      policy_loss: -16.17043113708496
      var_gnorm: 23.385719299316406
      vf_explained_var: 0.0
      vf_loss: 3.7053444385528564
    num_steps_sampled: 8310000
    num_steps_trained: 8310000
    wait_time_ms: 409.369
  iterations_since_restore: 277
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 12325.125421762466
  time_this_iter_s: 44.38656711578369
  time_total_s: 12325.125421762466
  timestamp: 1594164508
  timesteps_since_restore: 8310000
  timesteps_this_iter: 30000
  timesteps_total: 8310000
  training_iteration: 277
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 53.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 12325 s, 277 iter, 8310000 ts, 1.23e+03 rew

agent-1: 50.0
agent-2: 46.0
agent-3: 68.0
agent-4: 37.0
agent-5: 73.0
agent-6: 64.0
agent-7: 39.0
agent-8: 27.0
agent-9: 70.0
agent-10: 48.0
agent-11: 43.0
agent-12: 40.0
agent-13: 44.0
agent-14: 37.0
agent-15: 38.0
agent-16: 35.0
agent-17: 73.0
agent-18: 48.0
agent-19: 36.0
agent-20: 36.0
agent-21: 38.0
agent-22: 72.0
agent-23: 45.0
agent-24: 31.0
agent-25: 67.0
agent-26: 37.0
agent-27: 37.0
agent-28: 32.0
agent-29: 12.0
agent-30: 41.0
Sum Reward: 1364.0
Avg Reward: 45.46666666666667
Min Reward: 12.0
Max Reward: 73.0
Gini Coefficient: 0.17839687194525905
20:20 Ratio: 2.445086705202312
Max-min Ratio: 6.083333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-29-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1229.22
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 277
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.613
    dispatch_time_ms: 5.938
    learner:
      cur_lr: 0.0008065539877861738
      grad_gnorm: 35.08491897583008
      policy_entropy: 156.3966522216797
      policy_loss: 4.1680006980896
      var_gnorm: 23.389141082763672
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 82.86381530761719
    num_steps_sampled: 8340000
    num_steps_trained: 8340000
    wait_time_ms: 450.299
  iterations_since_restore: 278
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 12368.374976158142
  time_this_iter_s: 43.24955439567566
  time_total_s: 12368.374976158142
  timestamp: 1594164551
  timesteps_since_restore: 8340000
  timesteps_this_iter: 30000
  timesteps_total: 8340000
  training_iteration: 278
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 53.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 12368 s, 278 iter, 8340000 ts, 1.23e+03 rew

agent-1: 31.0
agent-2: 25.0
agent-3: 35.0
agent-4: 58.0
agent-5: 8.0
agent-6: 47.0
agent-7: 42.0
agent-8: 44.0
agent-9: 26.0
agent-10: 55.0
agent-11: 47.0
agent-12: 60.0
agent-13: 59.0
agent-14: 24.0
agent-15: 51.0
agent-16: 50.0
agent-17: 18.0
agent-18: 52.0
agent-19: 17.0
agent-20: 47.0
agent-21: 47.0
agent-22: 44.0
agent-23: 48.0
agent-24: 26.0
agent-25: 53.0
agent-26: 21.0
agent-27: 53.0
agent-28: 33.0
agent-29: 62.0
agent-30: 18.0
Sum Reward: 1201.0
Avg Reward: 40.03333333333333
Min Reward: 8.0
Max Reward: 62.0
Gini Coefficient: 0.21074104912572855
20:20 Ratio: 3.2735849056603774
Max-min Ratio: 7.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-29-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1227.7
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 278
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.521
    dispatch_time_ms: 6.474
    learner:
      cur_lr: 0.000804556009825319
      grad_gnorm: 40.0
      policy_entropy: 227.5905303955078
      policy_loss: -21.671390533447266
      var_gnorm: 23.38441276550293
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 7.475163459777832
    num_steps_sampled: 8370000
    num_steps_trained: 8370000
    wait_time_ms: 425.897
  iterations_since_restore: 279
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 12412.861720561981
  time_this_iter_s: 44.48674440383911
  time_total_s: 12412.861720561981
  timestamp: 1594164596
  timesteps_since_restore: 8370000
  timesteps_this_iter: 30000
  timesteps_total: 8370000
  training_iteration: 279
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 56.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 12412 s, 279 iter, 8370000 ts, 1.23e+03 rew

agent-1: 46.0
agent-2: 19.0
agent-3: 37.0
agent-4: 25.0
agent-5: 35.0
agent-6: 42.0
agent-7: 45.0
agent-8: 69.0
agent-9: 50.0
agent-10: 39.0
agent-11: 34.0
agent-12: 52.0
agent-13: 26.0
agent-14: 17.0
agent-15: 35.0
agent-16: 36.0
agent-17: 24.0
agent-18: 39.0
agent-19: 44.0
agent-20: 29.0
agent-21: 32.0
agent-22: 31.0
agent-23: 45.0
agent-24: 51.0
agent-25: 33.0
agent-26: 42.0
agent-27: 61.0
agent-28: 57.0
agent-29: 33.0
agent-30: 46.0
Sum Reward: 1174.0
Avg Reward: 39.13333333333333
Min Reward: 17.0
Max Reward: 69.0
Gini Coefficient: 0.1689381033503691
20:20 Ratio: 2.4285714285714284
Max-min Ratio: 4.0588235294117645
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-30-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1224.91
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 279
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.624
    dispatch_time_ms: 7.704
    learner:
      cur_lr: 0.0008025579736568034
      grad_gnorm: 40.0
      policy_entropy: 172.80691528320312
      policy_loss: 56.10654830932617
      var_gnorm: 23.387357711791992
      vf_explained_var: 0.0
      vf_loss: 157.6161346435547
    num_steps_sampled: 8400000
    num_steps_trained: 8400000
    wait_time_ms: 436.654
  iterations_since_restore: 280
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 12459.226393461227
  time_this_iter_s: 46.364672899246216
  time_total_s: 12459.226393461227
  timestamp: 1594164642
  timesteps_since_restore: 8400000
  timesteps_this_iter: 30000
  timesteps_total: 8400000
  training_iteration: 280
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 56.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 12459 s, 280 iter, 8400000 ts, 1.22e+03 rew

agent-1: 48.0
agent-2: 77.0
agent-3: 13.0
agent-4: 39.0
agent-5: 46.0
agent-6: 44.0
agent-7: 46.0
agent-8: 47.0
agent-9: 62.0
agent-10: 39.0
agent-11: 87.0
agent-12: 41.0
agent-13: 39.0
agent-14: 30.0
agent-15: 56.0
agent-16: 51.0
agent-17: 31.0
agent-18: 55.0
agent-19: 53.0
agent-20: 12.0
agent-21: 29.0
agent-22: 36.0
agent-23: 26.0
agent-24: 29.0
agent-25: 55.0
agent-26: 47.0
agent-27: 52.0
agent-28: 27.0
agent-29: 45.0
agent-30: 36.0
Sum Reward: 1298.0
Avg Reward: 43.266666666666666
Min Reward: 12.0
Max Reward: 87.0
Gini Coefficient: 0.19830508474576272
20:20 Ratio: 2.8823529411764706
Max-min Ratio: 7.25
W0707 19:31:25.093394 10987 node_manager.cc:250] Last heartbeat was sent 1213 ms ago 
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-31-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1225.96
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 280
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.939
    dispatch_time_ms: 9.302
    learner:
      cur_lr: 0.0008005599956959486
      grad_gnorm: 40.0
      policy_entropy: 210.8194580078125
      policy_loss: 24.85323143005371
      var_gnorm: 23.385452270507812
      vf_explained_var: 0.0
      vf_loss: 69.50726318359375
    num_steps_sampled: 8430000
    num_steps_trained: 8430000
    wait_time_ms: 400.373
  iterations_since_restore: 281
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 12502.07553601265
  time_this_iter_s: 42.84914255142212
  time_total_s: 12502.07553601265
  timestamp: 1594164687
  timesteps_since_restore: 8430000
  timesteps_this_iter: 30000
  timesteps_total: 8430000
  training_iteration: 281
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 56.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 12502 s, 281 iter, 8430000 ts, 1.23e+03 rew

agent-1: 15.0
agent-2: 21.0
agent-3: 31.0
agent-4: 25.0
agent-5: 62.0
agent-6: 51.0
agent-7: 9.0
agent-8: 56.0
agent-9: 30.0
agent-10: 47.0
agent-11: 43.0
agent-12: 38.0
agent-13: 26.0
agent-14: 32.0
agent-15: 41.0
agent-16: 35.0
agent-17: 30.0
agent-18: 42.0
agent-19: 43.0
agent-20: 48.0
agent-21: 30.0
agent-22: 39.0
agent-23: 23.0
agent-24: 39.0
agent-25: 44.0
agent-26: 40.0
agent-27: 40.0
agent-28: 18.0
agent-29: 64.0
agent-30: 38.0
Sum Reward: 1100.0
Avg Reward: 36.666666666666664
Min Reward: 9.0
Max Reward: 64.0
Gini Coefficient: 0.19466666666666665
20:20 Ratio: 2.954954954954955
Max-min Ratio: 7.111111111111111
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-32-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1221.81
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 281
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.909
    dispatch_time_ms: 6.344
    learner:
      cur_lr: 0.0007985620177350938
      grad_gnorm: 40.000003814697266
      policy_entropy: 184.05398559570312
      policy_loss: 21.982948303222656
      var_gnorm: 23.390838623046875
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 83.08023834228516
    num_steps_sampled: 8460000
    num_steps_trained: 8460000
    wait_time_ms: 460.353
  iterations_since_restore: 282
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 12545.822593450546
  time_this_iter_s: 43.74705743789673
  time_total_s: 12545.822593450546
  timestamp: 1594164731
  timesteps_since_restore: 8460000
  timesteps_this_iter: 30000
  timesteps_total: 8460000
  training_iteration: 282
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 56.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 12545 s, 282 iter, 8460000 ts, 1.22e+03 rew

agent-1: 42.0
agent-2: 32.0
agent-3: 32.0
agent-4: 30.0
agent-5: 49.0
agent-6: 37.0
agent-7: 26.0
agent-8: 30.0
agent-9: 9.0
agent-10: 54.0
agent-11: 41.0
agent-12: 23.0
agent-13: 62.0
agent-14: 45.0
agent-15: 36.0
agent-16: 36.0
agent-17: 42.0
agent-18: 66.0
agent-19: 43.0
agent-20: 56.0
agent-21: 21.0
agent-22: 55.0
agent-23: 37.0
agent-24: 61.0
agent-25: 34.0
agent-26: 33.0
agent-27: 41.0
agent-28: 42.0
agent-29: 50.0
agent-30: 27.0
Sum Reward: 1192.0
Avg Reward: 39.733333333333334
Min Reward: 9.0
Max Reward: 66.0
Gini Coefficient: 0.18115212527964206
20:20 Ratio: 2.6029411764705883
Max-min Ratio: 7.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-33-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1221.51
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 282
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.685
    dispatch_time_ms: 155.93
    learner:
      cur_lr: 0.0007965639815665781
      grad_gnorm: 40.0
      policy_entropy: 144.3558349609375
      policy_loss: 41.302330017089844
      var_gnorm: 23.39124298095703
      vf_explained_var: 0.0
      vf_loss: 84.94651794433594
    num_steps_sampled: 8490000
    num_steps_trained: 8490000
    wait_time_ms: 527.358
  iterations_since_restore: 283
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 12595.496679544449
  time_this_iter_s: 49.67408609390259
  time_total_s: 12595.496679544449
  timestamp: 1594164780
  timesteps_since_restore: 8490000
  timesteps_this_iter: 30000
  timesteps_total: 8490000
  training_iteration: 283
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 56.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 12595 s, 283 iter, 8490000 ts, 1.22e+03 rew

agent-1: 31.0
agent-2: 45.0
agent-3: 33.0
agent-4: 31.0
agent-5: 59.0
agent-6: 61.0
agent-7: 55.0
agent-8: 44.0
agent-9: 26.0
agent-10: 35.0
agent-11: 39.0
agent-12: 61.0
agent-13: 48.0
agent-14: 36.0
agent-15: 48.0
agent-16: 27.0
agent-17: 42.0
agent-18: 35.0
agent-19: 34.0
agent-20: 25.0
agent-21: 43.0
agent-22: 66.0
agent-23: 32.0
agent-24: 41.0
agent-25: 55.0
agent-26: 38.0
agent-27: 38.0
agent-28: 50.0
agent-29: 51.0
agent-30: 31.0
Sum Reward: 1260.0
Avg Reward: 42.0
Min Reward: 25.0
Max Reward: 66.0
Gini Coefficient: 0.15015873015873016
20:20 Ratio: 2.087719298245614
Max-min Ratio: 2.64
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-33-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1221.38
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 283
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.457
    dispatch_time_ms: 28.609
    learner:
      cur_lr: 0.0007945660036057234
      grad_gnorm: 40.0
      policy_entropy: 174.5759735107422
      policy_loss: -13.964336395263672
      var_gnorm: 23.393205642700195
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 18.028057098388672
    num_steps_sampled: 8520000
    num_steps_trained: 8520000
    wait_time_ms: 433.266
  iterations_since_restore: 284
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 12646.966233968735
  time_this_iter_s: 51.46955442428589
  time_total_s: 12646.966233968735
  timestamp: 1594164832
  timesteps_since_restore: 8520000
  timesteps_this_iter: 30000
  timesteps_total: 8520000
  training_iteration: 284
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 12646 s, 284 iter, 8520000 ts, 1.22e+03 rew

agent-1: 35.0
agent-2: 23.0
agent-3: 39.0
agent-4: 45.0
agent-5: 67.0
agent-6: 53.0
agent-7: 53.0
agent-8: 39.0
agent-9: 53.0
agent-10: 39.0
agent-11: 84.0
agent-12: 24.0
agent-13: 40.0
agent-14: 36.0
agent-15: 80.0
agent-16: 30.0
agent-17: 20.0
agent-18: 64.0
agent-19: 56.0
agent-20: 64.0
agent-21: 28.0
agent-22: 41.0
agent-23: 93.0
agent-24: 63.0
agent-25: 38.0
agent-26: 43.0
agent-27: 47.0
agent-28: 36.0
agent-29: 59.0
agent-30: 56.0
Sum Reward: 1448.0
Avg Reward: 48.266666666666666
Min Reward: 20.0
Max Reward: 93.0
Gini Coefficient: 0.20395948434622468
20:20 Ratio: 2.825
Max-min Ratio: 4.65
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-34-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1225.44
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 284
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.577
    dispatch_time_ms: 59.501
    learner:
      cur_lr: 0.0007925680256448686
      grad_gnorm: 40.000003814697266
      policy_entropy: 143.12234497070312
      policy_loss: 70.50178527832031
      var_gnorm: 23.391727447509766
      vf_explained_var: 0.0
      vf_loss: 135.4419403076172
    num_steps_sampled: 8550000
    num_steps_trained: 8550000
    wait_time_ms: 400.753
  iterations_since_restore: 285
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 12692.6235165596
  time_this_iter_s: 45.65728259086609
  time_total_s: 12692.6235165596
  timestamp: 1594164878
  timesteps_since_restore: 8550000
  timesteps_this_iter: 30000
  timesteps_total: 8550000
  training_iteration: 285
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 12692 s, 285 iter, 8550000 ts, 1.23e+03 rew

agent-1: 41.0
agent-2: 38.0
agent-3: 60.0
agent-4: 42.0
agent-5: 45.0
agent-6: 28.0
agent-7: 39.0
agent-8: 41.0
agent-9: 58.0
agent-10: 23.0
agent-11: 40.0
agent-12: 33.0
agent-13: 4.0
agent-14: 35.0
agent-15: 70.0
agent-16: 42.0
agent-17: 34.0
agent-18: 25.0
agent-19: 41.0
agent-20: 42.0
agent-21: 38.0
agent-22: 38.0
agent-23: 27.0
agent-24: 40.0
agent-25: 44.0
agent-26: 43.0
agent-27: 84.0
agent-28: 28.0
agent-29: 44.0
agent-30: 13.0
Sum Reward: 1180.0
Avg Reward: 39.333333333333336
Min Reward: 4.0
Max Reward: 84.0
Gini Coefficient: 0.19508474576271187
20:20 Ratio: 3.0083333333333333
Max-min Ratio: 21.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-35-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1225.96
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 285
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.472
    dispatch_time_ms: 5.63
    learner:
      cur_lr: 0.0007905699894763529
      grad_gnorm: 40.0
      policy_entropy: 161.6945037841797
      policy_loss: -25.228015899658203
      var_gnorm: 23.394887924194336
      vf_explained_var: 0.0
      vf_loss: 11.133283615112305
    num_steps_sampled: 8580000
    num_steps_trained: 8580000
    wait_time_ms: 448.343
  iterations_since_restore: 286
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 12736.111477136612
  time_this_iter_s: 43.48796057701111
  time_total_s: 12736.111477136612
  timestamp: 1594164921
  timesteps_since_restore: 8580000
  timesteps_this_iter: 30000
  timesteps_total: 8580000
  training_iteration: 286
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 12736 s, 286 iter, 8580000 ts, 1.23e+03 rew

agent-1: 11.0
agent-2: 68.0
agent-3: 50.0
agent-4: 43.0
agent-5: 53.0
agent-6: 25.0
agent-7: 56.0
agent-8: 22.0
agent-9: 62.0
agent-10: 29.0
agent-11: 54.0
agent-12: 67.0
agent-13: 27.0
agent-14: 37.0
agent-15: 38.0
agent-16: 43.0
agent-17: 23.0
agent-18: 55.0
agent-19: 53.0
agent-20: 36.0
agent-21: 41.0
agent-22: 63.0
agent-23: 38.0
agent-24: 35.0
agent-25: 63.0
agent-26: 16.0
agent-27: 54.0
agent-28: 56.0
agent-29: 48.0
agent-30: 18.0
Sum Reward: 1284.0
Avg Reward: 42.8
Min Reward: 11.0
Max Reward: 68.0
Gini Coefficient: 0.21194184839044652
20:20 Ratio: 3.2956521739130435
Max-min Ratio: 6.181818181818182
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-36-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1227.74
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 286
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.882
    dispatch_time_ms: 6.787
    learner:
      cur_lr: 0.0007885720115154982
      grad_gnorm: 39.999996185302734
      policy_entropy: 138.26657104492188
      policy_loss: 30.809396743774414
      var_gnorm: 23.396162033081055
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 74.45032501220703
    num_steps_sampled: 8610000
    num_steps_trained: 8610000
    wait_time_ms: 432.59
  iterations_since_restore: 287
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 12779.863860845566
  time_this_iter_s: 43.75238370895386
  time_total_s: 12779.863860845566
  timestamp: 1594164965
  timesteps_since_restore: 8610000
  timesteps_this_iter: 30000
  timesteps_total: 8610000
  training_iteration: 287
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 12779 s, 287 iter, 8610000 ts, 1.23e+03 rew

agent-1: 41.0
agent-2: 66.0
agent-3: 56.0
agent-4: 52.0
agent-5: 45.0
agent-6: 42.0
agent-7: 74.0
agent-8: 43.0
agent-9: 45.0
agent-10: 45.0
agent-11: 53.0
agent-12: 73.0
agent-13: 43.0
agent-14: 49.0
agent-15: 57.0
agent-16: 26.0
agent-17: 75.0
agent-18: 51.0
agent-19: 29.0
agent-20: 56.0
agent-21: 41.0
agent-22: 55.0
agent-23: 59.0
agent-24: 45.0
agent-25: 40.0
agent-26: 40.0
agent-27: 41.0
agent-28: 22.0
agent-29: 77.0
agent-30: 16.0
Sum Reward: 1457.0
Avg Reward: 48.56666666666667
Min Reward: 16.0
Max Reward: 77.0
Gini Coefficient: 0.16813086250285975
20:20 Ratio: 2.4508670520231215
Max-min Ratio: 4.8125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-36-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1229.48
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 287
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.681
    dispatch_time_ms: 8.409
    learner:
      cur_lr: 0.0007865739753469825
      grad_gnorm: 40.0
      policy_entropy: 155.707763671875
      policy_loss: -3.1832547187805176
      var_gnorm: 23.397233963012695
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 63.517391204833984
    num_steps_sampled: 8640000
    num_steps_trained: 8640000
    wait_time_ms: 435.31
  iterations_since_restore: 288
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 12823.90449976921
  time_this_iter_s: 44.04063892364502
  time_total_s: 12823.90449976921
  timestamp: 1594165009
  timesteps_since_restore: 8640000
  timesteps_this_iter: 30000
  timesteps_total: 8640000
  training_iteration: 288
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 12823 s, 288 iter, 8640000 ts, 1.23e+03 rew

agent-1: 67.0
agent-2: 42.0
agent-3: 45.0
agent-4: 31.0
agent-5: 50.0
agent-6: 43.0
agent-7: 22.0
agent-8: 33.0
agent-9: 48.0
agent-10: 17.0
agent-11: 24.0
agent-12: 28.0
agent-13: 26.0
agent-14: 80.0
agent-15: 54.0
agent-16: 59.0
agent-17: 58.0
agent-18: 36.0
agent-19: 59.0
agent-20: 19.0
agent-21: 47.0
agent-22: 56.0
agent-23: 21.0
agent-24: 27.0
agent-25: 40.0
agent-26: 43.0
agent-27: 32.0
agent-28: 43.0
agent-29: 45.0
agent-30: 48.0
Sum Reward: 1243.0
Avg Reward: 41.43333333333333
Min Reward: 17.0
Max Reward: 80.0
Gini Coefficient: 0.20410297666934835
20:20 Ratio: 2.937984496124031
Max-min Ratio: 4.705882352941177
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-37-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1228.38
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 288
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.492
    dispatch_time_ms: 39.155
    learner:
      cur_lr: 0.0007845759973861277
      grad_gnorm: 40.000003814697266
      policy_entropy: 177.074951171875
      policy_loss: -20.290050506591797
      var_gnorm: 23.393571853637695
      vf_explained_var: 0.0
      vf_loss: 27.63680076599121
    num_steps_sampled: 8670000
    num_steps_trained: 8670000
    wait_time_ms: 447.509
  iterations_since_restore: 289
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 12869.242122411728
  time_this_iter_s: 45.33762264251709
  time_total_s: 12869.242122411728
  timestamp: 1594165054
  timesteps_since_restore: 8670000
  timesteps_this_iter: 30000
  timesteps_total: 8670000
  training_iteration: 289
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 12869 s, 289 iter, 8670000 ts, 1.23e+03 rew

agent-1: 28.0
agent-2: 44.0
agent-3: 26.0
agent-4: 52.0
agent-5: 48.0
agent-6: 20.0
agent-7: 20.0
agent-8: 47.0
agent-9: 38.0
agent-10: 32.0
agent-11: 51.0
agent-12: 42.0
agent-13: 49.0
agent-14: 38.0
agent-15: 39.0
agent-16: 41.0
agent-17: 43.0
agent-18: 74.0
agent-19: 35.0
agent-20: 24.0
agent-21: 28.0
agent-22: 45.0
agent-23: 21.0
agent-24: 16.0
agent-25: 42.0
agent-26: 24.0
agent-27: 43.0
agent-28: 26.0
agent-29: 60.0
agent-30: 28.0
Sum Reward: 1124.0
Avg Reward: 37.46666666666667
Min Reward: 16.0
Max Reward: 74.0
Gini Coefficient: 0.19270462633451957
20:20 Ratio: 2.672
Max-min Ratio: 4.625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-38-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1226.92
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 289
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.701
    dispatch_time_ms: 23.314
    learner:
      cur_lr: 0.0007825780194252729
      grad_gnorm: 40.0
      policy_entropy: 140.99014282226562
      policy_loss: 31.089521408081055
      var_gnorm: 23.39372444152832
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 103.92340850830078
    num_steps_sampled: 8700000
    num_steps_trained: 8700000
    wait_time_ms: 441.561
  iterations_since_restore: 290
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 12914.863935709
  time_this_iter_s: 45.62181329727173
  time_total_s: 12914.863935709
  timestamp: 1594165100
  timesteps_since_restore: 8700000
  timesteps_this_iter: 30000
  timesteps_total: 8700000
  training_iteration: 290
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 12914 s, 290 iter, 8700000 ts, 1.23e+03 rew

agent-1: 22.0
agent-2: 33.0
agent-3: 35.0
agent-4: 56.0
agent-5: 42.0
agent-6: 37.0
agent-7: 49.0
agent-8: 31.0
agent-9: 50.0
agent-10: 26.0
agent-11: 31.0
agent-12: 63.0
agent-13: 40.0
agent-14: 27.0
agent-15: 15.0
agent-16: 27.0
agent-17: 39.0
agent-18: 60.0
agent-19: 29.0
agent-20: 44.0
agent-21: 49.0
agent-22: 48.0
agent-23: 61.0
agent-24: 50.0
agent-25: 31.0
agent-26: 80.0
agent-27: 22.0
agent-28: 70.0
agent-29: 38.0
agent-30: 46.0
Sum Reward: 1251.0
Avg Reward: 41.7
Min Reward: 15.0
Max Reward: 80.0
Gini Coefficient: 0.20221156408206767
20:20 Ratio: 2.805755395683453
Max-min Ratio: 5.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-39-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1224.6
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 290
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.615
    dispatch_time_ms: 36.778
    learner:
      cur_lr: 0.0007805799832567573
      grad_gnorm: 39.119361877441406
      policy_entropy: 147.3135223388672
      policy_loss: -13.042834281921387
      var_gnorm: 23.393604278564453
      vf_explained_var: 0.0
      vf_loss: 73.5406723022461
    num_steps_sampled: 8730000
    num_steps_trained: 8730000
    wait_time_ms: 456.556
  iterations_since_restore: 291
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 12960.795582056046
  time_this_iter_s: 45.9316463470459
  time_total_s: 12960.795582056046
  timestamp: 1594165146
  timesteps_since_restore: 8730000
  timesteps_this_iter: 30000
  timesteps_total: 8730000
  training_iteration: 291
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 12960 s, 291 iter, 8730000 ts, 1.22e+03 rew

agent-1: 35.0
agent-2: 45.0
agent-3: 43.0
agent-4: 48.0
agent-5: 48.0
agent-6: 47.0
agent-7: 19.0
agent-8: 28.0
agent-9: 35.0
agent-10: 51.0
agent-11: 55.0
agent-12: 42.0
agent-13: 43.0
agent-14: 31.0
agent-15: 40.0
agent-16: 73.0
agent-17: 37.0
agent-18: 46.0
agent-19: 46.0
agent-20: 18.0
agent-21: 44.0
agent-22: 41.0
agent-23: 36.0
agent-24: 41.0
agent-25: 33.0
agent-26: 21.0
agent-27: 26.0
agent-28: 45.0
agent-29: 31.0
agent-30: 58.0
Sum Reward: 1206.0
Avg Reward: 40.2
Min Reward: 18.0
Max Reward: 73.0
Gini Coefficient: 0.1572139303482587
20:20 Ratio: 2.3286713286713288
Max-min Ratio: 4.055555555555555
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-39-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1225.85
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 291
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.607
    dispatch_time_ms: 28.987
    learner:
      cur_lr: 0.0007785820052959025
      grad_gnorm: 35.686378479003906
      policy_entropy: 143.29554748535156
      policy_loss: 10.75692081451416
      var_gnorm: 23.397817611694336
      vf_explained_var: 0.0
      vf_loss: 75.26702117919922
    num_steps_sampled: 8760000
    num_steps_trained: 8760000
    wait_time_ms: 432.266
  iterations_since_restore: 292
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 13005.727786540985
  time_this_iter_s: 44.932204484939575
  time_total_s: 13005.727786540985
  timestamp: 1594165191
  timesteps_since_restore: 8760000
  timesteps_this_iter: 30000
  timesteps_total: 8760000
  training_iteration: 292
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 13005 s, 292 iter, 8760000 ts, 1.23e+03 rew

agent-1: 51.0
agent-2: 54.0
agent-3: 46.0
agent-4: 73.0
agent-5: 56.0
agent-6: 35.0
agent-7: 31.0
agent-8: 54.0
agent-9: 58.0
agent-10: 53.0
agent-11: 70.0
agent-12: 55.0
agent-13: 39.0
agent-14: 58.0
agent-15: 49.0
agent-16: 56.0
agent-17: 40.0
agent-18: 58.0
agent-19: 18.0
agent-20: 39.0
agent-21: 37.0
agent-22: 46.0
agent-23: 51.0
agent-24: 29.0
agent-25: 63.0
agent-26: 45.0
agent-27: 50.0
agent-28: 62.0
agent-29: 70.0
agent-30: 66.0
Sum Reward: 1512.0
Avg Reward: 50.4
Min Reward: 18.0
Max Reward: 73.0
Gini Coefficient: 0.14126984126984127
20:20 Ratio: 2.1375661375661377
Max-min Ratio: 4.055555555555555
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-40-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1231.86
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 292
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.962
    dispatch_time_ms: 31.976
    learner:
      cur_lr: 0.0007765840273350477
      grad_gnorm: 39.99999237060547
      policy_entropy: 139.35243225097656
      policy_loss: -0.2875882387161255
      var_gnorm: 23.399002075195312
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 74.58316040039062
    num_steps_sampled: 8790000
    num_steps_trained: 8790000
    wait_time_ms: 403.499
  iterations_since_restore: 293
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 13050.63976597786
  time_this_iter_s: 44.91197943687439
  time_total_s: 13050.63976597786
  timestamp: 1594165236
  timesteps_since_restore: 8790000
  timesteps_this_iter: 30000
  timesteps_total: 8790000
  training_iteration: 293
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 13050 s, 293 iter, 8790000 ts, 1.23e+03 rew

agent-1: 64.0
agent-2: 44.0
agent-3: 48.0
agent-4: 43.0
agent-5: 40.0
agent-6: 28.0
agent-7: 49.0
agent-8: 34.0
agent-9: 43.0
agent-10: 52.0
agent-11: 80.0
agent-12: 37.0
agent-13: 40.0
agent-14: 34.0
agent-15: 45.0
agent-16: 67.0
agent-17: 47.0
agent-18: 33.0
agent-19: 35.0
agent-20: 47.0
agent-21: 60.0
agent-22: 44.0
agent-23: 38.0
agent-24: 29.0
agent-25: 32.0
agent-26: 55.0
agent-27: 56.0
agent-28: 46.0
agent-29: 62.0
agent-30: 16.0
Sum Reward: 1348.0
Avg Reward: 44.93333333333333
Min Reward: 16.0
Max Reward: 80.0
Gini Coefficient: 0.1599901088031652
20:20 Ratio: 2.261627906976744
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-41-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1233.28
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 293
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.825
    dispatch_time_ms: 5.747
    learner:
      cur_lr: 0.000774585991166532
      grad_gnorm: 24.046344757080078
      policy_entropy: 132.35723876953125
      policy_loss: -5.140202522277832
      var_gnorm: 23.39927101135254
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 43.42398452758789
    num_steps_sampled: 8820000
    num_steps_trained: 8820000
    wait_time_ms: 451.127
  iterations_since_restore: 294
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 13094.758544683456
  time_this_iter_s: 44.118778705596924
  time_total_s: 13094.758544683456
  timestamp: 1594165280
  timesteps_since_restore: 8820000
  timesteps_this_iter: 30000
  timesteps_total: 8820000
  training_iteration: 294
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 13094 s, 294 iter, 8820000 ts, 1.23e+03 rew

agent-1: 39.0
agent-2: 39.0
agent-3: 34.0
agent-4: 38.0
agent-5: 42.0
agent-6: 41.0
agent-7: 59.0
agent-8: 67.0
agent-9: 56.0
agent-10: 21.0
agent-11: 24.0
agent-12: 42.0
agent-13: 35.0
agent-14: 72.0
agent-15: 59.0
agent-16: 33.0
agent-17: 36.0
agent-18: 52.0
agent-19: 41.0
agent-20: 39.0
agent-21: 52.0
agent-22: 58.0
agent-23: 53.0
agent-24: 48.0
agent-25: 43.0
agent-26: 47.0
agent-27: 44.0
agent-28: 25.0
agent-29: 36.0
agent-30: 25.0
Sum Reward: 1300.0
Avg Reward: 43.333333333333336
Min Reward: 21.0
Max Reward: 72.0
Gini Coefficient: 0.15923076923076923
20:20 Ratio: 2.2901234567901234
Max-min Ratio: 3.4285714285714284
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-42-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1234.03
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 294
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.974
    dispatch_time_ms: 6.038
    learner:
      cur_lr: 0.0007725880132056773
      grad_gnorm: 40.0
      policy_entropy: 141.9442901611328
      policy_loss: -1.6223808526992798
      var_gnorm: 23.398080825805664
      vf_explained_var: 0.0
      vf_loss: 46.20487594604492
    num_steps_sampled: 8850000
    num_steps_trained: 8850000
    wait_time_ms: 414.357
  iterations_since_restore: 295
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 13138.177289247513
  time_this_iter_s: 43.4187445640564
  time_total_s: 13138.177289247513
  timestamp: 1594165323
  timesteps_since_restore: 8850000
  timesteps_this_iter: 30000
  timesteps_total: 8850000
  training_iteration: 295
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 13138 s, 295 iter, 8850000 ts, 1.23e+03 rew

agent-1: 24.0
agent-2: 28.0
agent-3: 37.0
agent-4: 52.0
agent-5: 43.0
agent-6: 58.0
agent-7: 62.0
agent-8: 52.0
agent-9: 36.0
agent-10: 54.0
agent-11: 63.0
agent-12: 46.0
agent-13: 42.0
agent-14: 50.0
agent-15: 33.0
agent-16: 36.0
agent-17: 49.0
agent-18: 31.0
agent-19: 63.0
agent-20: 73.0
agent-21: 35.0
agent-22: 47.0
agent-23: 55.0
agent-24: 35.0
agent-25: 50.0
agent-26: 66.0
agent-27: 60.0
agent-28: 24.0
agent-29: 47.0
agent-30: 40.0
Sum Reward: 1391.0
Avg Reward: 46.36666666666667
Min Reward: 24.0
Max Reward: 73.0
Gini Coefficient: 0.15655403786244906
20:20 Ratio: 2.2114285714285713
Max-min Ratio: 3.0416666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-42-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1232.59
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 295
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.542
    dispatch_time_ms: 6.281
    learner:
      cur_lr: 0.0007705899770371616
      grad_gnorm: 40.0
      policy_entropy: 182.48228454589844
      policy_loss: -15.82895278930664
      var_gnorm: 23.39822006225586
      vf_explained_var: 0.0
      vf_loss: 25.239269256591797
    num_steps_sampled: 8880000
    num_steps_trained: 8880000
    wait_time_ms: 445.913
  iterations_since_restore: 296
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 13182.185426712036
  time_this_iter_s: 44.008137464523315
  time_total_s: 13182.185426712036
  timestamp: 1594165368
  timesteps_since_restore: 8880000
  timesteps_this_iter: 30000
  timesteps_total: 8880000
  training_iteration: 296
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 13182 s, 296 iter, 8880000 ts, 1.23e+03 rew

agent-1: 46.0
agent-2: 32.0
agent-3: 56.0
agent-4: 57.0
agent-5: 41.0
agent-6: 52.0
agent-7: 47.0
agent-8: 53.0
agent-9: 37.0
agent-10: 30.0
agent-11: 21.0
agent-12: 31.0
agent-13: 62.0
agent-14: 57.0
agent-15: 64.0
agent-16: 11.0
agent-17: 38.0
agent-18: 28.0
agent-19: 53.0
agent-20: 35.0
agent-21: 66.0
agent-22: 46.0
agent-23: 30.0
agent-24: 67.0
agent-25: 57.0
agent-26: 46.0
agent-27: 35.0
agent-28: 56.0
agent-29: 38.0
agent-30: 37.0
Sum Reward: 1329.0
Avg Reward: 44.3
Min Reward: 11.0
Max Reward: 67.0
Gini Coefficient: 0.1762478053674442
20:20 Ratio: 2.4701986754966887
Max-min Ratio: 6.090909090909091
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-43-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1233.52
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 296
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.9
    dispatch_time_ms: 7.667
    learner:
      cur_lr: 0.0007685919990763068
      grad_gnorm: 40.0
      policy_entropy: 216.27676391601562
      policy_loss: 52.567359924316406
      var_gnorm: 23.400529861450195
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 149.583251953125
    num_steps_sampled: 8910000
    num_steps_trained: 8910000
    wait_time_ms: 414.444
  iterations_since_restore: 297
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 13225.754349946976
  time_this_iter_s: 43.568923234939575
  time_total_s: 13225.754349946976
  timestamp: 1594165411
  timesteps_since_restore: 8910000
  timesteps_this_iter: 30000
  timesteps_total: 8910000
  training_iteration: 297
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 13225 s, 297 iter, 8910000 ts, 1.23e+03 rew

agent-1: 63.0
agent-2: 42.0
agent-3: 51.0
agent-4: 37.0
agent-5: 57.0
agent-6: 41.0
agent-7: 63.0
agent-8: 46.0
agent-9: 37.0
agent-10: 78.0
agent-11: 33.0
agent-12: 33.0
agent-13: 23.0
agent-14: 42.0
agent-15: 55.0
agent-16: 52.0
agent-17: 39.0
agent-18: 27.0
agent-19: 40.0
agent-20: 33.0
agent-21: 49.0
agent-22: 14.0
agent-23: 19.0
agent-24: 25.0
agent-25: 44.0
agent-26: 47.0
agent-27: 19.0
agent-28: 29.0
agent-29: 41.0
agent-30: 58.0
Sum Reward: 1237.0
Avg Reward: 41.233333333333334
Min Reward: 14.0
Max Reward: 78.0
Gini Coefficient: 0.19744004311506333
20:20 Ratio: 2.9448818897637796
Max-min Ratio: 5.571428571428571
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-44-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1233.6
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 297
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.57
    dispatch_time_ms: 5.729
    learner:
      cur_lr: 0.000766594021115452
      grad_gnorm: 40.000003814697266
      policy_entropy: 192.51760864257812
      policy_loss: -11.890898704528809
      var_gnorm: 23.39678955078125
      vf_explained_var: 0.0
      vf_loss: 23.366046905517578
    num_steps_sampled: 8940000
    num_steps_trained: 8940000
    wait_time_ms: 443.678
  iterations_since_restore: 298
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 13270.163303375244
  time_this_iter_s: 44.40895342826843
  time_total_s: 13270.163303375244
  timestamp: 1594165456
  timesteps_since_restore: 8940000
  timesteps_this_iter: 30000
  timesteps_total: 8940000
  training_iteration: 298
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 13270 s, 298 iter, 8940000 ts, 1.23e+03 rew

agent-1: 33.0
agent-2: 40.0
agent-3: 18.0
agent-4: 51.0
agent-5: 57.0
agent-6: 37.0
agent-7: 40.0
agent-8: 30.0
agent-9: 27.0
agent-10: 55.0
agent-11: 54.0
agent-12: 43.0
agent-13: 49.0
agent-14: 26.0
agent-15: 22.0
agent-16: 40.0
agent-17: 37.0
agent-18: 29.0
agent-19: 29.0
agent-20: 39.0
agent-21: 28.0
agent-22: 29.0
agent-23: 25.0
agent-24: 54.0
agent-25: 25.0
agent-26: 23.0
agent-27: 35.0
agent-28: 42.0
agent-29: 57.0
agent-30: 41.0
Sum Reward: 1115.0
Avg Reward: 37.166666666666664
Min Reward: 18.0
Max Reward: 57.0
Gini Coefficient: 0.17168908819133033
20:20 Ratio: 2.3597122302158273
Max-min Ratio: 3.1666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-45-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1234.26
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 298
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.393
    dispatch_time_ms: 61.308
    learner:
      cur_lr: 0.0007645959849469364
      grad_gnorm: 40.0
      policy_entropy: 246.59725952148438
      policy_loss: -42.244876861572266
      var_gnorm: 23.399507522583008
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.537599086761475
    num_steps_sampled: 8970000
    num_steps_trained: 8970000
    wait_time_ms: 390.432
  iterations_since_restore: 299
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 13315.30591392517
  time_this_iter_s: 45.14261054992676
  time_total_s: 13315.30591392517
  timestamp: 1594165501
  timesteps_since_restore: 8970000
  timesteps_this_iter: 30000
  timesteps_total: 8970000
  training_iteration: 299
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 13315 s, 299 iter, 8970000 ts, 1.23e+03 rew

agent-1: 56.0
agent-2: 21.0
agent-3: 50.0
agent-4: 14.0
agent-5: 64.0
agent-6: 85.0
agent-7: 38.0
agent-8: 29.0
agent-9: 44.0
agent-10: 53.0
agent-11: 64.0
agent-12: 50.0
agent-13: 36.0
agent-14: 53.0
agent-15: 31.0
agent-16: 26.0
agent-17: 51.0
agent-18: 32.0
agent-19: 53.0
agent-20: 55.0
agent-21: 22.0
agent-22: 61.0
agent-23: 23.0
agent-24: 15.0
agent-25: 45.0
agent-26: 36.0
agent-27: 51.0
agent-28: 13.0
agent-29: 40.0
agent-30: 23.0
Sum Reward: 1234.0
Avg Reward: 41.13333333333333
Min Reward: 13.0
Max Reward: 85.0
Gini Coefficient: 0.235440302539168
20:20 Ratio: 3.564814814814815
Max-min Ratio: 6.538461538461538
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-45-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1232.7
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 299
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.748
    dispatch_time_ms: 5.245
    learner:
      cur_lr: 0.0007625980069860816
      grad_gnorm: 40.0
      policy_entropy: 218.009521484375
      policy_loss: -20.31139373779297
      var_gnorm: 23.397415161132812
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.4618635177612305
    num_steps_sampled: 9000000
    num_steps_trained: 9000000
    wait_time_ms: 447.226
  iterations_since_restore: 300
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 13359.368310928345
  time_this_iter_s: 44.06239700317383
  time_total_s: 13359.368310928345
  timestamp: 1594165545
  timesteps_since_restore: 9000000
  timesteps_this_iter: 30000
  timesteps_total: 9000000
  training_iteration: 300
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 13359 s, 300 iter, 9000000 ts, 1.23e+03 rew

agent-1: 37.0
agent-2: 34.0
agent-3: 45.0
agent-4: 44.0
agent-5: 45.0
agent-6: 25.0
agent-7: 25.0
agent-8: 46.0
agent-9: 41.0
agent-10: 52.0
agent-11: 24.0
agent-12: 50.0
agent-13: 27.0
agent-14: 37.0
agent-15: 39.0
agent-16: 29.0
agent-17: 21.0
agent-18: 35.0
agent-19: 17.0
agent-20: 55.0
agent-21: 15.0
agent-22: 44.0
agent-23: 52.0
agent-24: 19.0
agent-25: 42.0
agent-26: 30.0
agent-27: 14.0
agent-28: 62.0
agent-29: 61.0
agent-30: 50.0
Sum Reward: 1117.0
Avg Reward: 37.233333333333334
Min Reward: 14.0
Max Reward: 62.0
Gini Coefficient: 0.20540137272455983
20:20 Ratio: 3.018181818181818
Max-min Ratio: 4.428571428571429
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-46-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1230.79
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 300
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.919
    dispatch_time_ms: 5.914
    learner:
      cur_lr: 0.0007606000290252268
      grad_gnorm: 39.999996185302734
      policy_entropy: 199.9637451171875
      policy_loss: -29.92995262145996
      var_gnorm: 23.404460906982422
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 10.90447998046875
    num_steps_sampled: 9030000
    num_steps_trained: 9030000
    wait_time_ms: 432.877
  iterations_since_restore: 301
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 13403.800844430923
  time_this_iter_s: 44.432533502578735
  time_total_s: 13403.800844430923
  timestamp: 1594165589
  timesteps_since_restore: 9030000
  timesteps_this_iter: 30000
  timesteps_total: 9030000
  training_iteration: 301
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 13403 s, 301 iter, 9030000 ts, 1.23e+03 rew

agent-1: 35.0
agent-2: 23.0
agent-3: 26.0
agent-4: 53.0
agent-5: 49.0
agent-6: 36.0
agent-7: 53.0
agent-8: 26.0
agent-9: 30.0
agent-10: 53.0
agent-11: 30.0
agent-12: 45.0
agent-13: 40.0
agent-14: 68.0
agent-15: 45.0
agent-16: 26.0
agent-17: 35.0
agent-18: 83.0
agent-19: 48.0
agent-20: 54.0
agent-21: 64.0
agent-22: 26.0
agent-23: 36.0
agent-24: 35.0
agent-25: 17.0
agent-26: 10.0
agent-27: 41.0
agent-28: 31.0
agent-29: 61.0
agent-30: 52.0
Sum Reward: 1231.0
Avg Reward: 41.03333333333333
Min Reward: 10.0
Max Reward: 83.0
Gini Coefficient: 0.21578662334145682
20:20 Ratio: 2.9921875
Max-min Ratio: 8.3
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-47-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1232.4
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 301
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.541
    dispatch_time_ms: 5.803
    learner:
      cur_lr: 0.0007586019928567111
      grad_gnorm: 40.0
      policy_entropy: 214.81077575683594
      policy_loss: -24.80816650390625
      var_gnorm: 23.405385971069336
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.7446789741516113
    num_steps_sampled: 9060000
    num_steps_trained: 9060000
    wait_time_ms: 442.171
  iterations_since_restore: 302
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 13448.127977848053
  time_this_iter_s: 44.32713341712952
  time_total_s: 13448.127977848053
  timestamp: 1594165634
  timesteps_since_restore: 9060000
  timesteps_this_iter: 30000
  timesteps_total: 9060000
  training_iteration: 302
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 13448 s, 302 iter, 9060000 ts, 1.23e+03 rew

agent-1: 20.0
agent-2: 49.0
agent-3: 44.0
agent-4: 46.0
agent-5: 55.0
agent-6: 35.0
agent-7: 30.0
agent-8: 34.0
agent-9: 19.0
agent-10: 27.0
agent-11: 11.0
agent-12: 33.0
agent-13: 10.0
agent-14: 55.0
agent-15: 40.0
agent-16: 54.0
agent-17: 48.0
agent-18: 43.0
agent-19: 43.0
agent-20: 37.0
agent-21: 25.0
agent-22: 41.0
agent-23: 39.0
agent-24: 35.0
agent-25: 51.0
agent-26: 36.0
agent-27: 26.0
agent-28: 32.0
agent-29: 17.0
agent-30: 26.0
Sum Reward: 1061.0
Avg Reward: 35.36666666666667
Min Reward: 10.0
Max Reward: 55.0
Gini Coefficient: 0.19864907320138234
20:20 Ratio: 3.0588235294117645
Max-min Ratio: 5.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-47-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1229.27
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 302
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.081
    dispatch_time_ms: 7.541
    learner:
      cur_lr: 0.0007566040148958564
      grad_gnorm: 40.0
      policy_entropy: 164.0022430419922
      policy_loss: -28.364137649536133
      var_gnorm: 23.40882110595703
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 7.490420341491699
    num_steps_sampled: 9090000
    num_steps_trained: 9090000
    wait_time_ms: 440.328
  iterations_since_restore: 303
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 13491.872279405594
  time_this_iter_s: 43.744301557540894
  time_total_s: 13491.872279405594
  timestamp: 1594165678
  timesteps_since_restore: 9090000
  timesteps_this_iter: 30000
  timesteps_total: 9090000
  training_iteration: 303
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 13491 s, 303 iter, 9090000 ts, 1.23e+03 rew

agent-1: 27.0
agent-2: 30.0
agent-3: 43.0
agent-4: 32.0
agent-5: 31.0
agent-6: 28.0
agent-7: 55.0
agent-8: 39.0
agent-9: 47.0
agent-10: 38.0
agent-11: 48.0
agent-12: 21.0
agent-13: 49.0
agent-14: 32.0
agent-15: 33.0
agent-16: 48.0
agent-17: 54.0
agent-18: 70.0
agent-19: 63.0
agent-20: 49.0
agent-21: 45.0
agent-22: 33.0
agent-23: 47.0
agent-24: 44.0
agent-25: 33.0
agent-26: 30.0
agent-27: 51.0
agent-28: 69.0
agent-29: 49.0
agent-30: 27.0
Sum Reward: 1265.0
Avg Reward: 42.166666666666664
Min Reward: 21.0
Max Reward: 70.0
Gini Coefficient: 0.16397891963109354
20:20 Ratio: 2.2208588957055215
Max-min Ratio: 3.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-48-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1229.13
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 303
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.863
    dispatch_time_ms: 22.973
    learner:
      cur_lr: 0.0007546059787273407
      grad_gnorm: 40.000003814697266
      policy_entropy: 174.13351440429688
      policy_loss: 48.675804138183594
      var_gnorm: 23.40821647644043
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 118.64453125
    num_steps_sampled: 9120000
    num_steps_trained: 9120000
    wait_time_ms: 424.177
  iterations_since_restore: 304
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 13536.347464323044
  time_this_iter_s: 44.47518491744995
  time_total_s: 13536.347464323044
  timestamp: 1594165722
  timesteps_since_restore: 9120000
  timesteps_this_iter: 30000
  timesteps_total: 9120000
  training_iteration: 304
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 13536 s, 304 iter, 9120000 ts, 1.23e+03 rew

agent-1: 42.0
agent-2: 22.0
agent-3: 40.0
agent-4: 34.0
agent-5: 44.0
agent-6: 37.0
agent-7: 29.0
agent-8: 77.0
agent-9: 52.0
agent-10: 61.0
agent-11: 16.0
agent-12: 56.0
agent-13: 42.0
agent-14: 40.0
agent-15: 59.0
agent-16: 50.0
agent-17: 44.0
agent-18: 28.0
agent-19: 39.0
agent-20: 42.0
agent-21: 73.0
agent-22: 34.0
agent-23: 39.0
agent-24: 57.0
agent-25: 40.0
agent-26: 64.0
agent-27: 43.0
agent-28: 77.0
agent-29: 77.0
agent-30: 33.0
Sum Reward: 1391.0
Avg Reward: 46.36666666666667
Min Reward: 16.0
Max Reward: 77.0
Gini Coefficient: 0.18895279175653007
20:20 Ratio: 2.6481481481481484
Max-min Ratio: 4.8125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-49-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1228.79
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 304
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.208
    dispatch_time_ms: 5.534
    learner:
      cur_lr: 0.0007526080007664859
      grad_gnorm: 39.999996185302734
      policy_entropy: 201.0756072998047
      policy_loss: 30.268234252929688
      var_gnorm: 23.413312911987305
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 65.41027069091797
    num_steps_sampled: 9150000
    num_steps_trained: 9150000
    wait_time_ms: 413.16
  iterations_since_restore: 305
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 13579.476074695587
  time_this_iter_s: 43.128610372543335
  time_total_s: 13579.476074695587
  timestamp: 1594165765
  timesteps_since_restore: 9150000
  timesteps_this_iter: 30000
  timesteps_total: 9150000
  training_iteration: 305
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 13579 s, 305 iter, 9150000 ts, 1.23e+03 rew

agent-1: 30.0
agent-2: 61.0
agent-3: 27.0
agent-4: 22.0
agent-5: 24.0
agent-6: 37.0
agent-7: 23.0
agent-8: 11.0
agent-9: 35.0
agent-10: 53.0
agent-11: 60.0
agent-12: 62.0
agent-13: 60.0
agent-14: 13.0
agent-15: 72.0
agent-16: 50.0
agent-17: 55.0
agent-18: 43.0
agent-19: 52.0
agent-20: 56.0
agent-21: 36.0
agent-22: 64.0
agent-23: 59.0
agent-24: 54.0
agent-25: 42.0
agent-26: 31.0
agent-27: 54.0
agent-28: 32.0
agent-29: 45.0
agent-30: 23.0
Sum Reward: 1286.0
Avg Reward: 42.86666666666667
Min Reward: 11.0
Max Reward: 72.0
Gini Coefficient: 0.21669258683255574
20:20 Ratio: 3.2672413793103448
Max-min Ratio: 6.545454545454546
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-50-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1229.86
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 305
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.397
    dispatch_time_ms: 7.566
    learner:
      cur_lr: 0.0007506100228056312
      grad_gnorm: 40.0
      policy_entropy: 194.75936889648438
      policy_loss: 119.77713775634766
      var_gnorm: 23.40803337097168
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 214.75064086914062
    num_steps_sampled: 9180000
    num_steps_trained: 9180000
    wait_time_ms: 420.724
  iterations_since_restore: 306
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 13623.892138004303
  time_this_iter_s: 44.41606330871582
  time_total_s: 13623.892138004303
  timestamp: 1594165810
  timesteps_since_restore: 9180000
  timesteps_this_iter: 30000
  timesteps_total: 9180000
  training_iteration: 306
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 13623 s, 306 iter, 9180000 ts, 1.23e+03 rew

agent-1: 11.0
agent-2: 37.0
agent-3: 59.0
agent-4: 63.0
agent-5: 21.0
agent-6: 40.0
agent-7: 24.0
agent-8: 37.0
agent-9: 77.0
agent-10: 19.0
agent-11: 56.0
agent-12: 42.0
agent-13: 66.0
agent-14: 32.0
agent-15: 54.0
agent-16: 41.0
agent-17: 40.0
agent-18: 61.0
agent-19: 28.0
agent-20: 34.0
agent-21: 43.0
agent-22: 50.0
agent-23: 16.0
agent-24: 49.0
agent-25: 25.0
agent-26: 76.0
agent-27: 38.0
agent-28: 58.0
agent-29: 29.0
agent-30: 51.0
Sum Reward: 1277.0
Avg Reward: 42.56666666666667
Min Reward: 11.0
Max Reward: 77.0
Gini Coefficient: 0.22759070738710518
20:20 Ratio: 3.4655172413793105
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-50-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1230.08
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 306
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.659
    dispatch_time_ms: 6.316
    learner:
      cur_lr: 0.0007486119866371155
      grad_gnorm: 40.0
      policy_entropy: 214.4810028076172
      policy_loss: -33.29142761230469
      var_gnorm: 23.40894889831543
      vf_explained_var: 0.0
      vf_loss: 6.153553009033203
    num_steps_sampled: 9210000
    num_steps_trained: 9210000
    wait_time_ms: 430.719
  iterations_since_restore: 307
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 13667.69634103775
  time_this_iter_s: 43.804203033447266
  time_total_s: 13667.69634103775
  timestamp: 1594165854
  timesteps_since_restore: 9210000
  timesteps_this_iter: 30000
  timesteps_total: 9210000
  training_iteration: 307
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 13667 s, 307 iter, 9210000 ts, 1.23e+03 rew

agent-1: 26.0
agent-2: 49.0
agent-3: 59.0
agent-4: 34.0
agent-5: 46.0
agent-6: 31.0
agent-7: 38.0
agent-8: 43.0
agent-9: 48.0
agent-10: 21.0
agent-11: 9.0
agent-12: 29.0
agent-13: 20.0
agent-14: 31.0
agent-15: 41.0
agent-16: 52.0
agent-17: 4.0
agent-18: 41.0
agent-19: 23.0
agent-20: 30.0
agent-21: 39.0
agent-22: 37.0
agent-23: 18.0
agent-24: 32.0
agent-25: 23.0
agent-26: 31.0
agent-27: 43.0
agent-28: 21.0
agent-29: 32.0
agent-30: 61.0
Sum Reward: 1012.0
Avg Reward: 33.733333333333334
Min Reward: 4.0
Max Reward: 61.0
Gini Coefficient: 0.22061923583662715
20:20 Ratio: 3.3870967741935485
Max-min Ratio: 15.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-51-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1225.72
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 307
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.867
    dispatch_time_ms: 6.494
    learner:
      cur_lr: 0.0007466140086762607
      grad_gnorm: 40.0
      policy_entropy: 207.72512817382812
      policy_loss: 83.77586364746094
      var_gnorm: 23.405691146850586
      vf_explained_var: 0.0
      vf_loss: 155.6422576904297
    num_steps_sampled: 9240000
    num_steps_trained: 9240000
    wait_time_ms: 413.249
  iterations_since_restore: 308
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 13712.223627567291
  time_this_iter_s: 44.527286529541016
  time_total_s: 13712.223627567291
  timestamp: 1594165898
  timesteps_since_restore: 9240000
  timesteps_this_iter: 30000
  timesteps_total: 9240000
  training_iteration: 308
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 13712 s, 308 iter, 9240000 ts, 1.23e+03 rew

agent-1: 29.0
agent-2: 20.0
agent-3: 26.0
agent-4: 49.0
agent-5: 26.0
agent-6: 26.0
agent-7: 35.0
agent-8: 14.0
agent-9: 44.0
agent-10: 62.0
agent-11: 34.0
agent-12: 31.0
agent-13: 41.0
agent-14: 10.0
agent-15: 27.0
agent-16: 26.0
agent-17: 72.0
agent-18: 43.0
agent-19: 15.0
agent-20: 44.0
agent-21: 46.0
agent-22: 32.0
agent-23: 44.0
agent-24: 56.0
agent-25: 46.0
agent-26: 55.0
agent-27: 32.0
agent-28: 53.0
agent-29: 19.0
agent-30: 43.0
Sum Reward: 1100.0
Avg Reward: 36.666666666666664
Min Reward: 10.0
Max Reward: 72.0
Gini Coefficient: 0.22545454545454546
20:20 Ratio: 3.3365384615384617
Max-min Ratio: 7.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-52-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1222.52
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 308
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.978
    dispatch_time_ms: 8.789
    learner:
      cur_lr: 0.000744615972507745
      grad_gnorm: 40.0
      policy_entropy: 146.69549560546875
      policy_loss: 19.156801223754883
      var_gnorm: 23.41024398803711
      vf_explained_var: 0.0
      vf_loss: 50.5997314453125
    num_steps_sampled: 9270000
    num_steps_trained: 9270000
    wait_time_ms: 421.145
  iterations_since_restore: 309
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 13756.208399057388
  time_this_iter_s: 43.984771490097046
  time_total_s: 13756.208399057388
  timestamp: 1594165942
  timesteps_since_restore: 9270000
  timesteps_this_iter: 30000
  timesteps_total: 9270000
  training_iteration: 309
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 13756 s, 309 iter, 9270000 ts, 1.22e+03 rew

agent-1: 16.0
agent-2: 27.0
agent-3: 48.0
agent-4: 30.0
agent-5: 46.0
agent-6: 38.0
agent-7: 22.0
agent-8: 45.0
agent-9: 42.0
agent-10: 28.0
agent-11: 60.0
agent-12: 26.0
agent-13: 52.0
agent-14: 45.0
agent-15: 37.0
agent-16: 45.0
agent-17: 26.0
agent-18: 31.0
agent-19: 36.0
agent-20: 15.0
agent-21: 36.0
agent-22: 50.0
agent-23: 28.0
agent-24: 47.0
agent-25: 15.0
agent-26: 45.0
agent-27: 47.0
agent-28: 43.0
agent-29: 51.0
agent-30: 58.0
Sum Reward: 1135.0
Avg Reward: 37.833333333333336
Min Reward: 15.0
Max Reward: 60.0
Gini Coefficient: 0.1831130690161527
20:20 Ratio: 2.658333333333333
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-53-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1220.21
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 309
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.886
    dispatch_time_ms: 52.454
    learner:
      cur_lr: 0.0007426179945468903
      grad_gnorm: 40.0
      policy_entropy: 197.78875732421875
      policy_loss: -26.496475219726562
      var_gnorm: 23.40831184387207
      vf_explained_var: 0.0
      vf_loss: 3.529315233230591
    num_steps_sampled: 9300000
    num_steps_trained: 9300000
    wait_time_ms: 403.412
  iterations_since_restore: 310
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 13801.41852593422
  time_this_iter_s: 45.210126876831055
  time_total_s: 13801.41852593422
  timestamp: 1594165987
  timesteps_since_restore: 9300000
  timesteps_this_iter: 30000
  timesteps_total: 9300000
  training_iteration: 310
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 13801 s, 310 iter, 9300000 ts, 1.22e+03 rew

agent-1: 57.0
agent-2: 36.0
agent-3: 54.0
agent-4: 44.0
agent-5: 54.0
agent-6: 49.0
agent-7: 50.0
agent-8: 44.0
agent-9: 72.0
agent-10: 33.0
agent-11: 34.0
agent-12: 44.0
agent-13: 29.0
agent-14: 33.0
agent-15: 35.0
agent-16: 50.0
agent-17: 28.0
agent-18: 54.0
agent-19: 33.0
agent-20: 15.0
agent-21: 39.0
agent-22: 47.0
agent-23: 50.0
agent-24: 16.0
agent-25: 53.0
agent-26: 52.0
agent-27: 43.0
agent-28: 29.0
agent-29: 75.0
agent-30: 59.0
Sum Reward: 1311.0
Avg Reward: 43.7
Min Reward: 15.0
Max Reward: 75.0
Gini Coefficient: 0.1752606153063819
20:20 Ratio: 2.473333333333333
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-53-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1221.54
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 310
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.717
    dispatch_time_ms: 31.435
    learner:
      cur_lr: 0.0007406200165860355
      grad_gnorm: 17.304916381835938
      policy_entropy: 181.35450744628906
      policy_loss: 4.963006019592285
      var_gnorm: 23.413589477539062
      vf_explained_var: 0.0
      vf_loss: 43.2734260559082
    num_steps_sampled: 9330000
    num_steps_trained: 9330000
    wait_time_ms: 433.543
  iterations_since_restore: 311
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 13846.667164325714
  time_this_iter_s: 45.24863839149475
  time_total_s: 13846.667164325714
  timestamp: 1594166033
  timesteps_since_restore: 9330000
  timesteps_this_iter: 30000
  timesteps_total: 9330000
  training_iteration: 311
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 13846 s, 311 iter, 9330000 ts, 1.22e+03 rew

agent-1: 33.0
agent-2: 48.0
agent-3: 49.0
agent-4: 36.0
agent-5: 19.0
agent-6: 35.0
agent-7: 24.0
agent-8: 18.0
agent-9: 60.0
agent-10: 25.0
agent-11: 49.0
agent-12: 59.0
agent-13: 76.0
agent-14: 26.0
agent-15: 53.0
agent-16: 40.0
agent-17: 48.0
agent-18: 71.0
agent-19: 61.0
agent-20: 39.0
agent-21: 26.0
agent-22: 44.0
agent-23: 48.0
agent-24: 47.0
agent-25: 45.0
agent-26: 35.0
agent-27: 68.0
agent-28: 33.0
agent-29: 60.0
agent-30: 44.0
Sum Reward: 1319.0
Avg Reward: 43.96666666666667
Min Reward: 18.0
Max Reward: 76.0
Gini Coefficient: 0.19390952741976245
20:20 Ratio: 2.869565217391304
Max-min Ratio: 4.222222222222222
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-54-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1221.37
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 311
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.524
    dispatch_time_ms: 36.711
    learner:
      cur_lr: 0.0007386219804175198
      grad_gnorm: 40.0
      policy_entropy: 153.6338348388672
      policy_loss: -7.452321529388428
      var_gnorm: 23.586719512939453
      vf_explained_var: 0.0
      vf_loss: 58.842262268066406
    num_steps_sampled: 9360000
    num_steps_trained: 9360000
    wait_time_ms: 301.148
  iterations_since_restore: 312
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 13892.47935795784
  time_this_iter_s: 45.812193632125854
  time_total_s: 13892.47935795784
  timestamp: 1594166078
  timesteps_since_restore: 9360000
  timesteps_this_iter: 30000
  timesteps_total: 9360000
  training_iteration: 312
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 13892 s, 312 iter, 9360000 ts, 1.22e+03 rew

agent-1: 55.0
agent-2: 42.0
agent-3: 44.0
agent-4: 46.0
agent-5: 46.0
agent-6: 23.0
agent-7: 41.0
agent-8: 54.0
agent-9: 43.0
agent-10: 21.0
agent-11: 102.0
agent-12: 52.0
agent-13: 48.0
agent-14: 38.0
agent-15: 54.0
agent-16: 53.0
agent-17: 51.0
agent-18: 28.0
agent-19: 48.0
agent-20: 53.0
agent-21: 32.0
agent-22: 47.0
agent-23: 39.0
agent-24: 40.0
agent-25: 65.0
agent-26: 24.0
agent-27: 15.0
agent-28: 44.0
agent-29: 51.0
agent-30: 61.0
Sum Reward: 1360.0
Avg Reward: 45.333333333333336
Min Reward: 15.0
Max Reward: 102.0
Gini Coefficient: 0.17681372549019608
20:20 Ratio: 2.734265734265734
Max-min Ratio: 6.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-55-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1220.55
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 312
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.914
    dispatch_time_ms: 20.491
    learner:
      cur_lr: 0.000736624002456665
      grad_gnorm: 39.999996185302734
      policy_entropy: 205.3688507080078
      policy_loss: 18.908578872680664
      var_gnorm: 23.60375213623047
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 89.45873260498047
    num_steps_sampled: 9390000
    num_steps_trained: 9390000
    wait_time_ms: 439.586
  iterations_since_restore: 313
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 13937.7621011734
  time_this_iter_s: 45.28274321556091
  time_total_s: 13937.7621011734
  timestamp: 1594166124
  timesteps_since_restore: 9390000
  timesteps_this_iter: 30000
  timesteps_total: 9390000
  training_iteration: 313
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 13937 s, 313 iter, 9390000 ts, 1.22e+03 rew

agent-1: 37.0
agent-2: 44.0
agent-3: 53.0
agent-4: 54.0
agent-5: 46.0
agent-6: 40.0
agent-7: 58.0
agent-8: 46.0
agent-9: 58.0
agent-10: 35.0
agent-11: 49.0
agent-12: 31.0
agent-13: 38.0
agent-14: 28.0
agent-15: 48.0
agent-16: 33.0
agent-17: 39.0
agent-18: 35.0
agent-19: 53.0
agent-20: 19.0
agent-21: 58.0
agent-22: 30.0
agent-23: 27.0
agent-24: 46.0
agent-25: 31.0
agent-26: 30.0
agent-27: 45.0
agent-28: 26.0
agent-29: 48.0
agent-30: 46.0
Sum Reward: 1231.0
Avg Reward: 41.03333333333333
Min Reward: 19.0
Max Reward: 58.0
Gini Coefficient: 0.14592472244787436
20:20 Ratio: 2.0875
Max-min Ratio: 3.0526315789473686
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-56-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1219.16
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 313
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.237
    dispatch_time_ms: 25.249
    learner:
      cur_lr: 0.0007346260244958103
      grad_gnorm: 40.0
      policy_entropy: 170.1713104248047
      policy_loss: -22.566469192504883
      var_gnorm: 23.60445785522461
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 3.5350475311279297
    num_steps_sampled: 9420000
    num_steps_trained: 9420000
    wait_time_ms: 455.928
  iterations_since_restore: 314
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 13983.88647222519
  time_this_iter_s: 46.12437105178833
  time_total_s: 13983.88647222519
  timestamp: 1594166170
  timesteps_since_restore: 9420000
  timesteps_this_iter: 30000
  timesteps_total: 9420000
  training_iteration: 314
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 13983 s, 314 iter, 9420000 ts, 1.22e+03 rew

agent-1: 54.0
agent-2: 27.0
agent-3: 30.0
agent-4: 82.0
agent-5: 71.0
agent-6: 58.0
agent-7: 41.0
agent-8: 29.0
agent-9: 55.0
agent-10: 43.0
agent-11: 64.0
agent-12: 34.0
agent-13: 61.0
agent-14: 53.0
agent-15: 59.0
agent-16: 26.0
agent-17: 33.0
agent-18: 50.0
agent-19: 48.0
agent-20: 56.0
agent-21: 30.0
agent-22: 26.0
agent-23: 47.0
agent-24: 24.0
agent-25: 20.0
agent-26: 41.0
agent-27: 33.0
agent-28: 18.0
agent-29: 20.0
agent-30: 33.0
Sum Reward: 1266.0
Avg Reward: 42.2
Min Reward: 18.0
Max Reward: 82.0
Gini Coefficient: 0.2182201158504476
20:20 Ratio: 2.9477611940298507
Max-min Ratio: 4.555555555555555
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-56-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1221.37
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 314
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.045
    dispatch_time_ms: 42.83
    learner:
      cur_lr: 0.0007326279883272946
      grad_gnorm: 40.0
      policy_entropy: 219.8992156982422
      policy_loss: 10.794089317321777
      var_gnorm: 23.610843658447266
      vf_explained_var: 0.0
      vf_loss: 53.08689498901367
    num_steps_sampled: 9450000
    num_steps_trained: 9450000
    wait_time_ms: 414.224
  iterations_since_restore: 315
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 14028.91570353508
  time_this_iter_s: 45.02923130989075
  time_total_s: 14028.91570353508
  timestamp: 1594166215
  timesteps_since_restore: 9450000
  timesteps_this_iter: 30000
  timesteps_total: 9450000
  training_iteration: 315
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 14028 s, 315 iter, 9450000 ts, 1.22e+03 rew

agent-1: 37.0
agent-2: 33.0
agent-3: 51.0
agent-4: 19.0
agent-5: 30.0
agent-6: 50.0
agent-7: 40.0
agent-8: 51.0
agent-9: 61.0
agent-10: 23.0
agent-11: 37.0
agent-12: 28.0
agent-13: 30.0
agent-14: 24.0
agent-15: 36.0
agent-16: 41.0
agent-17: 65.0
agent-18: 13.0
agent-19: 13.0
agent-20: 25.0
agent-21: 45.0
agent-22: 27.0
agent-23: 58.0
agent-24: 44.0
agent-25: 34.0
agent-26: 38.0
agent-27: 41.0
agent-28: 35.0
agent-29: 41.0
agent-30: 31.0
Sum Reward: 1101.0
Avg Reward: 36.7
Min Reward: 13.0
Max Reward: 65.0
Gini Coefficient: 0.1950045413260672
20:20 Ratio: 2.871794871794872
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-57-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1217.96
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 315
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.837
    dispatch_time_ms: 6.721
    learner:
      cur_lr: 0.0007306300103664398
      grad_gnorm: 40.0
      policy_entropy: 122.68008422851562
      policy_loss: -3.3793044090270996
      var_gnorm: 23.614791870117188
      vf_explained_var: 0.0
      vf_loss: 18.1616153717041
    num_steps_sampled: 9480000
    num_steps_trained: 9480000
    wait_time_ms: 425.577
  iterations_since_restore: 316
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 14073.383858919144
  time_this_iter_s: 44.46815538406372
  time_total_s: 14073.383858919144
  timestamp: 1594166259
  timesteps_since_restore: 9480000
  timesteps_this_iter: 30000
  timesteps_total: 9480000
  training_iteration: 316
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 14073 s, 316 iter, 9480000 ts, 1.22e+03 rew

agent-1: 55.0
agent-2: 44.0
agent-3: 32.0
agent-4: 64.0
agent-5: 67.0
agent-6: 54.0
agent-7: 64.0
agent-8: 69.0
agent-9: 51.0
agent-10: 31.0
agent-11: 55.0
agent-12: 57.0
agent-13: 50.0
agent-14: 64.0
agent-15: 51.0
agent-16: 64.0
agent-17: 34.0
agent-18: 63.0
agent-19: 31.0
agent-20: 38.0
agent-21: 36.0
agent-22: 48.0
agent-23: 42.0
agent-24: 60.0
agent-25: 57.0
agent-26: 30.0
agent-27: 57.0
agent-28: 23.0
agent-29: 40.0
agent-30: 17.0
Sum Reward: 1448.0
Avg Reward: 48.266666666666666
Min Reward: 17.0
Max Reward: 69.0
Gini Coefficient: 0.16464088397790055
20:20 Ratio: 2.3902439024390243
Max-min Ratio: 4.0588235294117645
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-58-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1582.0
  episode_reward_mean: 1217.82
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 316
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.631
    dispatch_time_ms: 6.219
    learner:
      cur_lr: 0.0007286319741979241
      grad_gnorm: 40.0
      policy_entropy: 164.61753845214844
      policy_loss: -23.479581832885742
      var_gnorm: 23.622575759887695
      vf_explained_var: 0.0
      vf_loss: 33.4433479309082
    num_steps_sampled: 9510000
    num_steps_trained: 9510000
    wait_time_ms: 432.301
  iterations_since_restore: 317
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 14116.263292074203
  time_this_iter_s: 42.879433155059814
  time_total_s: 14116.263292074203
  timestamp: 1594166302
  timesteps_since_restore: 9510000
  timesteps_this_iter: 30000
  timesteps_total: 9510000
  training_iteration: 317
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 14116 s, 317 iter, 9510000 ts, 1.22e+03 rew

agent-1: 50.0
agent-2: 30.0
agent-3: 42.0
agent-4: 37.0
agent-5: 71.0
agent-6: 65.0
agent-7: 40.0
agent-8: 66.0
agent-9: 36.0
agent-10: 41.0
agent-11: 60.0
agent-12: 49.0
agent-13: 63.0
agent-14: 43.0
agent-15: 41.0
agent-16: 32.0
agent-17: 55.0
agent-18: 40.0
agent-19: 29.0
agent-20: 66.0
agent-21: 88.0
agent-22: 56.0
agent-23: 36.0
agent-24: 66.0
agent-25: 46.0
agent-26: 47.0
agent-27: 75.0
agent-28: 50.0
agent-29: 56.0
agent-30: 24.0
Sum Reward: 1500.0
Avg Reward: 50.0
Min Reward: 24.0
Max Reward: 88.0
Gini Coefficient: 0.16946666666666665
20:20 Ratio: 2.3101604278074865
Max-min Ratio: 3.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-59-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1512.0
  episode_reward_mean: 1217.0
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 317
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.837
    dispatch_time_ms: 27.09
    learner:
      cur_lr: 0.0007266339962370694
      grad_gnorm: 27.2237491607666
      policy_entropy: 147.8726043701172
      policy_loss: 2.2329907417297363
      var_gnorm: 23.61705207824707
      vf_explained_var: 0.0
      vf_loss: 41.82756805419922
    num_steps_sampled: 9540000
    num_steps_trained: 9540000
    wait_time_ms: 435.481
  iterations_since_restore: 318
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 14161.352485656738
  time_this_iter_s: 45.08919358253479
  time_total_s: 14161.352485656738
  timestamp: 1594166347
  timesteps_since_restore: 9540000
  timesteps_this_iter: 30000
  timesteps_total: 9540000
  training_iteration: 318
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 14161 s, 318 iter, 9540000 ts, 1.22e+03 rew

agent-1: 36.0
agent-2: 35.0
agent-3: 51.0
agent-4: 29.0
agent-5: 16.0
agent-6: 65.0
agent-7: 39.0
agent-8: 46.0
agent-9: 42.0
agent-10: 50.0
agent-11: 23.0
agent-12: 60.0
agent-13: 38.0
agent-14: 71.0
agent-15: 43.0
agent-16: 51.0
agent-17: 35.0
agent-18: 42.0
agent-19: 34.0
agent-20: 36.0
agent-21: 75.0
agent-22: 64.0
agent-23: 25.0
agent-24: 77.0
agent-25: 34.0
agent-26: 47.0
agent-27: 50.0
agent-28: 60.0
agent-29: 48.0
agent-30: 31.0
Sum Reward: 1353.0
Avg Reward: 45.1
Min Reward: 16.0
Max Reward: 77.0
Gini Coefficient: 0.1880019709288002
20:20 Ratio: 2.607594936708861
Max-min Ratio: 4.8125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_19-59-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1512.0
  episode_reward_mean: 1218.34
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 318
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 5.044
    dispatch_time_ms: 37.168
    learner:
      cur_lr: 0.0007246360182762146
      grad_gnorm: 40.000003814697266
      policy_entropy: 133.69839477539062
      policy_loss: 14.564062118530273
      var_gnorm: 23.621116638183594
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 53.05072784423828
    num_steps_sampled: 9570000
    num_steps_trained: 9570000
    wait_time_ms: 417.761
  iterations_since_restore: 319
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 14206.085701227188
  time_this_iter_s: 44.73321557044983
  time_total_s: 14206.085701227188
  timestamp: 1594166392
  timesteps_since_restore: 9570000
  timesteps_this_iter: 30000
  timesteps_total: 9570000
  training_iteration: 319
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 14206 s, 319 iter, 9570000 ts, 1.22e+03 rew

agent-1: 54.0
agent-2: 28.0
agent-3: 57.0
agent-4: 35.0
agent-5: 31.0
agent-6: 53.0
agent-7: 39.0
agent-8: 50.0
agent-9: 57.0
agent-10: 36.0
agent-11: 34.0
agent-12: 33.0
agent-13: 41.0
agent-14: 40.0
agent-15: 33.0
agent-16: 34.0
agent-17: 39.0
agent-18: 59.0
agent-19: 57.0
agent-20: 40.0
agent-21: 91.0
agent-22: 46.0
agent-23: 53.0
agent-24: 28.0
agent-25: 39.0
agent-26: 33.0
agent-27: 53.0
agent-28: 40.0
agent-29: 41.0
agent-30: 61.0
Sum Reward: 1335.0
Avg Reward: 44.5
Min Reward: 28.0
Max Reward: 91.0
Gini Coefficient: 0.1532334581772784
20:20 Ratio: 2.053763440860215
Max-min Ratio: 3.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-00-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1512.0
  episode_reward_mean: 1220.57
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 319
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 4.277
    dispatch_time_ms: 33.209
    learner:
      cur_lr: 0.0007226379821076989
      grad_gnorm: 40.0
      policy_entropy: 126.41226959228516
      policy_loss: 88.98113250732422
      var_gnorm: 23.61792755126953
      vf_explained_var: 0.0
      vf_loss: 224.4202880859375
    num_steps_sampled: 9600000
    num_steps_trained: 9600000
    wait_time_ms: 694.271
  iterations_since_restore: 320
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 14255.035258054733
  time_this_iter_s: 48.949556827545166
  time_total_s: 14255.035258054733
  timestamp: 1594166441
  timesteps_since_restore: 9600000
  timesteps_this_iter: 30000
  timesteps_total: 9600000
  training_iteration: 320
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 14255 s, 320 iter, 9600000 ts, 1.22e+03 rew

agent-1: 79.0
agent-2: 43.0
agent-3: 49.0
agent-4: 38.0
agent-5: 41.0
agent-6: 49.0
agent-7: 43.0
agent-8: 23.0
agent-9: 59.0
agent-10: 21.0
agent-11: 51.0
agent-12: 35.0
agent-13: 44.0
agent-14: 32.0
agent-15: 53.0
agent-16: 52.0
agent-17: 50.0
agent-18: 35.0
agent-19: 68.0
agent-20: 36.0
agent-21: 48.0
agent-22: 40.0
agent-23: 55.0
agent-24: 60.0
agent-25: 78.0
agent-26: 48.0
agent-27: 34.0
agent-28: 19.0
agent-29: 24.0
agent-30: 51.0
Sum Reward: 1358.0
Avg Reward: 45.266666666666666
Min Reward: 19.0
Max Reward: 79.0
Gini Coefficient: 0.1789887088856161
20:20 Ratio: 2.607843137254902
Max-min Ratio: 4.157894736842105
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-01-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1512.0
  episode_reward_mean: 1219.96
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 320
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.489
    dispatch_time_ms: 36.392
    learner:
      cur_lr: 0.0007206400041468441
      grad_gnorm: 40.0
      policy_entropy: 125.16976928710938
      policy_loss: -6.579126834869385
      var_gnorm: 23.623912811279297
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 127.32816314697266
    num_steps_sampled: 9630000
    num_steps_trained: 9630000
    wait_time_ms: 422.463
  iterations_since_restore: 321
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 14296.32335472107
  time_this_iter_s: 41.28809666633606
  time_total_s: 14296.32335472107
  timestamp: 1594166483
  timesteps_since_restore: 9630000
  timesteps_this_iter: 30000
  timesteps_total: 9630000
  training_iteration: 321
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 14296 s, 321 iter, 9630000 ts, 1.22e+03 rew

agent-1: 71.0
agent-2: 57.0
agent-3: 48.0
agent-4: 68.0
agent-5: 54.0
agent-6: 46.0
agent-7: 55.0
agent-8: 44.0
agent-9: 46.0
agent-10: 63.0
agent-11: 57.0
agent-12: 53.0
agent-13: 74.0
agent-14: 51.0
agent-15: 73.0
agent-16: 58.0
agent-17: 21.0
agent-18: 37.0
agent-19: 48.0
agent-20: 16.0
agent-21: 32.0
agent-22: 54.0
agent-23: 49.0
agent-24: 48.0
agent-25: 46.0
agent-26: 82.0
agent-27: 85.0
agent-28: 46.0
agent-29: 51.0
agent-30: 47.0
Sum Reward: 1580.0
Avg Reward: 52.666666666666664
Min Reward: 16.0
Max Reward: 85.0
Gini Coefficient: 0.15569620253164557
20:20 Ratio: 2.311224489795918
Max-min Ratio: 5.3125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-02-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1580.0
  episode_reward_mean: 1222.63
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 321
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.852
    dispatch_time_ms: 5.648
    learner:
      cur_lr: 0.0007186420261859894
      grad_gnorm: 40.0
      policy_entropy: 138.80909729003906
      policy_loss: -16.123355865478516
      var_gnorm: 23.620481491088867
      vf_explained_var: 0.0
      vf_loss: 38.95185852050781
    num_steps_sampled: 9660000
    num_steps_trained: 9660000
    wait_time_ms: 443.509
  iterations_since_restore: 322
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 14340.609518051147
  time_this_iter_s: 44.286163330078125
  time_total_s: 14340.609518051147
  timestamp: 1594166527
  timesteps_since_restore: 9660000
  timesteps_this_iter: 30000
  timesteps_total: 9660000
  training_iteration: 322
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 14340 s, 322 iter, 9660000 ts, 1.22e+03 rew

agent-1: 41.0
agent-2: 14.0
agent-3: 40.0
agent-4: 60.0
agent-5: 41.0
agent-6: 24.0
agent-7: 51.0
agent-8: 54.0
agent-9: 72.0
agent-10: 28.0
agent-11: 21.0
agent-12: 62.0
agent-13: 51.0
agent-14: 49.0
agent-15: 32.0
agent-16: 27.0
agent-17: 31.0
agent-18: 41.0
agent-19: 28.0
agent-20: 32.0
agent-21: 55.0
agent-22: 39.0
agent-23: 39.0
agent-24: 44.0
agent-25: 46.0
agent-26: 31.0
agent-27: 77.0
agent-28: 31.0
agent-29: 70.0
agent-30: 42.0
Sum Reward: 1273.0
Avg Reward: 42.43333333333333
Min Reward: 14.0
Max Reward: 77.0
Gini Coefficient: 0.20060225189840272
20:20 Ratio: 2.788732394366197
Max-min Ratio: 5.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-02-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1580.0
  episode_reward_mean: 1223.02
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 322
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.844
    dispatch_time_ms: 6.273
    learner:
      cur_lr: 0.0007166439900174737
      grad_gnorm: 39.999996185302734
      policy_entropy: 124.45767211914062
      policy_loss: -17.247039794921875
      var_gnorm: 23.625038146972656
      vf_explained_var: 0.0
      vf_loss: 18.576519012451172
    num_steps_sampled: 9690000
    num_steps_trained: 9690000
    wait_time_ms: 432.449
  iterations_since_restore: 323
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 14383.553725004196
  time_this_iter_s: 42.944206953048706
  time_total_s: 14383.553725004196
  timestamp: 1594166570
  timesteps_since_restore: 9690000
  timesteps_this_iter: 30000
  timesteps_total: 9690000
  training_iteration: 323
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 14383 s, 323 iter, 9690000 ts, 1.22e+03 rew

agent-1: 28.0
agent-2: 31.0
agent-3: 40.0
agent-4: 45.0
agent-5: 48.0
agent-6: 31.0
agent-7: 47.0
agent-8: 44.0
agent-9: 34.0
agent-10: 45.0
agent-11: 51.0
agent-12: 40.0
agent-13: 20.0
agent-14: 47.0
agent-15: 41.0
agent-16: 27.0
agent-17: 20.0
agent-18: 53.0
agent-19: 40.0
agent-20: 29.0
agent-21: 17.0
agent-22: 33.0
agent-23: 31.0
agent-24: 48.0
agent-25: 45.0
agent-26: 63.0
agent-27: 24.0
agent-28: 69.0
agent-29: 37.0
agent-30: 57.0
Sum Reward: 1185.0
Avg Reward: 39.5
Min Reward: 17.0
Max Reward: 69.0
Gini Coefficient: 0.17701828410689172
20:20 Ratio: 2.5073529411764706
Max-min Ratio: 4.0588235294117645
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-03-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1580.0
  episode_reward_mean: 1222.37
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 323
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.58
    dispatch_time_ms: 5.679
    learner:
      cur_lr: 0.0007146460120566189
      grad_gnorm: 40.000003814697266
      policy_entropy: 143.66830444335938
      policy_loss: 79.03208923339844
      var_gnorm: 23.617990493774414
      vf_explained_var: 0.0
      vf_loss: 227.4491424560547
    num_steps_sampled: 9720000
    num_steps_trained: 9720000
    wait_time_ms: 426.806
  iterations_since_restore: 324
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 14428.448596477509
  time_this_iter_s: 44.89487147331238
  time_total_s: 14428.448596477509
  timestamp: 1594166615
  timesteps_since_restore: 9720000
  timesteps_this_iter: 30000
  timesteps_total: 9720000
  training_iteration: 324
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 14428 s, 324 iter, 9720000 ts, 1.22e+03 rew

agent-1: 55.0
agent-2: 38.0
agent-3: 37.0
agent-4: 12.0
agent-5: 63.0
agent-6: 46.0
agent-7: 50.0
agent-8: 56.0
agent-9: 38.0
agent-10: 41.0
agent-11: 49.0
agent-12: 48.0
agent-13: 35.0
agent-14: 39.0
agent-15: 19.0
agent-16: 50.0
agent-17: 33.0
agent-18: 42.0
agent-19: 31.0
agent-20: 23.0
agent-21: 59.0
agent-22: 54.0
agent-23: 46.0
agent-24: 41.0
agent-25: 27.0
agent-26: 30.0
agent-27: 41.0
agent-28: 66.0
agent-29: 41.0
agent-30: 44.0
Sum Reward: 1254.0
Avg Reward: 41.8
Min Reward: 12.0
Max Reward: 66.0
Gini Coefficient: 0.16485911749069643
20:20 Ratio: 2.4859154929577465
Max-min Ratio: 5.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-04-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1580.0
  episode_reward_mean: 1223.66
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 324
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.726
    dispatch_time_ms: 6.529
    learner:
      cur_lr: 0.0007126479758881032
      grad_gnorm: 40.0
      policy_entropy: 160.3602752685547
      policy_loss: -7.4455366134643555
      var_gnorm: 23.621856689453125
      vf_explained_var: 0.0
      vf_loss: 30.43002700805664
    num_steps_sampled: 9750000
    num_steps_trained: 9750000
    wait_time_ms: 427.921
  iterations_since_restore: 325
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 14471.862183570862
  time_this_iter_s: 43.41358709335327
  time_total_s: 14471.862183570862
  timestamp: 1594166658
  timesteps_since_restore: 9750000
  timesteps_this_iter: 30000
  timesteps_total: 9750000
  training_iteration: 325
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 14471 s, 325 iter, 9750000 ts, 1.22e+03 rew

agent-1: 29.0
agent-2: 50.0
agent-3: 33.0
agent-4: 46.0
agent-5: 30.0
agent-6: 26.0
agent-7: 14.0
agent-8: 26.0
agent-9: 32.0
agent-10: 33.0
agent-11: 76.0
agent-12: 16.0
agent-13: 47.0
agent-14: 52.0
agent-15: 47.0
agent-16: 25.0
agent-17: 64.0
agent-18: 24.0
agent-19: 27.0
agent-20: 36.0
agent-21: 27.0
agent-22: 29.0
agent-23: 43.0
agent-24: 35.0
agent-25: 16.0
agent-26: 12.0
agent-27: 40.0
agent-28: 37.0
agent-29: 23.0
agent-30: 20.0
Sum Reward: 1015.0
Avg Reward: 33.833333333333336
Min Reward: 12.0
Max Reward: 76.0
Gini Coefficient: 0.23083743842364532
20:20 Ratio: 3.3267326732673266
Max-min Ratio: 6.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-05-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1580.0
  episode_reward_mean: 1219.05
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 325
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.854
    dispatch_time_ms: 79.532
    learner:
      cur_lr: 0.0007106499979272485
      grad_gnorm: 40.0
      policy_entropy: 118.31137084960938
      policy_loss: -9.219528198242188
      var_gnorm: 23.61492347717285
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.892490029335022
    num_steps_sampled: 9780000
    num_steps_trained: 9780000
    wait_time_ms: 368.206
  iterations_since_restore: 326
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 14517.797852039337
  time_this_iter_s: 45.93566846847534
  time_total_s: 14517.797852039337
  timestamp: 1594166704
  timesteps_since_restore: 9780000
  timesteps_this_iter: 30000
  timesteps_total: 9780000
  training_iteration: 326
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 14517 s, 326 iter, 9780000 ts, 1.22e+03 rew

agent-1: 32.0
agent-2: 31.0
agent-3: 27.0
agent-4: 37.0
agent-5: 45.0
agent-6: 40.0
agent-7: 23.0
agent-8: 18.0
agent-9: 52.0
agent-10: 45.0
agent-11: 17.0
agent-12: 57.0
agent-13: 52.0
agent-14: 25.0
agent-15: 31.0
agent-16: 27.0
agent-17: 37.0
agent-18: 56.0
agent-19: 47.0
agent-20: 25.0
agent-21: 44.0
agent-22: 54.0
agent-23: 38.0
agent-24: 18.0
agent-25: 10.0
agent-26: 28.0
agent-27: 27.0
agent-28: 39.0
agent-29: 37.0
agent-30: 29.0
Sum Reward: 1048.0
Avg Reward: 34.93333333333333
Min Reward: 10.0
Max Reward: 57.0
Gini Coefficient: 0.20082697201017813
20:20 Ratio: 2.864864864864865
Max-min Ratio: 5.7
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-05-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1580.0
  episode_reward_mean: 1218.26
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 326
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.681
    dispatch_time_ms: 34.965
    learner:
      cur_lr: 0.0007086520199663937
      grad_gnorm: 40.000003814697266
      policy_entropy: 131.97525024414062
      policy_loss: 49.97524642944336
      var_gnorm: 23.621654510498047
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 122.71585083007812
    num_steps_sampled: 9810000
    num_steps_trained: 9810000
    wait_time_ms: 420.48
  iterations_since_restore: 327
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 14561.511881828308
  time_this_iter_s: 43.71402978897095
  time_total_s: 14561.511881828308
  timestamp: 1594166748
  timesteps_since_restore: 9810000
  timesteps_this_iter: 30000
  timesteps_total: 9810000
  training_iteration: 327
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 14561 s, 327 iter, 9810000 ts, 1.22e+03 rew

agent-1: 46.0
agent-2: 52.0
agent-3: 36.0
agent-4: 53.0
agent-5: 70.0
agent-6: 56.0
agent-7: 54.0
agent-8: 29.0
agent-9: 34.0
agent-10: 50.0
agent-11: 85.0
agent-12: 27.0
agent-13: 44.0
agent-14: 19.0
agent-15: 34.0
agent-16: 45.0
agent-17: 57.0
agent-18: 51.0
agent-19: 54.0
agent-20: 26.0
agent-21: 62.0
agent-22: 60.0
agent-23: 40.0
agent-24: 64.0
agent-25: 61.0
agent-26: 49.0
agent-27: 46.0
agent-28: 43.0
agent-29: 47.0
agent-30: 63.0
Sum Reward: 1457.0
Avg Reward: 48.56666666666667
Min Reward: 19.0
Max Reward: 85.0
Gini Coefficient: 0.16071837108213224
20:20 Ratio: 2.396449704142012
Max-min Ratio: 4.473684210526316
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-06-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1580.0
  episode_reward_mean: 1221.49
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 327
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.77
    dispatch_time_ms: 51.36
    learner:
      cur_lr: 0.000706653983797878
      grad_gnorm: 28.84868812561035
      policy_entropy: 142.65692138671875
      policy_loss: 1.7463610172271729
      var_gnorm: 23.61937713623047
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 49.79236602783203
    num_steps_sampled: 9840000
    num_steps_trained: 9840000
    wait_time_ms: 375.431
  iterations_since_restore: 328
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 14608.050847053528
  time_this_iter_s: 46.53896522521973
  time_total_s: 14608.050847053528
  timestamp: 1594166795
  timesteps_since_restore: 9840000
  timesteps_this_iter: 30000
  timesteps_total: 9840000
  training_iteration: 328
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 14608 s, 328 iter, 9840000 ts, 1.22e+03 rew

agent-1: 42.0
agent-2: 41.0
agent-3: 78.0
agent-4: 50.0
agent-5: 50.0
agent-6: 37.0
agent-7: 65.0
agent-8: 56.0
agent-9: 51.0
agent-10: 60.0
agent-11: 49.0
agent-12: 72.0
agent-13: 84.0
agent-14: 34.0
agent-15: 50.0
agent-16: 69.0
agent-17: 38.0
agent-18: 31.0
agent-19: 40.0
agent-20: 68.0
agent-21: 34.0
agent-22: 32.0
agent-23: 55.0
agent-24: 57.0
agent-25: 71.0
agent-26: 51.0
agent-27: 88.0
agent-28: 53.0
agent-29: 22.0
agent-30: 53.0
Sum Reward: 1581.0
Avg Reward: 52.7
Min Reward: 22.0
Max Reward: 88.0
Gini Coefficient: 0.17231709888256377
20:20 Ratio: 2.431578947368421
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-07-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1581.0
  episode_reward_mean: 1224.42
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 328
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.458
    dispatch_time_ms: 7.35
    learner:
      cur_lr: 0.0007046560058370233
      grad_gnorm: 40.000003814697266
      policy_entropy: 138.77926635742188
      policy_loss: 8.464212417602539
      var_gnorm: 23.624372482299805
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 61.462242126464844
    num_steps_sampled: 9870000
    num_steps_trained: 9870000
    wait_time_ms: 448.724
  iterations_since_restore: 329
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 14650.899740695953
  time_this_iter_s: 42.84889364242554
  time_total_s: 14650.899740695953
  timestamp: 1594166838
  timesteps_since_restore: 9870000
  timesteps_this_iter: 30000
  timesteps_total: 9870000
  training_iteration: 329
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 14650 s, 329 iter, 9870000 ts, 1.22e+03 rew

agent-1: 25.0
agent-2: 19.0
agent-3: 17.0
agent-4: 51.0
agent-5: 37.0
agent-6: 34.0
agent-7: 49.0
agent-8: 41.0
agent-9: 15.0
agent-10: 51.0
agent-11: 53.0
agent-12: 52.0
agent-13: 24.0
agent-14: 28.0
agent-15: 22.0
agent-16: 15.0
agent-17: 55.0
agent-18: 34.0
agent-19: 55.0
agent-20: 48.0
agent-21: 43.0
agent-22: 28.0
agent-23: 50.0
agent-24: 35.0
agent-25: 6.0
agent-26: 46.0
agent-27: 30.0
agent-28: 62.0
agent-29: 43.0
agent-30: 38.0
Sum Reward: 1106.0
Avg Reward: 36.86666666666667
Min Reward: 6.0
Max Reward: 62.0
Gini Coefficient: 0.22224231464737793
20:20 Ratio: 3.4893617021276597
Max-min Ratio: 10.333333333333334
agent-1: 44.0
agent-2: 47.0
agent-3: 44.0
agent-4: 42.0
agent-5: 17.0
agent-6: 39.0
agent-7: 54.0
agent-8: 36.0
agent-9: 50.0
agent-10: 31.0
agent-11: 30.0
agent-12: 57.0
agent-13: 43.0
agent-14: 62.0
agent-15: 22.0
agent-16: 46.0
agent-17: 48.0
agent-18: 45.0
agent-19: 41.0
agent-20: 48.0
agent-21: 42.0
agent-22: 43.0
agent-23: 40.0
agent-24: 61.0
agent-25: 58.0
agent-26: 29.0
agent-27: 39.0
agent-28: 29.0
agent-29: 48.0
agent-30: 49.0
Sum Reward: 1284.0
Avg Reward: 42.8
Min Reward: 17.0
Max Reward: 62.0
Gini Coefficient: 0.13639667705088265
20:20 Ratio: 2.1645569620253164
Max-min Ratio: 3.6470588235294117
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-08-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1581.0
  episode_reward_mean: 1223.96
  episode_reward_min: 884.0
  episodes_this_iter: 2
  episodes_total: 330
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.861
    dispatch_time_ms: 5.353
    learner:
      cur_lr: 0.0007026580278761685
      grad_gnorm: 40.0
      policy_entropy: 157.22413635253906
      policy_loss: -329.9365234375
      var_gnorm: 23.61617660522461
      vf_explained_var: -3.5762786865234375e-07
      vf_loss: 624.3969116210938
    num_steps_sampled: 9900000
    num_steps_trained: 9900000
    wait_time_ms: 448.847
  iterations_since_restore: 330
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 14696.008695840836
  time_this_iter_s: 45.1089551448822
  time_total_s: 14696.008695840836
  timestamp: 1594166883
  timesteps_since_restore: 9900000
  timesteps_this_iter: 30000
  timesteps_total: 9900000
  training_iteration: 330
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 14696 s, 330 iter, 9900000 ts, 1.22e+03 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-08-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1581.0
  episode_reward_mean: 1223.96
  episode_reward_min: 884.0
  episodes_this_iter: 0
  episodes_total: 330
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.209
    dispatch_time_ms: 6.057
    learner:
      cur_lr: 0.0007006599917076528
      grad_gnorm: 40.000003814697266
      policy_entropy: 142.7229461669922
      policy_loss: -18.3378849029541
      var_gnorm: 23.62150001525879
      vf_explained_var: 0.0
      vf_loss: 25.784717559814453
    num_steps_sampled: 9930000
    num_steps_trained: 9930000
    wait_time_ms: 429.325
  iterations_since_restore: 331
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 14738.571620941162
  time_this_iter_s: 42.56292510032654
  time_total_s: 14738.571620941162
  timestamp: 1594166926
  timesteps_since_restore: 9930000
  timesteps_this_iter: 30000
  timesteps_total: 9930000
  training_iteration: 331
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 14738 s, 331 iter, 9930000 ts, 1.22e+03 rew

agent-1: 29.0
agent-2: 51.0
agent-3: 40.0
agent-4: 42.0
agent-5: 41.0
agent-6: 35.0
agent-7: 63.0
agent-8: 39.0
agent-9: 42.0
agent-10: 42.0
agent-11: 58.0
agent-12: 42.0
agent-13: 65.0
agent-14: 46.0
agent-15: 62.0
agent-16: 32.0
agent-17: 39.0
agent-18: 32.0
agent-19: 35.0
agent-20: 49.0
agent-21: 56.0
agent-22: 50.0
agent-23: 67.0
agent-24: 45.0
agent-25: 33.0
agent-26: 12.0
agent-27: 45.0
agent-28: 52.0
agent-29: 40.0
agent-30: 51.0
Sum Reward: 1335.0
Avg Reward: 44.5
Min Reward: 12.0
Max Reward: 67.0
Gini Coefficient: 0.14559300873907616
20:20 Ratio: 2.1445086705202314
Max-min Ratio: 5.583333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-09-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1581.0
  episode_reward_mean: 1222.51
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 331
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 4.286
    dispatch_time_ms: 5.836
    learner:
      cur_lr: 0.000698662013746798
      grad_gnorm: 40.0
      policy_entropy: 118.34785461425781
      policy_loss: -9.937973022460938
      var_gnorm: 23.616458892822266
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 3.081101894378662
    num_steps_sampled: 9960000
    num_steps_trained: 9960000
    wait_time_ms: 405.085
  iterations_since_restore: 332
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 14783.161811590195
  time_this_iter_s: 44.59019064903259
  time_total_s: 14783.161811590195
  timestamp: 1594166970
  timesteps_since_restore: 9960000
  timesteps_this_iter: 30000
  timesteps_total: 9960000
  training_iteration: 332
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 14783 s, 332 iter, 9960000 ts, 1.22e+03 rew

agent-1: 37.0
agent-2: 41.0
agent-3: 36.0
agent-4: 37.0
agent-5: 34.0
agent-6: 45.0
agent-7: 44.0
agent-8: 44.0
agent-9: 29.0
agent-10: 33.0
agent-11: 23.0
agent-12: 37.0
agent-13: 43.0
agent-14: 66.0
agent-15: 53.0
agent-16: 33.0
agent-17: 20.0
agent-18: 72.0
agent-19: 22.0
agent-20: 18.0
agent-21: 39.0
agent-22: 33.0
agent-23: 29.0
agent-24: 17.0
agent-25: 60.0
agent-26: 30.0
agent-27: 71.0
agent-28: 24.0
agent-29: 37.0
agent-30: 48.0
Sum Reward: 1155.0
Avg Reward: 38.5
Min Reward: 17.0
Max Reward: 72.0
Gini Coefficient: 0.20366522366522366
20:20 Ratio: 2.9838709677419355
Max-min Ratio: 4.235294117647059
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-10-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1581.0
  episode_reward_mean: 1222.32
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 332
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.539
    dispatch_time_ms: 5.162
    learner:
      cur_lr: 0.0006966639775782824
      grad_gnorm: 40.0
      policy_entropy: 136.9491729736328
      policy_loss: 19.37061882019043
      var_gnorm: 23.63120460510254
      vf_explained_var: 0.0
      vf_loss: 74.93488311767578
    num_steps_sampled: 9990000
    num_steps_trained: 9990000
    wait_time_ms: 427.582
  iterations_since_restore: 333
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 14825.859282970428
  time_this_iter_s: 42.697471380233765
  time_total_s: 14825.859282970428
  timestamp: 1594167013
  timesteps_since_restore: 9990000
  timesteps_this_iter: 30000
  timesteps_total: 9990000
  training_iteration: 333
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 14825 s, 333 iter, 9990000 ts, 1.22e+03 rew

agent-1: 50.0
agent-2: 62.0
agent-3: 50.0
agent-4: 39.0
agent-5: 35.0
agent-6: 55.0
agent-7: 30.0
agent-8: 46.0
agent-9: 49.0
agent-10: 30.0
agent-11: 35.0
agent-12: 46.0
agent-13: 41.0
agent-14: 35.0
agent-15: 34.0
agent-16: 40.0
agent-17: 30.0
agent-18: 45.0
agent-19: 70.0
agent-20: 22.0
agent-21: 26.0
agent-22: 43.0
agent-23: 42.0
agent-24: 33.0
agent-25: 43.0
agent-26: 40.0
agent-27: 30.0
agent-28: 34.0
agent-29: 40.0
agent-30: 58.0
Sum Reward: 1233.0
Avg Reward: 41.1
Min Reward: 22.0
Max Reward: 70.0
Gini Coefficient: 0.1433630711002974
20:20 Ratio: 2.0535714285714284
Max-min Ratio: 3.1818181818181817
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-10-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1581.0
  episode_reward_mean: 1221.55
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 333
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.738
    dispatch_time_ms: 6.205
    learner:
      cur_lr: 0.0006946659996174276
      grad_gnorm: 40.0
      policy_entropy: 118.292724609375
      policy_loss: 7.350792407989502
      var_gnorm: 23.625898361206055
      vf_explained_var: 0.0
      vf_loss: 53.974212646484375
    num_steps_sampled: 10020000
    num_steps_trained: 10020000
    wait_time_ms: 432.912
  iterations_since_restore: 334
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 14870.346961259842
  time_this_iter_s: 44.48767828941345
  time_total_s: 14870.346961259842
  timestamp: 1594167058
  timesteps_since_restore: 10020000
  timesteps_this_iter: 30000
  timesteps_total: 10020000
  training_iteration: 334
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 14870 s, 334 iter, 10020000 ts, 1.22e+03 rew

agent-1: 45.0
agent-2: 44.0
agent-3: 52.0
agent-4: 48.0
agent-5: 46.0
agent-6: 52.0
agent-7: 28.0
agent-8: 41.0
agent-9: 65.0
agent-10: 43.0
agent-11: 41.0
agent-12: 39.0
agent-13: 29.0
agent-14: 40.0
agent-15: 47.0
agent-16: 60.0
agent-17: 57.0
agent-18: 61.0
agent-19: 40.0
agent-20: 32.0
agent-21: 75.0
agent-22: 53.0
agent-23: 37.0
agent-24: 57.0
agent-25: 55.0
agent-26: 60.0
agent-27: 88.0
agent-28: 40.0
agent-29: 45.0
agent-30: 74.0
Sum Reward: 1494.0
Avg Reward: 49.8
Min Reward: 28.0
Max Reward: 88.0
Gini Coefficient: 0.14872824631860776
20:20 Ratio: 2.0634146341463415
Max-min Ratio: 3.142857142857143
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-11-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1581.0
  episode_reward_mean: 1222.35
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 334
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.408
    dispatch_time_ms: 5.53
    learner:
      cur_lr: 0.0006926680216565728
      grad_gnorm: 40.0
      policy_entropy: 125.75505065917969
      policy_loss: 14.069299697875977
      var_gnorm: 23.63451385498047
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 73.75553894042969
    num_steps_sampled: 10050000
    num_steps_trained: 10050000
    wait_time_ms: 433.297
  iterations_since_restore: 335
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 14912.115619897842
  time_this_iter_s: 41.76865863800049
  time_total_s: 14912.115619897842
  timestamp: 1594167100
  timesteps_since_restore: 10050000
  timesteps_this_iter: 30000
  timesteps_total: 10050000
  training_iteration: 335
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 14912 s, 335 iter, 10050000 ts, 1.22e+03 rew

agent-1: 50.0
agent-2: 44.0
agent-3: 56.0
agent-4: 31.0
agent-5: 44.0
agent-6: 34.0
agent-7: 62.0
agent-8: 40.0
agent-9: 79.0
agent-10: 74.0
agent-11: 38.0
agent-12: 89.0
agent-13: 41.0
agent-14: 70.0
agent-15: 37.0
agent-16: 53.0
agent-17: 22.0
agent-18: 63.0
agent-19: 60.0
agent-20: 56.0
agent-21: 63.0
agent-22: 50.0
agent-23: 73.0
agent-24: 106.0
agent-25: 54.0
agent-26: 57.0
agent-27: 47.0
agent-28: 60.0
agent-29: 53.0
agent-30: 60.0
Sum Reward: 1666.0
Avg Reward: 55.53333333333333
Min Reward: 22.0
Max Reward: 106.0
Gini Coefficient: 0.17026810724289715
20:20 Ratio: 2.4306930693069306
Max-min Ratio: 4.818181818181818
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-12-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1227.1
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 335
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.496
    dispatch_time_ms: 6.024
    learner:
      cur_lr: 0.0006906699854880571
      grad_gnorm: 40.0
      policy_entropy: 197.94554138183594
      policy_loss: 21.748241424560547
      var_gnorm: 23.632080078125
      vf_explained_var: 0.0
      vf_loss: 102.02044677734375
    num_steps_sampled: 10080000
    num_steps_trained: 10080000
    wait_time_ms: 385.027
  iterations_since_restore: 336
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 14955.965549468994
  time_this_iter_s: 43.84992957115173
  time_total_s: 14955.965549468994
  timestamp: 1594167143
  timesteps_since_restore: 10080000
  timesteps_this_iter: 30000
  timesteps_total: 10080000
  training_iteration: 336
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 14955 s, 336 iter, 10080000 ts, 1.23e+03 rew

agent-1: 53.0
agent-2: 65.0
agent-3: 27.0
agent-4: 51.0
agent-5: 22.0
agent-6: 65.0
agent-7: 91.0
agent-8: 69.0
agent-9: 71.0
agent-10: 37.0
agent-11: 65.0
agent-12: 69.0
agent-13: 38.0
agent-14: 23.0
agent-15: 29.0
agent-16: 92.0
agent-17: 40.0
agent-18: 35.0
agent-19: 68.0
agent-20: 44.0
agent-21: 62.0
agent-22: 61.0
agent-23: 77.0
agent-24: 43.0
agent-25: 47.0
agent-26: 64.0
agent-27: 34.0
agent-28: 61.0
agent-29: 50.0
agent-30: 38.0
Sum Reward: 1591.0
Avg Reward: 53.03333333333333
Min Reward: 22.0
Max Reward: 92.0
Gini Coefficient: 0.19780012570710245
20:20 Ratio: 2.7588235294117647
Max-min Ratio: 4.181818181818182
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-13-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1233.36
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 336
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.756
    dispatch_time_ms: 6.485
    learner:
      cur_lr: 0.0006886720075272024
      grad_gnorm: 39.999996185302734
      policy_entropy: 189.50711059570312
      policy_loss: -17.727344512939453
      var_gnorm: 23.634878158569336
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 58.15721893310547
    num_steps_sampled: 10110000
    num_steps_trained: 10110000
    wait_time_ms: 429.869
  iterations_since_restore: 337
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 14999.077220916748
  time_this_iter_s: 43.111671447753906
  time_total_s: 14999.077220916748
  timestamp: 1594167187
  timesteps_since_restore: 10110000
  timesteps_this_iter: 30000
  timesteps_total: 10110000
  training_iteration: 337
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 14999 s, 337 iter, 10110000 ts, 1.23e+03 rew

agent-1: 44.0
agent-2: 28.0
agent-3: 32.0
agent-4: 44.0
agent-5: 34.0
agent-6: 28.0
agent-7: 73.0
agent-8: 54.0
agent-9: 41.0
agent-10: 58.0
agent-11: 26.0
agent-12: 44.0
agent-13: 15.0
agent-14: 39.0
agent-15: 25.0
agent-16: 23.0
agent-17: 59.0
agent-18: 60.0
agent-19: 44.0
agent-20: 40.0
agent-21: 17.0
agent-22: 67.0
agent-23: 55.0
agent-24: 42.0
agent-25: 48.0
agent-26: 62.0
agent-27: 45.0
agent-28: 55.0
agent-29: 41.0
agent-30: 33.0
Sum Reward: 1276.0
Avg Reward: 42.53333333333333
Min Reward: 15.0
Max Reward: 73.0
Gini Coefficient: 0.19367816091954024
20:20 Ratio: 2.828358208955224
Max-min Ratio: 4.866666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-13-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1234.68
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 337
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.127
    dispatch_time_ms: 40.737
    learner:
      cur_lr: 0.0006866739713586867
      grad_gnorm: 40.0
      policy_entropy: 215.6484375
      policy_loss: 121.15968322753906
      var_gnorm: 23.623828887939453
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 165.8275146484375
    num_steps_sampled: 10140000
    num_steps_trained: 10140000
    wait_time_ms: 370.542
  iterations_since_restore: 338
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 15045.321548461914
  time_this_iter_s: 46.244327545166016
  time_total_s: 15045.321548461914
  timestamp: 1594167233
  timesteps_since_restore: 10140000
  timesteps_this_iter: 30000
  timesteps_total: 10140000
  training_iteration: 338
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 15045 s, 338 iter, 10140000 ts, 1.23e+03 rew

agent-1: 52.0
agent-2: 22.0
agent-3: 23.0
agent-4: 31.0
agent-5: 43.0
agent-6: 35.0
agent-7: 55.0
agent-8: 40.0
agent-9: 35.0
agent-10: 34.0
agent-11: 61.0
agent-12: 46.0
agent-13: 37.0
agent-14: 58.0
agent-15: 32.0
agent-16: 45.0
agent-17: 32.0
agent-18: 33.0
agent-19: 31.0
agent-20: 39.0
agent-21: 14.0
agent-22: 62.0
agent-23: 51.0
agent-24: 21.0
agent-25: 22.0
agent-26: 43.0
agent-27: 55.0
agent-28: 47.0
agent-29: 44.0
agent-30: 34.0
Sum Reward: 1177.0
Avg Reward: 39.233333333333334
Min Reward: 14.0
Max Reward: 62.0
Gini Coefficient: 0.17816482582837723
20:20 Ratio: 2.5789473684210527
Max-min Ratio: 4.428571428571429
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-14-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1236.62
  episode_reward_min: 884.0
  episodes_this_iter: 1
  episodes_total: 338
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.712
    dispatch_time_ms: 26.586
    learner:
      cur_lr: 0.0006846759933978319
      grad_gnorm: 40.000003814697266
      policy_entropy: 224.31448364257812
      policy_loss: -4.5651445388793945
      var_gnorm: 23.631267547607422
      vf_explained_var: 0.0
      vf_loss: 31.041139602661133
    num_steps_sampled: 10170000
    num_steps_trained: 10170000
    wait_time_ms: 447.377
  iterations_since_restore: 339
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 15090.278900384903
  time_this_iter_s: 44.95735192298889
  time_total_s: 15090.278900384903
  timestamp: 1594167278
  timesteps_since_restore: 10170000
  timesteps_this_iter: 30000
  timesteps_total: 10170000
  training_iteration: 339
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 15090 s, 339 iter, 10170000 ts, 1.24e+03 rew

agent-1: 42.0
agent-2: 55.0
agent-3: 33.0
agent-4: 51.0
agent-5: 51.0
agent-6: 20.0
agent-7: 32.0
agent-8: 41.0
agent-9: 50.0
agent-10: 37.0
agent-11: 52.0
agent-12: 48.0
agent-13: 44.0
agent-14: 37.0
agent-15: 46.0
agent-16: 37.0
agent-17: 47.0
agent-18: 15.0
agent-19: 67.0
agent-20: 37.0
agent-21: 38.0
agent-22: 64.0
agent-23: 63.0
agent-24: 21.0
agent-25: 24.0
agent-26: 48.0
agent-27: 51.0
agent-28: 74.0
agent-29: 59.0
agent-30: 76.0
Sum Reward: 1360.0
Avg Reward: 45.333333333333336
Min Reward: 15.0
Max Reward: 76.0
Gini Coefficient: 0.1846078431372549
20:20 Ratio: 2.779310344827586
Max-min Ratio: 5.066666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-15-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1241.38
  episode_reward_min: 888.0
  episodes_this_iter: 1
  episodes_total: 339
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.871
    dispatch_time_ms: 6.296
    learner:
      cur_lr: 0.0006826780154369771
      grad_gnorm: 40.0
      policy_entropy: 274.5086975097656
      policy_loss: -5.676198959350586
      var_gnorm: 23.61992073059082
      vf_explained_var: 0.0
      vf_loss: 33.37299346923828
    num_steps_sampled: 10200000
    num_steps_trained: 10200000
    wait_time_ms: 406.882
  iterations_since_restore: 340
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 15135.958024978638
  time_this_iter_s: 45.67912459373474
  time_total_s: 15135.958024978638
  timestamp: 1594167324
  timesteps_since_restore: 10200000
  timesteps_this_iter: 30000
  timesteps_total: 10200000
  training_iteration: 340
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 15135 s, 340 iter, 10200000 ts, 1.24e+03 rew

agent-1: 13.0
agent-2: 13.0
agent-3: 20.0
agent-4: 31.0
agent-5: 23.0
agent-6: 24.0
agent-7: 29.0
agent-8: 46.0
agent-9: 39.0
agent-10: 34.0
agent-11: 33.0
agent-12: 42.0
agent-13: 30.0
agent-14: 58.0
agent-15: 47.0
agent-16: 44.0
agent-17: 36.0
agent-18: 53.0
agent-19: 48.0
agent-20: 42.0
agent-21: 29.0
agent-22: 35.0
agent-23: 63.0
agent-24: 29.0
agent-25: 25.0
agent-26: 46.0
agent-27: 26.0
agent-28: 25.0
agent-29: 31.0
agent-30: 33.0
Sum Reward: 1047.0
Avg Reward: 34.9
Min Reward: 13.0
Max Reward: 63.0
Gini Coefficient: 0.19251830627188793
20:20 Ratio: 2.669491525423729
Max-min Ratio: 4.846153846153846
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-16-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1237.48
  episode_reward_min: 888.0
  episodes_this_iter: 1
  episodes_total: 340
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.573
    dispatch_time_ms: 9.473
    learner:
      cur_lr: 0.0006806799792684615
      grad_gnorm: 40.0
      policy_entropy: 266.09588623046875
      policy_loss: -10.210968017578125
      var_gnorm: 23.623897552490234
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 18.053028106689453
    num_steps_sampled: 10230000
    num_steps_trained: 10230000
    wait_time_ms: 447.356
  iterations_since_restore: 341
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 15180.307952165604
  time_this_iter_s: 44.34992718696594
  time_total_s: 15180.307952165604
  timestamp: 1594167368
  timesteps_since_restore: 10230000
  timesteps_this_iter: 30000
  timesteps_total: 10230000
  training_iteration: 341
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 15180 s, 341 iter, 10230000 ts, 1.24e+03 rew

agent-1: 22.0
agent-2: 19.0
agent-3: 26.0
agent-4: 27.0
agent-5: 29.0
agent-6: 20.0
agent-7: 19.0
agent-8: 27.0
agent-9: 46.0
agent-10: 31.0
agent-11: 14.0
agent-12: 54.0
agent-13: 21.0
agent-14: 28.0
agent-15: 30.0
agent-16: 15.0
agent-17: 27.0
agent-18: 37.0
agent-19: 41.0
agent-20: 39.0
agent-21: 28.0
agent-22: 55.0
agent-23: 56.0
agent-24: 23.0
agent-25: 33.0
agent-26: 49.0
agent-27: 13.0
agent-28: 26.0
agent-29: 23.0
agent-30: 23.0
Sum Reward: 901.0
Avg Reward: 30.033333333333335
Min Reward: 13.0
Max Reward: 56.0
Gini Coefficient: 0.21572327044025158
20:20 Ratio: 3.01
Max-min Ratio: 4.3076923076923075
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-16-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1233.72
  episode_reward_min: 888.0
  episodes_this_iter: 1
  episodes_total: 341
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.684
    dispatch_time_ms: 8.03
    learner:
      cur_lr: 0.0006786820013076067
      grad_gnorm: 39.999996185302734
      policy_entropy: 225.5382843017578
      policy_loss: 116.02943420410156
      var_gnorm: 23.608137130737305
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 203.8035125732422
    num_steps_sampled: 10260000
    num_steps_trained: 10260000
    wait_time_ms: 419.938
  iterations_since_restore: 342
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 15225.191721916199
  time_this_iter_s: 44.88376975059509
  time_total_s: 15225.191721916199
  timestamp: 1594167413
  timesteps_since_restore: 10260000
  timesteps_this_iter: 30000
  timesteps_total: 10260000
  training_iteration: 342
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 15225 s, 342 iter, 10260000 ts, 1.23e+03 rew

agent-1: 27.0
agent-2: 42.0
agent-3: 40.0
agent-4: 30.0
agent-5: 29.0
agent-6: 76.0
agent-7: 26.0
agent-8: 37.0
agent-9: 24.0
agent-10: 30.0
agent-11: 25.0
agent-12: 26.0
agent-13: 19.0
agent-14: 39.0
agent-15: 28.0
agent-16: 49.0
agent-17: 38.0
agent-18: 27.0
agent-19: 21.0
agent-20: 25.0
agent-21: 20.0
agent-22: 39.0
agent-23: 35.0
agent-24: 49.0
agent-25: 47.0
agent-26: 56.0
agent-27: 37.0
agent-28: 24.0
agent-29: 26.0
agent-30: 50.0
Sum Reward: 1041.0
Avg Reward: 34.7
Min Reward: 19.0
Max Reward: 76.0
Gini Coefficient: 0.18927313480627603
20:20 Ratio: 2.4586466165413534
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-17-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1232.73
  episode_reward_min: 888.0
  episodes_this_iter: 1
  episodes_total: 342
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.019
    dispatch_time_ms: 30.791
    learner:
      cur_lr: 0.0006766840233467519
      grad_gnorm: 40.0
      policy_entropy: 202.62277221679688
      policy_loss: -23.833084106445312
      var_gnorm: 23.627593994140625
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.579193115234375
    num_steps_sampled: 10290000
    num_steps_trained: 10290000
    wait_time_ms: 432.66
  iterations_since_restore: 343
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 15270.87187743187
  time_this_iter_s: 45.680155515670776
  time_total_s: 15270.87187743187
  timestamp: 1594167459
  timesteps_since_restore: 10290000
  timesteps_this_iter: 30000
  timesteps_total: 10290000
  training_iteration: 343
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 15270 s, 343 iter, 10290000 ts, 1.23e+03 rew

agent-1: 51.0
agent-2: 44.0
agent-3: 18.0
agent-4: 26.0
agent-5: 40.0
agent-6: 40.0
agent-7: 44.0
agent-8: 37.0
agent-9: 40.0
agent-10: 33.0
agent-11: 55.0
agent-12: 49.0
agent-13: 49.0
agent-14: 44.0
agent-15: 31.0
agent-16: 71.0
agent-17: 46.0
agent-18: 40.0
agent-19: 44.0
agent-20: 12.0
agent-21: 26.0
agent-22: 50.0
agent-23: 37.0
agent-24: 47.0
agent-25: 57.0
agent-26: 34.0
agent-27: 35.0
agent-28: 51.0
agent-29: 25.0
agent-30: 36.0
Sum Reward: 1212.0
Avg Reward: 40.4
Min Reward: 12.0
Max Reward: 71.0
Gini Coefficient: 0.16177117711771177
20:20 Ratio: 2.427536231884058
Max-min Ratio: 5.916666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-18-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1233.27
  episode_reward_min: 888.0
  episodes_this_iter: 1
  episodes_total: 343
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 4.819
    dispatch_time_ms: 5.548
    learner:
      cur_lr: 0.0006746859871782362
      grad_gnorm: 40.0
      policy_entropy: 203.6569061279297
      policy_loss: -14.804518699645996
      var_gnorm: 23.624425888061523
      vf_explained_var: 3.5762786865234375e-07
      vf_loss: 2.804032325744629
    num_steps_sampled: 10320000
    num_steps_trained: 10320000
    wait_time_ms: 405.286
  iterations_since_restore: 344
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 15315.521190166473
  time_this_iter_s: 44.64931273460388
  time_total_s: 15315.521190166473
  timestamp: 1594167503
  timesteps_since_restore: 10320000
  timesteps_this_iter: 30000
  timesteps_total: 10320000
  training_iteration: 344
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 15315 s, 344 iter, 10320000 ts, 1.23e+03 rew

agent-1: 32.0
agent-2: 36.0
agent-3: 57.0
agent-4: 21.0
agent-5: 19.0
agent-6: 24.0
agent-7: 42.0
agent-8: 45.0
agent-9: 30.0
agent-10: 46.0
agent-11: 52.0
agent-12: 45.0
agent-13: 30.0
agent-14: 33.0
agent-15: 31.0
agent-16: 40.0
agent-17: 19.0
agent-18: 42.0
agent-19: 42.0
agent-20: 33.0
agent-21: 28.0
agent-22: 14.0
agent-23: 36.0
agent-24: 53.0
agent-25: 34.0
agent-26: 37.0
agent-27: 29.0
agent-28: 47.0
agent-29: 38.0
agent-30: 36.0
Sum Reward: 1071.0
Avg Reward: 35.7
Min Reward: 14.0
Max Reward: 57.0
Gini Coefficient: 0.16293183940242764
20:20 Ratio: 2.4
Max-min Ratio: 4.071428571428571
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-19-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1230.74
  episode_reward_min: 888.0
  episodes_this_iter: 1
  episodes_total: 344
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.698
    dispatch_time_ms: 5.403
    learner:
      cur_lr: 0.0006726880092173815
      grad_gnorm: 39.999996185302734
      policy_entropy: 226.919189453125
      policy_loss: -31.499561309814453
      var_gnorm: 23.632915496826172
      vf_explained_var: 0.0
      vf_loss: 10.294361114501953
    num_steps_sampled: 10350000
    num_steps_trained: 10350000
    wait_time_ms: 442.818
  iterations_since_restore: 345
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 15359.280529499054
  time_this_iter_s: 43.759339332580566
  time_total_s: 15359.280529499054
  timestamp: 1594167547
  timesteps_since_restore: 10350000
  timesteps_this_iter: 30000
  timesteps_total: 10350000
  training_iteration: 345
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 15359 s, 345 iter, 10350000 ts, 1.23e+03 rew

agent-1: 48.0
agent-2: 15.0
agent-3: 37.0
agent-4: 49.0
agent-5: 51.0
agent-6: 27.0
agent-7: 41.0
agent-8: 32.0
agent-9: 22.0
agent-10: 32.0
agent-11: 32.0
agent-12: 40.0
agent-13: 59.0
agent-14: 21.0
agent-15: 34.0
agent-16: 50.0
agent-17: 24.0
agent-18: 43.0
agent-19: 59.0
agent-20: 44.0
agent-21: 13.0
agent-22: 35.0
agent-23: 45.0
agent-24: 33.0
agent-25: 38.0
agent-26: 44.0
agent-27: 32.0
agent-28: 59.0
agent-29: 19.0
agent-30: 45.0
Sum Reward: 1123.0
Avg Reward: 37.43333333333333
Min Reward: 13.0
Max Reward: 59.0
Gini Coefficient: 0.18869100623330365
20:20 Ratio: 2.8684210526315788
Max-min Ratio: 4.538461538461538
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-19-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1226.86
  episode_reward_min: 888.0
  episodes_this_iter: 1
  episodes_total: 345
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.537
    dispatch_time_ms: 6.15
    learner:
      cur_lr: 0.0006706899730488658
      grad_gnorm: 40.0
      policy_entropy: 193.47364807128906
      policy_loss: 43.61834716796875
      var_gnorm: 23.62587547302246
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 85.90757751464844
    num_steps_sampled: 10380000
    num_steps_trained: 10380000
    wait_time_ms: 396.641
  iterations_since_restore: 346
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 15403.52216744423
  time_this_iter_s: 44.24163794517517
  time_total_s: 15403.52216744423
  timestamp: 1594167591
  timesteps_since_restore: 10380000
  timesteps_this_iter: 30000
  timesteps_total: 10380000
  training_iteration: 346
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 15403 s, 346 iter, 10380000 ts, 1.23e+03 rew

agent-1: 16.0
agent-2: 28.0
agent-3: 43.0
agent-4: 48.0
agent-5: 41.0
agent-6: 62.0
agent-7: 41.0
agent-8: 39.0
agent-9: 35.0
agent-10: 55.0
agent-11: 82.0
agent-12: 40.0
agent-13: 40.0
agent-14: 40.0
agent-15: 50.0
agent-16: 21.0
agent-17: 75.0
agent-18: 27.0
agent-19: 55.0
agent-20: 38.0
agent-21: 36.0
agent-22: 45.0
agent-23: 31.0
agent-24: 36.0
agent-25: 37.0
agent-26: 70.0
agent-27: 64.0
agent-28: 17.0
agent-29: 20.0
agent-30: 50.0
Sum Reward: 1282.0
Avg Reward: 42.733333333333334
Min Reward: 16.0
Max Reward: 82.0
Gini Coefficient: 0.20889235569422776
20:20 Ratio: 3.1627906976744184
Max-min Ratio: 5.125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-20-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1227.79
  episode_reward_min: 888.0
  episodes_this_iter: 1
  episodes_total: 346
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.777
    dispatch_time_ms: 6.112
    learner:
      cur_lr: 0.000668691995088011
      grad_gnorm: 40.0
      policy_entropy: 155.78933715820312
      policy_loss: 13.391908645629883
      var_gnorm: 23.63470458984375
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 51.284053802490234
    num_steps_sampled: 10410000
    num_steps_trained: 10410000
    wait_time_ms: 444.71
  iterations_since_restore: 347
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 15447.308102607727
  time_this_iter_s: 43.785935163497925
  time_total_s: 15447.308102607727
  timestamp: 1594167635
  timesteps_since_restore: 10410000
  timesteps_this_iter: 30000
  timesteps_total: 10410000
  training_iteration: 347
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 15447 s, 347 iter, 10410000 ts, 1.23e+03 rew

agent-1: 24.0
agent-2: 29.0
agent-3: 75.0
agent-4: 40.0
agent-5: 39.0
agent-6: 39.0
agent-7: 59.0
agent-8: 34.0
agent-9: 67.0
agent-10: 42.0
agent-11: 56.0
agent-12: 34.0
agent-13: 56.0
agent-14: 33.0
agent-15: 44.0
agent-16: 33.0
agent-17: 28.0
agent-18: 43.0
agent-19: 32.0
agent-20: 39.0
agent-21: 65.0
agent-22: 34.0
agent-23: 47.0
agent-24: 28.0
agent-25: 78.0
agent-26: 54.0
agent-27: 37.0
agent-28: 57.0
agent-29: 42.0
agent-30: 79.0
Sum Reward: 1367.0
Avg Reward: 45.56666666666667
Min Reward: 24.0
Max Reward: 79.0
Gini Coefficient: 0.18485735186539867
20:20 Ratio: 2.4310344827586206
Max-min Ratio: 3.2916666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-21-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1230.27
  episode_reward_min: 888.0
  episodes_this_iter: 1
  episodes_total: 347
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.026
    dispatch_time_ms: 7.852
    learner:
      cur_lr: 0.0006666940171271563
      grad_gnorm: 40.0
      policy_entropy: 285.55682373046875
      policy_loss: 30.980648040771484
      var_gnorm: 23.624038696289062
      vf_explained_var: 0.0
      vf_loss: 78.66162872314453
    num_steps_sampled: 10440000
    num_steps_trained: 10440000
    wait_time_ms: 439.338
  iterations_since_restore: 348
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 15491.733177185059
  time_this_iter_s: 44.42507457733154
  time_total_s: 15491.733177185059
  timestamp: 1594167680
  timesteps_since_restore: 10440000
  timesteps_this_iter: 30000
  timesteps_total: 10440000
  training_iteration: 348
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 15491 s, 348 iter, 10440000 ts, 1.23e+03 rew

agent-1: 17.0
agent-2: 26.0
agent-3: 27.0
agent-4: 32.0
agent-5: 39.0
agent-6: 33.0
agent-7: 26.0
agent-8: 45.0
agent-9: 10.0
agent-10: 33.0
agent-11: 32.0
agent-12: 30.0
agent-13: 29.0
agent-14: 33.0
agent-15: 34.0
agent-16: 21.0
agent-17: 50.0
agent-18: 49.0
agent-19: 29.0
agent-20: 39.0
agent-21: 37.0
agent-22: 23.0
agent-23: 29.0
agent-24: 37.0
agent-25: 39.0
agent-26: 30.0
agent-27: 23.0
agent-28: 30.0
agent-29: 48.0
agent-30: 17.0
Sum Reward: 947.0
Avg Reward: 31.566666666666666
Min Reward: 10.0
Max Reward: 50.0
Gini Coefficient: 0.16363956353396691
20:20 Ratio: 2.4324324324324325
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-22-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1228.18
  episode_reward_min: 888.0
  episodes_this_iter: 1
  episodes_total: 348
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.958
    dispatch_time_ms: 5.844
    learner:
      cur_lr: 0.0006646959809586406
      grad_gnorm: 40.0
      policy_entropy: 218.11463928222656
      policy_loss: -17.00980567932129
      var_gnorm: 23.626649856567383
      vf_explained_var: 0.0
      vf_loss: 12.777623176574707
    num_steps_sampled: 10470000
    num_steps_trained: 10470000
    wait_time_ms: 441.541
  iterations_since_restore: 349
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 15535.748404979706
  time_this_iter_s: 44.01522779464722
  time_total_s: 15535.748404979706
  timestamp: 1594167724
  timesteps_since_restore: 10470000
  timesteps_this_iter: 30000
  timesteps_total: 10470000
  training_iteration: 349
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 15535 s, 349 iter, 10470000 ts, 1.23e+03 rew

agent-1: 51.0
agent-2: 50.0
agent-3: 41.0
agent-4: 33.0
agent-5: 24.0
agent-6: 21.0
agent-7: 25.0
agent-8: 12.0
agent-9: 13.0
agent-10: 30.0
agent-11: 43.0
agent-12: 43.0
agent-13: 15.0
agent-14: 36.0
agent-15: 41.0
agent-16: 29.0
agent-17: 33.0
agent-18: 37.0
agent-19: 12.0
agent-20: 36.0
agent-21: 40.0
agent-22: 40.0
agent-23: 42.0
agent-24: 36.0
agent-25: 33.0
agent-26: 43.0
agent-27: 31.0
agent-28: 33.0
agent-29: 34.0
agent-30: 33.0
Sum Reward: 990.0
Avg Reward: 33.0
Min Reward: 12.0
Max Reward: 51.0
Gini Coefficient: 0.17232323232323232
20:20 Ratio: 2.804123711340206
Max-min Ratio: 4.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-22-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1226.2
  episode_reward_min: 888.0
  episodes_this_iter: 1
  episodes_total: 349
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.363
    dispatch_time_ms: 6.458
    learner:
      cur_lr: 0.0006626980029977858
      grad_gnorm: 40.000003814697266
      policy_entropy: 220.95285034179688
      policy_loss: 27.923093795776367
      var_gnorm: 23.612512588500977
      vf_explained_var: -3.5762786865234375e-07
      vf_loss: 62.427650451660156
    num_steps_sampled: 10500000
    num_steps_trained: 10500000
    wait_time_ms: 409.638
  iterations_since_restore: 350
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 15580.564945936203
  time_this_iter_s: 44.81654095649719
  time_total_s: 15580.564945936203
  timestamp: 1594167769
  timesteps_since_restore: 10500000
  timesteps_this_iter: 30000
  timesteps_total: 10500000
  training_iteration: 350
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 15580 s, 350 iter, 10500000 ts, 1.23e+03 rew

agent-1: 31.0
agent-2: 26.0
agent-3: 28.0
agent-4: 42.0
agent-5: 18.0
agent-6: 61.0
agent-7: 15.0
agent-8: 56.0
agent-9: 19.0
agent-10: 29.0
agent-11: 29.0
agent-12: 34.0
agent-13: 65.0
agent-14: 33.0
agent-15: 35.0
agent-16: 24.0
agent-17: 33.0
agent-18: 32.0
agent-19: 24.0
agent-20: 31.0
agent-21: 52.0
agent-22: 39.0
agent-23: 43.0
agent-24: 45.0
agent-25: 53.0
agent-26: 30.0
agent-27: 29.0
agent-28: 37.0
agent-29: 41.0
agent-30: 55.0
Sum Reward: 1089.0
Avg Reward: 36.3
Min Reward: 15.0
Max Reward: 65.0
Gini Coefficient: 0.1928680746862565
20:20 Ratio: 2.7142857142857144
Max-min Ratio: 4.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-23-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1226.36
  episode_reward_min: 888.0
  episodes_this_iter: 1
  episodes_total: 350
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.556
    dispatch_time_ms: 8.112
    learner:
      cur_lr: 0.000660700025036931
      grad_gnorm: 40.0
      policy_entropy: 229.06777954101562
      policy_loss: 88.52802276611328
      var_gnorm: 23.623981475830078
      vf_explained_var: 0.0
      vf_loss: 126.8310775756836
    num_steps_sampled: 10530000
    num_steps_trained: 10530000
    wait_time_ms: 428.534
  iterations_since_restore: 351
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 15624.570856332779
  time_this_iter_s: 44.00591039657593
  time_total_s: 15624.570856332779
  timestamp: 1594167813
  timesteps_since_restore: 10530000
  timesteps_this_iter: 30000
  timesteps_total: 10530000
  training_iteration: 351
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 15624 s, 351 iter, 10530000 ts, 1.23e+03 rew

agent-1: 20.0
agent-2: 33.0
agent-3: 56.0
agent-4: 12.0
agent-5: 30.0
agent-6: 56.0
agent-7: 37.0
agent-8: 17.0
agent-9: 42.0
agent-10: 27.0
agent-11: 29.0
agent-12: 60.0
agent-13: 47.0
agent-14: 66.0
agent-15: 18.0
agent-16: 17.0
agent-17: 23.0
agent-18: 23.0
agent-19: 33.0
agent-20: 49.0
agent-21: 32.0
agent-22: 43.0
agent-23: 49.0
agent-24: 57.0
agent-25: 47.0
agent-26: 14.0
agent-27: 29.0
agent-28: 52.0
agent-29: 36.0
agent-30: 51.0
Sum Reward: 1105.0
Avg Reward: 36.833333333333336
Min Reward: 12.0
Max Reward: 66.0
Gini Coefficient: 0.23466063348416288
20:20 Ratio: 3.5408163265306123
Max-min Ratio: 5.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-24-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1227.83
  episode_reward_min: 888.0
  episodes_this_iter: 1
  episodes_total: 351
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.509
    dispatch_time_ms: 6.167
    learner:
      cur_lr: 0.0006587019888684154
      grad_gnorm: 32.558837890625
      policy_entropy: 194.3754425048828
      policy_loss: -8.184345245361328
      var_gnorm: 23.62016487121582
      vf_explained_var: 0.0
      vf_loss: 35.8858757019043
    num_steps_sampled: 10560000
    num_steps_trained: 10560000
    wait_time_ms: 453.025
  iterations_since_restore: 352
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 15668.701869010925
  time_this_iter_s: 44.13101267814636
  time_total_s: 15668.701869010925
  timestamp: 1594167857
  timesteps_since_restore: 10560000
  timesteps_this_iter: 30000
  timesteps_total: 10560000
  training_iteration: 352
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 15668 s, 352 iter, 10560000 ts, 1.23e+03 rew

agent-1: 52.0
agent-2: 40.0
agent-3: 49.0
agent-4: 55.0
agent-5: 70.0
agent-6: 39.0
agent-7: 37.0
agent-8: 25.0
agent-9: 39.0
agent-10: 56.0
agent-11: 37.0
agent-12: 54.0
agent-13: 25.0
agent-14: 42.0
agent-15: 57.0
agent-16: 31.0
agent-17: 24.0
agent-18: 40.0
agent-19: 48.0
agent-20: 47.0
agent-21: 28.0
agent-22: 37.0
agent-23: 20.0
agent-24: 39.0
agent-25: 39.0
agent-26: 54.0
agent-27: 69.0
agent-28: 21.0
agent-29: 29.0
agent-30: 26.0
Sum Reward: 1229.0
Avg Reward: 40.96666666666667
Min Reward: 20.0
Max Reward: 70.0
Gini Coefficient: 0.18228912394901003
20:20 Ratio: 2.5602836879432624
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-25-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1228.76
  episode_reward_min: 888.0
  episodes_this_iter: 1
  episodes_total: 352
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.851
    dispatch_time_ms: 6.276
    learner:
      cur_lr: 0.0006567040109075606
      grad_gnorm: 40.000003814697266
      policy_entropy: 182.70143127441406
      policy_loss: -5.459316253662109
      var_gnorm: 23.626855850219727
      vf_explained_var: 0.0
      vf_loss: 41.74763870239258
    num_steps_sampled: 10590000
    num_steps_trained: 10590000
    wait_time_ms: 439.22
  iterations_since_restore: 353
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 15712.215527057648
  time_this_iter_s: 43.51365804672241
  time_total_s: 15712.215527057648
  timestamp: 1594167900
  timesteps_since_restore: 10590000
  timesteps_this_iter: 30000
  timesteps_total: 10590000
  training_iteration: 353
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 15712 s, 353 iter, 10590000 ts, 1.23e+03 rew

agent-1: 36.0
agent-2: 31.0
agent-3: 43.0
agent-4: 21.0
agent-5: 68.0
agent-6: 38.0
agent-7: 46.0
agent-8: 29.0
agent-9: 38.0
agent-10: 40.0
agent-11: 52.0
agent-12: 32.0
agent-13: 28.0
agent-14: 44.0
agent-15: 15.0
agent-16: 73.0
agent-17: 34.0
agent-18: 36.0
agent-19: 22.0
agent-20: 25.0
agent-21: 52.0
agent-22: 53.0
agent-23: 38.0
agent-24: 44.0
agent-25: 60.0
agent-26: 30.0
agent-27: 41.0
agent-28: 28.0
agent-29: 23.0
agent-30: 38.0
Sum Reward: 1158.0
Avg Reward: 38.6
Min Reward: 15.0
Max Reward: 73.0
Gini Coefficient: 0.1899251583189407
20:20 Ratio: 2.671641791044776
Max-min Ratio: 4.866666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-25-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1227.18
  episode_reward_min: 888.0
  episodes_this_iter: 1
  episodes_total: 353
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.783
    dispatch_time_ms: 6.412
    learner:
      cur_lr: 0.0006547059747390449
      grad_gnorm: 40.000003814697266
      policy_entropy: 237.3001251220703
      policy_loss: -33.32173156738281
      var_gnorm: 23.616849899291992
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 3.440032958984375
    num_steps_sampled: 10620000
    num_steps_trained: 10620000
    wait_time_ms: 454.415
  iterations_since_restore: 354
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 15756.755675554276
  time_this_iter_s: 44.54014849662781
  time_total_s: 15756.755675554276
  timestamp: 1594167945
  timesteps_since_restore: 10620000
  timesteps_this_iter: 30000
  timesteps_total: 10620000
  training_iteration: 354
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 15756 s, 354 iter, 10620000 ts, 1.23e+03 rew

agent-1: 54.0
agent-2: 37.0
agent-3: 46.0
agent-4: 19.0
agent-5: 60.0
agent-6: 36.0
agent-7: 39.0
agent-8: 26.0
agent-9: 35.0
agent-10: 41.0
agent-11: 33.0
agent-12: 49.0
agent-13: 58.0
agent-14: 28.0
agent-15: 56.0
agent-16: 21.0
agent-17: 54.0
agent-18: 40.0
agent-19: 44.0
agent-20: 32.0
agent-21: 56.0
agent-22: 25.0
agent-23: 27.0
agent-24: 21.0
agent-25: 27.0
agent-26: 60.0
agent-27: 61.0
agent-28: 46.0
agent-29: 34.0
agent-30: 37.0
Sum Reward: 1202.0
Avg Reward: 40.06666666666667
Min Reward: 19.0
Max Reward: 61.0
Gini Coefficient: 0.18319467554076538
20:20 Ratio: 2.5251798561151078
Max-min Ratio: 3.210526315789474
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-26-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1228.91
  episode_reward_min: 888.0
  episodes_this_iter: 1
  episodes_total: 354
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.771
    dispatch_time_ms: 6.4
    learner:
      cur_lr: 0.0006527079967781901
      grad_gnorm: 21.7857666015625
      policy_entropy: 272.06787109375
      policy_loss: -3.6085925102233887
      var_gnorm: 23.686748504638672
      vf_explained_var: 0.0
      vf_loss: 29.127294540405273
    num_steps_sampled: 10650000
    num_steps_trained: 10650000
    wait_time_ms: 424.594
  iterations_since_restore: 355
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 15800.529465913773
  time_this_iter_s: 43.77379035949707
  time_total_s: 15800.529465913773
  timestamp: 1594167989
  timesteps_since_restore: 10650000
  timesteps_this_iter: 30000
  timesteps_total: 10650000
  training_iteration: 355
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 15800 s, 355 iter, 10650000 ts, 1.23e+03 rew

agent-1: 46.0
agent-2: 61.0
agent-3: 26.0
agent-4: 43.0
agent-5: 32.0
agent-6: 36.0
agent-7: 23.0
agent-8: 19.0
agent-9: 36.0
agent-10: 25.0
agent-11: 19.0
agent-12: 29.0
agent-13: 37.0
agent-14: 42.0
agent-15: 24.0
agent-16: 35.0
agent-17: 42.0
agent-18: 46.0
agent-19: 38.0
agent-20: 65.0
agent-21: 18.0
agent-22: 31.0
agent-23: 47.0
agent-24: 39.0
agent-25: 42.0
agent-26: 28.0
agent-27: 31.0
agent-28: 22.0
agent-29: 47.0
agent-30: 66.0
Sum Reward: 1095.0
Avg Reward: 36.5
Min Reward: 18.0
Max Reward: 66.0
Gini Coefficient: 0.19205479452054794
20:20 Ratio: 2.656
Max-min Ratio: 3.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-27-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1229.57
  episode_reward_min: 888.0
  episodes_this_iter: 1
  episodes_total: 355
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.666
    dispatch_time_ms: 5.911
    learner:
      cur_lr: 0.0006507100188173354
      grad_gnorm: 40.000003814697266
      policy_entropy: 264.62744140625
      policy_loss: 19.54833221435547
      var_gnorm: 23.67391586303711
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 46.51795959472656
    num_steps_sampled: 10680000
    num_steps_trained: 10680000
    wait_time_ms: 429.607
  iterations_since_restore: 356
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 15845.32646727562
  time_this_iter_s: 44.797001361846924
  time_total_s: 15845.32646727562
  timestamp: 1594168034
  timesteps_since_restore: 10680000
  timesteps_this_iter: 30000
  timesteps_total: 10680000
  training_iteration: 356
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 15845 s, 356 iter, 10680000 ts, 1.23e+03 rew

agent-1: 42.0
agent-2: 23.0
agent-3: 45.0
agent-4: 38.0
agent-5: 53.0
agent-6: 15.0
agent-7: 59.0
agent-8: 43.0
agent-9: 37.0
agent-10: 30.0
agent-11: 48.0
agent-12: 56.0
agent-13: 44.0
agent-14: 59.0
agent-15: 10.0
agent-16: 25.0
agent-17: 19.0
agent-18: 35.0
agent-19: 51.0
agent-20: 46.0
agent-21: 28.0
agent-22: 40.0
agent-23: 37.0
agent-24: 40.0
agent-25: 45.0
agent-26: 44.0
agent-27: 42.0
agent-28: 36.0
agent-29: 30.0
agent-30: 54.0
Sum Reward: 1174.0
Avg Reward: 39.13333333333333
Min Reward: 10.0
Max Reward: 59.0
Gini Coefficient: 0.175809199318569
20:20 Ratio: 2.7666666666666666
Max-min Ratio: 5.9
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-27-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1230.06
  episode_reward_min: 888.0
  episodes_this_iter: 1
  episodes_total: 356
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.509
    dispatch_time_ms: 6.726
    learner:
      cur_lr: 0.0006487119826488197
      grad_gnorm: 40.0
      policy_entropy: 258.4225769042969
      policy_loss: -32.04285430908203
      var_gnorm: 23.67727279663086
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 3.679014205932617
    num_steps_sampled: 10710000
    num_steps_trained: 10710000
    wait_time_ms: 437.173
  iterations_since_restore: 357
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 15889.800072908401
  time_this_iter_s: 44.47360563278198
  time_total_s: 15889.800072908401
  timestamp: 1594168078
  timesteps_since_restore: 10710000
  timesteps_this_iter: 30000
  timesteps_total: 10710000
  training_iteration: 357
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 15889 s, 357 iter, 10710000 ts, 1.23e+03 rew

agent-1: 46.0
agent-2: 39.0
agent-3: 25.0
agent-4: 28.0
agent-5: 37.0
agent-6: 36.0
agent-7: 14.0
agent-8: 41.0
agent-9: 34.0
agent-10: 22.0
agent-11: 36.0
agent-12: 19.0
agent-13: 47.0
agent-14: 37.0
agent-15: 41.0
agent-16: 31.0
agent-17: 42.0
agent-18: 36.0
agent-19: 55.0
agent-20: 35.0
agent-21: 42.0
agent-22: 32.0
agent-23: 39.0
agent-24: 33.0
agent-25: 30.0
agent-26: 22.0
agent-27: 29.0
agent-28: 50.0
agent-29: 28.0
agent-30: 34.0
Sum Reward: 1040.0
Avg Reward: 34.666666666666664
Min Reward: 14.0
Max Reward: 55.0
Gini Coefficient: 0.14493589743589744
20:20 Ratio: 2.169230769230769
Max-min Ratio: 3.9285714285714284
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-28-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1230.35
  episode_reward_min: 888.0
  episodes_this_iter: 1
  episodes_total: 357
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.663
    dispatch_time_ms: 7.02
    learner:
      cur_lr: 0.0006467140046879649
      grad_gnorm: 9.801362037658691
      policy_entropy: 255.23133850097656
      policy_loss: -2.5222651958465576
      var_gnorm: 23.66966438293457
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 25.1785945892334
    num_steps_sampled: 10740000
    num_steps_trained: 10740000
    wait_time_ms: 432.037
  iterations_since_restore: 358
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 15934.07404589653
  time_this_iter_s: 44.27397298812866
  time_total_s: 15934.07404589653
  timestamp: 1594168122
  timesteps_since_restore: 10740000
  timesteps_this_iter: 30000
  timesteps_total: 10740000
  training_iteration: 358
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 15934 s, 358 iter, 10740000 ts, 1.23e+03 rew

agent-1: 55.0
agent-2: 67.0
agent-3: 56.0
agent-4: 47.0
agent-5: 42.0
agent-6: 38.0
agent-7: 40.0
agent-8: 36.0
agent-9: 37.0
agent-10: 30.0
agent-11: 24.0
agent-12: 46.0
agent-13: 37.0
agent-14: 45.0
agent-15: 42.0
agent-16: 35.0
agent-17: 36.0
agent-18: 31.0
agent-19: 32.0
agent-20: 16.0
agent-21: 34.0
agent-22: 40.0
agent-23: 44.0
agent-24: 16.0
agent-25: 43.0
agent-26: 31.0
agent-27: 42.0
agent-28: 19.0
agent-29: 21.0
agent-30: 47.0
Sum Reward: 1129.0
Avg Reward: 37.63333333333333
Min Reward: 16.0
Max Reward: 67.0
Gini Coefficient: 0.166607617360496
20:20 Ratio: 2.5238095238095237
Max-min Ratio: 4.1875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-29-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1231.42
  episode_reward_min: 888.0
  episodes_this_iter: 1
  episodes_total: 358
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.131
    dispatch_time_ms: 6.471
    learner:
      cur_lr: 0.0006447160267271101
      grad_gnorm: 40.0
      policy_entropy: 248.66241455078125
      policy_loss: -13.675721168518066
      var_gnorm: 23.67449188232422
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 16.253036499023438
    num_steps_sampled: 10770000
    num_steps_trained: 10770000
    wait_time_ms: 446.132
  iterations_since_restore: 359
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 15978.314599752426
  time_this_iter_s: 44.240553855895996
  time_total_s: 15978.314599752426
  timestamp: 1594168167
  timesteps_since_restore: 10770000
  timesteps_this_iter: 30000
  timesteps_total: 10770000
  training_iteration: 359
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 15978 s, 359 iter, 10770000 ts, 1.23e+03 rew

agent-1: 30.0
agent-2: 33.0
agent-3: 23.0
agent-4: 39.0
agent-5: 33.0
agent-6: 44.0
agent-7: 29.0
agent-8: 31.0
agent-9: 21.0
agent-10: 29.0
agent-11: 39.0
agent-12: 26.0
agent-13: 33.0
agent-14: 31.0
agent-15: 25.0
agent-16: 34.0
agent-17: 32.0
agent-18: 38.0
agent-19: 37.0
agent-20: 39.0
agent-21: 37.0
agent-22: 53.0
agent-23: 28.0
agent-24: 28.0
agent-25: 46.0
agent-26: 42.0
agent-27: 23.0
agent-28: 20.0
agent-29: 30.0
agent-30: 39.0
Sum Reward: 992.0
Avg Reward: 33.06666666666667
Min Reward: 20.0
Max Reward: 53.0
Gini Coefficient: 0.12768817204301075
20:20 Ratio: 1.9057971014492754
Max-min Ratio: 2.65
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-30-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1232.46
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 359
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.767
    dispatch_time_ms: 8.45
    learner:
      cur_lr: 0.0006427179905585945
      grad_gnorm: 40.0
      policy_entropy: 237.50038146972656
      policy_loss: -21.632307052612305
      var_gnorm: 23.6658992767334
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.1214680671691895
    num_steps_sampled: 10800000
    num_steps_trained: 10800000
    wait_time_ms: 423.346
  iterations_since_restore: 360
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 16022.920661211014
  time_this_iter_s: 44.60606145858765
  time_total_s: 16022.920661211014
  timestamp: 1594168211
  timesteps_since_restore: 10800000
  timesteps_this_iter: 30000
  timesteps_total: 10800000
  training_iteration: 360
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 16022 s, 360 iter, 10800000 ts, 1.23e+03 rew

agent-1: 49.0
agent-2: 52.0
agent-3: 20.0
agent-4: 60.0
agent-5: 12.0
agent-6: 34.0
agent-7: 49.0
agent-8: 33.0
agent-9: 39.0
agent-10: 16.0
agent-11: 31.0
agent-12: 25.0
agent-13: 41.0
agent-14: 54.0
agent-15: 38.0
agent-16: 48.0
agent-17: 42.0
agent-18: 26.0
agent-19: 30.0
agent-20: 33.0
agent-21: 27.0
agent-22: 49.0
agent-23: 25.0
agent-24: 25.0
agent-25: 14.0
agent-26: 52.0
agent-27: 25.0
agent-28: 24.0
agent-29: 37.0
agent-30: 42.0
Sum Reward: 1052.0
Avg Reward: 35.06666666666667
Min Reward: 12.0
Max Reward: 60.0
Gini Coefficient: 0.20519645120405577
20:20 Ratio: 2.8468468468468466
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-30-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1230.02
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 360
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.384
    dispatch_time_ms: 5.854
    learner:
      cur_lr: 0.0006407200125977397
      grad_gnorm: 40.000003814697266
      policy_entropy: 216.01925659179688
      policy_loss: 64.67796325683594
      var_gnorm: 23.670774459838867
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 137.86541748046875
    num_steps_sampled: 10830000
    num_steps_trained: 10830000
    wait_time_ms: 427.936
  iterations_since_restore: 361
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 16066.81972360611
  time_this_iter_s: 43.899062395095825
  time_total_s: 16066.81972360611
  timestamp: 1594168255
  timesteps_since_restore: 10830000
  timesteps_this_iter: 30000
  timesteps_total: 10830000
  training_iteration: 361
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 16066 s, 361 iter, 10830000 ts, 1.23e+03 rew

agent-1: 42.0
agent-2: 39.0
agent-3: 42.0
agent-4: 45.0
agent-5: 37.0
agent-6: 50.0
agent-7: 48.0
agent-8: 45.0
agent-9: 27.0
agent-10: 20.0
agent-11: 24.0
agent-12: 33.0
agent-13: 67.0
agent-14: 82.0
agent-15: 59.0
agent-16: 27.0
agent-17: 38.0
agent-18: 38.0
agent-19: 64.0
agent-20: 30.0
agent-21: 26.0
agent-22: 31.0
agent-23: 63.0
agent-24: 74.0
agent-25: 32.0
agent-26: 44.0
agent-27: 49.0
agent-28: 40.0
agent-29: 53.0
agent-30: 31.0
Sum Reward: 1300.0
Avg Reward: 43.333333333333336
Min Reward: 20.0
Max Reward: 82.0
Gini Coefficient: 0.19328205128205128
20:20 Ratio: 2.655844155844156
Max-min Ratio: 4.1
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-31-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1230.56
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 361
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.609
    dispatch_time_ms: 6.802
    learner:
      cur_lr: 0.000638721976429224
      grad_gnorm: 40.0
      policy_entropy: 248.27609252929688
      policy_loss: -34.39160919189453
      var_gnorm: 23.670196533203125
      vf_explained_var: 0.0
      vf_loss: 7.589376449584961
    num_steps_sampled: 10860000
    num_steps_trained: 10860000
    wait_time_ms: 439.835
  iterations_since_restore: 362
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 16111.050609588623
  time_this_iter_s: 44.23088598251343
  time_total_s: 16111.050609588623
  timestamp: 1594168300
  timesteps_since_restore: 10860000
  timesteps_this_iter: 30000
  timesteps_total: 10860000
  training_iteration: 362
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 16111 s, 362 iter, 10860000 ts, 1.23e+03 rew

agent-1: 51.0
agent-2: 77.0
agent-3: 49.0
agent-4: 63.0
agent-5: 40.0
agent-6: 69.0
agent-7: 58.0
agent-8: 43.0
agent-9: 40.0
agent-10: 42.0
agent-11: 42.0
agent-12: 33.0
agent-13: 22.0
agent-14: 66.0
agent-15: 28.0
agent-16: 33.0
agent-17: 23.0
agent-18: 61.0
agent-19: 51.0
agent-20: 63.0
agent-21: 44.0
agent-22: 23.0
agent-23: 31.0
agent-24: 39.0
agent-25: 27.0
agent-26: 55.0
agent-27: 48.0
agent-28: 36.0
agent-29: 33.0
agent-30: 51.0
Sum Reward: 1341.0
Avg Reward: 44.7
Min Reward: 22.0
Max Reward: 77.0
Gini Coefficient: 0.18436490181456625
20:20 Ratio: 2.590909090909091
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-32-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1232.26
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 362
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.861
    dispatch_time_ms: 7.242
    learner:
      cur_lr: 0.0006367239984683692
      grad_gnorm: 40.0
      policy_entropy: 263.40631103515625
      policy_loss: 25.787710189819336
      var_gnorm: 23.669132232666016
      vf_explained_var: 0.0
      vf_loss: 48.903709411621094
    num_steps_sampled: 10890000
    num_steps_trained: 10890000
    wait_time_ms: 433.669
  iterations_since_restore: 363
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 16155.570096492767
  time_this_iter_s: 44.51948690414429
  time_total_s: 16155.570096492767
  timestamp: 1594168344
  timesteps_since_restore: 10890000
  timesteps_this_iter: 30000
  timesteps_total: 10890000
  training_iteration: 363
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 16155 s, 363 iter, 10890000 ts, 1.23e+03 rew

agent-1: 16.0
agent-2: 27.0
agent-3: 44.0
agent-4: 37.0
agent-5: 48.0
agent-6: 42.0
agent-7: 15.0
agent-8: 41.0
agent-9: 44.0
agent-10: 23.0
agent-11: 29.0
agent-12: 33.0
agent-13: 36.0
agent-14: 32.0
agent-15: 38.0
agent-16: 41.0
agent-17: 23.0
agent-18: 26.0
agent-19: 27.0
agent-20: 33.0
agent-21: 18.0
agent-22: 33.0
agent-23: 25.0
agent-24: 35.0
agent-25: 45.0
agent-26: 26.0
agent-27: 45.0
agent-28: 35.0
agent-29: 18.0
agent-30: 22.0
Sum Reward: 957.0
Avg Reward: 31.9
Min Reward: 15.0
Max Reward: 48.0
Gini Coefficient: 0.1681992337164751
20:20 Ratio: 2.392857142857143
Max-min Ratio: 3.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-33-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1231.67
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 363
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.512
    dispatch_time_ms: 5.466
    learner:
      cur_lr: 0.0006347260205075145
      grad_gnorm: 40.00000762939453
      policy_entropy: 263.6999206542969
      policy_loss: -9.952767372131348
      var_gnorm: 23.664243698120117
      vf_explained_var: 4.76837158203125e-07
      vf_loss: 34.604454040527344
    num_steps_sampled: 10920000
    num_steps_trained: 10920000
    wait_time_ms: 451.319
  iterations_since_restore: 364
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 16200.129815340042
  time_this_iter_s: 44.55971884727478
  time_total_s: 16200.129815340042
  timestamp: 1594168389
  timesteps_since_restore: 10920000
  timesteps_this_iter: 30000
  timesteps_total: 10920000
  training_iteration: 364
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 16200 s, 364 iter, 10920000 ts, 1.23e+03 rew

agent-1: 48.0
agent-2: 44.0
agent-3: 47.0
agent-4: 44.0
agent-5: 38.0
agent-6: 45.0
agent-7: 36.0
agent-8: 33.0
agent-9: 64.0
agent-10: 37.0
agent-11: 19.0
agent-12: 42.0
agent-13: 39.0
agent-14: 38.0
agent-15: 32.0
agent-16: 27.0
agent-17: 20.0
agent-18: 26.0
agent-19: 8.0
agent-20: 14.0
agent-21: 11.0
agent-22: 15.0
agent-23: 36.0
agent-24: 23.0
agent-25: 29.0
agent-26: 32.0
agent-27: 24.0
agent-28: 32.0
agent-29: 36.0
agent-30: 18.0
Sum Reward: 957.0
Avg Reward: 31.9
Min Reward: 8.0
Max Reward: 64.0
Gini Coefficient: 0.21800766283524906
20:20 Ratio: 3.4352941176470586
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-33-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1230.26
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 364
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.797
    dispatch_time_ms: 6.642
    learner:
      cur_lr: 0.0006327279843389988
      grad_gnorm: 6.603171348571777
      policy_entropy: 229.52670288085938
      policy_loss: -2.173711061477661
      var_gnorm: 23.663944244384766
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 15.112170219421387
    num_steps_sampled: 10950000
    num_steps_trained: 10950000
    wait_time_ms: 439.803
  iterations_since_restore: 365
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 16244.44106912613
  time_this_iter_s: 44.311253786087036
  time_total_s: 16244.44106912613
  timestamp: 1594168433
  timesteps_since_restore: 10950000
  timesteps_this_iter: 30000
  timesteps_total: 10950000
  training_iteration: 365
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 16244 s, 365 iter, 10950000 ts, 1.23e+03 rew

agent-1: 22.0
agent-2: 37.0
agent-3: 30.0
agent-4: 24.0
agent-5: 28.0
agent-6: 45.0
agent-7: 24.0
agent-8: 54.0
agent-9: 37.0
agent-10: 28.0
agent-11: 30.0
agent-12: 28.0
agent-13: 42.0
agent-14: 56.0
agent-15: 31.0
agent-16: 32.0
agent-17: 45.0
agent-18: 44.0
agent-19: 45.0
agent-20: 36.0
agent-21: 30.0
agent-22: 34.0
agent-23: 25.0
agent-24: 25.0
agent-25: 48.0
agent-26: 18.0
agent-27: 30.0
agent-28: 46.0
agent-29: 35.0
agent-30: 31.0
Sum Reward: 1040.0
Avg Reward: 34.666666666666664
Min Reward: 18.0
Max Reward: 56.0
Gini Coefficient: 0.15384615384615385
20:20 Ratio: 2.130434782608696
Max-min Ratio: 3.111111111111111
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-34-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1228.76
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 365
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.561
    dispatch_time_ms: 6.103
    learner:
      cur_lr: 0.000630730006378144
      grad_gnorm: 40.000003814697266
      policy_entropy: 222.78440856933594
      policy_loss: 68.8622817993164
      var_gnorm: 23.666608810424805
      vf_explained_var: 0.0
      vf_loss: 104.96035766601562
    num_steps_sampled: 10980000
    num_steps_trained: 10980000
    wait_time_ms: 419.422
  iterations_since_restore: 366
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 16288.39448595047
  time_this_iter_s: 43.95341682434082
  time_total_s: 16288.39448595047
  timestamp: 1594168477
  timesteps_since_restore: 10980000
  timesteps_this_iter: 30000
  timesteps_total: 10980000
  training_iteration: 366
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 16288 s, 366 iter, 10980000 ts, 1.23e+03 rew

agent-1: 33.0
agent-2: 51.0
agent-3: 41.0
agent-4: 35.0
agent-5: 36.0
agent-6: 39.0
agent-7: 72.0
agent-8: 56.0
agent-9: 34.0
agent-10: 48.0
agent-11: 33.0
agent-12: 24.0
agent-13: 53.0
agent-14: 76.0
agent-15: 38.0
agent-16: 62.0
agent-17: 33.0
agent-18: 16.0
agent-19: 45.0
agent-20: 53.0
agent-21: 56.0
agent-22: 22.0
agent-23: 27.0
agent-24: 24.0
agent-25: 25.0
agent-26: 49.0
agent-27: 47.0
agent-28: 53.0
agent-29: 69.0
agent-30: 61.0
Sum Reward: 1311.0
Avg Reward: 43.7
Min Reward: 16.0
Max Reward: 76.0
Gini Coefficient: 0.20007627765064837
20:20 Ratio: 2.869565217391304
Max-min Ratio: 4.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-35-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1230.06
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 366
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.578
    dispatch_time_ms: 5.974
    learner:
      cur_lr: 0.0006287320284172893
      grad_gnorm: 40.0
      policy_entropy: 218.5421142578125
      policy_loss: 8.95034408569336
      var_gnorm: 23.666828155517578
      vf_explained_var: 0.0
      vf_loss: 18.59790802001953
    num_steps_sampled: 11010000
    num_steps_trained: 11010000
    wait_time_ms: 426.516
  iterations_since_restore: 367
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 16332.796417474747
  time_this_iter_s: 44.40193152427673
  time_total_s: 16332.796417474747
  timestamp: 1594168522
  timesteps_since_restore: 11010000
  timesteps_this_iter: 30000
  timesteps_total: 11010000
  training_iteration: 367
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 16332 s, 367 iter, 11010000 ts, 1.23e+03 rew

agent-1: 11.0
agent-2: 64.0
agent-3: 39.0
agent-4: 42.0
agent-5: 27.0
agent-6: 42.0
agent-7: 34.0
agent-8: 23.0
agent-9: 41.0
agent-10: 36.0
agent-11: 23.0
agent-12: 30.0
agent-13: 21.0
agent-14: 44.0
agent-15: 51.0
agent-16: 58.0
agent-17: 77.0
agent-18: 36.0
agent-19: 36.0
agent-20: 41.0
agent-21: 30.0
agent-22: 47.0
agent-23: 25.0
agent-24: 36.0
agent-25: 32.0
agent-26: 45.0
agent-27: 14.0
agent-28: 22.0
agent-29: 38.0
agent-30: 28.0
Sum Reward: 1093.0
Avg Reward: 36.43333333333333
Min Reward: 11.0
Max Reward: 77.0
Gini Coefficient: 0.2072888075632815
20:20 Ratio: 3.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-36-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1228.45
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 367
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.538
    dispatch_time_ms: 5.566
    learner:
      cur_lr: 0.0006267339922487736
      grad_gnorm: 39.999996185302734
      policy_entropy: 225.71624755859375
      policy_loss: -30.12055206298828
      var_gnorm: 23.665616989135742
      vf_explained_var: 0.0
      vf_loss: 15.686851501464844
    num_steps_sampled: 11040000
    num_steps_trained: 11040000
    wait_time_ms: 461.406
  iterations_since_restore: 368
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 16377.273524522781
  time_this_iter_s: 44.47710704803467
  time_total_s: 16377.273524522781
  timestamp: 1594168566
  timesteps_since_restore: 11040000
  timesteps_this_iter: 30000
  timesteps_total: 11040000
  training_iteration: 368
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 16377 s, 368 iter, 11040000 ts, 1.23e+03 rew

agent-1: 52.0
agent-2: 46.0
agent-3: 24.0
agent-4: 19.0
agent-5: 67.0
agent-6: 37.0
agent-7: 49.0
agent-8: 46.0
agent-9: 32.0
agent-10: 20.0
agent-11: 34.0
agent-12: 39.0
agent-13: 30.0
agent-14: 34.0
agent-15: 37.0
agent-16: 42.0
agent-17: 27.0
agent-18: 52.0
agent-19: 43.0
agent-20: 68.0
agent-21: 24.0
agent-22: 26.0
agent-23: 13.0
agent-24: 15.0
agent-25: 21.0
agent-26: 69.0
agent-27: 32.0
agent-28: 17.0
agent-29: 34.0
agent-30: 37.0
Sum Reward: 1086.0
Avg Reward: 36.2
Min Reward: 13.0
Max Reward: 69.0
Gini Coefficient: 0.23044812768569675
20:20 Ratio: 3.4
Max-min Ratio: 5.3076923076923075
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-36-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1226.78
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 368
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.047
    dispatch_time_ms: 9.157
    learner:
      cur_lr: 0.0006247360142879188
      grad_gnorm: 39.999996185302734
      policy_entropy: 246.26414489746094
      policy_loss: -28.484798431396484
      var_gnorm: 23.66547203063965
      vf_explained_var: 0.0
      vf_loss: 4.269583225250244
    num_steps_sampled: 11070000
    num_steps_trained: 11070000
    wait_time_ms: 303.784
  iterations_since_restore: 369
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 16421.51363015175
  time_this_iter_s: 44.240105628967285
  time_total_s: 16421.51363015175
  timestamp: 1594168610
  timesteps_since_restore: 11070000
  timesteps_this_iter: 30000
  timesteps_total: 11070000
  training_iteration: 369
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 16421 s, 369 iter, 11070000 ts, 1.23e+03 rew

agent-1: 48.0
agent-2: 38.0
agent-3: 46.0
agent-4: 42.0
agent-5: 50.0
agent-6: 39.0
agent-7: 56.0
agent-8: 16.0
agent-9: 61.0
agent-10: 52.0
agent-11: 49.0
agent-12: 35.0
agent-13: 30.0
agent-14: 35.0
agent-15: 35.0
agent-16: 39.0
agent-17: 51.0
agent-18: 45.0
agent-19: 42.0
agent-20: 42.0
agent-21: 35.0
agent-22: 22.0
agent-23: 32.0
agent-24: 59.0
agent-25: 13.0
agent-26: 12.0
agent-27: 50.0
agent-28: 26.0
agent-29: 54.0
agent-30: 10.0
Sum Reward: 1164.0
Avg Reward: 38.8
Min Reward: 10.0
Max Reward: 61.0
Gini Coefficient: 0.19868270332187857
20:20 Ratio: 3.3636363636363638
Max-min Ratio: 6.1
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-37-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1226.96
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 369
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.803
    dispatch_time_ms: 5.55
    learner:
      cur_lr: 0.0006227379781194031
      grad_gnorm: 28.906354904174805
      policy_entropy: 230.92579650878906
      policy_loss: -8.564650535583496
      var_gnorm: 23.663816452026367
      vf_explained_var: 0.0
      vf_loss: 27.001371383666992
    num_steps_sampled: 11100000
    num_steps_trained: 11100000
    wait_time_ms: 457.03
  iterations_since_restore: 370
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 16465.830535411835
  time_this_iter_s: 44.31690526008606
  time_total_s: 16465.830535411835
  timestamp: 1594168655
  timesteps_since_restore: 11100000
  timesteps_this_iter: 30000
  timesteps_total: 11100000
  training_iteration: 370
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 16465 s, 370 iter, 11100000 ts, 1.23e+03 rew

agent-1: 28.0
agent-2: 43.0
agent-3: 69.0
agent-4: 11.0
agent-5: 41.0
agent-6: 40.0
agent-7: 34.0
agent-8: 39.0
agent-9: 51.0
agent-10: 38.0
agent-11: 24.0
agent-12: 54.0
agent-13: 15.0
agent-14: 35.0
agent-15: 37.0
agent-16: 33.0
agent-17: 18.0
agent-18: 41.0
agent-19: 46.0
agent-20: 12.0
agent-21: 32.0
agent-22: 24.0
agent-23: 43.0
agent-24: 44.0
agent-25: 30.0
agent-26: 26.0
agent-27: 24.0
agent-28: 13.0
agent-29: 28.0
agent-30: 37.0
Sum Reward: 1010.0
Avg Reward: 33.666666666666664
Min Reward: 11.0
Max Reward: 69.0
Gini Coefficient: 0.213993399339934
20:20 Ratio: 3.3010752688172045
Max-min Ratio: 6.2727272727272725
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-38-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1222.97
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 370
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.654
    dispatch_time_ms: 5.57
    learner:
      cur_lr: 0.0006207400001585484
      grad_gnorm: 11.652945518493652
      policy_entropy: 226.69775390625
      policy_loss: 1.4153504371643066
      var_gnorm: 23.6610164642334
      vf_explained_var: 0.0
      vf_loss: 29.739727020263672
    num_steps_sampled: 11130000
    num_steps_trained: 11130000
    wait_time_ms: 433.485
  iterations_since_restore: 371
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 16510.156464099884
  time_this_iter_s: 44.325928688049316
  time_total_s: 16510.156464099884
  timestamp: 1594168699
  timesteps_since_restore: 11130000
  timesteps_this_iter: 30000
  timesteps_total: 11130000
  training_iteration: 371
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 16510 s, 371 iter, 11130000 ts, 1.22e+03 rew

agent-1: 45.0
agent-2: 61.0
agent-3: 49.0
agent-4: 27.0
agent-5: 32.0
agent-6: 38.0
agent-7: 35.0
agent-8: 49.0
agent-9: 37.0
agent-10: 29.0
agent-11: 40.0
agent-12: 37.0
agent-13: 42.0
agent-14: 42.0
agent-15: 27.0
agent-16: 34.0
agent-17: 29.0
agent-18: 72.0
agent-19: 33.0
agent-20: 37.0
agent-21: 26.0
agent-22: 19.0
agent-23: 62.0
agent-24: 54.0
agent-25: 24.0
agent-26: 48.0
agent-27: 54.0
agent-28: 44.0
agent-29: 36.0
agent-30: 35.0
Sum Reward: 1197.0
Avg Reward: 39.9
Min Reward: 19.0
Max Reward: 72.0
Gini Coefficient: 0.16672236145920358
20:20 Ratio: 2.3157894736842106
Max-min Ratio: 3.789473684210526
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-39-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1222.68
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 371
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.835
    dispatch_time_ms: 7.298
    learner:
      cur_lr: 0.0006187420221976936
      grad_gnorm: 39.99999237060547
      policy_entropy: 220.24560546875
      policy_loss: 12.971285820007324
      var_gnorm: 23.66172981262207
      vf_explained_var: 0.0
      vf_loss: 60.449729919433594
    num_steps_sampled: 11160000
    num_steps_trained: 11160000
    wait_time_ms: 429.516
  iterations_since_restore: 372
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 16554.050471782684
  time_this_iter_s: 43.89400768280029
  time_total_s: 16554.050471782684
  timestamp: 1594168743
  timesteps_since_restore: 11160000
  timesteps_this_iter: 30000
  timesteps_total: 11160000
  training_iteration: 372
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 16554 s, 372 iter, 11160000 ts, 1.22e+03 rew

agent-1: 35.0
agent-2: 64.0
agent-3: 26.0
agent-4: 32.0
agent-5: 56.0
agent-6: 37.0
agent-7: 48.0
agent-8: 53.0
agent-9: 38.0
agent-10: 26.0
agent-11: 44.0
agent-12: 38.0
agent-13: 64.0
agent-14: 65.0
agent-15: 53.0
agent-16: 26.0
agent-17: 26.0
agent-18: 31.0
agent-19: 36.0
agent-20: 35.0
agent-21: 24.0
agent-22: 37.0
agent-23: 36.0
agent-24: 43.0
agent-25: 28.0
agent-26: 27.0
agent-27: 24.0
agent-28: 37.0
agent-29: 55.0
agent-30: 28.0
Sum Reward: 1172.0
Avg Reward: 39.06666666666667
Min Reward: 24.0
Max Reward: 65.0
Gini Coefficient: 0.17639362912400455
20:20 Ratio: 2.348684210526316
Max-min Ratio: 2.7083333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-39-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1222.54
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 372
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.97
    dispatch_time_ms: 7.545
    learner:
      cur_lr: 0.0006167439860291779
      grad_gnorm: 40.0
      policy_entropy: 204.08038330078125
      policy_loss: -3.297529458999634
      var_gnorm: 23.657136917114258
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 42.042884826660156
    num_steps_sampled: 11190000
    num_steps_trained: 11190000
    wait_time_ms: 432.607
  iterations_since_restore: 373
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 16598.173894643784
  time_this_iter_s: 44.12342286109924
  time_total_s: 16598.173894643784
  timestamp: 1594168788
  timesteps_since_restore: 11190000
  timesteps_this_iter: 30000
  timesteps_total: 11190000
  training_iteration: 373
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 16598 s, 373 iter, 11190000 ts, 1.22e+03 rew

agent-1: 21.0
agent-2: 26.0
agent-3: 30.0
agent-4: 40.0
agent-5: 40.0
agent-6: 49.0
agent-7: 30.0
agent-8: 30.0
agent-9: 27.0
agent-10: 34.0
agent-11: 46.0
agent-12: 29.0
agent-13: 25.0
agent-14: 32.0
agent-15: 54.0
agent-16: 50.0
agent-17: 42.0
agent-18: 36.0
agent-19: 30.0
agent-20: 41.0
agent-21: 32.0
agent-22: 32.0
agent-23: 26.0
agent-24: 58.0
agent-25: 27.0
agent-26: 55.0
agent-27: 43.0
agent-28: 36.0
agent-29: 32.0
agent-30: 47.0
Sum Reward: 1100.0
Avg Reward: 36.666666666666664
Min Reward: 21.0
Max Reward: 58.0
Gini Coefficient: 0.14903030303030304
20:20 Ratio: 2.0592105263157894
Max-min Ratio: 2.761904761904762
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-40-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1223.91
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 373
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.664
    dispatch_time_ms: 49.769
    learner:
      cur_lr: 0.0006147460080683231
      grad_gnorm: 40.000003814697266
      policy_entropy: 180.53073120117188
      policy_loss: 15.687644004821777
      var_gnorm: 23.662416458129883
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 98.40240478515625
    num_steps_sampled: 11220000
    num_steps_trained: 11220000
    wait_time_ms: 407.352
  iterations_since_restore: 374
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 16641.922365903854
  time_this_iter_s: 43.7484712600708
  time_total_s: 16641.922365903854
  timestamp: 1594168831
  timesteps_since_restore: 11220000
  timesteps_this_iter: 30000
  timesteps_total: 11220000
  training_iteration: 374
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 16641 s, 374 iter, 11220000 ts, 1.22e+03 rew

agent-1: 50.0
agent-2: 26.0
agent-3: 52.0
agent-4: 35.0
agent-5: 13.0
agent-6: 54.0
agent-7: 28.0
agent-8: 65.0
agent-9: 46.0
agent-10: 75.0
agent-11: 34.0
agent-12: 63.0
agent-13: 22.0
agent-14: 26.0
agent-15: 59.0
agent-16: 34.0
agent-17: 34.0
agent-18: 59.0
agent-19: 51.0
agent-20: 27.0
agent-21: 32.0
agent-22: 47.0
agent-23: 57.0
agent-24: 31.0
agent-25: 59.0
agent-26: 61.0
agent-27: 86.0
agent-28: 50.0
agent-29: 65.0
agent-30: 47.0
Sum Reward: 1388.0
Avg Reward: 46.266666666666666
Min Reward: 13.0
Max Reward: 86.0
Gini Coefficient: 0.2064841498559078
20:20 Ratio: 2.9225352112676055
Max-min Ratio: 6.615384615384615
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-41-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1225.88
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 374
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.584
    dispatch_time_ms: 6.717
    learner:
      cur_lr: 0.0006127479718998075
      grad_gnorm: 40.0
      policy_entropy: 241.8955078125
      policy_loss: -6.3164567947387695
      var_gnorm: 23.66756248474121
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 54.84918212890625
    num_steps_sampled: 11250000
    num_steps_trained: 11250000
    wait_time_ms: 434.147
  iterations_since_restore: 375
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 16686.46950340271
  time_this_iter_s: 44.54713749885559
  time_total_s: 16686.46950340271
  timestamp: 1594168876
  timesteps_since_restore: 11250000
  timesteps_this_iter: 30000
  timesteps_total: 11250000
  training_iteration: 375
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 16686 s, 375 iter, 11250000 ts, 1.23e+03 rew

agent-1: 78.0
agent-2: 48.0
agent-3: 30.0
agent-4: 46.0
agent-5: 46.0
agent-6: 27.0
agent-7: 75.0
agent-8: 82.0
agent-9: 69.0
agent-10: 35.0
agent-11: 44.0
agent-12: 39.0
agent-13: 73.0
agent-14: 77.0
agent-15: 33.0
agent-16: 43.0
agent-17: 42.0
agent-18: 46.0
agent-19: 26.0
agent-20: 62.0
agent-21: 36.0
agent-22: 73.0
agent-23: 64.0
agent-24: 40.0
agent-25: 33.0
agent-26: 38.0
agent-27: 52.0
agent-28: 56.0
agent-29: 26.0
agent-30: 31.0
Sum Reward: 1470.0
Avg Reward: 49.0
Min Reward: 26.0
Max Reward: 82.0
Gini Coefficient: 0.1982312925170068
20:20 Ratio: 2.647398843930636
Max-min Ratio: 3.1538461538461537
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-42-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1228.59
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 375
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.338
    dispatch_time_ms: 19.979
    learner:
      cur_lr: 0.0006107499939389527
      grad_gnorm: 39.999996185302734
      policy_entropy: 195.12709045410156
      policy_loss: 19.607925415039062
      var_gnorm: 23.66456413269043
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 57.62355041503906
    num_steps_sampled: 11280000
    num_steps_trained: 11280000
    wait_time_ms: 465.17
  iterations_since_restore: 376
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 16732.665357351303
  time_this_iter_s: 46.19585394859314
  time_total_s: 16732.665357351303
  timestamp: 1594168922
  timesteps_since_restore: 11280000
  timesteps_this_iter: 30000
  timesteps_total: 11280000
  training_iteration: 376
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 16732 s, 376 iter, 11280000 ts, 1.23e+03 rew

agent-1: 20.0
agent-2: 28.0
agent-3: 48.0
agent-4: 28.0
agent-5: 22.0
agent-6: 26.0
agent-7: 22.0
agent-8: 48.0
agent-9: 26.0
agent-10: 46.0
agent-11: 40.0
agent-12: 24.0
agent-13: 30.0
agent-14: 47.0
agent-15: 44.0
agent-16: 53.0
agent-17: 35.0
agent-18: 43.0
agent-19: 22.0
agent-20: 48.0
agent-21: 35.0
agent-22: 32.0
agent-23: 54.0
agent-24: 14.0
agent-25: 25.0
agent-26: 47.0
agent-27: 46.0
agent-28: 36.0
agent-29: 20.0
agent-30: 30.0
Sum Reward: 1039.0
Avg Reward: 34.63333333333333
Min Reward: 14.0
Max Reward: 54.0
Gini Coefficient: 0.18610843760025667
20:20 Ratio: 2.4833333333333334
Max-min Ratio: 3.857142857142857
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-42-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1226.46
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 376
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.568
    dispatch_time_ms: 28.252
    learner:
      cur_lr: 0.0006087520159780979
      grad_gnorm: 40.0
      policy_entropy: 154.82460021972656
      policy_loss: 42.34767150878906
      var_gnorm: 23.661556243896484
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 103.09841918945312
    num_steps_sampled: 11310000
    num_steps_trained: 11310000
    wait_time_ms: 512.644
  iterations_since_restore: 377
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 16779.386638879776
  time_this_iter_s: 46.7212815284729
  time_total_s: 16779.386638879776
  timestamp: 1594168969
  timesteps_since_restore: 11310000
  timesteps_this_iter: 30000
  timesteps_total: 11310000
  training_iteration: 377
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 16779 s, 377 iter, 11310000 ts, 1.23e+03 rew

agent-1: 47.0
agent-2: 46.0
agent-3: 34.0
agent-4: 32.0
agent-5: 60.0
agent-6: 51.0
agent-7: 56.0
agent-8: 42.0
agent-9: 37.0
agent-10: 40.0
agent-11: 22.0
agent-12: 23.0
agent-13: 49.0
agent-14: 46.0
agent-15: 25.0
agent-16: 42.0
agent-17: 34.0
agent-18: 50.0
agent-19: 38.0
agent-20: 35.0
agent-21: 52.0
agent-22: 53.0
agent-23: 22.0
agent-24: 10.0
agent-25: 27.0
agent-26: 26.0
agent-27: 55.0
agent-28: 21.0
agent-29: 39.0
agent-30: 24.0
Sum Reward: 1138.0
Avg Reward: 37.93333333333333
Min Reward: 10.0
Max Reward: 60.0
Gini Coefficient: 0.18886936145284125
20:20 Ratio: 2.680327868852459
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-43-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1224.2
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 377
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.888
    dispatch_time_ms: 8.692
    learner:
      cur_lr: 0.0006067539798095822
      grad_gnorm: 40.0
      policy_entropy: 129.63096618652344
      policy_loss: -6.289912700653076
      var_gnorm: 23.665950775146484
      vf_explained_var: 0.0
      vf_loss: 69.50960540771484
    num_steps_sampled: 11340000
    num_steps_trained: 11340000
    wait_time_ms: 439.724
  iterations_since_restore: 378
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 16822.245161294937
  time_this_iter_s: 42.85852241516113
  time_total_s: 16822.245161294937
  timestamp: 1594169012
  timesteps_since_restore: 11340000
  timesteps_this_iter: 30000
  timesteps_total: 11340000
  training_iteration: 378
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 16822 s, 378 iter, 11340000 ts, 1.22e+03 rew

agent-1: 48.0
agent-2: 44.0
agent-3: 41.0
agent-4: 30.0
agent-5: 56.0
agent-6: 47.0
agent-7: 50.0
agent-8: 42.0
agent-9: 29.0
agent-10: 22.0
agent-11: 45.0
agent-12: 39.0
agent-13: 47.0
agent-14: 42.0
agent-15: 55.0
agent-16: 33.0
agent-17: 50.0
agent-18: 29.0
agent-19: 48.0
agent-20: 29.0
agent-21: 68.0
agent-22: 42.0
agent-23: 68.0
agent-24: 50.0
agent-25: 65.0
agent-26: 52.0
agent-27: 48.0
agent-28: 26.0
agent-29: 42.0
agent-30: 29.0
Sum Reward: 1316.0
Avg Reward: 43.86666666666667
Min Reward: 22.0
Max Reward: 68.0
Gini Coefficient: 0.15005065856129685
20:20 Ratio: 2.2195121951219514
Max-min Ratio: 3.090909090909091
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-44-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1225.35
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 378
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.1
    dispatch_time_ms: 7.42
    learner:
      cur_lr: 0.0006047560018487275
      grad_gnorm: 40.0
      policy_entropy: 128.6833953857422
      policy_loss: -14.489155769348145
      var_gnorm: 23.6644229888916
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 27.852813720703125
    num_steps_sampled: 11370000
    num_steps_trained: 11370000
    wait_time_ms: 423.947
  iterations_since_restore: 379
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 16865.828828573227
  time_this_iter_s: 43.583667278289795
  time_total_s: 16865.828828573227
  timestamp: 1594169055
  timesteps_since_restore: 11370000
  timesteps_this_iter: 30000
  timesteps_total: 11370000
  training_iteration: 379
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 16865 s, 379 iter, 11370000 ts, 1.23e+03 rew

agent-1: 40.0
agent-2: 46.0
agent-3: 32.0
agent-4: 63.0
agent-5: 20.0
agent-6: 52.0
agent-7: 29.0
agent-8: 60.0
agent-9: 41.0
agent-10: 39.0
agent-11: 39.0
agent-12: 40.0
agent-13: 47.0
agent-14: 54.0
agent-15: 51.0
agent-16: 39.0
agent-17: 41.0
agent-18: 82.0
agent-19: 40.0
agent-20: 34.0
agent-21: 21.0
agent-22: 19.0
agent-23: 45.0
agent-24: 61.0
agent-25: 14.0
agent-26: 20.0
agent-27: 25.0
agent-28: 40.0
agent-29: 36.0
agent-30: 71.0
Sum Reward: 1241.0
Avg Reward: 41.36666666666667
Min Reward: 14.0
Max Reward: 82.0
Gini Coefficient: 0.20942788074133764
20:20 Ratio: 3.2857142857142856
Max-min Ratio: 5.857142857142857
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-44-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1226.02
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 379
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.916
    dispatch_time_ms: 5.563
    learner:
      cur_lr: 0.0006027580238878727
      grad_gnorm: 40.0
      policy_entropy: 123.93228912353516
      policy_loss: 13.14217758178711
      var_gnorm: 23.66712188720703
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 64.76132202148438
    num_steps_sampled: 11400000
    num_steps_trained: 11400000
    wait_time_ms: 422.199
  iterations_since_restore: 380
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 16909.183480262756
  time_this_iter_s: 43.35465168952942
  time_total_s: 16909.183480262756
  timestamp: 1594169099
  timesteps_since_restore: 11400000
  timesteps_this_iter: 30000
  timesteps_total: 11400000
  training_iteration: 380
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 16909 s, 380 iter, 11400000 ts, 1.23e+03 rew

agent-1: 67.0
agent-2: 41.0
agent-3: 30.0
agent-4: 58.0
agent-5: 25.0
agent-6: 63.0
agent-7: 80.0
agent-8: 22.0
agent-9: 38.0
agent-10: 56.0
agent-11: 66.0
agent-12: 37.0
agent-13: 52.0
agent-14: 49.0
agent-15: 47.0
agent-16: 38.0
agent-17: 34.0
agent-18: 55.0
agent-19: 38.0
agent-20: 32.0
agent-21: 65.0
agent-22: 45.0
agent-23: 55.0
agent-24: 54.0
agent-25: 49.0
agent-26: 68.0
agent-27: 60.0
agent-28: 59.0
agent-29: 52.0
agent-30: 46.0
Sum Reward: 1481.0
Avg Reward: 49.36666666666667
Min Reward: 22.0
Max Reward: 80.0
Gini Coefficient: 0.15775376997524196
20:20 Ratio: 2.272222222222222
Max-min Ratio: 3.6363636363636362
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-45-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1227.85
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 380
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.546
    dispatch_time_ms: 5.596
    learner:
      cur_lr: 0.000600759987719357
      grad_gnorm: 27.976360321044922
      policy_entropy: 122.49844360351562
      policy_loss: -8.345500946044922
      var_gnorm: 23.66803741455078
      vf_explained_var: 0.0
      vf_loss: 47.05709457397461
    num_steps_sampled: 11430000
    num_steps_trained: 11430000
    wait_time_ms: 442.631
  iterations_since_restore: 381
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 16953.277459144592
  time_this_iter_s: 44.09397888183594
  time_total_s: 16953.277459144592
  timestamp: 1594169143
  timesteps_since_restore: 11430000
  timesteps_this_iter: 30000
  timesteps_total: 11430000
  training_iteration: 381
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 16953 s, 381 iter, 11430000 ts, 1.23e+03 rew

agent-1: 28.0
agent-2: 28.0
agent-3: 37.0
agent-4: 80.0
agent-5: 56.0
agent-6: 47.0
agent-7: 40.0
agent-8: 80.0
agent-9: 31.0
agent-10: 32.0
agent-11: 34.0
agent-12: 52.0
agent-13: 72.0
agent-14: 42.0
agent-15: 41.0
agent-16: 47.0
agent-17: 47.0
agent-18: 38.0
agent-19: 51.0
agent-20: 37.0
agent-21: 36.0
agent-22: 75.0
agent-23: 48.0
agent-24: 33.0
agent-25: 56.0
agent-26: 60.0
agent-27: 50.0
agent-28: 56.0
agent-29: 34.0
agent-30: 21.0
Sum Reward: 1389.0
Avg Reward: 46.3
Min Reward: 21.0
Max Reward: 80.0
Gini Coefficient: 0.18164146868250539
20:20 Ratio: 2.445086705202312
Max-min Ratio: 3.8095238095238093
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-46-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1230.74
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 381
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.726
    dispatch_time_ms: 6.003
    learner:
      cur_lr: 0.0005987620097585022
      grad_gnorm: 40.0
      policy_entropy: 117.51624298095703
      policy_loss: -6.832159996032715
      var_gnorm: 23.66871452331543
      vf_explained_var: 0.0
      vf_loss: 38.00575256347656
    num_steps_sampled: 11460000
    num_steps_trained: 11460000
    wait_time_ms: 446.147
  iterations_since_restore: 382
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 16996.296473503113
  time_this_iter_s: 43.01901435852051
  time_total_s: 16996.296473503113
  timestamp: 1594169186
  timesteps_since_restore: 11460000
  timesteps_this_iter: 30000
  timesteps_total: 11460000
  training_iteration: 382
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 16996 s, 382 iter, 11460000 ts, 1.23e+03 rew

agent-1: 40.0
agent-2: 50.0
agent-3: 65.0
agent-4: 42.0
agent-5: 63.0
agent-6: 35.0
agent-7: 47.0
agent-8: 39.0
agent-9: 51.0
agent-10: 42.0
agent-11: 55.0
agent-12: 29.0
agent-13: 45.0
agent-14: 30.0
agent-15: 37.0
agent-16: 40.0
agent-17: 47.0
agent-18: 26.0
agent-19: 51.0
agent-20: 50.0
agent-21: 61.0
agent-22: 38.0
agent-23: 34.0
agent-24: 36.0
agent-25: 55.0
agent-26: 71.0
agent-27: 57.0
agent-28: 28.0
agent-29: 34.0
agent-30: 34.0
Sum Reward: 1332.0
Avg Reward: 44.4
Min Reward: 26.0
Max Reward: 71.0
Gini Coefficient: 0.1475975975975976
20:20 Ratio: 2.0552486187845305
Max-min Ratio: 2.730769230769231
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-47-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1232.14
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 382
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.266
    dispatch_time_ms: 5.199
    learner:
      cur_lr: 0.0005967639735899866
      grad_gnorm: 39.999996185302734
      policy_entropy: 128.1795654296875
      policy_loss: 31.84601402282715
      var_gnorm: 23.66176414489746
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 89.96741485595703
    num_steps_sampled: 11490000
    num_steps_trained: 11490000
    wait_time_ms: 415.529
  iterations_since_restore: 383
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 17040.294374465942
  time_this_iter_s: 43.99790096282959
  time_total_s: 17040.294374465942
  timestamp: 1594169230
  timesteps_since_restore: 11490000
  timesteps_this_iter: 30000
  timesteps_total: 11490000
  training_iteration: 383
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 17040 s, 383 iter, 11490000 ts, 1.23e+03 rew

agent-1: 36.0
agent-2: 13.0
agent-3: 36.0
agent-4: 31.0
agent-5: 28.0
agent-6: 49.0
agent-7: 74.0
agent-8: 54.0
agent-9: 65.0
agent-10: 82.0
agent-11: 39.0
agent-12: 40.0
agent-13: 49.0
agent-14: 40.0
agent-15: 43.0
agent-16: 29.0
agent-17: 68.0
agent-18: 29.0
agent-19: 82.0
agent-20: 34.0
agent-21: 24.0
agent-22: 34.0
agent-23: 55.0
agent-24: 33.0
agent-25: 16.0
agent-26: 34.0
agent-27: 35.0
agent-28: 64.0
agent-29: 36.0
agent-30: 41.0
Sum Reward: 1293.0
Avg Reward: 43.1
Min Reward: 13.0
Max Reward: 82.0
Gini Coefficient: 0.22209332302139725
20:20 Ratio: 3.129496402877698
Max-min Ratio: 6.3076923076923075
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-47-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1232.47
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 383
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.784
    dispatch_time_ms: 6.599
    learner:
      cur_lr: 0.0005947659956291318
      grad_gnorm: 40.0
      policy_entropy: 158.89613342285156
      policy_loss: 2.643045425415039
      var_gnorm: 23.6684513092041
      vf_explained_var: 0.0
      vf_loss: 88.55522155761719
    num_steps_sampled: 11520000
    num_steps_trained: 11520000
    wait_time_ms: 429.029
  iterations_since_restore: 384
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 17083.163121700287
  time_this_iter_s: 42.86874723434448
  time_total_s: 17083.163121700287
  timestamp: 1594169273
  timesteps_since_restore: 11520000
  timesteps_this_iter: 30000
  timesteps_total: 11520000
  training_iteration: 384
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 17083 s, 384 iter, 11520000 ts, 1.23e+03 rew

agent-1: 69.0
agent-2: 74.0
agent-3: 29.0
agent-4: 64.0
agent-5: 77.0
agent-6: 49.0
agent-7: 53.0
agent-8: 51.0
agent-9: 22.0
agent-10: 55.0
agent-11: 41.0
agent-12: 70.0
agent-13: 51.0
agent-14: 25.0
agent-15: 49.0
agent-16: 43.0
agent-17: 56.0
agent-18: 66.0
agent-19: 51.0
agent-20: 43.0
agent-21: 34.0
agent-22: 50.0
agent-23: 27.0
agent-24: 54.0
agent-25: 54.0
agent-26: 45.0
agent-27: 30.0
agent-28: 54.0
agent-29: 51.0
agent-30: 45.0
Sum Reward: 1482.0
Avg Reward: 49.4
Min Reward: 22.0
Max Reward: 77.0
Gini Coefficient: 0.15829959514170042
20:20 Ratio: 2.5149700598802394
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-48-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1232.81
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 384
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.915
    dispatch_time_ms: 39.199
    learner:
      cur_lr: 0.000592768017668277
      grad_gnorm: 39.99999237060547
      policy_entropy: 193.72906494140625
      policy_loss: -16.565874099731445
      var_gnorm: 23.656192779541016
      vf_explained_var: 0.0
      vf_loss: 19.306093215942383
    num_steps_sampled: 11550000
    num_steps_trained: 11550000
    wait_time_ms: 400.949
  iterations_since_restore: 385
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 17128.222918748856
  time_this_iter_s: 45.059797048568726
  time_total_s: 17128.222918748856
  timestamp: 1594169318
  timesteps_since_restore: 11550000
  timesteps_this_iter: 30000
  timesteps_total: 11550000
  training_iteration: 385
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 17128 s, 385 iter, 11550000 ts, 1.23e+03 rew

agent-1: 52.0
agent-2: 49.0
agent-3: 41.0
agent-4: 35.0
agent-5: 37.0
agent-6: 57.0
agent-7: 22.0
agent-8: 59.0
agent-9: 70.0
agent-10: 39.0
agent-11: 42.0
agent-12: 32.0
agent-13: 67.0
agent-14: 20.0
agent-15: 50.0
agent-16: 53.0
agent-17: 42.0
agent-18: 26.0
agent-19: 36.0
agent-20: 50.0
agent-21: 36.0
agent-22: 49.0
agent-23: 45.0
agent-24: 40.0
agent-25: 58.0
agent-26: 52.0
agent-27: 46.0
agent-28: 36.0
agent-29: 23.0
agent-30: 17.0
Sum Reward: 1281.0
Avg Reward: 42.7
Min Reward: 17.0
Max Reward: 70.0
Gini Coefficient: 0.17358834244080146
20:20 Ratio: 2.6
Max-min Ratio: 4.117647058823529
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-49-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1233.82
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 385
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.776
    dispatch_time_ms: 4.361
    learner:
      cur_lr: 0.0005907699814997613
      grad_gnorm: 39.999996185302734
      policy_entropy: 198.9034881591797
      policy_loss: -12.676729202270508
      var_gnorm: 23.666336059570312
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 32.69752502441406
    num_steps_sampled: 11580000
    num_steps_trained: 11580000
    wait_time_ms: 447.526
  iterations_since_restore: 386
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 17172.024024009705
  time_this_iter_s: 43.801105260849
  time_total_s: 17172.024024009705
  timestamp: 1594169362
  timesteps_since_restore: 11580000
  timesteps_this_iter: 30000
  timesteps_total: 11580000
  training_iteration: 386
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 17172 s, 386 iter, 11580000 ts, 1.23e+03 rew

agent-1: 37.0
agent-2: 39.0
agent-3: 52.0
agent-4: 38.0
agent-5: 21.0
agent-6: 67.0
agent-7: 56.0
agent-8: 21.0
agent-9: 32.0
agent-10: 54.0
agent-11: 46.0
agent-12: 36.0
agent-13: 65.0
agent-14: 42.0
agent-15: 54.0
agent-16: 49.0
agent-17: 54.0
agent-18: 40.0
agent-19: 42.0
agent-20: 61.0
agent-21: 50.0
agent-22: 36.0
agent-23: 31.0
agent-24: 61.0
agent-25: 37.0
agent-26: 60.0
agent-27: 41.0
agent-28: 47.0
agent-29: 21.0
agent-30: 41.0
Sum Reward: 1331.0
Avg Reward: 44.36666666666667
Min Reward: 21.0
Max Reward: 67.0
Gini Coefficient: 0.15835211620335587
20:20 Ratio: 2.2839506172839505
Max-min Ratio: 3.1904761904761907
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-50-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1234.29
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 386
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.997
    dispatch_time_ms: 5.927
    learner:
      cur_lr: 0.0005887720035389066
      grad_gnorm: 39.999996185302734
      policy_entropy: 211.68380737304688
      policy_loss: 48.28024673461914
      var_gnorm: 23.64975929260254
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 114.14812469482422
    num_steps_sampled: 11610000
    num_steps_trained: 11610000
    wait_time_ms: 407.495
  iterations_since_restore: 387
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 17216.271652698517
  time_this_iter_s: 44.247628688812256
  time_total_s: 17216.271652698517
  timestamp: 1594169406
  timesteps_since_restore: 11610000
  timesteps_this_iter: 30000
  timesteps_total: 11610000
  training_iteration: 387
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 17216 s, 387 iter, 11610000 ts, 1.23e+03 rew

agent-1: 28.0
agent-2: 38.0
agent-3: 50.0
agent-4: 38.0
agent-5: 72.0
agent-6: 63.0
agent-7: 52.0
agent-8: 45.0
agent-9: 13.0
agent-10: 71.0
agent-11: 23.0
agent-12: 27.0
agent-13: 37.0
agent-14: 55.0
agent-15: 41.0
agent-16: 52.0
agent-17: 60.0
agent-18: 27.0
agent-19: 29.0
agent-20: 40.0
agent-21: 21.0
agent-22: 18.0
agent-23: 3.0
agent-24: 34.0
agent-25: 35.0
agent-26: 31.0
agent-27: 70.0
agent-28: 42.0
agent-29: 29.0
agent-30: 47.0
Sum Reward: 1191.0
Avg Reward: 39.7
Min Reward: 3.0
Max Reward: 72.0
Gini Coefficient: 0.24122586062132662
20:20 Ratio: 3.723809523809524
Max-min Ratio: 24.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-50-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1231.63
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 387
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.561
    dispatch_time_ms: 6.569
    learner:
      cur_lr: 0.0005867740255780518
      grad_gnorm: 9.670058250427246
      policy_entropy: 214.3769989013672
      policy_loss: 2.9160220623016357
      var_gnorm: 23.661495208740234
      vf_explained_var: 0.0
      vf_loss: 52.73664474487305
    num_steps_sampled: 11640000
    num_steps_trained: 11640000
    wait_time_ms: 436.636
  iterations_since_restore: 388
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 17259.564002752304
  time_this_iter_s: 43.29235005378723
  time_total_s: 17259.564002752304
  timestamp: 1594169450
  timesteps_since_restore: 11640000
  timesteps_this_iter: 30000
  timesteps_total: 11640000
  training_iteration: 388
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 17259 s, 388 iter, 11640000 ts, 1.23e+03 rew

agent-1: 43.0
agent-2: 50.0
agent-3: 46.0
agent-4: 11.0
agent-5: 54.0
agent-6: 20.0
agent-7: 37.0
agent-8: 55.0
agent-9: 87.0
agent-10: 46.0
agent-11: 91.0
agent-12: 48.0
agent-13: 71.0
agent-14: 40.0
agent-15: 41.0
agent-16: 26.0
agent-17: 22.0
agent-18: 25.0
agent-19: 64.0
agent-20: 72.0
agent-21: 32.0
agent-22: 75.0
agent-23: 54.0
agent-24: 36.0
agent-25: 43.0
agent-26: 59.0
agent-27: 41.0
agent-28: 43.0
agent-29: 55.0
agent-30: 93.0
Sum Reward: 1480.0
Avg Reward: 49.333333333333336
Min Reward: 11.0
Max Reward: 93.0
Gini Coefficient: 0.22918918918918918
20:20 Ratio: 3.5955882352941178
Max-min Ratio: 8.454545454545455
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-51-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1234.0
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 388
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.707
    dispatch_time_ms: 5.099
    learner:
      cur_lr: 0.0005847759894095361
      grad_gnorm: 40.0
      policy_entropy: 268.1145935058594
      policy_loss: -39.98007583618164
      var_gnorm: 23.6558895111084
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 4.426848888397217
    num_steps_sampled: 11670000
    num_steps_trained: 11670000
    wait_time_ms: 451.952
  iterations_since_restore: 389
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 17304.494033575058
  time_this_iter_s: 44.930030822753906
  time_total_s: 17304.494033575058
  timestamp: 1594169494
  timesteps_since_restore: 11670000
  timesteps_this_iter: 30000
  timesteps_total: 11670000
  training_iteration: 389
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 17304 s, 389 iter, 11670000 ts, 1.23e+03 rew

agent-1: 39.0
agent-2: 39.0
agent-3: 24.0
agent-4: 24.0
agent-5: 28.0
agent-6: 41.0
agent-7: 10.0
agent-8: 52.0
agent-9: 52.0
agent-10: 58.0
agent-11: 39.0
agent-12: 41.0
agent-13: 29.0
agent-14: 17.0
agent-15: 36.0
agent-16: 16.0
agent-17: 52.0
agent-18: 23.0
agent-19: 48.0
agent-20: 31.0
agent-21: 41.0
agent-22: 37.0
agent-23: 23.0
agent-24: 32.0
agent-25: 46.0
agent-26: 30.0
agent-27: 31.0
agent-28: 32.0
agent-29: 42.0
agent-30: 50.0
Sum Reward: 1063.0
Avg Reward: 35.43333333333333
Min Reward: 10.0
Max Reward: 58.0
Gini Coefficient: 0.18792724992160553
20:20 Ratio: 2.7610619469026547
Max-min Ratio: 5.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-52-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1233.39
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 389
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.592
    dispatch_time_ms: 5.833
    learner:
      cur_lr: 0.0005827780114486814
      grad_gnorm: 40.000003814697266
      policy_entropy: 254.90286254882812
      policy_loss: -20.501428604125977
      var_gnorm: 23.66035270690918
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 21.737403869628906
    num_steps_sampled: 11700000
    num_steps_trained: 11700000
    wait_time_ms: 432.059
  iterations_since_restore: 390
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 17348.338438749313
  time_this_iter_s: 43.84440517425537
  time_total_s: 17348.338438749313
  timestamp: 1594169538
  timesteps_since_restore: 11700000
  timesteps_this_iter: 30000
  timesteps_total: 11700000
  training_iteration: 390
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 17348 s, 390 iter, 11700000 ts, 1.23e+03 rew

agent-1: 47.0
agent-2: 24.0
agent-3: 42.0
agent-4: 42.0
agent-5: 32.0
agent-6: 23.0
agent-7: 23.0
agent-8: 42.0
agent-9: 43.0
agent-10: 34.0
agent-11: 40.0
agent-12: 37.0
agent-13: 66.0
agent-14: 43.0
agent-15: 52.0
agent-16: 32.0
agent-17: 24.0
agent-18: 24.0
agent-19: 42.0
agent-20: 35.0
agent-21: 42.0
agent-22: 29.0
agent-23: 31.0
agent-24: 31.0
agent-25: 26.0
agent-26: 19.0
agent-27: 36.0
agent-28: 38.0
agent-29: 24.0
agent-30: 47.0
Sum Reward: 1070.0
Avg Reward: 35.666666666666664
Min Reward: 19.0
Max Reward: 66.0
Gini Coefficient: 0.15781931464174453
20:20 Ratio: 2.1751824817518246
Max-min Ratio: 3.473684210526316
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-53-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1231.58
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 390
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.684
    dispatch_time_ms: 6.23
    learner:
      cur_lr: 0.0005807799752801657
      grad_gnorm: 40.0
      policy_entropy: 222.34498596191406
      policy_loss: 91.15805053710938
      var_gnorm: 23.650802612304688
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 171.85028076171875
    num_steps_sampled: 11730000
    num_steps_trained: 11730000
    wait_time_ms: 439.589
  iterations_since_restore: 391
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 17393.340142965317
  time_this_iter_s: 45.00170421600342
  time_total_s: 17393.340142965317
  timestamp: 1594169583
  timesteps_since_restore: 11730000
  timesteps_this_iter: 30000
  timesteps_total: 11730000
  training_iteration: 391
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 17393 s, 391 iter, 11730000 ts, 1.23e+03 rew

agent-1: 44.0
agent-2: 42.0
agent-3: 40.0
agent-4: 35.0
agent-5: 40.0
agent-6: 29.0
agent-7: 46.0
agent-8: 30.0
agent-9: 26.0
agent-10: 28.0
agent-11: 30.0
agent-12: 41.0
agent-13: 21.0
agent-14: 28.0
agent-15: 42.0
agent-16: 46.0
agent-17: 41.0
agent-18: 47.0
agent-19: 47.0
agent-20: 27.0
agent-21: 34.0
agent-22: 29.0
agent-23: 14.0
agent-24: 26.0
agent-25: 32.0
agent-26: 49.0
agent-27: 33.0
agent-28: 23.0
agent-29: 20.0
agent-30: 38.0
Sum Reward: 1028.0
Avg Reward: 34.266666666666666
Min Reward: 14.0
Max Reward: 49.0
Gini Coefficient: 0.1514267185473411
20:20 Ratio: 2.146153846153846
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-53-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1229.8
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 391
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.599
    dispatch_time_ms: 5.554
    learner:
      cur_lr: 0.0005787819973193109
      grad_gnorm: 40.0
      policy_entropy: 244.368408203125
      policy_loss: 34.73202896118164
      var_gnorm: 23.657377243041992
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 62.46735382080078
    num_steps_sampled: 11760000
    num_steps_trained: 11760000
    wait_time_ms: 432.896
  iterations_since_restore: 392
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 17437.177894115448
  time_this_iter_s: 43.837751150131226
  time_total_s: 17437.177894115448
  timestamp: 1594169627
  timesteps_since_restore: 11760000
  timesteps_this_iter: 30000
  timesteps_total: 11760000
  training_iteration: 392
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 17437 s, 392 iter, 11760000 ts, 1.23e+03 rew

agent-1: 5.0
agent-2: 18.0
agent-3: 18.0
agent-4: 27.0
agent-5: 28.0
agent-6: 28.0
agent-7: 25.0
agent-8: 37.0
agent-9: 42.0
agent-10: 53.0
agent-11: 29.0
agent-12: 44.0
agent-13: 47.0
agent-14: 31.0
agent-15: 31.0
agent-16: 17.0
agent-17: 72.0
agent-18: 40.0
agent-19: 42.0
agent-20: 31.0
agent-21: 12.0
agent-22: 32.0
agent-23: 45.0
agent-24: 45.0
agent-25: 0.0
agent-26: 38.0
agent-27: 12.0
agent-28: 44.0
agent-29: 24.0
agent-30: 37.0
Sum Reward: 954.0
Avg Reward: 31.8
Min Reward: 0.0
Max Reward: 72.0
Gini Coefficient: 0.2575821104122991
20:20 Ratio: 4.78125
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-54-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1224.22
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 392
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.845
    dispatch_time_ms: 5.721
    learner:
      cur_lr: 0.0005767840193584561
      grad_gnorm: 40.0
      policy_entropy: 213.94898986816406
      policy_loss: -8.980087280273438
      var_gnorm: 23.675411224365234
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.106197357177734
    num_steps_sampled: 11790000
    num_steps_trained: 11790000
    wait_time_ms: 447.221
  iterations_since_restore: 393
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 17482.27027606964
  time_this_iter_s: 45.092381954193115
  time_total_s: 17482.27027606964
  timestamp: 1594169672
  timesteps_since_restore: 11790000
  timesteps_this_iter: 30000
  timesteps_total: 11790000
  training_iteration: 393
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 17482 s, 393 iter, 11790000 ts, 1.22e+03 rew

agent-1: 32.0
agent-2: 21.0
agent-3: 38.0
agent-4: 49.0
agent-5: 21.0
agent-6: 45.0
agent-7: 24.0
agent-8: 22.0
agent-9: 31.0
agent-10: 46.0
agent-11: 50.0
agent-12: 32.0
agent-13: 5.0
agent-14: 40.0
agent-15: 64.0
agent-16: 26.0
agent-17: 33.0
agent-18: 41.0
agent-19: 23.0
agent-20: 53.0
agent-21: 28.0
agent-22: 49.0
agent-23: 27.0
agent-24: 26.0
agent-25: 59.0
agent-26: 28.0
agent-27: 28.0
agent-28: 6.0
agent-29: 56.0
agent-30: 44.0
Sum Reward: 1047.0
Avg Reward: 34.9
Min Reward: 5.0
Max Reward: 64.0
Gini Coefficient: 0.2308500477554919
20:20 Ratio: 3.377551020408163
Max-min Ratio: 12.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-55-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1221.21
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 393
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.021
    dispatch_time_ms: 41.482
    learner:
      cur_lr: 0.0005747859831899405
      grad_gnorm: 40.000003814697266
      policy_entropy: 215.3159637451172
      policy_loss: 10.674118041992188
      var_gnorm: 23.690366744995117
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 68.23526000976562
    num_steps_sampled: 11820000
    num_steps_trained: 11820000
    wait_time_ms: 451.236
  iterations_since_restore: 394
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 17527.13167142868
  time_this_iter_s: 44.86139535903931
  time_total_s: 17527.13167142868
  timestamp: 1594169717
  timesteps_since_restore: 11820000
  timesteps_this_iter: 30000
  timesteps_total: 11820000
  training_iteration: 394
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 17527 s, 394 iter, 11820000 ts, 1.22e+03 rew

agent-1: 39.0
agent-2: 54.0
agent-3: 48.0
agent-4: 45.0
agent-5: 58.0
agent-6: 48.0
agent-7: 51.0
agent-8: 50.0
agent-9: 35.0
agent-10: 58.0
agent-11: 73.0
agent-12: 47.0
agent-13: 59.0
agent-14: 47.0
agent-15: 52.0
agent-16: 51.0
agent-17: 43.0
agent-18: 12.0
agent-19: 46.0
agent-20: 37.0
agent-21: 55.0
agent-22: 56.0
agent-23: 30.0
agent-24: 48.0
agent-25: 41.0
agent-26: 51.0
agent-27: 58.0
agent-28: 47.0
agent-29: 51.0
agent-30: 17.0
Sum Reward: 1407.0
Avg Reward: 46.9
Min Reward: 12.0
Max Reward: 73.0
Gini Coefficient: 0.13113006396588486
20:20 Ratio: 2.1294117647058823
Max-min Ratio: 6.083333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-56-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1222.28
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 394
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.157
    dispatch_time_ms: 46.175
    learner:
      cur_lr: 0.0005727880052290857
      grad_gnorm: 39.999996185302734
      policy_entropy: 224.72703552246094
      policy_loss: -18.107568740844727
      var_gnorm: 23.683753967285156
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 7.092496395111084
    num_steps_sampled: 11850000
    num_steps_trained: 11850000
    wait_time_ms: 411.905
  iterations_since_restore: 395
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 17573.07058262825
  time_this_iter_s: 45.9389111995697
  time_total_s: 17573.07058262825
  timestamp: 1594169763
  timesteps_since_restore: 11850000
  timesteps_this_iter: 30000
  timesteps_total: 11850000
  training_iteration: 395
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 17573 s, 395 iter, 11850000 ts, 1.22e+03 rew

agent-1: 41.0
agent-2: 39.0
agent-3: 51.0
agent-4: 51.0
agent-5: 56.0
agent-6: 62.0
agent-7: 43.0
agent-8: 32.0
agent-9: 46.0
agent-10: 40.0
agent-11: 25.0
agent-12: 19.0
agent-13: 37.0
agent-14: 45.0
agent-15: 31.0
agent-16: 59.0
agent-17: 53.0
agent-18: 43.0
agent-19: 30.0
agent-20: 29.0
agent-21: 20.0
agent-22: 19.0
agent-23: 30.0
agent-24: 30.0
agent-25: 48.0
agent-26: 53.0
agent-27: 43.0
agent-28: 35.0
agent-29: 48.0
agent-30: 40.0
Sum Reward: 1198.0
Avg Reward: 39.93333333333333
Min Reward: 19.0
Max Reward: 62.0
Gini Coefficient: 0.16521981079577072
20:20 Ratio: 2.352112676056338
Max-min Ratio: 3.263157894736842
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-56-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1220.35
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 395
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.015
    dispatch_time_ms: 18.851
    learner:
      cur_lr: 0.0005707900272682309
      grad_gnorm: 25.77045440673828
      policy_entropy: 218.95404052734375
      policy_loss: -4.650998115539551
      var_gnorm: 23.69447135925293
      vf_explained_var: 0.0
      vf_loss: 26.39583969116211
    num_steps_sampled: 11880000
    num_steps_trained: 11880000
    wait_time_ms: 438.494
  iterations_since_restore: 396
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 17618.31274151802
  time_this_iter_s: 45.24215888977051
  time_total_s: 17618.31274151802
  timestamp: 1594169809
  timesteps_since_restore: 11880000
  timesteps_this_iter: 30000
  timesteps_total: 11880000
  training_iteration: 396
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 17618 s, 396 iter, 11880000 ts, 1.22e+03 rew

agent-1: 28.0
agent-2: 62.0
agent-3: 27.0
agent-4: 96.0
agent-5: 29.0
agent-6: 44.0
agent-7: 35.0
agent-8: 53.0
agent-9: 19.0
agent-10: 48.0
agent-11: 62.0
agent-12: 50.0
agent-13: 32.0
agent-14: 27.0
agent-15: 21.0
agent-16: 50.0
agent-17: 25.0
agent-18: 51.0
agent-19: 62.0
agent-20: 60.0
agent-21: 50.0
agent-22: 22.0
agent-23: 66.0
agent-24: 29.0
agent-25: 57.0
agent-26: 63.0
agent-27: 26.0
agent-28: 25.0
agent-29: 50.0
agent-30: 30.0
Sum Reward: 1299.0
Avg Reward: 43.3
Min Reward: 19.0
Max Reward: 96.0
Gini Coefficient: 0.22661021298434694
20:20 Ratio: 2.9782608695652173
Max-min Ratio: 5.052631578947368
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-57-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1220.05
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 396
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.522
    dispatch_time_ms: 57.033
    learner:
      cur_lr: 0.0005687919910997152
      grad_gnorm: 40.000003814697266
      policy_entropy: 187.3300323486328
      policy_loss: 39.25252914428711
      var_gnorm: 23.68358612060547
      vf_explained_var: 0.0
      vf_loss: 82.99801635742188
    num_steps_sampled: 11910000
    num_steps_trained: 11910000
    wait_time_ms: 346.447
  iterations_since_restore: 397
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 17663.299860715866
  time_this_iter_s: 44.98711919784546
  time_total_s: 17663.299860715866
  timestamp: 1594169854
  timesteps_since_restore: 11910000
  timesteps_this_iter: 30000
  timesteps_total: 11910000
  training_iteration: 397
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 17663 s, 397 iter, 11910000 ts, 1.22e+03 rew

agent-1: 41.0
agent-2: 26.0
agent-3: 64.0
agent-4: 33.0
agent-5: 56.0
agent-6: 24.0
agent-7: 54.0
agent-8: 16.0
agent-9: 39.0
agent-10: 26.0
agent-11: 54.0
agent-12: 46.0
agent-13: 48.0
agent-14: 31.0
agent-15: 31.0
agent-16: 41.0
agent-17: 51.0
agent-18: 58.0
agent-19: 46.0
agent-20: 32.0
agent-21: 29.0
agent-22: 21.0
agent-23: 26.0
agent-24: 44.0
agent-25: 43.0
agent-26: 41.0
agent-27: 36.0
agent-28: 43.0
agent-29: 31.0
agent-30: 31.0
Sum Reward: 1162.0
Avg Reward: 38.733333333333334
Min Reward: 16.0
Max Reward: 64.0
Gini Coefficient: 0.17286288009179576
20:20 Ratio: 2.4244604316546763
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-58-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1219.3
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 397
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.349
    dispatch_time_ms: 63.216
    learner:
      cur_lr: 0.0005667940131388605
      grad_gnorm: 40.000003814697266
      policy_entropy: 232.65496826171875
      policy_loss: 12.231941223144531
      var_gnorm: 23.693199157714844
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 61.37664031982422
    num_steps_sampled: 11940000
    num_steps_trained: 11940000
    wait_time_ms: 596.698
  iterations_since_restore: 398
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 17711.38316345215
  time_this_iter_s: 48.08330273628235
  time_total_s: 17711.38316345215
  timestamp: 1594169902
  timesteps_since_restore: 11940000
  timesteps_this_iter: 30000
  timesteps_total: 11940000
  training_iteration: 398
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 17711 s, 398 iter, 11940000 ts, 1.22e+03 rew

agent-1: 66.0
agent-2: 51.0
agent-3: 17.0
agent-4: 31.0
agent-5: 37.0
agent-6: 28.0
agent-7: 27.0
agent-8: 60.0
agent-9: 31.0
agent-10: 43.0
agent-11: 43.0
agent-12: 35.0
agent-13: 30.0
agent-14: 77.0
agent-15: 46.0
agent-16: 52.0
agent-17: 38.0
agent-18: 41.0
agent-19: 56.0
agent-20: 40.0
agent-21: 42.0
agent-22: 65.0
agent-23: 77.0
agent-24: 48.0
agent-25: 38.0
agent-26: 29.0
agent-27: 26.0
agent-28: 26.0
agent-29: 35.0
agent-30: 48.0
Sum Reward: 1283.0
Avg Reward: 42.766666666666666
Min Reward: 17.0
Max Reward: 77.0
Gini Coefficient: 0.19207586386074305
20:20 Ratio: 2.6209150326797386
Max-min Ratio: 4.529411764705882
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-59-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1220.98
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 398
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.058
    dispatch_time_ms: 41.083
    learner:
      cur_lr: 0.0005647959769703448
      grad_gnorm: 40.000003814697266
      policy_entropy: 261.44146728515625
      policy_loss: 51.922420501708984
      var_gnorm: 23.679241180419922
      vf_explained_var: 0.0
      vf_loss: 68.8207015991211
    num_steps_sampled: 11970000
    num_steps_trained: 11970000
    wait_time_ms: 411.596
  iterations_since_restore: 399
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 17756.160494089127
  time_this_iter_s: 44.77733063697815
  time_total_s: 17756.160494089127
  timestamp: 1594169946
  timesteps_since_restore: 11970000
  timesteps_this_iter: 30000
  timesteps_total: 11970000
  training_iteration: 399
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 17756 s, 399 iter, 11970000 ts, 1.22e+03 rew

agent-1: 36.0
agent-2: 22.0
agent-3: 28.0
agent-4: 18.0
agent-5: 37.0
agent-6: 24.0
agent-7: 18.0
agent-8: 33.0
agent-9: 22.0
agent-10: 15.0
agent-11: 44.0
agent-12: 49.0
agent-13: 31.0
agent-14: 32.0
agent-15: 23.0
agent-16: 33.0
agent-17: 24.0
agent-18: 50.0
agent-19: 41.0
agent-20: 36.0
agent-21: 38.0
agent-22: 18.0
agent-23: 41.0
agent-24: 34.0
agent-25: 47.0
agent-26: 52.0
agent-27: 53.0
agent-28: 22.0
agent-29: 44.0
agent-30: 40.0
Sum Reward: 1005.0
Avg Reward: 33.5
Min Reward: 15.0
Max Reward: 53.0
Gini Coefficient: 0.18835820895522387
20:20 Ratio: 2.6106194690265485
Max-min Ratio: 3.533333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_20-59-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1218.69
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 399
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.557
    dispatch_time_ms: 6.102
    learner:
      cur_lr: 0.00056279799900949
      grad_gnorm: 40.000003814697266
      policy_entropy: 269.7425231933594
      policy_loss: -15.609646797180176
      var_gnorm: 23.680646896362305
      vf_explained_var: 0.0
      vf_loss: 17.62632942199707
    num_steps_sampled: 12000000
    num_steps_trained: 12000000
    wait_time_ms: 458.147
  iterations_since_restore: 400
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 17800.37499165535
  time_this_iter_s: 44.214497566223145
  time_total_s: 17800.37499165535
  timestamp: 1594169991
  timesteps_since_restore: 12000000
  timesteps_this_iter: 30000
  timesteps_total: 12000000
  training_iteration: 400
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 17800 s, 400 iter, 12000000 ts, 1.22e+03 rew

agent-1: 16.0
agent-2: 22.0
agent-3: 25.0
agent-4: 33.0
agent-5: 25.0
agent-6: 29.0
agent-7: 69.0
agent-8: 52.0
agent-9: 23.0
agent-10: 31.0
agent-11: 17.0
agent-12: 47.0
agent-13: 21.0
agent-14: 34.0
agent-15: 28.0
agent-16: 48.0
agent-17: 23.0
agent-18: 8.0
agent-19: 33.0
agent-20: 42.0
agent-21: 40.0
agent-22: 28.0
agent-23: 51.0
agent-24: 17.0
agent-25: 60.0
agent-26: 46.0
agent-27: 63.0
agent-28: 57.0
agent-29: 36.0
agent-30: 29.0
Sum Reward: 1053.0
Avg Reward: 35.1
Min Reward: 8.0
Max Reward: 69.0
Gini Coefficient: 0.24320987654320989
20:20 Ratio: 3.485148514851485
Max-min Ratio: 8.625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_21-00-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1218.05
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 400
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 4.164
    dispatch_time_ms: 5.895
    learner:
      cur_lr: 0.0005608000210486352
      grad_gnorm: 40.0
      policy_entropy: 259.1034240722656
      policy_loss: 28.984495162963867
      var_gnorm: 23.659557342529297
      vf_explained_var: 0.0
      vf_loss: 52.20884704589844
    num_steps_sampled: 12030000
    num_steps_trained: 12030000
    wait_time_ms: 430.223
  iterations_since_restore: 401
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 17844.851776361465
  time_this_iter_s: 44.47678470611572
  time_total_s: 17844.851776361465
  timestamp: 1594170035
  timesteps_since_restore: 12030000
  timesteps_this_iter: 30000
  timesteps_total: 12030000
  training_iteration: 401
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 17844 s, 401 iter, 12030000 ts, 1.22e+03 rew

agent-1: 22.0
agent-2: 40.0
agent-3: 44.0
agent-4: 32.0
agent-5: 26.0
agent-6: 20.0
agent-7: 37.0
agent-8: 28.0
agent-9: 25.0
agent-10: 47.0
agent-11: 24.0
agent-12: 17.0
agent-13: 27.0
agent-14: 35.0
agent-15: 20.0
agent-16: 34.0
agent-17: 32.0
agent-18: 36.0
agent-19: 26.0
agent-20: 23.0
agent-21: 34.0
agent-22: 42.0
agent-23: 37.0
agent-24: 17.0
agent-25: 37.0
agent-26: 19.0
agent-27: 20.0
agent-28: 46.0
agent-29: 33.0
agent-30: 48.0
Sum Reward: 928.0
Avg Reward: 30.933333333333334
Min Reward: 17.0
Max Reward: 48.0
Gini Coefficient: 0.16954022988505746
20:20 Ratio: 2.3628318584070795
Max-min Ratio: 2.823529411764706
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_21-01-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1215.02
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 401
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.669
    dispatch_time_ms: 36.99
    learner:
      cur_lr: 0.0005588019848801196
      grad_gnorm: 40.0
      policy_entropy: 261.32476806640625
      policy_loss: 24.73176383972168
      var_gnorm: 23.669939041137695
      vf_explained_var: 0.0
      vf_loss: 39.495609283447266
    num_steps_sampled: 12060000
    num_steps_trained: 12060000
    wait_time_ms: 389.814
  iterations_since_restore: 402
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 17889.582105398178
  time_this_iter_s: 44.73032903671265
  time_total_s: 17889.582105398178
  timestamp: 1594170080
  timesteps_since_restore: 12060000
  timesteps_this_iter: 30000
  timesteps_total: 12060000
  training_iteration: 402
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 17889 s, 402 iter, 12060000 ts, 1.22e+03 rew

agent-1: 79.0
agent-2: 22.0
agent-3: 13.0
agent-4: 45.0
agent-5: 48.0
agent-6: 46.0
agent-7: 25.0
agent-8: 52.0
agent-9: 43.0
agent-10: 32.0
agent-11: 27.0
agent-12: 26.0
agent-13: 34.0
agent-14: 65.0
agent-15: 26.0
agent-16: 9.0
agent-17: 24.0
agent-18: 46.0
agent-19: 26.0
agent-20: 63.0
agent-21: 31.0
agent-22: 54.0
agent-23: 37.0
agent-24: 25.0
agent-25: 55.0
agent-26: 14.0
agent-27: 26.0
agent-28: 24.0
agent-29: 55.0
agent-30: 24.0
Sum Reward: 1096.0
Avg Reward: 36.53333333333333
Min Reward: 9.0
Max Reward: 79.0
Gini Coefficient: 0.25304136253041365
20:20 Ratio: 3.5
Max-min Ratio: 8.777777777777779
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_21-02-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1215.37
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 402
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.257
    dispatch_time_ms: 6.018
    learner:
      cur_lr: 0.0005568040069192648
      grad_gnorm: 39.999996185302734
      policy_entropy: 250.77207946777344
      policy_loss: 86.53961944580078
      var_gnorm: 23.66605567932129
      vf_explained_var: 0.0
      vf_loss: 110.73419952392578
    num_steps_sampled: 12090000
    num_steps_trained: 12090000
    wait_time_ms: 443.874
  iterations_since_restore: 403
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 17935.011965751648
  time_this_iter_s: 45.42986035346985
  time_total_s: 17935.011965751648
  timestamp: 1594170126
  timesteps_since_restore: 12090000
  timesteps_this_iter: 30000
  timesteps_total: 12090000
  training_iteration: 403
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 17935 s, 403 iter, 12090000 ts, 1.22e+03 rew

agent-1: 45.0
agent-2: 40.0
agent-3: 37.0
agent-4: 40.0
agent-5: 33.0
agent-6: 40.0
agent-7: 38.0
agent-8: 40.0
agent-9: 67.0
agent-10: 31.0
agent-11: 29.0
agent-12: 25.0
agent-13: 31.0
agent-14: 27.0
agent-15: 32.0
agent-16: 16.0
agent-17: 31.0
agent-18: 44.0
agent-19: 27.0
agent-20: 31.0
agent-21: 34.0
agent-22: 44.0
agent-23: 19.0
agent-24: 45.0
agent-25: 26.0
agent-26: 23.0
agent-27: 62.0
agent-28: 21.0
agent-29: 27.0
agent-30: 20.0
Sum Reward: 1025.0
Avg Reward: 34.166666666666664
Min Reward: 16.0
Max Reward: 67.0
Gini Coefficient: 0.17915447154471545
20:20 Ratio: 2.475806451612903
Max-min Ratio: 4.1875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_21-02-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1212.97
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 403
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.59
    dispatch_time_ms: 6.205
    learner:
      cur_lr: 0.00055480602895841
      grad_gnorm: 40.0
      policy_entropy: 223.32843017578125
      policy_loss: 18.825050354003906
      var_gnorm: 23.673606872558594
      vf_explained_var: 0.0
      vf_loss: 44.11698913574219
    num_steps_sampled: 12120000
    num_steps_trained: 12120000
    wait_time_ms: 421.205
  iterations_since_restore: 404
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 17978.643403053284
  time_this_iter_s: 43.63143730163574
  time_total_s: 17978.643403053284
  timestamp: 1594170169
  timesteps_since_restore: 12120000
  timesteps_this_iter: 30000
  timesteps_total: 12120000
  training_iteration: 404
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 17978 s, 404 iter, 12120000 ts, 1.21e+03 rew

agent-1: 61.0
agent-2: 51.0
agent-3: 29.0
agent-4: 38.0
agent-5: 35.0
agent-6: 27.0
agent-7: 57.0
agent-8: 38.0
agent-9: 28.0
agent-10: 24.0
agent-11: 33.0
agent-12: 42.0
agent-13: 71.0
agent-14: 33.0
agent-15: 29.0
agent-16: 57.0
agent-17: 26.0
agent-18: 64.0
agent-19: 47.0
agent-20: 42.0
agent-21: 35.0
agent-22: 31.0
agent-23: 41.0
agent-24: 34.0
agent-25: 31.0
agent-26: 32.0
agent-27: 55.0
agent-28: 33.0
agent-29: 34.0
agent-30: 51.0
Sum Reward: 1209.0
Avg Reward: 40.3
Min Reward: 24.0
Max Reward: 71.0
Gini Coefficient: 0.16793493245106147
20:20 Ratio: 2.2392638036809815
Max-min Ratio: 2.9583333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_21-03-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1211.15
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 404
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.126
    dispatch_time_ms: 5.567
    learner:
      cur_lr: 0.0005528079927898943
      grad_gnorm: 39.999996185302734
      policy_entropy: 213.73902893066406
      policy_loss: -34.630882263183594
      var_gnorm: 23.674938201904297
      vf_explained_var: 0.0
      vf_loss: 4.089986324310303
    num_steps_sampled: 12150000
    num_steps_trained: 12150000
    wait_time_ms: 419.272
  iterations_since_restore: 405
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 18022.6582570076
  time_this_iter_s: 44.014853954315186
  time_total_s: 18022.6582570076
  timestamp: 1594170213
  timesteps_since_restore: 12150000
  timesteps_this_iter: 30000
  timesteps_total: 12150000
  training_iteration: 405
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 18022 s, 405 iter, 12150000 ts, 1.21e+03 rew

agent-1: 54.0
agent-2: 38.0
agent-3: 77.0
agent-4: 49.0
agent-5: 44.0
agent-6: 62.0
agent-7: 32.0
agent-8: 50.0
agent-9: 24.0
agent-10: 52.0
agent-11: 48.0
agent-12: 39.0
agent-13: 39.0
agent-14: 43.0
agent-15: 56.0
agent-16: 61.0
agent-17: 68.0
agent-18: 33.0
agent-19: 23.0
agent-20: 44.0
agent-21: 24.0
agent-22: 57.0
agent-23: 69.0
agent-24: 56.0
agent-25: 39.0
agent-26: 63.0
agent-27: 34.0
agent-28: 32.0
agent-29: 49.0
agent-30: 56.0
Sum Reward: 1415.0
Avg Reward: 47.166666666666664
Min Reward: 23.0
Max Reward: 77.0
Gini Coefficient: 0.16652532391048291
20:20 Ratio: 2.380952380952381
Max-min Ratio: 3.347826086956522
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_21-04-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1212.44
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 405
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.066
    dispatch_time_ms: 6.154
    learner:
      cur_lr: 0.0005508100148290396
      grad_gnorm: 40.0
      policy_entropy: 193.05514526367188
      policy_loss: -17.026172637939453
      var_gnorm: 23.67951011657715
      vf_explained_var: 0.0
      vf_loss: 33.44693374633789
    num_steps_sampled: 12180000
    num_steps_trained: 12180000
    wait_time_ms: 424.824
  iterations_since_restore: 406
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 18066.201913833618
  time_this_iter_s: 43.54365682601929
  time_total_s: 18066.201913833618
  timestamp: 1594170257
  timesteps_since_restore: 12180000
  timesteps_this_iter: 30000
  timesteps_total: 12180000
  training_iteration: 406
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 18066 s, 406 iter, 12180000 ts, 1.21e+03 rew

agent-1: 33.0
agent-2: 50.0
agent-3: 49.0
agent-4: 26.0
agent-5: 20.0
agent-6: 56.0
agent-7: 62.0
agent-8: 43.0
agent-9: 35.0
agent-10: 9.0
agent-11: 51.0
agent-12: 47.0
agent-13: 39.0
agent-14: 48.0
agent-15: 63.0
agent-16: 51.0
agent-17: 41.0
agent-18: 35.0
agent-19: 36.0
agent-20: 21.0
agent-21: 47.0
agent-22: 26.0
agent-23: 39.0
agent-24: 60.0
agent-25: 38.0
agent-26: 18.0
agent-27: 37.0
agent-28: 23.0
agent-29: 42.0
agent-30: 54.0
Sum Reward: 1199.0
Avg Reward: 39.96666666666667
Min Reward: 9.0
Max Reward: 63.0
Gini Coefficient: 0.19168751737559078
20:20 Ratio: 2.9572649572649574
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_21-05-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1211.66
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 406
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.788
    dispatch_time_ms: 6.16
    learner:
      cur_lr: 0.0005488119786605239
      grad_gnorm: 39.999996185302734
      policy_entropy: 219.39871215820312
      policy_loss: 44.79599380493164
      var_gnorm: 23.68157958984375
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 82.44535827636719
    num_steps_sampled: 12210000
    num_steps_trained: 12210000
    wait_time_ms: 417.533
  iterations_since_restore: 407
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 18110.484773397446
  time_this_iter_s: 44.282859563827515
  time_total_s: 18110.484773397446
  timestamp: 1594170301
  timesteps_since_restore: 12210000
  timesteps_this_iter: 30000
  timesteps_total: 12210000
  training_iteration: 407
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 18110 s, 407 iter, 12210000 ts, 1.21e+03 rew

agent-1: 61.0
agent-2: 59.0
agent-3: 56.0
agent-4: 45.0
agent-5: 46.0
agent-6: 39.0
agent-7: 34.0
agent-8: 22.0
agent-9: 22.0
agent-10: 44.0
agent-11: 50.0
agent-12: 52.0
agent-13: 48.0
agent-14: 41.0
agent-15: 35.0
agent-16: 71.0
agent-17: 46.0
agent-18: 31.0
agent-19: 47.0
agent-20: 46.0
agent-21: 28.0
agent-22: 60.0
agent-23: 42.0
agent-24: 73.0
agent-25: 48.0
agent-26: 37.0
agent-27: 36.0
agent-28: 25.0
agent-29: 45.0
agent-30: 49.0
Sum Reward: 1338.0
Avg Reward: 44.6
Min Reward: 22.0
Max Reward: 73.0
Gini Coefficient: 0.15719980069755854
20:20 Ratio: 2.345679012345679
Max-min Ratio: 3.3181818181818183
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_21-05-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1214.92
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 407
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.186
    dispatch_time_ms: 5.951
    learner:
      cur_lr: 0.0005468140006996691
      grad_gnorm: 40.0
      policy_entropy: 223.210693359375
      policy_loss: 59.43881607055664
      var_gnorm: 23.687509536743164
      vf_explained_var: 0.0
      vf_loss: 125.27416229248047
    num_steps_sampled: 12240000
    num_steps_trained: 12240000
    wait_time_ms: 429.742
  iterations_since_restore: 408
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 18154.701753139496
  time_this_iter_s: 44.21697974205017
  time_total_s: 18154.701753139496
  timestamp: 1594170346
  timesteps_since_restore: 12240000
  timesteps_this_iter: 30000
  timesteps_total: 12240000
  training_iteration: 408
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 18154 s, 408 iter, 12240000 ts, 1.21e+03 rew

agent-1: 43.0
agent-2: 28.0
agent-3: 45.0
agent-4: 19.0
agent-5: 49.0
agent-6: 31.0
agent-7: 31.0
agent-8: 42.0
agent-9: 32.0
agent-10: 27.0
agent-11: 53.0
agent-12: 32.0
agent-13: 49.0
agent-14: 49.0
agent-15: 37.0
agent-16: 57.0
agent-17: 11.0
agent-18: 18.0
agent-19: 45.0
agent-20: 42.0
agent-21: 48.0
agent-22: 44.0
agent-23: 27.0
agent-24: 45.0
agent-25: 71.0
agent-26: 60.0
agent-27: 15.0
agent-28: 50.0
agent-29: 35.0
agent-30: 30.0
Sum Reward: 1165.0
Avg Reward: 38.833333333333336
Min Reward: 11.0
Max Reward: 71.0
Gini Coefficient: 0.19745350500715309
20:20 Ratio: 2.905982905982906
Max-min Ratio: 6.454545454545454
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_21-06-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1215.57
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 408
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.676
    dispatch_time_ms: 5.893
    learner:
      cur_lr: 0.0005448160227388144
      grad_gnorm: 38.032474517822266
      policy_entropy: 241.03829956054688
      policy_loss: -9.307172775268555
      var_gnorm: 23.672847747802734
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 23.624195098876953
    num_steps_sampled: 12270000
    num_steps_trained: 12270000
    wait_time_ms: 411.842
  iterations_since_restore: 409
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 18199.339562177658
  time_this_iter_s: 44.63780903816223
  time_total_s: 18199.339562177658
  timestamp: 1594170390
  timesteps_since_restore: 12270000
  timesteps_this_iter: 30000
  timesteps_total: 12270000
  training_iteration: 409
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 18199 s, 409 iter, 12270000 ts, 1.22e+03 rew

agent-1: 56.0
agent-2: 35.0
agent-3: 54.0
agent-4: 47.0
agent-5: 42.0
agent-6: 38.0
agent-7: 44.0
agent-8: 33.0
agent-9: 45.0
agent-10: 43.0
agent-11: 63.0
agent-12: 23.0
agent-13: 32.0
agent-14: 23.0
agent-15: 24.0
agent-16: 35.0
agent-17: 53.0
agent-18: 47.0
agent-19: 65.0
agent-20: 61.0
agent-21: 40.0
agent-22: 37.0
agent-23: 34.0
agent-24: 77.0
agent-25: 45.0
agent-26: 41.0
agent-27: 32.0
agent-28: 33.0
agent-29: 38.0
agent-30: 38.0
Sum Reward: 1278.0
Avg Reward: 42.6
Min Reward: 23.0
Max Reward: 77.0
Gini Coefficient: 0.1616588419405321
20:20 Ratio: 2.251497005988024
Max-min Ratio: 3.347826086956522
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_21-07-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1217.0
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 409
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.365
    dispatch_time_ms: 4.897
    learner:
      cur_lr: 0.0005428179865702987
      grad_gnorm: 40.00000762939453
      policy_entropy: 245.31321716308594
      policy_loss: -27.3945255279541
      var_gnorm: 23.68436050415039
      vf_explained_var: 0.0
      vf_loss: 38.17174530029297
    num_steps_sampled: 12300000
    num_steps_trained: 12300000
    wait_time_ms: 438.717
  iterations_since_restore: 410
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 18242.568605184555
  time_this_iter_s: 43.22904300689697
  time_total_s: 18242.568605184555
  timestamp: 1594170433
  timesteps_since_restore: 12300000
  timesteps_this_iter: 30000
  timesteps_total: 12300000
  training_iteration: 410
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 18242 s, 410 iter, 12300000 ts, 1.22e+03 rew

agent-1: 31.0
agent-2: 25.0
agent-3: 27.0
agent-4: 39.0
agent-5: 46.0
agent-6: 61.0
agent-7: 35.0
agent-8: 42.0
agent-9: 45.0
agent-10: 29.0
agent-11: 28.0
agent-12: 14.0
agent-13: 35.0
agent-14: 55.0
agent-15: 47.0
agent-16: 35.0
agent-17: 40.0
agent-18: 67.0
agent-19: 25.0
agent-20: 32.0
agent-21: 37.0
agent-22: 30.0
agent-23: 35.0
agent-24: 20.0
agent-25: 58.0
agent-26: 23.0
agent-27: 25.0
agent-28: 32.0
agent-29: 44.0
agent-30: 50.0
Sum Reward: 1112.0
Avg Reward: 37.06666666666667
Min Reward: 14.0
Max Reward: 67.0
Gini Coefficient: 0.18621103117505997
20:20 Ratio: 2.5606060606060606
Max-min Ratio: 4.785714285714286
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_21-07-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1215.01
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 410
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.585
    dispatch_time_ms: 7.138
    learner:
      cur_lr: 0.0005408200086094439
      grad_gnorm: 31.4689998626709
      policy_entropy: 263.43328857421875
      policy_loss: -9.811445236206055
      var_gnorm: 23.669010162353516
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 15.808561325073242
    num_steps_sampled: 12330000
    num_steps_trained: 12330000
    wait_time_ms: 407.822
  iterations_since_restore: 411
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 18287.690841197968
  time_this_iter_s: 45.122236013412476
  time_total_s: 18287.690841197968
  timestamp: 1594170479
  timesteps_since_restore: 12330000
  timesteps_this_iter: 30000
  timesteps_total: 12330000
  training_iteration: 411
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 18287 s, 411 iter, 12330000 ts, 1.22e+03 rew

agent-1: 27.0
agent-2: 67.0
agent-3: 59.0
agent-4: 57.0
agent-5: 18.0
agent-6: 40.0
agent-7: 55.0
agent-8: 53.0
agent-9: 31.0
agent-10: 55.0
agent-11: 28.0
agent-12: 27.0
agent-13: 64.0
agent-14: 35.0
agent-15: 21.0
agent-16: 21.0
agent-17: 27.0
agent-18: 59.0
agent-19: 65.0
agent-20: 43.0
agent-21: 29.0
agent-22: 25.0
agent-23: 33.0
agent-24: 48.0
agent-25: 33.0
agent-26: 43.0
agent-27: 62.0
agent-28: 58.0
agent-29: 25.0
agent-30: 40.0
Sum Reward: 1248.0
Avg Reward: 41.6
Min Reward: 18.0
Max Reward: 67.0
Gini Coefficient: 0.20961538461538462
20:20 Ratio: 2.7445255474452557
Max-min Ratio: 3.7222222222222223
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_21-08-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1214.3
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 411
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.536
    dispatch_time_ms: 6.867
    learner:
      cur_lr: 0.0005388219724409282
      grad_gnorm: 39.999996185302734
      policy_entropy: 259.1184387207031
      policy_loss: 9.974305152893066
      var_gnorm: 23.67040252685547
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 59.75379943847656
    num_steps_sampled: 12360000
    num_steps_trained: 12360000
    wait_time_ms: 442.724
  iterations_since_restore: 412
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 18331.518775224686
  time_this_iter_s: 43.82793402671814
  time_total_s: 18331.518775224686
  timestamp: 1594170522
  timesteps_since_restore: 12360000
  timesteps_this_iter: 30000
  timesteps_total: 12360000
  training_iteration: 412
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 18331 s, 412 iter, 12360000 ts, 1.21e+03 rew

agent-1: 26.0
agent-2: 28.0
agent-3: 30.0
agent-4: 35.0
agent-5: 58.0
agent-6: 48.0
agent-7: 42.0
agent-8: 35.0
agent-9: 37.0
agent-10: 53.0
agent-11: 61.0
agent-12: 20.0
agent-13: 31.0
agent-14: 35.0
agent-15: 15.0
agent-16: 25.0
agent-17: 37.0
agent-18: 43.0
agent-19: 32.0
agent-20: 23.0
agent-21: 55.0
agent-22: 34.0
agent-23: 24.0
agent-24: 49.0
agent-25: 26.0
agent-26: 41.0
agent-27: 40.0
agent-28: 33.0
agent-29: 57.0
agent-30: 33.0
Sum Reward: 1106.0
Avg Reward: 36.86666666666667
Min Reward: 15.0
Max Reward: 61.0
Gini Coefficient: 0.17890295358649788
20:20 Ratio: 2.5037593984962405
Max-min Ratio: 4.066666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_21-09-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1211.76
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 412
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.138
    dispatch_time_ms: 6.763
    learner:
      cur_lr: 0.0005368239944800735
      grad_gnorm: 34.74347686767578
      policy_entropy: 264.92901611328125
      policy_loss: 3.143124580383301
      var_gnorm: 23.665992736816406
      vf_explained_var: 2.980232238769531e-07
      vf_loss: 37.4947624206543
    num_steps_sampled: 12390000
    num_steps_trained: 12390000
    wait_time_ms: 448.831
  iterations_since_restore: 413
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 18376.614729642868
  time_this_iter_s: 45.09595441818237
  time_total_s: 18376.614729642868
  timestamp: 1594170568
  timesteps_since_restore: 12390000
  timesteps_this_iter: 30000
  timesteps_total: 12390000
  training_iteration: 413
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 18376 s, 413 iter, 12390000 ts, 1.21e+03 rew

agent-1: 40.0
agent-2: 29.0
agent-3: 41.0
agent-4: 23.0
agent-5: 44.0
agent-6: 24.0
agent-7: 56.0
agent-8: 23.0
agent-9: 29.0
agent-10: 39.0
agent-11: 36.0
agent-12: 40.0
agent-13: 45.0
agent-14: 41.0
agent-15: 16.0
agent-16: 40.0
agent-17: 45.0
agent-18: 34.0
agent-19: 34.0
agent-20: 51.0
agent-21: 45.0
agent-22: 28.0
agent-23: 27.0
agent-24: 45.0
agent-25: 32.0
agent-26: 55.0
agent-27: 37.0
agent-28: 28.0
agent-29: 20.0
agent-30: 18.0
Sum Reward: 1065.0
Avg Reward: 35.5
Min Reward: 16.0
Max Reward: 56.0
Gini Coefficient: 0.16741784037558685
20:20 Ratio: 2.3951612903225805
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_21-10-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1210.1
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 413
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.998
    dispatch_time_ms: 26.165
    learner:
      cur_lr: 0.0005348260165192187
      grad_gnorm: 40.0
      policy_entropy: 262.9845275878906
      policy_loss: 47.60133361816406
      var_gnorm: 23.670265197753906
      vf_explained_var: 0.0
      vf_loss: 105.8125
    num_steps_sampled: 12420000
    num_steps_trained: 12420000
    wait_time_ms: 462.851
  iterations_since_restore: 414
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 18421.98988842964
  time_this_iter_s: 45.37515878677368
  time_total_s: 18421.98988842964
  timestamp: 1594170613
  timesteps_since_restore: 12420000
  timesteps_this_iter: 30000
  timesteps_total: 12420000
  training_iteration: 414
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 18421 s, 414 iter, 12420000 ts, 1.21e+03 rew

agent-1: 26.0
agent-2: 31.0
agent-3: 40.0
agent-4: 47.0
agent-5: 24.0
agent-6: 13.0
agent-7: 57.0
agent-8: 41.0
agent-9: 43.0
agent-10: 41.0
agent-11: 27.0
agent-12: 23.0
agent-13: 28.0
agent-14: 45.0
agent-15: 46.0
agent-16: 22.0
agent-17: 38.0
agent-18: 48.0
agent-19: 34.0
agent-20: 31.0
agent-21: 37.0
agent-22: 33.0
agent-23: 39.0
agent-24: 47.0
agent-25: 33.0
agent-26: 36.0
agent-27: 39.0
agent-28: 32.0
agent-29: 40.0
agent-30: 21.0
Sum Reward: 1062.0
Avg Reward: 35.4
Min Reward: 13.0
Max Reward: 57.0
Gini Coefficient: 0.1524795982423101
20:20 Ratio: 2.248062015503876
Max-min Ratio: 4.384615384615385
agent-1: 41.0
agent-2: 26.0
agent-3: 86.0
agent-4: 35.0
agent-5: 41.0
agent-6: 51.0
agent-7: 21.0
agent-8: 26.0
agent-9: 51.0
agent-10: 31.0
agent-11: 26.0
agent-12: 33.0
agent-13: 72.0
agent-14: 14.0
agent-15: 40.0
agent-16: 34.0
agent-17: 13.0
agent-18: 20.0
agent-19: 29.0
agent-20: 48.0
agent-21: 17.0
agent-22: 45.0
agent-23: 44.0
agent-24: 64.0
agent-25: 43.0
agent-26: 35.0
agent-27: 37.0
agent-28: 21.0
agent-29: 47.0
agent-30: 51.0
Sum Reward: 1142.0
Avg Reward: 38.06666666666667
Min Reward: 13.0
Max Reward: 86.0
Gini Coefficient: 0.236077057793345
20:20 Ratio: 3.5377358490566038
Max-min Ratio: 6.615384615384615
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_21-11-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1208.47
  episode_reward_min: 901.0
  episodes_this_iter: 2
  episodes_total: 415
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.404
    dispatch_time_ms: 17.492
    learner:
      cur_lr: 0.000532827980350703
      grad_gnorm: 39.999996185302734
      policy_entropy: 212.22720336914062
      policy_loss: -352.7715759277344
      var_gnorm: 23.66556739807129
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 414.4251403808594
    num_steps_sampled: 12450000
    num_steps_trained: 12450000
    wait_time_ms: 479.257
  iterations_since_restore: 415
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 18469.282658338547
  time_this_iter_s: 47.29276990890503
  time_total_s: 18469.282658338547
  timestamp: 1594170660
  timesteps_since_restore: 12450000
  timesteps_this_iter: 30000
  timesteps_total: 12450000
  training_iteration: 415
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 18469 s, 415 iter, 12450000 ts, 1.21e+03 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_21-11-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1208.47
  episode_reward_min: 901.0
  episodes_this_iter: 0
  episodes_total: 415
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.544
    dispatch_time_ms: 5.637
    learner:
      cur_lr: 0.0005308300023898482
      grad_gnorm: 26.197200775146484
      policy_entropy: 173.2345428466797
      policy_loss: 8.654497146606445
      var_gnorm: 23.67133331298828
      vf_explained_var: 0.0
      vf_loss: 72.67273712158203
    num_steps_sampled: 12480000
    num_steps_trained: 12480000
    wait_time_ms: 420.375
  iterations_since_restore: 416
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 18511.347101211548
  time_this_iter_s: 42.0644428730011
  time_total_s: 18511.347101211548
  timestamp: 1594170703
  timesteps_since_restore: 12480000
  timesteps_this_iter: 30000
  timesteps_total: 12480000
  training_iteration: 416
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 18511 s, 416 iter, 12480000 ts, 1.21e+03 rew

agent-1: 48.0
agent-2: 55.0
agent-3: 71.0
agent-4: 45.0
agent-5: 26.0
agent-6: 69.0
agent-7: 41.0
agent-8: 43.0
agent-9: 51.0
agent-10: 54.0
agent-11: 47.0
agent-12: 51.0
agent-13: 58.0
agent-14: 79.0
agent-15: 43.0
agent-16: 38.0
agent-17: 59.0
agent-18: 46.0
agent-19: 45.0
agent-20: 51.0
agent-21: 46.0
agent-22: 79.0
agent-23: 44.0
agent-24: 32.0
agent-25: 44.0
agent-26: 71.0
agent-27: 55.0
agent-28: 27.0
agent-29: 24.0
agent-30: 57.0
Sum Reward: 1499.0
Avg Reward: 49.96666666666667
Min Reward: 24.0
Max Reward: 79.0
Gini Coefficient: 0.15363575717144765
20:20 Ratio: 2.276595744680851
Max-min Ratio: 3.2916666666666665
agent-1: 75.0
agent-2: 46.0
agent-3: 81.0
agent-4: 37.0
agent-5: 60.0
agent-6: 50.0
agent-7: 62.0
agent-8: 37.0
agent-9: 68.0
agent-10: 18.0
agent-11: 64.0
agent-12: 45.0
agent-13: 52.0
agent-14: 57.0
agent-15: 41.0
agent-16: 58.0
agent-17: 41.0
agent-18: 49.0
agent-19: 43.0
agent-20: 39.0
agent-21: 45.0
agent-22: 23.0
agent-23: 49.0
agent-24: 27.0
agent-25: 42.0
agent-26: 85.0
agent-27: 52.0
agent-28: 80.0
agent-29: 75.0
agent-30: 55.0
Sum Reward: 1556.0
Avg Reward: 51.86666666666667
Min Reward: 18.0
Max Reward: 85.0
Gini Coefficient: 0.17952013710368467
20:20 Ratio: 2.56353591160221
Max-min Ratio: 4.722222222222222
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_21-12-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1209.54
  episode_reward_min: 901.0
  episodes_this_iter: 2
  episodes_total: 417
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.932
    dispatch_time_ms: 6.168
    learner:
      cur_lr: 0.0005288320244289935
      grad_gnorm: 40.0
      policy_entropy: 243.5341339111328
      policy_loss: -761.0764770507812
      var_gnorm: 23.67660903930664
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1548.77294921875
    num_steps_sampled: 12510000
    num_steps_trained: 12510000
    wait_time_ms: 434.862
  iterations_since_restore: 417
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 18555.298587799072
  time_this_iter_s: 43.951486587524414
  time_total_s: 18555.298587799072
  timestamp: 1594170747
  timesteps_since_restore: 12510000
  timesteps_this_iter: 30000
  timesteps_total: 12510000
  training_iteration: 417
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 18555 s, 417 iter, 12510000 ts, 1.21e+03 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_21-13-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1209.54
  episode_reward_min: 901.0
  episodes_this_iter: 0
  episodes_total: 417
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.728
    dispatch_time_ms: 8.483
    learner:
      cur_lr: 0.0005268339882604778
      grad_gnorm: 39.999996185302734
      policy_entropy: 221.8339385986328
      policy_loss: -17.779022216796875
      var_gnorm: 23.67906951904297
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 19.237592697143555
    num_steps_sampled: 12540000
    num_steps_trained: 12540000
    wait_time_ms: 440.566
  iterations_since_restore: 418
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 18599.45149755478
  time_this_iter_s: 44.15290975570679
  time_total_s: 18599.45149755478
  timestamp: 1594170791
  timesteps_since_restore: 12540000
  timesteps_this_iter: 30000
  timesteps_total: 12540000
  training_iteration: 418
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 18599 s, 418 iter, 12540000 ts, 1.21e+03 rew

agent-1: 19.0
agent-2: 35.0
agent-3: 39.0
agent-4: 23.0
agent-5: 31.0
agent-6: 26.0
agent-7: 45.0
agent-8: 39.0
agent-9: 36.0
agent-10: 25.0
agent-11: 27.0
agent-12: 40.0
agent-13: 36.0
agent-14: 27.0
agent-15: 40.0
agent-16: 40.0
agent-17: 28.0
agent-18: 24.0
agent-19: 22.0
agent-20: 27.0
agent-21: 26.0
agent-22: 30.0
agent-23: 34.0
agent-24: 60.0
agent-25: 40.0
agent-26: 23.0
agent-27: 31.0
agent-28: 50.0
agent-29: 24.0
agent-30: 37.0
Sum Reward: 984.0
Avg Reward: 32.8
Min Reward: 19.0
Max Reward: 60.0
Gini Coefficient: 0.15060975609756097
20:20 Ratio: 2.037037037037037
Max-min Ratio: 3.1578947368421053
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_21-13-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1205.85
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 418
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.489
    dispatch_time_ms: 5.207
    learner:
      cur_lr: 0.000524836010299623
      grad_gnorm: 40.0
      policy_entropy: 244.76882934570312
      policy_loss: 212.605712890625
      var_gnorm: 23.801225662231445
      vf_explained_var: -0.008989930152893066
      vf_loss: 349.10467529296875
    num_steps_sampled: 12570000
    num_steps_trained: 12570000
    wait_time_ms: 439.06
  iterations_since_restore: 419
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 18644.71834754944
  time_this_iter_s: 45.266849994659424
  time_total_s: 18644.71834754944
  timestamp: 1594170836
  timesteps_since_restore: 12570000
  timesteps_this_iter: 30000
  timesteps_total: 12570000
  training_iteration: 419
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 18644 s, 419 iter, 12570000 ts, 1.21e+03 rew

agent-1: 19.0
agent-2: 44.0
agent-3: 53.0
agent-4: 44.0
agent-5: 31.0
agent-6: 43.0
agent-7: 22.0
agent-8: 33.0
agent-9: 40.0
agent-10: 57.0
agent-11: 44.0
agent-12: 58.0
agent-13: 29.0
agent-14: 51.0
agent-15: 44.0
agent-16: 55.0
agent-17: 43.0
agent-18: 20.0
agent-19: 16.0
agent-20: 44.0
agent-21: 37.0
agent-22: 35.0
agent-23: 41.0
agent-24: 40.0
agent-25: 30.0
agent-26: 34.0
agent-27: 33.0
agent-28: 40.0
agent-29: 49.0
agent-30: 45.0
Sum Reward: 1174.0
Avg Reward: 39.13333333333333
Min Reward: 16.0
Max Reward: 58.0
Gini Coefficient: 0.15519591141396932
20:20 Ratio: 2.375
Max-min Ratio: 3.625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_21-14-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1204.24
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 419
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.557
    dispatch_time_ms: 5.604
    learner:
      cur_lr: 0.0005228379741311073
      grad_gnorm: 40.000003814697266
      policy_entropy: 214.4623260498047
      policy_loss: 12.233742713928223
      var_gnorm: 23.80809211730957
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 49.04054641723633
    num_steps_sampled: 12600000
    num_steps_trained: 12600000
    wait_time_ms: 430.717
  iterations_since_restore: 420
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 18687.79396033287
  time_this_iter_s: 43.07561278343201
  time_total_s: 18687.79396033287
  timestamp: 1594170879
  timesteps_since_restore: 12600000
  timesteps_this_iter: 30000
  timesteps_total: 12600000
  training_iteration: 420
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 18687 s, 420 iter, 12600000 ts, 1.2e+03 rew

agent-1: 34.0
agent-2: 32.0
agent-3: 34.0
agent-4: 56.0
agent-5: 32.0
agent-6: 37.0
agent-7: 22.0
agent-8: 31.0
agent-9: 51.0
agent-10: 35.0
agent-11: 42.0
agent-12: 22.0
agent-13: 43.0
agent-14: 56.0
agent-15: 44.0
agent-16: 58.0
agent-17: 41.0
agent-18: 27.0
agent-19: 34.0
agent-20: 26.0
agent-21: 73.0
agent-22: 43.0
agent-23: 34.0
agent-24: 67.0
agent-25: 46.0
agent-26: 36.0
agent-27: 43.0
agent-28: 34.0
agent-29: 46.0
agent-30: 38.0
Sum Reward: 1217.0
Avg Reward: 40.56666666666667
Min Reward: 22.0
Max Reward: 73.0
Gini Coefficient: 0.16129827444535744
20:20 Ratio: 2.25625
Max-min Ratio: 3.3181818181818183
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_21-15-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1202.83
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 420
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.07
    dispatch_time_ms: 5.649
    learner:
      cur_lr: 0.0005208399961702526
      grad_gnorm: 40.0
      policy_entropy: 199.50125122070312
      policy_loss: 120.85028839111328
      var_gnorm: 23.802715301513672
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 327.6681213378906
    num_steps_sampled: 12630000
    num_steps_trained: 12630000
    wait_time_ms: 402.475
  iterations_since_restore: 421
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 18732.801997423172
  time_this_iter_s: 45.008037090301514
  time_total_s: 18732.801997423172
  timestamp: 1594170924
  timesteps_since_restore: 12630000
  timesteps_this_iter: 30000
  timesteps_total: 12630000
  training_iteration: 421
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 18732 s, 421 iter, 12630000 ts, 1.2e+03 rew

agent-1: 42.0
agent-2: 47.0
agent-3: 26.0
agent-4: 12.0
agent-5: 38.0
agent-6: 41.0
agent-7: 44.0
agent-8: 53.0
agent-9: 47.0
agent-10: 37.0
agent-11: 29.0
agent-12: 42.0
agent-13: 16.0
agent-14: 40.0
agent-15: 33.0
agent-16: 67.0
agent-17: 44.0
agent-18: 36.0
agent-19: 52.0
agent-20: 44.0
agent-21: 17.0
agent-22: 35.0
agent-23: 39.0
agent-24: 35.0
agent-25: 41.0
agent-26: 26.0
agent-27: 38.0
agent-28: 28.0
agent-29: 35.0
agent-30: 24.0
Sum Reward: 1108.0
Avg Reward: 36.93333333333333
Min Reward: 12.0
Max Reward: 67.0
Gini Coefficient: 0.16829121540312877
20:20 Ratio: 2.56198347107438
Max-min Ratio: 5.583333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_21-16-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1198.11
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 421
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.844
    dispatch_time_ms: 40.966
    learner:
      cur_lr: 0.0005188420182093978
      grad_gnorm: 40.0
      policy_entropy: 203.83172607421875
      policy_loss: -14.532232284545898
      var_gnorm: 23.810720443725586
      vf_explained_var: 0.0
      vf_loss: 19.497343063354492
    num_steps_sampled: 12660000
    num_steps_trained: 12660000
    wait_time_ms: 413.228
  iterations_since_restore: 422
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 18777.883081912994
  time_this_iter_s: 45.08108448982239
  time_total_s: 18777.883081912994
  timestamp: 1594170969
  timesteps_since_restore: 12660000
  timesteps_this_iter: 30000
  timesteps_total: 12660000
  training_iteration: 422
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 18777 s, 422 iter, 12660000 ts, 1.2e+03 rew

agent-1: 30.0
agent-2: 37.0
agent-3: 47.0
agent-4: 21.0
agent-5: 31.0
agent-6: 28.0
agent-7: 59.0
agent-8: 46.0
agent-9: 39.0
agent-10: 37.0
agent-11: 33.0
agent-12: 63.0
agent-13: 44.0
agent-14: 45.0
agent-15: 25.0
agent-16: 36.0
agent-17: 64.0
agent-18: 34.0
agent-19: 61.0
agent-20: 28.0
agent-21: 29.0
agent-22: 25.0
agent-23: 71.0
agent-24: 43.0
agent-25: 55.0
agent-26: 64.0
agent-27: 23.0
agent-28: 46.0
agent-29: 50.0
agent-30: 75.0
Sum Reward: 1289.0
Avg Reward: 42.96666666666667
Min Reward: 21.0
Max Reward: 75.0
Gini Coefficient: 0.19718127747607964
20:20 Ratio: 2.6533333333333333
Max-min Ratio: 3.5714285714285716
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_21-16-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1198.27
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 422
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.365
    dispatch_time_ms: 41.038
    learner:
      cur_lr: 0.0005168439820408821
      grad_gnorm: 40.0
      policy_entropy: 202.65650939941406
      policy_loss: 87.47936248779297
      var_gnorm: 23.807472229003906
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 237.5695343017578
    num_steps_sampled: 12690000
    num_steps_trained: 12690000
    wait_time_ms: 379.082
  iterations_since_restore: 423
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 18824.159411668777
  time_this_iter_s: 46.27632975578308
  time_total_s: 18824.159411668777
  timestamp: 1594171016
  timesteps_since_restore: 12690000
  timesteps_this_iter: 30000
  timesteps_total: 12690000
  training_iteration: 423
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 18824 s, 423 iter, 12690000 ts, 1.2e+03 rew

agent-1: 24.0
agent-2: 48.0
agent-3: 41.0
agent-4: 41.0
agent-5: 45.0
agent-6: 54.0
agent-7: 27.0
agent-8: 46.0
agent-9: 42.0
agent-10: 41.0
agent-11: 22.0
agent-12: 31.0
agent-13: 28.0
agent-14: 32.0
agent-15: 29.0
agent-16: 35.0
agent-17: 27.0
agent-18: 39.0
agent-19: 60.0
agent-20: 46.0
agent-21: 37.0
agent-22: 25.0
agent-23: 25.0
agent-24: 63.0
agent-25: 48.0
agent-26: 55.0
agent-27: 36.0
agent-28: 32.0
agent-29: 64.0
agent-30: 36.0
Sum Reward: 1179.0
Avg Reward: 39.3
Min Reward: 22.0
Max Reward: 64.0
Gini Coefficient: 0.1670624823296579
20:20 Ratio: 2.2933333333333334
Max-min Ratio: 2.909090909090909
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_21-17-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1198.21
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 423
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.213
    dispatch_time_ms: 6.451
    learner:
      cur_lr: 0.0005148460040800273
      grad_gnorm: 40.0
      policy_entropy: 172.3629150390625
      policy_loss: -4.924579620361328
      var_gnorm: 23.812742233276367
      vf_explained_var: 0.0
      vf_loss: 37.608978271484375
    num_steps_sampled: 12720000
    num_steps_trained: 12720000
    wait_time_ms: 449.531
  iterations_since_restore: 424
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 18867.922990322113
  time_this_iter_s: 43.76357865333557
  time_total_s: 18867.922990322113
  timestamp: 1594171060
  timesteps_since_restore: 12720000
  timesteps_this_iter: 30000
  timesteps_total: 12720000
  training_iteration: 424
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 18867 s, 424 iter, 12720000 ts, 1.2e+03 rew

agent-1: 58.0
agent-2: 43.0
agent-3: 44.0
agent-4: 41.0
agent-5: 16.0
agent-6: 47.0
agent-7: 24.0
agent-8: 19.0
agent-9: 46.0
agent-10: 54.0
agent-11: 41.0
agent-12: 46.0
agent-13: 44.0
agent-14: 49.0
agent-15: 27.0
agent-16: 28.0
agent-17: 54.0
agent-18: 54.0
agent-19: 44.0
agent-20: 40.0
agent-21: 22.0
agent-22: 25.0
agent-23: 74.0
agent-24: 43.0
agent-25: 52.0
agent-26: 59.0
agent-27: 37.0
agent-28: 86.0
agent-29: 72.0
agent-30: 59.0
Sum Reward: 1348.0
Avg Reward: 44.93333333333333
Min Reward: 16.0
Max Reward: 86.0
Gini Coefficient: 0.197675568743818
20:20 Ratio: 3.0676691729323307
Max-min Ratio: 5.375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_21-18-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1199.15
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 424
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.771
    dispatch_time_ms: 6.807
    learner:
      cur_lr: 0.0005128480261191726
      grad_gnorm: 40.0
      policy_entropy: 193.62425231933594
      policy_loss: 103.2531509399414
      var_gnorm: 23.807880401611328
      vf_explained_var: 0.0
      vf_loss: 161.08413696289062
    num_steps_sampled: 12750000
    num_steps_trained: 12750000
    wait_time_ms: 419.869
  iterations_since_restore: 425
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 18912.37078022957
  time_this_iter_s: 44.447789907455444
  time_total_s: 18912.37078022957
  timestamp: 1594171104
  timesteps_since_restore: 12750000
  timesteps_this_iter: 30000
  timesteps_total: 12750000
  training_iteration: 425
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 18912 s, 425 iter, 12750000 ts, 1.2e+03 rew

agent-1: 37.0
agent-2: 21.0
agent-3: 50.0
agent-4: 47.0
agent-5: 37.0
agent-6: 61.0
agent-7: 21.0
agent-8: 41.0
agent-9: 45.0
agent-10: 22.0
agent-11: 34.0
agent-12: 41.0
agent-13: 16.0
agent-14: 29.0
agent-15: 29.0
agent-16: 28.0
agent-17: 38.0
agent-18: 64.0
agent-19: 39.0
agent-20: 45.0
agent-21: 48.0
agent-22: 58.0
agent-23: 25.0
agent-24: 43.0
agent-25: 41.0
agent-26: 38.0
agent-27: 31.0
agent-28: 32.0
agent-29: 62.0
agent-30: 29.0
Sum Reward: 1152.0
Avg Reward: 38.4
Min Reward: 16.0
Max Reward: 64.0
Gini Coefficient: 0.18153935185185185
20:20 Ratio: 2.5789473684210527
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_21-19-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1200.52
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 425
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.851
    dispatch_time_ms: 16.474
    learner:
      cur_lr: 0.0005108499899506569
      grad_gnorm: 40.00001525878906
      policy_entropy: 192.4182891845703
      policy_loss: 20.295005798339844
      var_gnorm: 23.813018798828125
      vf_explained_var: -4.76837158203125e-07
      vf_loss: 51.76515197753906
    num_steps_sampled: 12780000
    num_steps_trained: 12780000
    wait_time_ms: 407.3
  iterations_since_restore: 426
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 18955.604678869247
  time_this_iter_s: 43.233898639678955
  time_total_s: 18955.604678869247
  timestamp: 1594171147
  timesteps_since_restore: 12780000
  timesteps_this_iter: 30000
  timesteps_total: 12780000
  training_iteration: 426
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 18955 s, 426 iter, 12780000 ts, 1.2e+03 rew

W0707 21:19:12.314317 10987 client_connection.cc:255] [worker]ProcessMessage with type 8 took 280 ms.
agent-1: 23.0
agent-2: 27.0
agent-3: 46.0
agent-4: 41.0
agent-5: 24.0
agent-6: 50.0
agent-7: 52.0
agent-8: 43.0
agent-9: 56.0
agent-10: 59.0
agent-11: 37.0
agent-12: 33.0
agent-13: 33.0
agent-14: 46.0
agent-15: 16.0
agent-16: 11.0
agent-17: 28.0
agent-18: 41.0
agent-19: 41.0
agent-20: 57.0
agent-21: 18.0
agent-22: 44.0
agent-23: 26.0
agent-24: 57.0
agent-25: 36.0
agent-26: 50.0
agent-27: 43.0
agent-28: 29.0
agent-29: 25.0
agent-30: 20.0
Sum Reward: 1112.0
Avg Reward: 37.06666666666667
Min Reward: 11.0
Max Reward: 59.0
Gini Coefficient: 0.2040767386091127
20:20 Ratio: 2.955357142857143
Max-min Ratio: 5.363636363636363
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_21-19-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1201.16
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 426
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.646
    dispatch_time_ms: 5.395
    learner:
      cur_lr: 0.0005088520119898021
      grad_gnorm: 40.0
      policy_entropy: 211.63446044921875
      policy_loss: 45.80117416381836
      var_gnorm: 23.810340881347656
      vf_explained_var: 0.0
      vf_loss: 99.2516860961914
    num_steps_sampled: 12810000
    num_steps_trained: 12810000
    wait_time_ms: 389.749
  iterations_since_restore: 427
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 19000.36006116867
  time_this_iter_s: 44.75538229942322
  time_total_s: 19000.36006116867
  timestamp: 1594171192
  timesteps_since_restore: 12810000
  timesteps_this_iter: 30000
  timesteps_total: 12810000
  training_iteration: 427
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 19000 s, 427 iter, 12810000 ts, 1.2e+03 rew

agent-1: 38.0
agent-2: 41.0
agent-3: 44.0
agent-4: 19.0
agent-5: 46.0
agent-6: 47.0
agent-7: 50.0
agent-8: 39.0
agent-9: 58.0
agent-10: 69.0
agent-11: 46.0
agent-12: 82.0
agent-13: 41.0
agent-14: 23.0
agent-15: 39.0
agent-16: 35.0
agent-17: 72.0
agent-18: 28.0
agent-19: 56.0
agent-20: 44.0
agent-21: 54.0
agent-22: 24.0
agent-23: 44.0
agent-24: 50.0
agent-25: 44.0
agent-26: 51.0
agent-27: 28.0
agent-28: 58.0
agent-29: 33.0
agent-30: 37.0
Sum Reward: 1340.0
Avg Reward: 44.666666666666664
Min Reward: 19.0
Max Reward: 82.0
Gini Coefficient: 0.17348258706467662
20:20 Ratio: 2.5483870967741935
Max-min Ratio: 4.315789473684211
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_21-20-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1199.99
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 427
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.681
    dispatch_time_ms: 5.146
    learner:
      cur_lr: 0.0005068539758212864
      grad_gnorm: 16.597698211669922
      policy_entropy: 198.13780212402344
      policy_loss: -5.651092529296875
      var_gnorm: 23.823503494262695
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 33.92802047729492
    num_steps_sampled: 12840000
    num_steps_trained: 12840000
    wait_time_ms: 439.029
  iterations_since_restore: 428
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 19043.95238351822
  time_this_iter_s: 43.59232234954834
  time_total_s: 19043.95238351822
  timestamp: 1594171236
  timesteps_since_restore: 12840000
  timesteps_this_iter: 30000
  timesteps_total: 12840000
  training_iteration: 428
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 19043 s, 428 iter, 12840000 ts, 1.2e+03 rew

agent-1: 59.0
agent-2: 32.0
agent-3: 39.0
agent-4: 26.0
agent-5: 48.0
agent-6: 22.0
agent-7: 43.0
agent-8: 35.0
agent-9: 16.0
agent-10: 41.0
agent-11: 46.0
agent-12: 47.0
agent-13: 52.0
agent-14: 33.0
agent-15: 37.0
agent-16: 46.0
agent-17: 51.0
agent-18: 74.0
agent-19: 43.0
agent-20: 35.0
agent-21: 52.0
agent-22: 31.0
agent-23: 30.0
agent-24: 41.0
agent-25: 33.0
agent-26: 50.0
agent-27: 37.0
agent-28: 37.0
agent-29: 39.0
agent-30: 40.0
Sum Reward: 1215.0
Avg Reward: 40.5
Min Reward: 16.0
Max Reward: 74.0
Gini Coefficient: 0.14954732510288066
20:20 Ratio: 2.1528662420382165
Max-min Ratio: 4.625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_21-21-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1196.33
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 428
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.512
    dispatch_time_ms: 22.952
    learner:
      cur_lr: 0.0005048559978604317
      grad_gnorm: 40.000003814697266
      policy_entropy: 173.98171997070312
      policy_loss: 77.70718383789062
      var_gnorm: 23.819475173950195
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 178.75283813476562
    num_steps_sampled: 12870000
    num_steps_trained: 12870000
    wait_time_ms: 432.663
  iterations_since_restore: 429
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 19089.202951669693
  time_this_iter_s: 45.250568151474
  time_total_s: 19089.202951669693
  timestamp: 1594171281
  timesteps_since_restore: 12870000
  timesteps_this_iter: 30000
  timesteps_total: 12870000
  training_iteration: 429
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 19089 s, 429 iter, 12870000 ts, 1.2e+03 rew

agent-1: 22.0
agent-2: 62.0
agent-3: 47.0
agent-4: 21.0
agent-5: 28.0
agent-6: 37.0
agent-7: 38.0
agent-8: 54.0
agent-9: 36.0
agent-10: 32.0
agent-11: 34.0
agent-12: 13.0
agent-13: 47.0
agent-14: 54.0
agent-15: 32.0
agent-16: 57.0
agent-17: 31.0
agent-18: 22.0
agent-19: 4.0
agent-20: 35.0
agent-21: 73.0
agent-22: 50.0
agent-23: 46.0
agent-24: 33.0
agent-25: 49.0
agent-26: 50.0
agent-27: 38.0
agent-28: 29.0
agent-29: 17.0
agent-30: 17.0
Sum Reward: 1108.0
Avg Reward: 36.93333333333333
Min Reward: 4.0
Max Reward: 73.0
Gini Coefficient: 0.23477737665463297
20:20 Ratio: 3.723404255319149
Max-min Ratio: 18.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_21-22-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1194.57
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 429
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 13.014
    dispatch_time_ms: 6.536
    learner:
      cur_lr: 0.0005028580198995769
      grad_gnorm: 39.999996185302734
      policy_entropy: 189.70472717285156
      policy_loss: -2.5017640590667725
      var_gnorm: 23.823740005493164
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 27.00140380859375
    num_steps_sampled: 12900000
    num_steps_trained: 12900000
    wait_time_ms: 407.751
  iterations_since_restore: 430
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 19132.773568868637
  time_this_iter_s: 43.57061719894409
  time_total_s: 19132.773568868637
  timestamp: 1594171325
  timesteps_since_restore: 12900000
  timesteps_this_iter: 30000
  timesteps_total: 12900000
  training_iteration: 430
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 19132 s, 430 iter, 12900000 ts, 1.19e+03 rew

agent-1: 44.0
agent-2: 52.0
agent-3: 20.0
agent-4: 42.0
agent-5: 18.0
agent-6: 47.0
agent-7: 38.0
agent-8: 31.0
agent-9: 36.0
agent-10: 29.0
agent-11: 52.0
agent-12: 41.0
agent-13: 34.0
agent-14: 42.0
agent-15: 37.0
agent-16: 20.0
agent-17: 48.0
agent-18: 34.0
agent-19: 23.0
agent-20: 27.0
agent-21: 40.0
agent-22: 17.0
agent-23: 57.0
agent-24: 55.0
agent-25: 33.0
agent-26: 42.0
agent-27: 33.0
agent-28: 24.0
agent-29: 36.0
agent-30: 47.0
Sum Reward: 1099.0
Avg Reward: 36.63333333333333
Min Reward: 17.0
Max Reward: 57.0
Gini Coefficient: 0.1707916287534122
20:20 Ratio: 2.5491803278688523
Max-min Ratio: 3.3529411764705883
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_21-22-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1194.5
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 430
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.695
    dispatch_time_ms: 6.603
    learner:
      cur_lr: 0.0005008599837310612
      grad_gnorm: 40.000003814697266
      policy_entropy: 225.18612670898438
      policy_loss: 109.8174819946289
      var_gnorm: 23.82034683227539
      vf_explained_var: 0.0
      vf_loss: 179.1048126220703
    num_steps_sampled: 12930000
    num_steps_trained: 12930000
    wait_time_ms: 434.483
  iterations_since_restore: 431
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 19177.59031367302
  time_this_iter_s: 44.816744804382324
  time_total_s: 19177.59031367302
  timestamp: 1594171369
  timesteps_since_restore: 12930000
  timesteps_this_iter: 30000
  timesteps_total: 12930000
  training_iteration: 431
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 19177 s, 431 iter, 12930000 ts, 1.19e+03 rew

agent-1: 21.0
agent-2: 42.0
agent-3: 58.0
agent-4: 56.0
agent-5: 56.0
agent-6: 40.0
agent-7: 34.0
agent-8: 13.0
agent-9: 65.0
agent-10: 38.0
agent-11: 32.0
agent-12: 92.0
agent-13: 57.0
agent-14: 61.0
agent-15: 48.0
agent-16: 36.0
agent-17: 80.0
agent-18: 48.0
agent-19: 54.0
agent-20: 31.0
agent-21: 44.0
agent-22: 38.0
agent-23: 33.0
agent-24: 51.0
agent-25: 38.0
agent-26: 73.0
agent-27: 49.0
agent-28: 59.0
agent-29: 63.0
agent-30: 41.0
Sum Reward: 1451.0
Avg Reward: 48.36666666666667
Min Reward: 13.0
Max Reward: 92.0
Gini Coefficient: 0.18991500114863313
20:20 Ratio: 2.6463414634146343
Max-min Ratio: 7.076923076923077
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_21-23-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1195.66
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 431
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.42
    dispatch_time_ms: 6.516
    learner:
      cur_lr: 0.0004988620057702065
      grad_gnorm: 40.0
      policy_entropy: 207.59164428710938
      policy_loss: 35.28840637207031
      var_gnorm: 23.825782775878906
      vf_explained_var: 0.0
      vf_loss: 117.78240203857422
    num_steps_sampled: 12960000
    num_steps_trained: 12960000
    wait_time_ms: 435.274
  iterations_since_restore: 432
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 19220.628129720688
  time_this_iter_s: 43.03781604766846
  time_total_s: 19220.628129720688
  timestamp: 1594171413
  timesteps_since_restore: 12960000
  timesteps_this_iter: 30000
  timesteps_total: 12960000
  training_iteration: 432
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 19220 s, 432 iter, 12960000 ts, 1.2e+03 rew

agent-1: 49.0
agent-2: 31.0
agent-3: 22.0
agent-4: 43.0
agent-5: 42.0
agent-6: 28.0
agent-7: 47.0
agent-8: 44.0
agent-9: 22.0
agent-10: 20.0
agent-11: 30.0
agent-12: 48.0
agent-13: 36.0
agent-14: 38.0
agent-15: 31.0
agent-16: 43.0
agent-17: 16.0
agent-18: 51.0
agent-19: 36.0
agent-20: 42.0
agent-21: 40.0
agent-22: 31.0
agent-23: 58.0
agent-24: 77.0
agent-25: 50.0
agent-26: 34.0
agent-27: 34.0
agent-28: 41.0
agent-29: 31.0
agent-30: 30.0
Sum Reward: 1145.0
Avg Reward: 38.166666666666664
Min Reward: 16.0
Max Reward: 77.0
Gini Coefficient: 0.17243085880640466
20:20 Ratio: 2.4130434782608696
Max-min Ratio: 4.8125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_21-24-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1195.56
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 432
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.863
    dispatch_time_ms: 6.184
    learner:
      cur_lr: 0.0004968640278093517
      grad_gnorm: 40.000003814697266
      policy_entropy: 148.75921630859375
      policy_loss: 32.94456100463867
      var_gnorm: 23.82356834411621
      vf_explained_var: 0.0
      vf_loss: 85.26948547363281
    num_steps_sampled: 12990000
    num_steps_trained: 12990000
    wait_time_ms: 418.4
  iterations_since_restore: 433
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 19265.463904619217
  time_this_iter_s: 44.83577489852905
  time_total_s: 19265.463904619217
  timestamp: 1594171457
  timesteps_since_restore: 12990000
  timesteps_this_iter: 30000
  timesteps_total: 12990000
  training_iteration: 433
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 19265 s, 433 iter, 12990000 ts, 1.2e+03 rew

agent-1: 44.0
agent-2: 43.0
agent-3: 23.0
agent-4: 67.0
agent-5: 81.0
agent-6: 37.0
agent-7: 61.0
agent-8: 61.0
agent-9: 43.0
agent-10: 39.0
agent-11: 55.0
agent-12: 30.0
agent-13: 54.0
agent-14: 23.0
agent-15: 54.0
agent-16: 69.0
agent-17: 61.0
agent-18: 56.0
agent-19: 24.0
agent-20: 39.0
agent-21: 54.0
agent-22: 45.0
agent-23: 54.0
agent-24: 23.0
agent-25: 53.0
agent-26: 22.0
agent-27: 70.0
agent-28: 26.0
agent-29: 44.0
agent-30: 34.0
Sum Reward: 1389.0
Avg Reward: 46.3
Min Reward: 22.0
Max Reward: 81.0
Gini Coefficient: 0.19522438204943604
20:20 Ratio: 2.900709219858156
Max-min Ratio: 3.6818181818181817
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_21-25-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1197.12
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 433
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.574
    dispatch_time_ms: 5.586
    learner:
      cur_lr: 0.000494865991640836
      grad_gnorm: 40.0
      policy_entropy: 137.52423095703125
      policy_loss: -11.897820472717285
      var_gnorm: 23.828060150146484
      vf_explained_var: 0.0
      vf_loss: 34.072113037109375
    num_steps_sampled: 13020000
    num_steps_trained: 13020000
    wait_time_ms: 494.613
  iterations_since_restore: 434
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 19308.378390312195
  time_this_iter_s: 42.914485692977905
  time_total_s: 19308.378390312195
  timestamp: 1594171500
  timesteps_since_restore: 13020000
  timesteps_this_iter: 30000
  timesteps_total: 13020000
  training_iteration: 434
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 19308 s, 434 iter, 13020000 ts, 1.2e+03 rew

agent-1: 68.0
agent-2: 59.0
agent-3: 67.0
agent-4: 80.0
agent-5: 76.0
agent-6: 45.0
agent-7: 38.0
agent-8: 45.0
agent-9: 39.0
agent-10: 53.0
agent-11: 52.0
agent-12: 54.0
agent-13: 21.0
agent-14: 37.0
agent-15: 29.0
agent-16: 44.0
agent-17: 72.0
agent-18: 41.0
agent-19: 33.0
agent-20: 37.0
agent-21: 50.0
agent-22: 46.0
agent-23: 57.0
agent-24: 45.0
agent-25: 39.0
agent-26: 73.0
agent-27: 56.0
agent-28: 36.0
agent-29: 69.0
agent-30: 36.0
Sum Reward: 1497.0
Avg Reward: 49.9
Min Reward: 21.0
Max Reward: 80.0
Gini Coefficient: 0.16849254063682922
20:20 Ratio: 2.28125
Max-min Ratio: 3.8095238095238093
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_21-25-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1666.0
  episode_reward_mean: 1197.15
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 434
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.657
    dispatch_time_ms: 5.127
    learner:
      cur_lr: 0.0004928680136799812
      grad_gnorm: 40.0
      policy_entropy: 152.725341796875
      policy_loss: 37.722652435302734
      var_gnorm: 23.82637596130371
      vf_explained_var: 0.0
      vf_loss: 194.04808044433594
    num_steps_sampled: 13050000
    num_steps_trained: 13050000
    wait_time_ms: 425.448
  iterations_since_restore: 435
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 19352.70647406578
  time_this_iter_s: 44.328083753585815
  time_total_s: 19352.70647406578
  timestamp: 1594171545
  timesteps_since_restore: 13050000
  timesteps_this_iter: 30000
  timesteps_total: 13050000
  training_iteration: 435
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 19352 s, 435 iter, 13050000 ts, 1.2e+03 rew

agent-1: 42.0
agent-2: 43.0
agent-3: 55.0
agent-4: 24.0
agent-5: 41.0
agent-6: 52.0
agent-7: 36.0
agent-8: 24.0
agent-9: 47.0
agent-10: 36.0
agent-11: 48.0
agent-12: 48.0
agent-13: 69.0
agent-14: 56.0
agent-15: 57.0
agent-16: 64.0
agent-17: 63.0
agent-18: 42.0
agent-19: 52.0
agent-20: 25.0
agent-21: 62.0
agent-22: 43.0
agent-23: 58.0
agent-24: 41.0
agent-25: 38.0
agent-26: 44.0
agent-27: 57.0
agent-28: 47.0
agent-29: 56.0
agent-30: 46.0
Sum Reward: 1416.0
Avg Reward: 47.2
Min Reward: 24.0
Max Reward: 69.0
Gini Coefficient: 0.13531073446327685
20:20 Ratio: 2.0382513661202184
Max-min Ratio: 2.875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_21-26-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1591.0
  episode_reward_mean: 1194.65
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 435
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.48
    dispatch_time_ms: 5.488
    learner:
      cur_lr: 0.0004908699775114655
      grad_gnorm: 40.0
      policy_entropy: 134.98480224609375
      policy_loss: -8.938611030578613
      var_gnorm: 23.828855514526367
      vf_explained_var: 0.0
      vf_loss: 24.21961212158203
    num_steps_sampled: 13080000
    num_steps_trained: 13080000
    wait_time_ms: 457.743
  iterations_since_restore: 436
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 19396.302708148956
  time_this_iter_s: 43.59623408317566
  time_total_s: 19396.302708148956
  timestamp: 1594171588
  timesteps_since_restore: 13080000
  timesteps_this_iter: 30000
  timesteps_total: 13080000
  training_iteration: 436
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 19396 s, 436 iter, 13080000 ts, 1.19e+03 rew

W0707 21:26:40.621872 10987 client_connection.cc:255] [worker]ProcessMessage with type 19 took 211 ms.
agent-1: 68.0
agent-2: 43.0
agent-3: 51.0
agent-4: 37.0
agent-5: 52.0
agent-6: 37.0
agent-7: 42.0
agent-8: 45.0
agent-9: 28.0
agent-10: 56.0
agent-11: 31.0
agent-12: 23.0
agent-13: 17.0
agent-14: 39.0
agent-15: 48.0
agent-16: 16.0
agent-17: 35.0
agent-18: 67.0
agent-19: 31.0
agent-20: 46.0
agent-21: 33.0
agent-22: 43.0
agent-23: 20.0
agent-24: 45.0
agent-25: 52.0
agent-26: 15.0
agent-27: 65.0
agent-28: 12.0
agent-29: 51.0
agent-30: 47.0
Sum Reward: 1195.0
Avg Reward: 39.833333333333336
Min Reward: 12.0
Max Reward: 68.0
Gini Coefficient: 0.21330543933054394
20:20 Ratio: 3.495145631067961
Max-min Ratio: 5.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_21-27-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1190.69
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 436
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 3.44
    dispatch_time_ms: 6.032
    learner:
      cur_lr: 0.0004888719995506108
      grad_gnorm: 39.999996185302734
      policy_entropy: 129.3311309814453
      policy_loss: -4.499838829040527
      var_gnorm: 23.825498580932617
      vf_explained_var: 0.0
      vf_loss: 25.344139099121094
    num_steps_sampled: 13110000
    num_steps_trained: 13110000
    wait_time_ms: 436.45
  iterations_since_restore: 437
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 19440.407318115234
  time_this_iter_s: 44.104609966278076
  time_total_s: 19440.407318115234
  timestamp: 1594171632
  timesteps_since_restore: 13110000
  timesteps_this_iter: 30000
  timesteps_total: 13110000
  training_iteration: 437
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 19440 s, 437 iter, 13110000 ts, 1.19e+03 rew

agent-1: 57.0
agent-2: 54.0
agent-3: 60.0
agent-4: 62.0
agent-5: 47.0
agent-6: 60.0
agent-7: 34.0
agent-8: 60.0
agent-9: 54.0
agent-10: 41.0
agent-11: 42.0
agent-12: 45.0
agent-13: 42.0
agent-14: 43.0
agent-15: 43.0
agent-16: 66.0
agent-17: 36.0
agent-18: 44.0
agent-19: 46.0
agent-20: 16.0
agent-21: 22.0
agent-22: 45.0
agent-23: 34.0
agent-24: 56.0
agent-25: 51.0
agent-26: 35.0
agent-27: 41.0
agent-28: 47.0
agent-29: 60.0
agent-30: 71.0
Sum Reward: 1414.0
Avg Reward: 47.13333333333333
Min Reward: 16.0
Max Reward: 71.0
Gini Coefficient: 0.14417727487034418
20:20 Ratio: 2.1412429378531073
Max-min Ratio: 4.4375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_21-27-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1192.07
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 437
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.787
    dispatch_time_ms: 6.59
    learner:
      cur_lr: 0.00048687399248592556
      grad_gnorm: 40.0
      policy_entropy: 130.4500732421875
      policy_loss: -11.890369415283203
      var_gnorm: 23.829784393310547
      vf_explained_var: 0.0
      vf_loss: 28.320449829101562
    num_steps_sampled: 13140000
    num_steps_trained: 13140000
    wait_time_ms: 433.139
  iterations_since_restore: 438
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 19483.2845389843
  time_this_iter_s: 42.87722086906433
  time_total_s: 19483.2845389843
  timestamp: 1594171675
  timesteps_since_restore: 13140000
  timesteps_this_iter: 30000
  timesteps_total: 13140000
  training_iteration: 438
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 19483 s, 438 iter, 13140000 ts, 1.19e+03 rew

agent-1: 37.0
agent-2: 50.0
agent-3: 66.0
agent-4: 55.0
agent-5: 35.0
agent-6: 45.0
agent-7: 78.0
agent-8: 27.0
agent-9: 65.0
agent-10: 76.0
agent-11: 76.0
agent-12: 51.0
agent-13: 18.0
agent-14: 31.0
agent-15: 58.0
agent-16: 38.0
agent-17: 53.0
agent-18: 46.0
agent-19: 65.0
agent-20: 25.0
agent-21: 70.0
agent-22: 46.0
agent-23: 42.0
agent-24: 67.0
agent-25: 72.0
agent-26: 34.0
agent-27: 79.0
agent-28: 38.0
agent-29: 19.0
agent-30: 58.0
Sum Reward: 1520.0
Avg Reward: 50.666666666666664
Min Reward: 18.0
Max Reward: 79.0
Gini Coefficient: 0.20258771929824562
20:20 Ratio: 2.9285714285714284
Max-min Ratio: 4.388888888888889
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_21-28-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1195.5
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 438
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.719
    dispatch_time_ms: 5.847
    learner:
      cur_lr: 0.0004848760145250708
      grad_gnorm: 40.000003814697266
      policy_entropy: 128.51571655273438
      policy_loss: 68.84192657470703
      var_gnorm: 23.828052520751953
      vf_explained_var: 0.0
      vf_loss: 176.80160522460938
    num_steps_sampled: 13170000
    num_steps_trained: 13170000
    wait_time_ms: 393.431
  iterations_since_restore: 439
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 19527.326199769974
  time_this_iter_s: 44.04166078567505
  time_total_s: 19527.326199769974
  timestamp: 1594171719
  timesteps_since_restore: 13170000
  timesteps_this_iter: 30000
  timesteps_total: 13170000
  training_iteration: 439
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 19527 s, 439 iter, 13170000 ts, 1.2e+03 rew

agent-1: 47.0
agent-2: 33.0
agent-3: 69.0
agent-4: 69.0
agent-5: 47.0
agent-6: -1.0
agent-7: 61.0
agent-8: 54.0
agent-9: 13.0
agent-10: 22.0
agent-11: 38.0
agent-12: 35.0
agent-13: 67.0
agent-14: 46.0
agent-15: 44.0
agent-16: 37.0
agent-17: 47.0
agent-18: 34.0
agent-19: 38.0
agent-20: 34.0
agent-21: 76.0
agent-22: 46.0
agent-23: 33.0
agent-24: 26.0
agent-25: 35.0
agent-26: 47.0
agent-27: 16.0
agent-28: 36.0
agent-29: 62.0
agent-30: 28.0
Sum Reward: 1239.0
Avg Reward: 41.3
Min Reward: -1.0
Max Reward: 76.0
Gini Coefficient: 0.23198816249663706
20:20 Ratio: 3.8846153846153846
Max-min Ratio: -76.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_21-29-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1194.29
  episode_reward_min: 901.0
  episodes_this_iter: 1
  episodes_total: 439
  experiment_id: cdf9ac1f7ce845f7bc01bac176e20d18
  hostname: gpu019
  info:
    apply_time_ms: 2.47
    dispatch_time_ms: 6.119
    learner:
      cur_lr: 0.00048287800746038556
      grad_gnorm: 40.00000762939453
      policy_entropy: 131.63818359375
      policy_loss: -11.471931457519531
      var_gnorm: 23.83381462097168
      vf_explained_var: 0.0
      vf_loss: 29.78470230102539
    num_steps_sampled: 13200000
    num_steps_trained: 13200000
    wait_time_ms: 456.191
  iterations_since_restore: 440
  node_ip: 172.17.8.19
  num_metric_batches_dropped: 0
  pid: 10992
  policy_reward_mean: {}
  time_since_restore: 19570.987323999405
  time_this_iter_s: 43.66112422943115
  time_total_s: 19570.987323999405
  timestamp: 1594171763
  timesteps_since_restore: 13200000
  timesteps_this_iter: 30000
  timesteps_total: 13200000
  training_iteration: 440
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10992], 19570 s, 440 iter, 13200000 ts, 1.19e+03 rew

